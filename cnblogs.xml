<?xml version="1.0" encoding="UTF-8" ?>
    <rss version="2.0">
    <channel>
        <title><![CDATA[ 主页 - 博客园 ]]></title>
        <link><![CDATA[ https://www.cnblogs.com/ ]]></link>
        <lastBuildDate>2025-12-22T15:15:29.469Z</lastBuildDate>
        <description><![CDATA[
        主页 - 博客园 RSS
    ]]></description>
        <language>zh-cn</language>
        <item>
    <title><![CDATA[ Flink源码阅读：集群启动 ]]></title>
    <link>https://www.cnblogs.com/Jackeyzhe/p/19384633</link>
    <guid>d9127f876e0823c699dcd2b74b4260d9</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/Jackeyzhe/p/19384633" title="发布于 2025-12-22 22:44">
    <span role="heading" aria-level="2">Flink源码阅读：集群启动</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                    <div id="cnblogs_post_description" style="display: none">
        <img src="https://img2024.cnblogs.com/blog/1828322/202512/1828322-20251222224421655-1662683197.png" alt="Flink源码阅读：集群启动" class="desc_img">
        前文中，我们已经了解了 Flink 的三种执行图是怎么生成的。今天继续看一下 Flink 集群是如何启动的。
    </div>
<div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>前文中，我们已经了解了 Flink 的三种执行图是怎么生成的。今天继续看一下 Flink 集群是如何启动的。</p>
<h3 id="启动脚本">启动脚本</h3>
<p>集群启动脚本的位置在：</p>
<pre><code class="language-bash">flink-dist/src/main/flink-bin/bin/start-cluster.sh
</code></pre>
<p>脚本会负责启动 JobManager 和 TaskManager，我们主要关注 standalone 启动模式，具体的流程见下图。</p>
<p><img alt="startcluster" loading="lazy" data-src="https://res.cloudinary.com/dxydgihag/image/upload/v1764258366/Blog/flink/11/start-cluster.png" class="lazyload"></p>
<p>从图中可以看出 JobManager 是通过 jobmanager.sh 文件启动的，TaskManager 是通过taskmanager.sh 启动的，两者都调用了 flink-daemon.sh，通过传递不同的参数，最终运行不同的 Java 类。</p>
<pre><code class="language-bash">case $DAEMON in
    (taskexecutor)
        CLASS_TO_RUN=org.apache.flink.runtime.taskexecutor.TaskManagerRunner
    ;;

    (zookeeper)
        CLASS_TO_RUN=org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer
    ;;

    (historyserver)
        CLASS_TO_RUN=org.apache.flink.runtime.webmonitor.history.HistoryServer
    ;;

    (standalonesession)
        CLASS_TO_RUN=org.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint
    ;;

    (standalonejob)
        CLASS_TO_RUN=org.apache.flink.container.entrypoint.StandaloneApplicationClusterEntryPoint
    ;;

    (sql-gateway)
        CLASS_TO_RUN=org.apache.flink.table.gateway.SqlGateway
        SQL_GATEWAY_CLASSPATH="`findSqlGatewayJar`":"`findFlinkPythonJar`"
    ;;

    (*)
        echo "Unknown daemon '${DAEMON}'. $USAGE."
        exit 1
    ;;
esac
</code></pre>
<h3 id="jobmanager-启动流程">JobManager 启动流程</h3>
<p>在 StandaloneSessionClusterEntrypoint 的 main 方法中，主要就是加载各种配置和环境变量，然后调用 ClusterEntrypoint.runClusterEntrypoint 来启动集群。跟着调用链一直找到 ClusterEntrypoint.runCluster 方法，这里会启动 ResourceManager、DispatcherRunner 等组件。</p>
<pre><code class="language-java">private void runCluster(Configuration configuration, PluginManager pluginManager)
        throws Exception {
    synchronized (lock) {
        // 初始化各种服务
        initializeServices(configuration, pluginManager);

        // 创建 DispatcherResourceManagerComponentFactory，
        // 包含了三个核心组件的 Factory
        // DispatcherRunnerFactory、ResourceManagerFactory、RestEndpointFactory
        final DispatcherResourceManagerComponentFactory
                dispatcherResourceManagerComponentFactory =
                        createDispatcherResourceManagerComponentFactory(configuration);

        // 启动 ResourceManager、DispatcherRunner、WebMonitorEndpoint
        clusterComponent =
                dispatcherResourceManagerComponentFactory.create(
                        configuration,
                        resourceId.unwrap(),
                        ioExecutor,
                        commonRpcService,
                        haServices,
                        blobServer,
                        heartbeatServices,
                        delegationTokenManager,
                        metricRegistry,
                        executionGraphInfoStore,
                        new RpcMetricQueryServiceRetriever(
                                metricRegistry.getMetricQueryServiceRpcService()),
                        failureEnrichers,
                        this);

        // 关闭服务
        clusterComponent
                .getShutDownFuture()
                .whenComplete(
                        (ApplicationStatus applicationStatus, Throwable throwable) -&gt; {
                            if (throwable != null) {
                                shutDownAsync(
                                        ApplicationStatus.UNKNOWN,
                                        ShutdownBehaviour.GRACEFUL_SHUTDOWN,
                                        ExceptionUtils.stringifyException(throwable),
                                        false);
                            } else {
                                // This is the general shutdown path. If a separate more
                                // specific shutdown was
                                // already triggered, this will do nothing
                                shutDownAsync(
                                        applicationStatus,
                                        ShutdownBehaviour.GRACEFUL_SHUTDOWN,
                                        null,
                                        true);
                            }
                        });
    }
}
</code></pre>
<p>下面来详细看一下这几个方法， initializeServices 就是负责初始化各种服务，有几个比较重要的可以着重关注下：</p>
<pre><code class="language-java">// 初始化并启动一个通用的 RPC Service
commonRpcService = RpcUtils.createRemoteRpcService(...);

// 创建一个 IO 线程池，线程数量位 CPU 核数 * 4
ioExecutor = Executors.newFixedThreadPool(...);

// 创建 HA 服务组件，根据配置初始化 Standalone、ZK、K8S 三种
haServices = createHaServices(configuration, ioExecutor, rpcSystem);

// 创建并启动 blobServer,blobServer 可以理解为是 Flink 内部的
blobServer = BlobUtils.createBlobServer(...);
blobServer.start();

// 创建心跳服务
heartbeatServices = createHeartbeatServices(configuration);

// 创建一个监控服务
processMetricGroup = MetricUtils.instantiateProcessMetricGroup(...);
</code></pre>
<p>createDispatcherResourceManagerComponentFactory 这个方法就是创建了三个工厂类，不需要过多介绍。我们重点关注 dispatcherResourceManagerComponentFactory.create 方法，即 ResourceManager、DispatcherRunner、WebMonitorEndpoint 是如何启动的。</p>
<h4 id="webmonitorendpoint">WebMonitorEndpoint</h4>
<p>WebMonitorEndpoint 的启动流程图如下，图中细箭头代表同一个方法中顺序调用，粗箭头代表进入上一个方法内部的调用。</p>
<p><img alt="webMonitorEndpoint" loading="lazy" data-src="https://res.cloudinary.com/dxydgihag/image/upload/v1764428386/Blog/flink/11/webmonitor.png" class="lazyload"></p>
<p>WebMonitorEndpoint 创建和启动步骤如下：</p>
<ol>
<li>
<p>通过工厂创建出了 WebMonitorEndpoint，这里就是比较常规的初始化操作。</p>
</li>
<li>
<p>调用 WebMonitorEndpoint 的 start 方法开始启动，start 方法内部先是创建了一个 Router 并调用 initializeHandlers 创建了一大堆 handler（是真的一大堆，这个方法有接近一千行，都是在创建 handler），创建完成之后，对 handler 进行排序和去重，再把它们都注册到 Router 中。这里排序是为了确保路由匹配的正确性，排序规则是先静态路径（/jobs/overview），后动态路径（/jobs/:jobid），假如我们没有排序，先注册了 /jobs/:jobid ，后注册 /jobs/overview ，这时当我们请求 /jobs/overview 时，就会被错误的路由到 /jobs/:jobid 上去。</p>
</li>
<li>
<p>是调用 startInternal 方法，在 startInternal 方法内部只有 leader 选举和启动缓存清理任务两个步骤。</p>
</li>
</ol>
<h4 id="resourcemanager">ResourceManager</h4>
<p><img alt="ResourceManager" loading="lazy" data-src="https://res.cloudinary.com/dxydgihag/image/upload/v1764517440/Blog/flink/11/resourceManager.png" class="lazyload"></p>
<p>ResourceManager 创建和启动步骤如下：</p>
<ol>
<li>
<p>调用 ResourceManagerServiceImpl.create 方法创建 ResourceManagerService，这里只是创建 ResourceManager 服务，实际创建 ResourceManager 在后面的步骤中。</p>
</li>
<li>
<p>调用 resourceManagerService.start 方法启动服务，这里就是启动选主服务，standalne 模式直接调用 grantLeadership 成为 leader。</p>
</li>
<li>
<p>成为 leader 后，就会调用 startNewLeaderResourceManager 方法，这个方法中会调用 resourceManagerFactory.createResourceManager 正式创建 resourceManager。创建完成后，就会调用 resourceManager.start 来启动它。</p>
</li>
<li>
<p>启动后会回调 ResourceManager.onStart 方法。这里调用 startHeartbeatServices 启动了两个心跳服务，一个是 ResourceManager 和 TaskManager 之间的心跳，一个是 ResourceManager 和 JobManager 之间的心跳，然后会启动 SlotManager。SlotManager 可以被当作 Flink 集群的资源调度中心。它会负责管理集群中的所有 Slot 资源，也需要响应 JobManager 的资源请求。</p>
</li>
</ol>
<h4 id="dispatcherrunner">DispatcherRunner</h4>
<p><img alt="dispatcherRunner" loading="lazy" data-src="https://res.cloudinary.com/dxydgihag/image/upload/v1764578180/Blog/flink/11/dispatcherRunner.png" class="lazyload"></p>
<ol>
<li>
<p>先创建工厂，创建完成后调用 DefaultDispatcherRunner.create 创建出 DispatcherRunner，接着是调用 start 启动选主流程。</p>
</li>
<li>
<p>选主完成后就调用 startNewDispatcherLeaderProcess 启动新的流程。启动新的流程需要先关闭旧流程，然后创建新的 dispatcherLeaderProcess，并调用 start 启动。</p>
</li>
<li>
<p>启动时，会回调 onStart 方法。</p>
</li>
<li>
<p>回调方法中，先启动 executionPlanStore，它主要是用于持久化 JobGraph。然后恢复执行计划，重建状态（如果是从失败中恢复），实例化 Dispatcher，完成作业启动。</p>
</li>
</ol>
<h3 id="taskmanager-启动流程">TaskManager 启动流程</h3>
<p><img alt="taskManager" loading="lazy" data-src="https://res.cloudinary.com/dxydgihag/image/upload/v1764666573/Blog/flink/11/taskManager.png" class="lazyload"></p>
<p>TaskManager 是 Flink 的执行节点，其最小执行单元是 slot。TaskManager 启动流程也主要是和资源管理相关，包括 slot 列表的管理和与 ResourceManager 的通信。</p>
<p>TaskManager 启动流程大体分为以下几部分：</p>
<ol>
<li>
<p>构建并启动 TaskManagerRunner（蓝色部分）</p>
</li>
<li>
<p>启动 TaskExecutor（红色部分）</p>
</li>
<li>
<p>完成与 ResourceManager 的连接（橙色部分）</p>
</li>
</ol>
<h4 id="启动-taskmanagerrunner">启动 TaskManagerRunner</h4>
<p>在 TaskManagerRunner 的 start 方法中，有两个步骤：</p>
<p>第一步是调用 startTaskManagerRunnerServices 创建和启动了很多服务，这一点和 JobManager 的启动流程比较像。这些服务包括了高可用服务、心跳服务、监控指标服务等，这里也创建了 taskExecutorService，它的启动在第二步。</p>
<p>第二步是调用 taskExecutorService.start 方法，启动 TaskExecutorService，它内部主要负责启动 TaskExecutor。</p>
<h4 id="启动-taskexecutor">启动 TaskExecutor</h4>
<p>TaskExecutor 是 TaskManager 内部的一个核心组件，负责帮助 TaskManager 完成 task 的部署和执行等核心操作。</p>
<p>在上一步调用 taskExecutor 的 start 方法后，会回调 onStart 方法，这里主要是三个步骤</p>
<ol>
<li>
<p>连接 ResourceManager 以及注册监听</p>
</li>
<li>
<p>启动 taskSlotTable</p>
</li>
<li>
<p>连接 JobMaster 以及注册监听</p>
</li>
</ol>
<p>第一步我们在下面详细解释。第二步启动的 TaskSlotTable 是 TaskManager 中负责资源的核心组件，它维护了一个 Slot 列表，管理每个 Slot 的状态，负责 Slot 的分配和释放。第三步主要是和 JobMaster 建立连接并保持心跳，同时也会接收 Slot 申请的请求。</p>
<h4 id="连接-resourcemanager">连接 ResourceManager</h4>
<p>TaskExecutor 注册完监听之后，会收到 ResourceManagerLeaderListener.notifyLeaderAddress 方法回调。回调方法中，会创建一个 TaskExecutorToResourceManagerConnection 实例并启动它。这个类是用来将 TaskExecutor 注册到 ResourceManager，注册成功会回调 onRegistrationSuccess 方法。回调成功的方法中，TaskManager 会调用 resourceManagerGateway.sendSlotReport 将 Slot 的状态进行上报。</p>
<h3 id="总结">总结</h3>
<p>本文介绍了 Flink 集群在 Standalone 模式下的启动过程，其中 JobManager 重点介绍了 WebMonitorEndpoint、ResourceManager 和 DispatcherRunner 这三个组件的启动过程。TaskManager 主要介绍了启动 TaskExecutor 和连接 ResourceManager 的过程。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 22:45">2025-12-22 22:44</span>&nbsp;
<a href="https://www.cnblogs.com/Jackeyzhe">Jackeyzhe</a>&nbsp;
阅读(<span id="post_view_count">4</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384633);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384633', targetLink: 'https://www.cnblogs.com/Jackeyzhe/p/19384633', title: 'Flink源码阅读：集群启动' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ ROS2之URDF建模 ]]></title>
    <link>https://www.cnblogs.com/zyly/p/19384606</link>
    <guid>5d20f47004e2df5cd9a59e7d093453a6</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/zyly/p/19384606" title="发布于 2025-12-22 22:31">
    <span role="heading" aria-level="2">ROS2之URDF建模</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><code>ROS</code>是机器人操作系统，当然要给机器人使用啦，不过在使用之前，还得让<code>ROS</code>认识下我们使用的机器人，如何把一个机器人介绍给<code>ROS</code>呢？</p>
<p>为此，<code>ROS</code>专门提供了一种机器人建模方法——<code>URDF</code>，用来描述机器人外观、性能等各方面属性。</p>
<h3 id="一urdf语法">一、<code>URDF</code>语法</h3>
<h4 id="11-机器人的组成">1.1 机器人的组成</h4>
<p>建模描述机器人的过程中，我们自己需要先熟悉机器人的组成和参数，比如机器人一般是由硬件结构、驱动系统、传感器系统、控制系统四大部分组成，市面上一些常见的机器人，无论是移动机器人还是机械臂，我们都可以按照这四大组成部分进行分解。</p>
<img src="https://gitee.com/zyly2033/blog-pic/raw/master/202512222019489.png" style="zoom: 80%">
<p>其中：</p>
<ul>
<li>硬件结构就是底盘、外壳、电机等实打实可以看到的设备；</li>
<li>驱动系统就是可以驱使这些设备正常使用的装置，比如电机的驱动器，电源管理系统等；</li>
<li>传感系统包括电机上的编码器、板载的<code>IMU</code>、安装的摄像头、雷达等等，便于机器人感知自己的状态和外部的环境；</li>
<li>控制系统就是我们开发过程的主要载体了，一般是树莓派、电脑等计算平台，以及里边的操作系统和应用软件。</li>
</ul>
<p>机器人建模的过程，其实就是按照类似的思路，通过建模语言，把机器人每一个部分都描述清楚，再组合起来的过程。</p>
<h4 id="12-什么是urdf">1.2 什么是<code>URDF</code></h4>
<p><code>URDF</code>（<code>Unified Robot Description Format</code>，统一机器人描述格式）是一种<code>XML</code>格式的文件，用于从物理和逻辑上描述一个机器人模型。</p>
<p>你可以把它理解为机器人的“数字说明书或三维装配图，它告诉计算机：</p>
<ul>
<li>机器人由哪些零件（连杆、关节）组成；</li>
<li>这些零件长什么样（形状、尺寸、颜色）；</li>
<li>零件之间如何连接（位置、旋转、运动类型）；</li>
<li>零件的物理属性（质量、惯性）；</li>
</ul>
<h4 id="13-urdf组成">1.3 <code>URDF</code>组成</h4>
<p><code>URDF</code>主要描述两大核心元素：</p>
<ul>
<li>连杆（<code>Link</code>）：代表机器人的刚性部件，如机械臂的每一节臂杆、底盘、轮子、传感器支架等，包括：
<ul>
<li>视觉属性：形状（立方体、圆柱体、网格模型）、尺寸、颜色、纹理；</li>
<li>碰撞属性：用于物理仿真的简化几何形状；</li>
<li>惯性属性：质量、转动惯量（对仿真至关重要）。</li>
</ul>
</li>
<li>关节（<code>Joint</code>）：定义连杆之间的连接方式和运动关系，主要类型：
<ul>
<li>固定关节（<code>fixed</code>）：完全固定连接；</li>
<li>旋转关节（<code>revolute</code>）：绕单轴旋转，有角度限制（如机械臂关节）；</li>
<li>连续关节（<code>continuous</code>）：无限旋转（如轮子）；</li>
<li>平移关节（<code>prismatic</code>）：线性滑动；</li>
<li>平面关节（<code>planar</code>）：在平面内运动；</li>
<li>浮动关节（<code>floating</code>）：完全自由（<code>6</code>自由度）。</li>
</ul>
</li>
</ul>
<p>机器人描述由一组连杆元素和一组将连杆连接起来的关节元素组成；</p>
<img src="https://gitee.com/zyly2033/blog-pic/raw/master/202512222052818.png" style="zoom: 80%">
<p>因此，典型的机器人描述大致如下所示：</p>
<pre><code class="language-xml">&lt;?xml version="1.0"?&gt;
&lt;?xml-model href="https://raw.githubusercontent.com/ros/urdfdom/master/xsd/urdf.xsd" ?&gt;
&lt;robot name="pr2" xmlns="http://www.ros.org"&gt;
  &lt;link&gt; ... &lt;/link&gt;
  &lt;link&gt; ... &lt;/link&gt;
  &lt;link&gt; ... &lt;/link&gt;

  &lt;joint&gt;  ....  &lt;/joint&gt;
  &lt;joint&gt;  ....  &lt;/joint&gt;
  &lt;joint&gt;  ....  &lt;/joint&gt;
&lt;/robot&gt;
</code></pre>
<p>可以看到，<code>URDF</code>格式的根元素是一个 <code>&lt;robot&gt;</code> 元素。</p>
<h5 id="131-link元素">1.3.1 <code>link</code>元素</h5>
<p><code>link</code>元素描述了一个具有惯性、视觉特征和碰撞属性的刚体。以下是一个<code>link</code>元素的示例：</p>
<pre><code class="language-xml">&lt;link name="my_link"&gt;
  &lt;inertial&gt;
    &lt;origin xyz="0 0 0.5" rpy="0 0 0"/&gt;
    &lt;mass value="1"/&gt;
    &lt;inertia ixx="100"  ixy="0"  ixz="0" iyy="100" iyz="0" izz="100" /&gt;
  &lt;/inertial&gt;

  &lt;visual&gt;
    &lt;origin xyz="0 0 0" rpy="0 0 0" /&gt;
    &lt;geometry&gt;
      &lt;box size="1 1 1" /&gt;
    &lt;/geometry&gt;
    &lt;material name="Cyan"&gt;
      &lt;color rgba="0 1.0 1.0 1.0"/&gt;
    &lt;/material&gt;
  &lt;/visual&gt;

  &lt;collision&gt;
    &lt;origin xyz="0 0 0" rpy="0 0 0"/&gt;
    &lt;geometry&gt;
      &lt;cylinder radius="1" length="0.5"/&gt;
    &lt;/geometry&gt;
  &lt;/collision&gt;
&lt;/link&gt;
</code></pre>
<img src="https://gitee.com/zyly2033/blog-pic/raw/master/202512222058481.png" style="zoom: 80%">
<p><code>link</code>元素有一个属性，即<code>name</code>（必选）：用来描述连杆本身的名称.。此外，<code>link</code>包含若干部元素，接下来我们一一介绍。</p>
<h6 id="1311--惯性属性inertial">1.3.1.1  惯性属性<code>inertial</code></h6>
<p><code>inertial</code>（可选）：用于描述连杆的质量、其质心的位置以及其中心惯性属性。</p>
<p>其下可以包含如下元素：</p>
<ul>
<li><code>origin</code>（可选）：此位姿（平移、旋转）描述了连杆质心坐标系<code>C</code>相对于连杆坐标系<code>L</code>的位置和方向。
<ul>
<li><code>xyz</code> (可选)：表示从<code>Lo</code>（连杆坐标系原点）到<code>Co</code>（连杆质心）的位置向量，形式为 <code>x L̂x + y L̂y + z L̂z</code>，其中 <code>L̂x</code>、<code>L̂y</code>、<code>L̂z</code> 是连杆坐标系<code>L</code>的正交单位向量；</li>
<li><code>rpy</code>（可选）：表示<code>C</code>的单位向量<code>Ĉx</code>、<code>Ĉy</code>、<code>Ĉz</code>相对于连杆坐标系<code>L</code>的方向，以欧拉旋转（横滚<code>roll</code>、俯仰<code>pitch</code>、偏航<code>yaw</code>）序列表示，单位为弧度。注意：<code>Ĉx</code>、<code>Ĉy</code>、<code>Ĉz</code>不需要与连杆的惯性主轴对齐；</li>
</ul>
</li>
<li><code>mass</code>：连杆的质量由该元素的<code>value</code>属性表示；</li>
<li><code>inertia</code>：此连杆关于<code>Co</code>（连杆质心）的惯性矩<code>ixx</code>、<code>iyy</code>、<code>izz</code>和惯性积 <code>ixy</code>、<code>ixz</code>、<code>iyz</code>，这些值对应于固定在质心坐标系<code>C</code>中的单位向量<code>Ĉx</code>、<code>Ĉy</code>、<code>Ĉz</code>。注意：<code>Ĉx</code>、<code>Ĉy</code>、<code>Ĉz</code>相对于<code>L̂x</code>、<code>L̂y</code>、<code>L̂z</code> 的方向由 <code>&lt;origin&gt;</code> 标签中的<code>rpy</code>值指定。</li>
</ul>
<h6 id="1312-视觉属性visual">1.3.1.2 视觉属性<code>visual</code></h6>
<p><code>visual</code>（可选）：连杆的视觉属性，此元素指定了用于可视化目的的对象形状（长方体、圆柱体等）。</p>
<p>注意：同一个连杆可以存在多个 <code>&lt;visual&gt;</code> 标签实例。它们定义的几何体的并集形成了该连杆的视觉表示。</p>
<p>其下可以包含如下元素：</p>
<ul>
<li><code>origin</code> (可选)：视觉元素相对于连杆坐标系的参考坐标系；
<ul>
<li><code>xyz</code> (可选)：分别是<code>x</code>、<code>y</code>、<code>z</code>方向上的平移；</li>
<li><code>py</code> (可选)：表示固定轴的横滚、俯仰和偏航角度，单位为弧度；</li>
</ul>
</li>
<li><code>geometry</code>（必选）：表示几何形状，可以是以下之一：
<ul>
<li><code>&lt;box&gt;</code>
<ul>
<li><code>size</code>属性包含长方体的三个边长，长方体的原点位于其中心；</li>
</ul>
</li>
<li><code>&lt;cylinder&gt;</code>
<ul>
<li>指定半径和长度。圆柱体的原点位于其中心；</li>
</ul>
</li>
<li><code>&lt;sphere&gt;</code>
<ul>
<li>指定半径。球体的原点位于其中心；</li>
</ul>
</li>
<li><code>&lt;mesh&gt;</code>
<ul>
<li>由文件名指定的三角网格元素，以及一个可选的缩放比例，用于缩放网格的轴对齐边界框。任何几何格式都可以接受，但具体应用程序的兼容性取决于实现。对于最佳纹理和颜色支持，推荐的格式是 <code>Collada .dae</code>文件。引用同一模型的机器之间不会传输网格文件。它必须是本地文件。在文件名前加上 <code>package://&lt;packagename&gt;/&lt;path&gt;</code> 可以使网格文件的路径相对于包 <code>&lt;packagename&gt;</code>。</li>
</ul>
</li>
</ul>
</li>
<li><code>material</code>（可选）：视觉元素的材质，其<code>name</code>属性可以用于指定材质的名称；
<ul>
<li><code>&lt;color&gt;</code> (可选)
<ul>
<li><code>rgba</code>由一组四个数字（代表红/绿/蓝/透明度<code>alpha</code>）指定的材质颜色，每个数字的范围为 [<code>0</code>,<code>1</code>]；</li>
</ul>
</li>
<li><code>&lt;texture&gt;</code> (可选)
<ul>
<li>材质的纹理由文件名指定。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h6 id="1313-碰撞属性collision">1.3.1.3 碰撞属性<code>collision</code></h6>
<p><code>collision</code>用于描述碰撞参数，里边的内容似乎和<code>&lt;visual&gt;</code>一样，也有<code>&lt;geometry&gt;</code>和<code>&lt;origin&gt;</code>，看似相同，其实区别还是比较大的；</p>
<ul>
<li><code>origin</code> (可选)：碰撞元素相对于连杆坐标系的参考坐标系；
<ul>
<li><code>xyz</code> (可选)：分别是<code>x</code>、<code>y</code>、<code>z</code>方向上的平移；</li>
<li><code>py</code> (可选)：表示固定轴的横滚、俯仰和偏航角度，单位为弧度；</li>
</ul>
</li>
<li><code>geometry</code>：请参见上述视觉元素中的几何描述。</li>
</ul>
<h5 id="132-joint元素">1.3.2 <code>joint</code>元素</h5>
<p><code>joint</code>元素描述了关节的运动学和动力学特性，并指定了关节的安全限制。</p>
<p>以下是一个<code> join</code>t 元素的示例：</p>
<pre><code class="language-xml">&lt;joint name="my_joint" type="floating"&gt;
   &lt;origin xyz="0 0 1" rpy="0 0 3.1416"/&gt;
   &lt;parent link="link1"/&gt;
   &lt;child link="link2"/&gt;

   &lt;calibration rising="0.0"/&gt;
   &lt;dynamics damping="0.0" friction="0.0"/&gt;
   &lt;limit effort="30" velocity="1.0" lower="-2.2" upper="0.7" /&gt;
   &lt;safety_controller k_velocity="10" k_position="15" soft_lower_limit="-2.0" soft_upper_limit="0.5" /&gt;
&lt;/joint&gt;
</code></pre>
<p>下面图中，蓝色关节表示出一个运动的轴，蓝色关节是可以围绕蓝色的轴旋转的，也就是<code>child</code>这个<code>link</code>是可以围绕<code>joint</code>上下旋转。</p>
<p><code>joint</code>连接两个<code>link</code>，需要分一个主次关系，主关节是<code>parent link</code>，子关节是<code>child link</code>， 在<code>xml</code>形式的描述中这个两个<code>link</code>是必须存在的。</p>
<img src="https://gitee.com/zyly2033/blog-pic/raw/master/202512222129254.png" style="zoom: 80%">
<p><code>joint</code>元素有两个属性：</p>
<ul>
<li>
<p><code>name</code>（必须）：指定关节的唯一名称；</p>
</li>
<li>
<p><code>type</code>（必须）：指定关节的类型，类型可以是以下之一；</p>
<ul>
<li>
<p><code>revolute</code> ：旋转关节，和<code>continuous</code>类型的区别在于不能无限旋转，而是带有角度限制，比如机械臂的两个连杆，就属于这种运动；</p>
</li>
<li>
<p><code>continuous</code>：旋转关节，可以围绕单轴无限旋转；比如小车的轮子，就属于这种类型；</p>
</li>
<li>
<p><code>prismatic</code>：滑动关节，可以沿某一个轴平移，也带有位置的极限，一般直线电机就是这种运动方式；</p>
</li>
<li>
<p><code>fixed</code>：固定关节，是唯一一种不允许运动的关节，不过使用还是比较频繁的，比如相机这个连杆，安装在机器人上，相对位置是不会变化的，此时使用的连接方式就是<code>fixed</code>；</p>
</li>
<li>
<p><code>floating</code>：浮动关节，允许进行平移、旋转运动；</p>
</li>
<li>
<p><code>planar</code> ：平面关节，允许在平面正交方向上平移或者旋转；</p>
</li>
</ul>
</li>
</ul>
<p>此外，<code>joint</code>包含若干部元素，接下来我们挑选部分介绍介绍。</p>
<h6 id="1321-origin">1.3.2.1 <code>origin</code></h6>
<p><code>origin</code>（可选）：表示从父连杆到子连杆的变换，元素属性有：</p>
<ul>
<li><code>xyz</code> (可选)：表示<code>x</code>、<code>y</code>、<code>z</code> 偏移量，所有位置均以米为单位指定；</li>
<li><code>rpy</code> (可选)：表示绕固定轴的旋转：先绕<code>x</code>轴横滚（<code>roll</code>），然后绕<code>y</code>轴俯仰（<code>pitch</code>），最后绕<code>z</code>轴偏航（<code>yaw</code>），所有角度均以弧度为单位指定。</li>
</ul>
<h6 id="1322-parent">1.3.2.2 <code>parent</code></h6>
<p><code>parent</code>描述父连杆名称，元素属性有：</p>
<ul>
<li><code>link</code>：在机器人树结构中作为此连杆父连杆的连杆名称。</li>
</ul>
<h6 id="1323-child">1.3.2.3 <code>child</code></h6>
<p><code>child</code>描述子连杆名称，元素属性有：</p>
<ul>
<li><code>link</code>：作为子连杆的连杆名称。</li>
</ul>
<h6 id="1324-calibration-">1.3.2.4 <code>calibration </code></h6>
<p>关节的参考位置，用来校准关节的绝对位置。</p>
<h6 id="1325-dynamics--">1.3.2.5 <code>dynamics  </code></h6>
<p>描述关节的物理属性，例如阻尼值、物理静摩擦力等，经常在动力学仿真中用到。</p>
<h6 id="1326-limit---">1.3.2.6 <code>limit   </code></h6>
<p>描述运动的一些极限值，包括关节运动的上下限位置、速度限制、力矩限制等。</p>
<h6 id="1327-mimic---">1.3.2.7 <code>mimic   </code></h6>
<p>描述该关节与已有关节的关系。</p>
<h6 id="1328-safety_controller--">1.3.2.8 <code>safety_controller  </code></h6>
<p>描述安全控制器参数。保护机器人关节的运动。</p>
<h3 id="二urdf案例">二、<code>URDF</code>案例</h3>
<p>创建<code>my_learning_urdf</code>的<code>Python</code>版本的功能包；</p>
<pre><code class="language-shell">pi@NanoPC-T6:~/dev_ws$ cd src
pi@NanoPC-T6:~/dev_ws/src$ ros2 pkg create --build-type ament_python my_learning_urdf
</code></pre>
<p>在包中创建如下文件夹：</p>
<ul>
<li><code>urdf</code>：存放机器人模型的<code>URDF</code>或<code>xacro</code>文件；</li>
<li><code>meshes</code>：放置<code>URDF</code>中引用的模型渲染文件；</li>
<li><code>launch</code>：保存相关启动文件；</li>
<li><code>rviz</code>：保存<code>rviz</code>的配置文件。</li>
</ul>
<p>我们需要修改<code>setup.py</code>文件，添加配置文件：</p>
<pre><code class="language-python">import os
from glob import glob

    ...

    data_files=[
        ('share/ament_index/resource_index/packages',
            ['resource/' + package_name]),
        ('share/' + package_name, ['package.xml']),
        (os.path.join('share', package_name, 'launch'), glob(os.path.join('launch', '*.launch.py'))),
        (os.path.join('share', package_name, 'urdf'), glob(os.path.join('urdf', '*.*'))),
        (os.path.join('share', package_name, 'urdf/sensors'), glob(os.path.join('urdf/sensors', '*.*'))),
        (os.path.join('share', package_name, 'meshes'), glob(os.path.join('meshes', '*.*'))),
        (os.path.join('share', package_name, 'rviz'), glob(os.path.join('rviz', '*.rviz'))),
    ],

    ...
</code></pre>
<h4 id="21-模型文件">2.1 模型文件</h4>
<p>在<code>urdf</code>下新建文件<code>mbot_base.urdf</code>；</p>
<pre><code class="language-xml">&lt;?xml version="1.0" ?&gt;
&lt;robot name="mbot"&gt;

    &lt;link name="base_link"&gt;
        &lt;visual&gt;
            &lt;origin xyz=" 0 0 0" rpy="0 0 0" /&gt; &lt;!-- 机器人中心，坐标系原点 --&gt;
            &lt;geometry&gt;
                &lt;cylinder length="0.16" radius="0.20"/&gt; &lt;!-- 直径0.4m，高0.16m的圆柱 --&gt;
            &lt;/geometry&gt;
            &lt;material name="yellow"&gt;
                &lt;color rgba="1 0.4 0 1"/&gt; &lt;!-- 橙黄色 --&gt;
            &lt;/material&gt;
        &lt;/visual&gt;
    &lt;/link&gt;

    &lt;joint name="left_wheel_joint" type="continuous"&gt;
        &lt;origin xyz="0 0.19 -0.05" rpy="0 0 0"/&gt; &lt;!-- 位置：Y轴+0.19，Z轴-0.05 --&gt;
        &lt;parent link="base_link"/&gt;
        &lt;child link="left_wheel_link"/&gt;
        &lt;axis xyz="0 1 0"/&gt;  &lt;!-- 绕Y轴旋转 --&gt;
    &lt;/joint&gt;

    &lt;link name="left_wheel_link"&gt;
        &lt;visual&gt;
            &lt;origin xyz="0 0 0" rpy="1.5707 0 0" /&gt; &lt;!-- 旋转90度（π/2=1.5707） --&gt;
            &lt;geometry&gt;
                &lt;cylinder radius="0.06" length = "0.025"/&gt; &lt;!-- 半径0.06m，厚0.025m --&gt;
            &lt;/geometry&gt;
            &lt;material name="white"&gt;
                &lt;color rgba="1 1 1 0.9"/&gt;
            &lt;/material&gt;
        &lt;/visual&gt;
    &lt;/link&gt;

    &lt;joint name="right_wheel_joint" type="continuous"&gt;
        &lt;origin xyz="0 -0.19 -0.05" rpy="0 0 0"/&gt;
        &lt;parent link="base_link"/&gt;
        &lt;child link="right_wheel_link"/&gt;
        &lt;axis xyz="0 1 0"/&gt;
    &lt;/joint&gt;

    &lt;link name="right_wheel_link"&gt;
        &lt;visual&gt;
            &lt;origin xyz="0 0 0" rpy="1.5707 0 0" /&gt;
            &lt;geometry&gt;
                &lt;cylinder radius="0.06" length = "0.025"/&gt;
            &lt;/geometry&gt;
            &lt;material name="white"&gt;
                &lt;color rgba="1 1 1 0.9"/&gt;
            &lt;/material&gt;
        &lt;/visual&gt;
    &lt;/link&gt;

    &lt;joint name="front_caster_joint" type="continuous"&gt;
        &lt;origin xyz="0.18 0 -0.095" rpy="0 0 0"/&gt;
        &lt;parent link="base_link"/&gt;
        &lt;child link="front_caster_link"/&gt;
        &lt;axis xyz="0 1 0"/&gt;
    &lt;/joint&gt;

    &lt;link name="front_caster_link"&gt;
        &lt;visual&gt;
            &lt;origin xyz="0 0 0" rpy="0 0 0"/&gt;
            &lt;geometry&gt;
                &lt;sphere radius="0.015" /&gt;
            &lt;/geometry&gt;
            &lt;material name="black"&gt;
                &lt;color rgba="0 0 0 0.95"/&gt;
            &lt;/material&gt;
        &lt;/visual&gt;
    &lt;/link&gt;

    &lt;joint name="back_caster_joint" type="continuous"&gt;
        &lt;origin xyz="-0.18 0 -0.095" rpy="0 0 0"/&gt;
        &lt;parent link="base_link"/&gt;
        &lt;child link="back_caster_link"/&gt;
        &lt;axis xyz="0 1 0"/&gt;
    &lt;/joint&gt;

    &lt;link name="back_caster_link"&gt;
        &lt;visual&gt;
            &lt;origin xyz="0 0 0" rpy="0 0 0"/&gt;
            &lt;geometry&gt;
                &lt;sphere radius="0.015" /&gt;
            &lt;/geometry&gt;
            &lt;material name="black"&gt;
                &lt;color rgba="0 0 0 0.95"/&gt;
            &lt;/material&gt;
        &lt;/visual&gt;
    &lt;/link&gt;

&lt;/robot&gt;
</code></pre>
<p>这将会创建一个两轮差分驱动机器人的<code>URDF</code>模型，包含若干个部分。</p>
<h5 id="211-1个主体base_link">2.1.1 <code>1</code>个主体<code>base_link</code></h5>
<p>圆柱体（直径<code>0.4</code>米，高<code>0.16</code>米），橙黄色，机器人中心，坐标系原点。</p>
<h5 id="212-2个驱动轮左右轮">2.1.2 <code>2</code>个驱动轮（左右轮）</h5>
<p>分别为<code>left_wheel_link</code>、<code>right_wheel_link</code>：</p>
<ul>
<li><code>left_wheel_link</code>：
<ul>
<li>圆柱体（半径<code>0.06</code>米，厚度<code>0.025</code>米）；</li>
<li>在基座坐标系中 <code>(0, 0.19, -0.05)</code>；</li>
<li>关节类型：<code>continuous</code>（连续旋转关节，无限旋转）；</li>
<li>旋转轴：绕<code>Y</code>轴 <code>(0, 1, 0)</code>；</li>
<li>视觉旋转：<code>rpy="1.5707 0 0"</code> 将圆柱旋转90度，使其直立（假设原始圆柱是平放的）；</li>
</ul>
</li>
<li><code>right_wheel_link</code>：与左轮对称布置，<code>Y</code>坐标为负；</li>
</ul>
<h5 id="213-2个万向轮前后脚轮用于支撑">2.1.3 <code>2</code>个万向轮（前后脚轮，用于支撑）</h5>
<p>分别为<code>front_caster_link</code>、<code>back_caster_link</code>：</p>
<ul>
<li><code>front_caster_link</code>：
<ul>
<li>形状：小球体（半径<code>0.015</code>米），模拟万向轮；</li>
<li>在基座坐标系中前方 <code>(0.18, 0, -0.095)</code>；</li>
<li>颜色：黑色；</li>
</ul>
</li>
<li><code>back_caster_link</code>：与前万向轮对称布置，<code>X</code>坐标为负（<code>-0.18</code>）。</li>
</ul>
<h4 id="22-launch文件">2.2 <code>launch</code>文件</h4>
<p>在<code>launch</code>文件夹下创建<code>display.launch.py</code>文件；</p>
<pre><code class="language-python">from ament_index_python.packages import get_package_share_path

from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument
from launch.conditions import IfCondition, UnlessCondition
from launch.substitutions import Command, LaunchConfiguration

from launch_ros.actions import Node
from launch_ros.parameter_descriptions import ParameterValue

def generate_launch_description():
    urdf_tutorial_path = get_package_share_path('my_learning_urdf')
    # 设置默认的URDF文件和RViz配置文件路径
    default_model_path = urdf_tutorial_path / 'urdf/mbot_base.urdf'
    default_rviz_config_path = urdf_tutorial_path / 'rviz/urdf.rviz'

    # 命令行参数：--gui true/false，控制是否使用GUI界面发布关节状态
    gui_arg = DeclareLaunchArgument(name='gui', default_value='false', choices=['true', 'false'],
                                    description='Flag to enable joint_state_publisher_gui')
    
    # 命令行参数：--model &lt;路径&gt;，指定URDF文件路径
    model_arg = DeclareLaunchArgument(name='model', default_value=str(default_model_path),
                                      description='Absolute path to robot urdf file')
    
    # 命令行参数：--rvizconfig &lt;路径&gt;，指定RViz配置文件
    rviz_arg = DeclareLaunchArgument(name='rvizconfig', default_value=str(default_rviz_config_path),
                                     description='Absolute path to rviz config file')

    # 关键：使用xacro命令解析URDF文件（支持参数化、宏等高级特性）
    robot_description = ParameterValue(Command(['xacro ', LaunchConfiguration('model')]),
                                       value_type=str)
	
    # robot_state_publisher 节点
    robot_state_publisher_node = Node(
        package='robot_state_publisher',
        executable='robot_state_publisher',
        parameters=[{'robot_description': robot_description}]
    )

    # 关节状态发布器（二选一）
    # 文本版本（无GUI）
    joint_state_publisher_node = Node(
        package='joint_state_publisher',
        executable='joint_state_publisher',
        condition=UnlessCondition(LaunchConfiguration('gui'))
    )

    # GUI版本（带滑动条控制）
    joint_state_publisher_gui_node = Node(
        package='joint_state_publisher_gui',
        executable='joint_state_publisher_gui',
        condition=IfCondition(LaunchConfiguration('gui'))
    )

    # rviz2 可视化节点
    rviz_node = Node(
        package='rviz2',
        executable='rviz2',
        name='rviz2',
        output='screen',
        arguments=['-d', LaunchConfiguration('rvizconfig')],
    )

    return LaunchDescription([
        gui_arg,
        model_arg,
        rviz_arg,
        joint_state_publisher_node,
        joint_state_publisher_gui_node,
        robot_state_publisher_node,
        rviz_node
    ])
</code></pre>
<p>这个<code>Launch</code>文件主要做三件事：</p>
<ul>
<li>加载机器人<code>URDF</code>模型（支持<code>xacro</code>格式）；</li>
<li>发布机器人的状态变换（<code>TF</code>）；</li>
<li>在<code>rviz2</code>中可视化机器人。</li>
</ul>
<h5 id="221-节点">2.2.1 节点</h5>
<p>脚本运行会创建以下几个节点：</p>
<ul>
<li><code>joint_state_publisher</code>：发布每个<code>joint</code>（除<code>fixed</code>类型）的状态，一个无界面的、基础版的关节状态发布器；</li>
<li><code>joint_state_publisher_gui</code>：发布每个<code>joint</code>（除<code>fixed</code>类型）的状态，可以通过<code>UI</code>界面对<code>joint</code>进行控制；</li>
<li><code>robot_state_publisher</code>：将机器人各个<code>links</code>、<code>joints</code>之间的关系，通过<code>TF</code>的形式，整理成三维姿态信息发布。</li>
<li><code>rviz2</code>：在<code>rviz2</code>中可视化机器人；</li>
</ul>
<p><code>joint_state_publisher</code>这是一个官方<code>ROS2</code>包，主要功能：</p>
<ul>
<li>
<p>输入：</p>
<ul>
<li>
<p>读取<code>URDF</code>中的关节定义；</p>
</li>
<li>
<p>接收用户或程序指定的关节角度；</p>
</li>
</ul>
</li>
<li>
<p>输出：</p>
<ul>
<li>
<p>发布 <code>/joint_states</code> 话题，消息类型为 <code>sensor_msgs/msg/JointState</code>；</p>
</li>
<li>
<p>包含所有关节的名称、位置、速度、力等信息。</p>
</li>
</ul>
</li>
</ul>
<h5 id="222-数据流与节点关系">2.2.2 数据流与节点关系</h5>
<p>数据流与节点关系:</p>
<pre><code class="language-tex">用户通过滑动条/GUI或程序 → joint_state_publisher(_gui)
                                     ↓ 发布/joint_states话题
                        robot_state_publisher
                                     ↓ 计算并发布TF变换
                              rviz2 和其他节点
                                     ↓ 接收TF并可视化
</code></pre>
<h4 id="23-urdfrviz">2.3 <code>urdf.rviz</code></h4>
<p>在<code>rviz</code>目录下新建<code>urdf.rviz</code>文件；</p>
<pre><code class="language-yaml">Panels:
  - Class: rviz_common/Displays
    Name: Displays
  - Class: rviz_common/Views
    Name: Views
Visualization Manager:
  Class: ""
  Displays:
    - Class: rviz_default_plugins/Grid
      Name: Grid
      Value: true
    - Alpha: 0.8
      Class: rviz_default_plugins/RobotModel
      Description Source: Topic
      Description Topic:
        Value: /robot_description
      Enabled: true
      Name: RobotModel
      Value: true
    - Class: rviz_default_plugins/TF
      Name: TF
      Value: true
  Global Options:
    Fixed Frame: base_link
    Frame Rate: 30
  Name: root
  Tools:
    - Class: rviz_default_plugins/MoveCamera
  Value: true
  Views:
    Current:
      Class: rviz_default_plugins/Orbit
      Distance: 1.7
      Name: Current View
      Pitch: 0.33
      Value: Orbit (rviz)
      Yaw: 5.5
Window Geometry:
  Height: 800
  Width: 1200
</code></pre>
<h4 id="24-编译运行">2.4 编译运行</h4>
<p>编译程序：</p>
<pre><code class="language-shell">pi@NanoPC-T6:~/dev_ws$ colcon build --paths src/my_learning_urdf
pi@NanoPC-T6:~/dev_ws$ source install/setup.sh
</code></pre>
<h5 id="241-可视化">2.4.1 可视化</h5>
<p>启动终端，运行如下命令；</p>
<pre><code class="language-shell">pi@NanoPC-T6:~/dev_ws$ ros2 launch my_learning_urdf display.launch.py
</code></pre>
<p>很快就可以看到<code>rviz</code>中显示的机器人模型啦，大家可以使用鼠标拖拽观察；</p>
<img src="https://gitee.com/zyly2033/blog-pic/raw/master/202512222247733.png" style="zoom: 80%">
<p>从可视化的效果来看，这个机器人由五个<code>link</code>和4个<code>joint</code>组成。</p>
<h5 id="242-查看urdf模型结构">2.4.2 查看<code>URDF</code>模型结构</h5>
<p>我们分析的对不对呢，可以在模型文件的路径下，使用<code>urdf_to_graphviz</code>这个小工具来分析下;</p>
<pre><code class="language-shell">pi@NanoPC-T6:~/dev_ws/src/my_learning_urdf/urdf$ urdf_to_graphviz mbot_base.urdf
WARNING: OUTPUT not given. This type of usage is deprecated!Usage: urdf_to_graphviz input.xml [OUTPUT]  Will create either $ROBOT_NAME.gv &amp; $ROBOT_NAME.pdf in CWD  or OUTPUT.gv &amp; OUTPUT.pdf.
Created file mbot.gv
Created file mbot.pdf

pi@NanoPC-T6:~/dev_ws/src/my_learning_urdf/urdf$ ls
mbot_base.urdf  mbot.gv  mbot.pdf
</code></pre>
<p>运行成功后会产生一个<code>pdf</code>文件，打开之后就可以看到<code>URDF</code>模型分析的结果啦，是不是和我们的猜测完全相同呢！</p>
<img src="https://gitee.com/zyly2033/blog-pic/raw/master/202512222230527.png" style="zoom: 80%">
<p><strong>参考文章</strong></p>
<p><strong>[1] <a href="https://book.guyuehome.com/ROS2/3.%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/3.3_URDF/" target="_blank" rel="noopener nofollow">古月居<code>ROS2</code>入门教程学习笔记</a></strong></p>
<p><strong>[2] <a href="https://zhuanlan.zhihu.com/p/341599469" target="_blank" rel="noopener nofollow"><code>ROS</code>中阶笔记（二）：机器人系统设计—<code>URDF</code>机器人建模</a></strong></p>
<p><strong>[3] <a href="https://wiki.ros.org/urdf/XML/model" target="_blank" rel="noopener nofollow"><code>XML Robot Description Format</code> (<code>URDF</code>)</a></strong></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.017361111111111112" data-date-updated="2025-12-22 22:56">2025-12-22 22:31</span>&nbsp;
<a href="https://www.cnblogs.com/zyly">大奥特曼打小怪兽</a>&nbsp;
阅读(<span id="post_view_count">4</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384606);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384606', targetLink: 'https://www.cnblogs.com/zyly/p/19384606', title: 'ROS2之URDF建模' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 化整为零、分而治之、异步编排：一文读懂现代并发的底层心法 ]]></title>
    <link>https://www.cnblogs.com/poemyang/p/19384431</link>
    <guid>705b50635a578b80efd5de08849cf652</guid>
    <description>
    <![CDATA[ 
        <h2 class="post-title">
            <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/poemyang/p/19384431" title="发布于 2025-12-22 21:34">
    <span role="heading" aria-level="2">化整为零、分而治之、异步编排：一文读懂现代并发的底层心法</span>
    

</a>

        </h2>
        <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><strong>LongAdder：化整为零，热点分散</strong><br>
在Java多线程编程中，‌原子变量（如AtomicLong）‌通过CAS操作实现线程安全的累加。然而，在高并发场景下，大量线程争抢同一原子变量会引发严重的‌缓存一致性问题‌。<br>
‌ 1）缓存行伪共享‌：多个线程频繁更新同一缓存行，导致缓存失效和MESI协议频繁触发，处理器性能急剧下降。<br>
‌ 2）CAS冲突开销‌：CAS操作需自旋重试，线程竞争激烈时重试次数增加，进一步拖慢性能。<br>
为解决上述瓶颈，Java 8引入了‌LongAdder‌，其核心思想是‌“分散竞争，延迟求和‌”。<br>
‌ 1）分段累加‌：将单一累加变量拆分为多个‌分段变量（cells）‌，每个线程仅更新其专属的分段，避免全局竞争。<br>
‌ 2）基础值优化‌：在低并发场景下，直接更新基础值（base），减少分段数组的开销。<br>
‌ 3）最终一致性求和‌：通过遍历所有分段和基础值，延迟计算总和，降低实时竞争压力。<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/757914/202512/757914-20251222213334386-1756695412.png" class="lazyload"></p>
<p>LongAdder的内部实现原理，可以用下面的伪代码演示。</p>
<pre><code class="language-java">public class LongAdder {
    private final AtomicLong[] cells; // 分段数组，每个线程映射到特定分段
    private final AtomicLong base;    // 基础值，低并发时直接更新

    public LongAdder() {
        cells = new AtomicLong[16]; // 假设初始化16个分段
        for (int i = 0; i &lt; cells.length; i++) {
            cells[i] = new AtomicLong(0); // 初始化分段值为0
        }
        base = new AtomicLong(0); // 初始化基础值为0
    }

    public void add(long x) {
        // 1. 计算线程对应的分段索引（简单取模实现）
        int index = (int) (Thread.currentThread().getId() % cells.length);
        // 2. 对专属分段执行CAS累加，避免全局竞争
        cells[index].addAndGet(x);
    }

    public long sum() {
        // 3. 求和：累加基础值和所有分段值
        long sum = base.get();
        for (AtomicLong cell : cells) {
            sum += cell.get();
        }
        return sum;
    }
}
</code></pre>
<p>然而，LongAdder 并非万能钥匙。在并发度较低的场景，AtomicLong 的简单直接反而更高效，就好比小型聚会中，大家直接共享一个果盘更方便，而不需要多个果篮。另外，当需要频繁读取累计结果时，LongAdder 的汇总过程就像逐个篮子统计水果数量，略显繁琐，性能会受影响。Fork/Join：分而治之，任务窃取<br>
Java 7 引入的 ‌Fork/Join Framework‌ 是一种强大的并行编程模型，专为解决“分而治之”（Divide and Conquer）类型的问题而设计。它充分利用多核处理器的计算能力，通过分解任务、并行执行和合并结果，显著提升程序的执行效率。<br>
Fork/Join特别适合处理可以被分解成独立子任务的问题，以实现任务的并行执行，如排序、搜索等。<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/757914/202512/757914-20251222213344110-564578910.png" class="lazyload"></p>
<pre><code class="language-java">if (任务足够小) {
    直接计算并返回结果;
} else {
    将任务拆分为N个子任务;
    对每个子任务调用 fork() 进行并行计算;
    调用 join() 合并子任务的结果;
    返回最终结果;
}
</code></pre>
<p>在Java 8中引入的并行流计算（Parallel stream computing），内部就是采用的ForkJoinPool来实现的。例如，下面使用并行流实现数组并行求和计算。</p>
<pre><code class="language-java">public class SumArray {
    public static void main(String[] args) {
        List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9);
         // map在实际编程中，可以是耗时高，计算量大的任务
        int sum = numbers.parallelStream().map(i -&gt; i * i).reduce(0, Integer::sum);
    }
}
</code></pre>
<p><strong>并行编程模型</strong><br>
并行编程模型（Parallel programming model）是一种用于描述和组织并行计算的框架或范式。它提供了一组抽象概念、编程接口和规范，用于指导开发者在多核处理器、分布式系统或并行计算环境中编写并行程序。<br>
常见的并行编程模型包括：数据并行（Data parallelism）、任务并行（Task parallelism）、多线程并行（Multithread parallelism）等。工作窃取<br>
工作窃取（Work Stealing）是一种高效的并行计算调度策略，其主要目标是解决负载不均衡问题，以充分利用所有的处理器核心，从而提升程序的执行效率。<br>
在工作窃取模型中，每个处理器都维护着自己的双端队列（Deque），用于存储分配给自己的任务。当一个处理器完成了所有自己的任务后，它会尝试从其他处理器的任务队列的末尾“窃取”任务来执行。这种策略确保了所有的处理器都能尽可能地保持忙碌状态，从而提高整体的并行性能。<br>
工作窃取策略的一个显著优点是其能够动态地平衡负载。这意味着它能够适应各种不同的任务分布和处理器性能，从而在各种情况下都能提供优秀的性能。<br>
在实际编程实践中，工作窃取调度策略通常由并行编程框架或库来实现。例如，Java的Fork/Join框架就采用了工作窃取策略来动态地分配任务，C++的Intel TBB（Threading Building Blocks）库也使用了类似的策略。<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/757914/202512/757914-20251222213355165-1177992061.png" class="lazyload"></p>
<p><strong>CompletableFuture：构建优雅的异步流水线</strong><br>
CompletableFuture 是 Java 8 引入的一个核心类，它实现了 Future 接口，并在其基础上提供了更强大、更灵活的异步编程能力。与传统的 Future 相比，CompletableFuture 不仅能够表示一个异步计算的结果，还支持丰富的函数式编程特性，使得开发者能够以声明式的方式处理异步任务的执行流程。<br>
CompletableFuture 的核心优势在于其支持链式调用（Chaining），允许在一个 CompletableFuture 上附加多个操作（如转换结果、处理异常、组合多个任务等）。这些操作会在 CompletableFuture 完成时自动触发，从而形成一个流水线式的任务处理流程。<br>
‌ 以下是一个简单的示例，展示了 ‌CompletableFuture‌ 的链式调用。</p>
<pre><code class="language-java">// supplyAsync方法用于启动一个异步任务，thenApply方法用于在任务完成时对结果进行转换
CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; {
     ......
    // 异步任务，模拟网络请求
    return "Hello";
}).thenApply(result -&gt; {
    // 对结果进行转换
    return result + " World";
});
// 主线程等待异步操作完成
future.join();
// 获取异步执行结果
future.get();
</code></pre>
<p><strong>异步编程</strong><br>
异步编程是一种高效的编程范式，旨在优化程序的执行效率和资源利用率。它通过允许程序在等待耗时操作（如网络请求、文件I/O等）完成的同时，继续执行其他任务，从而避免了传统同步编程中的线程阻塞问题。这种非阻塞的执行方式显著提升了程序的响应速度和并发处理能力，尤其适用于I/O密集型任务。<br>
在传统的同步编程模型中，当一个操作需要较长时间完成时，程序会停滞在该操作上，直到操作结束，这种现象称为阻塞。相比之下，异步编程模型允许程序在启动一个耗时操作后，立即转而执行其他任务，而无需等待该操作完成。当操作完成后，程序会通过回调、事件或Future等机制收到通知，并处理操作结果。<br>
异步编程在多种编程语言中都有应用和实现。例如，Java中的CompletableFuture、JavaScript中的Promise，以及Python中的asyncio库等，都提供了强大的异步编程支持。<br>
以下是一个简单的同步与异步读取文件的对比示例（伪代码）。</p>
<pre><code class="language-java">// 同步执行读取文件操作
let a = read("a.txt");
// 同步等待上次一次文件操作完成
let b = read("b.txt");
// 假设单个文件读取耗时50ms，一共需要耗时100ms
print(a+b)

// 异步执行读取文件操作
let op_a = read_async("a.txt");
let op_b = read_async("b.txt");
let a = wait_until_get_ready(op_a);
let b = wait_until_get_ready(op_b);
// 假设单个文件读取耗时50ms， 由于两次读取文件操作同时异步执行，最终耗时50ms
print(a+b);

fn wait_until_get_ready(Operation) -&gt; Response {
  // 阻塞任务，挂起线程，直到operation就绪再唤醒线程（唤醒操作，需要操作系统和硬件的底层支撑）
}
</code></pre>
<p>异步编程可以更有效地处理并发问题。当程序需要同时处理多个任务时，异步编程可以让这些任务并发执行，而不是按顺序一个接一个地执行。然而，异步编程的实现离不开操作系统和硬件的底层支持。如果在异步任务执行完之前，处理线程一直对异步任务执行状态进行空轮询，这将会浪费处理器资源。因此，操作系统和硬件的底层支持，如Linux系统支持的select、poll、epoll等技术，对于异步编程的实现至关重要。<br>
以下是一个没有底层支持时，异步编程可能面临的问题的示例（伪代码）。</p>
<pre><code class="language-java">let op_a = read_async("a.txt");
let a = "";
// 如果没有操作系统和硬件的底层支撑，将不断轮询op_a的任务状态
while true {
  if op_a.is_finish() {
    a = op_a.get_content();
    break;
  }
}
print(a);
</code></pre>
<p><strong>链式调用</strong><br>
“回调地狱”（Callback Hell）是异步编程中常见的一个问题，尤其在 JavaScript 等单线程、事件驱动型语言中尤为突出。当多个异步操作需要按照特定顺序执行时，开发者可能不得不在一个回调函数中嵌套另一个回调函数，导致代码层级过深、可读性差、难以维护。<br>
以下是一个典型的“回调地狱”示例（JavaScript）。</p>
<pre><code class="language-java">login(user =&gt; {
    getStatus(status =&gt; {
        getOrder(order =&gt; {
            getPayment(payment =&gt; {
                getRecommendAdvertisements(ads =&gt; {
                    setTimeout(() =&gt; {
                        alert(ads)
                    }, 1000)
                })
            })
        })
    })
})
</code></pre>
<p>链式调用（Chaining）成为一种常用的优化手段。在 JavaScript 中，‌Promise‌ 机制提供了链式调用的能力。每个 ‌Promise‌ 对象都包含一个 ‌then‌ 方法，该方法返回一个新的 ‌Promise‌ 对象，从而允许开发者将多个异步操作串联起来，形成清晰的逻辑流。<br>
以下是一个使用 ‌Promise‌ 链式调用的示例（JavaScript）。</p>
<pre><code class="language-java">login(username, password)
    .then(user =&gt; getStatus(user.id))
    .then(status =&gt; getOrder(status.id))
    .then(order =&gt; getPayment(order.id))
    .then(payment =&gt; getRecommendAdvertisements(payment.total_amount))
    .then(ads =&gt; {/*...*/});
</code></pre>
<p>需要注意的是，‌Promise‌ 并不是一种可以将同步代码转变为异步代码的魔法工具。它只是一种编程手法，或者说是一种封装方式，并没有借助操作系统的额外能力。‌Promise‌ 的主要作用是提供了一种更优雅的方式来组织和管理异步操作，使得代码更易于阅读和理解。</p>
<p><strong>总结：与硬件共舞，与冲突和解</strong><br>
Disruptor的环形缓冲、LongAdder的分散热点、Fork/Join的工作窃取、CompletableFuture的异步编排——这些看似迥异的技术，实则殊途同归。它们共同揭示了现代并发设计的核心要义：与其在冲突发生后被动地加锁仲裁，不如在设计之初就主动地消除冲突。<br>
这标志着并发编程的关注点，已从“如何正确加锁”的战术层面，升华为“如何精妙分工、避免锁”的战略高度。<br>
当摩尔定律的红利逐渐消退，真正的性能突破不再依赖于硬件的暴力堆砌，而是源于软件层面与硬件底层机制的“共舞”。无论是利用缓存行特性的内存对齐，还是借助CAS原子指令的乐观更新，每一次技术优化都印证了一个理念：硬件性能的极致发挥，源于对计算本质的深刻理解。这正是并发编程从技术迈向艺术的精髓所在。</p>
<p><strong>很高兴与你相遇！如果你喜欢本文内容，记得关注哦!!!</strong></p>

</div>
<div id="MySignature" role="contentinfo">
    <p>本文来自博客园，作者：<a href="https://www.cnblogs.com/poemyang/" target="_blank">poemyang</a>，转载请注明原文链接：<a href="https://www.cnblogs.com/poemyang/p/19384431" target="_blank">https://www.cnblogs.com/poemyang/p/19384431</a></p>
</div>
<div class="clear"></div>

        <p class="postfoot">
            posted on 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 21:34">2025-12-22 21:34</span>&nbsp;
<a href="https://www.cnblogs.com/poemyang">poemyang</a>&nbsp;
阅读(<span id="post_view_count">6</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384431);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384431', targetLink: 'https://www.cnblogs.com/poemyang/p/19384431', title: '化整为零、分而治之、异步编排：一文读懂现代并发的底层心法' })">举报</a>

        </p>
     ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 从源码角度解析C++20新特性如何简化线程超时取消 ]]></title>
    <link>https://www.cnblogs.com/apocelipes/p/19384377</link>
    <guid>f70ef329719078d279e9912cea847e9a</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/apocelipes/p/19384377" title="发布于 2025-12-22 21:15">
    <span role="heading" aria-level="2">从源码角度解析C++20新特性如何简化线程超时取消</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>C++20中增加了很多重量级新特性，它不仅带来了ranges、concept和协程，也为多线程编程带来了jthread和stop_source这些强力辅助。利用这些新特性，我们可以更高效地编写并发程序。</p>
<p>今天要说的就是利用jthread和stop_source来简化线程超时控制的实现，最终我们可以实现一个简单高效、可维护性不输给号称“天生支持并发”的Go语言的版本。</p>
<h2 id="为什么需要超时控制">为什么需要超时控制</h2>
<p>超时控制是很常见的需求，最普遍的场景是为了防止程序卡住或者长时间占用资源，程序会主动取消掉一些超过允许运行时间的或者无响应的线程，比如一些耗时很长的网络连接处理线程等。当然用户等得不耐烦了手动点击取消任务执行也勉强可以算在内。</p>
<p>通常超时发生或者用户点击取消之后，我们都期待线程能迅速终止执行并让整个程序保持一个完整且安全的状态。然而现实是复杂的，想实现上述功能对于线程来说是一件难事，尤其在Linux系统上。</p>
<p>第一个难点是如何让线程知道自己要退出。对于进程来说这不是难点，因为不管进程在做什么，我们都可以靠向其发送信号来立即中断进程的执行（前提是线程没有屏蔽这个信号），这样进程的停止请求可以被立即感知到，进程从而可以尽快完成善后工作退出执行。同样的招数对多线程程序来说就没那么好用了——信号默认是发给整个进程的，为了能让每个线程独立地接收信号，我们需要保存线程的标识符并在每个线程中设置接收和屏蔽信号的mask，这大大增加了程序的复杂性；其次信号处理函数是整个进程内所有线程共享的，我们需要额外的手段来保证并发安全，同时还得兼顾信号处理函数需要可重入、快速执行的最佳实践，这会提高程序的开发难度。</p>
<p>第二个难点在于如何保证线程一定会退出执行。前面说到信号可以打断进程的执行，但这只是通知，实际上进程完全可以在信号处理函数返回后无视这个通知继续运行，或者有一种更普遍的场景——程序正好卡在某个系统调用上，而程序又设置了系统调用被信号中断后自动重启，这样即使我们有效通知了进程，进程也会在收完通知之后再次进入系统调用从而无法响应停止请求。所以作为保底手段，Linux可以发送<code>SIGKILL</code>这个信号强制终止进程，这个信号无法捕获也无法屏蔽，是我们货真价实的“底牌”。</p>
<p>上述的情况在多线程中同样存在，而且我们没有“底牌”可用——因为不管给哪个线程发送<code>SIGKILL</code>，都会杀死整个进程而不是单独接收到信号的那个线程。另外即使有办法强制终止线程（比如早期的JVM），我们还会遇到资源释放的问题。进程退出执行之后，内核会尽可能释放进程持有的所有资源，打开的文件会被关闭，缓冲区的内容会被刷新，文件锁之类的同步机制也会正常解锁；但线程并没有这种自动清理机制，清理工作完全需要手动执行，一旦进程没有释放自己持有的资源就退出，系统就会遇到各种数据损坏和死锁等并发问题，排查和修复会极其困难。</p>
<p>为了克服上述难点并安全高效地实现终止超时线程的执行，我们需要一些额外的控制手段。这也一直都是开发者中的热门话题。</p>
<p>在介绍C++20如何简化超时控制之前，我们先来看看前人的智慧成果。</p>
<h2 id="golang实现超时控制">Golang实现超时控制</h2>
<p>Golang是天生支持并发的语言，这一点可谓名副其实，尤其是在超时控制上。</p>
<p>我们直接看个例子，例子里有主线程和工作线程，工作线程超时时间为5秒，如果超过这个时间还有线程没完成工作，就取消所有线程的执行。Golang里没有系统级的线程，但我们可以用goroutine模拟。</p>
<p>在工作线程中我们用sleep代替耗时的工作，这样便于测试：</p>
<pre><code class="language-golang">func Work(ctx context.Context, id int) error {
	for range 10 {
		select {
		case &lt;-ctx.Done():
			fmt.Printf("worker %d: canceled\n", id)
			return ctx.Err()
		default:
		}
		if rand.IntN(2) == 0 {
			time.Sleep(500 * time.Millisecond)
		} else {
			time.Sleep(time.Second)
		}
	}
	fmt.Printf("worker %d: done\n", id)
	return nil
}
</code></pre>
<p>超时控制是<code>ctx</code>参数实现的，每次循环处理前我们都会主动检查线程是否需要退出，这种协作式的“请求-检查-响应”是各种语言中取消线程执行的常见做法。</p>
<p>这个工作函数执行时间在5秒到10秒之间，取值的步长在0.5秒，加上go标准库默认随机数是均匀分布的，所以整体执行时间的概率是正态分布的，在7.5秒左右我们很容易看到超时和正常运行结束两种情况。所以我们把超时时间分别设为4秒、7.5秒、11秒，来进行模拟运行实验：</p>
<pre><code class="language-golang">func main() {
    // 从命令行获取超时时间，单位毫秒
    timeout, err := strconv.Atoi(os.Args[1])
    if err != nil {
        panic(err)
    }
	ctx, cancel := context.WithTimeout(context.Background(), time.Duration(timeout)*time.Millisecond)
	now := time.Now()
	defer cancel()
	g := &amp;errgroup.Group{}
	for i := range 3 {
		g.Go(func() error {
			return Work(ctx, i)
		})
	}
	err = g.Wait()
	fmt.Printf("run time: %s\n", time.Since(now))
	if err != nil {
		if errors.Is(err, context.DeadlineExceeded) {
			fmt.Println("Tasks canceled")
			return
		}
		panic(err)
	}
	fmt.Println("All work done!")
}
</code></pre>
<p>代码很简单，关键在这行：<code>ctx, cancel := context.WithTimeout(context.Background(), 7500*time.Millisecond)</code>，只要我们设定的时间到了，<code>&lt;-ctx.Done()</code>就会从阻塞变为非阻塞，循环开始处的检查会发现这个变化，然后会退出线程的执行。代码中使用了<code>errgroup</code>，但这不是必须的，实际上有很多办法可以通知主线程，这里我选择了一种最通用的，代价是代码会稍微复杂一些。</p>
<p>运行代码，会看到下面这样的输出，结果有很大的随机成分，下面只是无数种可能中的一种：</p>
<pre><code class="language-console">$ go build -o test

$ ./test 4000
worker 1: canceled
worker 0: canceled
worker 2: canceled
run time: 4.00431275s
Tasks canceled

$ ./test 7500
worker 0: done
worker 2: done
worker 1: canceled
run time: 7.507776458s
Tasks canceled

$ ./test 11000
worker 1: done
worker 2: done
worker 0: done
run time: 8.509193125s
All work done!
</code></pre>
<p>可以看到超时控制发挥了作用，尽管内置的time计时有一些误差，但程序的总体的运行时间是小于等于超时时间的。</p>
<p>Golang的超时控制可以通过<code>context</code>简单实现，但需要工作线程主动检查主动配合，前文我们也提到了强制终止工作线程很可能会造成并发问题，因此所有的线程超时控制中都是采用的这种协作式退出机制，即使天生并发的语言也不能免俗。作为代价，我们需要谨慎编码以免工作线程无法响应退出请求，同时还需要付出一点在循环里检查是否需要退出执行的性能损失。</p>
<h2 id="c中的典型超时控制实现">C++中的典型超时控制实现</h2>
<p>c++没有方便好用的<code>context</code>，想要实现协作式退出得自己造轮子。</p>
<p>Golang好用是因为标准库和运行时调度器隐藏了实现的细节：<code>WithTimeout</code>实际上会创建一个定时器，到时间后调度器会执行定时器的回调函数主动关闭<code>ctx</code>内部的channel，这样<code>&lt;-ctx.Done()</code>就会从阻塞变成非阻塞，协程就能检查到这一变化从而退出执行。</p>
<p>核心只在于两点，以合适的方法标记线程已被取消和异步地在超时后设置取消标记。</p>
<p>第一点很容易解决，使用原子变量即可。第二点的异步通知有些棘手，但我们还是有几种选择：</p>
<ol>
<li>使用alarm和信号: <code>alarm</code>会注册一个定时器，到时间后给进程发送<code>SIGALRM</code>信号，虽说多线程程序里不推荐用信号，但在这个场景下在信号处理函数里设置原子变量是合适的，另外使用<code>alarm(0)</code>可以取消之前注册的定时器。</li>
<li>使用多线程：我们可以另外创建一个线程，并在其中等待到超时时间过去之后设置标志，这样主线程也不会阻塞。</li>
</ol>
<p>当然两个方案各有缺点：</p>
<ol>
<li><code>alarm</code>是整个进程共享的，且同时只能设置一个定时器，最后它只能设置秒级精度的超时时间；使用<code>setitimer</code>可以解决上面这些问题，但会出现不知道信号是哪个超时的定时器发送的问题。</li>
<li>多线程方案问题比较少，集中在变量生命周期和任务正常完成如何取消超时控制线程这两点上。</li>
</ol>
<p>综合来看使用多线程方案才能真正解决问题，跨平台性也更强。知道原理后我们就可以写实验代码了。</p>
<p>转换后的工作函数是这样的：</p>
<pre><code class="language-c++">namespace {
    std::atomic&lt;int&gt; canceled_flag{0};
    std::atomic&lt;int&gt; is_canceled{0};
}

void Work(int id)
{
    std::mt19937 rng{std::random_device{}()};
    std::uniform_int_distribution&lt;int&gt; dist(0, 1);

    for (int i = 0; i &lt; 10; ++i) {
        if (canceled_flag.load(std::memory_order_acquire) == 1) {
            std::osyncstream{std::cout} &lt;&lt; "worker: " &lt;&lt; id &lt;&lt; " canceled\n";
            is_canceled.store(1, std::memory_order_release);
            return;
        }
        if (dist(rng) == 0) {
            std::this_thread::sleep_for(std::chrono::milliseconds(500));
        } else {
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
    }

    std::osyncstream{std::cout} &lt;&lt; "worker: " &lt;&lt; id &lt;&lt; " done\n";
}
</code></pre>
<p>代码和go版本的没有太大差异，唯一的区别是我们不靠返回值而是<code>is_canceled</code>标志来区分线程是否因为被取消而退出。只使用<code>canceled_flag</code>会导致竞态条件并导致误判，你可以想想是为什么，这算是课后练习。另外我在这还使用了memory_order，这不是必须的，但默认的cst内存序多少有些杀鸡用牛刀。</p>
<p>下面是主线程和超时控制线程的逻辑：</p>
<pre><code class="language-c++">int main(int argc, const char *argv[])
{
    if (argc != 2) {
        std::cerr &lt;&lt; "wrong arg\n";
        return 1;
    }
    auto timeout = std::stoi(argv[1]);

    std::vector&lt;std::thread&gt; workers;
    constexpr int worker_num = 3;
    workers.reserve(worker_num);
    for (int i = 0; i &lt; worker_num; ++i) {
        workers.emplace_back(work, i);
    }

    std::atomic&lt;int&gt; timeout_cancel_flag{0};
    std::thread{
        // 超时控制线程
        [&amp;timeout_cancel_flag](auto timeout){
            std::this_thread::sleep_for(timeout);
            if (timeout_cancel_flag.load(std::memory_order_acquire) == 1) { // 危险
                return;
            }
            canceled_flag.store(1, std::memory_order_release);
        }, std::chrono::milliseconds(timeout)
    }.detach();

    for (auto &amp;worker: workers) {
        worker.join();
    }
    timeout_cancel_flag.store(1, std::memory_order_release);

    if (is_canceled.load(std::memory_order_acquire) != 1) {
        std::osyncstream{std::cout} &lt;&lt; "All works done!\n";
    } else {
        std::osyncstream{std::cout} &lt;&lt; "Tasks canceled\n";
    }
}
</code></pre>
<p>整体上没什么难懂的地方，基本可以看做Golang版本的转译，如果线程都退出之后不管是否超时我们都要取消超时控制线程。整体上只有一点不一样：超时控制线程是detach的，因为我们不能让主线程阻塞。</p>
<p>然而这段代码有很致命的生命周期问题，想象一下如果worker都在timeout之前完成工作，且函数在timeout之前退出，但超时控制线程仍然需要睡眠到timeout为止，这时候它醒来访问到的<code>timeout_cancel_flag</code>将会是一个无效值。</p>
<p>问题出在两个地方，第一个是我们用了sleep，这不可中断，线程必须要等满timeout时间才能退出，这会造成线程泄漏；第二是因为sleep不可中断，导致我们的超时控制线程生命周期长于主线程和工作线程，在其中引用的主线程的局部变量很可能会失效。</p>
<p>解决方案当然也很多，最简单的就是用<code>std::shared_ptr</code>包裹我们需要跨线程访问的资源，这和在rust中使用<code>Arc</code>是一样的。但这种方案治标不治本，我们的超时控制线程仍然会有比其他线程长的生命周期。</p>
<p>第二种则是使用一种在超时等待中可以被中断的机制，c++20前我们有<code>std::timed_mutex</code>和条件变量可用。</p>
<p>改进后的代码：</p>
<pre><code class="language-c++">auto timeout_cancel_flag = std::make_shared&lt;std::condition_variable&gt;();
std::thread{
    [timeout_cancel_flag](auto timeout){
        std::mutex timeout_lock;
        std::unique_lock u{timeout_lock};
        if (timeout_cancel_flag-&gt;wait_for(u, timeout) == std::cv_status::timeout) {
            std::osyncstream{std::cout} &lt;&lt; "cancel all threads\n";
            canceled_flag.store(1, std::memory_order_release);
        } else {
            std::osyncstream{std::cout} &lt;&lt; "self was canceled by main thread\n";
        }
    }, std::chrono::milliseconds(timeout)
}.detach();

for (auto &amp;worker: workers) {
    worker.join();
}

timeout_cancel_flag-&gt;notify_all(); // 取消超时控制线程
</code></pre>
<p>我们可以使用条件变量的<code>wait_for</code>方法，它可以让当前线程阻塞到指定的时间，或者中途被<code>notify</code>唤醒。这完美实现了我们既要超时等待又要中途可被打断的需求。并且条件变量本身用<code>std::shared_ptr</code>包裹，不会有任何生命周期问题。</p>
<p>然而没有了生命周期问题，我们还有时序问题，如果主线程中的<code>notify_all()</code>早于控制线程中的<code>wait_for</code>执行（概率比较小但不为0），那么这次notify超时控制线程是收不到的，wait会一直阻塞到超过timeout，这时候再设置取消标志就没有意义了。想要解决这种“唤醒丢失”问题，我们需要借助wait重载的第三个参数，让它告诉我们超时控制线程本身是否被取消：</p>
<pre><code class="language-c++">struct TimeoutContext {
    std::atomic&lt;int&gt; canceled{0};
    std::mutex lock;
    std::condition_variable cv;
};

auto timeout_ctx = std::make_shared&lt;TimeoutContext&gt;();
std::thread{
    [timeout_ctx](auto timeout){
        // 必须使用ctx里的锁才能有效避免竞态条件
        std::unique_lock u{timeout_ctx-&gt;lock};
        if (!timeout_cancel_flag-&gt;wait_for(u, timeout, [&amp;](){ return timeout_ctx-&gt;canceled.load(std::memory_order_acquire) == 1; })) {
            // wait_for 返回 false，canceled是值还是0，说明是超时导致的返回
            std::osyncstream{std::cout} &lt;&lt; "cancel all threads\n";
            canceled_flag.store(1, std::memory_order_release);
        } else {
            // wait_for 返回 true，canceled被设置为1，说明主线程通知了取消
            std::osyncstream{std::cout} &lt;&lt; "self was canceled by main thread\n";
        }
    }, std::chrono::milliseconds(timeout)
}.detach();

for (auto &amp;worker: workers) {
    worker.join();
}

// 取消超时控制线程
{
    // 获取同一把锁，修改状态时要么超时控制线程还没运行，要么已经在wait了
    std::lock_guard lk(timeout_ctx-&gt;lock);
    timeout_ctx-&gt;canceled.store(1, std::memory_order_release);
}
// 解锁后才能通知
timeout_ctx-&gt;cv.notify_all();
</code></pre>
<p>因为有锁存在，所以不管怎么样运行顺序只有两种：</p>
<ol>
<li>超时线程先运行，一直到wait方法里解锁，我们可以保证wait一定在notify之前运行</li>
<li>主线程设置超时线程取消标志的代码先运行，这时wait是晚于notify执行的，但我们设置取消标志是先于wait的，而wait在休眠前会先检查谓词条件，所以条件变量会马上退出不会进行等待。</li>
<li>会不会存在wait中条件变量解除了锁，在即将进入休眠前主线程完成了执行？答案是不会的，标准有明文要求wait和它的兄弟函数里unlock+wait加在一起是原子的（实际上分为三部分，解锁+休眠、被唤醒、重新加锁，它们各自都是原子的）且和notify之间是全序关系——要么notify在前他们在后或者反过来，不可能同时执行。简单说，如果超时控制线程正在执行unlock+wait，这说明主线程没有拿到锁，此时主线程要么还没运行到notify（这种情况不会丢失唤醒），要么已经设置了标志并释放了锁，谓词会检测到标志被设置（谓词检测在锁的保护中），条件变量不进入休眠；如果notify在之后运行，则notify会看到超时控制线程已经进入wait，会唤醒它。所以不存在中间可以被打断的场景。</li>
</ol>
<p>现在不再有时序问题了。</p>
<p>总体来说这个实现还不错，能正常工作性能也尚可，很多框架也选择了类似的方案来实现线程的超时取消，比如Qt。然而它有几个显著的缺点：</p>
<ol>
<li>代码依赖很多全局状态</li>
<li>我们需要用<code>join</code>等待所有线程退出，这是因为标准库的thread不join就析构会导致程序崩溃，然而这是不必要的，我们只关心工作是否完成，剩下的资源释放和线程退出无需去等待</li>
<li>线程之间暴露了过多的实现细节，比如flag具体的值，再比如<code>std::condition_variable</code>用来通知超时控制线程</li>
<li>代码真的很复杂，想正确实现整体逻辑会比较麻烦，比如杜绝唤醒丢失</li>
</ol>
<p>尽管有这些缺点，但在新标准之前我们只能使用这个方案。当然如果放弃跨平台的话，Linux上更安全更简单的做法其实是<code>eventfd+epoll_wait</code>，它不需要太多的外部状态，且逻辑简单易懂，比用条件变量还要预防唤醒丢失强太多了，使用得当的话它的性能也不会比纯内存操作的条件变量差多少。</p>
<h2 id="c20带来的简化">C++20带来的简化</h2>
<p>C++20为并发编程体验带来了不少提升。</p>
<p>第一个就是<code>std::jthread</code>，它会在析构的时候自动join，从而避免了<code>std::thread</code>手动操作的麻烦。不仅如此，每个<code>jthread</code>中还包含一个<code>std::stop_token</code>，这可以简单实现线程的协作式取消执行。仅仅这一个新特性就已经解决了上一节说的缺点中的前两条。</p>
<p>第二个有用的新特性是<code>std::stop_source</code>和<code>std::stop_token</code>。一个<code>std::stop_source</code>可以产生多个<code>std::stop_token</code>，当一个source被取消的时候，每个从它那派生出来的token都会收到通知，这可以上位替代我们之前使用的<code>canceled_flag</code>。</p>
<p>第三个是<code>std::latch</code>，你可以把它当成go的<code>sync.WaitGroup</code>，它可以让我们在工作线程完成工作之后立即通知主线程，而不用调用<code>join</code>等待线程完全退出。</p>
<p>最后一个则是<code>std::condition_variable_any</code>新增了可以用<code>stop_token</code>中断等待的方法，无需我们自己手动notify，这样可以尽量隐藏实现细节。</p>
<p>我们首先改造工作函数：</p>
<pre><code class="language-c++">bool work(std::stop_token stoken, int id)
{
    std::mt19937 rng{std::random_device{}()};
    std::uniform_int_distribution&lt;int&gt; dist(0, 1);

    for (int i = 0; i &lt; 10; ++i) {
        if (stoken.stop_requested()) {
            std::osyncstream{std::cout} &lt;&lt; "worker: " &lt;&lt; id &lt;&lt; " canceled\n";
            return false;
        }
        if (dist(rng) == 0) {
            std::this_thread::sleep_for(std::chrono::milliseconds(500));
        } else {
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
    }

    std::osyncstream{std::cout} &lt;&lt; "worker: " &lt;&lt; id &lt;&lt; " done\n";
    return true;
}
</code></pre>
<p>现在我们不依赖全局变量通知线程退出了。并且函数的返回值改成了bool，以表示线程是否是因为被取消而退出的。我们通过<code>stoken.stop_requested()</code>判断线程是否被取消。</p>
<p>接下来我们利用C++20改造主线程和超时控制：</p>
<pre><code class="language-c++">int main(int argc, const char *argv[])
{
    if (argc != 2) {
        std::cerr &lt;&lt; "wrong arg\n";
        return 1;
    }
    auto timeout = std::stoi(argv[1]);

    std::atomic&lt;int&gt; is_canceled{0};
    std::stop_source source;
    std::vector&lt;std::jthread&gt; workers;
    constexpr int worker_num = 3;
    std::latch wait_group{worker_num};
    workers.reserve(worker_num);
    for (int i = 0; i &lt; worker_num; ++i) {
        workers.emplace_back([&amp;](int id){
            if (!work(source.get_token(), id)) {
                is_canceled.store(1, std::memory_order_release);
            }
            wait_group.count_down(); // 三个线程都调用过之后，wait会解除阻塞
        }, i);
    }

    // 现在不需要专门detach了，效果是一样的
    std::jthread timeout_control{
        [&amp;source](std::stop_token stoken, std::chrono::milliseconds timeout){
            std::mutex timeout_lock;
            std::unique_lock u{timeout_lock};
            std::condition_variable_any timeout_cancel;
            if (!timeout_cancel.wait_for(u, stoken, timeout, [&amp;stoken] { return stoken.stop_requested(); })) {
                std::osyncstream{std::cout} &lt;&lt; "cancel all threads\n";
                source.request_stop();
            } else {
                std::osyncstream{std::cout} &lt;&lt; "self was canceled by main thread\n";
            }
        }, std::chrono::milliseconds(timeout)
    };

    wait_group.wait(); // 等工作线程完成
    timeout_control.request_stop(); // 工作线程退出后立即取消超时控制线程，即使线程已经执行完成也能安全调用这个方法

    if (is_canceled.load(std::memory_order_acquire) != 1) {
        std::osyncstream{std::cout} &lt;&lt; "All works done!\n";
    } else {
        std::osyncstream{std::cout} &lt;&lt; "Tasks canceled\n";
    }
}
</code></pre>
<p>可以看到我们现在完全不使用全局变量了，而且线程的协作式取消是<code>request_stop()</code>和<code>stop_requested()</code>共同完成的，不会暴露太多实现细节。</p>
<p>需要注意的是<code>!timeout_cancel.wait_for(u, stoken, timeout, [&amp;stoken] { return stoken.stop_requested(); })</code>这行代码。这行代码和普通条件变量的<code>wait_for</code>一样，只不过多了一个参数<code>stoken</code>，这个函数会阻塞住当前线程，直到超时、被notify或者stoken被取消。最后一个参数lambda的返回值会作为<code>wait_for</code>的返回值，这个lambda会在阻塞解除后立即调用，因此我们在这个函数里检查<code>stoken</code>是否被取消。如果<code>stoken</code>没有被取消，说明是因为超时导致的返回，因为我们在其他地方调用notify，因此在这时我们需要取消其他工作线程。</p>
<p>新代码不仅更简洁，而且没有上一节那样的时序问题：</p>
<ol>
<li>如果stoken的取消发生在整个wait之前。wait里的谓词检测会发现wait被取消</li>
<li>stoken的取消发生在谓词检测之后、unlock+wait之前。<code>condition_variable_any</code>里有内部锁，调用<code>notify_all</code>（取消stoken会自动调用）和<code>unlock+wait</code>之前都会先尝试获取这个锁，<code>unlock+wait</code>在获取锁之后会检查stoken是否被取消，所以如果<code>notify</code>先执行，那么wait会检测到stoken已取消；如果<code>unlock+wait</code>先执行，那么notify一定是在wait之后执行的，不存在丢失</li>
<li>取消发生在wait之后，这是最安全的情况，不会有唤醒丢失。</li>
</ol>
<p><code>condition_variable_any</code>内部持有的锁正好对应我们上一节的<code>TimeoutContext::lock</code>，而<code>stop_token</code>对应<code>TimeoutContext::canceled</code>，<code>request_stop()</code>则对应了加锁设置标志并调用notify。现在所有操作all in one，代码在保证安全的同时将复杂的细节全部隐藏。</p>
<p>尽管仍有一定复杂性，但利用<code>condition_variable_any</code>已经是比较理想的超时控制解决方案了。</p>
<h3 id="condition_variable_any是如何配合stop_token的">condition_variable_any是如何配合stop_token的</h3>
<p>最后还有一个小插曲，<code>condition_variable_any</code>是如何配合<code>stop_token</code>的。</p>
<p>C++20只给<code>condition_variable_any</code>添加了支持<code>stop_token</code>的接口，这是因为普通的条件变量和其他的锁几乎都是系统接口的简单包装，这些系统接口本身不支持中断，因此也没法为这些包装接口添加支持，而<code>condition_variable_any</code>为了支持所有种类的锁，几乎所有标准库的实现都在自己内部创建了一个普通的条件变量和内部锁，并基于这个条件变量重新实现了所有接口，因此给支持<code>stop_token</code>留下了余地。</p>
<p>我们以libcxx的实现为例：</p>
<pre><code class="language-c++">// notify全都要先加内部锁
inline void condition_variable_any::notify_one() _NOEXCEPT {
  { lock_guard&lt;mutex&gt; __lx(*__mut_); }
  // notify时最好要解锁，否则wait线程被唤醒后发现加不了锁又会再次休眠，效率很低
  // 锁只是为了让notify的调用和unlock+wait互斥
  __cv_.notify_one();
}

inline void condition_variable_any::notify_all() _NOEXCEPT {
  { lock_guard&lt;mutex&gt; __lx(*__mut_); }
  __cv_.notify_all();
}

// wait_for最终调用的这个方法
template &lt;class _Lock, class _Clock, class _Duration, class _Predicate&gt;
bool condition_variable_any::wait_until(
    _Lock&amp; __user_lock,
    stop_token __stoken,
    const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __abs_time,
    _Predicate __pred) {
    // 先检查一次是否被取消，因为后面的操作都很重量级会浪费性能
  if (__stoken.stop_requested())
    return __pred();

  shared_ptr&lt;mutex&gt; __mut = __mut_;
  // 这行是关键，让底层的普通条件变量可以从wait中苏醒
  stop_callback __cb(__stoken, [this] { notify_all(); });

  while (true) {
    // 从wait中因为notify醒来会回到这里，调用最后的lambda来检查是否应该退出等待
    // 初次进入循环也会检查，以免进行不必要的等待
    // 检查其实在临界区之外，所以其实最好我们得持有传入的外部锁才能完全避免静态条件
    // 只不过恰好我们的谓词检查只检查了stoken是否被取消，和下面临界区内的一样，所以这地方的时序没有影响。我们在主线程中也无需加外部锁
    if (__pred())
      return true;

    // 先加内部锁，以免竞态条件出现，代码本身的注释已经解释清楚了，无需多言
    // We need to take the internal lock before checking stop_requested,
    // so that the notification cannot come in between the stop_requested
    // check and entering the wait.
    // Note that the stop_callback takes the same internal lock before notifying
    unique_lock&lt;mutex&gt; __internal_lock(*__mut);
    // 检查stop_token是否被取消
    // notify拿到锁先运行的话循环就会在这里退出
    if (__stoken.stop_requested())
      break;

    // 解锁用户传入的外部锁，和普通的条件变量一样
    __unlock_guard&lt;_Lock&gt; __unlock(__user_lock);
    unique_lock&lt;mutex&gt; __internal_lock2(
        std::move(__internal_lock)); // switch unlock order between __internal_lock and __user_lock

    // 内部锁的unlock+wait
    if (__cv_.wait_until(__internal_lock2, __abs_time) == cv_status::timeout)
      // 超时之后直接退出循环，否则回到循环开始处
      break;
  } // __internal_lock2.unlock(), __user_lock.lock()
  // 还会调用谓词，因此返回值总是能反应stoken是否被取消
  return __pred();
}

template &lt;class _Lock&gt;
struct __unlock_guard {
  _Lock&amp; __lock_;

  // 对象创建的时候解锁，析构的时候加锁
  _LIBCPP_HIDE_FROM_ABI __unlock_guard(_Lock&amp; __lock) : __lock_(__lock) { __lock_.unlock(); }

  _LIBCPP_HIDE_FROM_ABI ~__unlock_guard() _NOEXCEPT // turns exception to std::terminate
  {
    __lock_.lock();
  }

  __unlock_guard(const __unlock_guard&amp;)            = delete;
  __unlock_guard&amp; operator=(const __unlock_guard&amp;) = delete;
};
</code></pre>
<p>核心在于<code>stop_callback __cb(__stoken, [this] { notify_all(); });</code>这一行，<code>std::stop_callback</code>可以把回调函数注册给<code>stop_token</code>关联的<code>stop_source</code>，当source被要求停止时，注册的回调会在调用<code>request_stop()</code>的那个线程执行，回调可以注册多个，调用顺序是不确定的。</p>
<p>所以这行代码等于在我们要求取消<code>stoken</code>的时候，顺手调用<code>notify_all()</code>把底层的条件变量唤醒了，唤醒之后循环会检查lambda和<code>stoken</code>，然后发现自己被取消从而从wait中退出。这就是wait可以被立即中断的秘密。</p>
<p>不过如果token已经取消，<code>stop_callback</code>是不生效的，但这也没关系，因为在进入真正的等待支持，我们至少检查了两次<code>stoken</code>是否被取消，且第二次检查是被锁保护的，notify的callback不生效或者唤醒丢失了我们也能检查到stoken已经被取消，不会进入无意义的等待。</p>
<p>上面的代码也展现了<code>condition_variable_any</code>的问题，相比直接转发到系统接口的其他标准库功能，它的性能通常要差一些，对于性能要求较高的场景必须谨慎使用。</p>
<h2 id="总结">总结</h2>
<p>为了保证并发安全，上面的逻辑是有些绕的，但总结起来也就几句话：</p>
<ol>
<li>设置取消标志需要和unlock+wait互斥，这样超时控制线程才有机会检测自己是否被取消。</li>
<li>超时控制线程中的取消标志检查（C++20前的谓词匿名函数、C++20里的<code>stoken.stop_requested</code>）需要和unlock+wait在同一块临界区里，这样才能保证进入wait之前取消标志被正确检测到或者notify在wait之后才被调用。</li>
<li>notify通常在设置完取消标志之后执行，但不需要在临界区里，即使唤醒错过了我们也有保底措施。</li>
</ol>
<p>只要想明白这三点你就掌握了这种模式，以后遇到超时取消或者防止唤醒丢失的场景时不至于两眼一黑了。</p>
<p>这就是为什么要用现代C++，新特性有时候真的可以飞跃式提升开发效率，虽说这种程度和Golang相比还称不上优雅，但心智负担减轻了很多加班也没那么累了。</p>
<p>但话说回来，同样的需求如果不是追求极致性能/只能用C++，我更乐意用Golang去实现。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 21:15">2025-12-22 21:15</span>&nbsp;
<a href="https://www.cnblogs.com/apocelipes">apocelipes</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384377);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384377', targetLink: 'https://www.cnblogs.com/apocelipes/p/19384377', title: '从源码角度解析C++20新特性如何简化线程超时取消' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ C#/.NET/.NET Core技术前沿周刊 | 第 64 期（2025年12.1-12.21） ]]></title>
    <link>https://www.cnblogs.com/Can-daydayup/p/19384367</link>
    <guid>6ab9454194159f7c496e6e62337f9e99</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/Can-daydayup/p/19384367" title="发布于 2025-12-22 21:12">
    <span role="heading" aria-level="2">C#/.NET/.NET Core技术前沿周刊 | 第 64 期（2025年12.1-12.21）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p><img src="https://img2024.cnblogs.com/blog/1336199/202509/1336199-20250902130707396-140987169.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">前言</span></span></h2>
<p data-tool="mdnice编辑器">C#/.NET/.NET Core技术前沿周刊，你的每周技术指南针！记录、追踪C#/.NET/.NET Core领域、生态的每周最新、最实用、最有价值的技术文章、社区动态、优质项目和学习资源等。让你时刻站在技术前沿，助力技术成长与视野拓宽。</p>
<blockquote class="custom-blockquote multiquote-1" data-tool="mdnice编辑器">
<p>欢迎投稿、推荐或自荐优质文章、项目、学习资源等。</p>
</blockquote>
<ul data-tool="mdnice编辑器">
<li><strong>🏆技术前沿周刊Gitee开源地址：</strong> <a href="https://gitee.com/ysgdaydayup/DotNetGuide/blob/main/docs/DotNet/DotNetWeekly.md" rel="noopener nofollow">https://gitee.com/ysgdaydayup/DotNetGuide/blob/main/docs/DotNet/DotNetWeekly.md</a></li>
<li><strong>📰技术前沿周刊GitHub开源地址：</strong> <a href="https://github.com/YSGStudyHards/DotNetGuide/blob/main/docs/DotNet/DotNetWeekly.md" rel="noopener nofollow">https://github.com/YSGStudyHards/DotNetGuide/blob/main/docs/DotNet/DotNetWeekly.md</a></li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">精选 8 个 .NET 开发实用的类库，效率提升利器！</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 精选 8 个 .NET 开发实用的类库，.NET 开发效率提升利器！</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/hzHCwM3BaUyZO9HCqODIEQ" rel="noopener nofollow">https://mp.weixin.qq.com/s/hzHCwM3BaUyZO9HCqODIEQ</a></li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">Visual Studio 2026 正式版下载与安装详细教程（附带产品密钥）！</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 最近发现很多小伙伴反馈 Visual Studio 2026 安装占用磁盘空间较大，今天大姚出一期 Visual Studio 2026 正式版下载与安装详细教程，我们可以通过仅选择所需的工作负荷、组件、语言包来节省安装时间和磁盘空间，希望可以帮助到有需要的小伙伴！</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/wbZiTPjhKlFOeU3MgIbq0A" rel="noopener nofollow">https://mp.weixin.qq.com/s/wbZiTPjhKlFOeU3MgIbq0A</a></li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211437061-990924613.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">一个 .NET 开源免费、功能强大的 UI 自动化库</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> FlaUI 是一个 .NET 开源免费（MIT license）、功能强大 的 UI 自动化库，专为 Windows 桌面应用程序（如 Win32、WinForms、WPF、Store Apps 等应用）的自动化测试而设计。该项目基于 Microsoft 的原生 UI Automation 库构建，并作为这些库的封装器，提供了丰富的功能和灵活的 API，以便开发者能够高效地编写自动化测试脚本。</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/PE4S-fUyeG7U8Z78NYu6Rw" rel="noopener nofollow">https://mp.weixin.qq.com/s/PE4S-fUyeG7U8Z78NYu6Rw</a></li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211450021-574322057.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">Newtonsoft.Json 与 System.Text.Json 多态反序列化的安全性差异解析</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 多态反序列化是处理继承结构对象序列化的常见需求，但不同 JSON 序列化库的实现机制差异会带来显著的安全风险。微软 CA2326 规则明确警示：避免使用非安全的 JsonSerializerSettings 配置（如 Newtonsoft.Json 的 TypeNameHandling 非 None 值），否则可能引发类型注入攻击。本文将对比 Newtonsoft.Json 与 System.Text.Json 在多态反序列化中的实现差异，重点分析安全性问题，并通过代码实例验证两者的安全表现。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/MeteorSeed/p/19366736</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">.NET 和 .NET Framework 2025 年 12 月服务发布更新</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 欢迎来到我们 2025 年 12 月的联合.NET 服务更新。让我们进入.NET 和.NET Framework 的最新版本，这里简要介绍一下我们服务版本中的新内容。</li>
<li><strong>文章地址：</strong> https://devblogs.microsoft.com/dotnet/dotnet-and-dotnet-framework-december-2025-servicing-updates/</li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211504791-248672978.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">如何构建带有.NET MAUI 的 iOS 小部件</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 我是一名.NET 开发者，主要专注于.NET MAUI 到 ASP.NET 后端服务。因为我最近大量接触小部件，遇到了许多障碍和极其有限的文档，我决定写这篇文章，展示用 .NET MAUI 构建完整小部件是完全可能的。而且还能以类似原生开发环境的专业方式完成，不用担心每次新构建或更新都会让一切崩溃。</li>
<li><strong>文章地址：</strong> https://devblogs.microsoft.com/dotnet/how-to-build-ios-widgets-with-dotnet-maui</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">.NET 10 网络改进</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 和每次版本一样，我们会发布一篇关于.NET 网络领域新颖有趣变化和新增内容的博客文章。这次，我们将讨论 HTTP 改进、新的 Web 套接字 API、 安全变更以及许多网络原语的独特新增内容。</li>
<li><strong>文章地址：</strong> https://devblogs.microsoft.com/dotnet/dotnet-10-networking-improvements/</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">分享 4 款基于 C# 编写、实用、开源的 Visual Studio 扩展插件</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> EFCore.Visualizer 是一款可以直接在 Visual Studio 中查看 EF Core 查询计划调试器可视化工具（帮助开发者分析和优化数据库查询性能），目前，该可视化工具支持 SQL Server、PostgreSQL、SQLite、MySQL 和 Oracle。</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/DTX-UAZhle9dxnD4MjebCw" rel="noopener nofollow">https://mp.weixin.qq.com/s/DTX-UAZhle9dxnD4MjebCw</a></li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">完美复刻！一个基于 C# 和 WPF 开源的网易云音乐客户端</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> MusicApp 是一个基于 C# 和 WPF 技术开发的模仿网易云音乐界面的音乐应用项目。该项目旨在通过实践学习 WPF 开发，非常适合 WPF 入门学习者作为入门参考项目，本项目已实现基本音乐播放功能。</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/CIWd7qx-S95Xv02pZCBpgw" rel="noopener nofollow">https://mp.weixin.qq.com/s/CIWd7qx-S95Xv02pZCBpgw</a></li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211523726-2094328585.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">一款基于 .NET 和 Quartz.NET 开源的任务调度 Web 界面管理</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> quartzui 是一款基于 Quartz.NET 3.0（后升级至3.2.4）的任务调度 Web 界面管理工具，专为简化任务调度管理而设计。该项目支持通过 Web 界面进行任务调度配置、监控及管理，极大地提高了任务调度的便捷性和效率。</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/qByA7G0EFVY0S2J5l9in1A" rel="noopener nofollow">https://mp.weixin.qq.com/s/qByA7G0EFVY0S2J5l9in1A</a></li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211541692-730702520.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">一个 WPF 开源、免费的 SVG 图像查看控件</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> SVGImage 是一个为 WPF（Windows Presentation Foundation）应用程序设计、开源（MIT license）、免费的 SVG（Scalable Vector Graphics）图像查看控件。</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/69x0B6jhYja58Ze0NSi9ew" rel="noopener nofollow">https://mp.weixin.qq.com/s/69x0B6jhYja58Ze0NSi9ew</a></li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211555043-1633800824.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">一个基于 .NET + Vue3 开源、免费、精美的通用业务型后台管理系统</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> SimpleAdmin 是一个基于 .NET + Vue3 开发的通用业务型后台管理系统，适用于各类需要后台管理功能的企业级应用、网站后台、数据监控平台等场景。它提供了丰富的功能模块和精美的用户界面，能够帮助开发者快速搭建起稳定、高效的后台管理系统，提升开发效率和管理水平。</li>
<li><strong>文章地址：</strong> <a href="https://mp.weixin.qq.com/s/QV2B3et6Df9FrU3RzYDWrQ" rel="noopener nofollow">https://mp.weixin.qq.com/s/QV2B3et6Df9FrU3RzYDWrQ</a></li>
</ul>
<p><img src="https://img2024.cnblogs.com/blog/1336199/202512/1336199-20251222211607946-944175912.png" alt="image" loading="lazy"></p>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">精选 6 款开源的 WinForm UI 控件库，轻松让你的老牌 WinForm 应用焕然一新！</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 今天大姚给大家分享 6 款开源的 WinForm UI 控件库，轻松让你的老牌 WinForm 应用焕然一新！</li>
<li><strong>文章地址：</strong> https://mp.weixin.qq.com/s/l4ccmjKzodcwhxYDRTdukg</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">全面支持国产化！C# 开源跨平台 UI 框架，支持 Windows、Mac、Linux</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> CPF（Cross-Platform Framework）&nbsp;是一款基于 C# 开发的开源跨平台 UI 框架，专注于国产化适配与全平台支持（Windows/macOS/Linux）。项目采用模块化设计，提供高性能的渲染引擎与丰富的控件库，旨在解决国产操作系统生态中缺乏成熟 C# UI 解决方案的痛点，同时兼容主流国际平台。</li>
<li><strong>文章地址：</strong> https://mp.weixin.qq.com/s/qbmUS5gT1be6ZWpYm0FRPw</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">一个基于 .NET 开源、高性能、可扩展的套接字服务器应用程序框架</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> SuperSocket 是一个用于 .NET 的高性能、可扩展的套接字服务器应用程序框架。它为开发者提供了构建自定义网络通信应用程序的强大架构，支持包括 TCP、UDP 和 WebSocket 在内的多种协议。</li>
<li><strong>文章地址：</strong> https://mp.weixin.qq.com/s/oNA-dDh80e-WI__9Itf2JA</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">C#AI系列(7):从零开始LLM之Tokenizer实现</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> LLM只做一个事情，就是吃掉token吐出token，token是LLM（大语言模型）的基本元素。token与LLM的关系，相当于乐高积木与乐高工厂，我的世界方块与我的世界游戏。那么token到底是什么呢？有人翻译成令牌，有人翻译成词源。我们不妨换个概念理解，token就是最小操作、最小信息单元的意思。这个最小是相对于LLM要处理的原始文本来说的。举个栗子，当一个句子文本输入到电脑中，天然就就具有字符级别的切分。如果不打算继续拆分或组合，我们可以通过一个映射关系，将现有这些字符转换为整数数组，称为编码过程。编码后数组内的元素就是token，元素取值就等于token取值。LLM可以吃掉这个token数组，并吐出新数组。对这个新数组按前前述的映射进行逆转换，称为解码过程。解码后我们就能得到人类可以理解的文本了。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/luojin765/p/19378939</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">.NET10 New feature 新增功能介绍-JIT编译器改进</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 首先.NET10是一个LTS版本，微软官方支持3年，所以作为最新的主力版本，可以尽快升级使用。今天我们详细介绍一下.NET 10的一些新功能-JIT编译器改进。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/tianqing/p/19378803</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">.Net通过EFCore和仓储模式实现统一数据权限管控并且相关权限配置动态生成</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> .Net通过EFCore和仓储模式实现统一数据权限管控并且相关权限配置动态生成。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/net-kevin-li/p/19368351</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">OpenCVSharp：HOG行人检测</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> HOG行人检测是一种基于方向梯度直方图特征的计算机视觉目标检测技术，它通过计算图像局部区域的梯度方向直方图来描述目标的外观形状特征。该算法首先将图像分割为小的连通区域（细胞单元），计算每个单元内像素的梯度方向并生成直方图，然后将相邻的细胞单元组合成块并对块内的直方图进行归一化处理，最终形成能够有效描述行人轮廓和形状的特征向量。这些特征向量被输入到预先训练好的SVM分类器中，判断图像区域是否包含行人，并通过多尺度扫描策略在不同大小的窗口中搜索目标，从而实现对图像中行人的准确检测和定位。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/mingupupu/p/19365183</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">OpenCVSharp：学习人脸检测例子</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> OpenCVSharp关于人脸检测提供了两个例子，一个是使用级联分类器另一个是使用DNN模型。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/mingupupu/p/19363129</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">Aspire 13：从.NET 编排工具到真正的多语言云原生应用平台</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> Aspire 13 的发布标志着微软云原生开发工具链的一个决定性转折点。通过正式去除 ".NET" 前缀并更名为 "Aspire"，该平台已从一个以.NET 为中心的编排器演变为一个广泛的、多语言通用的应用平台 1。这一战略转变的核心在于将 Python 和 JavaScript (Node.js) 提升为与.NET 同等的一等公民，彻底解决了现代分布式系统开发中跨语言协作的碎片化痛点 2。本文将深入剖析 Aspire 13 的架构变革，重点阐述其如何通过标准化的 "AppHost" 模型来统一管理异构微服务的生命周期。我们将详细探讨新增的 Aspire.Hosting.Python 包及其对 Python 生态系统（如 uv 包管理器、ASGI 标准、虚拟环境）的深度集成；分析基于 OpenTelemetry (OTLP) 的统一可观测性架构如何消除语言间的监控壁垒；并揭示 Aspire 13 如何通过智能化的环境变量注入和自动化的 Dockerfile 生成，重塑了从本地开发到生产部署的完整工作流 1。此外，本文还将审视这一版本对底层基础设施的要求，包括对.NET 10 SDK 的依赖以及全新的生命周期管理工具 aspire do 的引入 2。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/shanyou/p/19360467</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">用 .NET 最小化 API 构建高性能 API</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 在当今快速发展的应用开发领域，构建快速、可扩展且可维护的API已成为现代应用的关键要求。随着.NET技术的不断演进，微软推出了最小化API(Minimal APIs)这一创新架构，旨在简化API开发流程同时显著提升性能。最小化API通过减少模板代码、优化启动时间，让开发者能够专注于业务逻辑而非框架复杂性，为构建高性能API提供了全新的解决方案。本文将深入探讨如何利用.NET中的最小化API架构构建高性能API，通过简洁的代码示例和实用建议，帮助开发者掌握这一现代API开发方法。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/powertoolsteam/p/19360421</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">2025年 WebTransport 生态深度研究：JavaScript 客户端与.NET 10 SignalR 的演进与融合</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 在实时网络通信领域，2025年标志着从传统的基于 TCP 的 WebSocket 协议向基于 UDP 和 QUIC 的下一代传输协议——WebTransport 的关键转型期。本报告旨在针对 WebTransport 在 JavaScript 客户端生态系统中的支持现状，以及微软.NET 10 框架下 ASP.NET Core SignalR 对该协议的服务端实现能力，进行详尽的基准测试与架构分析。研究显示，截至 2025 年第四季度，WebTransport 的生态呈现出显著的“两极分化”特征。在客户端方面，以 Chrome 和 Firefox 为代表的浏览器阵营已经实现了高度成熟且稳定的支持，不仅完全遵循 W3C 标准，更在流控制和拥塞管理上表现优异；然而，Apple 的 WebKit 内核（Safari）依旧是普及的最大阻碍，仅在实验性版本中有限度开放。在服务端方面，随着.NET 10 的发布，ASP.NET Core SignalR 将 WebTransport 从“实验性预览”正式推进至“生产就绪”阶段，尽管其对底层操作系统（如 Windows Server 2022/2025 和特定 Linux 发行版）的依赖依然构成了部署门槛。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/shanyou/p/19355053</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">OpenCVSharp：了解几种特征检测</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 前面已经介绍过了OpenCVSharp中封装的几个特征检测算法，其实里面还有很多特征检测算法，不再一篇一篇地介绍了，其它的都放在这一篇，简单过一下，有点印象即可。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/mingupupu/p/19352075</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">C#AI系列(6): C#离线实现高效OCR</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 实现OCR，我们直接从Tesseract（Apache 2.0，star 71.4K）开始。Tesseract 是目前最活跃、最精确的开源 OCR（光学字符识别）引擎之一，由 Google 维护。它能把图片中的印刷或手写文字转换成可编辑的纯文本、PDF、HTML 等多种格式，支持包括中文等 100 多种语言。Tesseract 4 以后引入基于深度学习的 LSTM 神经网络模型，对整行文字进行识别，准确率大幅提升。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/luojin765/p/19346320</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">OpenCVSharp：学习连通性检测的使用</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 连通性检测是计算机视觉中的一种基础图像处理技术，用于识别和标记二值图像中相互连接的像素区域。简单来说，它能够找出图像中所有独立的"连通区域"（即像素之间相互连接形成的区域）。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/mingupupu/p/19344713</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">WPF个人文档（一）—— 基础语法&amp;组件篇</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> WPF个人文档（一）—— 基础语法&amp;组件篇。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/leaf-7-scouts/p/19336808</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">.Net微服务网关注册和管理（基于Consul + Nginx实现）</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 在微服务架构中，API网关作为请求入口，负责路由转发、负载均衡、认证鉴权等核心功能。Consul提供服务注册与发现能力，Nginx作为高性能反向代理，二者结合可实现动态网关管理。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/net-kevin-li/p/19332353</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">.NET 10 网络改进：HTTP、安全与网络原语的全面升级</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 随着.NET 10的发布，微软在网络技术栈上带来了一系列令人兴奋的改进和新增功能。这些改进覆盖了HTTP协议处理、WebSockets API、安全增强以及网络基础原语等多个方面。本文将深入探讨这些技术改进，帮助开发者更好地理解和利用.NET 10在网络编程方面的最新能力。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/powertoolsteam/p/19330426</li>
</ul>
<h2 data-tool="mdnice编辑器"><span class="prefix"><span class="content">C#实现三菱MC通讯协议库（4C帧-格式1）</span></span></h2>
<ul data-tool="mdnice编辑器">
<li><strong>文章简介：</strong> 根据三菱的 Melsec 通讯协议(本文称MC协议)手册内容，使用串口实现了 PC 与 PLC 的通讯，能够通过QnA兼容4C帧的格式1实现 PC 读写 PLC 的软元件存储器内容(异步方法)，最后用一个 C#控制台项目测试了通讯库功能。</li>
<li><strong>文章地址：</strong> https://www.cnblogs.com/dragonet-Z/p/19318911</li>
</ul>
</div>
<div id="MySignature" role="contentinfo">
    <blockquote>
<p style="font-family:YouYuan;font-size: 16px;margin: 0 auto 0.01em auto;"><span style="font-size: 17px; ">作者名称：</span><a href="https://www.cnblogs.com/Can-daydayup/" target="_blank">追逐时光者</a></p>
<p style="font-family:YouYuan;font-size: 16px;margin: 0 auto 0.01em auto;"><span style="font-size: 17px; ">作者简介：</span>一个热爱编程、善于分享、喜欢学习、探索、尝试新事物和新技术的全栈软件工程师。</p>
<p style="font-family:YouYuan;font-size: 16px;margin: 0 auto 0.01em auto;">
本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。如果该篇文章对您有帮助的话，可以点一下右下角的<a onclick="votePost(cb_entryId,'Digg')" href="javascript:void(0)" style="color:red;">【♥推荐♥】</a>，希望能够持续的为大家带来好的技术文章，文中可能存在描述不正确的地方，欢迎指正或补充，不胜感激。
</p>
</blockquote>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.002777777777777778" data-date-updated="2025-12-22 21:16">2025-12-22 21:12</span>&nbsp;
<a href="https://www.cnblogs.com/Can-daydayup">追逐时光者</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384367);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384367', targetLink: 'https://www.cnblogs.com/Can-daydayup/p/19384367', title: 'C#/.NET/.NET Core技术前沿周刊 | 第 64 期（2025年12.1-12.21）' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ MQ 选型框架——Kafka/RabbitMQ/RocketMQ 的模型差异与业务匹配清单 ]]></title>
    <link>https://www.cnblogs.com/shiyuelp/p/19384355</link>
    <guid>fd7926119917bd0fabf846696ad776af</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/shiyuelp/p/19384355" title="发布于 2025-12-22 21:07">
    <span role="heading" aria-level="2">MQ 选型框架——Kafka/RabbitMQ/RocketMQ 的模型差异与业务匹配清单</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加微信：lpshiyue 感谢</strong></p>
<blockquote>
<p>消息队列选型不是技术参数的简单对比，而是业务需求与技术特性的精准匹配艺术</p>
</blockquote>
<p>在完成系统监控体系的建设后，我们面临另一个关键架构决策：如何选择适合业务需求的消息中间件。消息队列作为分布式系统的“血液循环系统”，其选型直接影响着架构的扩展性、可靠性和可维护性。本文将深入解析三大主流消息队列的核心差异，提供科学的选型框架和业务匹配清单，帮助您在复杂的技术选项中做出明智决策。</p>
<h2 id="1-消息队列选型的核心维度与业务影响">1 消息队列选型的核心维度与业务影响</h2>
<h3 id="11-选型决策的五个关键维度">1.1 选型决策的五个关键维度</h3>
<p>消息队列选型需要超越简单的性能参数对比，从​<strong>架构匹配度</strong>​、​<strong>性能特征</strong>​、​<strong>可靠性要求</strong>​、<strong>生态兼容性</strong>和<strong>团队能力</strong>五个维度进行综合评估。每个维度都对应着不同的业务需求和技术约束。</p>
<p><strong>架构匹配度</strong>是选型的首要考量，包括消息模型（发布-订阅 vs 点对点）、路由机制和扩展方式。<strong>性能特征</strong>涉及吞吐量、延迟和资源消耗的平衡。<strong>可靠性要求</strong>涵盖消息持久化、事务支持和故障恢复机制。<strong>生态兼容性</strong>评估与现有技术栈的集成成本。<strong>团队能力</strong>考量技术储备和运维成本。</p>
<p>忽视任一维度都可能导致选型偏差。例如，单纯追求高吞吐而忽略团队对复杂系统的运维能力，将在后期产生巨大技术债务。优秀的选型是这些维度与业务场景的最优平衡。</p>
<h3 id="12-业务场景的技术映射">1.2 业务场景的技术映射</h3>
<p>消息队列选型的本质是将<strong>业务特征</strong>转化为<strong>技术需求</strong>的映射过程。电商订单系统需要强一致性和顺序消息，物联网平台关注低延迟和协议支持，大数据平台追求高吞吐和流处理能力。</p>
<p>业务场景的技术映射需考虑六大因素：​<strong>数据规模</strong>​（日消息量）、​<strong>实时性要求</strong>​（延迟敏感度）、​<strong>一致性级别</strong>​（强一致性 vs 最终一致性）、​<strong>消息优先级</strong>​（顺序保证）、​<strong>协议需求</strong>​（多种协议支持）和​<strong>运维成本</strong>​（团队熟悉度）。</p>
<h2 id="2-三大消息队列架构深度解析">2 三大消息队列架构深度解析</h2>
<h3 id="21-kafka高吞吐的分布式流处理平台">2.1 Kafka：高吞吐的分布式流处理平台</h3>
<p>Kafka 采用​<strong>发布-订阅模型</strong>​，核心架构基于<strong>主题-分区-副本</strong>的三级设计。主题（Topic）是消息的逻辑分类，每个主题被划分为多个分区（Partition）实现并行处理，每个分区又有多个副本（Replica）保证高可用。</p>
<p>​<strong>设计哲学</strong>​：Kafka 追求极致的吞吐量和持久化能力，采用顺序 I/O 和零拷贝技术优化数据传输。其消费模式为​<strong>拉模式</strong>​（Pull），消费者主动从 Broker 拉取消息，适合高吞吐但不保证极低延迟的场景。</p>
<p>​<strong>核心优势</strong>​：</p>
<ul>
<li>​<strong>吞吐量极致</strong>​：单机每秒可处理百万级消息</li>
<li>​<strong>持久化能力</strong>​：消息持久化到磁盘，支持长期存储和回溯</li>
<li>​<strong>水平扩展</strong>​：通过增加分区和 Broker 轻松扩展容量</li>
<li>​<strong>流处理生态</strong>​：与 Flink、Spark 等流处理框架无缝集成</li>
</ul>
<p>​<strong>架构局限</strong>​：</p>
<ul>
<li>​<strong>延迟相对较高</strong>​：批量处理机制导致延迟在毫秒级</li>
<li>​<strong>功能相对简单</strong>​：缺少灵活的路由和复杂的事务支持</li>
<li>​<strong>运维复杂度高</strong>​：依赖 ZooKeeper（新版本已内置 Raft）</li>
</ul>
<h3 id="22-rabbitmq企业级可靠消息代理">2.2 RabbitMQ：企业级可靠消息代理</h3>
<p>RabbitMQ 基于 AMQP 协议，采用<strong>交换机-队列-绑定</strong>的核心架构。生产者将消息发送到交换机（Exchange），交换机根据绑定规则和路由键将消息路由到相应队列（Queue），消费者从队列获取消息。</p>
<p>​<strong>设计哲学</strong>​：RabbitMQ 注重消息的可靠传递和灵活路由，支持多种交换机类型（Direct、Topic、Fanout 等）实现复杂路由逻辑。其消费模式为​<strong>推模式</strong>​（Push），Broker 主动将消息推送给消费者，实现低延迟。</p>
<p>​<strong>核心优势</strong>​：</p>
<ul>
<li>​<strong>协议支持丰富</strong>​：支持 AMQP、MQTT、STOMP 等多种协议</li>
<li>​<strong>路由灵活</strong>​：通过交换机实现复杂的消息路由策略</li>
<li>​<strong>低延迟</strong>​：微秒级延迟，适合实时性要求高的场景</li>
<li>​<strong>管理界面完善</strong>​：提供友好的 Web 管理界面</li>
</ul>
<p>​<strong>架构局限</strong>​：</p>
<ul>
<li>​<strong>吞吐量相对较低</strong>​：单机吞吐量在万级到十万级</li>
<li>​<strong>扩展性受限</strong>​：队列与节点强耦合，水平扩展困难</li>
<li>​<strong>Erlang 技术栈</strong>​：基于 Erlang 开发，定制和二次开发门槛较高</li>
</ul>
<h3 id="23-rocketmq金融级可靠的消息队列">2.3 RocketMQ：金融级可靠的消息队列</h3>
<p>RocketMQ 采用<strong>主题-队列-消费组</strong>的架构模式。核心组件包括 NameServer（路由管理）、Broker（消息存储）和 Client（生产消费端）。NameServer 负责路由管理，Broker 集群负责消息存储，支持主从复制。</p>
<p>​<strong>设计哲学</strong>​：RocketMQ 在吞吐量和可靠性之间寻求平衡，既保证高吞吐又提供强一致性保障。其消费模式支持<strong>拉模式</strong>和​<strong>推模式</strong>​，兼具灵活性和实时性。</p>
<p>​<strong>核心优势</strong>​：</p>
<ul>
<li>​<strong>金融级可靠性</strong>​：支持事务消息、顺序消息等高级特性</li>
<li>​<strong>吞吐量与延迟平衡</strong>​：单机吞吐量达十万级，延迟在毫秒级</li>
<li>​<strong>消息回溯</strong>​：支持按时间偏移量回溯消息</li>
<li>​<strong>分布式事务</strong>​：提供完整的分布式事务解决方案</li>
</ul>
<p>​<strong>架构局限</strong>​：</p>
<ul>
<li>​<strong>生态系统相对局限</strong>​：主要面向 Java 生态</li>
<li>​<strong>社区活跃度一般</strong>​：相比 Kafka 社区活跃度较低</li>
<li>​<strong>配置复杂度高</strong>​：需要调整较多参数才能达到最优性能</li>
</ul>
<h2 id="3-核心特性对比与性能分析">3 核心特性对比与性能分析</h2>
<h3 id="31-性能指标对比分析">3.1 性能指标对比分析</h3>
<p>以下是三大消息队列在关键性能指标上的量化对比：</p>
<table>
<thead>
<tr>
<th><strong>性能指标</strong>​</th>
<th><strong>Kafka</strong>​</th>
<th><strong>RabbitMQ</strong>​</th>
<th><strong>RocketMQ</strong>​</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>吞吐量</strong>​</td>
<td>百万级/秒</td>
<td>万级-十万级/秒</td>
<td>十万级-百万级/秒</td>
</tr>
<tr>
<td><strong>延迟</strong>​</td>
<td>毫秒级(2-5ms)</td>
<td>微秒级(微秒级)</td>
<td>毫秒级(3-10ms)</td>
</tr>
<tr>
<td><strong>持久化</strong>​</td>
<td>强(磁盘顺序写)</td>
<td>中(内存/磁盘)</td>
<td>强(CommitLog)</td>
</tr>
<tr>
<td><strong>可用性</strong>​</td>
<td>极高(多副本 ISR)</td>
<td>高(镜像队列)</td>
<td>极高(主从同步)</td>
</tr>
</tbody>
</table>
<p><em>数据来源：</em></p>
<p>​<strong>吞吐量分析</strong>​：Kafka 的吞吐量优势源于<strong>顺序 I/O</strong> 和<strong>零拷贝</strong>技术，适合大数据量传输。RabbitMQ 因 AMQP 协议开销和 Erlang 虚拟机特性，吞吐量相对较低但足够满足多数企业应用。RocketMQ 在吞吐量和功能丰富性之间取得了较好平衡。</p>
<p>​<strong>延迟分析</strong>​：RabbitMQ 的微秒级延迟使其成为实时性要求高场景的首选。Kafka 和 RocketMQ 的毫秒级延迟在大多数业务场景中可接受，特别是考虑到它们的高吞吐优势。</p>
<h3 id="32-高级功能对比">3.2 高级功能对比</h3>
<p>​<strong>消息顺序性</strong>​：Kafka 和 RocketMQ 通过分区/队列内顺序保证实现消息有序，但全局有序会牺牲并发性。RabbitMQ 在单队列内可保证顺序，但复杂路由场景下难以保证。</p>
<p>​<strong>事务支持</strong>​：RocketMQ 提供最强的事务支持，尤其是分布式事务场景。Kafka 的事务主要服务于 Exactly-Once 语义。RabbitMQ 的事务性能较差，一般不建议在高并发场景使用。</p>
<p>​<strong>延迟消息</strong>​：RocketMQ 原生支持延迟消息，提供多个固定延迟级别。RabbitMQ 通过 DLX+TTL 模拟延迟消息，灵活性差。Kafka 原生不支持延迟消息，需应用层实现。</p>
<h2 id="4-业务场景匹配指南">4 业务场景匹配指南</h2>
<h3 id="41-典型业务场景技术选型">4.1 典型业务场景技术选型</h3>
<p>​<strong>大数据日志采集</strong>​：推荐 Kafka</p>
<ul>
<li>​<strong>核心需求</strong>​：高吞吐、持久存储、流式处理</li>
<li>​<strong>配置建议</strong>​：多分区并行、异步刷盘、适当副本数</li>
<li>​<strong>规避点</strong>​：避免需要低延迟或复杂路由的场景</li>
</ul>
<p>​<strong>电商交易系统</strong>​：推荐 RocketMQ</p>
<ul>
<li>​<strong>核心需求</strong>​：事务消息、顺序消息、高可靠性</li>
<li>​<strong>配置建议</strong>​：同步刷盘、主从同步、事务消息开关</li>
<li>​<strong>规避点</strong>​：避免协议多样性要求高的场景</li>
</ul>
<p>​<strong>物联网实时通信</strong>​：推荐 RabbitMQ</p>
<ul>
<li>​<strong>核心需求</strong>​：低延迟、多协议支持、设备级路由</li>
<li>​<strong>配置建议</strong>​：内存队列、适当预取值、MQTT 插件</li>
<li>​<strong>规避点</strong>​：避免大数据量持久化场景</li>
</ul>
<p>​<strong>金融支付系统</strong>​：推荐 RocketMQ</p>
<ul>
<li>​<strong>核心需求</strong>​：金融级可靠、消息回溯、分布式事务</li>
<li>​<strong>配置建议</strong>​：同步双写、多副本、严格有序</li>
<li>​<strong>规避点</strong>​：避免弱一致性要求的简单场景</li>
</ul>
<p>​<strong>微服务异步通信</strong>​：视场景选择</p>
<ul>
<li>​<strong>简单解耦</strong>​：RabbitMQ（路由灵活）</li>
<li>​<strong>数据同步</strong>​：Kafka（吞吐优先）</li>
<li>​<strong>事务协调</strong>​：RocketMQ（强一致性）</li>
</ul>
<h3 id="42-选型决策框架">4.2 选型决策框架</h3>
<p>基于业务特征的选型决策树可简化为以下路径：</p>
<ol>
<li>
<p><strong>是否需要极高吞吐(&gt;50 万 TPS)？</strong></p>
<ul>
<li>是 → 选择 Kafka</li>
<li>否 → 进入下一步</li>
</ul>
</li>
<li>
<p><strong>是否需要微秒级延迟？</strong></p>
<ul>
<li>是 → 选择 RabbitMQ</li>
<li>否 → 进入下一步</li>
</ul>
</li>
<li>
<p><strong>是否需要强事务支持？</strong></p>
<ul>
<li>是 → 选择 RocketMQ</li>
<li>否 → 进入下一步</li>
</ul>
</li>
<li>
<p><strong>技术团队熟悉度？</strong></p>
<ul>
<li>Java 技术栈 → RocketMQ/Kafka</li>
<li>多语言团队 → RabbitMQ</li>
<li>大数据团队 → Kafka</li>
</ul>
</li>
</ol>
<h2 id="5-集群部署与运维考量">5 集群部署与运维考量</h2>
<h3 id="51-运维复杂度对比">5.1 运维复杂度对比</h3>
<p><strong>Kafka</strong> 运维复杂度最高，需管理 ZooKeeper 集群（新版本已内置 Raft）、Broker 集群和监控体系。分区重平衡和数据迁移较为复杂，但生态工具丰富。</p>
<p><strong>RabbitMQ</strong> 运维相对简单，镜像队列配置直观，管理界面友好。但集群扩展性受限，跨机房同步需要额外配置。</p>
<p><strong>RocketMQ</strong> 运维复杂度中等，NameServer 无状态设计简化了部署，但性能调优需要较多经验。主从切换和故障恢复机制较为完善。</p>
<h3 id="52-资源消耗模型">5.2 资源消耗模型</h3>
<p>​<strong>内存消耗</strong>​：RabbitMQ 对内存最为敏感，大量连接和队列会显著增加内存压力。Kafka 和 RocketMQ 通过页缓存和磁盘顺序写优化内存使用。</p>
<p>​<strong>CPU 消耗</strong>​：Kafka 的压缩和序列化操作对 CPU 消耗较高。RabbitMQ 的 Erlang 虚拟机在并发连接处理上效率较高。RocketMQ 的 Java 实现需要关注 GC 调优。</p>
<p>​<strong>网络 IO</strong>​：Kafka 的批量传输减少网络往返，但副本同步增加内网流量。RabbitMQ 的单个消息传输效率低，但总体网络消耗与负载成正比。</p>
<h2 id="6-混合架构与迁移策略">6 混合架构与迁移策略</h2>
<h3 id="61-多消息队列共存模式">6.1 多消息队列共存模式</h3>
<p>在复杂系统中，可采用<strong>混合架构</strong>发挥各消息队列优势。常见模式包括：</p>
<p>​<strong>Kafka+RabbitMQ 混合</strong>​：Kafka 处理大数据流，RabbitMQ 处理实时业务消息。通过连接器实现数据双向同步，兼顾吞吐量与实时性。</p>
<p>​<strong>分层消息架构</strong>​：接入层使用 RabbitMQ 处理设备连接，核心层使用 RocketMQ 保证事务，分析层使用 Kafka 进行流处理。各层通过消息路由连接。</p>
<h3 id="62-迁移与升级策略">6.2 迁移与升级策略</h3>
<p>​<strong>从 RabbitMQ 迁移到 Kafka</strong>​：采用双写双读策略，逐步迁移消费者，最后迁移生产者。注意消息模型从队列到主题的转换。</p>
<p>​<strong>从 Kafka 升级集群</strong>​：利用滚动重启和副本机制实现零停机升级。注意版本兼容性和新特性适配。</p>
<p>​<strong>多消息队列共存</strong>​：通过明确边界和职责划分，避免功能重叠。建立统一监控体系，确保整体系统可观测性。</p>
<h2 id="总结">总结</h2>
<p>消息队列选型是技术决策与业务需求的精准匹配过程，没有放之四海皆皆准的最优解。<strong>Kafka</strong> 适用于大数据场景的“重载卡车”，<strong>RabbitMQ</strong> 好似城市中的“跑车”灵活快速，<strong>RocketMQ</strong> 则是全能的“SUV”平衡可靠与性能。</p>
<p>选型决策应基于<strong>业务场景</strong>而非技术参数，综合考虑团队能力和运维成本。在复杂系统中，混合架构往往比单一技术选型更为实用。通过科学的选型框架和持续的效能评估，才能构建既满足当前需求又适应未来发展的消息架构。</p>
<blockquote>
<p>​<strong>技术选型口诀</strong>​：小量低延 RabbitMQ，大数据流用 Kafka，金融可靠 RocketMQ</p>
</blockquote>
<hr>
<p><strong>📚 下篇预告</strong>​</p>
<p>《Kafka 入门必知概念——Topic、分区、Offset、消费组的协作机制与影响》—— 我们将深入探讨：</p>
<ul>
<li>📊 ​<strong>Topic 设计原则</strong>​：分区策略、副本因子与消息保序的平衡之道</li>
<li>🔄 ​<strong>消费组协调</strong>​：重平衡机制、分区分配算法与消费者故障转移</li>
<li>📍 ​<strong>Offset 管理策略</strong>​：提交时机、语义选择与数据一致性保障</li>
<li>⚙️ ​<strong>生产者调优</strong>​：ACK 机制、批量压缩与幂等发送的配置要点</li>
<li>🔍 ​<strong>故障诊断指南</strong>​：常见消费延迟、重复消费与数据丢失的解决方案</li>
</ul>
<p><strong>​点击关注，掌握 Kafka 核心原理与最佳实践！​</strong>​</p>
<blockquote>
<p>​<strong>今日行动建议</strong>​：</p>
<ol>
<li>分析当前业务的消息场景，明确吞吐量、延迟和可靠性需求</li>
<li>评估团队技术栈，选择匹配度最高的消息队列方案</li>
<li>设计概念验证，在测试环境验证选型假设</li>
<li>制定渐进式迁移策略，降低生产环境风险</li>
</ol>
</blockquote>

</div>
<div id="MySignature" role="contentinfo">
    进阶之路，神挡杀神佛挡杀佛，欢迎大家一起加ＱＱ群共同讨论成长，群号：<a href="https://jq.qq.com/?_wv=1027&amp;k=4AiobC0" target="view_window">620095084</a>
<br>
欢迎搜索关注微信公众号 基础全知道 ：JavaBasis ，第一时间阅读最新文章
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 21:07">2025-12-22 21:07</span>&nbsp;
<a href="https://www.cnblogs.com/shiyuelp">十月南城</a>&nbsp;
阅读(<span id="post_view_count">2</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384355);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384355', targetLink: 'https://www.cnblogs.com/shiyuelp/p/19384355', title: 'MQ 选型框架——Kafka/RabbitMQ/RocketMQ 的模型差异与业务匹配清单' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ CoT论文阅读笔记 ]]></title>
    <link>https://www.cnblogs.com/nanimono/p/19384310</link>
    <guid>d207ce2c7984d3b4bf185650b0da0220</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/nanimono/p/19384310" title="发布于 2025-12-22 20:46">
    <span role="heading" aria-level="2">CoT论文阅读笔记</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<h3>一、介绍</h3>
<div style="text-align: left"><span style="font-size: 14px">CoT(Chain of Thought)思维链是一种能够激发大模型潜力，提升模型解决<strong>复杂推理问题</strong>（如数学逻辑问题、常识问题和符号逻辑问题）正确率的经典提示方法。其原理是通过在提示词中提供带有<strong>分步推理过程</strong>的few-shot examples(少量示例)，或者添加明确的“请一步一步思考”指令，<strong>引导</strong>模型在生成最终答案前，先输出其推理过程。这种方法<strong>仅通过改变提示词，无需进行模型微调</strong>，即可显著提高输出准确率。 思维链的目的是希望大模型模仿人类在思考复杂问题时，进行<strong>内在的、逐步的探索性推理行为</strong>。Chain-of-Thought的本质，就是让AI模型像一名优秀的中国学生一样，在“草稿纸”上先写出严谨的解题步骤（Thinking），最后再 confidently 地写下最终答案（Answer）。</span></div>
<h3>二、核心优势</h3>
<p><span style="font-size: 14px">思维链有几大核心的优势：</span></p>
<ol>
<li class="ybc-li-component ybc-li-component_ol"><span class="ybc-li-component__dot-wp" style="font-size: 14px"><span class="ybc-li-component_content"><strong>动态计算资源分配</strong> 对于通用大模型，如果prompt没有应用思维链提示技巧，模型在处理一个只需一步思考的简单问题（如1+1=？）和一个需要多步探索的复杂问题（如制定20人团建计划）时，<strong>分配给每个生成步骤（token）的计算资源是相似的</strong>。但应用CoT提示后，模型被引导进行多步推理，<strong>通过增加推理步骤的数量</strong>，间接地为复杂问题分配了更多的<strong>总体计算资源（token数）</strong>，从而实现了计算能力的动态分配。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ol"><span class="ybc-li-component__dot-wp" style="font-size: 14px"><span class="ybc-li-component_content"><strong>可解释性和可调试性</strong> 通过显式输出模型的思考过程，模型的推理不再是一个“黑箱”。当输出错误时，开发者可以直接观察推理链，定位问题根源（是事实错误？逻辑错误？计算错误？），从而有针对性地优化提示词或调整流程。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ol"><span class="ybc-li-component__dot-wp" style="font-size: 14px"><span class="ybc-li-component_content"><strong>通用性</strong> 无论是数学问题、常识推理，还是具体的符号推理任务，都可以应用CoT技巧。论文通过实验验证了其在多个领域的有效性。CoT适用于几乎一切需要分步骤解决的复杂问题，不存在领域之间的隔阂。 而且，通过符号推理实验（如末字母拼接），研究者发现，模型可以通过模仿简单的示例（如拼接2个单词的末字母），<strong>泛化</strong>处理比示例本身更复杂的任务（如拼接3个或更多单词的末字母）。这体现了CoT赋予模型的<strong>长度泛化能力</strong>。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ol"><span class="ybc-li-component__dot-wp" style="font-size: 14px"><span class="ybc-li-component_content"><strong>易于实现</strong> 不需要微调模型，也不需要额外的训练，只需要在提示词里提供包含<strong>清晰分步推理过程</strong>的示例（Few-shot CoT），或者添加引导性指令（Zero-shot CoT），就可以显著提升模型在复杂任务上的表现。这与传统Few-shot prompting的区别在于，其示例的核心是<strong>展示“如何思考”的过程</strong>，而不仅仅是“输入-输出”对。 </span></span></li>
</ol>
<p><span style="font-size: 14px"><strong>总结</strong>：这四点共同勾勒出CoT的核心价值——它是一种强大、通用、透明且易于实施的方法，能有效<strong>激发和释放</strong>大模型已有的、但未被标准提示方法充分调用的推理潜力。 <strong>备注</strong>：在这篇论文发表的2022年，模型的能力还比较有限，很多常识问题都会出错。使用CoT可以大大降低出错率。现在随着模型能力的提升，一些简单常识问题的错误率已经很低了，但这并不是说CoT的思想过时了。相反，它从“教模型走路”变成了“指挥模型跑步”。当面对<strong>复杂、开放、模糊的现实世界任务</strong>时，“显式、分步推理”仍然是最优的引导方式之一。后续的ReAct架构（推理+行动）也是建立在CoT的基础上的。</span></p>
<h3>三、限制</h3>
<p>首先，论文中通过实验得出结论：只有模型达到<strong>一定规模（如论文中测试的约100B+参数）</strong>时，CoT对生成效果才有显著提升。对于（2022年时的）<strong>小模型（如远小于10B参数）</strong>而言，CoT非但对解决复杂问题没有帮助，<strong>其生成的推理链本身质量低下且可能包含错误</strong>，甚至可能干扰最终答案的生成（即“丢了西瓜捡芝麻”）。其次，对于不需要多步骤推理的<strong>简单任务</strong>，如单纯的知识检索或简单模式匹配，CoT带来的提升不大。 </p>
<p><strong>高收益任务</strong>：数学应用题、复杂规划、逻辑谜题、代码调试、策略分析等<strong>需要多步推理</strong>的任务。 </p>
<p><strong>低收益任务</strong>：简单分类、情感分析、实体识别、一步到位的<strong>事实问答</strong>等。</p>
<h3>四、总结</h3>
<h4>全文最重要的观点：<strong>CoT揭示了模型能力的“下限”</strong></h4>
<p>作者提出一个核心观点：我们之前用“标准提示”测出的模型性能，可能只是其<strong>真实能力的“下限”</strong>。CoT的出现证明，通过<strong>更优的“提问方式”或“引导方法”</strong>（即提示工程），我们还能从<strong>现有模型</strong>中激发出远未被标准提示方法挖掘的潜力。这打破了“模型性能<strong>仅</strong>由训练数据决定”的旧观念，<strong>极大地凸显了“提示工程”在解锁模型潜能方面的极端重要性</strong>。</p>
<h3>五、最新发展</h3>
<p><strong>1. 将CoT能力迁移到小模型 - 算法蒸馏与数据优化</strong> 近几年，基础模型公司推出了越来越多效果不错的<strong>小参数模型</strong>。这使得论文中“CoT主要在大模型（100B+）有效”的观点需要结合<strong>最新技术进展</strong>来看待。</p>
<ul class="ybc-ul-component">
<li class="ybc-li-component ybc-li-component_ul"><span class="ybc-li-component__dot-wp"><span class="ybc-li-component_content"><strong>算法蒸馏 (Algorithm Distillation)</strong>：小模型无法有效应用CoT常被归因于<strong>抽象推理能力的缺失</strong>。一种解决方案是<strong>算法蒸馏</strong>：在大量<strong>合成数据</strong>（由大模型自动生成的高质量“问题-推理链-答案”数据）上训练小模型，目标是让小模型<strong>直接学习底层的推理算法或模式</strong>（如“映射”、“过滤”、“归约”等核心操作），而不仅仅是模仿表面模式。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ul"><span class="ybc-li-component__dot-wp"><span class="ybc-li-component_content"><strong>注意力蒸馏/模式迁移 (Attention Distillation/Pattern Transfer)</strong>：另一种思路是<strong>迁移大模型的推理模式</strong>。例如，通过特定技术（如DeepSeek-VL的TinyThink架构），将大模型在推理过程中的<strong>跨步注意力模式</strong>提炼给小模型。研究表明，通过优化这种迁移，7B模型在特定符号任务上能达到540B模型92%的性能。 </span></span></li>
</ul>
<p><strong>什么是合成数据？</strong>​ 使用如 <strong>PromptCoT 2.0</strong>​ 的框架，让大语言模型自动生成大量高难度、包含详细推理步骤的“问题-推理链-答案”数据。然后用这些合成数据训练小模型。 <strong>2. 围绕CoT方法论的工程进展</strong> 从模型角度看，越来越多的模型在<strong>预训练或指令微调</strong>阶段就被赋予了“一步一步思考”的倾向或能力，CoT正从一种外部提示技巧，逐渐演变成模型<strong>内化的能力</strong>。 从工程角度看，CoT通过<strong>设计模型的“输出格式”来规范甚至提升其“思考质量”</strong>​ 的思想，催生了一系列更成熟的工程范式：</p>
<ul class="ybc-ul-component">
<li class="ybc-li-component ybc-li-component_ul"><span class="ybc-li-component__dot-wp"><span class="ybc-li-component_content"><strong>1）结构化输出 (Structured Output)</strong>：强制要求模型以JSON、XML等结构化格式输出推理过程和最终答案，便于程序解析和集成（如<code class="hyc-common-markdown__code__inline">{"reasoning": "...", "answer": "..."}</code>）。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ul"><span class="ybc-li-component__dot-wp"><span class="ybc-li-component_content"><strong>2）思维即代码/可执行推理 (Reasoning as Code / Executable Reasoning)</strong>：引导模型用类代码（如伪代码、特定DSL）的形式表达思考过程，这种表示更精确、无歧义，甚至可被解释执行（如<code class="hyc-common-markdown__code__inline">revenue = 1000000; cost = 700000; profit = revenue - cost; ...</code>）。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ul"><span class="ybc-li-component__dot-wp"><span class="ybc-li-component_content"><strong>3）智能体间通信协议 (Agent-to-Agent Communication Protocol - A2A)</strong>：在多智能体系统中，规定智能体之间交换信息的<strong>严格结构化格式</strong>（如基于JSON Schema）。一个智能体（规划者）的输出（结构化指令）即是另一个智能体（执行者）的输入，确保指令清晰无歧义。 </span></span></li>
<li class="ybc-li-component ybc-li-component_ul"><span class="ybc-li-component__dot-wp"><span class="ybc-li-component_content"><strong>4）ReAct架构 (Reasoning + Acting)</strong>：这是对CoT的<strong>重要扩展</strong>。它将CoT的“思考”步骤与<strong>行动（Action）</strong>（如调用API、查询知识库）和<strong>观察（Observation）</strong>（行动结果）交织在一起，形成 <code class="hyc-common-markdown__code__inline">思考 -&gt; 行动 -&gt; 观察 -&gt; 再思考 -&gt; ...</code>的循环，大大提升了智能体解决<strong>需要与环境交互</strong>的复杂任务的能力。</span></span></li>
</ul>
<p>&nbsp;</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 20:46">2025-12-22 20:46</span>&nbsp;
<a href="https://www.cnblogs.com/nanimono">溯光独立开发</a>&nbsp;
阅读(<span id="post_view_count">3</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384310);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384310', targetLink: 'https://www.cnblogs.com/nanimono/p/19384310', title: 'CoT论文阅读笔记' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 【Ubuntu】Ubuntu 22.04 与 Windows 跨系统文件共享的完整方案 ]]></title>
    <link>https://www.cnblogs.com/Skyrim-sssuuu/p/19381887</link>
    <guid>6c901c7ccf4728990494f3442a345d0a</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/Skyrim-sssuuu/p/19381887" title="发布于 2025-12-22 20:37">
    <span role="heading" aria-level="2">【Ubuntu】Ubuntu 22.04 与 Windows 跨系统文件共享的完整方案</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="引言">引言</h1>
<p>这应该也是个比较常见的需求，最近刚好就用到了，特在此记录一下。<br>
这篇随笔目的是：</p>
<ol>
<li><strong>将 Windows 的文件共享到 Ubuntu 中<br>
aim：方便将 Windows 本地文件工程转移到 Ubuntu</strong></li>
<li><strong>将 Ubuntu 的文件共享到 Windows 中<br>
aim：方便 Windows 某些程序方便定位某些位于 Ubuntu 上目标文件夹的路径</strong></li>
</ol>
<h1 id="参考文章">参考文章</h1>
<blockquote>
<p><a href="https://blog.csdn.net/qq_44078824/article/details/119847027" title="【详细步骤】Ubuntu安装Samba服务及配置共享文件夹" target="_blank" rel="noopener nofollow">【详细步骤】Ubuntu安装Samba服务及配置共享文件夹</a><br>
<a href="https://zhuanlan.zhihu.com/p/475119154" title="Ubuntu共享文件夹的创建和使用" target="_blank" rel="noopener nofollow">Ubuntu共享文件夹的创建和使用</a><br>
<a href="https://blog.csdn.net/ss_0507/article/details/150583096" title="Ubuntu22.04设置共享文件夹" target="_blank" rel="noopener nofollow">Ubuntu22.04设置共享文件夹</a></p>
</blockquote>
<h1 id="windows-文件共享到-ubuntu">Windows 文件共享到 Ubuntu</h1>
<h2 id="步骤一设置-windows-下的共享文件">步骤一：设置 Windows 下的共享文件</h2>
<p>我使用的是 VMware 这款虚拟机平台（其他的应该也差不多），操作如下：</p>
<ol>
<li><strong>右键虚拟机 -&gt; 设置</strong></li>
<li><strong>选项 -&gt; 共享文件夹 -&gt; 添加 -&gt; 选择 Windows 下的一个文件夹</strong></li>
</ol>
<p><img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222144536382-422437124.png" alt="3619091-20251222133645048-710056770" loading="lazy"></p>
<h2 id="步骤二将共享文件夹挂载在-ubuntu-下">步骤二：将共享文件夹挂载在 Ubuntu 下</h2>
<ol>
<li>
<p><strong>安装/更新工具包</strong></p>
<pre><code> // 以管理员权限更新系统软件包索引
 sudo apt update
 
 // 安装 VMware Tools 的开源替代版 open-vm-tools（实现虚拟机与主机的基础交互 / 共享功能）
 sudo apt install open-vm-tools
 
 // 更新 FUSE 版本
 sudo apt-get install fuse
</code></pre>
</li>
<li>
<p><strong>共享文件的文件夹位置在<code>/mnt/hgfs/</code>目录下，假如没有这个目录，就创建一个</strong></p>
<pre><code> sudo mkdir -p /mnt/hgfs/
</code></pre>
</li>
<li>
<p><strong>敲指令进入此目录，并进行挂载</strong></p>
<pre><code> // 进入 /mnt/hgfs/ 目录
 cd /mnt/hgfs/
 
 // 通过 VMware 的 hgfs 工具将主机所有共享文件夹挂载到虚拟机的/mnt/hgfs目录
 sudo vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other,uid=1000,gid=1000,umask=022
 
 // allow_other：允许普通用户访问挂载目录
 // uid=1000：将挂载目录的文件所有者设为 UID=1000 的普通用户（避免仅 root 可访问，可通过`id`命令查看）
 // gid=1000：将挂载目录的文件所属组设为 GID=1000 的用户组
 // umask=022：设置挂载目录的默认权限（让普通用户可读可写，其他用户只读）
</code></pre>
</li>
<li>
<p><strong>设置开机自动挂载</strong></p>
<pre><code> // 打开开机配置文件夹，编辑开机自动执行的命令
 sudo nano /etc/rc.local

 // 在配置文件夹中输入，即可完成开机自动挂载共享文件夹：
 sudo vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other,uid=1000,gid=1000,umask=022
</code></pre>
</li>
</ol>
<p>可以看到，已经挂载成功：</p>
<p><img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222183127087-1919558918.png" alt="image" loading="lazy"></p>
<h1 id="ubuntu-文件共享到-windows">Ubuntu 文件共享到 Windows</h1>
<h2 id="步骤一安装-samba-工具设置共享目录的读写权限">步骤一：安装 samba 工具，设置共享目录的读写权限</h2>
<pre><code>// 以管理员权限更新系统软件包索引
sudo apt update

// Samba 服务的主程序（实现 Linux 与 Windows 的文件共享）
// Samba 的通用配置文件和工具（提供共享配置的基础依赖）
// Samba 的客户端工具（用于在 Linux 终端测试 / 访问远程共享目录）
sudo apt-get install samba samba-common smbclient

// 将home设置为共享
sudo chmod 777 /home
</code></pre>
<h2 id="步骤二samba-配置">步骤二：samba 配置</h2>
<ol>
<li>
<p><strong>添加 samba 用户，并设置密码</strong></p>
<pre><code> // 输入两次密码
 sudo smbpasswd -a 用户名
</code></pre>
</li>
<li>
<p><strong>使用 nano 修改 samba 配置文件</strong></p>
<pre><code> // 个人习惯用 nano
 sudo nano /etc/samba/smb.conf
 
 添加：
 [share]
 comment = share folder  # 共享描述
 browseable = yes        # 允许网络中可见该共享
 path = /home            # 共享文件夹的实际路径
 create mask = 0700      # 新建文件的默认权限（仅文件所有者可读/写/执行）
 directory mask = 0700   # 新建文件夹的默认权限（仅文件夹所有者可读/写/执行）
 valid users = shf       # 仅允许xxx用户访问该共享
 force user = shf        # 强制将共享内文件的所有者设为xxx（避免权限混乱）
 force group = shf       # 强制将共享内文件的所属组设为xxx
 public = yes            # 允许匿名访问（注：与valid users冲突，实际仅shf可访问）
 available = yes         # 启用该共享（设为no则禁用）
 writable = yes          # 允许对共享目录进行写入/修改/删除操作
</code></pre>
<p>如图，将其添加到此文件最后的位置：</p>
<p><img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222201837632-881410970.png" alt="image" loading="lazy"></p>
</li>
<li>
<p><strong>重启samba服务器</strong></p>
<pre><code> sudo service smbd restart
</code></pre>
</li>
<li>
<p><strong>查看主机静态 IP 并测试是否能 Ping 通</strong><br>
由于之前已经配置好了简单的三网段，可以参考这篇文章：</p>
<blockquote>
<p><a href="https://www.cnblogs.com/Skyrim-sssuuu/p/19376866" title="【Ubuntu】Ubuntu 虚拟机配置三网段（桥接-WIFI、仅主机、桥接-开发板）" target="_blank">【Ubuntu】Ubuntu 虚拟机配置三网段（桥接-WIFI、仅主机、桥接-开发板）</a></p>
</blockquote>
<p>查看 IP 地址：</p>
<pre><code> ifconfig
</code></pre>
<p>返回如下图，其中<code>192.168.184.184</code>则是我给仅主机设置的静态 IP 地址，待会要用到。<br>
<img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222201510793-1988332202.png" alt="image" loading="lazy"></p>
<pre><code> // 输入：
 ping -c 3 192.168.184.1
 返回：
 PING 192.168.184.1 (192.168.184.1) 56(84) bytes of data.
 64 bytes from 192.168.184.1: icmp_seq=1 ttl=128 time=0.378 ms
 64 bytes from 192.168.184.1: icmp_seq=2 ttl=128 time=0.423 ms
 64 bytes from 192.168.184.1: icmp_seq=3 ttl=128 time=0.438 ms

 --- 192.168.184.1 ping statistics ---
 3 packets transmitted, 3 received, 0% packet loss, time 2050ms
 rtt min/avg/max/mdev = 0.378/0.413/0.438/0.025 ms
</code></pre>
</li>
<li>
<p><strong>测试 Samba 共享是否正常</strong></p>
<pre><code> 输入：
 smbclient -L //localhost/home -U 用户名
 输入密码后即可返回：
 		Sharename       Type      Comment
 		---------       ----      -------
 		home            Disk      home guest share
 		print$          Disk      Printer Drivers
 		IPC$            IPC       IPC Service (ubuntu-skyrim server (Samba, Ubuntu))
 SMB1 disabled -- no workgroup available
</code></pre>
</li>
<li>
<p><strong>Windows 操作挂载共享文件夹</strong><br>
右键此电脑，选择映射网络驱动。</p>
<p><img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222202958445-651518490.png" alt="image" loading="lazy"></p>
<p>选择一个驱动器，这里我选择了 H盘（由于我已经配置过了，所以后面会显示我的静态 IP 地址和共享文件夹），文件夹那里根据示例来填写即可：</p>
<pre><code> \\192.168.184.184\share
 注意这里 IP 地址后面好像只能填 share，我这里填写 home 不行。
 填写完后输入你的 Ubuntu 用户名和密码即可。
</code></pre>
<p><img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222203101977-1510784502.png" alt="image" loading="lazy"></p>
</li>
<li>
<p><strong>打开此电脑，查看共享文件夹</strong><br>
看到在网络位置多了一个盘，就说明挂载成功了。</p>
<p><img src="https://img2024.cnblogs.com/blog/3619091/202512/3619091-20251222203604661-363419804.png" alt="image" loading="lazy"></p>
</li>
</ol>
<h1 id="博客导航">博客导航</h1>
<blockquote>
<p><a href="https://www.cnblogs.com/Skyrim-sssuuu/p/19140894" title="博客导航" target="_blank">博客导航</a></p>
</blockquote>

</div>
<div id="MySignature" role="contentinfo">
    <p>本文来自博客园，作者：<a href="https://www.cnblogs.com/Skyrim-sssuuu/" target="_blank">膝盖中箭卫兵</a>，转载请注明原文链接：<a href="https://www.cnblogs.com/Skyrim-sssuuu/p/19381887" target="_blank">https://www.cnblogs.com/Skyrim-sssuuu/p/19381887</a></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.002777777777777778" data-date-updated="2025-12-22 20:41">2025-12-22 20:37</span>&nbsp;
<a href="https://www.cnblogs.com/Skyrim-sssuuu">膝盖中箭卫兵</a>&nbsp;
阅读(<span id="post_view_count">14</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19381887);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19381887', targetLink: 'https://www.cnblogs.com/Skyrim-sssuuu/p/19381887', title: '【Ubuntu】Ubuntu 22.04 与 Windows 跨系统文件共享的完整方案' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 【Agent】MemOS 源码笔记---(7)---MemScheduler 细节 ]]></title>
    <link>https://www.cnblogs.com/rossiXYZ/p/19364457</link>
    <guid>f3e434fdaea83dcfce7317d536ec9114</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/rossiXYZ/p/19364457" title="发布于 2025-12-22 20:15">
    <span role="heading" aria-level="2">【Agent】MemOS 源码笔记---(7)---MemScheduler 细节</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="agentmemos-源码笔记---7---memscheduler-细节">【Agent】MemOS 源码笔记---(7)---MemScheduler 细节</h1>
<p></p><div class="toc"><div class="toc-container-header">目录</div><ul><li><a href="#agentmemos-源码笔记---7---memscheduler-细节" rel="noopener nofollow">【Agent】MemOS 源码笔记---(7)---MemScheduler 细节</a><ul><li><a href="#0x00-摘要" rel="noopener nofollow">0x00 摘要</a></li><li><a href="#0x01-组件关系" rel="noopener nofollow">0x01 组件关系</a></li><li><a href="#0x02-实现" rel="noopener nofollow">0x02 实现</a><ul><li><a href="#21-generalscheduler" rel="noopener nofollow">2.1 GeneralScheduler</a><ul><li><a href="#211-消息处理" rel="noopener nofollow">2.1.1 消息处理</a><ul><li><a href="#消息类型与processor注册" rel="noopener nofollow">消息类型与processor注册</a></li><li><a href="#消息分发过程" rel="noopener nofollow">消息分发过程</a></li></ul></li><li><a href="#212-流程" rel="noopener nofollow">2.1.2 流程</a></li><li><a href="#213-完整代码" rel="noopener nofollow">2.1.3 完整代码</a></li></ul></li><li><a href="#22-schedulerdispatcher" rel="noopener nofollow">2.2 SchedulerDispatcher</a><ul><li><a href="#221-分发逻辑" rel="noopener nofollow">2.2.1 分发逻辑</a></li><li><a href="#222-流程" rel="noopener nofollow">2.2.2 流程</a></li><li><a href="#223-代码" rel="noopener nofollow">2.2.3 代码</a></li></ul></li><li><a href="#23-schedulerretriever" rel="noopener nofollow">2.3 SchedulerRetriever</a><ul><li><a href="#231-功能" rel="noopener nofollow">2.3.1 功能</a></li><li><a href="#232-详细步骤说明" rel="noopener nofollow">2.3.2 详细步骤说明</a></li><li><a href="#233-调用关系" rel="noopener nofollow">2.3.3 调用关系</a></li><li><a href="#234-实现" rel="noopener nofollow">2.3.4 实现</a><ul><li><a href="#记忆检索流程search-方法" rel="noopener nofollow">记忆检索流程（search 方法）</a></li><li><a href="#记忆全流程处理与重排process_and_rerank_memories-方法" rel="noopener nofollow">记忆全流程处理与重排（process_and_rerank_memories 方法）</a></li><li><a href="#llm-记忆重排流程rerank_memories-方法" rel="noopener nofollow">LLM 记忆重排流程（rerank_memories 方法）</a></li><li><a href="#代码" rel="noopener nofollow">代码</a></li></ul></li></ul></li></ul></li><li><a href="#0x03-关联" rel="noopener nofollow">0x03 关联</a><ul><li><a href="#31-schedulerdispatcher-和-generalscheduler" rel="noopener nofollow">3.1 SchedulerDispatcher 和 GeneralScheduler</a></li><li><a href="#32-generalscheduler-和-treetextmemory" rel="noopener nofollow">3.2 GeneralScheduler 和 TreeTextMemory</a></li><li><a href="#33-总结" rel="noopener nofollow">3.3 总结</a></li><li><a href="#34-moscore" rel="noopener nofollow">3.4 MosCore</a></li></ul></li><li><a href="#0xff-参考" rel="noopener nofollow">0xFF 参考</a></li></ul></li></ul></div><p></p>
<h2 id="0x00-摘要">0x00 摘要</h2>
<p>记忆调度就像大脑的注意力机制，动态决定在合适的时刻调用合适的记忆。</p>
<p>在 MemOS 中，<strong>记忆调度（Memory Scheduling）</strong> 通过对【不同使用效率（参数&gt;激活&gt;工作&gt;其他明文）的记忆】的相互调度，让模型能更高效、准确地获取用户所需的记忆。在对话和任务进行时，通过预测用户后续对话所需记忆并提前调入高效率记忆类型如激活记忆工作记忆，加速推理链路。</p>
<p>记忆调度的具体实现就是MemScheduler ，这是一个与 MemOS 系统并行运行的并发记忆管理系统，它协调 AI 系统中工作记忆、长时记忆和激活记忆之间的记忆操作。它通过事件驱动调度处理记忆检索、更新和压缩。该系统特别适合需要动态记忆管理的对话代理和推理系统。</p>
<p>备注：本文基于MemOS的文档和源码进行学习，似乎其文档并没有跟上源码更新的速度，而且也有部分功能未实现或者未开源。</p>
<p>前一篇介绍了 MemScheduler 的总体概念，本篇来看看实现细节。</p>
<h2 id="0x01-组件关系">0x01 组件关系</h2>
<p>最核心的几个组件关系如下：</p>
<ul>
<li>GeneralScheduler 是整个调度系统的核心组件，继承自 BaseScheduler，负责处理不同类型的消息（查询、回答、添加等），并协调其他组件完成具体任务。</li>
<li>SchedulerDispatcher 是消息分发器，负责将不同类型的消息分发给对应的processor，支持并行处理（可选）。</li>
<li>SchedulerRetriever 是记忆检索器，负责从记忆库中搜索、重排序和过滤记忆项，提供智能记忆管理功能。</li>
</ul>
<p><img alt="MemScheduler-7-1" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1850883/202512/1850883-20251217235057999-1525991890.png" class="lazyload"></p>
<p>MemOS-main\src\memos\templates\mem_scheduler_prompts.py 中可以看到使用的prompt。</p>
<pre><code>PROMPT_MAPPING = {
    "intent_recognizing": INTENT_RECOGNIZING_PROMPT,
    "memory_reranking": MEMORY_RERANKING_PROMPT,
    "query_keywords_extraction": QUERY_KEYWORDS_EXTRACTION_PROMPT,
    "memory_filtering": MEMORY_FILTERING_PROMPT,
    "memory_redundancy_filtering": MEMORY_REDUNDANCY_FILTERING_PROMPT,
    "memory_combined_filtering": MEMORY_COMBINED_FILTERING_PROMPT,
    "memory_answer_ability_evaluation": MEMORY_ANSWER_ABILITY_EVALUATION_PROMPT,
}
</code></pre>
<h2 id="0x02-实现">0x02 实现</h2>
<h3 id="21-generalscheduler">2.1 GeneralScheduler</h3>
<p>BaseScheduler是基类，而GeneralScheduler才是真正起作用的派生类。</p>
<p>GeneralScheduler采用生产者-消费者模型进行工作，是基于消息队列的内存调度器。</p>
<ul>
<li>
<p>该类是 MemOS 中基于<code>BaseScheduler</code>的具体调度器实现，专注于处理查询、回答和添加内存等核心任务。核心组件架构：</p>
<ul>
<li>消息队列：使用 memos_message_queue 来存储待处理的消息。</li>
<li>消费者线程：使用 _message_consumer 方法持续轮询队列并处理消息。</li>
<li>分发器：SchedulerDispatcher 负责将消息路由到对应的processor。</li>
<li>处理器：针对不同消息类型的具体processor。</li>
</ul>
</li>
<li>
<p>核心功能包括：</p>
<ul>
<li>注册消息类型（查询 / 回答 / 添加）注册对应的processor，实现任务的定向分发；</li>
<li>处理查询消息时，提取关键词、更新查询监控、执行内存检索与重排序，并支持激活内存的周期性更新；</li>
<li>处理添加内存消息时，记录新增内存日志并同步到监控系统；</li>
<li>基于会话对话轮次逻辑，根据意图检测和时间触发机制决定决定是否执行内存检索，确保工作内存的时效性和相关性。</li>
</ul>
</li>
<li>
<p>特色是基于消息类型的模块化处理机制，结合意图识别和时间触发的混合调度策略，支持按用户和内存立方体分组处理消息，保证多用户场景下的内存隔离和处理效率。</p>
</li>
</ul>
<h4 id="211-消息处理">2.1.1 消息处理</h4>
<p>SchedulerDispatcher将消息路由到适当的处理器。</p>
<h5 id="消息类型与processor注册">消息类型与processor注册</h5>
<p>初始化时注册了三种消息processor。</p>
<pre><code class="language-python">        # register handlers
        handlers = {
            QUERY_LABEL: self._query_message_consumer,
            ANSWER_LABEL: self._answer_message_consumer,
            ADD_LABEL: self._add_message_consumer,
        }
        self.dispatcher.register_handlers(handlers)
</code></pre>
<ul>
<li>_query_message_consumer：处理用户查询 QUERY_LABEL，触发记忆检索和重排序</li>
<li>_answer_message_consumer：处理系统回答 ANSWER_LABEL。</li>
<li>_add_message_consumer：处理新增记忆请求 ADD_LABEL。</li>
</ul>
<p>QUERY_LABEL在memos/mem_scheduler/schemas/general_schemas.py文件中定义为一个常量：</p>
<ul>
<li>QUERY_LABEL="query"</li>
<li>ANSWER_LABEL ="anSwer"</li>
<li>ADD_LABEL = "add"</li>
</ul>
<p>这是一个预定义的字符串常量，值为"query"。</p>
<h5 id="消息分发过程">消息分发过程</h5>
<ul>
<li>消息提交：通过submit_messages 将ScheduleMessageItem放入消息队列。</li>
<li>消息消费：_message_consumer 线程定期从队列中取出所有消息。</li>
<li>消息分发：调用self.dispatcher.dispatch(messages)按消息标签分发到对应的processor。</li>
</ul>
<h4 id="212-流程">2.1.2 流程</h4>
<p>GeneralScheduler的流程如下。</p>
<p><img alt="MemScheduler-7-2" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1850883/202512/1850883-20251217235110795-709389211.png" class="lazyload"></p>
<h4 id="213-完整代码">2.1.3 完整代码</h4>
<pre><code class="language-python">class GeneralScheduler(BaseScheduler):
    """通用调度器，实现查询、回答和添加内存等具体任务的处理逻辑"""

    def __init__(self, config: GeneralSchedulerConfig):
        """使用给定定配置初始化通用调度器"""
        super().__init__(config)

        # 查询关键词数量限制（从配置获取，默认20）
        self.query_key_words_limit = self.config.get("query_key_words_limit", 20)

        # 注册消息processor（按消息标签绑定对应的处理方法）
        handlers = {
            QUERY_LABEL: self._query_message_consumer,  # 处理查询消息
            ANSWER_LABEL: self._answer_message_consumer,  # 处理回答消息
            ADD_LABEL: self._add_message_consumer,  # 处理添加内存消息
        }
        self.dispatcher.register_handlers(handlers)

    def _query_message_consumer(self, messages: list[ScheduleMessageItem]) -&gt; None:
        """
        处理和响应队列中的查询触发消息

        参数:
            messages: 要处理的查询消息列表
        """
        # 按用户和内存立方体分组处理消息
        grouped_messages = self.dispatcher.group_messages_by_user_and_cube(messages=messages)

        # 验证消息合法性（确保标签与消息类型匹配）
        self.validate_schedule_messages(messages=messages, label=QUERY_LABEL)

        # 遍历分组消息，按用户和内存立方体处理
        for user_id in grouped_messages:
            for mem_cube_id in grouped_messages[user_id]:
                messages = grouped_messages[user_id][mem_cube_id]
                if len(messages) == 0:
                    return

                # 获取当前内存立方体实例
                mem_cube = messages[0].mem_cube

                # 从消息更新当前上下文（线程安全）
                self._set_current_context_from_message(msg=messages[0])

                # 更新查询监控器（为每个消息注册查询记录）
                for msg in messages:
                    # 若监控器不存在则创建
                    self.monitor.register_query_monitor_if_not_exists(
                        user_id=user_id, mem_cube_id=mem_cube_id
                    )

                    # 提取查询内容和关键词
                    query = msg.content
                    query_keywords = self.monitor.extract_query_keywords(query=query)

                    # 关键词提取失败时的 fallback 逻辑
                    if len(query_keywords) == 0:
                        stripped_query = query.strip()
                        # 根据语言类型选择分词方式
                        if is_all_english(stripped_query):
                            words = stripped_query.split()  # 英文按空格分词
                        elif is_all_chinese(stripped_query):
                            words = stripped_query  # 中文按字符处理
                        else:
                            words = stripped_query  # 混合语言默认按字符处理

                        # 取前N个关键词（去重）
                        query_keywords = list(set(words[: self.query_key_words_limit]))

                    # 创建查询监控项并添加到数据库
                    item = QueryMonitorItem(
                        user_id=user_id,
                        mem_cube_id=mem_cube_id,
                        query_text=query,
                        keywords=query_keywords,
                        max_keywords=DEFAULT_MAX_QUERY_KEY_WORDS,
                    )

                    # 同步到数据库
                    query_db_manager = self.monitor.query_monitors[user_id][mem_cube_id]
                    query_db_manager.obj.put(item=item)
                    query_db_manager.sync_with_orm()  # 添加后同步到数据库

                # 提取所有查询内容
                queries = [msg.content for msg in messages]

                # 执行会话轮次处理（检索相关内存）
                cur_working_memory, new_candidates = self.process_session_turn(
                    queries=queries,
                    user_id=user_id,
                    mem_cube_id=mem_cube_id,
                    mem_cube=mem_cube,
                    top_k=self.top_k,
                )

                # 重排序内存重排序并替换工作内存
                new_order_working_memory = self.replace_working_memory(
                    user_id=user_id,
                    mem_cube_id=mem_cube_id,
                    mem_cube=mem_cube,
                    original_memory=cur_working_memory,
                    new_memory=new_candidates,
                )

                # 若启用激活内存，执行周期性更新
                if self.enable_activation_memory:
                    self.update_activation_memory_periodically(
                        interval_seconds=self.monitor.act_mem_update_interval,
                        label=QUERY_LABEL,
                        user_id=user_id,
                        mem_cube_id=mem_cube_id,
                        mem_cube=messages[0].mem_cube,
                    )

    def _answer_message_consumer(self, messages: list[ScheduleMessageItem]) -&gt; None:
        """
        处理和响应队列中的回答触发消息

        参数:
          messages: 要处理的回答消息列表
        """
        # 按用户和内存立方体分组处理消息
        grouped_messages = self.dispatcher.group_messages_by_user_and_cube(messages=messages)

        # 验证消息合法性
        self.validate_schedule_messages(messages=messages, label=ANSWER_LABEL)

        # 遍历分组消息，更新上下文（具体回答逻辑可在此扩展）
        for user_id in grouped_messages:
            for mem_cube_id in grouped_messages[user_id]:
                messages = grouped_messages[user_id][mem_cube_id]
                if len(messages) == 0:
                    return

                # 从消息更新当前上下文
                self._set_current_context_from_message(msg=messages[0])

    def _add_message_consumer(self, messages: list[ScheduleMessageItem]) -&gt; None:
        """处理和响应队列中的添加内存消息"""
        # 按用户和内存立方体分组处理消息
        grouped_messages = self.dispatcher.group_messages_by_user_and_cube(messages=messages)

        # 验证消息合法性
        self.validate_schedule_messages(messages=messages, label=ADD_LABEL)
        try:
            # 遍历分组消息，处理每个添加内存请求
            for user_id in grouped_messages:
                for mem_cube_id in grouped_messages[user_id]:
                    messages = grouped_messages[user_id][mem_cube_id]
                    if len(messages) == 0:
                        return

                    # 从消息更新当前上下文
                    self._set_current_context_from_message(msg=messages[0])

                    # 处理每条消息中的内存ID列表
                    for msg in messages:
                        try:
                            # 解析消息内容中的内存ID列表（JSON格式）
                            userinput_memory_ids = json.loads(msg.content)
                        except Exception as e:
                            userinput_memory_ids = []

                        # 遍历内存ID，记录添加日志（跳过工作内存类型）
                        mem_cube = msg.mem_cube
                        for memory_id in userinput_memory_ids:
                            mem_item: TextualMemoryItem = mem_cube.text_mem.get(memory_id=memory_id)
                            mem_type = mem_item.metadata.memory_type
                            mem_content = mem_item.memory

                            # 跳过工作内存（通常不需要手动添加）
                            if mem_type == WORKING_MEMORY_TYPE:
                                continue

                            # 记录添加内存的日志
                            self.log_adding_memory(
                                memory=mem_content,
                                memory_type=mem_type,
                                user_id=msg.user_id,
                                mem_cube_id=msg.mem_cube_id,
                                mem_cube=msg.mem_cube,
                                log_func_callback=self._submit_web_logs,
                            )

        except Exception as e:
            logger.error(f"Error: {e}", exc_info=True)

    def process_session_turn(
        self,
        queries: str | list[str],
        user_id: UserID | str,
        mem_cube_id: MemCubeID | str,
        mem_cube: GeneralMemCube,
        top_k: int = 10,
    ) -&gt; tuple[list[TextualMemoryItem], list[TextualMemoryItem]] | None:
        """
        处理对话轮次：
        - 当查询列表达到窗口大小时，触发内存检索；
        - 若检索被触发，立即切换到新内存。
        """

        # 获取文本内存实例（仅支持TreeTextMemory类型）
        text_mem_base = mem_cube.text_mem
        if not isinstance(text_mem_base, TreeTextMemory):
            logger.error(
                f"未实现！期望TreeTextMemory，但获取到{type(text_mem_base).__name__} "
                f"（mem_cube_id={mem_cube_id}，user_id={user_id}）。 "
                f"text_mem_base值：{text_mem_base}",
                exc_info=True,
            )
            return None

        # 获取当前工作内存及文本内容
        cur_working_memory: list[TextualMemoryItem] = text_mem_base.get_working_memory()
        text_working_memory: list[str] = [w_m.memory for w_m in cur_working_memory]
        # 检测查询意图（判断是否需要触发检索）
        intent_result = self.monitor.detect_intent(
            q_list=queries, text_working_memory=text_working_memory
        )

        # 检查是否达到时间触发条件
        time_trigger_flag = False
        if self.monitor.timed_trigger(
            last_time=self.monitor.last_query_consume_time,
            interval_seconds=self.monitor.query_trigger_interval,
        ):
            time_trigger_flag = True

        # 根据意图和时间触发条件决定是否执行检索
        if (not intent_result["trigger_retrieval"]) and (not time_trigger_flag):
            return None
        elif (not intent_result["trigger_retrieval"]) and time_trigger_flag:
            intent_result["trigger_retrieval"] = True
            intent_result["missing_evidences"] = queries
        else:
            logger.info(
                f"触发查询调度（user_id={user_id}，mem_cube_id={mem_cube_id}）。 "
                f"缺失证据：{intent_result['missing_evidences']}"
            )

        # 处理缺失的证据（需要检索的内容）
        missing_evidences = intent_result["missing_evidences"]
        num_evidence = len(missing_evidences)
        # 为每个证据分配Top-K配额（确保至少返回1条）
        k_per_evidence = max(1, top_k // max(1, num_evidence))
        new_candidates = []

        # 为每个缺失证据执行检索
        for item in missing_evidences:
            info = {
                "user_id": user_id,
                "session_id": "",
            }

            # 执行检索
            results: list[TextualMemoryItem] = self.retriever.search(
                query=item,
                mem_cube=mem_cube,
                top_k=k_per_evidence,
                method=self.search_method,
                info=info,
            )
            new_candidates.extend(results)

        # 返回当前工作内存和新检索到的候选内存
        return cur_working_memory, new_candidates

</code></pre>
<h3 id="22-schedulerdispatcher">2.2 SchedulerDispatcher</h3>
<p>SchedulerDispatcher 负责将消息路由到对应的processor。SchedulerDispatcher 不使用任何模型进行消息分发或分类判断。下面是它的工作原理：</p>
<ul>
<li>该类是基于线程池的消息分发器，核心作用是根据消息标签（label）将消息路由到对应的processor，实现消息的定向批量处理。</li>
<li>核心功能包括：支持单个 / 批量注册消息processor、按用户 ID 和内存立方体 ID 分组消息、串行 / 并行两种分发模式、优雅关闭和任务监控。</li>
<li>特色是采用上下文感知线程池（ContextThreadPoolExecutor），支持并行任务执行以提升效率；消息分组机制保证同用户同内存立方体的消息集中处理，避免上下文混乱；完善的任务生命周期管理（取消、等待、异常捕获）确保系统稳定。</li>
</ul>
<h4 id="221-分发逻辑">2.2.1 分发逻辑</h4>
<p>SchedulerDispatcher 是基于消息标签进行操作的，而不是使用任何机器学习模型或大语言模型进行分类，具体分发逻辑如下：</p>
<ul>
<li>消息分组：将消息按标签进行分组。</li>
<li>processor查找：依据标签查找注册的processor。处理函数在初始化时被明确注册。</li>
<li>执行模式：
<ul>
<li>串行模式：直接调用processor</li>
<li>并行模式：通过线程池异步执行</li>
</ul>
</li>
</ul>
<p>消息通过其标签属性进行分发</p>
<pre><code class="language-python">class ScheduleMessageItem:
    def __init__(self, label: str, content: str, ...):
        self.label = label  # 分发键
        self.content = content
        # ... 其他属性
</code></pre>
<p>调度器使用简单的字典查找来路由消息到处理函数，在 SchedulerDispatcher.dispatch() 中：</p>
<pre><code class="language-python">label_groups = defaultdict(list)
for message in msg_list:
    label_groups[message.label].append(message)  # 按标签分组

for label, msgs in label_groups.items():
    handler = self.handlers.get(label, self._default_message_handler)
    handler(msgs)  # 基于标签直接调用函数
</code></pre>
<p>当启用并行分发时，也只是并行执行处理函数，但仍不使用模型进行路由：</p>
<pre><code class="language-python">if self.enable_parallel_dispatch and self.dispatcher_executor is not None:
    future = self.dispatcher_executor.submit(handler, msgs)  # 并行执行
</code></pre>
<p>消息流程示例</p>
<pre><code class="language-python">传入消息
├── 带有标签的消息 "query"
│       ├── 没有模型参与确定使用哪个处理函数
│       │
│       ├── 按标签分组
│       │
│       └── 查找 "query" 处理函数
│           ├── 调用已注册的 _query_message_consumer 函数直接调用
│
└── 并行处理（如果启用）
</code></pre>
<h4 id="222-流程">2.2.2 流程</h4>
<p>SchedulerDispatcher的流程如下。</p>
<p><img alt="MemScheduler-7-3" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1850883/202512/1850883-20251217235131608-1552561046.png" class="lazyload"></p>
<h4 id="223-代码">2.2.3 代码</h4>
<pre><code class="language-python">class SchedulerDispatcher(BaseSchedulerModule):
    """
    基于线程池的消息分发器，根据消息标签将消息路由到专用processor。

    特性：
    - 每个消息标签对应独立的线程池处理逻辑
    - 支持批量消息处理
    - 支持优雅关闭
    - 支持批量注册processor
    """

    def __init__(self, max_workers=30, enable_parallel_dispatch=False):
        super().__init__()
        self.max_workers = max_workers  # 线程池最大工作线程数

        # 仅在并行模式下初始化线程池
        self.enable_parallel_dispatch = enable_parallel_dispatch
        self.thread_name_prefix = "dispatcher"  # 线程名称前缀
        if self.enable_parallel_dispatch:
            self.dispatcher_executor = ContextThreadPoolExecutor(
                max_workers=self.max_workers, thread_name_prefix=self.thread_name_prefix
            )
        else:
            self.dispatcher_executor = None  # 串行模式下线程池为None

        self.handlers: dict[str, Callable] = {}  # 已注册的消息processor（标签→processor映射）
        self._running = False  # 分发器运行状态标识
        self._futures = set()  # 用于监控的活跃任务集合

    def register_handler(self, label: str, handler: Callable[[list[ScheduleMessageItem]], None]):
        """
        为特定消息标签注册processor函数。

        参数:
            label: 要处理的消息标签
            handler: 处理该标签消息的可调用对象，接收消息列表作为参数
        """
        self.handlers[label] = handler

    def register_handlers(
        self, handlers: dict[str, Callable[[list[ScheduleMessageItem]], None]]
    ) -&gt; None:
        """
        从字典中批量注册多个processor。

        参数:
            handlers: 标签到processor函数的映射字典，格式：{标签: processor可调用对象}
        """
        for label, handler in handlers.items():
            # 验证标签类型（必须为字符串）
            if not isinstance(label, str):
                continue
            # 验证processor是否可调用
            if not callable(handler):
                continue
            # 注册单个processor
            self.register_handler(label=label, handler=handler)

    def _default_message_handler(self, messages: list[ScheduleMessageItem]) -&gt; None:
        """默认消息processor（当找不到对应标签的processor时使用）"""
        logger.debug(f"使用默认消息processor处理消息：{messages}")

    def group_messages_by_user_and_cube(
        self, messages: list[ScheduleMessageItem]
    ) -&gt; dict[str, dict[str, list[ScheduleMessageItem]]]:
        """
        将消息按用户ID和内存立方体ID分组，生成嵌套字典结构。

        参数:
            messages: 要分组的ScheduleMessageItem对象列表

        返回:
            嵌套字典，结构如下：
            {
                "user_id_1": {
                    "mem_cube_id_1": [消息1, 消息2, ...],
                    "mem_cube_id_2": [消息3, 消息4, ...],
                    ...
                },
                "user_id_2": {
                    ...
                },
                ...
            }
            其中每个消息保持原始ScheduleMessageItem对象
        """
        # 初始化嵌套默认字典（自动创建不存在的键）
        grouped_dict = defaultdict(lambda: defaultdict(list))

        # 按用户ID→内存立方体ID的层级分组消息
        for msg in messages:
            grouped_dict[msg.user_id][msg.mem_cube_id].append(msg)

        # 将默认字典转换为普通字典，输出更简洁
        return {user_id: dict(cube_groups) for user_id, cube_groups in grouped_dict.items()}

    def _handle_future_result(self, future: Future):
        """处理异步任务结果，捕获异常并清理任务集合"""
        self._futures.remove(future)  # 从活跃任务集合中移除已完成任务
         future.result()  # 获取任务结果，触发可能的异常

    def dispatch(self, msg_list: list[ScheduleMessageItem]):
        """
        将消息列表分发到对应的processor。

        参数:
            msg_list: 要处理的ScheduleMessageItem对象列表
        """
        if not msg_list:
            return

        # 按消息标签分组（同一标签的消息交给同一个processor）
        label_groups = defaultdict(list)
        for message in msg_list:
            label_groups[message.label].append(message)

        # 处理每个标签对应的消息组
        for label, msgs in label_groups.items():
            # 获取该标签对应的processor，无则使用默认processor
            handler = self.handlers.get(label, self._default_message_handler)
            # 并行模式：提交任务到线程池异步执行
            if self.enable_parallel_dispatch and self.dispatcher_executor is not None:
                # 提交任务到线程池，捕获变量避免循环引用问题
                future = self.dispatcher_executor.submit(handler, msgs)
                self._futures.add(future)  # 将任务添加到活跃任务集合
                # 绑定任务完成回调函数
                future.add_done_callback(self._handle_future_result)
                logger.info(f"已将 {len(msgs)} 条消息作为异步任务分发")
            # 串行模式：直接调用processor同步执行
            else:
                handler(msgs)

    def join(self, timeout: float | None = None) -&gt; bool:
        """等待所有已分发任务完成。

        参数:
            timeout: 最大等待时间（秒），None表示无限等待

        返回:
            bool: 所有任务完成返回True，超时返回False
        """
        # 串行模式下无异步任务，直接返回True
        if not self.enable_parallel_dispatch or self.dispatcher_executor is None:
            return True

        # 等待所有活跃任务完成
        done, not_done = concurrent.futures.wait(
            self._futures, timeout=timeout, return_when=concurrent.futures.ALL_COMPLETED
        )

        # 检查已完成任务中的异常
        for future in done:
            try:
                future.result()
            except Exception:
                logger.error("关闭过程中processor执行失败", exc_info=True)

        # 返回是否所有任务都已完成
        return len(not_done) == 0
</code></pre>
<h3 id="23-schedulerretriever">2.3 SchedulerRetriever</h3>
<p>SchedulerRetriever 是MemOS中负责记忆检索和重排序的核心模块，是连接查询和记忆存储的关键桥梁，负责确保系统能够准确、高效地检索和排序相关记忆。</p>
<p>内存检索与推理的本质是：在正确时间找到正确信息。</p>
<h4 id="231-功能">2.3.1 功能</h4>
<p>SchedulerRetriever 的功能如下：</p>
<ul>
<li>记忆检索功能
<ul>
<li>搜索实现：通过 search 方法在文本记忆库中查找与查询相关的记忆项</li>
<li>支持多种搜索模式：
<ul>
<li>快速搜索（fast mode）</li>
<li>精细搜索（fine mode）</li>
<li>多类型记忆检索：同时搜索长期记忆和用户记忆</li>
</ul>
</li>
</ul>
</li>
<li>记忆重排序
<ul>
<li>LLM辅助重排序：使用 rerank_memories 方法通过大语言模型对检索到的记忆进行重新排序</li>
<li>智能相关性判断：基于查询内容判断记忆的相关性，提升记忆使用的准确性</li>
</ul>
</li>
<li>记忆处理与过滤
<ul>
<li>记忆去重：使用 filter_vector_based_similar_memories 过滤过于相似的记忆项</li>
<li>长度过滤：使用 filter_too_short_memories 移除过短的记忆项</li>
<li>无关记忆过滤：通过 filter_unrelated_memories 移除与当前查询历史无关的记忆</li>
<li>冗余记忆过滤：通过 filter_redundant_memories 移除重复的记忆项</li>
</ul>
</li>
<li>记忆整合：在 process_and_rerank_memories 方法中整合原始记忆和新检索的记忆，进行统一处理</li>
</ul>
<h4 id="232-详细步骤说明">2.3.2 详细步骤说明</h4>
<p>SchedulerRetriever 的详细步骤如下：</p>
<ul>
<li>搜索阶段：根据查询在 TreeTextMemory 中搜索相关记忆项</li>
<li>合并阶段：将原始记忆和新检索的记忆合并成一个列表</li>
<li>相似度过滤：使用相似度移除过于相似的记忆项</li>
<li>长度过滤：移除过短的记忆项（默认阈值为6个字符）</li>
<li>去重处理：确保记忆项唯一性，同时保持原有顺序</li>
<li>LLM重排序：利用大语言模型根据查询相关性对记忆进行重新排序</li>
<li>无关记忆过滤：移除与查询历史无关的记忆项</li>
<li>返回结果：返回优化后的记忆列表供系统使用</li>
</ul>
<h4 id="233-调用关系">2.3.3 调用关系</h4>
<p>一般来说，业界的<strong>检索时机</strong>有两种主要方法：</p>
<ul>
<li><strong>主动检索</strong>：在每轮开始时自动加载记忆，确保上下文始终可用，但会为不需要记忆访问的轮次引入不必要延迟</li>
<li><strong>反应式检索</strong>（内存即工具）：代理被赋予查询记忆的工具，自行决定何时检索上下文，更高效但需要额外LLM调用</li>
</ul>
<p>SchedulerRetriever 作为 BaseScheduler 的核心组件，主要在处理用户查询和更新工作记忆时被调用，负责记忆的检索、处理、重排序和过滤等核心功能，具体场景为：</p>
<ul>
<li>
<p>初始化：在BaseScheduler 的initialize_modules中建立SchedulerRetriever 实例。</p>
</li>
<li>
<p>查询处理：当 GeneralScheduler 接收到 QUERY_LABEL 消息时，调用 process_session_turn 方法触发 self.retriever.search() 来检索相关记忆。</p>
</li>
<li>
<p>工作记忆更新：在 replace_working_memory 过程中对候选记忆进行处理和重排序</p>
</li>
</ul>
<pre><code class="language-python">└── GeneralScheduler._query_message_consumer()
  └── BaseScheduler.process_session_turn()
      └── SchedulerRetriever.search() --------&gt; 检索相关记忆

└── BaseScheduler.replace_working_memory()
  └── SchedulerRetriever.process_and_rerank_memories() ------&gt; 处理和重排序记忆
      └──SchedulerRetriever.filter_unrelated_memories() -----&gt; 过滤无关记忆

</code></pre>
<h4 id="234-实现">2.3.4 实现</h4>
<h5 id="记忆检索流程search-方法">记忆检索流程（search 方法）</h5>
<p>作为对比，从业界角度看，一般会从多个维度评估潜在记忆，单纯依赖基于向量的相关性是常见陷阱。相似性得分可能找出概念相似但过时或琐碎的记忆。最有效策略是结合所有三个维度的混合方法：</p>
<ul>
<li><strong>相关性</strong>（语义相似性）：与当前对话的概念关联度</li>
<li><strong>新鲜度</strong>（基于时间）：记忆创建的时间远近</li>
<li><strong>重要性</strong>（显著性）：记忆的整体关键程度</li>
</ul>
<p>SchedulerRetriever的  search方法会 调用TreeTextMemory的功能来进行搜索。</p>
<p><img alt="MemScheduler-7-4" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1850883/202512/1850883-20251217235146352-1069858221.png" class="lazyload"></p>
<h5 id="记忆全流程处理与重排process_and_rerank_memories-方法">记忆全流程处理与重排（process_and_rerank_memories 方法）</h5>
<p><img alt="MemScheduler-7-5" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1850883/202512/1850883-20251217235158437-1421234719.png" class="lazyload"></p>
<h5 id="llm-记忆重排流程rerank_memories-方法">LLM 记忆重排流程（rerank_memories 方法）</h5>
<p><img alt="MemScheduler-7-6" loading="lazy" data-src="https://img2024.cnblogs.com/blog/1850883/202512/1850883-20251217235208004-2039529273.png" class="lazyload"></p>
<h5 id="代码">代码</h5>
<pre><code class="language-python">class SchedulerRetriever(BaseSchedulerModule):
    """
    MemOS 记忆检索与优化调度器
    核心功能：检索树状文本内存、合并新旧记忆、多维度过滤、LLM 智能重排，为 Agent 提供精准记忆支持
    继承自 BaseSchedulerModule，遵循 MemOS 调度器模块统一接口规范
    """
    def __init__(self, process_llm: BaseLLM, config: BaseSchedulerConfig):
        """
        初始化检索调度器实例
        Args:
            process_llm: 用于记忆重排的 LLM 实例（BaseLLM 基类对象）
            config: 调度器配置对象（BaseSchedulerConfig 基类，包含过滤、检索等参数）
        """
        super().__init__()  # 调用父类 BaseSchedulerModule 的初始化方法

        # 超参数配置：记忆过滤阈值
        self.filter_similarity_threshold = 0.75  # 相似度过滤阈值（≥0.75 的记忆视为重复）
        self.filter_min_length_threshold = 6     # 长度过滤阈值（字符数＜6 的记忆视为过短，将被过滤）

        self.config: BaseSchedulerConfig = config  # 保存调度器配置
        self.process_llm = process_llm             # 保存用于重排的 LLM 实例

        # 初始化记忆过滤器：委托处理「无关记忆」和「冗余记忆」过滤逻辑
        self.memory_filter = MemoryFilter(process_llm=process_llm, config=config)

    def search(
        self,
        query: str,
        mem_cube: GeneralMemCube,
        top_k: int,
        method: str = TreeTextMemory_SEARCH_METHOD,
        info: dict | None = None,
    ) -&gt; list[TextualMemoryItem]:
        """
        根据查询语句在文本内存中检索相关记忆
        Args:
            query: 检索查询字符串（如 Agent 的当前对话查询）
            mem_cube: 记忆立方体（GeneralMemCube，MemOS 中存储各类记忆的核心数据结构）
            top_k: 返回的Top-K 相关记忆数量
            method: 检索方法（默认使用 TreeTextMemory 的标准搜索方法）
            info: 检索附加信息（需包含 user_id、session_id，用于记录记忆使用历史）

        Returns:
            检索到的文本型记忆项列表（list[TextualMemoryItem]）；检索失败返回空列表
        """
        text_mem_base = mem_cube.text_mem  # 从记忆立方体中提取文本内存核心实例
        try:
            # 仅支持 TreeTextMemory 的两种检索方法
            if method in [TreeTextMemory_SEARCH_METHOD, TreeTextMemory_FINE_SEARCH_METHOD]:
                # 断言文本内存类型为 TreeTextMemory（确保检索方法兼容性）
                assert isinstance(text_mem_base, TreeTextMemory)
                # 若未传入 info，打印警告并初始化空信息（用于历史记录存储）
                if info is None:
                    info = {"user_id": "", "session_id": ""}

                # 根据检索方法设置模式：快速搜索（fast）或精细搜索（fine）
                mode = "fast" if method == TreeTextMemory_SEARCH_METHOD else "fine"
                # 检索长期记忆（LongTermMemory）
                results_long_term = text_mem_base.search(
                    query=query, top_k=top_k, memory_type="LongTermMemory", mode=mode, info=info
                )
                # 检索用户记忆（UserMemory）
                results_user = text_mem_base.search(
                    query=query, top_k=top_k, memory_type="UserMemory", mode=mode, info=info
                )
                # 合并长期记忆和用户记忆的检索结果
                results = results_long_term + results_user
            else:
                # 不支持的检索方法：抛出未实现异常（传入文本内存类型）
                raise NotImplementedError(str(type(text_mem_base)))
        except Exception as e:
            # 检索异常：打印错误日志（包含堆栈信息），返回空列表
            logger.error(f"Fail to search. The exeption is {e}.", exc_info=True)
            results = []
        return results

    def rerank_memories(
        self, queries: list[str], original_memories: list[str], top_k: int
    ) -&gt; Tuple[list[str], bool]:
        """
        基于 LLM 对记忆进行相关性重排（根据查询语句调整记忆顺序）
        Args:
            queries: 用于判断相关性的查询列表（通常为当前对话查询）
            original_memories: 待重排的记忆文本列表
            top_k: 重排后返回的 Top-K 记忆数量

        Returns:
            Tuple[重排后的记忆文本列表（长度≤top_k）, 重排成功标志（bool）]

        Note:
            若 LLM 重排失败（如 JSON 解析异常），降级为原始记忆顺序（截断至 top_k）
        """

        logger.info(f"Starting memory reranking for {len(original_memories)} memories")

        # 构建 LLM 重排提示词（使用 "memory_reranking" 模板）
        prompt = self.build_prompt(
            "memory_reranking",
            queries=[f"[0] {queries[0]}"],  # 格式化查询（仅取第一个查询，标记为 [0]）
            current_order=[f"[{i}] {mem}" for i, mem in enumerate(original_memories)],  # 格式化原始记忆顺序
        )

        # 调用 LLM 生成重排结果（构造用户角色消息）
        response = self.process_llm.generate([{"role": "user", "content": prompt}])

        try:
            # 解析 LLM 响应中的 JSON 数据（期望格式：{"new_order": [索引列表], "reasoning": "重排理由"}）
            response = extract_json_dict(response)
            new_order = response["new_order"][:top_k]  # 提取 Top-K 索引顺序
            # 根据新索引映射回原始记忆文本
            text_memories_with_new_order = [original_memories[idx] for idx in new_order]
            success_flag = True  # 重排成功标志
        except Exception as e:
            # 重排异常（如 JSON 解析失败、键缺失）：打印错误日志，使用原始顺序降级
            text_memories_with_new_order = original_memories[:top_k]  # 截断原始记忆至 top_k
            success_flag = False  # 重排失败标志
        return text_memories_with_new_order, success_flag

    def process_and_rerank_memories(
        self,
        queries: list[str],
        original_memory: list[TextualMemoryItem],
        new_memory: list[TextualMemoryItem],
        top_k: int = 10,
    ) -&gt; Tuple[Optional[list[TextualMemoryItem]], bool]:
        """
        记忆全流程处理：合并新旧记忆 → 过滤冗余/过短记忆 → LLM 重排 → 返回优化后记忆
        Args:
            queries: 用于重排的查询列表（判断记忆相关性的依据）
            original_memory: 原始记忆列表（已存储的历史记忆，TextualMemoryItem 类型）
            new_memory: 新记忆列表（待合并的新增记忆，TextualMemoryItem 类型）
            top_k: 最终返回的最大记忆数量（默认 10）

        Returns:
            Tuple[优化后的 TextualMemoryItem 列表（长度≤top_k）, 处理成功标志（bool）]；失败返回 (None, False)
        """
        # 1. 合并原始记忆和新记忆（形成完整记忆池）
        combined_memory = original_memory + new_memory

        # 2. 构建「归一化文本→记忆对象」的映射（用于后续重排后还原记忆对象）
        # transform_name_to_key：文本归一化函数（如去空格、小写，确保匹配一致性）
        memory_map = {
            transform_name_to_key(name=mem_obj.memory): mem_obj for mem_obj in combined_memory
        }

        # 2. 提取所有记忆的文本内容（用于过滤和重排）
        combined_text_memory = [m.memory for m in combined_memory]

        # 4. 相似度过滤：移除过于相似的记忆（基于向量相似度，阈值 0.75）
        filtered_combined_text_memory = filter_vector_based_similar_memories(
            text_memories=combined_text_memory,
            similarity_threshold=self.filter_similarity_threshold,
        )

        # 5. 长度过滤：移除过短记忆（字符数＜6 的记忆视为无效，阈值 6）
        filtered_combined_text_memory = filter_too_short_memories(
            text_memories=filtered_combined_text_memory,
            min_length_threshold=self.filter_min_length_threshold,
        )

        # 6. 去重：基于归一化文本的字典去重（保留原始顺序）
        unique_memory = list(dict.fromkeys(filtered_combined_text_memory))

        # 7. LLM 智能重排：按与查询的相关性调整记忆顺序
        text_memories_with_new_order, success_flag = self.rerank_memories(
            queries=queries,
            original_memories=unique_memory,
            top_k=top_k,
        )

        # 8. 映射回原始记忆对象（从文本列表还原为 TextualMemoryItem 列表）
        memories_with_new_order = []
        for text in text_memories_with_new_order:
            normalized_text = transform_name_to_key(name=text)  # 文本归一化（确保与 memory_map 键匹配）
            if normalized_text in memory_map:  # 检查归一化文本是否存在于映射中
                memories_with_new_order.append(memory_map[normalized_text])
            else:
                # 日志警告：记忆文本未找到映射（可能是归一化异常或记忆对象缺失）
                logger.warning(
                    f"Memory text not found in memory map. text: {text};\n"
                    f"Keys of memory_map: {memory_map.keys()}"
                )

        return memories_with_new_order, success_flag

    def filter_unrelated_memories(
        self,
        query_history: list[str],
        memories: list[TextualMemoryItem],
    ) -&gt; Tuple[list[TextualMemoryItem], bool]:
        """
        过滤与查询历史无关的记忆（委托给 MemoryFilter 实现）
        Args:
            query_history: 查询历史列表（Agent 的对话历史）
            memories: 待过滤的记忆列表（TextualMemoryItem 类型）
        Returns:
            Tuple[过滤后的记忆列表, 过滤成功标志]
        """
        return self.memory_filter.filter_unrelated_memories(query_history, memories)

    def filter_redundant_memories(
        self,
        query_history: list[str],
        memories: list[TextualMemoryItem],
    ) -&gt; Tuple[list[TextualMemoryItem], bool]:
        """
        过滤冗余记忆（委托给 MemoryFilter 实现）
        Args:
            query_history: 查询历史列表（判断冗余的上下文依据）
            memories: 待过滤的记忆列表（TextualMemoryItem 类型）
        Returns:
            Tuple[过滤后的记忆列表, 过滤成功标志]
        """
        return self.memory_filter.filter_redundant_memories(query_history, memories)

    def filter_unrelated_and_redundant_memories(
        self,
        query_history: list[str],
        memories: list[TextualMemoryItem],
    ) -&gt; Tuple[list[TextualMemoryItem], bool]:
        """
        同时过滤「无关记忆」和「冗余记忆」（基于 LLM 分析，委托给 MemoryFilter 实现）
        Args:
            query_history: 查询历史列表（上下文依据）
            memories: 待过滤的记忆列表（TextualMemoryItem 类型）
        Returns:
            Tuple[过滤后的记忆列表, 过滤成功标志]
        """
        return self.memory_filter.filter_unrelated_and_redundant_memories(query_history, memories)


</code></pre>
<h2 id="0x03-关联">0x03 关联</h2>
<p>SchedulerDispatcher、GeneralScheduler 和 TreeTextMemory 之间存在明确的依赖和协作关系。</p>
<h3 id="31-schedulerdispatcher-和-generalscheduler">3.1 SchedulerDispatcher 和 GeneralScheduler</h3>
<p>SchedulerDispatcher 负责消息的分发和处理，是一个底层的消息处理组件。GeneralScheduler 是一个更高级别的调度器，利用 SchedulerDispatcher 来管理不同类型的消息（如查询、回答、添加记忆等）。</p>
<ul>
<li>GeneralScheduler 依赖 SchedulerDispatcher</li>
<li>SchedulerDispatcher 是 GeneralScheduler 的一个组件，在 GeneralScheduler 的 init 方法中，创建了一个 SchedulerDispatcher 实例并赋值给 self.dispatcher</li>
</ul>
<p>GeneralScheduler 使用 self.dispatcher 来：</p>
<ul>
<li>注册消息处理器（handlers）</li>
<li>分发消息（通过 self.dispatcher.dispatch()）</li>
<li>批量处理消息（通过 self.dispatcher.group_messages_by_user_and_cube()）</li>
<li>等待任务完成（通过 self.dispatcher.join()）</li>
<li>关闭调度器（通过 self.dispatcher.shutdown()）</li>
</ul>
<h3 id="32-generalscheduler-和-treetextmemory">3.2 GeneralScheduler 和 TreeTextMemory</h3>
<p>TreeTextMemory 是记忆存储和检索的核心组件，提供了添加、搜索、更新和删除记忆的功能，GeneralScheduler 利用 TreeTextMemory 来管理记忆的生命周期，处理与记忆相关的各种操作。</p>
<ul>
<li>GeneralScheduler 依赖 TreeTextMemory来执行实际的记忆操作</li>
<li>TreeTextMemory 提供了 GeneralScheduler 所需的记忆存储和检索功能</li>
</ul>
<p>GeneralScheduler 通过 mem_cube.text_mem 访问 TreeTextMemory 实例，GeneralScheduler 使用 TreeTextMemory 来：</p>
<ul>
<li>TreeTextMemory 包含了 MemoryManager 和 Searcher 等组件，这些组件被 GeneralScheduler 间接使用</li>
<li>获取工作记忆（通过 text_mem_base.get_working_memory()）</li>
<li>搜索记忆（通过 self.retriever.search()，其中 retriever 使用 TreeTextMemory 的搜索功能），检索过程涉及：
<ul>
<li>使用 TaskGoalParser 解析查询</li>
<li>使用 GraphMemoryRetriever 从图数据库检索记忆</li>
<li>使用 Reranker 对检索到的记忆进行重排序</li>
<li>使用 MemoryReasoner 进行推理以优化结果</li>
</ul>
</li>
<li>添加记忆（通过 self.memory_manager.add()，其中 memory_manager 与 TreeTextMemory 相关联）</li>
<li>替换工作记忆（通过 text_mem_base.replace_working_memory()）</li>
<li>获取记忆（通过 mem_cube.text_mem.get(memory_id=memory_id)）</li>
<li>GeneralScheduler 接收不同类型的消息（查询、回答、添加记忆等），根据消息类型，GeneralScheduler 调用相应的处理器，处理器使用 TreeTextMemory 的方法来执行具体操作</li>
</ul>
<p>GeneralScheduler 和 TreeTextMemory 之间是一种协作关系，其中：</p>
<ul>
<li>GeneralScheduler 是一个高级调度器，负责处理不同类型的消息并协调记忆操作</li>
<li>TreeTextMemory 是记忆操作的实际执行者，提供了存储、检索、更新和组织记忆的功能</li>
</ul>
<p>两者通过定义良好的接口进行交互，GeneralScheduler 调用 TreeTextMemory 的方法来执行具体操作<br>
这种设计实现了关注点分离，使调度逻辑和记忆管理逻辑可以独立开发和维护。</p>
<p>协作范例如下：</p>
<pre><code class="language-python"># GeneralScheduler 处理查询消息的简化流程
def process_query(self, query, mem_cube):
    # 1. 获取当前工作记忆
    current_memory = mem_cube.text_mem.get_working_memory()
    # 2. 检索相关记忆
    new_candidates = mem_cube.text_mem.search(query, top_k=self.top_k)
    # 3. 更新工作记忆
    mem_cube.text_mem.replace_working_memory(new_candidates)
</code></pre>
<h3 id="33-总结">3.3 总结</h3>
<p>三者之间的依赖关系可以概括为：</p>
<ul>
<li>GeneralScheduler → SchedulerDispatcher（使用其进行消息分发）</li>
<li>GeneralScheduler → TreeTextMemory（使用其进行记忆操作）</li>
</ul>
<p>具体来说：</p>
<ul>
<li>SchedulerDispatcher 是一个消息分发器，负责将不同类型的消息路由到相应的处理器</li>
<li>GeneralScheduler 是一个高级调度器，它使用 SchedulerDispatcher 来管理消息，并使用 TreeTextMemory 来处理与记忆相关的操作</li>
<li>TreeTextMemory 是记忆存储和检索的核心组件，为 GeneralScheduler 提供底层的记忆操作支持</li>
</ul>
<p>这种设计使得系统能够有效地处理不同类型的消息，并对记忆进行相应的操作，实现了消息处理和记忆管理的解耦。</p>
<h3 id="34-moscore">3.4 MosCore</h3>
<p>MosCore 是一个很好的范例。</p>
<pre><code class="language-python">MosCore
- uses GeneralMemCube
- uses GeneralScheduler
  - uses MemoryManager
  - uses TreeTextMemory
- uses UserManager
</code></pre>
<p>在如下代码中，可以管窥。</p>
<pre><code class="language-python">class MOSCore:
    """
    The MOSCore (Memory Operating System Core) class manages multiple MemCube objects and their operations.
    It provides methods for creating, searching, updating, and deleting MemCubes, supporting multi-user scenarios.
    MOSCore acts as an operating system layer for handling and orchestrating MemCube instances.
    """

    def __init__(self, config: MOSConfig, user_manager: UserManager | None = None):
        self.config = config
        self.user_id = config.user_id
        self.session_id = config.session_id
        self.chat_llm = LLMFactory.from_config(config.chat_model)
        self.mem_reader = MemReaderFactory.from_config(config.mem_reader)
        self.chat_history_manager: dict[str, ChatHistory] = {}
        # use thread safe dict for multi-user product-server scenario
        self.mem_cubes: OptimizedThreadSafeDict[str, GeneralMemCube] = (
            OptimizedThreadSafeDict() if user_manager is not None else {}
        )
        self._register_chat_history()

        # Use provided user_manager or create a new one
        if user_manager is not None:
            self.user_manager = user_manager
        else:
            self.user_manager = UserManager(user_id=self.user_id if self.user_id else "root")

        # Initialize mem_scheduler
        self._mem_scheduler_lock = Lock()
        self.enable_mem_scheduler = self.config.get("enable_mem_scheduler", False)
        if self.enable_mem_scheduler:
            self._mem_scheduler = self._initialize_mem_scheduler()
            self._mem_scheduler.mem_cubes = self.mem_cubes
        else:
            self._mem_scheduler: GeneralScheduler = None

</code></pre>
<h2 id="0xff-参考">0xFF 参考</h2>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 20:16">2025-12-22 20:15</span>&nbsp;
<a href="https://www.cnblogs.com/rossiXYZ">罗西的思考</a>&nbsp;
阅读(<span id="post_view_count">12</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19364457);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19364457', targetLink: 'https://www.cnblogs.com/rossiXYZ/p/19364457', title: '【Agent】MemOS 源码笔记---(7)---MemScheduler 细节' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 吴恩达深度学习课程四：计算机视觉  第三周：检测算法 （一）目标定位与特征点检测 ]]></title>
    <link>https://www.cnblogs.com/Goblinscholar/p/19384242</link>
    <guid>469880176f4c26905d70177d26106101</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/Goblinscholar/p/19384242" title="发布于 2025-12-22 20:08">
    <span role="heading" aria-level="2">吴恩达深度学习课程四：计算机视觉  第三周：检测算法 （一）目标定位与特征点检测</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br>
课程相关信息链接如下：</p>
<ol>
<li>原课程视频链接：<a href="https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4" target="_blank" rel="noopener nofollow">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>
<li>github课程资料，含课件与笔记:<a href="https://github.com/robbertliu/deeplearning.ai-andrewNG" target="_blank" rel="noopener nofollow">吴恩达深度学习教学资料</a></li>
<li>课程配套练习（中英）与答案：<a href="https://blog.csdn.net/u013733326/article/details/79827273" target="_blank" rel="noopener nofollow">吴恩达深度学习课后习题与答案</a></li>
</ol>
<p>本篇为第四课的第三周内容，<a href="https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=130" target="_blank" rel="noopener nofollow">3.1</a>到<a href="https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=131" target="_blank" rel="noopener nofollow">3.2</a>的内容。</p>
<hr>
<p>本周为第四课的第三周内容，这一课所有内容的中心只有一个：<strong>计算机视觉</strong>。应用在深度学习里，就是专门用来进行图学习的模型和技术，是在之前全连接基础上的“特化”，也是相关专业里的一个重要研究大类。<br>
<strong>这一整节课都存在大量需要反复理解的内容和机器学习、数学基础。</strong> 因此我会尽可能的补足基础，用比喻和实例来演示每个部分，从而帮助理解。<br>
第三周的内容将从<strong>图像分类</strong>进一步拓展到<strong>目标检测（Object Detection）</strong> 这一更具挑战性的计算机视觉任务。<br>
与分类任务只需回答“图中有什么”不同，目标检测需要同时解决“ <strong>有什么</strong>”以及“<strong>在什么位置</strong>”两个问题，因此在模型结构设计、训练方式和评价标准上都更为复杂。<br>
本篇的内容关于目标定位与特征点检测。</p>
<h1 id="1目标定位">1.目标定位</h1>
<p>这个标题想必不用解释，在原本的分类算法中，我们构建模型来识别输入的图像“”是什么“，而现在，我们想进一步进行定位，找到检测内容在图像中的位置。<br>
这并不是另起炉灶，而是在原本的分类基础上的进一步发展，因此在这部分，我们就来看看如何从”是什么“到”在什么位置“。</p>
<h2 id="11-图像分类的传播逻辑">1.1 图像分类的传播逻辑</h2>
<p>图像分类的逻辑对我们来说早就不陌生了，我们再简单梳理一遍，来看这样课程里这样一个例子:<br>
<img src="https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251222200657746-1727850064.png" alt="image.png" loading="lazy"><br>
你会发现，在监督学习中，我们对每个样本都规定了它的”标准答案“。<br>
因此，网络才能在”传播——对比——改正“这样的循环中不断学习，最终实现分类。<br>
用通俗的话来说，这其中的一个关键点在于：<strong>模型并不知道汽车是什么，但是你通过标签告诉它：这是汽车。</strong><br>
而目标定位也是同样的逻辑：<strong>我们不仅要通过标签告诉模型什么是汽车，还要告诉它汽车在哪</strong>。</p>
<h2 id="12-从分类到定位">1.2 从分类到定位</h2>
<p>通过上一部分的了解，我们知道，要实现从分类到定位的逻辑，首先就要在标签中增加检测目标的位置信息。<br>
<img src="https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251222200659358-1846109048.png" alt="image.png" loading="lazy"><br>
我们知道，在分类问题中，可以用标签 0 和 1 来表示二分类，用独热编码来表示多分类。<br>
但显然，表示目标在图像中的位置是一个更复杂，需要更多参数的问题。<br>
你可能会想，可不可以在标签中增加四个参数对，来表示检测目标的四角？<br>
这的确是一种方法，但实际上，我们使用的是<strong>另一种参数量更少且更普适的方法</strong>：<br>
<img src="https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251222200658515-1899177316.png" alt="image.png" loading="lazy"><br>
再规范一下：<br>
在目标检测中，通常使用一个<strong>边界框（Bounding Box）</strong> 来描述目标在图像中的位置与大小。<br>
相比直接记录四个顶点坐标，更常见也更通用的做法是用<strong>中心点 + 宽高</strong>来表示：</p>
<ol>
<li><span class="math inline">\(b_x\)</span>：表示目标边界框<strong>中心点在水平方向上的位置</strong>，通常是相对于整张图像宽度的归一化坐标，取值范围为 <span class="math inline">\([0,1]\)</span>。</li>
<li><span class="math inline">\(b_y\)</span>：表示目标边界框<strong>中心点在垂直方向上的位置</strong>，同样是相对于图像高度归一化后的坐标。</li>
<li><span class="math inline">\(b_w\)</span>：表示目标边界框的<strong>宽度</strong>，一般以图像宽度为基准进行归一化，用来描述目标在水平方向上所占的比例。</li>
<li><span class="math inline">\(b_h\)</span>：表示目标边界框的<strong>高度</strong>，同样以图像高度为基准归一化，用来描述目标在垂直方向上所占的比例。</li>
</ol>
<p>通过这四个参数，模型不仅能够判断“<strong>是什么</strong>”，还可以同时给出“<strong>在什么位置、占多大范围</strong>”，从而完成最基本的目标定位任务。</p>
<h2 id="13-定位问题的完整样本标签">1.3 定位问题的完整样本标签</h2>
<p>了解了如何表示检测目标在图像中的位置信息后，继续延续上面的例子，来看看如何完整地表示一个样本的标签：<br>
<img src="https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251222200658627-1495275469.png" alt="image.png" loading="lazy"></p>
<p>同样再次列举一下：<br>
在<strong>单目标检测</strong>的设定下，一个样本的标签通常由以下几部分组成：</p>
<ol>
<li><span class="math inline">\(p_c\)</span>：表示<strong>当前图像中是否存在需要检测的目标</strong>，这是一个二值变量，通常取值为 <span class="math inline">\(0\)</span> 或 <span class="math inline">\(1\)</span>。<br>
当 <span class="math inline">\(p_c = 1\)</span> 时，表示图像中确实存在目标，此时后续的位置信息和类别信息才是“有效”的；<br>
当 <span class="math inline">\(p_c = 0\)</span> 时，表示图像中不存在目标，<strong>其余参数通常被忽略或置为 0。</strong></li>
<li><span class="math inline">\(b_x,b_y,b_h,b_w\)</span> :表示检测目标的<strong>位置信息</strong>。</li>
<li><span class="math inline">\(c_n\)</span>：表示目标所属的<strong>类别信息</strong>。<br>
在二分类问题中，它可以是一个标量；<br>
在多分类问题中，通常采用<strong>独热编码</strong> 的形式，用一个向量来表示目标属于哪一类。</li>
</ol>
<p>因此，在单目标检测任务中，一个完整的标签可以被表示为：</p>
<p></p><div class="math display">\[y=(p_c,b_x,b_y,b_w,b_h,c_1,c_2,…,c_n)
\]</div><p></p><p>它同时包含了<strong>是否存在目标、目标的位置与尺度，以及目标的类别信息</strong>。</p>
<p>这样，我们就在数据层面上为目标检测问题完成了准备工作。<br>
为了逻辑的完整性，下一步网络如何学习目标检测的问题就放在下一篇来展开。<br>
下面我们简单拓展一下课程里提到的另一项应用：特征点检测。</p>
<h1 id="2特征点检测keypoint-detection">2.特征点检测（Keypoint Detection）</h1>
<p>在我们了解了如何对图像中的目标进行定位后，结合实际，你会发现在很多实际任务中，我们关注的目标并不是汽车、行人这类需要用边界框描述的宏观物体，而是一些<strong>更精细、更局部的结构</strong>，例如：</p>
<ul>
<li>人的眼角、瞳孔</li>
<li>人体的关节位置</li>
<li>笔尖的位置</li>
<li>面部轮廓上的关键点</li>
</ul>
<p>这类目标本身<strong>几乎不具备“面积”或“尺寸”概念</strong>，用一个边界框来描述反而显得冗余。<br>
在这种情况下，目标往往可以直接用<strong>一个二维坐标点</strong>来表示。</p>
<p>因此，与目标检测类似，我们同样可以通过<strong>人工标注关键点坐标</strong>，构建训练样本，让神经网络学习这个关键点是否存在，以及如果存在，它在图像中的具体位置。<br>
从建模角度看，特征点检测本质上是一个对连续坐标进行预测的<strong>回归问题</strong>。<br>
这种任务，就叫<strong>特征点检测（Keypoint Detection）</strong>。<br>
来看课程里这样一个例子：<br>
<img src="https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251222200657530-300000923.png" alt="image.png" loading="lazy"><br>
我们可以通过检测得到的特征点做进一步应用，比如根据面部特征点分布判断人的表情，根据人的关节特征点位置预测人的动作等等。</p>
<h1 id="3总结">3.总结</h1>
<table>
<thead>
<tr>
<th>概念</th>
<th>原理</th>
<th>比喻</th>
</tr>
</thead>
<tbody>
<tr>
<td>图像分类</td>
<td>通过标签告诉模型“输入图像<strong>是什么</strong>”，模型在传播—对比—修正中学习从图像到类别的映射关系</td>
<td>像给学生一张照片，并直接告诉他：“这是汽车”</td>
</tr>
<tr>
<td>目标定位</td>
<td>在分类的基础上，进一步通过标签告诉模型目标<strong>在图像中的什么位置</strong></td>
<td>不仅说“这是汽车”，还用手指指出“汽车在这里”</td>
</tr>
<tr>
<td>边界框（Bounding Box）</td>
<td>用一个矩形区域描述目标的位置与大小，统一表示空间信息</td>
<td>在照片上用框把目标圈出来</td>
</tr>
<tr>
<td><span class="math inline">\(b_x, b_y\)</span></td>
<td>描述目标中心点在图像中的相对位置（归一化坐标）</td>
<td>用“地图坐标”标出目标的中心点</td>
</tr>
<tr>
<td><span class="math inline">\(b_w, b_h\)</span></td>
<td>描述目标在水平方向和垂直方向所占的比例</td>
<td>告诉别人这个框“有多宽、多高”</td>
</tr>
<tr>
<td>中心点 + 宽高表示法</td>
<td>相比四个角坐标，参数更少、形式更统一，便于网络学习</td>
<td>不报四个角地址，而是说“在市中心，方圆两公里”</td>
</tr>
<tr>
<td><span class="math inline">\(p_c\)</span>（目标存在性）</td>
<td>指示图像中是否存在需要检测的目标，决定后续标签是否有效</td>
<td>先确认“房间里有没有人”，再讨论他站在哪</td>
</tr>
<tr>
<td>类别向量 <span class="math inline">\(c_1,\dots,c_n\)</span></td>
<td>表示目标属于哪一类，可用标量或独热编码</td>
<td>给被圈出来的目标贴上“身份标签”</td>
</tr>
<tr>
<td>特征点检测</td>
<td>不用边界框，而是直接预测关键点的二维坐标</td>
<td>不给人画框，只标出“眼睛、关节、笔尖的位置”</td>
</tr>
</tbody>
</table>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 20:08">2025-12-22 20:08</span>&nbsp;
<a href="https://www.cnblogs.com/Goblinscholar">哥布林学者</a>&nbsp;
阅读(<span id="post_view_count">13</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19384242);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19384242', targetLink: 'https://www.cnblogs.com/Goblinscholar/p/19384242', title: '吴恩达深度学习课程四：计算机视觉  第三周：检测算法 （一）目标定位与特征点检测' })">举报</a>
</div>
         ]]>
    </description>
    </item>
        </channel>
        </rss>