<?xml version="1.0" encoding="UTF-8" ?>
    <rss version="2.0">
    <channel>
        <title><![CDATA[ 主页 - 博客园 ]]></title>
        <link><![CDATA[ https://www.cnblogs.com/ ]]></link>
        <lastBuildDate>2025-12-22T01:18:12.501Z</lastBuildDate>
        <description><![CDATA[
        主页 - 博客园 RSS
    ]]></description>
        <language>zh-cn</language>
        <item>
    <title><![CDATA[ AI 结对编程：如何让 AI 跳出死循环？ ]]></title>
    <link>https://www.cnblogs.com/guangzan/p/19380737</link>
    <guid>783729021538dbbf2b4365ff1378cf96</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/guangzan/p/19380737" title="发布于 2025-12-22 09:13">
    <span role="heading" aria-level="2">AI 结对编程：如何让 AI 跳出死循环？</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="问题背景">问题背景</h2>
<p>在一次开发过程中，遇到了一个典型但又颇具迷惑性的渲染问题：Markdown 表格的行分割线在 Xcode 预览中正常显示，但在运行时完全消失。</p>
<p><img src="https://img2024.cnblogs.com/blog/1501373/202512/1501373-20251220234255623-652241356.png" alt="image" width="903" height="302" loading="lazy"></p>
<p>代码块中的代码内容在 Xcode 预览中正常显示，但在运行时完全消失。</p>
<p><img src="https://img2024.cnblogs.com/blog/1501373/202512/1501373-20251220234308601-1880066633.png" alt="image" width="630" height="394" loading="lazy"></p>
<p>这类问题通常与运行环境差异、渲染上下文或视图修饰符有关。接下来，我记录了自己与 AI 结对编程、一步步定位并解决问题的过程。</p>
<h2 id="问题分析过程">问题分析过程</h2>
<p>我并没有一开始就把两个现象同时抛给 AI。原因很简单，第二个问题（代码块消失）涉及的代码更复杂，极容易把 AI 带进错误方向。</p>
<p>直觉告诉我，这两个现象很可能是同一个根因的不同表现。因此，我选择先挑一个“看起来更简单”的现象：表格分割线消失，作为切入点，让 AI 先集中精力解决一个问题。</p>
<h3 id="第一阶段错误的假设">第一阶段：错误的假设</h3>
<p>AI 的第一反应非常“教科书式”，它将注意力放在了表格样式配置上：</p>
<pre><code class="language-swift">// Theme+Zane.swift
.table { configuration in
  configuration.label
    .fixedSize(horizontal: false, vertical: true)
    .markdownTableBorderStyle(.init(.horizontalBorders, color: .grid))
    .markdownMargin(top: .em(1.6), bottom: .zero)
}
</code></pre>
<p>它提出了几个假设：</p>
<ol>
<li>颜色 <code>.grid</code> 在运行时未正确解析</li>
<li>MarkdownUI 的边框样式在运行时未正确应用</li>
<li>环境变量（colorScheme）未正确传递</li>
</ol>
<p>这些假设看起来合理，但都隐含着一个前提：问题一定出在 Markdown 样式本身。</p>
<h3 id="第二阶段调试验证">第二阶段：调试验证</h3>
<p>为了验证这些假设，我按 AI 的建议加入了一些调试代码：</p>
<pre><code class="language-swift">// 打印 colorScheme 值
.onAppear {
    print("colorScheme: \(colorScheme == .dark ? "dark" : "light")")
}

// 临时改为红色验证
.markdownTableBorderStyle(.init(.horizontalBorders, color: .red))
</code></pre>
<p>结果非常明确：</p>
<ul>
<li>Xcode 预览：红色边框可见</li>
<li>实际运行：依然不可见</li>
<li>colorScheme 值正常</li>
</ul>
<p>这一步基本可以确认：</p>
<ul>
<li>MarkdownUI 的样式机制是生效的</li>
<li>边框颜色、主题配置本身没有问题</li>
<li>问题只存在于运行时渲染环境</li>
</ul>
<h3 id="第三阶段陷入死循环重复多次">第三阶段：陷入死循环（重复多次）</h3>
<p>我明确向 AI 反馈：</p>
<blockquote>
<p>MarkdownUI 和自定义主题之前一直正常，现在才出问题，说明根因很可能不在这里，请从其他方向排查。</p>
</blockquote>
<p>但 AI 并没有真正“换脑子”，而是开始在同一条错误路径上反复尝试：</p>
<ul>
<li>修改 <code>.grid</code> 颜色定义</li>
<li>改用系统颜色</li>
<li>调整边框样式配置</li>
<li>在 <code>tableCell</code> 中添加 overlay</li>
</ul>
<p>这正是 AI 结对编程中最常见的问题之一在错误假设下不断做局部优化，形成思维死循环。</p>
<h3 id="第四阶段跳出循环">第四阶段：跳出循环</h3>
<p>我不得不更明确、甚至有点“强硬”地约束 AI：</p>
<blockquote>
<p>MarkdownUI 和 MarkdownView 本身没有问题。禁止再修改任何 Markdown 相关代码。从其他方向重新排查。</p>
</blockquote>
<p>这一次，AI 才真正开始切换视角，把注意力转向：</p>
<ol>
<li><code>MarkdownView</code> 的修饰符</li>
<li>父视图的布局容器</li>
<li>父级容器滚动视图配置</li>
</ol>
<p>最终，问题定位到了这一段代码：</p>
<pre><code class="language-swift">LazyVStack(alignment: .leading, spacing: 16) {
    // ...
}
.padding()
.drawingGroup()  // ← 问题根源
.transaction { transaction in
    transaction.animation = nil
}
</code></pre>
<p>当我移除 .drawingGroup() 后：表格分割线恢复显示，代码块内容也一并正常了！</p>
<p>为什么 <code>.drawingGroup()</code> 会导致问题？<code>.drawingGroup()</code> 将视图内容合成到离屏渲染层，用于性能优化。但这个过程可能影响细线渲染：</p>
<ol>
<li>合成精度：细线（1px）在合成时可能被抗锯齿或采样影响</li>
<li>渲染上下文：离屏渲染与直接渲染的上下文不同</li>
<li>颜色混合：合成过程中的颜色混合可能使浅色边框变淡或消失</li>
</ol>
<h2 id="关于-ai-结对编程的思考">关于 AI 结对编程的思考</h2>
<p>AI 在结对编程中并不是“不会解决问题”，而是很容易在错误前提下持续消耗时间。</p>
<p>AI 高度依赖模式匹配。一旦问题被归类为“表格渲染异常”，它就会自然地把注意力集中在样式、颜色、主题等常见因素上，而对“之前一直正常、最近才出问题”这类时间线线索不够敏感。当初始假设没有被及时推翻时，AI 往往会在同一方向上不断微调，形成事实上的思维死循环。</p>
<p>要让 AI 跳出这种状态，关键并不是提供更多细节，而是强制改变它的分析边界。明确指出当前方向可能是错的、强调哪些部分已经被确认没有问题，甚至直接禁止继续修改某类代码，反而能显著提升排查效率。一旦分析范围被重新划定，AI 才会开始关注父视图、修饰符链或最近的改动这些更有价值的线索。</p>
<p>这也决定了 AI 结对编程的合理分工方式。人类负责判断方向、提供上下文和时间线；AI 负责搜索、枚举和验证可能性。当人类不主动介入纠偏时，AI 很容易在“看似合理”的路径上反复打磨，却始终无法触及根因。</p>
<p>最终，这次问题能够被定位到 <code>.drawingGroup()</code> ，并不是因为 AI 突然变得更聪明，而是因为分析视角发生了改变。这也提醒我，在与 AI 协作调试时，比“如何写代码”更重要的，是如何约束和引导它的思考方式。有时候，问题不在你盯着的地方，而在你忽略的地方。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 09:13">2025-12-22 09:13</span>&nbsp;
<a href="https://www.cnblogs.com/guangzan">guangzan</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19380737);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19380737', targetLink: 'https://www.cnblogs.com/guangzan/p/19380737', title: 'AI 结对编程：如何让 AI 跳出死循环？' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 一文讲清楚图论相关算法 ]]></title>
    <link>https://www.cnblogs.com/sevencoding/p/19376818</link>
    <guid>d0ca001d15c3e56fc611a91b1841551e</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/sevencoding/p/19376818" title="发布于 2025-12-22 09:00">
    <span role="heading" aria-level="2">一文讲清楚图论相关算法</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>建图函数</p>
<pre><code class="language-java">List&lt;Integer&gt;[] buildGraph(int numCourses, int[][] prerequisites) {
    // 图中共有 numCourses 个节点
    List&lt;Integer&gt;[] graph = new LinkedList[numCourses];
    for (int i = 0; i &lt; numCourses; i++) {
        graph[i] = new LinkedList&lt;&gt;();
    }
    for (int[] edge : prerequisites) {
        int from = edge[1], to = edge[0];
        // 添加一条从 from 指向 to 的有向边
        // 边的方向是「被依赖」关系，即修完课程 from 才能修课程 to
        graph[from].add(to);
    }
    return graph;
}
</code></pre>
<h2 id="环检测算法">环检测算法</h2>
<h3 id="dfs">DFS</h3>
<pre><code class="language-java">// 记录一次递归堆栈中的节点
boolean[] onPath;
// 记录遍历过的节点，防止走回头路
boolean[] visited;
// 记录图中是否有环
boolean hasCycle = false;

boolean canFinish(int numCourses, int[][] prerequisites) {
    List&lt;Integer&gt;[] graph = buildGraph(numCourses, prerequisites);

    visited = new boolean[numCourses];
    onPath = new boolean[numCourses];

    for (int i = 0; i &lt; numCourses; i++) {
        // 遍历图中的所有节点
        traverse(graph, i);
    }
    // 只要没有循环依赖可以完成所有课程
    return !hasCycle;
}

void traverse(List&lt;Integer&gt;[] graph, int s) {
    if (onPath[s]) {
        // 出现环
        hasCycle = true;
    }

    if (visited[s] || hasCycle) {
        // 如果已经找到了环，也不用再遍历了
        return;
    }
    // 前序代码位置
    visited[s] = true;
    onPath[s] = true;
    for (int t : graph[s]) {
        traverse(graph, t);
    }
    // 后序代码位置
    onPath[s] = false;
}
</code></pre>
<h3 id="bfs">BFS</h3>
<pre><code class="language-java">// 主函数
public boolean canFinish(int numCourses, int[][] prerequisites) {
    // 建图，有向边代表「被依赖」关系
    List&lt;Integer&gt;[] graph = buildGraph(numCourses, prerequisites);
    // 构建入度数组
    int[] indgree = new int[numCourses];
    for (int[] edge : prerequisites) {
        int from = edge[1], to = edge[0];
        // 节点 to 的入度加一
        indgree[to]++;
    }

    // 根据入度初始化队列中的节点
    Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;();
    for (int i = 0; i &lt; numCourses; i++) {
        if (indgree[i] == 0) {
            // 节点 i 没有入度，即没有依赖的节点
            // 可以作为拓扑排序的起点，加入队列
            q.offer(i);
        }
    }

    // 记录遍历的节点个数
    int count = 0;
    // 开始执行 BFS 循环
    while (!q.isEmpty()) {
        // 弹出节点 cur，并将它指向的节点的入度减一
        int cur = q.poll();
        count++;
        for (int next : graph[cur]) {
            indgree[next]--;
            if (indgree[next] == 0) {
                // 如果入度变为 0，说明 next 依赖的节点都已被遍历
                q.offer(next);
            }
        }
    }

    // 如果所有节点都被遍历过，说明不成环
    return count == numCourses;
}
</code></pre>
<p>这段 BFS 算法的思路：</p>
<p>1、构建邻接表，和之前一样，边的方向表示「被依赖」关系。</p>
<p>2、构建一个 <code>indegree</code> 数组记录每个节点的入度，即 <code>indegree[i]</code> 记录节点 <code>i</code> 的入度。</p>
<p>3、对 BFS 队列进行初始化，将入度为 0 的节点首先装入队列。</p>
<p><strong>4、开始执行 BFS 循环，不断弹出队列中的节点，减少相邻节点的入度，并将入度变为 0 的节点加入队列</strong>。</p>
<p><strong>5、如果最终所有节点都被遍历过（<code>count</code> 等于节点数），则说明不存在环，反之则说明存在环</strong>。</p>
<h2 id="拓扑排序算法">拓扑排序算法</h2>
<p>对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，简称拓扑序列。简单的说，由某个集合上的一个偏序得到该集合上的一个全序，这个操作称之为拓扑排序。</p>
<h3 id="dfs-1">DFS</h3>
<pre><code class="language-java">// 记录后序遍历结果
List&lt;Integer&gt; postorder = new ArrayList&lt;&gt;();
// 记录是否存在环
boolean hasCycle = false;
boolean[] visited, onPath;

// 主函数
public int[] findOrder(int numCourses, int[][] prerequisites) {
    List&lt;Integer&gt;[] graph = buildGraph(numCourses, prerequisites);
    visited = new boolean[numCourses];
    onPath = new boolean[numCourses];
    // 遍历图
    for (int i = 0; i &lt; numCourses; i++) {
        traverse(graph, i);
    }
    // 有环图无法进行拓扑排序
    if (hasCycle) {
        return new int[]{};
    }
    // 逆后序遍历结果即为拓扑排序结果
    Collections.reverse(postorder);
    int[] res = new int[numCourses];
    for (int i = 0; i &lt; numCourses; i++) {
        res[i] = postorder.get(i);
    }
    return res;
}

// 图遍历函数
void traverse(List&lt;Integer&gt;[] graph, int s) {
    if (onPath[s]) {
        // 发现环
        hasCycle = true;
    }
    if (visited[s] || hasCycle) {
        return;
    }
    // 前序遍历位置
    onPath[s] = true;
    visited[s] = true;
    for (int t : graph[s]) {
        traverse(graph, t);
    }
    // 后序遍历位置
    postorder.add(s);
    onPath[s] = false;
}
</code></pre>
<h3 id="bfs-1">BFS</h3>
<pre><code class="language-java">// 主函数
public int[] findOrder(int numCourses, int[][] prerequisites) {
    // 建图，和环检测算法相同
    List&lt;Integer&gt;[] graph = buildGraph(numCourses, prerequisites);
    // 计算入度，和环检测算法相同
    int[] indgree = new int[numCourses];
    for (int[] edge : prerequisites) {
        int from = edge[1], to = edge[0];
        indgree[to]++;
    }

    // 根据入度初始化队列中的节点，和环检测算法相同
    Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;();
    for (int i = 0; i &lt; numCourses; i++) {
        if (indgree[i] == 0) {
            q.offer(i);
        }
    }

    // 记录拓扑排序结果
    int[] res = new int[numCourses];
    // 记录遍历节点的顺序（索引）
    int count = 0;
    // 开始执行 BFS 算法
    while (!q.isEmpty()) {
        int cur = q.poll();
        // 弹出节点的顺序即为拓扑排序结果
        res[count] = cur;
        count++;
        for (int next : graph[cur]) {
            indgree[next]--;
            if (indgree[next] == 0) {
                q.offer(next);
            }
        }
    }

    if (count != numCourses) {
        // 存在环，拓扑排序不存在
        return new int[]{};
    }

    return res;
}
</code></pre>
<h2 id="二分图判定算法">二分图判定算法</h2>
<p>二分图的顶点集可分割为两个互不相交的子集，图中每条边依附的两个顶点都分属于这两个子集，且两个子集内的顶点不相邻。</p>
<p><img src="https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404270956044.png" alt="" loading="lazy"></p>
<p><strong>给你一幅「图」，请你用两种颜色将图中的所有顶点着色，且使得任意一条边的两个端点的颜色都不相同，你能做到吗</strong>？</p>
<p>这就是图的「双色问题」，其实这个问题就等同于二分图的判定问题，如果你能够成功地将图染色，那么这幅图就是一幅二分图，反之则不是</p>
<h3 id="dfs-2">DFS</h3>
<pre><code class="language-java">// 记录图是否符合二分图性质
private boolean ok = true;
// 记录图中节点的颜色，false 和 true 代表两种不同颜色
private boolean[] color;
// 记录图中节点是否被访问过
private boolean[] visited;

// 主函数，输入邻接表，判断是否是二分图
public boolean isBipartite(int[][] graph) {
    int n = graph.length;
    color =  new boolean[n];
    visited =  new boolean[n];
    // 因为图不一定是联通的，可能存在多个子图
    // 所以要把每个节点都作为起点进行一次遍历
    // 如果发现任何一个子图不是二分图，整幅图都不算二分图
    for (int v = 0; v &lt; n; v++) {
        if (!visited[v]) {
            traverse(graph, v);
        }
    }
    return ok;
}

// DFS 遍历框架
private void traverse(int[][] graph, int v) {
    // 如果已经确定不是二分图了，就不用浪费时间再递归遍历了
    if (!ok) return;

    visited[v] = true;
    for (int w : graph[v]) {
        if (!visited[w]) {
            // 相邻节点 w 没有被访问过
            // 那么应该给节点 w 涂上和节点 v 不同的颜色
            color[w] = !color[v];
            // 继续遍历 w
            traverse(graph, w);
        } else {
            // 相邻节点 w 已经被访问过
            // 根据 v 和 w 的颜色判断是否是二分图
            if (color[w] == color[v]) {
                // 若相同，则此图不是二分图
                ok = false;
            }
        }
    }
}
</code></pre>
<h3 id="bfs-2">BFS</h3>
<pre><code class="language-java">// 记录图是否符合二分图性质
private boolean ok = true;
// 记录图中节点的颜色，false 和 true 代表两种不同颜色
private boolean[] color;
// 记录图中节点是否被访问过
private boolean[] visited;

public boolean isBipartite(int[][] graph) {
    int n = graph.length;
    color =  new boolean[n];
    visited =  new boolean[n];
    
    for (int v = 0; v &lt; n; v++) {
        if (!visited[v]) {
            // 改为使用 BFS 函数
            bfs(graph, v);
        }
    }
    
    return ok;
}

// 从 start 节点开始进行 BFS 遍历
private void bfs(int[][] graph, int start) {
    Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;();
    visited[start] = true;
    q.offer(start);
    
    while (!q.isEmpty() &amp;&amp; ok) {
        int v = q.poll();
        // 从节点 v 向所有相邻节点扩散
        for (int w : graph[v]) {
            if (!visited[w]) {
                // 相邻节点 w 没有被访问过
                // 那么应该给节点 w 涂上和节点 v 不同的颜色
                color[w] = !color[v];
                // 标记 w 节点，并放入队列
                visited[w] = true;
                q.offer(w);
            } else {
                // 相邻节点 w 已经被访问过
                // 根据 v 和 w 的颜色判断是否是二分图
                if (color[w] == color[v]) {
                    // 若相同，则此图不是二分图
                    ok = false;
                }
            }
        }
    }
}
</code></pre>
<h2 id="union-find并查集">Union-Find并查集</h2>
<p>大白话就是当我们需要判断两个元素是否在同一个集合里的时候，我们就要想到用并查集。</p>
<p>并查集主要有两个功能：</p>
<ul>
<li>将两个元素添加到一个集合中。</li>
<li>判断两个元素在不在同一个集合</li>
</ul>
<p>名称"并查集"直接体现了它的核心功能：合并集合与查询元素所属集合。在英文中，它通常被称为"Union-Find"数据结构或"Disjoint-Set"数据结构。</p>
<p>并查集的基本思想是使用树形结构来表示每个集合，树的根节点作为集合的代表元素。</p>
<p>并查集核心特性：</p>
<ol>
<li>快速查找：能够快速判断两个元素是否属于同一集合</li>
<li>快速合并：能够快速将两个集合合并为一个</li>
<li>路径压缩：优化查找操作，使树的高度尽量小</li>
<li>按秩合并：优化合并操作，减少树的高度增长</li>
</ol>
<p>Union-Find 算法主要需要实现这两个 API：</p>
<pre><code class="language-java">class UF {
    /* 将 p 和 q 连接 */
    public void union(int p, int q);
    /* 判断 p 和 q 是否连通 */
    public boolean connected(int p, int q);
    /* 返回图中有多少个连通分量 */
    public int count();
}
</code></pre>
<p>这里所说的「连通」是一种等价关系，也就是说具有如下三个性质：</p>
<p>1、自反性：节点<code>p</code>和<code>p</code>是连通的。</p>
<p>2、对称性：如果节点<code>p</code>和<code>q</code>连通，那么<code>q</code>和<code>p</code>也连通。</p>
<p>3、传递性：如果节点<code>p</code>和<code>q</code>连通，<code>q</code>和<code>r</code>连通，那么<code>p</code>和<code>r</code>也连通。</p>
<p>比如说有一幅图，0～9 任意两个<strong>不同</strong>的点都不连通，调用<code>connected</code>都会返回 false，连通分量为 10 个。</p>
<p>如果现在调用<code>union(0, 1)</code>，那么 0 和 1 被连通，连通分量降为 9 个。</p>
<p>再调用<code>union(1, 2)</code>，这时 0,1,2 都被连通，调用<code>connected(0, 2)</code>也会返回 true，连通分量变为 8 个。</p>
<h3 id="基础算法">基础算法</h3>
<p>设定树的每个节点有一个指针指向其父节点，如果是根节点的话，这个指针指向自己。比如说刚才那幅 10 个节点的图，一开始的时候没有相互连通，就是这样：</p>
<pre><code class="language-java">class UF {
    // 记录连通分量
    private int count;
    // 节点 x 的节点是 parent[x]
    private int[] parent;

    /* 构造函数，n 为图的节点总数 */
    public UF(int n) {
        // 一开始互不连通
        this.count = n;
        // 父节点指针初始指向自己
        parent = new int[n];
        for (int i = 0; i &lt; n; i++)
            parent[i] = i;
    }

    /* 其他函数 */
}
</code></pre>
<p><strong>如果某两个节点被连通，则让其中的（任意）一个节点的根节点接到另一个节点的根节点上</strong>：</p>
<pre><code class="language-java">public void union(int p, int q) {
    int rootP = find(p);
    int rootQ = find(q);
    if (rootP == rootQ)
        return;
    // 将两棵树合并为一棵
    parent[rootP] = rootQ;
    // parent[rootQ] = rootP 也一样
    count--; // 两个分量合二为一
}

/* 返回某个节点 x 的根节点 */
private int find(int x) {
    // 根节点的 parent[x] == x
    while (parent[x] != x)
        x = parent[x];
    return x;
}

/* 返回当前的连通分量个数 */
public int count() { 
    return count;
}
</code></pre>
<p><strong>这样，如果节点<code>p</code>和<code>q</code>连通的话，它们一定拥有相同的根节点</strong>：</p>
<pre><code class="language-java">public boolean connected(int p, int q) {
    int rootP = find(p);
    int rootQ = find(q);
    return rootP == rootQ;
}
</code></pre>
<p>至此，Union-Find 算法就基本完成了。</p>
<p>那么这个算法的复杂度是多少呢？我们发现，主要 API<code>connected</code>和<code>union</code>中的复杂度都是<code>find</code>函数造成的，所以说它们的复杂度和<code>find</code>一样。</p>
<p><code>find</code>主要功能就是从某个节点向上遍历到树根，其时间复杂度就是树的高度。我们可能习惯性地认为树的高度就是<code>logN</code>，但这并不一定。<code>logN</code>的高度只存在于平衡二叉树，对于一般的树可能出现极端不平衡的情况，使得「树」几乎退化成「链表」，树的高度最坏情况下可能变成<code>N</code>。</p>
<p>所以说上面这种解法，<code>find</code>,<code>union</code>,<code>connected</code>的时间复杂度都是 O(N)。这个复杂度很不理想的，你想图论解决的都是诸如社交网络这样数据规模巨大的问题，对于<code>union</code>和<code>connected</code>的调用非常频繁，每次调用需要线性时间完全不可忍受。</p>
<h3 id="平衡性优化">平衡性优化</h3>
<p>要知道哪种情况下可能出现不平衡现象，关键在于<code>union</code>过程：</p>
<pre><code class="language-java">public void union(int p, int q) {
    int rootP = find(p);
    int rootQ = find(q);
    if (rootP == rootQ)
        return;
    // 将两棵树合并为一棵
    parent[rootP] = rootQ;
    // parent[rootQ] = rootP 也可以
    count--; 
}
</code></pre>
<p>我们一开始就是简单粗暴的把<code>p</code>所在的树接到<code>q</code>所在的树的根节点下面，那么这里就可能出现「头重脚轻」的不平衡状况，比如下面这种局面：</p>
<p><img src="https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404271016400.png" alt="" loading="lazy"></p>
<p>长此以往，树可能生长得很不平衡。<strong>我们其实是希望，小一些的树接到大一些的树下面，这样就能避免头重脚轻，更平衡一些</strong>。解决方法是额外使用一个<code>size</code>数组，记录每棵树包含的节点数，我们不妨称为「重量」：</p>
<pre><code class="language-java">class UF {
    private int count;
    private int[] parent;
    // 新增一个数组记录树的“重量”
    private int[] size;

    public UF(int n) {
        this.count = n;
        parent = new int[n];
        // 最初每棵树只有一个节点
        // 重量应该初始化 1
        size = new int[n];
        for (int i = 0; i &lt; n; i++) {
            parent[i] = i;
            size[i] = 1;
        }
    }
    /* 其他函数 */
}
</code></pre>
<p>比如说<code>size[3] = 5</code>表示，以节点<code>3</code>为根的那棵树，总共有<code>5</code>个节点。这样我们可以修改一下<code>union</code>方法：</p>
<pre><code class="language-java">public void union(int p, int q) {
    int rootP = find(p);
    int rootQ = find(q);
    if (rootP == rootQ)
        return;

    // 小树接到大树下面，较平衡
    if (size[rootP] &gt; size[rootQ]) {
        parent[rootQ] = rootP;
        size[rootP] += size[rootQ];
    } else {
        parent[rootP] = rootQ;
        size[rootQ] += size[rootP];
    }
    count--;
}
</code></pre>
<p>这样，通过比较树的重量，就可以保证树的生长相对平衡，树的高度大致在<code>logN</code>这个数量级，极大提升执行效率。</p>
<p>此时，<code>find</code>,<code>union</code>,<code>connected</code>的时间复杂度都下降为 O(logN)，即便数据规模上亿，所需时间也非常少。</p>
<h3 id="路径压缩">路径压缩</h3>
<p><strong>其实我们并不在乎每棵树的结构长什么样，只在乎根节点</strong>。</p>
<p>因为无论树长啥样，树上的每个节点的根节点都是相同的，所以能不能进一步压缩每棵树的高度，使树高始终保持为常数？</p>
<p><img src="https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404271018216.png" alt="" loading="lazy"></p>
<p>如图所示，这样每个节点的父节点就是整棵树的根节点，<code>find</code>就能以 O(1) 的时间找到某一节点的根节点，相应的，<code>connected</code>和<code>union</code>复杂度都下降为 O(1)。</p>
<p>要做到这一点主要是修改<code>find</code>函数逻辑，非常简单，但你可能会看到两种不同的写法。</p>
<p>第一种是在<code>find</code>中加一行代码：</p>
<pre><code class="language-java">private int find(int x) {
    while (parent[x] != x) {
        // 这行代码进行路径压缩
        parent[x] = parent[parent[x]];
        x = parent[x];
    }
    return x;
}
</code></pre>
<p>用语言描述就是，每次 while 循环都会把一对儿父子节点改到同一层，这样每次调用<code>find</code>函数向树根遍历的同时，顺手就将树高缩短了。</p>
<p>路径压缩的第二种写法是这样：</p>
<pre><code class="language-java">// 第二种路径压缩的 find 方法
public int find(int x) {
    if (parent[x] != x) {
        parent[x] = find(parent[x]);
    }
    return parent[x];
}
</code></pre>
<p>这个递归过程有点不好理解，你可以自己手画一下递归过程。我把这个函数做的事情翻译成迭代形式，方便你理解它进行路径压缩的原理：</p>
<pre><code class="language-java">// 这段迭代代码方便你理解递归代码所做的事情
public int find(int x) {
    // 先找到根节点
    int root = x;
    while (parent[root] != root) {
        root = parent[root];
    }
    // 然后把 x 到根节点之间的所有节点直接接到根节点下面
    int old_parent = parent[x];
    while (x != root) {
        parent[x] = root;
        x = old_parent;
        old_parent = parent[old_parent];
    }
    return root;
}
</code></pre>
<p>这种路径压缩的效果如下：</p>
<p><img src="https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404271020276.png" alt="" loading="lazy"></p>
<p>比起第一种路径压缩，显然这种方法压缩得更彻底，直接把一整条树枝压平，一点意外都没有。就算一些极端情况下产生了一棵比较高的树，只要一次路径压缩就能大幅降低树高，从 <a href="https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzAxODQxMDM0Mw%3D%3D%26mid%3D2247496738%26idx%3D1%26sn%3D2c7d16c8b0ee64d8101abb35e06b08cc%26scene%3D21%23wechat_redirect&amp;source=article&amp;objectId=2190285" target="_blank" rel="noopener nofollow">摊还分析</a> 的角度来看，所有操作的平均时间复杂度依然是 O(1)，所以从效率的角度来说，推荐你使用这种路径压缩算法。</p>
<p><strong>另外，如果使用路径压缩技巧，那么<code>size</code>数组的平衡优化就不是特别必要了</strong>。所以你一般看到的 Union Find 算法应该是如下实现：</p>
<pre><code class="language-java">class UF {
    // 连通分量个数
    private int count;
    // 存储每个节点的父节点
    private int[] parent;

    // n 为图中节点的个数
    public UF(int n) {
        this.count = n;
        parent = new int[n];
        for (int i = 0; i &lt; n; i++) {
            parent[i] = i;
        }
    }

    // 将节点 p 和节点 q 连通
    public void union(int p, int q) {
        int rootP = find(p);
        int rootQ = find(q);

        if (rootP == rootQ)
            return;

        parent[rootQ] = rootP;
        // 两个连通分量合并成一个连通分量
        count--;
    }

    // 判断节点 p 和节点 q 是否连通
    public boolean connected(int p, int q) {
        int rootP = find(p);
        int rootQ = find(q);
        return rootP == rootQ;
    }

    public int find(int x) {
        if (parent[x] != x) {
            parent[x] = find(parent[x]);
        }
        return parent[x];
    }

    // 返回图中的连通分量个数
    public int count() {
        return count;
    }
}
</code></pre>
<p>Union-Find 算法的复杂度可以这样分析：构造函数初始化数据结构需要 O(N) 的时间和空间复杂度；连通两个节点<code>union</code>、判断两个节点的连通性<code>connected</code>、计算连通分量<code>count</code>所需的时间复杂度均为 O(1)。</p>
<p>到这里，相信你已经掌握了 Union-Find 算法的核心逻辑，总结一下我们优化算法的过程：</p>
<p>1、用<code>parent</code>数组记录每个节点的父节点，相当于指向父节点的指针，所以<code>parent</code>数组内实际存储着一个森林（若干棵多叉树）。</p>
<p>2、用<code>size</code>数组记录着每棵树的重量，目的是让<code>union</code>后树依然拥有平衡性，保证各个 API 时间复杂度为 O(logN)，而不会退化成链表影响操作效率。</p>
<p>3、在<code>find</code>函数中进行路径压缩，保证任意树的高度保持在常数，使得各个 API 时间复杂度为 O(1)。使用了路径压缩之后，可以不使用<code>size</code>数组的平衡优化。</p>
<h3 id="优点">优点</h3>
<ol>
<li>查找和合并操作的平均时间复杂度接近O(1)</li>
<li>实现简单，易于理解</li>
<li>空间复杂度低，只需要两个数组</li>
<li>适用于处理大量动态连通性问题</li>
</ol>
<h3 id="缺点">缺点</h3>
<ol>
<li>不支持分裂操作（将一个集合分成两个）</li>
<li>不方便查询集合中的所有元素</li>
<li>在某些特殊情况下，性能可能退化</li>
</ol>
<h3 id="应用场景">应用场景</h3>
<p>Kruskal最小生成树算法：在Kruskal算法中，并查集是核心数据结构。该算法按权重从小到大遍历边，使用并查集判断加入某条边是否会形成环，从而高效构建最小生成树。</p>
<p>网络连通性问题：并查集可高效解决动态连通性问题，比如判断网络中两个节点是否连通、社交网络中用户间的关系连接等。当关系变化时，只需执行简单的union操作，判断连通性时使用find操作即可。</p>
<p>等价类划分：在编译器设计、电路分析等领域，并查集可用于等价类识别与合并。当系统发现两个元素等价时执行union操作，需要判断等价关系时使用find操作，这种动态维护等价关系的能力正是并查集的优势所在。</p>
<p>判断无向图中的环：当向无向图中添加边时，如果边的两个端点已在同一个集合中，则添加这条边会形成环。在很多图算法和网络设计问题中都可以使用这一特性。</p>
<h2 id="kruskal-最小生成树算法">Kruskal 最小生成树算法</h2>
<p>Kruskal 的 关键就是 并查集算法</p>
<p><strong>先说「树」和「图」的根本区别：树不会包含环，图可以包含环</strong>。</p>
<p>如果一幅图没有环，完全可以拉伸成一棵树的模样。说的专业一点，树就是「无环连通图」。</p>
<p>那么什么是图的「生成树」呢，其实按字面意思也好理解，就是在图中找一棵包含图中的所有节点的树。专业点说，生成树是含有图中所有顶点的「无环连通子图」。</p>
<p>容易想到，一幅图可以有很多不同的生成树，比如下面这幅图，红色的边就组成了两棵不同的生成树：</p>
<p><img src="https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404271025443.webp" alt="" loading="lazy"></p>
<p>对于加权图，每条边都有权重，所以每棵生成树都有一个权重和。比如上图，右侧生成树的权重和显然比左侧生成树的权重和要小。</p>
<p><strong>那么最小生成树很好理解了，所有可能的生成树中，权重和最小的那棵生成树就叫「最小生成树」</strong>。</p>
<blockquote>
<p>PS：一般来说，我们都是在<strong>无向加权图</strong>中计算最小生成树的，所以使用最小生成树算法的现实场景中，图的边权重一般代表成本、距离这样的标量。</p>
</blockquote>
<p>所谓最小生成树，就是图中若干边的集合（我们后文称这个集合为<code>mst</code>，最小生成树的英文缩写），你要保证这些边：</p>
<p>1、包含图中的所有节点。</p>
<p>2、形成的结构是树结构（即不存在环）。</p>
<p>3、权重和最小。</p>
<p>前两条其实可以很容易地利用 Union-Find 算法做到，关键在于第 3 点，如何保证得到的这棵生成树是权重和最小的。</p>
<p>这里就用到了贪心思路：<strong>将所有边按照权重从小到大排序，从权重最小的边开始遍历，如果这条边和<code>mst</code>中的其它边不会形成环，则这条边是最小生成树的一部分，将它加入<code>mst</code>集合；否则，这条边不是最小生成树的一部分，不要把它加入<code>mst</code>集合</strong>。</p>
<p>这样，最后<code>mst</code>集合中的边就形成了最小生成树，算法代码如下：</p>
<pre><code class="language-java">int minimumCost(int n, int[][] connections) {
    // 城市编号为 1...n，所以初始化大小为 n + 1
    UF uf = new UF(n + 1);
    // 对所有边按照权重从小到大排序
    Arrays.sort(connections, (a, b) -&gt; (a[2] - b[2]));
    // 记录最小生成树的权重之和
    int mst = 0;
    for (int[] edge : connections) {
        int u = edge[0];
        int v = edge[1];
        int weight = edge[2];
        // 若这条边会产生环，则不能加入 mst
        if (uf.connected(u, v)) {
            continue;
        }
        // 若这条边不会产生环，则属于最小生成树
        mst += weight;
        uf.union(u, v);
    }
    // 保证所有节点都被连通
    // 按理说 uf.count() == 1 说明所有节点被连通
    // 但因为节点 0 没有被使用，所以 0 会额外占用一个连通分量
    return uf.count() == 2 ? mst : -1;
}

class UF {
    // 见上文并查集代码实现
}
</code></pre>
<p>复杂度分析：</p>
<p>假设一幅图的节点个数为V，边的条数为E，首先需要O(E)的空间装所有边，而且 Union-Find 算法也需要O(V)的空间，所以 Kruskal 算法总的空间复杂度就是O(V + E)。</p>
<p>时间复杂度主要耗费在排序，需要O(ElogE)的时间，Union-Find 算法所有操作的复杂度都是O(1)，套一个 for 循环也不过是O(E)，所以总的时间复杂度为O(ElogE)。</p>
<h2 id="prim-最小生成树算法">PRIM 最小生成树算法</h2>
<p><strong>Prim 算法也使用贪心思想来让生成树的权重尽可能小</strong>，也就是「切分定理」。</p>
<p><strong>其次，Prim 算法使用</strong> <strong>BFS 算法思想</strong> <strong>和</strong> <strong>visited</strong> <strong>布尔数组避免成环</strong>，来保证选出来的边最终形成的一定是一棵树。</p>
<p>Prim 算法不需要事先对所有边排序，而是利用优先级队列动态实现排序的效果，所以 Prim 算法类似于 Kruskal 的动态过程。</p>
<blockquote>
<p>切分定理：对于任意一种「切分」，其中权重最小的那条「横切边」一定是构成最小生成树的一条边。只要把图中的节点切成两个不重叠且非空的节点集合即可算作一个合法的「切分」</p>
</blockquote>
<blockquote>
<p>反证法证明：给定一幅图的最小生成树，那么随便给一种「切分」，一定至少有一条「横切边」属于最小生成树。假设这条「横切边」不是权重最小的，那说明最小生成树的权重和就还有再减小的余地，那这就矛盾了，最小生成树的权重和本来就是最小的，怎么再减？所以切分定理是正确的。</p>
</blockquote>
<p>算法实现：Prim 算法的逻辑就是，每次切分都能找到最小生成树的一条边，然后又可以进行新一轮切分，直到找到最小生成树的所有边为止。</p>
<pre><code class="language-java">class Prim {
    // 核心数据结构，存储「横切边」的优先级队列
    private PriorityQueue&lt;int[]&gt; pq;
    // 类似 visited 数组的作用，记录哪些节点已经成为最小生成树的一部分
    private boolean[] inMST;
    // 记录最小生成树的权重和
    private int weightSum = 0;
    // graph 是用邻接表表示的一幅图，
    // graph[s] 记录节点 s 所有相邻的边，
    // 三元组 int[]{from, to, weight} 表示一条边
    private List&lt;int[]&gt;[] graph;

    public Prim(List&lt;int[]&gt;[] graph) {
        this.graph = graph;
        this.pq = new PriorityQueue&lt;&gt;((a, b) -&gt; {
            // 按照边的权重从小到大排序
            return a[2] - b[2];
        });
        // 图中有 n 个节点
        int n = graph.length;
        this.inMST = new boolean[n];

        // 随便从一个点开始切分都可以，我们不妨从节点 0 开始
        inMST[0] = true;
        cut(0);
        // 不断进行切分，向最小生成树中添加边
        while (!pq.isEmpty()) {
            int[] edge = pq.poll();
            int to = edge[1];
            int weight = edge[2];
            if (inMST[to]) {
                // 节点 to 已经在最小生成树中，跳过
                // 否则这条边会产生环
                continue;
            }
            // 将边 edge 加入最小生成树
            weightSum += weight;
            inMST[to] = true;
            // 节点 to 加入后，进行新一轮切分，会产生更多横切边
            cut(to);
        }
    }

    // 将 s 的横切边加入优先队列
    private void cut(int s) {
        // 遍历 s 的邻边
        for (int[] edge : graph[s]) {
            int to = edge[1];
            if (inMST[to]) {
                // 相邻接点 to 已经在最小生成树中，跳过
                // 否则这条边会产生环
                continue;
            }
            // 加入横切边队列
            pq.offer(edge);
        }
    }

    // 最小生成树的权重和
    public int weightSum() {
        return weightSum;
    }

    // 判断最小生成树是否包含图中的所有节点
    public boolean allConnected() {
        for (int i = 0; i &lt; inMST.length; i++) {
            if (!inMST[i]) {
                return false;
            }
        }
        return true;
    }
}
</code></pre>
<p>复杂度分析：</p>
<p>复杂度主要在优先级队列 pq 的操作上，由于 pq 里面装的是图中的「边」，假设一幅图边的条数为 E，那么最多操作 O(E) 次 pq。每次操作优先级队列的时间复杂度取决于队列中的元素个数，取最坏情况就是 O(logE)。</p>
<p>这种 Prim 算法实现的总时间复杂度是 O(ElogE)</p>
<h2 id="dijkstra-最短路径规划算法">Dijkstra 最短路径规划算法</h2>
<p>算法签名：</p>
<pre><code class="language-java">// 输入一幅图和一个起点 start，计算 start 到其他节点的最短距离
int[] dijkstra(int start, List&lt;Integer&gt;[] graph);
</code></pre>
<p>输入是一幅图 graph 和一个起点 start，返回是一个记录最短路径权重的数组。</p>
<p>比方说，输入起点 start = 3，函数返回一个 int[] 数组，假设赋值给 distTo 变量，那么从起点 3 到节点 6 的最短路径权重的值就是 distTo[6]。标准的 Dijkstra 算法会把从起点 start 到所有其他节点的最短路径都算出来。</p>
<pre><code class="language-java">class State {
    // 图节点的 id
    int id;
    // 从 start 节点到当前节点的距离
    int distFromStart;

    State(int id, int distFromStart) {
        this.id = id;
        this.distFromStart = distFromStart;
    }
}
</code></pre>
<p>使用 distFromStart 变量记录从起点 start 到当前这个节点的距离。</p>
<p>普通 BFS 算法中，根据 BFS 的逻辑和无权图的特点，第一次遇到某个节点所走的步数就是最短距离，所以用一个 visited 数组防止走回头路，每个节点只会经过一次。</p>
<p>加权图中的 Dijkstra 算法和无权图中的普通 BFS 算法不同，在 Dijkstra 算法中，你第一次经过某个节点时的路径权重，不见得就是最小的，所以对于同一个节点，可能会经过多次，而且每次的 distFromStart 可能都不一样，取 distFromStart 最小的那次，就是从起点 start 到节点 5 的最短路径权重</p>
<p>Dijkstra 可以理解成一个带 dp table（或者说备忘录）的 BFS 算法，伪码如下：</p>
<pre><code class="language-java">// 返回节点 from 到节点 to 之间的边的权重
int weight(int from, int to);

// 输入节点 s 返回 s 的相邻节点
List&lt;Integer&gt; adj(int s);

// 输入一幅图和一个起点 start，计算 start 到其他节点的最短距离
int[] dijkstra(int start, List&lt;Integer&gt;[] graph) {
    // 图中节点的个数
    int V = graph.length;
    // 记录最短路径的权重，你可以理解为 dp table
    // 定义：distTo[i] 的值就是节点 start 到达节点 i 的最短路径权重
    int[] distTo = new int[V];
    // 求最小值，所以 dp table 初始化为正无穷
    Arrays.fill(distTo, Integer.MAX_VALUE);
    // base case，start 到 start 的最短距离就是 0
    distTo[start] = 0;

    // 优先级队列，distFromStart 较小的排在前面
    Queue&lt;State&gt; pq = new PriorityQueue&lt;&gt;((a, b) -&gt; {
        return a.distFromStart - b.distFromStart;
    });

    // 从起点 start 开始进行 BFS
    pq.offer(new State(start, 0));

     while (!pq.isEmpty()) {
        State curState = pq.poll();
        int curNodeID = curState.id;
        int curDistFromStart = curState.distFromStart;

        if (curDistFromStart &gt; distTo[curNodeID]) {
            // 已经有一条更短的路径到达 curNode 节点了
            continue;
        }
        // 将 curNode 的相邻节点装入队列
        for (int nextNodeID : adj(curNodeID)) {
            // 看看从 curNode 达到 nextNode 的距离是否会更短
            int distToNextNode = distTo[curNodeID] + weight(curNodeID, nextNodeID);
            if (distTo[nextNodeID] &gt; distToNextNode) {
                // 更新 dp table
                distTo[nextNodeID] = distToNextNode;
                // 将这个节点以及距离放入队列
                pq.offer(new State(nextNodeID, distToNextNode));
            }
        }
    }
    return distTo;
}
</code></pre>
<p>计算起点到终点end的最短距离</p>
<pre><code class="language-java">// 输入起点 start 和终点 end，计算起点到终点的最短距离
int dijkstra(int start, int end, List&lt;Integer&gt;[] graph) {

    // ...

    while (!pq.isEmpty()) {
        State curState = pq.poll();
        int curNodeID = curState.id;
        int curDistFromStart = curState.distFromStart;

        // 在这里加一个判断就行了，其他代码不用改
        if (curNodeID == end) {
            return curDistFromStart;
        }

        if (curDistFromStart &gt; distTo[curNodeID]) {
            continue;
        }

        // ...
    }

    // 如果运行到这里，说明从 start 无法走到 end
    return Integer.MAX_VALUE;
}
</code></pre>
<h2 id="a-算法">A* 算法</h2>
<p>Dijkstra算法的优点在于其简单可靠，能够保证找到全局最优解。然而，其缺点也明显：对大规模图的处理效率低下，因为它需要遍历整个图。</p>
<p>Astar 是一种 广搜的改良版。有的 Astar是 dijkstra 的改良版。</p>
<p>其实只是场景不同而已，在搜索最短路的时候， 如果是无权图（边的权值都是1） 那就用广搜，代码简洁，时间效率和 dijkstra 差不多 （具体要取决于图的稠密）如果是有权图（边有不同的权值），优先考虑 dijkstra。</p>
<p>而 Astar 关键在于 启发式函数， 也就是 影响 广搜或者 dijkstra 从 容器（队列）里取元素的优先顺序。</p>
<h3 id="实现机制">实现机制</h3>
<ol>
<li>
<p>启发式搜索的优势<br>
A*算法引入了启发式函数h(v)，它预估了从节点v到目标节点的最优路径成本。这使得A*能够在搜索过程中具有方向性，优先探索那些更有可能导向目标的路径，从而减少不必要的探索，提高搜索效率。</p>
</li>
<li>
<p>实现机制</p>
<ul>
<li>
<p>评估函数：A*的关键在于f(v)=g(v)+h(v)，其中g(v)是从起点到节点v的实际成本，h(v)是启发式函数，通常表示 当前节点 到终点的距离。因此两者相加就是起点到终点的距离。</p>
</li>
<li>
<p>开放与关闭集合：算法维护两个集合，开放集合存放待评估的节点，关闭集合存放已评估节点。每次迭代从开放集合中选择f值最小的节点进行扩展，直到目标节点被加入关闭集合。</p>
</li>
</ul>
</li>
</ol>
<p><strong>BFS 是没有目的性的 一圈一圈去搜索， 而 A* 是有方向性的去搜索</strong>。</p>
<p>那么 A* 为什么可以有方向性的去搜索，它的如何知道方向呢？<strong>其关键在于 启发式函数</strong>。</p>
<p>计算两点距离通常有如下三种计算方式：这也一般被选为启发式函数，用来预估当前节点到终点的距离</p>
<ol>
<li>曼哈顿距离，计算方式：d = abs(x1-x2)+abs(y1-y2)</li>
<li>欧氏距离（欧拉距离） ，计算方式：d = sqrt( (x1-x2)^2 + (y1-y2)^2 )</li>
<li>切比雪夫距离，计算方式：d = max(abs(x1 - x2), abs(y1 - y2))</li>
</ol>
<h3 id="与dijkstra的对比分析">与Dijkstra的对比分析</h3>
<ul>
<li>计算效率：A*由于采用了启发式信息，通常比Dijkstra算法更快找到解，尤其在复杂路网中更为显著。</li>
<li>路径质量：理论上，只要启发式函数满足可接纳性条件，A*保证找到最短路径。Dijkstra同样保证最短路径，但缺乏效率优势。</li>
<li>资源消耗：A*在内存使用上可能更高，因为它需要维护开放集合和关闭集合，而Dijkstra只需维护未访问集合和前驱节点映射。</li>
<li>适用场景：Dijkstra适用于小型或中型规模、对实时性要求不高的场景；A*更适合大型图搜索或对实时性要求较高的无场景。</li>
</ul>
<h3 id="代码实现">代码实现</h3>
<p>实现代码如下：启发式函数 采用 欧拉距离计算方式</p>
<pre><code class="language-java">class Node {
    //表示节点在网格中的位置
    int x, y;
    //gCost表示从起点到该节点的实际代价，hCost表示从该节点到目标节点的估计代价（启发式值），fCost是两者之和。
    double gCost, hCost, fCost;
    //用于重构路径
    Node parent;

    public Node(int x, int y) {
        this.x = x;
        this.y = x;
    }

    //计算当前节点到目标节点的欧拉距离。
    public double calculateHeuristic(Node target) {
        return Math.sqrt(Math.pow(this.x - target.x, 2) + Math.pow(this.y - target.y, 2));
    }

    public void updateCosts(Node target, double gCost) {
        this.gCost = gCost;
        this.hCost = calculateHeuristic(target);
        this.fCost = this.gCost + this.hCost;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null || getClass() != obj.getClass()) return false;
        Node node = (Node) obj;
        return x == node.x &amp;&amp; y == node.y;
    }

    @Override
    public int hashCode() {
        return Objects.hash(x, y);
    }
}

class AStar {
    private static final int[][] DIRECTIONS = {{1, 0}, {-1, 0}, {0, 1}, {0, -1},
            {1, 1}, {1, -1}, {-1, 1}, {-1, -1}};

    public List&lt;Node&gt; findPath(Node start, Node target, int[][] grid) {
        //表示待处理节点
        Set&lt;Node&gt; openSet = new HashSet&lt;&gt;();
        //表示已处理节点
        Set&lt;Node&gt; closedSet = new HashSet&lt;&gt;();
        //用于获取具有最小fCost的节点
        PriorityQueue&lt;Node&gt; priorityQueue = new PriorityQueue&lt;&gt;(Comparator.comparingDouble(n -&gt; n.fCost));

        start.updateCosts(target, 0);
        openSet.add(start);
        priorityQueue.add(start);

        while (!openSet.isEmpty()) {
            Node current = priorityQueue.poll();
            openSet.remove(current);
            closedSet.add(current);

            if (current.equals(target)) {
                return reconstructPath(current);
            }

            for (int[] direction : DIRECTIONS) {
                int newX = current.x + direction[0];
                int newY = current.y + direction[1];

                if (!isInBounds(newX, newY, grid) || grid[newX][newY] == 1) {
                    continue;
                }

                Node neighbor = new Node(newX, newY);
                if (closedSet.contains(neighbor)) {
                    continue;
                }

                double tentativeGCost = current.gCost + current.calculateHeuristic(neighbor);
                if (!openSet.contains(neighbor) || tentativeGCost &lt; neighbor.gCost) {
                    neighbor.updateCosts(target, tentativeGCost);
                    neighbor.parent = current;

                    if (!openSet.contains(neighbor)) {
                        openSet.add(neighbor);
                        priorityQueue.add(neighbor);
                    }
                }
            }
        }
        return Collections.emptyList();
    }

    // 检查节点是否在网格范围内。
    private boolean isInBounds(int x, int y, int[][] grid) {
        return x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; grid.length &amp;&amp; y &lt; grid[0].length;
    }

    //从目标节点回溯构建路径。
    private List&lt;Node&gt; reconstructPath(Node node) {
        List&lt;Node&gt; path = new ArrayList&lt;&gt;();
        while (node != null) {
            path.add(node);
            node = node.parent;
        }
        Collections.reverse(path);
        return path;
    }
}
</code></pre>
<h3 id="复杂度分析">复杂度分析</h3>
<p>A* 算法的时间复杂度 其实是不好去量化的，因为他取决于 启发式函数怎么写。</p>
<ul>
<li>
<p>最坏情况下，A* 退化成广搜，算法的时间复杂度 是 O(n * 2)，n 为节点数量。</p>
</li>
<li>
<p>最佳情况，是从起点直接到终点，时间复杂度为 O(dlogd)，d 为起点到终点的深度。因为在搜索的过程中也需要堆排序，所以是 O(dlogd)。</p>
</li>
</ul>
<p>实际上 A* 的时间复杂度是介于 最优 和最坏 情况之间， 可以 非常粗略的认为 A* 算法的时间复杂度是 O(nlogn) ，n 为节点数量。</p>
<p>A* 算法的空间复杂度 O(b ^ d) ,d 为起点到终点的深度，b 是 图中节点间的连接数量</p>
<h3 id="a-的缺点">A* 的缺点</h3>
<p>大家看上述 A * 代码的时候，可以看到 我们向队列里添加了很多节点，但真正从队列里取出来的 仅仅是 靠启发式函数判断 距离终点最近的节点。</p>
<p>相对于普通BFS，A* 算法只从 队列里取出 距离终点最近的节点。</p>
<p>那么问题来了，A* 在一次路径搜索中，大量不需要访问的节点都在队列里，会造成空间的过度消耗。</p>
<p>IDA* 算法对这一空间增长问题进行了优化，关于 IDA* 算法，后续再更新 //to do</p>
<p>另外还有一种场景 是 A* 解决不了的。</p>
<p>如果给出多个可能的目标，然后在这多个目标中选择最近的目标，这种 A* 就不擅长了， A* 只擅长给出明确的目标 然后找到最短路径。</p>
<p>如果是多个目标找最近目标（特别是潜在目标数量很多的时候），可以考虑 Dijkstra ，BFS 或者 Floyd。</p>

</div>
<div id="MySignature" role="contentinfo">
    <p>本文来自在线网站：seven的菜鸟成长之路，作者：seven，转载请注明原文链接：www.seven97.top</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 09:00">2025-12-22 09:00</span>&nbsp;
<a href="https://www.cnblogs.com/sevencoding">程序员Seven</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">1</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19376818);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19376818', targetLink: 'https://www.cnblogs.com/sevencoding/p/19376818', title: '一文讲清楚图论相关算法' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 上周热点回顾（12.15-12.21） ]]></title>
    <link>https://www.cnblogs.com/cmt/p/19380650</link>
    <guid>925a2be560ba21ad166c38c4a601b6e6</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/cmt/p/19380650" title="发布于 2025-12-22 08:51">
    <span role="heading" aria-level="2">上周热点回顾（12.15-12.21）</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p>热点随笔：</p>
<p> · <a href="https://www.cnblogs.com/yupi/archive/2025/12/16/19357567.html" target="_blank">全面封禁 Cursor！又一家大厂出手了</a> (<a href="https://www.cnblogs.com/yupi/" target="_blank">程序员鱼皮</a>) <br>
 · <a href="https://www.cnblogs.com/12lisu/archive/2025/12/15/19350919.html" target="_blank">假如有10亿QQ号如何去重？</a>
(<a href="https://www.cnblogs.com/12lisu/" target="_blank">苏三说技术</a>)                    <br>
 · <a href="https://www.cnblogs.com/MeteorSeed/archive/2025/12/17/19307311.html" target="_blank">【译】初探 Visual Studio 2026 全新的用户体验</a>
(<a href="https://www.cnblogs.com/MeteorSeed/" target="_blank">MeteorSeed</a>)                    <br>
 · <a href="https://www.cnblogs.com/mingupupu/archive/2025/12/15/19352075.html" target="_blank">OpenCVSharp：了解几种特征检测</a>
(<a href="https://www.cnblogs.com/mingupupu/" target="_blank">mingupupup</a>)                    <br>
 · <a href="https://www.cnblogs.com/shanyou/archive/2025/12/16/19355053.html" target="_blank">2025年 WebTransport 生态深度研究：JavaScript 客户端与.NET 10 SignalR 的演进与融合</a>
(<a href="https://www.cnblogs.com/shanyou/" target="_blank">张善友</a>)                    <br>
 · <a href="https://www.cnblogs.com/yupi/archive/2025/12/17/19363337.html" target="_blank">消息队列从入门到跑路，保姆级教程！傻子可懂</a>
(<a href="https://www.cnblogs.com/yupi/" target="_blank">程序员鱼皮</a>)                    <br>
 · <a href="https://www.cnblogs.com/yubaolee/archive/2025/12/18/stargantt.html" target="_blank">央企程序员AI创业后续</a>&nbsp;(<a href="https://www.cnblogs.com/yubaolee/" target="_blank">李玉宝</a>)                    <br>
 · <a href="https://www.cnblogs.com/yupi/archive/2025/12/15/19351700.html" target="_blank">什么是负载均衡？不就是加台服务器嘛！</a>
(<a href="https://www.cnblogs.com/yupi/" target="_blank">程序员鱼皮</a>)                    <br>
 · <a href="https://www.cnblogs.com/shanyou/archive/2025/12/17/19360467.html" target="_blank">Aspire 13：从.NET 编排工具到真正的多语言云原生应用平台</a>
(<a href="https://www.cnblogs.com/shanyou/" target="_blank">张善友</a>)                    <br>
 · <a href="https://www.cnblogs.com/MeteorSeed/archive/2025/12/18/19366736.html" target="_blank">Newtonsoft.Json 与 System.Text.Json 多态反序列化的安全性差异解析</a>
(<a href="https://www.cnblogs.com/MeteorSeed/" target="_blank">MeteorSeed</a>)                    <br>
 · <a href="https://www.cnblogs.com/cmt/archive/2025/12/15/19350596.html" target="_blank">上周热点回顾（12.8-12.14）</a>
(<a href="https://www.cnblogs.com/cmt/" target="_blank">博客园团队</a>)                    <br>
 · <a href="https://www.cnblogs.com/BettaFish/archive/2025/12/16/avalonia-grid.html" target="_blank">Avalonia源码解读：Grid（网格控件）</a>
(<a href="https://www.cnblogs.com/BettaFish/" target="_blank">zxbmmmmmmmmm</a>)                    <br>
            </p>
<p>热点新闻：</p>
<p>
 · <a href="https://news.cnblogs.com/n/809254/" target="_blank">最小全自主编程机器人研发成功</a><br>
 · <a href="https://news.cnblogs.com/n/809170/" target="_blank">中国燃油车在海外大火？国产燃油车是怎么行的？</a><br>
 · <a href="https://news.cnblogs.com/n/809106/" target="_blank">新方法提升AI预训练效率和准确性</a><br>
 · <a href="https://news.cnblogs.com/n/809157/" target="_blank">“俄版谷歌”，正帮中国商人大赚</a><br>
 · <a href="https://news.cnblogs.com/n/809021/" target="_blank">“永远50年”魔咒终结</a><br>
 · <a href="https://news.cnblogs.com/n/809101/" target="_blank">Linux 6.19-rc1 释出，龙芯为内核加入 32 位架构 LoongArch32 支持</a><br>
 · <a href="https://news.cnblogs.com/n/809386/" target="_blank">罗永浩吐槽上海电信网速问题：再不帮忙解决就要网上发疯</a><br>
 · <a href="https://news.cnblogs.com/n/809255/" target="_blank">小米突然发布新模型：媲美 DeepSeek-V3.2，把手机的性价比卷到 AI</a><br>
 · <a href="https://news.cnblogs.com/n/809116/" target="_blank">你初中用的计算器，现在还在乱杀。</a><br>
 · <a href="https://news.cnblogs.com/n/809039/" target="_blank">巨头裁员，这次史无前例</a><br>
 · <a href="https://news.cnblogs.com/n/809206/" target="_blank">学18个月胖东来，永辉亏在房本上</a><br>
 · <a href="https://news.cnblogs.com/n/809179/" target="_blank">新能源车VS燃油车：用车成本大PK</a></p>
<p>推广项目：</p>
<p>· <a href="https://www.ebcloud.com/chn_xhpwpopm" rel="noopener nofollow" target="_blank">英博云GPU容器服务平台，智能算力即开即用，立即免费试用</a><br>· <a href="https://ais.cn/u/VZZZJj" rel="noopener nofollow" target="_blank">科研领域的连接者艾思科蓝，一站式科研学术服务数字化平台</a><br>· <a href="https://www.cnblogs.com/cmt/p/19165152" rel="noopener" target="_blank">诚邀您体验阿里巴巴推出的新一代 Agentic 编程平台 Qoder</a><br>· <a href="https://dis.chatdesks.cn/chatdesk/jmcnblogs.html" rel="noopener nofollow" target="_blank">人像高清输出，百变风格随心换，快来即梦试试吧</a><br>·&nbsp;<a href="https://www.trae.com.cn/?utm_source=advertising&amp;utm_medium=cnblogs_ug_cpa&amp;utm_term=hw_trae_cnblogs" rel="noopener nofollow" target="_blank">TRAE SOLO 中国版正式上线，全面免费</a></p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-22 08:51">2025-12-22 08:51</span>&nbsp;
<a href="https://www.cnblogs.com/cmt">博客园团队</a>&nbsp;
阅读(<span id="post_view_count">0</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19380650);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19380650', targetLink: 'https://www.cnblogs.com/cmt/p/19380650', title: '上周热点回顾（12.15-12.21）' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 架构师必备：后端程序员需要了解的数仓知识 ]]></title>
    <link>https://www.cnblogs.com/toplist/p/19350289</link>
    <guid>71ffd31248490daf3dd410f5abc09ac9</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/toplist/p/19350289" title="发布于 2025-12-22 08:26">
    <span role="heading" aria-level="2">架构师必备：后端程序员需要了解的数仓知识</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>大家好，我是Java烘焙师。后端程序员平时除了接触业务代码、中间件、存储等，也难免会跟数仓有交集。下面结合笔者的经验和思考，从后端程序员的视角看数仓、做个总结，后续再跟数仓/BI argue的时候就不虚了😃</p>
<p>分成两部分介绍：离线数仓、实时数仓。</p>
<h1 id="离线数仓">离线数仓</h1>
<p>离线数仓是最典型的数仓应用场景。后端服务产生了业务数据、监控埋点、日志等，如果要做统计分析，就要先离线采集到数仓，再通过SQL做聚合查询。<br>
离线数仓的重点，在于统计分析历史存量数据，做合理的业务域划分、数据分层、数据分区。</p>
<p><img src="https://img2024.cnblogs.com/blog/1247698/202512/1247698-20251222013722221-284016663.png" alt="离线数仓数据分层、数据分区" width="550" loading="lazy"></p>
<h2 id="数据采集">数据采集</h2>
<p>需要采集的数据包括：业务数据、监控埋点、日志等。</p>
<ul>
<li>业务数据：一般存储在DB、或HBase，可一次性把存量数据导入hive表，后续定时扫描一段时间范围内的增量数据导入hive表</li>
<li>监控埋点：后端服务发出埋点消息，采集程序消费消息、解析、最终导入到hive表</li>
<li>日志：可通过filebeat采集日志，采集程序解析后、导入到hive表</li>
</ul>
<h2 id="数据分层">数据分层</h2>
<p>逻辑层面的水平数据分层：</p>
<ul>
<li><code>ODS (Operational Data Store)</code>：原始数据，一般不做任何加工</li>
<li><code>DWD (Data Warehouse Detail)</code>：数仓明细数据，在ODS的基础上做一些简单加工，如数据清洗，解析json格式字段、打平后存储</li>
<li><code>DWS (Data WareHouse Summary)</code>：数仓汇总数据，在DWD的基础上按维度做聚合宽表，方便业务方使用</li>
<li><code>ADS (Application Data Service)</code>：直接可用的报表应用数据</li>
</ul>
<p>离线数仓的数据分层，类似于后端代码结构的分层设计，比如分为接口层interface、逻辑层service、数据访问层repository。<br>
数据分层可以隔离每层之间的依赖，每层的变更只限于本层。比如mysql拆库迁移只需要更换ods表，但无需改dwd表，这样数据使用方不用感知数据源变更。<br>
数据分层可以在DW层聚合数据，提高数据使用方的效率、降低开发成本。</p>
<p>后端程序员接触最多的是ods和dwd表：</p>
<ul>
<li>ods表涉及到数据采集，并且是归档删在线数据的前提</li>
<li>dwd表可以用来排查历史数据，因为json格式字段已打平，所以方便做筛选查询</li>
</ul>
<h2 id="数据分区">数据分区</h2>
<p>按时间维度做垂直分区，一般是日级或小时级分区，取决于调度频率：</p>
<ul>
<li>天级增量表：包含某一天有变更的数据记录</li>
<li>天级全量表：包含某一天完整的数据记录，相当于快照</li>
<li>小时级增量表：包含某一小时有变更的数据记录</li>
</ul>
<p>因为数据量较大，所以不是所有的离线表都会永久保留。比如ods天级增量表可能仅保留最近n天、或最近n个分区，而dwd天级全量表会merge增量数据，可查到历史上的所有数据记录。</p>
<h2 id="离线数仓使用场景">离线数仓使用场景</h2>
<ul>
<li>离线统计：
<ul>
<li>通过hive sql做复杂的关联查询、聚合查询，底层会转成MapReduce任务，查询HDFS里的hive表</li>
<li>比如把多张事实表、维度表join起来，做某个维度的数量加总、金额加总。事实表是业务活动的事件记录，可以做聚合查询统计。维度表是元数据，按维度做聚合分析（max、count，group by维度）。事实表一般包含多个维度表的外键。</li>
</ul>
</li>
<li>数据对账：判断业务双方的数据是否一致，参考笔者之前写的文章：<a href="https://www.cnblogs.com/toplist/p/19009976" target="_blank">架构师必备：实时对账与离线对账</a></li>
<li>后端刷历史存量数据：需要先在离线统计符合条件的数据，再导出id消息，作为后端刷数据的输入依据</li>
</ul>
<h2 id="后端归档删除在线数据">后端归档删除在线数据</h2>
<p>后端在线数据不断膨胀，当业务层面不再访问时，需要做归档删除。一定要确保业务数据先被离线采集到、再删除在线数据，否则就可能丢数据、找不回来了。<br>
比如新增一个<code>archive_status</code>字段代表归档状态（而非有业务含义的<code>deleted</code>字段），初始值是0，被软删后改成1，那么如果hive表里记录的归档状态是1，则代表该记录已被离线采集到，可放心地删除对应在线记录。</p>
<h1 id="实时数仓">实时数仓</h1>
<p>有了离线数仓，为什么还需要实时数仓呢？</p>
<ul>
<li>主要还是为了时效性，离线数仓最快是小时级，如果需要秒级延迟，就需要上实时数仓了</li>
<li>实时数仓跑出来的结果，可以被后端服务查询，用于在线业务</li>
</ul>
<p>实时数仓的重点，在于低延迟计算、exactly-once处理，与后端应用结合可以实现很多功能。</p>
<h2 id="实时数仓构建流程">实时数仓构建流程</h2>
<p>使用flink把数据采集、数据计算、数据导出的流程串起来。这里引用一张某云厂商的实践教程图，里面的数仓存储可替代为其它。<br>
参考：<a href="https://help.aliyun.com/zh/flink/realtime-flink/use-cases/build-real-time-data-warehouse-based-on-flink-hologres" target="_blank" rel="noopener nofollow">实时数仓搭建</a><br>
<img src="https://img2024.cnblogs.com/blog/1247698/202512/1247698-20251221001017213-980708973.png" alt="image" loading="lazy"></p>
<ul>
<li>实时入仓：mysql binlog、或业务事件，触发实时数据流，通过flink实时入仓</li>
<li>数据计算：通过flink关联join多个ods表，得到dwd表，再实时计算得到按维度聚合的dws表</li>
<li>数据导出、对外提供接口查询：计算结果可导出到实时数仓，如Doris、Hologres等，也可以导出到mysql、hbase、或redis，并封装成RPC接口。这样后端服务可以查询实时数仓接口，对外提供高qps查询</li>
</ul>
<h2 id="实时数仓使用场景">实时数仓使用场景</h2>
<ul>
<li>内部报表查询</li>
<li>外部统计类查询：典型的例如用户看到的 排行榜、多少人看过/加购/收藏/买过 等</li>
<li>用户个性化推荐</li>
</ul>
<p>以上，就是后端程序员需要了解的数仓知识了，欢迎关注、转发、点赞。</p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.01597222222222222" data-date-updated="2025-12-22 08:49">2025-12-22 08:26</span>&nbsp;
<a href="https://www.cnblogs.com/toplist">Java烘焙师</a>&nbsp;
阅读(<span id="post_view_count">53</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19350289);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19350289', targetLink: 'https://www.cnblogs.com/toplist/p/19350289', title: '架构师必备：后端程序员需要了解的数仓知识' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 企业级多智能体系统（MAS）架构深度研究：C# 与Python生态系统的全面对比与战略评估 ]]></title>
    <link>https://www.cnblogs.com/shanyou/p/19380471</link>
    <guid>875aaba4d3397217a3d3700db58a179d</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/shanyou/p/19380471" title="发布于 2025-12-22 07:28">
    <span role="heading" aria-level="2">企业级多智能体系统（MAS）架构深度研究：C# 与Python生态系统的全面对比与战略评估</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="1-摘要"><strong>1. 摘要</strong></h2>
<p>随着生成式人工智能（Generative AI）从单一的对话式“Chatbot”向具备自主规划、工具调用和长期记忆能力的“多智能体系统”（Multi-Agent Systems, MAS）演进，企业级软件架构正面临着前所未有的范式转移。在此背景下，编程语言与开发框架的选择不再仅仅是技术偏好的问题，而是直接关系到系统稳定性、可维护性、安全性及运营成本的战略决策。</p>
<p>本文旨在响应关于C#与Python在企业级Agent应用开发中适用性的深度对比需求。报告基于TIOBE排名前五的编程语言格局，深入剖析了C#生态系统中的核心框架（BotSharp、Semantic Kernel、Microsoft Agent Framework）及平台产品（Microsoft AI Foundry、智用开物 Agent Foundry），并将其与Python生态系统中的主流竞品（LangGraph、CrewAI、Dify）进行多维度的技术与商业对比。</p>
<p>研究发现，尽管Python凭借其在模型训练和数据科学领域的先发优势占据了AI开发的主流地位，但在企业级多智能体系统的编排（Orchestration）<strong>与</strong>工程化落地（Operationalization）阶段，C# 及其背后的.NET 生态展现出了显著的架构优势。具体而言：</p>
<ol>
<li><strong>并发与性能</strong>：C# 的任务并行库（TPL）与真正的多线程能力，在处理大规模并发智能体交互时，相比受限于全局解释器锁（GIL）的 Python 具有数量级的吞吐量优势 1。</li>
<li><strong>类型安全与可维护性</strong>：多智能体系统本质上是复杂的分布式系统。C# 的静态类型系统为复杂的Agent间通信协议提供了编译时保障，极大地降低了大规模重构和长期维护的风险 3。</li>
<li><strong>部署与冷启动</strong>：.NET 8/9/10 引入的 Native AOT（Ahead-of-Time）编译技术，使得 C# Agent 可以被编译为无依赖的微型原生二进制文件，显著解决了 Serverless 环境下的冷启动延迟问题，这对于成本敏感的企业级应用至关重要 5。</li>
<li><strong>生态融合</strong>：Microsoft Agent Framework 的推出标志着 C# 生态的成熟，它成功融合了 AutoGen 的灵活性与 Semantic Kernel 的工程严谨性。同时，像“智用开物”这类由前微软专家创立的平台，验证了基于 C# 构建行业级（如制造业）Agent Foundry 的可行性与优越性 7。</li>
</ol>
<p>本文建议，对于追求高性能、高安全标准且业务逻辑复杂的企业级 MAS 系统，C# 是比 Python 更为稳健的架构选择；而 Python 则继续在快速原型验证及依赖特定数据科学库的场景中保持优势。</p>
<h2 id="2-宏观背景tiobe-排名前五语言在-ai-agent-时代的定位"><strong>2. 宏观背景：TIOBE 排名前五语言在 AI Agent 时代的定位</strong></h2>
<p>TIOBE 指数反映了编程语言的流行趋势，当前排名前五的语言通常包括 Python、C、C++、Java 和 C# 9。在多智能体系统（MAS）的语境下，这五种语言的角色发生了深刻的分化。</p>
<h3 id="21-python无可争议的模型训练霸主与原型先锋"><strong>2.1 Python：无可争议的模型训练霸主与原型先锋</strong></h3>
<p>Python 长期霸榜 TIOBE 第一名，其统治地位源于极其丰富的 AI/ML 库（PyTorch, TensorFlow, Hugging Face）。</p>
<ul>
<li><strong>优势</strong>：在 Agent 开发的早期阶段（Prompt Engineering、RAG 实验），Python 拥有最丰富的生态支持（如 LangChain）。几乎所有新的模型和论文复现代码都首选 Python。</li>
<li><strong>企业级挑战</strong>：然而，当 Agent 从“实验”走向“生产”时，Python 的解释型语言特性、动态类型系统以及 GIL 带来的并发限制，使其在构建高并发、低延迟的 Orchestration Layer（编排层）时面临性能瓶颈和维护挑战 1。</li>
</ul>
<h3 id="22-cc底层的算力引擎"><strong>2.2 C/C++：底层的算力引擎</strong></h3>
<p>尽管 C 和 C++ 常年位居前列，但它们在 Agent <strong>应用开发</strong>层面的直接使用极少。</p>
<ul>
<li><strong>定位</strong>：它们是 AI 的“基础设施”。TensorFlow 的底层、ONNX Runtime 以及 CUDA 核心都是用 C++ 编写的。</li>
<li><strong>Agent 相关性</strong>：企业开发者几乎不会直接用 C++ 编写 Agent 的业务逻辑（Prompt 管理、工具调用），因为其开发效率较低且内存管理复杂。它们的存在形式是对上层语言（Python/C#）提供高性能的推理接口 13。</li>
</ul>
<h3 id="23-java传统的企业后端巨人"><strong>2.3 Java：传统的企业后端巨人</strong></h3>
<p>Java 依然是大型企业（特别是金融、电信）后端系统的主力语言。</p>
<ul>
<li><strong>现状</strong>：Java 社区正在通过 <strong>Spring AI</strong> 等项目追赶 AI 浪潮，试图复制 LangChain 和 Semantic Kernel 的能力 14。</li>
<li><strong>局限</strong>：相比 C#，Java 在 AI 原生支持上稍显滞后。微软作为 OpenAI 的主要合作伙伴，其.NET 团队与 AI 模型的集成深度远超 Java 生态。Semantic Kernel 的 C# 版本通常比 Java 版本功能更新、更全，Microsoft Agent Framework直接就不支持Java 。</li>
</ul>
<h3 id="24-c企业级-ai-应用的甜蜜点"><strong>2.4 C#：企业级 AI 应用的“甜蜜点”</strong></h3>
<p>C# 是 TIOBE 年度语言（2023）的获得者，其地位在 AI 时代得到了重塑 11。</p>
<ul>
<li><strong>定位</strong>：C# 位于 Python（开发效率）和 C++（运行效率）的中间地带。随着.NET Core 的跨平台化和性能优化，C# 成为了构建“高性能应用层”的首选。</li>
<li><strong>战略优势</strong>：在 Agent 开发中，C# 提供了 Python 难以比拟的<strong>类型系统</strong>和<strong>并发模型</strong>，同时又比 Java 拥有更激进的 AI 框架支持（Semantic Kernel, Agent Framework）。它被视为连接“AI 模型能力”与“企业业务逻辑”的最佳桥梁 16。</li>
</ul>
<h2 id="3-c-多智能体生态深度解析框架与平台"><strong>3. C# 多智能体生态深度解析：框架与平台</strong></h2>
<p>微软及其生态合作伙伴构建了一个层次分明、功能完备的 C# Agent 开发栈。这一生态系统从底层的原子能力到上层的行业平台，均体现了显著的“企业级”特征。</p>
<h3 id="31-核心框架层"><strong>3.1 核心框架层</strong></h3>
<h4 id="311-microsoft-agent-framework集大成者"><strong>3.1.1 Microsoft Agent Framework：集大成者</strong></h4>
<p><strong>Microsoft Agent Framework</strong> 是微软在 2024-2025 年推出的重磅产品，被视为 Semantic Kernel 和 AutoGen 的“继任者”与“统一体” 17。</p>
<ul>
<li><strong>架构融合</strong>：
<ul>
<li><strong>继承 Semantic Kernel (SK)</strong>：它保留了 SK 的企业级特性，如依赖注入（DI）、过滤器（Filters）和遥测（Telemetry）。这确保了 Agent 可以无缝集成到现有的 ASP.NET Core 应用中，符合企业 IT 的合规要求。</li>
<li><strong>继承 AutoGen</strong>：它吸收了 AutoGen 的多智能体协作模式（Conversation Patterns）。开发者可以定义“群聊”，让多个 Agent（如“开发人员”、“测试人员”、“产品经理”）通过消息传递进行自主协作，解决复杂问题。</li>
</ul>
</li>
<li><strong>工作流（Workflows）</strong>：
<ul>
<li>与 Python 生态中 LangGraph 类似，Agent Framework 引入了基于图（Graph-based）的工作流引擎。这解决了纯对话式 Agent 执行过程不可控的问题。企业可以在保持 Agent 自主性的同时，强制执行特定的业务流程（如审批流、合规检查） 17。</li>
</ul>
</li>
<li><strong>技术特性</strong>：支持云端与边缘侧的混合部署，且深度集成了 Azure AI Foundry 的能力。</li>
</ul>
<h4 id="312-semantic-kernel-sk中间件与连接器"><strong>3.1.2 Semantic Kernel (SK)：中间件与连接器</strong></h4>
<p>虽然 Agent Framework 是最新的统一层，但 <strong>Semantic Kernel</strong> 依然是其底层的核心“内核”。</p>
<ul>
<li><strong>设计哲学</strong>：SK 的核心理念是“将 AI 模型视为一种函数调用”。它通过 <strong>Plugins（插件）</strong> 和 <strong>Planners（规划器）</strong> 的概念，将 LLM 的推理能力与原生代码（C# Functions）连接起来 19。</li>
<li><strong>企业级特性</strong>：
<ul>
<li><strong>记忆（Memory）</strong>：SK 提供了强大的向量数据库抽象层，支持 Azure AI Search、Qdrant、Pinecone 等多种后端，使 Agent 具备长期记忆能力。</li>
<li><strong>协议适配</strong>：SK 严格遵循企业开发规范，支持 OpenTelemetry 标准，使得 AI 调庸的链路追踪（Tracing）和监控变得标准化，这在 Python 的散装库中往往需要繁琐配置 20。</li>
</ul>
</li>
</ul>
<h4 id="313-botsharp纯粹的net-原生方案"><strong>3.1.3 BotSharp：纯粹的.NET 原生方案</strong></h4>
<p><strong>BotSharp</strong> 是一个开源的、专为企业级设计的 Agent 构建平台，其最大的特点是完全基于 C# 编写，拒绝了许多框架对 Python 的隐式依赖 3。</p>
<ul>
<li><strong>架构特点</strong>：
<ul>
<li><strong>无 Python 依赖</strong>：许多所谓的“多语言”框架底层实际上是在调用 Python 脚本。BotSharp 坚持使用 C# 实现 NLP 算法和逻辑，这对于那些严格限制生产环境运行时的企业（如不允许安装 Python 环境的银行系统）极具吸引力 3。</li>
<li><strong>模块化管道</strong>：采用严格的组件化设计，将 NLU（自然语言理解）、对话管理、UI 渲染完全解耦。</li>
<li><strong>路由与钩子（Hooks）</strong>：提供了强大的 Agent Hook 机制，允许开发者在对话生命周期的任何阶段（输入前、推理后、执行前）注入 C# 代码。这种强类型的钩子机制比 Python 的装饰器更易于调试和维护 3。</li>
</ul>
</li>
</ul>
<h3 id="32-平台产品层"><strong>3.2 平台产品层</strong></h3>
<h4 id="321-microsoft-ai-foundry-前-azure-ai-studio"><strong>3.2.1 Microsoft AI Foundry (前 Azure AI Studio)</strong></h4>
<p><strong>Microsoft AI Foundry</strong> 是微软提供的统一 AI 平台，其 Agent Service 深度集成了上述 C# 框架 7。</p>
<ul>
<li><strong>Foundry Agent Service</strong>：这是一个全托管的运行时环境。它允许开发者使用 C# (Agent Framework) 编写 Agent，然后一键部署到 Azure。</li>
<li><strong>企业价值</strong>：它解决了“运维”难题。企业不需要自己管理 Docker 容器或 Kubernetes 集群，Foundry 处理了 Agent 的扩缩容、状态持久化和身份认证（Entra ID） 24。</li>
</ul>
<h4 id="322-智用开物-agent-foundry"><strong>3.2.2 智用开物 Agent Foundry</strong></h4>
<p><strong>智用开物</strong> 是一个典型的基于 C# 技术栈构建的垂直行业平台案例。</p>
<ul>
<li><strong>背景</strong>：该公司由前微软首席技术专家团队创立，这种“微软系”的基因使其天然选择了.NET 技术栈作为底层架构 8。</li>
<li><strong>产品定位</strong>：其 <strong>AI Agent Foundry</strong> 平台主打“Intelligence as a Service”（智能即服务），专注于制造业、教育和公共服务领域。</li>
<li><strong>技术架构</strong>：
<ul>
<li>利用 C# 的高性能特性，该平台能够支持复杂的工业场景，如生产流程管理和实时数据分析。</li>
<li>它的存在证明了 C# 不仅能做通用的 Chatbot，更能胜任对稳定性要求极高的工业级 Agent 系统（Industry 4.0） 8。这也反驳了“C# 只能做企业内网应用”的刻板印象。</li>
</ul>
</li>
</ul>
<h2 id="4-python-多智能体生态深度解析"><strong>4. Python 多智能体生态深度解析</strong></h2>
<p>Python 生态虽然在架构严谨性上可能不如 C#，但其创新速度和社区活跃度是其最大优势。</p>
<h3 id="41-langgraph图论与状态机的结合"><strong>4.1 LangGraph：图论与状态机的结合</strong></h3>
<p><strong>LangGraph</strong> 是 LangChain 团队为了解决“构建循环和有状态 Agent”而推出的框架 19。</p>
<ul>
<li><strong>核心机制</strong>：它将 Agent 的执行流程建模为一个<strong>图（Graph）</strong>，其中节点（Nodes）是计算步骤，边（Edges）是控制流。这允许创建复杂的循环（如：生成 -&gt; 评估 -&gt; 修正 -&gt; 生成）。</li>
<li><strong>状态管理</strong>：LangGraph 引入了 <strong>Checkpointer</strong> 机制，支持将运行状态持久化到 Postgres 或 SQLite。这允许“时间旅行”（Time Travel），即回滚到之前的状态并分叉执行 28。</li>
<li><strong>对比视角</strong>：虽然功能强大，但 LangGraph 的配置主要基于 Python 字典和动态对象，随着图的复杂度增加，代码的可读性和类型安全性会迅速下降，导致“意大利面条式代码” 28。</li>
</ul>
<h3 id="42-crewai基于角色的编排"><strong>4.2 CrewAI：基于角色的编排</strong></h3>
<p><strong>CrewAI</strong> 专注于模拟人类团队的协作模式 29。</p>
<ul>
<li><strong>抽象层级</strong>：它提供了比 LangGraph 更高层的抽象。开发者定义“角色”（Role）、“目标”（Goal）和“背景故事”（Backstory）。</li>
<li><strong>局限性</strong>：CrewAI 非常适合快速构建 Demo 或简单的协作任务，但在需要精细控制执行逻辑（如复杂的条件分支、异常重试策略）的企业级场景下，其封装过度的特点反而成为了限制。</li>
</ul>
<h3 id="43-dify开源的后端即服务-baas"><strong>4.3 Dify：开源的后端即服务 (BaaS)</strong></h3>
<p><strong>Dify</strong> 是一个流行的开源 LLM 应用开发平台 31。</p>
<ul>
<li><strong>技术栈</strong>：
<ul>
<li><strong>后端</strong>：核心逻辑主要由 <strong>Python (42%)</strong> 编写，利用 Flask/Django 等框架提供 API 服务 32。</li>
<li><strong>前端</strong>：使用 <strong>TypeScript (51%)</strong> 和 Next.js 构建交互界面。</li>
</ul>
</li>
<li><strong>模式</strong>：Dify 采用“Backend-as-a-Service”模式。企业可以部署 Dify 作为中间件，业务系统通过 API 调用 Agent 能力。</li>
<li><strong>对比 C# 平台</strong>：与 BotSharp 或 Microsoft Agent Framework 这种“代码优先”（Code-First）的框架不同，Dify 更倾向于“低代码/无代码”（Low-Code/No-Code）。虽然它方便了非技术人员，但对于需要深度定制核心逻辑的开发团队，Python 后端的解释执行性质限制了其在高并发场景下的性能上限 32。</li>
</ul>
<h2 id="5-决战企业级c-与-python-的全维度特性对比研究"><strong>5. 决战企业级：C# 与 Python 的全维度特性对比研究</strong></h2>
<p>本节从企业级应用最关心的五个核心维度——并发性能、类型安全、部署运维、生态集成与安全性——对 C# 和 Python 进行详细的“背靠背”对比。</p>
<h3 id="51-并发模型与吞吐量-concurrency--throughput"><strong>5.1 并发模型与吞吐量 (Concurrency &amp; Throughput)</strong></h3>
<p>在多智能体系统中，Agent 需要同时处理成百上千个用户的请求，每个请求又可能触发多个并行的子任务（如同时搜索 Web、查询数据库、调用 LLM）。</p>
<table>
<thead>
<tr>
<th style="text-align: left">特性</th>
<th style="text-align: left">C# (.NET 8/9/10)</th>
<th style="text-align: left">Python (3.12+)</th>
<th style="text-align: left">企业级影响深度分析</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left"><strong>线程模型</strong></td>
<td style="text-align: left"><strong>真多线程 (True Multithreading)</strong>：基于 CLR 的线程池，配合 OS 级线程。任务并行库 (TPL) 提供了极其高效的异步抽象。</td>
<td style="text-align: left"><strong>事件循环 (Event Loop)</strong>：asyncio 实现了单线程并发。受限于 <strong>GIL (全局解释器锁)</strong>，同一时刻只能有一个 CPU 核心在执行 Python 字节码。</td>
<td style="text-align: left"><strong>C# 胜出</strong>：当 Agent 需要进行本地数据处理（如对检索到的文档进行清洗、排序、向量化）时，这些 CPU 密集型任务会阻塞 Python 的事件循环，导致整个服务吞吐量下降。C# 则可以利用多核 CPU 并行处理，单机支持的并发 Agent 数量远超 Python 2。</td>
</tr>
<tr>
<td style="text-align: left"><strong>异步性能</strong></td>
<td style="text-align: left">async/await 是语言底层实现的有限状态机，内存开销极低（Struct-based Tasks）。</td>
<td style="text-align: left">async/await 基于生成器对象，每个 Task 都是堆对象，大量并发时 GC 压力大。</td>
<td style="text-align: left"><strong>C# 胜出</strong>：在高并发场景下（如 10k+ 连接），C# 的内存占用通常仅为 Python 的 1/5 到 1/10 34。</td>
</tr>
</tbody>
</table>
<h3 id="52-类型系统与工程可维护性-type-safety--maintainability"><strong>5.2 类型系统与工程可维护性 (Type Safety &amp; Maintainability)</strong></h3>
<p>企业级系统通常拥有数十万行代码，且生命周期长达 5-10 年。</p>
<ul>
<li><strong>Python (动态类型)</strong>：
<ul>
<li>虽然有 Type Hints 和 Pydantic，但这仅是“建议”或运行时检查。</li>
<li><strong>风险</strong>：在 Agent 协作中，Agent A 输出的 JSON 结构如果发生微小变化，Agent B 可能在运行时崩溃。这种错误往往在生产环境中才被发现 1。</li>
<li><strong>重构噩梦</strong>：重命名一个工具函数的参数，需要全局搜索替换，且无法保证覆盖所有动态调用的场景。</li>
</ul>
</li>
<li><strong>C# (静态强类型)</strong>：
<ul>
<li><strong>编译时保障</strong>：Agent 之间的消息契约（Contracts）定义为 C# 类或接口。任何字段类型的变更都会导致编译失败，迫使开发者在部署前修正所有错误。</li>
<li><strong>BotSharp 的实践</strong>：BotSharp 利用 C# 的强类型特性，确保了插件（Plugin）之间的接口兼容性。这使得企业可以放心地升级某个模块，而不必担心破坏整个系统的稳定性 3。</li>
</ul>
</li>
</ul>
<h3 id="53-部署架构与冷启动-deployment--cold-starts"><strong>5.3 部署架构与冷启动 (Deployment &amp; Cold Starts)</strong></h3>
<p>这是 C# 近年来最大的突破点，也是 Python 在 Serverless 时代的阿喀琉斯之踵。</p>
<ul>
<li><strong>Python 的困境</strong>：
<ul>
<li><strong>容器体积</strong>：一个包含 PyTorch、Pandas、LangChain 的 Python Docker 镜像通常在 500MB 到 2GB 之间 35。</li>
<li><strong>冷启动</strong>：在 Azure Functions 或 AWS Lambda 上，Python 运行时的初始化、依赖包的加载（Import）非常耗时，冷启动延迟通常在 3-5 秒甚至更长 37。这对于需要即时响应的 Agent 来说是不可接受的。</li>
</ul>
</li>
<li><strong>C# 的 Native AOT 革命</strong>：
<ul>
<li><strong>技术原理</strong>：.NET 8 引入了 Native AOT，可以将 C# 代码直接编译为机器码（Native Code），剥离了 JIT 编译器，并裁剪掉未使用的库代码 5。</li>
<li><strong>结果</strong>：一个功能完备的 C# Agent 容器镜像可以小至 <strong>10MB-20MB</strong>。冷启动时间降低到 <strong>毫秒级</strong>（&lt;500ms）。</li>
<li><strong>经济账</strong>：对于按调用次数和内存时间计费的 Serverless 平台，C# Agent 的运行成本可能仅为 Python Agent 的 1/10 6。</li>
</ul>
</li>
</ul>
<h3 id="54-安全性与身份治理-security--governance"><strong>5.4 安全性与身份治理 (Security &amp; Governance)</strong></h3>
<p>企业级 Agent 绝不能是一个“黑盒”，它必须遵循企业的权限管控体系。</p>
<ul>
<li><strong>身份传递 (Identity Propagation)</strong>：
<ul>
<li>在 Microsoft AI Foundry 和 Semantic Kernel 中，C# 能够利用 ASP.NET Core 强大的中间件管道，自动捕获当前用户的 <strong>Entra ID (Azure AD)</strong> 令牌，并将其传递给后端数据源（On-Behalf-Of Flow）。这意味着 Agent 访问 SharePoint 或 SQL 数据库时，是以“当前用户”的身份进行的，天然继承了所有的权限配置 40。</li>
</ul>
</li>
<li><strong>Python 的差距</strong>：虽然 Python 也可以实现类似逻辑，但通常需要手动处理 OAuth 令牌流，且缺乏统一的标准库支持，容易出现安全漏洞。LangChain 等框架更多关注模型交互，而在企业身份集成方面往往是“留白”，需要开发者自行填补 42。</li>
</ul>
<h3 id="55-数据持久化与状态一致性-persistence"><strong>5.5 数据持久化与状态一致性 (Persistence)</strong></h3>
<ul>
<li><strong>Python (LangGraph)</strong>：依赖 Pickle 或 JSON 序列化来保存状态。Pickle 存在严重的安全风险（反序列化漏洞），而 JSON 难以处理复杂的对象引用图。在系统升级后，旧版本的状态文件往往无法加载 28。</li>
<li><strong>C# (Microsoft Agent Framework)</strong>：利用了.NET 强大的序列化机制（System.Text.Json 或 Protobuf）以及 <strong>Microsoft Orleans</strong> 的虚拟 Actor 模式。状态不仅可以持久化到 SQL Server/CosmosDB，还支持事务性操作，确保在 Agent 执行失败时数据的一致性。这对于涉及资金交易或关键业务流程的 Agent 至关重要 44。</li>
</ul>
<h2 id="6-案例研究智用开物与微软-ai-foundry-的启示"><strong>6. 案例研究：智用开物与微软 AI Foundry 的启示</strong></h2>
<h3 id="61-智用开物-agent-foundry行业垂直领域的-c-实践"><strong>6.1 智用开物 (Agent Foundry)：行业垂直领域的 C# 实践</strong></h3>
<p>智用开物的成功通过其实践证明了 C# 在特定垂直领域的优势。制造业场景通常要求：</p>
<ul>
<li><strong>低延迟</strong>：实时响应生产线传感器数据。</li>
<li><strong>高稳定性</strong>：7x24 小时运行，不能因为内存泄漏（Python常见问题）而宕机。</li>
<li><strong>协议集成</strong>：需要对接 PLC、SCADA 等工业协议，C# 在工控领域有着深厚的积累（.NET IoT 库）。</li>
<li><strong>结论</strong>：智用开物选择 C# 构建 Agent Foundry，正是看中了其在“软硬结合”与“高可靠性”方面的不可替代性 7。</li>
</ul>
<h3 id="62-microsoft-ai-foundry平台化的信任"><strong>6.2 Microsoft AI Foundry：平台化的信任</strong></h3>
<p>微软将整个 AI 平台建立在.NET 之上，向企业客户传递了一个信号：<strong>Agent 不仅仅是玩具，而是企业资产</strong>。通过 AI Foundry，企业可以获得：</p>
<ul>
<li><strong>SLA 保障</strong>：基于 C# 构建的底层服务提供了确定的服务等级协议。</li>
<li><strong>合规性</strong>：内置的数据驻留（Data Residency）和隐私合规检查，这些都是 Python 开源社区往往忽视但企业必须具备的特性 24。</li>
</ul>
<h2 id="_"></h2>
<h2 id="7-战略结论与建议"><strong>7. 战略结论与建议</strong></h2>
<p>综合 TIOBE 排名趋势、技术架构特性以及现有平台产品案例，我们可以得出以下结论：</p>
<h3 id="71-c-是否更适合企业级-agent-开发"><strong>7.1 C# 是否更适合企业级 Agent 开发？</strong></h3>
<p><strong>是的，但有前提。</strong></p>
<ul>
<li><strong>对于“系统工程”而言，C# 具有压倒性优势</strong>。如果你的 Agent 需要集成复杂的企业 ERP、需要处理高并发用户请求、需要极低的冷启动成本、或者需要符合严格的安全审计标准，C#（配合 Microsoft Agent Framework / Semantic Kernel）是目前市场上最成熟、最稳健的选择。</li>
<li><strong>对于“算法研究”而言，Python 依然不可替代</strong>。如果你的团队主要由数据科学家组成，且 Agent 的核心在于探索新的 Prompt 策略或微调小模型，那么 Python 的灵活性更有价值。</li>
</ul>
<h3 id="72-推荐架构模式c-核心--python-侧车-sidecar"><strong>7.2 推荐架构模式：C# 核心 + Python 侧车 (Sidecar)</strong></h3>
<p>未来的企业级 MAS 系统不应是单语言的，而应是<strong>混合架构</strong>：</p>
<ol>
<li><strong>大脑与骨架（C#）</strong>：使用 <strong>Microsoft Agent Framework</strong> 构建 Orchestration Layer。负责状态管理、身份认证、路由分发、安全过滤。利用 C# 的高并发和类型安全确保系统“不死”。</li>
<li><strong>手与眼（Python）</strong>：利用 <strong>MCP (Model Context Protocol)</strong> 或微服务模式，将 Python 封装为“工具服务”。当 Agent 需要进行复杂的数据分析（Pandas）或调用特定的 ML 模型时，C# 主脑调度 Python 服务执行，并获取结果 46。</li>
</ol>
<h3 id="73-最终建议"><strong>7.3 最终建议</strong></h3>
<p>对于正在进行技术选型的企业 CTO 或架构师：</p>
<ul>
<li>如果你的企业已经是 <strong>Microsoft /.NET 技术栈</strong>的用户，切勿为了跟风而全面转向 Python。利用 <strong>Microsoft Agent Framework</strong> 和 <strong>BotSharp</strong>，你可以在不改变现有技术积累的情况下，构建出比纯 Python 竞品性能更优、更安全的 Agent 系统。</li>
<li>关注 <strong>Native AOT</strong> 技术，它是 C# 在 AI 时代相对于 Java 和 Python 的核心杀手锏，能够显著降低云资源成本。</li>
<li>参考 <strong>智用开物</strong> 的模式，将 Agent 视为一种“工业级服务”而非简单的“聊天机器人”，注重系统的鲁棒性和行业协议的兼容性。</li>
</ul>
<p>C# 已不再是那个只能写 Windows 窗体程序的语言，在 Microsoft Agent Framework 的加持下，它正成为企业级多智能体系统的<strong>首选基石</strong>。</p>
<h4 id="引用的文章"><strong>引用的文章</strong></h4>
<ol>
<li>Python vs C#: The Battle of Titans | Shakuro, 访问时间为 十二月 22, 2025， <a href="https://shakuro.com/blog/python-vs-c-sharp" target="_blank" rel="noopener nofollow">https://shakuro.com/blog/python-vs-c-sharp</a></li>
<li>.NET is Faster Than Python—and Better Overall! - YouTube, 访问时间为 十二月 22, 2025， <a href="https://www.youtube.com/watch?v=nLK1XGt6t7A" target="_blank" rel="noopener nofollow">https://www.youtube.com/watch?v=nLK1XGt6t7A</a></li>
<li>The Open Source LLM Application Framework — BotSharp 1.1.0 documentation, 访问时间为 十二月 22, 2025， <a href="https://botsharp.readthedocs.io/" target="_blank" rel="noopener nofollow">https://botsharp.readthedocs.io/</a></li>
<li>How effective is AI at writing C# as compared to Python : r/csharp - Reddit, 访问时间为 十二月 22, 2025， <a href="https://www.reddit.com/r/csharp/comments/1j6zgmb/how_effective_is_ai_at_writing_c_as_compared_to/" target="_blank" rel="noopener nofollow">https://www.reddit.com/r/csharp/comments/1j6zgmb/how_effective_is_ai_at_writing_c_as_compared_to/</a></li>
<li>Native AOT deployment overview - .NET | Microsoft Learn, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/dotnet/core/deploying/native-aot/</a></li>
<li>ASP.NET Core support for Native AOT - Microsoft Learn, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/aspnet/core/fundamentals/native-aot?view=aspnetcore-10.0" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/aspnet/core/fundamentals/native-aot?view=aspnetcore-10.0</a></li>
<li>Microsoft Foundry: Scale innovation on a modular, interoperable, and secure agent stack, 访问时间为 十二月 22, 2025， <a href="https://azure.microsoft.com/en-us/blog/microsoft-foundry-scale-innovation-on-a-modular-interoperable-and-secure-agent-stack/" target="_blank" rel="noopener nofollow">https://azure.microsoft.com/en-us/blog/microsoft-foundry-scale-innovation-on-a-modular-interoperable-and-secure-agent-stack/</a></li>
<li>Embodied intelligence, financing is crazy-Electronics Headlines-EEWORLD, 访问时间为 十二月 22, 2025， <a href="https://en.eeworld.com.cn/mp/JQR/a397766.jspx" target="_blank" rel="noopener nofollow">https://en.eeworld.com.cn/mp/JQR/a397766.jspx</a></li>
<li>Top Programming Languages to Learn in 2025: What the Data Says - Lemon.io, 访问时间为 十二月 22, 2025， <a href="https://lemon.io/blog/most-popular-programming-languages/" target="_blank" rel="noopener nofollow">https://lemon.io/blog/most-popular-programming-languages/</a></li>
<li>TIOBE Index for December 2025: Top 10 Most Popular Programming Languages, 访问时间为 十二月 22, 2025， <a href="https://www.techrepublic.com/article/news-tiobe-index-language-rankings/" target="_blank" rel="noopener nofollow">https://www.techrepublic.com/article/news-tiobe-index-language-rankings/</a></li>
<li>TIOBE Index - TIOBE Software, 访问时间为 十二月 22, 2025， <a href="https://www.tiobe.com/tiobe-index/" target="_blank" rel="noopener nofollow">https://www.tiobe.com/tiobe-index/</a></li>
<li>Comparing python Fast API with .NET webServer | by Sriram Alagappa - Medium, 访问时间为 十二月 22, 2025， <a href="https://medium.com/@sriram.alv/comparing-python-fast-api-with-net-webserver-76ee06760836" target="_blank" rel="noopener nofollow">https://medium.com/@sriram.alv/comparing-python-fast-api-with-net-webserver-76ee06760836</a></li>
<li>Top 8 Emerging Programming Languages to Watch in 2025 - Semaphore CI, 访问时间为 十二月 22, 2025， <a href="https://semaphore.io/blog/programming-languages-2025" target="_blank" rel="noopener nofollow">https://semaphore.io/blog/programming-languages-2025</a></li>
<li>Spring AI, 访问时间为 十二月 22, 2025， <a href="https://spring.io/projects/spring-ai/" target="_blank" rel="noopener nofollow">https://spring.io/projects/spring-ai/</a></li>
<li>Spring AI vs Langchain4j - which to use as of July 2024 : r/java - Reddit, 访问时间为 十二月 22, 2025， <a href="https://www.reddit.com/r/java/comments/1efospd/spring_ai_vs_langchain4j_which_to_use_as_of_july/" target="_blank" rel="noopener nofollow">https://www.reddit.com/r/java/comments/1efospd/spring_ai_vs_langchain4j_which_to_use_as_of_july/</a></li>
<li>Host a LLM Powered Chatbot in .NET | by Haiping Chen - Medium, 访问时间为 十二月 22, 2025， <a href="https://haiping008.medium.com/host-a-llm-powered-chatbot-in-net-c6d68b28b8f1" target="_blank" rel="noopener nofollow">https://haiping008.medium.com/host-a-llm-powered-chatbot-in-net-c6d68b28b8f1</a></li>
<li>Introduction to Microsoft Agent Framework, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview</a></li>
<li>Microsoft Agent Framework: The Next Evolution Beyond Semantic Kernel and AutoGen, 访问时间为 十二月 22, 2025， <a href="https://medium.com/@howtodoml/microsoft-agent-framework-the-next-evolution-beyond-semantic-kernel-and-autogen-2919e9345b29" target="_blank" rel="noopener nofollow">https://medium.com/@howtodoml/microsoft-agent-framework-the-next-evolution-beyond-semantic-kernel-and-autogen-2919e9345b29</a></li>
<li>Semantic Kernel vs LangChain in 2025: Startup vs Enterprise Fit - Kanerika, 访问时间为 十二月 22, 2025， <a href="https://kanerika.com/blogs/semantic-kernel-vs-langchain/" target="_blank" rel="noopener nofollow">https://kanerika.com/blogs/semantic-kernel-vs-langchain/</a></li>
<li>What's coming next? Summer / Fall roadmap for Semantic Kernel - Microsoft Dev Blogs, 访问时间为 十二月 22, 2025， <a href="https://devblogs.microsoft.com/semantic-kernel/whats-coming-next-summer-fall-roadmap-for-semantic-kernel/" target="_blank" rel="noopener nofollow">https://devblogs.microsoft.com/semantic-kernel/whats-coming-next-summer-fall-roadmap-for-semantic-kernel/</a></li>
<li>Just tried out Semantic Kernel in .NET : r/LocalLLaMA - Reddit, 访问时间为 十二月 22, 2025， <a href="https://www.reddit.com/r/LocalLLaMA/comments/1ghaz6q/just_tried_out_semantic_kernel_in_net/" target="_blank" rel="noopener nofollow">https://www.reddit.com/r/LocalLLaMA/comments/1ghaz6q/just_tried_out_semantic_kernel_in_net/</a></li>
<li>Installation — BotSharp 1.1.0 documentation - Read the Docs, 访问时间为 十二月 22, 2025， <a href="https://botsharp.readthedocs.io/en/latest/quick-start/installation.html" target="_blank" rel="noopener nofollow">https://botsharp.readthedocs.io/en/latest/quick-start/installation.html</a></li>
<li>SciSharp/BotSharp: AI Multi-Agent Framework in .NET - GitHub, 访问时间为 十二月 22, 2025， <a href="https://github.com/SciSharp/BotSharp" target="_blank" rel="noopener nofollow">https://github.com/SciSharp/BotSharp</a></li>
<li>What Is Foundry Agent Service? - Microsoft Learn, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/agents/overview?view=foundry-classic" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/azure/ai-foundry/agents/overview?view=foundry-classic</a></li>
<li>Azure-Samples/get-started-with-ai-agents: Basic sample for deploying AI agents web app with Azure AI Foundry and SDKs - GitHub, 访问时间为 十二月 22, 2025， <a href="https://github.com/Azure-Samples/get-started-with-ai-agents" target="_blank" rel="noopener nofollow">https://github.com/Azure-Samples/get-started-with-ai-agents</a></li>
<li>Embodied intelligence, financing is crazy-Electronics Headlines, 访问时间为 十二月 22, 2025， <a href="https://en.eeworld.com.cn/mp/EEWorld/a397951.jspx" target="_blank" rel="noopener nofollow">https://en.eeworld.com.cn/mp/EEWorld/a397951.jspx</a></li>
<li>We Tried and Tested 8 Best Semantic Kernel Alternatives to Build AI Agents - ZenML Blog, 访问时间为 十二月 22, 2025， <a href="https://www.zenml.io/blog/semantic-kernel-alternatives" target="_blank" rel="noopener nofollow">https://www.zenml.io/blog/semantic-kernel-alternatives</a></li>
<li>LangGraph vs Semantic Kernel Comparison 2025 - Leanware, 访问时间为 十二月 22, 2025， <a href="https://www.leanware.co/insights/langgraph-vs-semantic-kernel" target="_blank" rel="noopener nofollow">https://www.leanware.co/insights/langgraph-vs-semantic-kernel</a></li>
<li>Battle of AI Agent Frameworks: CrewAI vs LangGraph vs AutoGen | by Vikas Kumar Singh, 访问时间为 十二月 22, 2025， <a href="https://medium.com/@vikaskumarsingh_60821/battle-of-ai-agent-frameworks-langgraph-vs-autogen-vs-crewai-3c7bf5c18979" target="_blank" rel="noopener nofollow">https://medium.com/@vikaskumarsingh_60821/battle-of-ai-agent-frameworks-langgraph-vs-autogen-vs-crewai-3c7bf5c18979</a></li>
<li>Mastering Agents: LangGraph Vs Autogen Vs Crew AI - Galileo AI, 访问时间为 十二月 22, 2025， <a href="https://galileo.ai/blog/mastering-agents-langgraph-vs-autogen-vs-crew" target="_blank" rel="noopener nofollow">https://galileo.ai/blog/mastering-agents-langgraph-vs-autogen-vs-crew</a></li>
<li>Dify: Leading Agentic Workflow Builder, 访问时间为 十二月 22, 2025， <a href="https://dify.ai/" target="_blank" rel="noopener nofollow">https://dify.ai/</a></li>
<li>langgenius/dify: Production-ready platform for agentic ... - GitHub, 访问时间为 十二月 22, 2025， <a href="https://github.com/langgenius/dify" target="_blank" rel="noopener nofollow">https://github.com/langgenius/dify</a></li>
<li>Dify Rolls Out New Architecture, Enhancing Flexibility and Scalability - Dify Blog, 访问时间为 十二月 22, 2025， <a href="https://dify.ai/blog/dify-rolls-out-new-architecture" target="_blank" rel="noopener nofollow">https://dify.ai/blog/dify-rolls-out-new-architecture</a></li>
<li>How Much Memory Do You Need to Run 1 Million Concurrent Tasks? | Piotr Kołaczkowski, 访问时间为 十二月 22, 2025， <a href="https://pkolaczk.github.io/memory-consumption-of-async/" target="_blank" rel="noopener nofollow">https://pkolaczk.github.io/memory-consumption-of-async/</a></li>
<li>Docker minimal image sizes for different programming languages - Reddit, 访问时间为 十二月 22, 2025， <a href="https://www.reddit.com/r/docker/comments/1iuwotd/docker_minimal_image_sizes_for_different/" target="_blank" rel="noopener nofollow">https://www.reddit.com/r/docker/comments/1iuwotd/docker_minimal_image_sizes_for_different/</a></li>
<li>Why is the python docker image so big (~750 MB)? - Stack Overflow, 访问时间为 十二月 22, 2025， <a href="https://stackoverflow.com/questions/31060871/why-is-the-python-docker-image-so-big-750-mb" target="_blank" rel="noopener nofollow">https://stackoverflow.com/questions/31060871/why-is-the-python-docker-image-so-big-750-mb</a></li>
<li>Azure Function benchmark as of November 2025 | by Loïc Labeye - Medium, 访问时间为 十二月 22, 2025， <a href="https://medium.com/@loic.labeye/azure-function-benchmark-as-of-november-2025-ff9f1801ed28" target="_blank" rel="noopener nofollow">https://medium.com/@loic.labeye/azure-function-benchmark-as-of-november-2025-ff9f1801ed28</a></li>
<li>Compile .NET Lambda function code to a native runtime format - AWS Documentation, 访问时间为 十二月 22, 2025， <a href="https://docs.aws.amazon.com/lambda/latest/dg/dotnet-native-aot.html" target="_blank" rel="noopener nofollow">https://docs.aws.amazon.com/lambda/latest/dg/dotnet-native-aot.html</a></li>
<li>Minimizing python docker images - Rodney Osodo - Medium, 访问时间为 十二月 22, 2025， <a href="https://rodneyosodo.medium.com/minimizing-python-docker-images-cf99f4468d39" target="_blank" rel="noopener nofollow">https://rodneyosodo.medium.com/minimizing-python-docker-images-cf99f4468d39</a></li>
<li>Agent Factory: Creating a blueprint for safe and secure AI agents | Microsoft Azure Blog, 访问时间为 十二月 22, 2025， <a href="https://azure.microsoft.com/en-us/blog/agent-factory-creating-a-blueprint-for-safe-and-secure-ai-agents/" target="_blank" rel="noopener nofollow">https://azure.microsoft.com/en-us/blog/agent-factory-creating-a-blueprint-for-safe-and-secure-ai-agents/</a></li>
<li>What's new in Microsoft Foundry | October and November 2025, 访问时间为 十二月 22, 2025， <a href="https://devblogs.microsoft.com/foundry/whats-new-in-microsoft-foundry-oct-nov-2025/" target="_blank" rel="noopener nofollow">https://devblogs.microsoft.com/foundry/whats-new-in-microsoft-foundry-oct-nov-2025/</a></li>
<li>Overview of Microsoft Agent 365, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/microsoft-agent-365/overview" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/microsoft-agent-365/overview</a></li>
<li>Microsoft Agent Framework Workflows - Checkpoints, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/agent-framework/user-guide/workflows/checkpoints" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/agent-framework/user-guide/workflows/checkpoints</a></li>
<li>Checkpointing and Resuming Workflows - Microsoft Learn, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/agent-framework/tutorials/workflows/checkpointing-and-resuming" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/agent-framework/tutorials/workflows/checkpointing-and-resuming</a></li>
<li>Microsoft Foundry documentation, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/?view=foundry-classic" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/azure/ai-foundry/?view=foundry-classic</a></li>
<li>AutoGen to Microsoft Agent Framework Migration Guide, 访问时间为 十二月 22, 2025， <a href="https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-autogen/" target="_blank" rel="noopener nofollow">https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-autogen/</a></li>
</ol>

</div>
<div id="MySignature" role="contentinfo">
    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>
<img src="https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg" width="170">
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.06736111111111111" data-date-updated="2025-12-22 09:05">2025-12-22 07:28</span>&nbsp;
<a href="https://www.cnblogs.com/shanyou">张善友</a>&nbsp;
阅读(<span id="post_view_count">133</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19380471);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19380471', targetLink: 'https://www.cnblogs.com/shanyou/p/19380471', title: '企业级多智能体系统（MAS）架构深度研究：C# 与Python生态系统的全面对比与战略评估' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 【面试题】数据库事务隔离与传播属性是什么？ ]]></title>
    <link>https://www.cnblogs.com/sun-10387834/p/19369929</link>
    <guid>c3f51cb6150af5b3a5611220271ec816</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/sun-10387834/p/19369929" title="发布于 2025-12-21 23:10">
    <span role="heading" aria-level="2">【面试题】数据库事务隔离与传播属性是什么？</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="数据库事务隔离与mvcc深度剖析">数据库事务隔离与MVCC深度剖析</h1>
<h2 id="一事务隔离问题详解">一、事务隔离问题详解</h2>
<h3 id="1-脏读dirty-read">1. 脏读（Dirty Read）</h3>
<p><strong>定义</strong>：一个事务读取了另一个<strong>未提交事务</strong>修改的数据。</p>
<p><strong>核心问题</strong>：读到了"临时"的、可能被回滚的数据，破坏了数据一致性。</p>
<p><strong>场景示例</strong>：</p>
<pre><code class="language-sql">-- 事务A（转账操作，但未提交）
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- 余额从1000改为900

-- 事务B（读取数据）
BEGIN;
SELECT balance FROM accounts WHERE id = 1;  -- 读到900（脏数据）
-- 此时页面显示用户余额为900

-- 事务A因异常回滚
ROLLBACK;
-- 实际余额仍为1000，但事务B以为余额是900
</code></pre>
<p><strong>危害</strong>：</p>
<ul>
<li>业务决策基于错误数据</li>
<li>可能导致"幽灵数据"问题</li>
<li>财务系统等对一致性要求高的场景绝对不能接受</li>
</ul>
<h3 id="2-不可重复读non-repeatable-read">2. 不可重复读（Non-repeatable Read）</h3>
<p><strong>定义</strong>：同一事务内，多次读取同一数据行，结果不一致（被其他已提交事务修改）。</p>
<p><strong>核心问题</strong>：事务内的<strong>读一致性</strong>被破坏。</p>
<p><strong>场景示例</strong>：</p>
<pre><code class="language-sql">-- 事务A（统计报表事务）
BEGIN;
-- 第一次读取
SELECT balance FROM accounts WHERE id = 1;  -- 返回1000

-- 事务B（更新操作并提交）
BEGIN;
UPDATE accounts SET balance = 900 WHERE id = 1;
COMMIT;

-- 事务A继续
-- 第二次读取（同一事务内）
SELECT balance FROM accounts WHERE id = 1;  -- 返回900
-- 事务A同一数据行读取结果不一致，影响报表准确性
COMMIT;
</code></pre>
<p><strong>与脏读的区别</strong>：</p>
<ul>
<li>脏读：读取<strong>未提交</strong>的数据</li>
<li>不可重复读：读取<strong>已提交</strong>的数据，但同一事务内前后不一致</li>
</ul>
<h3 id="3-幻读phantom-read">3. 幻读（Phantom Read）</h3>
<p><strong>定义</strong>：同一事务内，多次执行相同查询，返回的<strong>行数</strong>不同（被其他已提交事务插入/删除）。</p>
<p><strong>核心问题</strong>：影响<strong>范围查询</strong>的一致性。</p>
<p><strong>场景示例</strong>：</p>
<pre><code class="language-sql">-- 事务A（统计部门人数）
BEGIN;
SELECT COUNT(*) FROM employees WHERE dept_id = 1;  -- 返回5人

-- 事务B（新增员工并提交）
BEGIN;
INSERT INTO employees(name, dept_id) VALUES('新员工', 1);
COMMIT;

-- 事务A再次统计
SELECT COUNT(*) FROM employees WHERE dept_id = 1;  -- 返回6人
-- 好像出现了"幻影行"，统计结果不一致
COMMIT;
</code></pre>
<p><strong>不可重复读 vs 幻读</strong>：</p>
<ul>
<li>不可重复读：针对<strong>已存在行</strong>的<strong>值</strong>变化</li>
<li>幻读：针对<strong>结果集</strong>的<strong>行数</strong>变化（新增或删除行）</li>
</ul>
<h2 id="二事务隔离级别详解">二、事务隔离级别详解</h2>
<h3 id="sql标准定义的四个级别从宽松到严格">SQL标准定义的四个级别（从宽松到严格）：</h3>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
<th>实现机制</th>
<th>性能</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>READ UNCOMMITTED</strong></td>
<td>❌ 可能</td>
<td>❌ 可能</td>
<td>❌ 可能</td>
<td>无锁/直接读</td>
<td>最高</td>
<td>数据仓库分析、不关心一致性的统计</td>
</tr>
<tr>
<td><strong>READ COMMITTED</strong></td>
<td>✅ 避免</td>
<td>❌ 可能</td>
<td>❌ 可能</td>
<td>MVCC+行锁</td>
<td>高</td>
<td>Oracle默认，Web应用常用</td>
</tr>
<tr>
<td><strong>REPEATABLE READ</strong></td>
<td>✅ 避免</td>
<td>✅ 避免</td>
<td>❌ 可能*</td>
<td>MVCC+行锁+间隙锁</td>
<td>中</td>
<td>MySQL默认，需要读一致性</td>
</tr>
<tr>
<td><strong>SERIALIZABLE</strong></td>
<td>✅ 避免</td>
<td>✅ 避免</td>
<td>✅ 避免</td>
<td>严格锁/序列化</td>
<td>最低</td>
<td>金融交易、票务系统</td>
</tr>
</tbody>
</table>
<p>*注：MySQL的REPEATABLE READ通过Next-Key Locking解决了大部分幻读问题</p>
<h3 id="各数据库默认级别">各数据库默认级别：</h3>
<pre><code class="language-sql">-- MySQL (默认: REPEATABLE READ)
SELECT @@transaction_isolation;  -- REPEATABLE-READ

-- PostgreSQL (默认: READ COMMITTED)
SHOW transaction_isolation;  -- read committed

-- Oracle (默认: READ COMMITTED)
-- SQL Server (默认: READ COMMITTED)
</code></pre>
<h3 id="设置隔离级别示例">设置隔离级别示例：</h3>
<pre><code class="language-sql">-- 会话级别设置
SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;

-- 全局设置
SET GLOBAL TRANSACTION ISLOLATION LEVEL REPEATABLE READ;

-- 在事务开始时指定
START TRANSACTION WITH CONSISTENT SNAPSHOT;
</code></pre>
<h2 id="三mvcc多版本并发控制深度剖析">三、MVCC（多版本并发控制）深度剖析</h2>
<h3 id="什么是mvcc">什么是MVCC？</h3>
<p>MVCC（Multi-Version Concurrency Control）是一种<strong>无锁并发控制</strong>技术，通过保存数据的多个版本来实现读写并发，避免读写冲突。</p>
<h3 id="mvcc核心原理">MVCC核心原理</h3>
<h4 id="1-版本链机制">1. 版本链机制</h4>
<pre><code class="language-sql">-- 每行数据隐藏的系统字段：
-- DB_TRX_ID: 创建/最后一次修改该行的事务ID
-- DB_ROLL_PTR: 回滚指针，指向undo log中的旧版本
-- DB_ROW_ID: 隐藏的自增ID（如果表没有主键）
</code></pre>
<p><strong>版本链示例</strong>：</p>
<pre><code>当前行 → 版本1 (事务10修改) → 版本2 (事务20修改) → 版本3 (事务30修改)
        ↑                   ↑                   ↑
    回滚指针             回滚指针             回滚指针
</code></pre>
<h4 id="2-readview机制">2. ReadView机制</h4>
<p>每个事务开始时或执行查询时，会创建一个ReadView，包含：</p>
<ul>
<li><code>trx_list</code>: 当前活跃事务ID列表</li>
<li><code>up_limit_id</code>: 活跃事务中最小ID</li>
<li><code>low_limit_id</code>: 下一个将要分配的事务ID</li>
<li><code>creator_trx_id</code>: 创建该ReadView的事务ID</li>
</ul>
<h4 id="3-可见性判断规则">3. 可见性判断规则</h4>
<p>对于版本链中的每个版本：</p>
<ol>
<li>如果 <code>DB_TRX_ID &lt; up_limit_id</code>，说明在ReadView创建前已提交 → <strong>可见</strong></li>
<li>如果 <code>DB_TRX_ID &gt;= low_limit_id</code>，说明在ReadView创建后才开始 → <strong>不可见</strong></li>
<li>如果 <code>up_limit_id ≤ DB_TRX_ID &lt; low_limit_id</code>：
<ul>
<li>如果 <code>DB_TRX_ID</code> 在 <code>trx_list</code> 中，说明未提交 → <strong>不可见</strong></li>
<li>否则已提交 → <strong>可见</strong></li>
</ul>
</li>
</ol>
<h3 id="mvcc在不同隔离级别的表现">MVCC在不同隔离级别的表现</h3>
<h4 id="1-read-committed读已提交">1. READ COMMITTED（读已提交）</h4>
<pre><code class="language-sql">-- 每次查询都生成新的ReadView
-- 只能看到已提交的数据
事务A: SELECT * FROM users;  -- 生成ReadView1
事务B: INSERT INTO users ... COMMIT;  -- 已提交
事务A: SELECT * FROM users;  -- 生成ReadView2，能看到B的修改
</code></pre>
<p><strong>实现机制</strong>：每次SELECT都重新生成ReadView</p>
<h4 id="2-repeatable-read可重复读">2. REPEATABLE READ（可重复读）</h4>
<pre><code class="language-sql">-- 事务第一次查询时生成ReadView，后续复用
-- 保证同一事务内看到的数据一致
事务A: BEGIN;
事务A: SELECT * FROM users;  -- 生成ReadView（事务开始时）
事务B: INSERT INTO users ... COMMIT;
事务A: SELECT * FROM users;  -- 使用同一个ReadView，看不到B的插入
</code></pre>
<p><strong>实现机制</strong>：事务开始时生成ReadView并复用</p>
<h3 id="mvcc的undo-log实现">MVCC的Undo Log实现</h3>
<pre><code class="language-sql">-- 更新操作示例
UPDATE users SET name = 'Bob' WHERE id = 1;

-- MVCC执行流程：
1. 将当前行拷贝到Undo Log（保存旧版本）
2. 修改当前行，更新DB_TRX_ID为当前事务ID
3. 设置DB_ROLL_PTR指向Undo Log中的旧版本

-- 读操作：
通过版本链和ReadView找到合适的可见版本
</code></pre>
<h3 id="mvcc的优缺点">MVCC的优缺点</h3>
<h4 id="优点">优点：</h4>
<ol>
<li><strong>读写不阻塞</strong>：读操作不会阻塞写操作，写操作不会阻塞读操作</li>
<li><strong>高并发</strong>：避免锁竞争，提升并发性能</li>
<li><strong>回滚高效</strong>：通过版本链快速回滚</li>
</ol>
<h4 id="缺点">缺点：</h4>
<ol>
<li><strong>存储开销</strong>：需要存储多个版本的数据</li>
<li><strong>清理机制</strong>：需要定期清理过期版本（purge操作）</li>
<li><strong>写冲突</strong>：写操作之间仍可能冲突</li>
</ol>
<h3 id="mvcc与锁的配合">MVCC与锁的配合</h3>
<pre><code class="language-sql">-- 实际是MVCC+锁的混合机制
SELECT * FROM users WHERE id = 1;  -- MVCC，无锁快照读
SELECT * FROM users WHERE id = 1 FOR UPDATE;  -- 当前读，加锁
UPDATE users SET name = '...' WHERE id = 1;  -- 当前读，加锁
</code></pre>
<h2 id="四spring事务传播属性详解">四、Spring事务传播属性详解</h2>
<h3 id="传播属性是什么">传播属性是什么？</h3>
<p><strong>事务传播属性</strong>定义了<strong>多个事务方法相互调用时</strong>，事务应该如何传播。它解决的是"事务边界"问题——当一个事务方法调用另一个事务方法时，这两个事务应该如何互动。</p>
<h3 id="7种传播行为深度解析">7种传播行为深度解析</h3>
<h4 id="1-required默认---需要事务">1. REQUIRED（默认） - 需要事务</h4>
<p><strong>行为</strong>：如果当前存在事务，则加入该事务；如果当前没有事务，则新建一个事务。</p>
<p><strong>使用场景</strong>：大多数业务方法，确保操作在事务中执行。</p>
<pre><code class="language-java">@Service
public class OrderService {
    @Transactional(propagation = Propagation.REQUIRED)
    public void placeOrder(Order order) {
        // 如果调用方有事务，加入；否则新建事务
        orderDao.save(order);
        inventoryService.deductStock(order);  // 也会在同一个事务中
    }
}
</code></pre>
<h4 id="2-requires_new---新建事务">2. REQUIRES_NEW - 新建事务</h4>
<p><strong>行为</strong>：创建一个新的事务，如果当前存在事务，则挂起当前事务。</p>
<p><strong>使用场景</strong>：日志记录、审计操作等，需要独立提交，不受主事务影响。</p>
<pre><code class="language-java">@Service
public class AuditService {
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void logOperation(String action) {
        // 独立事务，即使主事务回滚，日志仍然保留
        auditDao.save(new AuditLog(action));
    }
}

// 调用示例
@Transactional
public void businessMethod() {
    try {
        // 业务操作
        orderService.process();
    } catch (Exception e) {
        // 即使业务回滚，审计日志仍然提交
        auditService.logOperation("业务异常: " + e.getMessage());
        throw e;
    }
}
</code></pre>
<h4 id="3-nested---嵌套事务">3. NESTED - 嵌套事务</h4>
<p><strong>行为</strong>：如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则新建事务。</p>
<p><strong>关键特性</strong>：使用<strong>保存点（Savepoint）</strong> 机制，可以部分回滚。</p>
<pre><code class="language-java">@Service
public class ComplexService {
    @Transactional(propagation = Propagation.NESTED)
    public void updateUserProfile(User user, Profile profile) {
        userDao.update(user);
        profileDao.update(profile);
        // 如果失败，只回滚这个方法，不影响外部事务
    }
}

// 外层事务
@Transactional
public void completeUserRegistration(User user) {
    userService.register(user);           // 主事务的一部分
    complexService.updateUserProfile(...); // 嵌套事务，可独立回滚
    notificationService.sendWelcome(user); // 主事务的一部分
}
</code></pre>
<h4 id="4-supports---支持事务">4. SUPPORTS - 支持事务</h4>
<p><strong>行为</strong>：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务方式执行。</p>
<p><strong>使用场景</strong>：查询方法，可以接受事务但不强求。</p>
<pre><code class="language-java">@Service
public class QueryService {
    @Transactional(propagation = Propagation.SUPPORTS)
    public User getUserById(Long id) {
        // 有事务就加入，没有也无妨
        return userDao.findById(id);
    }
}
</code></pre>
<h4 id="5-not_supported---不支持事务">5. NOT_SUPPORTED - 不支持事务</h4>
<p><strong>行为</strong>：以非事务方式执行，如果当前存在事务，则挂起该事务。</p>
<p><strong>使用场景</strong>：不需要事务支持的操作，如复杂计算、调用外部API。</p>
<pre><code class="language-java">@Service
public class ReportService {
    @Transactional(propagation = Propagation.NOT_SUPPORTED)
    public Report generateMonthlyReport() {
        // 复杂统计计算，不需要事务
        // 也不会受外部事务影响
        return reportDao.complexQuery();
    }
}
</code></pre>
<h4 id="6-never---绝不使用事务">6. NEVER - 绝不使用事务</h4>
<p><strong>行为</strong>：以非事务方式执行，如果当前存在事务，则抛出异常。</p>
<p><strong>使用场景</strong>：确保方法不在事务上下文中执行。</p>
<pre><code class="language-java">@Service
public class UtilityService {
    @Transactional(propagation = Propagation.NEVER)
    public void clearCache() {
        // 缓存清理，绝对不能有事务
        // 如果调用方有事务，会抛出异常
        cacheManager.clearAll();
    }
}
</code></pre>
<h4 id="7-mandatory---强制存在事务">7. MANDATORY - 强制存在事务</h4>
<p><strong>行为</strong>：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</p>
<p><strong>使用场景</strong>：必须在事务中执行的关键操作。</p>
<pre><code class="language-java">@Service
public class PaymentService {
    @Transactional(propagation = Propagation.MANDATORY)
    public void processPayment(Payment payment) {
        // 必须在事务中执行，否则报错
        // 确保数据一致性
        accountDao.deduct(payment.getAmount());
        paymentDao.save(payment);
    }
}
</code></pre>
<h3 id="传播属性组合使用策略">传播属性组合使用策略</h3>
<h4 id="分层架构中的传播属性设计">分层架构中的传播属性设计：</h4>
<pre><code class="language-java">// Controller层 - 不管理事务
@RestController
public class UserController {
    @Autowired
    private UserFacade userFacade;
}

// Facade/Service层 - 开启事务
@Service
public class UserFacade {
    @Transactional(propagation = Propagation.REQUIRED)
    public UserDTO registerUser(UserRequest request) {
        // 协调多个Service，统一事务管理
        User user = userService.createUser(request);
        profileService.initProfile(user.getId());
        auditService.logRegistration(user);
        return convertToDTO(user);
    }
}

// 业务Service层 - 根据需要使用不同传播属性
@Service
public class UserService {
    // 主业务方法，使用默认REQUIRED
    @Transactional
    public User createUser(UserRequest request) {
        return userRepository.save(convertToEntity(request));
    }
}

@Service  
public class AuditService {
    // 审计日志，独立事务
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void logRegistration(User user) {
        auditRepository.save(new AuditLog("USER_REGISTER", user.getId()));
    }
}

@Service
public class ProfileService {
    // 嵌套事务，可部分回滚
    @Transactional(propagation = Propagation.NESTED)
    public void initProfile(Long userId) {
        profileRepository.createDefaultProfile(userId);
    }
}
</code></pre>
<h4 id="常见陷阱与解决方案">常见陷阱与解决方案：</h4>
<pre><code class="language-java">// 陷阱1：自调用导致@Transactional失效
@Service
public class OrderService {
    public void processOrder(Order order) {
        // 自调用，@Transactional失效！
        this.updateInventory(order);  
    }
    
    @Transactional
    public void updateInventory(Order order) {
        // 不会开启事务
    }
}

// 解决方案1：使用代理对象
@Service
public class OrderService {
    @Autowired
    private OrderService selfProxy;  // 注入自身代理
    
    public void processOrder(Order order) {
        selfProxy.updateInventory(order);  // 通过代理调用
    }
}

// 解决方案2：使用AopContext
@EnableAspectJAutoProxy(exposeProxy = true)
public class Application {
    // 配置类启用代理暴露
}

public void processOrder(Order order) {
    OrderService proxy = (OrderService) AopContext.currentProxy();
    proxy.updateInventory(order);
}

// 陷阱2：异常被捕获不抛出
@Transactional
public void saveWithRollback() {
    try {
        userRepository.save(user);
        throw new RuntimeException();  // 触发回滚的异常
    } catch (Exception e) {
        // 异常被捕获，事务不会回滚！
        log.error("Error occurred", e);
    }
}

// 解决方案：手动回滚或重新抛出
@Transactional
public void saveWithRollback() {
    try {
        userRepository.save(user);
        throw new RuntimeException();
    } catch (Exception e) {
        TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();
        throw e;  // 或者重新抛出
    }
}
</code></pre>
<h3 id="隔离级别与传播属性的组合实践">隔离级别与传播属性的组合实践</h3>
<pre><code class="language-java">@Service
public class FinancialService {
    
    // 资金转移：最高隔离级别，需要事务
    @Transactional(
        isolation = Isolation.SERIALIZABLE,
        propagation = Propagation.REQUIRED,
        timeout = 30,
        rollbackFor = {BusinessException.class, RuntimeException.class}
    )
    public void transferFunds(TransferRequest request) {
        // 1. 检查账户（需要一致性读）
        Account from = accountService.getAccount(request.getFromAccountId());
        Account to = accountService.getAccount(request.getToAccountId());
        
        // 2. 扣款（强一致性要求）
        accountService.deduct(from, request.getAmount());
        
        // 3. 存款
        accountService.deposit(to, request.getAmount());
        
        // 4. 记录交易日志（独立事务）
        auditService.logTransaction(request);
        
        // 5. 发送通知（非事务，不影响主流程）
        notificationService.sendTransferNotification(request);
    }
}

@Service
public class AccountService {
    @Transactional(
        isolation = Isolation.REPEATABLE_READ,
        propagation = Propagation.MANDATORY  // 必须在外层事务中调用
    )
    public void deduct(Account account, BigDecimal amount) {
        // 扣款操作
    }
}

@Service
public class AuditService {
    @Transactional(
        propagation = Propagation.REQUIRES_NEW,  // 独立事务
        isolation = Isolation.READ_COMMITTED     // 日志不需要强一致性
    )
    public void logTransaction(TransferRequest request) {
        // 审计日志
    }
}

@Service
public class NotificationService {
    @Transactional(propagation = Propagation.NOT_SUPPORTED)
    public void sendTransferNotification(TransferRequest request) {
        // 调用外部通知服务，不需要事务
    }
}
</code></pre>
<h2 id="五最佳实践总结">五、最佳实践总结</h2>
<h3 id="1-隔离级别选择原则">1. 隔离级别选择原则：</h3>
<ul>
<li><strong>Web应用</strong>：READ COMMITTED（平衡性能与一致性）</li>
<li><strong>金融系统</strong>：REPEATABLE READ 或 SERIALIZABLE（强一致性）</li>
<li><strong>报表系统</strong>：READ UNCOMMITTED 或 READ COMMITTED（查询性能优先）</li>
<li><strong>电商系统</strong>：根据业务模块选择不同级别</li>
</ul>
<h3 id="2-传播属性使用指南">2. 传播属性使用指南：</h3>
<ul>
<li><strong>默认使用</strong>：REQUIRED（满足80%场景）</li>
<li><strong>日志审计</strong>：REQUIRES_NEW（独立提交）</li>
<li><strong>复杂业务</strong>：NESTED（部分回滚能力）</li>
<li><strong>查询方法</strong>：SUPPORTS（灵活适应）</li>
<li><strong>外部调用</strong>：NOT_SUPPORTED（避免事务传播）</li>
</ul>
<h3 id="3-mvcc优化建议">3. MVCC优化建议：</h3>
<ul>
<li><strong>控制事务长度</strong>：避免长事务导致版本链过长</li>
<li><strong>合理设计索引</strong>：提升快照读效率</li>
<li><strong>定期清理</strong>：监控undo log大小，避免膨胀</li>
<li><strong>版本选择</strong>：根据业务选择当前读或快照读</li>
</ul>
<h3 id="4-监控与调优">4. 监控与调优：</h3>
<pre><code class="language-sql">-- 监控长事务
SELECT * FROM information_schema.innodb_trx 
WHERE TIME_TO_SEC(timediff(now(), trx_started)) &gt; 60;

-- 查看锁等待
SELECT * FROM information_schema.innodb_lock_waits;

-- 监控undo log
SHOW VARIABLES LIKE 'innodb_undo%';
</code></pre>
<p>理解这些核心概念和技术细节，可以帮助你设计出更合理、高性能的数据库应用架构，有效平衡一致性、并发性和性能之间的关系。</p>

</div>
<div id="MySignature" role="contentinfo">
    
<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>

<p>本文来自博客园，作者：<a href="https://www.cnblogs.com/sun-10387834/" target="_blank">佛祖让我来巡山</a>，转载请注明原文链接：<a href="https://www.cnblogs.com/sun-10387834/p/19369929" target="_blank">https://www.cnblogs.com/sun-10387834/p/19369929</a></p>


</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-21 23:11">2025-12-21 23:10</span>&nbsp;
<a href="https://www.cnblogs.com/sun-10387834">佛祖让我来巡山</a>&nbsp;
阅读(<span id="post_view_count">32</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19369929);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19369929', targetLink: 'https://www.cnblogs.com/sun-10387834/p/19369929', title: '【面试题】数据库事务隔离与传播属性是什么？' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ 定制 CentOS7 ISO 的最佳实践 ]]></title>
    <link>https://www.cnblogs.com/optimus007/p/19379438</link>
    <guid>4cf8f7ea53d33a815adf9f71f4712977</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/optimus007/p/19379438" title="发布于 2025-12-21 15:54">
    <span role="heading" aria-level="2">定制 CentOS7 ISO 的最佳实践</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h2 id="背景">背景：</h2>
<p>随着业务形态，业务种类的不断拓展，使用公版 ISO 安装树 与 ISO 镜像存在较大的不便与弊端；<br>
存在安装配置不统一，溯源难等特点；给后期的系统运维带来很高的复杂度</p>
<h2 id="目的">目的：</h2>
<ul>
<li>解决业务需要多种不同系统需求，版本管理困难，溯源难， 运维排障复杂度高等痛点问题</li>
<li>适应新型态下的多种类装机需求，灵活支持，便于迭代更新</li>
<li>自定义的软件包组设置，结合 kickstart 应答控制文件 结合 沙箱技术与 iPXE 技术可以使用大规模自动化装机部署</li>
</ul>
<h2 id="术语与缩写">术语与缩写：</h2>
<table>
<thead>
<tr>
<th><strong>术语名称</strong></th>
<th><strong>术语解释</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RHEL</strong></td>
<td>全称为 Redhat Enterprise Linux ，为红帽子公司推出的免费开源的 Linux 商业发行版</td>
</tr>
<tr>
<td><strong>CentOS</strong></td>
<td>CentOS 为基于 RHEL 上游释放的源码去掉 RHEL logo 与商业软件后重新编码的再发行版，CentOS 社区已被 RHEL 收编，目前 CentOS-7 版本于2020年结束主流支持</td>
</tr>
<tr>
<td><strong>Fedora</strong></td>
<td>Fedora 目前已被 Redhat 收编，红帽子用来实验一些新技术在此发行版，稳定后移植到 RHEL</td>
</tr>
<tr>
<td><strong>kickstart</strong></td>
<td>红帽系发行版操作系统的自动化部署控制脚本与方法</td>
</tr>
<tr>
<td><strong>ISO</strong></td>
<td>一种文件格式与标准</td>
</tr>
<tr>
<td><strong>BIOS</strong></td>
<td>基本输入输出系统，为X86架构的计算机的底层的软件</td>
</tr>
<tr>
<td><strong>EFI/UEFI</strong></td>
<td>统一可扩展固件；为全新的一种计算机的底层软件，支持多种新处理器架构</td>
</tr>
<tr>
<td><strong>RPM</strong></td>
<td>redhat package management 红帽子包管理系统</td>
</tr>
<tr>
<td><strong>Anaconda</strong></td>
<td>anaconda 为红帽系发行版的 安装器（installer）程序</td>
</tr>
<tr>
<td><strong>grub</strong></td>
<td>当代 linux&nbsp;发行版的主流的引导程序</td>
</tr>
<tr>
<td><strong>xml</strong></td>
<td>一种文件格式与标准</td>
</tr>
<tr>
<td><strong>dd</strong></td>
<td>linux 下的一种操作裸磁盘块的工具</td>
</tr>
<tr>
<td><strong>yum</strong></td>
<td>yellow&nbsp;dog package management 黄狗包管理系统，是红帽系自动管理RPM依赖关系，自动安装软件包的一种工具，python 编写</td>
</tr>
<tr>
<td><strong>python</strong></td>
<td>当代的流行的一种解释性的语言</td>
</tr>
<tr>
<td><strong>GPL</strong></td>
<td>一种开源协议</td>
</tr>
</tbody>
</table>
<h1 id="原-centos-社区官方基于-rhel-构建二进制兼容版本的基本流程"><strong>原 CentOS 社区官方基于 RHEL 构建二进制兼容版本的基本流程：</strong></h1>
<p><img alt="0d3ff18c-04d3-40ff-85aa-9aa7bb5b0c6b" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154506939-1443173551.png" class="lazyload"></p>
<h1 id="根据实际需求出发选择基本centos-社区版本进行二次定制开发"><strong>根据实际需求出发，选择基本CentOS 社区版本进行二次定制开发</strong></h1>
<p>二次定制开发的流程大致如下：</p>
<ul>
<li>分析公版 minimal 镜像 ISO 文件结构</li>
<li>抽取拷贝原公版 ISO 中的所有文件与目录结构到 二次定制开发路径，并需要留意修复抽取 ISO 后部分长文件名文件后缀名丢失的问题</li>
<li>根据需求收集需要的 RPM 软件包与依赖包放置在 Packages 目录下</li>
<li>根据需求收集需求的 RPM 名字，修改适配软件组的主控文件 XML 文件 repodata/cca56f3cffa18f1e52302dbfcf2f0250a94c8a37acd8347ed6317cb52c8369dc-c7-x86_64-comps.xml</li>
<li>根据上述修改后的 XML 与 Packages 中的包重新生成 repodatas 中的 ISO RPM包的 repo 数据库</li>
<li>定制修改 anaconda installer 安装器。并输出新的&nbsp; boot.iso ，用于替换旧的 ISO 中的 vmlinux initrd.img 以及&nbsp; suqashfs.img</li>
<li>添加需要的额外拷贝的工具或者文件包到 ISO 构建目录</li>
<li>修改原生的 BIOS 模式与 UEFI 模式下的 grub 引导配置文件</li>
<li>按需修改添加 ks 文件到 ISO 中 （可选步骤）</li>
<li>封装打包为 ISO 镜像，为了支持超大单个文件输出为 UDF 格式</li>
<li>嵌入 hybrid 启动 与 MD5 指纹到 ISO 中</li>
<li>测试安装 ISO</li>
<li>发布</li>
</ul>
<h1 id="定制需求"><strong>定制需求</strong></h1>
<ol>
<li>基于公版 centos 7.9 minimal 镜像二次定制开发</li>
<li>定制修改 anaconda installer 支持高级功能</li>
<li>软件组越小越好，需要支持基本的容器项目的正常运行</li>
<li>需要自动化安装无需人工干预</li>
<li>系统盘分区采用标准分区</li>
<li>根据主流的 CSI benchmark 安全红线要求，设置用户的密码强度要求，弱密码不准使用</li>
<li>首次登录必须更改密码</li>
<li>默认不开防火墙与 selinux 服务</li>
<li>默认系统为英语环境，美式键盘，上海时区</li>
<li>默认增大系统单个进程能打开的句柄数到&nbsp;65536*2</li>
<li>默认启用 root用户的 ssh 访问</li>
<li>采用图形化安装界面</li>
<li>默认系统盘选盘逻辑要适应多盘位的使用场景，支持多种类型的磁盘，支持 vmware与 KVM 虚拟机部署</li>
<li>增加的个性化的定制化信息</li>
<li>支持放入超大的软件包超过 4GB</li>
<li>支持使用U盘刻录安装，支持带外 BMC 挂载 ISO 安装，刻录 cd/dvd 安装</li>
<li>支持 UEFI 与 BIOS 两种引导方式</li>
<li>默认系统需要禁用 CPU C-stat 省电，安装完后的系统中删除ks文件，防止泄密</li>
<li>默认需要开启 KDUMP 服务</li>
<li>默认需要关闭不必要的后台服务</li>
<li>系统默认网络采用 DHCP，无需设置主机名</li>
<li>系统默认预置两个用户，一个 root 用户，一个 isotest 用户； root 用户密码为 XXXXX； iso_test 用户默认密码为  isotest</li>
<li>系统默认密码文件采用影子形式加密存储</li>
</ol>
<h2 id="原版社区的-iso-镜像俗称公版iso镜像树的结构解析">原版社区的 ISO 镜像（俗称公版ISO镜像）树的结构解析：</h2>
<p>公版的 CentOS-2009-Minimal_x86_64.iso 镜像文件，将镜像挂载到 /media 目录可以看到 ISO 抽取后的文件目录结构如下：<br>
<img alt="d2630aca-be5b-4176-8011-f7ddbc53b922" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154538962-835409174.png" class="lazyload"></p>
<p>目录说明：</p>
<ul>
<li>EFI 存放EFI 模式的引导文件</li>
<li>images&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;    存放efi 文件与PXE 启动的内核与临时跟文件系统文件 （stage1 image 目录）</li>
<li>isolinux&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;     存放 BIOS 模式引导文件 （stage1 image 目录）</li>
<li>LiveOS&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;    存放 Anaconda installer 的目录（stage2 image 目录）</li>
<li>Packages&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;    存放 RPM 软件包的目录</li>
<li>repodata&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;    存放 RPM 软件组元数据的目录</li>
<li>文件说明：</li>
<li>CentOS_BuildTag&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CentOS 构建标签</li>
<li>.discinfo &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;记录构建 ISO 时间戳，ISO架构信息，版本号</li>
<li>.treeinfo &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;记录构建 ISO 中重要文件的配置文件</li>
<li>RPM-GPG-KEY-CentOS-7&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RPM 包的 GPG KEY</li>
<li>RPM-GPG-KEY-CentOS-Testing-7 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RPM 包的 GPG KEY</li>
<li>.TBL&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;记录 ISO 生成时的文件名转换的文件</li>
<li>EULA&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;用户协议文档</li>
<li>GPL&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CentOS 的开源协议<br>
BIOS 模式 ISO 启动流程：</li>
</ul>
<p>BIOS 模式： server 启动 ---- &gt;&nbsp; BIOS POST ----- &gt;&nbsp; BIOS 选择选择从 CD/DVD 启动 ----- &gt; ISO 读取启动扇区偏移 ---- &gt; （isolinux/isolinux.bin）grub2 程序 ---- &gt; 读取 isolinux/isolinux.cfg 启动菜单(stage1 阶段 ) ----- &gt; 按照菜单的配置 stage2&nbsp; 阶段 加载 isolinux/vmlinuz 内核 +&nbsp; isolinux/initrd.img ----- &gt;&nbsp; (切换加载 安装器 anaconda installer rootfs LiveOS/squashfs.img ) ----- &gt; （加载基础的各类 systemd 服务） ------ &gt; 启动默认的 default-target 实际指向&nbsp; ----- &gt;&nbsp; anaconda.service ----- &gt; 启动 anaconda 图形安装界面 or anaconda text 安装界面 ----- &gt; 手动选择安装 or&nbsp; kickstart 自动安装</p>
<p>UEFI 模式： server 启动 ---- &gt;&nbsp; BIOS POST ----- &gt;&nbsp; UEFI 选择选择从 CD/DVD 启动 ----- &gt; ISO 读取 EFI BOOT 信息---- &gt; grub2 程序（BOOTX64.EFI） ---- &gt; 读取 EFI/BOOT/grub.cfg 启动菜单(stage1 阶段 ) ----- &gt; 按照菜单的配置 stage2&nbsp; 阶段 加载 image/pxeboot/vmlinuz 内核 +&nbsp; image/pxeboot/initrd.img ----- &gt;&nbsp; (切换加载 安装器 anaconda installer rootfs LiveOS/squashfs.img) ----- &gt; （加载基础的各类 systemd 服务） ------ &gt; 启动默认的 default-target 实际指向&nbsp; ----- &gt;&nbsp; anaconda.service ----- &gt; 启动 anaconda 图形安装界面 or anaconda text 安装界面 ----- &gt; 手动选择安装 or kickstart 自动安装</p>
<h2 id="引导菜单定制开发">引导菜单定制开发：</h2>
<p>背景：<br>
引导菜单的设计分为两类，一种是传统的 BIOS 类型引导，一种是 UEFI/EFI 类型的引导；<br>
其中BIOS类型的引导目前使用的是开源的 syslinux 组件中的 isolinux 部分组件实现的， 而 EFI/UEFI 模式则采用 grubx64.efi 或 BOOTX64.EFI 完成引导<br>
实现方法逻辑两种类型引导的原版引导文件打开进行走读，掌握两种模式的引导菜单的语法，格式，参数等等；<br>
主要修改点是修改引导时指定的安装菜单的标签名称，stage2 阶段映像的加载的媒介的标签，以及添加获取自动安装 ks 的内核传参，外加一些额外的内核参数 ; 定制的图形启动菜单背景图 LOGO 信息也可以写在里面，但是目前图形化的引导菜单支持目前 BIOS 模式支持比较好，UEFI 模式不做处理于支持<br>
修改后的配置文件示意：<br>
BIOS 模式启动菜单： 引导文件为 ISO目录中的 isolinux/isolinux.cfg 文件</p>
<pre><code>prompt 1
ui vesamenu.c32
menu background splash.jpg
default kickstart

MENU TITLE RTX-9090 Linux BOOT MENU

timeout 50

# Do not display the actual menu unless the user presses a key. All that is displayed is a timeout message.

menu tabmsg Press Tab for full configuration options on menu items.

menu separator # insert an empty line
menu separator # insert an empty line

label kickstart
  menu label ^INSTALL RTXOS X86_64 LAGACY
  kernel vmlinuz
  append initrd=initrd.img inst.stage2=hd:LABEL=rtxOS:/ inst.ks=hd:LABEL=rtxOS:/ks.cfg vga=791 modprobe.blacklist=nouveau

menu separator # insert an empty line

label isocheck
  menu label Test This Media &amp;&amp; Install RTXOS 
  kernel vmlinuz
  append initrd=initrd.img inst.stage2=hd:LABEL=rtxOS:/ inst.ks=hd:LABEL=rtxOS:/ks.cfg rd.live.check quiet vga=791 modprobe.blacklist=nouveau

menu separator # insert an empty line

label memtest
  menu label Run a ^Memory Test
  text help
    If your system is having issues, a problem with your
    system's memory may be the cause. Use this utility to
    see if the memory is working correctly.
  endtext
  kernel memtest

menu separator # insert an empty line

label rescue
  menu indent count 5
  menu label ^Rescue a RTXOS system
  text help
    If the system will not boot, this lets you access files
    and edit config files to try to get it booting again.
  endtext
  kernel vmlinuz
  append initrd=initrd.img inst.stage2=hd:LABEL=rtxOS:/ rescue vga=791 modprobe.blacklist=nouveau

menu separator # insert an empty line
menu separator # insert an empty line
 
menu end
</code></pre>
<p>UEFI 模式下的启动菜单：</p>
<pre><code>set default="1"

function load_video {
  insmod efi_gop
  insmod efi_uga
  insmod video_bochs
  insmod video_cirrus
  insmod all_video
}

load_video
set gfxpayload=keep
insmod gzio
insmod part_gpt
insmod ext2

set timeout=5
### END /etc/grub.d/00_header ###

search --no-floppy --set=root -l 'rtxOS'

### BEGIN /etc/grub.d/10_linux ###

menuentry 'Test This Media &amp; Install RTXOS X86_64 UEFI' --class fedora --class gnu-linux --class gnu --class os {
    linuxefi /images/pxeboot/vmlinuz rd.live.check inst.stage2=hd:LABEL=rtxOS:/ inst.ks=hd:LABEL=rtxOS:/ks.cfg vga=791 modprobe.blacklist=nouveau
    initrdefi /images/pxeboot/initrd.img
}
menuentry 'INSTALL RTXOS X86_64 UEFI' --class fedora --class gnu-linux --class gnu --class os {
    linuxefi /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=rtxOS:/ inst.ks=hd:LABEL=rtxOS:/ks.cfg vga=791 modprobe.blacklist=nouveau
    initrdefi /images/pxeboot/initrd.img
}
menuentry 'Rescue A RTXOS System' --class fedora --class gnu-linux --class gnu --class os {
    linuxefi /images/pxeboot/vmlinuz inst.stage2=hd:LABEL=rtxOS:/ rescue vga=791 modprobe.blacklist=nouveau
    initrdefi /images/pxeboot/initrd.img
}
</code></pre>
<p>定制 修改 XML 配置文件： 阅红帽子的官方资料后得知，XXXX-minimal-x86_64-comps.xml 即为定义软件组的XML控制文件，XML中存放着软件包的语言，描述，名字；环境组，软件组等等信息<br>
eg: 简化后的 软件组环境组的基本结构如下：<br>
<img alt="b3d761d2-dd11-4068-9b4f-e67d1c8deed9" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154610481-1073401321.png" class="lazyload"></p>
<p>一个环境组中可以包含多个软件组<br>
软件包组：包含需要安装的 RPM 包的名称列表<br>
环境包组：包含需要安装的软件包组的名称<br>
使用tab 缩进4个字符！！<br>
定义软件组：（软件组包含需要的RPM包列表）</p>
<pre><code>	&lt;group&gt;  代表定义一个软件组
	    &lt;id&gt;XXXX&lt;/id&gt;  软件组的检索字段
	    &lt;name xml:lang="en_GB"&gt;custom_name&lt;/name&gt;  软件组的英文基本名称，自行编写
     &lt;name xml:lang="zh_CN"&gt;定制的软件组名称&lt;/name&gt;  软件组的中文基本名称，自行编写
		   &lt;description&gt;Smallest possible installation.&lt;/description&gt;  软件组的英文的基本描述，自行编写
		   &lt;description xml:lang="zh_CN"&gt;最小可能安装。&lt;/description&gt;  软件组的支持中文的基本描述，自行编写
		   &lt;default&gt;false&lt;/default&gt;  是否为默认，一般保持默认不用更改
		   &lt;uservisible&gt;false&lt;/uservisible&gt;  是否用户可见，一般保持默认不用更改
		   &lt;packagelist&gt;  RPM包列表，XML固定语法写法
			      &lt;packagereq type="mandatory"&gt;XXXXX&lt;/packagereq&gt;  需要的RPM包在这里定义，XXXXX为rpm包名称；其中 type 字段有三类，default（默认的） ，mandatory（强制的） ，optional（可选的）可选的包一般不会进行安装 
		   &lt;/packagelist&gt; XML 语法写法
	&lt;/group&gt; XML语法写法
 
 
</code></pre>
<p>定义环境组：（环境组包含了需要的软件组）</p>
<pre><code>&lt;enviroment&gt;  定义一个环境组
    &lt;id&gt;XXXX&lt;/id&gt;  环境组检索字段
	   &lt;name&gt;XXXXXXXXXX&lt;/name&gt;  环境组名称，自行编写
	   &lt;name xml:lang="zh_CN"&gt;简体中文描述&lt;/name&gt;  环境组名称的基本名称，自行编写
	   &lt;description&gt;Basic functionality.&lt;/description&gt;  环境组的英文基本描述，自行编写
	   &lt;description xml:lang="zh_CN"&gt;简体中文的描述&lt;/description&gt;  环境组的支持中文的基本描述，自行编写
	   &lt;display_order&gt;5&lt;/display_order&gt;  显示顺序，一般不用更改
	   &lt;grouplist&gt;  声明使用哪些软件组，自行编写
		      &lt;groupid&gt;XXXX&lt;/groupid&gt;  需要的软件组的名称
	   &lt;/grouplist&gt;  XML语法固定写法
&lt;/enviroment&gt;  XML语法固定写法
</code></pre>
<p>软件组与环境组关系如下：<br>
<img alt="e9920f38-5b60-43e9-9928-a2c50a05a1cd" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154622532-1112254238.png" class="lazyload"></p>
<p>重建包依赖 repo 数据库：<br>
上述修改后，使用 createrepo 工具 重新基于上面的 XML 重新生成 repodata 下面的 RPM 包的依赖关系数据库 保存到 ISO 构建的本地路径下</p>
<h2 id="anaconda-installer-的定制开发">Anaconda Installer 的定制开发：</h2>
<p><strong>Anaconda 安装器简介</strong>&nbsp;Anaconda 安装器是 RHEL，CentOS，Fedora 发行版的操作系统安装器，采用python语言编写； Anaconda是在ISO加载完内核 vmlinuz与临时的 initrd.img 完成初始化后，chroot 后切换到安装器所在的真实&nbsp;rootfs 文件系统然后调用&nbsp;/usr/sbin/anaconda 住入库启动； 安装器的文件系统是运行在内存中的，最小的内存需求为大于等于1536 MB，否则 GUI 的 Ananconda 安装器无法初始化，只能进入text （文本模式）安装模式；<br>
土办法修改：<br>
Anaconda 安装器是包在 ISO 文件的&nbsp;LiveOS 目录下的&nbsp;squashf.img中一组 python 程序，其中LiveOS 下的squashfs.img 是可以解压进行修改，重新打包；所以也可以用来做定制；<br>
可以在 LIVE rootfs 中进行厂商信息修改，或者添加缺少命令工具的话可以利用 yum install XXXXX --installroot=XXXXX 补全部分缺少的命令工具；<br>
最后修改完成后安装 解压 squashfs.img 的逆操作全部反过来操作就行<br>
当然也可以用原厂开源的专用制作工具进行定制开发修改 关键命令行工具说明：</p>
<ul>
<li><strong>mock</strong>：创建干净构建环境 使用 mock build RPM</li>
<li><strong>rpmbuild</strong>：RPM 包构建工具</li>
<li><strong>createrepo</strong>：创建YUM仓库</li>
<li><strong>lorax</strong>：红帽子系列发行版的 OS 官方镜像构建工具</li>
<li><strong>pungi</strong>：Fedora/CentOS 镜像构建工具</li>
<li><strong>mkisofs/genisoimage</strong>：ISO 镜像创建工具</li>
<li><strong>Anaconda</strong>：红帽子系列发行版的 OS 安装程序器<br>
X86_64 处理器架构对应的 7.x KE linux 定制版 lorax 修改点如下： 说明 lorax 主要修改的配置文件模板的路径为： /usr/share/lorax/</li>
</ul>
<p>/usr/share/lorax/runtime-install.tmpl：             安装配置 anaconda liveos 的主配置文件<br>
/usr/share/lorax/runtime-postinstall.tmpl：      安装完基础的 OS 后额外配置的入口配置文件<br>
/usr/share/lorax/runtime-cleanup.tmpl：          安装完成后执行清理的配置文件<br>
/usr/share/lorax/x86.tmpl：                               最后阶段生成对应架构的 ISO 的模板文件<br>
/usr/share/lorax/config_files/common：            存放模板配置文件的 目录</p>
<p>修改新增原有 anaconda 安装器缺少的功能：<br>
不能执行 ipmitool 设置带外<br>
缺少部分编辑器，压缩，解压，下载工具<br>
缺少调试日志用的网络连接<br>
ssh 功能被禁用<br>
增加集成阵列卡的识别管理工具<br>
增加自由品牌厂商的定制化安装信息， LOGO ， 自定义安装类 (installclass)，<br>
自定义 systemd 服务 等等</p>
<h2 id="自定义安装类说明">自定义安装类说明：</h2>
<p>配置安装类存放目录 /usr/lib64/python2.7/site-packages/pyanaconda/installclasses/<br>
分析： 通过解压 公版的 suqashfs.img rootfs 根，解读下面的 /.buildstamp 中的配置定义推测<br>
[Main]<br>
Product=centos<br>
Version=7<br>
BugURL=xxxxxxx<br>
IsFinal=True<br>
UUID=202011251613<br>
[Compose]<br>
Lorax=19.7.19-xxx</p>
<p>厂商信息为 product=XXX 定义的，其中 XXX 为修改后的自定义的厂商信息； 修改此处要在 rootfs 的 /usr/lib64/python2.7/site-packages/pyanaconda/installclasses/ 里面添加修改对应的包含 product=XXX 字段的&nbsp;install_class 的方法，否则安装器会出现奔溃报错 厂商自定义的安装类参考&nbsp;centos.py 的写法：</p>
<pre><code>#
# rhel.py
#
# Copyright (C) 2010  Red Hat, Inc.  All rights reserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
#

import os
import logging
log = logging.getLogger("anaconda")

from pyanaconda.installclass import BaseInstallClass
from pyanaconda.product import productName
from pyanaconda import network
from pyanaconda import nm
from pyanaconda import iutil
from pyanaconda.kickstart import getAvailableDiskSpace
from blivet.partspec import PartSpec
from blivet.platform import platform
from blivet.devicelibs import swap
from blivet.size import Size

__all__ = ["RHELBaseInstallClass", "RHELAtomicInstallClass"]


class RHELBaseInstallClass(BaseInstallClass):
    name = "CentOS Linux"
    sortPriority = 20001
    if not productName.startswith("CentOS"):
        hidden = True
    defaultFS = "xfs"

    bootloaderTimeoutDefault = 5

    ignoredPackages = ["ntfsprogs", "reiserfs-utils", "hfsplus-tools"]

    installUpdates = False

    _l10n_domain = "comps"

    efi_dir = "centos"

    help_placeholder = "CentOSPlaceholder.html"
    help_placeholder_with_links = "CentOSPlaceholderWithLinks.html"

    def configure(self, anaconda):
        BaseInstallClass.configure(self, anaconda)

    def setNetworkOnbootDefault(self, ksdata):
        if any(nd.onboot for nd in ksdata.network.network if nd.device):
            return
        # choose the device used during installation
        # (ie for majority of cases the one having the default route)
        dev = network.default_route_device() \
              or network.default_route_device(family="inet6")
        if not dev:
            return
        # ignore wireless (its ifcfgs would need to be handled differently)
        if nm.nm_device_type_is_wifi(dev):
            return
        network.update_onboot_value(dev, True, ksdata=ksdata)

    def __init__(self):
        BaseInstallClass.__init__(self)

class RHELAtomicInstallClass(RHELBaseInstallClass):
    name = "CentOS Atomic Host"
    sortPriority=21001
    hidden = not productName.startswith(("CentOS Atomic Host", "CentOS Linux Atomic"))

    def __init__(self):
        self.localemap = {} # loaded lazily
        RHELBaseInstallClass.__init__(self)

    def setDefaultPartitioning(self, storage):
        autorequests = [PartSpec(mountpoint="/", fstype=storage.defaultFSType,
                                 size=Size("3GiB"), maxSize=Size("15GiB"), grow=True, lv=True,
                                 thin=True, encrypted=True)]

        bootreqs = platform.setDefaultPartitioning()
        if bootreqs:
            autorequests.extend(bootreqs)

        disk_space = getAvailableDiskSpace(storage)
        swp = swap.swapSuggestion(disk_space=disk_space)
        autorequests.append(PartSpec(fstype="swap", size=swp, grow=False,
                                    lv=True, encrypted=True))

        for autoreq in autorequests:
            if autoreq.fstype is None:
                if autoreq.mountpoint == "/boot":
                    autoreq.fstype = storage.defaultBootFSType
                    autoreq.size = Size("300MiB")
                else:
                    autoreq.fstype = storage.defaultFSType

        storage.autoPartitionRequests = autorequests

    def filterSupportedLangs(self, ksdata, langs):
        self._initialize_localemap(ksdata.ostreesetup.ref,
                                   ksdata.ostreesetup.url)
        for lang in langs:
            if lang in self.localemap:
                yield lang

    def filterSupportedLocales(self, ksdata, lang, locales):
        self._initialize_localemap(ksdata.ostreesetup.ref,
                                   ksdata.ostreesetup.url)
        supported = []
        if lang in self.localemap:
            for locale in locales:
                stripped = self._strip_codeset_and_modifier(locale)
                if stripped in self.localemap[lang]:
                    supported.append(locale)
        return supported

    def _initialize_localemap(self, ref, repo):

        if self.localemap:
            return

        # fallback to just en_US in case of errors
        self.localemap = { "en": ["en_US"] }

        # Let's only handle local embedded repos for now. Anyway, it'd probably
        # not be very common to only override ostreesetup through kickstart and
        # still want the interactive installer. Though to be nice, let's handle
        # that case.
        if not repo.startswith("file://"):
            log.info("ostree repo is not local; defaulting to en_US")
            return

        # convert to regular UNIX path
        repo = repo[len("file://"):]

        iutil.mkdirChain(os.path.join(repo, "tmp/usr/lib"))
        rc = iutil.execWithRedirect("/usr/bin/ostree",
            ["checkout", "--repo", repo, ref,
             "--subpath", "/usr/lib/locale/locale-archive",
             "install/ostree/tmp/usr/lib/locale"])
        if rc != 0:
            log.error("failed to check out locale-archive; check program.log")
            return

        for line in iutil.execReadlines("/usr/bin/localedef",
                                        ["--prefix", os.path.join(repo, "tmp"),
                                         "--list-archive"]):
            line = self._strip_codeset_and_modifier(line)
            (lang, _) = line.split('_')
            if lang not in self.localemap:
                self.localemap[lang] = [line]
            else:
                self.localemap[lang].append(line)

    @staticmethod
    def _strip_codeset_and_modifier(locale):
        if '@' in locale:
            locale = locale[:locale.find('@')]
        if '.' in locale:
            locale = locale[:locale.find('.')]
        return locale
</code></pre>
<p>其中我们需要修改点需要基于本身的&nbsp;centos.py 拷贝一份新的命名为 xxxx.py 再进行修改；<br>
需要修改为&nbsp;RHELBaseInstallClass 与 RHELAtomicInstallClass 两个类中的厂商信息 productName 变量，这个信息字段为 /.buildstamp 中 product=&nbsp;后面的字段<br>
分析 centos.py 安装类的导入函数时，可以看到&nbsp;productName 是从 pyanaconda.product 里面导入的<br>
检查 /usr/lib64/python2.7/site-packages/pyanaconda/product.py 代码逻辑如下：</p>
<pre><code>#
# product.py: product identification string
#
# Copyright (C) 2003  Red Hat, Inc.  All rights reserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
#

import ConfigParser
import os

from pyanaconda.i18n import _

# First, load in the defaults.  In order of precedence:  contents of
# .buildstamp, environment, stupid last ditch hardcoded defaults.
config = ConfigParser.ConfigParser()
config.add_section("Main")
config.set("Main", "Arch", os.environ.get("ANACONDA_PRODUCTARCH", os.uname()[4]))
config.set("Main", "BugURL", os.environ.get("ANACONDA_BUGURL", "your distribution provided bug reporting tool"))
config.set("Main", "IsFinal", os.environ.get("ANACONDA_ISFINAL", "false"))
config.set("Main", "Product", os.environ.get("ANACONDA_PRODUCTNAME", "anaconda"))
config.set("Main", "UUID", "")
config.set("Main", "Version", os.environ.get("ANACONDA_PRODUCTVERSION", "bluesky"))

# Now read in the .buildstamp file, wherever it may be.
config.read(["/.buildstamp", "/tmp/product/.buildstamp", os.environ.get("PRODBUILDPATH", "")])

# Set up some variables we import throughout, applying a couple transforms as necessary.
bugUrl = config.get("Main", "BugURL")
isFinal = config.getboolean("Main", "IsFinal")
productArch = config.get("Main", "Arch")
productName = config.get("Main", "Product")
if productName.endswith(" Alternate Architectures"):
    productName = productName[:-len(" Alternate Architectures")]
productStamp = config.get("Main", "UUID")
productVersion = config.get("Main", "Version")

if not productArch and productStamp.index(".") != -1:
    productArch = productStamp[productStamp.index(".")+1:]
if productVersion == "development":
    productVersion = "rawhide"

def distributionText():
    return _("%(productName)s %(productVersion)s INSTALLATION") % \
             {"productName": productName, "productVersion": productVersion}

def translated_new_install_name():
    return _("New %(name)s %(version)s Installation") % \
        {"name" : productName, "version" : productVersion}
</code></pre>
<p>修改后的自定义的 xxxxos.py 安装类配置方法 , 比如定义为 rtxos.py</p>
<pre><code>#
# rhel.py
#
# Copyright (C) 2010  Red Hat, Inc.  All rights reserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
#

from pyanaconda.installclass import BaseInstallClass
from pyanaconda.product import productName
from pyanaconda import network
from pyanaconda import nm
from pyanaconda.kickstart import getAvailableDiskSpace
from blivet.partspec import PartSpec
from blivet.platform import platform
from blivet.devicelibs import swap
from blivet.size import Size

class RHELBaseInstallClass(BaseInstallClass):
    name = "rtxOS Linux"
    sortPriority = 20002
    if not productName.startswith("rtxOS"):
        hidden = True
    defaultFS = "xfs"

    bootloaderTimeoutDefault = 5

    ignoredPackages = ["ntfsprogs", "reiserfs-utils", "hfsplus-tools"]

    installUpdates = False

    _l10n_domain = "comps"

    efi_dir = "centos"

    help_placeholder = "CentOSPlaceholder.html"
    help_placeholder_with_links = "CentOSPlaceholderWithLinks.html"

    def configure(self, anaconda):
        BaseInstallClass.configure(self, anaconda)
        self.setDefaultPartitioning(anaconda.storage)

    def setNetworkOnbootDefault(self, ksdata):
        if any(nd.onboot for nd in ksdata.network.network if nd.device):
            return
        # choose the device used during installation
        # (ie for majority of cases the one having the default route)
        dev = network.default_route_device() \
              or network.default_route_device(family="inet6")
        if not dev:
            return
        # ignore wireless (its ifcfgs would need to be handled differently)
        if nm.nm_device_type_is_wifi(dev):
            return
        network.update_onboot_value(dev, "yes", ksdata)

    def __init__(self):
        BaseInstallClass.__init__(self)

class RHELAtomicInstallClass(RHELBaseInstallClass):
    name = "rtxOS Atomic Host"
    sortPriority=21001
    hidden = not productName.startswith(("rtxOS Atomic Host", "rtxOS Linux Atomic"))

    def setDefaultPartitioning(self, storage):
        autorequests = [PartSpec(mountpoint="/", fstype=storage.defaultFSType,
                                size=Size("1GiB"), maxSize=Size("3GiB"), grow=True, lv=True)]

        bootreqs = platform.setDefaultPartitioning()
        if bootreqs:
            autorequests.extend(bootreqs)

        disk_space = getAvailableDiskSpace(storage)
        swp = swap.swapSuggestion(disk_space=disk_space)
        autorequests.append(PartSpec(fstype="swap", size=swp, grow=False,
                                    lv=True, encrypted=True))

        for autoreq in autorequests:
            if autoreq.fstype is None:
                if autoreq.mountpoint == "/boot":
                    autoreq.fstype = storage.defaultBootFSType
                    autoreq.size = Size("300MiB")
                else:
                    autoreq.fstype = storage.defaultFSType

        storage.autoPartitionRequests = autorequests
</code></pre>
<p><strong>注意:</strong>&nbsp;<br>
自定义的安装类的 sortPriority 的值需要大于 20000 才会优先加载并启动运行<br>
efi_dir 目录的名字，不要修改成 productName 变量的值，否则会出现 EFI 模式安装完成系统后，安装 EFI 引导文件失败的问题，<br>
原因是公版的 CentOS 发行版中，grub2-efi-x64-2.02-0.81.el7.centos.x86_64.rpm 包中包含的引导项的默认&nbsp;efi_dir 的值为 centos ，所以如果这里改成厂商定义的其他值会导致 EFI 引导文件无法写入，所以系统也就无法引导；<br>
除非拿到 grub2-efi SRPM 源码进行修改，再重新打包成二进制 RPM 包，否则不推荐修改这里</p>
<h2 id="修改-anaconda-制作的配置模板">修改 anaconda 制作的配置模板：</h2>
<p>修改 /usr/share/lorax/runtime-install.tmpl ： 增加部分需要的安装包<br>
filesystem tools 里面<br>
增加了 ntfs-3g ntfsprogs RPM 包用于支持 ntfs 格式文件系统的读写<br>
<img alt="d8e00ad6-8642-4074-a58d-99699fd8b7d2" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154720908-1887723656.png" class="lazyload"><br>
hardware utility 中增加了：硬盘检测工具， ipmi 带内带外工具<br>
<img alt="6793a9bc-b977-456d-8d3f-3b21b18c6b9d" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154818303-1207777044.png" class="lazyload"></p>
<p>extra tools 中增加如下工具 （vim less bc wget unzip iperf 等）：<br>
<img alt="d4a5517f-e0d6-4a96-9a40-41f97f84d7fb" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221154850705-422427427.png" class="lazyload"></p>
<p>net/server tools 里面新增 ：<br>
<img alt="061f2978-9448-4b82-b43f-2f5a1635981a" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155051419-107166058.png" class="lazyload"></p>
<p>修改 /usr/share/lorax/runtime-postinstall.tmpl： 调整运行的时区为 UTC+8 shanghai 时区<br>
<img alt="79a86280-1405-476b-b9ae-ac1650eac31e" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155109815-1569783147.png" class="lazyload"></p>
<p>安装增加下面的 OEM 定制化厂商信息， 比如 rtx<br>
<img alt="53003c25-6e0b-4dfc-83d4-29e67c4b28be" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155126148-1470080791.png" class="lazyload"></p>
<p>增加部分安装器 bash shell 使用的 环境变量配置模板<br>
<img alt="d6547c8e-51bb-4547-b508-1b5b15fc6c37" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155142785-1605577079.png" class="lazyload"></p>
<p>增加自定义的服务<br>
<img alt="b8d8fc6a-f9e8-4b7f-b143-629173d8acd3" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155154551-1524724382.png" class="lazyload"></p>
<p>. tmpl 配置文件中的语法说明：</p>
<ol>
<li>大部分语法与构建 RPM 包的 SPEC 中的语法类似</li>
<li>${xxxx} 中的变量使用预定义好的模板的参数赋值<br>
installclasses 路径： /usr/lib64/python2.7/site-packages/pyanaconda/installclasses/<br>
服务器上的路径 ： /usr/share/lorax/config_files/common/ 等于 runtime-postinstall.tmpl 文件中 ${configdir} 变量所指的路径<br>
anaconda GUI 背景图替换文件路径 ：<br>
/usr/share/anaconda/pixmaps/ 替换原有的 sidebar-bg.png sidebar-logo.png topbar-bg.png<br>
/usr/share/anaconda/pixmaps/rnotes/en 路径下：<br>
centos-artwork.png<br>
centos-cloud.png<br>
centos-cloud.png<br>
centos-core.png<br>
centos-promotion.png<br>
centos-virtualization.png</li>
</ol>
<h1 id="制作并输出新的-anaconda-安装器">制作并输出新的 anaconda 安装器：</h1>
<p>参数说明 ：<br>
最后的  /home/new_anaconda/ 代表制作新输出的 anaconda boot.iso 的根目录路径（输出目录不能先存在，否则会提示报错）<br>
-p 代表 product name<br>
-r 代表 release version<br>
-v 代表 version identifier<br>
-s 代表 软件仓库的 URL 地址， 可用网上的开源镜像站的源，也可以换成自己搭建维护的 http 仓库源<br>
--isfinal 表示构建最终用于发布的 anaconda build 版本<br>
CMD：<br>
lorax -p 'rtxOS' -v '7' -r '9' -s "<a href="http://192.168.2.24/ISO_TREE_REPO/CentOS-7-x86_64-Everything-2207-02/" target="_blank" rel="noopener nofollow">http://192.168.2.24/ISO_TREE_REPO/CentOS-7-x86_64-Everything-2207-02/</a>" $(pwd)/new_anaconda/ --isfinal<br>
<img alt="" loading="lazy" data-src="1dcf1faa-e3a6-5279-a68d-5c1e09ef2901/199144cd-a8fe-4ed4-a32c-b3ed4380d318.png" class="lazyload"><br>
替换打包 ISO 根目录中的同名同路径资源文件：</p>
<pre><code>#!/bin/bash

anaconda_path=/mnt/workspace/new_anaconda
target_path=/mnt/workspace/RTX_ISO_ROOT

/bin/cp -fa ${anaconda_path:?}/.discinfo ${target_path:?}/
/bin/cp -fa ${anaconda_path:?}/.treeinfo ${target_path:?}/

/bin/cp -fa ${anaconda_path:?}/isolinux/vmlinuz ${target_path:?}/isolinux/vmlinuz
/bin/cp -fa ${anaconda_path:?}/isolinux/initrd.img ${target_path:?}/isolinux/initrd.img
/bin/cp -fa ${anaconda_path:?}/images/pxeboot/vmlinuz ${target_path:?}/images/pxeboot/vmlinuz
/bin/cp -fa ${anaconda_path:?}/images/pxeboot/initrd.img ${target_path:?}/images/pxeboot/initrd.img
/bin/cp -Rfa ${anaconda_path:?}/LiveOS ${target_path:?}/
</code></pre>
<p>最终打包输出： 根据需求，镜像需要支持存放大于4GB的单个文件，所以参考 genisoimage 的 man 文件后，外加参考红帽子提供的资料<br>
打包ISO的命令参数如下：</p>
<pre><code>#!/bin/bash 

#CURRENT_PATH=$(pwd)
ISO_SOURCE=/mnt/workspace/RTX_ISO_ROOT/
ISO_PATH="isolinux"
ISO_FORMAT="-no-emul-boot -boot-load-size 4 -boot-info-table"
echo ""

para=$1
if [ -z ${para} ];then
    read -p " Please Make A Name For ISO : " name
else
    name=${para}
fi

if [ -z $name ];then
    name="biubiubiu_rtx9090_os_custom_$(uname -m)_$(date +"%Y%m%d")_7.9"
fi

cd "$ISO_SOURCE" || exit 1

#### make iso
genisoimage  -U -r -v -T -J -udf -joliet-long -V "rtxOS" -volset "rtxOS" -A "rtxOS" \
-o /mnt/workspace/${name}.iso -c ${ISO_PATH}/boot.cat -b ${ISO_PATH}/isolinux.bin ${ISO_FORMAT} \
-eltorito-alt-boot -e images/efiboot.img -allow-limited-size -no-emul-boot ${ISO_SOURCE}

#### insert md5 checksum
implantisomd5 /mnt/workspace/${name}.iso
#### make to hybrid boot
isohybrid -v /mnt/workspace/${name}.iso
[ $? = 0 ] &amp;&amp; echo -e "\n ${name}.iso generate complete !! \n"
</code></pre>
<p>参数 -U -r -v -T -J -udf -joliet-long 含义为：不翻译文件名，生成 RockRidge 目录信息，可视化的，给系统无法理解的长文件名生成转换表信息，生成 Joliet 目录信息，使用UDF格式（支持大于4GB的文件），允许 Joliet 文件名的达到 103 个 unicode 字符。<br>
参数 -V "rtxOS" -volset "rtxOS" -A "rtxOS" 表示生成 ISO 的卷名称标签（label）为： ‘rtxOS’<br>
参数 -o /mnt/workspace/${name}.iso 表示输出 ISO 文件到  /mnt/workspace/ 下<br>
参数 -c isolinux/boot.cat -b isolinux/isolinux.bin 表示使用ISO打包目录中 isolinux目录下的 boot.cat 与 isolinux.bin 两个固件引导 BIOS 模式<br>
参数 -eltorito-alt-boot -e images/efiboot.img 表示使用ISO 打包目录中的 image/efiboot.img 引导EFI 模式<br>
参数 -allow-limited-size -no-emul-boot 表示允许限制尺寸，非模拟启动<br>
参数 $ISO_SOURCE 代表制作 ISO 的打包根目录路径<br>
ISO 安装测试：<br>
BIOS 模式：</p>
<p><img alt="27e21ae1-19cd-4511-81d9-c6576f25dc86" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155252288-1552849659.png" class="lazyload"></p>
<p>UEFI 模式：<br>
<img alt="79b25468-f677-4a1c-b8c5-20ec553f827d" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3701941/202512/3701941-20251221155302162-421696528.png" class="lazyload"></p>

</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-21 15:54">2025-12-21 15:54</span>&nbsp;
<a href="https://www.cnblogs.com/optimus007">微软其实巨硬</a>&nbsp;
阅读(<span id="post_view_count">78</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19379438);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19379438', targetLink: 'https://www.cnblogs.com/optimus007/p/19379438', title: '定制 CentOS7 ISO 的最佳实践' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ C#AI系列(7):从零开始LLM之Tokenizer实现 ]]></title>
    <link>https://www.cnblogs.com/luojin765/p/19378939</link>
    <guid>4cb64f4b423c3a98d1543e125ada6afe</guid>
    <description>
    <![CDATA[ 
    <h2 class="postTitle"><a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/luojin765/p/19378939" title="发布于 2025-12-21 12:17">
    <span role="heading" aria-level="2">C#AI系列(7):从零开始LLM之Tokenizer实现</span>
    

</a>
</h2>
    <div class="postText"><div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<h1 id="一前言-token是什么">一、前言: token是什么</h1>
<p>LLM只做一个事情，就是吃掉token吐出token，token是LLM（大语言模型）的基本元素。token与LLM的关系，相当于乐高积木与乐高工厂，我的世界方块与我的世界游戏。那么token到底是什么呢？有人翻译成令牌，有人翻译成词源。我们不妨换个概念理解，token就是最小操作、最小信息单元的意思。这个最小是相对于LLM要处理的原始文本来说的。</p>
<p>举个栗子，当一个句子文本输入到电脑中，天然就就具有字符级别的切分。如果不打算继续拆分或组合，我们可以通过一个映射关系，将现有这些字符转换为整数数组，称为编码过程。编码后数组内的元素就是token，元素取值就等于token取值。LLM可以吃掉这个token数组，并吐出新数组。对这个新数组按前前述的映射进行逆转换，称为解码过程。解码后我们就能得到人类可以理解的文本了。</p>
<pre><code class="language-js">// 原句子
"我有一个 apple."

// 句子拆分
["我","有","一","个"," ","a","p","p","l","e",".","\0"]

// 编码为整数数组
[1,2,3,4,5,6,7,7,8,9,10,11]
</code></pre>
<p>从实际应用看，主流LLM几乎不用纯字符级级别切分，而是为了更好效果，使用BPE/WordPiece/SentencePiece等子词（sub-word）算法。此时"hello"大概率是1个或2个token，而不是5个。对于中文来说，"我有一个" 可能切成了 "我/有/一/个"，也可能是"我有/一个"，取决于词表。在字词算法中，单个token拎出来会存在不可解释性，因为是打散的词根。</p>
<p>但是无论怎么处理，LLM传入传出的都是一个整数数组，数组元素的数量，就是token数量（也是LLM服务的计费标准）。</p>
<p>再从实际应用看，主流LLM几乎都采用BPE或BBPE方式进行Tokenizer。我们接下来继续了解BPE。</p>
<h1 id="二bpe字节对编码">二、BPE(字节对编码)</h1>
<p>字节对编码 是一种简单的数据压缩形式，这种方法用数据中不存的一个字节表示最常出现的连续字节数据。这样的替换需要重建全部原始数据。编码过程如下：</p>
<pre><code class="language-json">// wiki的BPE案例
"aaabdaaabac": "aa"=&gt;"Z" //“aa”出现次数最多，用中没有出现的“Z”替换
"ZabdZabac": "aa"=&gt;"Z", "Za"=&gt;"Y" //同上，更新替换表
"YbdYbac": "aa"=&gt;"Z", "Za"=&gt;"Y", "Yb"=&gt;"X" //同上，更新替换表
"XdXac":"aa"=&gt;"Z", "Za"=&gt;"Y", "Yb"=&gt;"X" // 无可用替换
</code></pre>
<p>我们将"aaabdaaabac"通过BPE方式编码成了"XdXac"。解码时只需要对附带的 替换表("aa"=&gt;"Z", "Za"=&gt;"Y", "Yb"=&gt;"X")按顺序逆向操作，就能得到原信息。</p>
<p>BPE 用“比字符大、比单词小”的子词当积木，之所以能流行主要是因为其编码后的token数量适中，处于单字符切分，全词切分之间。相对与全词切分，BPE是子词切分，不仅可以控制上限避免词库膨胀，还能最小可退到字节/字符，最大可保留整词，粒度随频率动态伸缩。就算预见新的词组也无所谓，不存在未登录词的问题。而且一套算法与英语、阿拉伯语语言无关，都是一套处理方式。还具有词表可读性好，在一定效果下计算成本低等特点。</p>
<h1 id="三bpe-tokenizer">三、BPE Tokenizer</h1>
<p>一个BPE Tokenizer，主要功能可分为1.训练处理得到词表；2.编解码。词表的训练上面已经做了示意，接下来我们主要针对编解码部分。</p>
<p>训练好的BPE的数据主要包括三个部分：</p>
<ul>
<li>vocab.json：符号 → id 的字典；</li>
<li>merges.txt：按合并顺序排列的“信息对”；</li>
<li>tokenizer_config.json：预处理规则(regex文本)、特殊标记。</li>
</ul>
<p>另外常见的还有tokenizer.json文件，他是Hugging Face 生态把“原本分散的三份文件”压进一个JSON文件。典型的结构如下（在不同版本中，merges可能会有字符串和数组两种对象存储方式，解析时候需要注意）：</p>
<pre><code class="language-json">// cl100k_base
{
  "version": "1.0",
  "truncation": null,
  "padding": null,
  "added_tokens": [ //特殊token
    {
      "id": 100257,
      "content": "&lt;|endoftext|&gt;",
      "single_word": false,
      "lstrip": false,
      "rstrip": false,
      "normalized": false,
      "special": true
    }
  ],
  "normalizer": null,
  "pre_tokenizer": {  // 有的有，有的没有，因此regex需要预先硬编码
    "type": "Sequence",
    "pretokenizers": [
      {
        "type": "Split",  // 预处理分割，“防呆尺”
        "pattern": {
          "Regex": "(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+"
        },
        "behavior": "Removed",   //一般默认写死，命中正则的片段保留，没命中的扔掉（与invert 配合）。
        "invert": true //一般默认写死，把“命中/没命中”反转——最终只保留上面正则抓到的那些片段，其余全部丢弃。
      },
      {
        "type": "ByteLevel",
        "add_prefix_space": false,
        "trim_offsets": true,
        "use_regex": false
      }
    ]
  },
  "post_processor": null,
  "decoder": {
    "type": "ByteLevel",
    "add_prefix_space": true,
    "trim_offsets": true,
    "use_regex": true
  },
  "model": {
    "type": "BPE",
    "dropout": null,
    "unk_token": null,
    "continuing_subword_prefix": "",
    "end_of_word_suffix": "",
    "fuse_unk": false,
    "byte_fallback": false,
    "vocab": {
      "!": 0,
       "&lt;|endofprompt|&gt;": 100276
    },
    "merges": [
      "ĠCon veyor"		// 或 ["Ġp","ain"]
    ]
  }
}
</code></pre>
<p>通过读取预先的数据，BPE Tokenizer就可以用了，其核心的功能就是编码和解码，即Encode和Decode。</p>
<h1 id="四tokenizer的c实现">四、Tokenizer的C#实现</h1>
<p>在python中，可以直接用HuggingFace的AutoTokenizer载入本地权重。在C#中我们可以拉取SharpToken (2.0.4)和 TiktokenSharp(1.2.0)计算Token。</p>
<p>但是，如果我们要自己在C# 开发LLM（尽管很少有人这么干），一个好的Tokenizer就很重要了，需要更多自定义的功能，如支持huggingFac的tokenizer.json数据，并灵活的处理special token，充分优化。</p>
<p>于是就有了LumTokenizer这个项目。<br>
<img alt="image" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3529796/202512/3529796-20251221121606828-292387909.png" class="lazyload"></p>
<p>主要功能实现如下:</p>
<ol>
<li>读取tokenizer.json数据，如果没有regex，内置了3种pretoken的regex，Regex50KBase：≈GPT-2 的 5 万级别基础词表；RegexCl100KBase：≈OpenAI CLIP / GPT-3.5 / GPT-4 使用的 10 万级别 CL-100K 词表；<br>
RegexO200KBase：≈Meta LLaMA、Mistral 等开源模型偏好的 20 万级别 O-200K 词表</li>
<li>高效的特殊token切分：如果是模型训练用，tokenizer需要单独高效处理特殊token。因为特殊token的目的是正文出现越少越好，因此一般不会出现在词表中，需要通过单独切分的机制进行识别和切分。</li>
<li>高效的缓存机制：LumTokenizer 在分词阶段，订制了一套SpanDictionary, 为了实现高效的切片搜索，也就是说一个stirng可以基于NET的Span特性切成多个Slice，而SpanDictionary可以直接基于Span<t>执行Key的匹配（Span无法作为传统Dictionary的泛型），极大节省了子串string转换的开销。</t></li>
</ol>
<p>Benchmark测试如下：在含有中文这种多字节字符的长文（500字符左右）处理时，具有很好的性能。</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>text</th>
<th style="text-align: right">Mean</th>
<th style="text-align: right">Error</th>
<th style="text-align: right">StdDev</th>
<th style="text-align: right">Ratio</th>
<th style="text-align: right">RatioSD</th>
<th style="text-align: right">Gen0</th>
<th style="text-align: right">Allocated</th>
<th style="text-align: right">Alloc Ratio</th>
</tr>
</thead>
<tbody>
<tr>
<td>SharpToken_cl100k_base</td>
<td>Chinese</td>
<td style="text-align: right">122.99 us</td>
<td style="text-align: right">2.314 us</td>
<td style="text-align: right">2.273 us</td>
<td style="text-align: right">5.71</td>
<td style="text-align: right">0.12</td>
<td style="text-align: right">0.7324</td>
<td style="text-align: right">9.1 KB</td>
<td style="text-align: right">1.19</td>
</tr>
<tr>
<td>TiktokenSharp_cl100k_base</td>
<td>Chinese</td>
<td style="text-align: right">96.00 us</td>
<td style="text-align: right">1.829 us</td>
<td style="text-align: right">2.106 us</td>
<td style="text-align: right">4.45</td>
<td style="text-align: right">0.11</td>
<td style="text-align: right">0.4883</td>
<td style="text-align: right">6.34 KB</td>
<td style="text-align: right">0.83</td>
</tr>
<tr>
<td>LumTokenizer_cl100k_base</td>
<td>Chinese</td>
<td style="text-align: right">21.56 us</td>
<td style="text-align: right">0.268 us</td>
<td style="text-align: right">0.251 us</td>
<td style="text-align: right">1.00</td>
<td style="text-align: right">0.02</td>
<td style="text-align: right">0.6104</td>
<td style="text-align: right">7.63 KB</td>
<td style="text-align: right">1.00</td>
</tr>
<tr>
<td></td>
<td></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
</tr>
<tr>
<td>SharpToken_cl100k_base</td>
<td>English</td>
<td style="text-align: right">26.77 us</td>
<td style="text-align: right">0.520 us</td>
<td style="text-align: right">0.639 us</td>
<td style="text-align: right">1.02</td>
<td style="text-align: right">0.03</td>
<td style="text-align: right">0.6714</td>
<td style="text-align: right">8.38 KB</td>
<td style="text-align: right">0.74</td>
</tr>
<tr>
<td>TiktokenSharp_cl100k_base</td>
<td>English</td>
<td style="text-align: right">20.21 us</td>
<td style="text-align: right">0.383 us</td>
<td style="text-align: right">0.376 us</td>
<td style="text-align: right">0.77</td>
<td style="text-align: right">0.02</td>
<td style="text-align: right">0.4272</td>
<td style="text-align: right">5.51 KB</td>
<td style="text-align: right">0.49</td>
</tr>
<tr>
<td>LumTokenizer_cl100k_base</td>
<td>English</td>
<td style="text-align: right">26.13 us</td>
<td style="text-align: right">0.495 us</td>
<td style="text-align: right">0.509 us</td>
<td style="text-align: right">1.00</td>
<td style="text-align: right">0.03</td>
<td style="text-align: right">0.9155</td>
<td style="text-align: right">11.31 KB</td>
<td style="text-align: right">1.00</td>
</tr>
<tr>
<td></td>
<td></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
<td style="text-align: right"></td>
</tr>
<tr>
<td>SharpToken_cl100k_base</td>
<td>Mixed</td>
<td style="text-align: right">90.97 us</td>
<td style="text-align: right">1.580 us</td>
<td style="text-align: right">1.478 us</td>
<td style="text-align: right">3.78</td>
<td style="text-align: right">0.09</td>
<td style="text-align: right">0.8545</td>
<td style="text-align: right">10.9 KB</td>
<td style="text-align: right">1.23</td>
</tr>
<tr>
<td>TiktokenSharp_cl100k_base</td>
<td>Mixed</td>
<td style="text-align: right">63.85 us</td>
<td style="text-align: right">1.274 us</td>
<td style="text-align: right">1.564 us</td>
<td style="text-align: right">2.65</td>
<td style="text-align: right">0.08</td>
<td style="text-align: right">0.4883</td>
<td style="text-align: right">6.74 KB</td>
<td style="text-align: right">0.76</td>
</tr>
<tr>
<td>LumTokenizer_cl100k_base</td>
<td>Mixed</td>
<td style="text-align: right">24.08 us</td>
<td style="text-align: right">0.465 us</td>
<td style="text-align: right">0.435 us</td>
<td style="text-align: right">1.00</td>
<td style="text-align: right">0.03</td>
<td style="text-align: right">0.7019</td>
<td style="text-align: right">8.83 KB</td>
<td style="text-align: right">1.00</td>
</tr>
</tbody>
</table>
<p>具体可以去仓库看详细代码。</p>
<pre><code class="language-csharp">  [MemoryDiagnoser]
  public class CompareBenchmark
  {
      internal GptEncoding _sharpToken;
      internal TikToken _tikToken;
      internal BPETokenizer _tokenizer1;
      internal BPETokenizer _tokenizer2;

      [GlobalSetup]
      public void Setup()
      {
          _sharpToken = GptEncoding.GetEncoding("cl100k_base");
          _tikToken = TikToken.GetEncodingAsync("cl100k_base").ConfigureAwait(false).GetAwaiter().GetResult();
          _tokenizer1 = BPETokenizer.CreateTokenizer(
              @"D:\Data\Personal\AI\llm\tokenizer\cl100k.txt", true, RegexType.RegexCl100KBase);
          _tokenizer2 = BPETokenizer.CreateTokenizer(
              @"D:\Data\Personal\AI\llm\tokenizer\qw_tokenizer.json", false, RegexType.RegexCl100KBase);
      }

      // ====== 1. 声明参数源 ======
      public IEnumerable&lt;string&gt; TextSamples()
      {
          yield return TextCatalog.English;
          yield return TextCatalog.Chinese;
          yield return TextCatalog.Mixed;
      }

      // ====== 2. 每个方法改成带参数 ======
      [Benchmark]
      [ArgumentsSource(nameof(TextSamples))]
      public int SharpToken_cl100k_base(string text)
      {
          var encoded = _sharpToken.Encode(text);
          var decoded = _sharpToken.Decode(encoded);
          return encoded.Count;
      }

      [Benchmark]
      [ArgumentsSource(nameof(TextSamples))]
      public int TiktokenSharp_cl100k_base(string text)
      {
          var encoded = _tikToken.Encode(text);
          var decoded = _tikToken.Decode(encoded);
          return encoded.Count;
      }

      [Benchmark(Baseline =true)]
      [ArgumentsSource(nameof(TextSamples))]
      public int LumTokenizer_cl100k_base(string text)
      {
          var encoded = _tokenizer1.Encode(text, false);
          var decoded = _tokenizer1.Decode(encoded, false);
          return encoded.Count;
      }
            
      public int LumTokenizer_qwen150k(string text)
      {
          var encoded = _tokenizer2.Encode(text, false);
          var decoded = _tokenizer2.Decode(encoded, false);
          return encoded.Count;
      }
  }
</code></pre>
<h1 id="五单元测试">五、单元测试</h1>
<p>现在单元测试可以说是越来越重要了，因为只有具有了完善的单元测试，才能放心的让ai去优化修改已有代码。<br>
本文这个BPE Tokenizer项目单元测试分了5类。</p>
<ul>
<li>P0_BasicTest：基础测试，测试编解码，数据读取，词表完善性等主要功能；</li>
<li>P1_RobustnessTests：鲁棒性测试，针对边缘条件，如仅空字符、仅特殊字符、超长文本、越界id等情况；</li>
<li>P2_VocabBpeTests：编解码准确性，要求正确的对原文进行分割，并准确编码，通过几种特定情况下的案例进行兜底。</li>
<li>P3_ChineseSubwordTests：中文字符测试，其中也包含了token压缩率的检验。主要是考虑在代码编写过程中，可能导致部分尾字节或特殊混编情况下不能准确字节合并的bug。</li>
<li>P4_EnglishSubwordTests：英文字符测试，目的同上，部分bug出现时，尽管decode正常，但encode编码也可能未达到预期（忽略了某些合并环节导致压缩率过高）。</li>
</ul>
<p>编解码准确度与常用库比较：</p>
<pre><code>LumTokenizer_cl100k_base
34655,61078,11,832,315,42482,596,77069,323,1455,73135,11335,11,10975,279,3446,315,279,46337,323,12280,12970,61078,11,889,65928,813,26135,11,439,568,1587,813,3611,38705,11,4184,311,52671,323,74571,13,61078,753,8060,439,264,7126,2995,360,3933,5678,323,813,1917,304,63355,323,31926,16134,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,29
King Lear, one of Shakespeare's darkest and most savage plays, tells the story of the foolish and Job-like Lear, who divides his kingdom, as he does his affections, according to vanity and whim. Lear’s failure as a father engulfs himself and his world in turmoil and tragedy.&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;

SharpToken_cl100k_base
34655,61078,11,832,315,42482,596,77069,323,1455,73135,11335,11,10975,279,3446,315,279,46337,323,12280,12970,61078,11,889,65928,813,26135,11,439,568,1587,813,3611,38705,11,4184,311,52671,323,74571,13,61078,753,8060,439,264,7126,2995,360,3933,5678,323,813,1917,304,63355,323,31926,16134,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,29
King Lear, one of Shakespeare's darkest and most savage plays, tells the story of the foolish and Job-like Lear, who divides his kingdom, as he does his affections, according to vanity and whim. Lear’s failure as a father engulfs himself and his world in turmoil and tragedy.&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;

TikTokenr_cl100k_base
34655,61078,11,832,315,42482,596,77069,323,1455,73135,11335,11,10975,279,3446,315,279,46337,323,12280,12970,61078,11,889,65928,813,26135,11,439,568,1587,813,3611,38705,11,4184,311,52671,323,74571,13,61078,753,8060,439,264,7126,2995,360,3933,5678,323,813,1917,304,63355,323,31926,16134,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,1822,91,318,5011,91,29,15339,220,220,57668,53901,27,91,318,6345,91,29
King Lear, one of Shakespeare's darkest and most savage plays, tells the story of the foolish and Job-like Lear, who divides his kingdom, as he does his affections, according to vanity and whim. Lear’s failure as a father engulfs himself and his world in turmoil and tragedy.&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;


LumTokenizer_qwen150k
33555,59978,11,825,315,41382,594,75969,323,1429,72035,11088,11,10742,279,3364,315,279,45237,323,12011,12681,59978,11,879,64828,806,25079,11,438,566,1558,806,3527,37605,11,4092,311,51571,323,73471,13,59978,748,7901,438,264,6981,2922,360,3848,5561,323,806,1879,304,62255,323,30826,13,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645,151644,14990,220,220,108386,151645
King Lear, one of Shakespeare's darkest and most savage plays, tells the story of the foolish and Job-like Lear, who divides his kingdom, as he does his affections, according to vanity and whim. Lear’s failure as a father engulfs himself and his world in turmoil and tragedy.&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;&lt;|im_start|&gt;hello  你好&lt;|im_end|&gt;
</code></pre>
<h1 id="六最后">六、最后</h1>
<p>LumTokenizer这个项目现在版本是1.0.6.1，整体效果较好，很快速稳定，现在自己训练模型就在用它，尽管目前某些常用习惯写死了，但大家需要的可自行适配和扩展。MiniGPT和MiniMind都是很好的LLM学习入门python项目，但C#基本没有。Tokenier是C#开发LLM的重要环节，奈何.Net生态还是差很多，资料也少，现在AI生成的内容都千篇一律，很多现有库更新的又很慢。真要用C#来干LLM真是难上加难（估计也没人这么干）。</p>
<p>如果您觉得有收获的话，请多多支持本系列。再次感谢您的阅读，本案例及更加完整丰富的机器学习模型案例的代码已全部开源，新朋友们可以关注公众号回复Tokenizer查看仓库地址，获取全部完整代码实现。</p>
<p><img alt="QR" loading="lazy" data-src="https://img2024.cnblogs.com/blog/3529796/202509/3529796-20250915150401305-1035823235.jpg" class="lazyload"></p>

</div>
<div class="clear"></div>
</div>
    <p class="postfoot">posted on 
<span id="post-date" data-last-update-days="0.0020833333333333333" data-date-updated="2025-12-21 12:20">2025-12-21 12:17</span>&nbsp;
<a href="https://www.cnblogs.com/luojin765">LdotJdot</a>&nbsp;
阅读(<span id="post_view_count">102</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19378939);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19378939', targetLink: 'https://www.cnblogs.com/luojin765/p/19378939', title: 'C#AI系列(7):从零开始LLM之Tokenizer实现' })">举报</a>
</p>
 ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ Pytest 测试用例自动生成：接口自动化进阶实践 ]]></title>
    <link>https://www.cnblogs.com/lfr0123/p/19378880</link>
    <guid>043aa6696943bd23b122fe07be083365</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/lfr0123/p/19378880" title="发布于 2025-12-21 11:58">
    <span role="heading" aria-level="2">Pytest 测试用例自动生成：接口自动化进阶实践</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown">
<p>引言：为什么我们要抛弃 “<strong>手写用例</strong>”？</p>
<p>在接口自动化实践中，当项目规模扩大、用例数量激增时，传统“手写Pytest用例”的模式往往会陷入瓶颈。</p>
<p>做接口自动化的同学，大概率都踩过这样的硬编码坑：写一条 “新增 - 查询 - 删除” 的流程用例，要重复写 3 个接口的请求、参数与断言代码；不同同事写的用例，有的把数据塞代码里，有的存 Excel，交接时看得头大；新手没代码基础，想加个用例还要先学 Python 语法。</p>
<h2 id="一遇到的3个核心痛点">一、遇到的3个核心痛点</h2>
<p>我们公司在维护Pytest接口自动化项目时，深刻感受到手写用例带来的诸多困扰，随着项目规模扩大，问题愈发凸显：</p>
<ol>
<li><strong>用例编写效率低，重复劳动多</strong>。一条流程用例要调用多个接口，每个接口的请求头、参数、断言都要手写，浪费时间。</li>
<li><strong>代码混乱无规范，维护成本高</strong>。测试同学各自为战，测试数据存储方式不一样（硬编码、data.py、Excel等）；并且重复编写“发送请求”“数据库查询”等通用功能，导致项目冗余代码堆积，新人接手时难以梳理逻辑。</li>
<li><strong>门槛高，新手难上手</strong>。无Python基础的测试同学，需先学习requests库、Pytest语法、断言写法等技术内容，再结合混乱的项目结构，入门难度大，难以快速参与用例编写。</li>
</ol>
<h2 id="二核心解决方案数据与逻辑分离自动生成测试用例">二、核心解决方案：数据与逻辑分离，自动生成测试用例</h2>
<p>针对上述痛点，我们提出核心解决方案：<strong>测试人员仅负责“设计测试数据”（基于YAML），用例生成器自动完成“用例代码编写”</strong>，通过“数据与逻辑分离”的思路，从根源解决手写用例的弊端。</p>
<h3 id="1-核心设计思路">1. 核心设计思路</h3>
<ol>
<li><strong>把 “测试数据” 和 “用例逻辑” 彻底分开</strong>，使数据与逻辑解耦。将接口参数、断言规则、前置后置操作等测试数据，按约定格式存入YAML文件，测试人员无需关注代码逻辑，专注业务数据设计。</li>
<li><strong>自动生成 Pytest 测试用例文件</strong>。定义一个用例生成器模块，，读取YAML文件中的测试数据，自动校验格式并生成标准化的Pytest用例代码，完全替代手写用例。</li>
</ol>
<h3 id="2-方案核心优势">2. 方案核心优势</h3>
<ol>
<li>零代码门槛：测试人员无需编写Python代码，只需按模板填写YAML，降低技术要求。</li>
<li>输出标准化：生成的用例命名、目录结构、日志格式、断言方式完全统一，告别代码混乱。</li>
<li>批量高效生成：支持整个目录的 YAML 文件批量生成，一次生成上百条用例；</li>
<li>零维护成本：接口变更时，只改 YAML 数据，生成器重新运行即可更新用例。</li>
</ol>
<h3 id="3-完整实施流程">3. 完整实施流程</h3>
<p>完整流程为：<code>编写YAML测试数据</code> → <code>运行生成器自动生成测试用例</code> → <code>执行自动生成的Pytest用例</code></p>
<h2 id="三关键步骤从-yaml-设计到自动生成用例">三、关键步骤：从 YAML 设计到自动生成用例</h2>
<p>下面通过“实操步骤+代码示例”的方式，详细说明方案的落地过程，以“新增设备→查询设备→解绑设备”的完整流程用例为例。</p>
<h3 id="第一步设计标准化yaml测试数据格式">第一步：设计标准化YAML测试数据格式</h3>
<p>YAML文件是方案的核心，需兼顾“完整性”与“易用性”，既要覆盖接口测试的全场景需求，又要让测试人员容易理解和填写。</p>
<p>我们设计的YAML格式支持：基础信息配置、前置/后置操作、多接口步骤串联、多样化断言（常规断言+数据库断言）。</p>
<p>YAML示例如下（test_device_bind.yaml）：</p>
<pre><code class="language-yaml"># test_device_bind.yaml
testcase:
  name: bind_device  # 用例唯一标识，建议和文件名一致（去掉test_）
  description: 新增设备→查询设备→解绑设备  # 用例说明，清晰易懂
  allure:  # Allure报告配置，方便统计
    epic: 商家端
    feature: 设备管理
    story: 新增设备
    
  setups:  # 前置操作：执行测试前的准备（如数据库查询、数据初始化）
    - id: check_database
      description: 检查设备是否已存在
      operation_type: db  # 操作类型：db=数据库操作
      query: SELECT id FROM device WHERE imei = '865403062000000'
      expected: id  # 预期查询结果存在id字段

  steps:  # 核心测试步骤：每个步骤对应一个接口请求
    - id: device_bind  # 步骤唯一标识，用于跨步骤取值
      description: 新增设备
      project: merchant  # 所属项目（用于获取对应的host、token）
      path: '/device/bind'  # 接口路径
      method: POST  # 请求方法
      headers:
        Content-Type: 'application/json'
        Authorization: '{{merchant.token}}'  # 从全局变量取merchant的token
      data:  # 请求参数
        code: deb45899-957-10972b35515
        name: test_device_name
        imei: '865403062000000'
      assert:  # 断言配置，支持多种断言类型
        - type: equal  # 等于断言
          field: code  # 响应字段：code
          expected: 0  # 预期值
        - type: is not None  # 非空断言
          field: data.id  # 响应字段：data.id
        - type: equal
          field: message
          expected: success

    - id: device_list  # 第二个步骤：查询新增的设备
      description: 查询设备列表
      project: merchant
      path: '/device/list'
      method: GET
      headers:
        Content-Type: 'application/json'
        Authorization: '{{merchant.token}}'
      data:
        goodsId: '{{steps.device_bind.data.id}}'  # 跨步骤取值：从device_bind步骤的响应中取id
      assert:
        - type: equal
          field: status_code  # 断言HTTP状态码
          expected: 200
        - type: equal
          field: data.code
          expected: '{{steps.device_bind.data.code}}'  # 跨步骤取参数
        - type: mysql_query  # 数据库断言：查询设备是否存在
          query: SELECT id FROM users WHERE name='test_device_name'
          expected: id

  teardowns:  # 后置操作：测试完成后清理数据（如解绑设备、删除数据库记录）
    - id: device_unbind
      description: 解绑设备
      operation_type: api  # 操作类型：api=接口请求
      project: plateform
      path: '/device/unbind'
      method: POST
      headers:
        Content-Type: 'application/json'
        Authorization: '{{merchant.token}}'
      data:
        deviceId: '{{steps.device_bind.data.id}}'  # 跨步骤取新增设备的id
      assert:
        - type: equal
          field: code
          expected: 0

    - id: clear_database
      description: 清理数据库
      operation_type: db  # 数据库操作
      query: DELETE FROM device WHERE id = '{{steps.device_bind.data.id}}'
</code></pre>
<h3 id="第二步编写用例生成器自动生成的-核心引擎">第二步：编写用例生成器（自动生成的 “核心引擎”）</h3>
<p>用例生成器的作用是：读取 YAML 文件→校验数据格式→生成标准的 Pytest 用例代码，支持单个文件或目录批量处理。</p>
<p>以下是生成器核心代码（case_generator.py），关键逻辑已添加详细注释：</p>
<pre><code class="language-python"># case_generator.py
# @author:  xiaoqq

import os
import yaml
from utils.log_manager import log


class CaseGenerator:
	"""
	测试用例文件生成器
	"""
	def generate_test_cases(self, project_yaml_list=None, output_dir=None):
		"""
		根据YAML文件生成测试用例并保存到指定目录
		:param project_yaml_list: 列表形式，项目名称或YAML文件路径
		:param output_dir: 测试用例文件生成目录
		"""
		# 如果没有传入project_yaml_list，默认遍历tests目录下所有project
		if not project_yaml_list:
			project_yaml_list = ["tests/"]
		
		# 遍历传入的project_yaml_list
		for item in project_yaml_list:
			if os.path.isdir(item):  # 如果是项目目录，如tests/merchant
				self._process_project_dir(item, output_dir)
			elif os.path.isfile(item) and item.endswith('.yaml'):  # 如果是单个YAML文件
				self._process_single_yaml(item, output_dir)
			else:  # 如果是项目名称，如merchant
				project_dir = os.path.join("tests", item)
				self._process_project_dir(project_dir, output_dir)
		
		log.info("测试用例生成完毕！")
	
	def _process_project_dir(self, project_dir, output_dir):
		"""
		处理项目目录，遍历项目下所有YAML文件生成测试用例
		:param project_dir: 项目目录路径
		:param output_dir: 测试用例文件生成目录
		"""
		for root, dirs, files in os.walk(project_dir):
			for file in files:
				if file.endswith('.yaml'):
					yaml_file = os.path.join(root, file)
					self._process_single_yaml(yaml_file, output_dir)
	
	def _process_single_yaml(self, yaml_file, output_dir):
		"""
		处理单个YAML文件，生成对应的测试用例文件
		:param yaml_file: YAML文件路径
		:param output_dir: 测试用例文件生成目录
		"""
		# 读取YAML文件内容
		_test_data = self.load_test_data(yaml_file)
		validate_test_data = self.validate_test_data(_test_data)
		if not validate_test_data:
			log.warning(f"{yaml_file} 数据校验不通过，跳过生成测试用例。")
			return
		test_data = _test_data['testcase']
		teardowns = test_data.get('teardowns')
		validate_teardowns = self.validate_teardowns(teardowns)
		
		# 生成测试用例文件的相对路径。yaml文件路径有多个层级时，获取项目名称，以及tests/后、yaml文件名前的路径
		relative_path = os.path.relpath(yaml_file, 'tests')
		path_components = relative_path.split(os.sep)
		project_name = path_components[0] if path_components[0] else path_components[1]
		# 移除最后一个组件（文件名）
		if path_components:
			path_components.pop()  # 移除最后一个元素
		directory_path = os.path.join(*path_components)	# 重新组合路径
		directory_path = directory_path.rstrip(os.sep)	# 确保路径不以斜杠结尾
		
		module_name = test_data['name']
		description = test_data.get('description')
		# 日志记录中的测试用例名称
		case_name = f"test_{module_name} ({description})" if description is not None else f"test_{module_name}"
		
		# 判断test_data中的name是否存在"_"，存在则去掉将首字母大写组成一个新的字符串，否则首字母大写
		module_class_name = (''.join(s.capitalize() for s in module_name.split('_'))
							 if '_' in module_name else module_name.capitalize())
		file_name = f'test_{module_name}.py'
		
		# 生成文件路径
		if output_dir:
			file_path = os.path.join(output_dir, directory_path, file_name)
		else:
			file_path = os.path.join('test_cases', directory_path, file_name)
		
		# 检查test_cases中对应的.py文件是否存在，存在则跳过生成
		if os.path.exists(file_path):
			log.info(f"测试用例文件已存在，跳过生成: {file_path}")
			return
		
		# 创建目录
		os.makedirs(os.path.dirname(file_path), exist_ok=True)
		
        # 解析Allure配置
		allure_epic = test_data.get("allure", {}).get("epic", project_name)
		allure_feature = test_data.get("allure", {}).get("feature")
		allure_story = test_data.get("allure", {}).get("story", module_name)
		
        # 生成并写入用例代码
		with open(file_path, 'w', encoding='utf-8') as f:
            # 写入导入语句
			f.write(f"# Auto-generated test module for {module_name}\n")
			f.write(f"from utils.log_manager import log\n")
			f.write(f"from utils.globals import Globals\n")
			f.write(f"from utils.variable_resolver import VariableResolver\n")
			f.write(f"from utils.request_handler import RequestHandler\n")
			f.write(f"from utils.assert_handler import AssertHandler\n")
			if validate_teardowns:
				f.write(f"from utils.teardown_handler import TeardownHandler\n")
				f.write(f"from utils.project_login_handler import ProjectLoginHandler\n")
			f.write(f"import allure\n")
			f.write(f"import yaml\n\n")
			
            # 写入类装饰器（Allure配置）
			f.write(f"@allure.epic('{allure_epic}')\n")
			if allure_feature:
				f.write(f"@allure.feature('{allure_feature}')\n")
			f.write(f"class Test{module_class_name}:\n")
			
            # 写入setup_class（类级前置操作）
			f.write(f"    @classmethod\n")
			f.write(f"    def setup_class(cls):\n")
			f.write(f"        log.info('========== 开始执行测试用例：{case_name} ==========')\n")
			f.write(f"        cls.test_case_data = cls.load_test_case_data()\n")	# 获取测试数据
			# 如果存在teardowns，则将步骤列表转换为字典， 在下面的测试方法中通过 id 查找步骤的信息
			if validate_teardowns:
				f.write(f"        cls.login_handler = ProjectLoginHandler()\n")
				f.write(f"        cls.teardowns_dict = {{teardown['id']: teardown for teardown in cls.test_case_data['teardowns']}}\n")
				f.write(f"        for teardown in cls.test_case_data.get('teardowns', []):\n")
				f.write(f"            project = teardown.get('project')\n")
				f.write(f"            if project:\n")
				f.write(f"                cls.login_handler.check_and_login_project(project, Globals.get('env'))\n")
			# 将步骤列表转换为字典， 在下面的测试方法中通过 id 查找步骤的信息
			f.write(f"        cls.steps_dict = {{step['id']: step for step in cls.test_case_data['steps']}}\n")
			f.write(f"        cls.session_vars = {{}}\n")
			f.write(f"        cls.global_vars = Globals.get_data()\n")  # 获取全局变量
			# 创建VariableResolver实例并保存在类变量中
			f.write(f"        cls.VR = VariableResolver(global_vars=cls.global_vars, session_vars=cls.session_vars)\n")
			f.write(f"        log.info('Setup completed for Test{module_class_name}')\n\n")
			
            # 写入加载测试数据的静态方法
			f.write(f"    @staticmethod\n")
			f.write(f"    def load_test_case_data():\n")
			f.write(f"        with open(r'{yaml_file}', 'r', encoding='utf-8') as file:\n")
			f.write(f"            test_case_data = yaml.safe_load(file)['testcase']\n")
			f.write(f"        return test_case_data\n\n")
			
            # 写入核心测试方法
			f.write(f"    @allure.story('{allure_story}')\n")
			f.write(f"    def test_{module_name}(self):\n")
			f.write(f"        log.info('Starting test_{module_name}')\n")
			# 遍历步骤，生成接口请求和断言代码
			for step in test_data['steps']:
				step_id = step['id']
				step_project = step.get("project") # 场景测试用例可能会请求不同项目的接口，需要在每个step中指定对应的project
				f.write(f"        # Step: {step_id}\n")
				f.write(f"        log.info(f'开始执行 step: {step_id}')\n")
				f.write(f"        {step_id} = self.steps_dict.get('{step_id}')\n")
				if step_project:
					f.write(f"        project_config = self.global_vars.get('{step_project}')\n")
				else:
					f.write(f"        project_config = self.global_vars.get('{project_name}')\n")
				# 生成请求代码
				f.write(f"        response = RequestHandler.send_request(\n")
				f.write(f"            method={step_id}['method'],\n")
				f.write(f"            url=project_config['host'] + self.VR.process_data({step_id}['path']),\n")
				f.write(f"            headers=self.VR.process_data({step_id}.get('headers')),\n")
				f.write(f"            data=self.VR.process_data({step_id}.get('data')),\n")
				f.write(f"            params=self.VR.process_data({step_id}.get('params')),\n")
				f.write(f"            files=self.VR.process_data({step_id}.get('files'))\n")
				f.write(f"        )\n")
				f.write(f"        log.info(f'{step_id} 响应：{{response}}')\n")
				f.write(f"        self.session_vars['{step_id}'] = response\n")
				# 生成断言代码
				if 'assert' in step:
					f.write(f"        db_config = project_config.get('mysql')\n")
					f.write(f"        AssertHandler().handle_assertion(\n")
					f.write(f"            asserts=self.VR.process_data({step_id}['assert']),\n")
					f.write(f"            response=response,\n")
					f.write(f"            db_config=db_config\n")
					f.write(f"        )\n\n")
			
			# 写入teardown_class（类级后置操作）
			if validate_teardowns:
				f.write(f"    @classmethod\n")
				f.write(f"    def teardown_class(cls):\n")
				f.write(f"        log.info('Starting teardown for the Test{module_class_name}')\n")
				for teardown_step in teardowns:
					teardown_step_id = teardown_step['id']
					teardown_step_project = teardown_step.get("project")
					f.write(f"        {teardown_step_id} = cls.teardowns_dict.get('{teardown_step_id}')\n")
					if teardown_step_project:
						f.write(f"        project_config = cls.global_vars.get('{teardown_step_project}')\n")
					else:
						f.write(f"        project_config = cls.global_vars.get('{project_name}')\n")
					# 处理API类型的后置操作
					if teardown_step['operation_type'] == 'api':
						f.write(f"        response = RequestHandler.send_request(\n")
						f.write(f"            method={teardown_step_id}['method'],\n")
						f.write(f"            url=project_config['host'] + cls.VR.process_data({teardown_step_id}['path']),\n")
						f.write(f"            headers=cls.VR.process_data({teardown_step_id}.get('headers')),\n")
						f.write(f"            data=cls.VR.process_data({teardown_step_id}.get('data')),\n")
						f.write(f"            params=cls.VR.process_data({teardown_step_id}.get('params')),\n")
						f.write(f"            files=cls.VR.process_data({teardown_step_id}.get('files'))\n")
						f.write(f"        )\n")
						f.write(f"        log.info(f'{teardown_step_id} 响应：{{response}}')\n")
						f.write(f"        cls.session_vars['{teardown_step_id}'] = response\n")
						if 'assert' in teardown_step:
							# if any(assertion['type'].startswith('mysql') for assertion in teardown_step['assert']):
							# 	f.write(f"        db_config = project_config.get('mysql')\n")
							f.write(f"        db_config = project_config.get('mysql')\n")
							f.write(f"        AssertHandler().handle_assertion(\n")
							f.write(f"            asserts=cls.VR.process_data({teardown_step_id}['assert']),\n")
							f.write(f"            response=response,\n")
							f.write(f"            db_config=db_config\n")
							f.write(f"        )\n\n")
					# 处理数据库类型的后置操作
					elif teardown_step['operation_type'] == 'db':
						f.write(f"        db_config = project_config.get('mysql')\n")
						f.write(f"        TeardownHandler().handle_teardown(\n")
						f.write(f"            asserts=cls.VR.process_data({teardown_step_id}),\n")
						f.write(f"            db_config=db_config\n")
						f.write(f"        )\n\n")
						f.write(f"        pass\n")
					else:
						log.info(f"未知的 operation_type: {teardown_step['operation_type']}")
						f.write(f"        pass\n")
				f.write(f"        log.info('Teardown completed for Test{module_class_name}.')\n")
			f.write(f"\n        log.info(f\"Test case test_{module_name} completed.\")\n")
		
		log.info(f"已生成测试用例文件: {file_path}")
		
	@staticmethod
	def load_test_data(test_data_file):
        """读取YAML文件，处理读取异常"""
		try:
			with open(test_data_file, 'r', encoding='utf-8') as file:
				test_data = yaml.safe_load(file)
			return test_data
		except FileNotFoundError:
			log.error(f"未找到测试数据文件: {test_data_file}")
		except yaml.YAMLError as e:
			log.error(f"YAML配置文件解析错误: {e}，{test_data_file} 跳过生成测试用例。")
	
	@staticmethod
	def validate_test_data(test_data):
		 """校验测试数据格式是否符合要求"""
		if not test_data:
			log.error("test_data 不能为空.")
			return False
		if not test_data.get('testcase'):
			log.error("test_data 必须包含 'testcase' 键.")
			return False
		if not test_data['testcase'].get('name'):
			log.error("'testcase' 下的 'name' 字段不能为空.")
			return False
		steps = test_data['testcase'].get('steps')
		if not steps:
			log.error("'testcase' 下的 'steps' 字段不能为空.")
			return False
		
		for step in steps:
			if not all(key in step for key in ['id', 'path', 'method']):
				log.error("每个步骤必须包含 'id', 'path', 和 'method' 字段.")
				return False
			if not step['id']:
				log.error("步骤中的 'id' 字段不能为空.")
				return False
			if not step['path']:
				log.error("步骤中的 'path' 字段不能为空.")
				return False
			if not step['method']:
				log.error("步骤中的 'method' 字段不能为空.")
				return False

		return True
	
	@staticmethod
	def validate_teardowns(teardowns):
		"""
		验证 teardowns 数据是否符合要求
		:param teardowns: teardowns 列表
		:return: True 如果验证成功，否则 False
		"""
		if not teardowns:
			# log.warning("testcase 下的 'teardowns' 字段为空.")
			return False
		
		for teardown in teardowns:
			if not all(key in teardown for key in ['id', 'operation_type']):
				log.warning("teardown 必须包含 'id' 和 'operation_type' 字段.")
				return False
			if not teardown['id']:
				log.warning("teardown 中的 'id' 字段为空.")
				return False
			if not teardown['operation_type']:
				log.warning("teardown 中的 'operation_type' 字段为空.")
				return False
			
			if teardown['operation_type'] == 'api':
				required_api_keys = ['path', 'method', 'headers', 'data']
				if not all(key in teardown for key in required_api_keys):
					log.warning("对于 API 类型的 teardown，必须包含 'path', 'method', 'headers', 'data' 字段.")
					return False
				if not teardown['path']:
					log.warning("teardown 中的 'path' 字段为空.")
					return False
				if not teardown['method']:
					log.warning("teardown 中的 'method' 字段为空.")
					return False
			
			elif teardown['operation_type'] == 'db':
				if 'query' not in teardown or not teardown['query']:
					log.warning("对于数据库类型的 teardown，'query' 字段不能为空.")
					return False

		return True

if __name__ == '__main__':
    # 运行生成器，生成指定YAML文件的用例
	CG = CaseGenerator()
	CG.generate_test_cases(project_yaml_list=["tests/merchant/test_device_bind.yaml"])
</code></pre>
<h3 id="第三步运行生成器自动生成pytest用例">第三步：运行生成器，自动生成Pytest用例</h3>
<p>运行上述生成器代码后，会自动在指定目录（默认test_cases）生成标准化的Pytest用例文件（如test_device_bind.py），无需手动修改，可通过项目入口文件执行（入口文件详细代码可参考文末开源项目）。</p>
<p>生成的用例代码示例（关键部分）：</p>
<pre><code class="language-python"># Auto-generated test module for device_bind
from utils.log_manager import log
from utils.globals import Globals
from utils.variable_resolver import VariableResolver
from utils.request_handler import RequestHandler
from utils.assert_handler import AssertHandler
from utils.teardown_handler import TeardownHandler
import allure
import yaml

@allure.epic('商家端')
@allure.feature('设备管理')
class TestDeviceBind:
    @classmethod
    def setup_class(cls):
        log.info('========== 开始执行测试用例：test_device_bind (新增设备) ==========')
        cls.test_case_data = cls.load_test_case_data()
        cls.steps_dict = {step['id']: step for step in cls.test_case_data['steps']}
        cls.session_vars = {}
        cls.global_vars = Globals.get_data()
        cls.VR = VariableResolver(global_vars=cls.global_vars, session_vars=cls.session_vars)
        log.info('Setup 完成')

    @staticmethod
    def load_test_case_data():
        with open(r'tests/merchant\device_management\test_device_bind.yaml', 'r', encoding='utf-8') as file:
            test_case_data = yaml.safe_load(file)['testcase']
        return test_case_data

    @allure.story('新增设备')
    def test_device_bind(self):
        log.info('开始执行 test_device_bind')
        
        # Step: device_bind
        log.info(f'开始执行 step: device_bind')
        device_bind = self.steps_dict.get('device_bind')
        project_config = self.global_vars.get('merchant')
        response = RequestHandler.send_request(
            method=spu_deviceType['method'],
            url=project_config['host'] + self.VR.process_data(device_bind['path']),
            headers=self.VR.process_data(device_bind.get('headers')),
            data=self.VR.process_data(device_bind.get('data')),
            params=self.VR.process_data(device_bind.get('params')),
            files=self.VR.process_data(device_bind.get('files'))
        )
        log.info(f'device_bind 请求结果为：{response}')
        self.session_vars['device_bind'] = response
        db_config = project_config.get('mysql')
        AssertHandler().handle_assertion(
            asserts=self.VR.process_data(device_bind['assert']),
            response=response,
            db_config=db_config
        )

        # Step: device_list
        log.info(f'开始执行 step: device_list')
        device_list = self.steps_dict.get('device_list')
        project_config = self.global_vars.get('merchant')
        response = RequestHandler.send_request(
            method=device_list['method'],
            url=project_config['host'] + self.VR.process_data(device_list['path']),
            headers=self.VR.process_data(device_list.get('headers')),
            data=self.VR.process_data(device_list.get('data')),
            params=self.VR.process_data(device_list.get('params')),
            files=self.VR.process_data(device_list.get('files'))
        )
        log.info(f'device_list 请求结果为：{response}')
        self.session_vars['device_list'] = response
        db_config = project_config.get('mysql')
        AssertHandler().handle_assertion(
            asserts=self.VR.process_data(device_list['assert']),
            response=response,
            db_config=db_config
        )
      	
        log.info(f"Test case test_device_bind completed.")

	@classmethod
    def teardown_class(cls):
    	# 示例代码省略
    	......

        log.info(f'Teardown completed for TestDeviceBind.')

</code></pre>
<h2 id="四其他核心工具类">四、其他核心工具类</h2>
<p>生成的用例文件依赖多个自定义工具类，这些工具类封装了通用功能，确保用例可正常运行。以下是各工具类的核心作用（详细实现可参考文末开源项目）：</p>
<table>
<thead>
<tr>
<th>工具类</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>log_manager</td>
<td>统一日志记录，输出用例执行过程</td>
</tr>
<tr>
<td>Globals</td>
<td>存储全局配置，如各项目的host、token、数据库连接信息、环境变量等。</td>
</tr>
<tr>
<td>VariableResolver</td>
<td>解析 YAML 中的变量（如{{steps.device_bind.data.id}}），支持全局变量、跨步骤变量取值。</td>
</tr>
<tr>
<td>RequestHandler</td>
<td>统一发送 HTTP 请求，处理超时、重试</td>
</tr>
<tr>
<td>AssertHandler</td>
<td>解析YAML中的断言配置，支持常规断言（等于、非空、包含等）和数据库断言。</td>
</tr>
<tr>
<td>TeardownHandler</td>
<td>处理后置操作，支持接口请求型和数据库操作型的后置清理逻辑。</td>
</tr>
</tbody>
</table>
<h2 id="五方案落地价值重构后我们获得了什么">五、方案落地价值：重构后我们获得了什么？</h2>
<ol>
<li><strong>效率翻倍</strong>：用例编写时间减少 70%+。以前写一条 3 步流程用例要 15 分钟，现在写 YAML 只需要 5 分钟，生成用例秒级完成，还不用关心代码格式。</li>
<li><strong>维护成本大幅降低</strong>：接口变更时，仅需修改对应YAML文件的相关字段（如参数、断言），重新运行生成器即可更新用例，无需全局搜索和修改代码，避免引入新bug。</li>
<li><strong>入门门槛极低</strong>：无Python基础的测试人员，只需学习简单的YAML格式规则，按模板填写数据即可参与用例编写，团队协作效率大幅提升。</li>
<li><strong>项目规范统一</strong>：所有用例的命名、目录结构、日志格式、断言方式均由生成器统一控制，彻底告别“各自为战”的混乱局面，项目可维护性显著增强。</li>
</ol>
<h2 id="六后续优化方向">六、后续优化方向</h2>
<p>目前方案已满足核心业务需求，但仍有优化空间，后续将重点推进以下方向：</p>
<ol>
<li>支持用例间依赖：实现用例级别的数据传递，比如用例A的输出作为用例B的输入，满足更复杂的业务场景。</li>
<li>增强YAML灵活性：支持在YAML中调用自定义Python函数（如生成随机数、加密参数），提升数据设计的灵活性。</li>
<li>简化YAML编写：增加通用配置默认值（如默认请求头、默认项目配置），减少重复填写工作。</li>
<li>多数据源支持：新增Excel/CSV导入功能，满足不熟悉YAML格式的测试人员需求，进一步降低使用门槛。</li>
</ol>
<h2 id="七参考项目">七、参考项目</h2>
<p>如果想直接落地，可以参考我的开源示例项目：<a href="https://gitee.com/xiaoqq23/api-auto-test" target="_blank" rel="noopener nofollow">api-auto-test</a>，里面包含了完整的工具类实现、YAML 模板、生成器代码和执行脚本。</p>

</div>
<div id="MySignature" role="contentinfo">
    <div style="font-size: 13px; border: 1px dashed rgb(45, 161, 45); padding: 10px 15px; background-color: rgb(248, 248, 248)">
	<div>
        <label style="font-weight: bold">&nbsp;&nbsp;&nbsp;&nbsp;
            <label style="font-weight: bold; color: red; font-size: 15px">左边二维码</label>
            为博主
            <label style="font-weight: bold; color: red; font-size: 15px">个人微信</label>
            ，
            <label style="font-weight: bold; color: red; font-size: 15px">扫码添加微信后可加入测试学习交流群</label>
            （添加时请务必备注：加入测试学习交流群）。
            <label style="font-weight: bold; color: red; font-size: 15px">右边二维码</label>
            为博主
            <label style="font-weight: bold; color: red; font-size: 15px">微信公众号</label>
            ，专注于自动化测试、测试开发技术分享，欢迎关注。
            书山有路勤为径，学海无涯苦做舟。希望通过分享学习交流，大家能够朝着
            <label style="font-weight: bold; color: red; font-size: 15px">最朴实的愿望--成长、加薪、升职</label>
            更进一步。
        </label>
    </div>
    <!-- <div align="center">
        <img style="height: 160px; width: 160px;" alt="个人微信" src="https://images.cnblogs.com/cnblogs_com/lfr0123/2106623/t_220220120615_wechat_black.png">
    </div> -->
    <div style="text-align: center; margin-top: 10px">
        <img style="width: 180px; padding-right: 20%" alt="个人微信" src="https://images.cnblogs.com/cnblogs_com/lfr0123/2106623/o_220303134143_WeChat_with_logo.png">
        <img style="width: 180px" alt="个人微信公众号" src="https://images.cnblogs.com/cnblogs_com/lfr0123/2106623/o_220303134126_gzh_with_ps.png">
    </div>
    <div><b>本文作者</b>：<a href="https://www.cnblogs.com/lfr0123/">给你一页白纸</a></div>
	<div><b>版权申明</b>：本博客所有文章除特殊声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">BY-NC-SA
	</a> 许可协议。转载请注明出处！</div>
	<div><b>声援博主</b>：如果觉得这篇文章对您有帮助，请点一下右下角的
		<a id="recommend" style="font-weight: bold; color: red; font-size: 15px; text-decoration: underline">“推荐”</a>
		图标哦，您的
		<a id="recommend" style="font-weight: bold; color: red; font-size: 15px; text-decoration: underline">“推荐”</a>
		是我写作的最大动力。您也可以点击下方的
        <a id="recommend" style="font-weight: bold; color: red; font-size: 15px; text-decoration: underline">【关注我】</a>
        按钮，关注博主不迷路。
	</div>
</div>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0" data-date-updated="2025-12-21 11:58">2025-12-21 11:58</span>&nbsp;
<a href="https://www.cnblogs.com/lfr0123">给你一页白纸</a>&nbsp;
阅读(<span id="post_view_count">44</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19378880);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19378880', targetLink: 'https://www.cnblogs.com/lfr0123/p/19378880', title: 'Pytest 测试用例自动生成：接口自动化进阶实践' })">举报</a>
</div>
         ]]>
    </description>
    </item>
<item>
    <title><![CDATA[ .NET10 New feature 新增功能介绍-JIT编译器改进 ]]></title>
    <link>https://www.cnblogs.com/tianqing/p/19378803</link>
    <guid>c76f4733f4d5a2e42c61b9376355d2fb</guid>
    <description>
    <![CDATA[ 
            <h1 class="postTitle">
                <a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/tianqing/p/19378803" title="发布于 2025-12-21 11:26">
    <span role="heading" aria-level="2">.NET10 New feature 新增功能介绍-JIT编译器改进</span>
    

</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                <div id="cnblogs_post_body" class="blogpost-body blogpost-body-html">
<p>首先.NET10是一个LTS版本，微软官方支持3年，所以作为最新的主力版本，可以尽快升级使用。</p>
<p>今天我们详细介绍一下.NET 10的一些新功能-JIT编译器改进</p>
<blockquote><strong>.NET 10 的 JIT 改进不是让慢代码变快，而是让“设计良好的代码不再被性能惩罚”。</strong></blockquote>
<p><img src="https://img2024.cnblogs.com/blog/23525/202512/23525-20251221112145258-191880994.png" alt="image" width="643" height="271" loading="lazy"></p>
<h3><strong>对业务代码是否有“侵入性”？</strong><span class="s2"><strong>几乎没有</strong></span></h3>
<ul>
<li>
<p class="p1">不需要改写代码</p>
</li>
<li>
<p class="p1">不需要 unsafe</p>
</li>
<li>
<p class="p1">不需要特殊编译选项&nbsp;</p>
</li>
</ul>
<blockquote>你写的是“好代码”，JIT 会越来越聪明地帮你榨干性能。</blockquote>
<p>.NET 10 中的 JIT 编译器包括通过更好的代码生成和优化策略提高性能的重要增强功能。<strong>改进结构参数的代码生成</strong></p>
<p>.NET 的 JIT 编译器能够进行称为物理提升的优化，其中结构的成员放置在寄存器而不是堆栈中，从而消除了内存访问。 将结构传递给方法时，此优化特别有用，调用约定要求在寄存器中传递结构成员。</p>
<p>.NET 10 改进了 JIT 编译器的内部表示形式，以处理共享寄存器的值。 以前，当需要将结构成员打包到单个寄存器中时，JIT 将首先将值存储在内存中，然后将其加载到寄存器中。 现在，JIT 编译器可以将结构参数的优化成员直接存储到共享寄存器中，从而消除不必要的内存操作。</p>
<div class="cnblogs_Highlighter">
<pre class="brush:csharp;gutter:true;">struct Point
{
    public long X;
    public long Y;

    public Point(long x, long y)
    {
        X = x;
        Y = y;
    }
}

[MethodImpl(MethodImplOptions.NoInlining)]
private static void Consume(Point p)
{
    Console.WriteLine(p.X + p.Y);
}

private static void Main()
{
    Point p = new Point(10, 20);
    Consume(p);
}
</pre>
</div>
<p>　　在 x64 CPU架构上，<code>Point</code>&nbsp;的成员会分配到单独的寄存器，并传递给&nbsp;<code>Consume</code>。由于本地&nbsp;<code>p</code>&nbsp;的物理提升已启动，因此最初不会在堆栈上分配任何内容。</p>
<p>Program:Main() (FullOpts):<br>       mov      edi, 10<br>       mov      esi, 20<br>       tail.jmp [Program:Consume(Program+Point)]</p>
<p>现在，假设成员&nbsp;<code>Point</code>&nbsp;的类型已更改为&nbsp;<code>int</code>&nbsp;而不是&nbsp;<code>long</code>。 由于 a&nbsp;<code>int</code>&nbsp;为四个字节宽，寄存器在 x64 上宽 8 个字节，因此调用约定要求在一个寄存器中传递成员&nbsp;<code>Point</code>&nbsp;。</p>
<p> 以前，JIT 编译器首先将值存储到内存中，然后将八字节区块加载到寄存器中。 </p>
<p>在.NET 10中，JIT 编译器现在可以直接将结构参数的提升成员放入共享寄存器中：</p>
<p>Program:Main() (FullOpts):<br>       mov      rdi, 0x140000000A<br>       tail.jmp [Program:Consume(Program+Point)]</p>
<p>这样就不需要中间内存存储，从而生成更高效的程序集代码。</p>
<h3 id="improved-loop-inversion" class="heading-anchor">改进了循环转化</h3>
<p>JIT 编译器可以提升循环的条件&nbsp;<code>while</code>&nbsp;，并将循环体转换为&nbsp;<code>do-while</code>&nbsp;循环，从而生成最终形状：</p>
<div class="cnblogs_Highlighter">
<pre class="brush:csharp;gutter:true;">if (loopCondition)
{
    do
    {
        // loop body
    } while (loopCondition);
}
</pre>
</div>
<p>此转换称为循环反转。 通过将条件移动到循环底部，JIT 无需将分支到循环顶部来测试条件，从而改进代码布局。 许多优化（如循环克隆、循环展开和感应变量优化）也依赖于循环反转来生成此形状来帮助分析。</p>
<p>.NET 10 通过从词法分析实现切换到基于图形的循环识别实现来增强循环反转。</p>
<p>此更改会考虑所有自然循环（即只有单个入口点的循环）并忽略以前被考虑的误报，从而提高了精度。 这使得包含&nbsp;<code>for</code>&nbsp;和&nbsp;<code>while</code>&nbsp;语句的 .NET 程序具有了更高的优化潜力。</p>
<h3 id="array-interface-method-devirtualization" class="heading-anchor">数组接口方法反虚拟化</h3>
<p>.NET 10 的重点&nbsp;<a href="https://github.com/dotnet/runtime/issues/108988" data-linktype="external" rel="noopener nofollow">领域</a>&nbsp;之一是减少常用语言功能的抽象开销。 为了追求此目标，JIT 去虚拟化方法调用的能力已经扩展为涵盖数组接口方法。</p>
<p>请考虑遍历一个数组的典型方法：</p>
<div class="cnblogs_Highlighter">
<pre class="brush:csharp;gutter:true;">static int Sum(int[] array)
{
    int sum = 0;
    for (int i = 0; i &lt; array.Length; i++)
    {
        sum += array[i];
    }
    return sum;
}
</pre>
</div>
<p>此代码形式易于 JIT 优化，主要是因为不存在虚拟调用。 相反，JIT 可以专注于删除对数组访问的边界检查，并应用&nbsp;<a href="https://learn.microsoft.com/zh-cn/dotnet/core/whats-new/dotnet-9/runtime#loop-optimizations" data-linktype="relative-path" rel="noopener nofollow">.NET 9 中添加的循环优化</a>。 以下示例添加一些虚拟调用：</p>
<div class="cnblogs_Highlighter">
<pre class="brush:csharp;gutter:true;">static int Sum(int[] array)
{
    int sum = 0;
    IEnumerable&lt;int&gt; temp = array;

    foreach (var num in temp)
    {
        sum += num;
    }
    return sum;
}
</pre>
</div>
<p>　　</p>
<p>基础集合的类型是明确的，JIT 应该能够将此代码片段转换为第一个代码片段。 但是，数组接口的实现方式与“普通”接口不同，因此 JIT 不知道如何对它们进行反虚拟化。 这意味着循环中的&nbsp;<code>foreach</code>&nbsp;枚举器调用仍然是虚拟的，从而阻止了多个优化，例如内联和堆栈分配。</p>
<p>从 .NET 10 开始，JIT 可以取消虚拟化和内联数组接口方法。 这是实现两者性能相等的诸多步骤中的第一步，如<a href="https://github.com/dotnet/runtime/issues/108913" data-linktype="external" rel="noopener nofollow">.NET 10 去抽象计划</a>中所述。</p>
<div>
<div class="heading-wrapper" data-heading-level="h3">
<h3 id="inlining-improvements" class="heading-anchor">内联改进</h3>
</div>
<p>.NET 10 中进行了各种内联改进。</p>
<p>JIT 现在可以内联因以前的内联而适合实现非虚拟化的方法。 这种改进使 JIT 可以发现更多的优化机会，例如进一步内联和去虚拟化。</p>
<p>某些具有异常处理语义的方法（尤其是具有&nbsp;<code>try-finally</code>&nbsp;块的方法）也可以内联。</p>
<p>为了更好地利用 JIT 的堆栈分配某些数组的能力，内联器的启发式算法已进行调整，以提高可能返回小型固定大小数组的候选项的收益。</p>
<div class="heading-wrapper" data-heading-level="h4">
<h4 id="return-types" class="heading-anchor">返回类型</h4>
</div>
<p>在内联过程中，JIT 编译器现在会更新临时变量的类型，这些变量用于存储返回值。 如果被调用方中的所有返回站点都生成相同的类型，则使用此精确的类型信息来取消后续调用的虚拟化。 此增强功能补充了后期非虚拟化和数组枚举去抽象的改进。</p>
<div class="heading-wrapper" data-heading-level="h4">
<h4 id="profile-data" class="heading-anchor">配置文件数据</h4>
</div>
<p>.NET 10 改进了 JIT 的内联策略，以更好地利用配置文件数据。 在众多启发式算法中，JIT 内联器不会对超过一定大小的方法进行内联，以避免使调用方法变得臃肿。 当调用方拥有表明某个内联候选函数被频繁执行的配置文件数据时，内联器会增加对该候选函数的大小容忍度。</p>
<p>假设 JIT 将没有配置文件数据的被调用方&nbsp;<code>Callee</code>&nbsp;内联到具有配置文件数据的调用方&nbsp;<code>Caller</code>&nbsp;中。 这种不一致可能发生在被调用方过小而不值得进行检测，或者被调用方被内联调用过于频繁，从而导致调用次数不足。 如果&nbsp;<code>Callee</code>&nbsp;拥有自己的内联候选项，JIT 此前并未将其纳入考虑范围，因为&nbsp;<code>Callee</code>&nbsp;缺乏性能分析数据。 现在，JIT 将识别到&nbsp;<code>Caller</code>&nbsp;拥有配置文件数据，并因此放宽其大小限制（但为了弥补精度损失，这种放宽程度不及&nbsp;<code>Callee</code>&nbsp;拥有配置文件数据时）。</p>
<p>同样，当 JIT 决定某个调用点不适合进行内联优化时，它会用&nbsp;<code>NoInlining</code>&nbsp;标记该方法，以避免未来再次尝试对该方法进行内联优化。 但是，许多内联启发法对配置文件数据很敏感。 例如，在缺少配置文件数据的情况下，JIT 可能会认为某个方法太大而不值得进行内联。 但是，当调用方足够热时，JIT 可能愿意放宽其大小限制并内联调用。 在 .NET 10 中，JIT 不再用&nbsp;<code>NoInlining</code>&nbsp;标记那些无利可图的内联函数，以避免配置文件数据导致调用点的性能恶化。</p>
</div>
<div class="heading-wrapper" data-heading-level="h3">&nbsp;
<div class="heading-wrapper" data-heading-level="h2">
<h2 id="stack-allocation" class="heading-anchor">堆栈分配</h2>
</div>
<p>堆栈分配可减少 GC 必须跟踪的对象数，并且还会解锁其他优化。 例如，在对象被堆栈分配后，JIT 可以考虑将其完全替换为其标量值。 因此，堆栈分配是减少引用类型的抽象惩罚的关键。 .NET 10 为<em>值类型和</em><a href="https://learn.microsoft.com/zh-cn/dotnet/core/whats-new/dotnet-10/runtime#small-arrays-of-reference-types" data-linktype="self-bookmark" rel="noopener nofollow">引用类型的小型数组</a>添加堆栈分配。 它还包括对本地结构字段和委托的<a href="https://learn.microsoft.com/zh-cn/dotnet/core/whats-new/dotnet-10/runtime#escape-analysis" data-linktype="self-bookmark" rel="noopener nofollow">转义分析</a>。 （无法转义的对象可以在堆栈上分配。）</p>
</div>
<p>&nbsp;</p>
<p>周国庆</p>
<p>2025/12/21</p>
<p>&nbsp;</p>
</div>
<div class="clear"></div>

            </div>
            <div class="postDesc">posted @ 
<span id="post-date" data-last-update-days="0.001388888888888889" data-date-updated="2025-12-21 11:28">2025-12-21 11:26</span>&nbsp;
<a href="https://www.cnblogs.com/tianqing">Eric zhou</a>&nbsp;
阅读(<span id="post_view_count">160</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(19378803);return false;">收藏</a>&nbsp;
<a href="javascript:void(0)" onclick="reportManager.report({ currentUserId: '', targetType: 'blogPost', targetId: '19378803', targetLink: 'https://www.cnblogs.com/tianqing/p/19378803', title: '.NET10 New feature 新增功能介绍-JIT编译器改进' })">举报</a>
</div>
         ]]>
    </description>
    </item>
        </channel>
        </rss>