{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "[大模型实战 03预备] 云端炼丹房 1：Google Colab 上手指南",
      "link": "https://www.cnblogs.com/algieba/p/19571424",
      "published": "",
      "description": "<div class=\"postcontent\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"[大模型实战 03预备] 云端炼丹房 1：Google Colab 上手指南\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203202001276-892195093.png\" />\n        本地显卡跑不动大模型？本文手把手教学薅 Google 羊毛！从 Colab 基础操作、免费 T4 GPU 开启，到挂载 Google Drive 持久化存储 HuggingFace 模型，为云端炼丹做好全套准备。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"大模型实战-03预备-云端炼丹房-1google-colab-上手指南\">[大模型实战 03预备] 云端炼丹房 1：Google Colab 上手指南</h1>\n<blockquote>\n<p><strong>核心摘要 (TL;DR)</strong></p>\n<ul>\n<li><strong>痛点</strong>：本地电脑显存不足，跑不动 7B 以上的大模型，或者运行速度如蜗牛。</li>\n<li><strong>方案</strong>：利用 <strong>Google Colab</strong> 提供的免费 Tesla T4 GPU 算力。</li>\n<li><strong>技巧</strong>：通过挂载 <strong>Google Drive</strong>，解决 Colab 运行时重置导致模型文件丢失的问题。</li>\n<li><strong>目标</strong>：配置好云端环境，为下一篇“云端运行 RAG”打好地基。</li>\n</ul>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>Ollama因为有llama.cpp库和量化技术的加成，是可以在cpu和更日常的电脑上运行的，但是性能是远比不上在专业的显存设备上的。<br />\n有高端显卡（NVIDIA 4090/5090/A100/H100），可以在自己的服务器上脱缰运行小规模的大模型。但是对于没有高端显卡设备的友人们也不用担心, 我们可以使用谷歌大善人带给我们的免费GPU算力：爱来自Google Colab。 本篇博文的主要目的就是提前带各位友人们从零上手Colab的核心操作，确保在我们后续的实战过程中的流畅操作。</p>\n<h2 id=\"1-google-colab\">1. Google Colab</h2>\n<p>一言概之，<a href=\"https://colab.research.google.com/\" rel=\"noopener nofollow\" target=\"_blank\">Google Colab</a> = <strong>Jupyter Notebook</strong> + <strong>云端服务器</strong></p>\n<ul>\n<li><strong>Jupyter Notebook</strong>：我们知道python是一门动态脚本语言，意味着我们可以一边编写，一边以交互式的方式看到当前结果，然后还能继续往下写。Jupyter Notebook就是一种可以一边写代码，一边写文档，还能实时看到代码运行结果的交互式笔记。</li>\n<li><strong>云端服务器</strong>：区别于在我们本地环境写代码时，代码在我们的本地电脑，换一台电脑就需要重新拉取代码运行，在云端服务器编码是在远程的服务器编码，我们通过自己的电脑，甚至手机或者任何能联网打开浏览器的设备，连接上远程的那台服务器进行代码编写和模型训练。会更为灵活，不受设备限制。</li>\n</ul>\n<h2 id=\"2-快速介绍\">2. 快速介绍</h2>\n<h3 id=\"21-访问与创建\">2.1 访问与创建</h3>\n<ol>\n<li>咱们确保有一个Google账户，并且登录</li>\n<li>访问<a href=\"https://colab.research.google.com/\" rel=\"noopener nofollow\" target=\"_blank\">Google Colab 官网</a>,就会进入到一个欢迎界面<br />\n<img alt=\"进入Colab的欢迎页面截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834576-1761513178.png\" /></li>\n<li>点击菜单栏上<strong>File</strong>-&gt;<strong>new notebook in drive</strong>创建新的笔记本<br />\n<img alt=\"Colab菜单栏打开File鼠标指向其下拉菜单new notebook in drive的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834093-1639885746.png\" /><br />\n<img alt=\"创建新的notebook后的新notebook界面截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201835540-570983137.png\" /></li>\n</ol>\n<h3 id=\"22-界面介绍\">2.2 界面介绍</h3>\n<p>在新的notebook界面，我们可以看到</p>\n<ul>\n<li><strong>文件名</strong>：左上角“Untitled0.ipynb”的文件名,可以单击重命名,ipynb就是jupyter notebook的后缀名<br />\n<img alt=\"notebook界面重新重命名后的文件名截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201835718-558218591.png\" /></li>\n<li><strong>单元格</strong>：页面中心一长条带一个▶按钮的就说单元格，也叫Cell，是我们的核心编码区域, Jupyter notebook的逻辑是“一段一段”执行代码，而非我们平常写代码时候写完一整个文件再执行。<br />\n<img alt=\"notebook界面中心单元格的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201835730-1829068104.png\" /></li>\n<li><strong>快捷操作栏</strong>：在单元格上方的位置有一条快捷菜单栏，支持我们添加新的代码块（Code Cell）和文本块（Text Cell），运行全部单元格（Run All）。<br />\n<img alt=\"在单元格上方的快捷操作栏的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834893-14728608.png\" /></li>\n<li><strong>左侧工具栏</strong>： 包含目录速览，查找替换，密钥管理，数据查看等等工具。<br />\n<img alt=\"左侧工具栏的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834216-1225871717.png\" /></li>\n<li><strong>变量和终端</strong>：这里的变量按钮可以查看执行到当前的变量信息，就不用去print变量了，很方便。终端按钮就和Linux终端一样，可以用来执行一些命令。<br />\n<img alt=\"最下方的变量按钮和终端按钮\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201835497-2041960710.png\" /></li>\n</ul>\n<h3 id=\"3-核心操作\">3. 核心操作</h3>\n<p>在界面介绍时，咱们快速介绍了一下两种单元格：<strong>代码块</strong>和<strong>文本块</strong>，接下来可以稍微多了解一点点这两种单元格</p>\n<h3 id=\"31-代码块\">3.1 代码块</h3>\n<p>就是我们的主力战场，编写Python代码的地方，可以快速体验一下使用流程</p>\n<ul>\n<li>直接输入python代码，然后点击运行（那个▶按钮或者使用快捷键 <strong><code>Shift + Enter</code></strong>）<br />\n<img alt=\"在代码块中写入代码后运行之后的界面截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834009-1869315854.png\" /></li>\n<li>可以看到代码块左侧有一个[1],一个绿色的√，代码块下方有输出的打印结果<br />\n前面的序号标明代码块的执行顺序，因为我们可以乱序执行，执行完下方代码块再回来执行前面的代码块</li>\n</ul>\n<h3 id=\"32-文本块\">3.2 文本块</h3>\n<p>jupyter notebook是支持直接渲染markdown格式的文档的，所以也有人直接用它当文档。相比于我们用注释去记录，markdown格式的文本块会更直观。</p>\n<ul>\n<li>点击上面的<strong>➕Text</strong>按钮（或者在当前单元格上方/下方中间浮现显示的快捷按钮）去新增一个文本块</li>\n<li><strong>Shift+Enter</strong>快捷键“运行/渲染”它，<br />\n<img alt=\"输入了# This is Title!!的文本块截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834557-224158255.png\" /><br />\n<img alt=\"渲染之后的文本块截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834523-54180414.png\" /></li>\n</ul>\n<h2 id=\"4-开启免费gpu算力\">4. <strong>开启免费GPU算力</strong></h2>\n<p>默认状态下Colab是使用的CPU，我们接下来去开启GPU</p>\n<ul>\n<li>点击顶部菜单栏的<strong>Runtime（运行时）</strong>下拉菜单中的<strong>Change runtime type（更改运行时类型）</strong><br />\n<img alt=\"点击Runtime下来菜单，鼠标指向Change runtime type的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834973-1363298837.png\" /></li>\n<li>选择<strong>Hardware accelerator(硬件加速器)</strong>的<strong>T4 GPU</strong>.<br />\n<img alt=\"进入change runtime type后鼠标选择T4GPU的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834344-277085401.png\" /></li>\n<li>弹出的窗口警告我们会断联当前运行时，切换到T4GPU的硬件，选择OK<br />\n<img alt=\"点击T4GPU后，弹出结束运行时的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834739-555876133.png\" /></li>\n<li>保存，然后会发现之前运行过的代码块失活了（前面框框里的数字消失了，所有运行过的代码块需要重新运行）</li>\n<li>我们来输入以下代码验证</li>\n</ul>\n<pre><code class=\"language-python\">!nvidia-smi\n</code></pre>\n<p><img alt=\"nvidia-smi的运行结果截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834176-1231975840.png\" /><br />\n从返回的表格结果中，能看到咱们的设备是TeslaT4。</p>\n<p>在notebook代码块中以<code>!</code>开头即可运行命令，这里等效为在terminal中运行<code>nvidia-smi</code><br />\n<strong>PS:除了切换文件夹得用<code>%cd</code>而不是<code>!cd</code></strong></p>\n<h2 id=\"5-下载大模型\">5. <strong>下载大模型</strong></h2>\n<p>我们使用Colab主要是为了使用大模型以及训练大模型，对于Colab而言，模型的下载有个痛点：<strong>Colab是临时的</strong>，哪怕我们通过命令下载了好几个G的模型，甚至好几十G的模型，但是每次重置运行时的时候，这一切都会灰飞烟灭，消散如烟。为了避免每次都重新下载，浪费时间，我们可以通过挂在Google Drive来保存模型。</p>\n<h3 id=\"51-挂载google-drive\">5.1 挂载Google Drive</h3>\n<ol>\n<li>我们运行以下代码</li>\n</ol>\n<pre><code class=\"language-python\">from google.colab import drive\ndrive.mount('/content/drive')\n</code></pre>\n<ol start=\"2\">\n<li>然后在弹出授权窗口中授权<br />\n<img alt=\"运行完挂载代码后，弹出的授权提示截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834509-1760419411.png\" /></li>\n<li>就能在代码块下方看见已经成功挂载的打印信息<br />\n<img alt=\"成功挂载google drive后的打印信息截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834445-1089132265.png\" /></li>\n</ol>\n<h3 id=\"52-配置huggingface环境变量和token\">5.2 配置HuggingFace环境变量和Token</h3>\n<p>在下载受限模型（如 Llama 3）时，你需要 Hugging Face Token。</p>\n<ol>\n<li>去 <a href=\"https://huggingface.co/settings/tokens\" rel=\"noopener nofollow\" target=\"_blank\">Hugging Face Settings</a> 获取 Token。</li>\n<li>在 Colab 左侧钥匙图标（Secrets）里添加 <code>HF_TOKEN</code>。</li>\n</ol>\n<p><img alt=\"Colab 左侧 Secrets 面板配置 HF_TOKEN 的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834471-1969164958.png\" /></p>\n<h3 id=\"53-指定缓存路径下载\">5.3 指定缓存路径下载</h3>\n<p>因为咱们在Colab环境，是国外的魔法环境，我们可以直接使用hugging face来下载模型，我们接下来指定一下模型下载的缓存路径到挂载的Google Drive。</p>\n<ol>\n<li>咱们先切回CPU环境，因为下载模型并不需要GPU,切回去可以节约一点咱们的额度。</li>\n<li>输入以下代码然后运行</li>\n</ol>\n<pre><code class=\"language-python\">from google.colab import drive\nimport os\n\n# 1. 挂载云盘\nif not os.path.exists('/content/drive'):\n    drive.mount('/content/drive')\n\n# 2. 准备目录\ncache_dir = \"/content/drive/MyDrive/huggingface_cache\"\nos.makedirs(cache_dir, exist_ok=True)\n\n# 3. 设置 Token (如果你在左侧 Secrets 设置了 HF_TOKEN，这里自动读取)\n# 如果没设置，请手动把下行代码引号里换成你的 token，或者留空试下（Qwen 有时不需要）\nmy_token = os.getenv('HF_TOKEN') or \"\"\n\nprint(\"屏幕可能会静止 5-10 分钟，请盯着左边的小圆圈转动即可。\")\n\ncmd = f\"huggingface-cli download Qwen/Qwen2.5-7B-Instruct --cache-dir {cache_dir} --quiet\"\nif my_token:\n    cmd += f\" --token {my_token}\"\n\n# 执行命令\nresult = os.system(cmd)\n\nif result == 0:\n    print(\"\\n 下载成功！\")\nelse:\n    print(\"\\n 下载失败，请检查网络或 Token。\")\n</code></pre>\n<ol start=\"3\">\n<li>然后运行下面的命令检验模型是否下载完毕</li>\n</ol>\n<pre><code class=\"language-python\"># check disk usage (查看磁盘占用)\n# -s: 汇总大小, -h: 人类可读格式 (GB/MB)\n!du -sh /content/drive/MyDrive/huggingface_cache/models--Qwen--Qwen2.5-7B-Instruct\n</code></pre>\n<p>看到的结果应该是15G大小的文件<br />\n<img alt=\"运行du -sh /content/drive/MyDrive/huggingface_cache/models--Qwen--Qwen2.5-7B-Instruct后的结果截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834031-689746531.png\" /></p>\n<p><strong>一般情况下，建议模型下载和数据处理都在CPU模式下进行，然后处理完毕存入云盘.</strong> 4. 然后新建代码块，运行如下代码，来确认模型是否能够被识别</p>\n<pre><code class=\"language-python\">import os\nimport glob\nfrom transformers import AutoConfig, AutoTokenizer\n\n# 1. 设置你的缓存根目录\nbase_cache_path = '/content/drive/MyDrive/huggingface_cache'\n\n# 2. 构造快照目录的通配符路径\n# 结构通常是: base / models--ID / snapshots / &lt;哈希值&gt;\nsnapshot_pattern = os.path.join(\n    base_cache_path,\n    \"models--Qwen--Qwen2.5-7B-Instruct\",\n    \"snapshots\",\n    \"*\"  # 这里用 * 匹配那个随机生成的哈希文件夹\n)\n\n# 3. 寻找真实的文件夹路径\nfound_folders = glob.glob(snapshot_pattern)\n\nif not found_folders:\n    print(\" 错误：找不到 snapshots 文件夹，请检查下载是否成功或路径是否正确。\")\nelse:\n    local_model_path = found_folders[0]\n\n    print(f\"锁定本地模型路径: {local_model_path}\")\n    print(\"正在尝试直接加载...\")\n\n    try:\n        config = AutoConfig.from_pretrained(local_model_path)\n        tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n\n        print(\"\\n成功！模型可以被正确加载。\")\n        print(f\"模型隐藏层维度: {config.hidden_size}\")\n        print(f\"词表大小: {tokenizer.vocab_size}\")\n\n    except Exception as e:\n        print(f\"\\n加载依然失败。可能是 Google Drive 的软链接失效了。\")\n        print(f\"错误信息: {e}\")\n</code></pre>\n<p><img alt=\"通过运行模型加载命令，显示模型成功加载的截图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260203201834785-1187356910.png\" /></p>\n<h2 id=\"05-常见问题-qa\">05. 常见问题 (Q&amp;A)</h2>\n<p><strong>Q: CPU 和 GPU 跑大模型，性能差异到底有多大？</strong><br />\n<strong>A:</strong> 差异巨大，就像<strong>法拉利</strong>和<strong>拖拉机</strong>的区别。</p>\n<ul>\n<li><strong>CPU (中央处理器)</strong>：像一个知识渊博的教授，计算能力强但只能一个一个任务串行处理。推理大模型时，它需要逐个计算矩阵乘法，生成一个字可能需要好几秒。</li>\n<li><strong>GPU (图形处理器)</strong>：像一个由几千名小学生组成的方阵，虽然单人能力不如教授，但能同时进行大规模并行计算。大模型的本质是海量的矩阵运算，GPU 可以瞬间完成，生成速度通常是 CPU 的几十倍甚至上百倍。</li>\n</ul>\n<p><strong>Q: 那一台 RTX 4090 能运行多大的模型？能微调多大？</strong><br />\n<strong>A:</strong> RTX 4090 拥有 <strong>24GB 显存</strong>，这是核心瓶颈。</p>\n<ul>\n<li><strong>推理 (运行)</strong>：\n<ul>\n<li><strong>4-bit 量化</strong>：显存占用 ≈ 参数量 × 0.7。4090 极限可以跑 <strong>30B - 34B</strong> 参数的模型（如 Yi-34B-Chat-Int4）。</li>\n<li><strong>全精度 (FP16)</strong>：显存占用 ≈ 参数量 × 2。4090 最多跑 <strong>10B - 12B</strong> 参数的模型。</li>\n</ul>\n</li>\n<li><strong>微调 (训练)</strong>：\n<ul>\n<li><strong>全量微调</strong>：想都不要想，需要几百 GB 显存。</li>\n<li><strong>LoRA / QLoRA (轻量微调)</strong>：这是咱们个人玩家的主流。4090 可以轻松微调 <strong>7B - 10B</strong> 的模型。</li>\n</ul>\n</li>\n</ul>\n<p><strong>Q: 动态脚本语言 (Python) 和常规预编译语言 (C++/Java) 有什么区别？</strong><br />\n<strong>A:</strong></p>\n<ul>\n<li><strong>预编译语言 (C++/Java)</strong>：像写书。写完一整本书（代码），送去印刷厂（编译），最后出来成品书（可执行文件）。执行速度快，但修改麻烦，改一个字要重新印刷。</li>\n<li><strong>动态脚本语言 (Python)</strong>：像聊天。你说一句（写一行代码），解释器就执行一句。虽然执行速度稍慢，但胜在<strong>交互性极强</strong>。在数据科学和 AI 领域，我们需要频繁查看数据的中间结果（比如查看模型输出的张量形状），Python 的这种特性让它成为了 AI 领域的霸主。</li>\n</ul>\n<p><strong>Q: Colab 里的 T4, A100, TPU 都有什么差别？</strong><br />\n<strong>A:</strong></p>\n<ul>\n<li><strong>T4 (免费版标配)</strong>：入门级推理卡，16GB 显存。跑 7B 模型推理没问题，微调 QLoRA 勉强够用。咱们薅羊毛主要就薅它。</li>\n<li><strong>A100 (付费版)</strong>：顶级计算卡，40GB/80GB 显存。速度极快，显存极大，适合跑大参数模型或进行严肃的训练任务。Colab Pro/Pro+ 才能刷到。</li>\n<li><strong>TPU (Tensor Processing Unit)</strong>：Google 专门为机器学习定制的芯片，处理矩阵运算比 GPU 更快，但生态和兼容性（PyTorch 支持）不如 Nvidia GPU 通用，上手门槛稍高。</li>\n</ul>\n<hr />\n<p><strong>本文作者：</strong> Algieba<br />\n<strong>本文链接：</strong> <a href=\"https://blog.algieba12.cn/llm02-1-online-environment-colab/\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.algieba12.cn/llm02-1-online-environment-colab/</a><br />\n<strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</p>\n<pre><code>\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"itemdesc\">\n\t\t\t发表于 \n<span id=\"post-date\">2026-02-03 20:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/algieba\">阿尔的代码屋</a>&nbsp;\n阅读(<span id=\"post_view_count\">2</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</div>"
    },
    {
      "title": "操作教程 | 使用开源三件套（OpenClaw+Ollama+1Panel）部署7×24运行的个人AI助理",
      "link": "https://www.cnblogs.com/xiaobaiysf/p/19571167",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaobaiysf/p/19571167\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 19:01\">\n    <span>操作教程 | 使用开源三件套（OpenClaw+Ollama+1Panel）部署7×24运行的个人AI助理</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><strong>一、写在前面</strong><br />\n本次操作教程将以开源 Linux 服务器运维面板 1Panel 为基础，搭配 Ollama 本地大模型（无需担心 Token 消耗费用），手把手教你部署 OpenClaw 个人 AI 助理，实现 7×24 小时稳定运行，轻松拥有专属智能助手！</p>\n<p><strong>二、资源准备</strong><br />\n本次 OpenCalw 本地个人 AI 助理基于一台腾讯 GPU 云服务器构建，云服务器获取过程不做赘述，参见腾讯云官网。其中服务器的配置参见如下：</p>\n<ul>\n<li>操作系统：Ubuntu Server 24.04 LTS 64 位</li>\n<li>计算资源：20 核 80 G</li>\n<li>磁盘容量：100G</li>\n<li>GPU： 计算型 GN7 | GN7.5XLARGE80</li>\n<li>网络：绑定弹性公网IP</li>\n</ul>\n<p><img alt=\"image-2026-2-3_16-29-44\" class=\"lazyload\" /></p>\n<p><strong>三、操作过程</strong><br />\n本次基于 1Panel 服务器运维管理面板构建本地化 AI 助理大致需要以下几个步骤；</p>\n<ul>\n<li>第一步：1Panel 安装部署；</li>\n<li>第二步：GPU 资源调度配置；</li>\n<li>第三步：Ollama 的安装部署；</li>\n<li>第四步：Qwen3 模型加载；</li>\n<li>第五步：OpenClaw 安装部署及配置。</li>\n</ul>\n<p><strong>四、详细操作步骤说明</strong><br />\n4.1.&nbsp;<strong>1Panel 安装部署</strong><br />\n1Panel 的安装部署比较简单，可以参照官网在线安装：<a href=\"https://1panel.cn/docs/v2/installation/online_installation/\" rel=\"noopener nofollow\" target=\"_blank\">https://1panel.cn/docs/v2/installation/online_installation/</a></p>\n<p>步骤一：<strong>获取 root 权限</strong>，登录服务器后首先切换到 root 权限</p>\n<p><code>sudo su -</code><br />\n步骤二：<strong>输入命令安装</strong>，输入在线安装命令执行安装：</p>\n<p><code>bash&nbsp;-c&nbsp;\"$(curl&nbsp;-sSL&nbsp;https://resource.fit2cloud.com/1panel/package/v2/quick_start.sh)\"</code><br />\n步骤三：<strong>Docker 安装</strong>，指定安装目录并安装 Docker</p>\n<p><img alt=\"2\" class=\"lazyload\" /></p>\n<p>步骤四：<strong>镜像加速器配置</strong>，选择配置镜像加速器并设置 1Panel 面板访问参数。</p>\n<p><img alt=\"3\" class=\"lazyload\" /></p>\n<p>步骤五：<strong>获取 1Panel 面板登录信息</strong></p>\n<p><img alt=\"4\" class=\"lazyload\" /></p>\n<p>步骤六：<strong>验证 1Panel 部署成功：</strong>将外部地址输入浏览器进入登录页面，输入对应的面板用户以及面板密码，确认安装完成。</p>\n<p><img alt=\"5\" class=\"lazyload\" /></p>\n<p>步骤七：<strong>1Panel 访问地址设置：</strong>进入面板后，切换到「面板设置」中，将默认访问地址设置为1Panel访问的公网IP，方便后续部署的应用可以通过跳转快速跳转。</p>\n<p><img alt=\"6\" class=\"lazyload\" /></p>\n<p><strong>4.2、&nbsp;GPU 资源调度配置</strong><br />\n进入1Panel的「终端」管理完成 NVIDIA 容器镜像配置，最终让基于容器安装的模型能够调度 GPU 资源。</p>\n<p>步骤一：<strong>NVIDIA 显卡驱动确认：</strong>需要确保 NVIDIA 显卡驱动已正确安装，输入以下命令：</p>\n<p><code>nvidia-smi</code><br />\n如下图展示，则代表成功。如果没有安装则自行前往英伟达官网下载安装：</p>\n<p><a href=\"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-apt\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-apt</a></p>\n<p><img alt=\"7\" class=\"lazyload\" /></p>\n<p>步骤二：<strong>安装 NVIDIA 容器镜像：</strong>为了在 docker 容器中使用 GPU 加速，我们需要安装 NVIDIA 的容器镜像，参照如下逐个命令行执行操作：</p>\n<p>命令行一：添加 NVIDIA 容器工具仓库与签名</p>\n<pre><code>curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n&nbsp;&nbsp;&amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n&nbsp;&nbsp;&nbsp;&nbsp;sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n&nbsp;&nbsp;&nbsp;&nbsp;sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n</code></pre>\n<p>命令行二：启用仓库中的 experimental 组件（可选）</p>\n<p><code>sed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list</code></p>\n<p>命令行三：更新软件源</p>\n<p><code>sudo apt-get update</code></p>\n<p>命令行四：安装 nvidia-container-toolkit</p>\n<p><code>sudo apt-get install -y nvidia-container-toolkit</code></p>\n<p>步骤三：<strong>配置 Docker 镜像使用 NVIDIA：</strong>安装完容器镜像后，需要配置 Docker 以使用 NVIDIA，并重启 Docker 服务。</p>\n<p>命令行一：配置 Docker 以使用 NVIDIA</p>\n<p><code>sudo nvidia-ctk runtime configure --runtime=docker</code></p>\n<p>命令行二：重启 docker</p>\n<p><code>sudo systemctl restart docker</code></p>\n<p><strong>4.3、Ollama 安装部署</strong><br />\n1Panel 安装以及服务器的 GPU 资源配置完成以后，我们就可以基于1Panel的运维管理面板进行个人助理的本地化安装部署了，一切就会变得非常简单，小白都能轻松上手。首先我们来安装Ollama，Ollama 是一个开源的大型语言模型服务，提供了类似 OpenAI 的 API 接口和聊天界面，可以非常方便地部署最新版本的 Qwen 模型并通过接口使用。</p>\n<p>步骤一： <strong>开始安装 Ollama 应用：</strong>首先我们进入1Panel 的应用商店，点击「AI」，然后选择 Ollama，直接点击安装。</p>\n<p><img alt=\"8\" class=\"lazyload\" /></p>\n<p>步骤二：<strong>设置 Ollama 安装参数：</strong>安装参数配置时需要确认版本号以及端口号，另外记得勾选「端口外部访问」，同时勾选「开启 GPU 支持」，确保后续我们可以正常访问 Ollama 且模型使用 GPU 资源，其他参数保持默认点击确认即可。</p>\n<p><img alt=\"9\" class=\"lazyload\" /></p>\n<p>步骤三：<strong>下载镜像并安装 Ollama：</strong>点击确认后，系统开始自动拉取镜像并安装应用，直到提醒安装应用「ollama」成功，则代表完成安装。</p>\n<p><img alt=\"10\" class=\"lazyload\" /></p>\n<p>步骤四：<strong>验证Ollama是否成功：</strong>进入已安装应用，找到 Ollama 应用，点击跳转，确认输出内容为“Ollama is running”，则代表部署成功。</p>\n<p><img alt=\"11\" class=\"lazyload\" /><br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<p><strong>4.4、Qwen3 本地模型部署</strong><br />\n部署完成 Ollama 以后，我们继续基于 1Panel 来完成基于 Ollama 本地 qwen3:14b 模型加载部署，参照如下操作步骤逐步完成即可。</p>\n<p>步骤一：<strong>创建 Qwen3 模型：</strong>进入 「AI」 的模型管理页面，点击添加模型。</p>\n<p><img alt=\"12\" class=\"lazyload\" /></p>\n<p>步骤二：<strong>加载模型：</strong>根据引导到 Ollama 官网找到模型 ID，在名称中输入模型名称，点击添加开始加载模型文件。本次我们选择的是 qwen3:14b 的模型，这里模型加载大概需要 20-30 分钟</p>\n<p><img alt=\"13\" class=\"lazyload\" /><br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<p>步骤三：<strong>模型运行确认：</strong>当模型列表中的「状态」更新为成功后，可以点击运行验证模型部署效果，如果能够正常对话则代表模型加载成功，如下图所示：</p>\n<p><img alt=\"14\" class=\"lazyload\" /></p>\n<p><strong>4.5、OpenClaw 安装部署</strong><br />\n基于以上步骤我们完成了本地模型的准备，然后我们再基于 1Panel 快速搭建个人 AI 助理 OpenClaw 。</p>\n<p>步骤一：<strong>开始安装 OpenClaw 应用</strong>，进入应用商店点击安装 OpenClaw 应用，如下图所示进入应用商店，点击「安装」，进入安装参数设置页面。</p>\n<p><img alt=\"15\" class=\"lazyload\" /></p>\n<p>步骤二：<strong>设置应用安装参数</strong>，如下图设置 OpenClaw 的版本号及端口、Ollama 本地模型以及是否外部访问等配置项，设置完成后点击确认开始安装，其中参数具体说明如下：</p>\n<ul>\n<li>版本：OpenClaw 版本默认为最新版本；</li>\n<li>端口：OpenClaw 应用访问端口默认为 18789、18790，如有占用自行调整变更，最终需要确保端口已开通，可外部访问；</li>\n<li>模型供应商：下拉选择 Ollama；</li>\n<li>模型：按照 Ollama/模型 ID 输入（即模型管理中添加的模型 ID），如：Ollama/qwen3:14b；</li>\n<li>模型API Key：本地模型输入任意字符即可；</li>\n<li>Base URL：输入上述步骤部署的 Ollama 应用的地址，即 <a href=\"http://IP:11434/v1\" rel=\"noopener nofollow\" target=\"_blank\">http://IP:11434/v1</a> 即可;</li>\n<li>端口外部访问：勾选端口外部访问，方便后续 OpenClaw 应用访问。</li>\n</ul>\n<p><img alt=\"16\" class=\"lazyload\" /></p>\n<p>步骤三：<strong>OpenClaw 应用安装</strong>，点击确认后系统自动开始拉取镜像，并安装应用，如下图所示则代表 OpenClaw 应用安装成功。</p>\n<p><img alt=\"17\" class=\"lazyload\" /></p>\n<p>步骤四：<strong>应用 token 获取</strong>，通过「已安装」应用如图点击进入目录，一路点击如图所示，进入 data/conf 文件，找到 openclaw.json 文件点击打开；找到 “gateway” 中的 “token” 复制其中的 token 值，如：9bfd07dd800a8c304b62bfac09f698cb7ad9f939d812021a，</p>\n<p><img alt=\"18\" class=\"lazyload\" /><br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<p><img alt=\"18\" class=\"lazyload\" /></p>\n<p>步骤五：<strong>Web 应用访问设置</strong>，将获取到的 token 与 IP 地址以及端口号按照 <strong>IP:端口？token={token}</strong>具体值（如：</p>\n<p>139.186.147.190:18789?token=9bfd07dd800a8c304b62bfac09f698cb7ad9f939d812021a</p>\n<p>） 拼接起来 ，定义在参数中的 「Web 访问地址」中，如下图所示：</p>\n<p><img alt=\"18\" class=\"lazyload\" /></p>\n<p><img alt=\"18\" class=\"lazyload\" /></p>\n<p><strong>五、个人 AI 助理效果</strong><br />\n完成以上操作我们就基于 1Panel 完成了 OpenClaw 个人 AI 助理的搭建。直接进入应用商店已安装，点击跳转，选择带 token 的链接地址点击即可进入OpenClaw 体验了，具体参见如下图：</p>\n<p><img alt=\"19\" class=\"lazyload\" /></p>\n<p>我们输入可以输入一些简单的事情交给 AI 助理帮你完成，如下图所示：</p>\n<p><img alt=\"20\" class=\"lazyload\" /></p>\n<p><strong>六、总结</strong><br />\n通过上述完整步骤，我们能依托 1Panel 运维管理面板快速搭建 7X24 小时不间断运行的本地 AI 助理。最终只需通过浏览器访问 OpenClaw，即可畅享本地模型驱动的 AI 智能助理服务，无论是日常咨询还是轻量办公辅助都能轻松应对。</p>\n<p>全程操作以 1Panel 为核心载体，无需复杂的命令行功底，所有配置流程可视化、步骤化，即便是小白新手也能按指引快速完成部署。不过经实测发现，当前本地模型在工具调用的灵活性上仍存在些许局限，但随着 OpenClaw、Ollama 等开源项目的持续迭代优化，这些问题我们相信会很快得到优化改善，未来该 AI 助理的功能会愈发强大，为我们的生活和工作效率带来显著提升。</p>\n<p>最后在模型选择方面，经过多次实测验证，基于当前的硬件资源配置，Qwen3:14b、Qwen coder:30b 是兼顾性能与资源消耗的优选方案；若服务器配置充足（如更高显存、更强算力），也可尝试部署参数更大的模型以获得更优效果。</p>\n<p>这套本地化 AI 助理方案无需依赖外部 Token，数据隐私更有保障，诚邀大家动手实操体验，感受开源三件套工具带来的高效智能服务。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 19:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaobaiysf\">小白跃升坊</a>&nbsp;\n阅读(<span id=\"post_view_count\">76</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "spring6-工厂设计模式与bean的实例化方式",
      "link": "https://www.cnblogs.com/alineverstop/p/19570969",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/alineverstop/p/19570969\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 18:14\">\n    <span>spring6-工厂设计模式与bean的实例化方式</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"bean的作用域\">bean的作用域</h1>\n<p>ioc容器默认bean是单例的（singleton）。</p>\n<p>bean对象的创建是在初始化上下文的时候就创建了，每一次调用getBean()时，都返回那个单例对象。</p>\n<pre><code class=\"language-java\">// 这行代码会创建配置里面的bean对象\nApplicationContext context = new FileSystemXmlApplicationContext(\"D:/applicationContext.xml\");\n</code></pre>\n<p>那如何把bean设置成多例的？</p>\n<pre><code class=\"language-xml\">&lt;!--    scope=\"prototype\" 会使这个bean变成多例的--&gt;\n&lt;bean id=\"sb\" class=\"com.ali.bean.SpringBean\"  scope=\"prototype\"/&gt;\n</code></pre>\n<pre><code class=\"language-java\">// 由于这个bean是多例模式，这行代码不会创建bean对象。而是在调用getBean（）时创建对象\nApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\",\"spring-dao.xml\");\n// 这行代码才会创建bean对象\nObject user=  context.getBean(\"sb\");\n</code></pre>\n<pre><code class=\"language-xml\">&lt;!--    scope=\"prototype\" 会使这个bean变成多例的\n        目前scope有2个值：singleton 和 prototype\n        当项目引入spring-webmvc依赖变成web项目时，scope会多2个属性\n        request：表示每次http请求都会创建一个新的bean对象\n        session: 表示每次 session都会创建一个新的bean对象\n--&gt;\n    &lt;bean id=\"sb\" class=\"com.ali.bean.SpringBean\"  scope=\"prototype\"/&gt;\n</code></pre>\n<h2 id=\"自定义scope\">自定义scope</h2>\n<ol>\n<li>\n<p>自定义Scope（实现Scope接口）</p>\n<ul>\n<li>spring内置了线程范围类： org.springframework.context.support.SimpleThreadScope</li>\n</ul>\n</li>\n<li>\n<p>添加配置信息</p>\n</li>\n</ol>\n<pre><code class=\"language-xml\">    &lt;bean id=\"sb\" class=\"com.ali.bean.SpringBean\"  scope=\"threadScope\"/&gt;\n\n&lt;!--    配置自定义的作用域，实现一个线程一个bean--&gt;\n    &lt;bean class=\"org.springframework.beans.factory.config.CustomScopeConfigurer\" &gt;\n        &lt;property name=\"scopes\"&gt;\n            &lt;map&gt;\n                &lt;entry key=\"threadScope\"&gt;\n&lt;!--                    这个SimpleThreadScope 是spring框架内置的，也可以自定义--&gt;\n                    &lt;bean class=\"org.springframework.context.support.SimpleThreadScope\"&gt;&lt;/bean&gt;\n                &lt;/entry&gt;\n            &lt;/map&gt;\n        &lt;/property&gt;\n    &lt;/bean&gt;\n</code></pre>\n<h1 id=\"gof之工厂模式\">GoF之工厂模式</h1>\n<h2 id=\"工厂模式的三种形态\">工厂模式的三种形态</h2>\n<ol>\n<li>简单工厂模式（Simple Factory）：又叫静态工厂方法模式。是工厂方法模式的一种特殊实现。</li>\n<li>工厂方法模式 （Factory Method）</li>\n<li>抽象工厂模式 （Abstract Factory）</li>\n</ol>\n<h2 id=\"简单工厂模式\">简单工厂模式</h2>\n<p>简单工厂模式包括三个角色：抽象产品、具体产品、工厂类。代码如下：</p>\n<ol>\n<li>抽象产品类</li>\n</ol>\n<pre><code class=\"language-java\">// 抽象产品角色\npublic abstract class Weapon {\n\tpublic abstract void attack();\n}\n</code></pre>\n<ol start=\"2\">\n<li>\n<p>具体产品</p>\n<pre><code class=\"language-java\">// 具体产品角色：匕首\npublic class Dagger extends Weapon{\n    @Override\n    public void attack() {\n        System.out.println(\"匕首攻击...\");\n    }\n}\n</code></pre>\n</li>\n</ol>\n<pre><code class=\"language-java\">// 具体产品角色：战斗机\npublic class Fighter extends Weapon{\n    @Override\n    public void attack() {\n        System.out.println(\"战斗机攻击...\");\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">// 具体产品角色：坦克\npublic class Tank extends Weapon{\n    @Override\n    public void attack() {\n      System.out.println( \"坦克攻击。。。\");\n    }\n}\n</code></pre>\n<ol start=\"3\">\n<li>工厂类角色</li>\n</ol>\n<pre><code class=\"language-java\">// 工厂类角色\npublic class WeaponFactory {\n    /**\n     * 静态方法：根据传入的参数获取相应的武器\n     * @return\n     */\n    public static Weapon get(String type){\n        switch (type){\n            case \"Tank\":\n                return new Tank();\n            case \"Fighter\":\n                return new Fighter();\n            case \"Dagger\":\n                return new Dagger();\n            default:\n                return null;\n        }\n    }\n}\n</code></pre>\n<p>测试代码：</p>\n<pre><code class=\"language-java\">public class Main {\n    public static void main(String[] args) {\n        // 简单工厂模式达到职责分离。客户端不关心产品生产的细节\n        // 客户端只负责消费，工厂类负责生产。这就是简单工厂模式的作用。\n        Weapon weapon1 = WeaponFactory.get(\"Tank\");\n        weapon1.attack();\n        Weapon weapon2 = WeaponFactory.get(\"Fighter\");\n        weapon2.attack();\n        Weapon weapon3 = WeaponFactory.get(\"Dagger\");\n        weapon3.attack();\n    }\n}\n</code></pre>\n<p>优缺点：</p>\n<p>优点：实现职责分离。</p>\n<p>缺点：假如要添加新产品。需要修改工厂类代码。显然违反了ocp原则。</p>\n<p>​            工厂类责任重大。一旦瘫痪，这个系统必然瘫痪。</p>\n<h2 id=\"工厂方法模式\">工厂方法模式</h2>\n<p>工厂方法模式保留了简单工厂模式的优点。同时解决了简单工厂模式的缺点。</p>\n<p>解决方法是：一个工厂对应一个产品。符合ocp原则。</p>\n<p>优点：扩展性高。要想增加一个产品。只要扩展一个工厂类就可以。</p>\n<pre><code>\t屏蔽产品具体实现。调用者只关心产品的接口。\n</code></pre>\n<p>缺点：会使类的数量成倍增加，增加系统复杂度。</p>\n<p>工厂方法模式的角色包括：</p>\n<ul>\n<li>抽象工厂角色</li>\n<li>具体工厂角色</li>\n<li>抽象产品角色</li>\n<li>具体产品角色</li>\n</ul>\n<p>代码如下：</p>\n<pre><code class=\"language-java\">// 抽象产品角色\npublic abstract class Weapon {\n    public abstract void attack();\n}\n\n// 具体产品角色：匕首\npublic class Dagger extends Weapon {\n    @Override\n    public void attack() {\n        System.out.println(\"匕首攻击...\");\n    }\n}\n\n// 具体工厂类：枪械工厂\npublic class GunFactory extends WeaponFactory{\n    @Override\n    public Weapon get() {\n        return new Gun();\n    }\n}\n\n// 抽象工厂类\npublic abstract class WeaponFactory {\n\n    public abstract Weapon get();\n}\n\n// 具体工厂类：匕首工厂\npublic class DaggerFactory extends WeaponFactory{\n    @Override\n    public Weapon get() {\n        return new Dagger();\n    }\n}\n\n// 具体工厂类：枪械工厂\npublic class GunFactory extends WeaponFactory{\n    @Override\n    public Weapon get() {\n        return new Gun();\n    }\n}\n</code></pre>\n<p>测试代码：</p>\n<pre><code class=\"language-java\">public static void main(String[] args) {\n    WeaponFactory weaponFactory = new DaggerFactory();\n    Weapon dagger = weaponFactory.get();\n    dagger.attack();\n\n    WeaponFactory weaponFactory1 = new GunFactory();\n    Weapon gun = weaponFactory1.get();\n    gun.attack();\n}\n</code></pre>\n<h1 id=\"bean的实例化\">bean的实例化</h1>\n<p>spring为bean提供了多种实例化的方式，通常包括4种方式。</p>\n<ol>\n<li>通过构造方法实例化</li>\n<li>通过简单工厂模式实例化</li>\n<li>通过factory-bean实例化</li>\n<li>通过FactoryBean接口实例化</li>\n</ol>\n<h2 id=\"通过构造方法实例化\">通过构造方法实例化</h2>\n<pre><code class=\"language-xml\">&lt;!--    spring会自动调用该类的无参数构造方法来实例化对象，这个SpringBean类必须有一个无参数的构造方法--&gt;\n    &lt;bean id=\"springBean\" class=\"com.ali.bean.SpringBean\" /&gt;\n</code></pre>\n<h2 id=\"通过简单工厂模式实例化\">通过简单工厂模式实例化</h2>\n<pre><code class=\"language-java\">// 工厂类\npublic class StarFactory {\n    public static Star createStar() {\n        return new Star();\n    }\n}\n</code></pre>\n<pre><code class=\"language-xml\">&lt;!--    静态(简单)工厂方法实例化bean 指定调用哪个类的哪个方法。这里实例化的是Star对象。\n      factory-method 指定的是工厂类中的静态方法名称。\n--&gt;\n  &lt;bean id=\"starBean\" class=\"com.ali.bean.StarFactory\" factory-method=\"createStar\"&gt;&lt;/bean&gt;\n</code></pre>\n<h2 id=\"通过factory-bean实例化\">通过factory-bean实例化</h2>\n<pre><code class=\"language-java\">// 工厂方法模式中的具体产品类\npublic class Gun {\n    public Gun() {\n        System.out.println(\"无参数构造器：Gun()\");\n    }\n}\n\n// 工厂方法模式中的具体工厂类\npublic class GunFactory {\n    public Gun get(){\n        return new Gun();\n    }\n}\n</code></pre>\n<pre><code class=\"language-xml\">&lt;!--    通过工厂方法模式实例化bean。由factory-bean指定工厂类的bean id，factory-method指定工厂类中的实例方法名称--&gt;\n    &lt;bean id=\"gunFactory\" class=\"com.ali.bean.GunFactory\"&gt;&lt;/bean&gt;\n    &lt;bean id=\"gun\" factory-bean=\"gunFactory\" factory-method=\"get\"&gt;&lt;/bean&gt;\n</code></pre>\n<h2 id=\"通过factorybean接口实例化\">通过FactoryBean接口实例化</h2>\n<p>通过factory-bean实例化的方式需要我们自定义factory-bean和factory-method。</p>\n<p>在spring中，当自己的类实现了FactoryBean接口后factory-bean和factory-method就不需要指定了。factory-bean会自动指向实现FactoryBean接口的类，factory-method会自动指向getObject()方法。</p>\n<pre><code class=\"language-java\">public class PersonFactoryBean implements FactoryBean&lt;Person&gt; {\n    @Override\n    public Person getObject() throws Exception {\n        // 手动创建对象\n        return new Person();\n    }\n\n    @Override\n    public Class&lt;?&gt; getObjectType() {\n        return null;\n    }\n\n}\n</code></pre>\n<pre><code class=\"language-xml\">&lt;!--PersonFactoryBean实现了FactoryBean接口，Spring会调用它的getObject方法来实例化person对象\n不用写factory-bean和factory-method，直接将PersonFactoryBean配置为一个普通的bean即可\n 这样spring会自动调用PersonFactoryBean的getObject方法来实例化person对象--&gt;\n&lt;bean id=\"person\" class=\"com.ali.bean.PersonFactoryBean\"&gt;&lt;/bean&gt;\n</code></pre>\n<h2 id=\"beanfactory和factorybean的区别\">BeanFactory和FactoryBean的区别</h2>\n<p>BeanFactory：spring ioc容器的顶级对象，负责创建bean对象。BeanFactory是工厂</p>\n<p>FactoryBean：本质是一个bean。能够辅助spring实例化其他bean对象。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/alineverstop/\" target=\"_blank\">NE_STOP</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/alineverstop/p/19570969\" target=\"_blank\">https://www.cnblogs.com/alineverstop/p/19570969</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 18:14</span>&nbsp;\n<a href=\"https://www.cnblogs.com/alineverstop\">NE_STOP</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "LLVM Pass快速入门(三)：指令替换",
      "link": "https://www.cnblogs.com/ClownLMe/p/19570905",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ClownLMe/p/19570905\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 18:05\">\n    <span>LLVM Pass快速入门(三)：指令替换</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"指令替换\">指令替换</h1>\n<p>项目需求：将加法指令替换为减法</p>\n<h1 id=\"项目目录如下\">项目目录如下</h1>\n<pre><code>/MyProject\n├── CMakeLists.txt # CMake 配置文件\n├── build/ #构建目录\n│   └── test.c #测试编译代码\n└── mypass2.cpp # pass 项目代码\n</code></pre>\n<h3 id=\"一测试代码示例\">一，测试代码示例</h3>\n<p><strong>test.c</strong></p>\n<pre><code class=\"language-c\">// test.c\n#include &lt;stdio.h&gt;\n\nint my_add(int a, int b) {\n    return a + b; \n}\n\nint main() {\n    int x = 10;\n    int y = 20;\n    printf(\"Result: %d\\n\", my_add(x, y));\n    return 0;\n}\n</code></pre>\n<h3 id=\"二编写pass\">二，编写Pass</h3>\n<p>其他的固定的模板之前文章注释有，这里我只注释当前项目重要的部分<br />\n<strong>代码流程：</strong> 遍历指令并匹配<code>ADD</code>指令-&gt;替换为<code>sub</code>指令</p>\n<pre><code class=\"language-cpp\">#include \"llvm/IR/PassManager.h\"\n#include \"llvm/Passes/PassBuilder.h\"\n#include \"llvm/Passes/PassPlugin.h\"\n#include \"llvm/Support/raw_ostream.h\"\n#include \"llvm/IR/Function.h\"\n#include \"llvm/IR/BasicBlock.h\"\n#include \"llvm/IR/Instruction.h\"\n#include \"llvm/IR/Instructions.h\"\n#include \"llvm/IR/IRBuilder.h\" // &lt;--- 【新增】必须包含这个头文件！\n\nusing namespace llvm;\n\nnamespace {\n\tstruct mypass3 : public PassInfoMixin&lt;mypass3&gt; {\n\t    PreservedAnalyses run(Function &amp;F, FunctionAnalysisManager &amp;) {\n\t        errs() &lt;&lt; \"Analyzing Function: \" &lt;&lt; F.getName() &lt;&lt; \"\\n\";\n\t        \n\t        bool changed = false; \n\t\t\t\n\t\t\t//这里的2个循环获取的是遍历函数的指令(函数-&gt;代码块-&gt;指令)\n\t        for (BasicBlock &amp;BB : F) {\n\t            for (Instruction &amp;Inst : BB) {\n\t\t            ]//判断当前的指令是ADD指令(加法)\n\t                if (Inst.getOpcode() == Instruction::Add) {\n\t\t\t\t\t\t\n\t                    errs() &lt;&lt; \"Found ADD, changing to SUB...\\n\" &lt;&lt; Inst &lt;&lt; \"\\n\";\n\t\t\t\t\t\t//创建IR构建器\n\t\t\t\t\t\t//在修改IR时需要用到构建器\n\t                    IRBuilder&lt;&gt; builder(&amp;Inst);\n\t                    \n\t                    //这里时获取ADD的操作数：\n\t                    //%add = add nsw i32 %0, %1中的%0和%1\n\t                    Value *lhs = Inst.getOperand(0); // 左操作数\n\t                    Value *rhs = Inst.getOperand(1); // 右操作数\n\t                    //这里是构建新的指令：sub\n\t                    //其中参数是：\n\t                    //1：左操作数\n\t                    //2：操作数\n\t                    //3：返回的变量名，相当于：%add = add nsw i32 %0, %1中的%add\n\t                    Value *newSub = builder.CreateSub(lhs, rhs, \"new_sub\");\n\t                    \n\t                    //替换指令\n\t                    Inst.replaceAllUsesWith(newSub);\n\t                    errs() &lt;&lt; \"Replaced with SUB: \\n\" &lt;&lt; *lhs &lt;&lt; \"\\n\" &lt;&lt; *rhs &lt;&lt; \"\\n\" &lt;&lt; *newSub &lt;&lt; \"\\n\";\n\t                    changed = true;\n\t                    \n\t                }\n\t            }\n\t        }\n\t\t\t\n\t        if (changed) {\n\t            return PreservedAnalyses::none();\n\t        }\n\t\n\t        return PreservedAnalyses::all();\n\t    }\n\t};\n\n} \n\nextern \"C\" LLVM_ATTRIBUTE_WEAK ::llvm::PassPluginLibraryInfo\nllvmGetPassPluginInfo() {\n    return {\n        LLVM_PLUGIN_API_VERSION,\n        \"mypass3\",\n        \"v0.1\",\n        [](PassBuilder &amp;PB) {\n            PB.registerPipelineParsingCallback(\n                [](StringRef Name, FunctionPassManager &amp;FPM,\n                   ArrayRef&lt;PassBuilder::PipelineElement&gt;) {\n                    if (Name == \"mypass3\") {\n                        FPM.addPass(mypass3());\n                        return true;\n                    }\n                    return false;\n                });\n        }};\n}\n</code></pre>\n<h3 id=\"三pass的构建\">三，Pass的构建</h3>\n<p><strong>下面引用的是之前文章的内容</strong><br />\n构建LLVM Pass需要写<code>CMakeLists.txt</code>构建声明</p>\n<h5 id=\"1-配置cmake配置文件\">1. 配置CMake配置文件</h5>\n<p><strong>CMakeLists.txt</strong><br />\n下面的<code>cmake</code>配置可以直接拿去用，我已经标注好需要修改的位置</p>\n<pre><code class=\"language-python\">#cmake 版本，可通过 cmake --version 判断\ncmake_minimum_required(VERSION 4.1.1) #----&gt;修改 cmake版本号\n#项目名字\nproject(mypass2) #----&gt;修改 项目名称\n\n#导入项目的 LLVM cmake 配置文件路径(如果根据我之前文章安装这里就相同)\nset(LLVM_DIR \"D:/LLVM/llvm-project/build/lib/cmake/llvm\")#----&gt;修改 llvm cmake配置路径\n#寻找 LLVM 的包文件\n#REQUIRED 找不到 LLVM 则停止构建\n#强制使用 LLVM 安装时生成的配置文件进行定位\nfind_package(LLVM REQUIRED CONFIG)\n#将 LLVM 的 CMake 模块路径添加到当前 CMake 搜索路径中，以便后续使用 include(AddLLVM)。\nlist(APPEND CMAKE_MODULE_PATH \"${LLVM_CMAKE_DIR}\")\n\n#引入 LLVM 提供的专用 CMake 宏\ninclude(AddLLVM)\n#将 LLVM 的头文件目录（如 llvm/IR/Function.h）加入编译器的搜索路径\ninclude_directories(${LLVM_INCLUDE_DIRS})\n#导入 LLVM 编译时使用的宏定义\nadd_definitions(${LLVM_DEFINITIONS})\n#设置 C++ 标准为 C++17。(这里如果不用17编译会报错)\nset(CMAKE_CXX_STANDARD 17)\n#强制要求必须支持 C++17，如果编译器不支持则失败。\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\n\n#创建一个模块化的库(.dll)\nadd_library(mypass2 MODULE mypass1.cpp) #----&gt;修改 项目名称，文件名\n#windows不用会报错：导出符号\n#LLVM Pass 需要暴露一些特定的入口点（如 getAnalysisUsage）给 opt 工具调用。\nset_target_properties(mypass2 PROPERTIES WINDOWS_EXPORT_ALL_SYMBOLS ON) #----&gt;修改 项目名称\n# 指定该 Pass 需要链接的 LLVM 核心组件。 \n# LLVMCore: 提供 IR、Function、Module 等核心类。 \n# LLVMSupport: 提供各种辅助工具类（如 errs() 输出）。\ntarget_link_libraries(mypass2 LLVMCore LLVMSupport) #----&gt;修改 项目名称，文件名  \n# 为该目标设置特定的编译器选项。 \n# /utf-8: 告诉 MSVC 编译器使用 UTF-8 编码处理源代码，防止中文注释引起的乱码或编译错误。  \ntarget_compile_options(mypass2 PRIVATE /utf-8)#----&gt;修改 项目名称，文件名\n</code></pre>\n<h5 id=\"2编译并构建pass\">2.编译并构建Pass</h5>\n<p><strong>打开visual studio<code>的工作台，我这里是</code>x64 Native Tools Command Prompt for VS 2022`</strong></p>\n<p>进到<code>build</code>目录</p>\n<pre><code class=\"language-bash\">#构建项目\n#其中-DCMAKE_BUILD_TYPE=RelWithDebInfo不选会报错，由于我之前编译的是带符号的relase版本\ncmake -G \"Ninja\"  -DCMAKE_BUILD_TYPE=RelWithDebInfo ..\n#编译\nninja\n</code></pre>\n<p>最后出现下面提示，即为编译成功</p>\n<pre><code class=\"language-bash\">[2/2] Linking CXX shared module mypass2.dll\n</code></pre>\n<h3 id=\"四使用当前的pass\">四，使用当前的pass</h3>\n<p>进到<code>build</code>目录</p>\n<pre><code class=\"language-bash\">#把.c文件编译为.ll\n#-O1 使用O1优化（这里我尝试-O0不优化，会导致我的pass无法应用）\n#-Xclang -disable-llvm-passes 不使用默认的pass优化\nclang -S -emit-llvm -O1 -Xclang -disable-llvm-passes test.c -S -o test.ll\n\n#使用pass\nopt -load-pass-plugin=mypass2.dll -passes=mypass2  test.ll -S -o test_opt.ll\n\n#编译使用pass后的exe\nclang test_opt.ll -o test_opt.exe\n#编译使用pass前的exe\nclang test.ll -o test.exe\n</code></pre>\n<p><strong>输出结果</strong><br />\n<code>运行test.exe</code>：<strong>不使用</strong>pass，输出结果如下：</p>\n<pre><code class=\"language-bash\">Result: 30\n</code></pre>\n<p><code>运行test_opt.exe</code>：<strong>使用</strong>pass后，输出结果如下：</p>\n<pre><code class=\"language-bash\">Result: -10\n</code></pre>\n<p><strong>我们成功让我们的代码 加法 变 减法</strong></p>\n<p><strong>如果❤喜欢❤本系列教程，就点个关注吧，后续不定期更新~</strong></p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/ClownLMe/\" target=\"_blank\">ClownLMe</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/ClownLMe/p/19570905\" target=\"_blank\">https://www.cnblogs.com/ClownLMe/p/19570905</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 18:05</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ClownLMe\">ClownLMe</a>&nbsp;\n阅读(<span id=\"post_view_count\">7</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "天翼云全栈赋能OpenClaw，打造会干活的专属AI！",
      "link": "https://www.cnblogs.com/developer-tianyiyun/p/19570215",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/developer-tianyiyun/p/19570215\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 16:37\">\n    <span>天翼云全栈赋能OpenClaw，打造会干活的专属AI！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>最近科技圈的新顶流非OpenClaw (原Moltbot/Clawdbot) 莫属！不同于只会聊天的AI，它是真正能“上手干活”的全功能智能体——授权后能<strong>操作文件、运行程序、处理数据</strong>，还能记住长期目标和对话历史，7x24小时在线当你的专属“数字员工”，彻底把人从重复劳动里解放出来。</p>\n<p>不用复杂操作，几句指令就能解锁高效体验：</p>\n<ul>\n<li>让它监控邮箱，自动提取客户询价信息生成Excel，定时推送；</li>\n<li>让它管理待办，未完成事项自动顺延调优，还能根据日历给通勤穿搭建议；</li>\n<li>50份市场调研PDF丢给它，喝杯咖啡的功夫，竞品定价策略+市场趋势报告直接到手。</li>\n</ul>\n<p>如今，这股高效能AI力量已<strong>全面登陆天翼云生态</strong>，通过<strong>息壤智算一体机/息壤桌面型一体机、魔乐社区</strong>，实现多场景覆盖、零门槛接入，无论你是重视隐私的企业客户，还是热爱探索的开发者，都能找到专属的使用方式！</p>\n<h1 align=\"center\"><span style=\"font-size: 16px;\">息壤智算一体机/息壤桌面型一体机</span></h1>\n<h1 align=\"center\"><span style=\"font-size: 16px;\">本地化需求直接拿捏</span></h1>\n<p>采用“<strong>算力+模型+应用</strong>”软硬件一体设计，适配昇腾、桌面型设备等多元算力，还预置了DeepSeek、Qwen等主流大模型；息壤桌面型一体机现在深度融合OpenClaw，开箱即用不用额外部署，搭配天翼云自研推理平台与训推一体工具，数据本地处理更安全，企业用着超放心。</p>\n<p>&nbsp;<img alt=\"\" class=\"lazyload\" /></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>适用场景：息壤桌面型一体机+OpenClaw打造有温度的陪伴式机器人</strong></p>\n<p>息壤桌面型一体机以硬核本地化算力为核心，搭建稳定可靠的硬件平台，并提供全方位的交互接口，实现人机无缝对话。内置开源大模型的“情感认知中枢”，精准解读情绪、自然对话、智能规划任务；OpenClaw智能体作为“高效执行者”，确保指令精准落地。场景化的机器人软件融合核心能力，结合拟人化界面和长期记忆系统，不仅记住你的喜好、回应你的情绪，还能提供专属提醒与陪伴，构建温暖且深入的人机连接。</p>\n<h1 align=\"center\"><span style=\"font-size: 16px;\">魔乐社区</span></h1>\n<h1 align=\"center\"><span style=\"font-size: 16px;\">OpenClaw镜像一键下载</span></h1>\n<p>魔乐社区作为天翼云打造的中立公益的AI开源创新阵地，聚合海量优质AI开源资源。为了让更多开发者能够快速上手OpenClaw、降低部署门槛，魔乐社区现已将OpenClaw打包为开箱即用的镜像，并<strong>正式上线社区工具中心</strong>。无需源码克隆、无需本地构建、无需复杂配置、全系统适配，打开魔乐社区即可一键获取，直接下载部署，让开发者轻松探索OpenClaw的无限拓展可能。</p>\n<p><strong>适用场景：开源模型+OpenClaw，打造专属本地智能研发工作站</strong></p>\n<p>依托魔乐社区丰富的免费开源模型资源，用户可轻松在本地部署各类适配业务的开源模型，一键下载OpenClaw镜像完成本地部署后，结合OpenClaw的本地自动化、多岗位适配能力，通过OpenClaw便捷调用本地模型。&nbsp;</p>\n<p><strong>下载链接：</strong></p>\n<p><strong><a href=\"https://modelers.cn/images/openclaw\" rel=\"noopener nofollow\">https://modelers.cn/images/openclaw</a></strong></p>\n<p>&nbsp;<img alt=\"\" class=\"lazyload\" /></p>\n<p>天翼云始终以“息壤”为核心构建开放AI生态，此次与OpenClaw的创新协同，正是通过全栈智算能力，让前沿AI技术走出实验室，走进千行百业与日常生活。从云端部署到本地落地，从企业需求到个人体验，天翼云用技术打破壁垒，让每个用户都能零门槛拥有专属“数字员工”，在效率革命中抢占先机。</p>\n<p>特别提醒：</p>\n<p>“This bot can read files and run actions if tools are enabled.”</p>\n<p>“A bad prompt can trick it into doing unsafe things.”</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 16:37</span>&nbsp;\n<a href=\"https://www.cnblogs.com/developer-tianyiyun\">天翼云开发者社区</a>&nbsp;\n阅读(<span id=\"post_view_count\">37</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "再谈模拟退火",
      "link": "https://www.cnblogs.com/reasa/p/19570188",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/reasa/p/19570188\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 16:34\">\n    <span>再谈模拟退火</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"源于现实的启发性算法模拟退火与混合策略\">源于现实的启发性算法：模拟退火与混合策略</h1>\n<h2 id=\"前言\">前言</h2>\n<p>模拟退火（Simulated Annealing, SA）在算法竞赛圈素来以“玄学”著称，广泛地被用于骗分。这类方法看似不需要过多思考，参数一设，成败全看天命（和脸黑不黑）。</p>\n<p>但在我上大学接触机器学习后，发现这个被戏称为“骗分大法”的算法，其实有着严谨的理论。更有意思的是，如果将它与<strong>梯度下降</strong>结合，就能搞出一种强力混合算法。</p>\n<h2 id=\"一模拟退火算法源于热力学的全局优化方法\">一、模拟退火算法：源于热力学的全局优化方法</h2>\n<h3 id=\"11-物理溯源从固体退火到算法抽象\">1.1 物理溯源：从固体退火到算法抽象</h3>\n<p>模拟退火的灵感来自于<strong>固体退火</strong>这一工艺流程，主要有两个阶段：</p>\n<ol>\n<li><strong>升温阶段</strong>：将固体加热至高温，粒子获得足够能量，处于无序的高能量状态（对应算法中的随机乱跑）；</li>\n<li><strong>降温阶段</strong>：缓慢且稳定降低温度，粒子热运动减弱，最终形成规则晶体（对应算法收敛到最优解）。</li>\n</ol>\n<p>算法层面将这一过程抽象为：</p>\n<ul>\n<li><strong>能量</strong>：目标函数值（Function Loss）。我们的目标是让能量越低越好（最小化问题）；</li>\n<li><strong>温度</strong>：控制<strong>探索（Exploration）与利用（Exploitation）</strong>权衡的核心参数。高温时“瞎逛”寻找新大陆，低温时“内卷”精细打磨；</li>\n<li><strong>状态转移</strong>：从当前解生成邻域新解，并决定是否接受它。</li>\n</ul>\n<p>值得注意的是，粒子热运动本质上都是通过统计学来预测的，所以存在一种可能即粒子能量可能反常升高，而这是模拟退火能够不同于其他算法的核心所在，即在温度下降过程中有一定概率接受劣解（比当前最优解差的解）。</p>\n<h3 id=\"12-算法核心流程拆解\">1.2 算法核心流程拆解</h3>\n<p>流程严格对应物理退火，分为五步：</p>\n<ol>\n<li><strong>初始化</strong>：设定初始解、初始温度 <span class=\"math inline\">\\(T_0\\)</span>、衰减系数 <span class=\"math inline\">\\(\\alpha\\)</span>、终止温度 <span class=\"math inline\">\\(T_{end}\\)</span>；</li>\n<li><strong>迭代降温</strong>：在当前温度下，多次生成邻域新解；</li>\n<li><strong>Metropolis判定</strong>：关键一步！决定是否接受新解；</li>\n<li><strong>温度衰减</strong>：<span class=\"math inline\">\\(T = T \\times \\alpha\\)</span>，逐步收缩探索范围；</li>\n<li><strong>终止输出</strong>：温度降至冰点，输出历史最优解。</li>\n</ol>\n<h3 id=\"13-核心公式metropolis接受准则\">1.3 核心公式：Metropolis接受准则</h3>\n<p>这是模拟退火能够跳出局部最优解的关键。设当前能量 <span class=\"math inline\">\\(E_{now}\\)</span>，新解能量 <span class=\"math inline\">\\(E_{new}\\)</span>，能量差 <span class=\"math inline\">\\(\\Delta E = E_{new}-E_{now}\\)</span>：</p>\n<ol>\n<li>若 <span class=\"math inline\">\\(\\Delta E &lt; 0\\)</span>：新解更优（能量降低），<strong>无条件接受</strong>；</li>\n<li>若 <span class=\"math inline\">\\(\\Delta E \\geq 0\\)</span>：新解更劣（能量升高），以概率 <span class=\"math inline\">\\(P\\)</span> <strong>概率性接受</strong>：<p></p><div class=\"math display\">\\[P = \\exp\\left(-\\frac{\\Delta E}{T}\\right) \n\\]</div><p></p></li>\n</ol>\n<p><strong>直观理解</strong>：</p>\n<ul>\n<li>温度 <span class=\"math inline\">\\(T\\)</span> 很高时，<span class=\"math inline\">\\(\\exp\\)</span> 的结果接近 1，算法接受大部分劣解</li>\n<li>温度 <span class=\"math inline\">\\(T\\)</span> 接近 0 时，<span class=\"math inline\">\\(\\exp\\)</span> 的结果接近 0，算法基本只接受更好的解（类似于普通贪心）</li>\n</ul>\n<h3 id=\"14-实操案例模拟退火求解物理平衡点\">1.4 实操案例：模拟退火求解物理平衡点</h3>\n<p>以洛谷 P1337《平衡点/吊打XXX》为例。<br />\n<em>注：虽然这个特定的物理问题本质上是一个<strong>凸优化问题</strong>（能量函数是一个单峰的函数，只有一个全局最优解，不存在局部陷阱），用梯度下降甚至三分法就能解决，但它非常适合用来演示模拟退火的标准流程。</em></p>\n<p><strong>题目大意</strong>：<span class=\"math inline\">\\(n\\)</span> 个重物系在绳子上，求绳结最终静止的 <span class=\"math inline\">\\((x, y)\\)</span> 坐标。本质是求系统总重力势能最小的点。</p>\n<p><strong>目标函数</strong>：</p>\n<p></p><div class=\"math display\">\\[E(x,y) = \\sum_{i=1}^n w_i \\cdot \\sqrt{(x-x_i)^2+(y-y_i)^2} \n\\]</div><p></p><p><strong>代码实现</strong>：</p>\n<pre><code class=\"language-cpp\">#include &lt;bits/stdc++.h&gt;\nusing namespace std;\ndouble deltaT = 0.996;\ndouble initT = 3000;\ndouble goalT = 1e-15;\ndouble a[10001],b[10001],c[10010];\nint n;\ninline double cal(double x,double y){\n\tdouble sum = 0;\n\tfor (int i=1;i&lt;=n;i++){\n\t\tsum+=sqrt(pow(x-a[i],2)+pow(y-b[i],2))*c[i];\n\t}\n\treturn sum;\n}\ninline pair&lt;double,double&gt; SA(double x,double y){\n\tdouble nowT = initT;\n\tdouble nowx = x,nowy = y;\n\tdouble nowans = cal(nowx,nowy);\n\twhile (nowT&gt;=goalT){\n\t\tdouble newx = nowx+(rand()*2-RAND_MAX)*nowT;\n\t\tdouble newy = nowy+(rand()*2-RAND_MAX)*nowT;\n\t\tdouble newans = cal(newx,newy);\n\t\tif (newans&lt;nowans){\n\t\t\tnowx = newx;\n\t\t\tnowy = newy;\n\t\t\tnowans = cal(nowx,nowy);\n\t\t}\n\t\telse {\n\t\t\tdouble tmp = exp((nowans-newans)/nowT);\n\t\t\tdouble l = (double)rand()/RAND_MAX*1.0;\n\t\t\tif (tmp &gt;= l){\n\t\t\t\tnowx = newx;\n\t\t\t\tnowy = newy;\n\t\t\t\tnowans = cal(nowx,nowy);\n\t\t\t}\n\t\t}\n\t\tnowT*=deltaT;\n\t}\n\treturn {nowx,nowy};\n}\nsigned main(){\n\tsrand(time(0));\n\tcin&gt;&gt;n;\n\tdouble x1 = 0,y1 = 0;\n\tfor (int i=1;i&lt;=n;i++){\n\t\tcin&gt;&gt;a[i]&gt;&gt;b[i]&gt;&gt;c[i];\n\t\tx1+=a[i];\n\t\ty1+=b[i];\n\t}\n\tpair&lt;double,double&gt; ans;\n\tdouble minn = 10000000000.0;\n\tfor (int i=1;i&lt;=10;i++){\n\t\tpair&lt;double,double&gt; tmp = SA(x1/n,y1/n);\n\t\tif (minn&gt;cal(tmp.first,tmp.second)){\n\t\t\tans = tmp;\n\t\t\tminn = cal(tmp.first,tmp.second);\n\t\t}\n\t}\n\t\n\tcout&lt;&lt;fixed&lt;&lt;setprecision(3)&lt;&lt;ans.first&lt;&lt;\" \"&lt;&lt;ans.second&lt;&lt;endl;\n\treturn 0;\n}\n</code></pre>\n<hr />\n<h2 id=\"二梯度下降\">二、梯度下降</h2>\n<h3 id=\"21-核心原理\">2.1 核心原理</h3>\n<p>如果说模拟退火是“到处乱跑碰运气”，那梯度下降（Gradient Descent, GD）就是“看着地形找路”。<br />\n其数学含义是：<strong>沿梯度的反方向更新参数，能最快逼近极小值</strong>。</p>\n<p>这句话的意思是根据函数的导数的陡峭程度，判断下一步该往哪里走，走多大步。这种能较快收敛得到最佳结果的方法常被用在机器学习中求解最优参数。</p>\n<p>参数更新公式：</p>\n<p></p><div class=\"math display\">\\[\\boldsymbol{\\theta}_{new} = \\boldsymbol{\\theta}_{old} - \\eta \\cdot \\nabla E(\\boldsymbol{\\theta}_{old}) \n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(\\eta\\)</span> 是<strong>学习率（Learning Rate）</strong>，决定了步子迈多大；<span class=\"math inline\">\\(\\nabla E\\)</span> 是梯度向量，决定了往哪个方向迈。</p>\n<h3 id=\"22-原生梯度下降的硬伤\">2.2 原生梯度下降的“硬伤”</h3>\n<p>梯度下降是<strong>贪心算法</strong>，这导致它有几个致命弱点：</p>\n<ol>\n<li><strong>易陷局部最优</strong>：如果是凹凸不平的复杂函数，它掉进第一个小坑（局部最优）就出不来了，因为它拒绝往高处走，这也是贪心的通病。</li>\n<li><strong>对初始值极度敏感</strong>：寻优结果高度依赖初始解的选择，如果初始解在最优解的谷里则容易得到最优解，否则不容易得到。</li>\n<li><strong>鞍点停滞</strong>：在梯度为0的平坦区域，它会直接“躺平”不再更新。</li>\n</ol>\n<hr />\n<h2 id=\"三sa-gd模拟退火与梯度下降的结合\">三、SA-GD：模拟退火与梯度下降的结合</h2>\n<h3 id=\"31-融合动机\">3.1 融合动机</h3>\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>特点</th>\n<th>缺陷</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>纯模拟退火</td>\n<td>乱跑，不怕坑</td>\n<td>盲目，收敛慢，效率低</td>\n</tr>\n<tr>\n<td>纯梯度下降</td>\n<td>定向，跑得快</td>\n<td>贪心，掉坑里出不来</td>\n</tr>\n</tbody>\n</table>\n<p>我们希望结合两者：<strong>在大体方向上顺着梯度快跑（GD），但在每一步行走时加入随机的“抖动”（SA），防止掉入小坑出不来</strong>。</p>\n<h3 id=\"32-注意点\">3.2 注意点</h3>\n<p>许多人可能会恍然大悟：原来如此，那么我先算梯度下降得到新解，再用SA判断接不接受不就万事大吉了。<br />\n<strong>这是错的！</strong><br />\n因为梯度下降的方向必然是能量减少的方向（<span class=\"math inline\">\\(E_{new} &lt; E_{now}\\)</span>），这会导致Metropolis准则中 <span class=\"math inline\">\\(\\Delta E\\)</span> 永远小于0，算法<strong>永远接受</strong>新解。这样SA模块就失效了，算法退化回了纯梯度下降。</p>\n<p><strong>正确的结合方式</strong>：<strong>在梯度更新中引入噪声</strong>。</p>\n<p></p><div class=\"math display\">\\[\\boldsymbol{\\theta}_{new} = \\boldsymbol{\\theta}_{old} - \\eta \\nabla E + \\mathbf{Noise}(T) \n\\]</div><p></p><p>这个 <span class=\"math inline\">\\(\\mathbf{Noise}(T)\\)</span> 是一个随温度衰减的随机扰动项。</p>\n<ul>\n<li><strong>高温时</strong>：噪声很大，梯度指东，你可能往西，主打一个“由于能量过高而胡乱冲撞”；</li>\n<li><strong>低温时</strong>：噪声较小，不再有较大的跳跃，算法乖乖顺着梯度滑向坑底。</li>\n</ul>\n<h3 id=\"33-sa-gd-完整代码实现\">3.3 SA-GD 完整代码实现</h3>\n<p>注：为了代码演示的清晰性，这里我们使用线性回归作为示例。虽然线性回归本质上也是凸优化问题（单纯 GD 即可解决），但这套‘梯度+噪声’的代码框架完全适用于神经网络等复杂的非凸优化场景。</p>\n<pre><code class=\"language-cpp\">#include &lt;bits/stdc++.h&gt;\nusing namespace std;\n\n// === 全局配置与随机数生成 ===\nmt19937 rng(chrono::steady_clock::now().time_since_epoch().count());\nuniform_real_distribution&lt;double&gt; dist(0.0, 1.0);\n\ninline double read(){ \n    double x = 0.0;\n    int f = 1;\n    char c = getchar();\n    while(!isdigit(c) &amp;&amp; c != '.'){\n        if (c == '-') f = -1;\n        c = getchar();\n    }\n    while(isdigit(c)) {\n        x = x * 10 + (c - '0');\n        c = getchar();\n    }\n    if(c == '.'){\n        c = getchar();\n        double decimal = 0.1;\n        while(isdigit(c)){\n            x += (c-'0')*decimal;\n            decimal *= 0.1;\n            c = getchar();\n        }\n    }\n    return x*f;\n}\n\nint n;\nvector&lt;double&gt; true_w;      // 实际权重 \nvector&lt;vector&lt;double&gt;&gt; simple_x; // 示例x \nvector&lt;double&gt; simple_y;    // 示例y \n\n// === 核心计算函数 ===\n\n// 计算当前的预测值 (y_pred)\n// 参数: w-权重向量, b-偏差\ninline vector&lt;double&gt; predict(const vector&lt;double&gt;&amp; w, double b) {\n    vector&lt;double&gt; preds(100);\n    for (int i = 0; i &lt; 100; i++) {\n        preds[i] = b;\n        for (int j = 0; j &lt; n; j++) {\n            preds[i] += w[j] * simple_x[j][i];\n        }\n    }\n    return preds;\n}\n\n// 计算能量（即损失函数 MSE）\n// 这是 SA 算法判断解优劣的标准\ninline double calc_energy(const vector&lt;double&gt;&amp; preds) {\n    double loss = 0;\n    for (int i = 0; i &lt; 100; i++) {\n        double diff = preds[i] - simple_y[i];\n        loss += diff * diff;\n    }\n    return loss / 100.0; // Mean Squared Error\n}\n\n// 计算梯度 (Gradient)\n// 返回: pair&lt;w的梯度向量, b的梯度&gt;\npair&lt;vector&lt;double&gt;, double&gt; calc_gradient(const vector&lt;double&gt;&amp; preds) {\n    vector&lt;double&gt; w_grad(n, 0.0);\n    double b_grad = 0.0;\n\n    for (int i = 0; i &lt; 100; i++) {\n        double diff = preds[i] - simple_y[i]; // (y_pred - y_true)\n        b_grad += diff; \n        for (int j = 0; j &lt; n; j++) {\n            w_grad[j] += diff * simple_x[j][i];\n        }\n    }\n    \n    // 平均化梯度\n    b_grad /= 100.0;\n    for(int j=0; j&lt;n; j++) w_grad[j] /= 100.0;\n    \n    return {w_grad, b_grad};\n}\n\nsigned main(){\n    srand(114514); // 保持数据生成的随机种子一致，方便对比\n    n = read(); \n    \n    // 读取真实权重\n    for (int i=0; i&lt;n; i++) true_w.push_back(read());\n    double true_b = read(); \n\n    // === 生成模拟数据===\n    for (int i=0; i&lt;n; i++){ \n        simple_x.push_back(vector&lt;double&gt;());\n        double maxn = -200.0, minn = 200.0;\n        for (int j=0; j&lt;100; j++){\n            double tmp = (1 + rand()%100) * 0.1;\n            maxn = max(maxn, tmp);\n            minn = min(minn, tmp);\n            simple_x[i].push_back(tmp);\n        }\n        // 归一化\n        for (int j=0; j&lt;100; j++){\n            simple_x[i][j] = (simple_x[i][j]-minn)/(maxn-minn);\n        }\n    }\n    \n    // 生成带噪声的 y\n    vector&lt;double&gt; tmp_y(100);\n    for (int i=0; i&lt;100; i++){\n        tmp_y[i] = true_b + (1 + rand()%100)*0.01;\n    }\n    for (int i=0; i&lt;n; i++){ \n        for (int j=0; j&lt;100; j++){\n            tmp_y[j] += true_w[i] * simple_x[i][j];\n        }\n    }\n    simple_y = tmp_y;\n\n    // === SA-GD 参数设置 ===\n    int train_times = read(); \n    double init_lr = read(); \n    \n    // 模拟退火参数\n    double T = 100.0;       // 初始温度\n    double endT = 1e-6;     // 终止温度\n    double decayT = 0.99;   // 温度衰减系数\n    // 根据训练次数动态调整衰减速度，确保能跑完 train_times\n    if (train_times &gt; 0) decayT = pow(endT/T, 1.0/train_times);\n\n    // 初始化当前解\n    vector&lt;double&gt; now_w(n, 0);\n    double now_b = 0;\n    \n    // 记录全局最优解（防止最后停在劣解上）\n    vector&lt;double&gt; best_w = now_w;\n    double best_b = now_b;\n    double min_loss = 1e18;\n\n    // 当前的学习率\n    double lr = init_lr;\n\n    // === SA-GD 主循环 ===\n    for (int iter = 1; iter &lt;= train_times; iter++){\n        // 1. 计算当前状态的预测和能量\n        vector&lt;double&gt; current_preds = predict(now_w, now_b);\n        double current_loss = calc_energy(current_preds);\n\n        // 更新全局最优\n        if (current_loss &lt; min_loss) {\n            min_loss = current_loss;\n            best_w = now_w;\n            best_b = now_b;\n        }\n\n        // 2. 计算梯度 (理性的方向)\n        auto grads = calc_gradient(current_preds);\n        \n        // 3. 生成新解 (梯度下降 + 随机噪声)\n        vector&lt;double&gt; next_w = now_w;\n        double next_b = now_b;\n        \n        // 噪声系数随温度降低而减小\n        double noise_scale = T * lr * 5.0; \n\n        for(int j=0; j&lt;n; j++) {\n            // 梯度项 + 噪声项\n            double noise = (dist(rng) * 2 - 1) * noise_scale; \n            next_w[j] = now_w[j] - lr * grads.first[j] + noise;\n        }\n        double noise_b = (dist(rng) * 2 - 1) * noise_scale;\n        next_b = now_b - lr * grads.second + noise_b;\n\n        // 4. 计算新解的能量\n        vector&lt;double&gt; next_preds = predict(next_w, next_b);\n        double next_loss = calc_energy(next_preds);\n        double delta_E = next_loss - current_loss;\n\n        // 5. Metropolis 准则 (SA的核心)\n        if (delta_E &lt; 0) {\n            // 新解更好，接受\n            now_w = next_w;\n            now_b = next_b;\n        } else {\n            // 新解更差，概率接受 (跳出局部最优)\n            if (exp(-delta_E / T) &gt; dist(rng)) {\n                now_w = next_w;\n                now_b = next_b;\n            }\n        }\n\n        // 6. 协同衰减\n        T *= decayT;\n        // 学习率也可以随温度衰减，以便后期精细收敛\n        // lr *= 0.999; \n    } \n\n    // 输出全局最优解\n    for (int i=0; i&lt;n; i++){\n        printf(\"%.2lf \", best_w[i]); \n    }\n    printf(\"%.2lf\\n\", best_b); \n\n    return 0;\n}\n</code></pre>\n<hr />\n<h2 id=\"四实用调参指南\">四、实用调参指南</h2>\n<p>SA-GD 虽然强大，但参数也更多了。以下是“炼丹”心得：</p>\n<ol>\n<li>\n<p><strong>关于噪声系数</strong>：<br />\n代码中的 <code>noise_scale</code> 极其重要。</p>\n<ul>\n<li>如果太小，算法退化成纯梯度下降，跳不出坑。</li>\n<li>如果太大，噪声淹没了梯度信息，算法退化成纯随机乱跑。</li>\n<li><em>经验法则</em>：噪声的量级在初期应该能让解产生明显的坐标偏移，但不至于飞出地图边界。</li>\n</ul>\n</li>\n<li>\n<p><strong>关于学习率 <span class=\"math inline\">\\(\\eta\\)</span></strong>：</p>\n<ul>\n<li>这里的学习率不仅控制步长，还配合梯度的数值大小。如果梯度值很大（如物理引力问题在近距离时），学习率要设极小（如 <span class=\"math inline\">\\(10^{-3}\\)</span>），否则就算找对地方也有可能因为步长太大跳过去。</li>\n</ul>\n</li>\n<li>\n<p><strong>多点启动（Restart）</strong>：<br />\n对于非凸的极难问题，不要指望一次SA-GD就能成。随机生成10个不同的初始坐标，跑10次算法，最后取最好的那个。这是工程上最稳的策略。</p>\n</li>\n</ol>\n<h2 id=\"五总结\">五、总结</h2>\n<ol>\n<li><strong>模拟退火（SA）</strong>：靠随机游走，概率性接受劣解，拥有全局视野，但收敛慢。</li>\n<li><strong>梯度下降（GD）</strong>：靠学习率和导数值，贪心逼近极值，速度快但容易掉坑。</li>\n<li><strong>SA-GD 混合</strong>：在梯度下降的理性步伐中，混入随温度衰减的随机噪声。<strong>用梯度保证效率，用噪声保证可逆性</strong>。</li>\n</ol>\n<p>下次再遇到让人头秃的黑箱优化问题，不妨试试给你的梯度下降加个模拟退火，说不定有奇效！</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 16:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/reasa\">reasa</a>&nbsp;\n阅读(<span id=\"post_view_count\">36</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "《让子弹飞》之\"插入排序办公室\"风云",
      "link": "https://www.cnblogs.com/lixingqiu/p/19570172",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lixingqiu/p/19570172\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 16:31\">\n    <span>《让子弹飞》之\"插入排序办公室\"风云</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h2><img alt=\"插入排序算法可视化演示程序-封面\" class=\"lazyload\" height=\"236\" width=\"133\" /></h2>\n<p><span style=\"font-size: 1.5em;\">先看视频，更好理解：</span><a href=\"https://www.douyin.com/video/7602545031836093731\" rel=\"noopener nofollow\" style=\"font-size: 1.5em;\" target=\"_blank\">https://www.douyin.com/video/7602545031836093731</a></p>\n<h2>&nbsp;</h2>\n<h2>第一幕：乱序入职</h2>\n<p><img alt=\"插入01\" class=\"lazyload\" height=\"63\" width=\"241\" /></p>\n<p>&nbsp;</p>\n<div class=\"paragraph\">场景：鹅城政务大厅，一群五颜六色的大小圆圈正在排队办入职手续。</div>\n<div class=\"paragraph\">张麻子（<code class=\"segment-code-inline\">rocket</code>）拿着喇叭喊：\"都给老子站好！从左边开始，小的站前面，大的站后面！\"</div>\n<div class=\"paragraph\">结果现场一片混乱——红色的块头小却站在最左边，青色的体积最大却夹在C位，紫色的却委曲的蹲在最右边...</div>\n<div class=\"paragraph\">旁白：这就是你的 <code class=\"segment-code-inline\">datas</code> 向量，一群 <code class=\"segment-code-inline\">Node</code> 结构体，带着各自的 <code class=\"segment-code-inline\">value</code>（体重）和 <code class=\"segment-code-inline\">sp</code>（ Sprite 造型），在 <code class=\"segment-code-inline\">startX</code> 坐标处傻站着。</div>\n<hr />\n<h2>第二幕：\"关键先生\"登场</h2>\n<div class=\"paragraph\">张麻子（指着 <code class=\"segment-code-inline\">ptr</code> 粉色箭头）：\"你！从第二个开始，一个个往前审！\"</div>\n<div class=\"paragraph\">马邦德（指着正在颤抖的橙圆圈）：\"大人，这橙圈在抖什么？\"</div>\n<div class=\"paragraph\">张麻子：\"<code class=\"segment-code-inline\">tremble()</code> 懂不懂？这叫'紧张'！它发现自己 <code class=\"segment-code-inline\">value</code> 可能不对，正在怀疑人生！\"</div>\n<div class=\"paragraph\">这时候，橙圆圈被标记为 <code class=\"segment-code-inline\">key</code> ——关键先生临时出局，手里攥着自己的 <code class=\"segment-code-inline\">value</code>，心里嘀咕：\"老子该站哪儿？\"</div>\n<blockquote>\n<div class=\"paragraph\">💡 插入排序精髓第一步：先抽出来，别急着站队！</div>\n</blockquote>\n<hr />\n<h2>第三幕：往后挪！都给老子往后挪！</h2>\n<div class=\"paragraph\">名场面复刻：</div>\n<div class=\"paragraph\">张麻子掏出枪（代码里的 <code class=\"segment-code-inline\">while</code> 循环），对着前面已经排好的队伍：</div>\n<div class=\"segment-code\">\n<div class=\"syntax-highlighter light segment-code-content\">\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">while<span class=\"token punctuation\">(j<span class=\"token operator\">&gt;=<span class=\"token number\">0 <span class=\"token operator\">&amp;&amp; key<span class=\"token operator\">-&gt;value <span class=\"token operator\">&lt; datas<span class=\"token punctuation\">[j<span class=\"token punctuation\">]<span class=\"token operator\">-&gt;value<span class=\"token punctuation\">)<span class=\"token punctuation\">{\n    <span class=\"token function\">movebackward<span class=\"token punctuation\">(j<span class=\"token punctuation\">)<span class=\"token punctuation\">;   <span class=\"token comment\">// 给我往后退！\n    j<span class=\"token operator\">--<span class=\"token punctuation\">;\n<span class=\"token punctuation\">}</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>\n</div>\n</div>\n<div>&nbsp;</div>\n<div class=\"paragraph\">橙圈往前一看：前面的红圈 <code class=\"segment-code-inline\">value</code> 比我大？</div>\n<div class=\"paragraph\">张麻子：\"红圈！<code class=\"segment-code-inline\">movebackward(0)</code>！你，往后挪一位！\"</div>\n<div class=\"paragraph\">红圈一脸懵逼地执行 <code class=\"segment-code-inline\">go(newX, -50)</code>，骂骂咧咧地滑到了索引 1 的位置。</div>\n<div class=\"paragraph\">橙圈再往前看：前面没有了（j==0了)</div>\n<div class=\"paragraph\">于是橙圈兴高采列的滑到了索引为0的位置。</div>\n<blockquote>\n<div class=\"paragraph\">💡 插入排序精髓第二步：<span>前面比咱大的，统统后移让位！ 这不是谦让，是算法暴力！</span></div>\n</blockquote>\n<hr />\n<h2>&nbsp;</h2>\n<h2>第四幕：周而复始，鹅城太平</h2>\n<div class=\"paragraph\">接下来，其它颜色的蓝圈、紫圈、粉圈依次被枪（&nbsp;<code class=\"segment-code-inline\">ptr</code> 箭头)指到，重复这套\"抽出来→前面大的后退→插入正确位置\"的流程。</div>\n<div class=\"paragraph\">汤师爷（看着最后排好的队伍）：\"县长，这算法为什么叫'插入'啊？\"</div>\n<div class=\"paragraph\">张麻子（吐烟圈）：\"因为每个人都是插入到已经排好的队伍里，就像插秧！不是冒泡那种换来换去的笨办法，也不是快排那种分而治之的洋玩意儿。\"</div>\n<div class=\"paragraph\">张麻子（指着代码）：\"看见没？<code class=\"segment-code-inline\">for(int i=1; i&lt;n; i++)</code>，从第二个开始，因为第一个默认就有序——一个人的队伍当然是有序的！\"</div>\n<hr />\n<h2>大结局：ptr 退场，全体立正！</h2>\n<div class=\"segment-code\">\n<div class=\"segment-code-header-content\"><span class=\"segment-code-lang\"><span class=\"segment-code-lang\">cpp</span></span>\n<div class=\"simple-button size-medium\"><span>复制</span></div>\n</div>\n<div class=\"syntax-highlighter light segment-code-content\">\n<pre class=\"language-cpp\"><code class=\"language-cpp\">ptr<span class=\"token punctuation\">.<span class=\"token function\">hide<span class=\"token punctuation\">(<span class=\"token punctuation\">)<span class=\"token punctuation\">;  <span class=\"token comment\">// 粉色箭头功成身退\nrocket<span class=\"token punctuation\">.<span class=\"token function\">write<span class=\"token punctuation\">(<span class=\"token string\">\"演示完毕！\"<span class=\"token punctuation\">,<span class=\"token number\">42<span class=\"token punctuation\">)<span class=\"token punctuation\">.<span class=\"token function\">done<span class=\"token punctuation\">(<span class=\"token punctuation\">)<span class=\"token punctuation\">;  </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></code></pre>\n</div>\n</div>\n<div>&nbsp;</div>\n<div class=\"paragraph\">所有圆圈按 <code class=\"segment-code-inline\">value</code> 从小到大，红橙黄绿青蓝紫，像彩虹一样整齐。</div>\n<div class=\"paragraph\">汤师爷：\"县长，这算法复杂度...\"</div>\n<div class=\"paragraph\">张麻子：\"最坏情况 <span class=\"katex-wrapper\"><span class=\"katex-container\"><span class=\"katex\"><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\"><span class=\"mord mathnormal\">O<span class=\"mopen\">(<span class=\"mord\"><span class=\"mord mathnormal\">n<span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\"><span class=\"pstrut\"><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2<span class=\"mclose\">) ，最好 <span class=\"katex-wrapper\"><span class=\"katex-container\"><span class=\"katex\"><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\"><span class=\"mord mathnormal\">O<span class=\"mopen\">(<span class=\"mord mathnormal\">n<span class=\"mclose\">) ！但你别管，站着把钱挣了，就是优雅！\"</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></div>\n<hr />\n<h2>后记：中心思想总结</h2>\n<blockquote>\n<div class=\"paragraph\">插入排序就像张麻子整编鹅城保安队——</div>\n<ol start=\"1\">\n<li>\n<div class=\"paragraph\">抓一个出来（<code class=\"segment-code-inline\">key = datas[i]</code>）</div>\n</li>\n<li>\n<div class=\"paragraph\">前面块头大的统统后退（<code class=\"segment-code-inline\">movebackward</code> 循环）</div>\n</li>\n<li>\n<div class=\"paragraph\">按个头插到该站的位置（<code class=\"segment-code-inline\">placekey</code>）</div>\n</li>\n<li>\n<div class=\"paragraph\">前面队伍永远有序，后面逐个加入</div>\n</li>\n</ol>\n<div class=\"paragraph\">核心口诀：抽、退、插，三步走，前面有序后面凑！</div>\n</blockquote>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-03 16:31</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lixingqiu\">李兴球</a>&nbsp;\n阅读(<span id=\"post_view_count\">23</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "字符编码知多少(二)",
      "link": "https://www.cnblogs.com/lmy5215006/p/19567495",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lmy5215006/p/19567495\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 16:14\">\n    <span>字符编码知多少(二)</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"bom头\">BOM头</h1>\n<p>BOM头全程Byte Order Mark (字节顺序标记), 是Unicode编码标准中，最早是用于UTF32/16中标识字节顺序的特殊字符，后来随着UTF-8的出现，为了兼容，又有了标识文本编码格式的作用。</p>\n<blockquote>\n<p>最初主要是为了解决UTF32/16编码方案中大小端的问题，(大端BE：高字节在前，小端LE：低字节在前)。所以需要在字符串前增加一个特殊标记，以方便识别解析。<br />\n随着UTF-8的出现，不再需要BOM头。但微软为了方便自家软件能快速区分UTF-8与ANSI编码，而额外引入了<code>非标准拓展</code>。因此有了独特的UTF-8 BOM 编码方式</p>\n</blockquote>\n<hr />\n<h2 id=\"不同unicode编码中的bom头表现\">不同Unicode编码中的BOM头表现</h2>\n<table>\n<thead>\n<tr>\n<th>编码格式</th>\n<th>BOM头字节序列</th>\n<th>长度</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>UTF-8 BOM (微软特色)</td>\n<td><strong>EF BB BF</strong></td>\n<td>3字节</td>\n<td>仅作编码标识，无字节顺序问题</td>\n</tr>\n<tr>\n<td>UTF-8</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>UTF-16 BE（大端）</td>\n<td><strong>FE FF</strong></td>\n<td>2字节</td>\n<td>表示高位字节在前</td>\n</tr>\n<tr>\n<td>UTF-16 LE（小端）</td>\n<td><strong>FF FE</strong></td>\n<td>2字节</td>\n<td>表示低位字节在前</td>\n</tr>\n<tr>\n<td>UTF-32 BE</td>\n<td><strong>00 00 FE FF</strong></td>\n<td>4字节</td>\n<td>表示高位字节在前</td>\n</tr>\n<tr>\n<td>UTF-32 LE</td>\n<td><strong>FF FE 00 00</strong></td>\n<td>4字节</td>\n<td>表示低位字节在前</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"眼见为实\">眼见为实</h2>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<blockquote>\n<p>使用文本编辑器，选择另存为，保存为不同的编码方案</p>\n</blockquote>\n<pre><code>        public static void Run()\n        {\n            var utf8_path = @\"C:\\Users\\liu\\Documents\\utf-8.txt\";\n            var utf8_bom_path = @\"C:\\Users\\liu\\Documents\\utf-8 bom.txt\";\n            var utf16_le_path = @\"C:\\Users\\liu\\Documents\\utf-16 be.txt\";\n            var utf16_be_path = @\"C:\\Users\\liu\\Documents\\utf-16 le.txt\";\n\n            var utf8= BitConverter.ToString(File.ReadAllBytes(utf8_path));\n            Console.WriteLine(\"utf8 无bom: \"+utf8 +\"\\n\");\n\n            var utf8_bom= BitConverter.ToString(File.ReadAllBytes(utf8_bom_path));\n            Console.WriteLine(\"utf8 有bom: \"+utf8_bom + \"\\n\");\n\n            var utf16_le= BitConverter.ToString(File.ReadAllBytes(utf16_le_path));\n            Console.WriteLine(\"utf-16 be大端: \"+utf16_le + \"\\n\");\n\n            var utf16_be = BitConverter.ToString(File.ReadAllBytes(utf16_be_path));\n            Console.WriteLine(\"utf-16 le小端: \"+utf16_be + \"\\n\");\n        }\n</code></pre>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h1 id=\"为什么utf-8不需要bom\">为什么UTF-8不需要BOM</h1>\n<p>BOM的本质是为了解决UTF-16/32大小端歧义的问题，而UTF8的编码特性<code>从根本上解决了BOM要处理问题</code>，所以BOM对UTF-8而言既无必要，而且还属于\"额外附加\"的内容。</p>\n<h2 id=\"utf-1632为什么需要\">UTF-16/32为什么需要</h2>\n<p>假如我要传输一个字符串“中“，Unicode编码：U+4E2D，在我传输给你的过程中，它可以是FE-FF-4E-2D（大端），也可以是FF-FE-2D-4E(小端)，如果我没有标识字节顺序，你如何解析？</p>\n<h2 id=\"utf-8-核心编码规则\">UTF-8 核心编码规则</h2>\n<p>要想知道为什么UTF-8不需要BOM，先从它的原理开始说起。</p>\n<ol>\n<li>可变长编码<br />\n用1-4个字节表示一个Unicode字符，码点越小，占用的字节数越小。</li>\n<li>标准的字节格式<br />\n每个字符的起始字节，会有一个<code>特殊标识</code>来表示该字符占用的总字节数，后续的字节用<code>固定格式</code>来表示，相当于有一个标准模板来定义UTF-8字符。</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>字符占用字节数</th>\n<th>起始字节二进制格式</th>\n<th>续字节二进制格式</th>\n<th>可表示的Unicode码点范围</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1字节</td>\n<td><code>0xxxxxxx</code></td>\n<td>无续字节</td>\n<td><code>U+0000</code> ~ <code>U+007F</code></td>\n<td>对应ASCII字符</td>\n</tr>\n<tr>\n<td>2字节</td>\n<td><code>110xxxxx</code></td>\n<td><code>10xxxxxx</code></td>\n<td><code>U+0080</code> ~ <code>U+07FF</code></td>\n<td>欧洲、中东等字符</td>\n</tr>\n<tr>\n<td>3字节</td>\n<td><code>1110xxxx</code></td>\n<td><code>10xxxxxx</code></td>\n<td><code>U+0800</code> ~ <code>U+FFFF</code></td>\n<td>中文、日文、韩文等常用字符</td>\n</tr>\n<tr>\n<td>4字节</td>\n<td><code>11110xxx</code></td>\n<td><code>10xxxxxx</code></td>\n<td><code>U+10000</code> ~ <code>U+10FFFF</code></td>\n<td>罕见字符、emoji等</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"眼见为实以中举例\">眼见为实，以\"中\"举例</h3>\n<ol>\n<li>确定字节数<br />\n\"中\"这个字符的码点为<code>U+4E2D</code>，在<code>U+0800~U+FFFF</code>范围内，占用 3 字节。</li>\n<li>十六进制转换成二进制<br />\n<code>4E2D</code>转成二进制，得到<code>0100 1110 0010 1101</code><br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>按照UTF-8模板格式填充<br />\n已知占用3字节，模板格式为：<code>1110xxxx</code> <code>10xxxxxx</code> <code>10xxxxxx</code> (起始字节+2个续字节)<br />\n-----------得到UTF-8编码<code>11100100</code> <code>10111000</code> <code>10101101</code></li>\n<li>二进制转换成十六进制<br />\n<code>11100100</code> =&gt; <code>0xE4</code><br />\n<img alt=\"image\" class=\"lazyload\" /><br />\n<code>10111000</code> =&gt; <code>0xB8</code><br />\n<img alt=\"image\" class=\"lazyload\" /><br />\n<code>10101101</code> =&gt; <code>0xAD</code><br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n</ol>\n<p>最终\"中\"这个字符的UTF-8编码序列是<code>E4 B8 AD</code> ，也就是我们日常中经常看到的UTF-8 十六进制表示<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"眼见为实以a举例\">眼见为实，以\"A\"举例</h3>\n<ol>\n<li>确定字节数<br />\n\"A\"的码点为<code>U+0041</code>，在<code>U+0000~U+007F</code>访问内，占用1字节。</li>\n<li>十六进制转换成二进制<br />\n<code>0041</code>转成二进制，得到<code>0100 0001</code><br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>按照UTF-8模板格式填充<br />\n1字节的模板格式为:<code>0xxxxxxx</code> (起始字节)<br />\n----得到UTF-8编码:<code>01000001</code></li>\n<li>二进制转换成十六进制<br />\n实际上又转换回来，又变回了<code>0041</code>。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<blockquote>\n<p>UTF-8 以一种很<code>偷鸡又巧妙</code>的办法 ，实现了与ASCII的兼容。<br />\n因为ASCII只占用7bit，最高位默认为0，而UTF-8，1字节的模板也是0xxxxxxx ，从而实现了与ASCII的兼容</p>\n</blockquote>\n<h2 id=\"回到主题\">回到主题</h2>\n<ol>\n<li>\n<p>UTF-8 不存在大小端问题<br />\n由于UTF-8的可变长编码与标准的字节格式，所以每个字符的格式是固定的，有明确的先后顺序。<br />\n比如\"中\"的U+4E2D，UTF-8编码是<code>E4-B8-AD</code>， 这三个字节的顺序是唯一且固定的，解析时如果顺序颠倒，就会解析失败，所以不用管大端还是小端，严格按照顺序解析即可。</p>\n</li>\n<li>\n<p>UTF-8能够自我解析/识别，无需BOM作为签名<br />\nBOM 还有一个附加作用：作为文件编码的 “签名”，帮助软件快速识别 Unicode 编码格式。但对于 UTF-8 而言，这种 “签名” 也是多余的。<br />\n因为解析软件可以通过扫描文本的二进制内容，根据UTF-8的格式规则，（上面提到的<code>0xxxxxxx</code>、<code>110xxxxx</code>等），直接判断文件是否为 UTF-8 编码，无需依赖文件开头的 BOM 标记</p>\n</li>\n</ol>\n<h1 id=\"为什么有utf-8-bom的存在\">为什么有UTF-8 BOM的存在？</h1>\n<p>UTF-8 BOM并非Unicode官方标准，而是微软为<code>解决兼容问题而留下的历史包袱</code>。<br />\n早期的Windows默认编码是 <strong>本地化ANSI</strong>，它是Windows早期为适配本地语言设计的历史编码方案，它千好万好，为windows全球化立下了汗马功劳，但有一个致命的缺点，<code>文件开头没有任何特殊标识</code>。</p>\n<blockquote>\n<p>比如中文系统默认 GBK/GB2312，英文系统默认 ISO-8859-1，日文系统默认 Shift_JIS—— 这些 ANSI 编码都是无标记的多字节编码，和 UTF-8 一样，文件开头没有任何特殊标识。<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n</blockquote>\n<h2 id=\"眼见为实-1\">眼见为实</h2>\n<p>比如用户在记事本中写了字符\"中\"，保存为 UTF-8（无 BOM），下次打开时，记事本没有任何标记可以判断这是 UTF-8，可能会按照<strong>系统ANSI</strong> ，比如GBK来解析，导致出现乱码。<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<h1 id=\"为什么中文在utf-16下占用2字节反而在utf-8中占用3字节了\">为什么中文在UTF-16下占用2字节，反而在UTF-8中占用3字节了？</h1>\n<p><strong>简单来说，就是运气问题，UTF-8 的字节数是按码点容量分层设计的，中文的码点大小决定了它只能落在 3 字节区间。</strong><br />\n我们日常使用的 99% 以上的中文，码点都在BMP 平面的<code>U+4E00（一）~U+9FA5（龥）</code> 区间，<br />\n而UTF-16的编码规则是，对BMP平面字符直接<code>用2字节编码</code>,对SMP平面<code>用4字节编码</code>。而<code>刚好落在BMP的中文码点</code>自然而然的就使用2字节编码<br />\n但UTF-8的编码规则是根据Unicode 码点的大小来决定字节数，而中文的<code>U+4E00~U+9FA5</code> 刚好落在了<code>U+0800 ~ U+FFFF</code>这个3字节码点的区间内，因此要遵守3字节编码的规则。</p>\n<h2 id=\"为什么utf-8不把中文设计为2字节\">为什么UTF-8不把中文设计为2字节？</h2>\n<p>主要是2字节的UTF-8区间<code>U+0080 ~ U+07FF</code>容量有限，装不下这么多中文。<br />\n2字节的UTF-8 去掉前面的110，10 标识位，只剩下5+6=11位的有效容量，只能表示2^11=2048个码点，容纳不下中文。只有3字节的有效容量是4+6+6=16 ，可以表示2^16=65536个码点，刚好覆盖整个 BMP 平面，足以容纳所有中文常用字。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 16:14</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lmy5215006\">叫我安不理</a>&nbsp;\n阅读(<span id=\"post_view_count\">82</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第三周：序列模型与注意力机制（四）语音识别和触发字检测",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19569924",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19569924\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 16:03\">\n    <span>吴恩达深度学习课程五：自然语言处理  第三周：序列模型与注意力机制（四）语音识别和触发字检测</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课第三周的内容，<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=181\" rel=\"noopener nofollow\" target=\"_blank\">3.9</a>到<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=182\" rel=\"noopener nofollow\" target=\"_blank\">3.10</a>的内容，同时也是本周理论部分的最后一篇。</p>\n<hr />\n<p>本周为第五课的第三周内容，与 CV 相对应的，这一课所有内容的中心只有一个：<strong>自然语言处理（Natural Language Processing，NLP）</strong>。<br />\n应用在深度学习里，它是专门用来进行<strong>文本与序列信息建模</strong>的模型和技术，本质上是在全连接网络与统计语言模型基础上的一次“结构化特化”，也是人工智能中<strong>最贴近人类思维表达方式</strong>的重要研究方向之一。<br />\n<strong>这一整节课同样涉及大量需要反复消化的内容，横跨机器学习、概率统计、线性代数以及语言学直觉。</strong><br />\n语言不像图像那样“直观可见”，更多是抽象符号与上下文关系的组合，因此<strong>理解门槛反而更高</strong>。<br />\n因此，我同样会尽量补足必要的背景知识，尽可能用比喻和实例降低理解难度。<br />\n本周的内容关于<strong>序列模型和注意力机制</strong>，这里的序列模型其实是<strong>指多对多非等长模型</strong>，这类模型往往更加复杂，其应用领域也更加贴近工业和实际，自然也会衍生相关的模型和技术。而注意力机制则让模型在长序列中学会主动分配信息权重，而不是被动地一路传递。二者结合，为 Transformer 等现代架构奠定了基础。</p>\n<p>本篇的内容关于<strong>语音识别和触发字检测</strong>，是 seq2seq 模型在音频数据上的应用。</p>\n<h1 id=\"1-音频数据audio-data\">1. 音频数据（Audio data）</h1>\n<p>音频数据虽然和文本数据同样都为序列数据，但是如果我们希望实现相关的应用，所寻找到的数据集样本往往都是<strong>一段段连续的录音</strong>，无法直接输入模型。<br />\n因此，就像为文本数据构建词典一样，在使用 seq2seq 模型完成在语音领域的任务时，我们同样需要对音频数据进行预处理，而这就涉及到音频数据本身的特点。</p>\n<h2 id=\"11-音位phoneme\">1.1 音位（Phoneme）</h2>\n<p>在展开音频数据的预处理方式之前，有必要先引入一个语言学中的概念：<strong>音位（phoneme）</strong>。</p>\n<p>音位是一种<strong>抽象的语音单位</strong>，其定义并非基于声学相似性，而是基于<strong>是否能够区分词义</strong>。<br />\n在某一语言中，如果两个发音单元的替换会导致词义变化，它们就属于不同的音位；反之，即使在物理发音上存在差异，只要不影响词义，它们仍被视为同一音位。<br />\n换句话说，音位关心的是<strong>语言系统内部能区分意义的功能</strong>，而不是具体的发音表现。</p>\n<p>通过大量对比，语言学家逐步归纳出某一语言的音位系统。<strong>在英语中，音位通常借助音标来表示，但音标与音位又并不等同</strong>：音标只是描述发音的工具，而音位是一种功能性分类结果。同一个音位在不同语音环境中可能呈现略有不同的实际发音形式（如口音差异），但只要这些差异不承担区分语义的功能，它们仍被视为同一音位的不同实现。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202602/3708248-20260203155945196-1250283629.png\" /><br />\n这便是音位的基本概念，到这里，一个自然而然的想法就是<strong>把音频数据处理为连续的音位序列</strong>，就像文本数据一样进行处理输入模型。<br />\n然而，我们刚刚也提到了，音位虽然可以代表语义，但是<strong>这是我们人为归纳的特征而不是音频本身的属性</strong>。因此，在实验中，<strong>音位并不是可以直接从连续的音频波形中观测得到的量</strong>。<br />\n其获取过程高度依赖<strong>人工标注</strong>、规则设计或复杂的对齐模型，这也在实践中限制了其作为模型直接输入的可行性。<br />\n这一现实，直接推动了后续更偏向信号层面的语音表示方法的发展，也为声谱图等特征形式的广泛应用奠定了背景。</p>\n<h2 id=\"12-声谱图spectrogram\">1.2 声谱图（Spectrogram）</h2>\n<p>由于音位是人为抽象的单位，无法直接从连续的音频波形中观测得到，因此在实际语音处理与建模中，我们更倾向于使用<strong>信号层面的连续特征表示</strong>，其中最常用的表示方式之一就是<strong>声谱图（spectrogram）</strong>。</p>\n<p>声谱图是一种将音频信号在<strong>时间与频率域</strong>上进行表示的二维图像。<br />\n简单来说，它将连续的音频波形分割为短时片段，并对每个片段计算频谱能量，从而得到<strong>时间-频率矩阵</strong>，矩阵中的每个值反映该时刻该频率成分的强度，就像这样：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202602/3708248-20260203155952737-472972628.png\" /></p>\n<p>通过这种方式，原本<strong>连续的波形被转换为一组能够揭示语音细节的特征</strong>，既保留了声音的动态变化，也便于计算机处理。<br />\n在计算机处理时，声谱图的每一列包含该时间片段所有频率的能量值，可以看作一个多维向量。因此，我们通常<strong>把声谱图的每一列视为一个时间步的输入向量</strong>。<br />\n这样，原本二维的时间-频率矩阵就被转化为<strong>时间序列的特征向量序列</strong>，与文本序列类似，使模型能够在连续语音中捕捉语义和声学模式。</p>\n<p>声谱图的关键优势在于<strong>无需人工标注音位的同时保留了丰富的声学信息，并且其二维矩阵形式可以直接作为模型输入</strong>，实现端到端语音识别、声学建模或语音生成。<br />\n了解了对音频数据的基本处理逻辑后，现在就来看看其应用：</p>\n<h1 id=\"2-语音识别speech-recognition\">2. 语音识别（Speech Recognition）</h1>\n<p>对音频数据最常见的应用领域就是语音识别。生活中，我们最常用的例子可能是微信的语音转文字，也包括语音助手、电话客服的语音输入等。<br />\n语音识别的核心任务是<strong>将连续的音频信号映射为文字序列</strong>。由于音频本身是连续信号，而文字序列是离散符号序列，因此，这一任务本质上也是一个 <strong>seq2seq 问题</strong>。<br />\n一个主流且常见的训练方式就是应用我们刚刚介绍的带<a href=\"https://www.cnblogs.com/Goblinscholar/p/19563950\" target=\"_blank\">注意力机制</a>的编码解码框架：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202602/3708248-20260203155927580-326667711.png\" /><br />\n此外，还存在一种独特的技术，我们称为 <strong>CTC（Connectionist Temporal Classification）</strong> 。<br />\nCTC 是一种<strong>专门用于处理输入输出长度不匹配的序列学习方法</strong>，非常适合语音识别这样的任务。它的核心思想是：<strong>允许模型在连续的时间步上输出“空白”或重复符号，从而自动对齐输入序列与输出序列</strong>。<br />\n它提出于 06 年的一篇论文：<a href=\"https://sferics.idsia.ch/pub/juergen/icml2006.pdf\" rel=\"noopener nofollow\" target=\"_blank\">Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks</a><br />\n可以发现，CTC 的提出较早，因此也并没有使用编码解码框架，而是<strong>等长多对多模型</strong>框架。不过如今 CTC 也并没有被完全淘汰，它仍常见于一些混合方案中。<br />\n我们简单展开如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202602/3708248-20260203155951242-1300096674.png\" /><br />\n再复述一下其核心思想： CTC 通过引入 <strong>blank（空白）符号</strong> 和 <strong>重复合并规则</strong> 来对齐输入与输出，来实现端到端训练，无需在标签中人工对齐每一帧。<br />\n当然，你也会发现它对长距离依赖建模能力有限，对长句子性能很大可能不如注意力机制，了解即可。</p>\n<h1 id=\"3-触发字检测trigger-word-detection--keyword-spotting\">3. 触发字检测（Trigger Word Detection / Keyword Spotting）</h1>\n<p>对于触发字检测我们也并不陌生，生活中最常见的例子包括语音助手的唤醒词“Hey Siri”“小爱同学”“Alexa”，只有检测到这些触发词后，设备才会进入完整语音识别流程。</p>\n<p>不同于语音识别，触发字检测任务更为精简，它在建模中关注的问题是：<strong>在连续语音流中，判断某个特定关键词是否被说出，以及它出现的大致时间位置。</strong><br />\n因此，一个关键点在于：<strong>触发字检测模型因其实时性更适合多对多等长模型，模型每个时间帧预测一个触发概率或二分类信号，表示当前帧是否属于触发词的一部分。</strong><br />\n简单展开如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202602/3708248-20260203155928163-1676940697.png\" /><br />\n传播过程并不复杂，但有一点需要注意：<strong>触发字检测的任务特征决定了其数据往往是不平衡的</strong>，即绝大多数标签都为 0 ，这导致即使模型全部输出 0 ，也能得到较好的指标，从而导致错误判断和部署。<br />\n对此，一种常用缓解策略是<strong>扩展正样本标签</strong>：不仅将触发词对应的帧标记为 1，还将其之后若干帧也标记为 1，形成一个时间段的正样本窗口，这既平衡了样本，也符合实际触发的延迟容忍需求。</p>\n<p>总结来说，触发字检测本质是<strong>低延迟的序列二分类任务</strong>。建模逻辑为：<strong>先将音频转化为时间序列特征，再利用多对多等长模型预测每一帧的触发概率，也可通过平滑或滑窗处理得到最终触发决策</strong>。</p>\n<h1 id=\"4总结\">4.总结</h1>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>原理</th>\n<th>比喻</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>音位（Phoneme）</strong></td>\n<td>语言学中的抽象单位，基于是否能区分词义进行分类；同一音位在不同环境下可有不同发音，但功能相同。</td>\n<td>就像文字中的字母，不同字母组合产生不同单词，但同一字母在不同字体中仍表示相同字母。</td>\n</tr>\n<tr>\n<td><strong>声谱图（Spectrogram）</strong></td>\n<td>将音频分帧并计算每帧的频谱能量，得到时间-频率矩阵；每列作为时间步输入向量，用于模型训练。</td>\n<td>好比把连续的声音切成一格格“照片”，每格显示不同频率的亮度，连续播放形成动态影像。</td>\n</tr>\n<tr>\n<td><strong>语音识别（Speech Recognition）</strong></td>\n<td>将连续音频信号映射为文字序列，可用注意力编码解码框架处理 seq2seq 问题，也可用 CTC 进行端到端训练。</td>\n<td>就像把一段连续的河流水流（声音波形）逐段翻译成文字，注意力机制像有导游指引每段对应文字，CTC像自动对齐标记。</td>\n</tr>\n<tr>\n<td><strong>CTC（Connectionist Temporal Classification）</strong></td>\n<td>输入为时间序列特征；允许输出空白符和重复符号，通过合并规则对齐输出序列；无需逐帧标注。</td>\n<td>好比在长河上放置浮标（空白符），只标记关键节点，最后整理成整段文字。</td>\n</tr>\n<tr>\n<td><strong>触发字检测（Trigger Word Detection / Keyword Spotting）</strong></td>\n<td>输入音频转时间序列特征；多对多等长模型预测每帧触发概率；可通过标签扩展、平滑或滑窗处理缓解数据不平衡。</td>\n<td>就像警报系统监测连续流水声，只在听到特定声响（触发词）后报警，而非逐秒记录每滴水。</td>\n</tr>\n</tbody>\n</table>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 16:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">5</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Qt 技巧笔记 (五) Qt消息框（QMessageBox）的全面使用指南",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19569909",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19569909\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 15:55\">\n    <span>Qt 技巧笔记 (五) Qt消息框（QMessageBox）的全面使用指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"qt-技巧笔记-五---qt消息框qmessagebox的全面使用指南\">Qt 技巧笔记 (五)   Qt消息框（QMessageBox）的全面使用指南</h1>\n<p>​       在Qt框架开发中，消息框组件(QMessageBox) 是处理用户交互的核心工具。本笔记系统梳理了QMessageBox的6种预定义类型，静态调用与实例化调用的对比，自定义实现方法及常见问题解决方案，帮助开发者实现用户提示功能。</p>\n<p>​       <code>QMessageBox</code>是Qt中用于<strong>弹出对话框消息</strong>的类，继承于<span class=\"math inline\">\\(QDialog\\)</span>，常用于提示消息、警告、错误、确认等场景，是Qt GUI应用开发中非常常用的组件之一。用于弹出一个模式对话框（模态窗口），显示消息给用户，并等待用户点击按钮（如“确定”、\"取消\"、”是“、“否”等）后再继续程序执行。其核心特征是<strong>阻塞交互式</strong>，用户必须响应对话框（点击按钮）后，程序才会继续执行后续代码。</p>\n<p>​</p>\n<h2 id=\"11-预定义消息框类型\">1.1 预定义消息框类型</h2>\n<p>Qt提供6种标准消息类型，通过静态方法快速调用：</p>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>调用方法</th>\n<th>适用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>消息提示框</td>\n<td><code>QMessageBox::information()</code></td>\n<td>普通信息展示</td>\n</tr>\n<tr>\n<td>警告提示框</td>\n<td><code>QMessageBox::warning()</code></td>\n<td>操作风险警示</td>\n</tr>\n<tr>\n<td>错误提示框</td>\n<td><code>QMessageBox::critical()</code></td>\n<td>严重错误警示</td>\n</tr>\n<tr>\n<td>确认选择框</td>\n<td><code>QMessageBox::question()</code></td>\n<td>二选一决策</td>\n</tr>\n<tr>\n<td>关于对话框</td>\n<td>QMessageBox::about()</td>\n<td>应用信息扩展</td>\n</tr>\n<tr>\n<td>版本信息框</td>\n<td>QMessageBox::aboutQt()</td>\n<td>Qt版本说明</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>其典型调用案例：</p>\n<p>1.显示信息提示框（information）</p>\n<pre><code class=\"language-C++\">QMessageBox::information(this, \"标题\", \"这是一个信息提示框\");\n</code></pre>\n<p>2.警告窗（warning）</p>\n<pre><code class=\"language-C++\">QMessageBox::warning(this,\"警告\",\"这是一个警告框\");\n</code></pre>\n<p>3.错误框（critial）</p>\n<pre><code class=\"language-C++\">QMessageBox::critical(this,\"错误\",\"出现了严重的错误\");\n</code></pre>\n<p>4.提问框（question）</p>\n<pre><code class=\"language-C++\">    int ret = QMessageBox::question(nullptr, (\"MyNoteBook Notice:\"),\n                                    (\"The document has been modified.\\n\"\n                                     \"Do you want to save your changes?\"),\n                                    QMessageBox::Save | QMessageBox::Discard\n                                    | QMessageBox::Cancel, /*按钮的属性*/\n                                    QMessageBox::Save); /*默认按钮按下*/\n    switch (ret)\n    {\n    case QMessageBox::Save:\n        qDebug()&lt;&lt;\"QMessageBox::Save\";\n        break;\n    case QMessageBox::Discard:\n        qDebug()&lt;&lt;\"QMessageBox::Discard\";\n        break;\n    case QMessageBox::Cancel:\n        qDebug()&lt;&lt;\"QMessageBox::Cancel\";\n        break;\n     default:\n        break;\n    }\n</code></pre>\n<p>其中按钮类型（QMessage::StandardButton）</p>\n<table>\n<thead>\n<tr>\n<th>按钮枚举值</th>\n<th>显示内容</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>QMessageBox::Ok</code></td>\n<td>确定</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Cancel</code></td>\n<td>取消</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Yes</code></td>\n<td>是</td>\n</tr>\n<tr>\n<td><code>QMessageBox::No</code></td>\n<td>否</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Abort</code></td>\n<td>终止</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Retry</code></td>\n<td>重试</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Ignore</code></td>\n<td>忽略</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"12-静态调用与实例化调用对比\">1.2 静态调用与实例化调用对比</h2>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>静态调用</th>\n<th>实例化调用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>语法形式</td>\n<td><code>QMessageBox::type(parent, ...)</code></td>\n<td><code>QMessageBox box; box.setXXX(...)</code></td>\n</tr>\n<tr>\n<td>定制能力</td>\n<td>仅支持预设按钮/图标</td>\n<td>支持完整UI定制</td>\n</tr>\n<tr>\n<td>线程阻塞</td>\n<td>自动模态显示</td>\n<td>需手动调用exec()</td>\n</tr>\n<tr>\n<td>典型场景</td>\n<td>快速实现简单提示</td>\n<td>复杂交互需求</td>\n</tr>\n</tbody>\n</table>\n<p>其中图标定制类型如下：</p>\n<table>\n<thead>\n<tr>\n<th>图标类型</th>\n<th>含   义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>QMessageBox::NoIcon</code></td>\n<td>无图标</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Information</code></td>\n<td>信息图标（ℹ️）</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Warning</code></td>\n<td>警告图标（⚠）</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Critical</code></td>\n<td>错误图标（❌）</td>\n</tr>\n<tr>\n<td><code>QMessageBox::Question</code></td>\n<td>问号图标（❓）</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"13-深度定制实现方案\">1.3 深度定制实现方案</h2>\n<p>对话框的关键定制方法：</p>\n<table>\n<thead>\n<tr>\n<th>方法</th>\n<th>功能说明</th>\n<th>参数说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>setWindowTitle()</code></td>\n<td>设置对话框标题</td>\n<td><code>QString</code></td>\n</tr>\n<tr>\n<td><code>setText()</code></td>\n<td>设置主提示文本</td>\n<td><code>QString</code></td>\n</tr>\n<tr>\n<td>setIconPixmap()</td>\n<td>设置自定义图标</td>\n<td>QPixmap</td>\n</tr>\n<tr>\n<td>addButton()</td>\n<td>添加自定义按钮</td>\n<td>(QString, ButtonRole)</td>\n</tr>\n<tr>\n<td>setStyleSheet()</td>\n<td>应用CSS样式</td>\n<td>QString</td>\n</tr>\n</tbody>\n</table>\n<p>完整自定义示例：</p>\n<pre><code class=\"language-C++\">#include &lt;QMessageBox&gt;\n#include &lt;QPushButton&gt;\n#include &lt;QDebug&gt;\n\nvoid showCustomMessageBox() {\n    QMessageBox box;\n    box.setWindowTitle(\"自定义对话框\");\n    box.setText(\"请确认操作：\");\n    \n    // 添加自定义按钮\n    QPushButton *confirmBtn = box.addButton(\"确认\", QMessageBox::AcceptRole);\n    QPushButton *cancelBtn = box.addButton(\"取消\", QMessageBox::RejectRole);\n    \n    // 设置图标（支持缩放）\n    box.setIconPixmap(QPixmap(\":/icons/warning.png\").scaled(64, 64));\n    \n    // 样式定制\n    box.setStyleSheet(\n        \"QMessageBox { background-color: #f0f0f0; font-size: 14px; }\"\n        \"QPushButton { min-width: 80px; min-height: 30px; }\"\n    );\n    \n    box.exec();\n    \n    if (box.clickedButton() == confirmBtn) {\n        qDebug() &lt;&lt; \"用户点击了确认\";\n    } else {\n        qDebug() &lt;&lt; \"用户点击了取消\";\n    }\n}\n</code></pre>\n<h2 id=\"14-高级应用场景\">1.4 高级应用场景</h2>\n<p><strong>动态内容切换</strong></p>\n<pre><code class=\"language-C++\">void showDynamicMessage(bool isSuccess) {\n    QMessageBox box;\n    box.setWindowTitle(isSuccess ? \"操作结果\" : \"错误提示\");\n    box.setText(isSuccess ? \"操作成功完成\" : \"操作失败，请重试\");\n    box.setIcon(isSuccess ? QMessageBox::Information : QMessageBox::Critical);\n    box.exec();\n}\n</code></pre>\n<p><strong>多语言支持</strong></p>\n<pre><code class=\"language-C++\">void showLocalizedMessage(QLocale locale) {\n    QMessageBox box;\n    if (locale == QLocale::Chinese) {\n        box.setWindowTitle(\"提示\");\n        box.setText(\"确定要执行此操作吗？\");\n    } else {\n        box.setWindowTitle(\"Warning\");\n        box.setText(\"Are you sure to proceed?\");\n    }\n    box.exec();\n}\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 15:55</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">34</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}