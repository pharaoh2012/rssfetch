{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "Supertonic 部署与使用全流程保姆级指南（附已部署镜像）",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19453758",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19453758\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 19:57\">\n    <span>Supertonic 部署与使用全流程保姆级指南（附已部署镜像）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Supertonic开源工具Python版部署与使用指南 摘要：本文详细介绍了Supertonic(一款语音处理工具)Python版本的完整部署流程，包括服务器环境准备、源码下载、依赖安装、常见报错解决方法等关键步骤。部署成功后，用户只需修改示例脚本中的文本内容，即可生成对应的音频结果文件。文章还提供了已部署镜像的获取方式，帮助用户快速上手。部署过程中需注意模型自动下载、依赖版本冲突等常见问题。通过本指南，用户可以快速完成Supertonic的环境搭建并开始使用其核心功能。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>Supertonic 是一款实用的开源工具（注：可根据实际补充Supertonic的核心功能，如语音合成/处理等），本文将详细讲解其 Python 版本的完整部署流程、日常使用方法，并附上我已部署好的镜像链接，帮大家快速上手。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h1 id=\"一部署前准备\">一、部署前准备</h1>\n<ol>\n<li>服务器环境要求：已安装 Python 3.7+（推荐3.8-3.10）、pip 工具，确保服务器有基础的网络访问权限；</li>\n<li>工具准备：本地电脑（或服务器）可通过 <code>scp</code>/<code>rz</code>/<code>sftp</code> 等方式传输文件到服务器。<br />\n<strong>我的服务器是在星图上面租的4090，1.46元一小时，相对来说还是很便的</strong><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></li>\n</ol>\n<h1 id=\"二完整部署步骤\">二、完整部署步骤</h1>\n<h2 id=\"步骤1从github下载源码包\">步骤1：从GitHub下载源码包</h2>\n<p>首先在本地或服务器直接下载 Supertonic 的 Python 版本源码，GitHub 地址（请替换为实际地址）：</p>\n<pre><code class=\"language-bash\"># 方式1：服务器直接git克隆（推荐）\ngit clone https://github.com/supertone-inc/supertonic\n\n# 方式2：本地下载zip包后，手动上传到服务器\n# 访问上述GitHub地址，点击「Code」→「Download ZIP」下载压缩包\n</code></pre>\n<p>github链接：<a href=\"https://github.com/supertone-inc/supertonic\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/supertone-inc/supertonic</a><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"步骤2将源码包转移到服务器\">步骤2：将源码包转移到服务器</h2>\n<p>如果是本地下载的 zip 包，通过jupyter可以直接拖动上传到服务器上面<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"步骤3解压程序包\">步骤3：解压程序包</h2>\n<p>登录服务器，进入文件存放目录，解压源码包：<br />\n<strong>在左侧切换到压缩包所在的目录的时候，右边界面点击 Terminal</strong></p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><strong>输入以下命令解压包</strong></p>\n<pre><code class=\"language-bash\"># 解压zip包（如果是git克隆则无需此步骤）\nunzip supertonic-main.zip\n\n# 解压后会生成 supertonic-main 目录\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"步骤4进入指定路径并安装依赖\">步骤4：进入指定路径并安装依赖</h2>\n<p>进入 Supertonic Python 代码的核心路径，安装 <code>requirements.txt</code> 中的依赖：</p>\n<pre><code class=\"language-bash\"># 进入supertonic-main/py路径\ncd supertonic-main/py/\n\n# 安装依赖（建议先升级pip，避免安装失败）\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"步骤5首次运行示例脚本并补充缺失库\">步骤5：首次运行示例脚本并补充缺失库</h2>\n<p>运行示例脚本 <code>example_pypi.py</code>，此时大概率会提示缺少某个库（如 <code>supertonic</code> 库）：</p>\n<pre><code class=\"language-bash\"># 首次运行示例脚本\npython example_pypi.py\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h3 id=\"常见报错示例\">常见报错示例：</h3>\n<pre><code>ModuleNotFoundError: No module named 'supertonic'\n</code></pre>\n<h4 id=\"解决方法\">解决方法：</h4>\n<p>根据报错提示，用 pip 补充安装缺失的库：</p>\n<pre><code class=\"language-bash\"># 替换xxx为实际缺失的库名，如 pip install soundfile\npip install supertonic\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"步骤6重新运行脚本并等待模型下载\">步骤6：重新运行脚本并等待模型下载</h2>\n<p>补充安装缺失库后，再次运行示例脚本：</p>\n<pre><code class=\"language-bash\">python example_pypi.py\n</code></pre>\n<p>⚠️ 注意：<strong>第一次运行时，脚本会自动下载所需的模型文件</strong>，下载速度取决于服务器网络，需耐心等待（通常几分钟），不要中断进程。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"步骤7验证部署成功\">步骤7：验证部署成功</h2>\n<p>运行完成后，检查 <code>supertonic-main/py/result</code> 目录，若生成了 wav 格式的结果文件，说明部署成功！</p>\n<pre><code class=\"language-bash\"># 查看result目录内容\nls result/\n</code></pre>\n<p>或者直接利用左侧文件管理系统查看<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"三supertonic-使用步骤\">三、Supertonic 使用步骤</h2>\n<p>部署完成或者直接使用我部署完的镜像之后，日常使用只需以下4步：</p>\n<h3 id=\"步骤1进入指定工作路径\">步骤1：进入指定工作路径</h3>\n<p>每次使用前，先登录服务器并进入核心路径：</p>\n<pre><code class=\"language-bash\">cd /supertonic-main/py/\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h3 id=\"步骤2修改示例脚本的文本内容\">步骤2：修改示例脚本的文本内容</h3>\n<p>编辑 <code>example_pypi.py</code> 文件，修改其中的 <code>text</code> 变量（核心输入内容，如语音合成的文本）：</p>\n<pre><code class=\"language-bash\"># 用vim编辑文件\nvim example_pypi.py\n\n# 找到类似如下的代码行，修改text的值\ntext = \"这是默认的测试文本\"  # 将此行改为你需要的内容\n</code></pre>\n<p>修改完成后，按 <code>Esc</code> → 输入 <code>:wq</code> 保存并退出 vim。</p>\n<p>或者直接用可视化界面修改内容<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h3 id=\"步骤3运行脚本生成结果\">步骤3：运行脚本生成结果</h3>\n<p>在当前路径下执行脚本，触发处理流程：</p>\n<pre><code class=\"language-bash\">python example_pypi.py\n</code></pre>\n<p>结果没有任何输出就是生成成功了，直接在result里面查看就可以了</p>\n<h3 id=\"步骤4查看生成的结果文件\">步骤4：查看生成的结果文件</h3>\n<p>处理完成后，所有结果会以 <code>wav</code> 音频文件格式存储在 <code>supertonic-main/py/result</code> 目录下，可通过 <code>scp</code> 下载到本地播放，或直接在服务器上用音频工具查看：</p>\n<pre><code class=\"language-bash\"># 下载结果文件到本地（示例）\nscp root@192.168.1.100:/opt/supertonic-main/py/result/xxx.wav ~/Desktop/\n</code></pre>\n<h1 id=\"四已部署好的镜像链接\">四、已部署好的镜像链接</h1>\n<p>为了方便大家快速使用，我已将部署完成的 Supertonic 环境打包为星图的社区镜像，可直接拉取使用，等待审核通过之后我会把链接搬到博客上面来。</p>\n<h1 id=\"五常见注意事项\">五、常见注意事项</h1>\n<ol>\n<li>模型下载失败：若首次运行时模型下载中断，可手动下载模型文件后放到脚本指定的缓存目录（通常在 <code>~/.cache/</code> 下）；</li>\n<li>依赖版本冲突：若安装 <code>requirements.txt</code> 时出现版本冲突，可尝试添加 <code>--force-reinstall</code> 参数重新安装，或降级对应库版本；</li>\n<li>权限问题：若运行脚本提示权限不足，执行 <code>chmod +x example_pypi.py</code> 或用 <code>sudo python example_pypi.py</code> 运行。</li>\n</ol>\n<hr />\n<h1 id=\"总结\">总结</h1>\n<ol>\n<li>Supertonic Python 版本部署核心步骤：下载源码→上传服务器→解压→安装依赖→补装缺失库→首次运行（等待模型下载）；</li>\n<li>日常使用只需修改 <code>example_pypi.py</code> 的 <code>text</code> 内容，运行脚本即可在 <code>result</code> 目录获取 wav 结果；</li>\n<li>可直接使用博主提供的已部署镜像，跳过繁琐的环境配置步骤，快速上手。</li>\n</ol>\n<p>如果部署或使用过程中遇到问题，欢迎在评论区交流～</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 19:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\n阅读(<span id=\"post_view_count\">11</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "LLM | ARC-AGI：有趣的 benchmark",
      "link": "https://www.cnblogs.com/moonout/p/19449723",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/moonout/p/19449723\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 19:57\">\n    <span>LLM | ARC-AGI：有趣的 benchmark</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        ARC-AGI benchmark 提供了基于视觉网格的谜题，它们是“对于人类简单、对于大模型困难”的问题。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<br />\n<p>ARC-AGI benchmark 提供了基于视觉网格的谜题，这些谜题是“对于人类简单、对于大模型困难”的问题。ARC-AGI 通过评测大模型解决这类问题的能力，来衡量大模型距通用智能的距离。</p>\n<p>每个谜题仅提供少量示例，大模型需要基于这些示例，通过抽象推理，理解谜题的含义。（另一方面，示例较少也意味着训练数据集较少，即，ARC-AGI benchmark 不容易通过专门训练来刷点。）该 benchmark 测试模型识别 pattern 并将其快速应用于新情况的能力。</p>\n<p>ARC-AGI 的主要评估指标是 Pass@2，它衡量模型在两次尝试内生成正确输出的能力。</p>\n<p>示例：</p>\n<p align=\"center\"><img align=\"center\" src=\"https://arcprize.org/media/images/arc-task-grids.jpg\" /></p>\n<p align=\"center\">(ARC-AGI-1)</p>\n<br />\n<p align=\"center\"><img align=\"center\" src=\"https://arcprize.org/media/images/v2-example.png\" /></p>\n<p align=\"center\">(ARC-AGI-2)</p>\n<p>如何解决 ARC-AGI 问题？ARC-AGI 团队在 Kaggle 上发布了相关竞赛，然而，由于训练数据过少，无法训出一个用于解决 ARC-AGI 问题的模型（这个思想也与考察模型通用推理能力的初衷相悖），因此在 2024 年 GPT 等模型兴起之前，基于深度学习的方法并未取得好的结果。</p>\n<p>根据 <a href=\"\" rel=\"noopener nofollow\">ARC Prize 2024: Technical Report</a>，在 2024 年度，ARC-AGI 的求解取得突破，主要使用了以下三种方法：</p>\n<ul>\n<li>深度学习引导的程序合成：利用深度学习模型，特别是专门的代码 LLMs，来生成解决任务的程序，或对搜索程序的过程进行指导。</li>\n<li>直推模型（transductive models）在测试时训练（test-time training，TTT）：在给定的 ARC-AGI 任务规范上对 LLM 进行微调，以便将 LLM 的先验知识重新组合成一个新的模型，适应当前的任务。直推模型指的是，接收输入后直接输出结果，而非输出一个程序。</li>\n<li>将程序合成与直推模型相结合：将上述两种方法合并为一个超级方法，因为据观察，这两种方法擅长解决不同类型的任务。</li>\n</ul>\n<hr />\n<p>ARC-AGI 任务的官网：<a href=\"https://arcprize.org/\" rel=\"noopener nofollow\" target=\"_blank\">https://arcprize.org/</a></p>\n<p>ARC-AGI-1/2/3 ：</p>\n<ul>\n<li><a href=\"https://arcprize.org/arc-agi/1/\" rel=\"noopener nofollow\" target=\"_blank\">https://arcprize.org/arc-agi/1/</a></li>\n<li><a href=\"https://arcprize.org/arc-agi/2/\" rel=\"noopener nofollow\" target=\"_blank\">https://arcprize.org/arc-agi/2/</a></li>\n<li><a href=\"https://arcprize.org/arc-agi/3/\" rel=\"noopener nofollow\" target=\"_blank\">https://arcprize.org/arc-agi/3/</a></li>\n</ul>\n<p>ARC-AGI-1/2 的榜单：<a href=\"https://arcprize.org/leaderboard\" rel=\"noopener nofollow\" target=\"_blank\">https://arcprize.org/leaderboard</a></p>\n<p>ARC Prize 2024: Technical Report：<a href=\"https://arxiv.org/html/2412.04604v1\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/html/2412.04604v1</a></p>\n<p>相关博客：</p>\n<ul>\n<li>像 AI 写的神秘博客：<a href=\"https://labs.adaline.ai/p/what-is-the-arc-agi-benchmark-and\" rel=\"noopener nofollow\" target=\"_blank\">https://labs.adaline.ai/p/what-is-the-arc-agi-benchmark-and</a></li>\n<li>知乎 · 机器之心 |「压缩即智能」得到实验验证，无需预训练和大量数据就能解决 ARC-AGI 问题：<a href=\"https://zhuanlan.zhihu.com/p/30426666081\" rel=\"noopener nofollow\" target=\"_blank\">https://zhuanlan.zhihu.com/p/30426666081</a></li>\n<li>知乎 | ARC-AGI 测试集对人工智能来说难在哪里？<a href=\"https://www.zhihu.com/question/7955529556/answer/65269819236\" rel=\"noopener nofollow\" target=\"_blank\">https://www.zhihu.com/question/7955529556/answer/65269819236</a></li>\n</ul>\n<br />\n<br />\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 19:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/moonout\">MoonOut</a>&nbsp;\n阅读(<span id=\"post_view_count\">1</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "3D-AIGC 存储架构演进：从 NFS、GlusterFS 到 JuiceFS",
      "link": "https://www.cnblogs.com/JuiceData/p/19453125",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/JuiceData/p/19453125\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 16:55\">\n    <span>3D-AIGC 存储架构演进：从 NFS、GlusterFS 到 JuiceFS</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>光影焕像（Lightillusions）是一家专注于空间智能技术，结合 3D 视觉、图形学和生成模型技术，致力于打造创新的 3D 基础模型公司。公司由谭平教授领导，谭教授曾担任阿里巴巴达摩院实验室负责人，目前是香港科技大学的教授，同时担任冯诺伊曼人工智能研究室副院长，并是香港科技大学与比亚迪联合实验室的主任。</p>\n<p>区别于二维模型，三维模型单个模型的大小可达几 GB，尤其是点云数据等复杂模型。当数据量达到 PB 级别时，管理与存储成为巨大的挑战。经过尝试 NFS、GlusterFS 等方案后，我们最终选择了 JuiceFS，成功搭建了一个统一的存储平台，为多个场景服务，并支持跨平台访问，包括 Windows 和 Linux 系统。<strong>该平台目前已管理上亿文件，数据处理速度提升了 200%~250%，还实现了高效的存储扩容，同时运维管理得到了极大简化，使得团队能够更专注于核心任务的推进</strong>。</p>\n<h2 id=\"01-3d-aigc-存储需求\">01 3D-AIGC 存储需求</h2>\n<p>我们的研究主要集中在感知和生成两个方向。在三维领域，任务的复杂性与图像和文本处理有本质区别，这对我们的 AI 模型、算法以及基础设施建设都提出了更高的要求。</p>\n<p>我们通过一个 3D 数据处理流程，来展示三维数据处理的复杂性。下图左侧是一个三维模型，包含纹理（左上角的折射纹理）和几何信息（右下角的几何结构）。首先，我们生成渲染图像。每个模型还附带文本标签，描述其内容、几何特征和纹理特征，这些标签与每个模型紧密相关。此外，我们还处理几何数据，如采样点以及从数据预处理过程中得到的必要数值（如 3DS、SDF 等）。需要注意的是，三维模型的文件格式非常多样，图片格式也各不相同。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>我们的工作场景涉及语言模型、图像/视频模型到三维模型，随着数据量的增长，存储负担也在不断增加。以下是这些场景中数据使用的主要特点：</p>\n<ul>\n<li>语言模型的数据通常由大量小文件组成。尽管单个文本文件较小，但随着数据量的增加，文件数量可能达到数百万甚至数千万个，这使得管理如此庞大的文件数成为存储的一个主要难点。</li>\n<li>图像和视频数据，尤其是高分辨率图像和长时间的视频，通常较为庞大。单张图像的大小通常在几百 KB 到几 MB 之间，而视频文件可能达到 GB 级别。在预处理过程中，如数据增强、分辨率调整和帧提取等，数据量会显著增加，特别是在视频处理中，每个视频通常会被拆解为大量的图像文件，管理这些庞大的文件集，带来了更高的复杂性。</li>\n<li>三维模型，特别是点云数据等复杂模型，单个模型的大小可达几 GB。<strong>三维数据的预处理过程比其他数据更加复杂，涉及纹理映射、几何重建等多个步骤，这些处理不仅消耗大量计算资源，还可能增加数据体积</strong>。此外，三维模型通常由多个文件组成，文件数量庞大，随着数据量的增长，管理这些文件的难度也会增加。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>由上述环节的存储特点，我们希望构建的存储平台能够满足以下几项要求：</p>\n<ul>\n<li>\n<p><strong>多样的数据格式与跨节点共享</strong>：不同模型的数据格式差异较大，特别是三维模型的格式复杂性和跨平台兼容问题，存储系统需要支持多种格式，并有效管理跨节点和跨平台的数据共享。</p>\n</li>\n<li>\n<p><strong>可以处理不同尺寸的数据模型</strong>：无论是语言模型的小文件、大规模图片/视频数据，还是三维模型的大文件，存储系统必须具备高扩展性，以应对快速增长的存储需求，并高效处理大尺寸数据的存储和访问。</p>\n</li>\n<li>\n<p><strong>跨云与集群存储的挑战</strong>：随着数据量的增加，特别是三维模型的 PB 级存储需求，跨云和集群存储问题愈加突出。存储系统需要支持跨区域、跨云的无缝数据访问和高效的集群管理。</p>\n</li>\n<li>\n<p><strong>方便扩容</strong>：无论是语言模型、图片/视频模型，还是三维模型，扩容需求始终存在，尤其是三维模型的存储和处理对扩容的需求更高。</p>\n</li>\n<li>\n<p><strong>简单的运维</strong>：存储系统应提供简便的管理界面和工具，尤其是对于三维模型的管理，运维要求更高，自动化管理和容错能力是必不可少的。</p>\n</li>\n</ul>\n<h2 id=\"02-存储方案探索从-nfsglustercephfs-到-juicefs\">02 存储方案探索：从 NFS、Gluster、CephFS 到 JuiceFS</h2>\n<h3 id=\"前期方案nfs-挂载\">前期方案：NFS 挂载</h3>\n<p>最初，我们采用了最简单的方案——使用 NFS 进行挂载。然而，在实际操作中，我们发现训练集群和渲染集群需要各自独立的集群来进行挂载操作。这种方式的维护非常繁琐，尤其是当添加新的数据时，我们需要单独为每个新数据写入挂载点。到了数据量达到约 100 万物体级别时，我们已经无法继续维持这种方案，因此在早期阶段，我们就放弃了这一方案。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"中期方案glusterfs\">中期方案：GlusterFS</h3>\n<p>GlusterFS 是一个相对易于上手的选择，安装配置简单，性能也能得到一定保障，且无需划分多个挂载点，只需增加新节点即可。虽然在前期使用时，GlusterFS 大大减轻了我们的工作量，但我们也发现它的生态系统存在一些问题。</p>\n<p>首先，GlusterFS 许多执行脚本和功能需要手动编写定时任务。特别是在添加新存储时，它还会有一些额外要求，例如需要按特定倍数增加节点。此外，像克隆、数据同步等操作的支持也相对较弱，导致我们在使用过程中频繁查阅文档，且许多操作并不稳定。例如，使用 FIO 等工具进行测速时，结果并不总是可靠。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p><strong>更为严重的问题是，当存储的小文件数量达到一定规模时，GlusterFS 的性能会急剧下降</strong>。举个例子，一个模型可能会生成 100 张图片，若有 1000 万个模型，就会产生 10 亿张图片。GlusterFS 在后期的寻址变得极为困难，尤其是小文件过多时，性能会显著下降，导致系统崩溃。</p>\n<h3 id=\"最终选型cephfs-vs-juicefs\">最终选型：CephFS vs JuiceFS</h3>\n<p>随着存储需求的增加，我们决定转向可持续性更好的方案。在评估了多种方案后，我们主要对比了 CephFS 和 JuiceFS。虽然 Ceph 被广泛使用，但通过自己的实践和对比文档，我们发现 Ceph 的运维和管理成本非常高，尤其对于我们这样的小团队来说，处理这些复杂的运维任务显得尤为困难。</p>\n<p>JuiceFS 有两个原生自带的特性非常符合我们的需求。<strong>首先是客户端数据缓存功能</strong>。对于我们的模型训练集群，通常会配备高性能的 NVMe 存储。如果能够充分利用客户端的缓存，便能显著加速模型训练，并减少对 JuiceFS 存储的压力。</p>\n<p><strong>其次，JuiceFS 对 S3 的兼容性对我们也至关重要</strong>。由于我们基于存储开发了一些可视化平台用于数据标注、整理和统计，S3 兼容性使得我们能够快速进行网页开发，支持可视化和数据统计操作等功能。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h2 id=\"03-基于-juicefs-的存储平台实践\">03 基于 JuiceFS 的存储平台实践</h2>\n<h3 id=\"元数据引擎选择与拓扑\">元数据引擎选择与拓扑</h3>\n<p>JuiceFS 采用的是元数据与数据分离的架构，有多种元数据引擎可供选择。我们首先快速验证了 Redis 存储方案，官方提供了详细的文档支持。Redis 的优势在于其轻量化，配置过程通常只需一天或半天时间，数据迁移也相对顺利。<strong>然而，当小文件数量超过 1 亿时，Redis 的速度和性能会显著下降</strong>。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>正如之前提到的，每个模型可能会渲染出 100 张图片，再加上其他杂项文件，导致小文件的数量急剧增加。虽然我们可以通过打包小文件来减轻问题，但一旦打包后进行修改或可视化操作，复杂性就大大增加。因此，我们希望能够保留原始的小图片文件，以便后续处理。</p>\n<p>随着文件数量的增加，很快超出 Redis 的处理能力，我们决定将存储系统迁移到 TiKV 和 Kubernetes 组合上。TiKV 与 K8s 的组合能够为我们提供更高可用的元数据存储方案。此外，通过基准测试我们发现，尽管 TiKV 的性能稍逊一筹，但差距并不显著，且相较于 Redis，它对小文件的支持更好。我们也咨询过 JuiceFS 的工程师，了解到 Redis 在集群模式下的扩展性较差，于是我们准备切换到 TiKV。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"最新架构juicefs--tikv--seaweedfs\">最新架构：JuiceFS + TiKV + SeaweedFS</h3>\n<p>我们使用了 JuiceFS 来管理对象存储。TiKV 和 K8s 来搭建元数据存储系统。对象存储部分使用了 SeaweedFS，这使得我们能够快速扩展存储规模，且无论是小数据还是大数据，访问速度都很快。此外，我们的对象存储分布在多个平台：包括本地存储、阿里云存储以及国外的 R2 和 Amazon 对象存储。通过 JuiceFS，我们能够将这些不同存储系统集成起来，并提供一个统一的接口。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>为了更好地管理系统资源，我们在 K8s 上搭建了资源监控平台。当前系统由大约 60 台 Linux 机器和若干 Windows 机器组成，负责渲染和数据处理任务。我们对读取稳定性进行了监控，结果显示，即使是多台异构服务器同时进行读取操作，整个系统的 I/O 性能依然非常稳定，基本能够充分利用带宽资源。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"实践中遇到的问题\">实践中遇到的问题</h3>\n<p>在优化存储方案的过程中，我们最初尝试了 EC（纠删码） 存储方案，旨在减少存储需求并提升效率。然而，在大规模数据迁移中，EC 存储的计算速度较慢，并且在高吞吐量和频繁数据变化的场景下，性能表现不佳，尤其与 SeaweedFS 结合时，存在性能瓶颈。基于这些问题，我们决定放弃 EC 存储，转而采用副本存储方案。</p>\n<p>我们设置了独立服务器并配置了定时任务，以进行大数据量的元数据备份。在 TiKV 中，我们实现了冗余副本机制，采用了多个副本方案来确保数据的完整性。同时，在对象存储方面，我们采用了双副本编码来进一步提高数据可靠性。虽然副本存储能够有效保证数据冗余和高可用性，但由于处理 PB 级数据和大量增量数据，存储成本依然较高。未来，我们可能会考虑进一步优化存储方案，以降低存储成本。</p>\n<p>另外，我们也发现当使用全闪存服务器 + JuiceFS 并未带来显著的性能提升。瓶颈主要出现在网络带宽和延迟上。因此，我们计划在后期考虑使用 InfiniBand（IB）连接存储服务器和训练服务器，以最大化资源利用效率。</p>\n<h2 id=\"04-小结\">04 小结</h2>\n<p>在使用 GlusterFS 时，我们每天最多只能处理 20 万个模型；<strong>而切换到 JuiceFS 后，处理能力大幅提升，日均数据处理能力增加了 2.5 倍，小文件吞吐能力也显著提高，特别是在存储量达到 70% 后，系统仍能保持稳定运行</strong>。此外，扩容也非常便捷，而之前的架构，扩容过程非常繁琐，操作起来比较麻烦。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>最后再总结一下 JuiceFS 在三维生成任务中表现出来的优势：</p>\n<ul>\n<li>\n<p><strong>小文件性能</strong>： 小文件处理能力是一个关键点，JuiceFS 依然提供了一个较好的解决方案。</p>\n</li>\n<li>\n<p><strong>跨平台特性</strong>： 跨平台支持非常重要。我们发现有些数据只能在 Windows 软件中打开，因此需要同时在 Windows 和 Linux 系统上处理相同的数据，并在同一个挂载节点上进行读写。这种需求使得跨平台的特性尤为关键，JuiceFS 的设计很好地解决了这一问题。</p>\n</li>\n<li>\n<p><strong>低运维成本</strong>： JuiceFS 的运维成本极低。配置完成后，只需要进行一些简单的测试和节点的管理（例如，丢弃某些节点并监控鲁棒性）。我们在迁移数据时花费了大约半年的时间，到目前为止并未遇到太大的问题。</p>\n</li>\n<li>\n<p><strong>本地缓存机制</strong>： 之前，如果想使用本地缓存，我们需要手动在代码中实现本地缓存逻辑，但 JuiceFS 提供了非常方便的本地缓存机制，通过设置挂载参数来优化训练场景的性能。</p>\n</li>\n<li>\n<p><strong>迁移成本低</strong>： 尤其是在迁移小文件时，我们发现使用 JuiceFS 进行元数据和对象存储的迁移非常方便，节省了我们大量时间和精力。相比之下，之前使用其他存储系统迁移时，过程非常痛苦。</p>\n</li>\n</ul>\n<p>综上所述，JuiceFS 在大规模数据处理中的表现非常出色，提供了高效、稳定的存储解决方案。它不仅简化了存储管理和扩容过程，还大大提升了系统性能，让我们能够更加专注于核心任务的推进。</p>\n<p>此外，官方提供一些工具也非常便捷，例如我们使用 Sync 在处理小文件迁移时，效率极高。在没有额外性能优化的情况下，我们成功迁移了 500TB 的数据，其中包含大量的小数据和图片文件，迁移时间不到 5 天，结果超出我们的预期。</p>\n<p>我们希望本文中的一些实践经验，能为正在面临类似问题的开发者提供参考，如果有其他疑问欢迎加入&nbsp;<a href=\"https://juicefs.com/zh-cn/\" rel=\"noopener nofollow\" target=\"_blank\">JuiceFS 社区</a>与大家共同交流。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 16:55</span>&nbsp;\n<a href=\"https://www.cnblogs.com/JuiceData\">JuiceFS</a>&nbsp;\n阅读(<span id=\"post_view_count\">57</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "51单片机__LED相关",
      "link": "https://www.cnblogs.com/WIRO/p/19452806",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/WIRO/p/19452806\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 16:06\">\n    <span>51单片机__LED相关</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"51单片机__led相关\">51单片机__LED相关</h1>\n<h2 id=\"单片机介绍\">单片机介绍</h2>\n<p>单片机，英文Micro Controller Unit，简称MCU<br />\n内部集成了CPU、RAM、ROM、定时器、中断系统、通讯接口等一系列电脑的常用硬件功能<br />\n单片机的任务是信息采集（依靠传感器）、处理（依靠CPU）和硬件设备（例如电机，LED等）的控制<br />\n单片机跟计算机相比，单片机算是一个袖珍版计算机，一个芯片就能构成完整的计算机系统。但在性能上，与计算机相差甚远，但单片机成本低、体积小、结构简单，在生活和工业控制领域大有所用<br />\n同时，学习使用单片机是了解计算机原理与结构的最佳选择</p>\n<h2 id=\"单片机应用\">单片机应用</h2>\n<p>单片机的使用领域已十分广泛，如智能仪表、实时工控、通讯设备、导航系统、家用电器等。各种产品一旦用上了单片机，就能起到使产品升级换代的功效，常在产品名称前冠以形容词——“智能型”，如智能型洗衣机等。</p>\n<p><img alt=\"image-20260107113142288\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519528-2082922721.png\" /></p>\n<h2 id=\"stc89c52单片机\">STC89C52单片机</h2>\n<p><img alt=\"image-20260107113244328\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519123-1391531477.png\" /></p>\n<p><img alt=\"image-20260107113324739\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519527-1511351430.png\" /></p>\n<p><img alt=\"image-20260107113519962\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519188-402559776.png\" /></p>\n<p><img alt=\"image-20260107113540042\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519297-1849899687.png\" /></p>\n<p><img alt=\"image-20260107113612706\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519274-1889121421.png\" /></p>\n<h2 id=\"开发板原理图和复位单路\">开发板原理图和复位单路</h2>\n<p><img alt=\"image-20260107113715018\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519312-2037859992.png\" /></p>\n<p><img alt=\"image-20260107114043371\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519369-1523164322.png\" /></p>\n<p><img alt=\"image-20260107114127756\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519480-912853277.png\" /></p>\n<h1 id=\"创建工程并实现led控制\">创建工程并实现LED控制</h1>\n<h2 id=\"1点亮led灯\">1）点亮LED灯</h2>\n<p><img alt=\"image-20260107115032547\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519089-1326428079.png\" /></p>\n<p>观察原理图，LED灯低电平点亮，下面开始编写代码：</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n\nvoid main()\n{\n\tP2 = 0;\n}\n\n// 现象:所有LED灯均被点亮\n</code></pre>\n<h2 id=\"2实现led_1灯闪烁\">2）实现LED_1灯闪烁</h2>\n<p><strong>延时方法与实现：</strong></p>\n<p>通过单片机驱动外围显示电路，为了能够让人眼识别到所显示内容的变化，需要保证所显示的内容有所停留。在单片机中，实现这一效果有两种方式，一种是通过C语言编写一段延时效果的程序或者子程序，实现该目的。另一种是调用单片机自带的定式/计数器，这里暂时使用第一种方式。</p>\n<p>使用单片机烧录软件AiCube-ISP-v6.96A，生成一段500ms的延时函数。</p>\n<pre><code class=\"language-c\">// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n</code></pre>\n<p><img alt=\"image-20260107120433086\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519161-1654264043.png\" /></p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\nvoid main()\n{\n\twhile(1)\n\t{\t\n\t\tP2 = 0xFE;     // 1111 1110\n\t\tDelay500ms();  // 延时0.5s\n\t\tP2 = 0xFF;     // 1111 1111\n\t\tDelay500ms();  // 延时0.5s\n\t}\n}\n\n// 现象: LED_1 闪烁，其他LED灯不亮\n</code></pre>\n<h2 id=\"3实现led流水灯\">3）实现LED流水灯</h2>\n<h3 id=\"第一种方式使用数组实现流水灯效果\"><strong>第一种方式：使用数组实现流水灯效果</strong></h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\n// 定义流水灯数组\nunsigned char LedCode[] = {0xFE,0xFD,0xFB,0xF7,0Xef,0xDF,0xBF,0x7F};\n\nvoid main()\n{\n\tunsigned char i;\n\twhile(1)\n\t{\t\n\t\tfor(i = 0;i &lt; 8;i ++)\n\t\t{\n\t\t\tP2 = LedCode[i];\n\t\t\tDelay500ms();\n\t\t}\n\t}\n}\n\n// 现象：LED灯从低到高依次点亮\n\n//附加内容：\n//0xFE  1111 1110\n//0xFD  1111 1101\n//0xFB  1111 1011\n//0xF7  1111 0111\n//0Xef  1110 1111\n//0xDF  1101 1111\n//0xBF  1011 1111\n//0x7F  0111 1111\n</code></pre>\n<h3 id=\"第二种方式左右移运算符实现\"><strong>第二种方式：左右移运算符实现</strong></h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\n\nvoid main() {\n    unsigned char Led = 0x01; // 0000 0001\n    \n    while(1) {\n        P2 = ~Led;      // 取反，输出到P2端口\n        Delay500ms();   // 延时500ms\n        \n        // 使用左移运算符\n        Led = Led &lt;&lt; 1;\n        \n        // 如果移到最右边，重新从最左边开始\n        if(Led == 0x00) {\n            Led = 0x01;\n        }\n    }\n}\n\n// 现象：LED灯从低到高依次点亮\n</code></pre>\n<h3 id=\"第三种方式循环左右移函数的调用\"><strong>第三种方式：循环左右移函数的调用</strong></h3>\n<h3 id=\"1-cror---循环右移函数\">1. <strong><em>cror</em>() - 循环右移函数</strong></h3>\n<p><strong>头文件：</strong> <code>#include &lt;intrins.h&gt;</code><br />\n<strong>原型：</strong> <code>unsigned char _cror_(unsigned char val, unsigned char n);</code></p>\n<p><strong>功能：</strong> 将 8 位数据循环右移 n 位，移出的位从左边补入</p>\n<p><strong>示例：</strong></p>\n<pre><code class=\"language-c\">unsigned char data = 0x81;  // 二进制：10000001\ndata = _cror_(data, 1);     // 结果：0xC0 (11000000)\n// 原：10000001 → 右移1位 → 11000000\n</code></pre>\n<p><img alt=\"image-20260107153044727\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519436-108965670.png\" /></p>\n<h3 id=\"2-crol---循环左移函数\">2. <strong><em>crol</em>() - 循环左移函数</strong></h3>\n<p><strong>头文件：</strong> <code>#include &lt;intrins.h&gt;</code><br />\n<strong>原型：</strong> <code>unsigned char _crol_(unsigned char val, unsigned char n);</code></p>\n<p><strong>功能：</strong> 将 8 位数据循环左移 n 位，移出的位从右边补入</p>\n<p><strong>示例：</strong></p>\n<pre><code class=\"language-c\">unsigned char data = 0x81;  // 二进制：10000001\ndata = _crol_(data, 1);     // 结果：0x03 (00000011)\n// 原：10000001 → 左移1位 → 00000011\n</code></pre>\n<p><img alt=\"image-20260107153844168\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519302-1190082079.png\" /></p>\n<p>流水灯应用示例：</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\n\nvoid main() \n\t{\n\t\tunsigned char aa;\n\t\taa = 0xFE;  // 1111 1110\n\t\t\n\t\twhile(1)\n\t\t{\n\t\t\tP2 = aa;\n\t\t\tDelay500ms();\n\t\t\taa = _crol_(aa,1);  // 循环左移函数\n\t\t}\n\n\t}\n\n// 现象：LED灯从低到高依次点亮\n</code></pre>\n<p><strong>注意：</strong> 这两个函数是 C51 编译器特有，仅适用于 51 单片机开发。</p>\n<h2 id=\"综合练习双向流水灯\">综合练习：双向流水灯</h2>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 包含移位函数头文件\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\nvoid main() \n{\n    unsigned char aa;\n    unsigned char direction = 0;  // 0:左移, 1:右移\n    unsigned char counter = 0;    // 计数左移/右移的次数\n    \n    aa = 0xFE;  // 1111 1110，第一个灯亮\n    \n    while(1)\n    {\n        P2 = aa;\n        Delay500ms();\n        \n        // 左移8次后改为右移\n        if(direction == 0)\n        {\n            aa = _crol_(aa, 1);  // 循环左移\n            counter++;\n            \n            if(counter &gt;= 7)  // 左移7次后（共8个状态）\n            {\n                direction = 1;  // 改为右移方向\n                counter = 0;    // 计数器清零\n            }\n        }\n        // 右移8次后改为左移\n        else\n        {\n            aa = _cror_(aa, 1);  // 循环右移\n            counter++;\n            \n            if(counter &gt;= 7)  // 右移7次后（共8个状态）\n            {\n                direction = 0;  // 改为左移方向\n                counter = 0;    // 计数器清零\n            }\n        }\n    }\n}\n\n// 现象：LED左右依次点亮\n</code></pre>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 16:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/WIRO\">Q&amp;25</a>&nbsp;\n阅读(<span id=\"post_view_count\">104</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "XAML Studio 已正式开源",
      "link": "https://www.cnblogs.com/shanyou/p/19452660",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shanyou/p/19452660\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:46\">\n    <span>XAML Studio 已正式开源</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>微软开发者博客于 2026 年 1 月 6 日正式宣布(<a href=\"https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/\" rel=\"noopener nofollow\" title=\"https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/\">https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/</a>)，<b>XAML Studio 已正式开源</b>，并成为了 .NET 基金会（.NET Foundation）旗下的一个种子项目。</p><h5><font face=\"微软雅黑 Light\" size=\"3\">1. 什么是 XAML Studio？</font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">XAML Studio 是一款专为 <b>WinUI</b> 开发者打造的辅助工具，最初是 Microsoft Garage（微软车库）的一个项目。它允许开发者在不创建完整工程的情况下，快速进行 XAML 界面原型设计和交互调试。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">其核心功能包括：</font></p><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>实时编辑与预览</b>：即时查看 XAML 代码的效果。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>绑定调试器 (Binding Debugger)</b>：直观排查数据绑定问题。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>数据上下文编辑器</b>：快速模拟测试数据。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>IntelliSense 与文档工具箱</b>：提供代码补全和控件查阅。</font></font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\">2. 开源背景与现状</font></h5><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>项目历程</b>：该项目始于 8 年前，一直计划开源，如今终于实现。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>V2 版本</b>：目前开源的是正在开发中的 <b>XAML Studio v2</b>。相比商店里的 1.1 版本，v2 采用了全新的界面，并针对 WinUI 3 进行了优化。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>社区贡献</b>：XAML Studio 的许多核心组件早已回馈给社区，例如 <b>Windows Community Toolkit (WCT)</b> 中的 <code>SwitchPresenter</code>、<code>Sizer</code> 控件（如 <code>GridSplitter</code> 的改进版）以及实验性的 <b>Adorners（装饰器）</b> 功能，最初都源于 XAML Studio。</font></font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\">3. 未来计划</font></h5><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>开发分支</b>：开发者目前可以从 GitHub 的 <code>dev</code> 分支获取 v2 版本的源代码并自行构建。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>正式发布</b>：开发团队计划在 2026 年晚些时候在 Microsoft Store 发布 v2 的正式稳定版。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>参与方式</b>：微软鼓励开发者通过 GitHub 提交反馈、建议或直接贡献代码。</font></font></p></li></ul><p><b><font face=\"微软雅黑 Light\" size=\"3\">相关资源：</font></b></p><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>GitHub 仓库</b>：</font></font><a href=\"https://www.google.com/search?q=https://github.com/microsoft/XamlStudio\" rel=\"noopener nofollow\"><font face=\"微软雅黑 Light\" size=\"3\">microsoft/XamlStudio</font></a><font face=\"微软雅黑 Light\" size=\"3\">（或通过 .NET Foundation 查找）。</font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>官方博客全文</b>：</font></font><a href=\"https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/\" rel=\"noopener nofollow\"><font face=\"微软雅黑 Light\" size=\"3\">XAML Studio is now Open Sourced</font></a></p></li></ul><p>这对 WinUI 开发者来说是一个重要的里程碑，不仅工具本身变得透明、可定制，也预示着 WinUI 生态系统的进一步开放。</p>\n</div>\n<div id=\"MySignature\">\n    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>\n<img src=\"https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg\" width=\"170\" />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 15:46</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shanyou\">张善友</a>&nbsp;\n阅读(<span id=\"post_view_count\">374</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【终极踩坑指南】Windows 10上MsQuic证书加载失败？坑不在证书，而在Schannel！",
      "link": "https://www.cnblogs.com/haibindev/p/19452652",
      "published": "",
      "description": "<div class=\"postTitle\">\n\t\t<h1><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/haibindev/p/19452652\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:45\">\n    <span>【终极踩坑指南】Windows 10上MsQuic证书加载失败？坑不在证书，而在Schannel！</span>\n    \n\n</a>\n</h1>\n\t</div>\n\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        摘要：如果你在Windows 10上被 ConfigurationLoadCredential failed, 0x80070490 或 E_NOINTERFACE 错误折磨良久，试遍所有证书方案仍无解，那么恭喜，本文就是你的终点站。真正原因极可能是：新版MsQuic已默认放弃对Windows 10上Schannel的支持。无需再折腾证书，切换至OpenSSL后端即可一键解决。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"终极踩坑指南windows-10上msquic证书加载失败坑不在证书而在schannel\">【终极踩坑指南】Windows 10上MsQuic证书加载失败？坑不在证书，而在Schannel！</h1>\n<blockquote>\n<p><strong>摘要</strong>：如果你在Windows 10上被 <code>ConfigurationLoadCredential failed, 0x80070490</code> 或 <code>E_NOINTERFACE</code> 错误折磨良久，试遍所有证书方案仍无解，那么恭喜，本文就是你的终点站。真正原因极可能是：<strong>新版MsQuic已默认放弃对Windows 10上Schannel的支持</strong>。无需再折腾证书，切换至OpenSSL后端即可一键解决。</p>\n</blockquote>\n<h3 id=\"一问题现象一个极具迷惑性的错误\"><strong>一、问题现象：一个极具迷惑性的错误</strong></h3>\n<p>环境：Windows 10 22H2，使用GitHub主线版本MsQuic编译QUIC Server。</p>\n<p>在调用 <code>MsQuic-&gt;ConfigurationLoadCredential(...)</code> 时，稳定失败，返回错误：</p>\n<pre><code>ConfigurationLoadCredential failed, 0x80070490\n</code></pre>\n<p>或者：</p>\n<pre><code>E_NOINTERFACE\n</code></pre>\n<p><strong>所有迹象都指向证书问题</strong>，于是开始了漫长的“踩坑”之旅。</p>\n<h3 id=\"二排查弯路我被证书问题带偏的全过程\"><strong>二、排查弯路：我被“证书问题”带偏的全过程</strong></h3>\n<p>以下是我的排查流水账，几乎试遍了Windows下所有证书方案：</p>\n<ol>\n<li>\n<p><strong>证书哈希（官方推荐）</strong></p>\n<pre><code class=\"language-cpp\">QUIC_CERTIFICATE_HASH CertHash{};\nmemcpy(CertHash.ShaHash, hashbuf_.data(), 20);\nCredConfig.Type = QUIC_CREDENTIAL_TYPE_CERTIFICATE_HASH;\n</code></pre>\n<p><strong>结果</strong>：<code>HRESULT_FROM_WIN32(ERROR_NOT_FOUND)</code>。确认证书在本地计算机存储、有私钥、验证通过，但就是不行。</p>\n</li>\n<li>\n<p><strong>哈希存储（显式指定仓库）</strong></p>\n<pre><code class=\"language-cpp\">strcpy_s(CertHashStore.StoreName, \"LocalMachine\\\\My\");\nCredConfig.Type = QUIC_CREDENTIAL_TYPE_CERTIFICATE_HASH_STORE;\n</code></pre>\n<p><strong>结果</strong>：<code>E_INVALIDARG</code>。</p>\n</li>\n<li>\n<p><strong>怀疑证书生成方式</strong><br />\n怀疑OpenSSL生成的证书不行，换用PowerShell生成“纯正”的CNG证书：</p>\n<pre><code class=\"language-powershell\">New-SelfSignedCertificate -Provider \"Microsoft Software Key Storage Provider\" ...\n</code></pre>\n<p><strong>结果</strong>：失败依旧。</p>\n</li>\n<li>\n<p><strong>终极尝试：PFX文件</strong></p>\n<pre><code class=\"language-cpp\">CredConfig.Type = QUIC_CREDENTIAL_TYPE_CERTIFICATE_FILE_PROTECTED;\n</code></pre>\n<p><strong>结果</strong>：熟悉的 <code>E_NOINTERFACE</code>。</p>\n</li>\n<li>\n<p><strong>关键转折点：官方示例也挂了</strong><br />\n当怀疑人生时，直接测试MsQuic自带的 <code>quicsample.exe</code>：</p>\n<pre><code class=\"language-bash\">quicsample.exe -server -cert_hash:&lt;your_thumbprint&gt;\n</code></pre>\n<p><strong>同样失败！</strong> 这证明问题与我的代码无关，是<strong>环境或库本身的问题</strong>。</p>\n</li>\n</ol>\n<h3 id=\"三真相揭露不是证书的锅是schannel掉了链子\"><strong>三、真相揭露：不是证书的锅，是Schannel掉了链子</strong></h3>\n<p>所有排查都失效后，我将目光从证书移开，最终锁定核心矛盾：</p>\n<blockquote>\n<p><strong>当前较新版本的MsQuic，在Windows 10系统上，其默认的Schannel TLS后端可能已无法正常加载服务器证书。</strong></p>\n</blockquote>\n<p>这是一个<strong>官方文档未明确标注、但实际存在的兼容性断点</strong>。错误 <code>0x80070490</code> (找不到元素) 和 <code>E_NOINTERFACE</code> 极具误导性，让你在证书的迷宫里无限打转，而真正的出口是：<strong>更换TLS后端</strong>。</p>\n<h3 id=\"四一行命令解决切换到openssl后端\"><strong>四、一行命令解决：切换到OpenSSL后端</strong></h3>\n<p><strong>解决方案简单到令人发指：</strong></p>\n<ol>\n<li>\n<p><strong>使用OpenSSL后端重新编译MsQuic</strong>：</p>\n<pre><code class=\"language-bash\"># 在MsQuic仓库目录下执行\n.\\scripts\\build.ps1 -Config Debug -Arch x64 -Tls openssl\n</code></pre>\n</li>\n<li>\n<p><strong>使用OpenSSL生成的证书</strong>（如PEM或PFX格式）。</p>\n</li>\n<li>\n<p>再次运行你的程序或 <code>quicsample</code>：</p>\n<pre><code class=\"language-bash\">quicsample.exe -server -cert_file:server.pfx -key_file:key.pem\n</code></pre>\n<p><strong>✅ 服务器顺利启动，问题解决。</strong></p>\n</li>\n</ol>\n<h3 id=\"五为什么会有这个坑深度分析\"><strong>五、为什么会有这个坑？（深度分析）</strong></h3>\n<p>这个问题在 <strong>Windows 11 或 Windows Server 2022</strong> 上通常不会出现，因为它们内置了完整的、支持最新QUIC规范的Schannel实现。</p>\n<p>而 <strong>Windows 10</strong>（尤其是某些版本）的Schannel对MsQuic新版本所需功能的支持可能不完整或存在缺陷。MsQuic在更新过程中，可能默认启用了某些Windows 10上Schannel无法满足的特性或API，导致证书加载路径从根源上失败。</p>\n<p><strong>因此，这本质上是一个平台兼容性断档问题。</strong> 对于开发者而言，表象是证书错误，根因是系统组件落后于开发库的演进。</p>\n<h3 id=\"六总结与建议\"><strong>六、总结与建议</strong></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">场景</th>\n<th style=\"text-align: left;\">推荐动作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>在Windows 10上开发/部署MsQuic</strong></td>\n<td style=\"text-align: left;\"><strong>直接使用OpenSSL后端</strong>，一劳永逸。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">遇到<code>0x80070490</code>或<code>E_NOINTERFACE</code>错误</td>\n<td style=\"text-align: left;\">首要怀疑<strong>TLS后端兼容性</strong>，而非证书本身。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">需要跨平台（Windows/Linux）一致性</td>\n<td style=\"text-align: left;\">选择OpenSSL后端更能保证行为一致。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>目标环境为Windows 11/Server 2022+</strong></td>\n<td style=\"text-align: left;\">可放心使用默认Schannel，性能更佳。</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<p><strong>拓展思考</strong>：对于从事<strong>视频流传输</strong>（如基于QUIC优化RTMP、HLS延迟）的开发者来说，理解底层网络库的这些平台细微差别至关重要。一次成功的协议升级，往往从顺利编译和部署开始。希望这篇踩坑记录能助你畅通无阻。</p>\n<p>（本文基于Windows 10 22H2家庭中文版、x64架构、MsQuic GitHub主线版本测试验证）</p>\n<p><img alt=\"\" src=\"https://img2023.cnblogs.com/blog/254714/202307/254714-20230701143418754-1351786962.jpg\" /></p>\n<p><strong>合作请加WX：hbstream</strong><br />\n<strong>合作请加作者hbstream（<a href=\"http://haibindev.cnblogs.com\" target=\"_blank\">http://haibindev.cnblogs.com</a>），转载请注明作者和出处</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-07 15:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/haibindev\">haibindev</a>&nbsp;\n阅读(<span id=\"post_view_count\">46</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "NIVIDIA高性能计算CUDA笔记（三） cuFFT的简介及实现案例",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19452487",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19452487\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:21\">\n    <span>NIVIDIA高性能计算CUDA笔记（三） cuFFT的简介及实现案例</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        cuFFT是NVIDIA提供的GPU加速的Fourier变换FFT库，能极大提升涉及FFT计算的科学计算、信号处理和深度学习等任务的速度。本笔记就cufft进行简单介绍并给出一个一维信号的fft变换示例\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"nividia高性能计算cuda笔记三-cufft的简介及实现案例\">NIVIDIA高性能计算CUDA笔记（三） cuFFT的简介及实现案例</h1>\n<h2 id=\"1-cufft库的简介introduction-of-cufft-libaray\">1. cuFFT库的简介（Introduction of cuFFT libaray）</h2>\n<p>​      Fourier变换是数字信号处理领域一个很重要的数学变换，它用来实现将信号实现将信号从时域到频域的变换，在物理学、数论、组合数学、信号处理、概率、统计、密码学、声学、光学等领域有广泛的应用。离散傅里叶变换(Discrete Fourier Transform，DFT)是连续傅里叶变换在离散系统中的表示形式，由于DFT的计算量很大，因此在很长一段时间内其应用受到了很大的限制。20世纪60年代（1965年）由Cooley和Tukey提出了快速傅里叶变换(Fast Fourier Transform，FFT)算法，它是DFT的快速算法，使得离散傅里叶变换和卷积这类难度很大的计算工作的复杂度从N2量级降到了Nlog2N量级，大大提高了DFT的运算速度，从而使DFT在实际应用中得到了广泛的应用。</p>\n<p>​       cuFFT是NVIDIA提供的GPU加速的Fourier变换FFT库，能极大提升涉及FFT计算的科学计算、信号处理和深度学习等任务的速度。下表概括了器主要特征和应用场景：</p>\n<table>\n<thead>\n<tr>\n<th>cuFFT的特征</th>\n<th>具体描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>基本功能</td>\n<td>提供GPU加速的1D、2D、3D复数/实数FFT计算</td>\n</tr>\n<tr>\n<td>核心优势</td>\n<td>相比CPU实现，利用GPU并行性可获得显著加速</td>\n</tr>\n<tr>\n<td>编程接口</td>\n<td>提供类似的FFTW的API，便于熟悉CPU FFT的用户迁移</td>\n</tr>\n<tr>\n<td>高级功能</td>\n<td>支持批量执行、流异步、半/单/双精度、多GPU计算</td>\n</tr>\n<tr>\n<td>主要应用领域</td>\n<td>深度学习、计算物理学、医学成像、信号处理等</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"2-基于cufft库的fourier变换步骤workflow-of-fourier-transform-based-cufft\">2. 基于cuFFT库的Fourier变换步骤（workflow of Fourier Transform based cuFFT）</h2>\n<p>在CUDA上进行傅里叶变换一般需要做以下几步工作：</p>\n<ol>\n<li>在主机端，准备输入数据；</li>\n<li>在GPU设备端上分配内存，并将数据从主机复制到设备；（<code>cudaMalloc</code>,<code>cudaMemcpy</code>的接口 ）</li>\n<li>创建一个<span class=\"math inline\">\\(plan\\)</span>, 调用函数<span class=\"math inline\">\\(cufftPlane1D/cufftPlane2D/cufftPlan3D\\)</span> 可以创建一个简单的Fourier变换。调用函数<span class=\"math inline\">\\(cufftPlanMany\\)</span> 则可以创建支持更多配置操作的变换计划。\n<ul>\n<li><span class=\"math inline\">\\(cufftPlan1d()\\)</span>: 针对单个1维信号</li>\n<li><span class=\"math inline\">\\(cufftPlan2d()\\)</span>:针对单个2维信号</li>\n<li><span class=\"math inline\">\\(cufftPlan3d()\\)</span>:针对单个3维信号</li>\n</ul>\n</li>\n<li>执行<span class=\"math inline\">\\(plane\\)</span>。这一步可以使用<span class=\"math inline\">\\(cufftExecC2C()\\)</span>、<span class=\"math inline\">\\(cufftExecR2C()\\)</span>或<span class=\"math inline\">\\(cufftExecC2R()\\)</span>等函数完成上一步完成<span class=\"math inline\">\\(plane\\)</span>的计算任务。</li>\n<li>执行完成以下若不再需要该<span class=\"math inline\">\\(plan\\)</span>，则调用<span class=\"math inline\">\\(cufftDestroy()\\)</span>函数销毁该<span class=\"math inline\">\\(plan\\)</span> 及为其分配的计算资源。</li>\n</ol>\n<h2 id=\"3-cufft的傅里叶变换api接口类型fourier-transform-types\">3. cuFFT的傅里叶变换API接口类型（Fourier Transform Types）</h2>\n<p>​        <span class=\"math inline\">\\(cuFFT\\)</span> 库实现了三种不同类型的Fourier变换接口分为：<span class=\"math inline\">\\(C2C\\)</span>(复数变换到复数)，<span class=\"math inline\">\\(C2R\\)</span>(复数到实数),  <span class=\"math inline\">\\(R2C\\)</span> (实数到复数)。本质上，这三种转换都可以被看做是复数域到复数域的变换，之所以这样划分，其最主要的考量是性能因素。例如，在一般的数字信号处理中，输入数据是一些离散的实数域上的采样点，这时候对它们做Fourier变换实际上就是<span class=\"math inline\">\\(R2C\\)</span>，根据埃尔米特对称性（Hermitian symmetry)，变换<span class=\"math inline\">\\(X_k=X_{N-k}^{*}\\)</span>, <span class=\"math inline\">\\(*\\)</span> 代表共轭复数。<span class=\"math inline\">\\(cuFFT\\)</span> 的傅里叶变换则利用了这些冗余，将计算量降到最低。</p>\n<p>​       变换执行函数的单精度和双精度版本分别定义如下：</p>\n<table>\n<thead>\n<tr>\n<th>API</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span class=\"math inline\">\\(cufftExecC2C()/cufftExecZ2Z()\\)</span></td>\n<td>单精度/双精度浮点数复数域到复数域的傅里叶变换</td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(cufftExecR2C()/cufftExecD2Z()\\)</span></td>\n<td>单精度/双精度浮点数实数域到复数域的傅里叶变换（正变换）</td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(cufftExecC2R()/cufftExecZ2D()\\)</span></td>\n<td>单精度/双精度浮点数复数域到实数域的傅里叶变换（逆变换）</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"4-数据布局data-layout\">4. 数据布局(Data Layout)</h2>\n<p>​       <span class=\"math inline\">\\(CUFFT\\)</span>库保含若干种数据类型，对于复数有<span class=\"math inline\">\\(cufftComplex/cufftDoubleComplex\\)</span> 两种数据类型，对于实数则分别有<span class=\"math inline\">\\(cufftReal/cufftDouble\\)</span> 两种数据类型 。</p>\n<p>​         根据转换结果的存储位置不同，<span class=\"math inline\">\\(FFT\\)</span>变换可分为就地变换(<span class=\"math inline\">\\(in-place\\)</span>)和外部变换（<span class=\"math inline\">\\(out-place\\)</span>)，前者直接在输入数据进行变换，而后者则会将变换后结果存入新的存储器地址。</p>\n<p>​         就地转换(<span class=\"math inline\">\\(in-place\\)</span>) 支持数据的两种布局：<span class=\"math inline\">\\(native\\)</span> 和 <span class=\"math inline\">\\(padded\\)</span>，前者用于获取最佳性能，而后者则用于与FFTW兼容。</p>\n<p>​         在<span class=\"math inline\">\\(padded\\)</span>布局中输出信号的开始地址与输入信号一样，换句话说，实数域到复数域变换的输入数据和复数域到实数域的输出数据必须被填充。在native布局中则没有填入要求。</p>\n<p>​         输入数据和输出数据的尺寸总结如下：</p>\n<table>\n<thead>\n<tr>\n<th>FFT type</th>\n<th>input data size</th>\n<th>output data size</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span class=\"math inline\">\\(C2C\\)</span></td>\n<td><span class=\"math inline\">\\(X \\space cufftComplex\\)</span></td>\n<td><span class=\"math inline\">\\(X \\space cufftComplex\\)</span></td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(C2R\\)</span></td>\n<td><span class=\"math inline\">\\([\\frac{X}{2}]+1 \\space cufftComplex\\)</span></td>\n<td><span class=\"math inline\">\\(X\\)</span> <span class=\"math inline\">\\(cufftReal\\)</span></td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(R2C^{*}\\)</span></td>\n<td><span class=\"math inline\">\\(X\\)</span> <span class=\"math inline\">\\(cufftReal\\)</span></td>\n<td><span class=\"math inline\">\\([\\frac{X}{2}]+1 \\space cufftComplex\\)</span></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5-单个一维信号的fft变换代码实现one-dimension-signal-fft-transfrom\">5. 单个一维信号的FFT变换代码实现（One Dimension SIgnal FFT Transfrom）</h2>\n<p>在本次测试代码中：首先生成一维的随机信号，利用cufft 先进行正变换，然后逆变换，并判定逆变换后结果与原输入信号判断是否相等。</p>\n<pre><code class=\"language-C\">#include &lt;iostream&gt;\n#include &lt;time.h&gt;\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include &lt;cufft.h&gt;\n\n#define NX 3335 // 有效数据个数\n#define N 5335 // 补0之后的数据长度\n#define BATCH 1\n#define BLOCK_SIZE 1024\nusing std::cout;\nusing std::endl;\n\n\n/**\n* 功能：判断两个 cufftComplex 数组的是否相等\n* 输入：idataA 输入数组A的头指针\n* 输入：idataB 输出数组B的头指针\n* 输入：size 数组的元素个数\n* 返回：true | false\n*/\nbool IsEqual(cufftComplex *idataA, cufftComplex *idataB, const int size)\n{\n    for (int i = 0; i &lt; size; i++)\n    {\n        if (abs(idataA[i].x - idataB[i].x) &gt; 0.000001 || abs(idataA[i].y - idataB[i].y) &gt; 0.000001)\n            return false;\n    }\n\n    return true;\n}\n\n\n\n/**\n* 功能：实现 cufftComplex 数组的尺度缩放，也就是乘以一个数\n* 输入：idata 输入数组的头指针\n* 输出：odata 输出数组的头指针\n* 输入：size 数组的元素个数\n* 输入：scale 缩放尺度\n*/\nstatic __global__ void cufftComplexScale(cufftComplex *idata, cufftComplex *odata, const int size, float scale)\n{\n    const int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (threadID &lt; size)\n    {\n        odata[threadID].x = idata[threadID].x * scale;\n        odata[threadID].y = idata[threadID].y * scale;\n    }\n}\n\nint main()\n{\n    cufftComplex *data_dev; // 设备端数据头指针\n    cufftComplex *data_Host = (cufftComplex*)malloc(NX*BATCH * sizeof(cufftComplex)); // 主机端数据头指针\n    cufftComplex *resultFFT = (cufftComplex*)malloc(N*BATCH * sizeof(cufftComplex)); // 正变换的结果\n    cufftComplex *resultIFFT = (cufftComplex*)malloc(NX*BATCH * sizeof(cufftComplex)); // 先正变换后逆变换的结果\n\n    // 初始数据\n    for (int i = 0; i &lt; NX; i++)\n    {\n        data_Host[i].x = float((rand() * rand()) % NX) / NX;\n        data_Host[i].y = float((rand() * rand()) % NX) / NX;\n    }\n\n\n    dim3 dimBlock(BLOCK_SIZE); // 线程块\n    dim3 dimGrid((NX + BLOCK_SIZE - 1) / dimBlock.x); // 线程格\n\n    cufftHandle plan; // 创建cuFFT句柄\n    cufftPlan1d(&amp;plan, N, CUFFT_C2C, BATCH);\n\n    // 计时\n    clock_t start, stop;\n    double duration;\n    start = clock();\n\n    cudaMalloc((void**)&amp;data_dev, sizeof(cufftComplex)*N*BATCH); // 开辟设备内存\n    cudaMemset(data_dev, 0, sizeof(cufftComplex)*N*BATCH); // 初始为0\n    cudaMemcpy(data_dev, data_Host, NX * sizeof(cufftComplex), cudaMemcpyHostToDevice); // 从主机内存拷贝到设备内存\n\n    cufftExecC2C(plan, data_dev, data_dev, CUFFT_FORWARD); // 执行 cuFFT，正变换\n    cudaMemcpy(resultFFT, data_dev, N * sizeof(cufftComplex), cudaMemcpyDeviceToHost); // 从设备内存拷贝到主机内存\n\n    cufftExecC2C(plan, data_dev, data_dev, CUFFT_INVERSE); // 执行 cuFFT，逆变换\n    cufftComplexScale &lt;&lt; &lt;dimGrid, dimBlock &gt;&gt; &gt; (data_dev, data_dev, N, 1.0f / N); // 乘以系数\n    cudaMemcpy(resultIFFT, data_dev, NX * sizeof(cufftComplex), cudaMemcpyDeviceToHost); // 从设备内存拷贝到主机内存\n\n    stop = clock();\n    duration = (double)(stop - start) * 1000 / CLOCKS_PER_SEC;\n    cout &lt;&lt; \"时间为 \" &lt;&lt; duration &lt;&lt; \" ms\" &lt;&lt; endl;\n\n    cufftDestroy(plan); // 销毁句柄\n    cudaFree(data_dev); // 释放空间\n\n    cout &lt;&lt; IsEqual(data_Host, resultIFFT, NX) &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>\n<p>其中<code>cufftPlan1d()</code> :</p>\n<ul>\n<li>第一个参数就是要配置的<span class=\"math inline\">\\(cuFFT\\)</span>句柄；</li>\n<li>第二个参数就是要进行fft的信号的长度；</li>\n<li>第三个<code>CUFFT_C2C</code> 为要执行<span class=\"math inline\">\\(fft\\)</span> 的信号输入类型及输出类型复数；<code>CUFFT_C2R</code>表示输入复数，输出实数；<code>CUFFT_R2C</code>表示输入实数，输出复数；<code>CUFFT_R2R</code> 表示输入实数，输出实数；</li>\n<li>第四个参数<code>BATCH</code>表示要执行fft的信号的个数，新版的已经使用<code>cufftPlanMany()</code>来同时完成多个信号的fft；</li>\n</ul>\n<p><code>cufftExecC2C()</code>:</p>\n<ul>\n<li>第一个参数就是配置好的 cuFFT 句柄；</li>\n<li>第二个参数为输入信号的首地址；</li>\n<li>第三个参数为输出信号的首地址；</li>\n<li>第四个参数为<code>CUFFT_FORWARD</code>表示执行的是<span class=\"math inline\">\\(fft\\)</span>正变换；<code>CUFFT_INVERSE</code>表示执行<span class=\"math inline\">\\(fft\\)</span>逆变换</li>\n</ul>\n<p>需要注意的是，执行完<span class=\"math inline\">\\(fft\\)</span>之后，要对信号中的每个值乘以<span class=\"math inline\">\\(1/N\\)</span>;</p>\n<p>输出结果：</p>\n<p><img alt=\"cufft\" class=\"lazyload\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 15:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">77</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "IQR四分位数法是什么？",
      "link": "https://www.cnblogs.com/sun-10387834/p/19386427",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19386427\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:06\">\n    <span>IQR四分位数法是什么？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>IQR（Interquartile Range，四分位距）四分位数法是一种统计学中用于描述数据离散程度、识别异常值的重要工具。它通过数据的四分位数（Quartiles）来刻画数据的分布特征，尤其适用于非正态分布或存在离群点的场景。以下从核心概念、计算方法、应用场景和理解要点展开说明：</p>\n<h3 id=\"一核心概念四分位数与iqr\"><strong>一、核心概念：四分位数与IQR</strong></h3>\n<h4 id=\"1-四分位数quartiles\">1. 四分位数（Quartiles）</h4>\n<p>将一组有序数据（从小到大排列）划分为4个相等部分的三个关键分割点，分别记为：</p>\n<ul>\n<li><strong>Q1（第一四分位数，25%分位数）</strong>：数据中25%的数值小于或等于它（即第25百分位数）。</li>\n<li><strong>Q2（第二四分位数，中位数）</strong>：数据中50%的数值小于或等于它（即第50百分位数，Median）。</li>\n<li><strong>Q3（第三四分位数，75%分位数）</strong>：数据中75%的数值小于或等于它（即第75百分位数）。</li>\n</ul>\n<p>例如，数据集 [1, 3, 5, 7, 9, 11, 13] 的中位数是7（Q2）；前半部分 [1,3,5] 的中位数是3（Q1），后半部分 [9,11,13] 的中位数是11（Q3）。</p>\n<h4 id=\"2-iqr四分位距\">2. IQR（四分位距）</h4>\n<p><strong>IQR = Q3 - Q1</strong>，表示中间50%数据的分布范围（即数据在Q1到Q3之间的“宽度”）。它是衡量数据离散程度的稳健指标（不受极端值影响）。</p>\n<h3 id=\"二iqr四分位数法的核心作用识别异常值\"><strong>二、IQR四分位数法的核心作用：识别异常值</strong></h3>\n<p>IQR法最常用的是通过“箱线图（Box Plot）”或“Tukey’s Fences”规则识别异常值（Outliers）。具体步骤如下：</p>\n<h4 id=\"1-计算上下边界\">1. 计算上下边界</h4>\n<p>以IQR为基准，定义数据的“正常范围”：</p>\n<ul>\n<li><strong>下边界（Lower Bound）</strong>：Q1 - 1.5×IQR</li>\n<li><strong>上边界（Upper Bound）</strong>：Q3 + 1.5×IQR</li>\n</ul>\n<h4 id=\"2-判定异常值\">2. 判定异常值</h4>\n<ul>\n<li><strong>温和异常值（Mild Outliers）</strong>：小于下边界或大于上边界的数据点（通常用1.5×IQR界定）。</li>\n<li><strong>极端异常值（Extreme Outliers）</strong>：小于Q1 - 3×IQR 或大于Q3 + 3×IQR 的数据点（更严格的阈值）。</li>\n</ul>\n<p><strong>逻辑</strong>：正常数据应集中在中间50%（Q1到Q3），而超出1.5倍IQR的点被视为“偏离较远的异常”。1.5倍的选择是经验性的（基于正态分布假设下约覆盖99.3%的数据，剩余0.7%视为异常）。</p>\n<h3 id=\"三应用场景\"><strong>三、应用场景</strong></h3>\n<ol>\n<li><strong>数据清洗</strong>：识别并验证离群点（如传感器误差、输入错误）。</li>\n<li><strong>可视化分析</strong>：箱线图的核心组件（箱体表示Q1到Q3，触须延伸至非异常值的最远点，异常值单独标记）。</li>\n<li><strong>统计描述</strong>：替代标准差（SD）衡量离散程度（尤其当数据非正态时，IQR更稳健）。</li>\n</ol>\n<h3 id=\"四如何理解iqr法的优势与局限\"><strong>四、如何理解IQR法的优势与局限</strong></h3>\n<h4 id=\"优势\">优势：</h4>\n<ul>\n<li><strong>稳健性</strong>：仅依赖中间50%的数据，不受极端值干扰（标准差易受异常值影响）。</li>\n<li><strong>普适性</strong>：适用于任何分布（无需假设数据正态）。</li>\n<li><strong>直观性</strong>：通过四分位数直接反映数据的集中与分散趋势。</li>\n</ul>\n<h4 id=\"局限\">局限：</h4>\n<ul>\n<li><strong>主观性</strong>：1.5倍IQR是经验阈值，不同领域可能调整（如金融风控可能用3倍）。</li>\n<li><strong>小样本偏差</strong>：样本量过小时（如n&lt;10），四分位数估计可能不稳定。</li>\n<li><strong>无法反映分布形态</strong>：仅描述离散程度，不体现数据的对称性或峰度。</li>\n</ul>\n<h3 id=\"五示例说明\"><strong>五、示例说明</strong></h3>\n<p>假设数据集：[12, 15, 17, 19, 20, 22, 24, 28, 30, 35, 40, 100]（已排序）。</p>\n<ol>\n<li>\n<p>计算四分位数：</p>\n<ul>\n<li>n=12，中位数Q2是第6和第7个数的平均：(22+24)/2=23。</li>\n<li>Q1是前6个数的中位数：(17+19)/2=18（前6数：12,15,17,19,20,22）。</li>\n<li>Q3是后6个数的中位数：(30+35)/2=32.5（后6数：24,28,30,35,40,100）。</li>\n</ul>\n</li>\n<li>\n<p>计算IQR：IQR=Q3-Q1=32.5-18=14.5。</p>\n</li>\n<li>\n<p>确定边界：</p>\n<ul>\n<li>下边界=18 - 1.5×14.5=18-21.75=-3.75</li>\n<li>上边界=32.5 + 1.5×14.5=32.5+21.75=54.25</li>\n</ul>\n</li>\n<li>\n<p>识别异常值：数据中100&gt;54.25，因此100是异常值；其他数据点均在[-3.75, 54.25]范围内。</p>\n</li>\n</ol>\n<h3 id=\"总结\"><strong>总结</strong></h3>\n<p>IQR四分位数法通过“中间50%数据的范围”（IQR）量化离散程度，并通过1.5倍IQR的边界识别异常值。它的核心是<strong>关注数据的主体分布，忽略极端干扰</strong>，是探索性数据分析（EDA）中简单却强大的工具。理解其逻辑的关键在于把握“四分位数划分数据、IQR衡量主体波动、边界外视为异常”这一链条。</p>\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19386427\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19386427</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 15:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">53</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "SQL 性能避坑：为什么阿里强制禁用 ORDER BY RAND()？",
      "link": "https://www.cnblogs.com/xzqcsj/p/19452232",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzqcsj/p/19452232\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 14:43\">\n    <span>SQL 性能避坑：为什么阿里强制禁用 ORDER BY RAND()？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"SQL 性能避坑：为什么阿里强制禁用 ORDER BY RAND()？\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3703499/202601/3703499-20260107144026422-1062364965.png\" />\n        如果你翻阅过《阿里巴巴 Java 开发手册》，在 MySQL 数据库规约中，一定见过这条醒目的“红线”：【强制】不得在 database 中使用 ORDER BY RAND() 进行随机排序。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzYyMzM2MjA2OA==&amp;action=getalbum&amp;album_id=4252891456433995787#wechat_redirect\" rel=\"noopener nofollow\" target=\"_blank\">MySQL专栏</a></p>\n<p>如果你翻阅过《阿里巴巴 Java 开发手册》，在 MySQL 数据库规约中，一定见过这条醒目的“红线”：</p>\n<blockquote>\n<p><strong>【强制】不得在 database 中使用 ORDER BY RAND() 进行随机排序。</strong></p>\n</blockquote>\n<p>很多人第一反应是：“不就随机查几条数据吗？MySQL 既然提供了这个内置函数，为什么不让用？”</p>\n<p>事实上，这可能是 MySQL 里最“坑爹”的内置函数之一。在数据量只有几百条时，它是省时省力的小甜甜；一旦数据量突破十万级，它立马变身吸干 CPU 的“牛夫人”，分分钟让你的数据库报警。</p>\n<p>今天我们就来扒一扒，为什么这个函数是性能杀手，以及在海量数据下，我们该如何<strong>优雅且高性能</strong>地实现“<strong>随机推荐</strong>”功能。</p>\n</blockquote>\n<p><img alt=\"874681b40ba63432d5615fd64ad878f4\" class=\"lazyload\" /></p>\n<h2 id=\"案发现场一条-sql-引发的血案\">案发现场：一条 SQL 引发的血案</h2>\n<p>那个让 DBA 暴跳如雷的 SQL 长这样：</p>\n<pre><code class=\"language-sql\">-- 看起来人畜无害，实则剧毒无比\nSELECT * FROM product ORDER BY RAND() LIMIT 3;\n</code></pre>\n<p>如果你的商品表只有几百条数据，怎么玩都行。但当数据量达到 <strong>几万、几十万甚至上百万</strong> 时，这条 SQL 就是一颗定时炸弹。</p>\n<h3 id=\"为什么它这么慢\">为什么它这么慢？</h3>\n<p>我在测试环境重现了一下，顺手敲了个 <code>EXPLAIN</code>。好家伙，<code>Extra</code> 字段里赫然写着：</p>\n<blockquote>\n<p><strong>Using temporary; Using filesort</strong></p>\n</blockquote>\n<p>这简直是 MySQL 性能杀手界的“卧龙凤雏”！</p>\n<p><code>ORDER BY RAND()</code> 的执行流程大致是这样的：</p>\n<ol>\n<li><strong>全表扫描</strong>：MySQL 需要为每一行数据生成一个随机值。</li>\n<li><strong>创建临时表</strong>：把<strong>查询列</strong>和<strong>对应的随机值</strong>塞进临时表（如果内存不够，还会用到磁盘临时表）。</li>\n<li><strong>全局排序</strong>：对临时表里的随机值进行排序。</li>\n<li><strong>取出前几条</strong>：这就好比你要从一袋米里随机挑 3 粒，却先把整袋米倒出来，给每粒米编个号，排个序，再挑前 3 个。</li>\n</ol>\n<p>这不崩谁崩？</p>\n<hr />\n<h2 id=\"深入剖析五种高性能替代方案\">深入剖析：五种高性能替代方案</h2>\n<p>既然 <code>ORDER BY RAND()</code> 不能用，那怎么实现“随机推荐”？其实思路很简单：<strong>把“计算随机”的压力从 Database 转移到 Application（应用层）</strong>，或者<strong>减少数据库的扫描行数</strong>。</p>\n<h3 id=\"方案一应用层随机法application-shuffle\">方案一：应用层随机法（Application Shuffle）</h3>\n<p><strong>适用场景</strong>：数据量不大（例如 &lt; 10万），内存不值钱。</p>\n<p><strong>核心思想</strong>：既然数据库随机排序慢，那我把 ID 全拿出来，在 Java 代码里洗牌行不行？</p>\n<h4 id=\"代码实现\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 查出所有商品ID（只查ID，速度飞快）\n// SQL: SELECT id FROM product;\nList&lt;Integer&gt; allProductIds = productMapper.selectAllIds();\n\n// 2. 利用 Java 的 Collections 工具类进行洗牌\nCollections.shuffle(allProductIds);\n\n// 3. 截取前3个\nList&lt;Integer&gt; randomIds = allProductIds.subList(0, 3);\n\n// 4. 回表批量查询详情\n// SQL: SELECT * FROM product WHERE id IN (..., ..., ...);\nList&lt;Product&gt; results = productMapper.selectByIds(randomIds);\n</code></pre>\n<h4 id=\"优缺点点评\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：真・随机，由于用了 <code>Collections.shuffle</code>，随机分布非常均匀；逻辑简单粗暴。</li>\n<li><strong>缺点</strong>：太占内存。如果表里有 1000 万条 ID，全拉到内存里，JVM 直接 OOM 教做人。</li>\n<li><strong>避坑</strong>：一定要给 ID 列表加缓存（Redis 或本地缓存），别每次请求都去查全量 ID，那跟直接攻击数据库没区别。</li>\n</ul>\n<hr />\n<h3 id=\"方案二limit-偏移法limit-offset\">方案二：Limit 偏移法（Limit Offset）</h3>\n<p><strong>适用场景</strong>：数据量大（百万级以上），对随机性要求没那么严苛。</p>\n<p><strong>核心思想</strong>：给所有数据编个号，随机生成一个“偏移量”，直接跳到那里去拿。</p>\n<h4 id=\"代码实现-1\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 先查询总数（可以走缓存）\n// SQL: SELECT COUNT(*) FROM product;\nint totalCount = productMapper.count();\n\n// 2. 随机生成一个偏移量\n// 注意：totalCount - 3 是为了防止 limit 越界，确保能取够3条\nint offset = new Random().nextInt(totalCount - 3);\n\n// 3. 直接利用 LIMIT 偏移量查询\n// SQL: SELECT * FROM product LIMIT #{offset}, 3;\nList&lt;Product&gt; results = productMapper.selectByOffset(offset, 3);\n</code></pre>\n<h4 id=\"优缺点点评-1\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：性能极佳！大部分情况下只需要扫描 <code>offset + 3</code> 行 ，count值可以放缓存中，定期更新。</li>\n<li><strong>缺点</strong>：\n<ol>\n<li><strong>伪随机</strong>：你取出来的 3 条数据是<strong>物理上连续</strong>的。比如正好取出了“iPhone 13, iPhone 14, iPhone 15”，看起来不够随机。</li>\n<li><strong>深分页问题</strong>：如果随机到的 <code>offset</code> 很大（比如 900万），<code>LIMIT 9000000, 3</code> 的性能也会下降，因为 MySQL 要先扫过前 900 万行扔掉。</li>\n</ol>\n</li>\n</ul>\n<hr />\n<h3 id=\"方案三多次查询法multiple-queries\">方案三：多次查询法（Multiple Queries）</h3>\n<p><strong>适用场景</strong>：数据量大，且要求高质量随机。</p>\n<p><strong>核心思想</strong>：既然方案二取出的数据是连续的，那我多随机几次，每次取 1 条，拼凑出 3 条不就行了？</p>\n<h4 id=\"代码实现-2\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 获取总数\nint total = productMapper.count();\n\n// 2. 生成3个不重复的随机下标（Java 8 Stream 写法）\nList&lt;Integer&gt; randomOffsets = new Random()\n        .ints(0, total) // 生成无限流\n        .distinct()     // 去重\n        .limit(3)       // 截取前3个\n        .boxed()\n        .collect(Collectors.toList());\n\n// 3. 循环查询（或者拼接 SQL 用 UNION ALL）\nList&lt;Product&gt; result = new ArrayList&lt;&gt;();\nfor (Integer offset : randomOffsets) {\n    // SQL: SELECT * FROM product LIMIT #{offset}, 1\n    result.add(productMapper.selectByLimit(offset, 1));\n}\n</code></pre>\n<p>其实这就是 <strong>MySQL 45讲</strong> 里推荐的优化思路。相比于方案二，它打散了连续性。</p>\n<h4 id=\"优缺点点评-2\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：既避免了全表排序，又保证了较好的随机性。</li>\n<li><strong>缺点</strong>：要与数据库交互多次（N 次查询）。不过对于高并发应用，一般都是多次查询 + 缓存，这点开销完全可以接受。</li>\n</ul>\n<h3 id=\"方案四主键范围法index-random\">方案四：主键范围法（Index Random）</h3>\n<p><strong>适用场景</strong>：ID 必须这是连续的（或空洞很少），追求极致性能。</p>\n<p><strong>核心思想</strong>：既然 <code>LIMIT N, M</code> 越往后越慢，那我直接算出随机 ID，用主键索引“跳”过去不就完事了？</p>\n<h4 id=\"代码实现-3\">代码实现</h4>\n<p><strong>Java 逻辑处理：</strong></p>\n<pre><code class=\"language-java\">// 1. 获取 ID 范围（minId 和 maxId）\n// SQL: SELECT MIN(id), MAX(id) FROM product;\nlong minId = productMapper.selectMinId();\nlong maxId = productMapper.selectMaxId();\n\n// 2. 计算随机起点\n// 注意：maxId - minId - 3 是为了保证起点的 id 后面至少还有 3 条数据（假设 ID 连续）\n// 如果 ID 极其稀疏，这个范围可能需要预留更大\nlong range = maxId - minId - 3; \nlong randomId = minId + (long)(Math.random() * range);\n\n// 3. 执行查询\nList&lt;Product&gt; products = productMapper.selectGtId(randomId, 3);\n</code></pre>\n<p><strong>SQL 实现：</strong></p>\n<pre><code class=\"language-sql\">SELECT * FROM product \nWHERE id &gt;= #{randomId} \nLIMIT 3;\n</code></pre>\n<h4 id=\"优缺点点评-3\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：速度快到飞起！复杂度直接降为 $O(\\log N)$（主键查找），完全没有 <code>LIMIT</code> 深分页的性能衰减。</li>\n<li><strong>缺点</strong>：<strong>非常挑食！</strong> 它假设 ID 是连续的。如果你的商品表里因为删删改改导致 ID 中间空洞很大，这类 SQL 会导致分布严重不均（空洞前的那条数据被选中的概率会暴增），甚至可能取不到数据。</li>\n</ul>\n<hr />\n<h3 id=\"方案五redis-预处理法redis-set\">方案五：Redis 预处理法（Redis Set）</h3>\n<p><strong>适用场景</strong>：高并发、高性能、大数据量，标准的互联网大厂打法。</p>\n<p><strong>核心思想</strong>：既然 MySQL 不擅长做随机，那就别难为它了，交给最擅长的 Redis。</p>\n<h4 id=\"代码实现-4\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 初始化（只需做一次）：把所有商品ID丢进 Redis Set\n// Redis Key: \"all_product_ids\"\n\n// 2. 利用 Redis 原生命令随机获取 ID\n// 命令：SRANDMEMBER key count\n// 时间复杂度：O(N)，N是你取的数量，极快\nList&lt;Integer&gt; randomIds = redisTemplate.opsForSet().randomMembers(\"all_product_ids\", 3);\n\n// 3. 回表 MySQL 查详情（这里全是主键查询，性能无压力）\nList&lt;Product&gt; products = productMapper.selectByIds(randomIds);\n</code></pre>\n<h4 id=\"优缺点点评-4\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：<strong>天花板级别的性能</strong>。无论你有多少数据，Redis 都基本能在几毫秒内吐出随机 ID。</li>\n<li><strong>缺点</strong>：架构变复杂了。你需要维护 Redis 和 MySQL 的数据同步（也就是经典的缓存一致性问题）。</li>\n</ul>\n<hr />\n<h2 id=\"最终总结选型指南\">最终总结：选型指南</h2>\n<p>那这几种方案怎么选？</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">你的场景</th>\n<th style=\"text-align: left;\">推荐方案</th>\n<th style=\"text-align: left;\">理由</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &lt; 10W</strong></td>\n<td style=\"text-align: left;\"><strong>方案一（应用层 Shuffle）</strong></td>\n<td style=\"text-align: left;\">开发最快，逻辑最简单，随机性最完美。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &gt; 10W，ID连续</strong></td>\n<td style=\"text-align: left;\"><strong>方案四（索引跳跃）</strong></td>\n<td style=\"text-align: left;\">既不用维护缓存，又能享受极致性能。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &gt; 10W，允许连续</strong></td>\n<td style=\"text-align: left;\"><strong>方案二（Limit Offset）</strong></td>\n<td style=\"text-align: left;\">性能不错，通用性强，是个老实人。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &gt; 10W，要求打散</strong></td>\n<td style=\"text-align: left;\"><strong>方案三（多次查询）</strong></td>\n<td style=\"text-align: left;\">在性能和随机性之间找到了平衡点。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>高并发 / 追求极致</strong></td>\n<td style=\"text-align: left;\"><strong>方案五（Redis Set）</strong></td>\n<td style=\"text-align: left;\">工业界标准答案，虽然稍微麻烦点，但真香。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>想被辞退</strong></td>\n<td style=\"text-align: left;\"><strong>ORDER BY RAND()</strong></td>\n<td style=\"text-align: left;\">只要你敢用，P0 故障随时带回家。</td>\n</tr>\n</tbody>\n</table>\n<p><strong>最后多嘴一句</strong>：<br />\n如果你的业务可以接受“伪随机”（比如每个人看到的随机列表在 1 小时内是一样的），<strong>强烈建议把算好的随机结果丢进 Redis</strong>。毕竟，<strong>最好的 SQL 优化就是不执行 SQL</strong>。</p>\n<p>别让你写的代码，成为深夜报警的罪魁祸首。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 14:43</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzqcsj\">一旅人</a>&nbsp;\n阅读(<span id=\"post_view_count\">229</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "三大 Agent-UI 协议深度剖析：AG-UI、A2UI 与 MCP-UI 的设计哲学与工程实践",
      "link": "https://www.cnblogs.com/madtom/p/19452209",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/madtom/p/19452209\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 14:36\">\n    <span>三大 Agent-UI 协议深度剖析：AG-UI、A2UI 与 MCP-UI 的设计哲学与工程实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        随着大模型从\"对话框\"演进为\"自主智能体\"，如何让 Agent 具备富交互能力成为关键挑战。本文基于项目实战，结合 AG-UI、A2UI、MCP-UI 三大协议的源码深度分析，系统阐述它们的设计哲学、核心机制、实现方案及对接方式，并探讨协议组合使用的最佳实践。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>摘要</strong>：随着大模型从\"对话框\"演进为\"自主智能体\"，如何让 Agent 具备富交互能力成为关键挑战。本文基于项目实战，结合 AG-UI、A2UI、MCP-UI 三大协议的源码深度分析，系统阐述它们的设计哲学、核心机制、实现方案及对接方式，并探讨协议组合使用的最佳实践。</p>\n</blockquote>\n<p><img alt=\"占位符：文章封面图 - 三大协议的技术架构全景图\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"目录\">目录</h2>\n<ol>\n<li><a href=\"#1-%E5%BC%95%E8%A8%80%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-agent-ui-%E5%8D%8F%E8%AE%AE\" rel=\"noopener nofollow\">引言：为什么需要 Agent-UI 协议？</a></li>\n<li><a href=\"#2-ag-ui%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E4%BA%A4%E4%BA%92%E5%8D%8F%E8%AE%AE\" rel=\"noopener nofollow\">AG-UI：事件驱动的智能体交互协议</a></li>\n<li><a href=\"#3-a2ui%E5%A3%B0%E6%98%8E%E5%BC%8F-ui-%E7%9A%84%E9%9B%B6%E4%BF%A1%E4%BB%BB%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E\" rel=\"noopener nofollow\">A2UI：声明式 UI 的零信任渲染引擎</a></li>\n<li><a href=\"#4-mcp-uimcp-%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%89%A9%E5%B1%95%E5%B1%82\" rel=\"noopener nofollow\">MCP-UI：MCP 协议的可视化扩展层</a></li>\n<li><a href=\"#5-%E5%8D%8F%E8%AE%AE%E7%BB%84%E5%90%88ag-ui--a2ui-%E7%9A%84%E5%8D%8F%E5%90%8C%E6%9E%B6%E6%9E%84\" rel=\"noopener nofollow\">协议组合：AG-UI + A2UI 的协同架构</a></li>\n<li><a href=\"#6-%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E5%86%B3%E7%AD%96%E6%A1%86%E6%9E%B6\" rel=\"noopener nofollow\">技术选型决策框架</a></li>\n<li><a href=\"#7-demo-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E8%A7%A3%E6%9E%90\" rel=\"noopener nofollow\">Demo 项目实战解析</a></li>\n<li><a href=\"#8-%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B\" rel=\"noopener nofollow\">总结与展望</a></li>\n</ol>\n<hr />\n<h2 id=\"1-引言为什么需要-agent-ui-协议\">1. 引言：为什么需要 Agent-UI 协议？</h2>\n<h3 id=\"11-传统-chatbot-的局限性\">1.1 传统 Chatbot 的局限性</h3>\n<p>传统的 AI 聊天机器人采用简单的 <strong>Request-Response</strong> 模式：用户输入文本，模型返回文本。这种模式在面对复杂业务场景时暴露出严重不足：</p>\n<pre><code>用户 → \"帮我订一家北京的川菜馆\"\n传统 Bot → \"好的，我找到了以下餐厅：1. 川办餐厅... 2. 眉州东坡...\"\n</code></pre>\n<p><strong>问题</strong>：</p>\n<ul>\n<li>❌ 无法展示餐厅图片、评分、价格等结构化信息</li>\n<li>❌ 用户需要手动复制餐厅名称再去搜索</li>\n<li>❌ 无法直接在对话中完成预订操作</li>\n</ul>\n<h3 id=\"12-agent-时代的新需求\">1.2 Agent 时代的新需求</h3>\n<p>当 AI 从 Chatbot 升级为 Agent 后，交互模式发生了本质变化：</p>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>Chatbot</th>\n<th>Agent</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>运行时间</strong></td>\n<td>短（毫秒级）</td>\n<td>长（秒/分钟级）</td>\n</tr>\n<tr>\n<td><strong>输出类型</strong></td>\n<td>纯文本</td>\n<td>文本 + 结构化数据 + UI 控制</td>\n</tr>\n<tr>\n<td><strong>状态管理</strong></td>\n<td>无状态</td>\n<td>复杂状态机</td>\n</tr>\n<tr>\n<td><strong>交互模式</strong></td>\n<td>单轮 Q&amp;A</td>\n<td>多轮工具调用 + 人机协作</td>\n</tr>\n</tbody>\n</table>\n<div class=\"mermaid\">flowchart TB\n    subgraph Chatbot[\"🤖 传统 Chatbot\"]\n        direction TB\n        U1[\"👤 用户\"] --&gt;|\"文本输入\"| B1[\"💬 Bot\"]\n        B1 --&gt;|\"文本输出\"| U1\n    end\n    \n    subgraph Agent[\"🦾 智能体 Agent\"]\n        direction TB\n        U2[\"👤 用户\"] --&gt;|\"多模态输入\"| A[\"🧠 Agent\"]\n        A --&gt;|\"状态事件\"| SM[\"📊 状态机\"]\n        SM --&gt;|\"UI 更新\"| UI[\"🖥️ 富交互 UI\"]\n        A &lt;--&gt;|\"工具调用\"| T[\"🔧 Tools\"]\n        UI --&gt;|\"用户操作\"| A\n    end\n    \n    Chatbot -.-&gt;|\"演进\"| Agent\n</div><h3 id=\"13-三种协议的定位\">1.3 三种协议的定位</h3>\n<p>业界给出了三种截然不同的解决方案：</p>\n<table>\n<thead>\n<tr>\n<th>协议</th>\n<th>来源</th>\n<th>核心定位</th>\n<th>一句话概括</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>AG-UI</strong></td>\n<td>CopilotKit</td>\n<td>事件驱动的状态同步协议</td>\n<td>\"让前端实时感知 Agent 的每一步思考\"</td>\n</tr>\n<tr>\n<td><strong>A2UI</strong></td>\n<td>Google</td>\n<td>声明式 UI 组件规范</td>\n<td>\"Agent 描述意图，客户端负责渲染\"</td>\n</tr>\n<tr>\n<td><strong>MCP-UI</strong></td>\n<td>社区</td>\n<td>MCP 工具的可视化扩展</td>\n<td>\"让工具调用结果具备可视化能力\"</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"2-ag-ui事件驱动的智能体交互协议\">2. AG-UI：事件驱动的智能体交互协议</h2>\n<h3 id=\"21-设计哲学\">2.1 设计哲学</h3>\n<p>AG-UI（Agent-User Interaction Protocol）的核心理念可以概括为：</p>\n<blockquote>\n<p><strong>\"UI 是前端的领域，Agent 只负责广播状态变化\"</strong></p>\n</blockquote>\n<p>AG-UI 认为：Agent 不应该知道\"按钮是圆的还是方的\"，不应该知道\"当前是 React 还是 Vue\"。Agent 只需要告诉前端：\"我正在调用搜索工具\"、\"搜索参数是 XXX\"、\"搜索结果是 YYY\"。至于如何渲染这些信息，完全由前端决定。</p>\n<p>这种设计带来了几个核心优势：</p>\n<ol>\n<li><strong>前端自由度最大化</strong>：同一个 Agent 可以对接 Web、Mobile、CLI 等不同客户端</li>\n<li><strong>实时性极强</strong>：基于流式事件，用户能看到 Agent 思考的每一步</li>\n<li><strong>与现有应用深度集成</strong>：Agent 可以驱动现有 UI 的状态变化</li>\n</ol>\n<div class=\"mermaid\">flowchart LR\n    subgraph Backend[\"🔙 Agent Backend\"]\n        LLM[\"🧠 LLM\"] --&gt; EP[\"Event Producer\"]\n        Tools[\"🔧 Tools\"] --&gt; EP\n    end\n    \n    subgraph Transport[\"📡 传输层\"]\n        EP --&gt;|\"SSE Stream\"| SSE[\"text/event-stream\"]\n    end\n    \n    subgraph Frontend[\"🖥️ Frontend\"]\n        SSE --&gt; Parser[\"Event Parser\"]\n        Parser --&gt; SM[\"State Machine\"]\n        SM --&gt; |\"TEXT_MESSAGE\"| Chat[\"💬 聊天区\"]\n        SM --&gt; |\"TOOL_CALL\"| TC[\"🔧 工具卡片\"]\n        SM --&gt; |\"STATE_DELTA\"| App[\"📊 应用状态\"]\n    end\n</div><h3 id=\"22-核心机制事件类型系统\">2.2 核心机制：事件类型系统</h3>\n<p>AG-UI 定义了一套完整的事件类型体系（约 20+ 种），按功能可分为四大类：</p>\n<h4 id=\"221-生命周期事件\">2.2.1 生命周期事件</h4>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/sdks/typescript/packages/core/src/events.ts\n\nenum EventType {\n  // 运行生命周期\n  RUN_STARTED = \"RUN_STARTED\",      // Agent 开始执行\n  RUN_FINISHED = \"RUN_FINISHED\",    // Agent 执行完成\n  RUN_ERROR = \"RUN_ERROR\",          // Agent 执行出错\n  \n  // 步骤生命周期\n  STEP_STARTED = \"STEP_STARTED\",    // 开始执行某个步骤\n  STEP_FINISHED = \"STEP_FINISHED\",  // 步骤执行完成\n}\n</code></pre>\n<h4 id=\"222-消息流事件\">2.2.2 消息流事件</h4>\n<pre><code class=\"language-typescript\">enum EventType {\n  // 文本消息（流式）\n  TEXT_MESSAGE_START = \"TEXT_MESSAGE_START\",\n  TEXT_MESSAGE_CONTENT = \"TEXT_MESSAGE_CONTENT\",  // delta: 增量文本\n  TEXT_MESSAGE_END = \"TEXT_MESSAGE_END\",\n  TEXT_MESSAGE_CHUNK = \"TEXT_MESSAGE_CHUNK\",      // 批量模式\n  \n  // 思考过程（可选暴露）\n  THINKING_TEXT_MESSAGE_START = \"THINKING_TEXT_MESSAGE_START\",\n  THINKING_TEXT_MESSAGE_CONTENT = \"THINKING_TEXT_MESSAGE_CONTENT\",\n  THINKING_TEXT_MESSAGE_END = \"THINKING_TEXT_MESSAGE_END\",\n}\n</code></pre>\n<h4 id=\"223-工具调用事件\">2.2.3 工具调用事件</h4>\n<pre><code class=\"language-typescript\">enum EventType {\n  // 工具调用生命周期\n  TOOL_CALL_START = \"TOOL_CALL_START\",   // 包含 toolCallId, toolCallName\n  TOOL_CALL_ARGS = \"TOOL_CALL_ARGS\",      // 流式参数：delta 字段\n  TOOL_CALL_END = \"TOOL_CALL_END\",\n  TOOL_CALL_RESULT = \"TOOL_CALL_RESULT\",  // 工具执行结果\n  TOOL_CALL_CHUNK = \"TOOL_CALL_CHUNK\",    // 批量模式\n}\n</code></pre>\n<h4 id=\"224-状态同步事件\">2.2.4 状态同步事件</h4>\n<pre><code class=\"language-typescript\">enum EventType {\n  // 状态管理\n  STATE_SNAPSHOT = \"STATE_SNAPSHOT\",      // 完整状态快照\n  STATE_DELTA = \"STATE_DELTA\",            // 增量状态（JSON Patch RFC 6902）\n  MESSAGES_SNAPSHOT = \"MESSAGES_SNAPSHOT\", // 完整消息历史\n  \n  // 活动状态（用于 UI 展示）\n  ACTIVITY_SNAPSHOT = \"ACTIVITY_SNAPSHOT\",\n  ACTIVITY_DELTA = \"ACTIVITY_DELTA\",\n}\n</code></pre>\n<h3 id=\"23-实现方案传输层与客户端\">2.3 实现方案：传输层与客户端</h3>\n<h4 id=\"231-传输层sse--http-binary\">2.3.1 传输层：SSE + HTTP Binary</h4>\n<p>AG-UI 支持多种传输方式，其中 SSE（Server-Sent Events）是最常用的：</p>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/sdks/typescript/packages/client/src/agent/http.ts\n\nexport class HttpAgent extends AbstractAgent {\n  protected requestInit(input: RunAgentInput): RequestInit {\n    return {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Accept: \"text/event-stream\",  // 关键：请求 SSE 格式\n      },\n      body: JSON.stringify(input),\n    };\n  }\n\n  run(input: RunAgentInput): Observable&lt;BaseEvent&gt; {\n    // 1. 发起 HTTP 请求获取 SSE 流\n    const httpEvents = runHttpRequest(this.url, this.requestInit(input));\n    // 2. 转换为 AG-UI 事件流\n    return transformHttpEventStream(httpEvents);\n  }\n}\n</code></pre>\n<p>传输层数据格式示例：</p>\n<pre><code>event: TEXT_MESSAGE_START\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"msg_001\",\"role\":\"assistant\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"msg_001\",\"delta\":\"我来帮您\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"msg_001\",\"delta\":\"搜索餐厅...\"}\n\nevent: TOOL_CALL_START\ndata: {\"type\":\"TOOL_CALL_START\",\"toolCallId\":\"call_001\",\"toolCallName\":\"search_restaurants\"}\n\nevent: TOOL_CALL_ARGS\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_001\",\"delta\":\"{\\\"cuisine\\\":\\\"川菜\\\"}\"}\n</code></pre>\n<h4 id=\"232-客户端observable--中间件架构\">2.3.2 客户端：Observable + 中间件架构</h4>\n<p>AG-UI 客户端采用 <strong>RxJS Observable</strong> 模式处理事件流，并支持中间件扩展：</p>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/sdks/typescript/packages/client/src/agent/agent.ts\n\nexport abstract class AbstractAgent {\n  private middlewares: Middleware[] = [];\n  \n  // 订阅者模式：支持多个消费者\n  public subscribe(subscriber: AgentSubscriber) {\n    this.subscribers.push(subscriber);\n    return { unsubscribe: () =&gt; { /* ... */ } };\n  }\n  \n  // 中间件注册\n  public use(...middlewares: (Middleware | MiddlewareFunction)[]): this {\n    this.middlewares.push(...normalizedMiddlewares);\n    return this;\n  }\n  \n  // 抽象方法：具体 Agent 实现事件流\n  abstract run(input: RunAgentInput): Observable&lt;BaseEvent&gt;;\n}\n</code></pre>\n<h3 id=\"24-对接方式\">2.4 对接方式</h3>\n<h4 id=\"241-服务端对接python-示例\">2.4.1 服务端对接（Python 示例）</h4>\n<pre><code class=\"language-python\"># Demo 项目：demo-agent-ui-protocols/agents/ag-ui-agent/server.py\n\nfrom sse_starlette.sse import EventSourceResponse\n\nasync def generate_events() -&gt; AsyncGenerator[str, None]:\n    # 1. 发送 RUN_STARTED\n    yield create_event(EventType.RUN_STARTED, {\n        \"threadId\": thread_id,\n        \"runId\": run_id\n    })\n    \n    # 2. 流式调用 LLM\n    async for chunk in llm_stream:\n        if chunk.choices[0].delta.content:\n            yield create_event(EventType.TEXT_MESSAGE_CONTENT, {\n                \"messageId\": msg_id,\n                \"delta\": chunk.choices[0].delta.content\n            })\n        \n        if chunk.choices[0].delta.tool_calls:\n            # 处理工具调用...\n            yield create_event(EventType.TOOL_CALL_START, {...})\n    \n    # 3. 发送 RUN_FINISHED\n    yield create_event(EventType.RUN_FINISHED, {\n        \"threadId\": thread_id,\n        \"runId\": run_id\n    })\n\n@app.post(\"/run\")\nasync def run(request: RunRequest):\n    return EventSourceResponse(generate_events())\n</code></pre>\n<h4 id=\"242-前端对接react-示例\">2.4.2 前端对接（React 示例）</h4>\n<pre><code class=\"language-tsx\">// Demo 项目：demo-agent-ui-protocols/apps/web/src/app/ag-ui-demo/page.tsx\n\nconst handleSendMessage = async (content: string) =&gt; {\n  const response = await fetch('http://localhost:8001/run', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ messages: [{ role: 'user', content }] }),\n  });\n  \n  const reader = response.body.getReader();\n  const decoder = new TextDecoder();\n  \n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) break;\n    \n    // 解析 SSE 事件\n    const events = parseSSE(decoder.decode(value));\n    \n    for (const event of events) {\n      switch (event.type) {\n        case 'TEXT_MESSAGE_CONTENT':\n          // 更新消息内容（流式）\n          setMessages(prev =&gt; updateMessageContent(prev, event));\n          break;\n        case 'TOOL_CALL_START':\n          // 显示工具调用 UI\n          setMessages(prev =&gt; addToolCall(prev, event));\n          break;\n        case 'TOOL_CALL_RESULT':\n          // 渲染工具结果\n          setMessages(prev =&gt; updateToolResult(prev, event));\n          break;\n      }\n    }\n  }\n};\n</code></pre>\n<div class=\"mermaid\">stateDiagram-v2\n    [*] --&gt; Idle: 初始化\n    \n    Idle --&gt; Running: RUN_STARTED\n    \n    state Running {\n        [*] --&gt; Streaming\n        Streaming --&gt; ToolCalling: TOOL_CALL_START\n        ToolCalling --&gt; Streaming: TOOL_CALL_RESULT\n        Streaming --&gt; Streaming: TEXT_MESSAGE_CONTENT\n    }\n    \n    Running --&gt; Idle: RUN_FINISHED\n    Running --&gt; Error: RUN_ERROR\n    Error --&gt; Idle: 重试\n</div><hr />\n<h2 id=\"3-a2ui声明式-ui-的零信任渲染引擎\">3. A2UI：声明式 UI 的零信任渲染引擎</h2>\n<h3 id=\"31-设计哲学\">3.1 设计哲学</h3>\n<p>A2UI（Agent-to-User Interface）由 Google 推出，其核心理念是：</p>\n<blockquote>\n<p><strong>\"Safe like data, expressive like code\"</strong>（像数据一样安全，像代码一样有表现力）</p>\n</blockquote>\n<p>与 AG-UI 的\"前端主导\"不同，A2UI 采用\"<strong>后端主导</strong>\"的思路：Agent 不仅发送数据，还发送 <strong>UI 结构描述</strong>。但为了安全，A2UI 绝对不允许 Agent 发送可执行代码（HTML/JS），而是发送一种<strong>声明式的组件描述 JSON</strong>。</p>\n<h4 id=\"311-安全性设计\">3.1.1 安全性设计</h4>\n<p>A2UI 的安全模型基于\"白名单组件库\"（Catalog）机制：</p>\n<pre><code>Agent 只能说：\"我要渲染一个 Card 组件，ID 是 123，标题是 XXX\"\nAgent 不能说：\"&lt;script&gt;alert('XSS')&lt;/script&gt;\"\n</code></pre>\n<p>这种设计完全杜绝了 LLM 生成恶意代码的风险。</p>\n<h4 id=\"312-跨平台设计\">3.1.2 跨平台设计</h4>\n<p>由于 A2UI 发送的是抽象组件描述而非具体实现，同一套协议可以：</p>\n<ul>\n<li>在 <strong>Web</strong> 端渲染为 DOM 元素</li>\n<li>在 <strong>iOS</strong> 端渲染为 SwiftUI View</li>\n<li>在 <strong>Android</strong> 端渲染为 Compose 组件</li>\n<li>在 <strong>Flutter</strong> 中渲染为 Widget</li>\n</ul>\n<div class=\"mermaid\">flowchart TB\n    subgraph Agent[\"🧠 Agent\"]\n        LLM[\"LLM\"] --&gt; Gen[\"A2UI Generator\"]\n    end\n    \n    subgraph Protocol[\"📦 A2UI JSON\"]\n        Gen --&gt; JSON[\"{“updateComponents”: ...}\"]\n    end\n    \n    subgraph Renderers[\"🌐 各平台渲染器\"]\n        JSON --&gt; Web[\"🌐 Web\\nLit/React\"]\n        JSON --&gt; iOS[\"🍎 iOS\\nSwiftUI\"]\n        JSON --&gt; Android[\"🤖 Android\\nCompose\"]\n        JSON --&gt; Flutter[\"🐦 Flutter\\nWidget\"]\n    end\n    \n    subgraph Output[\"📱 原生 UI\"]\n        Web --&gt; O1[\"🖥️ DOM\"]\n        iOS --&gt; O2[\"📱 UIKit View\"]\n        Android --&gt; O3[\"📱 Compose UI\"]\n        Flutter --&gt; O4[\"📱 Widget Tree\"]\n    end\n</div><h3 id=\"32-核心机制邻接表组件模型\">3.2 核心机制：邻接表组件模型</h3>\n<h4 id=\"321-为什么不用嵌套-json\">3.2.1 为什么不用嵌套 JSON？</h4>\n<p>传统的 UI 描述通常采用嵌套结构：</p>\n<pre><code class=\"language-json\">// ❌ 传统嵌套结构 - 对 LLM 不友好\n{\n  \"type\": \"Column\",\n  \"children\": [\n    {\n      \"type\": \"Text\",\n      \"text\": \"Hello\"\n    },\n    {\n      \"type\": \"Button\",\n      \"children\": [{ \"type\": \"Text\", \"text\": \"Click\" }]\n    }\n  ]\n}\n</code></pre>\n<p><strong>问题</strong>：</p>\n<ul>\n<li>LLM 必须一次性生成完美嵌套，容易出错</li>\n<li>难以增量更新（需要重新发送整个树）</li>\n<li>深层嵌套难以流式生成</li>\n</ul>\n<h4 id=\"322-邻接表模型\">3.2.2 邻接表模型</h4>\n<p>A2UI 采用<strong>邻接表</strong>（Adjacency List）结构，将组件树\"拍平\"为列表：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/docs/concepts/components.md\n\n// ✅ A2UI 邻接表结构 - LLM 友好\n{\n  \"surfaceUpdate\": {\n    \"surfaceId\": \"main\",\n    \"components\": [\n      {\"id\": \"root\", \"component\": {\"Column\": {\"children\": {\"explicitList\": [\"greeting\", \"buttons\"]}}}},\n      {\"id\": \"greeting\", \"component\": {\"Text\": {\"text\": {\"literalString\": \"Hello\"}}}},\n      {\"id\": \"buttons\", \"component\": {\"Row\": {\"children\": {\"explicitList\": [\"cancel-btn\", \"ok-btn\"]}}}},\n      {\"id\": \"cancel-btn\", \"component\": {\"Button\": {\"child\": \"cancel-text\", \"action\": {\"name\": \"cancel\"}}}},\n      {\"id\": \"cancel-text\", \"component\": {\"Text\": {\"text\": {\"literalString\": \"Cancel\"}}}},\n      {\"id\": \"ok-btn\", \"component\": {\"Button\": {\"child\": \"ok-text\", \"action\": {\"name\": \"ok\"}}}},\n      {\"id\": \"ok-text\", \"component\": {\"Text\": {\"text\": {\"literalString\": \"OK\"}}}}\n    ]\n  }\n}\n</code></pre>\n<p><strong>优势</strong>：</p>\n<ul>\n<li>✅ LLM 可以逐个生成组件，无需考虑嵌套</li>\n<li>✅ 增量更新：只发送变化的组件</li>\n<li>✅ 天然支持流式传输（JSONL 格式）</li>\n</ul>\n<h3 id=\"33-消息类型体系\">3.3 消息类型体系</h3>\n<p>A2UI 定义了四种核心消息类型：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/specification/0.9/json/server_to_client.json\n\n{\n  \"oneOf\": [\n    { \"$ref\": \"#/$defs/CreateSurfaceMessage\" },     // 创建 UI 表面\n    { \"$ref\": \"#/$defs/UpdateComponentsMessage\" },  // 更新组件\n    { \"$ref\": \"#/$defs/UpdateDataModelMessage\" },   // 更新数据模型\n    { \"$ref\": \"#/$defs/DeleteSurfaceMessage\" }      // 删除 UI 表面\n  ]\n}\n</code></pre>\n<h4 id=\"331-createsurface初始化-ui-表面\">3.3.1 createSurface：初始化 UI 表面</h4>\n<pre><code class=\"language-json\">{\n  \"createSurface\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"catalogId\": \"a2ui.dev:standard\"  // 声明使用的组件库\n  }\n}\n</code></pre>\n<h4 id=\"332-updatecomponents发送组件定义\">3.3.2 updateComponents：发送组件定义</h4>\n<pre><code class=\"language-json\">{\n  \"updateComponents\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"components\": [\n      {\n        \"id\": \"root\",\n        \"component\": {\n          \"Column\": {\n            \"children\": {\"explicitList\": [\"header\", \"list\"]}\n          }\n        }\n      },\n      {\n        \"id\": \"header\",\n        \"component\": {\n          \"Text\": {\n            \"text\": {\"literalString\": \"推荐餐厅\"},\n            \"usageHint\": \"h1\"\n          }\n        }\n      }\n      // ... 更多组件\n    ]\n  }\n}\n</code></pre>\n<h4 id=\"333-updatedatamodel数据与-ui-分离\">3.3.3 updateDataModel：数据与 UI 分离</h4>\n<p>A2UI 的一个重要设计是<strong>数据模型与组件结构分离</strong>。组件可以通过 <code>path</code> 绑定数据：</p>\n<pre><code class=\"language-json\">// 1. 组件定义（结构）\n{\n  \"updateComponents\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"components\": [{\n      \"id\": \"restaurant-name\",\n      \"component\": {\n        \"Text\": {\n          \"text\": {\"path\": \"/restaurants/0/name\"}  // 数据绑定\n        }\n      }\n    }]\n  }\n}\n\n// 2. 数据更新（内容）\n{\n  \"updateDataModel\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"path\": \"/restaurants/0\",\n    \"op\": \"replace\",\n    \"value\": {\n      \"name\": \"川办餐厅\",\n      \"rating\": 4.8,\n      \"price\": \"$$\"\n    }\n  }\n}\n</code></pre>\n<p><strong>优势</strong>：</p>\n<ul>\n<li>更新数据无需重新发送组件结构</li>\n<li>多个组件可以绑定同一数据路径</li>\n<li>LLM 可以分步生成结构和数据</li>\n</ul>\n<h3 id=\"34-标准组件库catalog\">3.4 标准组件库（Catalog）</h3>\n<p>A2UI 定义了一套标准组件库，涵盖常见 UI 需求：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/specification/0.9/json/standard_catalog_definition.json\n\n{\n  \"$defs\": {\n    \"anyComponent\": {\n      \"oneOf\": [\n        // 展示类\n        { \"$ref\": \"#/$defs/Text\" },\n        { \"$ref\": \"#/$defs/Image\" },\n        { \"$ref\": \"#/$defs/Icon\" },\n        { \"$ref\": \"#/$defs/Video\" },\n        { \"$ref\": \"#/$defs/AudioPlayer\" },\n        \n        // 布局类\n        { \"$ref\": \"#/$defs/Row\" },\n        { \"$ref\": \"#/$defs/Column\" },\n        { \"$ref\": \"#/$defs/List\" },\n        \n        // 容器类\n        { \"$ref\": \"#/$defs/Card\" },\n        { \"$ref\": \"#/$defs/Tabs\" },\n        { \"$ref\": \"#/$defs/Modal\" },\n        { \"$ref\": \"#/$defs/Divider\" },\n        \n        // 交互类\n        { \"$ref\": \"#/$defs/Button\" },\n        { \"$ref\": \"#/$defs/CheckBox\" },\n        { \"$ref\": \"#/$defs/TextField\" },\n        { \"$ref\": \"#/$defs/DateTimeInput\" },\n        { \"$ref\": \"#/$defs/ChoicePicker\" },\n        { \"$ref\": \"#/$defs/Slider\" }\n      ]\n    }\n  }\n}\n</code></pre>\n<h3 id=\"35-客户端渲染器renderer\">3.5 客户端渲染器（Renderer）</h3>\n<p>A2UI 提供了多种渲染器实现：</p>\n<pre><code class=\"language-typescript\">// 源码位置：A2UI/renderers/lit/src/0.8/core.ts\n\nexport * as Events from \"./events/events.js\";\nexport * as Types from \"./types/types.js\";\n\nimport { create as createSignalA2uiMessageProcessor } from \"./data/signal-model-processor.js\";\nimport { A2uiMessageProcessor } from \"./data/model-processor.js\";\n\nexport const Data = {\n  createSignalA2uiMessageProcessor,  // 响应式数据处理\n  A2uiMessageProcessor,               // 消息处理器\n  Guards,\n};\n</code></pre>\n<p>渲染流程：</p>\n<ol>\n<li><strong>解析消息</strong>：将 JSONL 解析为消息对象</li>\n<li><strong>构建组件树</strong>：根据邻接表重建树结构</li>\n<li><strong>数据绑定</strong>：将 dataModel 注入组件</li>\n<li><strong>原生渲染</strong>：调用平台原生组件库</li>\n</ol>\n<div class=\"mermaid\">flowchart LR\n    subgraph Input[\"📥 输入\"]\n        JSONL[\"JSONL Stream\"]\n    end\n    \n    subgraph Process[\"⚙️ 处理流程\"]\n        JSONL --&gt; Parse[\"1️⃣ 解析消息\"]\n        Parse --&gt; Build[\"2️⃣ 构建组件树\"]\n        Build --&gt; Bind[\"3️⃣ 数据绑定\"]\n        Bind --&gt; Render[\"4️⃣ 原生渲染\"]\n    end\n    \n    subgraph Output[\"📱 输出\"]\n        Render --&gt; UI[\"原生 UI 组件\"]\n    end\n    \n    subgraph DataFlow[\"📊 数据流\"]\n        DM[(\"DataModel\")] -.-&gt;|\"/path/to/data\"| Bind\n    end\n</div><h3 id=\"36-用户交互action-回传\">3.6 用户交互：Action 回传</h3>\n<p>当用户点击按钮等交互时，客户端发送 <code>userAction</code> 消息：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/specification/0.9/json/client_to_server.json\n\n{\n  \"userAction\": {\n    \"name\": \"book_restaurant\",           // action 名称\n    \"surfaceId\": \"restaurant-list\",\n    \"sourceComponentId\": \"book-btn\",\n    \"timestamp\": \"2024-01-07T10:30:00Z\",\n    \"context\": {                         // 上下文数据\n      \"restaurantId\": \"rest_001\",\n      \"restaurantName\": \"川办餐厅\"\n    }\n  }\n}\n</code></pre>\n<h3 id=\"37-对接方式\">3.7 对接方式</h3>\n<h4 id=\"371-服务端对接python-示例\">3.7.1 服务端对接（Python 示例）</h4>\n<pre><code class=\"language-python\"># Demo 项目：demo-agent-ui-protocols/agents/a2ui-agent/server.py\n\nclass A2UIGenerator:\n    @staticmethod\n    def surface_update(surface_id: str, components: list) -&gt; dict:\n        return {\"surfaceUpdate\": {\"surfaceId\": surface_id, \"components\": components}}\n\n    @staticmethod\n    def data_model_update(surface_id: str, path: str, value: any) -&gt; dict:\n        return {\n            \"updateDataModel\": {\n                \"surfaceId\": surface_id,\n                \"path\": path,\n                \"op\": \"replace\",\n                \"value\": value\n            }\n        }\n\nasync def generate_ui(restaurants: list):\n    # 1. 创建 Surface\n    yield json.dumps({\"createSurface\": {\"surfaceId\": \"main\", \"catalogId\": \"standard\"}})\n    \n    # 2. 发送组件结构\n    components = create_restaurant_list_components()\n    yield json.dumps(A2UIGenerator.surface_update(\"main\", components))\n    \n    # 3. 发送数据\n    for i, restaurant in enumerate(restaurants):\n        yield json.dumps(A2UIGenerator.data_model_update(\n            \"main\", \n            f\"/restaurants/{i}\", \n            restaurant\n        ))\n</code></pre>\n<h4 id=\"372-前端对接react-示例\">3.7.2 前端对接（React 示例）</h4>\n<pre><code class=\"language-tsx\">// Demo 项目：demo-agent-ui-protocols/apps/web/src/app/a2ui-demo/A2UIRenderer.tsx\n\nconst A2UIRenderer = ({ messages }: { messages: A2UIMessage[] }) =&gt; {\n  const [components, setComponents] = useState&lt;Map&lt;string, ComponentDef&gt;&gt;();\n  const [dataModel, setDataModel] = useState&lt;Record&lt;string, any&gt;&gt;({});\n  \n  useEffect(() =&gt; {\n    for (const msg of messages) {\n      if (msg.updateComponents) {\n        // 更新组件 Map\n        msg.updateComponents.components.forEach(comp =&gt; {\n          setComponents(prev =&gt; new Map(prev).set(comp.id, comp));\n        });\n      }\n      if (msg.updateDataModel) {\n        // 更新数据模型\n        setDataModel(prev =&gt; ({\n          ...prev,\n          [msg.updateDataModel.path]: msg.updateDataModel.value\n        }));\n      }\n    }\n  }, [messages]);\n  \n  // 递归渲染组件树\n  const renderComponent = (id: string) =&gt; {\n    const comp = components.get(id);\n    if (!comp) return null;\n    \n    // 根据组件类型映射到 React 组件\n    switch (Object.keys(comp.component)[0]) {\n      case 'Text':\n        const textValue = resolveValue(comp.component.Text.text, dataModel);\n        return &lt;span key={id}&gt;{textValue}&lt;/span&gt;;\n      case 'Column':\n        return (\n          &lt;div key={id} className=\"flex flex-col\"&gt;\n            {comp.component.Column.children.explicitList.map(renderComponent)}\n          &lt;/div&gt;\n        );\n      // ... 其他组件\n    }\n  };\n  \n  return renderComponent('root');\n};\n</code></pre>\n<hr />\n<h2 id=\"4-mcp-uimcp-协议的可视化扩展层\">4. MCP-UI：MCP 协议的可视化扩展层</h2>\n<h3 id=\"41-设计哲学\">4.1 设计哲学</h3>\n<p>MCP-UI 是社区基于 Anthropic 的 <strong>Model Context Protocol (MCP)</strong> 开发的 UI 扩展。其核心理念是：</p>\n<blockquote>\n<p><strong>\"让工具调用结果具备可视化能力\"</strong></p>\n</blockquote>\n<p>与 AG-UI、A2UI 不同，MCP-UI 不试图定义新的协议，而是<strong>复用现有的 MCP 协议</strong>，在工具返回值中添加 <code>UIResource</code> 字段。</p>\n<h4 id=\"411-与-mcp-的关系\">4.1.1 与 MCP 的关系</h4>\n<pre><code>MCP 协议：\n  - Tool Definition（工具定义）\n  - Tool Call（工具调用）\n  - Tool Result（工具结果） ← MCP-UI 在这里扩展\n</code></pre>\n<p>MCP-UI 的创新在于：工具不仅可以返回文本/JSON 数据，还可以返回<strong>可交互的 UI 片段</strong>。</p>\n<h3 id=\"42-核心机制uiresource\">4.2 核心机制：UIResource</h3>\n<h4 id=\"421-uiresource-数据结构\">4.2.1 UIResource 数据结构</h4>\n<pre><code class=\"language-typescript\">// 源码位置：mcp-ui/sdks/typescript/server/src/types.ts\n\ninterface UIResource {\n  type: 'resource';\n  resource: {\n    uri: string;       // 唯一标识，如 ui://component/booking-form\n    mimeType: MimeType; // 内容类型\n    text?: string;      // 内联内容\n    blob?: string;      // Base64 编码内容\n    _meta?: Record&lt;string, unknown&gt;;\n  };\n}\n\ntype MimeType =\n  | 'text/html'                           // 内联 HTML\n  | 'text/uri-list'                       // 外部 URL\n  | 'application/vnd.mcp-ui.remote-dom+javascript; framework=react'\n  | 'application/vnd.mcp-ui.remote-dom+javascript; framework=webcomponents';\n</code></pre>\n<h4 id=\"422-三种渲染模式\">4.2.2 三种渲染模式</h4>\n<p>MCP-UI 支持三种不同的 UI 资源类型：</p>\n<p><strong>1. Raw HTML（内联 HTML）</strong></p>\n<pre><code class=\"language-typescript\">{\n  uri: \"ui://restaurant/card\",\n  mimeType: \"text/html\",\n  text: `\n    &lt;div class=\"restaurant-card\"&gt;\n      &lt;h2&gt;川办餐厅&lt;/h2&gt;\n      &lt;button onclick=\"window.parent.postMessage({type:'tool',payload:{toolName:'book'}},'*')\"&gt;\n        预订\n      &lt;/button&gt;\n    &lt;/div&gt;\n  `\n}\n</code></pre>\n<p><strong>2. External URL（外部页面）</strong></p>\n<pre><code class=\"language-typescript\">{\n  uri: \"ui://restaurant/detail\",\n  mimeType: \"text/uri-list\",\n  text: \"https://restaurant.example.com/embed/123\"\n}\n</code></pre>\n<p><strong>3. Remote DOM（远程 DOM）</strong></p>\n<p>这是 MCP-UI 最强大的模式，基于 Shopify 的 <a href=\"https://github.com/Shopify/remote-dom\" rel=\"noopener nofollow\" target=\"_blank\">remote-dom</a> 技术：</p>\n<pre><code class=\"language-typescript\">{\n  uri: \"ui://restaurant/form\",\n  mimeType: \"application/vnd.mcp-ui.remote-dom+javascript; framework=react\",\n  text: `\n    // 这段 JS 在沙箱中执行，通过 JSON 消息与宿主通信\n    const form = document.createElement('ui-form');\n    form.addEventListener('submit', (e) =&gt; {\n      window.postMessage({ type: 'tool', payload: { toolName: 'submit_booking', params: e.detail } });\n    });\n    document.body.appendChild(form);\n  `\n}\n</code></pre>\n<div class=\"mermaid\">flowchart TB\n    subgraph Server[\"🔧 MCP Server\"]\n        Tool[\"Tool Result\"] --&gt; UIRes[\"UIResource\"]\n    end\n    \n    UIRes --&gt; Type{\"mimeType?\"}\n    \n    subgraph Mode1[\"📄 Raw HTML\"]\n        Type --&gt;|\"text/html\"| HTML[\"iframe srcDoc\"]\n        HTML --&gt; Sandbox1[\"🔒 沙箱渲染\"]\n    end\n    \n    subgraph Mode2[\"🌐 External URL\"]\n        Type --&gt;|\"text/uri-list\"| URL[\"iframe src\"]\n        URL --&gt; Sandbox2[\"🔒 外部页面\"]\n    end\n    \n    subgraph Mode3[\"🖥️ Remote DOM\"]\n        Type --&gt;|\"remote-dom\"| Script[\"JS Script\"]\n        Script --&gt; Worker[\"🔒 沙箱执行\"]\n        Worker --&gt;|\"JSON Patch\"| Host[\"🏠 宿主渲染\"]\n    end\n    \n    Sandbox1 &amp; Sandbox2 &amp; Host --&gt; Actions[\"📤 postMessage\"]\n    Actions --&gt; Client[\"📱 客户端处理\"]\n</div><h3 id=\"43-客户端渲染器\">4.3 客户端渲染器</h3>\n<h4 id=\"431-uiresourcerenderer-组件\">4.3.1 UIResourceRenderer 组件</h4>\n<pre><code class=\"language-tsx\">// 源码位置：mcp-ui/sdks/typescript/client/src/components/UIResourceRenderer.tsx\n\nexport const UIResourceRenderer = (props: UIResourceRendererProps) =&gt; {\n  const { resource, onUIAction, supportedContentTypes } = props;\n  const contentType = getContentType(resource);\n\n  switch (contentType) {\n    case 'rawHtml':\n    case 'externalUrl':\n      // 使用 iframe 沙箱渲染\n      return &lt;HTMLResourceRenderer resource={resource} onUIAction={onUIAction} /&gt;;\n      \n    case 'remoteDom':\n      // 使用 Remote DOM 渲染（更安全、更灵活）\n      return &lt;RemoteDOMResourceRenderer resource={resource} onUIAction={onUIAction} /&gt;;\n      \n    default:\n      return &lt;p&gt;Unsupported resource type.&lt;/p&gt;;\n  }\n};\n</code></pre>\n<h4 id=\"432-remote-dom-渲染器\">4.3.2 Remote DOM 渲染器</h4>\n<p>Remote DOM 模式下，UI 逻辑在 iframe 沙箱中执行，但 DOM 变化通过 JSON 消息同步到宿主：</p>\n<pre><code class=\"language-tsx\">// 源码位置：mcp-ui/sdks/typescript/client/src/components/RemoteDOMResourceRenderer.tsx\n\nconst RemoteDOMResourceRenderer: React.FC&lt;RemoteDOMResourceProps&gt; = ({\n  resource, library, onUIAction\n}) =&gt; {\n  const iframeRef = useRef&lt;HTMLIFrameElement&gt;(null);\n  \n  // 1. 创建 Remote Receiver（接收 DOM 变化）\n  const { receiver, components } = useMemo(() =&gt; {\n    const reactReceiver = new RemoteReceiver();\n    // 将组件库映射为 Remote Components\n    // ...\n    return { receiver: reactReceiver, components: componentMap };\n  }, [library]);\n  \n  // 2. 监听 iframe 消息（UI Action）\n  useEffect(() =&gt; {\n    const handleMessage = (event: MessageEvent) =&gt; {\n      if (event.source === iframeRef.current?.contentWindow) {\n        onUIAction?.(event.data as UIActionResult);\n      }\n    };\n    window.addEventListener('message', handleMessage);\n    return () =&gt; window.removeEventListener('message', handleMessage);\n  }, [onUIAction]);\n  \n  // 3. iframe 加载后注入代码\n  const handleIframeLoad = () =&gt; {\n    const thread = new ThreadIframe&lt;SandboxAPI&gt;(iframeRef.current);\n    thread.imports.render({ code: resource.text, ... }, receiver.connection);\n  };\n  \n  return (\n    &lt;&gt;\n      &lt;iframe ref={iframeRef} srcDoc={IFRAME_SRC_DOC} onLoad={handleIframeLoad} /&gt;\n      {/* Remote DOM 渲染结果 */}\n      &lt;RemoteRootRenderer receiver={receiver} components={components} /&gt;\n    &lt;/&gt;\n  );\n};\n</code></pre>\n<h3 id=\"44-ui-action-系统\">4.4 UI Action 系统</h3>\n<p>MCP-UI 定义了五种 UI 交互类型：</p>\n<pre><code class=\"language-typescript\">// 源码位置：mcp-ui/sdks/typescript/client/src/types.ts\n\nexport type UIActionResult =\n  | { type: 'tool', payload: { toolName: string, params: Record&lt;string, unknown&gt; } }\n  | { type: 'prompt', payload: { prompt: string } }\n  | { type: 'link', payload: { url: string } }\n  | { type: 'intent', payload: { intent: string, params: Record&lt;string, unknown&gt; } }\n  | { type: 'notify', payload: { message: string } };\n</code></pre>\n<p><strong>使用场景</strong>：</p>\n<ul>\n<li><code>tool</code>：触发工具调用（如\"预订\"按钮）</li>\n<li><code>prompt</code>：发送新的用户消息</li>\n<li><code>link</code>：打开外部链接</li>\n<li><code>intent</code>：触发应用内意图</li>\n<li><code>notify</code>：显示通知消息</li>\n</ul>\n<h3 id=\"45-对接方式\">4.5 对接方式</h3>\n<h4 id=\"451-服务端对接python-示例\">4.5.1 服务端对接（Python 示例）</h4>\n<pre><code class=\"language-python\"># Demo 项目：demo-agent-ui-protocols/agents/mcp-ui-agent/server.py\n\ndef create_restaurant_card_ui(restaurants: list) -&gt; dict:\n    html = f\"\"\"\n    &lt;div class=\"restaurant-list\"&gt;\n        {''.join([f'''\n        &lt;div class=\"restaurant-card\" data-id=\"{r['id']}\"&gt;\n            &lt;img src=\"{r['image']}\" /&gt;\n            &lt;h3&gt;{r['name']}&lt;/h3&gt;\n            &lt;p&gt;评分: {r['rating']} | 价格: {r['price']}&lt;/p&gt;\n            &lt;button onclick=\"window.parent.postMessage({{\n                type: 'tool',\n                payload: {{\n                    toolName: 'show_booking_form',\n                    params: {{ restaurant_name: '{r['name']}' }}\n                }}\n            }}, '*')\"&gt;预订&lt;/button&gt;\n        &lt;/div&gt;\n        ''' for r in restaurants])}\n    &lt;/div&gt;\n    \"\"\"\n    \n    return {\n        \"type\": \"ui_resource\",\n        \"resource\": {\n            \"uri\": \"ui://restaurant/list\",\n            \"mimeType\": \"text/html\",\n            \"text\": html\n        }\n    }\n\n@app.post(\"/run\")\nasync def run(request: RunRequest):\n    if request.tool_call:\n        # 直接执行工具调用\n        result = execute_tool(request.tool_call.name, request.tool_call.params)\n        return result\n    else:\n        # 让 LLM 决定调用哪个工具\n        response = await call_llm_with_tools(request.messages)\n        return response\n</code></pre>\n<h4 id=\"452-前端对接react-示例\">4.5.2 前端对接（React 示例）</h4>\n<pre><code class=\"language-tsx\">// Demo 项目：demo-agent-ui-protocols/apps/web/src/app/mcp-ui-demo/page.tsx\n\nconst MCPUIDemo = () =&gt; {\n  const [currentUI, setCurrentUI] = useState&lt;UIResource | null&gt;(null);\n  \n  // 处理来自 UI 的 Action\n  useEffect(() =&gt; {\n    const handleMessage = async (event: MessageEvent) =&gt; {\n      const { type, payload } = event.data;\n      \n      if (type === 'tool') {\n        // 调用后端工具\n        const response = await fetch('http://localhost:8003/run', {\n          method: 'POST',\n          body: JSON.stringify({ tool_call: payload }),\n        });\n        const result = await response.json();\n        \n        if (result.type === 'ui_resource') {\n          setCurrentUI(result.resource);\n        }\n      }\n    };\n    \n    window.addEventListener('message', handleMessage);\n    return () =&gt; window.removeEventListener('message', handleMessage);\n  }, []);\n  \n  return (\n    &lt;div&gt;\n      {currentUI &amp;&amp; (\n        &lt;UIResourceRenderer \n          resource={currentUI.resource}\n          onUIAction={handleToolCallback}\n        /&gt;\n      )}\n    &lt;/div&gt;\n  );\n};\n</code></pre>\n<hr />\n<h2 id=\"5-协议组合ag-ui--a2ui-的协同架构\">5. 协议组合：AG-UI + A2UI 的协同架构</h2>\n<h3 id=\"51-为什么要组合使用\">5.1 为什么要组合使用？</h3>\n<p>三种协议并非互斥关系，它们可以<strong>协同工作</strong>，发挥各自优势。特别是 <strong>AG-UI + A2UI</strong> 的组合，在 A2UI 官方文档中被明确提及：</p>\n<blockquote>\n<p>\"AG UI translates from A2UI messages to AG UI messages, and handles transport and state sync automatically.\"</p>\n<p>— <a href=\"A2UI/docs/transports.md\" rel=\"noopener nofollow\" target=\"_blank\">A2UI Transports 文档</a></p>\n</blockquote>\n<h3 id=\"52-ag-ui-作为-a2ui-的传输层\">5.2 AG-UI 作为 A2UI 的传输层</h3>\n<p>在这种架构下：</p>\n<ul>\n<li><strong>A2UI</strong> 负责：UI 结构定义、组件规范、数据模型</li>\n<li><strong>AG-UI</strong> 负责：消息传输、状态同步、事件路由</li>\n</ul>\n<div class=\"mermaid\">flowchart TB\n    subgraph Frontend[\"🖥️ Frontend\"]\n        Client[\"AG-UI Client\\n(Events)\"] --&gt; A2UIMsg[\"A2UI Messages\\n(JSON)\"]\n        A2UIMsg --&gt; Renderer[\"A2UI Renderer\\n(Components)\"]\n    end\n    \n    subgraph Transport[\"📡 Transport\"]\n        Client &lt;-.-&gt;|\"SSE Events\"| Server\n    end\n    \n    subgraph Agent[\"🤖 Agent\"]\n        Server[\"AG-UI Server\\n(SSE Stream)\"] --&gt; Generator[\"A2UI Generator\\n(JSONL)\"]\n        Generator --&gt; LLM[\"LLM / Tools\"]\n    end\n    \n    style Frontend fill:#e3f2fd\n    style Transport fill:#fff3e0\n    style Agent fill:#f3e5f5\n</div><h3 id=\"53-实现方式将-a2ui-消息包装为-ag-ui-事件\">5.3 实现方式：将 A2UI 消息包装为 AG-UI 事件</h3>\n<pre><code class=\"language-typescript\">// 伪代码：AG-UI + A2UI 集成\n\n// 1. Agent 生成 A2UI 消息\nconst a2uiMessages = generateA2UIComponents(restaurants);\n\n// 2. 包装为 AG-UI 的 CUSTOM 或 ACTIVITY_SNAPSHOT 事件\nfor (const msg of a2uiMessages) {\n  yield {\n    type: EventType.ACTIVITY_SNAPSHOT,\n    messageId: `a2ui-${Date.now()}`,\n    activityType: \"a2ui\",  // 标记为 A2UI 消息\n    content: msg,          // A2UI 原始消息\n  };\n}\n\n// 3. 前端根据 activityType 路由到 A2UI 渲染器\nagent.subscribe({\n  onActivitySnapshot: (event) =&gt; {\n    if (event.activityType === \"a2ui\") {\n      a2uiRenderer.processMessage(event.content);\n    }\n  }\n});\n</code></pre>\n<h3 id=\"54-ag-ui--mcp-ui-的组合\">5.4 AG-UI + MCP-UI 的组合</h3>\n<p>AG-UI 官方提供了 <code>@ag-ui/mcp-apps-middleware</code>，可以将 MCP-UI 的 UI 资源集成到 AG-UI 事件流中：</p>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/middlewares/mcp-apps-middleware/README.md\n\nimport { MCPAppsMiddleware } from \"@ag-ui/mcp-apps-middleware\";\n\nconst agent = new YourAgent().use(\n  new MCPAppsMiddleware({\n    mcpServers: [\n      { type: \"http\", url: \"http://localhost:3001/mcp\" }\n    ],\n  })\n);\n\n// 中间件自动：\n// 1. 发现 MCP Server 的 UI-enabled Tools\n// 2. 将工具注入 Agent 的工具列表\n// 3. 执行工具调用并获取 UIResource\n// 4. 发射 ACTIVITY_SNAPSHOT 事件（activityType: \"mcp-apps\"）\n</code></pre>\n<h3 id=\"55-三协议融合架构\">5.5 三协议融合架构</h3>\n<p>在复杂场景下，三种协议可以同时使用：</p>\n<div class=\"mermaid\">flowchart TB\n    subgraph Frontend[\"🖥️ Frontend\"]\n        subgraph Router[\"AG-UI Event Router\"]\n            TextR[\"📝 Text/Tool\\nRenderer\"]\n            A2UIR[\"📱 A2UI Renderer\\n(a2ui type)\"]\n            MCPR[\"🔧 MCP-UI Renderer\\n(mcp-apps type)\"]\n        end\n    end\n    \n    Router &lt;-.-&gt;|\"SSE Events\"| Server\n    \n    subgraph Agent[\"🤖 Agent\"]\n        subgraph ServerLayer[\"AG-UI Server + Middlewares\"]\n            LLMAdapter[\"LLM Adapter\"]\n            A2AMW[\"A2A Middleware\"]\n            MCPMW[\"MCP-Apps Middleware\"]\n        end\n        \n        LLMAdapter --&gt; LLM[(\"🧠 LLM\\n(OpenAI)\")]\n        A2AMW --&gt; SubAgents[(\"🤝 A2A Agents\\n(Sub-agents)\")]\n        MCPMW --&gt; MCPServers[(\"🔌 MCP Servers\\n(Tools+UI)\")]\n    end\n    \n    style Frontend fill:#e3f2fd\n    style Agent fill:#f3e5f5\n    style Router fill:#e8f5e9\n    style ServerLayer fill:#fff3e0\n</div><p><strong>各协议职责</strong>：</p>\n<ul>\n<li><strong>AG-UI</strong>：作为\"总线\"，负责事件路由和状态同步</li>\n<li><strong>A2UI</strong>：负责复杂的、跨平台的声明式 UI</li>\n<li><strong>MCP-UI</strong>：负责工具级别的快速 UI 扩展</li>\n</ul>\n<hr />\n<h2 id=\"6-技术选型决策框架\">6. 技术选型决策框架</h2>\n<h3 id=\"61-维度对比表\">6.1 维度对比表</h3>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>AG-UI</th>\n<th>A2UI</th>\n<th>MCP-UI</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>核心理念</strong></td>\n<td>事件驱动的状态同步</td>\n<td>声明式 UI 组件规范</td>\n<td>MCP 工具的 UI 扩展</td>\n</tr>\n<tr>\n<td><strong>UI 控制权</strong></td>\n<td>前端主导</td>\n<td>后端主导（结构）</td>\n<td>后端主导（内容）</td>\n</tr>\n<tr>\n<td><strong>安全模型</strong></td>\n<td>依赖前端实现</td>\n<td><strong>最高</strong>（白名单组件）</td>\n<td>中等（iframe 沙箱）</td>\n</tr>\n<tr>\n<td><strong>跨平台能力</strong></td>\n<td>弱（需各端适配）</td>\n<td><strong>最强</strong>（抽象组件）</td>\n<td>中等（Web 优先）</td>\n</tr>\n<tr>\n<td><strong>实时性</strong></td>\n<td><strong>最强</strong>（流式事件）</td>\n<td>中等（JSONL 流）</td>\n<td>弱（Request-Response）</td>\n</tr>\n<tr>\n<td><strong>开发复杂度</strong></td>\n<td>前端复杂</td>\n<td>架构复杂</td>\n<td><strong>最简单</strong></td>\n</tr>\n<tr>\n<td><strong>生态兼容性</strong></td>\n<td>CopilotKit 生态</td>\n<td>Google 生态</td>\n<td>MCP 生态</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"62-场景-协议匹配指南\">6.2 场景-协议匹配指南</h3>\n<h4 id=\"场景-a企业级-copilot-系统\">场景 A：企业级 Copilot 系统</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>需要与现有复杂业务系统深度集成</li>\n<li>Agent 需要操作现有 UI 状态（如高亮表格行、填写表单）</li>\n<li>需要实时展示 Agent 思考过程</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>AG-UI 为主</strong></p>\n<pre><code class=\"language-typescript\">// AG-UI 可以驱动现有 UI 状态\nagent.subscribe({\n  onStateDelta: (event) =&gt; {\n    // 增量更新应用状态\n    applyJsonPatch(appState, event.delta);\n  },\n  onToolCallStart: (event) =&gt; {\n    // 高亮相关 UI 区域\n    highlightUIRegion(event.toolCallName);\n  }\n});\n</code></pre>\n<h4 id=\"场景-b跨平台消费级-app\">场景 B：跨平台消费级 App</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>同时支持 Web、iOS、Android</li>\n<li>对安全性要求极高（防止 XSS、幻觉输出）</li>\n<li>需要统一的设计语言</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>A2UI 为主</strong></p>\n<pre><code class=\"language-json\">// A2UI 一次定义，多端渲染\n{\n  \"updateComponents\": {\n    \"components\": [\n      {\"id\": \"card\", \"component\": {\"Card\": {...}}}\n    ]\n  }\n}\n\n// Web 端：渲染为 &lt;div class=\"card\"&gt;\n// iOS 端：渲染为 SwiftUI Card\n// Android 端：渲染为 Compose Card\n</code></pre>\n<h4 id=\"场景-c开发者工具--ide-插件\">场景 C：开发者工具 / IDE 插件</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>需要快速为现有工具添加 UI</li>\n<li>希望第三方开发者能贡献 UI 插件</li>\n<li>不需要复杂的跨平台支持</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>MCP-UI 为主</strong></p>\n<pre><code class=\"language-typescript\">// MCP Server 返回 UI\nserver.tool(\"show_code_diff\", () =&gt; ({\n  type: \"ui_resource\",\n  resource: {\n    uri: \"ui://diff/viewer\",\n    mimeType: \"text/html\",\n    text: generateDiffHTML(changes)\n  }\n}));\n</code></pre>\n<h4 id=\"场景-d复杂多-agent-系统\">场景 D：复杂多 Agent 系统</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>多个 Agent 协作</li>\n<li>既需要实时状态同步，又需要丰富 UI</li>\n<li>需要调用外部 MCP 工具</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>AG-UI + A2UI + MCP-UI 组合</strong></p>\n<pre><code class=\"language-typescript\">const agent = new OrchestrationAgent()\n  .use(new A2AMiddleware({ agentUrls: [...] }))    // 连接子 Agent\n  .use(new MCPAppsMiddleware({ mcpServers: [...] })) // 连接 MCP 工具\n  .use(new A2UIMiddleware({ catalog: 'standard' })); // 支持 A2UI 渲染\n</code></pre>\n<h3 id=\"63-决策流程图\">6.3 决策流程图</h3>\n<div class=\"mermaid\">flowchart TB\n    Start([\"🚀 开始选型\"]) --&gt; Q1{\"是否需要&lt;br/&gt;跨平台原生渲染？\"}\n    \n    Q1 --&gt;|\"✅ Yes\"| A2UI[\"📱 A2UI 为主&lt;br/&gt;&lt;i&gt;统一定义，多端原生&lt;/i&gt;\"]\n    Q1 --&gt;|\"❌ No\"| Q2{\"是否需要&lt;br/&gt;实时状态同步？\"}\n    \n    Q2 --&gt;|\"✅ Yes\"| AGUI[\"⚡ AG-UI 为主&lt;br/&gt;&lt;i&gt;事件驱动，状态透明&lt;/i&gt;\"]\n    Q2 --&gt;|\"❌ No\"| Q3{\"是否复用&lt;br/&gt;MCP 生态？\"}\n    \n    Q3 --&gt;|\"✅ Yes\"| MCPUI[\"🔧 MCP-UI 为主&lt;br/&gt;&lt;i&gt;工具即 UI，渐进增强&lt;/i&gt;\"]\n    Q3 --&gt;|\"❌ No\"| Custom[\"🎨 自定义方案&lt;br/&gt;&lt;i&gt;根据需求定制&lt;/i&gt;\"]\n    \n    subgraph Combinations[\"💡 组合方案\"]\n        AGUI --&gt; Combo1[\"AG-UI + A2UI&lt;br/&gt;&lt;i&gt;事件传输 + 声明式UI&lt;/i&gt;\"]\n        AGUI --&gt; Combo2[\"AG-UI + MCP-UI&lt;br/&gt;&lt;i&gt;事件传输 + 工具UI&lt;/i&gt;\"]\n        A2UI --&gt; Combo1\n    end\n    \n    style Start fill:#e1f5fe\n    style A2UI fill:#c8e6c9\n    style AGUI fill:#fff3e0\n    style MCPUI fill:#f3e5f5\n    style Custom fill:#ffecb3\n</div><hr />\n<h2 id=\"7-demo-项目实战解析\">7. Demo 项目实战解析</h2>\n<h3 id=\"71-项目结构\">7.1 项目结构</h3>\n<p><code>demo-agent-ui-protocols</code> 项目通过一个统一的\"餐厅搜索\"场景，同时演示三种协议：</p>\n<pre><code>demo-agent-ui-protocols/\n├── apps/web/                 # Next.js 前端\n│   └── src/app/\n│       ├── ag-ui-demo/       # AG-UI 演示页面\n│       ├── a2ui-demo/        # A2UI 演示页面\n│       └── mcp-ui-demo/      # MCP-UI 演示页面\n│\n├── agents/\n│   ├── ag-ui-agent/          # AG-UI Python Agent (port 8001)\n│   ├── a2ui-agent/           # A2UI Python Agent (port 8002)\n│   └── mcp-ui-agent/         # MCP-UI Python Agent (port 8003)\n│\n└── packages/shared/          # 共享类型定义\n</code></pre>\n<h3 id=\"72-同一场景的三种实现对比\">7.2 同一场景的三种实现对比</h3>\n<h4 id=\"721-用户输入\">7.2.1 用户输入</h4>\n<blockquote>\n<p>\"帮我找一家北京的川菜馆\"</p>\n</blockquote>\n<h4 id=\"722-ag-ui-实现\">7.2.2 AG-UI 实现</h4>\n<pre><code>[SSE Stream]\nevent: RUN_STARTED\ndata: {\"runId\":\"run_001\",\"threadId\":\"thread_001\"}\n\nevent: TEXT_MESSAGE_START\ndata: {\"messageId\":\"msg_001\",\"role\":\"assistant\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"messageId\":\"msg_001\",\"delta\":\"好的，我来帮您\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"messageId\":\"msg_001\",\"delta\":\"搜索北京的川菜馆...\"}\n\nevent: TOOL_CALL_START\ndata: {\"toolCallId\":\"call_001\",\"toolCallName\":\"search_restaurants\"}\n\nevent: TOOL_CALL_ARGS\ndata: {\"toolCallId\":\"call_001\",\"delta\":\"{\\\"cuisine\\\":\\\"川菜\\\",\\\"location\\\":\\\"北京\\\"}\"}\n\nevent: TOOL_CALL_RESULT\ndata: {\"toolCallId\":\"call_001\",\"result\":\"[{\\\"name\\\":\\\"川办餐厅\\\",...}]\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"messageId\":\"msg_001\",\"delta\":\"为您找到以下餐厅：\"}\n\nevent: RUN_FINISHED\ndata: {\"runId\":\"run_001\"}\n</code></pre>\n<p><strong>前端效果</strong>：实时展示打字效果 + 工具调用卡片</p>\n<h4 id=\"723-a2ui-实现\">7.2.3 A2UI 实现</h4>\n<pre><code>[JSONL Stream]\n{\"createSurface\":{\"surfaceId\":\"results\",\"catalogId\":\"standard\"}}\n\n{\"updateComponents\":{\"surfaceId\":\"results\",\"components\":[\n  {\"id\":\"root\",\"component\":{\"Column\":{\"children\":{\"explicitList\":[\"header\",\"list\"]}}}},\n  {\"id\":\"header\",\"component\":{\"Text\":{\"text\":{\"literalString\":\"推荐餐厅\"},\"usageHint\":\"h1\"}}},\n  {\"id\":\"list\",\"component\":{\"List\":{\"children\":{\"template\":{\"dataBinding\":\"/restaurants\",\"componentId\":\"card-template\"}}}}}\n]}}\n\n{\"updateDataModel\":{\"surfaceId\":\"results\",\"path\":\"/restaurants\",\"value\":[\n  {\"name\":\"川办餐厅\",\"rating\":4.8,\"price\":\"$$\",\"image\":\"...\"},\n  {\"name\":\"眉州东坡\",\"rating\":4.5,\"price\":\"$$$\",\"image\":\"...\"}\n]}}\n</code></pre>\n<p><strong>前端效果</strong>：原生组件渲染的餐厅卡片列表</p>\n<h4 id=\"724-mcp-ui-实现\">7.2.4 MCP-UI 实现</h4>\n<pre><code class=\"language-json\">// Request\n{ \"messages\": [{ \"role\": \"user\", \"content\": \"帮我找一家北京的川菜馆\" }] }\n\n// Response\n{\n  \"role\": \"assistant\",\n  \"content\": \"好的，这是搜索结果：\",\n  \"ui_resource\": {\n    \"type\": \"resource\",\n    \"resource\": {\n      \"uri\": \"ui://restaurant/list\",\n      \"mimeType\": \"text/html\",\n      \"text\": \"&lt;div class='restaurant-list'&gt;...\"\n    }\n  }\n}\n</code></pre>\n<p><strong>前端效果</strong>：iframe 内嵌的 HTML 卡片</p>\n<h3 id=\"73-运行-demo\">7.3 运行 Demo</h3>\n<pre><code class=\"language-bash\"># 1. 克隆项目\ngit clone https://github.com/MadLongTom/demo-agent-ui-protocols\ncd demo-agent-ui-protocols\n\n# 2. 配置环境变量\ncp .env.example .env\n# 编辑 .env 填入 OPENAI_API_KEY 等\n\n# 3. 安装依赖\n./install.sh\n\n# 4. 启动所有服务\n./run.sh\n\n# 5. 访问 Demo\n# AG-UI:  http://localhost:3000/ag-ui-demo\n# A2UI:   http://localhost:3000/a2ui-demo\n# MCP-UI: http://localhost:3000/mcp-ui-demo\n</code></pre>\n<p><img alt=\"AG-UI\" class=\"lazyload\" /><br />\n<img alt=\"A2UI\" class=\"lazyload\" /><br />\n<img alt=\"MCP-UI\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"8-总结与展望\">8. 总结与展望</h2>\n<h3 id=\"81-核心观点回顾\">8.1 核心观点回顾</h3>\n<ol>\n<li>\n<p><strong>AG-UI</strong> 是\"事件总线\"：它不关心 UI 长什么样，只负责把 Agent 的状态变化广播出去。适合需要<strong>深度集成</strong>和<strong>实时反馈</strong>的场景。</p>\n</li>\n<li>\n<p><strong>A2UI</strong> 是\"UI 契约\"：它定义了一套抽象的组件语言，让 Agent 能够\"描述 UI 意图\"而不是\"生成 UI 代码\"。适合<strong>跨平台</strong>和<strong>高安全性</strong>场景。</p>\n</li>\n<li>\n<p><strong>MCP-UI</strong> 是\"UI 插件\"：它让 MCP 工具能够直接返回可视化结果，无需修改宿主应用。适合<strong>快速扩展</strong>和<strong>插件生态</strong>场景。</p>\n</li>\n<li>\n<p><strong>组合使用</strong>是最佳实践：AG-UI 可以作为 A2UI 的传输层，MCP-UI 可以通过中间件集成到 AG-UI。</p>\n</li>\n</ol>\n<h3 id=\"82-未来展望\">8.2 未来展望</h3>\n<table>\n<thead>\n<tr>\n<th>趋势</th>\n<th>预期发展</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>协议融合</strong></td>\n<td>AG-UI 和 A2UI 可能会进一步整合，形成统一的 Agent-UI 标准</td>\n</tr>\n<tr>\n<td><strong>语音交互</strong></td>\n<td>多模态支持（语音输入、语音输出）将成为标配</td>\n</tr>\n<tr>\n<td><strong>边缘计算</strong></td>\n<td>轻量级协议支持设备端 Agent（手机、IoT）</td>\n</tr>\n<tr>\n<td><strong>安全增强</strong></td>\n<td>更完善的沙箱隔离、权限控制机制</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"83-参考资源\">8.3 参考资源</h3>\n<table>\n<thead>\n<tr>\n<th>协议</th>\n<th>官方仓库</th>\n<th>文档</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AG-UI</td>\n<td><a href=\"https://github.com/ag-ui-protocol/ag-ui\" rel=\"noopener nofollow\" target=\"_blank\">github.com/ag-ui-protocol/ag-ui</a></td>\n<td><a href=\"https://docs.ag-ui.com\" rel=\"noopener nofollow\" target=\"_blank\">docs.ag-ui.com</a></td>\n</tr>\n<tr>\n<td>A2UI</td>\n<td><a href=\"https://github.com/google/A2UI\" rel=\"noopener nofollow\" target=\"_blank\">github.com/google/A2UI</a></td>\n<td><a href=\"https://a2ui.dev\" rel=\"noopener nofollow\" target=\"_blank\">a2ui.org</a></td>\n</tr>\n<tr>\n<td>MCP-UI</td>\n<td><a href=\"https://github.com/idosal/mcp-ui\" rel=\"noopener nofollow\" target=\"_blank\">github.com/idosal/mcp-ui</a></td>\n<td>[mcpui.dev]</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<p><em>本文基于 <code>demo-agent-ui-protocols</code> 项目源码分析，建议读者下载运行体验。如有问题或建议，欢迎交流讨论。</em></p>\n<p><a href=\"https://github.com/MadLongTom/demo-agent-ui-protocols\" rel=\"noopener nofollow\">https://github.com/MadLongTom/demo-agent-ui-protocols</a></p>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/madtom/\" target=\"_blank\">MadLongTom</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/madtom/p/19452209\" target=\"_blank\">https://www.cnblogs.com/madtom/p/19452209</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 14:36</span>&nbsp;\n<a href=\"https://www.cnblogs.com/madtom\">MadLongTom</a>&nbsp;\n阅读(<span id=\"post_view_count\">117</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}