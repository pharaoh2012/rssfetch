{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "9、PipedInputStream和PipedOutputStream的源码分析和使用方法详细分析",
      "link": "https://www.cnblogs.com/Carey-ccl/p/19625392",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Carey-ccl/p/19625392\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 22:07\">\n    <span>9、PipedInputStream和PipedOutputStream的源码分析和使用方法详细分析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>  在多线程编程中，线程间的数据交换是一个常见需求。Java IO包中的PipedInputStream和PipedOutputStream提供了一种高效的线程间通信机制，允许一批（多个）线程向PipedOutputStream写入数据，另一批（多个）线程从PipedInputStream读取数据。<br />\n  但是，同一批（多个）线程相互之间会存在竞争，比如，同一批向PipedOutputStream写入数据的线程会存在竞争，同一批从PipedInputStream读取数据的线程也会存在竞争。因此PipedInputStream和PipedOutputStream中的线程安全需要通过synchronized关键字和wait()/notifyAll()机制实现。不建议在一个线程中同时使用PipedInputStream和PipedOutputStream，因为这样可能会导致这个线程陷入死锁状态。<br />\n  PipedInputStream和PipedOutputStream之间的通信本质上是一个生产者-消费者模型，其中PipedOutputStream作为生产者，PipedInputStream作为消费者。两者通过一个循环缓冲区（byte[]数组）进行数据交换，PipedOutputStream将数据缓存在PipedInputStream的数组当中，等待PipedInputStream的读取。<br />\n  PipedInputStream和PipedOutputStream的UML关系图，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h4 id=\"一pipedoutputstream生产者源码向pipedinputstream消费者中的缓冲区byte数组写入字节数据的输出stream生产者\">一、PipedOutputStream（生产者）源码——向PipedInputStream（消费者）中的缓冲区（byte[]数组）写入字节数据的输出Stream（生产者）</h4>\n<pre><code>package java.io;\n\nimport java.io.*;\n\npublic\nclass PipedOutputStream extends OutputStream {\n    //与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）\n    private PipedInputStream sink;\n    \n    //构造函数\n    public PipedOutputStream(PipedInputStream snk)  throws IOException {\n        connect(snk);//调用connect()函数，来改变PipedInputStream （消费者）中一些变量的值\n    }\n    \n    //构造函数\n    public PipedOutputStream() {\n    }\n    \n    //线程同步函数：用来改变将要关联的PipedInputStream （消费者）中一些变量的值\n    public synchronized void connect(PipedInputStream snk) throws IOException {\n        if (snk == null) {\n            throw new NullPointerException();//如果将要关联的PipedInputStream （消费者）为null，抛出NullPointerException\n        } else if (sink != null || snk.connected) {\n            //如果与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）!=null或者将要关联的PipedInputStream （消费者）的boolean connected变量为true，则抛出IOException\n            throw new IOException(\"Already connected\");\n        }\n        sink = snk;//将这个PipedOutputStream（生产者）与这个PipedInputStream （消费者）相关联\n        snk.in = -1;//改变PipedInputStream （消费者）中的变量int in=-1\n        snk.out = 0;//改变PipedInputStream （消费者）中的变量int out=0\n        snk.connected = true;//改变PipedInputStream （消费者）中的变量boolean connected=true\n    }\n    \n    //向与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）的缓冲区（byte[]数组）写入1个字节\n    public void write(int b)  throws IOException {\n        if (sink == null) {\n             //如果与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）== null，抛出IOException\n            throw new IOException(\"Pipe not connected\");\n        }\n        sink.receive(b);//最终调用的是这个相关联的 PipedInputStream （消费者）的receive(int b)函数\n    }\n    \n    //向与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）的缓冲区（byte[]数组）写入byte[]数组b的[off,off+len)（左闭右开，不包括off+len）索引位置的字节\n    public void write(byte b[], int off, int len) throws IOException {\n        if (sink == null) {\n            //如果与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）== null，抛出IOException\n            throw new IOException(\"Pipe not connected\");\n        } else if (b == null) {\n            throw new NullPointerException();//如果byte[]数组b==null，抛出一个NullPointerException\n        } else if ((off &lt; 0) || (off &gt; b.length) || (len &lt; 0) ||\n                   ((off + len) &gt; b.length) || ((off + len) &lt; 0)) {//byte[]数组b的[off,off+len)（左闭右开）索引位置是否有越界的检查\n            throw new IndexOutOfBoundsException();//越界的话，抛出一个IndexOutOfBoundsException\n        } else if (len == 0) {\n            return;//如果len==0，结束本次函数调用\n        }\n        sink.receive(b, off, len);//最终调用的是这个相关联的 PipedInputStream （消费者）的receive(byte b[], int off, int len)函数\n    }\n    \n    //线程同步函数：使用notifyAll()函数唤醒所有与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）线程（这个消费者可以绑定1~多个线程）\n    public synchronized void flush() throws IOException {\n        if (sink != null) {\n            synchronized (sink) {\n                sink.notifyAll();\n            }\n        }\n    }\n    //关闭这个PipedOutputStream（生产者），这个PipedOutputStream（生产者）不能再向与它相关联的PipedInputStream（消费者）中的缓冲区（byte[]数组）写入字节数据\n    public void close()  throws IOException {\n        if (sink != null) {\n            sink.receivedLast();\n        }\n    }\n}\n</code></pre>\n<h4 id=\"二pipedinputstream消费者源码从自己的缓冲区byte数组读取字节数据的输入stream消费者\">二、PipedInputStream（消费者）源码——从自己的缓冲区（byte[]数组）读取字节数据的输入Stream（消费者）</h4>\n<pre><code>package java.io;\n\npublic class PipedInputStream extends InputStream {\n    //标记符：true表示与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）已经关闭，反之，反之\n    boolean closedByWriter = false;\n    //标记符：true表示当前这个 PipedInputStream （消费者）已经关闭了，反之，反之\n    volatile boolean closedByReader = false;\n    //标记符：true表示与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）已经持有了这个PipedInputStream （消费者）对象（或者叫已经连接上了），反之，反之\n    boolean connected = false;\n\n    Thread readSide;//当前消费的线程\n    Thread writeSide;//当前生产者的线程\n    \n    //默认的PipedInputStream （消费者）的缓冲区（byte[]数组）的长度\n    private static final int DEFAULT_PIPE_SIZE = 1024;\n\n    //PipedInputStream （消费者）的缓冲区（byte[]数组）\n    protected byte buffer[];\n    //缓冲区（byte[]数组）的写指针\n    protected int in = -1;\n    //缓冲区（byte[]数组）的读指针\n    protected int out = 0;\n    //构造函数\n    public PipedInputStream(PipedOutputStream src) throws IOException {\n        this(src, DEFAULT_PIPE_SIZE);//缓冲区（byte[]数组）的长度使用默认值1024\n    }\n\n    //构造函数\n    public PipedInputStream(PipedOutputStream src, int pipeSize)\n            throws IOException {\n         initPipe(pipeSize);//缓冲区（byte[]数组）的长度使用指定的长度\n         //最终还是调用PipedOutputStream（生产者）的connect()函数，并把自身对象this传递进去，然后在PipedOutputStream（生产者）的connect()函数中，改变自己的3个变量int in=-1、int out=0、boolean connected=true\n         connect(src);\n    }\n    \n    //构造函数，缓冲区（byte[]数组）的长度使用默认值1024\n    public PipedInputStream() {\n        initPipe(DEFAULT_PIPE_SIZE);\n    }\n\n    //构造函数，缓冲区（byte[]数组）的长度使用指定的长度\n    public PipedInputStream(int pipeSize) {\n        initPipe(pipeSize);\n    }\n    \n    //初始化缓冲区（byte[]数组）\n    private void initPipe(int pipeSize) {\n         if (pipeSize &lt;= 0) {\n            throw new IllegalArgumentException(\"Pipe Size &lt;= 0\");\n         }\n         buffer = new byte[pipeSize];\n    }\n\n    public void connect(PipedOutputStream src) throws IOException {\n        src.connect(this); //最终还是调用PipedOutputStream（生产者）的connect()函数，并把自身对象this传递进去，然后在PipedOutputStream（生产者）的connect()函数中，改变自己的3个变量int in=-1、int out=0、boolean connected=true\n    }\n    \n    //线程同步函数：该函数只被PipedOutputStream（生产者）的write(int b)函数调用\n    protected synchronized void receive(int b) throws IOException {\n        checkStateForReceive();//检查PipedInputStream （消费者）的状态\n        writeSide = Thread.currentThread();//当前执行该函数的线程，就是生产者线程\n        if (in == out)\n            //如果缓冲区（byte[]数组）的读指针==缓冲区（byte[]数组）的写指针，唤醒所有消费者线程，自己这个生产者线程调用wait(1000)函数\n            awaitSpace();\n        if (in &lt; 0) {//缓冲区（byte[]数组）的写指针&lt;0时，设置缓冲区（byte[]数组）的写指针=0，缓冲区（byte[]数组）的读指针=0\n            in = 0;\n            out = 0;\n        }\n        buffer[in++] = (byte)(b &amp; 0xFF);//向缓冲区的写指针位置写入1个字节\n        if (in &gt;= buffer.length) {\n            in = 0;//如果缓冲区满了，设置缓冲区的写指针=0\n        }\n    }\n\n    //线程同步函数：该函数只被PipedOutputStream（生产者）的write(byte b[], int off, int len)函数调用\n    synchronized void receive(byte b[], int off, int len)  throws IOException {\n        checkStateForReceive();//检查PipedInputStream （消费者）的状态\n        writeSide = Thread.currentThread();//当前执行该函数的线程，就是生产者线程\n        int bytesToTransfer = len;//生产者线程要写入到缓冲区（byte[]数组）中的字节总量\n        while (bytesToTransfer &gt; 0) {\n            if (in == out)\n                //如果缓冲区（byte[]数组）的读指针==缓冲区（byte[]数组）的写指针，唤醒所有消费者线程，自己这个生产者线程调用wait(1000)函数\n                awaitSpace();\n            int nextTransferAmount = 0;//本次生产者线程要写入到缓冲区（byte[]数组）中的字节数量\n            if (out &lt; in) {\n                //如果缓冲区的读指针&lt;缓冲区的写指针，本次要写入到缓冲区（byte[]数组）中的字节数量=缓冲区的长度-缓冲区的写指针\n                nextTransferAmount = buffer.length - in;\n            } else if (in &lt; out) {\n                if (in == -1) {\n                    in = out = 0;\n                    //如果缓冲区的读指针（out）&gt; 缓冲区的写指针（in）并且缓冲区的写指针（in）=-1，先设置缓冲区的读（out）、写（in）指针=0，本次要写入到缓冲区（byte[]数组）中的字节数量=缓冲区的长度\n                    nextTransferAmount = buffer.length - in;\n                } else {\n                    //如果缓冲区的读指针（out）&gt; 缓冲区的写指针（in）并且缓冲区的写指针（in）=-1，本次要写入到缓冲区（byte[]数组）中的字节数量=读指针（out）-写指针（in）\n                    nextTransferAmount = out - in;\n                }\n            }\n            //本次生产者线程要写入到缓冲区（byte[]数组）中的字节数量最多为len，下次为len-本次写入到缓冲区（byte[]数组）中的字节数量，也就是每次写入的基于len个字节循环递减上一次写入的\n            if (nextTransferAmount &gt; bytesToTransfer)\n                nextTransferAmount = bytesToTransfer;\n            assert(nextTransferAmount &gt; 0);\n            System.arraycopy(b, off, buffer, in, nextTransferAmount);//向缓冲区（byte[]数组）的[in,in+nextTransferAmount)索引位置写入byte[]数组b中[off,off+nextTransferAmount)索引位置的字节，都是左闭右开。\n            bytesToTransfer -= nextTransferAmount;//每一次都基于len个字节循环递减本次写入到缓冲区（byte[]数组）中的字节数量nextTransferAmount\n            off += nextTransferAmount;//将下次要从byte[]数组b中取字节的起始索引的位置（偏移量）+本次写入到缓冲区（byte[]数组）中的字节数量nextTransferAmount\n            in += nextTransferAmount;//将缓冲区的写指针（in）+本次写入到缓冲区（byte[]数组）中的字节数量nextTransferAmount\n            if (in &gt;= buffer.length) {\n                in = 0;//如果缓冲区的写指针（in）&gt; 缓冲区（byte[]数组）的长度，设置缓冲区的写指针（in）=0\n            }\n        }\n    }\n\n    //检查PipedInputStream （消费者）的状态\n    private void checkStateForReceive() throws IOException {\n        if (!connected) {\n            throw new IOException(\"Pipe not connected\");\n        } else if (closedByWriter || closedByReader) {\n            throw new IOException(\"Pipe closed\");\n        } else if (readSide != null &amp;&amp; !readSide.isAlive()) {\n            throw new IOException(\"Read end dead\");\n        }\n    }\n    \n    //如果缓冲区（byte[]数组）的读指针==缓冲区（byte[]数组）的写指针，唤醒所有消费者线程，自己这个生产者线程调用wait(1000)函数\n    private void awaitSpace() throws IOException {\n        while (in == out) {\n            checkStateForReceive();\n\n            /* full: kick any waiting readers */\n            notifyAll();\n            try {\n                wait(1000);\n            } catch (InterruptedException ex) {\n                throw new java.io.InterruptedIOException();\n            }\n        }\n    }\n    //关闭与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）\n    synchronized void receivedLast() {\n        closedByWriter = true;\n        notifyAll();//唤醒所有消费者线程\n    }\n    //线程同步函数：消费者线程每次从缓冲区（byte[]数组）中读取1个字节\n    public synchronized int read()  throws IOException {\n        if (!connected) {//检查标记符connected，如果为false，抛出IOException\n            throw new IOException(\"Pipe not connected\");\n        } else if (closedByReader) {//检查标记符closedByReader，如果为true，抛出IOException\n            throw new IOException(\"Pipe closed\");\n        } else if (writeSide != null &amp;&amp; !writeSide.isAlive()\n                   &amp;&amp; !closedByWriter &amp;&amp; (in &lt; 0)) {\n           //检查当前这个PipedInputStream （消费者）对象中引用的生产者线程和生产者线程的状态，如果和标记符closedByWriter还有缓冲区（byte[]数组）的写指针（in）不能对应的话，抛出一个IOException\n            throw new IOException(\"Write end dead\");\n        }\n\n        readSide = Thread.currentThread();//当前执行该函数的线程，就是消费者线程\n        int trials = 2;//这是一个多次检测的策略变量，防止生产者线程没有关闭了与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）时便抛出IOException\n        //in=-1的情况有种：\n        //①、生产者线程还没有向缓冲区（byte[]数组）中写任何字节\n        //②、消费者线程从缓冲区（byte[]数组）中读完字节（byte）数据以后读指针（out）=写指针（in），那么，当前消费者线程会设置写指针（in）=-1\n        //③、消费者线程执行PipedInputStream 的close()函数后，关闭了这个 PipedInputStream （消费者）\n        while (in &lt; 0) {\n            if (closedByWriter) {\n                /* closed by writer, return EOF */\n                return -1;\n            }\n            if ((writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)) {\n                //多个消费者线程从缓冲区（byte[]数组）中读的时候，并且前一个消费者线程已经把缓冲区（byte[]数组）中写入的字节读完了，并且前一个线程设置了写指针（in）=-1，生产者线程也关闭了与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）时，抛出一个IOException\n                throw new IOException(\"Pipe broken\");\n            }\n            /* might be a writer waiting */\n            notifyAll();//此处的目的是为了唤醒所有生产者线程\n            try {\n                wait(1000);\n            } catch (InterruptedException ex) {\n                throw new java.io.InterruptedIOException();\n            }\n        }\n        int ret = buffer[out++] &amp; 0xFF;//获取缓冲区（byte[]数组）中读指针（out）索引位置的字节,并且将读指针（out）+1\n        if (out &gt;= buffer.length) {\n            out = 0;//如果读指针（out）&gt;=缓冲区（byte[]数组）的长度，设置读指针（out）=0\n        }\n        if (in == out) {\n            /* now empty */\n            in = -1;//如果消费者线程从缓冲区（byte[]数组）中读完字节（byte）数据以后读指针（out）=写指针（in），那么，当前消费者线程会设置写指针（in）=-1\n        }\n\n        return ret;\n    }\n\n    //线程同步函数：如果缓冲区（byte[]数组）中有足够多的字节的话（数量&gt;len），消费者线程每次从缓冲区（byte[]数组）中读取len个字节放到byte[]数组b的[off, off+len)索引位置（左闭右开，不包括off+len）\n    //如果缓冲区（byte[]数组）中字节的数量&lt;len个（比如有in（写指针）-out（读指针）个），消费者线程每次从缓冲区（byte[]数组）中读取（in-out）个字节放到byte[]数组b的[off, off+in-out)索引位置（左闭右开，不包括off+in-out）\n    public synchronized int read(byte b[], int off, int len)  throws IOException {\n        if (b == null) {\n            throw new NullPointerException();\n        } else if (off &lt; 0 || len &lt; 0 || len &gt; b.length - off) {//byte[]数组b的[off,off+len)（左闭右开）索引位置是否有越界的检查\n            throw new IndexOutOfBoundsException();//越界的话，抛出一个IndexOutOfBoundsException\n        } else if (len == 0) {\n            return 0;//如果len==0，返回0\n        }\n\n        /* possibly wait on the first character */\n        int c = read();//先调用read()函数试探性从缓冲区（byte[]数组）中读1个字节\n        if (c &lt; 0) {\n            return -1;//如果试探性的从缓冲区（byte[]数组）中都读不到1个字节，返回-1\n        }\n        b[off] = (byte) c;//把试探性从缓冲区（byte[]数组）中读到的第1个字节放到byte[]数组b的off索引位置\n        int rlen = 1;//累计从缓冲区（byte[]数组）中读到的所有字节数量\n        while ((in &gt;= 0) &amp;&amp; (len &gt; 1)) {\n\n            int available;//本次执行System.arraycopy()函数可以从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n\n            if (in &gt; out) {\n                available = Math.min((buffer.length - out), (in - out));\n            } else {\n                available = buffer.length - out;\n            }\n\n            // A byte is read beforehand outside the loop\n            if (available &gt; (len - 1)) {//减掉试探性从缓冲区（byte[]数组）中读到的第1个字节\n                available = len - 1;\n            }\n            System.arraycopy(buffer, out, b, off + rlen, available);\n            out += available;//读指针（out）+System.arraycopy()函数从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n            rlen += available;//累计从缓冲区（byte[]数组）中读到的所有字节数量 + System.arraycopy()函数从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n            len -= available;//len - System.arraycopy()函数从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n\n            if (out &gt;= buffer.length) {\n                out = 0;//如果读指针（out）&gt;=缓冲区（byte[]数组）的长度，设置读指针（out）=0\n            }\n            if (in == out) {\n                /* now empty */\n                in = -1;//如果消费者线程从缓冲区（byte[]数组）中读完字节（byte）数据以后读指针（out）=写指针（in），那么，当前消费者线程会设置写指针（in）=-1\n            }\n        }\n        return rlen;//返回累计从缓冲区（byte[]数组）中读到的所有字节数量\n    }\n    \n    //线程同步函数：返回缓冲区（byte[]数组）中可以被消费者线程读取的字节数量\n    public synchronized int available() throws IOException {\n        if(in &lt; 0)\n            return 0;\n        else if(in == out)\n            return buffer.length;\n        else if (in &gt; out)\n            return in - out;\n        else\n            return in + buffer.length - out;\n    }\n    \n    //关闭这个 PipedInputStream （消费者），其实就是设置标记符closedByReader=true， 设置写指针（in）=-1\n    public void close()  throws IOException {\n        closedByReader = true;\n        synchronized (this) {\n            in = -1;\n        }\n    }\n}\n</code></pre>\n<h4 id=\"三1个线程向pipedoutputstream生产者写字节数据1个线程从pipedinputstream消费者读取字节数据的过程\">三、1个线程向PipedOutputStream（生产者）写字节数据，1个线程从PipedInputStream（消费者）读取字节数据的过程</h4>\n<h5 id=\"31非循环直接写和非循环直接读\">3.1、非循环直接写和非循环直接读</h5>\n<pre><code>package com.chelong.StreamAndReader;\n\nimport java.io.IOException;\nimport java.io.PipedInputStream;\nimport java.io.PipedOutputStream;\n\npublic class PipedTest {\n   public static void main(String[] args) throws IOException {\n      final PipedOutputStream output = new PipedOutputStream();\n      final PipedInputStream input = new PipedInputStream(output);\n      Thread thread1 = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               output.write(\"Hello world, pipe!\".getBytes());//write()函数是阻塞的\n            } catch (IOException e) {\n            }\n         }\n      });\n\n      Thread thread2 = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               int data = -1;\n               while ((data = input.read()) != -1) {//read()函数是阻塞的\n                  System.out.print((char) data);\n               }\n            } catch (IOException e) {\n            }\n         }\n      });\n\n      thread1.start();\n      thread2.start();\n   }\n}\n</code></pre>\n<p>程序运行结果，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  main线程构造PipedOutputStream（生产者）和PipedInputStream（消费者）的过程如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  向PipedOutputStream（生产者）写字节数据的生产者线程的执行过程如下：</p>\n<p><img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  从PipedInputStream（消费者）读取字节数据的消费者线程的执行过程如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h6 id=\"311非循环直接写和非循环直接读时1个生产者线程和1个消费者线程处理数据的过程\">3.1.1、非循环直接写和非循环直接读时1个生产者线程和1个消费者线程处理数据的过程</h6>\n<p>  Java 语言定义了 6 种线程状态, 在任意一个时间点, 一个线程只能有且只有其中的一种状态, 这 6 种状态分别如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>这 6 种线程状态的简单介绍，如下所示<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  JVM运行时内存结构主要包含了五个部分：程序计数器 （PC寄存器）、 JVM栈、Native方法栈、堆、 方法区。如下图所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>图中红色部分是线程私有区域，进入这个区域的数据不会出现线程竞争的关系。而绿色区域中的数据则被所有线程共享，其中Java堆中存放的是大量对象，方法区中存放class信息、常量、静态变量等数据。<br />\n  每个线程的线程栈中会存放函数（方法）的描述符，成员（本地）变量等，函数（方法）在线程栈中会通过压栈和弹栈来执行，除了8种（byte、short、int、long、float、double、boolean、char）基本的数据类型存储在线程栈中以外，其余的引用数据类型（对象）都存储在堆中，然后通过引用将堆中的对象和线程栈中的变量关联起来（也可以叫线程栈中的引用指向堆中的对象）。<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>那么，当使用者执行3.1中的代码时，1个生产者线程和1个消费者线程处理数据的过程如下：<br />\n①、main线程初始化一个缓冲区（byte[]数组），长度为1024（默认值），然后生产者线程通过不断的压栈来完成函数之间的调用，最终执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>②、当生产者线程填充完缓冲区之后，写指针变量int in=17，读指针变量int out=0，Thread writeSide = 当前这个生产者线程（Thread）对象，生产者线程会把自己线程栈中修改的变量最终刷新到堆中PipedInputStream对象中，以确保其它消费者线程的线程栈从堆中读取这3个变量时，这3个变量已经为修改后的值，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>③、消费者线程读缓冲区（byte[]数组）的过程中会不断地执行out++（读指针）以读取缓冲区（byte[]数组）中的可用字节并返回，直到out（读指针）==in（写指针），修改in（写指针）=-1，并且每次同步执行PipedInputStream.class::read()函数时，都会更新Thread readSide = 当前这个消费者线程（Thread）对象，消费者线程也会把自己线程栈中修改的变量最终刷新到堆中PipedInputStream对象中，以确保其它消费者线程的线程栈从堆中读取这3个变量时，这3个变量已经为修改后的值，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>④、更新in（写指针）=-1后，消费者线程再次同步执行PipedInputStream.class::read()函数时，如果PipedInputStream::boolean closedByWriter变量为true，则会返回-1</p>\n<h5 id=\"32加锁循环写和非加锁循环读到byte数组b中再处理\">3.2、加锁循环写和非加锁循环读到byte[]数组b中再处理</h5>\n<pre><code>package com.chelong.pipe;\nimport java.io.IOException;\nimport java.io.PipedInputStream;\nimport java.io.PipedOutputStream;\n\npublic class PipeForTransferInThread {\n   public static void main(String[] args) throws IOException, InterruptedException {\n      final PipedOutputStream output = new PipedOutputStream();\n      final PipedInputStream input = new PipedInputStream(output);\n      //生产者线程\n      Thread producer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            for (int i = 0; i &lt; 3; i++) {\n               synchronized (input) {\n                  try {\n//                    input.wait();\n                     output.write(\"Hello world, pipe!\".getBytes());\n                     input.wait();//释放锁并无限等待，直到消费者线程consumer 执行notifyAll()函数来唤醒当前阻塞\n                  } catch (Exception e) {\n                     e.printStackTrace();\n                  }\n               }\n            }\n         }\n      },\"生产者线程\");\n      \n      //消费者线程\n      Thread consumer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               byte[] b = new byte[1024];//1KB\n               int readBytes = -1;\n               long lastTime = System.currentTimeMillis();\n               while ((readBytes = input.read(b, 0, b.length)) != -1) {\n                  long curTime = System.currentTimeMillis();\n                  System.out.print(Thread.currentThread().getName()+\"本次读取花费时间：\" + (curTime - lastTime) + \"ms，读到的数据是：\");\n                  lastTime = curTime;\n                  for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n                  System.out.println();\n               }\n            } catch (IOException e) {\n               e.printStackTrace();\n            }\n         }\n      },\"消费者线程\");\n      producer.start();//生产者线程启动\n      consumer.start();//消费者线程启动\n   }\n}\n</code></pre>\n<p>程序运行结果，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  main线程构造PipedOutputStream（生产者）和PipedInputStream（消费者）的过程可以参考3.1；<br />\n  向PipedOutputStream（生产者）写字节数据的生产者线程的执行过程可以参考3.1；<br />\n  从PipedInputStream（消费者）读取字节数据的消费者线程的执行过程如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h6 id=\"321加锁循环写和非加锁循环读到byte数组b中再处理时1个生产者线程和1个消费者线程处理数据的过程\">3.2.1、加锁循环写和非加锁循环读到byte[]数组b中再处理时1个生产者线程和1个消费者线程处理数据的过程</h6>\n<p>  标题3.2中的代码的整个执行过程如下：<br />\n①、main线程初始化一个缓冲区（byte[]数组），长度为1024（默认值），如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>②、然后生产者线程通过不断的压栈来完成函数之间的调用，最终执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，并且先在自己的线程栈中更新in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程（Thread）对象 如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>当生产者线程对缓冲区（byte[]数组）填充完成之后，再执行标题3.2中的代码</p>\n<pre><code>input.wait();\n</code></pre>\n<p>这行代码会释放锁并让生产者线程进入无限等待，直到消费者线程consumer执行notifyAll()函数来唤醒当前这个生产者线程。在这之前，生产者线程会将自己线程栈中的in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>③、消费者线程读缓冲区（byte[]数组）的过程也是通过不断的压栈来完成函数之间的调用，最终执行PipedInputStream::read()函数（试探性的读取1个字节）和PipedInputStream::read(byte b[], int off, int len)函数（读取剩余其它的字节）将步骤②中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<blockquote>\n<p>附言：最终消费者线程也会将自己线程栈中的in（写指针）= -1，out（读指针）= 17，writeSide=当前这个消费者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。</p>\n</blockquote>\n<p>因此，本次消费者线程从缓冲区（byte[]数组）中读数据的过程中没有执行read()函数中的wait(1000)这一行代码，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>所以，本次消费者线程从缓冲区（byte[]数组）中读取数据到消费者线程中自己创建的byte[]数组中时，只花费了0ms：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>接下来，当消费者线程将步骤②中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来以后（通过System.arraycopy()函数复制到了消费者线程中自己创建的byte[]数组中），消费者线程会遍历从缓冲区读到的这个byte[]数组，来处理这些数据，如下所示（标题3.2中的代码片段）：</p>\n<pre><code>                   //标题3.2中的代码片段\n                   for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n</code></pre>\n<p>然后，当消费者线程再次执行</p>\n<pre><code>//标题3.2中的代码片段\ninput.read(b, 0, b.length)\n</code></pre>\n<p>从缓冲区（byte[]数组）中读数据到自己创建的byte[]数组中时，由于此时in（写指针）=-1，并且当下图中的其它5个条件都不成立时，唤醒执行了</p>\n<pre><code>input.wait()\n</code></pre>\n<p>的生产者线程，然后当前这个正在从缓冲区(byte数组)中读数据的消费者线程执行wait 1000ms ，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>④、当生产者线程被消费者线程执行的</p>\n<pre><code>notifyAll();\n</code></pre>\n<p>唤醒之后，会再次通过不断的压栈来完成函数之间的调用，再次执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，并且先在自己的线程栈中先更新in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程（Thread）对象 如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>当生产者线程对缓冲区（byte[]数组）填充完成之后，再执行标题3.2中的代码</p>\n<pre><code>input.wait();\n</code></pre>\n<p>这行代码会释放锁并让生产者线程进入无限等待，直到消费者线程consumer执行notifyAll()函数来唤醒当前这个生产者线程。在这之前，生产者线程会将自己线程栈中的in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑤、消费者线程在第③步执行了</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>在等待了1000ms之后，消费者线程会自动唤醒继续执行，此时自己线程栈中的in（写指针）= -1，out（读指针）= 17已经被第④步中的生产者线程修改为in（写指针）=17，out（读指针）=0（生产者线程不会直接修改消费者线程栈中的变量，生产者线程会先将自己线程栈中in（写指针），out（读指针）变量的值修改到主内存中，然后消费者线程会自己将主内存中的这2个变量值刷新到消费者自己的线程栈中），如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>然后执行PipedInputStream::read()函数（试探性的读取1个字节）和PipedInputStream::read(byte b[], int off, int len)函数（读取剩余其它的字节）将步骤④中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<blockquote>\n<p>附言：最终消费者线程也会将自己线程栈中的in（写指针）= -1，out（读指针）= 17，writeSide=当前这个消费者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。</p>\n</blockquote>\n<p>由于，本次消费者线程从缓冲区（byte[]数组）中读数据的过程是从步骤③中自动唤醒继续执行的，所以，本次消费者线程从缓冲区（byte[]数组）中读取数据到消费者线程中自己创建的byte[]数组中时，花费了1015ms：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>接下来，当消费者线程将步骤④中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来以后（通过System.arraycopy()函数复制到了消费者线程中自己创建的byte[]数组中），消费者线程会遍历从缓冲区读到的这个byte[]数组，来处理这些数据，如下所示（标题3.2中的代码片段）：</p>\n<pre><code>                   //标题3.2中的代码片段\n                   for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n</code></pre>\n<p>然后，当消费者线程再次执行</p>\n<pre><code>//标题3.2中的代码片段\ninput.read(b, 0, b.length)\n</code></pre>\n<p>从缓冲区（byte[]数组）中读数据到自己创建的byte[]数组中时，由于此时in（写指针）=-1，并且当下图中的其它5个条件都不成立时，唤醒执行了</p>\n<pre><code>input.wait()\n</code></pre>\n<p>的生产者线程，然后当前这个正在从缓冲区(byte[]数组)中读数据的消费者线程执行wait 1000ms ，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑥、当生产者线程被消费者线程执行的</p>\n<pre><code>notifyAll();\n</code></pre>\n<p>唤醒之后，会再次通过不断的压栈来完成函数之间的调用，再次执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，并且先在自己的线程栈中先更新in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程（Thread）对象 如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>当生产者线程对缓冲区（byte[]数组）填充完成之后，再执行标题3.2中的代码</p>\n<pre><code>input.wait();\n</code></pre>\n<p>这行代码会释放锁并让生产者线程进入无限等待，直到消费者线程consumer执行notifyAll()函数来唤醒当前这个生产者线程。在这之前，生产者线程会将自己线程栈中的in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑦、消费者线程在第⑤步执行了</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>在等待了1000ms之后，消费者线程会自动唤醒继续执行，此时自己线程栈中的in（写指针）= -1，out（读指针）= 17已经被第⑥步中的生产者线程修改为in（写指针）=17，out（读指针）=0（生产者线程不会直接修改消费者线程栈中的变量，生产者线程会先将自己线程栈中in（写指针），out（读指针）变量的值修改到主内存中，然后消费者线程会自己将主内存中的这2个变量值刷新到消费者自己的线程栈中），然后执行PipedInputStream::read()函数（试探性的读取1个字节）和PipedInputStream::read(byte b[], int off, int len)函数（读取剩余其它的字节）将步骤⑥中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<blockquote>\n<p>附言：最终消费者线程也会将自己线程栈中的in（写指针）= -1，out（读指针）= 17，writeSide=当前这个消费者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。</p>\n</blockquote>\n<p>由于，本次消费者线程从缓冲区（byte[]数组）中读数据的过程是从步骤⑤中自动唤醒继续执行的，所以，本次消费者线程从缓冲区（byte[]数组）中读取数据到消费者线程中自己创建的byte[]数组中时，花费了1017ms：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>接下来，当消费者线程将步骤⑥中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来以后（通过System.arraycopy()函数复制到了消费者线程中自己创建的byte[]数组中），消费者线程会遍历从缓冲区读到的这个byte[]数组，来处理这些数据，如下所示（标题3.2中的代码片段）：</p>\n<pre><code>                   //标题3.2中的代码片段\n                   for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n</code></pre>\n<p>然后，当消费者线程再次执行</p>\n<pre><code>//标题3.2中的代码片段\ninput.read(b, 0, b.length)\n</code></pre>\n<p>从缓冲区（byte[]数组）中读数据到自己创建的byte[]数组中时，由于此时in（写指针）=-1，并且当下图中的其它5个条件都不成立时，唤醒执行了</p>\n<pre><code>input.wait()\n</code></pre>\n<p>的生产者线程，然后当前这个正在从缓冲区(byte[]数组)中读数据的消费者线程执行wait 1000ms ，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑧、当生产者线程被消费者线程执行的</p>\n<pre><code>notifyAll();\n</code></pre>\n<p>唤醒之后，会跳出for循环，结束生产者线程的生命周期，之后，该线程对象会被操作系统回收。<br />\n⑨、消费者线程在第⑦步执行了</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>在等待了1000ms之后，消费者线程会自动唤醒继续执行，此时自己线程栈中的in（写指针）= -1，out（读指针）= 17，并且从</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>的代码之后，继续执行，执行过程如下（从下图的紫色流程继续执行）：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>在执行了2个循环后，直到int trials = 0时，执行到判断(writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)这个条件时就会为true（下图的红色流程）<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>然后，抛出了一个IOException(\"Pipe broken\")，因此，可以得出int trials变量的含义：这个变量是一个多次检测的策略变量，当生产者线程没有关闭了与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）时，并且writeSide变量指向的当前生产者线程已经被操作系统回收时（此时当前生产者线程对象的isAlive()函数会返回false），消费者线程会抛出1个IOException(\"Pipe broken\")，并结束while循环，进而结束消费者线程的生命周期。之后，该线程对象也会被操作系统回收。如下图所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h6 id=\"322怎样防止321中第步的生产者线程抛出ioexceptionpipe-broken\">3.2.2、怎样防止3.2.1中第⑨步的生产者线程抛出IOException(\"Pipe broken\")</h6>\n<p>  回顾3.2.1中第⑨步中的消费者线程抛出IOException(\"Pipe broken\")的产生过程：当执行到判断(writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)这个条件时就会为true（下图的红色流程）<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>那么，使用者就可以将上图中红色流程的前一步变成true即可，如下代码所示（只修改了生产者线程中的代码，消费者线程中的代码没有变化）：</p>\n<pre><code>package com.chelong.pipe;\nimport java.io.IOException;\nimport java.io.PipedInputStream;\nimport java.io.PipedOutputStream;\n   public static void main(String[] args) throws IOException, InterruptedException {\n      final PipedOutputStream output = new PipedOutputStream();\n      final PipedInputStream input = new PipedInputStream(output);\n      //生产者线程\n      Thread producer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               for (int i = 0; i &lt; 3; i++) {\n                  synchronized (input) {\n//                    input.wait();\n                     output.write(\"Hello world, pipe!\".getBytes());\n                     input.wait();//释放锁并无限等待，直到消费者线程thread2执行notifyAll()函数来唤醒当前阻塞\n                  }\n               }\n            } catch (Exception e) {\n               e.printStackTrace();\n            } finally {\n               try {\n                  if (output != null) output.close();//调用close()函数关闭生产者对象\n               } catch (IOException e) {\n                  e.printStackTrace();\n               }\n            }\n         }\n      }, \"生产者线程\");\n\n      //消费者线程\n      Thread consumer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               byte[] b = new byte[1024];//1KB\n               int readBytes = -1;\n               long lastTime = System.currentTimeMillis();\n               while ((readBytes = input.read(b, 0, b.length)) != -1) {\n                  long curTime = System.currentTimeMillis();\n                  System.out.print(Thread.currentThread().getName() + \"本次读取花费时间：\" + (curTime - lastTime) + \"ms，读到的数据是：\");\n                  lastTime = curTime;\n                  for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n                  System.out.println();\n               }\n            } catch (IOException e) {\n               e.printStackTrace();\n            }\n         }\n      }, \"消费者线程\");\n      producer.start();//生产者线程启动\n      consumer.start();//消费者线程启动\n   }\n}\n</code></pre>\n<p>程序运行结果，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  通过PipedOutputStream.class::close()的源码可以看到这样修改后消费者线程不再抛出IOException(\"Pipe broken\")原因：<br />\nPipedOutputStream.class（生产者类）的源码</p>\n<pre><code>package java.io;\n\nimport java.io.*;\n\npublic\nclass PipedOutputStream extends OutputStream {\n    ...省略部分代码...\n    //关闭这个PipedOutputStream（生产者），这个PipedOutputStream（生产者）不能再向与它相关联的PipedInputStream（消费者）中的缓冲区（byte[]数组）写入字节数据\n    public void close()  throws IOException {\n        if (sink != null) {\n            sink.receivedLast();//调用PipedInputStream.class::receivedLast()函数\n        }\n    }\n}\n</code></pre>\n<p>PipedInputStream .class（消费者类）的源码</p>\n<pre><code>package java.io;\n\npublic class PipedInputStream extends InputStream {\n    //标记符：true表示与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）已经关闭，反之，反之\n    boolean closedByWriter = false;\n    ...省略部分代码...\n    //关闭与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）\n    synchronized void receivedLast() {\n        closedByWriter = true;//关闭后消费者再从缓冲区（byte[]）数组中读取字节数据时，会返回-1，不会抛出IOException了\n        notifyAll();//唤醒所有消费者线程\n    }\n    ...省略部分代码...\n</code></pre>\n<h4 id=\"四多个线程向pipedoutputstream生产者写字节数据多个线程从pipedinputstream消费者读取字节数据的过程\">四、多个线程向PipedOutputStream（生产者）写字节数据，多个线程从PipedInputStream（消费者）读取字节数据的过程</h4>\n<p>  略（待补充）</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 22:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Carey-ccl\">Carey_ccl</a>&nbsp;\n阅读(<span id=\"post_view_count\">34</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2023年电赛国赛经历",
      "link": "https://www.cnblogs.com/badboy02/p/19623709",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/badboy02/p/19623709\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 14:06\">\n    <span>2023年电赛国赛经历</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"2023年电赛国赛经历\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3763221/202602/3763221-20260219000428689-1446099918.png\" />\n        2023年全国大学生电子设计竞赛经历，D题信号题，国赛二等奖。\n一些比赛经历和经验技巧\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>--- markdown描述<br />\ntitle: 电赛2023国赛D题比赛经历<br />\ndate: 2023/8/15 11:52:25<br />\ncover: true<br />\nmathjax: false<br />\nsummary: 比赛过程和一些准备工作的碎碎念<br />\ncategories: Note<br />\ntags:</p>\n<ul>\n<li>电赛</li>\n<li>信号</li>\n</ul>\n<hr />\n<h2 id=\"补档声明\">补档声明</h2>\n<p>由于我的博客服务器和备案到期，所以选择转移到博客园平台来进行保存和记录。以后也有可能会在上面不定期更新一些技术类博客。</p>\n<h2 id=\"写在前面\">写在前面</h2>\n<p>🪓突然意识到自己已经8个月没更新博客了，这段时间其实也没遇上啥太复杂的事，大概就是一些沉淀之类的，决定了之后的学业去向，推免了本校的研究生。进一步认识了一群未来志同道合的的同门，激情爽玩塞尔达旷野之息和王国之泪，狠狠地治愈了一阵子的电子阳痿，以及开始健身（存疑）。<br />\n当然，电赛什么的也是有在准备的，由于团队其他两个都是硬件佬，他们承受着画板与焊接调试的水深火热，我只需要安安静静的写代码就足够了（笑），每天实验室上下班，把自己的部分搞定，然后去健身房锻炼一会，回来美美加个餐洗个澡，然后打打机去睡觉，也算是某种意义上的平静的生活，求之不得。毕竟当初决定打电赛说到底也只是为了提升自己，探索一下电子世界的奥妙，这么久走过来也是重在坚持，也希望最后能有一个好结果。<br />\n截止到写博客的时候，我们组的成绩省赛以省一并列第一出线，综合测评应该也能过线，山东大学国测复测不出意外的话，应该是国二以上。</p>\n<p>这篇博客会分为上下两部分，上篇主要是比赛的过程和一些前置的准备(没有营养的碎碎念)，下篇主要是一些算法具体的实现(一些情急之下的灵机一动，大佬轻锤)。</p>\n<h2 id=\"比赛过程\">比赛过程</h2>\n<ol>\n<li>准备阶段</li>\n</ol>\n<p>我们队伍一直以来训练的是仪表和高频题，一开始侧重FPGA高速信号采集和数字域处理这一块，但是后面逐渐意识到，对于电赛的指标范围内好像也不需要这么高的频率，高载波带来的高采样率问题可以通过下混频缓解，而高频直采带来是的FIR滤波器的资源消耗成倍增加，以及数字域处理带来的资源占用和量化噪声问题。</p>\n<p><img alt=\"ZYNQ7100平台\" class=\"lazyload\" /><br />\n这是我们准备的ZYNQ7100的平台，可以外接高速ADDA，板载DDR3.<br />\n但是吧，ZYNQ平台的综合速度和固化难度以及Verilog代码的验证难度，在分秒必争的竞赛里，如果没有长期的训练和准备，在比赛那四天着急上头去写，恐怕会翻车。</p>\n<p>于是在训练后期又重回STM32H743的单片机平台，侧重模块叠加后的健壮性和代码的可复用性。</p>\n<p>从训练开始，🪓就有意识地把一些算法，尤其是FFT分析这一块，写成了独立的函数去进行一些参数的分析，然后把其他的像是屏幕显示，按键输入，外设驱动，都封装成主循环中的函数，用参数和标志位去控制。不得不说在电赛的信号分析题中还是一种很好用的代码架构。</p>\n<p><img alt=\"Main函数截图\" class=\"lazyload\" /></p>\n<p>本次代码的组织结构，可以清楚的看到，是首先进行ADC采集，FFT计算，然后将参数传入Judge_ModeType函数计算出调制类型，然后进入相应的部分去进行分析和显示。</p>\n<p>2.正式开始</p>\n<p>比赛的那几天，第一天上午8点队友一拿到题目基本上就确定了是D题，然后就开始画系统框图，找模块，搭系统。<br />\n🪓是九点钟到的实验室。然后一看题，哦豁，Ma和Mf！ 这不是老朋友吗，去年省赛这两位重量级，特别是Mf，让无数队伍刹羽而归。<br />\n其奇妙的多值和莫名其妙的算不准问题，难到了一大批电赛壬。<br />\n不过算法方面🪓早有应对，具体请看后文分析。<br />\n队友把混频模块弄好，确定好中频频率后，把混频后的信号通入ADC模块，此时🪓进行了简单的测试，确定了ADC采样率。<br />\n然后就开始了算法的编写。在第一天的中午就把Ma的计算搞定了，精度误差大概在0.05左右。<br />\n然后下午把Mf的算法也基本调试正确了，精度误差在0.2左右，有少量的多值问题，这时候时间已经是第一天晚上的8点，🪓进行了第一次备份。（时常备份真是好习惯）<br />\n<img alt=\"备份截图\" class=\"lazyload\" /><br />\n这是工程的几次备份图，可以看到从7月17日确定了基本平台之后，就是几天一备份，在比赛那几天更是一天备份几次。<br />\n为什么没有使用git之类的版本控制工具呢，因为我不会（其实是懒得建仓库+没找到合适的托管平台，github连不上，gitee不想用）<br />\n然后就是ASK，FSK，PSK的判别、解调以及FSK的h参数计算问题，总的说来，这个花费了🪓一番功夫，也算是最核心的代码部分。<br />\n第二天的中午完成了模拟调制和数字调制两大类的初步判断，下午进一步完成了模拟的AM，FM，CW的进一步判断，以及数字的ASK，FSK，PSK的进一步判断和解调。(充实的一天)<br />\n<img alt=\"PSK解调\" class=\"lazyload\" /><br />\n第二天晚上回寝室的时候🪓在和队友闲扯的时候突然想到了FSK的h参数计算方法，然后在小本本上记了下来。<br />\n第三天，🪓一到实验室就开始着手验证自己的想法，发现完全可以，直接芜湖起飞。<br />\n然后下午的时间就是加入射频开关和滤波器，放大器等原件，完成了系统的整体级联和最后解调波形的实时切换。<br />\n第三天的晚上其实整个系统已经级联并且测试好了。<br />\n最后一天就是一些锦上添花的功能，比如实时频谱显示和QPSK的判断以及高频载波下的解调以及准度的修正，在下午三点左右完成了最后的测试和封箱。<br />\n<img alt=\"封箱\" class=\"lazyload\" /><br />\n总的来说这几天的流程还是稳扎稳打，逐步推进的。我们团队一直以来配合的也很不错，效率贼高，最后呈现出来的效果就是电赛这三天每天晚上11点都回寝室睡觉了，第二天9点再到实验室，也还能完成所有的基础和提高指标并做出3项其他指标。不知不觉中完成了我们团队刚开始接触电赛的时的一个玩笑-希望以后能不熬夜就打完电赛。<br />\n<img alt=\"交作品\" class=\"lazyload\" /><br />\n作为东道主，半夜交作品也是很合理的罢。</p>\n<p>3.省赛测评</p>\n<p>封箱后的第二天就是省测了，总的来说还是蛮顺利的，所有功能都演示出来了，测评表的指标也没有很难的点。<br />\n测完直接和朋友出去快乐吃喝，等待综合测评名单。</p>\n<p>4.综合测评<br />\n由于🪓理论上是纯软件队员(其实🪓也会画板子和焊板子，这就是EEer的素养)，综合测评的硬件大业当然就交给我的两位大爹队友了，🪓只需要在旁边写个报告算个参数就好。<br />\n在准备硬件测评器件，我们测试了各种555电路，二极管检波，微分积分器，加法器，带通滤波器的电路图。<br />\n综合测评那天，一进现场，发现题目竟然是模拟计算器，用来解一个微分方程。<br />\n不过稍加分析，就会发现其本质是文氏桥正弦发生器，三角波发生器，两个积分器，一个微分器，一个加法器的组合。<br />\n这一里面的每一项单独拎出来都很简单，但是在当时时间比较紧促的情况下，我们虽然把电路全部级联出来了，但是在零状态的时候，并没有像计算的那样，产生一个33Hz的自激波形。<br />\n也许是中间的某项RC常数没有配置正确，也许是某一段未修正相差，也许是某一段的偏置需要消除，总是零状态的时候就是妹有出波形。<br />\n说到模拟计算电路，其实这是个展开来讲有非常多可以讲的话题，想进一步研究的同学可以移步CNPP大佬的模拟计算 <a href=\"https://hackaday.io/project/191142-analog-lorenz-attractor-computer/details\" rel=\"noopener nofollow\" target=\"_blank\">https://hackaday.io/project/191142-analog-lorenz-attractor-computer/details</a><br />\n我们也就停止了后面的输入激励。静待比赛时间结束，毕竟这只是一个达标测试，就不冒进去做进一步的冒险了。</p>\n<p>有一说一中午学校提供的饭菜还可以，菜品有土豆烧牛肉，木耳炒蛋，水煮虾，还有酸奶和水果，我TM吃吃吃。</p>\n<p>4.国赛评测</p>\n<p>等🪓玩回来更新</p>\n<h2 id=\"题目分析\">题目分析</h2>\n<p><img alt=\"题目描述1\" class=\"lazyload\" /></p>\n<p><img alt=\"题目描述2\" class=\"lazyload\" /></p>\n<p><strong>题目分析（*的数量为重要程度）</strong></p>\n<ul>\n<li>题目的输入信号有100mv，属于一个比较大的信号，从信号源直出，通过SMA线输入，<strong>信噪比非常高，不需要考虑信号在无线传输过程中被干扰和多径效应等问题</strong></li>\n<li>载波频率2MHz，说实话，是一个比较微妙的频率，刚好超过了市面上单片机内置ADC的最大采样频率，但是对于FPGA外挂的50M左右的高速ADC来说(AD9225:没错正是在下)，又看上去是一个很合适的频率。所以使用单片机的组一般会<strong>选择下混频</strong>，而使用FPGA的组如果选择直采，经过我们当时的分析，可能会遇到一些问题问题，比如FFT后频率分辨率不够，FIR资源消耗大带来的综合慢，数字下混频相位不对齐造成的失真和误差(更别提Vivado的FFT的IP核要想用好其实并不容易，定点FFT很容易产生很大的舍入误差)。肯定有FPGA佬能想到规避或者解决的办法。但是受限与我们当时知识理解的程度，我们还是选择了单片机平台。所以从这也可以看出电赛的出题并不一味地要求好的器件，而更多的是<strong>因地制宜选择方案</strong></li>\n<li><strong>要计算调幅度Ma，这就要求获得调制后信号的频谱，也就是要做FFT</strong>。这就要求ADC的采样频率能够高于中心频点+最大频偏之和的两倍。当然，实际上为了频谱的可读性和频率精确度的考量，一般选择4至6倍的采样频率*</li>\n<li>要计算调频度Mf和最大频偏Δf，同上，还涉及到一些算法的<strong>多值问题</strong>，在后面详细讨论</li>\n<li>要进行模拟调制的解调，可以先通过混频**把信号混到10.7M高中频，使用ADL5511 ，NE564等芯片进行解调</li>\n<li>要识别ASK，FSK，PSK等调制方式，这就要求<strong>把它们的频谱差异提取出来并做好特征区分，以及对于某些非常相似情况下引入多重判断维度来进行区分</strong> 。</li>\n<li>要通过频谱进行FSK的h参数的计算，其实在单片机里做是很难的，但是我们可以<strong>通过FM和FSK的相似性，来进行一些取巧的操作</strong>，这个后面详细讨论**</li>\n<li>要识别待调制波的频率，其实就是<strong>计算调制后波形的FFT相邻频点之间的间隔</strong>，这一点是由调制的性质所导致的，所有调制方式都能通过这种方式判断待调制波的频率*</li>\n<li>要进行数字调制波形的解调，<strong>要结合不同调制方式的特点，混合使用模拟模块和数字域判决的方式来进行解调</strong>，比如ASK使用的是先通过模拟AD8310检波后通过直流量高低来判断0，1波形。FSK使用了数字FIR把频率转变为包络的变化，进行0，1的判决。而PSK使用了先数字域下混频和FIR的方式，把相位的跳变导致的相乘后的包络变化通过滤波器检出</li>\n<li>要综合上述的识别和计算，通<strong>过模拟开关将解调结果通过一个通道显示</strong>在示波器上，并通过AGC等手段，保证电压大于1Vpp*</li>\n</ul>\n<h2 id=\"系统架构\">系统架构</h2>\n<p><img alt=\"系统架构\" class=\"lazyload\" /></p>\n<p>本系统硬件框图如图所示，乍一看非常复杂(实际上也确实很复杂，最后数了一下，作品上一共有26块板子)。别急，让我们慢慢来，一步步分析，<br />\n由于输入信号的峰峰值是100mV，换算一下也就是-16dbm，所以首先经过24dB增益的低噪放ERA-3SM进行放大。<br />\n此时的信号幅度有8dbm，也就是峰峰值1.5Vpp，正好适合后面的各种器件的电压范围。<br />\n然后将信号通过功分器，同时混频到50kHz中频和10.7MHz中频。这是为了一路用来分析，一路用来模拟解调。<br />\n50kHz 的中频信号，经过滤波、放大和电平搬移后，一路经过ADS8688变为数字信号送入单片机。另一路经过检波器 AD8310 和滤波器 UAF42 后检出 ASK 的直流，并送给单片机进一步完成 ASK 信号的定时抽判。<br />\n10.7MHz 的中频信号经过陶瓷滤波器、放大器和射频开关后，分别进行基于 ADL5511 的 AM 包络检波解调和基于 NE564 的FM 解调.<br />\n最后通过 MCU 控制的模拟开关TMUX1109，将解调结果送给示波器显示。在单片机内，通过对 50kHz 的中频信号的频谱分析，得到调制信号类型和调制参数，<br />\n以及FSK和PSK的解调结果的输出，并控制其他模块完成最后结果的汇总输出，以及控制液晶屏显示识别结果和参数。</p>\n<h2 id=\"一些准备工作和小寄巧\">一些准备工作和小寄巧</h2>\n<h3 id=\"电压和dbm的换算\">电压和dbm的换算</h3>\n<p>在射频电路中，为了表示比较小的电压，一般采用对数形式，其中dbm是一个常用的单位，它是在某一阻抗匹配系统下，功率相对于1mW的比值，而由于已经射频电路阻抗一般是50欧姆，所以相当于也知道了电压。<br />\n不过由于功率的计算还涉及到波形的有效值啥的，方波1，正弦0.707，三角波0.57，实际中一般不会自己去算，都是使用这种在线计算器。<br />\n可以记忆一下一些常见的值</p>\n<table>\n<thead>\n<tr>\n<th>正弦波</th>\n<th>50欧姆阻抗下</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-116dbm</td>\n<td>1uVpp</td>\n</tr>\n<tr>\n<td>-56dbm</td>\n<td>1mVpp</td>\n</tr>\n<tr>\n<td>-36dbm</td>\n<td>10mVpp</td>\n</tr>\n<tr>\n<td>-16dbm</td>\n<td>100mVpp</td>\n</tr>\n<tr>\n<td>0dbm</td>\n<td>632mVpp</td>\n</tr>\n<tr>\n<td>4dbm</td>\n<td>1Vpp</td>\n</tr>\n<tr>\n<td>14dbm</td>\n<td>3.3Vpp</td>\n</tr>\n</tbody>\n</table>\n<p>实用小工具 电压和dbm的换算<br />\n<a href=\"https://www.analog.com/cn/design-center/interactive-design-tools/dbconvert.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.analog.com/cn/design-center/interactive-design-tools/dbconvert.html</a></p>\n<p><img alt=\"ADI电压换算工具\" class=\"lazyload\" /><br />\n注意这里的VPeak是峰值，换算成峰峰值的话要乘以2</p>\n<h3 id=\"adc的一些准备工作\">ADC的一些准备工作</h3>\n<p><img alt=\"ADS8688手册\" class=\"lazyload\" /></p>\n<h4 id=\"adc选型\">ADC选型</h4>\n<p>我们本次使用的是ADS8688A作为系统的ADC，它是一个16bit，500KSPS采样率的SAR型ADC。<br />\n它的特点有双极性输入，可配置动态范围，内部基准，八通道MUX采样，误差和漂移都很低，对于本题来说肯定是够用的。<br />\n我们用它主要还是看上了它支持双极性输入和可变动态范围这一点，这样就不用自己做前级的搬移和放大。<br />\n而且自带过压保护，比较耐造。<br />\nPS.我们的STM32H743平台的内置ADC，在某次测试的时候，对单频大幅值信号采样做FFT后，其二次谐波值会大的超出常理，理论上来说是不会有这么大的。<br />\n怀疑内置SAR积分电路被过压橄榄了😓<br />\n所以换用了这个外置的ADC，以后可以开一篇文章讲一下ADC的各种参数，以及这种失真是怎么来的，此时就要请出另一位小信号领域的expert，FloydFish🐟<br />\n可以移步<a href=\"https://www.emoe.xyz/opamp-noise-analyze/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.emoe.xyz/opamp-noise-analyze/</a> ，以及相关的小信号测量。</p>\n<p>驱动代码<br />\n这个的驱动我已经打包好了，下载下来改一下管脚直接用就可以了 <a href=\"https://megrez-hong.oss-cn-shanghai.aliyuncs.com/blogs/ADS8688_Driver.zip\" rel=\"noopener nofollow\" target=\"_blank\">https://megrez-hong.oss-cn-shanghai.aliyuncs.com/blogs/ADS8688_Driver.zip</a><br />\n<strong>ADC的驱动要注意的两点是，一是这个ADC的数据Latch和吐出是根据SPI的速率来的</strong><br />\n所以为了控制采样速率，需要自己控制其中的IO操作后的Delay函数，经过测试，在ARMCC6编译器，O2水平的优化下，使用volatile参数，下面这种delay方法依然可以达到延时效果。</p>\n<p><img alt=\"Delay的实现\" class=\"lazyload\" /></p>\n<p><img alt=\"ADS8688的采样函数\" class=\"lazyload\" /><br />\n二是采样的时候需要关闭中断响应，因为我们不希望采样的时候定时器中断什么的把采样操作打扰了。</p>\n<p>这里的采样率根据实测大概在250K左右，达不到官方的标称的500K。应该是已经达到了软件SPI的IO速度上限了，250kSPS*16bit = 4Mbit的速度了。</p>\n<p>如果要更快一点，可以使用硬件SPI+DMA的方式，但是比赛当前，就不折腾花活了，能用就好。</p>\n<p>另外一点是STM32的H7系列的软SPI的会有的一个毛病，在CubeMX中需要把这些个管脚(CLK,MISO,MOSI,CS)的最大频率设置成Low，否则如果设置为High之类的。</p>\n<p>较大的驱动电流会造成信号的过冲和振铃，造成读出的数据有时是对的，有时读出的会是全1或者全0。</p>\n<p>这一点我是在调试RDA5820的时候发现的，之前用STM32U5驱动RDA5820是正常的，同样的代码在H7下就会有时正确有时不能读出。后来在思考信号完整性链路的时候有了新的想法。</p>\n<p>我个人的看法是，可能由于是H7的驱动电流能力比较强，IO翻转的上升沿相比F1，F7这些要陡峭很多，而数字信号链路是通过一段比较长的XH2.54线接到了外部的模块上，<br />\n根据传输线模型的推论，当传输线长度和1/6上升沿波长可以相比拟时，就有可能造成信号完整性问题。<br />\n所以这时IO驱出来的数字波形会有过冲和振铃等信号完整性问题也是可以理解的。</p>\n<p>验证ADC采集时候，一般会串口打印波形，再使用SerialPlot查看，是不是和理论符合，比如下图就是ASK波形的采样结果。</p>\n<p><img alt=\"ASK的采集到的波形\" class=\"lazyload\" /></p>\n<h3 id=\"fft的准备工作\">FFT的准备工作</h3>\n<ul>\n<li>使用Cmsis DSP库，在Keil的包管理里面勾选即可，最新版本有窗函数的需要从官网上下载（怎么感觉有点似曾相识，我去年暑假好像也写过）</li>\n</ul>\n<p><img alt=\"Keil添加Pack\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>在Keil的设置里面，加入ARM_MATH_CM7, ARM_MATH_LOOPUNROLL这两条宏定义，前面是Cortex版本，需要是MCU的内核版本，可以是CM1，CM4，CM7,后面的是控制数学舍入的，一般来说不用动。<br />\n<img alt=\"keil的编译设置\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>然后在include的地方加入 #include \"arm_math.h\"   和  #include \"arm_const_structs.h\"，然后开辟一个fft的全局数组，就可以愉快的调用啦。</p>\n</li>\n<li>\n<p><strong>FFT的调用</strong>**</p>\n</li>\n</ul>\n<pre><code class=\"language-C\">/* ADC采样并做FFT 结果放在全局数组fft_outputbuf中 */\n/* 做FFT 结果放在全局数组fft_outputbuf中 一次4096个点 */\nvoid FFT(unsigned short *ADC_Buffer, unsigned int SampleRate, unsigned int len, int debug, int serialplot)\n{\n    for(int i=0;i&lt;Sampling_CNT;i++)\n    Global_ADC_Value[i] = ADC_Buffer[i]*3.3/4096;   // 将采样结果转化到0-3.3V\n    \n    for(int i=0;i &lt; FFT_LENGTH;i++)   \n    {\n    fft_inputbuf[i*2] = Global_ADC_Value[i];  // 按手册要求的实部虚部交替的方法填充数组\n    fft_inputbuf[2*i +1] = 0;\n    }\n\n    arm_cfft_f32(&amp;arm_cfft_sR_f32_len4096,fft_inputbuf,0,1); // 执行FFT变换，arm_cfft_sR_f32_len4096为宏，定义旋转因子\n    arm_cmplx_mag_f32(fft_inputbuf,fft_outputbuf,FFT_LENGTH);    // 把运算结果复数求模得幅值\n\n    /* Debug打印区 */\n    \n    if(debug == 1)\n     for(int i=0;i &lt; FFT_LENGTH/2;i++)       // 是否打印FFT每个频点的幅值信息\n       printf(\"%d  %.3lf KHz Mag %.3f\\n\", i,SampleRate*1.0/len*i, fft_outputbuf[i] );\n    \n    if(serialplot == 1)\n     for(int i=0;i &lt; FFT_LENGTH;i++)       //  是否打印fft结果到到SerialPlot\n        printf(\"%.3f\\n\", fft_outputbuf[i]);\n\n}\n</code></pre>\n<p>做完FFT后，我们一般会通过SerialPlot软件来查看FFT的结果和和理论估计是否符合。<br />\n下图是1KHz载波，3KHz频偏的FM频谱的实测图<br />\n<img alt=\"FM的频谱\" class=\"lazyload\" /></p>\n<h3 id=\"代码组织的思路\">代码组织的思路</h3>\n<p>这题是一个经典的测量-分析-显示的题目，所以采用的思路就是先采集，判断调制类型后，进一步去对应的部分进行进一步的分析和显示。<br />\n由于FFT分析后给的参数值不止一个，所以使用了函数传地址的办法。<br />\n<img alt=\"函数传参参数\" class=\"lazyload\" /><br />\n而且由于Keil没有比较方便的代码补全和快捷提示功能，如果所有的算法都在main中实现，会导致代码实现那一段到下面的main函数的里调用段，有一段非常长的距离，所以我个人的建议是把一些更基础的算法代码另外封装到一个Algorithm文件里。<br />\n<img alt=\"Algorithm.c截图\" class=\"lazyload\" /></p>\n<h3 id=\"下节预告鸽了实际上因为神秘赛制的原因我们没有去到比赛现场但是还是国赛二等奖就不献丑了\">下节预告（鸽了，实际上因为神秘赛制的原因，我们没有去到比赛现场，但是还是国赛二等奖，就不献丑了）</h3>\n<ul>\n<li>模拟调制和数字调制两个大类的区分(中心载频与相邻频点之间的距离)</li>\n<li>三种模拟调制的区分(CW, AM, FM)</li>\n<li>三种数字调制的区分(ASK, FSK, PSK)</li>\n<li>各种调制载波频率的计算(频谱最近相邻谱线的距离)</li>\n<li>AM调制的Ma的计算(寻峰算法)</li>\n<li>FM调制的Mf的计算(基于模式匹配的思想)</li>\n<li>FSK调制的h参数的计算(基于和FM的相似带来的模式复用)</li>\n<li>ASK的抽判(基于直流量的定时抽判)</li>\n<li>FSK的抽判(两路FIR后的抽判)</li>\n<li>PSK的抽判(满足特定频率的相位突变点抽判法)</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 14:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/badboy02\">Badboy02</a>&nbsp;\n阅读(<span id=\"post_view_count\">75</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从零开始学Flink：实时数仓与维表时态Join实战",
      "link": "https://www.cnblogs.com/daimajiangxin/p/19624638",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/daimajiangxin/p/19624638\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 12:58\">\n    <span>从零开始学Flink：实时数仓与维表时态Join实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"从零开始学Flink：实时数仓与维表时态Join实战\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3365149/202602/3365149-20260219125729266-340455730.png\" />\n        以电商订单实时数仓为例，演示如何在 Flink SQL 中通过维表时态 Join 将事实流与维度数据关联，构建带用户属性的明细宽表，并结合 Kafka 与 MySQL 环境完成一套可落地的实时数仓入门实践。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在前一篇 <a href=\"https://mp.weixin.qq.com/s/kLxoo6mHi49HvrrmaOdTsA\" rel=\"noopener nofollow\" target=\"_blank\">《Flink 双流 JOIN 实战详解》</a> 中，我们用「订单流 + 支付流」搞懂了事实双流之间的时间关联。</p>\n<p>但在真实的实时数仓项目里，光有事实流还不够，业务同学更关心的是：</p>\n<ul>\n<li>下单用户是新客还是老客</li>\n<li>用户当前的等级、城市、渠道</li>\n<li>商品所属品类、类目层级</li>\n</ul>\n<p>这些信息通常存放在 <strong>维度表</strong>（维表）中，例如 MySQL 的 <code>dim_user</code>、<code>dim_product</code> 等。我们希望在实时计算时，能把「事实流」和「维表」在时间维度上正确地关联起来，构建一张带有完整业务属性的<strong>明细宽表</strong>。</p>\n<p>这就是 <strong>维表时态 Join（Temporal Table Join）</strong> 要解决的问题。</p>\n<p>本文我们就以「订单事实流 + 用户维表」为例，完成一个从 Kafka 到 MySQL 的简易实时数仓 Demo，并重点理解 Flink SQL 中维表时态 Join 的语法和注意事项。</p>\n<h2 id=\"一业务场景与数仓目标\">一、业务场景与数仓目标</h2>\n<p>设想一个简化的电商业务场景：</p>\n<ul>\n<li>Kafka 中有实时写入的 <code>orders</code> 订单事实流</li>\n<li>MySQL 中维护一张 <code>dim_user</code> 用户维表，包含用户等级、所属城市、注册渠道等信息</li>\n</ul>\n<p>我们想要在 Flink 中构建一张「<strong>订单明细宽表</strong>」，字段大致包括：</p>\n<ul>\n<li>订单信息：订单号、下单用户、下单金额、下单时间</li>\n<li>用户属性：用户昵称、等级、城市、注册渠道</li>\n</ul>\n<p>并且要求：</p>\n<ul>\n<li>当我们回看 10 分钟前的某条订单时，看到的是 <strong>当时</strong> 用户的等级和城市，而不是被后续变更“冲掉”的最新值</li>\n</ul>\n<p>这正是 <strong>时态 Join</strong> 和「实时数仓」的关键：<strong>按事件发生时刻回放维度视图</strong>。</p>\n<h2 id=\"二环境前提与依赖准备\">二、环境前提与依赖准备</h2>\n<h3 id=\"1-基础组件\">1. 基础组件</h3>\n<p>本篇默认你已经完成前几篇中的环境准备：</p>\n<ul>\n<li>Flink 1.20.1（WSL2 Ubuntu 下部署）</li>\n<li>Kafka 集群已启动，且能正常写入 / 读取 Topic</li>\n<li>Flink SQL Client 可以正常连接集群</li>\n</ul>\n<p>在此基础上，我们还需要：</p>\n<ul>\n<li>一套可访问的 MySQL（本地或远程均可）</li>\n<li>Flink 的 JDBC Connector JAR 包</li>\n</ul>\n<h3 id=\"2-安装-flink-jdbc-connector\">2. 安装 Flink JDBC Connector</h3>\n<p>和 Kafka 一样，JDBC 连接器也需要以 JAR 包形式放到 Flink 的 <code>lib</code> 目录中。</p>\n<p>以 Flink 1.20.x 对应的 <code>flink-connector-jdbc</code> 为例：</p>\n<ol>\n<li>\n<p>确认 Flink 安装目录（假设为 <code>/opt/flink</code>）：</p>\n<pre><code class=\"language-bash\">export FLINK_HOME=/opt/flink\n</code></pre>\n</li>\n<li>\n<p>下载 JDBC Connector JAR 到 Flink 的 <code>lib</code> 目录：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME/lib\nwget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc/3.3.0-1.20/flink-connector-jdbc-3.3.0-1.20.jar\n</code></pre>\n</li>\n<li>\n<p>如果你使用的是独立集群或远程集群，需要重启 Flink 集群，让新 JAR 在 JobManager/TaskManager 上生效：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME\nbin/stop-cluster.sh\nbin/start-cluster.sh\n</code></pre>\n</li>\n<li>\n<p>重启 Flink SQL Client，使用新 Connector：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME\nbin/sql-client.sh\n</code></pre>\n</li>\n</ol>\n<p>如果你在 Windows + WSL2 上部署，只需在 WSL2 内执行上述命令即可；或者手动下载 JAR 后拷贝到 <code>lib</code> 目录，步骤完全一致。</p>\n<h2 id=\"三准备-mysql-用户维度表-dim_user\">三、准备 MySQL 用户维度表 dim_user</h2>\n<p>首先在 MySQL 中准备一张简单的用户维度表，用来存用户的基础属性。</p>\n<p>在 MySQL 中执行：</p>\n<pre><code class=\"language-sql\">CREATE DATABASE IF NOT EXISTS realtime_dwh;\nUSE realtime_dwh;\n\nCREATE TABLE dim_user (\n  user_id      VARCHAR(32)  PRIMARY KEY,\n  user_name    VARCHAR(64),\n  user_level   VARCHAR(16),\n  city         VARCHAR(64),\n  register_time DATETIME\n);\n\nINSERT INTO dim_user (user_id, user_name, user_level, city, register_time) VALUES\n('u_1', '张三', 'VIP1', '北京', '2025-12-01 10:00:00'),\n('u_2', '李四', 'VIP2', '上海', '2025-12-05 11:00:00'),\n('u_3', '王五', 'VIP1', '广州', '2025-12-10 12:00:00');\n</code></pre>\n<p>为了演示「时态」效果，你可以在后续实验中手动更新某个用户的等级或城市，例如：</p>\n<pre><code class=\"language-sql\">UPDATE dim_user\nSET user_level = 'VIP3'\nWHERE user_id = 'u_2';\n</code></pre>\n<p>这样我们在 Flink 里做时态 Join 时，就能观察“变更前后”的区别。</p>\n<h2 id=\"四在-flink-中注册事实流与维表\">四、在 Flink 中注册事实流与维表</h2>\n<p>接下来回到 Flink SQL Client，把 Kafka 中的订单事实流和 MySQL 中的维表都注册成 Flink 表。</p>\n<h3 id=\"1-kafka-订单事实表-orders\">1. Kafka 订单事实表 orders</h3>\n<p>和上一篇双流 JOIN 类似，我们假设 Kafka 中有一个 <code>orders</code> Topic，写入订单事实数据。</p>\n<p>在 Flink SQL Client 中执行：</p>\n<pre><code class=\"language-sql\">CREATE TABLE orders (\n  order_id     STRING,\n  user_id      STRING,\n  order_amount DECIMAL(10, 2),\n  order_time   TIMESTAMP_LTZ(3),\n  WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND,\n  proc_time AS PROCTIME()\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'orders',\n  'properties.bootstrap.servers' = '127.0.0.1:9092',\n  'properties.group.id' = 'flink-orders-dim',\n  'scan.startup.mode' = 'earliest-offset',\n  'format' = 'json',\n  'json.timestamp-format.standard' = 'ISO-8601'\n);\n</code></pre>\n<p>你可以沿用上一篇中 Kafka 造数的方式，用 <code>kafka-console-producer.sh</code> 发送 JSON 订单数据，只需要保证字段名一致。</p>\n<h3 id=\"2-mysql-用户维表-dim_userjdbc-lookup-表\">2. MySQL 用户维表 dim_user（JDBC Lookup 表）</h3>\n<p>然后把刚才在 MySQL 中建好的 <code>dim_user</code> 注册为 Flink 的 JDBC 表：</p>\n<pre><code class=\"language-sql\">CREATE TABLE dim_user (\n  user_id       STRING,\n  user_name     STRING,\n  user_level    STRING,\n  city          STRING,\n  register_time TIMESTAMP(3),\n  PRIMARY KEY (user_id) NOT ENFORCED\n) WITH (\n  'connector' = 'jdbc',\n  'url' = 'jdbc:mysql://127.0.0.1:3306/realtime_dwh',\n  'table-name' = 'dim_user',\n  'driver' = 'com.mysql.cj.jdbc.Driver',\n  'username' = 'root',\n  'password' = '1qaz@WSX'\n);\n</code></pre>\n<p>注意几点：</p>\n<ul>\n<li><code>PRIMARY KEY (user_id) NOT ENFORCED</code> 告诉 Flink 这是一张以 <code>user_id</code> 为主键的表，是做时态 Join 的前提</li>\n<li>这里使用的是典型的 JDBC Lookup 模式，Flink 会在 Join 时按需去 MySQL 查维度信息</li>\n</ul>\n<p>在生产环境中，你可以把 MySQL 作为维度存储，或者通过 CDC 把维表变更同步到 Kafka，构造成 changelog 流，这些都可以和 Temporal Join 结合使用。</p>\n<h2 id=\"五维表时态-join把订单打上用户维度\">五、维表时态 Join：把订单打上用户维度</h2>\n<p>有了订单事实表 <code>orders</code> 和维度表 <code>dim_user</code>，就可以通过时态 Join 来构建订单明细宽表。</p>\n<h3 id=\"1-基础时态-join-语法\">1. 基础时态 Join 语法</h3>\n<p>Flink SQL 中的 Temporal Table Join 对于 JDBC 这类 <strong>外部维表</strong>，通常采用「处理时间（Processing Time）」语义来做 Lookup Join，典型写法如下：</p>\n<pre><code class=\"language-sql\">SELECT\n  o.order_id,\n  o.user_id,\n  d.user_name,\n  d.user_level,\n  d.city,\n  o.order_amount,\n  o.order_time\nFROM orders AS o\nLEFT JOIN dim_user FOR SYSTEM_TIME AS OF o.proc_time AS d\nON o.user_id = d.user_id;\n</code></pre>\n<p><img alt=\"FlinkJoin\" class=\"lazyload\" /><br />\n这里有几个关键点：</p>\n<ul>\n<li><code>proc_time AS PROCTIME()</code> 是在 <code>orders</code> 上定义的处理时间字段</li>\n<li><code>FOR SYSTEM_TIME AS OF o.proc_time</code> 表示“以 Flink 处理这条订单记录的当前时间，去查维表的一个快照”，这是 JDBC Lookup 支持的典型用法</li>\n<li>Join 条件依然是 <code>user_id</code> 等值关联</li>\n<li>使用 <code>LEFT JOIN</code> 可以保留找不到维度的订单，并用空值来表示“维度缺失”</li>\n</ul>\n<p>在 SQL Client 中执行这段查询，会看到实时流式刷新的结果，每一行订单都带上了对应的用户属性。</p>\n<h3 id=\"2-验证时态效果修改维表再观察-join\">2. 验证时态效果：修改维表再观察 Join</h3>\n<p>为了验证这是“时态 Join”而不是“始终查最新维度”，可以按下面步骤操作：</p>\n<ol>\n<li>\n<p>先往 Kafka 的 <code>orders</code> Topic 写入几条订单数据，例如用户 <code>u_2</code> 下单的记录</p>\n</li>\n<li>\n<p>观察 Flink SQL 中 Join 后的结果，此时 <code>u_2</code> 的等级是 <code>VIP2</code></p>\n</li>\n<li>\n<p>回到 MySQL，执行：</p>\n<pre><code class=\"language-sql\">UPDATE dim_user\nSET user_level = 'VIP3'\nWHERE user_id = 'u_2';\n</code></pre>\n</li>\n<li>\n<p>再写入一批新的订单，仍然是用户 <code>u_2</code></p>\n</li>\n</ol>\n<pre><code class=\"language-bash\">bin/kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic orders\n</code></pre>\n<p>在命令行中输入一条 JSON 数据（按回车发送一条）：</p>\n<pre><code class=\"language-json\">{\"order_id\":\"o_3\",\"user_id\":\"u_2\",\"order_amount\":200.00,\"order_time\":\"2026-02-19T14:42:00Z\"}\n</code></pre>\n<p><img alt=\"FlinkJoin\" class=\"lazyload\" /><br />\n这时你会看到：</p>\n<ul>\n<li>变更前的订单，维度字段仍然显示 <code>VIP2</code></li>\n<li>变更后的订单，维度字段变成了 <code>VIP3</code></li>\n</ul>\n<p>这就说明 Flink 的时态 Join 确实是“按订单发生时刻去回放维度视图”的，而不是简单查当前最新值。</p>\n<h2 id=\"六把结果写回-kafka-或-mysql形成实时数仓明细层\">六、把结果写回 Kafka 或 MySQL，形成实时数仓明细层</h2>\n<p>在真实项目中，我们不会只在 SQL Client 里 <code>SELECT</code> 一下就结束，而是要把 Join 后的订单明细宽表，写回到下游存储，形成实时数仓的一个层级。</p>\n<p>例如，可以把结果写回 Kafka，作为 DWD 层的订单宽表：</p>\n<pre><code class=\"language-sql\">CREATE TABLE dwd_order_user_wide (\n  order_id     STRING,\n  user_id      STRING,\n  user_name    STRING,\n  user_level   STRING,\n  city         STRING,\n  order_amount DECIMAL(10, 2),\n  order_time   TIMESTAMP_LTZ(3),\n  WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'dwd_order_user_wide',\n  'properties.bootstrap.servers' = '127.0.0.1:9092',\n  'properties.group.id' = 'flink-dwd-order-wide',\n  'scan.startup.mode' = 'earliest-offset',\n  'format' = 'json',\n  'json.timestamp-format.standard' = 'ISO-8601'\n);\n\nINSERT INTO dwd_order_user_wide\nSELECT\n  o.order_id,\n  o.user_id,\n  d.user_name,\n  d.user_level,\n  d.city,\n  o.order_amount,\n  o.order_time\nFROM orders AS o\nLEFT JOIN dim_user FOR SYSTEM_TIME AS OF o.proc_time AS d\nON o.user_id = d.user_id;\n</code></pre>\n<p>这样，下游的实时应用或 BI 查询就可以直接订阅 <code>dwd_order_user_wide</code> 这个 Topic，拿到已经打好用户标签的订单明细数据。</p>\n<p>你也可以把结果同步到 MySQL、ClickHouse 等分析型数据库中，构建实时明细表，为报表和可视化提供数据。</p>\n<h2 id=\"七小结与下一步建议\">七、小结与下一步建议</h2>\n<p>通过这篇文章，我们完成了这样一件事：</p>\n<ul>\n<li>在 Kafka 中维护订单事实流 <code>orders</code></li>\n<li>在 MySQL 中维护用户维度表 <code>dim_user</code></li>\n<li>使用 Flink SQL 的 JDBC Connector 把 MySQL 注册为维表</li>\n<li>利用 <code>FOR SYSTEM_TIME AS OF</code> 语法做维表时态 Join</li>\n<li>将 Join 结果写回 Kafka，形成实时数仓中的一张订单明细宽表</li>\n</ul>\n<p>这背后有几个非常重要的实时数仓设计理念：</p>\n<ul>\n<li>事实流是不断追加的事件序列，维表是相对缓慢变更的业务视图</li>\n<li>时态 Join 让你能够“按事件发生的时间点”，回看当时的维度快照</li>\n<li>实时数仓的 DWD 层，往往就是「事实表 + 多个维表时态 Join」后形成的明细宽表</li>\n</ul>\n<p>在后续的文章中，我们可以继续沿着这个方向深入：</p>\n<ul>\n<li>在一个任务里同时关联多张维表，构建更宽的明细表</li>\n<li>引入 CDC，把维表变更实时同步到 Kafka，再在 Flink 中构建 changelog 维表</li>\n<li>把实时数仓的明细层、汇总层（DWS）、指标主题层（ADS）串起来，做一个端到端的实时数仓小项目</li>\n</ul>\n<p>如果你已经跑通了本文的 Demo，不妨试着自己设计一张商品维表 <code>dim_product</code>，再给订单打上商品品类维度，体验一下“事实 + 多维表时态 Join”在 Flink SQL 里的完整味道。</p>\n<hr />\n<p><a href=\"http://blog.daimajiangxin.com.cn\" rel=\"noopener nofollow\" target=\"_blank\">原文来自:http://blog.daimajiangxin.com.cn</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 12:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/daimajiangxin\">代码匠心</a>&nbsp;\n阅读(<span id=\"post_view_count\">59</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "赋予 AI Agent “无限续航”：语义保护型上下文压缩技术解析",
      "link": "https://www.cnblogs.com/noear/p/19624614",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19624614\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 12:21\">\n    <span>赋予 AI Agent “无限续航”：语义保护型上下文压缩技术解析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Solon AI框架的SummarizationInterceptor创新性地解决了AI长对话中的\"上下文窗口爆炸\"问题。这套智能记忆管理系统通过四步策略：锁定核心任务指令、确保行动-结果完整性、保持语义连贯性、添加系统提示，实现了优雅的记忆压缩。其采用插件式设计，支持层级压缩、关键信息提取和向量库归档等策略组合，让AI既能记住核心目标，又能处理超长任务。这种\"有逻辑地遗忘\"机制，有效避免了传统粗暴裁剪导致的逻辑混乱，为AI处理复杂任务提供了\"无限续航\"\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>想象一下，你正在指挥一个超级聪明的AI助手（我们称之为Agent）帮你完成一项复杂任务，比如策划一次跨国旅行。一开始，它记得你的所有要求：想去哪些国家、预算多少、喜欢什么类型的酒店。但随着任务的进行，它需要查询航班、比较酒店、查看天气……每一次查询和思考都会增加它的“记忆负担”。</p>\n<p>如果它“记性”不好，聊到一半就会忘了最开始的要求，或者陷入混乱的逻辑中，这就是开发者常说的“上下文窗口爆炸”问题。</p>\n<p>Solon AI 框架里有一个秘密武器——<code>SummarizationInterceptor</code>（智能记忆压缩器），它能让AI助手像人一样，<strong>既不会忘记初心，又能轻装上阵，实现真正的“无限续航”</strong>。它不是简单粗暴地“断片”，而是一套优雅的“记忆管理大师”。</p>\n<h3 id=\"1为什么不能简单粗暴地断片\">1、为什么不能简单粗暴地“断片”？</h3>\n<p>处理长对话，最直接的想法是：对话太长？那就删掉前面一半吧！但这种“暴力裁剪”对AI来说，会带来两个致命伤：</p>\n<ul>\n<li><strong>忘本（失去初心）：</strong> AI Agent 最开头的系统设定和你交给它的第一个任务，如果被删掉，它就会像无头苍蝇一样，完全不知道自己要干嘛了。</li>\n<li><strong>断片（逻辑断层）：</strong> AI Agent 的工作模式通常是“思考 -&gt; 行动 -&gt; 观察结果”（ReAct）。如果你恰好把它的某个“行动”和对应的“观察结果”给拆散了，它看到结果却不知道为什么会有这个结果，逻辑瞬间混乱，甚至陷入死循环，无法自拔。</li>\n</ul>\n<p>所以，忘记也是一门艺术，需要有策略地忘记。</p>\n<h3 id=\"2智能记忆压缩器是如何工作的\">2、智能记忆压缩器是如何工作的？</h3>\n<p><code>SummarizationInterceptor</code> 就像一个聪明的图书管理员，它不会随意丢弃书籍，而是按照一套精密的流程来整理书架。它的工作分为四步：</p>\n<h4 id=\"第一步锁死初心锚点锁定\">第一步：锁死“初心”（锚点锁定）</h4>\n<p>无论后面的对话有多长，管理员都会第一时间找到两样东西并永久保留：</p>\n<ul>\n<li><strong>任务指令：</strong> 你第一次给AI布置的任务（UserMessage），这是它的“初心”。</li>\n<li><strong>基本守则：</strong> AI的系统设定（SystemMessage），这是它的“行为准则”。</li>\n</ul>\n<p>这两样东西被牢牢锁定，确保AI永不迷失方向。</p>\n<h4 id=\"第二步禁止断片原子对齐\">第二步：禁止“断片”（原子对齐）</h4>\n<p>这是整个机制最核心的“黑科技”。当管理员决定要清理一部分旧内容时，他不会直接动手。他会仔细检查，确保永远不会把 <strong>“行动”</strong> 和 <strong>“结果”</strong> 这对“连体婴儿”给拆散。</p>\n<ul>\n<li><strong>智能检查：</strong> 如果发现准备清理的起点正好落在一个“观察结果”（<code>ToolMessage</code>）或者一个“行动指令”（<code>AssistantMessage</code>）上，管理员会立刻把清理起点向后挪，直到确保每一对“行动-结果”都完整地保留下来。</li>\n</ul>\n<h4 id=\"第三步让记忆更连贯语义补齐\">第三步：让记忆更连贯（语义补齐）</h4>\n<p>为了让你和AI的对话读起来更通顺，管理员还会再多做一步“人情味”的检查。如果清理后的第一条记录是一个“行动结果”，管理员会看看它前面是不是紧跟着一条AI的“思考过程”（Thought）。如果是，他会把这条“思考”也一并留下。这样一来，AI看到的历史永远是从一个思考片段开始的，理解起来更自然。</p>\n<h4 id=\"第四步贴个便利贴提醒断裂感知\">第四步：贴个“便利贴”提醒（断裂感知）</h4>\n<p>在永久保存的“初心”和压缩后的“最近记忆”之间，管理员会贴上一张醒目的 <strong>“小贴士”</strong>：</p>\n<pre><code>--- [系统提示：中间部分历史对话已优化压缩，请根据当前计划和剩余历史继续任务...] ---\n</code></pre>\n<p>这张“小贴士”非常重要，它用AI能理解的语言告诉它：“别担心，中间有些细节我帮你精简了，你专注眼前的任务和核心目标就好。”这能有效防止AI因为记忆断层而产生困惑和幻觉。</p>\n<h3 id=\"3如何实现无限续航\">3、如何实现“无限续航”？</h3>\n<p>通过这套“记忆管理术”，SummarizationInterceptor 把AI的内存变成了一个动态的“新陈代谢系统”：</p>\n<ul>\n<li><strong>内存恒定：</strong> 无论AI运行了10步还是1000步，它一次“思考”所需要处理的信息量（Token数）始终维持在一个安全的范围内。</li>\n<li><strong>逻辑清晰：</strong> 因为“原子对齐”机制，AI看到的每一段记忆都是完整的“思考-行动-反馈”闭环，逻辑链条非常稳固。</li>\n<li><strong>目标永存：</strong> “系统设定”和“用户任务”这两大核心目标永远在线，AI永远不会忘记“我是谁”和“我要去哪”。</li>\n</ul>\n<h3 id=\"4更强大的组合插件式的记忆策略\">4、更强大的组合：插件式的记忆策略</h3>\n<p>这个“记忆管理器”最妙的地方在于，它采用了 <strong>策略模式</strong>，就像手机可以安装不同的APP来扩展功能一样，你可以给它接入不同的“记忆处理插件”。框架已经为我们准备了几款强大的插件：</p>\n<ul>\n<li><strong>层级压缩器：</strong> 它会像滚雪球一样，把旧的记忆摘要和新的对话历史不断融合、压缩，生成一个始终更新的“全局进度摘要”，让记忆像洋葱一样层层包裹，永不丢失核心。</li>\n<li><strong>关键信息提取器：</strong> 它像一个信息审计员，只从对话中提取最核心的“干货”，比如用户要求、获取到的数据、已经失败的尝试等，过滤掉那些啰嗦的思考过程。</li>\n<li><strong>向量库记忆师：</strong> 它会将被清理的详细对话“归档”到一个巨大的知识库里（向量数据库）。当AI需要回忆某个细节时，可以通过一个专门的“召回历史”工具，像用搜索引擎一样把它找回来。</li>\n</ul>\n<p>你可以把这些插件组合起来使用，比如先归档，再提纯，最后压缩，打造一个最适合你AI助手的记忆管理方案。</p>\n<p>应用示例：</p>\n<pre><code class=\"language-java\">import org.noear.solon.ai.agent.react.ReActAgent;\nimport org.noear.solon.ai.agent.react.intercept.SummarizationInterceptor;\nimport org.noear.solon.ai.agent.react.intercept.summarize.*;\nimport org.noear.solon.ai.agent.session.InMemoryAgentSession;\nimport org.noear.solon.ai.chat.ChatModel;\n\nCompositeSummarizationStrategy compositeStrategy = new CompositeSummarizationStrategy();\ncompositeStrategy.addStrategy(new KeyInfoExtractionStrategy(chatModel));\ncompositeStrategy.addStrategy(new HierarchicalSummarizationStrategy(chatModel));\nSummarizationInterceptor summarizationInterceptor = new SummarizationInterceptor(12, compositeStrategy);\n\nReActAgent agent = ReActAgent.of(chatModel)\n        .defaultInterceptorAdd(summarizationInterceptor)\n        .build();\n</code></pre>\n<h3 id=\"5总结\">5、总结</h3>\n<p><code>SummarizationInterceptor</code> 的设计哲学是：<strong>有尊严地裁剪，有逻辑地遗忘</strong>。</p>\n<p>它不仅仅是一个节省计算资源的工具，更是AI能够保持逻辑连贯、处理超长复杂任务的“护航者”。有了它，开发者可以放心地让AI助手去处理那些需要几个小时甚至几天才能完成的、真正复杂和智能化的工作，而不用担心它会中途“失忆”或“精神错乱”。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 12:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">54</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]持久化状态的提取",
      "link": "https://www.cnblogs.com/jaydenai/p/19623976/read-state",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19623976/read-state\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 07:58\">\n    <span>[拆解LangChain执行引擎]持久化状态的提取</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        前面以`写入`的角度介绍了BaseCheckpointSaver的`put/aput`和`put_writes/aput_writes`方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面以<code>写入</code>的角度介绍了BaseCheckpointSaver的<code>put/aput</code>和<code>put_writes/aput_writes</code>方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。</p>\n<h2 id=\"1-读取checkpoint和pinding-write\">1. 读取Checkpoint和Pinding Write</h2>\n<p>如下这个<code>CheckpointTuple</code>用来表示Checkpoint和Pending Write的结合体。除了这两个核心成员，它还包括当前的执行配置（config和parent_config）和元数据。具体的Pending Write由Task ID、Channel名称和写入数组组成的三元组PendingWrite表示。</p>\n<pre><code class=\"language-python\">class CheckpointTuple(NamedTuple):\n    config: RunnableConfig\n    checkpoint: Checkpoint\n    metadata: CheckpointMetadata\n    parent_config: RunnableConfig | None = None\n    pending_writes: list[PendingWrite] | None = None\nPendingWrite = tuple[str, str, Any]\n</code></pre>\n<p>BaseCheckpointSaver提供了用于读取CheckpointTuple的<code>get_tuple/aget_tuple</code>方法。作为参数的RunnableConfig对象需要提供Thread ID（必需）和Checkpoint 命名空间（可选）。如果没有提供Checkpoint ID，方法会返回最终的状态，如果尚未完成，得到的CheckpointTuple元组可能包含Pending Write。如果提供了Checkpoint ID, 只有在此ID对应最新的Checkpoint且后一Superstep尚未完成，返回的CheckpointTuple元组才有可能包含Pending Write。对于实现在BaseCheckpointSaver中的另一组方法<code>get/aget</code>，会在内部调用<code>get_tuple/aget_tuple</code>方法，并返回CheckpointTuple元组封装的Checkpoint对象。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):    \n    def get(self, config: RunnableConfig) -&gt; Checkpoint | None\n    async def aget(self, config: RunnableConfig) -&gt; Checkpoint | None\n\n    def get_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n    async def aget_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n\n    def list(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[CheckpointTuple]:\n    async def alist(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[CheckpointTuple]\n</code></pre>\n<p>对于InMemorySaver来说，它的get_tuple/aget_tuple方法会从RunnableConfig配置中提取Thread ID和Checkpoint命名空间，如果指定了Checkpoint ID，它们会利用这三个值从storage和blobs字典中提取相应数据组成返回的CheckpointTuple对象。如果没有指定Checkpoint ID，就选择最近的那一个Checkpoint的ID。</p>\n<p>BaseCheckpointSaver的alist方法会列出并检索与指定条件匹配的所有CheckpointTuple，这些元组构成了一段 “历史” 。该方法主要用于会话管理、审计历史轨迹以及状态回溯，它具有如下的参数：</p>\n<ul>\n<li>config：如果RunnableConfig如果提供了Thread ID，该方法将仅返回该特定线程下的Checkpoint。如果不提供，在某些实现中会列出所有线程的最新Checkpoint（取决于具体的实现逻辑）。</li>\n<li>filter：提供基于元数据的过滤功能，例如 {\"status\": \"completed”} ，这在需要筛选特定业务状态的Checkpoint时非常有用。</li>\n<li>before：以RunnableConfig对象的形式提供Checkpoint ID，返回在此 之前创建的记录。这对于实现 “时间旅行” 功能至关重要，允许你查看图执行历史中的旧版本。</li>\n<li>limit：用于限制返回数据的数量。</li>\n</ul>\n<p>我们通过如下的实例演示来进一步了解持久化。我们构建了一个由foo、bar1和bar2这三个Node组成的Pregel，启动的时候利用输入针对通道foo的写入驱动执行节点foo，后者完成后写入通道bar驱动节点bar1和bar2并行执行。三个Node的处理函数都是handle，它会将传入的Node名称写入一个BinaryOperatorAggregate类型Channel（nodes），由此确定成功执行的Node。如果调用handle函数将interrupt参数指定为True，它会通过抛出一个GraphInterrupt异常模拟一个中断。在我们的演示实例中，节点foo和bar2会执行成功，中断会发生在节点bar1上。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue, BinaryOperatorAggregate\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.errors import GraphInterrupt\nimport operator, json\n\ndef handle(node_name: str, interrupt: bool = False) -&gt; list[str]:\n    if interrupt:\n        raise GraphInterrupt(\"manual interrupt\")\n    return [node_name]\n\nfoo = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: handle(\"foo\"))\n    .write_to(nodes=lambda x: x, bar=lambda _: \"triggered by foo\")\n)\n\nbar1 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar1\", interrupt=True))\n    .write_to(\"nodes\")\n)\n\nbar2 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar2\", interrupt=False))\n    .write_to(\"nodes\")\n)\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar1\": bar1, \"bar2\": bar2},\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n        \"nodes\": BinaryOperatorAggregate(list, operator.add),\n    },\n    checkpointer=InMemorySaver(),\n    input_channels=[\"foo\"],\n    output_channels=[\"nodes\"],\n)\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke({\"foo\": \"triggered by user\"}, config=config)\nassert result[\"nodes\"] == [\"foo\", \"bar2\"]\n\n(config, checkpoint, metadata, parent_config, pending_writes) = (\n    app.checkpointer.get_tuple(config)\n)\nprint(f\"config:\\n{json.dumps(config, indent=4)}\")\nprint(f\"checkpoint:\\n{json.dumps(checkpoint, indent=4)}\")\nprint(f\"metadata:\\n{json.dumps(metadata, indent=4)}\")\nprint(f\"parent_config:\\n{json.dumps(parent_config, indent=4)}\")\nprint(f\"pending_writes:\\n{json.dumps(pending_writes, indent=4)}\")\n</code></pre>\n<p>我们为创建的Pregel对象提供了一个InMemorySaver作为它的Checkpointer，并在调用时利用提供的RunnableConfig设置了Thread ID。由于我们将通道nodes作为输出，所以调用结果会反映三个Node的执行状态（只有节点foo和bar2成功执行）。我们随后传入相同的配置调用Checkpointer的get_tuple方法，并将得到的CheckpointTuple元组进行拆包输出。</p>\n<pre><code class=\"language-json\">config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\"\n    }\n}\ncheckpoint:\n{\n    \"v\": 4,\n    \"ts\": \"2026-01-19T10:17:07.498064+00:00\",\n    \"id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\",\n    \"channel_versions\": {\n        \"foo\": \"00000000000000000000000000000001.0.06769883673554666\",\n        \"nodes\": \"00000000000000000000000000000002.0.3174924500871408\",\n        \"bar\": \"00000000000000000000000000000002.0.3174924500871408\"\n    },\n    \"versions_seen\": {\n        \"__input__\": {},\n        \"foo\": {\n            \"foo\": \"00000000000000000000000000000001.0.06769883673554666\"\n        }\n    },\n    \"updated_channels\": [\n        \"bar\",\n        \"nodes\"\n    ],\n    \"channel_values\": {\n        \"foo\": \"triggered by user\",\n        \"nodes\": [\n            \"foo\"\n        ],\n        \"bar\": \"triggered by foo\"\n    }\n}\nmetadata:\n{\n    \"source\": \"loop\",\n    \"step\": 0,\n    \"parents\": {}\n}\nparent_config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24ee-671f-bfff-2e9f3ca91778\"\n    }\n}\npending_writes:\n[\n    [\n        \"30b17cb1-76f1-3c5a-0d32-33f544fcabdf\",\n        \"nodes\",\n        [\n            \"bar2\"\n        ]\n    ],\n    [\n        \"e126d089-c354-0ac8-bb9e-b12bbe3f20b8\",\n        \"__interrupt__\",\n        \"manual interrupt\"\n    ]\n]\n</code></pre>\n<p>整个执行过程涉及三个Superstep，会创建两个Checkpoint。第一个Checkpoint的创建发生在调用invoke方法的时候，此时提供的输入被写入Channel，首批待执行的Node（foo）准备就绪，此时创建的Checkpoint 记录了 <code>接收到了初始任务，但尚未开始执行任何Node</code> 的状态。此时对应的Superstep序号为-1，输出结果的parent_config部分提供了此Checkpoint的ID。</p>\n<p>第二个Checkpoint是为序号为0的Superstep创建的，此时节点foo成功执行，执行结果最终被输入目标Channel，创建的Checkpoint反映的就是的状态，config部分提供了此Checkpoint的ID。上面的输出还提供了这个Checkpoint的时间戳、Channel的版本和值、涉及Node的可见Channel（f和版本，以及涉及更新的Channel列表。</p>\n<p>由于最后一个Superstep（序号为1）没有完全结束，它们会利用对应的Pending Write来描述。上面输出的第一个Pending Write表示成功执行的节点bar针对通道nodes的写入，第二个针对特殊系统Channel <code>__interrupt__</code>的写入很明显就是因为节点bar1的中断导致。</p>\n<h2 id=\"2-读取状态快照\">2. 读取状态快照</h2>\n<p>BaseCheckpointSaver提供了get_tuple/aget_tuple方法以Checkpoint_Tuple的形式返回最新或者基于过去时间点的状态。对于CheckpointTuple这个五元组，除了Checkpoint和PendingWrite列表，还包括Checkpoint的元数据和相关配置。这个元组主要由执行引擎内部使用的，针对最终开发者来说可读性差点，所以Pregel类定义了如下所示的<code>get_state/aget_state</code>方法，它们提供的StateSnapshot类型更具可读性。</p>\n<pre><code class=\"language-python\">class Pregel(\n    PregelProtocol[StateT, ContextT, InputT, OutputT],\n    Generic[StateT, ContextT, InputT, OutputT]): \n\n    def get_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n    async def aget_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n\n    def get_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[StateSnapshot]\n    async def aget_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[StateSnapshot]\n</code></pre>\n<p>当我们调用Pregel对象的<code>get_state/aget_state</code>方法的时候，它会将指定的RunnableConfig对象作为参数调用Checkpointer的<code>get_tuple/aget_tuple</code>方法，并利用返回的Checkpoint_Tuple元组生成StateSnapshot对象。StateSnapshot的<code>values</code>字段提供的值来源于Checkpoint对象的channel_values字段，它的<code>metadata</code>字段表示的CheckpointMetadata 直接来源于Checkpoint_Tuple的同名字段，而<code>config</code>和<code>parent_config</code>返回的RunnableConfig则是由Checkpoint_Tuple同名字段于元数据合并而成。表示快照创建时间的<code>created_at</code>对应于Checkpoint_Tuple表示时间戳的ts字段，而interrupts返回的Interrupt列表是根据中断类型的PendingWrite构建的。</p>\n<pre><code class=\"language-python\">class StateSnapshot(NamedTuple):\n    values: dict[str, Any] | Any\n    next: tuple[str, ...]\n    config: RunnableConfig\n    metadata: CheckpointMetadata | None\n    created_at: str | None\n    parent_config: RunnableConfig | None\n    tasks: tuple[PregelTask, ...]\n    interrupts: tuple[Interrupt, ...]\n\nclass PregelTask(NamedTuple):\n    id: str\n    name: str\n    path: tuple[str | int | tuple, ...]\n    error: Exception | None = None\n    interrupts: tuple[Interrupt, ...] = ()\n    state: None | RunnableConfig | StateSnapshot = None\n    result: Any | None = None\n</code></pre>\n<p>StateSnapshot的<code>tasks</code>字段返回一组PregelTask对象，它们表示根据Checkpoint创建的待执行任务，<code>next</code>字段以元组的形式返回这些任务的Node名称。对于最新的Checkpoint，若下一个Superstep尚未完成，PregelTask的信息还会利用对应的Pending Write进一步完善。我们可以利用PregelTask对象得到每个任务的ID、Node名称、执行路径、抛出的异常和中断（根据异常和中断类型的PendingWrite创建），而<code>state</code>和<code>result</code>分别承载这任务的状态和输出结果。如果整个执行流程结束，自然就没有所谓后续任务的说法，此时StateSnapshot的tasks字段为空。</p>\n<p>除了返回一个具体的状态快照，Pregel类还定义了<code>get_state_history/aget_state_history</code>，它们的参数列表与BaseCheckpointSaver的<code>list/alist</code>方法完全一致。当这两个方法被调用的时候，Pregel会调用Checkpointer的<code>list/alist</code>方法，并将得到Checkpoint_Tuple元组转换成StateSnapshot对象。<code>get_state_history/aget_state_history</code>方法返回的迭代器以时间逆序的方式返回对应的状态快照。</p>\n<p>如下这个程序演示了一个具体的Pregel对象的历史由哪些快照组成，每个快照又反映当时的状态。我们构建的Pregel对象由四个Node组成，调用时指定通道foo会驱动执行节点foo，它执行结束后写入通道bar驱动bar1、bar2和bar3并行执行。除了bar1能够顺利执行外，我们为bar2设置了一个中断，让bar3抛出异常。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.checkpoint.memory import  InMemorySaver\nfrom langgraph.types import interrupt\n    \ndef handle(node_name: str, halt : bool, raise_error: bool) -&gt; None:\n    if halt:\n        _ = interrupt(f\"Manually be interrupted at {node_name}\")\n    if raise_error:\n        raise Exception(f\"Manually raised error at {node_name}\")\n\nfoo = (NodeBuilder()\n       .subscribe_to(\"foo\", read=False)\n       .do(lambda _: handle(\"foo\", halt=False, raise_error=False))\n       .write_to(bar = lambda _:None))\nbar1 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar1\", halt=False, raise_error=False)))\nbar2 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar2\", halt=True, raise_error=False)))\nbar3 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar3\", halt=False, raise_error=True)))\napp = Pregel(\n    nodes={\n        \"foo\": foo,\n        \"bar1\": bar1,\n        \"bar2\": bar2,\n        \"bar3\": bar3\n    },\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer= InMemorySaver())\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\n\ntry:\n    app.invoke(input={\"foo\": \"begin\"},config=config)\nexcept Exception as e:\n    pass\n\nfor snapshot in app.get_state_history(config):\n    print(f\"\"\"\nvalues: {snapshot.values}\nnext: {snapshot.next}\ninterrupts: {snapshot.interrupts}   \ntasks:\"\"\")\n    for task in snapshot.tasks:\n        print(f\"\"\"  id: {task.id}\n    name: {task.name}\n    path: {task.path}\n    error: {task.error} \n    interrupts: {task.interrupts}\n    state: {task.state}\n    result: {task.result}\"\"\")\n</code></pre>\n<p>在完成了针对Pregel对象的调用后，我们采用相同的配置调用它的<code>get_state_history</code>方法得到完整的历史，并将承载历史片段的StateSnapshot信息打印出来。整个过程涉及三个Superstep，前两个成功完成的Superstep会提供两个Checkpoint，第三个尚未完成的Superstep只提供针对三个Node任务的Pending Write。</p>\n<pre><code class=\"language-json\">values: {'start': 'begin', 'bar': None}\nnext: ('bar1', 'bar2', 'bar3')\ninterrupts: (Interrupt(value='Manually be interrupted at bar2', \n    id='26f309d618c42ff31d2b3404369232e4'),)\ntasks:\n  id: dbb24ec5-f1ba-f845-7351-54e88f34db0f\n    name: bar1\n    path: ('__pregel_pull', 'bar1')\n    error: None\n    interrupts: ()\n    state: None\n    result: {}\n  id: 794fffda-2e6c-0685-0d44-3ed6c57ca366\n    name: bar2\n    path: ('__pregel_pull', 'bar2')\n    error: None\n    interrupts: (Interrupt(value='Manually be interrupted at bar2', \n        id='26f309d618c42ff31d2b3404369232e4'),)\n    state: None\n    result: None\n  id: 1055ec55-49dc-0629-86b5-661a2614f349\n    name: bar3\n    path: ('__pregel_pull', 'bar3')\n    error: Exception('Manually raised error at bar3')\n    interrupts: ()\n    state: None\n    result: None\n\nvalues: {'start': 'begin'}\nnext: ('foo',)\ninterrupts: ()\ntasks:\n  id: 88904475-3edc-733a-d84d-98aa6d3f5e80\n    name: foo\n    path: ('__pregel_pull', 'foo')\n    error: None\n    interrupts: ()\n    state: None\n    result: {'bar': None}\n</code></pre>\n<h2 id=\"3任务路径\">3.任务路径</h2>\n<p>还记得我们前面说个任务的两种创建方式，一种是站在Node的角度，通过查看订阅Channel的更新状态确定是否应该执行，我们称这种任务创建模式为<code>Pull模式</code>。与之相对的则是<code>Push模式</code>，Node利用写入<code>__pregel_tasks</code>这个特殊Channel的Send对象决定后续执行的Node，执行引擎会从此Channel读取Send对象的来创建对应的任务。任务路径的第一部分通常就反映了任务的驱动模式，对应的值为<code>__pregel_pull</code>和<code>__pregel_push</code>。</p>\n<p>由于前面演示的都是基于Channel订阅驱动的任务，所以路径采用(“__pregel_pull”,{node})的形式。如下的程序演示“Push任务”的路径，我们构建的Pregel由四个Node（foo、bar1、bar2和bar3）组成，节点foo的处理函数最终会生成三个针对其他Node的Send对象，并写入“__pregel_tasks”Channel以驱动它们并行执行。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.pregel._read import PregelNode\nfrom langgraph.pregel._write import ChannelWrite, ChannelWriteTupleEntry\nfrom langgraph.types import Send\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nentry = ChannelWriteTupleEntry(lambda args: [(\"__pregel_tasks\", args)])\nwriter = ChannelWrite(writes=[entry])\nfoo: PregelNode = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: [Send(node=node, arg=\"foo\") for node in [\"bar1\", \"bar2\", \"bar3\"]])\n).build()\nfoo.writers.append(writer)\n\nbars = {name: NodeBuilder() for name in [\"bar1\", \"bar2\", \"bar3\"]}\n\napp = Pregel(\n    nodes={\"foo\": foo, **bars},\n    channels={\n        \"foo\": LastValue(None),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer=InMemorySaver(),\n)\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke(input={\"foo\": None}, config=config, interrupt_before=\"bar2\")\nsnapshot = app.get_state(config)\nfor task in snapshot.tasks:\n    print(f\"{task.name}:{task.path}\")\n</code></pre>\n<p>为了能看到三个任务，我们在在最后一个Superstep中产生一个中断，为此我们在调用的时候通过指定<code>interrupt_before</code>参数在执行节点bar2前中断。我们随后调用Pregel的get_state方法得到描述最终状态的StateSnapshot，并输出所有任务的执行路径。从如下的输出可以看出，由于是三个基于Push模式的任务，所以组成路径的第一个部分内容为 <code>__pregel_push</code> 。每个任务由 <code>__pregel_tasks</code> Channel的Send对象构建而成，第二部分的数组代表对应的Send对象在Channel中的索引。由于整个程序只有唯一的Pregel对象，不设置子图调用，所以第三部分返回False。</p>\n<pre><code>bar1:('__pregel_push', 0, False)\nbar2:('__pregel_push', 1, False)\nbar3:('__pregel_push', 2, False)\n</code></pre>\n<h2 id=\"4状态嵌套\">4.状态嵌套</h2>\n<p>这里我们有必要提一下PregelTask类的<code>state</code>字段。从给出的定义可以看出，它可以返回一个RunnableConfig配置，也可以返回一个StateSnapshot对象。如果任务涉及子图的调用，并且在调用get_state/aget_state方法时将subgraphs参数设置为True，它的state字段就会返回一个描述子图当前状态的<code>StateSnapshot</code>对象。借助于反映执行链路和调用顺序的Checkpoint命名空间，就可以形成的嵌套层次结构（state =&gt;task=&gt;state）使我们可以可以看到一个任务完整的调用链条。</p>\n<p><img alt=\"Alternative Text\" class=\"lazyload\" /></p>\n<p>以如下这个验证程序为例。我们构建了两个具有单一Node的Pregel对象app和sub_graph，前者的节点main_node以子图调用的方式调用sub_graph，后者的Node命名为 “sub_node”。为了在StateSnapshot中将任务保留下来，我们在两个Node中引入了中断。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import interrupt\nfrom typing import Any\nfrom langgraph.types import StateSnapshot\n\nsub_node = (NodeBuilder()\n    .subscribe_to(\"start\")\n    .do(lambda _: interrupt(\"manual interrupt\"))\n)\nsub_graph = Pregel(\n    nodes={\"sub_node\": sub_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n)\n\ndef handle(args: dict[str, Any]) -&gt; None:\n    sub_graph.invoke(input={\"start\": \"begin\"})\n    interrupt(\"main graph interrupt\")\n\nmain_node = NodeBuilder().subscribe_to(\"start\").do(handle)\napp = Pregel(\n    nodes={\"main_node\": main_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n    checkpointer=InMemorySaver())\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\napp.invoke(input={\"start\": \"begin\"}, config=config)\nsnapshot = app.get_state(config, subgraphs=True)\n\nindent = -1\ndef print_snapshot(snapshot: StateSnapshot) -&gt; None:\n    global indent\n    indent += 1\n    config = snapshot.config[\"configurable\"]\n    print(f\"{'  ' * indent}checkpoint_ns: {config.get('checkpoint_ns', None)}\")\n    for task in snapshot.tasks:\n        print(f\"{'  ' * indent}task: {task.name}:{task.id}\")\n        if sub_snapshot := task.state:\n            print_snapshot(sub_snapshot)\n\nprint_snapshot(snapshot)\n</code></pre>\n<p>在完成调用后，我们调用作为主图的Pregel对象的<code>get_state</code>方法，并将参数subgraphs设置为True。我们调用print_snapshot函数输出StateSnapshot提供的Checkpoint命名空间和任务的名称与ID。如果描述任务的PregelTask对象的state字段也是一个StateSnapshot对象，那么继续递归调用此函数。从如下的输出可以看出，作为子图的Pregel将当前任务的名称和ID的组合作为Checkpoint命名空间，这样的结构确保了 “主图” 恢复的时候能够精准地加载 “子图” 的状态。</p>\n<pre><code>checkpoint_ns: \ntask: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    checkpoint_ns: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    task: sub_node:a483bfb8-bcc6-92b3-2f64-9f9e9f4fe158\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 07:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">51</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 学习笔记：Agent 的基础应用",
      "link": "https://www.cnblogs.com/owlman/p/19623216",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19623216\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 16:09\">\n    <span>AI 学习笔记：Agent 的基础应用</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记对应的是《[[关于 AI 的学习路线图]]》一文中所规划的第四个学习阶段。其中记录了我学习 AI Agent 的工作原理，并将其应用于实际工作场景的全过程，以及在该过程中所获得的心得体会。同样的，这些内容也将成为我 AI 系列笔记的一部分，被存储在本人 Github 上的<a href=\"https://github.com/owlman/CS_StudyNotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机学习笔记库</a>中，并予以长期维护。</p>\n</blockquote>\n<h2 id=\"ai-agent-简介\">AI Agent 简介</h2>\n<p>在理解了 LLM 在生产环境中所扮演的角色之后，初学者们接下来要思考的问题是：如何让它参与到自己的实际工作中？到目前为止（截至 2026 年 2 月），这个问题最具可行性的解决方案是：构建并使用 AI Agent。</p>\n<h3 id=\"为什么需要-ai-agent\">为什么需要 AI Agent</h3>\n<p>在早期，大多数用户是通过 Web 端或移动端的即时通信应用，主要以文本聊天的方式来使用 LLM 的（例如 ChatGPT、豆包等）。这类应用本质上是基于 HTTP API 构建的人机交互界面，其主要交互模式是“输入文本—生成文本”的往返过程。我们之前在《[[LLM 的部署与测试]]》一文中基于 PyTest 框架编写的测试用例，实际上模拟的就是这种交互模式。</p>\n<p>尽管，这类应用极大地降低了 LLM 的使用门槛，使其成为了一种能惠及普通用户的智能问答工具，但 AI 所能带来的生产力也在很大程度上被局限在了这种即时通信式的交互模式中。因为在这种交互模式下，LLM 只能根据用户当前的输入来生成文本结果，无法主动访问本地环境、调用系统资源或执行实际任务。更重要的是，LLM 在这种模式下并不处于一个持续运行的控制结构之中，它只在收到请求时做出一次性响应，无法负责具体的工作流程与状态管理。</p>\n<p>试想一下，如果 LLM 已经具备了复杂的任务规划与执行能力，我们却把它限制在聊天窗口中，这岂不是太浪费了？正是为了避免这种浪费，并赋予 LLM 在特定环境中“执行操作”的能力，AI 的研究者们重新审视了 AI Agent 这一在 20 世纪 80-90 年代就已经形成体系的概念，并在工程实践领域给了它全新的实现形式。</p>\n<p>关于 AI Agent 这个概念，读者可以参考我之前在《[[关于 AI 的学习路线图]]》中推荐的《人工智能：现代方法》一书给出的定义，原文如下：</p>\n<blockquote>\n<p>An agent is anything that can perceive its environment through sensors and act upon that environment through actuators.</p>\n<p>翻译过来就是：</p>\n<p>任何能够通过传感器感知环境，并通过执行器对环境产生影响的实体，都可以称为 Agent。</p>\n</blockquote>\n<p>这个定义成为了后来所有 AI Agent 应用的理论基础。由此也可以看出，AI Agent 的核心功能并不是提升 LLM 本身的智能水平，而是赋予它与外部系统交互的能力，使其能够参与到真实的工作流程之中。从本质上来说，这其实是 AI 应用在客户端方面的一次角色转变，它现在从单纯的答题工具被转变成了一个可以参与任务执行的系统组件。在特定的应用场景中，这种架构上的转变为工作流程的自动化提供了可行的工程路径。</p>\n<h3 id=\"ai-agent-的工作原理\">AI Agent 的工作原理</h3>\n<p>下面，让我们来了解一下 AI Agent 具体是怎么工作的。在传统聊天式的 AI 应用中，我们可以将其基本的执行模式简单概括为：</p>\n<blockquote>\n<p>用户输入 → 模型推理 → 输出结果 → 结束</p>\n</blockquote>\n<p>这种执行模式本质上是一次性的请求—响应（request-response）结构。即在这种执行模式下，LLM 会在接收到用户输入后生成文本，然后就立即退出当前工作流程，不再参与后续状态管理了。AI Agent 与这类应用的核心差异就在于：它在执行模式中引入了一个可持续运行的控制循环（control loop）。这种循环结构将 LLM 从被动接收用户输入的文本生成器，转变成了用于驱动整个程序执行结构的决策组件。换言之，Agent 的存在将 AI 应用的基本执行模式从“请求—响应”转变成了下面这样一个“感知—决策—执行”的循环结构：</p>\n<blockquote>\n<p>感知环境 → 生成决策 → 执行动作 → 更新环境状态 → 再次感知</p>\n</blockquote>\n<p>这个循环结构会持续运行下去，直到任务完成或满足终止条件。从该执行模式可以看出，一个典型的 AI Agent 应用通常包含以下几个核心组件：</p>\n<ul>\n<li><strong>LLM</strong>：该组件负责理解当前任务目标、分析上下文状态并生成下一步行动决策，不负责直接执行外部操作；</li>\n<li><strong>工具接口</strong>：该组件负责将 LLM 生成的结构化指令转换为实际可执行的操作，例如：调用 API、访问数据库、读写文件、执行系统命令、触发外部服务等。它们通常由开发者定义，并通过函数调用或插件机制暴露给模型；</li>\n<li><strong>状态管理</strong>：该组件负责维护任务的中间状态，例如：当前任务进度、已执行步骤、外部环境变化、历史决策记录等。这些状态通常会被存储在内存变量、数据库、向量存储、文件系统等介质中，如果缺乏有效的状态管理机制，我们就难以构建一个真正的 Agent 应用；</li>\n<li><strong>控制器</strong>：该组件负责驱动循环、判断是否继续执行、解析模型输出、调用对应工具、处理异常与失败重试。从架构角度来看，控制器可被视为 Agent 系统的“骨架”，而 LLM 只是其中的决策模块。</li>\n</ul>\n<p>基于以上核心组件，我们就可以简单地归纳出一个 Agent 应用的工作流程，其主要步骤如下：</p>\n<ol>\n<li>接收任务目标</li>\n<li>将目标与当前状态输入 LLM</li>\n<li>LLM 输出下一步行动计划（通常为结构化格式）</li>\n<li>控制器解析输出</li>\n<li>调用相应工具执行</li>\n<li>更新状态</li>\n<li>判断是否完成任务</li>\n<li>若未完成，则进入下一轮循环</li>\n</ol>\n<p>从工程角度来看，AI Agent 是一种新的系统架构模式，它通过持续运行的控制循环，使模型能够参与真实任务的执行过程，而不仅仅是生成文本结果。</p>\n<h2 id=\"ai-agent-的使用方法\">AI Agent 的使用方法</h2>\n<p>在了解了使用 AI Agent 的必要性及其工作原理之后，接下来就可以正式开始研究如何将它运用到自己的日常工作中了。而当我们要讨论 AI Agent 在实际工作中的使用方法时，首先需要回答的问题是“它运行在哪里、由谁控制、承担什么责任”。不同的运行形态，决定了它在工程系统中的角色边界。下面，让我们按照\"运行在哪里\"这个维度分三类来介绍 AI Agent 的使用方法，以及它们在这些应用场景中所承担的任务角色。</p>\n<h3 id=\"命令行工具型-agent\">命令行工具型 Agent</h3>\n<p>对于大多数开发者而言，以命令行工具的形式使用 AI Agent 是一种更符合工程直觉的方式。它运行在熟悉的终端环境中，可以直接访问文件系统与系统命令，因此看起来类似于自动化脚本。当然了，与传统脚本不同的是，AI Agent 的内部决策路径并非预先编写，而是由 LLM 在循环结构中动态生成。这类 AI Agent 应用的典型代表是 <a href=\"https://github.com/anthropics/claude-code\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code</a>，目前同类的主流应用还包括 <a href=\"https://github.com/anomalyco/opencode\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode</a>、<a href=\"https://github.com/openai/codex\" rel=\"noopener nofollow\" target=\"_blank\">Codex CLI</a>、<a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener nofollow\" target=\"_blank\">Gemini CLI</a>、<a href=\"https://github.com/iflow-ai/iflow-cli\" rel=\"noopener nofollow\" target=\"_blank\">iFlow CLI</a> 等。下面，我们首先要做的就是：先将这些工具安装到自己所在的操作系统中。</p>\n<h4 id=\"安装与配置\">安装与配置</h4>\n<p>命令行工具型 Agent 的安装方式其实是非常简单的。因为，虽然它们各自针对 MacOS/Linux/Windows 系统提供了不同的 bash/powershell 安装脚本，或者基于 homeberw/pacman/scoop 等针对不同操作系统平台的包管理器安装命令，但基本都提供了基于 NPM 这一包管理器的跨平台安装方式。所以，读者在大多数情况下都可以按照以下步骤来安装并使用这些工具：</p>\n<ol>\n<li>\n<p>确保自己所在的操作系统中已经安装了版本在 20.0.0 之上的 Node.js 运行环境，其中自带了 NPM 包管理器；</p>\n</li>\n<li>\n<p>在管理员权限下执行<code>npm install -g &lt;agent-name&gt;@&lt;version&gt;</code>命令，在这里，<code>&lt;agent-name&gt;</code>可以通过查询相关工具的官方网站来获得，而<code>&lt;version&gt;</code>则除了可以是我们在工具官网中查到的具体版本号之外，也可以用<code>latest</code>来表示最新版本。例如，如果我们需要安装最新版本的 OpenCode，就只需要在命令行终端中使用管理员权限执行<code>npm install -g opencode@latest</code>命令即可。</p>\n</li>\n</ol>\n<p>在安装完成之后，我们就可以用 CLI 和 TUI 两种方式来使用这种命令行工具型的 Agent 了。其中，TUI 的方式已经被大家所熟知，它实际上就是一个基于命令行界面的交互式程序，运作方式类似于 Python Shell 或 Node.js REPL，拥有属于自己的独立线程。例如在安装完 OpenCode 之后，我们只需要直接在命令行终端中输入<code>opencode</code>命令（如果想延续之前与 OpenCode 的会话，还在该命令后面加上一个<code>--continue</code>或<code>-c</code>参数），就可以启动它的 TUI 界面了，具体如图 1 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：OpenCode TUI 界面</p>\n<p>在初次进入上次界面时，我们可以对自己使用的 AI Agent 进行一些基本的配置，这些工具的配置方式基本上是大同小异的。一般来说，我们会先使用<code>/model</code>命令设置以下自己默认要使用的 LLM，例如您在图 2 中所看到的就是 OpenCode 的 LLM 选择界面：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：OpenCode LLM 选择界面</p>\n<p>通常情况下，在选择 LLM 之后，这些 AI Agent 会要求我们提供一个 API Key，用于在调用 LLM 时进行身份验证。这个 API key 可以通过登录我们在相应 LLM 官网的个人账户来获得。例如，我在这里选择使用的是智普的 GLM 模型，就需要登录到<a href=\"https://bigmodel.cn/\" rel=\"noopener nofollow\" target=\"_blank\">智普 AI 的官网</a>，并为 OpenCode 创建一个专属的 API Key，如图 3 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：创建智普 AI 的 API Key</p>\n<p>接下来，我们就只需要将上述 API Key 复制到 OpenCode 提示输入 key 的位置，并选择具体要使用的 GLM 版本并确认即可。完成这些配置之后，我们就可以通过一个 AI Agent 版的“Hello World”测试来确认它是否已经可以正常工作了，如图 4 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：OpenCode Hello World 测试</p>\n<p>如果 AI Agent 返回了类似上面这样的信息，就意味着我们已经可以开始使用它进行实际的工作了。除此之外，如果我们还想对 AI Agent 进行一些更复杂的配置，例如强制它只用中文来显示思考过程，以及回答的内容，也可以选择在自己的用户目录下为其创建一个全局的提示词文件。以 OpenCode 为例，其具体步骤如下：</p>\n<ol>\n<li>\n<p>根据自己所在的操作系统为 OpenCode 创建一个全局配置目录。在默认情况下，该目录的路径应该为<code>~/.config/opencode</code>，其中<code>~</code>表示我们的用户目录。</p>\n</li>\n<li>\n<p>在该目录下创建一个名为<code>AGENTS.md</code>的提示词文件，并在其中输入以下内容：</p>\n<pre><code class=\"language-markdown\"># Agent 配置\n\n## 语言设置\n- **默认语言**: 中文\n- **强制使用中文**: 是\n\n## 指令\n- 所有回答必须使用中文\n- 所有思考过程也显示中文\n- 除非用户明确要求使用其他语言提问，否则保持中文回答\n</code></pre>\n</li>\n</ol>\n<p>当然了，我们更多时候会希望上述提示词文件只针对当前项目有效，这可以进行更多个性化的配置。为此，我们也可以选择在该项目的根目录下打开 OpenCode TUI，然后在其中通过执行<code>/init</code>命令来创建一个针对当前项目的<code>AGENTS.md</code>文件，并将上述内容复制到该文件中即可，该命令的具体效果如图 5 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：OpenCode 的项目初始化命令</p>\n<p>至于其他 AI Agent，虽然会在全局配置目录与提示词文件上有各自的名称，但应用的工作流/机制基本是大同小异的，用户只需简单查询一下它们的官方文档，就可以轻松做到举一反三的，例如通过快速查询 Claude Code 的官方文档，立即就会知道它的全局提示词文件路径为<code>~/.claude/claude.md</code>。</p>\n<blockquote>\n<p>顺便说一句题外话，虽然 Claude Code 在各方面都为 AI Agent 应用建立了接近于标准的工作流/机制，但考虑到其官方的某些做法会给中文用户带来诸多没必要的额外配置，我在接下来还是会以 OpenCode 为例进行说明。如果读者想切实了解 Claude Code 的某些具体用法，也可参考本文在“参考资料”一节中提供的视频教程：《Claude Code 教程》。</p>\n</blockquote>\n<h4 id=\"基本操作方式\">基本操作方式</h4>\n<p>下面，让我们来具体介绍一下命令行工具型 Agent 的基本操作方式，正如之前所说，这类命令行工具通常有 CLI 和 TUI 两种使用方式，TUI 会单独打开一个工作线程来执行交互式操作，通常用于执行一些需要使用多轮提示词交互，并确认内容的复杂任务。因此，这些 Agent 应用的 TUI 往往至少会提供“计划（plan）”和“构建（build）”两个模式（个别 Agent 还会提供”自动（auto）“之类的第三种模式，或者在模式名称上存在差异，但其在基本使用逻辑上是一致的），其中，”计划“模式通常没有执行外部命令的权限，主要用于与 LLM 执行多轮交互，并确认某一杂任务的解决方案。例如在之前展示的 OpenCode TUI 中，读者可以在其输入框的下方看到，它默认处于“构建”模式。现在，我们可以通过输入<code>&lt;tab&gt;</code>键来将其切换到“计划”模式，然后再试着让它执行“使用 Python 编写并执行一个 hello world 程序”的操作，就会得到类似图 5 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：OpenCode 的计划模式</p>\n<p>正如读者所见，现在 OpenCode TUI 输入框下面提示其当前处于“计划”模式，并且告诉用户自己当前不能编辑文件和执行程序，然后开始与用户讨论任务的具体解决方案。而当我们切换到“构建”模式时，OpenCode 就会直接执行这个解决方案，并输出类似图 7 的结果：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：OpenCode 的构建模式</p>\n<p>当然了，就上面这种仅需一句简短的提示词就可以完成的任务而言，我们实际上更适合使用 CLI 的方式来执行。这种方式允许我们在 bash/powershell 这类命令行终端程序所在的当前线程中直接执行 AI Agent，并输出结果。例如，如果我们想使用 OpenCode CLI 的方式来编写并执行上面那个 Python 程序，可以直接在命令行终端中输入<code>opencode run \"使用 Python 编写并执行一个 hello world 程序\"</code>命令，并得到类似图 8 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：OpenCode 的 CLI 模式</p>\n<p>如读者所见，上述命令直接在 powershell 所在的当前线程中输出了 OpenCode 的执行结果。这样做的好处，除了避免因一些简单的任务反复启动和关闭 OpenCode TUI 之外，在必要情况下还可以使用 Shell/Python 这样的脚本语言来实现对 AI Agent 应用的批量调用，例如，如果我们想使用 Python 脚本批量调用 OpenCode CLI 来执行 5 个不同的任务，就可以像下面这样编写一个简单的 Python 脚本：</p>\n<pre><code class=\"language-python\">import subprocess\n\ntasks = [\n    \"使用 Python 编写并执行一个 hello world 程序\",\n    \"使用 Python 编写并执行一个计算斐波那契数列的程序\",\n    \"使用 Python 编写并执行一个计算阶乘的程序\",\n    \"使用 Python 编写并执行一个计算素数的程序\",\n    \"使用 Python 编写并执行一个计算回文数的程序\",\n]\n\nfor task in tasks:\n    try:\n        result = subprocess.run(\n            [\"opencode\", \"run\", task],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=120\n        )\n        print(f\"任务成功: {task}\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(f\"任务失败: {task}\")\n        print(e.stderr)\n    except subprocess.TimeoutExpired:\n        print(f\"任务超时: {task}\")\n</code></pre>\n<p>除了<code>opencode run</code>命令之外，我们还可以通过执行<code>opencode -h</code>命令来查看其他可用 CLI 方式执行的 OpenCode 操作，如图 9 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 9</strong>：OpenCode 的 CLI 帮助信息</p>\n<p>虽然，上面这种多次调用<code>opencode run</code>命令的做法，在某些特定的情况下并不是最佳的任务编排方式。例如在某些时候，先将所有的需求写入一个 Markdown 文档中，再将其作为提示词一次性发给 AI Agent 可能会是一种更合适的做法。但是，我们可以基于这一思路发展出许多更复杂的 AI Agent 工作流，例如利用部署在服务端的 Agent 来操作这些命令行工具型的 Agent。下面，就让我们基于 OpenClaw 这一可部署服务型的 AI Agent 来了解一下这一工作流的具体实现方式。</p>\n<h3 id=\"可部署服务型-agent\">可部署服务型 Agent</h3>\n<p>如果我们将命令行工具型的 AI Agent 视为一种增强型的自动化工具，那么以 OpenClaw 为代表的、可在服务端部署的 AI Agent 则就是一种系统级执行单元，二者的差异主要在于运行形态与系统边界。具体来说就是，命令行工具型 Agent 的运行方式通常是：</p>\n<ul>\n<li>被用户触发</li>\n<li>执行一轮或多轮任务</li>\n<li>输出结果</li>\n<li>退出进程</li>\n</ul>\n<p>而可部署服务型 Agent 则具有以下完全不同的特征：</p>\n<ul>\n<li>常驻运行</li>\n<li>通过 HTTP / RPC / WebSocket 等方式对外提供能力</li>\n<li>持续维护会话状态</li>\n<li>支持多用户并发访问</li>\n<li>可以被其他系统调用</li>\n</ul>\n<p>在这种形态下，Agent 就不再是一个功能类似于自动化脚本的增强型工具了，它成为了常驻在操作系统中的一个服务组件。具体来说，如果从程序架构的角度来看，这两种 Agent 的差别主要体现在以下几个方面：</p>\n<ol>\n<li>\n<p>生命周期管理：命令行工具型 Agent 的生命周期通常是一次性的，执行完成即销毁，而可部署服务型 Agent 则具有长生命周期，需要考虑健康检查、日志管理、异常恢复机制。</p>\n</li>\n<li>\n<p>会话与状态管理：命令行工具型 Agent 的状态通常也是一次性的，而可部署服务型 Agent 则需要维护会话状态，这意味着它需要支持用户级会话隔离、长期上下文存储、记忆机制（Memory）以及外部数据库支持。</p>\n</li>\n<li>\n<p>多 Agent 编排能力：一旦 Agent 以系统服务组件的形式存在，它就可以调用其他 Agent，被其他 Agent 调用，参与更复杂的任务链。例如像这样：</p>\n<pre><code class=\"language-plaintext\">用户请求\n↓\n调度 Agent\n↓\n分析 Agent → 代码生成 Agent → 测试 Agent\n↓\n结果汇总\n</code></pre>\n<p>这种执行结构显然已经不再是单纯的工具调用，它关注的实际上已经是任务的编排与调度了。这也就意味着，我们需要在服务型的 Agent 中引入任务队列、消息队列、异步任务调度系统等机制。</p>\n</li>\n</ol>\n<p>下面，让我们以 OpenClaw 为例来具体介绍一下使用这种服务型 Agent 的一些基本工作流。假设，我们现在想使用 OpenClaw 指挥 OpenCode 来完成一个简单的网站重构任务，通常需要按照以下步骤来完成。</p>\n<h4 id=\"步骤-1安装并配置一个-openclaw-服务\">步骤 1：安装并配置一个 OpenClaw 服务</h4>\n<p>正如之前所说，OpenClaw 本质上是一个系统服务，这意味着免不了要赋予它较大的操作权限，基于安全方面的考虑，我个人不建议用户将其安装在自己日常的工作设备上。另外，如果想最大限度地发挥 OpenClaw 的功能，最好要能让它长时间持续运行，并执行一定程度的实际设备管理能力。因此，我们在安装 OpenClaw 时通常需要执行的操作如下：</p>\n<ul>\n<li>\n<p>配置好一台可与我们日常工作设备相连通的独立计算机（如果仅用于学习目的，也可以是一台虚拟机），并在其中安装好操作系统与 Node.js 22.x 以上版本的运行环境。</p>\n</li>\n<li>\n<p>在这台独立计算机上打开命令行终端，并执行<code>npm install -g openclaw@latest</code>命令来安装 OpenClaw。当然了，这是使用跨平台的方式。如果读者不想使用 NPM，也可以通过直接执行 bash/powershell 的安装脚本来完成这个操作，相关命令如下：</p>\n<pre><code class=\"language-bash\"># MacOS/Linux 系统下使用 bash 脚本安装：\ncurl -fsSL https://openclaw.ai/install.sh | bash\n# Windows 系统下使用 powershell 脚本安装：\niwr -useb https://openclaw.ai/install.ps1 | iex\n</code></pre>\n</li>\n<li>\n<p>待安装完成之后，继续执行<code>openclaw onboard --install-daemon</code>命令来启动新手安装向导（如图 10 所示），进一步安装 OpenClaw 的服务端组件（例如飞书机器人、WhatsApp 机器人等），关于这方面的内容，读者可参考本文在“参考资料”一节中提供的视频教程：《OpenClaw +飞书的工具流搭建过程》。</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 10</strong>：OpenClaw 的安装向导</p>\n</li>\n<li>\n<p>在配置完相关服务端组件之后，我们还需要通过执行如下命令来配置 OpenClaw 的 Gateway 网关：</p>\n<pre><code class=\"language-bash\">openclaw channels login\nopenclaw gateway --port 18789\n</code></pre>\n<p>在这里，<code>--port</code>参数用于指定 OpenClaw Gateway 的监听端口，如果读者希望使用默认的 18789 端口，则可以省略该参数。</p>\n</li>\n<li>\n<p>待 Gateway 启动之后，我们就可以使用浏览器打开<code>http://localhost:18789</code>来访问 OpenClaw 的 Web 端了，如果我们能看到如图 11 所示的界面，就说明 OpenClaw 已经成功安装并完成了初步的配置工作。</p>\n  \n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 11</strong>：OpenClaw 的 Web 端</p>\n</li>\n</ul>\n<h4 id=\"步骤-2配置-openclaw-调用-opencode-的方式\">步骤 2：配置 OpenClaw 调用 OpenCode 的方式</h4>\n<p>截止到目前为止，我们主要有<strong>两种方式</strong>可以让 OpenClaw 使用 OpenCode 来连接 LLM 并执行指定的任务。如果用户已购买了 OpenCode 的官方模型服务（即 OpenCode Zen），可以选择直接使用 OpenClaw 自带的 Zen 插件来调用 OpenCode，这种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>先获取到 OpenCode Zen 的 API Key，然后通过执行如下命令之一，将其添加到 OpenClaw 的配置中：</p>\n<pre><code class=\"language-bash\"># 使用交互式命令，这需要根据该命令的提示输入你的 API Key\nopenclaw onboard --auth-choice opencode-zen\n# 或非交互式命令，直接将 API Key 作为参数传入\nopenclaw onboard --opencode-zen-api-key \"&lt;你的 API Key&gt;\"\n</code></pre>\n</li>\n<li>\n<p>如果需要的话，还可以通过执行如下命令来设置自己要使用的默认模型：</p>\n<pre><code class=\"language-bash\">openclaw config set agents.defaults.model.primary \"opencode/claude-opus-4-6\"\n</code></pre>\n</li>\n</ul>\n<p>当然了，选择上述方式需要用户不计较按量计费所带来的开销。如果我们想使用免费的 LLM 的话（譬如  kimi-k2.5-free），也可以通过给 OpenClaw 安装 <code>opencode-to-openai</code>这样的第三方插件来实现。这第二种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>安装<code>opencode-to-openai</code>插件，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/dxxzst/opencode-to-openai\ncd opencode-to-openai\nopenclaw plugins install .\n</code></pre>\n</li>\n<li>\n<p>安装完成后，需要执行如下命令来重启 OpenClaw，并确保插件已启用：</p>\n<pre><code class=\"language-bash\">openclaw gateway restart\n</code></pre>\n<p>在这里，如果我们在 OpenClaw 中启用了插件白名单，就还需要通过执行如下命令将该加入该白名单：</p>\n<pre><code class=\"language-bash\">openclaw config get plugins.allow --json\n# 假设返回 [\"a\",\"b\"]\n\nopenclaw config set plugins.allow '[\"a\",\"b\",\"opencode-to-openai\"]' --json\nopenclaw gateway restart\n</code></pre>\n</li>\n<li>\n<p>同步模型并认证 LLM 服务，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local\n</code></pre>\n<p>如果你想顺便设置默认模型：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local --set-default\n</code></pre>\n</li>\n<li>\n<p>选择模型，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models set opencode-to-openai/opencode/kimi-k2.5-free\n</code></pre>\n<p>在这里，如果担心对 LLM 的请求会被卡住，也可以用<code>useIsolatedHome=false</code>这个插件配置让 OpenCode 使用真实 HOME，具体配置命令如下：</p>\n<pre><code class=\"language-bash\">openclaw config set plugins.opencode-to-openai.useIsolatedHome false\n</code></pre>\n</li>\n</ul>\n<h4 id=\"步骤-3与-openclaw-进行对话\">步骤 3：与 OpenClaw 进行对话</h4>\n<p>如果上述操作一切顺利，我们就可以在步骤 1 中配置好的 Web 端或飞书之类的应用中打开与 OpenClaw 的对话窗口，通过发送提示词来调度 OpenCode 完成相关任务了，如图 12 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 12</strong>：与 OpenClaw 的对话窗口</p>\n<p>当然了，如果想让提示词发挥到最大的作用，并在生产环境中实际使用 OpenClaw/OpenCode 来完成具体的项目任务，我们还需要再配置一下 OpenClaw/OpenCode 所接入的 MCP 服务和 Agent Skills 机制了。关于这部分的内容，我将会在《[[Agent 的进阶应用]]》这一篇笔记中进行详细介绍。</p>\n<h2 id=\"结束语\">结束语</h2>\n<p>在完成了对 AI Agent 的学习与实践之后，我最为明显的体会之一是：Agent 并没有让系统变得更简单，反而让系统的边界变得更加清晰。与传统的自动化脚本或工具不同，Agent 并不是一组固定规则的集合，而是一个基于语言模型进行任务理解、规划与执行的系统组件。这意味着，在很多场景下，它所做的并不是“按预期运行”，而是“尽力完成任务”。</p>\n<p>正因如此，Agent 的引入并没有削弱人类在系统中的作用，反而对人的判断能力提出了更高要求：<br />\n我们需要能够理解 Agent 在做什么、为什么这么做，以及在什么情况下应该介入、修正甚至中止它的行为。从这个角度来看，学习和使用 AI Agent，并不意味着把控制权完全交给 AI，而是学会如何在一个由 AI 参与执行的系统中，重新定位人的职责与边界。这也正是本学习阶段的核心目标。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>\n<p>官方文档：</p>\n<ul>\n<li><a href=\"https://code.claude.com/docs/zh-CN/overview?utm_source=copilot.com\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code 官方文档</a></li>\n<li><a href=\"https://opencode.doczh.com/docs/\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode 官方文档</a></li>\n<li><a href=\"https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers\" rel=\"noopener nofollow\" target=\"_blank\">基于 Agent skills 和 MCP 服务的协同工作流</a></li>\n<li><a href=\"https://docs.openclaw.ai/zh-CN\" rel=\"noopener nofollow\" target=\"_blank\">OpenClaw 官方文档</a></li>\n</ul>\n</li>\n<li>\n<p>视频教程：</p>\n<ul>\n<li>Claude Code 教程：<a href=\"https://www.youtube.com/watch?v=AT4b9kLtQCQ\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV14rzQB9EJj\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n<li>OpenClaw +飞书的工具流搭建过程：<a href=\"https://www.youtube.com/watch?v=giv63OtX720\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV1rvcpzDEsH\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n</ul>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-18 16:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">228</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "这也行？按键动作模式识别也能用贝叶斯？",
      "link": "https://www.cnblogs.com/pie-o/p/19622890",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/pie-o/p/19622890\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:38\">\n    <span>这也行？按键动作模式识别也能用贝叶斯？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        基于朴素贝叶斯对按键动作进行模式识别的一次学习实验\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><a href=\"https://bbs.21ic.com/icview-3503975-1-1.html\" rel=\"noopener nofollow\" target=\"_blank\">首发于21ic论坛</a></p>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>之前学习了贝叶斯更新的相关内容，正好现在也在玩开发板，板子上面有几个小的单击按键，一般识别按键动作的做法就很简单，不是中断就是查询，基本都是靠边沿或者电平的状态来进行的，这一套就很无聊，没有实现的欲望，所以想用点不一样的方法。</p>\n<p>这就有了本片文章的出现，基于<code>朴素贝叶斯分类</code>，使用滑动窗口捕捉电平序列，提取特征进行模式识别，理想情况下识别效果杠杠的，但是出现边界以及混合的情况，效果一言难尽，目前水平不够，这应该也是后续需要解决的主要问题了。</p>\n<h2 id=\"技术要点\">技术要点</h2>\n<h3 id=\"核心原理\">核心原理</h3>\n<ol>\n<li>贝叶斯定理</li>\n</ol>\n<p>本文实现的方法基于朴素贝叶斯分类器，主要就是两方面内容：<code>贝叶斯定理</code>与<code>条件独立假设</code>，涉及的概念有<strong>先验概率</strong>、<strong>后验概率</strong>和<strong>条件概率</strong>，其中先验和条件概率都是提前准备好的，可以是主观经验的，也可以是统计量化的，而贝叶斯定理中的条件概率(不是后验概率)，又称为似然概率。</p>\n<p>这个方法的基本思想是：对于给定的待分类项(就是窗口中的电平序列)，求解当这个待分类项出现时，各个<strong>已经定义过</strong>的模式类别出现的概率，哪个概率最大，那么这个待分类项就属于哪个模式。</p>\n<p>在开始分类之前需要一些必要的准备工作：</p>\n<ul>\n<li>定义有哪些模式类别，这些模式边界要明确，不然不容易分析特征</li>\n<li>定义这些模式的特征属性，这些属性在不同模式下的表现是不同的，这是识别的关键，对应了贝叶斯定理中的似然概率</li>\n</ul>\n<ol start=\"2\">\n<li>滑动窗口</li>\n</ol>\n<p>这里的窗口是实时更新的窗口，老数据移出，新数据加入，滑动窗口确定电平序列数据的范围，只有处在窗口中的序列数据才会得到特征提取的机会，它的长度与序列的时间长度成比例，也就是说采样频率会影响到窗口时效性。</p>\n<p>它需要考虑的问题是怎么捕捉到完整的信号，对应于滑动的步长，以及特征提取的周期。</p>\n<h3 id=\"基本步骤\">基本步骤</h3>\n<p>通过以下步骤实现按键动作模式识别：</p>\n<ol>\n<li><strong>滑动窗口采集</strong>：使用固定大小的滑动窗口持续采集按键状态数据</li>\n<li><strong>特征提取</strong>：从窗口数据中提取多个维度的特征</li>\n<li><strong>概率计算</strong>：基于先验概率和<strong>似然概率</strong>计算后验概率</li>\n<li><strong>模式判断</strong>：根据后验概率和<strong>阈值</strong>确定当前按键模式</li>\n</ol>\n<h2 id=\"具体实现\">具体实现</h2>\n<p>为了验证设想的可行性，通过逻辑分析仪记录按键的引脚电平变化，低电平表示按键按下，高电平表示无按键动作，采样率1MHz，时长20s，在后面的实验中，认为序列是连续的，这就是电平序列的来源，具体序列如下图所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上面记录的数据可以作为一个样本，我通过观察和测量确定了几种模式，以及一些帮助识别的特征属性，在实验过程中使用<code>python</code>进行了方法验证。</p>\n<h3 id=\"模式定义\">模式定义</h3>\n<p>我在设计过程中定义了四种按键模式，分别如下：</p>\n<ul>\n<li><strong>无效</strong>：无有效按键动作</li>\n<li><strong>单击</strong>：单次短暂按键动作</li>\n<li><strong>双击</strong>：快速连续两次按键动作</li>\n<li><strong>长按</strong>：持续时间较长的按键动作</li>\n</ul>\n<p>动作的实施都是通过一个单按键来进行的，其中单击和双击涉及到电平的较快速变化，是识别的难点</p>\n<h3 id=\"特征选择\">特征选择</h3>\n<p>基于对提取的特征包括：</p>\n<ul>\n<li><strong>高电平占比</strong>：窗口内高电平信号的比例</li>\n<li><strong>上升沿数量</strong>：信号从低到高的转换次数</li>\n<li><strong>下降沿数量</strong>：信号从高到低的转换次数</li>\n<li><strong>最长连续高电平持续时间</strong>：窗口内持续高电平的最长时间</li>\n</ul>\n<h3 id=\"概率模型\">概率模型</h3>\n<ul>\n<li><strong>先验概率</strong>：初始假设四种模式等概率出现，即每个模式的先验都是0.25。并且和一般的贝叶斯方法不同的是，在实现过程中认为先验是不需要更新的，也就是在每一次识别时认为每个模式都是<strong>等概率</strong>出现的，没有转移概率或者历史因素影响</li>\n<li><strong>似然概率</strong>：基于<strong>特征分布参数</strong>计算观测到当前特征的概率，其中的分布参数是根据实际捕捉的序列数据来设计的，概率分布模型采用正态分布来<strong>近似</strong>，需要均值和标准差，统一使用<em>概率密度</em>表达似然结果\n<ul>\n<li>高电平占比的分布参数\n<ul>\n<li>无效：0.05，0.2</li>\n<li>单击：0.2，0.2</li>\n<li>双击：0.3，0.2</li>\n<li>长按：0.9，0.2</li>\n</ul>\n</li>\n<li>(上升沿/下降沿)数量的分布参数\n<ul>\n<li>无效：0.1，0.3</li>\n<li>单击：1，0.3</li>\n<li>双击：2，0.3</li>\n<li>长按：0.7，0.3</li>\n</ul>\n</li>\n<li>最长高电平持续时间的分布参数\n<ul>\n<li>无效：0，2</li>\n<li>单击：0.2，5</li>\n<li>双击：0.17，3</li>\n<li>长按：0.9，10</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>后验概率</strong>：使用贝叶斯公式计算各模式的后验概率，先计算提取的特征在每个模式下的<em>联合似然</em>，基于条件独立假设，可以直接相乘，然后计算后验并归一化可得最终的概率表</li>\n</ul>\n<h3 id=\"代码实现\">代码实现</h3>\n<ol>\n<li>数据采集与预处理</li>\n</ol>\n<p>把逻辑分析仪中的数据导出为csv文件，代码首先实现了&nbsp;read_sigrok_csv_simple&nbsp;函数，用于读取 sigrok CSV 格式的按键数据：</p>\n<pre><code class=\"language-python\">def&nbsp;read_sigrok_csv_simple(filename):\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data&nbsp;=&nbsp;[]\n&nbsp;&nbsp;&nbsp;&nbsp;signal_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;open(filename,&nbsp;'r',&nbsp;newline='')&nbsp;as&nbsp;csvfile:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reader&nbsp;=&nbsp;csv.reader(csvfile)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;row&nbsp;in&nbsp;reader:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过注释行和空行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;row&nbsp;or&nbsp;row[0].startswith(';'):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;确保行有两个列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(row)&nbsp;&gt;=&nbsp;2:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_val&nbsp;=&nbsp;float(row[0])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data_val&nbsp;=&nbsp;float(row[1])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_data.append(time_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;signal_data.append(data_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;except&nbsp;ValueError:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过无法转换为数字的行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;time_data,&nbsp;signal_data\n</code></pre>\n<p>该函数读取 CSV 文件中的时间戳和信号值，返回两个列表分别存储时间数据和信号数据，通过plot输出采样的数据图如下所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>识别器类设计</li>\n</ol>\n<p>核心实现是&nbsp;BayesianButtonRecognizer&nbsp;类，用于实现基于贝叶斯分类的按键模式识别：</p>\n<pre><code class=\"language-python\">class&nbsp;BayesianButtonRecognizer:\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"基于滑动窗口和贝叶斯更新的按键模式识别器\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;__init__(self,&nbsp;window_size=20,&nbsp;sample_interval=0.01,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.7):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;初始化识别器\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Args:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;window_size:&nbsp;滑动窗口大小\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_interval:&nbsp;采样间隔(秒)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;threshold:&nbsp;判定阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window_size&nbsp;=&nbsp;window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.sample_interval&nbsp;=&nbsp;sample_interval\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.threshold&nbsp;=&nbsp;threshold\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;滑动窗口存储最近的观测序列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window&nbsp;=&nbsp;deque(maxlen=window_size)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;模式类别\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.modes&nbsp;=&nbsp;['无效',&nbsp;'单击',&nbsp;'双击',&nbsp;'长按']\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;先验概率&nbsp;-&nbsp;初始等可能\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.prior&nbsp;=&nbsp;np.array([0.25,&nbsp;0.25,&nbsp;0.25,&nbsp;0.25])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征提取相关的参数(单位:采样点数)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.short_press_max&nbsp;=&nbsp;15&nbsp;&nbsp;#&nbsp;短按最大持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.long_press_min&nbsp;=&nbsp;30&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按最小持续时间&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.double_click_interval&nbsp;=&nbsp;10&nbsp;&nbsp;#&nbsp;双击间隔阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;初始化特征分布参数(基于物理理解预设)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self._init_feature_distributions()\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征权重\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.featwight={\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"无效\":np.array([1.2,0.8,0.8,1.2]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"单击\":np.array([1,1.2,1.2,1]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"双击\":np.array([1,1.2,1.2,0.8]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"长按\":np.array([1.2,0.8,0.8,1.2])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"3\">\n<li>特征分布初始化</li>\n</ol>\n<p>识别器初始化时设置了各模式下特征的概率分布参数：</p>\n<pre><code class=\"language-python\">def&nbsp;_init_feature_distributions(self):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"初始化各模式下特征的概率分布参数\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;高电平占比的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.high_ratio_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.05,&nbsp;&nbsp;&nbsp;#&nbsp;无效时高电平占比很低\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;0.2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有短暂高电平\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;0.3,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时高电平占比稍高\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按时高电平占比很高\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;上升沿数量的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.rise_count_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时几乎无上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时有2个上升沿&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;最长高电平持续时间的分布参数(正态分布:均值,标准差)\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.max_duration_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;(0,&nbsp;2),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时持续时间很短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;(0.2,&nbsp;5),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击中等持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;(0.17,&nbsp;3),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击每次按下时间短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;(0.9,&nbsp;10)&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按持续时间长\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"4\">\n<li>特征提取</li>\n</ol>\n<p>从滑动窗口数据中提取特征，其中高电平占比是通过求序列平均值来获得的，然后边沿计数对应了记录序列跳变数量，最长高电平时间通过记录连续高电平时长获取：</p>\n<pre><code class=\"language-python\">def&nbsp;extract_features(self,&nbsp;window_data):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"从滑动窗口数据中提取特征\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(window_data)&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;None\n\n&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;=&nbsp;np.array(window_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征1:&nbsp;高电平占比\n\n&nbsp;&nbsp;&nbsp;&nbsp;high_ratio&nbsp;=&nbsp;np.mean(data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征2:&nbsp;上升沿数量(0-&gt;1的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;0&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征3:&nbsp;下降沿数量(1-&gt;0的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;1&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征4:&nbsp;最长连续高电平持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;val&nbsp;in&nbsp;data:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;val&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;max(max_duration,&nbsp;current_duration)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'high_ratio':&nbsp;high_ratio,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'rise_count':&nbsp;rises,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'fall_count':&nbsp;falls,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'max_duration':&nbsp;max_duration\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"5\">\n<li>似然概率计算</li>\n</ol>\n<p>计算给定模式下观测到特征值的似然概率，即条件概率，通过上面定义的分布参数，使用<code>正态分布</code>近似，在python中通过<code>stats.norm.pdf</code>求特征对应每个模式的似然程度，然后基于条件独立的假设，求解联合似然，表示样本对某一模式的最终似然结果：</p>\n<pre><code class=\"language-python\">def&nbsp;calculate_likelihood(self,&nbsp;features,&nbsp;mode):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"计算给定模式下观测到特征值的似然概率\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;features&nbsp;is&nbsp;None:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1.0&nbsp;&nbsp;#&nbsp;无特征时返回中性似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用概率密度函数计算各特征的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;1.&nbsp;高电平占比的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_ratio&nbsp;=&nbsp;self.high_ratio_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用正态分布近似,&nbsp;标准差根据经验设定\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_ratio&nbsp;=&nbsp;stats.norm.pdf(features['high_ratio'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_ratio,&nbsp;0.2)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_ratio&nbsp;+&nbsp;1e-10)&nbsp;&nbsp;#&nbsp;避免零\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;2.&nbsp;上升沿数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_rises&nbsp;=&nbsp;stats.norm.pdf(features['rise_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_rises&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;3.&nbsp;下降沿(同上升沿)数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_falls&nbsp;=&nbsp;stats.norm.pdf(features['fall_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_falls&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;4.&nbsp;最长持续时间的似然(使用正态分布)\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur&nbsp;=&nbsp;self.max_duration_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur&nbsp;*=&nbsp;self.window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_duration&nbsp;=&nbsp;stats.norm.pdf(features['max_duration'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_duration&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;组合各特征的似然(假设特征条件独立)\n\n&nbsp;&nbsp;&nbsp;&nbsp;total_likelihood&nbsp;=&nbsp;np.prod(np.array(likelihoods))\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征在mode[%s]的似然：\"%{mode},likelihoods,\"最终联合似然:%.\n\n&nbsp;&nbsp;&nbsp;&nbsp;3f\"%total_likelihood)\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;total_likelihood\n</code></pre>\n<ol start=\"6\">\n<li>滑动窗口更新</li>\n</ol>\n<pre><code class=\"language-python\">def&nbsp;slide_window(self,io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;移除最旧的值\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.popleft()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;将新观测值加入滑动窗口\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.append(io_state)\n</code></pre>\n<ol start=\"7\">\n<li>信念更新与模式判断</li>\n</ol>\n<p>计算完样本对每个模式的似然后，就于先验概率相乘，就得到了后验概率，然后归一化得到最终结果，同时使用阈值判定机制，当最大后验超过判定阈值后，才会识别具体模式，否则就是不确定</p>\n<pre><code class=\"language-python\">def&nbsp;update_belief(self,&nbsp;io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"根据新观测值更新信念\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;提取当前窗口的特征\n\n&nbsp;&nbsp;&nbsp;&nbsp;features&nbsp;=&nbsp;self.extract_features(self.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征提取：\",features)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;计算各模式的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;np.array([self.calculate_likelihood(features,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;mode)&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;mode&nbsp;in&nbsp;self.modes])\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;贝叶斯更新:&nbsp;后验&nbsp;∝&nbsp;似然&nbsp;×&nbsp;先验\n\n&nbsp;&nbsp;&nbsp;&nbsp;unnormalized_posterior&nbsp;=&nbsp;likelihoods&nbsp;*&nbsp;self.prior\n\n&nbsp;&nbsp;&nbsp;&nbsp;evidence&nbsp;=&nbsp;np.sum(unnormalized_posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;evidence&nbsp;&gt;&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;unnormalized_posterior&nbsp;/&nbsp;evidence\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;self.prior.copy()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;更新先验(用于下一次迭代)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;self.prior&nbsp;=&nbsp;posterior\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;判断当前模式\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_mode_idx&nbsp;=&nbsp;np.argmax(posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_prob&nbsp;=&nbsp;posterior[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"后验：\",posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;best_prob&nbsp;&gt;&nbsp;self.threshold:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;self.modes[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;'不确定'\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;detected_mode,&nbsp;posterior\n</code></pre>\n<ol start=\"8\">\n<li>主函数与演示</li>\n</ol>\n<p>因为定义了高电平为有效电平，但实际中低电平，或者说下降沿是按键动作的反应，所以处理数据序列时做了相应的取反处理。</p>\n<pre><code class=\"language-python\">if&nbsp;__name__&nbsp;==&nbsp;\"__main__\":\n\n&nbsp;&nbsp;&nbsp;&nbsp;DeltaT&nbsp;=&nbsp;0.01 # 采样间隔\n\n&nbsp;&nbsp;&nbsp;&nbsp;UnitTime&nbsp;=&nbsp;1e-06 # 原始数据点的时基\n\n&nbsp;&nbsp;&nbsp;&nbsp;SampleInterval&nbsp;=&nbsp;math.floor(DeltaT&nbsp;/&nbsp;UnitTime)\n\n&nbsp;&nbsp;&nbsp;&nbsp;filename&nbsp;=&nbsp;\"key_data_20s_all.csv\"&nbsp;&nbsp;#&nbsp;逻辑分析仪导出的数据\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer&nbsp;=&nbsp;BayesianButtonRecognizer(window_size=100,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.8)\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer.reset()\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data,&nbsp;signal_data&nbsp;=&nbsp;read_sigrok_csv_simple(filename)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"成功读取数据，共&nbsp;{len(time_data)}&nbsp;个数据点\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"时间范围:&nbsp;{time_data[0]}s&nbsp;到&nbsp;{time_data[-1]}s\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;res_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_num&nbsp;=&nbsp;math.floor(len(signal_data)&nbsp;/&nbsp;SampleInterval)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"sample&nbsp;size&nbsp;is:\",sample_num)\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(sample_num-1):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_data.append(int(not&nbsp;signal_data[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;recognizer.slide_window(int(not&nbsp;signal_data\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;i%recognizer.window_size==0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res,postrior=recognizer.update_belief(i)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(res&nbsp;not&nbsp;in[\"不确定\",\"无效\"]):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res_data.append(res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(\"win[%d]:\"%i,res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(recognizer.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(sample_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(res_data)\n</code></pre>\n<p>当窗口中样本序列是理想情况时，识别效果相当好：</p>\n<p>无效样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个无效按键样本序列图，保持无效电平，没有边沿变化。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，高电平占比为0，边沿计数为0，最长高电平延时为0，在各个模式的似然列表中，给出了对应的似然结果，同时从列数据对比来看，也可以直接从数值上看出样本特征更偏向哪个模式，最终的后验结果，确实是无效模式的概率最高，即判定窗口中的序列为无效。</p>\n<p>单击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个单击按键样本序列图，有边沿变化，一个上升沿，一个下降沿，高电平占比大约0.2。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，最终的识别结果也是正确的</p>\n<p>双击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个双击样本的示例图，可以看到由两个高电平组成，下图给出识别过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出特征提取信息正确，有两个上升沿和两个下降沿，然后最终的后验概率中也是双击的概率最大，并且超过阈值判定正确。</p>\n<p>下面给出一些因为信号完整性缺失造成的误判示例。</p>\n<p>边界双击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图中可以看出很明显是一个双击的动作，但是由于窗口长度固定的原因，导致一部分序列缺失，下图给出识别结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征提取的信息倒是正确的，识别出下降沿只有1个，在计算似然过程中，相应位置的似然结果也反应了这一点，最终的后验表中可以看到前两个大的概率是单击和双击，但是都没超过阈值，所以判定为不确定</p>\n<p>边界单击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出这个情况像是单击，但是实际上是一段长按序列，下图给出识别过程：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征信息提取是正确的，然后似然结果都偏低，表示不偏向某一个模式，但在最终的后验结果中单击的后验概率异常的高，应该是在归一化过程中，单击概率占比比其他概率大很多导致的，这也是同样的问题，也就是信号完整性缺失导致了误判</p>\n<h2 id=\"总结\">总结</h2>\n<p>在这次实验中，基于朴素贝叶斯分类方法，通过<em>滑动窗口</em>采集数据、提取多维度特征、计算概率分布和应用贝叶斯更新，学到了不少，也融合了很多内容，算是一次不小的学习体验吧，虽然目前测试下来效果有限，还无法真正用在项目中，也总结了一些不足的地方。</p>\n<p>比如信号完整性保证不了，不同特征属性对不同模式的权重实际并不一致等，这些都是需要解决的问题，虽然对现在的我来说很困难，但探索新方法的过程还是蛮喜欢的，也可能是对现有方法的审美疲劳导致的吧。</p>\n<p>但有一说一，传统的方法，还是简单高效的，也不涉及到什么数学的内容，全凭逻辑加判断就可以搞定了，真是省时省力啊。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/pie-o/\" target=\"_blank\">pie_thn</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/pie-o/p/19622890\" target=\"_blank\">https://www.cnblogs.com/pie-o/p/19622890</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:38</span>&nbsp;\n<a href=\"https://www.cnblogs.com/pie-o\">pie_thn</a>&nbsp;\n阅读(<span id=\"post_view_count\">93</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]基于Checkpoint的持久化",
      "link": "https://www.cnblogs.com/jaydenai/p/19622525/checkpoint-persistent",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19622525/checkpoint-persistent\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 08:40\">\n    <span>[拆解LangChain执行引擎]基于Checkpoint的持久化</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Pregel基于Checkpoint的持久化机制是实现Agent应用`高可用性`和`长期记忆`的基础，它本质上是将 不断向前推进的图在“Superstep”之间将其状态固化的过程。和很多数据库持久化类似，Pregel采用`基于全量数据的状态快照+基于增量更新的操作日志`的持久化策略。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Pregel基于Checkpoint的持久化机制是实现Agent应用<code>高可用性</code>和<code>长期记忆</code>的基础，它本质上是将 不断向前推进的图在“Superstep”之间将其状态固化的过程。和很多数据库持久化类似，Pregel采用<code>基于全量数据的状态快照+基于增量更新的操作日志</code>的持久化策略。</p>\n<h2 id=\"1-持久化channel状态\">1. 持久化Channel状态</h2>\n<p>Pregel将状态“焊死”在Channel上，这使持久化变得很简单，它只要针对每个Superstep将每个Channel状态存下来就可以了。为了提高性能，它只需要考虑有过更新的Channel，而确Channel是否更新可以利用它的版本来决定。每个Channel都具有一个不断更新的版本，如果某个Channel在某个Superstep内有过更新，版本会往前更替。至于这个版本采用何种格式，具体如何管理，执行引擎将其下放到具体的Checkpointer实现中。</p>\n<p>作为Checkpointer的基类，<code>BaseCheckpointSaver</code>将基于更新快照的存储实现在如下所示的<code>put</code>方法中。待持久化的数据被封装在一个<code>Checkpoint</code>对象中以<code>checkpoint</code>参数传入该方法，<code>config</code>和<code>metadata</code>参数提供描述该Checkpoint的配置和元数据，而<code>new_versions</code>以一个字典的形式提供了涉及的每个Channel的版本。config参数提供的RunnableConfig主要提供标识当前调用会话的<code>Thread ID</code>和<code>Checkpoint命名空间</code>。方法会返回的RunnableConfig对象一般会携带<code>Thread ID</code>、<code>Checkpoint命名空间</code>和<code>Checkpoint ID</code>。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def put(\n        self,\n        config: RunnableConfig,\n        checkpoint: Checkpoint,\n        metadata: CheckpointMetadata,\n        new_versions: ChannelVersions,\n    ) -&gt; RunnableConfig\n\n    async def aput(\n        self,\n        config: RunnableConfig,\n        checkpoint: Checkpoint,\n        metadata: CheckpointMetadata,\n        new_versions: ChannelVersions,\n    ) -&gt; RunnableConfig\n    …\nChannelVersions = dict[str, str | int | float]\n</code></pre>\n<h3 id=\"11-checkpointmetadata\">1.1 CheckpointMetadata</h3>\n<p>描述Checkpoint元数据的<code>CheckpointMetadata</code>类型定义如下，其三个成员构成了图执行的谱系追踪（Lineage Tracking）和控制流导航的核心。它们不参与业务逻辑计算，但决定了如何管理、回溯和审计图的状态。</p>\n<pre><code class=\"language-python\">class CheckpointMetadata(TypedDict, total=False):\n    source: Literal[\"input\", \"loop\", \"update\", \"fork\"]\n    step: int\n    parents: dict[str, str]\n</code></pre>\n<p>CheckpointMetadata的<code>step</code>字段返回Superstep编号，代表当前Checkpoint在逻辑时间轴上的位置。<code>source</code>字段定义了当前这个Checkpoint是由哪种类型的操作触发生成的，它是理解图<code>生命历程</code>的关键，具体的选项包括：</p>\n<ul>\n<li>\n<p>input: 首次调用invoke或stream方法时触发，代表图的“创世点”。这是由外部初始数据输入产生的第一个Checkpoint（Superstep序号为 -1）；</p>\n</li>\n<li>\n<p>loop：内部根据 Node 和 Channel 的订阅关系进行迭代时触发，代表图在正常执行流程中的自动化流转。大多数中间步骤的 source 都是此值。</p>\n</li>\n<li>\n<p>update：用户手动调用了update_state方法时触发，代表一种“非自然”的状态变更。这通常用于人为干预、修正数据或在中断后注入信息。</p>\n</li>\n<li>\n<p>fork: 当用户从历史中的某个非最新Checkpoint重新启动执行时触发，代表图产生了分支。它标记了执行流从主线脱离，开启了一个独立的时间线。</p>\n</li>\n</ul>\n<p>CheckpointMetadata的<code>parents</code>字段返回一个字典，记录了当前Checkpoint与之前Checkpoint之间的拓扑关系，其结果通常为通常形式为dict[namespace, parent_checkpoint_id]。由于 采用增量持久化，当我们需要恢复一个完整的状态视图时，引擎必须知道去哪里找那些没变动的数据，parents字典提供了回溯路径。如果当前 Checkpoint 没有 某个Channel的值，引擎就会根据parents指引，跳转到父级Checkpoint去查找，直到找到该 Channel最近一次被更新的版本。</p>\n<p>在包含子图的复杂场景中，parents字段会记录父图命名空间对应的Checkpoint ID，确保父子图之间的状态逻辑能够跨层级对齐。当source为“fork”时，parents字段指向的是那个被分叉的历史点，而不是时间线上的物理前一个点。</p>\n<p>当我们查看一个CheckpointMetadata对象时，可以构建出如下逻辑：这个状态是由于<code>source</code>产生的，目前处于第<code>step</code>步。如果你想知道这个状态从何而来，或者想找回那些没变的数据，请根据<code>parents</code>列表向回追溯。</p>\n<h3 id=\"12-channel版本\">1.2 Channel版本</h3>\n<p>执行引擎将Channel版本的格式化权力下放给具体的Checkpointer实现，它们通过重写如下这个<code>get_next_version</code>方法提供某个Channel的下一个版本。如果表示当前版本的current参数为None，该方法会返回Channel的初始版本。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def get_next_version(self, current: V | None, channel: None) -&gt; V\n</code></pre>\n<p>以InMemorySaver为例，它会将Channel版本格式化成一个由51个字符组成的字符串，具体格式为<code>f\"{sequence:032}.{random:016}\"</code>。sequence从1开始递增，代表了“物理状态的演进顺序”。在顺序执行时反映了Superstep的进度，但是在遇到人为干预、中断、分叉或重试的情况下，物理序列号仅能反映“存盘的次数”。Superstep序号反映的是“算法迭代的深度”，所以不能将两者等同起来，前者是大于或等于Superstep序号的。</p>\n<p>“random”部分是一个0-1之间的随机数。如果说Channel版本前 32 位（第一部分）是时间轴上的<code>大刻度</code>，那么这第二部分就是确保状态在微观层面绝对唯一且可追溯的<code>防伪码</code>。由于 CPU 处理速度极快，多个并行任务可能在极短的微秒级时间内尝试触发写入。如果仅依靠前 32 位的递增序列号，在Superstep内部的多次写入可能会因为序列号来不及递增或在高并发下产生冲突。第二部分包含的随机数（源自浮点数的小数位）确保了即使第一部分相同，物理上的 Checkpoint ID 也是全球唯一的，这保证了UUID 级别的碰撞安全性。</p>\n<p>从支持<code>时间旅行</code>与<code>状态分叉</code>的角度来看，第二部分就显得更加重要了。当我们从某个历史点重启时流程时，假设从历史上的“00...001”处分叉出两条不同的执行路径，两条路径的序列号可能都会递增到“00...002”，但通过第二部分的随机随机值，系统能以如下形式物理隔离这两条路径。所以版本的第二部分的内容不仅仅为了解决冲突而存在，它使得持久化层可以同时存储同一逻辑步下的多个平行宇宙而不会发生覆盖。</p>\n<ul>\n<li>路径 A: 00...002.0.8494...</li>\n<li>路径 B: 00...002.0.1234...</li>\n</ul>\n<p>有的实现会严格采用类似于<code>{ sequence}.{step_index}.{random_entropy}</code>这样的三段式的版本格式化，第二部分通常包含了.0. 或.1.这样的前缀，它还兼具如下的功能：</p>\n<ul>\n<li>子图导航：当主图调用子图时，子图产生的Checkpoint会通过第二部分的特定位来标识它属于哪个父级任务的“逻辑分支”。</li>\n<li>任务索引：在同一个Superstep中，如果一个Node产生了多条Pending Write，第二部分可以用来索引这些写入的先后次序，确保在恢复合并时不会错位。</li>\n</ul>\n<h3 id=\"13-checkpoint\">1.3 Checkpoint</h3>\n<p>如下所示的是Checkpoint类型的定义。它的<code>v</code>字段表示决定Checkpoint结构的版本号，用于后向兼容性。如果未来改变了存储格式，运行时会根据这个值决定如何正确地反序列化旧数据。<code>id</code>和<code>ts</code>分别表示Checkpoint的唯一标识和生成时间戳。<code>updated_channels</code>字段返回的本Superstep内涉及更新的Channel列表。引擎根据订阅它们的Node来创建下一步执行的任务。<code>channel_values</code>字段存储了“涉及更新”的每个Channel的更新值。<code>channel_versions</code>字段返回所有Channel的版本。</p>\n<pre><code class=\"language-python\">class Checkpoint(TypedDict):\n    v : int\n    id : str\n    ts : str\t\t\n    channel_values : dict[str, Any]\n    channel_versions : ChannelVersions\n    versions_seen : dict[str, ChannelVersions]\n    updated_channels : list[str] | None\n</code></pre>\n<p>Node并不能实时观察到Channel的变化，<code>versions_seen</code>字段以<code>{ \"Node名\": { \"依赖Channel名\": \"版本ID\" } }</code>这样的结构返回每个Node执行时所能“看到”的Channel版本， 它记录了Node完成计算时的前置条件。在中断恢复时，引擎对比<code>versions_seen</code>，如果Node看到的输入版本没变，且它已经有了输出记录，那么就无需重复执行，所以这是实现因果一致性和幂等性的关键。如下的JSON是由Pregel生成的一个Checkpoint对象序列化后的结果。</p>\n<pre><code class=\"language-json\">{\n  \"v\": 4,\n  \"ts\": \"2026-01-18T13:42:07.542155+00:00\",\n  \"id\": \"1f0f4737-b4b1-6bbb-8001-1e44d720a9df\",\n  \"channel_versions\": {\n    \"foo\": \"00000000000000000000000000000001.0.6943525017042773\",\n    \"bar\": \"00000000000000000000000000000002.0.24038201058058928\",\n    \"baz\": \"00000000000000000000000000000003.0.8444674692332181\"\n  },\n\n  \"versions_seen\": {\n    \"__input__\": {},\n    \"foo\": { \"foo\": \"00000000000000000000000000000001.0.6943525017042773\" },\n    \"bar\": { \"bar\": \"00000000000000000000000000000002.0.24038201058058928\" }\n  },\n\n  \"updated_channels\": [ \"baz\" ],\n  \"channel_values\": {\n    \"foo\": \"begin\",\n    \"bar\": \"bar\",\n    \"baz\": \"baz\"\n  }\n}\n</code></pre>\n<h3 id=\"14存储结构\">1.4\t存储结构</h3>\n<p>接下来，我们以<code>InMemorySaver</code>为例看看Checkpoint会采用怎样的存储结构，以及以此结构基础的读取方式。InMemorySave针对Checkpoint的存储涉及两个字典。一个名为<code>blobs</code>的字典用于存储Channel的荷载内容（值），采用的Key是由<code>Thread ID</code>、<code>Checkpoint命名空间</code>、<code>Channel名称</code>和<code>版本</code>构成的四元组。另一个名为<code>storage</code>的字典时一个具有四层结构的字典，具体类型为<code>defaultdict[str, dict[str, dict[str, tuple[tuple[str, bytes], tuple[str, bytes], str | None]]]]</code>，每一层字典的Key顶如下。我们可以认为blobs用于存储数据，storage为索引表。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">层级</th>\n<th style=\"text-align: left;\">Key 类型</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">第一层</td>\n<td style=\"text-align: left;\">Thread_id</td>\n<td style=\"text-align: left;\">会话隔离，区分不同的用户或对话流</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">第二层</td>\n<td style=\"text-align: left;\">Checkpoint_ns</td>\n<td style=\"text-align: left;\">命名空间隔离，支持子图或不同模块的独立状态空间</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">第三层</td>\n<td style=\"text-align: left;\">checkpoint_id</td>\n<td style=\"text-align: left;\">版本隔离，用于定位特定版本的快照</td>\n</tr>\n</tbody>\n</table>\n<p>最后一层字典的值是一个三元组<code>tuple[tuple[str, bytes], tuple[str, bytes], str | None]</code>，它们将数据序列化后存储，以确保内存中的数据是不可变且易于复制的，三个部分包括：</p>\n<ul>\n<li>tuple[str, bytes]：前一部分表示的序列化类型（通常是json或msgpack），第二部分表示经过序列化后的Checkpoint对象（由于具体的值已经存储在blobs中了，所以此时的Checkpoint的channel_values字段已经被移除）。这里不再存储 Python 字典对象，而是存储字节流。这模拟了数据库存取过程，并防止了Node在内存中意外修改已存盘的状态，实现对象的深度隔离。</li>\n<li>tuple[str, bytes]：Checkpoint元数据，前一部分同样表示序列化类型，第二部分为经过序列化后的CheckpointMetadata对象。</li>\n<li>str | None：父级checkpoint_id（这里的Parent与是否以子图形式执行没有关系，这里代表作为调用者的Node），InMemorySaver可以通过这个 ID在内存中顺着链条向上追溯，从而在恢复时合并增量状态。</li>\n</ul>\n<h2 id=\"2-持久化pending-write\">2. 持久化Pending Write</h2>\n<p>Checkpoint是在Superstep成功结束时针对Channel状态创建的，它并不能反映一个尚未结束Superstep内的真实状态。Pregel在执行过程中可以能出现不可预期的错误，或者需要人为介入导致可预期的中断，并行执行的任务就会出现部分部分成功、部分失败和中断的情况。对于成功执行的操作，它们针对目标Channel的写入并没有通过一个Checkpoint固定下来，仅仅属于一个<code>Pending Write</code>。如果这种中间状态没有被持久化，等下次恢复执行的时候，本来已经成功执行的任务还会重复执行，这是无法接受的。</p>\n<p>如果某个任务涉及到多次人为中断，每次恢复执行都需要提供<code>Resume Value</code>。如果这些Resume Value没有持久化，那么每次恢复调用提供的Resume Value永远都会提供给第一个中断，多次中断根本就没法实现，所以提供的Resume Value也需要以Pending Write的形式存储下来。</p>\n<p>持久化不仅仅需要将Superstep完成时将Channel的状态以Checkpoint固定下来，还需要将涉及到的所有Pending Write按照先后顺序记录下来。Pending Write不仅仅限于描述成功任务针对目标Channel的写入和依序提供Resume Value，任务在执行中抛出的异常和中断也会以Pending Write的形式被记录下来。</p>\n<p>实际上这种基于全量基础数据和增量操作日志相结合的持久化形式，在很多内存数据库中得到了广泛的应用。以Redis为例，它会采用相应的策略每隔一段时间将当前时间点的内存快照以<code>RDB</code>形式固化下来，同时针对数据库所作的每个操作都会按照时间顺序以<code>AOL</code>的形式存储下来。对于Pregel来说，Checkpoint就是RDB，Pending Wrtes就是AOL。当Pregel以恢复形式执行的时候，它会先提取并应用指定的Checkpoint快照，然后对状态为成功执行的Pending Write进行重放就能恢复中断时的状态。</p>\n<p>针对Pending Write的持久化通过调用BaseCheckpointSaver如下所示的put_writes/aput_writes方法完成。Pending Write的持久化是基于任务进行的，所以我们需要指定任务的ID和路径。config参数提供RunnableConfig对象携带了所需的Thread ID， Checkpoint命名空间和Checkpoint ID。具体针对Channel的Pending Write由writes参数提供的， 这是一个由Channel名称和值的二元组组成的序列。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def put_writes(\n        self,\n        config: RunnableConfig,\n        writes: Sequence[tuple[str, Any]],\n        task_id: str,\n        task_path: str = \"\",\n    ) -&gt; None\n    async def aput_writes(\n        self,\n        config: RunnableConfig,\n        writes: Sequence[tuple[str, Any]],\n        task_id: str,\n        task_path: str = \"\",\n    ) -&gt; None\n</code></pre>\n<p>对于InMemorySaver来说，它将PendingWrite存储于一个结构为<code>defaultdict[tuple[str, str, str], dict[tuple[str, int], tuple[str, str, tuple[str, bytes], str]]]</code>的两层字典中。第一层字典的Key为<code>Thread ID</code>， <code>Checkpoint命名空间</code>和<code>Checkpoint ID</code>三元组。第二层元组的第一个部分为Task ID，第二部分是当前Pending Write在writes序列中的索引。真正存储的内容是由如下四部分组成的元组：</p>\n<ul>\n<li>task_id：冗余存储任务 ID，便于快速检索。</li>\n<li>channel： Channel的名称。</li>\n<li>tuple[str, bytes]：前部分表示序列化格式（如\"json\"或\"pickle\"）。后一部分为序列化后的字节。</li>\n<li>task_path：任务在图结构中的完整路径。</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 08:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">54</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Ubuntu ä¸Š ROS2 çš„å®‰è£",
      "link": "https://www.cnblogs.com/pycr/p/19622095",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/pycr/p/19622095\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 23:01\">\n    <span>Ubuntu 上 ROS2 的安装</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<center><font face=\"华文新魏\" size=\"7\">Ubuntu 上 ROS2 的安装</font></center>\n<h1 id=\"一前言\">一、前言</h1>\n<p>​\t最近至少配置了 4 次 ROS2 了，该踩的坑都踩过了，遂发一篇博客记录一下。其实 ROS2 的安装并没有想象中的那么难，可能只是出于未知便觉得不知所措，但是其实本质上就只有两步：添加源、然后安装。</p>\n<p>​\t但是在此之前，我觉得有必要说一下 Ubuntu 和 ROS2 的各个版本代号以及对应关系。众所周知，Ubuntu 的版本除了我们喜闻乐见的 20.04/22.04/24.04 之外，还有固定为「形容词 + 动物」的版本代号，最近的几个大版本如下：</p>\n<table>\n<thead>\n<tr>\n<th>Ubuntu 版本号</th>\n<th>英文代号</th>\n<th>中文俗称</th>\n<th>支持周期</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>16.04 LTS</td>\n<td>Xenial Xerus</td>\n<td>好客的非洲地松鼠</td>\n<td>2016-2021</td>\n</tr>\n<tr>\n<td>18.04 LTS</td>\n<td>Bionic Beaver</td>\n<td>仿生海狸</td>\n<td>2018-2023</td>\n</tr>\n<tr>\n<td>20.04 LTS</td>\n<td>Focal Fossa</td>\n<td>焦点猫鼬</td>\n<td>2020-2025</td>\n</tr>\n<tr>\n<td>22.04 LTS</td>\n<td>Jammy Jellyfish</td>\n<td>急躁的水母</td>\n<td>2022-2027</td>\n</tr>\n<tr>\n<td>24.04 LTS</td>\n<td>Noble Numbat</td>\n<td>高贵的袋食蚁兽</td>\n<td>2024-2029</td>\n</tr>\n</tbody>\n</table>\n<p>​\t而有些地方会直接用第一个单词来指代 Ubuntu 的版本，比如 Focal/Jammy/Noble 分别代表 20.04/22.04/24.04。</p>\n<p>​\t而 ROS2 也有自己的版本代号（ROS1基本上已经不支持了，所以我们默认直接略过 ROS1），比如 Humble/Jazzy（这里和 Ubuntu 的代号有点像注意别弄混了），而每个版本支持的 Ubuntu 版本也不尽相同，具体信息可以去 <a href=\"https://ros.org/\" rel=\"noopener nofollow\" target=\"_blank\">ROS 官网</a> 查看。以下教程只针对于截止目前相对较新的 22.04 和 24.04 来安装。</p>\n<h1 id=\"二安装\">二、安装</h1>\n<blockquote>\n<p>其实 Ubuntu 上的软件安装方式十分统一，统一到只需要同一个命令就行：<strong>apt</strong>。</p>\n<p>唯一的区别就是有的软件在系统自带的软件源里，而有的需要自己添加软件源。</p>\n</blockquote>\n<h2 id=\"1-终端配置-locale\">1. 终端配置 locale</h2>\n<p>​\tROS2 需要 UTF-8 编码支持，但是中文英文貌似都可以，目前来说还没有遇到什么由中文编码产生的问题。可以在终端运行一下 <code>locale</code> 来查看一下支持的语言，只要是 UTF-8 的比如 en_US.UTF-8 或者 zh_CN.UTF-8 暂时都行。如果不是 UTF-8 的得运行一下如下命令永久设置系统的全局 locale 环境变量：</p>\n<pre><code class=\"language-bash\">sudo apt install -y locales\nsudo locale-gen en_US en_US.UTF-8\nsudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8\nexport LANG=en_US.UTF-8\n</code></pre>\n<h2 id=\"2-添加-ros2-软件源\">2. 添加 ROS2 软件源</h2>\n<blockquote>\n<p>Ubuntu 默认源没有 ROS2，需要添加官方源。</p>\n</blockquote>\n<h3 id=\"21-导入-ros2-官方密钥\">2.1. 导入 ROS2 官方密钥</h3>\n<pre><code class=\"language-bash\"># 导入 ROS2 GPG 密钥\ncurl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key | sudo gpg --dearmor -o /usr/share/keyrings/ros-archive-keyring.gpg\n</code></pre>\n<p>​\t这一步的作用是将 ROS2 官方的密钥下载保存到 <code>/usr/share/keyrings/ros-archive-keyring.gpg</code>，防止下载的软件被恶意篡改。</p>\n<h3 id=\"22-配置-ros2-官方仓库\">2.2. 配置 ROS2 官方仓库</h3>\n<pre><code class=\"language-bash\"># 添加 ROS2 源到 sources.list.d\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n</code></pre>\n<p>​\t这一步的作用是将 ROS2 的官方仓库添加到 <code>apt</code> 的下载源中，从而保证能通过 <code>apt</code> 下载 ROS2。其中 <code>$(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME)</code> 的作用是自动识别 Ubuntu 版本（比如22.04 对应 <code>jammy</code>），无需手动修改，也可以用<code>$(lsb_release -cs)</code> 代替。</p>\n<p>​\t如果安装过程中遇到网络问题，可切换国内镜像源，如清华、中科大 ROS2 镜像。将上述地址换为中科大镜像地址即可：</p>\n<pre><code class=\"language-bash\">echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] https://mirrors.ustc.edu.cn/ros2/ubuntu/ $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n</code></pre>\n<h2 id=\"3-安装-ros2\">3. 安装 ROS2</h2>\n<p>​\t配置结束之后终于可以一键安装了，首先更新一下软件包索引：</p>\n<pre><code class=\"language-bash\">sudo apt update\n</code></pre>\n<p>​\t然后一键安装桌面完整版，包含 ROS2 核心库、可视化工具（RViz）、开发工具等，是最常用的版本：</p>\n<pre><code class=\"language-bash\">sudo apt install -y ros-jazzy-desktop\n</code></pre>\n<p>​\t如果只需要核心库（无可视化工具），可以安装精简版：</p>\n<pre><code class=\"language-bash\">sudo apt install -y ros-jazzy-ros-base\n</code></pre>\n<p>​\t<strong>注意：jazzy 对应的是 Ubuntu24.04，如果当前 Ubuntu 的版本是 22.04，请将上述命令中的 jazzy 替换为 humble。</strong></p>\n<h2 id=\"4-配置环境变量\">4. 配置环境变量</h2>\n<p>​\t安装完成后，需要让系统识别 ROS2 的命令，有两种配置方式：</p>\n<ol>\n<li>\n<p>临时配置（仅当前终端有效）：每次打开新终端都需要执行：</p>\n<pre><code class=\"language-bash\">source /opt/ros/jazzy/setup.bash\n</code></pre>\n</li>\n<li>\n<p>永久配置（写入配置文件）：将配置写入 <code>~/.bashrc</code>，每次打开终端自动生效：</p>\n<pre><code class=\"language-bash\">echo \"source /opt/ros/jazzy/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc # 立即生效\n</code></pre>\n</li>\n</ol>\n<h2 id=\"5-验证安装\">5. 验证安装</h2>\n<h3 id=\"1检查-ros2-版本\">（1）检查 ROS2 版本</h3>\n<pre><code class=\"language-bash\">ros2 --version\n</code></pre>\n<p>​\t如果输出类似 <code>ros2 jazzy</code> 的版本信息，说明基础安装成功。</p>\n<h3 id=\"2运行示例测试\">（2）运行示例测试</h3>\n<p>​\t打开两个终端：</p>\n<p>​\t终端 1 运行 ROS2 的示例话题发布节点：</p>\n<pre><code class=\"language-bash\">ros2 run demo_nodes_cpp talker\n</code></pre>\n<p>​\t终端 2 运行示例话题订阅节点：</p>\n<pre><code class=\"language-bash\">ros2 run demo_nodes_cpp listener\n</code></pre>\n<p>​\t如果终端 2 能看到终端 1 发布的 <code>Hello World</code> 信息，说明 ROS2 完整运行。</p>\n<h2 id=\"6-安装额外开发工具\">6. 安装额外开发工具</h2>\n<p>​\t有许多 ROS 开发中常用的开发工具可能并不在 ROS2 的安装包里，需要额外安装，比如 colcon。colcon 并不是 ROS2 安装包的默认组件，需要单独安装：</p>\n<pre><code class=\"language-bash\"># 安装 colcon 核心扩展包（ROS2 官方推荐）\nsudo apt install -y python3-colcon-common-extensions\n</code></pre>\n<p>​\trosdep也是：</p>\n<pre><code class=\"language-bash\">sudo apt install -y python3-rosdep\n# 初始化rosdep（解决依赖查找问题）\nsudo rosdep init\nrosdep update\n</code></pre>\n\n\n</div>\n<div id=\"MySignature\">\n    靡不有初，鲜克有终\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 23:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/pycr\">pycr</a>&nbsp;\n阅读(<span id=\"post_view_count\">114</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "凸优化数学基础笔记（三）：方向导数、梯度向量",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19621942",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19621942\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 20:18\">\n    <span>凸优化数学基础笔记（三）：方向导数、梯度向量</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        ​ 所谓方向导数的概念是作为偏导数的概念的前瞻数学概念而引入的，是矩阵微分的重要概念，其主要研究多元函数在变量空间沿任意方向的变化率。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1方向导数及曲线弧线导数\">1.方向导数及曲线弧线导数</h2>\n<p>​       所谓方向导数的概念是作为偏导数的概念的前瞻数学概念而引入的，是矩阵微分的重要概念，其主要研究多元函数在变量空间沿任意方向的变化率。</p>\n<p>​       <strong>Definition 1</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow\\mathbf{R}\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处可微，<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 是固定不变的非零向量，<span class=\"math inline\">\\(\\mathbf{e}\\)</span> 是方向<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 上的单位向量，则称极限</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X_0})}}{\\part{\\mathbf{P}}}=\\lim_{t\\rightarrow{0}^{+}}\\frac{f(\\mathbf{X}_0+t\\mathbf{e})-f(\\mathbf{X}_0)}{t} \\tag{1}\n\\]</div><p></p><p>为函数<span class=\"math inline\">\\(f(\\mathbf{X}_0)\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向的方向导数，式中<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X_0})}}{\\part{\\mathbf{P}}}\\)</span> 是其简单记。</p>\n<p>​       <strong>Definition 2</strong>  设<span class=\"math inline\">\\(f:\\mathbf{R}^{n}\\rightarrow\\mathbf{R}\\)</span> 是连续函数，<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>，<span class=\"math inline\">\\(\\mathbf{P}\\in\\mathbf{R}^n\\)</span>，且<span class=\"math inline\">\\(\\mathbf{P}\\neq{\\mathbf{0}}\\)</span>，若有存在<span class=\"math inline\">\\(\\delta&gt;0\\)</span>。当<span class=\"math inline\">\\(t\\in(0,\\delta)\\)</span> 时都有<span class=\"math inline\">\\(f(\\mathbf{X_0}+t\\mathbf{P})&lt;f(\\mathbf{X}_0)\\)</span> ，则称<span class=\"math inline\">\\(\\mathbf{P}\\)</span>为<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的下降方向。若<span class=\"math inline\">\\(f(\\mathbf{X}_0+t\\mathbf{P})&gt;f(\\mathbf{X}_0)\\)</span> ，则称<span class=\"math inline\">\\(\\mathbf{P}\\)</span>为<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处的上升方向。</p>\n<p>​       由此以上的两个定义可立刻得到如下的结论：</p>\n<ol>\n<li>若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}&lt;0\\)</span>，则多元函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 从<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 附近沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向是下降的；</li>\n<li>若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P_0}}}&gt;0\\)</span>，则多元函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 从<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 附近沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向是上升的；</li>\n</ol>\n<p>​      事实上，若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}&lt;0\\)</span>，则当<span class=\"math inline\">\\(\\exist t&gt;0\\)</span> ,必有如下的充分小，根据上式Definition必有如下表达：</p>\n<p></p><div class=\"math display\">\\[\\frac{f(\\mathbf{X}_0+t\\mathbf{e})-f(\\mathbf{X}_0)}{t}&lt;0 \\tag{2}\n\\]</div><p></p><p>即可得：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X})&lt;f(\\mathbf{X}_0)  \\tag{3}\n\\]</div><p></p><p>其中：<span class=\"math inline\">\\(\\mathbf{X}=\\mathbf{X}_0+t\\mathbf{e}\\)</span> 是从 <span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向上的点，说明<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 方向上是下降的点；同理可以说明，<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> ，则<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span>是上升的。</p>\n<p>​       在直角坐标系中，方向导数有如下定理给出的计算公式，以空间三维函数为例。</p>\n<p>​       <strong>定理 1</strong> 若三维多元函数<span class=\"math inline\">\\(f=f(x,y,z)\\)</span>在点<span class=\"math inline\">\\(M_0(x_0,y_0,z_0)\\)</span>处可微，<span class=\"math inline\">\\(\\cos(\\alpha),cos(\\beta),\\cos(\\gamma)\\)</span> 以<span class=\"math inline\">\\(l\\)</span>方向的方向余弦，则函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M_0\\)</span> 处沿<span class=\"math inline\">\\(l\\)</span> 方向导数必存在，且由如下公式给出</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f}}{\\part{l}}=\\frac{\\part{f}}{\\part{x}}\\cos(\\alpha)+\\frac{\\part{f}}{\\part{y}}\\cos{(\\beta)}+\\frac{\\part{f}}{\\part{z}}\\cos{(\\gamma)}  \\tag{4}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(\\frac{\\part{f}}{\\part{x}},\\frac{\\part{f}}{\\part{y}},\\frac{\\part{f}}{\\part{z}}\\)</span> 是在点<span class=\"math inline\">\\(M_0\\)</span> 处的偏导数。</p>\n<p><strong>证   明：</strong> 设在<span class=\"math inline\">\\(M_0(x,y,z)\\)</span>的<span class=\"math inline\">\\(\\delta-\\)</span>领域内存在动点<span class=\"math inline\">\\(M\\)</span>的坐标为<span class=\"math inline\">\\(M(x_0+\\Delta{x},y_0+\\Delta{y},z_0+\\Delta{z})\\)</span> 。因为<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M_0\\)</span> 可微，故有</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n \\Delta{f}&amp;=f(\\mathbf{M})-f(\\mathbf{M_0}) \\\\\n   &amp;=\\frac{\\part{f}}{\\part{x}}\\Delta{x}+\\frac{\\part{f}}{\\part{y}}\\Delta{y}+\\frac{\\part{f}}{\\part{z}}\\Delta{z}+o(r)\n   \n\\end{aligned}\n\\tag{5}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(r=\\sqrt{\\Delta{x}^2+\\Delta{y}^2+\\Delta{z}^2}\\)</span>， 将上式除以<span class=\"math inline\">\\(r\\)</span>:</p>\n<p></p><div class=\"math display\">\\[\\frac{\\Delta{f}}{r}=\\frac{\\part{f}}{\\part{x}}\\frac{\\Delta{x}}{r}+\\frac{\\part{f}}{\\part{y}}\\frac{\\Delta{y}}{r}+\\frac{\\part{f}}{\\part{z}}\\frac{\\Delta{z}}{r}+\\frac{o(r)}{r} \\tag{6}\n\\]</div><p></p><p>当<span class=\"math inline\">\\(r\\rightarrow{0}\\)</span> ,结合切线的定义可得：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f}}{\\part{l}}=\\frac{\\part{f}}{\\part{x}}\\cos{\\alpha}+\\frac{\\part{f}}{\\part{y}}\\cos{\\beta}+\\frac{\\part{f}}{\\part{z}}\\cos{\\gamma} \\tag{7}\n\\]</div><p></p><p>​        <strong>定理2</strong>   若存在有向曲线<span class=\"math inline\">\\(C\\)</span>上取一定的<span class=\"math inline\">\\(M_0\\)</span> ，作为计算弧长<span class=\"math inline\">\\(s\\)</span>的起点，并以<span class=\"math inline\">\\(C\\)</span>之正向作为<span class=\"math inline\">\\(s\\)</span>增大的方向；<span class=\"math inline\">\\(M\\)</span>为<span class=\"math inline\">\\(C\\)</span> 上的一点，在点<span class=\"math inline\">\\(M\\)</span> 处沿<span class=\"math inline\">\\(C\\)</span>之正向作一与<span class=\"math inline\">\\(C\\)</span>的相切射线<span class=\"math inline\">\\(l\\)</span>，则在点<span class=\"math inline\">\\(M\\)</span>处，当函数<span class=\"math inline\">\\(u\\)</span> 沿<span class=\"math inline\">\\(l\\)</span> 方向的方向导数就等于函数<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数，既有下式成立：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{\\part{u}}{\\part{s}} \\tag{8}\n\\]</div><p></p><p><strong>证  明：</strong> 设曲线<span class=\"math inline\">\\(C\\)</span>以<span class=\"math inline\">\\(s\\)</span>为参数的参数方程为：</p>\n<p></p><div class=\"math display\">\\[x=x(s),y=y(s),z=z(s) \\tag{9}\n\\]</div><p></p><p>则沿曲线<span class=\"math inline\">\\(C\\)</span>,函数</p>\n<p></p><div class=\"math display\">\\[u=u[x(s),y(s),z(s)] \\tag{10}\n\\]</div><p></p><p>又由于在点<span class=\"math inline\">\\(M\\)</span>处，函数<span class=\"math inline\">\\(u\\)</span>的可微、曲线<span class=\"math inline\">\\(C\\)</span>光滑，按照复合函数求导定理，得到<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数：</p>\n<p></p><div class=\"math display\">\\[\\frac{du}{ds}=\\frac{\\part{u}}{\\part{x}}\\frac{dx}{ds}+\\frac{\\part{u}}{\\part{y}}\\frac{dy}{ds}+\\frac{\\part{u}}{\\part{z}}\\frac{d{z}}{ds} \\tag{11}\n\\]</div><p></p><p>注意到<span class=\"math inline\">\\(\\frac{dx}{ds},\\frac{dy}{ds},\\frac{dz}{ds}\\)</span> 是曲线<span class=\"math inline\">\\(C\\)</span>的正方向切线<span class=\"math inline\">\\(l\\)</span>的方向余弦，若将其写成<span class=\"math inline\">\\(\\cos{(\\alpha)},\\cos{(\\beta)},\\cos{(\\gamma)}\\)</span> ，即得到<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数：</p>\n<p></p><div class=\"math display\">\\[\\frac{du}{ds}=\\frac{\\part{u}}{\\part{s}}\\cos(\\alpha)+\\frac{\\part{u}}{\\part{s}}\\cos(\\beta)+\\frac{\\part{u}}{\\part{s}}\\cos{(\\gamma)} \\tag{12}\n\\]</div><p></p><p>即知道，</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{du}{ds} \\tag{13}\n\\]</div><p></p><p>上面讲的是函数 <span class=\"math inline\">\\(u\\)</span>沿直线的方向导数。此外，有时还需要研究函数<span class=\"math inline\">\\(u\\)</span>沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数，其定义的如下：</p>\n<p>​       <strong>Definition 3</strong> 从点<span class=\"math inline\">\\(M\\)</span>出发沿<span class=\"math inline\">\\(C\\)</span>之正向取一点<span class=\"math inline\">\\(M_1\\)</span>, 记弧长 <span class=\"math inline\">\\(\\overset{\\LARGE{\\frown}}{MM_1}=\\Delta{s}\\)</span> ，若当<span class=\"math inline\">\\(M_1\\rightarrow{M}\\)</span>时，比式</p>\n<p></p><div class=\"math display\">\\[\\frac{\\Delta{u}}{\\Delta{s}}=\\frac{u(M_1)-u(M)}{|\\overset{\\LARGE{\\frown}}{MM_1}|} \\tag{14}\n\\]</div><p></p><p>的极限存在，则称此极限为函数<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M\\)</span>处沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数，记作<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span>，即：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds} \\tag{15}\n\\]</div><p></p><p><strong>定 理3</strong>  若在点<span class=\"math inline\">\\(M\\)</span>处函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M\\)</span> 处沿函数<span class=\"math inline\">\\(\\mathbf{C}\\)</span> (正向)的方向导数，记作<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span> ，则有</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds} \\tag{16}\n\\]</div><p></p><p><strong>证   明</strong>：由于在点<span class=\"math inline\">\\(M\\)</span>处函数<span class=\"math inline\">\\(u\\)</span> 可微，曲线<span class=\"math inline\">\\(C\\)</span>光滑，故有全导数<span class=\"math inline\">\\(\\frac{du}{ds}\\)</span>存在。而<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span> 按照定义实际上的是一个右极限</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\lim_{\\Delta{t}\\rightarrow{0}}\\frac{\\Delta{u}}{\\Delta{s}} \\tag{17}\n\\]</div><p></p><p>故当<span class=\"math inline\">\\(\\frac{du}{ds}=\\lim_{\\Delta{t}\\rightarrow{0}}\\frac{\\Delta{u}}{\\Delta{s}}\\)</span> 存在时，就有<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds}\\)</span>.</p>\n<p><strong>推  论</strong>：若在点<span class=\"math inline\">\\(\\mathbf{M}\\)</span>处函数<span class=\"math inline\">\\(u\\)</span> 可微、曲线<span class=\"math inline\">\\(C\\)</span>光滑，则有：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{\\part{u}}{\\part{l}} \\tag{18}\n\\]</div><p></p><p>换而言之：函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M\\)</span>处沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数与函数<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M\\)</span> 处沿切线方法（指向<span class=\"math inline\">\\(C\\)</span>的正向一侧）的方向导数相等。</p>\n<h2 id=\"2-梯度向量\">2. 梯度向量</h2>\n<p>​        方向导数解决了多元变量数性函数<span class=\"math inline\">\\(u(\\mathbf{M})\\)</span> 在给定点处沿某个方向的变化率描述问题，然而从变量空间中的定义点出发，有无穷多个方向，那么函数<span class=\"math inline\">\\(u(\\mathbf{M})\\)</span> 沿其中哪个方向的变化率最大？最大的变化率又是多少呢? 在科学技术中常常需要讨论的问题，为了解决这个问题，那么我们从方向导数计算公式（12）出发：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{\\part{u}}{\\part{x}}\\cos{\\alpha}+ \\frac{\\part{u}}{\\part{y}}\\cos{\\beta}+\\frac{\\part{u}}{\\part{z}}\\cos{\\gamma} \\tag{19}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(\\cos{\\alpha},\\cos{\\beta},\\cos{\\gamma}\\)</span> 为<span class=\"math inline\">\\(l\\)</span>方向的方向余弦，也就是这个方向上的单位矢量 <span class=\"math inline\">\\(\\boldsymbol{l}=\\cos{\\alpha}\\boldsymbol{i}+\\cos{\\beta}\\boldsymbol{j}+\\cos{\\gamma}\\boldsymbol{k}\\)</span> 的坐标，若把公式（19）右端可以写为<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 与<span class=\"math inline\">\\(\\boldsymbol{l}\\)</span> 的数量积：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\mathbf{G}\\cdot\\boldsymbol{l}=|\\mathbf{G}|\\cos(\\mathbf{G},\\boldsymbol{l}) \\tag{20}\n\\]</div><p></p><p>显然，<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 在给定点的处为一固定矢量，上式表示：<span class=\"math inline\">\\(\\mathbf{G}\\)</span>在<span class=\"math inline\">\\(l\\)</span>方向上的投影正好等于函数<span class=\"math inline\">\\(u\\)</span>在该方向上的方向导数，因此，当方向<span class=\"math inline\">\\(l\\)</span>与<span class=\"math inline\">\\(\\mathbf{G}\\)</span>的方向一致时，即<span class=\"math inline\">\\(cos(\\mathbf{G},\\boldsymbol{l})=1\\)</span> 时，方向导数取得最大值，其值为：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=|\\mathbf{G}| \\tag{21}\n\\]</div><p></p><p>由此可知，矢量<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 的方向就是函数<span class=\"math inline\">\\(u(M)\\)</span> 变化率最大的方向，其模也正好是这个最大变化率的数值。我们把<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 叫做函数<span class=\"math inline\">\\(u(M)\\)</span> 在给定点处的梯度。一般，有如下的定义。</p>\n<p><strong>Definition 4</strong>  以<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 的<span class=\"math inline\">\\(n\\)</span> 个偏导数为分量的向量称为<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 处的梯度，记为：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left[\\frac{\\part{f}}{\\part{x_1}},\\frac{\\part{f}}{\\part{x_2}},\\frac{\\part{f}}{\\part{x_3}},...,\\frac{\\part{f}}{\\part{x_n}}\\right]^T \\tag{22}\n\\]</div><p></p><p>梯度也可以称为函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于向量<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的一阶导数。</p>\n<p>由此，可以从定义给出梯度与方向导数之间的关系。</p>\n<p><strong>定 理 4</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow{\\mathbf{R}}\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处可微，则方向导数与梯度关系：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}=\\nabla{f(\\mathbf{X}_0)}^T\\mathbf{e} \\tag{23}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(\\mathbf{e}\\)</span> 是<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向上的单位向量。</p>\n<p>​\t由这个定理容易得到下列结论：</p>\n<p>​\t（1）若<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X}_0)^T\\mathbf{P}}&lt;0\\)</span>，则<span class=\"math inline\">\\(P\\)</span>的方向是函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的下降方向。</p>\n<p>​\t（2）若<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X}_0)}^T\\mathbf{P}&gt;0\\)</span> , 则<span class=\"math inline\">\\(P\\)</span>的方向是函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的上升方向。</p>\n<p>方向导数的正负决定了函数值的升降，而升降的快慢就由它的绝对值大小决定。绝对值越大，升降的速度就越快。根据式（19）到式（22）即：</p>\n<p></p><div class=\"math display\">\\[\\left|\\frac{\\part{f(X_0)}}{\\part{\\mathbf{P}}}\\right|=|\\nabla f(\\mathbf{X}_0)^T\\mathbf{e}|= |\\nabla{{f}(\\mathbf{X}_0)}|\\cdot|\\cos(\\nabla{f(\\mathbf{X}_0)},\\mathbf{e})|\\leq |\\nabla f(\\mathbf{X}_0)| \\tag{24} \n\\]</div><p></p><p>上式中的等号，当且仅当<span class=\"math inline\">\\(\\mathbf{e}\\)</span>的方向与<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X_0})}\\)</span> 的方向共线才成立。由此可知，得到如下重要结论：</p>\n<ol>\n<li>梯度向量是函数值的最速上升方向；</li>\n<li>函数在其梯度正交的方向上的变化率为零；</li>\n<li>函数在与其梯度成锐角方向上是上升的，而在成钝角的方向是下降的；</li>\n<li>梯度的反向是函数值最速下降方法；</li>\n</ol>\n<p>对于一个最优化问题，为了尽快得到最优解，在每一步迭代过程中选取的搜索方向<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 总是希望它等于或者是靠近于目标函数的负梯度（即<span class=\"math inline\">\\(-\\nabla{f(\\mathbf{X})}\\)</span>）的方向，这样才能使函数值下降的最快。</p>\n<p>梯度的性质及以下几个特殊类型的函数的常用梯度公式：</p>\n<p>（1）若 <span class=\"math inline\">\\(f(\\mathbf{X})=c\\)</span> (c为常数)，则 <span class=\"math inline\">\\(\\nabla f(\\mathbf{X})=0\\)</span>，即 <span class=\"math inline\">\\(\\nabla{c}=0\\)</span>;</p>\n<p>（2）<span class=\"math inline\">\\(\\nabla(cf(\\mathbf{x}))=c\\nabla(f(\\mathbf{x}))\\)</span> （其中<span class=\"math inline\">\\(c\\)</span>为常数）；</p>\n<p>（3）<span class=\"math inline\">\\(\\nabla(u\\pm v)=\\nabla(u)\\pm\\nabla(v)\\)</span>;</p>\n<p>(4) <span class=\"math inline\">\\(\\nabla(uv)=u\\nabla(v)+v\\nabla(u)\\)</span></p>\n<p>(5) <span class=\"math inline\">\\(\\nabla{\\frac{u}{v}}=\\frac{1}{v^2}(v\\nabla{u}-u\\nabla{v})\\)</span></p>\n<p>(6) <span class=\"math inline\">\\(\\nabla f(u)=f^{\\prime}(u)\\nabla{u}\\)</span></p>\n<p>（7）<span class=\"math inline\">\\(\\nabla(f(u,v))=\\frac{\\part{f}}{\\part{u}}\\nabla(u)+\\frac{\\part{f}}{\\part{v}}\\nabla{v}\\)</span></p>\n<p>(8) <span class=\"math inline\">\\(\\nabla{\\mathbf{b}^T\\mathbf{X}}=\\mathbf{b}\\)</span></p>\n<p>(9) <span class=\"math inline\">\\(\\nabla(\\mathbf{X}^T\\mathbf{X})=2\\mathbf{X}\\)</span></p>\n<p>(10) 若 <span class=\"math inline\">\\(Q\\)</span> 是对称矩阵矩阵，则 <span class=\"math inline\">\\(\\nabla(\\mathbf{X}^T\\mathbf{Q}\\mathbf{X})=2\\mathbf(QX)\\)</span></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 20:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">62</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}