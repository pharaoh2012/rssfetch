{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "3年，从0到全球领跑：万字长文拆解DeepSeek大模型技术演进",
      "link": "https://www.cnblogs.com/aifrontiers/p/19608897",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/aifrontiers/p/19608897\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 16:15\">\n    <span>3年，从0到全球领跑：万字长文拆解DeepSeek大模型技术演进</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>原文: <a href=\"https://mp.weixin.qq.com/s/MG9nB7VYK-N4Q3RQFiwcuw\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/MG9nB7VYK-N4Q3RQFiwcuw</a></p>\n<p>关注gzh: AI-Frontiers</p>\n<p>自2022年chatgpt发布以来，全球人工智能领域进入了以大语言模型（LLM）为核心的激烈军备竞赛。OpenAI、Google、Anthropic等硅谷巨头，通过数百亿美元的资本投入和数万张H100GPU的算力堆叠，不断刷新着模型智能的上限。在这种大力出奇迹（Scaling Laws）的主流叙事下，算力成为了制约模型发展的核心硬通货，也构建了极高的行业准入门槛。</p>\n<p>不同于国外通过堆砌硬件来解决问题的传统路径，中国杭州的AI初创公司Deepseek，走出了一条截然不同的技术演进路线，即对极致效率的追求和对算法边界的探索，其技术哲学可以概括为「算法-硬件协同优化的极致主义」。</p>\n<p>DeepSeek作为一家源自量化对冲基金High-Flyer的AI研究机构，成立于2023年，在短短三年内从跟随者迅速蜕变为全球大模型架构创新的引领者。其技术路线展现出鲜明的长期主义与极致效率特征，通过在模型架构、推理算法、多模态及训练基础设施四个维度的持续突破，成功重塑了开源大模型的性能天花板。</p>\n<p>DeepSeek的技术演进可清晰地划分为四个阶段：</p>\n<ul>\n<li>\n<p><strong>基石奠定模型（2023年）：</strong> 以DeepSeek-Coder和DeepSeek-LLM为代表，验证了在有限算力下训练高质量稠密模型的能力，确立了「代码+数学」为核心竞争力的差异化路线。</p>\n</li>\n<li>\n<p><strong>架构革新与<strong><strong>MOE</strong></strong>化（2024年）：</strong> 通过DeepSeek-V2和V3，在大模型架构底层进行了革命性创新。提出了多头潜在注意力和细粒度专家混合架构，彻底解决了长上下文推理的显存瓶颈与训练成本问题，以极低的成本实现了对标顶尖闭源模型GPT-4 Turbo的效果。</p>\n</li>\n<li>\n<p><strong>推理与系统2思维（2025年）：</strong> 以DeepSeek-R1为里程碑，探索出纯强化学习驱动的推理能力涌现路径，证明了无需大规模监督微调，即可激发模型的自我反思与修正能力。随后通过V3.1、V3.2系列将这种「思考」能力泛化至工具调用与Agent场景。</p>\n</li>\n<li>\n<p><strong>记忆与因果视觉（2025末-2026初）：</strong> 在DeepSeek-OCR-2中引入视觉因果流，在Engram架构中提出基于查表的可扩展条件记忆机制，试图从根本上突破Transformer的上下文长度限制与视觉理解的逻辑缺陷，为下一代模型DeepSeek-V4奠定基础。</p>\n</li>\n</ul>\n<p>官网发布信息，见：<a href=\"https://api-docs.deepseek.com/news/news251201\" rel=\"noopener nofollow\" target=\"_blank\">https://api-docs.deepseek.com/news/news251201</a></p>\n<h1 id=\"tl-dr总结版\">TL; DR（总结版）</h1>\n<h2 id=\"deepseek模型演进时间线汇总2023-20260210\">DeepSeek模型演进时间线汇总（2023-2026.02.10）</h2>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>发布日期</td>\n<td>模型名称</td>\n<td>核心参数/架构</td>\n<td>关键技术创新</td>\n<td>对标/性能亮点</td>\n</tr>\n<tr>\n<td>2023/11/2</td>\n<td>DeepSeek Coder</td>\n<td>1.3B/6.7B/33B</td>\n<td>FIM预训练, 项目级上下文</td>\n<td>代码能力超越CodeLlama-34B</td>\n</tr>\n<tr>\n<td>2023/11/29</td>\n<td>DeepSeek LLM</td>\n<td>7B/67B</td>\n<td>稠密架构, 中英双语对齐</td>\n<td>67B打破LLaMA 2 70B垄断</td>\n</tr>\n<tr>\n<td>2023/12/18</td>\n<td>DreamCraft3D</td>\n<td>N/A</td>\n<td>3D一致性生成</td>\n<td>高质量文生3D资产</td>\n</tr>\n<tr>\n<td>2024/2/5</td>\n<td>DeepSeek-Math</td>\n<td>7B</td>\n<td>GRPO强化学习, 拒绝采样</td>\n<td>数学能力逼近GPT-4，RL技术验证</td>\n</tr>\n<tr>\n<td>2024/3/11</td>\n<td>DeepSeek-VL</td>\n<td>1.3B/7B</td>\n<td>混合视觉编码器</td>\n<td>真实世界视觉理解，高分辨率处理</td>\n</tr>\n<tr>\n<td>2024/5/7</td>\n<td>DeepSeek-V2</td>\n<td>236B (21B激活)</td>\n<td>MLA, DeepSeekMoE</td>\n<td>重新定义MoE架构，显存占用降93%</td>\n</tr>\n<tr>\n<td>2024/6/17</td>\n<td>DeepSeek-Coder-V2</td>\n<td>16B/236B</td>\n<td>MoE for Code, 338种语言</td>\n<td>开源模型首次在代码领域对齐GPT-4 Turbo</td>\n</tr>\n<tr>\n<td>2024/9/6</td>\n<td>DeepSeek-V2.5</td>\n<td>236B</td>\n<td>Chat与Coder合并</td>\n<td>通用与垂类能力统一，硬盘缓存API</td>\n</tr>\n<tr>\n<td>2024/10/18</td>\n<td>Janus</td>\n<td>1.3B</td>\n<td>视觉理解/生成解耦</td>\n<td>解决多模态理解与生成的冲突</td>\n</tr>\n<tr>\n<td>2024/12/13</td>\n<td>DeepSeek-VL2</td>\n<td>1B/2.8B/4.5B (激活)</td>\n<td>MoE多模态, 动态分辨率</td>\n<td>提升OCR与图表理解能力</td>\n</tr>\n<tr>\n<td>2024/12/26</td>\n<td>DeepSeek-V3</td>\n<td>671B (37B激活)</td>\n<td>FP8训练, MTP, 无损负载均衡</td>\n<td>557万美元练出GPT-4o级模型，开源新基座</td>\n</tr>\n<tr>\n<td>2025/1/20</td>\n<td>DeepSeek-R1</td>\n<td>671B</td>\n<td>纯RL训练, 思维链涌现, 蒸馏</td>\n<td>Aha Moment，开启推理大模型时代</td>\n</tr>\n<tr>\n<td>2025/1/27</td>\n<td>Janus-Pro</td>\n<td>1B/7B</td>\n<td>多模态Scaling</td>\n<td>更强的文生图与指令遵循</td>\n</tr>\n<tr>\n<td>2025/5/1</td>\n<td>DeepSeek-Prover-V2</td>\n<td>671B</td>\n<td>形式化证明 (Lean 4)</td>\n<td>解决数学证明步骤分解问题</td>\n</tr>\n<tr>\n<td>2025/8/21</td>\n<td>DeepSeek-V3.1</td>\n<td>671B</td>\n<td>混合思维模式, Agent优化</td>\n<td>将R1的思考能力泛化至Agent任务</td>\n</tr>\n<tr>\n<td>2025/12/1</td>\n<td>DeepSeek-V3.2</td>\n<td>671B</td>\n<td>DeepSeek Sparse Attention (DSA)</td>\n<td>长上下文效率突破，Thinking in Tool-Use</td>\n</tr>\n<tr>\n<td>2026/1/3</td>\n<td>mHC</td>\n<td>N/A</td>\n<td>引入几何约束</td>\n<td>超大规模模型的信号发散与训练不稳定性</td>\n</tr>\n<tr>\n<td>2026/1/14</td>\n<td>Engram (论文)</td>\n<td>N/A</td>\n<td>可扩展查表记忆</td>\n<td>解决超长上下文记忆遗忘问题</td>\n</tr>\n<tr>\n<td>2026/1/27</td>\n<td>DeepSeek-OCR-2</td>\n<td>3B</td>\n<td>视觉因果流</td>\n<td>模拟人类阅读顺序，极致文档理解</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"deepseek模型功能分类汇总\">DeepSeek模型功能分类汇总</h2>\n<p><img alt=\"image\" class=\"lazyload\" /><br />\n<img alt=\"8b843b06359b40d7ba1a91a59a820af1\" class=\"lazyload\" /></p>\n<h1 id=\"2023年基石奠定与稠密模型时代\">2023年：基石奠定与稠密模型时代</h1>\n<p>2023年是大模型爆发的元年。在LLaMA等开源模型引发「百模大战」的背景下，DeepSeek并未急于发布对话模型，而是敏锐地选择了代码作为切入点，基于两个核心判断：① 代码数据具有极强的逻辑性，是提升模型推理能力的最佳语料；② 代码生成是开发者最高频的刚需，且当时开源界尚缺乏能真正对标OpenAI Codex的模型。</p>\n<h2 id=\"deepseek-coder代码智能的崛起\">DeepSeek Coder：代码智能的崛起</h2>\n<ul>\n<li>\n<p>发布时间: 2023年11月2日</p>\n</li>\n<li>\n<p>核心定位： 垂类代码大模型</p>\n</li>\n<li>\n<p>技术创新： Fill-In-the-Middle (FIM) / Project-Level Context</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2401.14196\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2401.14196</a></p>\n</li>\n<li>\n<p>gitbub：<a href=\"https://github.com/deepseek-ai/DeepSeek-Coder\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-Coder</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek Coder是DeepSeek推出的首个具有广泛影响力的模型系列，包含1.3B、6.7B、33B等多种尺寸。该系列模型并非简单的微调，而是从零开始预训练。</p>\n<ul>\n<li>\n<p><strong>数据构成与训练策略：</strong> 模型使用了2万亿（2T）Token的高质量数据进行训练，其中87%为代码，13%为中英文自然语言。这种配比确保了模型既具备深厚的编程知识，又拥有流畅的指令遵循能力 。</p>\n</li>\n<li>\n<p><strong>架构亮点：</strong></p>\n<ul>\n<li>\n<p><strong>Fill-In-the-Middle (FIM)：</strong> 为了适应IDE中的代码补全场景，DeepSeek Coder在预训练阶段引入了FIM任务，即让模型根据上下文填补中间缺失的代码片段。这一能力使其在实际编程辅助中表现远超仅支持「从左到右」生成的模型。</p>\n</li>\n<li>\n<p><strong>项目级上下文（Project-Level Context）：</strong> 模型支持16K的上下文窗口，能够理解跨文件的代码依赖关系，这在当时是开源代码模型中的领先水平。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现：</strong> 在HumanEval和MBPP等基准测试中，DeepSeek Coder 33B不仅超越了同量级的CodeLlama-34B，甚至在部分指标上逼近了GPT-3.5 Turbo，确立了DeepSeek在代码领域的领先地位。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-llm-67b通用能力的全面对标\">DeepSeek LLM (67B)：通用能力的全面对标</h2>\n<ul>\n<li>\n<p>发布时间： 2023年11月29日</p>\n</li>\n<li>\n<p>核心定位： 通用稠密大模型</p>\n</li>\n<li>\n<p>技术创新： 中英双语对齐/规模化训练稳定性</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2401.02954\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2401.02954</a></p>\n</li>\n<li>\n<p>github：<a href=\"https://github.com/deepseek-ai/DeepSeek-LLM\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-LLM</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>在代码模型取得成功后，DeepSeek迅速发布了通用大模型DeepSeek LLM 67B。这是中国首个完全开源参数量达到670亿级别的模型，直接对标Meta的LLaMA-2 70B。</p>\n<ul>\n<li>\n<p><strong>双语优势：</strong> 相比LLaMA-2主要以英语为主，DeepSeek LLM在预训练数据中大幅增加了中文语料的权重，使其在中文理解、文化常识及逻辑推理上表现出显著优势。</p>\n</li>\n<li>\n<p><strong>推理与数学能力：</strong> 继承了DeepSeek Coder的基因，DeepSeek LLM在数学推理（GSM8K）和逻辑推断任务上表现出色，证明了「代码训练提升通用推理」的假设。</p>\n</li>\n<li>\n<p><strong>开源策略：</strong> DeepSeek不仅开源了模型权重，还开放了中间检查点（Checkpoints），极大地促进了学术界对大模型训练动态的研究，展示了DeepSeek独特的开源精神，提供结果，更提供过程。</p>\n</li>\n</ul>\n<h2 id=\"dreamcraft3d多模态生成的早期探索\">DreamCraft3D：多模态生成的早期探索</h2>\n<ul>\n<li>\n<p>发布时间： 2023年12月18日</p>\n</li>\n<li>\n<p>核心定位： 文生3D内容生成</p>\n</li>\n<li>\n<p>技术创新： 3D一致性优化</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2310.16818\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2310.16818</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DreamCraft3D\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DreamCraft3D</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>除了语言模型，DeepSeek在2023年底还探索了多模态生成领域。DreamCraft3D是一个能够从文本描述生成高保真3D资产的模型。它通过解决多视角一致性问题，实现了从2D图像到3D几何的高质量转换，为后续的Janus系列奠定了多模态技术积累。</p>\n<ul>\n<li>\n<p><strong>架构亮点</strong>：</p>\n<ul>\n<li>\n<p>分层优化流水线：几何雕刻阶段融合 2D+3D 混合 SDS 损失、扩散时间步退火、渐进式视角训练等策略，从 NeuS 隐式表面表示过渡到 DMTet 网格表示，确保 3D 几何的多视角一致性；纹理增强阶段提出自举式分数蒸馏（BSD），通过交替优化 3D 场景与 DreamBooth 个性化扩散模型，实现纹理细节与视角一致性的相互强化。</p>\n</li>\n<li>\n<p>3D 感知先验融合：引入 Zero-1-to-3 视图条件扩散模型提供丰富 3D 先验，缓解单图生成的视角模糊性；利用多视图渲染增强与高斯噪声扰动，让扩散模型学习场景专属 3D 知识，突破固定分布蒸馏的局限。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现</strong>：在包含 300 张图像的测试基准上，CLIP 得分（0.896）、PSNR（31.801）和 LPIPS（0.005）均显著超越 Make-it-3D、Magic123 等主流方法；用户研究中 92% 的参与者更偏好其生成结果，在 360° 渲染中展现出更锐利的几何细节和逼真纹理，有效解决了传统模型的语义不一致问题，推进了 3D 生成的技术上限。</p>\n</li>\n</ul>\n<h1 id=\"2024年上架构革命与moemla的提出\">2024年（上）：架构革命与MoE/MLA的提出</h1>\n<p>进入2024年，大模型竞争进入深水区。随着模型参数量的膨胀，训练成本和推理显存占用成为制约发展的核心瓶颈。DeepSeek在这一阶段完成了从「架构跟随」到「架构创新」的华丽转身，提出了改变行业的MLA和DeepSeekMoE架构。</p>\n<h2 id=\"deepseek-math强化学习推理的先声\">DeepSeek-Math：强化学习推理的先声</h2>\n<ul>\n<li>\n<p>发布时间： 2024年2月5日</p>\n</li>\n<li>\n<p>核心定位： 数学推理模型</p>\n</li>\n<li>\n<p>技术创新： Group Relative Policy Optimization (GRPO)</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2402.03300\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2402.03300</a></p>\n</li>\n<li>\n<p>gitbub：<a href=\"https://github.com/deepseek-ai/DeepSeek-Math\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-Math</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-Math 7B虽然参数规模不大，但其技术意义深远。它是DeepSeek首次大规模应用强化学习（RL）来提升推理能力，并为此发明了GRPO（Group Relative Policy Optimization）算法。</p>\n<ul>\n<li>\n<p><strong>GRPO算法详解：</strong> 传统的RLHF（基于人类反馈的强化学习）通常依赖PPO算法，需要训练一个与策略模型同等大小的评论家模型，这会带来双倍的显存和计算开销。DeepSeek-Math提出的GRPO算法摒弃了评论家模型，而是通过对同一问题采样多组输出（Group Sampling），利用组内输出的相对优劣来计算优势函数。这一创新不仅大幅降低了RL训练成本，还提高了训练稳定性，为2025年DeepSeek-R1的爆发埋下了伏笔。</p>\n</li>\n<li>\n<p><strong>性能：</strong> 在MATH基准测试中，DeepSeek-Math 7B凭借GRPO和精选的数理数据，击败了众多70B级别的开源模型，甚至在部分指标上逼近GPT-4。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-vl迈向真实世界的视觉理解\">DeepSeek-VL：迈向真实世界的视觉理解</h2>\n<ul>\n<li>\n<p>发布时间： 2024年3月11日</p>\n</li>\n<li>\n<p>核心定位： 多模态理解模型</p>\n</li>\n<li>\n<p>技术创新： 混合视觉编码器（Hybrid Vision Encoder）</p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/abs/2403.05525\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2403.05525</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-VL\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-VL</a></p>\n</li>\n</ul>\n<p>DeepSeek-VL（1.3B/7B）的设计哲学是实用主义。不同于当时许多多模态模型专注于简短的看图说话，DeepSeek-VL着重于处理真实世界中的复杂视觉任务，如逻辑图表分析、网页代码转换、OCR识别等。</p>\n<ul>\n<li><strong>架构设计：</strong> 采用了混合视觉编码器架构，结合了用于提取高层语义的SigLIP和用于捕捉低层细节的SAM-B（Segment Anything Model）。这种设计使得模型在处理高分辨率（1024x1024）图像时，既能保持全局理解，又不会丢失关键的文字和细节信息。</li>\n</ul>\n<h2 id=\"deepseek-v2moe与mla的里程碑\">DeepSeek-V2：MoE与MLA的里程碑</h2>\n<ul>\n<li>\n<p>发布时间： 2024年5月</p>\n</li>\n<li>\n<p>核心定位： 经济高效的MoE通用大模型</p>\n</li>\n<li>\n<p>技术创新： Multi-Head Latent Attention (MLA) / DeepSeekMoE</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2405.04434\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2405.04434</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V2</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-V2是DeepSeek发展史上的关键转折点。它不仅是一个模型，更是一套全新的高效架构标准。</p>\n<ul>\n<li>\n<p><strong>Multi-Head Latent Attention (<strong><strong>MLA</strong></strong>)：</strong></p>\n<ul>\n<li>\n<p><strong>背景：</strong> 在长上下文推理中，KV Cache（键值缓存）会占用海量显存，限制了Batch Size和推理速度。</p>\n</li>\n<li>\n<p><strong>原理：</strong> MLA通过低秩压缩技术，将KV Cache压缩为一个潜在向量（Latent Vector），大幅减少了推理时的显存占用。</p>\n</li>\n<li>\n<p><strong>效果：</strong> 相比标准多头注意力技术，MLA将KV Cache减少了93.3%，使得DeepSeek-V2在单卡上就能支持极长的上下文窗口，并将推理吞吐量提升了5.76倍。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>DeepSeekMoE：</strong></p>\n<ul>\n<li>\n<p><strong>细粒度专家（Fin****e-grained Experts）：</strong> 不同于Mixtral等模型将FFN作为一个大专家，DeepSeekMoE将专家切分得更细，使得知识分配更加灵活。</p>\n</li>\n<li>\n<p><strong>共享专家（Share****d Experts）：</strong> 专门设置一部分专家始终处于激活状态，用于捕捉通用知识，而路由专家专注于特定领域知识。这种“共享+路由”的机制有效解决了MoE模型训练中的知识冗余和路由坍缩问题。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>综合效能：</strong> DeepSeek-V2总参数236B，激活参数仅21B，训练成本节省了42.5%，性能却超越了LLaMA 3 70B，不仅成为当时最强的开源MoE模型，更将API价格打到了白菜价1元/百万Tokens。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-coder-v2代码能力的全面爆发\">DeepSeek-Coder-V2：代码能力的全面爆发</h2>\n<ul>\n<li>\n<p>发布时间： 2024年6月17日</p>\n</li>\n<li>\n<p>核心定位： 代码MoE模型</p>\n</li>\n<li>\n<p>技术创新： 338种编程语言支持</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2406.11931\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2406.11931</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-Coder-V2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-Coder-V2</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-Coder-V2是V2架构在代码领域的延续。它在DeepSeek-V2的中间检查点基础上，额外使用了6万亿（6T）Token的高质量代码和数学数据进行持续预训练。</p>\n<ul>\n<li>\n<p><strong>多语言支持：</strong> 支持的编程语言从86种扩展到了338种，几乎覆盖了所有主流及冷门语言。</p>\n</li>\n<li>\n<p><strong>性能跃升：</strong> 首个在代码生成和数学推理能力上能与闭源模型GPT-4 Turbo一较高下的开源模型。在HumanEval、MBPP+等榜单上，其表现令人震惊，证明了MoE架构在垂类任务上的巨大潜力 。</p>\n</li>\n</ul>\n<h1 id=\"2024年下融合优化与v3的诞生\">2024年（下）：融合、优化与V3的诞生</h1>\n<p>2024年下半年，DeepSeek一方面致力于模型功能的融合与对齐，另一方面在基础设施层面进行底层优化，为V3的发布积蓄力量。</p>\n<h2 id=\"deepseek-v25chat与coder的合二为一\">DeepSeek-V2.5：Chat与Coder的合二为一</h2>\n<ul>\n<li>\n<p>发布时间： 2024年9月6日</p>\n</li>\n<li>\n<p>核心定位： 融合模型</p>\n</li>\n<li>\n<p>技术创新： 人类偏好对齐优化</p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/pdf/2405.04434\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2405.04434</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V2</a></p>\n</li>\n<li>\n<p>HuggingFace1: <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V2.5\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/deepseek-ai/DeepSeek-V2.5</a></p>\n</li>\n<li>\n<p>HuggingFace2: <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>此前，DeepSeek同时维护Chat（通用）和Coder（代码）两条产品线。DeepSeek-V2.5的发布标志着这两条路线的合并。通过精细的数据配比和强化学习对齐，V2.5在保留Coder-V2强大代码能力的同时，大幅提升了通用对话和指令遵循能力，使得用户不再需要在不同模型间切换。这一版本也引入了针对API用户的硬盘缓存（Context Caching on Disk）技术，进一步降低了使用成本 。</p>\n<ul>\n<li>\n<p><strong>数据构成与训练策略</strong>：基于8.1T高质量多源 Token 预训练（中文Token占比略高于英文），经去偏和质量筛选；通过150万会话SFT及两阶段RL对齐人类偏好，分别聚焦推理优化与多奖励信号融合。</p>\n</li>\n<li>\n<p><strong>架构亮点</strong>：</p>\n<ul>\n<li>\n<p>MLA：低秩 KV 联合压缩 + 解耦RoPE，减少93.3%KV 缓存，兼顾性能与推理效率。</p>\n</li>\n<li>\n<p>DeepSeekMoE 稀疏架构：细粒度专家分割 + 多重负载均衡策略，降低训练成本并避免路由崩溃与通信过载。</p>\n</li>\n<li>\n<p>128K 长上下文：基于YaRN方法扩展，32K训练序列实现128K稳定性能，“Needle In A Haystack” 测试表现优异。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现</strong>：在仅21B激活参数的情况下，基座模型在 MMLU、BBH 等基准跻身开源第一梯队；Chat（RL）版本 MT-Bench 8.97 分、AlpacaEval 2.0 胜率 38.9%，中文 AlignBench 7.91 分超多数闭源模型；训练成本降 42.5%，生成吞吐量提升至 5.76 倍。</p>\n</li>\n</ul>\n<h2 id=\"janus--janusflow多模态理解与生成的解耦\">Janus &amp; JanusFlow：多模态理解与生成的解耦</h2>\n<ul>\n<li>\n<p>发布时间： 2024年10月（Janus），11月（JanusFlow）</p>\n</li>\n<li>\n<p>核心定位： 统一多模态模型</p>\n</li>\n<li>\n<p>技术创新： 解耦视觉编码（Decoupling Visual Encoding）</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2410.13848\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2410.13848</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/Janus\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/Janus</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>在Janus之前，业界的多模态模型通常难以兼顾理解（看图）和生成（画图），因为两者的视觉表征需求截然不同。DeepSeek提出了Janus架构，创造性地将视觉编码解耦：</p>\n<ul>\n<li>\n<p><strong>理解路径：</strong> 使用SigLIP提取高维语义特征。</p>\n</li>\n<li>\n<p><strong>生成路径：</strong> 使用VQ Tokenizer提取离散视觉Token。 两者通过同一个Transformer基座进行处理，互不干扰。随后发布的<strong>JanusFlow</strong>更是引入了整流流（Rectified Flow）技术，替代传统的自回归生成，大幅提升了图像生成的质量和速度。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-v3定义开源新标准\">DeepSeek-V3：定义开源新标准</h2>\n<ul>\n<li>\n<p>发布时间： 2024年12月26日</p>\n</li>\n<li>\n<p>核心定位： 旗舰MoE模型</p>\n</li>\n<li>\n<p>技术创新： FP8训练/无辅助损失负载均衡/多Token预测</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2412.19437\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2412.19437</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V3\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V3</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-V3是2024年的收官之作，也是DeepSeek技术实力的集大成者。它不仅是一个模型，更是一次对AI基础设施的极限挑战。</p>\n<ul>\n<li>\n<p><strong>FP8混合精度训练：</strong> V3是全球首个在超大规模（671B参数）上成功验证FP8（8位浮点数）训练的模型。通过深度优化的FP8 GEMM内核，V3极大减少了显存带宽压力和通信开销，使得训练成本仅为557万美元（278.8万H800 GPU时），震惊了全球业界。</p>\n</li>\n<li>\n<p><strong>无辅助损失<strong><strong>负载均衡</strong></strong>（Auxiliary-Loss-Free Load Balancing）：</strong> 传统MoE依赖辅助损失（Auxiliary Loss）来强迫专家负载均衡，但会干扰模型的主任务学习。V3创新性地采用了基于偏置的动态均衡策略，在不牺牲模型性能的前提下实现了完美的负载均衡。</p>\n</li>\n<li>\n<p><strong>多Token预测（Multi-Token Prediction, MTP）：</strong> V3在训练时不再只预测下一个Token，而是同时预测后续多个Token。这种机制增加了训练信号的密度，提升了模型的长程规划能力，并支持推理时的投机解码，使生成速度提升了3倍。</p>\n</li>\n<li>\n<p><strong>DualPipe：</strong>为了解决大规模MoE训练中的跨节点通信瓶颈，DeepSeek研发了DualPipe算法，实现了计算与通信的完全重叠，将硬件利用率推向极致。</p>\n</li>\n</ul>\n<p>DeepSeek-V3在百科知识、数学、代码等维度的表现全面对标GPT-4o和Claude 3.5 Sonnet，成为当时最强的开源基座模型。</p>\n<h1 id=\"2025年上推理模型与agent的全面进化\">2025年（上）：推理模型与Agent的全面进化</h1>\n<p>2025年，DeepSeek引领了从「知识积累（System 1）」向「深度推理（System 2）」的范式转移。通过强化学习激发模型的思考能力成为这一阶段的主旋律。</p>\n<h2 id=\"deepseek-r1纯强化学习的奇点\">DeepSeek-R1：纯强化学习的奇点</h2>\n<ul>\n<li>\n<p>发布时间： 2025年1月20日</p>\n</li>\n<li>\n<p>核心定位： 推理模型（Reasoning Model）</p>\n</li>\n<li>\n<p>技术创新： 纯RL训练/思维链涌现/蒸馏</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2501.12948\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2501.12948</a></p>\n</li>\n<li>\n<p>GitHub代码：<a href=\"https://github.com/deepseek-ai/DeepSeek-R1\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-R1</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-R1的发布引发了全球范围内的「 R1时刻」。它证明了推理能力可以通过纯强化学习涌现，而无需大量的人工标注数据。</p>\n<ul>\n<li>\n<p><strong>DeepSeek-R1-Zero：</strong> R1的前身，通过在V3基座上直接应用GRPO算法进行纯RL训练。模型在训练过程中自然涌现出了自我反思、验证和长思维链（Chain-of-Thought）能力，甚至出现了「顿悟，Aha Moment」现象。虽然R1-Zero存在语言混杂和可读性差的问题，但验证了RL激发推理潜力的可行性。</p>\n</li>\n<li>\n<p><strong>DeepSeek-R1正式版：</strong> 为了解决Zero版的问题，正式版R1采用了「冷启动数据+RL」的多阶段训练管线。</p>\n<ul>\n<li>\n<p><strong>冷启动：</strong> 使用少量高质量的长思维链数据微调V3，使其学会规范的思考格式。</p>\n</li>\n<li>\n<p><strong>推理<strong><strong>RL</strong></strong>：</strong> 使用GRPO进行大规模强化学习，提升解决复杂数学和代码问题的能力。</p>\n</li>\n<li>\n<p><strong>对齐：</strong> 结合通用数据进行最终微调，兼顾推理能力与通用对话体验。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>模型蒸馏：</strong> DeepSeek不仅开源了R1（671B），还开源了利用R1生成的推理数据蒸馏出的一系列小模型：Qwen和Llama架构，1.5B-70B。这些小模型在推理能力上大幅超越了同尺寸的基座模型，甚至优于OpenAI o1-mini。</p>\n</li>\n</ul>\n<h2 id=\"janus-pro多模态的尺度定律\">Janus-Pro：多模态的尺度定律</h2>\n<ul>\n<li>\n<p>发布时间： 2025年1月27日</p>\n</li>\n<li>\n<p>核心定位： 增强版多模态模型</p>\n</li>\n<li>\n<p>技术创新： 数据与模型规模化</p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/pdf/2501.17811v1\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2501.17811v1</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/Janus\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/Janus</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>Janus-Pro是Janus架构的升级版。通过优化训练策略、扩展训练数据和增大模型参数（1B -&gt; 7B），Janus-Pro在多模态理解和文生图指令遵循能力上取得了显著提升，证明了Janus架构具有良好的Scaling Law（尺度定律）特性 。</p>\n<h2 id=\"deepseek-v31--terminusagent能力的觉醒\">DeepSeek-V3.1 &amp; Terminus：Agent能力的觉醒</h2>\n<ul>\n<li>\n<p>发布时间： 2025年8月21日（V3.1），9月22日（Terminus）</p>\n</li>\n<li>\n<p>核心定位： Agent基座模型</p>\n</li>\n<li>\n<p>技术创新： 混合思维模式/工具调用优化</p>\n</li>\n<li>\n<p>Huggingface: <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus</a></p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/pdf/2412.19437\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2412.19437</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/deepseek-v3\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/deepseek-v3</a></p>\n</li>\n</ul>\n<p>随着推理能力的成熟，DeepSeek开始探索将「思考」应用于Agent（智能体）场景。</p>\n<ul>\n<li>\n<p><strong>DeepSeek-V3.1：</strong> 引入了「DeepThink」模式，用户可以在对话中一键开启深度思考。该版本重点提升了工具使用（Tool Use）能力，使其能够处理多步复杂的Agent任务。</p>\n</li>\n<li>\n<p><strong>DeepSeek-V3.1-Terminus：</strong> 针对V3.1存在的语言混杂（中英夹杂）和Agent执行不稳定的问题进行了专项修复。Terminus版本在Code Agent和Search Agent任务上的表现更加鲁棒，SWE-bench Verified分数达到66.0，标志着DeepSeek正式进入Agent时代。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-v32--speciale稀疏注意力的突破\">DeepSeek-V3.2 &amp; Speciale：稀疏注意力的突破</h2>\n<ul>\n<li>\n<p>发布时间： 2025年12月1日</p>\n</li>\n<li>\n<p>核心定位： 长上下文Agent模型</p>\n</li>\n<li>\n<p>技术创新： DeepSeek Sparse Attention (DSA) /Thinking in Tool-Use</p>\n</li>\n<li>\n<p>论文: <a href=\"https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V3.2-Exp\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V3.2-Exp</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-V3.2着重解决了长上下文下的计算效率问题，并进一步强化了Agent的推理能力。</p>\n<ul>\n<li>\n<p><strong>DeepSeek</strong> <strong>Sparse</strong> <strong>Attention (DSA)：</strong> 一种细粒度的稀疏注意力机制。与标准全注意力相比，DSA在处理128K甚至更长上下文时，能显著降低计算复杂度和显存占用，且几乎不损失模型性能。这使得V3.2在长文档分析和RAG（检索增强生成）场景下极具优势。</p>\n</li>\n<li>\n<p><strong>Thinking in Tool-Use：</strong> V3.2不仅会思考，还能在调用工具的过程中进行思考。例如，在执行代码解释器之前，会先推演代码逻辑；在获得工具返回结果后，会再次思考下一步行动。</p>\n</li>\n<li>\n<p><strong>DeepSeek-V3.2-Speciale：</strong> 一个专为极高难度推理任务设计的版本，虽然成本较高，但在IMO 2025（国际数学奥林匹克）和IOI 2025（国际信息学奥林匹克）中均获得了金牌级表现，推理能力对标Gemini-3.0-Pro。</p>\n</li>\n</ul>\n<h1 id=\"2026年1月-2月突破记忆与视觉的极限\">2026年1月-2月：突破记忆与视觉的极限</h1>\n<p>截至发稿日，DeepSeek在保持语言模型优势的同时，开始向大模型最底层的三个痛点：记忆遗忘、视觉逻辑和Transformer底层架构，发起全面冲击。</p>\n<h2 id=\"深度解析manifold-constrained-hyper-connections-mhc\">深度解析：Manifold-Constrained Hyper-Connections (mHC)</h2>\n<ul>\n<li>\n<p>发布日期：2026年1月3日</p>\n</li>\n<li>\n<p>核心定位：超大规模模型的信号发散与训练不稳定性。</p>\n</li>\n<li>\n<p>技术创新：引入几何约束</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2512.24880\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2512.24880</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>mHC 的提出解决了困扰深度学习界十年的“深度-宽度”权衡问题。它证明了通过施加严格的几何约束，我们可以在不牺牲训练稳定性的前提下，极大地扩展模型的宽度和容量。这为 DeepSeek V4 训练万亿参数模型奠定了数学基础。</p>\n<ul>\n<li>\n<p><strong>架构亮点</strong>：</p>\n<ul>\n<li>\n<p>流形约束机制：通过Sinkhorn-Knopp算法将残差映射投影到双随机矩阵流形，恢复恒等映射特性，解决 HC 架构的训练不稳定性。</p>\n</li>\n<li>\n<p>高效基础设施优化：融合核函数减少内存带宽瓶颈，选择性重计算降低显存占用，扩展DualPipe调度实现通信与计算重叠，仅增加6.7%训练开销。</p>\n</li>\n<li>\n<p>多流残差设计：扩展残差流宽度（n=4），同时通过非负约束避免信号抵消，兼顾拓扑复杂度与传播稳定性。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现</strong>：27B 模型在BBH、DROP等8项基准中全面超越基线和HC架构，推理性能提升2.1%-2.3%；在3B到 27B规模下保持稳定性能优势，信号增益幅度从HC的3000降至1.6，大幅提升训练scalability。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-ocr-2视觉因果流\">DeepSeek-OCR-2：视觉因果流</h2>\n<ul>\n<li>\n<p>发布时间： 2026年1月27日</p>\n</li>\n<li>\n<p>核心定位： 下一代视觉理解模型</p>\n</li>\n<li>\n<p>技术创新： 视觉因果流（Visual Causal Flow）</p>\n</li>\n<li>\n<p>论文1：<a href=\"https://arxiv.org/abs/2601.20552\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2601.20552</a></p>\n</li>\n<li>\n<p>github2: <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR-2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-OCR-2</a></p>\n</li>\n<li>\n<p>论文2：<a href=\"https://arxiv.org/abs/2510.18234\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2510.18234</a></p>\n</li>\n<li>\n<p>github2: <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-OCR</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>传统的视觉编码器（如ViT）通常将图像视为无序的补丁（Patches）集合。DeepSeek-OCR-2（3B参数）颠覆了这一范式，引入了<strong>视觉因果流</strong>概念。</p>\n<ul>\n<li>\n<p><strong>核心逻辑：</strong> 强制模型按照人类的阅读顺序（如从左到右、从上到下、先标题后正文）来处理视觉信息，而不是并行处理。这种有序的因果处理方式使得模型在理解多栏排版、复杂表格、嵌套公式等文档结构时，准确率实现了质的飞跃。</p>\n</li>\n<li>\n<p><strong>性能：</strong> 尽管参数仅为3B，但在复杂文档理解任务上超越了许多百亿级模型。</p>\n</li>\n</ul>\n<h2 id=\"engram无限记忆的曙光\">Engram：无限记忆的曙光</h2>\n<ul>\n<li>\n<p>发布时间： 2026年1月14日（论文发布）</p>\n</li>\n<li>\n<p>核心定位： 新型记忆架构研究</p>\n</li>\n<li>\n<p>技术创新： 可扩展查表条件记忆（Conditional Memory via Scalable Lookup）</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2601.07372\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2601.07372</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/Engram\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/Engram</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>Transformer的注意力机制虽然强大，但其计算复杂度随长度呈二次方增长，限制了上下文的无限扩展。DeepSeek提出了<strong>Engram</strong>架构。</p>\n<ul>\n<li>\n<p><strong>原理：</strong> 放弃了让模型时刻记住所有信息，而是建立了一个外挂的静态N-gram记忆库。模型通过高效的查表机制（Lookup）按需检索记忆，并将其与当前的动态隐藏状态融合。</p>\n</li>\n<li>\n<p><strong>意义：</strong> 这种设计将记忆存储从昂贵的GPU显存转移到了廉价的CPU内存甚至硬盘上，理论上可以支持无限的上下文长度，为处理代码库级别的超长任务扫清了障碍。这也是即将发布的DeepSeek-V4的核心技术储备 ()。</p>\n</li>\n</ul>\n<h1 id=\"基础设施与生态护城河\">基础设施与生态护城河</h1>\n<p>DeepSeek 的成功离不开其底层基础设施的极致优化。这些工具库均已开源，构成了其技术护城河。</p>\n<ul>\n<li>\n<p><strong>DeepGEMM</strong>：专为FP8优化的矩阵乘法库，支持细粒度缩放（Fine-grained Scaling），是V3/V4高效训练的基石。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/DeepGEMM\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepGEMM</a></li>\n</ul>\n</li>\n<li>\n<p><strong>FlashMLA</strong>：针对Hopper架构 GPU 优化的 MLA 解码内核，极大提升了推理吞吐量。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/FlashMLA\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/FlashMLA</a></li>\n</ul>\n</li>\n<li>\n<p><strong>DeepEP</strong>：高效的专家并行（Expert Parallel）通信库，解决了MoE模型中专家路由带来的巨大通信开销。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/DeepEP\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepEP</a></li>\n</ul>\n</li>\n<li>\n<p><strong>DualPipe</strong>：双向流水线并行算法，实现了计算与通信的完美重叠（Overlap）。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/DualPipe\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DualPipe</a></li>\n</ul>\n</li>\n<li>\n<p><strong>3FS</strong>：高性能分布式文件系统，专为 AI 训练的海量数据吞吐设计。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/3FS\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/3FS</a></li>\n</ul>\n</li>\n</ul>\n<p>从2023年到2026年，DeepSeek走过了一条从跟随者到颠覆者的道路。如果说V2和V3是通过工程极致优化（MLA, FP8, MoE）来打破算力垄断，那么2026年mHC和Engram的提出，则标志着DeepSeek开始触碰深度学习的理论天花板。</p>\n<p>mHC通过引入流形约束，数学上保证了万亿参数模型的信号稳定性；Engram通过引入外部记忆，打破了 Transformer仅仅依赖参数记忆知识的低效范式。这两项技术不仅为即将到来的 DeepSeek V4奠定了基础，更为整个AI行业在后 「Scaling Law」时代指明了新的方向：向几何要稳定性，向内存要知识容量。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 16:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/aifrontiers\">AI-Frontiers</a>&nbsp;\n阅读(<span id=\"post_view_count\">89</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AiReader：一个不联网的 AI 阅读助手，让你的算力为你服务",
      "link": "https://www.cnblogs.com/lissajous/p/19608767",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lissajous/p/19608767\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 15:54\">\n    <span>AiReader：一个不联网的 AI 阅读助手，让你的算力为你服务</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"AiReader：一个不联网的 AI 阅读助手，让你的算力为你服务\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3618712/202602/3618712-20260212155315495-120542706.png\" />\n        AiReader ：一个内置 AI 的桌面阅读器，所有 AI 推理都在你本地的 CPU/GPU 上运行。\n不需要联网，不需要注册，不需要 API Key。安装后首次配置下载一个 AI 模型（几百 MB 到几 GB），之后拔掉网线也能用。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"你的文档正在被谁阅读\">你的文档，正在被谁阅读？</h2>\n<p>每次你把一篇论文扔进在线翻译工具，每次你让 AI 帮你解读一份合同——你的文档都被上传到了某家公司的服务器上。</p>\n<p>也许你觉得无所谓。但如果有一种方式，<strong>AI 一样好用，但文档永远不离开你的电脑呢？</strong></p>\n<p>这就是 AiReader 在做的事。</p>\n<hr />\n<h2 id=\"aireader-是什么\">AiReader 是什么</h2>\n<p>一句话：<strong>一个内置 AI 的桌面阅读器，所有 AI 推理都在你本地的 CPU/GPU 上运行。</strong></p>\n<p>不需要联网，不需要注册，不需要 API Key。安装后首次配置下载一个 AI 模型（几百 MB 到几 GB），之后拔掉网线也能用。</p>\n<p>它支持阅读 <strong>PDF、EPUB、Markdown、TXT</strong> 四种格式，内置以下 AI 能力：</p>\n<hr />\n<h3 id=\"-选中即译\">📖 选中即译</h3>\n<p>在文档中选中任意文字，AI 立即翻译。支持三种模式：</p>\n<ul>\n<li><strong>直译</strong>：保留原文结构</li>\n<li><strong>意译</strong>：更自然的目标语言表达</li>\n<li><strong>白话</strong>：用最简单的话解释</li>\n</ul>\n<p>自动识别中英文方向。不是逐词机翻，是理解上下文后的翻译。</p>\n<h3 id=\"-文法解释\">🔍 文法解释</h3>\n<p>选中一个复杂句子，AI 拆解句子结构：主谓宾、从句关系、关键词汇用法。</p>\n<p>比起翻译，这才是真正帮你「读懂」一门语言的工具。</p>\n<h3 id=\"-上下文对话\">💬 上下文对话</h3>\n<p>选中一段内容，然后像和 ChatGPT 一样追问。可以锁定上下文反复深入，对话历史按文档自动保存。</p>\n<h3 id=\"-智能笔记\">📝 智能笔记</h3>\n<p>翻译、解释、对话内容都可以一键保存为笔记。笔记关联文档，支持 Markdown 导出。</p>\n<h3 id=\"-离线词典\">📚 离线词典</h3>\n<p>内置 ECDICT（英汉）+ CC-CEDICT（汉英），双击任意单词弹窗查词，无需联网。</p>\n<p><img alt=\"select-translate\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"它凭什么能在本地跑-ai\">它凭什么能在本地跑 AI？</h2>\n<p>底层用的是 <strong>llama.cpp</strong> —— 目前最成熟的开源本地大模型推理引擎，被全球数百万开发者使用。内置的模型是 <strong>Qwen3 系列</strong>（通义千问），从 0.6B 到 32B 参数量都有。</p>\n<p>在不同硬件上的表现：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">你的硬件</th>\n<th style=\"text-align: left;\">能跑什么</th>\n<th style=\"text-align: left;\">体验</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">游戏笔记本（RTX 3060+）</td>\n<td style=\"text-align: left;\">8B 模型</td>\n<td style=\"text-align: left;\">和 ChatGPT 一样流畅</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">普通笔记本（无独显）</td>\n<td style=\"text-align: left;\">1.7B-4B 模型</td>\n<td style=\"text-align: left;\">流畅，翻译质量够用</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">办公电脑</td>\n<td style=\"text-align: left;\">0.6B 模型</td>\n<td style=\"text-align: left;\">可用，简单翻译没问题</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Mac M 系列芯片</td>\n<td style=\"text-align: left;\">4B-8B 模型</td>\n<td style=\"text-align: left;\">Metal 加速，非常流畅</td>\n</tr>\n</tbody>\n</table>\n<p><strong>你不需要了解这些细节。</strong> 首次启动时，应用会自动检测你的硬件、跑基准测试、推荐最合适的模型，全程一键完成。</p>\n<hr />\n<h2 id=\"三个平台都能用\">三个平台都能用</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">平台</th>\n<th style=\"text-align: left;\">GPU 加速</th>\n<th style=\"text-align: left;\">安装包</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>Windows</strong> x64</td>\n<td style=\"text-align: left;\">NVIDIA (CUDA) · AMD/Intel (Vulkan)</td>\n<td style=\"text-align: left;\"><code>.exe</code> 安装包</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>macOS</strong> ARM / Intel</td>\n<td style=\"text-align: left;\">Metal</td>\n<td style=\"text-align: left;\"><code>.dmg</code></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Linux</strong> x64</td>\n<td style=\"text-align: left;\">Vulkan</td>\n<td style=\"text-align: left;\"><code>.AppImage</code> / <code>.deb</code></td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"完全免费完全开源\">完全免费，完全开源</h2>\n<ul>\n<li><strong>MIT 协议</strong>：你可以自由使用、修改、分发</li>\n<li><strong>无付费版</strong>：所有功能免费</li>\n<li><strong>无广告</strong>：没有任何广告和推广</li>\n<li><strong>无数据收集</strong>：不收集任何用户数据</li>\n<li><strong>代码公开</strong>：每一行代码都在 GitHub 上，欢迎审查</li>\n</ul>\n<hr />\n<h2 id=\"谁适合用\">谁适合用</h2>\n<ul>\n<li>📄 经常阅读英文论文、技术文档、外文书籍的人</li>\n<li>🔒 处理敏感文件（商业合同、内部报告、未发表研究）不想上传云端的人</li>\n<li>🎓 正在学外语，需要文法拆解而不只是翻译的学生</li>\n<li>🖥️ 想体验本地大模型但不知道从哪里开始的技术爱好者</li>\n<li>💡 信奉\"我的数据我做主\"的人</li>\n</ul>\n<hr />\n<h2 id=\"怎么获取\">怎么获取</h2>\n<h3 id=\"下载\">下载</h3>\n<p>GitHub Releases 页面下载对应平台安装包：</p>\n<p>🔗 <strong><a href=\"https://github.com/LissajousX/aireader/releases\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/LissajousX/aireader/releases</a></strong></p>\n<h3 id=\"安装\">安装</h3>\n<ul>\n<li><strong>Windows</strong>：双击 <code>.exe</code> 安装包，一路下一步</li>\n<li><strong>macOS</strong>：打开 <code>.dmg</code>，拖入应用程序文件夹\n<blockquote>\n<p>⚠️ macOS 版本暂未完成 Apple 签名认证，首次打开需要：右键点击 App → 选择「打开」→ 确认。或在终端执行 <code>xattr -cr /Applications/Aireader.app</code></p>\n</blockquote>\n</li>\n<li><strong>Linux</strong>：运行 <code>.AppImage</code> 或安装 <code>.deb</code> 包</li>\n</ul>\n<h3 id=\"首次使用\">首次使用</h3>\n<p>启动后跟随引导向导：选择语言 → 设置存储路径 → 一键配置 AI → 开始阅读。</p>\n<p>整个过程 3-5 分钟（主要是下载模型的时间）。</p>\n<hr />\n<h2 id=\"一些你可能会问的问题\">一些你可能会问的问题</h2>\n<p><strong>Q: 翻译质量和在线工具比怎么样？</strong><br />\nA: 4B 以上的模型，日常翻译质量接近 GPT-3.5 水平。8B 模型在大多数场景下和 GPT-4 差距不大。专业术语密集的场景（如医学、法律），建议用更大的模型或接入云端 API。</p>\n<p><strong>Q: 只能用内置模型吗？</strong><br />\nA: 不是。你也可以连接 Ollama（本地跑更大的模型）或任何 OpenAI 兼容的 API（如 DeepSeek）。</p>\n<p><strong>Q: 电脑配置不够怎么办？</strong><br />\nA: 最低 4GB 内存 + 任意 CPU 就能跑 0.6B 模型。如果觉得质量不够，可以接 Ollama 或云端 API 作为补充。</p>\n<p><strong>Q: 支持中文文档吗？</strong><br />\nA: 支持。Qwen3 模型本身就擅长中英双语。界面也支持中英文切换。</p>\n<p><strong>Q: 安全吗？代码可信吗？</strong><br />\nA: MIT 开源，全部代码公开。你可以自己审查，也可以自己编译。没有混淆，没有后门。</p>\n<hr />\n<h2 id=\"让你的算力为你服务\">让你的算力为你服务</h2>\n<p>你的电脑里有一颗强大的处理器，可能还有一块不便宜的显卡。大多数时候，它们都在闲着。</p>\n<p>AiReader 让这些算力做它们最擅长的事：<strong>帮你阅读、翻译、理解、思考。</strong></p>\n<p>而且，完全在你自己的电脑上。</p>\n<hr />\n<p><strong>🔗 GitHub: <a href=\"https://github.com/LissajousX/aireader\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/LissajousX/aireader</a></strong></p>\n<p>如果觉得有用，一个 ⭐ Star 就是最好的支持。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 15:54</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lissajous\">李萨如</a>&nbsp;\n阅读(<span id=\"post_view_count\">83</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "来自地平星上的物理学",
      "link": "https://www.cnblogs.com/szdytom/p/19608620/from-a-flat-planet",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/szdytom/p/19608620/from-a-flat-planet\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 15:26\">\n    <span>来自地平星上的物理学</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>假设有这样一个星球。不是比喻，我们真的想象一下——那里的所有人，从孩童到物理学家，都坚信大地是平的。这不是愚昧，这是他们全部经验的基础：目之所及，海天之间是一条直线；长途跋涉，脚下从无可见的弯曲。</p>\n<p>但他们和我们一样聪明，一样擅长做实验、列方程、建理论。只是他们的理论框架里，地面是绝对平面，重力方向垂直向下，处处平行。</p>\n<p>然后他们遇到了一个难题。</p>\n<h2 id=\"一我们先做一道地球上的物理题\">一、我们先做一道地球上的物理题</h2>\n<p>在我们熟悉的球形地球上，忽略空气阻力，从高度 <span class=\"math inline\">\\(h\\)</span> 水平抛出一个物体，初速度 <span class=\"math inline\">\\(v\\)</span>。我们都知道答案：</p>\n<p>下落时间 <span class=\"math inline\">\\(t = \\sqrt{2h/g}\\)</span>，水平射程 <span class=\"math inline\">\\(x_0 = v\\sqrt{2h/g}\\)</span>。</p>\n<p>这是高中物理，完全正确——只要 <span class=\"math inline\">\\(v\\)</span> 不太大。</p>\n<p>但如果 <span class=\"math inline\">\\(v\\)</span> 非常大呢？比如接近第一宇宙速度？这时候地面开始“往下躲”。地球是圆的，物体向前飞，地面向前弯曲。下落的时间变长了，射程自然比平抛公式算出来的更远。</p>\n<p>精确计算会给出一个很有意思的形式：</p>\n<p></p><div class=\"math display\">\\[x = v \\sqrt{\\frac{2h}{g - v^2/R}}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(R\\)</span> 是地球半径。注意这个分母：当 <span class=\"math inline\">\\(v^2\\)</span> 接近 <span class=\"math inline\">\\(gR\\)</span> 时，射程急剧增长；当 <span class=\"math inline\">\\(v^2 = gR\\)</span> 时，分母为零，射程无限远——这就是环绕速度。</p>\n<p>这个公式告诉我们一件事：<strong>曲率的效果，在数学上可以写成对重力加速度的“修正”</strong>，修正项与 <span class=\"math inline\">\\(v^2\\)</span> 成正比，比例系数是 <span class=\"math inline\">\\(1/R\\)</span>。</p>\n<p>记住这个形式。马上有用。</p>\n<h2 id=\"二地平星上的困惑\">二、地平星上的困惑</h2>\n<p>现在回到地平星。那里的物理学家也做平抛实验。</p>\n<p>起初一切正常。低速时，射程符合 <span class=\"math inline\">\\(x = v\\sqrt{2h/g}\\)</span>。但他们中有好事者——我们不妨称他为地平星的牛顿——决定把速度提上去。</p>\n<p>奇怪的事发生了。<strong>射程总是比理论值远一点</strong>，而且速度越大，偏得越多。</p>\n<p>数据不会撒谎。地平星的物理学家面临两个选择：</p>\n<ol>\n<li>怀疑“地面是平的”这一千年根基；</li>\n<li>在现有框架内找补。</li>\n</ol>\n<p>他们选了第二条路。这很正常，我们也会这么选。</p>\n<h2 id=\"三地斥力假说的诞生\">三、地斥力假说的诞生</h2>\n<p>地平星的牛顿这样推理：</p>\n<p>物体在空中只受重力，按理说应该下落得更快——但实际射程变远了，说明它下落得更慢。为什么？一定是受到了一个向上的力，抵消了一部分重力。</p>\n<p>这个力从哪里来？它和速度有关：速度越大，射程越远，说明向上的力越大。</p>\n<p>地平星上的物理学家进行了精确的实验，这些实验显示向上的加速度 <span class=\"math inline\">\\(a\\)</span> 与速度的平方成正比，即 <span class=\"math inline\">\\(a \\propto k v^2\\)</span>。这意味着，存在一种力，满足关系式</p>\n<p></p><div class=\"math display\">\\[F = k m v^2\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(k\\)</span> 是一个常数。于是竖直方向的有效加速度变成 <span class=\"math inline\">\\(g - kv^2\\)</span>。</p>\n<p>那么下落时间就变成了 <span class=\"math inline\">\\(t = \\sqrt{\\frac{2h}{g - kv^2}}\\)</span>，射程：</p>\n<p></p><div class=\"math display\">\\[x = v \\sqrt{\\frac{2h}{g - kv^2}}\n\\]</div><p></p><p>漂亮。公式完美拟合实验数据。地平星的物理学家满意了：他们发现了一种新的基本力——“地斥力”。它只在高速时明显，方向永远向上，大小与速度平方成正比，比例常数 <span class=\"math inline\">\\(k\\)</span> 是宇宙的基本参数。</p>\n<p>他们甚至还预言了一个临界速度 <span class=\"math inline\">\\(v_c = \\sqrt{g/k}\\)</span>：当发射速度达到这个值时，地斥力完全抵消重力，物体将永不落地。他们称之为“漂浮速度”。</p>\n<p>地平星物理学欣欣向荣。</p>\n<h2 id=\"四两个公式同一个数学\">四、两个公式，同一个数学</h2>\n<p>现在我们暂停，并排写下两个公式。</p>\n<p><strong>球形地球（曲率视角）</strong>：</p>\n<p></p><div class=\"math display\">\\[x = v \\sqrt{\\frac{2h}{g - v^2/R}}\n\\]</div><p></p><p><strong>地平星（地斥力视角）</strong>：</p>\n<p></p><div class=\"math display\">\\[x = v \\sqrt{\\frac{2h}{g - k v^2}}\n\\]</div><p></p><p>一模一样。只要令 <span class=\"math inline\">\\(k = 1/R\\)</span>，两个公式完全等价。</p>\n<p>这意味着什么？</p>\n<p><strong>给定同样的实验数据，我们可以用两种完全不同的理论来解释。</strong> 一种说，地面是弯的，物体走的是“直线”（测地线）；另一种说，地面是平的，但存在一个速度依赖的力。</p>\n<p>两者数学等价。实验无法区分。</p>\n<p>地平说学者不仅可以用“地斥力”解释曲率效应——事实上，随着地平星上的测量越来越精确，他们还可以用类似的思路解释<strong>科里奥利力</strong>和<strong>离心力</strong>——如果他们不承认地球在自转的话。</p>\n<ul>\n<li>\n<p><strong>傅科摆</strong>：平面地球学者会说存在“旋转力场”，使摆平面每天转一圈。</p>\n</li>\n<li>\n<p><strong>落体东偏</strong>：他们会说存在“东向力”，与下落速度成正比。</p>\n</li>\n</ul>\n<p>但一个承认地球自转的人会指出：<strong>这些“力”只是你在非惯性系中观察惯性运动的结果</strong>。</p>\n<h2 id=\"五我们站在哪一边\">五、我们站在哪一边？</h2>\n<p>现在你是裁判。</p>\n<p>地平星的物理学家拥有一个自洽的理论。他们用“地斥力”解释了一切：从炮弹射程到人造卫星的“悬浮”，都可以用那个 <span class=\"math inline\">\\(F = m k v^2\\)</span> 的公式计算。常数 <span class=\"math inline\">\\(k\\)</span> 可以通过实验精确测定。</p>\n<p>但他们也付出了代价：</p>\n<ul>\n<li>引入了一个全新的、无法归约的力；</li>\n<li>这个力与质量成正比（巧合？）；</li>\n<li>常数k的来源是谜，它只是“世界的一个基本参数”；</li>\n<li>他们无法回答：为什么偏偏是速度平方？为什么不是速度本身，或者其他形式？</li>\n</ul>\n<p>而我们——知道地球是球形的我们——有一个更简洁的解释：</p>\n<ul>\n<li>不需要任何新力；</li>\n<li>物体只是在惯性运动，是地面自己弯了下去；</li>\n<li>那个神秘的常数 <span class=\"math inline\">\\(k\\)</span>，其实就是曲率半径的倒数 <span class=\"math inline\">\\(1/R\\)</span>。</li>\n</ul>\n<p>我们用一个几何事实，取代了他们的一套力学假设。</p>\n<h2 id=\"六这不是关于地平说\">六、这不是关于地平说</h2>\n<p>你大概已经猜到我要说什么了。</p>\n<p>我们站在地球上，嘲笑地平星人——但我们自己呢？</p>\n<p>我们教给学生的“万有引力”：两个有质量的物体互相吸引，力的大小正比于质量乘积，反比于距离平方。力的方向沿连线。</p>\n<p>这是一个非常成功的理论。用它发射了卫星，登上了月球，飞向了太阳系边缘。</p>\n<p>但这个“力”真的存在吗？</p>\n<p>1915年，一个叫爱因斯坦的人说：也许我们和地平星人一样，把一个几何效应误读成了力。</p>\n<p>他的理由是：引力和惯性力在局部无法区分。你在加速上升的电梯里感受到的“地板压力”，和在地面静止的电梯里感受到的，感觉完全一样。而惯性力（离心力、科里奥利力）从来就不是真正的力，只是你在非惯性系里观察惯性运动的结果。</p>\n<p>如果惯性力是几何的，为什么引力不能也是几何的？</p>\n<p>于是他做了一个极其大胆的操作：把“万有引力”从力的名单里删除。没有引力，只有时空弯曲。行星绕日不是被“拉”着走，而是沿着弯曲时空中的“直线”（测地线）惯性滑行。</p>\n<p>正如地平星上不是真的有地斥力，只是地面弯了。</p>\n<h2 id=\"七选择哪一种世界观\">七、选择哪一种世界观？</h2>\n<p>地平星的物理学家只要愿意，完全可以拒绝曲率假说，继续用“地斥力”框架。公式照样算，卫星照样发，常数k照样测。他们甚至可以说：你们地球人说的“曲率”，不过是我们“地斥力”的一种几何化翻译罢了。</p>\n<p>他们说得对。<strong>理论和实验之间没有一一对应关系。</strong> 同一套现象，永远可以用不同的理论框架来描述。</p>\n<p>那为什么我们选择了爱因斯坦？</p>\n<p>不是因为实验“证明”了引力是几何（实验只能验证预言，不能判定概念的本质），而是因为<strong>几何化带来的简洁性、统一性和洞察力</strong>。</p>\n<p>在牛顿那里，引力常数 <span class=\"math inline\">\\(G\\)</span> 是一个孤零零的数字。在爱因斯坦这里，<span class=\"math inline\">\\(G\\)</span> 成为物质与时空之间的耦合常数，出现在一个优美的方程里：</p>\n<p></p><div class=\"math display\">\\[G_{\\mu\\nu} = \\frac{8\\pi G}{c^4} T_{\\mu\\nu}\n\\]</div><p></p><p>左边是时空的几何，右边是物质与能量。这个方程说：<strong>质量告诉时空如何弯曲，弯曲的时空告诉质量如何运动。</strong></p>\n<p>没有力。只有几何。</p>\n<h2 id=\"八地平星的下一站\">八、地平星的下一站</h2>\n<p>让我们再往前想一步。</p>\n<p>如果地平星的某位物理学家——我们不妨称他为地平星的爱因斯坦——某天突然意识到：与其引入一个神秘的速度依赖力，不如假设地面是弯的。那么他会立刻发现：</p>\n<ul>\n<li>那个常数 <span class=\"math inline\">\\(k\\)</span> 突然有了几何意义：<span class=\"math inline\">\\(k = 1/R\\)</span>，R就是“世界”的曲率半径；</li>\n<li>他可以用大地测量独立验证这个 <span class=\"math inline\">\\(R\\)</span>；</li>\n<li>他还可以问：如果地面是弯的，那整个世界是不是也可能是弯的？更高维度呢？</li>\n</ul>\n<p>他正走在我们一百年前走过的路上。</p>\n<p>而我们呢？我们至今仍在寻找“引力”的更根本解释。弦理论、圈量子引力、涌现时空……都在追问同一个问题：<strong>时空本身是不是也是“地斥力”？</strong></p>\n<p>也许有一天，我们也会像地平星人一样，笑着承认：噢，原来我们说的“引力”，从头到尾都不是力。</p>\n<hr />\n<p>现在，闭上眼。</p>\n<p>你站在地平星的物理学大会上，听一位年轻学者报告“地斥力常数 <span class=\"math inline\">\\(k\\)</span> 的精确测量”。屏幕上数据闪烁，一切完美自洽。</p>\n<p>你该怎么告诉他？说他错了吗？他没有任何实验错误。</p>\n<p>也许你只是轻轻问一句：</p>\n<p>“你有没有想过，如果地面本身就是弯的，会怎么样？”</p>\n<p>这大概就是 1915 年，有人问牛顿力学时的心情。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 15:26</span>&nbsp;\n<a href=\"https://www.cnblogs.com/szdytom\">方而静</a>&nbsp;\n阅读(<span id=\"post_view_count\">81</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "数据库算子",
      "link": "https://www.cnblogs.com/aslanvon/p/19608578",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/aslanvon/p/19608578\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 15:18\">\n    <span>数据库算子</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"回表\">回表</h1>\n<h2 id=\"1-为什么会发生回表\">1. 为什么会发生回表？</h2>\n<p>想象你在图书馆查书：</p>\n<ol>\n<li><strong>索引（Index）</strong>：就像图书馆的<strong>索引卡片</strong>。卡片上写着：书名《数据库原理》，存放位置：3排-B架-12号。</li>\n<li><strong>表（Table/Heap）</strong>：就像<strong>书架上的实物书</strong>。书里才有具体的内容（作者、出版社、正文）。</li>\n</ol>\n<p>如果你只想知道书名，看卡片（索引）就够了。但如果你想看“作者是谁”或者“具体内容”，你就必须拿着卡片上的位置，走到书架前把那本书抽出来翻开。<strong>这个“从索引到书架取书”的过程，就是回表。</strong></p>\n<hr />\n<h2 id=\"2-回表的过程以-postgresqlmysql-为例\">2. 回表的过程（以 PostgreSQL/MySQL 为例）</h2>\n<p>假设你有一张表 <code>users</code>，在 <code>username</code> 字段上有索引：</p>\n<pre><code class=\"language-sql\">-- 查询语句\nSELECT id, username, age FROM users WHERE username = 'a';\n</code></pre>\n<ol>\n<li><strong>第一步：查索引。</strong> 数据库在 <code>username</code> 索引树中快速定位到 <code>'a'</code>。</li>\n<li><strong>第二步：拿指针。</strong> 索引节点里存储着该行数据的物理地址（在 MySQL 中是主键 ID，在 PostgreSQL 中是 CTID/TID）。</li>\n<li><strong>第三步：回表。</strong> 索引里<strong>没有 <code>age</code> 字段</strong>。数据库根据物理地址，回到原始数据表（Heap）中找到这一行，把 <code>age</code> 的值读出来。</li>\n</ol>\n<hr />\n<h2 id=\"3-回表有什么代价\">3. 回表有什么代价？</h2>\n<p>回表是数据库性能优化的<strong>头号公敌</strong>，主要原因有两个：</p>\n<ul>\n<li><strong>随机 I/O 增加</strong>：索引通常是顺序排列的，但数据行在磁盘上的分布是零散的。每回表一次，可能都要进行一次磁盘随机读，这比顺序读慢得多。</li>\n<li><strong>性能损耗</strong>：如果查询结果有 10,000 行，数据库就要执行 10,000 次“回表”动作。</li>\n</ul>\n<hr />\n<h2 id=\"4-如何避免回表\">4. 如何避免回表？</h2>\n<p>最有效的方案是：<strong>覆盖索引（Covering Index）</strong>。</p>\n<p>如果你经常需要根据 <code>username</code> 查 <code>age</code>，你可以建立一个包含这两个字段的索引：</p>\n<pre><code class=\"language-sql\">-- PostgreSQL 语法\nCREATE INDEX idx_user_age ON users(username) INCLUDE (age);\n\n-- 或者通用的复合索引\nCREATE INDEX idx_user_age_composite ON users(username, age);\n</code></pre>\n<p><strong>发生了什么变化？</strong></p>\n<p>现在，<code>age</code> 字段的信息直接存在了索引树里。数据库查到 <code>username</code> 时，顺手就能把旁边的 <code>age</code> 带走，再也不用去翻原始表了。这种算子在执行计划中会显示为 <strong>Index Only Scan</strong>。</p>\n<hr />\n<h2 id=\"5-什么时候回表比不回表还快\">5. 什么时候“回表”比“不回表”还快？</h2>\n<p>并不是所有时候都要避免回表。</p>\n<ul>\n<li>如果你的 <code>WHERE</code> 条件过滤后，<strong>只剩下几行数据</strong>，回表的代价微乎其微。</li>\n<li>如果表很小，数据库可能会直接放弃索引，选择 <strong>Seq Scan（全表扫描）</strong>。因为它觉得“与其先看卡片再翻书，不如直接把这本薄书从头到尾翻一遍”。</li>\n</ul>\n<h2 id=\"总结\">总结</h2>\n<ul>\n<li><strong>回表</strong> = 在索引里没找全，得回原表取。</li>\n<li><strong>后果</strong> = 产生随机 I/O，变慢。</li>\n<li><strong>对策</strong> = 覆盖索引（把查的字段都塞进索引里）。</li>\n</ul>\n<h1 id=\"算子\">算子</h1>\n<p>在 PostgreSQL 中，算子（Operators/Nodes）是构成执行计划的最小单元。为了方便记忆，我们可以按照它们在数据处理流中的<strong>功能角色</strong>，将其分为四大类：<strong>数据扫描</strong>、<strong>连接查询</strong>、<strong>集合/聚合操作</strong>、以及<strong>辅助控制算子</strong>。</p>\n<hr />\n<h2 id=\"1-数据扫描算子-scan-nodes\">1. 数据扫描算子 (Scan Nodes)</h2>\n<p>这类算子负责从物理存储（磁盘或内存缓冲区）中读取原始数据。</p>\n<table>\n<thead>\n<tr>\n<th><strong>算子名称</strong></th>\n<th><strong>英文名</strong></th>\n<th><strong>功能描述</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>全表扫描</strong></td>\n<td><strong>Seq Scan</strong></td>\n<td>顺序读取整个表的所有数据页。</td>\n</tr>\n<tr>\n<td><strong>索引扫描</strong></td>\n<td><strong>Index Scan</strong></td>\n<td>先扫描索引找到位置，再回表读取数据行。</td>\n</tr>\n<tr>\n<td><strong>索引覆盖扫描</strong></td>\n<td><strong>Index Only Scan</strong></td>\n<td>仅通过索引就能拿到所有所需字段，无需回表。</td>\n</tr>\n<tr>\n<td><strong>位图扫描</strong></td>\n<td><strong>Bitmap Heap/Index Scan</strong></td>\n<td>先在内存中构建位图标记匹配行，再批量回表，减少随机 IO。</td>\n</tr>\n<tr>\n<td><strong>TID 扫描</strong></td>\n<td><strong>Tid Scan</strong></td>\n<td>通过行标识符（Tuple ID）直接定位数据。</td>\n</tr>\n</tbody>\n</table>\n<p>在 PostgreSQL 中，<strong>扫描算子（Scan Nodes）</strong>是执行计划的“地基”。所有数据的处理都始于扫描，它的效率直接决定了查询的生死。</p>\n<p>PostgreSQL 会根据数据量的大小、过滤条件的筛选率以及索引的分布，从以下几种主要扫描方式中选择最优解。</p>\n<hr />\n<h3 id=\"1-全表扫描-seq-scan\">1. 全表扫描 (Seq Scan)</h3>\n<p>这是最原始的扫描方式。</p>\n<ul>\n<li><strong>工作原理：</strong> 数据库从磁盘上顺序读取该表的所有数据页（Blocks），并对每一行进行条件检查。</li>\n<li><strong>适用场景：</strong>\n<ul>\n<li>表非常小（加载索引的代价反而比全表扫描高）。</li>\n<li>查询条件没有索引。</li>\n<li>返回的数据占全表比例很高（例如超过 20%-30%），此时顺序 IO 比频繁的随机 IO 更快。</li>\n</ul>\n</li>\n<li><strong>EXPLAIN 标志：</strong> <code>Seq Scan on table_name</code>。</li>\n</ul>\n<hr />\n<h3 id=\"2-索引扫描-index-scan\">2. 索引扫描 (Index Scan)</h3>\n<p>当查询条件命中索引时，数据库会先去查索引。</p>\n<ul>\n<li><strong>工作原理：</strong>\n<ol>\n<li>在 B-Tree 索引中找到匹配条件的 Entry（条目）。</li>\n<li>根据 Entry 中的指针（TID），回表（Heap）读取完整的数据行。</li>\n</ol>\n</li>\n<li><strong>优缺点：</strong> 适合返回少量数据的查询。如果返回行数太多，频繁的“回表”会导致大量随机 IO，性能反而不如 Seq Scan。</li>\n<li><strong>EXPLAIN 标志：</strong> <code>Index Scan using index_name on table_name</code>。</li>\n</ul>\n<hr />\n<h3 id=\"3-索引覆盖扫描-index-only-scan\">3. 索引覆盖扫描 (Index Only Scan)</h3>\n<p>这是性能优化的“天花板”。</p>\n<ul>\n<li><strong>工作原理：</strong> 如果你查询的字段全都在索引里（例如 <code>SELECT id FROM users WHERE id &lt; 10</code>），数据库直接从索引树拿到结果就返回，<strong>完全不需要回表</strong>。</li>\n<li><strong>关键点：</strong> 受 <strong>Visibility Map</strong> 的影响。如果某些数据页刚被更新过，数据库还是得回表确认数据的可见性（MVCC）。</li>\n<li><strong>EXPLAIN 标志：</strong> <code>Index Only Scan using index_name on table_name</code>。</li>\n</ul>\n<hr />\n<h3 id=\"4-位图扫描-bitmap-scan\">4. 位图扫描 (Bitmap Scan)</h3>\n<p>这是 PostgreSQL 的一大特色，专门解决“索引扫描导致随机 IO 太多”的问题。</p>\n<ul>\n<li><strong>工作原理（分两步）：</strong>\n<ol>\n<li><strong>Bitmap Index Scan：</strong> 扫描索引，但不立刻回表。它在内存中创建一个“位图”，标记哪些数据页包含符合条件的行。</li>\n<li><strong>Bitmap Heap Scan：</strong> 根据位图，按磁盘顺序访问数据页。</li>\n</ol>\n</li>\n<li><strong>意义：</strong> 它将随机 IO 转换成了<strong>局部顺序 IO</strong>。它比 Index Scan 更适合查询“中等规模”的数据（既不太多也不太少）。</li>\n<li><strong>EXPLAIN 标志：</strong> 往往成对出现，先有 <code>Bitmap Index Scan</code>，后有 <code>Bitmap Heap Scan</code>。</li>\n</ul>\n<hr />\n<h3 id=\"5-常见扫描算子对比表\">5. 常见扫描算子对比表</h3>\n<p>为了直观理解，我们假设有一张 100 万行的表：</p>\n<table>\n<thead>\n<tr>\n<th><strong>扫描类型</strong></th>\n<th><strong>动作比喻</strong></th>\n<th><strong>适用情况</strong></th>\n<th><strong>性能瓶颈</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Seq Scan</strong></td>\n<td>翻完整本书找一个词</td>\n<td>查大量数据/小表</td>\n<td>磁盘总 IO 量</td>\n</tr>\n<tr>\n<td><strong>Index Scan</strong></td>\n<td>看目录，查到一个页码翻一下书</td>\n<td>查极少量数据</td>\n<td>随机读取延迟</td>\n</tr>\n<tr>\n<td><strong>Index Only Scan</strong></td>\n<td>只看目录就找到了答案</td>\n<td>覆盖索引查询</td>\n<td>索引页的大小</td>\n</tr>\n<tr>\n<td><strong>Bitmap Scan</strong></td>\n<td>看目录，把所有页码记在纸上，按页码从小到大翻书</td>\n<td>查中等量数据</td>\n<td>内存 (Work_mem)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"2-连接算子-join-nodes\">2. 连接算子 (Join Nodes)</h2>\n<p>连接算子（Join Nodes）是数据库执行计划中最核心的部分之一。当你的 SQL 查询涉及两张或更多的表时，数据库必须决定<strong>“用什么算法把这两堆数据拼在一起”</strong>。PostgreSQL（以及大多数关系型数据库）主要支持三种连接算法。理解它们的区别，是优化多表查询的关键。</p>\n<table>\n<thead>\n<tr>\n<th><strong>算子名称</strong></th>\n<th><strong>英文名</strong></th>\n<th><strong>功能描述</strong></th>\n<th><strong>适用场景</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>嵌套循环连接</strong></td>\n<td><strong>Nested Loop</strong></td>\n<td>对外表的每一行，去内表中查找匹配行。</td>\n<td>小数据集连接，或内表有索引。</td>\n</tr>\n<tr>\n<td><strong>哈希连接</strong></td>\n<td><strong>Hash Join</strong></td>\n<td>为内表在内存建立哈希表，扫描外表进行匹配。</td>\n<td>大表关联，且无索引支持。</td>\n</tr>\n<tr>\n<td><strong>归并连接</strong></td>\n<td><strong>Merge Join</strong></td>\n<td>将两个有序集合像拉链一样合并。</td>\n<td>两表在关联键上均已有序（如已有索引）。</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"1-嵌套循环连接-nested-loop-join\">1. 嵌套循环连接 (Nested Loop Join)</h3>\n<p>这是最简单、最直观，但在特定场景下也是最快的一种方式。</p>\n<ul>\n<li>\n<p><strong>直观理解：</strong> 就像写代码时的“双层 <code>for</code> 循环”。</p>\n<pre><code class=\"language-Python\"># 伪代码逻辑\nfor outer_row in Outer_Table:        # 外层循环（驱动表）\n    for inner_row in Inner_Table:    # 内层循环（被驱动表）\n        if outer_row.id == inner_row.id:\n            yield (outer_row, inner_row)\n</code></pre>\n</li>\n<li>\n<p><strong>工作流程：</strong></p>\n<ol>\n<li>优化器选择一张表作为<strong>驱动表（Outer Table）</strong>，通常是过滤后结果集较小的那张表。</li>\n<li>逐行读取驱动表的数据。</li>\n<li>拿着这一行数据的关联键，去<strong>被驱动表（Inner Table）</strong>中查找匹配的行。</li>\n</ol>\n</li>\n<li>\n<p><strong>性能关键点：</strong></p>\n<ul>\n<li><strong>被驱动表必须有索引！</strong> 如果内层循环每次都要全表扫描，性能就是灾难级的 O(N*M)。</li>\n<li>如果有索引，复杂度降为 O(N*log M)。</li>\n</ul>\n</li>\n<li>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li><strong>“小表驱动大表”</strong>：驱动表只有几百行，被驱动表有几亿行但有索引。</li>\n<li><strong>首行快速响应</strong>：因为它不需要预处理，找到第一行匹配就能立即返回，适合分页查询的第一页。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"2-哈希连接-hash-join\">2. 哈希连接 (Hash Join)</h3>\n<p>这是处理<strong>大数据量</strong>连接的神器，也是现代数据库最常用的算法之一。</p>\n<ul>\n<li><strong>工作流程（分两个阶段）：</strong>\n<ol>\n<li><strong>构建阶段 (Build Phase)：</strong> 选择较小的那张表，在<strong>内存</strong>中建立一张<strong>哈希表（Hash Table）</strong>。键是连接字段，值是行数据。</li>\n<li><strong>探测阶段 (Probe Phase)：</strong> 扫描较大的那张表，对每一行计算连接字段的哈希值，去内存的哈希表中查找是否存在。</li>\n</ol>\n</li>\n<li><strong>性能关键点：</strong>\n<ul>\n<li><strong>内存（work_mem）：</strong> 哈希表必须能装入内存。如果内存不够，数据库会把哈希表切分写入磁盘（临时文件），性能会急剧下降（你会看到 <code>Disk: xxx kB</code>）。</li>\n<li><strong>只支持等值连接：</strong> 只能用于 <code>ON a.id = b.id</code>，不支持 <code>&gt;</code> 或 <code>&lt;</code>。</li>\n</ul>\n</li>\n<li><strong>适用场景：</strong>\n<ul>\n<li><strong>两张表都很大</strong>，且被驱动表上没有合适的索引。</li>\n<li>查询结果集很大，索引扫描产生的随机 I/O 代价太高。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"3-归并连接-merge-join--sort-merge-join\">3. 归并连接 (Merge Join / Sort Merge Join)</h3>\n<p>这是一种优雅的算法，前提是数据<strong>已经排好序</strong>。</p>\n<ul>\n<li><strong>工作流程：</strong>\n<ol>\n<li>如果不有序，先对两张表分别进行<strong>排序 (Sort)</strong>。</li>\n<li>使用双指针算法，同时遍历两张表。</li>\n<li>如果 <code>A.id &lt; B.id</code>，A 的指针往下移；如果 <code>A.id &gt; B.id</code>，B 的指针往下移；如果相等，输出结果。</li>\n</ol>\n</li>\n<li><strong>性能关键点：</strong>\n<ul>\n<li><strong>排序成本：</strong> 如果数据本身没排序，排序的代价非常高。</li>\n<li><strong>索引优势：</strong> 如果连接字段上本来就有 B-Tree 索引（索引本质就是有序的），那么可以直接跳过排序步骤，性能极快。</li>\n</ul>\n</li>\n<li><strong>适用场景：</strong>\n<ul>\n<li>连接字段上有<strong>索引</strong>（天然有序）。</li>\n<li>SQL 中包含 <code>ORDER BY</code>，正好利用连接后的有序结果。</li>\n<li><strong>非等值连接</strong>中的范围连接（如 <code>BETWEEN</code> ）。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"4-三种算子对比总结表\">4. 三种算子对比总结表</h3>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>Nested Loop (嵌套循环)</strong></th>\n<th><strong>Hash Join (哈希连接)</strong></th>\n<th><strong>Merge Join (归并连接)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>核心逻辑</strong></td>\n<td>双层循环</td>\n<td>内存哈希表匹配</td>\n<td>排序后拉链式合并</td>\n</tr>\n<tr>\n<td><strong>适用数据量</strong></td>\n<td><strong>小数据量</strong> (小表驱动大表)</td>\n<td><strong>大数据量</strong> (两表均大)</td>\n<td><strong>大数据量</strong> (且有序)</td>\n</tr>\n<tr>\n<td><strong>索引依赖</strong></td>\n<td>强依赖 (被驱动表需索引)</td>\n<td>不依赖</td>\n<td>最好有 (可免去排序)</td>\n</tr>\n<tr>\n<td><strong>内存消耗</strong></td>\n<td>极低</td>\n<td><strong>高</strong> (需构建哈希表)</td>\n<td>中 (若需排序则高)</td>\n</tr>\n<tr>\n<td><strong>支持条件</strong></td>\n<td>任何 (等值/不等值/范围)</td>\n<td><strong>仅限等值</strong> (<code>=</code>)</td>\n<td>等值或范围</td>\n</tr>\n<tr>\n<td><strong>启动速度</strong></td>\n<td>快 (立即返回首行)</td>\n<td>慢 (需先构建哈希表)</td>\n<td>慢 (需先排序)</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h3 id=\"5-如何根据算子优化-sql\">5. 如何根据算子优化 SQL？</h3>\n<p>当你在 <code>EXPLAIN</code> 中看到以下情况时，可以尝试优化：</p>\n<ol>\n<li><strong>看到 <code>Nested Loop</code> 但很慢：</strong>\n<ul>\n<li>检查被驱动表（Inner Table）的连接字段是否有<strong>索引</strong>。如果没有，数据库在疯狂做全表扫描。</li>\n</ul>\n</li>\n<li><strong>看到 <code>Hash Join</code> 且带有 <code>Batches</code> 或 <code>Disk</code>：</strong>\n<ul>\n<li>说明内存不够用了，数据溢出到了磁盘。尝试调大 <code>work_mem</code> 参数，或者优化 WHERE 条件减少参与连接的数据量。</li>\n</ul>\n</li>\n<li><strong>看到 <code>Merge Join</code> 之前有一个巨大的 <code>Sort</code>：</strong>\n<ul>\n<li>排序非常消耗 CPU 和内存。如果在连接字段建立索引，可以消除这个排序步骤，直接利用 Index Scan 进行 Merge Join。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-集合与聚合算子-aggregation--set-nodes\">3. 集合与聚合算子 (Aggregation &amp; Set Nodes)</h2>\n<p>这类算子负责对数据进行去重、分组计算或合并多个结果集。</p>\n<ul>\n<li><strong>聚合类：</strong>\n<ul>\n<li><strong>Aggregate:</strong> 实现 <code>COUNT</code>, <code>SUM</code>, <code>AVG</code> 等。</li>\n<li><strong>GroupAggregate:</strong> 针对<strong>已排序</strong>的数据进行分组聚合。</li>\n<li><strong>HashAggregate:</strong> 针对<strong>未排序</strong>的数据，利用哈希表在内存中进行分组。</li>\n</ul>\n</li>\n<li><strong>集合类：</strong>\n<ul>\n<li><strong>Unique:</strong> 对有序数据进行去重（如 <code>DISTINCT</code>）。</li>\n<li><strong>HashSetOp:</strong> 利用哈希表进行集合操作（如 <code>INTERSECT</code> 或 <code>EXCEPT</code>）。</li>\n<li><strong>Append:</strong> 将多个子查询的结果集（如 <code>UNION ALL</code>）简单堆叠在一起。</li>\n</ul>\n</li>\n</ul>\n<p>在数据库执行计划中，<strong>集合与聚合算子（Aggregation &amp; Set Nodes）</strong> 负责对扫描或连接后的“原材料”数据进行深加工。</p>\n<p>简单来说：</p>\n<ul>\n<li><strong>聚合算子</strong>是做“数学题”的（求和、计数、平均、分组）。</li>\n<li><strong>集合算子</strong>是做“拼图”的（合并、交集、去重）。</li>\n</ul>\n<h3 id=\"第一部分聚合算子-aggregation-nodes\">第一部分：聚合算子 (Aggregation Nodes)</h3>\n<p>当你使用 <code>GROUP BY</code>、<code>COUNT</code>、<code>SUM</code>、<code>AVG</code> 等语句时，就会触发此类算子。数据库通常有两种策略来处理聚合：<strong>哈希（Hash）</strong> 和 <strong>排序（Sort/Group）</strong>。</p>\n<h5 id=\"1-hashaggregate-哈希聚合\">1. HashAggregate (哈希聚合)</h5>\n<p>这是处理<strong>未排序数据</strong>最常用的聚合方式。</p>\n<ul>\n<li><strong>工作原理（桶排序思想）：</strong>\n<ol>\n<li>数据库在内存（<code>work_mem</code>）中创建一个哈希表。</li>\n<li>扫描每一行数据，计算 <code>GROUP BY</code> 字段的哈希值。</li>\n<li>将数据丢进对应的“桶”里，并实时更新聚合状态（例如：如果是 <code>COUNT</code> 就 +1，如果是 <code>SUM</code> 就累加）。</li>\n<li>扫描结束后，遍历哈希表输出结果。</li>\n</ol>\n</li>\n<li><strong>优点：</strong> 不需要数据预先排序，速度通常很快。</li>\n<li><strong>缺点：</strong> <strong>非常吃内存</strong>。如果分组的数量太多（比如按 UserID 分组，有 100 万个用户），哈希表会撑爆内存，导致溢出到磁盘（Disk Spill），性能急剧下降。</li>\n<li><strong>场景：</strong> 数据无序，且分组基数（Cardinality）适中。</li>\n</ul>\n<h5 id=\"2-groupaggregate-分组聚合\">2. GroupAggregate (分组聚合)</h5>\n<p>这是基于<strong>有序数据</strong>的聚合方式。</p>\n<ul>\n<li><strong>工作原理（流水线思想）：</strong>\n<ol>\n<li><strong>前提：</strong> 输入的数据必须已经按 <code>GROUP BY</code> 字段排好序了（通常由下层的 <code>Sort</code> 算子或 <code>Index Scan</code> 保证）。</li>\n<li>数据库逐行读取数据。</li>\n<li>如果当前行的分组键和上一行一样，就累加；如果不一样，说明上一个组结束了，输出结果，开始下一个组。</li>\n</ol>\n</li>\n<li><strong>优点：</strong> <strong>内存占用极低</strong>（只需要存当前这一组的状态），且可以流式输出（不用等所有数据读完就能出第一行结果）。</li>\n<li><strong>缺点：</strong> 强依赖数据有序。如果数据本身没序，前面必须加一个昂贵的 <code>Sort</code> 算子。</li>\n<li><strong>场景：</strong> <code>GROUP BY</code> 字段上有索引，或者数据量大到内存装不下哈希表。</li>\n</ul>\n<h5 id=\"3-plain-aggregate-普通聚合\">3. Plain Aggregate (普通聚合)</h5>\n<ul>\n<li><strong>含义：</strong> 没有 <code>GROUP BY</code>，只算一个全局的总数。例如 <code>SELECT COUNT(*) FROM table</code>。</li>\n<li><strong>特点：</strong> 最简单，扫一遍全表，维护一个计数器即可。</li>\n</ul>\n<hr />\n<h3 id=\"第二部分集合与去重算子-set--unique-nodes\">第二部分：集合与去重算子 (Set &amp; Unique Nodes)</h3>\n<p>当你使用 <code>UNION</code>、<code>INTERSECT</code>、<code>EXCEPT</code> 或 <code>DISTINCT</code> 时，会用到这些算子。</p>\n<h4 id=\"1-append-追加\">1. Append (追加)</h4>\n<ul>\n<li><strong>对应 SQL：</strong> <code>UNION ALL</code></li>\n<li><strong>工作原理：</strong> 极其简单。先把第一个子查询的结果吐出来，再把第二个子查询的结果吐出来。不做去重，不做排序。</li>\n<li><strong>性能：</strong> <strong>极快</strong>。只要不需要去重，尽量用 <code>UNION ALL</code> 代替 <code>UNION</code>。</li>\n</ul>\n<h4 id=\"2-unique-去重\">2. Unique (去重)</h4>\n<ul>\n<li><strong>对应 SQL：</strong> <code>DISTINCT</code> 或 <code>UNION</code>（不带 ALL）。</li>\n<li><strong>工作原理：</strong> 类似于 <code>GroupAggregate</code>，它要求输入数据是有序的。它对比当前行和上一行，如果相同就丢弃，不同就输出。</li>\n<li><strong>注意：</strong> 如果数据没序，通常会先看到 <code>Sort</code>，再看到 <code>Unique</code>。</li>\n</ul>\n<h4 id=\"3-hashsetop--sortsetop-集合操作\">3. HashSetOp / SortSetOp (集合操作)</h4>\n<ul>\n<li><strong>对应 SQL：</strong> <code>INTERSECT</code> (交集) 或 <code>EXCEPT</code> (差集)。</li>\n<li><strong>HashSetOp：</strong> 用哈希表来判断元素是否存在于两个集合中。</li>\n<li><strong>SortSetOp：</strong> 先把两个集合排序，然后用双指针算法比对。</li>\n</ul>\n<hr />\n<h4 id=\"第三部分实战中的性能博弈\">第三部分：实战中的性能博弈</h4>\n<p>在看执行计划时，你需要关注以下几点：</p>\n<h4 id=\"1-内存-vs-排序-hashagg-vs-groupagg\">1. 内存 vs 排序 (HashAgg vs GroupAgg)</h4>\n<ul>\n<li>如果你的 SQL 跑得很慢，且看到 <strong>HashAggregate</strong> 下方有 <code>Disk: xxx kB</code>，说明内存不够了。\n<ul>\n<li><strong>优化：</strong> 调大 <code>work_mem</code> 参数，让哈希表能装入内存。</li>\n</ul>\n</li>\n<li>如果你看到 <strong>GroupAggregate</strong> 下方有一个巨大的 <strong>Sort</strong>，且 <code>Sort Method: external merge</code>。\n<ul>\n<li><strong>优化：</strong> 尝试在 <code>GROUP BY</code> 字段上加索引。有了索引，数据天然有序，<code>Sort</code> 算子就会消失，直接进行 <code>GroupAggregate</code>，性能起飞。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-distinct-的代价\">2. DISTINCT 的代价</h4>\n<p><code>DISTINCT</code> 本质上就是一次聚合或排序。</p>\n<ul>\n<li><code>SELECT DISTINCT user_id ...</code> 等价于 <code>SELECT user_id ... GROUP BY user_id</code>。</li>\n<li>千万不要滥用 <code>DISTINCT</code>。如果你写了 <code>DISTINCT</code>，数据库就必须把所有数据拿来进行一次昂贵的去重计算。</li>\n</ul>\n<h4 id=\"总结对比表\">总结对比表</h4>\n<table>\n<thead>\n<tr>\n<th><strong>算子名称</strong></th>\n<th><strong>功能</strong></th>\n<th><strong>依赖条件</strong></th>\n<th><strong>内存消耗</strong></th>\n<th><strong>适用场景</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>HashAggregate</strong></td>\n<td>分组/去重</td>\n<td>无</td>\n<td><strong>高</strong> (受基数影响)</td>\n<td>无索引，分组数量适中</td>\n</tr>\n<tr>\n<td><strong>GroupAggregate</strong></td>\n<td>分组/去重</td>\n<td><strong>数据必须有序</strong></td>\n<td>低</td>\n<td>有索引，或数据量极大</td>\n</tr>\n<tr>\n<td><strong>Append</strong></td>\n<td>合并结果</td>\n<td>无</td>\n<td>极低</td>\n<td><code>UNION ALL</code></td>\n</tr>\n<tr>\n<td><strong>Unique</strong></td>\n<td>排序去重</td>\n<td><strong>数据必须有序</strong></td>\n<td>低</td>\n<td><code>DISTINCT</code> (配合排序)</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"4-辅助与控制算子-materialize--control-nodes\">4. 辅助与控制算子 (Materialize &amp; Control Nodes)</h2>\n<p>这类算子不直接产生新数据，而是为了满足特定语法（排序、分页）或优化执行效率。</p>\n<ul>\n<li><strong>排序 (Sort):</strong> 执行 <code>ORDER BY</code>，如果内存装不下会触发磁盘排序。</li>\n<li><strong>物化 (Materialize):</strong> 将下层算子的结果缓存到内存中，供上层算子重复读取（常见于 Nested Loop）。</li>\n<li><strong>限制 (Limit):</strong> 处理 <code>LIMIT</code> 和 <code>OFFSET</code>，达到行数后立即停止下层算子。</li>\n<li><strong>锁定 (LockRows):</strong> 处理 <code>SELECT FOR UPDATE</code> 等锁定行操作。</li>\n<li><strong>结果 (Result):</strong> 处理不涉及表的计算（如 <code>SELECT 1+1</code>）。</li>\n</ul>\n<p>在 PostgreSQL 的执行计划中，<strong>辅助与控制算子（Auxiliary &amp; Control Nodes）</strong> 虽然不直接负责“找数据”或“拼数据”，但它们是整个流水线的<strong>调度员</strong>和<strong>加工厂</strong>。它们决定了数据如何排序、何时停止、如何并行处理以及如何锁定。</p>\n<p>以下是这类核心算子的详细讲解：</p>\n<hr />\n<h3 id=\"1-排序算子-sort-node\">1. 排序算子 (Sort Node)</h3>\n<p>这是最常见，也是最容易成为性能瓶颈的辅助算子。</p>\n<ul>\n<li>\n<p><strong>功能：</strong> 对下层算子返回的数据集进行排序（响应 <code>ORDER BY</code>，或者为 <code>Merge Join</code> 做准备）。</p>\n</li>\n<li>\n<p><strong>关键算法与内存机制：</strong></p>\n<ul>\n<li><strong>Quicksort (内存排序):</strong> 当数据量小于 <code>work_mem</code> 参数时，PostgreSQL 会在内存中完成快速排序。<strong>这是最快的。</strong></li>\n<li><strong>External Merge Sort (磁盘排序):</strong> 当数据量超过 <code>work_mem</code> 时，数据库被迫把数据写到临时文件（Disk），排好序后再合并。<strong>这会产生大量磁盘 I/O，非常慢。</strong></li>\n<li><strong>Top-N Heapsort:</strong> 当 SQL 包含 <code>ORDER BY ... LIMIT n</code> 时，数据库不需要全排，只需要维护一个大小为 N 的堆。这比全排快得多。</li>\n</ul>\n</li>\n<li>\n<p><strong>性能警报：</strong></p>\n<p>如果在 EXPLAIN 中看到 <code>Sort Method: external merge Disk: 25000kB</code>，说明内存不够用了。</p>\n<ul>\n<li><strong>优化：</strong> 调大 <code>work_mem</code>，或者建立索引（索引本身就是有序的，可以消除 Sort 算子）。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"2-限制算子-limit-node\">2. 限制算子 (Limit Node)</h3>\n<p>它是查询优化的“刹车片”。</p>\n<ul>\n<li><strong>功能：</strong> 对应 SQL 中的 <code>LIMIT</code> 和 <code>OFFSET</code>。</li>\n<li><strong>工作原理：</strong> 它像一个计数器，紧盯着下层算子吐出来的数据。一旦拿到了指定的行数（比如 10 行），它会立即<strong>切断</strong>下层算子的执行，不再让它们继续工作。</li>\n<li><strong>性能意义：</strong>\n<ul>\n<li>这是一个“逻辑算子”，本身消耗极小。</li>\n<li>它的价值在于<strong>“短路效应”</strong>。比如 <code>SELECT * FROM billion_table LIMIT 1</code>，Limit 算子会让 Seq Scan 在读到第一行时就停止，而不是扫完十亿行。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"3-物化算子-materialize-node\">3. 物化算子 (Materialize Node)</h3>\n<p>注意，这跟“物化视图”是两码事。这里的 Materialize 是执行计划中的一个<strong>临时缓存机制</strong>。</p>\n<ul>\n<li><strong>功能：</strong> 将下层算子的结果<strong>完整地读取并暂存</strong>（在内存或磁盘中），以便上层算子可以<strong>反复读取</strong>这些数据。</li>\n<li><strong>典型场景：</strong>\n<ul>\n<li>出现在 <strong>Nested Loop Join</strong>（嵌套循环连接）中。</li>\n<li>如果内表（被驱动表）是一个复杂的子查询或计算结果，数据库不希望每处理外表的一行，内表就重新计算一次。</li>\n<li><strong>优化逻辑：</strong> 内表计算一次 -&gt; Materialize 存起来 -&gt; 外表每行去 Materialize 里查。</li>\n</ul>\n</li>\n<li><strong>EXPLAIN 特征：</strong> 通常夹在 Nested Loop 和内层扫描之间。</li>\n</ul>\n<hr />\n<h3 id=\"4-并行控制算子-parallel-nodes\">4. 并行控制算子 (Parallel Nodes)</h3>\n<p>当 PostgreSQL 决定动用多个 CPU 核心来加速查询时，就会出现这些算子。它们负责协调“领队”和“工人”之间的关系。</p>\n<ul>\n<li><strong>Gather (收集):</strong>\n<ul>\n<li><strong>角色：</strong> 它是“工头”（Leader Process）。</li>\n<li><strong>功能：</strong> 启动多个并行工作线程（Workers），等待它们干完活，把结果汇总到这里，再发给上层。</li>\n</ul>\n</li>\n<li><strong>Gather Merge (有序收集):</strong>\n<ul>\n<li><strong>功能：</strong> 类似于 Gather，但它要求所有 Worker 返回的数据是有序的，并且它在汇总时会保持这种顺序（类似于归并排序的最后一步）。</li>\n<li><strong>场景：</strong> 并行查询且带有 <code>ORDER BY</code> 时。</li>\n</ul>\n</li>\n<li><strong>Parallel Seq Scan / Parallel Hash Join:</strong>\n<ul>\n<li>这些带有 <code>Parallel</code> 前缀的算子，说明它们是在 Worker 线程内部执行的。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"5-结果算子-result-node\">5. 结果算子 (Result Node)</h3>\n<p>这是最简单的算子，通常处理不涉及表扫描的计算。</p>\n<ul>\n<li><strong>功能：</strong> 计算并返回一个常量或表达式。</li>\n<li><strong>场景：</strong>\n<ul>\n<li><code>SELECT 1;</code></li>\n<li><code>SELECT version();</code></li>\n<li>某些复杂的 <code>CASE WHEN</code> 逻辑，如果优化器认为不需要查表，也会用 Result。</li>\n<li><strong>One-Time Filter:</strong> 如果 <code>WHERE</code> 条件是常量且为假（如 <code>WHERE 1=2</code>），Result 算子会直接返回空，整个查询瞬间结束。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"6-锁定算子-lockrows-node\">6. 锁定算子 (LockRows Node)</h3>\n<p>这是为了并发控制而存在的。</p>\n<ul>\n<li><strong>功能：</strong> 对应 SQL 中的 <code>SELECT ... FOR UPDATE</code> 或 <code>FOR SHARE</code>。</li>\n<li><strong>工作原理：</strong>\n<ul>\n<li>它会去访问数据行，并尝试在行头（Tuple Header）打上锁标记。</li>\n<li>如果有其他事务锁住了这行，它会在这里<strong>等待</strong>（Blocked），直到锁释放或超时。</li>\n</ul>\n</li>\n<li><strong>位置：</strong> 通常位于执行计划的最顶层附近，确保数据在返回给用户前已经被锁住。</li>\n</ul>\n<hr />\n<h3 id=\"总结如何通过这些算子诊断问题\">总结：如何通过这些算子诊断问题？</h3>\n<table>\n<thead>\n<tr>\n<th><strong>算子</strong></th>\n<th><strong>看到的现象</strong></th>\n<th><strong>潜在问题</strong></th>\n<th><strong>解决方案</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Sort</strong></td>\n<td><code>Disk: xxx kB</code></td>\n<td>内存溢出，磁盘排序</td>\n<td>调大 <code>work_mem</code> 或加索引</td>\n</tr>\n<tr>\n<td><strong>Materialize</strong></td>\n<td>耗时很久</td>\n<td>内层子查询太重</td>\n<td>优化子查询，或改写 JOIN 逻辑</td>\n</tr>\n<tr>\n<td><strong>Gather</strong></td>\n<td><code>Workers Planned: 2, Launched: 0</code></td>\n<td>并行未生效</td>\n<td>检查服务器负载或并行参数配置</td>\n</tr>\n<tr>\n<td><strong>LockRows</strong></td>\n<td>查询卡死不返回</td>\n<td>锁竞争</td>\n<td>检查是否有长事务未提交</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"5并行算子-parallel-nodes\">5.并行算子 (Parallel Nodes)</h2>\n<p>在开启并行查询时，你会看到带 <code>Gather</code> 前缀的特殊算子：</p>\n<ul>\n<li><strong>Gather:</strong> 汇总节点。收集所有并行工作线程（Workers）的结果。</li>\n<li><strong>Gather Merge:</strong> 收集结果的同时保持数据的有序性。</li>\n<li><strong>Parallel Seq Scan:</strong> 多个线程同时分段扫描一张表。</li>\n</ul>\n<p>在 PostgreSQL 9.6 之前，无论服务器有多少个 CPU 核心，一条 SQL 查询只能使用<strong>一个 CPU 核</strong>（单线程）。这就像让你一个人搬一万块砖，哪怕旁边站着 10 个人也没用。<strong>并行算子 (Parallel Nodes)</strong> 的引入彻底改变了这一点。它允许数据库启动多个后台工作线程（Background Workers），大家一起干活，最后由“包工头”汇总结果。以下是并行查询的核心架构与关键算子详解：</p>\n<hr />\n<h3 id=\"1-核心架构领队与工人-leader--workers\">1. 核心架构：领队与工人 (Leader &amp; Workers)</h3>\n<p>理解并行算子，首先要理解 PostgreSQL 的并行模型：</p>\n<ol>\n<li><strong>Leader Process (领队进程):</strong>\n<ul>\n<li>这是你连接数据库的那个主会话进程。</li>\n<li>它负责制定计划、分配任务、启动 Worker、收集结果，并把最终结果返回给客户端。</li>\n</ul>\n</li>\n<li><strong>Worker Processes (工人进程):</strong>\n<ul>\n<li>由 Leader 动态启动。</li>\n<li>它们执行计划中标记为 <code>Parallel</code> 的部分（如扫描、聚合、连接）。</li>\n<li>它们通过<strong>动态共享内存 (Dynamic Shared Memory, DSM)</strong> 与 Leader 交换数据。</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h3 id=\"2-关键算子详解\">2. 关键算子详解</h3>\n<p>在执行计划树中，并行部分通常位于树的<strong>下半部分</strong>，顶部总会有一个 <code>Gather</code> 类的节点作为分界线。</p>\n<h5 id=\"a-gather-汇总算子\">A. Gather (汇总算子)</h5>\n<p>这是并行执行的<strong>总出口</strong>，也是 Leader 进程主要工作的地方。</p>\n<ul>\n<li><strong>功能：</strong>\n<ol>\n<li>启动 N 个 Worker 线程。</li>\n<li>等待所有 Worker 把数据处理完。</li>\n<li>把 Worker 传回来的数据（以及 Leader 自己处理的一部分数据）合并在一起。</li>\n<li>向上层算子输出非并行的结果流。</li>\n</ol>\n</li>\n<li><strong>EXPLAIN 关键信息：</strong>\n<ul>\n<li><code>Workers Planned: 2</code>: 计划启动 2 个工人。</li>\n<li><code>Workers Launched: 2</code>: 实际启动了 2 个。如果系统负载太高，Launched 可能小于 Planned，甚至为 0（降级为单线程）。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"b-gather-merge-有序汇总算子\">B. Gather Merge (有序汇总算子)</h5>\n<p>这是 <code>Gather</code> 的升级版，用于需要<strong>保留顺序</strong>的场景。</p>\n<ul>\n<li><strong>功能：</strong>\n<ul>\n<li>假设下层的每个 Worker 返回的数据都已经局部排好序了。</li>\n<li><code>Gather Merge</code> 就像归并排序的最后一步，它读取所有 Worker 的输出，通过比较，按顺序把数据吐给上层。</li>\n</ul>\n</li>\n<li><strong>适用场景：</strong> SQL 中有 <code>ORDER BY</code>，且下层走了 <code>Parallel Index Scan</code> 或做过并行排序。</li>\n</ul>\n<h5 id=\"c-parallel-seq-scan-并行全表扫描\">C. Parallel Seq Scan (并行全表扫描)</h5>\n<p>这是 Worker 们最常干的活。</p>\n<ul>\n<li><strong>工作原理：</strong>\n<ul>\n<li>并不是把表切成 N 份固定分配给 N 个 Worker。</li>\n<li>而是采用<strong>“抢任务”模式（Block-by-Block）</strong>。</li>\n<li>所有 Worker（加上 Leader）共享一个扫描游标。谁扫完一个数据块（Block），就向系统申请下一个块。这样能防止有的 Worker 扫到了空闲页很快干完，有的 Worker 扫到了大对象页累死。</li>\n</ul>\n</li>\n<li><strong>优势：</strong> 极大地提高了 IO吞吐量（如果磁盘撑得住）和 CPU 过滤速度。</li>\n</ul>\n<h5 id=\"d-parallel-hash--parallel-hash-join-并行哈希连接\">D. Parallel Hash / Parallel Hash Join (并行哈希连接)</h5>\n<p>这是 PostgreSQL 11+ 引入的重磅功能。</p>\n<ul>\n<li><strong>传统 Hash Join：</strong> 一个进程构建哈希表，构建完再探测。</li>\n<li><strong>并行 Hash Join：</strong>\n<ol>\n<li><strong>Shared Hash Table:</strong> 所有 Worker 共同在共享内存中构建<strong>同一个</strong>巨大的哈希表。</li>\n<li><strong>协同探测:</strong> 构建完成后，所有 Worker 再并行去扫描外表，利用这个共享哈希表进行探测。</li>\n</ol>\n</li>\n<li><strong>注意：</strong> 这非常消耗内存！</li>\n</ul>\n<hr />\n<h3 id=\"3-一个典型的并行执行计划\">3. 一个典型的并行执行计划</h3>\n<p>假设我们要统计一张 1 亿行大表 <code>big_table</code> 的行数：</p>\n<p>SQL</p>\n<pre><code class=\"language-sql\">EXPLAIN SELECT count(*) FROM big_table;\n</code></pre>\n<p><strong>执行计划可能长这样：</strong></p>\n<pre><code class=\"language-sql\">Finalize Aggregate  (cost=... rows=1 ...)\n  -&gt;  Gather  (cost=... rows=3 ...)\n        Workers Planned: 2\n        -&gt;  Partial Aggregate  (cost=... rows=1 ...)\n              -&gt;  Parallel Seq Scan on big_table  (cost=... rows=41666666 ...)\n</code></pre>\n<p><strong>解读（自下而上）：</strong></p>\n<ol>\n<li>\n<p><strong>Parallel Seq Scan:</strong> 表被分成了很多块，3 个进程（1 个 Leader + 2 个 Workers）同时去抢着扫描。</p>\n</li>\n<li>\n<p><strong>Partial Aggregate (部分聚合):</strong> 每个 Worker 扫完自己那部分数据后，先在本地算一个 <code>count</code>（比如 Worker A 算出 3000 万，Worker B 算出 3500 万）。</p>\n</li>\n<li>\n<p><strong>Partial Aggregate (部分聚合):</strong> 是<strong>工人</strong>（Worker）在干活。每个人只算自己手头那一小堆数据的“小账”。</p>\n<p><strong>Aggregate / Finalize Aggregate (最终聚合):</strong> 是<strong>老板</strong>（Leader）在干活。他把工人们报上来的“小账”加在一起，算出“总账”。</p>\n</li>\n<li>\n<p><strong>Gather:</strong> Leader 进程把这 3 个部分结果收上来。</p>\n</li>\n<li>\n<p><strong>Finalize Aggregate (最终聚合):</strong> Leader 把收上来的 3 个数字加在一起，得到最终的 1 亿，返回给用户。</p>\n</li>\n</ol>\n<hr />\n<h3 id=\"4-并行算子的坑与调优\">4. 并行算子的“坑”与调优</h3>\n<p>虽然并行很快，但它不是银弹，使用时需注意：</p>\n<ol>\n<li><strong>启动成本：</strong> 启动 Worker 进程是有开销的。如果查询本身只需 10ms，开启并行可能反而要花 20ms。PostgreSQL 会通过 <code>min_parallel_table_scan_size</code> 参数自动判断表够不够大，小表不会走并行。</li>\n<li><strong>内存倍增风险 (work_mem):</strong>\n<ul>\n<li><strong>切记：</strong> <code>work_mem</code> 是限制<strong>每个进程</strong>的内存。</li>\n<li>如果你设置 <code>work_mem = 1GB</code>，并启动了 4 个 Worker。那么这个查询理论上最高可能消耗 <code>(4 + 1) * 1GB = 5GB</code> 内存。容易导致 OOM（内存溢出）。</li>\n</ul>\n</li>\n<li><strong>写操作限制：</strong> 目前，并行查询主要用于 <code>SELECT</code>。对于 <code>UPDATE</code> / <code>DELETE</code>，只有在 <code>RETURNING</code> 子句后的部分或者子查询中才能利用并行，修改数据本身的操作通常是单线程的。</li>\n</ol>\n<h3 id=\"总结-1\">总结</h3>\n<ul>\n<li><strong>Gather</strong> = 包工头（汇总）。</li>\n<li><strong>Parallel Scan</strong> = 工人（干苦力）。</li>\n<li><strong>核心优势</strong> = OLAP 类查询（大表扫描、聚合、大连接）速度成倍提升。</li>\n<li><strong>代价</strong> = CPU 飙升，内存消耗翻倍。</li>\n</ul>\n<h1 id=\"阻塞算子和非阻塞算子\">阻塞算子和非阻塞算子</h1>\n<p>这是一个非常关键的概念，它直接决定了你的 SQL 查询是<strong>“马上就有结果蹦出来”</strong>，还是<strong>“等了半天没反应，然后哗啦一下全出来了”</strong>。</p>\n<p>在数据库执行计划中，算子根据处理数据的方式，分为<strong>阻塞（Blocking）</strong>和<strong>非阻塞（Non-Blocking / Pipelined）</strong>两大类。</p>\n<p>我们可以用<strong>“自来水管”</strong>和<strong>“蓄水池”</strong>来比喻。</p>\n<hr />\n<h2 id=\"1-非阻塞算子-non-blocking-operators--自来水管\">1. 非阻塞算子 (Non-Blocking Operators) —— 自来水管</h2>\n<p><strong>特点：</strong></p>\n<ul>\n<li><strong>即时性：</strong> 只要从下层拿到了<strong>一行</strong>数据，处理完马上就吐给上层（或者返回给用户）。</li>\n<li><strong>流式处理 (Pipelined)：</strong> 数据像水流一样，源源不断地穿过算子。</li>\n<li><strong>低延迟：</strong> 用户能很快看到第一条结果（First Row Time 极短）。</li>\n</ul>\n<p><strong>典型算子：</strong></p>\n<ul>\n<li><strong>Seq Scan / Index Scan:</strong> 读到一行，就给一行。</li>\n<li><strong>Nested Loop Join:</strong> 只要外表找到一行，去内表匹配到了，就立马返回这一行结果。</li>\n<li><strong>Limit:</strong> 拿到一行算一行，数够了就关门。</li>\n<li><strong>Append:</strong> (<code>UNION ALL</code>) 读完这表读那表，中间不停顿。</li>\n</ul>\n<p><strong>场景举例：</strong></p>\n<pre><code class=\"language-sql\">SELECT * FROM users WHERE age &gt; 20 LIMIT 10;\n</code></pre>\n<p>数据库扫到第一条 <code>age &gt; 20</code> 的人，你马上就能在屏幕上看到。不需要等全表扫完。</p>\n<hr />\n<h2 id=\"2-阻塞算子-blocking-operators--蓄水池\">2. 阻塞算子 (Blocking Operators) —— 蓄水池</h2>\n<p><strong>特点：</strong></p>\n<ul>\n<li><strong>全量等待：</strong> 必须把下层传上来的<strong>所有数据</strong>都读完、存下来（通常在内存或磁盘），处理完毕后，才能吐出<strong>第一行</strong>结果。</li>\n<li><strong>物化 (Materialization)：</strong> 数据在这个算子这里“停滞”了，被堆积成了临时结果集。</li>\n<li><strong>高延迟：</strong> 在处理完最后一行数据之前，用户什么都看不到。</li>\n</ul>\n<p><strong>典型算子：</strong></p>\n<ul>\n<li><strong>Sort (排序):</strong> 这是最典型的阻塞算子。你想输出“最贵”的商品，必须把<strong>所有</strong>商品都看一遍并排好序，才能知道谁是第一名。</li>\n<li><strong>Aggregate (聚合):</strong> 比如 <code>COUNT</code>, <code>SUM</code>, <code>AVG</code>。你必须数完所有豆子，才能告诉我总共有多少颗。</li>\n<li><strong>Hash Join (Build Phase):</strong> 哈希连接的第一步是构建哈希表。它必须把一张表完全读入内存构建好 Hash Map，才能开始探测第二张表。</li>\n<li><strong>Unique / DISTINCT:</strong> 为了去重，通常需要把数据全看一遍（除非基于有序索引）。</li>\n</ul>\n<p><strong>场景举例：</strong></p>\n<pre><code class=\"language-sql\">SELECT * FROM users ORDER BY age;\n</code></pre>\n<p>哪怕你只看前 10 行，数据库也得把 100 万行用户全读出来，排好序，才能给你最年轻的那 10 个。</p>\n<hr />\n<h2 id=\"3-半阻塞算子-hash-join-的特殊性\">3. 半阻塞算子 (Hash Join 的特殊性)</h2>\n<p><strong>Hash Join</strong> 是个有趣的混合体：</p>\n<ol>\n<li><strong>阶段一（阻塞）：</strong> 构建哈希表（Build Hash Table）。\n<ul>\n<li>数据库读取<strong>右表（内表）</strong>的所有数据。此时，查询处于“卡顿”状态，没有任何输出。</li>\n</ul>\n</li>\n<li><strong>阶段二（非阻塞）：</strong> 探测（Probe）。\n<ul>\n<li>哈希表建好后，数据库开始扫描<strong>左表（外表）</strong>。每读一行左表，去哈希表里查一下。查到了，<strong>立刻输出</strong>。</li>\n</ul>\n</li>\n</ol>\n<p>所以，Hash Join 的启动速度取决于右表的大小。这也解释了为什么优化器总是喜欢用<strong>小表</strong>来做 Hash Join 的构建表。</p>\n<hr />\n<h2 id=\"4-为什么要区分这个\">4. 为什么要区分这个？</h2>\n<p>理解阻塞与非阻塞，对性能优化有两大指导意义：</p>\n<h3 id=\"a-响应时间-vs-总时间-response-time-vs-total-time\">A. 响应时间 vs. 总时间 (Response Time vs. Total Time)</h3>\n<ul>\n<li><strong>OLTP 系统（Web 应用）：</strong> 用户希望点开页面立马看到内容。\n<ul>\n<li><strong>目标：</strong> 尽量使用<strong>非阻塞算子</strong>。</li>\n<li><strong>策略：</strong> 利用索引消除 <code>Sort</code>，利用 Nested Loop 代替 Hash Join（在数据量小时）。</li>\n</ul>\n</li>\n<li><strong>OLAP 系统（报表分析）：</strong> 用户可以等 10 秒，但必须跑完几亿行数据。\n<ul>\n<li><strong>目标：</strong> 吞吐量优先。</li>\n<li><strong>策略：</strong> <strong>阻塞算子</strong>（如 Hash Join, Sort Merge Join）通常在处理大数据量时效率更高。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"b-内存消耗-work_mem\">B. 内存消耗 (<code>work_mem</code>)</h3>\n<ul>\n<li><strong>非阻塞算子</strong>通常不怎么吃内存，因为它们只处理当前这一行。</li>\n<li><strong>阻塞算子</strong>是<strong>内存杀手</strong>。<code>Sort</code> 需要内存排序，<code>Hash Agg</code> 需要内存存哈希表。如果内存 (<code>work_mem</code>) 不够，它们就会把数据写到<strong>磁盘临时文件</strong>，导致性能从“内存级”跌落到“磁盘级”（慢 1000 倍）。</li>\n</ul>\n<h2 id=\"5-如何在-explain-中看出来\">5. 如何在 EXPLAIN 中看出来？</h2>\n<p>看 <code>cost</code> 的两个数字：</p>\n<pre><code>cost=启动代价..总代价\n</code></pre>\n<ul>\n<li><strong>非阻塞算子：</strong> 启动代价（第一个数字）通常很小，接近 <strong>0.00</strong>。\n<ul>\n<li><code>Seq Scan (cost=0.00..145.00)</code> -&gt; 马上开始。</li>\n</ul>\n</li>\n<li><strong>阻塞算子：</strong> 启动代价通常<strong>很大</strong>，接近总代价。\n<ul>\n<li><code>Sort (cost=1000.00..1050.00)</code> -&gt; 前 1000 的代价都在等它排序，排完才开始输出。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"总结图表\">总结图表</h3>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>非阻塞算子 (Pipeline)</strong></th>\n<th><strong>阻塞算子 (Blocking)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>比喻</strong></td>\n<td>水管流过</td>\n<td>蓄水池蓄满</td>\n</tr>\n<tr>\n<td><strong>首行输出</strong></td>\n<td>极快 (0ms 级别)</td>\n<td>慢 (需处理完所有数据)</td>\n</tr>\n<tr>\n<td><strong>内存消耗</strong></td>\n<td>低 (处理完即丢)</td>\n<td>高 (需缓存所有数据)</td>\n</tr>\n<tr>\n<td><strong>典型代表</strong></td>\n<td>Nested Loop, Seq/Index Scan</td>\n<td>Sort, Hash Agg, Hash Join(构建端)</td>\n</tr>\n<tr>\n<td><strong>优化方向</strong></td>\n<td>适合分页、快速响应</td>\n<td>适合全量统计、大数据吞吐</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"执行计划分析\">执行计划分析</h1>\n<h2 id=\"第一维度explain\">第一维度：EXPLAIN</h2>\n<p>在使用之前，你必须知道你手里拿的是哪一把“手术刀”。不同的参数组合，看到的深度完全不同。</p>\n<ol>\n<li><strong>Level 1: <code>EXPLAIN SELECT ...</code> (静态推演)</strong>\n<ul>\n<li><strong>发生了什么：</strong> 数据库<strong>没有</strong>执行 SQL。它只是根据统计信息（Statistics）“脑补”了一个计划。</li>\n<li><strong>能看什么：</strong> 优化器打算怎么做、预估的成本（Cost）、预估的行数。</li>\n<li><strong>缺点：</strong> 它是猜的。如果统计信息过期，看到的计划可能完全是错的。</li>\n<li><strong>适用场景：</strong> SQL 跑得太慢不敢运行，或者涉及 <code>DELETE</code>/<code>UPDATE</code> 不想弄脏数据。</li>\n</ul>\n</li>\n<li><strong>Level 2: <code>EXPLAIN (ANALYZE) SELECT ...</code> (实战复盘)</strong>\n<ul>\n<li><strong>发生了什么：</strong> 数据库<strong>真的</strong>执行了 SQL（注意：如果是修改语句，数据真的会变！）。</li>\n<li><strong>能看什么：</strong> 除了预估值，还能看到<strong>实际耗时（Actual Time）</strong>、<strong>实际行数（Actual Rows）</strong>、<strong>循环次数（Loops）</strong>。</li>\n<li><strong>核心价值：</strong> 对比“预估”和“实际”的差异，这是调优的根基。</li>\n</ul>\n</li>\n<li><strong>Level 3: <code>EXPLAIN (ANALYZE, BUFFERS) SELECT ...</code> (IO 透视)</strong> —— <strong>最推荐！</strong>\n<ul>\n<li><strong>发生了什么：</strong> 在执行的基础上，统计了<strong>内存和磁盘的交互</strong>。</li>\n<li><strong>能看什么：</strong> 数据是从内存（Shared Buffers）读的，还是从硬盘（Disk）读的。</li>\n<li><strong>核心价值：</strong> 数据库慢，90% 是因为 IO。不看 Buffers 就无法精准定位 IO 瓶颈。</li>\n</ul>\n</li>\n<li><strong>Level 4: <code>EXPLAIN (ANALYZE, VERBOSE, SETTINGS) SELECT ...</code> (全息视图)</strong>\n<ul>\n<li><strong>VERBOSE:</strong> 显示每个算子具体输出了哪些列（Output List），有助于分析是否查了不该查的字段。</li>\n<li><strong>SETTINGS:</strong> 显示哪些非默认参数影响了这次计划（比如你临时把 <code>enable_seqscan</code> 关了）。</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第二维度解构树状执行流\">第二维度：解构树状执行流</h2>\n<p>执行计划是一个嵌套的树状结构。理解它的阅读顺序至关重要。</p>\n<h4 id=\"1-阅读法则由内向外自下而上\">1. 阅读法则：由内向外，自下而上</h4>\n<ul>\n<li><strong>缩进最深</strong>的节点，通常是“叶子节点”，最先开始工作（通常是扫描表）。</li>\n<li><strong>缩进相同</strong>的节点，通常按顺序执行（对于 Hash Join，上面的分支是 Build，下面的分支是 Probe）。</li>\n<li><strong>父节点</strong>依赖子节点的输出。</li>\n</ul>\n<h4 id=\"2-箭头---的含义\">2. 箭头 <code>-&gt;</code> 的含义</h4>\n<p>它代表数据的<strong>流动方向</strong>。子节点把处理好的数据“喂”给父节点。</p>\n<h4 id=\"3-示例结构解析\">3. 示例结构解析</h4>\n<p>Plaintext</p>\n<pre><code class=\"language-sql\">-&gt;  Sort  (Level 1: 最后执行，等待 Hash Join 的结果)\n    -&gt;  Hash Join  (Level 2: 它是 Sort 的孩子，等待 Hash 和 Seq Scan 的结果)\n          Hash Cond: (t1.id = t2.uid)\n          -&gt;  Seq Scan on large_table t1  (Level 3: 和下面的 Hash 处于同一级)\n          -&gt;  Hash  (Level 3: 它是 Hash Join 的内表构建过程)\n                -&gt;  Seq Scan on small_table t2 (Level 4: 最先执行，扫描小表)\n</code></pre>\n<p><strong>真实执行逻辑：</strong></p>\n<ol>\n<li>先扫描 <code>small_table t2</code>。</li>\n<li>将 t2 的数据构建成一个内存哈希表（Hash 节点）。</li>\n<li>扫描 <code>large_table t1</code>。</li>\n<li>每扫描一行 t1，就去哈希表里比对（Hash Join）。</li>\n<li>比对成功的结果，交给 <code>Sort</code> 节点排序。</li>\n<li>排序完返回给用户。</li>\n</ol>\n<hr />\n<h2 id=\"第三维度核心参数深度解码\">第三维度：核心参数深度解码</h2>\n<p>我们来看一行典型的输出，把它像拆炸弹一样拆解开：</p>\n<pre><code class=\"language-sql\">-&gt;  Seq Scan on orders  (cost=0.00..188.00 rows=1000 width=45) (actual time=0.006..2.500 rows=1200 loops=1)\n</code></pre>\n<h4 id=\"a-预估部分-括号第一部分\">A. 预估部分 (括号第一部分)</h4>\n<ol>\n<li><strong><code>cost=0.00..188.00</code> (代价)</strong>\n<ul>\n<li><strong>单位：</strong> 这是一个抽象值，没有单位（通常 1.0 代表读取一个磁盘页的代价）。</li>\n<li><strong>0.00 (Startup Cost - 启动代价)：</strong> 拿到<strong>第一行</strong>数据前需要多长时间。\n<ul>\n<li><code>Seq Scan</code> 是 0，因为我们要的第一行就在第一页。</li>\n<li><code>Sort</code> 节点这里会很大，因为它必须把所有数据排完序才能吐出第一行。</li>\n</ul>\n</li>\n<li><strong>188.00 (Total Cost - 总代价)：</strong> 拿到<strong>所有</strong>数据需要的总代价。优化器（Planner）就是凭这个数字选路，它会选 Total Cost 最小的那条路。</li>\n</ul>\n</li>\n<li><strong><code>rows=1000</code> (预估行数)</strong>\n<ul>\n<li>优化器根据统计信息（pg_statistic）猜出来的。</li>\n<li><strong>重要性：</strong> 它是决定走 Nested Loop 还是 Hash Join 的关键。如果这里猜错了，计划就会选错。</li>\n</ul>\n</li>\n<li><strong><code>width=45</code> (行宽度)</strong>\n<ul>\n<li>平均每一行数据占用 45 字节。</li>\n<li><strong>重要性：</strong> <code>rows * width</code> = 预估的总数据量。这决定了需不需要把数据写到临时文件（Disk Spill），因为内存（work_mem）是有限的。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"b-实际执行部分-括号第二部分仅在-analyze-模式下出现\">B. 实际执行部分 (括号第二部分，仅在 ANALYZE 模式下出现)</h4>\n<ol>\n<li>\n<p><strong><code>actual time=0.006..2.500</code> (实际时间)</strong></p>\n<ul>\n<li><strong>单位：</strong> 毫秒 (ms)。</li>\n<li><strong>0.006 (Start Time)：</strong> 拿到第一行花了 0.006ms。</li>\n<li><strong>2.500 (Total Time)：</strong> <strong>平均每次循环</strong>拿到所有数据花了 2.5ms。</li>\n<li><strong>坑点：</strong> 如果 <code>loops &gt; 1</code>，真实总时间 = <code>Total Time * loops</code>。</li>\n</ul>\n</li>\n<li>\n<p><strong><code>rows=1200</code> (实际行数)</strong></p>\n<ul>\n<li>真实返回了多少行。</li>\n</ul>\n</li>\n<li>\n<p><strong><code>loops=1</code> (循环次数)</strong></p>\n<ul>\n<li>\n<p>这个算子被执行了几次。</p>\n</li>\n<li>\n<p><strong>Nested Loop 中的大坑：</strong></p>\n<pre><code class=\"language-sql\">-&gt;  Index Scan on child_table ... (actual time=0.005..0.010 rows=1 loops=10000)\n</code></pre>\n<p>乍一看只花了 0.01ms？<strong>错！</strong> 真实的耗时是 <code>0.010 * 10000 = 100ms</code>。<strong>一定要乘 Loops！</strong></p>\n</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第四维度buffers--io-的秘密\">第四维度：Buffers —— IO 的秘密</h2>\n<p>加上 <code>BUFFERS</code> 选项后，你会看到类似这样的输出：</p>\n<pre><code>Buffers: shared hit=5 read=10 dirtied=2 written=1\n</code></pre>\n<p>这是判断性能瓶颈的金标准：</p>\n<ol>\n<li><strong>Shared Hit (内存命中):</strong>\n<ul>\n<li>数据直接从 PostgreSQL 的共享内存（Shared Buffers）里拿到了。</li>\n<li><strong>评价：</strong> 很好，极快。我们希望 Hit 越高越好。</li>\n</ul>\n</li>\n<li><strong>Read (磁盘读取):</strong>\n<ul>\n<li>内存里没有，必须向操作系统申请从磁盘读。</li>\n<li><strong>评价：</strong> 慢。如果 Read 很高，说明内存不够用，或者索引没建好导致扫描了太多冷数据。</li>\n</ul>\n</li>\n<li><strong>Dirtied (脏页):</strong>\n<ul>\n<li>查询过程中，发现数据页被修改了（通常是未提交的事务），需要标记为脏页。</li>\n<li><strong>评价：</strong> 在 <code>SELECT</code> 查询中不应该大量出现。</li>\n</ul>\n</li>\n<li><strong>Temp Read / Written (临时文件读写):</strong>\n<ul>\n<li><strong>评价：</strong> <strong>灾难级</strong>。</li>\n<li>说明 <code>work_mem</code> 太小，排序（Sort）或哈希表（Hash）在内存装不下，被迫把数据写到硬盘上再读回来。这会让查询慢几个数量级。</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第五维度警示信号--看到这些要报警\">第五维度：警示信号 —— 看到这些要报警</h2>\n<p>在审视长篇大论的计划时，请带上“找茬”的眼镜，寻找以下红线：</p>\n<h4 id=\"1-估算与实际的巨大偏差-estimation-skew\">1. 估算与实际的巨大偏差 (Estimation Skew)</h4>\n<ul>\n<li><strong>现象：</strong> <code>rows=1</code>，但 <code>actual rows=1000000</code>。</li>\n<li><strong>后果：</strong> 优化器以为数据很少，选了 Nested Loop，结果被海量数据教做人。</li>\n<li><strong>对策：</strong> <code>ANALYZE table_name;</code> 更新统计信息。</li>\n</ul>\n<h4 id=\"2-高-filter-移除率-high-filter-ratio\">2. 高 Filter 移除率 (High Filter Ratio)</h4>\n<ul>\n<li><strong>现象：</strong> <code>Rows Removed by Filter: 99999</code> (Seq Scan 返回了 10 万行，过滤丢掉了 9 万 9 千行)。</li>\n<li><strong>含义：</strong> 数据库做了大量无用功。它像个笨拙的图书管理员，把整架书搬下来，一本本看，最后只给你一本。</li>\n<li><strong>对策：</strong> 针对 Filter 的条件建立索引。</li>\n</ul>\n<h4 id=\"3-临时文件溢出-disk-spill\">3. 临时文件溢出 (Disk Spill)</h4>\n<ul>\n<li><strong>现象：</strong> <code>Disk: 10240kB</code> (出现在 Sort 或 Hash 节点)。</li>\n<li><strong>对策：</strong> 调大 <code>work_mem</code> 参数，或者优化 SQL 减少排序/聚合的数据量。</li>\n</ul>\n<h4 id=\"4-错误的连接方式\">4. 错误的连接方式</h4>\n<ul>\n<li><strong>现象：</strong> 两个大表连接（比如各 100 万行），却用了 <code>Nested Loop</code>。</li>\n<li><strong>原因：</strong> 通常是因为上述的“估算偏差”导致的。</li>\n</ul>\n<hr />\n<h2 id=\"第六维度实战逐行拆解案例\">第六维度：实战逐行拆解案例</h2>\n<p>让我们来看一个包含“坑”的真实复杂案例。</p>\n<pre><code class=\"language-sql\">SELECT * FROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE u.age &gt; 20 AND o.status = 'paid'\nORDER BY o.create_time LIMIT 10;\n</code></pre>\n<p><strong>Execution Plan:</strong></p>\n<pre><code class=\"language-sql\">Limit  (cost=100.50..100.60 rows=10) (actual time=55.000..55.010 rows=10 loops=1)\n  -&gt;  Sort  (cost=100.50..105.00 rows=500) (actual time=55.000..55.005 rows=10 loops=1)\n        Sort Key: o.create_time\n        Sort Method: external merge  Disk: 800kB  &lt;-- 警报 1\n        -&gt;  Hash Join  (cost=20.00..80.00 rows=500) (actual time=10.000..45.000 rows=10000 loops=1)\n              Hash Cond: (o.user_id = u.id)\n              -&gt;  Seq Scan on orders o  (cost=0.00..50.00 rows=2000) (actual time=0.005..15.000 rows=50000 loops=1) &lt;-- 警报 2\n                    Filter: (status = 'paid')\n                    Rows Removed by Filter: 100000  &lt;-- 警报 3\n              -&gt;  Hash  (cost=15.00..15.00 rows=100) (actual time=5.000..5.000 rows=100 loops=1)\n                    Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                    -&gt;  Seq Scan on users u  (cost=0.00..15.00 rows=100) (actual time=0.004..3.000 rows=100 loops=1)\n                          Filter: (age &gt; 20)\n</code></pre>\n<p><strong>逐行侦探分析：</strong></p>\n<ol>\n<li><strong>看最下面 (users):</strong> <code>Seq Scan on users</code>。扫了 users 表，过滤 <code>age &gt; 20</code>，剩 100 行。速度挺快 (3ms)，没大毛病。</li>\n<li><strong>看中间 (Hash):</strong> 把这 100 个 user 放入内存哈希表。内存只用了 9kB，很健康。</li>\n<li><strong>看下面 (orders) - [警报 2 &amp; 3]:</strong>\n<ul>\n<li><code>Seq Scan on orders</code>。</li>\n<li><code>Filter: status='paid'</code>。</li>\n<li><code>Rows Removed by Filter: 100000</code>。</li>\n<li><strong>解读：</strong> 为了找 'paid' 的订单，全表扫描并扔掉了 10 万行废数据！</li>\n<li><strong>优化：</strong> 应该在 <code>orders(status)</code> 上加索引。</li>\n</ul>\n</li>\n<li><strong>看 Join (Hash Join):</strong>\n<ul>\n<li><code>actual rows=10000</code>。Join 完有 1 万行数据。</li>\n</ul>\n</li>\n<li><strong>看排序 (Sort) - [警报 1]:</strong>\n<ul>\n<li><code>Sort Method: external merge Disk: 800kB</code>。</li>\n<li><strong>解读：</strong> 这里的 1 万行数据要排序，但是内存不够用了，数据溢出到了磁盘（Disk）。这严重拖慢了速度。</li>\n<li><strong>优化：</strong> 调大 <code>work_mem</code>，或者给 <code>orders(user_id, status, create_time)</code> 加复合索引，可能直接消除排序。</li>\n</ul>\n</li>\n<li><strong>看顶层 (Limit):</strong> 取了前 10 条。</li>\n</ol>\n<h2 id=\"总结-2\">总结</h2>\n<p>看执行计划，本质上是在回答三个问题：</p>\n<ol>\n<li><strong>数据怎么找的？</strong> (Scan: 是傻傻的扫全表，还是聪明的查索引？)</li>\n<li><strong>数据怎么连的？</strong> (Join: 是双层循环，还是哈希匹配？)</li>\n<li><strong>资源够不够？</strong> (Buffer/Disk: 内存命中率高吗？有没有溢出到磁盘？)</li>\n</ol>\n<p>只要抓住了 <code>Actual Time</code>（真实耗时）、<code>Rows Removed</code>（过滤浪费）和 <code>Disk/Buffers</code>（资源瓶颈），你就掌握了性能优化的钥匙。</p>\n<h1 id=\"查询优化器\">查询优化器</h1>\n<p>简单来说，数据库做决定的过程，就像是你在用地图软件导航。</p>\n<ul>\n<li><strong>起点</strong>是数据现在的状态。</li>\n<li><strong>终点</strong>是你想要的查询结果。</li>\n<li><strong>路径</strong>就是各种“执行计划”。</li>\n<li><strong>优化器</strong>就是那个算法，它需要在成千上万条可能的路线中，算出一条<strong>“代价（Cost）最低”</strong>的路。</li>\n</ul>\n<p>这个过程被称为 <strong>CBO (Cost-Based Optimization，基于代价的优化)</strong>。以下是它做决定的完整逻辑链条：</p>\n<hr />\n<h2 id=\"第一阶段预处理与逻辑优化-query-rewriting\">第一阶段：预处理与逻辑优化 (Query Rewriting)</h2>\n<p>在计算代价之前，优化器会先对你的 SQL 做“整形手术”，把它改写成逻辑上等价但更容易优化的形式。这叫<strong>逻辑优化</strong>。</p>\n<ul>\n<li><strong>去除多余条件：</strong> 比如 <code>WHERE 1=1</code> 会被删掉。</li>\n<li><strong>常量折叠：</strong> <code>WHERE id = 1 + 2</code> 会变成 <code>WHERE id = 3</code>。</li>\n<li><strong>视图合并 (View Merging)：</strong> 如果查询里用了视图，优化器会试图把视图拆开，把里面的表直接拿出来和外面的表连接，扩大选择空间。</li>\n<li><strong>子查询扁平化 (Subquery Unnesting)：</strong> 尽量把子查询改写成 JOIN，因为数据库处理 JOIN 的算法比处理子查询丰富得多。</li>\n</ul>\n<hr />\n<h2 id=\"第二阶段枚举候选计划-plan-enumeration\">第二阶段：枚举候选计划 (Plan Enumeration)</h2>\n<p>这是最耗时的步骤。优化器会像变魔术一样，排列组合出各种可能的执行路径。</p>\n<p>如果不加限制，一个涉及 5 张表的查询，可能的连接顺序就有 5! = 120 种，再乘以每两张表可能有 3 种连接方式（Hash/Nested/Merge），再乘以每张表可能有 2-3 种扫描方式（Seq/Index/Bitmap）……<strong>搜索空间是指数级爆炸的</strong>。</p>\n<p>优化器主要考虑三个维度的组合：</p>\n<ol>\n<li><strong>访问路径 (Access Path)：</strong>\n<ul>\n<li>表 A：是用全表扫描，还是用索引 X，还是用索引 Y？</li>\n</ul>\n</li>\n<li><strong>连接顺序 (Join Order)：</strong>\n<ul>\n<li>是先 A Join B，结果再 Join C？</li>\n<li>还是先 B Join C，结果再 Join A？</li>\n</ul>\n</li>\n<li><strong>连接算法 (Join Method)：</strong>\n<ul>\n<li>是用 Nested Loop，还是 Hash Join，还是 Merge Join？</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第三阶段代价估算-cost-estimation--核心中的核心\">第三阶段：代价估算 (Cost Estimation) —— 核心中的核心</h2>\n<p>面对生成的一堆候选计划，优化器怎么知道哪个好？它需要给每个计划算一个分（Cost）。</p>\n<p><strong>公式大致如下（简化版）：</strong></p>\n<p>Cost = (IO代价 \\times IO权重) + (CPU代价 \\times CPU权重)</p>\n<p>为了算出这个公式，优化器必须依赖<strong>统计信息 (Statistics)</strong>。如果统计信息不准，优化器就会变成“盲人”。</p>\n<h4 id=\"1-统计信息-the-fuel\">1. 统计信息 (The Fuel)</h4>\n<p>数据库会定期（通过 <code>ANALYZE</code> 命令）收集每张表的情报，存放在系统表里（如 PG 的 <code>pg_statistic</code>）：</p>\n<ul>\n<li><strong>行数 (Tuples):</strong> 表里大概有多少行？</li>\n<li><strong>页面数 (Pages):</strong> 表占了多少磁盘块？</li>\n<li><strong>唯一值个数 (n_distinct):</strong> 某一列有多少个不同的值？（决定了过滤性）</li>\n<li><strong>高频值 (MCV - Most Common Values):</strong> 哪几个值出现得最多？（比如“状态”字段，90% 都是 'success'）</li>\n<li><strong>直方图 (Histogram):</strong> 数据的分布情况是怎样的？（用于范围查询估算）</li>\n</ul>\n<h4 id=\"2-推算过程-the-calculation\">2. 推算过程 (The Calculation)</h4>\n<p>优化器利用统计信息进行<strong>基数估算 (Cardinality Estimation)</strong>，也就是猜每一各步骤会返回多少行。</p>\n<ul>\n<li><strong>例子：</strong> <code>SELECT * FROM users WHERE age &gt; 20 AND city = 'Beijing'</code>\n<ul>\n<li>统计信息说：<code>age &gt; 20</code> 的大概占 50%，<code>city = 'Beijing'</code> 的大概占 10%。</li>\n<li>优化器假设两列不相关，估算出符合条件的行数 = 总行数 $\\times$ 50% $\\times$ 10%。</li>\n<li>如果算出来只有 10 行，它可能选 <strong>Index Scan</strong>。</li>\n<li>如果算出来有 100 万行，它可能选 <strong>Seq Scan</strong>。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"第四阶段搜索算法-search-algorithms\">第四阶段：搜索算法 (Search Algorithms)</h2>\n<p>因为候选计划太多了，不可能真的把每一个都算一遍（那光是生成计划就要几分钟）。数据库使用高效的算法来“剪枝”和搜索。</p>\n<h4 id=\"1-动态规划-dynamic-programming--system-r-风格\">1. 动态规划 (Dynamic Programming) —— System R 风格</h4>\n<p>这是大多数数据库（包括 PostgreSQL 和 Oracle）处理中小型查询（通常 &lt; 12 张表）的标准算法。</p>\n<ul>\n<li><strong>思路：</strong> 自底向上。\n<ul>\n<li>先算出访问单表 A、B、C 的最优路径。</li>\n<li>再基于此，算出 {A, B} 连接的最优路径，和 {B, C} 连接的最优路径。</li>\n<li>再算出 {A, B, C} 的最优路径。</li>\n</ul>\n</li>\n<li><strong>优势：</strong> 能保证找到<strong>全局最优解</strong>。</li>\n</ul>\n<h4 id=\"2-遗传算法-genetic-algorithm--geqo\">2. 遗传算法 (Genetic Algorithm / GEQO)</h4>\n<p>当表非常多（比如 PostgreSQL 默认超过 12 张表 JOIN）时，动态规划太慢了。优化器会切换到遗传算法。</p>\n<ul>\n<li><strong>思路：</strong> 随机生成几个计划（种群），让它们“变异”和“杂交”（交换连接顺序），保留 Cost 低的，淘汰高的，迭代几轮后，选一个“足够好”的（但不一定是最优的）。</li>\n<li><strong>优势：</strong> 速度快，避免优化过程本身把数据库搞死。</li>\n</ul>\n<hr />\n<h2 id=\"第五阶段最终决策-plan-selection\">第五阶段：最终决策 (Plan Selection)</h2>\n<p>经过上述步骤，优化器手里捏着几个经过筛选的“决赛圈”计划。它会简单粗暴地比较它们的 <strong>Total Cost</strong>：</p>\n<ul>\n<li>计划 A (Hash Join): Cost = 500</li>\n<li>计划 B (Nested Loop): Cost = 2000</li>\n<li>计划 C (Merge Join): Cost = 480</li>\n</ul>\n<p><strong>决定：</strong> 选用计划 C。</p>\n<hr />\n<h2 id=\"总结为什么优化器有时候会犯傻\">总结：为什么优化器有时候会“犯傻”？</h2>\n<p>了解了原理，你就知道为什么数据库有时候会选错计划（比如选了全表扫描而不走索引）：</p>\n<ol>\n<li><strong>统计信息过期：</strong> 数据变了，但没运行 <code>ANALYZE</code>，优化器以为表是空的，结果表里有 1 亿行。它会错误地选择 Nested Loop，导致系统卡死。</li>\n<li><strong>数据相关性 (Correlation)：</strong> 优化器默认假设列与列之间是独立的。\n<ul>\n<li>比如查询“省份=湖北 AND 城市=武汉”。</li>\n<li>优化器觉得这两个概率要相乘（0.03 * 0.01 = 0.0003），认为结果极少。</li>\n<li>实际上这两个条件是强相关的，结果很多。估算错误导致选错索引。</li>\n</ul>\n</li>\n<li><strong>代价模型偏差：</strong> 传统的 Cost 模型主要看 IO。现在的 SSD 很快，有时候随机读（Index Scan）比顺序读（Seq Scan）快，但旧的代价参数可能还觉得机械硬盘的随机读很慢，从而不敢用索引。</li>\n</ol>\n<h2 id=\"一图胜千言\">一图胜千言</h2>\n<p>可以将整个过程想象成一个漏斗：</p>\n<ol>\n<li><strong>SQL 文本</strong> (输入)</li>\n<li><strong>Parser</strong> (语法树)</li>\n<li><strong>Rewriter</strong> (逻辑优化后的树)</li>\n<li><strong>Planner</strong> (生成 1000 个路径 -&gt; 估算 Cost -&gt; 动态规划剪枝 -&gt; 剩 1 个路径)</li>\n<li><strong>Executor</strong> (执行选定的那个计划)</li>\n</ol>\n<h1 id=\"hash-join的buckets和batches\">Hash Join的Buckets和Batches</h1>\n<p>在 PostgreSQL 的 <code>EXPLAIN (ANALYZE)</code> 输出中，<code>Buckets</code> 和 <code>Batches</code> 是 Hash Join（哈希连接）算子下两个至关重要的参数。它们直接揭示了你的查询是<strong>“在内存里飞”</strong>，还是<strong>“在硬盘里爬”</strong>。</p>\n<p>简单总结：</p>\n<ul>\n<li><strong>Buckets (桶):</strong> 是哈希表的<strong>“房间数”</strong>。它决定了 CPU 查找的效率（解决哈希冲突）。</li>\n<li><strong>Batches (批次):</strong> 是哈希表的<strong>“分身数”</strong>。它决定了内存够不够用（解决内存溢出）。<strong>这是性能杀手。</strong></li>\n</ul>\n<hr />\n<h2 id=\"1-buckets-桶--内存里的门牌号\">1. Buckets (桶) —— 内存里的“门牌号”</h2>\n<p>Hash Join 的第一步是构建哈希表（Build Phase）。数据库会申请一块内存，把这块内存划分为 N 个槽位，每个槽位就是一个 <strong>Bucket</strong>。</p>\n<ul>\n<li>\n<p><strong>工作原理：</strong></p>\n<ol>\n<li>数据库读取内表（Build Table）的一行数据。</li>\n<li>对连接键（Join Key）算出一个哈希值。</li>\n<li>用 <code>哈希值 % Bucket总数</code> 算出这行数据该进哪个桶。</li>\n<li>把数据挂在这个桶的链表后面。</li>\n</ol>\n</li>\n<li>\n<p><strong>理想情况：</strong></p>\n<p>每个桶里只有 1 行数据。这样探测（Probe）的时候，算一次哈希就能直接定位到数据，复杂度是 O(1)。</p>\n</li>\n<li>\n<p><strong>糟糕情况（哈希冲突）：</strong></p>\n<p>如果 Buckets 太少，或者哈希函数不好，导致几千行数据都挤在一个桶里（冲突）。那在这个桶内部查找就变成了线性扫描，CPU 消耗剧增。</p>\n</li>\n<li>\n<p><strong>EXPLAIN 中的表现：</strong></p>\n<p>PostgreSQL 通常会自动调整 Buckets 的数量以保持较高的效率（通常是 2 的幂次方）。</p>\n<blockquote>\n<p><code>Buckets: 1024  Memory Usage: 50kB</code></p>\n</blockquote>\n<blockquote>\n<ul>\n<li>这说明申请了 1024 个槽位，内存用了 50kB。这通常不是瓶颈。</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<hr />\n<h2 id=\"2-batches-批次--内存不够时的分身术\">2. Batches (批次) —— 内存不够时的“分身术”</h2>\n<p>这是最需要警惕的指标。</p>\n<p>Hash Join 必须把整个哈希表建在内存里。但是，如果你的 <code>work_mem</code>（工作内存）只有 4MB，而内表有 100MB，怎么办？内存装不下！</p>\n<p>这时候，PostgreSQL 就会启动 <strong>Batching（分批）机制</strong>，也就是<strong>把大象切块装进冰箱</strong>。</p>\n<ul>\n<li><strong>工作原理（分治法）：</strong>\n<ol>\n<li><strong>切分：</strong> 数据库根据哈希值，将内表（Build Table）和外表（Probe Table）切分成 N 个 <strong>Batches</strong>。</li>\n<li><strong>驻留与落盘：</strong>\n<ul>\n<li><strong>Batch 0</strong>：留在内存里，立刻开始做连接。</li>\n<li><strong>Batch 1 ~ N</strong>：内存放不下了，<strong>写到磁盘临时文件（Temp Files）里</strong>。</li>\n</ul>\n</li>\n<li><strong>轮询：</strong> 等 Batch 0 处理完，清空内存，把 Batch 1 从磁盘读回内存，构建哈希表，再处理……直到所有 Batch 处理完。</li>\n</ol>\n</li>\n<li><strong>Batches = 1 (完美状态)：</strong>\n<ul>\n<li>说明所有数据都能装进内存 (<code>work_mem</code>)。</li>\n<li>没有磁盘 I/O，速度最快。</li>\n<li><strong>EXPLAIN:</strong> <code>Batches: 1  Memory Usage: ...</code></li>\n</ul>\n</li>\n<li><strong>Batches &gt; 1 (溢出状态)：</strong>\n<ul>\n<li>说明内存不够，触发了磁盘读写。</li>\n<li><strong>EXPLAIN:</strong> <code>Batches: 4  Disk: 2500kB</code>。</li>\n<li>这意味着你的查询正在经历“写盘 -&gt; 读盘”的折磨，性能会下降几个数量级。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"3-实战案例如何通过这两个参数调优\">3. 实战案例：如何通过这两个参数调优？</h2>\n<p>让我们看一个发生“内存溢出”的 Hash Join 执行计划：</p>\n<p>Plaintext</p>\n<pre><code class=\"language-sql\">-&gt;  Hash Join  (cost=...) (actual time=...)\n      Hash Cond: (outer.id = inner.id)\n      -&gt;  Seq Scan on outer_table ...\n      -&gt;  Hash  (cost=...) (actual time=...)\n            Buckets: 65536  Batches: 8  Memory Usage: 4096kB  &lt;-- 关键点在这里！\n            Disk: 12000kB                                     &lt;-- 证据确凿\n            -&gt;  Seq Scan on inner_table ...\n</code></pre>\n<h4 id=\"分析\">分析：</h4>\n<ol>\n<li><strong>Buckets: 65536</strong>\n<ul>\n<li>桶很多，说明数据量不小，PostgreSQL 试图分散哈希冲突。</li>\n</ul>\n</li>\n<li><strong>Batches: 8</strong>\n<ul>\n<li><strong>报警！</strong> 这意味着数据被分成了 8 份。</li>\n<li>第 1 份在内存处理了，剩下 7 份被写到了磁盘上。</li>\n</ul>\n</li>\n<li><strong>Disk: 12000kB</strong>\n<ul>\n<li>为了做这个 Join，数据库临时写了 12MB 的数据到硬盘。</li>\n</ul>\n</li>\n<li><strong>Memory Usage: 4096kB</strong>\n<ul>\n<li>当前的 <code>work_mem</code> 设置限制了它只能用 4MB 内存。因为装不下 16MB（12MB+4MB）的数据，所以被迫分批。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"优化方案\">优化方案：</h4>\n<p>为了让 <code>Batches</code> 变回 1，我们需要增加 <code>work_mem</code>。</p>\n<pre><code class=\"language-sql\">-- 临时调大当前会话的内存限制（比如调到 32MB）\nSET work_mem = '32MB';\n\n-- 再次运行 EXPLAIN ANALYZE\nEXPLAIN ANALYZE SELECT ...\n</code></pre>\n<p><strong>优化后的可能结果：</strong></p>\n<p>Plaintext</p>\n<pre><code class=\"language-sql\">-&gt;  Hash  (cost=...) (actual time=...)\n      Buckets: 65536  Batches: 1  Memory Usage: 16100kB  &lt;-- 舒服了\n      Disk: 0kB                                          &lt;-- 磁盘 I/O 消失\n</code></pre>\n<ul>\n<li><strong>Batches: 1</strong>: 所有数据都在内存里。</li>\n<li><strong>Memory Usage: 16100kB</strong>: 实际上只用了 16MB 内存，完全在我们的预算（32MB）之内。</li>\n<li><strong>性能提升</strong>: 查询速度通常会提升 2-10 倍。</li>\n</ul>\n<hr />\n<h2 id=\"4-深度机制dynamic-growing-动态增长\">4. 深度机制：Dynamic Growing (动态增长)</h2>\n<p>有时候你会看到这样的输出：</p>\n<pre><code class=\"language-sql\">Buckets: 1024  Batches: 1 (originally 1)  Memory Usage: ...\n</code></pre>\n<p>或者：</p>\n<pre><code class=\"language-sql\">Buckets: 1024  Batches: 2 (originally 1)  Memory Usage: ...\n</code></pre>\n<p><strong>这是什么意思？</strong></p>\n<p>PostgreSQL 的优化器在开始执行前，只是<strong>估算</strong>需要多少 Buckets 和 Batches。</p>\n<ul>\n<li>如果执行过程中发现：“哎呀，估算少了，内存快爆了！”</li>\n<li>它会<strong>动态增加 Batches</strong>（Doubling strategy，通常翻倍）。</li>\n<li>它会将当前哈希表里的数据“分裂”，把一半的数据赶出内存（写到磁盘的新 Batch 里），从而腾出空间。</li>\n</ul>\n<p><strong>这说明：</strong> 你的统计信息（Statistics）可能严重过期了，导致优化器低估了行数。</p>\n<p><strong>对策：</strong> 运行 <code>ANALYZE table_name;</code>。</p>\n<h2 id=\"总结-3\">总结</h2>\n<table>\n<thead>\n<tr>\n<th><strong>参数</strong></th>\n<th><strong>含义</strong></th>\n<th><strong>理想值</strong></th>\n<th><strong>异常值</strong></th>\n<th><strong>影响</strong></th>\n<th><strong>解决方案</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Buckets</strong></td>\n<td>哈希表槽位数</td>\n<td>2^N (如 1024)</td>\n<td>无特定异常</td>\n<td>影响 CPU (哈希冲突)</td>\n<td>通常无需手动干预</td>\n</tr>\n<tr>\n<td><strong>Batches</strong></td>\n<td>分批处理数</td>\n<td><strong>1</strong></td>\n<td><strong>&gt; 1</strong></td>\n<td><strong>严重影响 IO</strong> (写磁盘)</td>\n<td><strong>调大 <code>work_mem</code></strong></td>\n</tr>\n</tbody>\n</table>\n<p>看到 <code>Batches &gt; 1</code>，就是看到数据库在向你求救：“给我点内存吧！”</p>\n<h1 id=\"hash-join-hash-冲突\">Hash Join Hash 冲突</h1>\n<p>在数据库的 Hash Join 中，<strong>Hash 冲突（Hash Collision）</strong> 是不可避免的物理现象。</p>\n<p>简单回顾一下定义：<strong>不同的 Join Key（比如 ID=10 和 ID=100），经过哈希函数计算后，得到了完全相同的哈希值（比如都等于 5），于是它们都要挤进同一个 Bucket（桶）里。</strong></p>\n<p>数据库（以 PostgreSQL 为例）解决这个问题的标准方案是：<strong>拉链法（Separate Chaining）</strong> + <strong>值比较（Recheck）</strong>。</p>\n<h2 id=\"1-核心机制拉链法-separate-chaining\">1. 核心机制：拉链法 (Separate Chaining)</h2>\n<p>想象一下，Hash Table 是一个巨大的<strong>“快递柜”</strong>，每个格子就是一个 <strong>Bucket</strong>。</p>\n<p>如果两个包裹（数据行）的取件码（Hash 值）算出来都是“5号柜”，怎么办？</p>\n<p>数据库不会把后来的包裹扔掉，也不会覆盖前面的，而是<strong>在 5 号柜后面挂一条长长的链子（Linked List）</strong>。</p>\n<ul>\n<li><strong>Bucket 的结构：</strong> 它不再是一个只能存一行数据的“死格子”，而是一个<strong>链表头指针</strong>。</li>\n<li><strong>冲突处理：</strong>\n<ul>\n<li>第一个冲突的行，挂在 Bucket 后面。</li>\n<li>第二个冲突的行，挂在第一个行后面。</li>\n<li>以此类推……</li>\n</ul>\n</li>\n</ul>\n<pre><code>Bucket 0: [ NULL ]\nBucket 1: [ Row A (id=10) ] -&gt; [ Row B (id=100) ] -&gt; [ Row C (id=999) ] -&gt; NULL\nBucket 2: [ Row D (id=5) ] -&gt; NULL\n...\n</code></pre>\n<p>在上面的例子中，Row A、Row B、Row C 的 ID 不同，但哈希值都撞到了 Bucket 1。这就是哈希冲突。</p>\n<hr />\n<h2 id=\"2-探测阶段必须进行验身-recheck\">2. 探测阶段：必须进行“验身” (Recheck)</h2>\n<p>解决了“存”的问题，关键在于“取”（Probe 阶段）。</p>\n<p>当外表（Outer Table）的一行数据来匹配时，数据库如何区分链表里的 A、B、C 谁才是真正的“亲人”？</p>\n<p><strong>步骤如下：</strong></p>\n<ol>\n<li><strong>算哈希：</strong> 拿外表数据的 Join Key（比如 ID=100），算出哈希值 -&gt; <code>Bucket 1</code>。</li>\n<li><strong>找桶：</strong> CPU 定位到内存中的 Bucket 1。</li>\n<li><strong>遍历链表（关键步骤）：</strong>\n<ul>\n<li><strong>看第一个节点 (Row A)：</strong> 它的哈希值匹配，但数据库<strong>不敢确信</strong>。必须拿出原始值比对：<code>Outer.ID (100) == Inner.ID (10)</code> 吗？<strong>不相等</strong>。跳过。</li>\n<li><strong>看第二个节点 (Row B)：</strong> 拿出原始值比对：<code>Outer.ID (100) == Inner.ID (100)</code> 吗？<strong>相等！</strong> 匹配成功，返回结果。</li>\n<li><strong>看第三个节点 (Row C)：</strong> ...</li>\n</ul>\n</li>\n</ol>\n<p><strong>结论：</strong> Hash Join 在匹配时，<strong>不仅仅比较哈希值，还必须在内存中比较原始的 Join Key</strong>。</p>\n<hr />\n<h2 id=\"3-性能影响冲突是-cpu-杀手\">3. 性能影响：冲突是 CPU 杀手</h2>\n<p>理解了上述过程，你就明白了为什么哈希冲突是性能的敌人：</p>\n<ul>\n<li><strong>理想情况 (无冲突)：</strong> Bucket 里只有 1 个节点。\n<ul>\n<li>复杂度：<strong>O(1)</strong>。算一次哈希，比对一次，搞定。</li>\n</ul>\n</li>\n<li><strong>糟糕情况 (严重冲突)：</strong> Bucket 后面挂了 1000 个节点。\n<ul>\n<li>复杂度：<strong>O(N)</strong>。算一次哈希，然后要进行 1000 次 CPU 比较操作（遍历链表）。</li>\n<li><strong>后果：</strong> 这实际上把高效的 Hash Join 退化成了低效的 <strong>Nested Loop</strong>（在桶内部做循环）。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"4-极端案例数据倾斜-data-skew\">4. 极端案例：数据倾斜 (Data Skew)</h2>\n<p>有时候，哈希冲突不是因为运气不好，而是因为<strong>数据本身的问题</strong>。</p>\n<p><strong>场景：</strong></p>\n<p>你连接的字段是 <code>status</code>（状态），且 99% 的数据都是 <code>'Success'</code>，只有 1% 是 <code>'Failed'</code>。</p>\n<ul>\n<li>Hash('Success') = Bucket 5</li>\n<li>Hash('Failed') = Bucket 8</li>\n</ul>\n<p><strong>结果：</strong></p>\n<ul>\n<li>Bucket 5 后面挂了一个<strong>长达几百万行</strong>的链表（因为 99% 的数据都一样）。</li>\n<li>Bucket 8 只有寥寥几行。</li>\n<li>其他 Bucket 全是空的。</li>\n</ul>\n<p><strong>这是 Hash Join 的噩梦。</strong> 在这种情况下，Hash Join 的性能会急剧下降，甚至比 Nested Loop 还要慢（因为还多了解析哈希和维护链表的开销）。</p>\n<p><strong>PostgreSQL 的对策：</strong></p>\n<p>PostgreSQL 的优化器（Planner）通常会利用<strong>高频值统计（MCV - Most Common Values）</strong>。如果它发现 Join Key 分布极度不均匀（倾斜严重），它可能会：</p>\n<ol>\n<li><strong>放弃 Hash Join</strong>，改用 Merge Join 或 Nested Loop。</li>\n<li>或者在 Hash Join 之前，对高频值做特殊处理（但这比较复杂）。</li>\n</ol>\n<hr />\n<h2 id=\"5-怎么避免冲突数据库在做什么\">5. 怎么避免冲突？(数据库在做什么)</h2>\n<p>虽然我们改变不了数据，但数据库内核在努力减少“意外冲突”：</p>\n<ol>\n<li><strong>优秀的哈希算法：</strong> PostgreSQL 使用 <code>Jenkins Hash</code> 或 <code>MurmurHash</code> 等算法，确保哈希值像“撒胡椒面”一样均匀分布，避免不同的值算出一样的哈希。</li>\n<li><strong>动态扩容 (Resizing)：</strong> 如果发现数据量比预期的多，导致 Bucket 不够用了（比如每个桶都挂了 5 个节点），数据库可能会重新申请更大的内存，把 Bucket 数量翻倍（比如从 1024 扩到 2048），然后把数据重新撒一遍（Rehash）。\n<ul>\n<li><em>注：PostgreSQL 的 Hash Join 更多是通过 Batches（分批）来解决内存不足，通过预估足够大的 Buckets 来解决冲突。</em></li>\n</ul>\n</li>\n</ol>\n<h2 id=\"总结-4\">总结</h2>\n<p>Hash Join 遇到冲突时：</p>\n<ol>\n<li><strong>存：</strong> 用<strong>链表</strong>把冲突的数据串起来。</li>\n<li><strong>取：</strong> 遍历链表，逐个进行<strong>原始值比较 (Recheck)</strong>。</li>\n<li><strong>代价：</strong> 冲突越多，链表越长，CPU 遍历越慢，性能越差。</li>\n</ol>\n<h1 id=\"parallel和partial\">Parallel和Partial</h1>\n<p><strong>\"Parallel\"</strong>（并行）和 <strong>\"Partial\"</strong>（部分）经常成对出现，但它们描述的是完全不同的两个维度：</p>\n<ul>\n<li><strong>Parallel (并行):</strong> 描述的是<strong>“动作的方式”</strong> —— <strong>大家一起干</strong>。</li>\n<li><strong>Partial (部分):</strong> 描述的是<strong>“结果的状态”</strong> —— <strong>干了一半，还没完</strong>。</li>\n</ul>\n<h2 id=\"1-parallel动作怎么干\">1. \"Parallel\"：动作（怎么干？）</h2>\n<p>当你在执行计划中看到 <strong>Parallel</strong>（如 <code>Parallel Seq Scan</code>），它意味着<strong>“分身术”</strong>。</p>\n<ul>\n<li><strong>含义：</strong> 数据库启动了多个工人（Worker Processes），大家<strong>同时</strong>去干这一件事。</li>\n<li><strong>场景：</strong>\n<ul>\n<li><strong>Parallel Seq Scan:</strong> 3 个工人，每人负责扫 1/3 的表。</li>\n<li><strong>Parallel Hash Join:</strong> 3 个工人，每人负责连接 1/3 的数据。</li>\n</ul>\n</li>\n<li><strong>关键点：</strong> 它的反义词是 \"Serial\"（串行，单线程）。</li>\n</ul>\n<h2 id=\"2-partial结果干成啥样了\">2. \"Partial\"：结果（干成啥样了？）</h2>\n<p>当你在执行计划中看到 <strong>Partial</strong>（如 <code>Partial Aggregate</code>），它意味着<strong>“半成品”</strong>。</p>\n<ul>\n<li><strong>含义：</strong> 因为数据是大家分开处理的，所以每个人算出来的结果<strong>只是局部的</strong>，不是最终答案。</li>\n<li><strong>场景：</strong>\n<ul>\n<li><strong>Partial Aggregate:</strong> 工人 A 算出他那部分有 100 票，工人 B 算出他那部分有 200 票。</li>\n<li><strong>注意：</strong> 这时候谁都不知道总票数是多少。</li>\n</ul>\n</li>\n<li><strong>关键点：</strong> 它的反义词是 \"Finalize\"（最终汇总）。</li>\n</ul>\n<hr />\n<h2 id=\"3-为什么有时候有-partial有时候没有\">3. 为什么有时候有 Partial，有时候没有？</h2>\n<p>这取决于你的 SQL <strong>是否需要“聚合”（Aggregation）</strong>。</p>\n<h4 id=\"情况-a有-parallel也有-partial-聚合查询\">情况 A：有 Parallel，也有 Partial (聚合查询)</h4>\n<p><strong>SQL:</strong> <code>SELECT count(*) FROM big_table;</code></p>\n<p>你想要一个<strong>汇总的数字</strong>。</p>\n<ol>\n<li><strong>Parallel Seq Scan:</strong> 大家分头去数票（动作是并行的）。</li>\n<li><strong>Partial Aggregate:</strong> 每个人先把手里的票数加一加，记在小本本上（结果是局部的）。\n<ul>\n<li><em>如果不做这一步，每个人都要把几百万张选票扔给领导，领导会被砸死。</em></li>\n</ul>\n</li>\n<li><strong>Gather:</strong> 领导把小本本收上来。</li>\n<li><strong>Finalize Aggregate:</strong> 领导把小本本上的数字加在一起（最终结果）。</li>\n</ol>\n<p><strong>执行计划长这样：</strong></p>\n<pre><code class=\"language-sql\">Finalize Aggregate          &lt;-- 4. 算出总账\n  -&gt; Gather                 &lt;-- 3. 收小本本\n       -&gt; Partial Aggregate &lt;-- 2. 记小本本 (Partial出现了！)\n            -&gt; Parallel Seq Scan &lt;-- 1. 分头数票 (Parallel出现了！)\n</code></pre>\n<h4 id=\"情况-b有-parallel但没有-partial-明细查询\">情况 B：有 Parallel，但没有 Partial (明细查询)</h4>\n<p><strong>SQL:</strong> <code>SELECT * FROM big_table WHERE id &gt; 1000;</code></p>\n<p>你只想要<strong>原始数据</strong>，不需要汇总。</p>\n<ol>\n<li><strong>Parallel Seq Scan:</strong> 大家分头去找 <code>id &gt; 1000</code> 的行。</li>\n<li><strong>Gather:</strong> 找到一行，就直接扔给领导。</li>\n<li><strong>Result:</strong> 领导直接发给用户。</li>\n</ol>\n<p><strong>执行计划长这样：</strong></p>\n<pre><code class=\"language-sql\">Gather                      &lt;-- 2. 收原始票据\n  -&gt; Parallel Seq Scan      &lt;-- 1. 分头找票 (只有Parallel，没有Partial)\n</code></pre>\n<p><strong>为什么这里没有 Partial？</strong></p>\n<p>因为不需要计算 <code>SUM</code> 或 <code>COUNT</code>，不需要“中间状态”。工人找到的就是最终需要的行。</p>\n<hr />\n<h2 id=\"4-深度对比表\">4. 深度对比表</h2>\n<table>\n<thead>\n<tr>\n<th><strong>关键词</strong></th>\n<th><strong>词性</strong></th>\n<th><strong>潜台词</strong></th>\n<th><strong>典型算子</strong></th>\n<th><strong>出现位置</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Parallel</strong></td>\n<td><strong>副词</strong> (Adverb)</td>\n<td>\"我不孤单，有兄弟帮我一起做\"</td>\n<td><code>Parallel Seq Scan</code> <code>Parallel Index Scan</code> <code>Parallel Hash Join</code></td>\n<td>树的<strong>底层</strong> (干苦力的地方)</td>\n</tr>\n<tr>\n<td><strong>Partial</strong></td>\n<td><strong>形容词</strong> (Adjective)</td>\n<td>\"这不是最终答案，还要再加工\"</td>\n<td><code>Partial Aggregate</code> <code>Partial HashAggregate</code></td>\n<td>夹在 Parallel 和 Gather <strong>中间</strong> (为了压缩数据)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"总结-5\">总结</h2>\n<ul>\n<li>看到 <strong>Parallel</strong>，说明<strong>“为了快，人多力量大”</strong>。</li>\n<li>看到 <strong>Partial</strong>，说明<strong>“为了省，先在本地算个小账”</strong>。</li>\n</ul>\n<p><strong>Partial 是 Parallel 在做聚合运算时的“必经之路”。</strong> 如果你只是简单地搬运数据（SELECT *），就不需要 Partial 这个步骤。</p>\n<h1 id=\"数据库缓存和操作系统缓存的关系\">数据库缓存和操作系统缓存的关系</h1>\n<p>简单来说，它们是<strong>两层防御体系</strong>，既有合作，也有竞争。</p>\n<p>我们可以用一个<strong>“图书馆复习”</strong>的例子来打比方：</p>\n<ul>\n<li><strong>硬盘 (Disk):</strong> 图书馆的<strong>闭架书库</strong>。书很多，但取书非常慢（毫秒级）。</li>\n<li><strong>操作系统缓存 (OS Page Cache):</strong> 图书馆的<strong>还书手推车</strong>。\n<ul>\n<li>虽然书还没归架，但就在手边，拿起来很快。</li>\n<li>这里书很杂，什么都有，而且管理员（OS）会定期把车清空。</li>\n</ul>\n</li>\n<li><strong>数据库缓存 (DB Buffer Pool):</strong> 你自己的<strong>书桌</strong>。\n<ul>\n<li>这是你精心挑选的、马上要用的书。</li>\n<li>你知道哪一页最重要，你会一直把它们摊开放在桌上。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"1-核心架构数据的流动路径\">1. 核心架构：数据的流动路径</h2>\n<p>当数据库想要读取一行数据时，并不是直接从硬盘变到数据库里的。这中间经过了层层关卡。</p>\n<p><strong>读取路径 (Read Path):</strong></p>\n<ol>\n<li><strong>App 请求数据:</strong> SQL 发给数据库。</li>\n<li><strong>DB Cache (Shared Buffers):</strong> 数据库先查自己的内存（书桌）。\n<ul>\n<li><em>Hit:</em> 直接返回。速度最快（纳秒级）。</li>\n<li><em>Miss:</em> 需要去读文件。</li>\n</ul>\n</li>\n<li><strong>System Call (read):</strong> 数据库发起系统调用，请求操作系统读文件。</li>\n<li><strong>OS Cache (Page Cache):</strong> 操作系统查自己的内存（手推车）。\n<ul>\n<li><em>Hit:</em> 操作系统发现这页数据刚好在内存里（可能是刚才有人读过，或者刚写进去还没落盘）。直接拷贝给数据库。</li>\n<li><em>Miss:</em> 操作系统真的去读硬盘。</li>\n</ul>\n</li>\n<li><strong>Disk I/O:</strong> 硬盘旋转，磁头寻道，把数据读入 OS Cache。</li>\n<li><strong>Copy:</strong> 操作系统把数据从 <strong>OS Cache</strong> 复制到 <strong>DB Cache</strong>。</li>\n</ol>\n<p><strong>关键点：</strong> 如果数据在 DB Cache 没命中，但在 OS Cache 命中，虽然比直接读内存慢一点（因为有系统调用和内存拷贝的开销），但比读硬盘快 1000 倍。</p>\n<hr />\n<h2 id=\"2-双重缓存-double-buffering-现象\">2. “双重缓存” (Double Buffering) 现象</h2>\n<p>仔细看上面的第 6 步，你会发现一个尴尬的现象：</p>\n<p><strong>同一份数据，在内存里存了两份！</strong></p>\n<ul>\n<li>一份在 OS Page Cache 里。</li>\n<li>一份在 DB Buffer Pool 里。</li>\n</ul>\n<p>这就叫 <strong>Double Buffering</strong>。</p>\n<h4 id=\"这种冗余是好是坏\">这种冗余是好是坏？</h4>\n<ul>\n<li><strong>坏处：</strong> 浪费内存。如果你的服务器有 64GB 内存，结果 30GB 存的是重复数据，那是极大的浪费。</li>\n<li><strong>好处：</strong> 互补。\n<ul>\n<li>DB Cache 满了要淘汰数据时，被淘汰的数据只是从“书桌”移回了“手推车”（OS Cache）。</li>\n<li>下次如果又突然需要这页数据，虽然书桌上没有，但手推车里有，还是很快。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"3-postgresql-的策略依赖与合作\">3. PostgreSQL 的策略：依赖与合作</h2>\n<p>PostgreSQL 在这方面非常特别。它<strong>默认不使用 Direct I/O</strong>（即不绕过 OS Cache），而是选择利用它。</p>\n<ul>\n<li><strong>配置策略：</strong>\n<ul>\n<li>这就是为什么 PostgreSQL 官方建议 <code>shared_buffers</code>（DB Cache）只设置为总内存的 <strong>25% - 40%</strong>。</li>\n<li><strong>剩下的内存去哪了？</strong> 留给操作系统！PostgreSQL 指望操作系统用剩下的内存做 Page Cache，来做它的“二级缓存”。</li>\n</ul>\n</li>\n<li><strong>优点：</strong> 代码简单，利用了操作系统成熟的预读（Prefetching）算法。</li>\n<li><strong>缺点：</strong> 存在双重缓存带来的内存浪费和 CPU 拷贝开销。</li>\n</ul>\n<hr />\n<h2 id=\"4-其他数据库的策略direct-io-绕过\">4. 其他数据库的策略：Direct I/O (绕过)</h2>\n<p>很多其他数据库（如 Oracle, MySQL InnoDB）倾向于一种更霸道的做法：<strong>O_DIRECT</strong>。</p>\n<ul>\n<li><strong>Direct I/O:</strong> 数据库告诉操作系统：“我要读写文件，但你别管闲事，别给我做缓存，直接把硬盘数据读到我的内存里。”</li>\n<li><strong>效果：</strong>\n<ul>\n<li><strong>消除了双重缓存：</strong> 数据只存在于 DB Buffer Pool 中。</li>\n<li><strong>内存利用率高：</strong> 数据库可以把 80% 甚至 90% 的物理内存都据为己有。</li>\n</ul>\n</li>\n<li><strong>代价：</strong> 数据库必须自己实现极其复杂的缓存管理、预读算法和刷盘策略。因为一旦离开了 OS 的保护，自己必须全权负责。</li>\n</ul>\n<hr />\n<h2 id=\"5-写入与刷盘-write--fsync\">5. 写入与刷盘 (Write &amp; Fsync)</h2>\n<p>在写入数据时，两者的关系更加微妙，关乎<strong>数据安全</strong>。</p>\n<ol>\n<li><strong>DB Write:</strong> 数据库修改了 Buffer Pool 里的数据（变成了脏页 Dirty Page）。此时数据还在用户空间内存。</li>\n<li><strong>OS Write:</strong> 数据库调用 <code>write()</code>。操作系统把数据从 DB Cache 拷贝到 OS Cache。<strong>注意：此时数据还没到硬盘！</strong> 如果这时候拔电源，数据就丢了。</li>\n<li><strong>Fsync (刷盘):</strong> 为了保证 ACID 中的 D（持久性），数据库必须显式调用 <code>fsync()</code>。\n<ul>\n<li>这就像是对操作系统大喊：“别只放在手推车里，现在、立刻、马上把它放回闭架书库（硬盘）去！”</li>\n<li>只有 <code>fsync</code> 返回成功，数据库才敢告诉用户“事务提交成功”。</li>\n</ul>\n</li>\n</ol>\n<p><strong>WAL (预写日志) 的角色：</strong></p>\n<p>因为 <code>fsync</code> 随机写数据文件太慢了，数据库会先顺序写 WAL 日志，并频繁 <code>fsync</code> WAL 文件。至于真正的数据页（Data Page），可以在 OS Cache 里多待一会儿，由操作系统的 pdflush 线程或者数据库的 Checkpointer 慢慢刷盘。</p>\n<h2 id=\"总结谁更聪明\">总结：谁更聪明？</h2>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>OS Cache (傻快)</strong></th>\n<th><strong>DB Cache (精明)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>置换算法</strong></td>\n<td>LRU (最近最少使用) 的通用变种。比较简单粗暴。</td>\n<td><strong>Clock-Sweep / ARC</strong>。数据库知道哪是索引，哪是全表扫描。它会保护索引页，快速淘汰全表扫描的页。</td>\n</tr>\n<tr>\n<td><strong>预读能力</strong></td>\n<td>基于文件偏移量的简单预读（往下读 128KB）。</td>\n<td>理解 B+ 树结构，知道下一个叶子节点在磁盘的什么位置，预读更精准。</td>\n</tr>\n<tr>\n<td><strong>内存控制</strong></td>\n<td>动态抢占，应用内存不够时会压缩 Cache。</td>\n<td>大小固定（通常启动时分配）。</td>\n</tr>\n<tr>\n<td><strong>适用场景</strong></td>\n<td>文件服务器、通用计算。</td>\n<td>复杂的查询处理。</td>\n</tr>\n</tbody>\n</table>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>未经作者同意请勿转载</p>\n<p>本文来自博客园作者：<a href=\"https://www.cnblogs.com/aslanvon/\" target=\"_blank\">aixueforever</a>，原文链接：<a href=\"https://www.cnblogs.com/aslanvon/p/19608578\" target=\"_blank\">https://www.cnblogs.com/aslanvon/p/19608578</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 15:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/aslanvon\">aixueforever</a>&nbsp;\n阅读(<span id=\"post_view_count\">60</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "40 个 Agent Skills 精选资源：入门教程 + 实用工具 + 必装推荐",
      "link": "https://www.cnblogs.com/yupi/p/19608327",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yupi/p/19608327\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 14:17\">\n    <span>40 个 Agent Skills 精选资源：入门教程 + 实用工具 + 必装推荐</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"40 个 Agent Skills 精选资源：入门教程 + 实用工具 + 必装推荐\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2225420/202602/2225420-20260212141634834-1360269128.png\" />\n        精心汇总了全网最主流实用的 Agent Skills 资源，从 Skills 入门教程、Skills 安装管理工具、Skills 资源合集、再到推荐安装的 Skills，一条龙服务，墙裂建议收藏备用！\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"md-end-block md-heading\"><span class=\"md-plain\">大家好，我是程序员鱼皮。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Agent Skills 最近在 AI 圈儿火得一塌糊涂。简单来说，它就是给 AI 装备的技能包，里面有精心设计的提示词、代码脚本、还有各种资源文件，让 AI 能在特定任务上表现得更专业，比如做 PPT、操作 Excel 表格、剪辑视频等等。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">鱼皮精心汇总了全网最主流实用的 Agent Skills 资源，从 Skills 入门教程、Skills 安装管理工具、Skills 资源合集、再到推荐安装的 Skills，一条龙服务，墙裂建议收藏备用！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">Agent Skills 入门教程</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">⭐️ <span class=\"md-pair-s \"><strong>鱼皮的 Agent Skills 保姆级入门教程</strong><span class=\"md-plain\">：从零开始讲 Agent Skills 是什么、怎么安装和使用、内部原理是什么、怎么创建自己的 Skills、和 MCP 的区别等，一个视频全讲明白了，喂饭级教程。</span></span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://www.bilibili.com/video/BV1T7zzBQEaA/\" rel=\"noopener nofollow\">https://www.bilibili.com/video/BV1T7zzBQEaA/</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>吴恩达 × Anthropic 官方课程</strong><span class=\"md-plain\">：DeepLearning.AI 和 Anthropic 联合出品的 Agent Skills 课程，教你按照最佳实践创建 Skills，课程虽然是英文的但质量很高，可以搭配个字幕翻译的浏览器插件食用。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://www.deeplearning.ai/short-courses/agent-skills-with-anthropic/\" rel=\"noopener nofollow\">https://www.deeplearning.ai/short-courses/agent-skills-with-anthropic/</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>鱼皮的 AI 编程零基础教程</strong><span class=\"md-plain\">：想学 AI 编程但不知道从哪开始？这个教程从 Vibe Coding 概念讲起，手把手教你用 Claude Code、Cursor 这些工具，以及 Agent Skills、MCP 等扩展能力，零基础也能看懂。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://ai.codefather.cn/vibe\" rel=\"noopener nofollow\">https://ai.codefather.cn/vibe</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img alt=\"鱼皮AI导航-教程图文并茂\" class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">Agent Skills 安装管理</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>skills CLI</strong><span class=\"md-plain\">：Vercel 官方出品的命令行工具，一行命令就能安装任何 Skills，简单好用。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">用法是 <span class=\"md-pair-s\"><code>npx skills add &lt;owner/repo&gt;</code><span class=\"md-plain\">，比如 <span class=\"md-pair-s\"><code>npx skills add vercel-labs/agent-skills</code><span class=\"md-plain\"> 就能装上 Vercel 官方的所有 Skills。</span></span></span></span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://www.npmjs.com/package/skills\" rel=\"noopener nofollow\">https://www.npmjs.com/package/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>Skill Seeker</strong><span class=\"md-plain\">：这个工具牛了，能自动抓取文档网站、GitHub 仓库、PDF 文件，然后直接转换成 Agent Skills，省去了手写技能说明文档的麻烦。支持多源抓取、代码深度分析、一键打包，特别适合给自己常用的库或框架快速生成 Skills。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/yusufkaraaslan/Skill_Seekers\" rel=\"noopener nofollow\">https://github.com/yusufkaraaslan/Skill_Seekers</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>everything-claude-code</strong><span class=\"md-plain\">：Anthropic 黑客松冠军的完整配置集合，包括 agents、skills、hooks、commands、rules、MCPs，都是实战验证过的配置，拿来就能用。想一次性配置好 Claude Code 的话装这个就够了。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/affaan-m/everything-claude-code\" rel=\"noopener nofollow\">https://github.com/affaan-m/everything-claude-code</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">Agent Skills 资源合集</span></h2>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">在线市场</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>skills.sh</strong><span class=\"md-plain\">：Vercel 官方出品的 Skills 排行榜，能看到每个 Skill 的安装量、使用趋势，还支持一键安装。想知道哪些 Skills 最火，来这里看就对了。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://skills.sh/\" rel=\"noopener nofollow\">https://skills.sh</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>鱼皮 AI 导航 - Skills 专区</strong><span class=\"md-plain\">：我的中文 Agent Skills 导航网站，按分类整理好了几百个 Skills，界面友好、查找方便，适合国内的朋友们使用。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://ai.codefather.cn/skills\" rel=\"noopener nofollow\">https://ai.codefather.cn/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>skillsmp</strong><span class=\"md-plain\">：自动抓取 GitHub 上所有 Skills 项目，按分类、更新时间、Star 数量整理，数据更新及时。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://skillsmp.com/zh\" rel=\"noopener nofollow\">https://skillsmp.com/zh</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>MCP Market</strong><span class=\"md-plain\">：MCP Market 的每日 Skills 榜单，能看到每天最热门的 Skills 排名，帮你发现新趋势。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://mcpmarket.com/daily/skills\" rel=\"noopener nofollow\">https://mcpmarket.com/daily/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">开源合集</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>anthropics/skills</strong><span class=\"md-plain\">：Anthropic 官方 Skills 仓库，包含文档处理（PDF、Word、PPT、Excel）、前端设计、MCP 构建、算法艺术等十几个高质量的 Skills。建议刚开始玩 Skills 的朋友首先安装这个。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/anthropics/skills\" rel=\"noopener nofollow\">https://github.com/anthropics/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>awesome-claude-skills</strong><span class=\"md-plain\">：Skills 精选列表，收录了各种类型的 Skills，分类清晰，是目前最全的 Skills 合集之一。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/ComposioHQ/awesome-claude-skills\" rel=\"noopener nofollow\">https://github.com/ComposioHQ/awesome-claude-skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>openai/skills</strong><span class=\"md-plain\">：OpenAI 官方的 Codex Skills 目录。可以通过 Codex 内置的 <span class=\"md-pair-s\"><code>$skill-installer</code><span class=\"md-plain\"> 命令一键安装，让 Codex 在特定任务上表现更专业。</span></span></span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/openai/skills\" rel=\"noopener nofollow\">https://github.com/openai/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>vercel-labs/agent-skills</strong><span class=\"md-plain\">：Vercel 出品的 React/Next.js 最佳实践，包括 React 开发规范、Web 设计指南、组件组合模式等，做前端的同学必装。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/vercel-labs/agent-skills\" rel=\"noopener nofollow\">https://github.com/vercel-labs/agent-skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>expo/skills</strong><span class=\"md-plain\">：Expo 官方的 React Native 开发 Skills。Expo 是一个基于 React Native 的移动应用开发框架，可以让你用 JavaScript / TypeScript 开发 iOS 和 Android 应用。这个 Skills 包括原生 UI 构建、数据获取、部署、CI/CD 等，做移动端开发的朋友可以装上。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/expo/skills\" rel=\"noopener nofollow\">https://github.com/expo/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>kepano/obsidian-skills</strong><span class=\"md-plain\">：Obsidian 出品的 Skills 集合。Obsidian 是一款基于本地 Markdown 文件的知识管理和笔记应用，深受程序员和知识创作者喜爱。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这些 Skills 能增强 Obsidian 的功能，让 AI Agent 能更好地管理你的笔记和知识库。</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/kepano/obsidian-skills\" rel=\"noopener nofollow\">https://github.com/kepano/obsidian-skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>stripe/ai</strong><span class=\"md-plain\">：Stripe 官方 AI Skills。Stripe 是全球领先的在线支付处理平台，被无数互联网公司用于收款。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这个 Skills 包含金融支付相关的最佳实践，比如优先使用 Checkout Sessions API、动态支付方式配置、订阅计费集成等，做支付功能的朋友可以参考。</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/stripe/ai\" rel=\"noopener nofollow\">https://github.com/stripe/ai</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>trailofbits/skills</strong><span class=\"md-plain\">：Trail of Bits 安全公司出品的 Skills，专注安全研究和漏洞检测。内容非常丰富，包含智能合约安全审计、Burp Suite 项目解析、Semgrep 规则创建、YARA 恶意软件检测规则编写、差异化代码审查、常量时间分析、属性测试等 20+ 个安全相关插件，强烈推荐给安全方向的朋友。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/trailofbits/skills\" rel=\"noopener nofollow\">https://github.com/trailofbits/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>Notion Skills</strong><span class=\"md-plain\">：Notion 官方出品的 Skills，让 AI 能更好地与 Notion 工作区交互。可以帮你自动整理会议记录和待办事项、帮你整理和组织研究资料等，适合重度使用 Notion 的朋友。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0\" rel=\"noopener nofollow\">https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">Agent Skills 必备推荐</span></h2>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">项目开发</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>superpowers</strong><span class=\"md-plain\">：一套完整的 AI 编程技能框架和软件开发方法论。它包含十几个可组合的编程技能，比如头脑风暴、编写计划、执行计划、TDD 测试驱动开发、系统性调试、代码审查等。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">装了它之后，AI 不会直接开始写代码，而是会先问清楚需求、出设计方案让你确认、制定详细执行计划，最后才分步骤实现。适合开发大型项目、需要高质量代码的场景。</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/obra/superpowers\" rel=\"noopener nofollow\">https://github.com/obra/superpowers</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>planning-with-files</strong><span class=\"md-plain\">：被 X 上的开发者评为最强 Skill！它借鉴了被 Meta 以 20 亿美元收购的 Manus AI 的核心工作模式：用 Markdown 文件作为 AI 的外部记忆，解决 AI 上下文丢失的问题。适合多步骤任务、研究任务、跨多次对话的项目开发，让 AI 在复杂项目中也能保持清醒不跑偏。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/OthmanAdi/planning-with-files\" rel=\"noopener nofollow\">https://github.com/OthmanAdi/planning-with-files</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>ui-ux-pro-max</strong><span class=\"md-plain\">：专业前端设计 Skill，让 AI Agent 具备专业设计师的能力，生成的界面不再是千篇一律的 AI 风格。支持各种主流 AI 编程工具，强烈推荐。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/nextlevelbuilder/ui-ux-pro-max-skill\" rel=\"noopener nofollow\">https://github.com/nextlevelbuilder/ui-ux-pro-max-skill</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>vercel-react-best-practices</strong><span class=\"md-plain\">：Vercel 出品的 React 最佳实践，让 AI 按照 React 官方推荐的模式来写代码，包括组件设计、状态管理、性能优化等规范，避免写出反模式的代码。做 React 项目必装。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：通过 <span class=\"md-pair-s\"><code>npx skills add vercel-labs/agent-skills</code><span class=\"md-plain\"> 命令安装</span></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>web-design-guidelines</strong><span class=\"md-plain\">：Web 设计规范 Skill，包含间距、颜色、排版、响应式设计等专业设计规范，让 AI 生成的页面更加美观，而不是千篇一律的 AI 风格。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：通过 <span class=\"md-pair-s\"><code>npx skills add vercel-labs/agent-skills</code><span class=\"md-plain\"> 命令安装</span></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>frontend-design</strong><span class=\"md-plain\">：Anthropic 官方的前端设计 Skill，帮你开发独具辨识度的生产级前端界面。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：通过 <span class=\"md-pair-s\"><code>npx skills add anthropics/skills</code><span class=\"md-plain\"> 安装</span></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>vue-skills</strong><span class=\"md-plain\">：Vue.js 最佳实践 Skills，尤雨溪团队成员维护。让 AI 按照 Vue 生态的最佳实践来写代码，包括 Vue 3 组合式 API、Vite 构建配置、Vitest 单元测试、Pinia 状态管理、UnoCSS 样式方案等。做 Vue 项目必装。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/vuejs-ai/skills\" rel=\"noopener nofollow\">https://github.com/vuejs-ai/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>supabase-postgres-best-practices</strong><span class=\"md-plain\">：Supabase 出品的 PostgreSQL 数据库最佳实践，教 AI Agent 怎么写出高质量的数据库代码，包括查询优化、索引设计等。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/supabase/agent-skills\" rel=\"noopener nofollow\">https://github.com/supabase/agent-skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">浏览器自动化</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>browser-use</strong><span class=\"md-plain\">：让 AI Agent 能访问和操作网站的工具（不仅是 Skill，也可以独立使用），功能强大，可以用来做自动化测试、数据抓取、网页操作等。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/browser-use/browser-use\" rel=\"noopener nofollow\">https://github.com/browser-use/browser-use</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>agent-browser</strong><span class=\"md-plain\">：Vercel 出品的浏览器自动化 Skill，让 AI Agent 能操作浏览器。比如可以自动填表单、点击按钮、截图、抓取动态渲染的内容等，非常适合做端到端测试、自动化爬虫、网页监控等场景。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/vercel-labs/agent-browser\" rel=\"noopener nofollow\">https://github.com/vercel-labs/agent-browser</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">内容创作</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>remotion-dev/skills</strong><span class=\"md-plain\">：Remotion 官方出品的视频动画制作 Skills，能用 Claude Code 一句话生成可编辑的动画视频，几分钟就能做出专业效果，最近特别火。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/remotion-dev/skills\" rel=\"noopener nofollow\">https://github.com/remotion-dev/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>baoyu-skills</strong><span class=\"md-plain\">：宝玉老师自用的 Skills 集合，包括公众号文章写作、PPT 制作、封面图生成、小红书配图、漫画生成等，对内容创作者非常有帮助，直接把大佬的创作工作流复制过来用。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/JimLiu/baoyu-skills\" rel=\"noopener nofollow\">https://github.com/JimLiu/baoyu-skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img alt=\"小红书配图技能\" class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>humanizer</strong><span class=\"md-plain\">：去除 AI 生成痕迹的 Skill，让 AI 写的文章更像人写的。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/blader/humanizer\" rel=\"noopener nofollow\">https://github.com/blader/humanizer</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>heygen-com/skills</strong><span class=\"md-plain\">：HeyGen 官方的 Skills。HeyGen 是一个 AI 数字人视频生成平台，可以用虚拟人物来制作视频。这个 Skills 让 AI 能调用 HeyGen API 生成数字人视频，包括选择虚拟形象、配置语音、生成透明背景视频、视频翻译配音等功能，还支持和 Remotion 集成做程序化视频合成。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/heygen-com/skills\" rel=\"noopener nofollow\">https://github.com/heygen-com/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">Skills 管理工具</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>find-skills</strong><span class=\"md-plain\">：Vercel 出品的 Skills 发现工具，帮你快速找到和安装需要的 Skills。支持交互式搜索和关键词搜索，用 <span class=\"md-pair-s\"><code>npx skills find</code><span class=\"md-plain\"> 命令即可启动。</span></span></span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：通过 <span class=\"md-pair-s\"><code>npx skills add vercel-labs/skills</code><span class=\"md-plain\"> 安装</span></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>skill-creator</strong><span class=\"md-plain\">：Anthropic 官方的 Skill 创建工具，教你怎么创建自定义 Skill。会引导你按照最佳实践编写 SKILL.md 文件，包括技能描述、触发条件、执行步骤等。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：通过 <span class=\"md-pair-s\"><code>npx skills add anthropics/skills</code><span class=\"md-plain\"> 安装</span></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">网站审计</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>seo-audit</strong><span class=\"md-plain\">：SEO 审计 Skill，帮你分析网站的 SEO 问题并给出优化建议。来自 marketingskills 仓库，该仓库还有 25+ 个营销相关技能，涵盖转化优化、文案撰写、数据分析、增长策略等。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/coreyhaines31/marketingskills\" rel=\"noopener nofollow\">https://github.com/coreyhaines31/marketingskills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>audit-website</strong><span class=\"md-plain\">：网站安全审计 Skill，基于 squirrelscan 工具，包含 230+ 条审计规则，覆盖 SEO、性能、可访问性、内容和安全等 21 个类别，还能检测 96 种泄露的密钥。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/squirrelscan/skills\" rel=\"noopener nofollow\">https://github.com/squirrelscan/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">官方文档</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>Anthropic 官方文档</strong><span class=\"md-plain\">：想深入了解 Agent Skills 的技术细节，看官方文档准没错，包括概念介绍、快速开始、最佳实践、API 集成等。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://docs.anthropic.com/en/docs/agents-and-tools/agent-skills/overview\" rel=\"noopener nofollow\">https://docs.anthropic.com/en/docs/agents-and-tools/agent-skills/overview</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>Agent Skills 开放标准</strong><span class=\"md-plain\">：Anthropic 主导的开放标准网站，定义了 Skills 的规范格式，OpenAI、Google、Microsoft 都在用这套标准。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://agentskills.io/\" rel=\"noopener nofollow\">https://agentskills.io</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>Claude Skills 博客</strong><span class=\"md-plain\">：Anthropic 官方博客，包括 Skills 的介绍和一些相关的资源，想进一步了解 Skills 的同学可以看看。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://claude.com/blog/skills\" rel=\"noopener nofollow\">https://claude.com/blog/skills</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>Skills API 快速入门</strong><span class=\"md-plain\">：想通过 API 使用 Skills 的话，看这个文档就好（或者直接把文档甩给 AI 让它帮你对接）。</span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://docs.claude.com/en/api/skills-guide\" rel=\"noopener nofollow\">https://docs.claude.com/en/api/skills-guide</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<div class=\"md-hr md-end-block\"><hr /></div>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">以上就是我整理的 40 多个 Agent Skills 精选资源，如果你觉得有用，记得点个收藏。后续我会持续分享更多实用的 AI 编程干货，感谢关注，也欢迎在评论区分享你发现的宝藏 Skills~</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">更多编程学习资源</span></h2>\n<ul class=\"ul-list\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course\" rel=\"noopener nofollow\"><span class=\"md-plain\">Java前端程序员必做项目实战教程+毕设网站</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费编程学习交流社区（自学必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course/cv\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员保姆级求职写简历指南（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.mianshiya.com/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费面试刷题网站工具（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640584449888772098\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Java零基础入门学习路线 + Java教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586673306091521\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Python零基础入门学习路线 + Python教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586014108303362\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新前端零基础入门学习路线 + 前端教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586867363954689\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据结构和算法零基础入门学习路线 + 算法教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1644279832026075138\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新C++零基础入门学习路线、C++教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641797333479903234\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据库零基础入门学习路线 + 数据库教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640589994284695553\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Redis零基础入门学习路线 + Redis教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641035880439271426\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机基础入门学习路线 + 计算机基础教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641366118197153793\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新小程序入门学习路线 + 小程序开发教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"http://sqlmother.yupi.icu/\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新SQL零基础入门学习路线 + SQL教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586295529324545\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Linux零基础入门学习路线 + Linux教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588753362108417\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Git/GitHub零基础入门学习路线 + Git教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640587909942099969\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新操作系统零基础入门学习路线 + 操作系统教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588119619551233\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机网络零基础入门学习路线 + 计算机网络教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588392073150465\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新设计模式零基础入门学习路线 + 设计模式教程</span></a></span></p>\n</li>\n<li class=\"md-list-item md-focus-container\">\n<p class=\"md-end-block md-p md-focus\"><span class=\"md-meta-i-c md-link md-expand\"><a href=\"https://www.code-nav.cn/post/1640648711119892481\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新软件工程零基础入门学习路线 + 软件工程教程</span></a></span></p>\n</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 14:17</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yupi\">程序员鱼皮</a>&nbsp;\n阅读(<span id=\"post_view_count\">306</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "三、控制权之争：从 Workflow 到 Claude Skills，AI 正在进入「执行契约时代」",
      "link": "https://www.cnblogs.com/mchao/p/19608272",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/mchao/p/19608272\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 14:06\">\n    <span>三、控制权之争：从 Workflow 到 Claude Skills，AI 正在进入「执行契约时代」</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div class=\"lake-content\">\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"ub023dac1\"><span class=\"ne-text\">导读：本文作为《LLM进化史》三部曲终章，让我们看穿AI世界层出不穷的新概念背后的真正本质——所有技术演进，其实都是围绕\"谁来决定AI的行为\"这一核心问题展开的控制权之争。</span></p>\n</div>\n<hr class=\"ne-hr\" id=\"jd6dS\" />\n<h2 id=\"ZXidv\"><span class=\"ne-text\">一、AI圈最大的幻觉：每天都在诞生新技术</span></h2>\n<p class=\"ne-p\" id=\"u4cb7b10c\"><img class=\"ne-image\" id=\"ULc01\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875738215-f7ccb930-a7b2-497d-a52a-a035e310dc48.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u4d7ad2f6\"><span class=\"ne-text\">图：AI控制权之争的核心概念示意图</span></p>\n</div>\n<p class=\"ne-p\" id=\"uab70b3c2\"><span class=\"ne-text\">如果在AI圈待过一年，大概率会产生一种错觉：每天都有革命性新概念诞生。Workflow、Agent、Tool、Function Calling、MCP、Skills……名字越来越科幻，架构图越来越像星际飞船。</span></p>\n<p class=\"ne-p\" id=\"u0db9fe6b\"><span class=\"ne-text\">但这些看似眼花缭乱的概念，其实都在解决同一个问题：<strong>下一步该做什么，到底谁说了算？</strong></span></p>\n<p class=\"ne-p\" id=\"ub1370c7c\"><span class=\"ne-text\">这，就是Agent世界的真正核心矛盾：<span class=\"ne-text\">👉<span class=\"ne-text\"> <strong>控制权之争</strong></span></span></span></p>\n<p class=\"ne-p\" id=\"u4113807b\"><span class=\"ne-text\">就像公司里的项目决策，到底是老板拍板、部门经理定夺，还是一线员工自主决定？AI世界的技术演进，本质上就是在不断重新定义这个\"决策权限\"。</span></p>\n<hr class=\"ne-hr\" id=\"XBsYt\" />\n<h2 id=\"Hwofp\"><span class=\"ne-text\">二、最初的世界：人类拥有绝对控制权</span></h2>\n<p class=\"ne-p\" id=\"uf31e273a\"><img class=\"ne-image\" id=\"JJzjB\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875738104-96e331e7-78c4-4a46-96bc-21737024ac84.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u0bb97112\"><span class=\"ne-text\">图：早期Workflow时代人类绝对控制流程模式</span></p>\n</div>\n<p class=\"ne-p\" id=\"u9839208f\"><span class=\"ne-text\">在AI诞生之前，软件世界规则极其简单：程序员写死流程，机器无条件执行。Step1 → Step2 → Step3，这就是最早形态：<strong>Workflow</strong><span class=\"ne-text\">。</span></span></p>\n<p class=\"ne-p\" id=\"u1363d5c5\"><span class=\"ne-text\">本质一句话：<strong>人类完全掌控流程，机器只负责执行</strong><span class=\"ne-text\">。就像工厂里的流水线，每一步都提前设计好，工人只需按部就班操作。</span></span></p>\n<p class=\"ne-p\" id=\"u1a1aa22b\"><span class=\"ne-text\">例如一个自动化任务：读取PDF → 提取文本 → 调用翻译API → 保存Markdown。所有分支都提前写死：if PDF → 用解析器A；if Word → 用解析器B。</span></p>\n<p class=\"ne-p\" id=\"ud4742777\"><span class=\"ne-text\">这个时代的特点：<br /><span class=\"ne-text\">● 极度稳定<br /><span class=\"ne-text\">● 完全可预测<br /><span class=\"ne-text\">● 没有任何\"智能\"</span></span></span></span></p>\n<p class=\"ne-p\" id=\"ub384087b\"><span class=\"ne-text\">但有一个致命缺陷：<span class=\"ne-text\">❌<span class=\"ne-text\"> <strong>无法处理模糊需求</strong><span class=\"ne-text\">。只要任务稍微复杂一点，比如用户输入不规范、文档格式多样、执行路径不固定，Workflow就会像精密钟表掉进沙堆一样彻底停摆。因为它的前提是：<strong>流程必须提前确定</strong><span class=\"ne-text\">。</span></span></span></span></span></p>\n<p class=\"ne-p\" id=\"u6f881ded\"><span class=\"ne-text\">于是问题出现了：如果流程无法写死，该怎么办？控制权第一次开始动摇。</span></p>\n<hr class=\"ne-hr\" id=\"cVNYI\" />\n<h2 id=\"yedba\"><span class=\"ne-text\">三、第一次权力转移：流程控制权交给模型</span></h2>\n<p class=\"ne-p\" id=\"u3d7be9e4\"><img class=\"ne-image\" id=\"EbsCk\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875738605-fe0b869a-6b1a-4544-a983-24c103b13adf.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u11c78f5b\"><span class=\"ne-text\">图：第一次权力转移：流程控制权从程序到模型</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"uf162f218\"><span class=\"ne-text\">随着LLM出现，人类突然发现一件惊人的事情：模型居然能理解需求。也就是说，它可以决定下一步该做什么。这意味着：<span class=\"ne-text\">👉<span class=\"ne-text\"> <strong>流程控制权开始从程序转移到模型</strong><span class=\"ne-text\">。</span></span></span></span></p>\n<p class=\"ne-p\" id=\"u6439e510\"><span class=\"ne-text\">Agent就这样诞生了。新的架构变成：人类 → Agent → LLM → Tool。模型开始负责：<br /><span class=\"ne-text\">● 判断任务类型<br /><span class=\"ne-text\">● 决定调用什么工具<br /><span class=\"ne-text\">● 规划执行顺序</span></span></span></span></p>\n<p class=\"ne-p\" id=\"u128e47c6\"><span class=\"ne-text\">这一刻，控制权发生第一次转移：<strong>程序 → 模型</strong><span class=\"ne-text\">。就像公司老板开始授权部门经理自主决策项目流程，不再事无巨细地干预每一步。</span></span></p>\n<p class=\"ne-p\" id=\"u8f59573e\"><span class=\"ne-text\">听起来很美好，但很快问题就来了。</span></p>\n<hr class=\"ne-hr\" id=\"LoVI0\" />\n<h2 id=\"RT6BX\"><span class=\"ne-text\">四、失控的世界：模型太\"自由\"了</span></h2>\n<p class=\"ne-p\" id=\"u66763f82\"><img class=\"ne-image\" id=\"knecA\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875738429-d4f2197d-8f01-450c-b0bd-56321cfe8706.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"uf48c69d3\"><span class=\"ne-text\">图：模型失控场景示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"ue3ab5a05\"><span class=\"ne-text\">当流程控制权交给LLM后，人类立刻发现：事情开始变得不可控。模型可能会：<br /><span class=\"ne-text\">● 选择错误工具<br /><span class=\"ne-text\">● 设计奇怪流程<br /><span class=\"ne-text\">● 写出毫无必要的复杂步骤<br /><span class=\"ne-text\">● 把简单问题变成史诗级任务</span></span></span></span></span></p>\n<p class=\"ne-p\" id=\"u1b91c942\"><span class=\"ne-text\">一句话总结：<strong>模型太聪明，但也太不稳定</strong><span class=\"ne-text\">。就像授权给了一个才华横溢但缺乏经验的经理，有时候能做出惊艳的决策，有时候却会把项目带向奇怪的方向。</span></span></p>\n<p class=\"ne-p\" id=\"u1d7c29d8\"><span class=\"ne-text\">于是人类又试图夺回部分控制权。就像老板发现经理决策过于随意，开始制定一些基本规则来规范决策过程。</span></p>\n<hr class=\"ne-hr\" id=\"hGAK7\" />\n<h2 id=\"hh8tP\"><span class=\"ne-text\">五、MCP：限制模型的\"能力边界\"</span></h2>\n<p class=\"ne-p\" id=\"u652e3e18\"><img class=\"ne-image\" id=\"aRVfb\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875738541-6c1f980f-d122-4b4a-ac36-65768d643f58.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u0b4f4a54\"><span class=\"ne-text\">图：MCP限制模型能力边界原理示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u1a7f1ea9\"><span class=\"ne-text\">MCP经常被误解为\"工具协议\"，但它真正解决的问题其实是：<strong>模型能触达的世界边界在哪里？</strong></span></p>\n<p class=\"ne-p\" id=\"uebbe4c2c\"><span class=\"ne-text\">MCP规定：<br /><span class=\"ne-text\">● 有哪些工具存在<br /><span class=\"ne-text\">● 如何调用<br /><span class=\"ne-text\">● 能传什么参数<br /><span class=\"ne-text\">● 返回什么结构</span></span></span></span></span></p>\n<p class=\"ne-p\" id=\"u005bf1cf\"><span class=\"ne-text\">所以它控制的不是流程，而是：<span class=\"ne-text\">👉<span class=\"ne-text\"> <strong>模型\"能做什么\"</strong></span></span></span></p>\n<p class=\"ne-p\" id=\"ud1f688b3\"><span class=\"ne-text\">换句话说：Workflow控制<strong>怎么做</strong><span class=\"ne-text\">，MCP控制<strong>能做什么</strong><span class=\"ne-text\">。这是控制权的第二次博弈：<strong>人类放弃流程控制权，但保住能力控制权</strong><span class=\"ne-text\">。</span></span></span></span></p>\n<p class=\"ne-p\" id=\"u5bcd0411\"><span class=\"ne-text\">就像老板不再干预经理的具体决策流程，但会明确规定：我们可以调动哪些资源，不能动用哪些预算，决策范围必须在这些边界之内。</span></p>\n<hr class=\"ne-hr\" id=\"RwR24\" />\n<h2 id=\"rYOEs\"><span class=\"ne-text\">六、但真正的问题还没解决：执行的不确定性</span></h2>\n<p class=\"ne-p\" id=\"u0c1657eb\"><img class=\"ne-image\" id=\"iRT93\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739287-edef5f00-405e-4771-b861-6aaf2ae8a840.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u6002cefa\"><span class=\"ne-text\">图：Prompt层不确定性带来的问题示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u50fe023a\"><span class=\"ne-text\">即便有了MCP，一个核心问题仍然存在：模型的执行行为依然不稳定。原因很简单：在早期Agent体系中，执行逻辑往往写在Prompt里。</span></p>\n<p class=\"ne-p\" id=\"ue45da88f\"><span class=\"ne-text\">这导致：<br /><span class=\"ne-text\">● 结果不可复现<br /><span class=\"ne-text\">● 行为不可预测<br /><span class=\"ne-text\">● 依赖提示词技巧</span></span></span></span></p>\n<p class=\"ne-p\" id=\"u83149200\"><span class=\"ne-text\">本质问题是：<span class=\"ne-text\">❌<span class=\"ne-text\"> <strong>不确定性集中在Prompt层</strong><span class=\"ne-text\">。就像经理虽然有明确的权限边界，但具体怎么决策全凭个人经验和喜好，同样的问题不同时间可能会做出完全不同的决定。</span></span></span></span></p>\n<p class=\"ne-p\" id=\"ue36aeebf\"><span class=\"ne-text\">于是下一阶段的进化出现了。</span></p>\n<hr class=\"ne-hr\" id=\"dcI6y\" />\n<h2 id=\"wOoIW\"><span class=\"ne-text\">七、Claude Skills：把不确定性从Prompt中剥离</span></h2>\n<p class=\"ne-p\" id=\"uce2080b5\"><img class=\"ne-image\" id=\"TkLMN\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739284-9253728e-e2ec-41a4-87da-5ad7acb5c44f.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"ud4bfd79e\"><span class=\"ne-text\">图：Claude Skills的三层结构示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u01d5f20f\"><span class=\"ne-text\">Claude Skills的出现，并不是为了增强智能。它解决的是一个更工程化的问题：<strong>如何让模型的决策，变成稳定可复现的执行行为？</strong></span></p>\n<p class=\"ne-p\" id=\"uf1bde9cc\"><span class=\"ne-text\">Skills的本质不是工具，也不是简单上下文。它是一种：<span class=\"ne-text\">👉<span class=\"ne-text\"> <strong>执行契约</strong></span></span></span></p>\n<p class=\"ne-p\" id=\"uf6394006\"><span class=\"ne-text\">一个Skill包含三层结构：<br /><span class=\"ne-text\">1️⃣<span class=\"ne-text\"> <strong>能力暴露层</strong><span class=\"ne-text\">：告诉模型我有哪些能力，适用于什么场景<br /><span class=\"ne-text\">2️⃣<span class=\"ne-text\"> <strong>调用契约层</strong><span class=\"ne-text\">：明确输入结构、输出结构、调用规则<br /><span class=\"ne-text\">3️⃣<span class=\"ne-text\"> <strong>执行实现层</strong><span class=\"ne-text\">：提供确定性代码、可校验结果、稳定执行逻辑</span></span></span></span></span></span></span></span></span></span></p>\n<p class=\"ne-p\" id=\"u22cce76d\"><span class=\"ne-text\">本质一句话：<strong>LLM负责决策，Skill负责确定性执行</strong><span class=\"ne-text\">。就像公司制定了标准化的操作流程，经理只需做决策\"要不要做\"，而具体\"怎么做\"则完全按照标准化流程执行，确保结果稳定可预测。</span></span></p>\n<hr class=\"ne-hr\" id=\"XiB7r\" />\n<h2 id=\"Nf5zx\"><span class=\"ne-text\">八、控制权的第三次迁移：从Prompt到契约</span></h2>\n<p class=\"ne-p\" id=\"ua22689b1\"><img class=\"ne-image\" id=\"oIIvG\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739274-6e48d5da-50a5-47f1-86eb-6a5ae37f33b6.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"ua5e71a63\"><span class=\"ne-text\">图：第三次控制权迁移对比图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u343a022b\"><span class=\"ne-text\">在没有Skills时：<strong>Prompt决定执行逻辑</strong><span class=\"ne-text\"><br /><span class=\"ne-text\">引入Skills后：<strong>LLM决策 → Skill执行</strong></span></span></span></p>\n<p class=\"ne-p\" id=\"u08171a07\"><span class=\"ne-text\">控制权发生第三次转移：<strong>Prompt → 执行契约</strong></span></p>\n<p class=\"ne-p\" id=\"ua1e18a68\"><span class=\"ne-text\">也就是说：不确定性被拆分：<br /><span class=\"ne-text\">● 语义不确定性 → 模型负责<br /><span class=\"ne-text\">● 执行确定性 → Skill负责</span></span></span></p>\n<p class=\"ne-p\" id=\"ud78bfbd9\"><span class=\"ne-text\">这才是Skills的真正革命意义。就像公司把决策和执行彻底分离：经理只需要决定\"做什么\"，而\"怎么做\"则由标准化的流程和团队负责，既保留了决策的灵活性，又确保了执行的稳定性。</span></p>\n<hr class=\"ne-hr\" id=\"VvDxt\" />\n<h2 id=\"t6JsJ\"><span class=\"ne-text\">九、重新审视整个演化轴</span></h2>\n<p class=\"ne-p\" id=\"u77b99c42\"><img class=\"ne-image\" id=\"Fycpb\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739254-2a029cc7-6578-4024-b12c-68a283776982.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"ud217130e\"><span class=\"ne-text\">图：AI控制权演化轴的三个阶段示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u9ab8ca0d\"><span class=\"ne-text\">现在我们可以用一条清晰的控制权进化线来总结：</span></p>\n<h3 id=\"BtiKC\"><span class=\"ne-text\">第一阶段：流程统治时代</span></h3>\n<ul class=\"ne-ul\">\n<li id=\"u4bdc9663\"><span class=\"ne-text\">控制权属于：程序</span></li>\n<li id=\"ua84353b1\"><span class=\"ne-text\">代表技术：Workflow</span></li>\n<li id=\"u33766f8c\"><span class=\"ne-text\">特点：稳定、刚性、无智能</span></li>\n\n</ul>\n<h3 id=\"Hbogj\"><span class=\"ne-text\">第二阶段：能力边界时代</span></h3>\n<ul class=\"ne-ul\">\n<li id=\"u2e3b037b\"><span class=\"ne-text\">控制权属于：接口与协议</span></li>\n<li id=\"u495a13c7\"><span class=\"ne-text\">代表技术：MCP / Tools</span></li>\n<li id=\"u5974fbca\"><span class=\"ne-text\">特点：模型决定流程，人类限定能力范围</span></li>\n\n</ul>\n<h3 id=\"KbCZm\"><span class=\"ne-text\">第三阶段：执行契约时代（正在发生）</span></h3>\n<ul class=\"ne-ul\">\n<li id=\"ub71c2a55\"><span class=\"ne-text\">控制权属于：能力契约设计者</span></li>\n<li id=\"u85c1ab26\"><span class=\"ne-text\">代表技术：Claude Skills</span></li>\n<li id=\"u96785401\"><span class=\"ne-text\">特点：模型负责决策，契约保证执行稳定</span></li>\n\n</ul>\n<p class=\"ne-p\" id=\"ue8181f2e\"><span class=\"ne-text\">就像公司管理模式的进化：从创始人一言堂，到授权管理加边界限制，再到标准化流程加灵活决策。</span></p>\n<hr class=\"ne-hr\" id=\"G7v5F\" />\n<h2 id=\"U9aK4\"><span class=\"ne-text\">十、真正的结论</span></h2>\n<p class=\"ne-p\" id=\"u9a671c0d\"><img class=\"ne-image\" id=\"oLBWq\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739543-be9147f8-3b8d-4481-b45a-6a8b14f674f0.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u364d9acc\"><span class=\"ne-text\">图：AI技术发展本质示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u878e1c4b\"><span class=\"ne-text\">到这里我们应该能看清一个事实：<strong>AI技术的发展，并不是在不断增强智能，而是在不断回答一个问题：谁来控制不确定性？</strong></span></p>\n<p class=\"ne-p\" id=\"ubb8c43aa\"><span class=\"ne-text\">答案经历三次转移：<strong>程序 → 接口 → 契约</strong></span></p>\n<p class=\"ne-p\" id=\"u723aa540\"><span class=\"ne-text\">本质上：<strong>所有新技术，都在做同一件事：把不可控的部分，从系统中剥离出来。</strong></span></p>\n<p class=\"ne-p\" id=\"u5dda81d3\"><span class=\"ne-text\">就像不断优化的公司管理体系，核心都是在减少不确定性，让组织既能保持灵活性，又能确保稳定运行。</span></p>\n<hr class=\"ne-hr\" id=\"uUs8g\" />\n<h2 id=\"fqPqp\"><span class=\"ne-text\">十一、这也是为什么前两篇一直强调一句话</span></h2>\n<p class=\"ne-p\" id=\"u339a12f3\"><img class=\"ne-image\" id=\"vxN2d\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739836-f2c6542e-d08e-48c0-a643-8af9a6e58aa0.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u9fc35138\"><span class=\"ne-text\">图：Agent本质示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u0f21abcb\"><span class=\"ne-text\">现在我们应该能彻底理解这句话：<strong>Agent是所有不需要智能的部分</strong><span class=\"ne-text\">。</span></span></p>\n<p class=\"ne-p\" id=\"ud5a91319\"><span class=\"ne-text\">因为真正的智能始终只有一个地方：<strong>对语言与语义的理解</strong><span class=\"ne-text\">。而Workflow、MCP、Skills，本质都是在做同一件事：<strong>帮助我们控制不确定性</strong><span class=\"ne-text\">。</span></span></span></p>\n<p class=\"ne-p\" id=\"u9021315e\"><span class=\"ne-text\">就像公司里真正需要\"智能\"的是高层战略决策，而大部分执行工作都应该标准化、流程化，减少不确定性，提高效率。</span></p>\n<hr class=\"ne-hr\" id=\"MY6Y3\" />\n<h2 id=\"JozNz\"><span class=\"ne-text\">十二、未来趋势：Skills也不会是终点</span></h2>\n<p class=\"ne-p\" id=\"ub0605252\"><img class=\"ne-image\" id=\"nR9HQ\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770875739956-7292e546-861d-4516-a257-0a9ed011dc72.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u1613b627\"><span class=\"ne-text\">图：AI未来趋势示意图</span></p>\n\n</div>\n<p class=\"ne-p\" id=\"u0fc43d92\"><span class=\"ne-text\">Skills并不是终极形态，它只是AI进入\"执行契约时代\"的阶段性产物。未来趋势其实非常清晰：<br /><span class=\"ne-text\">● <strong>能力契约会内化进模型生态</strong><span class=\"ne-text\">：就像操作系统会内置各种标准API，未来的AI模型会默认集成各种常用能力契约<br /><span class=\"ne-text\">● <strong>配置会被完全隐藏</strong><span class=\"ne-text\">：用户不需要了解复杂的配置细节，就像我们现在不需要知道手机底层的技术细节一样<br /><span class=\"ne-text\">● <strong>用户只需要表达意图</strong><span class=\"ne-text\">：用户只需说\"帮我整理这份报告\"，而不需要说明具体怎么整理</span></span></span></span></span></span></span></p>\n<p class=\"ne-p\" id=\"ub9f461a5\"><span class=\"ne-text\">最终形态可能是：<strong>一个默认拥有完整执行能力体系的超级Agent</strong><span class=\"ne-text\">。人类只负责提需求，系统自动完成一切。就像拥有一个全能助手，我们只需要说\"我要开个生日派对\"，它会自动完成场地布置、邀请嘉宾、安排餐饮等所有细节。</span></span></p>\n<h2 id=\"kOjEr\"><span class=\"ne-text\">十三、三部曲终章总结</span></h2>\n<p class=\"ne-p\" id=\"ua578a9e3\"><img class=\"ne-image\" id=\"ud5449770\" src=\"https://cdn.nlark.com/yuque/0/2026/jpeg/503577/1770876170620-2f826230-d68c-4616-aea0-06a0a3f2b388.jpeg\" title=\"\" width=\"700\" /></p>\n<div class=\"ne-quote\">\n<p class=\"ne-p\" id=\"u8d8035fe\"><span class=\"ne-text\">图：《LLM进化史》三部曲核心结论示意图</span></p>\n\n</div>\n<h3 id=\"lZIf9\"><span class=\"ne-text\">第一篇我们拆掉神话：</span></h3>\n<p class=\"ne-p\" id=\"u2976eb3c\"><span class=\"ne-text\">LLM不是智能，而是概率预测机器。它并不理解语言，只是根据统计规律生成最可能的下一个词。</span></p>\n<h3 id=\"VRhtS\"><span class=\"ne-text\">第二篇我们拆掉架构幻觉：</span></h3>\n<p class=\"ne-p\" id=\"u4a38d04c\"><span class=\"ne-text\">Agent只是自动化外设系统。它本身没有智能，只是连接LLM和外部工具的桥梁。</span></p>\n<h3 id=\"pKMzL\"><span class=\"ne-text\">第三篇我们揭示终极本质：</span></h3>\n<p class=\"ne-p\" id=\"u12ec1e06\"><span class=\"ne-text\">所有AI技术的演进，其实都是一场控制权之争。从Workflow到Claude Skills，所有技术都在回答同一个问题：<strong>到底谁来决定AI的行为？</strong></span></p>\n<hr class=\"ne-hr\" id=\"NHLsD\" />\n<h2 id=\"LS4lq\"><span class=\"ne-text\">总结</span></h2>\n<p class=\"ne-p\" id=\"u5478310f\"><span class=\"ne-text\">📌<span class=\"ne-text\"> 核心要点：</span></span></p>\n<ul class=\"ne-ul\">\n<li id=\"uc4689296\"><strong>AI技术的发展本质上是围绕\"谁来控制不确定性\"的持续演化</strong></li>\n<li id=\"u31bcb9cb\"><strong>控制权经历三次典型转移：程序 → 接口 → 执行契约</strong></li>\n<li id=\"u618b4e7a\"><strong>Workflow控制流程，MCP控制能力边界，Skills控制执行稳定性</strong></li>\n<li id=\"u52e62b06\"><strong>LLM负责决策与语义理解，Skill负责确定性执行与结果可靠性</strong></li>\n<li id=\"u61a7bc6d\"><strong>Skills并非终极形态，而是AI进入\"执行契约时代\"的阶段性产物</strong></li>\n\n</ul>\n<hr class=\"ne-hr\" id=\"eU5rT\" /></div>\n\n</div>\n<div id=\"MySignature\">\n    天行健，君子以自强不息；\n地势坤，君子以厚德载物；\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 14:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/mchao\">咸鱼翻身？</a>&nbsp;\n阅读(<span id=\"post_view_count\">28</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "韩国国民搜索 NAVER：使用 JuiceFS 打通 Hadoop 与 Kubernetes 存储实践",
      "link": "https://www.cnblogs.com/JuiceData/p/19607717",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/JuiceData/p/19607717\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:45\">\n    <span>韩国国民搜索 NAVER：使用 JuiceFS 打通 Hadoop 与 Kubernetes 存储实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>NAVER 是韩国领先的互联网科技公司，运营着韩国最大的搜索引擎，并在人工智能、自动驾驶等高科技领域积极布局。作者 Nam Kyung-wan 来自 NAVER Infra 团队，自 2023 年参与 JuiceFS 社区代码贡献 (GitHub: <a href=\"https://github.com/kyungwan-nam\" rel=\"noopener nofollow\" target=\"_blank\">kyungwan-nam</a>)，为 Hadoop 场景提出了多项改进。本文是作者继“ <a href=\"https://juicefs.com/zh-cn/blog/user-stories/naver-storage-solution-juicefs-ai-platforms\" rel=\"noopener nofollow\" target=\"_blank\">为 AI 平台引入存储方案 JuiceFS</a>”后的第二篇博客。</p>\n<p>NAVER Infra 团队负责运营公共 Hadoop 集群，使用 Spark、Hive、MapReduce 等 Hadoop 应用处理数据，并将数据存储在 HDFS 中。HDFS 在 Hadoop 生态系统中通过数据本地性支持高性能，具备优异的容错性和可扩展性。</p>\n<p><strong>随着人工智能服务的普及，数据规模急剧增长，对多样化数据存储的需求也日益增加。同时，如何高效地共享 Hadoop 集群外部 AI 平台（如 Kubernetes）中的数据，成为了一项重要挑战。在这一背景下，NAVER 探讨了对象存储是否可以替代 HDFS，并明确了 JuiceFS 结合对象存储的适用场景</strong>。</p>\n<h2 id=\"01-hdfs-的局限\">01 HDFS 的局限</h2>\n<p><strong>存储成本上升</strong></p>\n<p>AI 开发需要以高效且经济的方式存储不断增长的数据，并在某些情况下长期保留原始数据，以便进行模型改进和重新训练。</p>\n<p>然而，Hadoop 的计算和存储是紧密耦合的，导致存储扩展难以独立进行。当没有计算需求时，仅为扩展存储空间而增加节点会造成不必要的成本。此外，HDFS 默认保留三重副本，进一步增加了存储成本。</p>\n<p><strong>文件数量限制</strong></p>\n<p>AI 开发涉及数千万个小文件，如图像、音频和文本等。HDFS 存在著名的<a href=\"https://www.cloudera.com/blog/technical/the-small-files-problem.html\" rel=\"noopener nofollow\" target=\"_blank\">小文件问题</a>，因为所有文件和块的元数据都存储在 NameNode 的内存中。例如，管理 1000 万个文件大约需要 3GB 的内存。因此，HDFS 可管理的文件数量受到单个 NameNode 内存容量的限制。</p>\n<p><strong>数据中心容灾能力弱</strong></p>\n<p>HDFS 通常由单个数据中心的节点组成。为应对数据中心故障或灾难，需使用额外方案将数据复制到其他数据中心，从而产生增加成本。</p>\n<p><strong>运营成本增加</strong></p>\n<p>NAVER 由专业人员运营公共 Hadoop 集群，负担相对较小，但通常 Hadoop 集群的构建和运营非常复杂且成本高昂。若要单独构建和运营稳定的 Hadoop 环境，需要专业知识和较高的维护成本。</p>\n<p><strong>Kubernetes 中的生态兼容性差</strong></p>\n<p>NAVER AI 平台基于 Kubernetes 构建，并利用 Kubeflow、KServe 等多种 AI 开源工具及 GPU 支持。但 HDFS 不支持 POSIX API 和 CSI 驱动，无法作为 Kubernetes 常规存储方式（即 PersistentVolume）使用。因此，在 Kubernetes 中使用 HDFS 需在容器中准备 Hadoop 包、配置和认证信息，并编写 HDFS API 代码，非常繁琐且会降低 AI 开发效率。</p>\n<h2 id=\"02-对象存储的优势与劣势\">02 对象存储的优势与劣势</h2>\n<p>Hadoop 通过数据本地性提供高性能，但由于 HDFS 与计算节点耦合，计算和存储资源难以独立扩展。因此，扩展存储空间时，仍需增加额外的计算节点。</p>\n<p>相比之下，云环境支持计算和存储的独立扩展。通常，数据存储在对象存储中而非 HDFS，计算可以通过托管服务（如 AWS EMR、Google Dataproc）或基于 Kubernetes 的数据处理引擎进行，数据则存储在 S3、GCS 等对象存储中。这种架构支持灵活扩展计算和存储资源。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>此外，Hadoop 社区和云供应商提供了 <a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aws/tools/hadoop-aws/index.html\" rel=\"noopener nofollow\" target=\"_blank\">S3A</a>、<a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-azure/index.html\" rel=\"noopener nofollow\" target=\"_blank\">Azure Blob</a>、<a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aliyun/tools/hadoop-aliyun/index.html\" rel=\"noopener nofollow\" target=\"_blank\">Aliyun OSS</a> 等 HDFS 兼容文件系统，使得对象存储可以像 HDFS 一样使用。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>对象存储作为远程存储，虽然难以实现数据本地性，但具有以下优势：</p>\n<ol>\n<li><strong>存储成本降低</strong>：计算和存储分离，可独立扩展。对象存储通常成本较低，并能根据需要选择不同的存储类别。例如，对于访问频率低但需长期保留的数据，可使用低成本存储类别（如 S3 Glacier）。</li>\n<li><strong>出色的扩展性和弹性</strong>：对象存储设计上支持近乎无限的扩展。对象数量和容量无限制，可根据工作负载变化轻松扩展或缩减。</li>\n<li><strong>数据中心灾难恢复支持</strong>：S3 等对象存储提供跨区域复制功能，可防止数据中心故障或灾难导致的数据丢失。</li>\n<li><strong>运营成本降低</strong>：避免 Hadoop 集群的构建和运营负担，从而降低运营成本。</li>\n</ol>\n<p>但对象存储替代 HDFS 是好的选择吗？</p>\n<p><strong>不支持目录</strong>：<br />\n在文件系统中，文件通过目录进行组织，列出目录下的文件是一项基本操作，通常速度较快。<br />\n而对象存储没有目录的概念，所有对象是独立的扁平结构。列出文件时需要通过对象前缀搜索，速度较慢。此外，为模拟目录结构而临时创建的 Directory Marker 对象也会影响性能。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p><strong>不支持重命名</strong>：<br />\n在文件系统中，重命名是基本操作，以 O(1) 级别的原子事务快速执行。但对象存储不支持重命名，需通过复制全部数据再删除原数据的方式处理，导致速度非常慢且可能中途失败。</p>\n<p>这一问题对于 MapReduce 和 Spark 等大数据框架影响尤为明显(<a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aws/tools/hadoop-aws/committers.html#Introduction:_The_Commit_Problem\" rel=\"noopener nofollow\" target=\"_blank\">Apache Hadoop Amazon Web Services support – Committing work to S3 with the S3A Committers</a>)。文件输出操作通常依赖重命名来保证一致性，FileOutputFormatCommitter 就是基于重命名实现的。因此，在对象存储中直接使用 FileOutputFormatCommitter 会显著降低性能。</p>\n<p>为了解决这一问题，可以使用 <a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aws/tools/hadoop-aws/committers.html#The_Magic_Committer\" rel=\"noopener nofollow\" target=\"_blank\">Magic Committer</a>，它避免了重命名操作，并针对对象存储进行了优化。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ol start=\"3\">\n<li>\n<p><strong>不支持文件权限</strong>：<br />\nHDFS 支持 POSIX 权限体系，可以设置文件和目录的所有者、组以及其他用户的权限。而对象存储不提供此功能，因此文件的所有者和组通常被视为当前用户，所有文件和目录的权限默认为 666 和 777（即文件可读写，目录可读写并可执行）(参考: <a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-project-dist/hadoop-common/filesystem/introduction.html#Object_Stores_vs._Filesystems\" rel=\"noopener nofollow\" target=\"_blank\">Object Stores vs. Filesystems</a>).。</p>\n</li>\n<li>\n<p><strong>数据访问速度慢</strong>：<br />\n对象存储作为远程存储，无法保证数据本地性，并且每次访问都涉及网络传输，因此相较于 HDFS，其数据访问速度较慢，性能受到网络延迟和带宽限制的影响。</p>\n</li>\n<li>\n<p><strong>Kubernetes 中的低可用性</strong>：<br />\n一些工具，如 Mountpoint for Amazon S3 和 s3fs，支持通过 POSIX API 将对象存储挂载为类似本地文件系统的方式。AWS S3 还通过 Mountpoint for Amazon S3 CSI 驱动 支持将对象存储作为 Kubernetes 卷使用。</p>\n</li>\n</ol>\n<p>然而，由于对象存储与传统文件系统存在根本差异，它无法完全兼容 POSIX API，且性能较低。因此，在使用这些工具时，需要充分了解它们的工作原理和局限性。最终，即使在 Kubernetes 环境中使用对象存储，低可用性问题仍然无法解决。</p>\n<ol start=\"6\">\n<li><strong>S3 兼容对象存储的 API 兼容性</strong>：<br />\nS3 已成为对象存储的事实标准，被多种应用广泛支持。因此，许多云供应商和开源项目提供 S3 兼容对象存储。然而，S3 兼容对象存储并不完全等同于原生 S3 服务。在使用时，需要确认其是否与 S3AFileSystem 或其他应用所使用的 S3 API 兼容。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>综上，对象存储可以像 HDFS 一样使用，但需要充分理解其局限性。现有 Hadoop 应用难以直接迁移，仍需额外的开发和适配工作。对于直接使用 HDFS API 编写的代码，需要避免重命名操作，并减少文件列表操作，以适应对象存储的特性。为避免现有 Spark 应用性能下降，需考虑使用 Magic Committer，但它并非总是有效，特别是在不支持 Spark 动态分区覆盖的情况下。</p>\n<p>此外，虽然 Spark 和 Hadoop 社区持续改进对象存储相关问题，但更新软件包版本和解决问题仍然面临挑战。使用 S3 兼容的对象存储时，还需验证其与 S3 API 的兼容性。</p>\n<h2 id=\"03-在-hadoop-中使用-juicefs\">03 在 Hadoop 中使用 JuiceFS</h2>\n<p>JuiceFS 是一款分布式文件系统，架构由客户端、元数据引擎和数据存储组成。对象存储仅用于存储数据块，而文件系统所需的元数据则由数据库管理。</p>\n<p><strong>需注意 JuiceFS 是与 HDFS 类似的分布式文件系统。因此，与直接使用对象存储不同，JuiceFS 能完美支持 HDFS API、POSIX API 和 Kubernetes CSI 驱动</strong>。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>为了在速度慢且修改困难的对象存储上实现分布式文件系统，JuiceFS 引入了 chunk、slice 和 block 概念。</p>\n<ul>\n<li>chunk（64MB）：将文件分割为 64MB 单位，支持基于偏移的并行处理。</li>\n<li>slice：chunk 内的修改单位，写入时创建新 slice 并优先使用最新版本。</li>\n<li>block（默认 4MB）：实际存储在对象存储中的最小单位，通过并行处理缩短上传时间。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>此外，从远程对象存储读取数据较慢，JuiceFS 支持多级缓存，以此弥补此性能不足。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>NAVER 内部 AI 平台已使用 JuiceFS。更多关于 JuiceFS 的详细信息及 AI 平台引入过程可参考<a href=\"https://juicefs.com/zh-cn/blog/user-stories/naver-storage-solution-juicefs-ai-platforms\" rel=\"noopener nofollow\" target=\"_blank\">为 AI 平台引入存储方案 JuiceFS</a>。</p>\n<p>JuiceFS 支持 Hadoop SDK，通过配置 JuiceFS 后，用户即可在 Hadoop 环境中使用它。</p>\n<h3 id=\"配置-juicefs\">配置 JuiceFS</h3>\n<p>为使 Hadoop 识别 JuiceFS 文件系统，需在 core-site.xml 文件中添加以下内容。其中 <a href=\"https://juicefs.com/docs/community/hadoop_java_sdk/#core-configurations\" rel=\"noopener nofollow\" target=\"_blank\">fs.jfs.impl、fs.AbstractFileSystem.jfs.impl 和 juicefs.meta</a> 是必需的。</p>\n<pre><code>&lt;!-- Configure JuiceFS to be available via jfs:// --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;fs.jfs.impl&lt;/name&gt;  \n    &lt;value&gt;io.juicefs.JuiceFileSystem&lt;/value&gt;  \n  &lt;/property&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;fs.AbstractFileSystem.jfs.impl&lt;/name&gt;  \n    &lt;value&gt;io.juicefs.JuiceFS&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- juicefs meta url --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.meta&lt;/name&gt;  \n    &lt;value&gt;redis://:password@addr&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- In this example, grant access permissions to all users to avoid permission issues. --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.umask&lt;/name&gt;  \n    &lt;value&gt;000&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Cache up to 100 GiB. --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.cache-size&lt;/name&gt;  \n    &lt;value&gt;102400&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Cache under the temporary path of YARN containers, so the cache is removed when the container terminates.    \nSince it's a shared Hadoop, caching is temporary only during job execution. --&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.cache-dir&lt;/name&gt;  \n    &lt;value&gt;${env.PWD}/tmp&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Prometheus remote write configuration for metrics collection --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.push-remote-write&lt;/name&gt;  \n    &lt;value&gt;http://host:port&lt;/value&gt;  \n  &lt;/property&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.push-remote-write-auth&lt;/name&gt;  \n    &lt;value&gt;username:password&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Additionally collect Hadoop user and YARN container ID.    \nFor shared Hadoop to distinguish users and applications. --&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.push-labels&lt;/name&gt;  \n    &lt;value&gt;user:${env.USER};container_id:${env.CONTAINER_ID}&lt;/value&gt;  \n  &lt;/property&gt;  \n</code></pre>\n<p>以上为单文件系统的默认配置，但也可根据需要配置多个文件系统同时使用。<br />\n更多配置选项可参考“<a href=\"https://juicefs.com/docs/community/hadoop_java_sdk/#client-configurations\" rel=\"noopener nofollow\" target=\"_blank\">客户端配置</a>”。</p>\n<h3 id=\"hadoop-sdk\">Hadoop SDK</h3>\n<p>Hadoop SDK 的 JAR 文件可以通过下载预编译客户端或自行编译源代码获取。为了简化部署，通常可以在所有 Hadoop 节点的 Hadoop 发行版安装路径中预先安装。然而，在大规模 Hadoop 集群中，这种方法操作繁琐，尤其是对于公共 Hadoop 环境，它会限制所有用户使用特定版本。</p>\n<p>大多数 Hadoop 应用支持将所需 JAR 文件部署并添加到 classpath 中，用户可根据实际需要选择部署方式。以下是 HDFS CLI、MapReduce 和 Spark 中的具体部署方法。</p>\n<h3 id=\"hdfs-cli\">HDFS CLI</h3>\n<p>配置完上述 <code>core-site.xml</code> 文件后，需要在 <code>HADOOP_CLASSPATH</code> 环境变量中设置 Hadoop SDK 文件路径。完成此设置后，您可以使用 <code>hdfs</code> 命令操作 <code>hdfs://</code> 和 <code>jfs://</code> 文件系统。</p>\n<pre><code>$ export HADOOP_CLASSPATH=/home/juicefs/juicefs-hadoop-1.2.3.jar  \n$ hdfs dfs -ls hdfs://home/foo  \nFound 6 items    \n...  \ndrwx------   - foo users          0 2022-10-14 20:55 hdfs://home/foo/.Trash    \ndrwx------   - foo users          0 2022-01-06 10:18 hdfs://home/foo/dfsio    \ndrwx------   - foo users          0 2025-01-22 17:54 hdfs://home/foo/tpcds\n\n$ hdfs dfs -ls jfs://default/  \n2025-08-25 19:15:43,964 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 60 minutes, Emptier interval = 60 minutes.    \nFound 8 items    \n...  \ndrwxrwxrwx   - 10000 hadoop-admins       4096 2025-06-10 18:06 jfs://default/nyc    \ndrwxrwxrwx   - 10000 hadoop-admins       4096 2025-05-15 19:42 jfs://default/subdir    \n</code></pre>\n<h3 id=\"mapreduce\">MapReduce</h3>\n<p>MapReduce 在 Hadoop 的多个节点上并行运行，因此所有分配任务的节点都需要部署 JAR 文件。推荐的方法是通过分布式缓存进行部署。使用此方法时，任务执行时会自动将 <code>mapreduce.application.framework.path</code> 中设置的 MapReduce 框架部署到任务节点。</p>\n<p>以下是 <code>mapred-site.xml</code> 文件的示例配置：</p>\n<ul>\n<li><code>mapreduce.application.framework.path</code>：指定包含 Hadoop SDK 的 MapReduce 框架的 HDFS 路径。</li>\n<li><code>mapreduce.application.classpath</code>：配置为包含 Hadoop SDK 的路径。</li>\n</ul>\n<pre><code>&lt;property&gt;  \n   &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;  \n   &lt;value&gt;$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*&lt;/value&gt;  \n &lt;/property&gt;  \n &lt;property&gt;  \n   &lt;name&gt;mapreduce.application.framework.path&lt;/name&gt;  \n   &lt;value&gt;hdfs://mapred/framework/hadoop-mapreduce-3.1.2-juicefs-1.2.3.tar.gz#mrframework&lt;/value&gt;  \n &lt;/property&gt;  \n</code></pre>\n<h3 id=\"spark\">Spark</h3>\n<p>Spark 的基本配置文件是 <code>spark-defaults.conf</code>。在该文件中，可以替代 <code>core-site.xml</code> 进行如下设置：</p>\n<ul>\n<li>任意 Hadoop 设置可以通过 <code>spark.hadoop.key=value</code> 形式添加。</li>\n<li><code>spark.jars</code>：指定要部署到 Spark driver 和 executor，并包含在 classpath 中的 JAR 文件。</li>\n</ul>\n<pre><code>spark.hadoop.fs.jfs.impl io.juicefs.JuiceFileSystem    \nspark.hadoop.fs.AbstractFileSystem.jfs.impl io.juicefs.JuiceFS    \nspark.hadoop.juicefs.meta redis://:password@addr    \nspark.hadoop.juicefs.umask 000    \nspark.hadoop.juicefs.push-remote-write http://host:port    \nspark.hadoop.juicefs.push-remote-write-auth username:password    \nspark.hadoop.juicefs.push-labels user:${env.USER};container_id:${env.CONTAINER_ID}    \nspark.hadoop.juicefs.cache-size 102400    \nspark.hadoop.juicefs.cache-dir ${env.PWD}/tmp    \nspark.jars hdfs://juicefs/juicefs-hadoop/juicefs-hadoop-1.2.3.jar  \n</code></pre>\n<h2 id=\"04-juicefs-改进事项\">04 JuiceFS 改进事项</h2>\n<p>JuiceFS 提供多种接口，支持跨平台的数据共享。例如，在 Hadoop 中使用 MapReduce 或 Spark 处理的数据存储到 JuiceFS 后，可以轻松在 Kubernetes 环境中访问和使用这些数据。</p>\n<p>为使 NAVER 公共 Hadoop 和基于 Kubernetes 的 AI 平台顺畅共享数据，需要进行一些改进。（已经全部贡献到社区版。）</p>\n<h3 id=\"支持-all-squash-挂载5394\"><a href=\"https://github.com/juicedata/juicefs/issues/5394\" rel=\"noopener nofollow\" target=\"_blank\">支持 all-squash 挂载</a>（#5394）</h3>\n<p>NAVER 公共 Hadoop 与 LDAP 集成管理用户账户，因此 Hadoop 中创建的数据由相应用户的 LDAP UID 和 GID 所有。然而，在 Kubernetes 中，容器可以使用任意 UID 和 GID 运行，这可能导致访问 Hadoop 创建的数据时产生权限问题。</p>\n<p>为了解决这个问题，我们增加了挂载选项 <code>--all-squash</code>。该选项使得访问挂载路径时，操作不会以当前账户的 UID 和 GID 进行，而是使用指定的 UID:GID。因此，设置 Hadoop 用户的 LDAP UID 和 GID 后，Kubernetes 中的容器可以无权限问题地访问数据。</p>\n<h3 id=\"改进-juicefsusers-和-juicefsgroup-设置方式4723\"><a href=\"https://github.com/juicedata/juicefs/issues/4723\" rel=\"noopener nofollow\" target=\"_blank\">改进 juicefs.users 和 juicefs.group 设置方式</a>（#4723）</h3>\n<p>如前所述，在 Hadoop 集群中执行任务时，数据归 Hadoop 用户的 LDAP UID 和 GID 所有。但在 Hadoop 集群外部使用 Hadoop SDK 时，数据归任意 UID 和 GID 所有。例如，在 Docker 容器中使用 HDFS 命令存储数据时，所有者为容器内部账户的 UID 和 GID。</p>\n<p>为了解决这个问题，用户需要通过 <code>juicefs.users</code> 和 <code>juicefs.groups</code> 设置指定所需的 UID 和 GID。之前，这要求用户编写 <code>&lt;用户名&gt;:&lt;UID&gt;</code> 和 <code>&lt;组名&gt;:&lt;GID&gt;</code> 格式的文件，并设置文件路径，这个过程非常繁琐。现在，我们增加了直接通过配置值来指定 UID 和 GID 的功能，简化了操作。</p>\n<h3 id=\"支持-subdir6096\"><a href=\"https://github.com/juicedata/juicefs/issues/6096\" rel=\"noopener nofollow\" target=\"_blank\">支持 subdir</a>（#6096）</h3>\n<p>在基于 Kubernetes 的 AI 平台中，JuiceFS 以动态供应方式使用。创建 PersistentVolumeClaim（PVC）时，会在 JuiceFS 文件系统内生成与该卷对应的子目录。若要在 Hadoop 中共享该 PVC，需仅安全地共享该卷对应的目录。</p>\n<p>然而，Hadoop SDK 并不提供类似 <code>--subdir</code> 的挂载选项，无法限制 Hadoop 仅访问 JuiceFS 的特定子路径。为了解决这个问题，我们在 Hadoop SDK 中增加了 <code>juicefs.subdir</code> 设置，使用此设置可以限制仅访问指定路径。</p>\n<h3 id=\"通过-hdfs-命令查看配额5937\"><a href=\"https://github.com/juicedata/juicefs/issues/5937\" rel=\"noopener nofollow\" target=\"_blank\">通过 hdfs 命令查看配额</a>（#5937）</h3>\n<p>JuiceFS 可以为整个文件系统或特定目录设置配额。在 Kubernetes 中，PVC 的 <code>spec.resources.requests.storage</code> 值将设置为该目录的配额。</p>\n<p>在 Hadoop 与 PVC 共享时，也需要查看配额信息。然而，原有的 HDFS 命令 <code>hdfs dfs -count -q</code> 无法查看 JuiceFS 的配额。为了解决这个问题，我们对该功能进行了改进，现在可以通过相同的命令查看 JuiceFS 的配额信息。</p>\n<h3 id=\"支持-prometheus-remote_write-协议6295\"><a href=\"https://github.com/juicedata/juicefs/issues/6295\" rel=\"noopener nofollow\" target=\"_blank\">支持 Prometheus remote_write 协议</a>（#6295）</h3>\n<p>使用 JuiceFS Hadoop SDK 时，可以将指标发送到 Pushgateway 和 Graphite。但 Pushgateway 需要定期清理指标，且 Graphite 格式独特，使用起来较为困难。</p>\n<p>许多系统支持 Prometheus <code>remote_write</code> 协议。为了解决这个问题，我们在 JuiceFS 中增加了通过该协议发送指标的功能。通过 <code>juicefs.push-remote-write</code> 和 <code>juicefs.push-remote-write-auth</code> 设置，用户可以指定 VictoriaMetrics  <code>vmagent</code> 或 Prometheus。这一功能不仅整合了跨平台数据，还能整合监控系统。</p>\n<h2 id=\"05-juicefs-的优势\">05 JuiceFS 的优势</h2>\n<h3 id=\"优势-1通过并行处理和缓存克服对象存储的性能瓶颈\">优势 1：通过并行处理和缓存克服对象存储的性能瓶颈</h3>\n<p>JuiceFS 需要通过网络与远程对象存储交换数据块，因此在性能上难以超越具有数据本地性优势的 HDFS。<strong>然而，通过将数据分块并行处理以及缓存已读取数据，可以克服这一性能瓶颈</strong>。我们通过性能测试验证了 HDFS 和 JuiceFS 在不同场景下的表现。</p>\n<h4 id=\"dfsio\">DFSIO</h4>\n<p>使用 10 个 map task，针对 100GB 文件测量 HDFS 和 JuiceFS 的顺序数据写入和读取的吞吐量。数值越高性能越好。为适应顺序写入/读取，将 JuiceFS 的块大小设为 16MB。</p>\n<ul>\n<li>写入：JuiceFS 的吞吐量是 HDFS 的 1.7 倍。这是因为数据被分割成小块并行上传。</li>\n<li>读取：JuiceFS 的吞吐量是 HDFS 的 0.75 倍。但如果数据已缓存，预期性能与 HDFS 相似。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h4 id=\"tpc-ds\">TPC-DS</h4>\n<p>使用 Spark SQL 测量对存储在 HDFS 和 JuiceFS 的 100GB 规模表的查询响应时间。数值越低性能越好。</p>\n<ul>\n<li>JuiceFS 的响应时间是 HDFS 的 1.8 倍，这是由于数据本地性差异所致。</li>\n<li>已缓存的 JuiceFS 表现出与 HDFS 相似的性能。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"优势-2与-hdfs-完全兼容无需修改现有-hadoop-应用即可使用\">优势 2：与 HDFS 完全兼容，无需修改现有 Hadoop 应用即可使用</h3>\n<p>NAVER 拥有稳定运营的公共 Hadoop 集群，运行着多种服务的 Hadoop 应用。如果仅将不常用的数据存储在对象存储中以降低存储成本，可能会出现问题。正如前所述，对象存储不是文件系统，无法保证现有 Hadoop 应用的性能和运行。为此，需要重写代码或检查数据处理引擎是否支持对象存储。此外，还需根据存储类型单独运行和管理 Hadoop 应用，增加了管理负担。</p>\n<p>与之相反，使用 JuiceFS 可以保持现有 Hadoop 应用不变。用户只需将输入输出路径指定为 <code>hdfs://</code> 或 <code>jfs://</code>，即可以相同方式运行应用。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>HDFS 基于数据本地性保证高性能，而对象存储则在低成本和扩展性方面具有优势。两者各有所长，难以完全替代，需要根据需求选择。使用 JuiceFS 可以在不修改现有 Hadoop 应用的情况下，同时利用 HDFS 和对象存储的优势。</p>\n<h3 id=\"优势-3支持多种接口可作为跨平台集成存储\">优势 3：支持多种接口，可作为跨平台集成存储</h3>\n<p>NAVER 使用多种平台进行服务开发和运营。例如，在开发/运营 AI 服务时，需要在数据处理平台中清洗数据，在 AI 平台中训练模型，并通过容器平台提供服务。</p>\n<p>在 NAVER，各个平台提供独立的存储，平台内部易于使用，但难以访问其他平台的存储。不同平台的存储隔离导致了数据孤岛现象，并容易造成数据重复和资源浪费。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>JuiceFS 不仅支持 HDFS，还完美兼容 POSIX 和 Kubernetes CSI 驱动，适合作为跨平台的集成存储。通过在多个平台间顺畅使用 JuiceFS 共享数据，可大幅提升 AI 服务开发效率，实现数据统一管理。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h2 id=\"06-结语\">06 结语</h2>\n<p>本文探讨了 JuiceFS 在 Hadoop 环境中的使用方法及其优势，而在部分业务场景下，直接采用 HDFS 或对象存储会是更适配的选择。例如，当业务需要依托数据本地性实现高效快速处理时，建议将数据存储于 HDFS 中；此外，针对访问频率较低的数据，或采用 Iceberg 等专为对象存储优化的数据格式时，直接使用对象存储则更为简便。</p>\n<p>而在以下场景中，JuiceFS 会是更优选择：</p>\n<ol>\n<li>需在 Kubernetes 与 Hadoop 环境之间实现数据共享时；</li>\n<li>希望在不修改现有 Hadoop 应用代码的前提下，与 HDFS 并行部署使用时；</li>\n<li>处理存在重复读取行为、可通过缓存显著提升效率的数据作业时；</li>\n<li>业务所用 S3 API 无法被底层 S3 兼容存储良好支持时。</li>\n</ol>\n<p>本文介绍了在 NAVER 内部本地环境中的应用案例，但在 AWS、Google Cloud 等公有云环境中同样适用。希望对有类似困扰的读者有所帮助。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/JuiceData\">JuiceFS</a>&nbsp;\n阅读(<span id=\"post_view_count\">59</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "布谷鸟过滤器原理详解",
      "link": "https://www.cnblogs.com/lxl-233/p/19607712",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lxl-233/p/19607712\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:46\">\n    <span>布谷鸟过滤器原理详解</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div>\n<div><span style=\"font-size: 18px;\"><strong>布谷鸟过滤器 vs 布隆过滤器 核心原理与特性解析</strong></span></div>\n</div>\n<p>与布隆过滤器一样,布谷鸟过滤器也是用来快速判断一个元素是否存在的,但是解决了布隆过滤器\"无法删除\"的痛点</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>一、底层数据结构对比</strong></span></div>\n</div>\n<p>底层数据结构中,布隆过滤器采用的是一维bit数组,每个位只能存储01状态,通过若干hash函数命中多个位来判断元素是否存在,具有存在的误判风险<br />而布谷鸟过滤器采用的是一维桶数组,每个bucket存储元素的\"指纹\"fingerprint,也就是将元素值做了一边hash,是一个8位2进制数,而且只有两个hash函数,同样也具有存在误判风险</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>二、布谷鸟过滤器核心操作</strong></span></div>\n</div>\n<p>1. 插入数据：“双哈希找巢，指纹占位置” 对要存入的任意值（比如字符串 “user123”）：<br />① 生成指纹：先通过哈希函数把值转化为短且固定长度的 “指纹”（比如把 “user123” 哈希成 8 位二进制数 “10110010”）—— 指纹是值的 “精简版”，比原值小得多，目的是节省内存； <br />② 双哈希定位桶：用两个独立的哈希函数（Hash1、Hash2），计算出这个值在 “桶数组” 里的两个候选桶位置（比如 Hash1 算出来是第 10 号桶，Hash2 算出来是第 25 号桶）； <br />③ 存入规则：把指纹放进任意一个候选桶（只要桶里还有空位）；如果两个桶都满了，就 “踢走” 其中一个桶里已有的指纹（类似布谷鸟占别的鸟的巢），被踢走的指纹再用它自己的另一个候选桶位置重新插入，直到找到空位（或重试上限，说明过滤器满了）。</p>\n<p>2. 查询数据：“双桶找指纹，有则判存在”（对应官方 “membership query”） 要判断 “值 x 是否存在”：<br />① 生成 x 的指纹（和插入时的规则一致）；<br />② 用 Hash1、Hash2 算出 x 的两个候选桶；<br />③ 只要其中一个桶里能找到和 x 完全匹配的指纹，就返回 “存在”；两个桶都没有，就返回 “不存在”。 关键特性：只有 “假阳性”，没有 “假阴性” 和布隆过滤器一样，布谷鸟过滤器的判断结果规则是： 说 “不存在”：100% 准确（绝对不存在）； 说 “存在”：可能误判（实际不存在，但指纹巧合匹配）—— 这就是 “假阳性（false positive）”。</p>\n<p>3. 删除数据:&nbsp; &nbsp;\"生成待删除元素指纹, 双哈希找巢, 找到两个候选桶, 桶中找到任意相同指纹,删除一个即可\"<br />为什么传统布隆过滤器无法删除呢? 因为布隆过滤器依靠bit数组hash命中,多个元素可能命中相同位置,那么这个位置实际包含了两个元素存在的信息,是\"共享\"的,删除一个元素,需要把对应位置置为0,就会影响到其他元素的判断<br />而布谷鸟过滤器不同,它使用的是桶数组,就算两个元素恰好计算的两个候选桶是相同的,恰好计算出的指纹也是相同的,且恰好存放指纹的实际桶也是同一个,也没关系,直接往桶里塞<br />因为桶是可以存放多个的,存放多个相同的指纹也没关系,天然支持存放相同指纹<br />删除的时候,直接找到候选桶,删除对应的一个指纹就行了<br />但也正因如此,只删除一个对应指纹,再去判断此元素是否存在时,有其他元素恰好指纹是相同的,且存于同一个桶中,这样可能会存在误判,官方论文中称为\"假阳性\"</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>三、误判率：指纹长度的核心影响</strong></span></div>\n</div>\n<p>官方明确 “fingerprint size will directly determine the false positive rate”，意思是 指纹是值的 “精简标识”，长度越短（比如 4 位），不同值生成相同指纹的概率越高，误判率就越高； 指纹越长（比如 16 位），相同指纹的概率越低，误判率就越低，但每个元素生成的指纹越长,&nbsp; 占用的内存也越多。 <br />举个实际数值（Redis 中常用配置）：<br />8 位指纹：误判率≈1/256（0.39%），适合对误判率要求不高、追求内存极致节省的场景； <br />16 位指纹：误判率≈1/65536（0.0015%），适合对误判率敏感的场景（比如黑名单校验）。</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>四、Redis 中布谷鸟过滤器的优劣势</strong></span></div>\n</div>\n<p>支持删除数据：布隆过滤器的位数组一旦置 1 无法回退，无法删除；布谷鸟过滤器只需删除对应桶里的指纹即可，适合需要动态更新的场景（比如黑名单新增 / 删除）；<br />空间效率更高：指纹是紧凑存储的，相比布隆过滤器的稀疏位数组(存在大量浪费) 相同误判率下，布谷鸟过滤器的内存占用约为布隆过滤器的 1/2~2/3；<br />哈希函数更少：固定 2 个哈希函数，计算开销比布隆过滤器（3-5 个）更低。<br />性能: 布谷鸟过滤器只需要计算一次找到hash桶,且各个桶的位置较为集中,内存上较为靠近,CPU的缓存命中率更高,查询速度快于布隆过滤器<br /><br />劣势:<br />在接近满时,布谷鸟过滤器插入元素可能会频繁占巢,导致后续指纹不得不移动自己的位置,导致插入性能大幅下降(由于布谷鸟过滤器的\"占巢\"特点,元素越多,越趋向于满时,插入数据的性能会越来越低,因为插入一个就要占别人的巢,别人又要去找另一个巢,重复如此,性能会越来越低)<br />而且布谷鸟过滤器的容量大小必须为2的幂<br />可惜的是现在的具体实现并不多,GitHub上只有零星几个Go,C++,Java的实现</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>五、核心总结</strong></span></div>\n</div>\n<p>布谷鸟过滤器底层是桶数组 + 指纹，靠 2 个哈希函数定位桶，不同于布隆过滤器的 “位数组 + 多哈希”；<br />查询逻辑：双桶找匹配指纹，有则判存在，无则判不存在（仅可能假阳性）； <br />误判率核心：指纹长度越短，误判率越高，内存占用越少，可按需平衡；<br />核心优势：支持删除、内存效率高，是 Redis 中布隆过滤器的升级版, 但是插入性能略逊于传统布隆过滤器</p>\n<p>官方文档: <a href=\"https://redis.io/docs/latest/develop/data-types/probabilistic/cuckoo-filter/\" rel=\"noopener nofollow\" target=\"_blank\">https://redis.io/docs/latest/develop/data-types/probabilistic/cuckoo-filter/</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:46</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lxl-233\">风乐</a>&nbsp;\n阅读(<span id=\"post_view_count\">15</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "鸿蒙应用开发UI基础第六节:Want拉起应用跳转传参匹配规则实战",
      "link": "https://www.cnblogs.com/san-xiu/p/19607664",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/san-xiu/p/19607664\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:41\">\n    <span>鸿蒙应用开发UI基础第六节:Want拉起应用跳转传参匹配规则实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"学习目标\">【学习目标】</h2>\n<ol>\n<li>理解 Want 本质：掌握 Want 作为组件间信息传递载体的核心作用，明确显式/隐式 Want 的划分与适用场景；</li>\n<li>掌握显式启动：精通跨应用通过 <code>bundleName+abilityName</code> 精准启动组件；</li>\n<li>掌握隐式启动：吃透 <code>linkFeature</code>、<code>action</code>、<code>entities</code>、<code>uri</code>、<code>type</code> 的完整层级匹配规则；</li>\n<li>数据传递与校验：规范使用 <code>parameters</code> 传递数据，合理运用功能标识实现精准匹配。</li>\n</ol>\n<h2 id=\"内容铺垫\">【内容铺垫】</h2>\n<p>在 HarmonyOS 中，<strong>Want 是组件（Ability/Extension）间交互的标准信息载体</strong>，核心用于描述“操作目标”“操作意图”和“附加数据”，是应用内/跨应用组件通信的核心桥梁。无论是应用内页面跳转、跨应用功能调用（如打开文档、分享内容），本质都是通过传递 Want 对象实现的。</p>\n<p>在之前的章节中，我们已多次使用 Want 实现 Ability 拉起操作，本节将所有 Want 核心能力直接在 <code>Index</code> 页演示，无需额外跳转页面。</p>\n<blockquote>\n<p>核心规范提示：从 API 12 开始，已不再推荐三方应用使用指定 Ability 方式（即显式 Want）拉起其他应用，推荐使用指定应用链接方式（下一节讲），但作为开发者，我们仍需掌握显式/隐式 Want 的核心原理，以便应对各类组件通信场景。</p>\n</blockquote>\n<p>示意图如下：</p>\n<p><img alt=\"StartAbility调用原理\" class=\"lazyload\" /></p>\n<h2 id=\"一want-核心概念与结构\">一、Want 核心概念与结构</h2>\n<p>Want 是对象类型，核心字段决定组件匹配与启动逻辑，关键字段及约束如下：</p>\n<h3 id=\"1-核心字段解析\">1. 核心字段解析</h3>\n<table>\n<thead>\n<tr>\n<th>字段名</th>\n<th>类型</th>\n<th>核心作用</th>\n<th>必选性</th>\n<th>核心说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>deviceId</code></td>\n<td>string</td>\n<td>目标设备ID</td>\n<td>否</td>\n<td>空字符串表示本机，跨设备场景需指定设备标识；隐式 Want 暂不支持跨设备调用</td>\n</tr>\n<tr>\n<td><code>bundleName</code></td>\n<td>string</td>\n<td>目标应用包名</td>\n<td>显式必选</td>\n<td>显式 Want 必须指定</td>\n</tr>\n<tr>\n<td><code>abilityName</code></td>\n<td>string</td>\n<td>目标组件名称</td>\n<td>显式必选</td>\n<td>显式 Want 核心字段；API 12+ 跨应用场景不推荐使用</td>\n</tr>\n<tr>\n<td><code>moduleName</code></td>\n<td>string</td>\n<td>目标模块名称</td>\n<td>否</td>\n<td>同一应用多模块存在重名组件时，需指定，否则默认匹配第一个模块</td>\n</tr>\n<tr>\n<td><code>uri</code></td>\n<td>string</td>\n<td>统一资源标识符</td>\n<td>隐式可选</td>\n<td>格式为 <code>scheme://host:port/path</code>；自定义 scheme 不可与系统应用重复（如 <code>ohos</code> 前缀）</td>\n</tr>\n<tr>\n<td><code>action</code></td>\n<td>string</td>\n<td>操作意图</td>\n<td>隐式核心</td>\n<td>常用值：<code>ohos.want.action.viewData</code>（查看数据）、<code>ohos.want.action.share</code>（分享）、<code>ohos.want.action.search</code>（搜索）</td>\n</tr>\n<tr>\n<td><code>entities</code></td>\n<td>Array</td>\n<td>组件类别约束</td>\n<td>隐式可选</td>\n<td>常用值：<code>entity.system.browsable</code>（浏览器类组件）、<code>entity.system.home</code>（桌面应用）</td>\n</tr>\n<tr>\n<td><code>type</code></td>\n<td>string</td>\n<td>数据MIME类型</td>\n<td>隐式可选</td>\n<td>如 <code>text/plain</code>（纯文本）、<code>image/png</code>（PNG图片），需与 <code>uri</code> 协同匹配</td>\n</tr>\n<tr>\n<td><code>parameters</code></td>\n<td>Object</td>\n<td>自定义附加数据</td>\n<td>否</td>\n<td>支持基础数据类型（字符串、数字、布尔值等）；可通过 <code>linkFeature</code> 字段标记功能类型（隐式匹配最高优先级）</td>\n</tr>\n<tr>\n<td><code>flags</code></td>\n<td>number</td>\n<td>启动模式标记</td>\n<td>否</td>\n<td>仅 <code>FLAG_START_WITHOUT_TIPS</code> 支持隐式 Want 取消“暂无可用打开方式”弹框；无法取消“是否允许跳转”系统弹框</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"2-want-的两种核心类型\">2. Want 的两种核心类型</h3>\n<ul>\n<li><strong>显式 Want</strong>：同时指定 <code>bundleName</code> 和 <code>abilityName</code>，直接定位目标组件，无需系统遍历匹配，匹配效率高、无系统开销。</li>\n<li><strong>隐式 Want</strong>：不指定 <code>abilityName</code>，通过 <code>linkFeature</code>、<code>action</code>、<code>entities</code>、<code>uri</code>、<code>type</code> 描述操作意图，由系统匹配声明对应 <code>skills</code> 的组件，<strong>适用于跨应用通用功能调用</strong>（如调用系统分享、打开浏览器）。</li>\n</ul>\n<h3 id=\"3-隐式-want-匹配规则核心重点\">3. 隐式 Want 匹配规则（核心重点）</h3>\n<h4 id=\"1匹配基础前提\">（1）匹配基础前提</h4>\n<p>隐式 Want 匹配的基础前提：若 <code>action</code>/<code>entities</code>/<code>uri</code>/<code>type</code>/<code>parameters(linkFeature)</code> 五个属性均未配置，系统直接判定匹配失败，无需后续校验。</p>\n<h4 id=\"2匹配优先级从高到低\">（2）匹配优先级（从高到低）</h4>\n<p><code>linkFeature（parameters 内置字段）</code> → <code>action</code> → <code>entities</code> → <code>uri + type</code></p>\n<blockquote>\n<p><code>linkFeature</code> 是 HarmonyOS API 11+ 新增的最高优先级匹配字段，通过 <code>parameters</code> 传递，专门解决传统隐式匹配范围过宽的问题，适用于跨应用固定功能的精准隐式调用。</p>\n</blockquote>\n<h4 id=\"3分步详细规则\">（3）分步详细规则</h4>\n<p>表格中 action 值如 <code>abc</code> 仅为表达匹配，工程中取值要规范。</p>\n<h5 id=\"-linkfeature-匹配最高优先级\">① linkFeature 匹配（最高优先级）</h5>\n<h6 id=\"核心匹配字段及校验逻辑精准匹配为唯一规则\">核心匹配字段及校验逻辑（精准匹配为唯一规则）</h6>\n<table>\n<thead>\n<tr>\n<th>校验字段</th>\n<th>触发校验条件</th>\n<th>匹配规则</th>\n<th>失败判定</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>linkFeature</td>\n<td>调用方传该参数则必校验</td>\n<td>需与 skills 配置值完全一致</td>\n<td>配置值≠调用方值（如 link≠errLink）</td>\n</tr>\n<tr>\n<td>scheme（URI）</td>\n<td>调用方传 uri 则必校验 scheme</td>\n<td>需与 uri 的 scheme 完全一致</td>\n<td>scheme≠uri 的 scheme（如 https≠file）</td>\n</tr>\n<tr>\n<td>type</td>\n<td>调用方传 type 则必校验</td>\n<td>需与调用方 type 完全一致</td>\n<td>type≠调用方值（如 text/plain≠image/png）</td>\n</tr>\n</tbody>\n</table>\n<h6 id=\"分场景匹配规则\">分场景匹配规则</h6>\n<ol>\n<li><strong>场景1（仅传 linkFeature）</strong>：仅校验 linkFeature，scheme/type 不参与，一致则成功，否则失败；</li>\n<li><strong>场景2（传 uri+linkFeature）</strong>：需同时满足 scheme 匹配 + linkFeature 匹配，任一不满足则失败；</li>\n<li><strong>场景3（传 type+linkFeature）</strong>：需同时满足 type 匹配 + linkFeature 匹配，任一不满足则失败；</li>\n<li><strong>场景4（传 uri+type+linkFeature）</strong>：需同时满足 scheme 匹配 + type 匹配 + linkFeature 匹配，任一不满足则失败。</li>\n</ol>\n<h6 id=\"补充说明\">补充说明</h6>\n<ul>\n<li>无通配符、前缀匹配等宽松规则，所有参与校验的字段均为<strong>精准完全匹配</strong>；</li>\n<li>调用方未传的字段（如 uri/type），skills 中对应字段不参与校验；</li>\n<li>无“部分匹配”“降级匹配”逻辑，任一需校验字段不匹配则整体失败。</li>\n</ul>\n<h5 id=\"-action-匹配规则\">② action 匹配规则</h5>\n<table>\n<thead>\n<tr>\n<th>调用方 <code>want</code> 的 <code>action</code></th>\n<th>目标方 <code>skills.actions</code></th>\n<th>匹配结果</th>\n<th>核心说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>空值 <code>action:\"\"</code></td>\n<td>空值 <code>actions: []</code></td>\n<td>失败</td>\n<td>双方均未声明操作意图，系统无法匹配</td>\n</tr>\n<tr>\n<td>空值 <code>action:\"\"</code></td>\n<td>非空值 <code>actions: [\"abc\"]</code></td>\n<td>成功</td>\n<td>调用方未指定意图，目标方声明了能力，默认匹配</td>\n</tr>\n<tr>\n<td>非空值 <code>action:\"abc\"</code></td>\n<td>空值 <code>actions: []</code></td>\n<td>失败</td>\n<td>调用方指定了意图，目标方未声明对应能力</td>\n</tr>\n<tr>\n<td>非空值 <code>action:\"abc\"</code></td>\n<td>包含调用方 <code>actions: [\"abc\"]</code></td>\n<td>成功</td>\n<td>目标方声明的能力包含调用方意图</td>\n</tr>\n<tr>\n<td>非空值 <code>action:\"abc\"</code></td>\n<td>不包含调用方 <code>actions: [\"bcd\"]</code></td>\n<td>失败</td>\n<td>目标方未声明调用方所需能力</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"-entities-匹配规则\">③ entities 匹配规则</h5>\n<table>\n<thead>\n<tr>\n<th>调用方 <code>entities</code></th>\n<th>目标方 <code>skills.entities</code></th>\n<th>匹配结果</th>\n<th>核心说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>空（<code>entities: []</code>）</td>\n<td>非空（<code>entities: [\"a\",\"b\"]</code>）</td>\n<td>成功</td>\n<td>调用方未限定组件类别，目标方无论是否声明类别均匹配</td>\n</tr>\n<tr>\n<td>空（<code>entities: []</code>）</td>\n<td>空（<code>entities: []</code>）</td>\n<td>成功</td>\n<td>调用方未限定组件类别，目标方无论是否声明类别均匹配</td>\n</tr>\n<tr>\n<td>非空（<code>entities: [\"a\"]</code>）</td>\n<td>空（<code>entities: []</code>）</td>\n<td>失败</td>\n<td>调用方限定了组件类别，目标方未声明任何类别</td>\n</tr>\n<tr>\n<td>非空（<code>entities: [\"a\",\"b\"]</code>）</td>\n<td>包含所有调用方（<code>entities: [\"a\",\"b\",\"c\"]</code>）</td>\n<td>成功</td>\n<td>目标方声明的类别完全包含调用方需求</td>\n</tr>\n<tr>\n<td>非空（<code>entities: [\"a\",\"b\"]</code>）</td>\n<td>未包含所有调用方（<code>entities: [\"a\",\"c\"]</code>）</td>\n<td>失败</td>\n<td>目标方声明的类别缺失调用方所需类别（如调用方要 <code>browsable</code>，目标方仅声明 <code>home</code>）</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"-uri--type-匹配规则协同校验\">④ uri + type 匹配规则（协同校验）</h5>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>调用方配置</th>\n<th>匹配规则</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>场景1</td>\n<td>uri 空 + type 空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 成功；<br />2. 目标方 <code>skills.uris</code> 存在「scheme 和 type 均空」的元素 → 成功；<br />3. 其他情况 → 失败</td>\n</tr>\n<tr>\n<td>场景2</td>\n<td>uri 非空 + type 空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 失败；<br />2. 目标方 <code>skills.uris</code> 存在「uri 匹配 + type 空」的元素 → 成功；<br />3. 前两步失败且 uri 为文件路径 → 按后缀推导 MIME 类型，匹配目标方 <code>type</code> → 成功/失败</td>\n</tr>\n<tr>\n<td>场景3</td>\n<td>uri 空 + type 非空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 失败；<br />2. 目标方 <code>skills.uris</code> 存在「scheme 空 + type 匹配」的元素 → 成功；<br />3. 其他情况 → 失败</td>\n</tr>\n<tr>\n<td>场景4</td>\n<td>uri 非空 + type 非空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 失败；<br />2. 目标方 <code>skills.uris</code> 存在「uri 匹配 + type 匹配」的元素 → 成功；<br />3. 其他情况 → 失败</td>\n</tr>\n</tbody>\n</table>\n<h6 id=\"type-单独匹配规则仅调用方-type-非空时生效\">Type 单独匹配规则（仅调用方 <code>type</code> 非空时生效）</h6>\n<p>Type 匹配核心为 <strong>MIME 媒体类型匹配</strong>，遵循 HarmonyOS 官方规范，无降级匹配逻辑，规则如下：</p>\n<ol>\n<li><strong>精准匹配（最高优先级）</strong>：调用方 <code>type</code> 与目标方 <code>skills.uris</code> 中 <code>type</code> 完全一致 → 匹配成功；</li>\n<li><strong>通配符匹配</strong>：仅支持「主类型/*」格式，目标方 <code>type</code> 为此格式且调用方 <code>type</code> 属于该主类型范畴 → 成功；不支持 <code>*/子类型</code> 格式；</li>\n<li><strong>匹配失败场景</strong>：\n<ul>\n<li>目标方 <code>type</code> 为具体值但与调用方 <code>type</code> 不一致；</li>\n<li>目标方 <code>type</code> 通配符格式不规范；</li>\n<li>调用方 <code>type</code> 为复合 MIME 类型，目标方无对应配置。</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>补充说明：Type 匹配仅在「调用方传递 type」且「进入 uri+type 协同校验环节」时触发；若目标方 <code>type</code> 为空，仅当调用方 <code>type</code> 也为空时匹配成功。</p>\n</blockquote>\n<h6 id=\"uri-匹配规则\">uri 匹配规则</h6>\n<p>URI 匹配以 <code>scheme → host → port → 路径</code> 为核心层级，仅当前一级匹配通过时触发下一级校验，任一层级失败则整体 URI 匹配失败，具体规则：</p>\n<ol>\n<li><strong>scheme 层级（首验层级）</strong>：\n<ul>\n<li>目标 URI 项 <code>scheme</code> 为空 → 仅调用方 <code>uri</code> 为空时匹配成功，否则失败；</li>\n<li>目标 URI 项 <code>scheme</code> 非空 → 调用方 <code>uri</code> 的 <code>scheme</code> 需与其完全一致（大小写敏感，官方建议全小写），否则失败。</li>\n</ul>\n</li>\n<li><strong>host 层级（仅 scheme 匹配成功后触发）</strong>：\n<ul>\n<li>目标 URI 项 <code>host</code> 为空 → 直接匹配成功；</li>\n<li>目标 URI 项 <code>host</code> 非空 → 调用方 <code>uri</code> 的 <code>host</code> 需与其完全一致，否则失败。</li>\n</ul>\n</li>\n<li><strong>port 层级（仅 scheme+host 匹配成功后触发）</strong>：\n<ul>\n<li>目标 URI 项 <code>port</code> 为空 → 直接匹配成功；</li>\n<li>目标 URI 项 <code>port</code> 非空 → 调用方 <code>uri</code> 的 <code>port</code> 需与其完全一致（数字格式），否则失败。</li>\n</ul>\n</li>\n<li><strong>路径层级（仅 scheme+host+port 匹配成功后触发）</strong>：<br />\n按 <code>path → pathStartWith → pathRegex</code> 优先级校验，任一规则匹配成功则终止校验，全部失败则 URI 匹配失败：\n<ul>\n<li><strong>path 精准匹配</strong>：目标 URI 项 <code>path</code> 非空 → 调用方 <code>uri</code> 全路径与其完全一致 → 成功，否则进入下一级；</li>\n<li><strong>pathStartWith 前缀匹配</strong>：目标 URI 项 <code>pathStartWith</code> 非空 → 调用方 <code>uri</code> 路径包含该前缀 → 成功，否则进入下一级；</li>\n<li><strong>pathRegex 正则匹配</strong>：目标 URI 项 <code>pathRegex</code> 非空 → 调用方 <code>uri</code> 路径符合该正则表达式 → 成功，否则 URI 匹配失败；</li>\n<li><strong>路径字段均为空</strong>：目标 URI 项 <code>path</code>、<code>pathStartWith</code>、<code>pathRegex</code> 均为空 → 直接匹配成功。</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>补充说明：</p>\n<ol>\n<li>最左 URI 匹配：仅当目标 URI 项仅配置 <code>scheme</code>/<code>scheme+host</code>/<code>scheme+host+port</code>（路径字段均为空）时生效，调用方 <code>uri</code> 需以目标配置为前缀；</li>\n<li>文件 URI 解析：<code>file://</code> 开头的 URI，系统自动解析文件后缀推导 MIME 类型，用于补充场景2的 type 匹配；</li>\n<li>URI 格式规范：自定义 <code>scheme</code> 不可与系统内置（<code>ohos</code>/<code>http</code>/<code>https</code>/<code>file</code>）重复。</li>\n</ol>\n</blockquote>\n<h4 id=\"4匹配结果说明\">（4）匹配结果说明</h4>\n<p>根据系统中待匹配应用组件的匹配情况不同，使用隐式 Want 启动应用组件时会出现以下三种情况：</p>\n<ul>\n<li>未匹配到满足条件的应用组件：启动失败。</li>\n<li>匹配到一个满足条件的应用组件：直接启动该应用组件。</li>\n<li>匹配到多个满足条件的应用组件（UIAbility）：弹出选择框让用户选择。</li>\n</ul>\n<h2 id=\"二本节工程\">二、本节工程</h2>\n<h3 id=\"一工程创建\">（一）工程创建</h3>\n<h4 id=\"1-调用方工程wantandlinkingdemo\">1. 调用方工程：WantAndLinkingDemo</h4>\n<ul>\n<li>基础配置：HarmonyOS 5.0+、API 18+、Stage 模型；</li>\n<li>核心用途：演示显式/隐式 Want 启动；</li>\n<li>包名：<code>com.example.wantandlinkingdemo</code>。</li>\n</ul>\n<h4 id=\"2-接收方工程implicitreceiverdemo\">2. 接收方工程：ImplicitReceiverDemo</h4>\n<ul>\n<li>基础配置：HarmonyOS 5.0+、API 18+、Stage 模型；</li>\n<li>核心用途：作为跨应用显式/隐式启动的目标应用，接收并展示传递的参数；</li>\n<li>包名：<code>com.example.implicitreceiverdemo</code>。</li>\n</ul>\n<h3 id=\"二调用方工程核心目录结构\">（二）调用方工程核心目录结构</h3>\n<pre><code>WantAndLinkingDemo/                  # 项目根目录（Want实战Demo）\n├─ AppScope/                        # 应用全局配置目录（多模块应用共享）\n│  ├─ resources/                    # 应用全局资源文件（如全局样式、多语言字符串）\n│  └─ app.json5                     # 应用级配置文件（应用名称、版本号等）\n├─ entry/                           # 主模块目录（核心代码所在）\n│  ├─ src/\n│  │  ├─ main/                      # 主代码目录（应用运行的核心代码）\n│  │  │  ├─ ets/                    # ArkTS代码目录（逻辑实现核心）\n│  │  │  │  ├─ entryability/        # 主Ability目录（应用入口）\n│  │  │  │  │  └─ EntryAbility.ets  # 应用入口Ability（处理启动初始化）\n│  │  │  │  └─ pages/               # 主Ability对应的页面目录\n│  │  │  │     └─ Index.ets          # 核心功能页（整合显式/隐式Want启动所有案例）\n│  │  │  ├─ resources/              # 模块级资源目录（页面布局、图片、局部样式）\n│  │  │  └─ module.json5            # 模块配置文件（核心！配置skills、exported等）\n│  ├─ build-profile.json5           # 模块构建配置文件（编译、打包参数）\n│  ├─ hvigorfile.ts                 # 模块构建脚本（hvigor构建任务配置）\n│  ├─ obfuscation-rules.txt         # 代码混淆规则文件（发布时加密代码，可选）\n│  └─ oh-package.json5              # 模块依赖配置文件（第三方库、工具依赖）\n</code></pre>\n<h3 id=\"三隐式显示拉起应用传参示例\">（三）隐式/显示拉起应用传参示例</h3>\n<h4 id=\"调用方wantandlinkingdemo-indexets\">调用方：WantAndLinkingDemo Index.ets</h4>\n<p>构造Want数据，演示显式/隐式不同模式拉起应用，通过不同匹配规则。</p>\n<pre><code class=\"language-javascript\">import { BusinessError } from '@ohos.base';\nimport { common, Want, wantConstant } from '@kit.AbilityKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\nimport { promptAction } from '@kit.ArkUI';\n\nconst DOMAIN = 0xFF00;\nconst TAG = 'WantAndLinkingDemo';\n\n@Entry\n@Component\nstruct Index {\n  // 获取UIAbility上下文\n  private context = this.getUIContext().getHostContext() as common.UIAbilityContext;\n\n  build() {\n    Column({ space: 15 }) {\n      // 页面标题\n      Text('Want 显式/隐式启动实战（匹配规则修正版）')\n        .fontSize(30)\n        .fontWeight(FontWeight.Bold)\n        .margin({ bottom: 30 })\n\n      // 1. 显式Want（精准匹配，无规则问题）\n      Button('1. 显式Want跨应用拉起传参')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.crossAppExplicitStart();\n        })\n\n      // 2. 隐式Want - linkFeature（最高优先级，需精准匹配）\n      Button('2. 隐式Want-linkFeature匹配（最高优先级）')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartShare();\n        })\n\n      // 3. 隐式Want - action单独匹配（核心：仅传action，无其他干扰字段）\n      Button('3. 隐式Want-action单独匹配')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartActionMatch();\n        })\n\n      // 4. 隐式Want - entities单独匹配\n      Button('4. 隐式Want-entities单独匹配')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartEntitiesMatch();\n        })\n\n      // 5. 隐式Want - uri+type协同匹配（核心：仅传uri+type，配通用action）\n      Button('5. 隐式Want-uri+type协同匹配')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartUriTypeMatch();\n        })\n    }\n    .width('100%')\n    .height('100%')\n    .justifyContent(FlexAlign.Center)\n    .backgroundColor('#f5f5f5')\n  }\n\n  /**\n   * 场景1：显式Want\n   * 规则：指定bundleName+abilityName，无需匹配skills，仅需接收方设置 exported=true\n   */\n  private async crossAppExplicitStart() {\n    try {\n      const want: Want = {\n        bundleName: \"com.example.implicitreceiverdemo\", // 接收方包名（必须与实际一致）\n        abilityName: \"EntryAbility\", // 接收方组件名（必须与实际一致）\n        parameters: {\n          \"shareContent\": \"显式Want测试：跨应用精准传递内容\",\n          \"linkFeature\": \"Explicit\"\n        }\n      };\n\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"显式Want跨应用拉起成功\");\n    } catch (err) {\n      const businessErr = err as BusinessError;\n      promptAction.showToast({\n        message: `启动失败：${businessErr.message}`,\n        duration: 3000\n      });\n    }\n  }\n\n  /**\n   * 场景2：隐式Want - linkFeature（最高优先级）\n   * 规则：uri和type均为空时，仅校验linkFeature精准匹配\n   * 规则：uri或type不为空时，需同时满足linkFeature精准匹配 + uri的scheme匹配 + type精准匹配\n   */\n  private async implicitStartShare() {\n    const want: Want = {\n      uri: \"data://com.example.wantandlinkingdemo/share/text\", // scheme/host需匹配\n      type: \"text/plain\", // 必须精准匹配\n      parameters: {\n        shareContent: \"隐式Want测试：linkFeature匹配成功！\",\n        linkFeature: \"Share\" // 最高优先级，接收方必须精准配置\n      },\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(linkFeature)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `linkFeature匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到支持分享的应用',\n        duration: 3000\n      });\n    }\n  }\n\n  /**\n   * 场景3：隐式Want - action单独匹配\n   * 规则：调用方action需匹配接收方skills中的action配置\n   */\n  private async implicitStartActionMatch() {\n    const want: Want = {\n      action: 'ohos.want.action.viewData',\n      parameters: {\n        \"shareContent\": \"隐式Want测试：action匹配成功！\",\n      }\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(action)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `action匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到支持查看数据的应用',\n        duration: 3000\n      });\n    }\n  }\n  \n  /**\n   * 场景4：隐式Want - entities匹配\n   * entities匹配规则：调用方传递的所有entities值，需被目标方skills.entities完全包含才匹配成功（本示例为\"abc\"）\n   * 系统标准值参考：entity.system.browsable（浏览器类别，处理网页链接）、entity.system.home（应用主入口组件）\n   */\n  private async implicitStartEntitiesMatch() {\n    const want: Want = {\n      action: 'ohos.want.action.viewData', // 查看数据\n      entities: [\"abc\"],\n      parameters: {\n        \"shareContent\": \"隐式Want测试：entities匹配成功！\",\n      }\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(entities)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `entities匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到浏览器类应用',\n        duration: 3000\n      });\n    }\n  }\n\n  /**\n   * 场景5：隐式Want - uri+type协同匹配\n   * 核心：需同时满足uri层级匹配（scheme→host→port→路径） + type精准匹配\n   */\n  private async implicitStartUriTypeMatch() {\n    const want: Want = {\n      action: 'ohos.want.action.viewData',\n      uri: \"data://com.implicitreceiverdemo:8080/detail/page123\",\n      type: \"text/plain\",\n      flags: wantConstant.Flags.FLAG_START_WITHOUT_TIPS // 取消失败弹窗提示\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(uri+type)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `uri+type匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到符合uri+type规则的应用',\n        duration: 3000\n      });\n    }\n  }\n}\n</code></pre>\n<h5 id=\"2接收方implicitreceiverdemo\">（2）接收方：ImplicitReceiverDemo</h5>\n<p>跨应用接收调用方Want传递的参数（拉起组件内Ability接收参数同理，本节不做示例演示）</p>\n<pre><code class=\"language-javascript\">import { AbilityConstant, UIAbility, Want } from '@kit.AbilityKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\nimport { ConfigurationConstant } from '@kit.AbilityKit';\nimport { window } from '@kit.ArkUI';\n\nconst DOMAIN = 0x0000;\nconst TAG = 'ImplicitReceiverDemo';\n\nexport default class EntryAbility extends UIAbility {\n  onCreate(want: Want, launchParam: AbilityConstant.LaunchParam): void {\n    hilog.info(DOMAIN, TAG, '%{public}s', 'ImplicitReceiverDemo onCreate 触发');\n    try {\n      // 解析 Want 中的参数（显式传递的 data + 隐式传递的 shareContent）\n      const parameters = want.parameters as Record&lt;string, Object&gt;;\n      // 存储参数到 AppStorage，供 UI 页面展示（默认值避免空显示）\n      AppStorage.setOrCreate(\"shareContent\", parameters[\"shareContent\"] || '未接收分享数据');\n\n      // 设置应用颜色模式（可选，保持系统默认）\n      this.context.getApplicationContext().setColorMode(ConfigurationConstant.ColorMode.COLOR_MODE_NOT_SET);\n    } catch (err) {\n      hilog.error(DOMAIN, TAG, 'Failed to set colorMode. Cause: %{public}s', JSON.stringify(err));\n    }\n  }\n\n  /**\n   * 已启动时接收新的 Want 参数（如隐式启动多次触发）\n   */\n  onNewWant(want: Want, launchParam: AbilityConstant.LaunchParam): void {\n    hilog.info(DOMAIN, TAG, '%{public}s', 'ImplicitReceiverDemo onNewWant 触发');\n    const parameters = want.parameters as Record&lt;string, Object&gt;;\n    // 更新参数（实时同步到 UI 页面）\n    AppStorage.setOrCreate(\"shareContent\", parameters[\"shareContent\"] || '未接收分享数据');\n    // 打印接收的参数\n    console.log(`ImplicitReceiverDemo 接收参数：${JSON.stringify(want.parameters)}`);\n  }\n\n  /**\n   * 加载 UI 页面\n   */\n  onWindowStageCreate(windowStage:  window.WindowStage): void {\n    windowStage.loadContent('pages/Index', (err) =&gt; {\n      if (err.code) {\n        hilog.error(DOMAIN, TAG, 'Failed to load the content. Cause: %{public}s', JSON.stringify(err));\n        return;\n      }\n      hilog.info(DOMAIN, TAG, 'Succeeded in loading the content: Index');\n    });\n  }\n}\n</code></pre>\n<h6 id=\"-接收方indexets展示跨应用接收的参数\">② 接收方：Index.ets（展示跨应用接收的参数）</h6>\n<pre><code class=\"language-javascript\">@Entry\n@Component\nstruct Index {\n  @StorageProp('shareContent') shareContent: string = '隐式/显式分享数据未接收';\n\n  build() {\n    Column({ space: 20 }) {\n      Text('ImplicitReceiverDemo（参数接收）')\n        .fontSize(25)\n        .fontWeight(FontWeight.Bold)\n        .margin({ bottom: 10 })\n\n      Text(`接收的内容：${this.shareContent}`)\n        .fontColor(Color.Red)\n        .fontSize(18)\n        .textWrap(true)\n        .padding(10)\n    }.justifyContent(FlexAlign.Center)\n    .height('100%')\n    .width('100%')\n    .padding(20)\n  }\n}\n</code></pre>\n<h6 id=\"-接收方modulejson5配置\">③ 接收方：module.json5配置</h6>\n<pre><code class=\"language-json\">{\n  \"module\": {\n    \"name\": \"entry\",\n    \"type\": \"entry\",\n    \"description\": \"$string:module_desc\",\n    \"mainElement\": \"EntryAbility\",\n    \"deviceTypes\": [\n      \"phone\"\n    ],\n    \"deliveryWithInstall\": true,\n    \"installationFree\": false,\n    \"pages\": \"$profile:main_pages\",\n    \"abilities\": [\n      {\n        \"name\": \"EntryAbility\",\n        \"srcEntry\": \"./ets/entryability/EntryAbility.ets\",\n        \"description\": \"$string:EntryAbility_desc\",\n        \"icon\": \"$media:layered_image\",\n        \"label\": \"$string:EntryAbility_label\",\n        \"startWindowIcon\": \"$media:startIcon\",\n        \"startWindowBackground\": \"$color:start_window_background\",\n        \"exported\": true, // 必须开启：允许外部应用调用（显式/隐式均需）\n        \"skills\": [\n          {\n            // 基础技能：桌面应用（默认配置）\n            \"entities\": [\"entity.system.home\"],\n            \"actions\": [\"ohos.want.action.home\"]\n          },\n          // 场景2：linkFeature匹配规则\n          {\n            \"uris\": [\n              {\n                \"scheme\": \"data\",\n                \"host\": \"com.example.wantandlinkingdemo\",\n                \"type\": \"text/plain\",\n                \"linkFeature\": \"Share\"\n              }\n            ]\n          },\n          // 场景3：action单独匹配规则\n          {\n            \"actions\": [\"ohos.want.action.viewData\"]\n          },\n          // 场景4：entities单独匹配规则\n          {\n            \"actions\": [\"ohos.want.action.viewData\"],\n            \"entities\": [\"abc\"]\n          },\n          // 场景5：uri+type协同匹配规则\n          {\n            \"actions\": [\"ohos.want.action.viewData\"],\n            \"uris\": [\n              {\n                \"scheme\": \"data\",                   // 协议必须完全一致\n                \"host\": \"com.implicitreceiverdemo\", // 域名需完整匹配\n                \"port\": \"8080\",                     // 端口不可省略\n                \"path\": \"detail/page123\",            // 路径需完全一致或使用通配符\n                \"type\": \"text/plain\"                // MIME类型需严格匹配\n              }\n            ]\n          }\n        ]\n      }\n    ],\n    \"extensionAbilities\": [\n      {\n        \"name\": \"EntryBackupAbility\",\n        \"srcEntry\": \"./ets/entrybackupability/EntryBackupAbility.ets\",\n        \"type\": \"backup\",\n        \"exported\": false,\n        \"metadata\": [\n          {\n            \"name\": \"ohos.extension.backup\",\n            \"resource\": \"$profile:backup_config\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>\n<h4 id=\"运行结果\">运行结果</h4>\n<p><img alt=\"Want显式隐式拉起应用\" class=\"lazyload\" /></p>\n<p><img alt=\"Want显式/隐式拉起应用\" class=\"lazyload\" /></p>\n<h2 id=\"四开发核心规范与避坑指南\">四、开发核心规范与避坑指南</h2>\n<h3 id=\"1-核心约束\">1. 核心约束</h3>\n<ul>\n<li>所有对外提供调用的 Ability（显式/隐式），必须在 <code>module.json5</code> 中配置 <code>exported: true</code>，否则无法被外部调用；</li>\n<li>自定义 scheme 不可与系统内置 scheme（如 <code>ohos</code>、<code>http</code>、<code>https</code>、<code>file</code>）重复，建议采用“应用标识+功能”命名（如 <code>harmonydemo</code>）；</li>\n<li>隐式 Want 若使用 <code>linkFeature</code> 匹配，<code>actions</code> 字段可忽略；使用 <code>action/entities/uri+type</code> 匹配时，对应字段不可为空。</li>\n</ul>\n<h3 id=\"2-避坑指南\">2. 避坑指南</h3>\n<table>\n<thead>\n<tr>\n<th>问题现象</th>\n<th>排查/解决方法</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>隐式启动匹配失败</td>\n<td>检查 <code>linkFeature</code>、<code>action</code>、<code>entities</code>、<code>uri</code>、<code>type</code> 是否与接收方配置一致，尤其是 <code>scheme</code>、<code>host</code> 大小写（建议全小写）；</td>\n</tr>\n<tr>\n<td>参数传递失败</td>\n<td>确保传递的参数为基础数据类型（避免传递复杂对象），接收方通过 <code>want.parameters</code> 解析时需做类型断言；</td>\n</tr>\n<tr>\n<td>跨应用显式启动失败</td>\n<td>确认目标应用已安装、<code>bundleName</code> 和 <code>abilityName</code> 配置正确，且目标 Ability 已设置 <code>exported: true</code>；</td>\n</tr>\n<tr>\n<td>uri 匹配失败</td>\n<td>按 <code>scheme→host→port→路径</code> 层级逐一校验，路径匹配优先精准匹配，前缀/正则匹配需确保规则正确。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"五内容总结\">五、内容总结</h2>\n<ol>\n<li>核心载体：Want 是组件间通信的核心载体，显式 Want 用于跨应用精准启动，隐式 Want 用于跨应用通用功能调用；</li>\n<li>隐式匹配规则：按 <code>linkFeature→action→entities→uri+type</code> 优先级校验，前序字段匹配失败则整体失败，所有参与匹配的字段均为精准匹配（uri路径除外）；</li>\n<li>配置关键：对外调用的 Ability 需设 <code>exported: true</code>，隐式启动需保证调用方 Want 字段与接收方 <code>skills</code> 配置完全一致；</li>\n<li>实践原则：按场景选择匹配规则，重视异常处理和用户体验，遵循 API 12+ 规范（优先使用应用链接替代显式 Want）。</li>\n</ol>\n<h2 id=\"六代码仓库\">六、代码仓库</h2>\n<ul>\n<li>调用方工程：WantAndLinkingDemo</li>\n<li>接收方工程：ImplicitReceiverDemo</li>\n<li>仓库地址：<a href=\"https://gitee.com/HarmonyOS-UI-Basics/harmony-os-ui-basics.git\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/HarmonyOS-UI-Basics/harmony-os-ui-basics.git</a></li>\n</ul>\n<h2 id=\"七下节预告\">七、下节预告</h2>\n<p>下一节我们将学习 <strong>Deep Linking 与 App Linking 应用链接</strong> 的完整配置与调用，重点包括：</p>\n<ol>\n<li>掌握 Deep Linking 自定义 scheme 配置、<code>openLink</code> 调用及 <code>canOpenLink</code> 校验；</li>\n<li>掌握 App Linking HTTPS 域名配置、域名校验、参数解析及未安装应用的降级处理；</li>\n<li>明晰 Deep Linking 与 App Linking 的安全性、适用场景核心差异，能按需选型；</li>\n<li>掌握应用链接与 Want 结合的最佳实践，实现跨应用通信的解耦与高安全性。</li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/san-xiu\">鸿蒙-散修</a>&nbsp;\n阅读(<span id=\"post_view_count\">13</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "认识区块链和比特币（一）：余额与小票",
      "link": "https://www.cnblogs.com/ofnoname/p/19592966",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ofnoname/p/19592966\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:07\">\n    <span>认识区块链和比特币（一）：余额与小票</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这篇文章不谈价格涨跌和投资讨论。只做一件事：把比特币的基本原理讲清楚。读完你应该能看懂区块浏览器里一笔交易的“输入/输出”，能理解为什么在没有银行的情况下，比特币也能维护余额和支付。</p>\n<p>需要的前置知识不多，你只需要了解三件基础概念即可：<strong>公钥/私钥与数字签名（私钥像“签名章”，用来证明你有权花钱）</strong>、<strong>哈希（像数据指纹）</strong>、以及<strong>分布式系统的入门概念</strong>。这不是密码学课程，所以我们不会推导数学证明，只用直觉和例子把机制讲明白。</p>\n<h2 id=\"比特币是什么\">比特币是什么？</h2>\n<p>在完整理解<strong>比特币是一个去中心化的账本/交易数据库/支付系统</strong>之前，你可以先把比特币当成：<strong>一份公开的、全网同步的“历史记录”</strong>，上面只写两类信息——“哪些钱还没被花掉”和“这些钱未来需要满足什么条件才允许被花”。任何人都可以保存一份副本（运行节点），并用同一套公开规则检查：新来的记录有没有作弊、有没有双花、有没有伪造签名。它不像银行系统那样由某个机构维护“账户余额表”，更像一个班级共同维护的共享记账本：没有班长能单方面改分数，每个人都可以拿规则对照检查。不过这个“共享账本为什么不会乱、为什么最后大家能收敛到同一份版本、为什么有人愿意付出成本来维护它”，要到后面讲完网络规则与挖矿机制后，你才会彻底吃透——而今天我们先从最底层的“钱的形态”开始：UTXO。</p>\n<h2 id=\"比特币与区块链的关系\">比特币与区块链的关系</h2>\n<p><strong>区块链（blockchain）</strong>：从字面上看就是“区块组成的链”。它是一种数据组织方式：把一批记录打包成“区块”，再用哈希把新区块和前一个区块链接起来，让历史记录更难被悄悄篡改。你可以把它理解为一种“按时间顺序装订成册、每页都盖了前一页指纹”的账本结构。</p>\n<p>而 <strong>比特币（Bitcoin）</strong>：是一套运行在互联网上的系统（协议 + 软件 + 节点网络 + 规则），它<strong>用区块链来保存交易历史</strong>，并用一套公开规则让全网在“哪些交易有效、哪些区块算数”上达成一致。换句话说：<strong>区块链是比特币使用的一种账本结构，但比特币不仅仅是区块链</strong>——它还有交易格式、验证规则、网络传播、挖矿激励等一整套机制。在比特币系统里，词语 <strong>比特币（bitcoin / BTC）</strong>：这个词也是这个系统里的“记账单位/资产”。</p>\n<p>比特币是区块链思想最早的大规模成功落地之一，因此影响力最大、生态最成熟；但区块链后来被许多系统采用并拓展了用途（不止做转账，还尝试做更通用的“可验证记录”），如<strong>以太坊（Ethereum）</strong>。同时也出现了大量基于比特币技术理念衍生出来的其他币种与系统，如<strong>莱特币（Litecoin）</strong>、<strong>门罗币（Monero）</strong>。</p>\n<h2 id=\"utxo比特币里的钱\">UTXO：比特币里的“钱”</h2>\n<p>在比特币里，“你有多少钱”不是写在某张<strong>账户余额表</strong>上，而是散落在账本历史里的一堆“小票”。这些小票的正式名字叫：</p>\n<p><strong>UTXO（Unspent Transaction Output，未花费交易输出）</strong>：一笔交易产生的每个“输出（output）”，只要还没有被后续交易花掉，就处于“未花费”状态，它就是一个 UTXO。</p>\n<p>所以钱包里显示的“余额”，本质上是：</p>\n<blockquote>\n<p><strong>你所控制的私钥，能够解锁的一组 UTXO 的总和。</strong></p>\n</blockquote>\n<p>这里有一个非常关键但容易忽略的点：UTXO 不是“记在你名下的余额”，而是“带着使用条件的价值片段”。这份“使用条件”通常会指向某个公钥哈希（也就是我们日常看到的“地址”），意思是：<strong>未来想花这笔钱的人，必须拿出能满足条件的证明（通常就是签名）</strong>。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212111529650-1331403071.png\" /></p>\n<h3 id=\"utxo-里到底包含了什么\">UTXO 里到底包含了什么</h3>\n<p>把 UTXO 当成“小票”，这张小票上至少写了两样最重要的东西：</p>\n<ol>\n<li><strong>金额（value）</strong>：比如 0.5 BTC</li>\n<li><strong>锁定条件（locking condition）</strong>：例如“能提供某个公钥对应的有效签名的人才能花”（在这个场景下，可以简单类比普通支付系统，理解为“钱属于谁”）。</li>\n</ol>\n<h3 id=\"utxo-从哪里来交易输出如何变成可花的小票\">UTXO 从哪里来：交易输出如何变成“可花的小票”</h3>\n<p>UTXO 的来源非常朴素：<strong>每一笔交易的每一个输出，都有可能变成未来的 UTXO</strong>。</p>\n<p>举个最简单的“收款”场景：</p>\n<ul>\n<li>\n<p>小明拥有自己的公钥和私钥，他把自己的公钥（即收款地址）给小红</p>\n</li>\n<li>\n<p>小红生成一笔交易，在交易里写一个输出：</p>\n<ul>\n<li>金额：0.5 BTC</li>\n<li>锁定条件：只能由“小明的公钥”对应的私钥花掉</li>\n</ul>\n</li>\n<li>\n<p>这笔交易一旦被网络接受并最终写进区块链历史里，这个输出就成了一个 UTXO</p>\n</li>\n<li>\n<p>小明的钱包之所以“看到余额增加”，是因为它扫描网络历史记录时发现：“有一张新的小票锁给我，而且还没被花掉”。钱包并不是从“某个中心服务器”读取余额，而是在本地（或通过服务）根据历史记录推导“哪些 UTXO 属于我”。之后，小明也可以花掉这个 UTXO（也只有他可以花，因为只有他有收款公钥对应的私钥）。</p>\n</li>\n</ul>\n<h2 id=\"utxo-的花费和找零\">UTXO 的花费和找零</h2>\n<p>你不能“从一个 UTXO 里只花一部分”。花它的方式只有一种：整张用掉。相比微信支付，这其实更类似现金支付：你用一张 100 去买 30 的东西，收银台不会“把纸币剪掉 30”，而是收走 100，再找你 70。</p>\n<p>比特币交易也是同样的逻辑：</p>\n<ul>\n<li><strong>输入（inputs）</strong>：你这次准备“用掉”的若干张旧小票（旧 UTXO）</li>\n<li><strong>输出（outputs）</strong>：这次交易“新生成”的若干张新小票（新的 UTXO）</li>\n</ul>\n<p>一个典型的简单支付几乎总会出现两个输出：</p>\n<ol>\n<li><strong>给收款人</strong>：比如给小红 0.7 BTC（锁给小红的条件）</li>\n<li><strong>找零给自己</strong>：比如找回 0.399 BTC（锁给小明自己的另一个地址）</li>\n</ol>\n<p>绝大多数时候，一笔支付总会有找零。你在区块浏览器里看到“一笔交易输出 2 个”时，十有八九就是“付款 + 找零”。</p>\n<p><img alt=\"典型的 UTXO 交易链条\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212104533493-1727523767.png\" /></p>\n<h3 id=\"手续费\">手续费</h3>\n<p>一笔支付合法的基本逻辑是：<strong>输入金额总和 &gt;= 输出金额总和</strong>，即你不能多花，当然你可以少花（不过没人会主动把自己的钱丢了）。</p>\n<p>更多的时候，输入输出的金额差被作为<strong>手续费</strong>。</p>\n<blockquote>\n<p><strong>手续费 = 输入金额总和 − 输出金额总和</strong></p>\n</blockquote>\n<p>它不是写在某个“手续费字段”里，而是由差额自然形成的。</p>\n<ul>\n<li>\n<p>小明手里有两张 UTXO：0.6 BTC 和 0.5 BTC（共 1.1 BTC）</p>\n</li>\n<li>\n<p>小明要付给小红 0.7 BTC</p>\n</li>\n<li>\n<p>小明创建交易：</p>\n<ul>\n<li>输入：0.6 + 0.5</li>\n<li>输出：0.7 给小红 + 0.399 给自己</li>\n</ul>\n</li>\n<li>\n<p>输入总额 1.1，输出总额 1.099，差额 0.001 BTC</p>\n</li>\n<li>\n<p>这 0.001 BTC 就是手续费。<strong>手续费本质上就是“你少找回来的那点零钱”</strong>。</p>\n</li>\n</ul>\n<p>为什么不全部找零给自己，而是要留一些手续费呢？这类似于现实消费的交税。留出一些钱作为交易费可以让矿工更愿意打包这次交易，有利于维护整个比特币网络的运行。</p>\n<h3 id=\"防双花节点维护-utxo-set\">防“双花”：节点维护 UTXO Set</h3>\n<p>没有银行，谁来防止同一笔钱被花两次？</p>\n<p>每个全节点都在检查各个想被确认的交易的合法性，<strong>都在维护一份“当前（所有人）仍然未花费的小票清单”——UTXO Set。</strong></p>\n<p>当节点收到一笔新交易时，它做的核心检查之一就是：</p>\n<ol>\n<li>这笔交易引用的每一个输入，对应的那张旧小票（旧 UTXO）真的存在吗？</li>\n<li>它还在 UTXO Set 里吗？（如果不在，说明早就被花过了，或者压根不存在）</li>\n<li>你是否提供了满足锁定条件的证明（签名等）？</li>\n<li>金额是否正确？（不能多花）</li>\n</ol>\n<p>一旦这笔交易被接受并最终进入区块，节点就会更新自己的 UTXO Set：</p>\n<ul>\n<li>把被花掉的旧 UTXO 从集合里移除</li>\n<li>把交易新产生的 outputs 加进集合里</li>\n</ul>\n<p>这里没有任何“中心裁判”。每个节点都在做同一套确定性的检查，所以“双花”不是靠“相信某个机构”解决的，而是靠“所有人按规则验算”解决的。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212105542420-446956606.png\" /></p>\n<p>一个 UTXO 只能花费一次，因此有了交易 2 后，交易 3 就是非法的，不能被确认了（除非你直接丢弃交易 2，切换到交易 3）。</p>\n<h2 id=\"utxo-vs-余额账本\">UTXO vs 余额账本</h2>\n<p>通常理解的支付系统（包括银行、支付宝/微信）更像“账户模型”：维护一张表，写着“张三余额 100”。转账时就是把一个账户减、另一个账户加。</p>\n<p>比特币不这么做。它更像“票据模型”：账本不写“你有多少钱”，而是写“哪些票据还没用掉，以及每张票据的使用条件”。所谓“余额”，是你把“自己能解锁的所有未花费票据（UTXO）”加总出来的结果。</p>\n<p>这两种模型并没有绝对优劣，但对理解比特币来说很关键：</p>\n<ul>\n<li>\n<p>在账户模型里，“余额”是系统的显式字段；</p>\n</li>\n<li>\n<p>在 UTXO 模型里，“余额”是从历史记录推导出来的（因此钱包需要扫描/同步/索引）。</p>\n</li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212110631731-1587525664.png\" /></p>\n<h3 id=\"影响一utxo-越碎花钱越重\">影响一：UTXO 越碎，花钱越“重”</h3>\n<p>UTXO 模型有个很现实的副作用：如果你的 UTXO 很碎，付款时可能需要拼很多张“小票”。而每多用一个输入，就要在交易里多写一段“我引用的是哪张旧票据 + 我如何解锁它”的数据，交易体积通常会变大。体积变大，矿工打包的成本也更高，于是你往往需要付更高的手续费，交易才更容易被尽快确认。</p>\n<p>所以同样是“转 0.7 BTC”，有时你只需要 1 个输入（恰好有一张 0.7 的票据），有时却需要 10 个输入（十张 0.07 的碎票据）。<br />\n这就是为什么很多钱包会在合适的时候做“合并 UTXO”（把多张碎票据整合成更少的、面额更合适的票据），从体验上看就像“整理零钱”。</p>\n<h3 id=\"影响二隐私线索\">影响二：隐私线索</h3>\n<p>绝大多数交易都会存在找零。一笔“付款”常常会有两个输出——给对方 + 找零给自己。现实里这是常识，但在链上它会变成线索：旁观者可以尝试猜测哪个输出是找零，从而把多笔交易串成“同一个人/同一钱包”的行为轨迹。</p>\n<p>早期钱包之所以倾向于把找零打到一个“新地址”，部分原因就是为了减少“把所有行为都绑在同一个地址上”的明显痕迹——但注意，这并不等于真正匿名：交易本身是公开可查的，地址之间仍可能被启发式规则关联。因此，比特币的\"匿名与安全\"并不能让人高枕无忧。他更像“假名制”而不是“匿名制”：你不写姓名，但你写了可被分析的行为轨迹。其中的攻防逻辑门道很深，这里不讲。</p>\n<h2 id=\"查看一个典型的-utxo\">查看一个典型的 UTXO</h2>\n<p>有很多网站都可以查看比特币主链的信息。以 <a href=\"https://mempool.space\" rel=\"noopener nofollow\" target=\"_blank\">mempool.space</a> 为例子：</p>\n<p>我们随意选择一个已经确认的区块。向下滚动，就可以看到本区块确认的所有交易，每个交易引用一个或多个 UTXO，并生成新的 UTXO：</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260211214405360-554665115.png\" /></p>\n<p>上图中我随手截取了两笔交易（上、下各一笔）。</p>\n<p>先看第一笔交易（交易哈希以 <code>fb2628a7…</code> 开头）。它只有 <strong>1 个输入</strong>：来自地址 <code>bc1qvtdvv…zdd70msz</code>，金额 0.03382740 BTC。这表示：此前账本里存在一张面额 0.03382740 BTC、锁给这个地址的“旧小票”，现在被这笔交易整张用掉了。然后它生成了 2 个输出：一个输出转到地址 <code>3NCU3KvX…W5tm3</code>，金额 0.00089565 BTC；另一个输出又回到了 <code>bc1qvtdvv…zdd70msz</code>，金额 0.03229910 BTC。这就是典型的“<strong>付款 + 找零</strong>”：前者是付给对方的金额，后者是找回给自己的零钱。页面右下角蓝色框显示这笔交易的 输出总额为 0.03319475 BTC（也就是两笔输出相加）。</p>\n<p>这笔交易的手续费：输入是 0.03382740，输出是 0.03319475，相减得到 0.00063265 BTC，换算成 satoshi 就是 63,265 sats（BTC 是比特币，而 Satoshi 是比特币系统的最小单位，1 BTC 等于 1亿 Satoshi）。交易里手续费往往不是一个单独的字段，而是由“少找回来的零钱”自然形成的。</p>\n<p>再看第二笔交易（交易哈希以 <code>d9195032…</code> 开头）。它有 2 个输入，而且两张旧小票都来自同一个地址 <code>bc1qvtdvv…zdd70msz</code>，金额分别是 0.00003777 BTC 和 0.00642833 BTC。两张加起来输入总额是 0.00646610 BTC。它同样产生了 2 个输出：一个输出到 <code>bc1qzgqf…njp90rhl</code>，金额 0.00004840 BTC（这是付款）；另一个输出回 <code>bc1qvtdvv…zdd70msz</code>，金额 0.00578845 BTC（这显然是找零）。输出总额 0.00583685 BTC（页面右下蓝框），因此手续费就是 0.00646610 − 0.00583685 = 0.00062925 BTC = 62,925 sats。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ofnoname\">Ofnoname</a>&nbsp;\n阅读(<span id=\"post_view_count\">152</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}