{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "[拆解LangChain执行引擎]持久化状态的提取",
      "link": "https://www.cnblogs.com/jaydenai/p/19623976/read-state",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19623976/read-state\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 07:58\">\n    <span>[拆解LangChain执行引擎]持久化状态的提取</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        前面以`写入`的角度介绍了BaseCheckpointSaver的`put/aput`和`put_writes/aput_writes`方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面以<code>写入</code>的角度介绍了BaseCheckpointSaver的<code>put/aput</code>和<code>put_writes/aput_writes</code>方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。</p>\n<h2 id=\"1-读取checkpoint和pinding-write\">1. 读取Checkpoint和Pinding Write</h2>\n<p>如下这个<code>CheckpointTuple</code>用来表示Checkpoint和Pending Write的结合体。除了这两个核心成员，它还包括当前的执行配置（config和parent_config）和元数据。具体的Pending Write由Task ID、Channel名称和写入数组组成的三元组PendingWrite表示。</p>\n<pre><code class=\"language-python\">class CheckpointTuple(NamedTuple):\n    config: RunnableConfig\n    checkpoint: Checkpoint\n    metadata: CheckpointMetadata\n    parent_config: RunnableConfig | None = None\n    pending_writes: list[PendingWrite] | None = None\nPendingWrite = tuple[str, str, Any]\n</code></pre>\n<p>BaseCheckpointSaver提供了用于读取CheckpointTuple的<code>get_tuple/aget_tuple</code>方法。作为参数的RunnableConfig对象需要提供Thread ID（必需）和Checkpoint 命名空间（可选）。如果没有提供Checkpoint ID，方法会返回最终的状态，如果尚未完成，得到的CheckpointTuple元组可能包含Pending Write。如果提供了Checkpoint ID, 只有在此ID对应最新的Checkpoint且后一Superstep尚未完成，返回的CheckpointTuple元组才有可能包含Pending Write。对于实现在BaseCheckpointSaver中的另一组方法<code>get/aget</code>，会在内部调用<code>get_tuple/aget_tuple</code>方法，并返回CheckpointTuple元组封装的Checkpoint对象。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):    \n    def get(self, config: RunnableConfig) -&gt; Checkpoint | None\n    async def aget(self, config: RunnableConfig) -&gt; Checkpoint | None\n\n    def get_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n    async def aget_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n\n    def list(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[CheckpointTuple]:\n    async def alist(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[CheckpointTuple]\n</code></pre>\n<p>对于InMemorySaver来说，它的get_tuple/aget_tuple方法会从RunnableConfig配置中提取Thread ID和Checkpoint命名空间，如果指定了Checkpoint ID，它们会利用这三个值从storage和blobs字典中提取相应数据组成返回的CheckpointTuple对象。如果没有指定Checkpoint ID，就选择最近的那一个Checkpoint的ID。</p>\n<p>BaseCheckpointSaver的alist方法会列出并检索与指定条件匹配的所有CheckpointTuple，这些元组构成了一段 “历史” 。该方法主要用于会话管理、审计历史轨迹以及状态回溯，它具有如下的参数：</p>\n<ul>\n<li>config：如果RunnableConfig如果提供了Thread ID，该方法将仅返回该特定线程下的Checkpoint。如果不提供，在某些实现中会列出所有线程的最新Checkpoint（取决于具体的实现逻辑）。</li>\n<li>filter：提供基于元数据的过滤功能，例如 {\"status\": \"completed”} ，这在需要筛选特定业务状态的Checkpoint时非常有用。</li>\n<li>before：以RunnableConfig对象的形式提供Checkpoint ID，返回在此 之前创建的记录。这对于实现 “时间旅行” 功能至关重要，允许你查看图执行历史中的旧版本。</li>\n<li>limit：用于限制返回数据的数量。</li>\n</ul>\n<p>我们通过如下的实例演示来进一步了解持久化。我们构建了一个由foo、bar1和bar2这三个Node组成的Pregel，启动的时候利用输入针对通道foo的写入驱动执行节点foo，后者完成后写入通道bar驱动节点bar1和bar2并行执行。三个Node的处理函数都是handle，它会将传入的Node名称写入一个BinaryOperatorAggregate类型Channel（nodes），由此确定成功执行的Node。如果调用handle函数将interrupt参数指定为True，它会通过抛出一个GraphInterrupt异常模拟一个中断。在我们的演示实例中，节点foo和bar2会执行成功，中断会发生在节点bar1上。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue, BinaryOperatorAggregate\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.errors import GraphInterrupt\nimport operator, json\n\ndef handle(node_name: str, interrupt: bool = False) -&gt; list[str]:\n    if interrupt:\n        raise GraphInterrupt(\"manual interrupt\")\n    return [node_name]\n\nfoo = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: handle(\"foo\"))\n    .write_to(nodes=lambda x: x, bar=lambda _: \"triggered by foo\")\n)\n\nbar1 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar1\", interrupt=True))\n    .write_to(\"nodes\")\n)\n\nbar2 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar2\", interrupt=False))\n    .write_to(\"nodes\")\n)\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar1\": bar1, \"bar2\": bar2},\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n        \"nodes\": BinaryOperatorAggregate(list, operator.add),\n    },\n    checkpointer=InMemorySaver(),\n    input_channels=[\"foo\"],\n    output_channels=[\"nodes\"],\n)\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke({\"foo\": \"triggered by user\"}, config=config)\nassert result[\"nodes\"] == [\"foo\", \"bar2\"]\n\n(config, checkpoint, metadata, parent_config, pending_writes) = (\n    app.checkpointer.get_tuple(config)\n)\nprint(f\"config:\\n{json.dumps(config, indent=4)}\")\nprint(f\"checkpoint:\\n{json.dumps(checkpoint, indent=4)}\")\nprint(f\"metadata:\\n{json.dumps(metadata, indent=4)}\")\nprint(f\"parent_config:\\n{json.dumps(parent_config, indent=4)}\")\nprint(f\"pending_writes:\\n{json.dumps(pending_writes, indent=4)}\")\n</code></pre>\n<p>我们为创建的Pregel对象提供了一个InMemorySaver作为它的Checkpointer，并在调用时利用提供的RunnableConfig设置了Thread ID。由于我们将通道nodes作为输出，所以调用结果会反映三个Node的执行状态（只有节点foo和bar2成功执行）。我们随后传入相同的配置调用Checkpointer的get_tuple方法，并将得到的CheckpointTuple元组进行拆包输出。</p>\n<pre><code class=\"language-json\">config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\"\n    }\n}\ncheckpoint:\n{\n    \"v\": 4,\n    \"ts\": \"2026-01-19T10:17:07.498064+00:00\",\n    \"id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\",\n    \"channel_versions\": {\n        \"foo\": \"00000000000000000000000000000001.0.06769883673554666\",\n        \"nodes\": \"00000000000000000000000000000002.0.3174924500871408\",\n        \"bar\": \"00000000000000000000000000000002.0.3174924500871408\"\n    },\n    \"versions_seen\": {\n        \"__input__\": {},\n        \"foo\": {\n            \"foo\": \"00000000000000000000000000000001.0.06769883673554666\"\n        }\n    },\n    \"updated_channels\": [\n        \"bar\",\n        \"nodes\"\n    ],\n    \"channel_values\": {\n        \"foo\": \"triggered by user\",\n        \"nodes\": [\n            \"foo\"\n        ],\n        \"bar\": \"triggered by foo\"\n    }\n}\nmetadata:\n{\n    \"source\": \"loop\",\n    \"step\": 0,\n    \"parents\": {}\n}\nparent_config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24ee-671f-bfff-2e9f3ca91778\"\n    }\n}\npending_writes:\n[\n    [\n        \"30b17cb1-76f1-3c5a-0d32-33f544fcabdf\",\n        \"nodes\",\n        [\n            \"bar2\"\n        ]\n    ],\n    [\n        \"e126d089-c354-0ac8-bb9e-b12bbe3f20b8\",\n        \"__interrupt__\",\n        \"manual interrupt\"\n    ]\n]\n</code></pre>\n<p>整个执行过程涉及三个Superstep，会创建两个Checkpoint。第一个Checkpoint的创建发生在调用invoke方法的时候，此时提供的输入被写入Channel，首批待执行的Node（foo）准备就绪，此时创建的Checkpoint 记录了 <code>接收到了初始任务，但尚未开始执行任何Node</code> 的状态。此时对应的Superstep序号为-1，输出结果的parent_config部分提供了此Checkpoint的ID。</p>\n<p>第二个Checkpoint是为序号为0的Superstep创建的，此时节点foo成功执行，执行结果最终被输入目标Channel，创建的Checkpoint反映的就是的状态，config部分提供了此Checkpoint的ID。上面的输出还提供了这个Checkpoint的时间戳、Channel的版本和值、涉及Node的可见Channel（f和版本，以及涉及更新的Channel列表。</p>\n<p>由于最后一个Superstep（序号为1）没有完全结束，它们会利用对应的Pending Write来描述。上面输出的第一个Pending Write表示成功执行的节点bar针对通道nodes的写入，第二个针对特殊系统Channel <code>__interrupt__</code>的写入很明显就是因为节点bar1的中断导致。</p>\n<h2 id=\"2-读取状态快照\">2. 读取状态快照</h2>\n<p>BaseCheckpointSaver提供了get_tuple/aget_tuple方法以Checkpoint_Tuple的形式返回最新或者基于过去时间点的状态。对于CheckpointTuple这个五元组，除了Checkpoint和PendingWrite列表，还包括Checkpoint的元数据和相关配置。这个元组主要由执行引擎内部使用的，针对最终开发者来说可读性差点，所以Pregel类定义了如下所示的<code>get_state/aget_state</code>方法，它们提供的StateSnapshot类型更具可读性。</p>\n<pre><code class=\"language-python\">class Pregel(\n    PregelProtocol[StateT, ContextT, InputT, OutputT],\n    Generic[StateT, ContextT, InputT, OutputT]): \n\n    def get_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n    async def aget_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n\n    def get_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[StateSnapshot]\n    async def aget_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[StateSnapshot]\n</code></pre>\n<p>当我们调用Pregel对象的<code>get_state/aget_state</code>方法的时候，它会将指定的RunnableConfig对象作为参数调用Checkpointer的<code>get_tuple/aget_tuple</code>方法，并利用返回的Checkpoint_Tuple元组生成StateSnapshot对象。StateSnapshot的<code>values</code>字段提供的值来源于Checkpoint对象的channel_values字段，它的<code>metadata</code>字段表示的CheckpointMetadata 直接来源于Checkpoint_Tuple的同名字段，而<code>config</code>和<code>parent_config</code>返回的RunnableConfig则是由Checkpoint_Tuple同名字段于元数据合并而成。表示快照创建时间的<code>created_at</code>对应于Checkpoint_Tuple表示时间戳的ts字段，而interrupts返回的Interrupt列表是根据中断类型的PendingWrite构建的。</p>\n<pre><code class=\"language-python\">class StateSnapshot(NamedTuple):\n    values: dict[str, Any] | Any\n    next: tuple[str, ...]\n    config: RunnableConfig\n    metadata: CheckpointMetadata | None\n    created_at: str | None\n    parent_config: RunnableConfig | None\n    tasks: tuple[PregelTask, ...]\n    interrupts: tuple[Interrupt, ...]\n\nclass PregelTask(NamedTuple):\n    id: str\n    name: str\n    path: tuple[str | int | tuple, ...]\n    error: Exception | None = None\n    interrupts: tuple[Interrupt, ...] = ()\n    state: None | RunnableConfig | StateSnapshot = None\n    result: Any | None = None\n</code></pre>\n<p>StateSnapshot的<code>tasks</code>字段返回一组PregelTask对象，它们表示根据Checkpoint创建的待执行任务，<code>next</code>字段以元组的形式返回这些任务的Node名称。对于最新的Checkpoint，若下一个Superstep尚未完成，PregelTask的信息还会利用对应的Pending Write进一步完善。我们可以利用PregelTask对象得到每个任务的ID、Node名称、执行路径、抛出的异常和中断（根据异常和中断类型的PendingWrite创建），而<code>state</code>和<code>result</code>分别承载这任务的状态和输出结果。如果整个执行流程结束，自然就没有所谓后续任务的说法，此时StateSnapshot的tasks字段为空。</p>\n<p>除了返回一个具体的状态快照，Pregel类还定义了<code>get_state_history/aget_state_history</code>，它们的参数列表与BaseCheckpointSaver的<code>list/alist</code>方法完全一致。当这两个方法被调用的时候，Pregel会调用Checkpointer的<code>list/alist</code>方法，并将得到Checkpoint_Tuple元组转换成StateSnapshot对象。<code>get_state_history/aget_state_history</code>方法返回的迭代器以时间逆序的方式返回对应的状态快照。</p>\n<p>如下这个程序演示了一个具体的Pregel对象的历史由哪些快照组成，每个快照又反映当时的状态。我们构建的Pregel对象由四个Node组成，调用时指定通道foo会驱动执行节点foo，它执行结束后写入通道bar驱动bar1、bar2和bar3并行执行。除了bar1能够顺利执行外，我们为bar2设置了一个中断，让bar3抛出异常。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.checkpoint.memory import  InMemorySaver\nfrom langgraph.types import interrupt\n    \ndef handle(node_name: str, halt : bool, raise_error: bool) -&gt; None:\n    if halt:\n        _ = interrupt(f\"Manually be interrupted at {node_name}\")\n    if raise_error:\n        raise Exception(f\"Manually raised error at {node_name}\")\n\nfoo = (NodeBuilder()\n       .subscribe_to(\"foo\", read=False)\n       .do(lambda _: handle(\"foo\", halt=False, raise_error=False))\n       .write_to(bar = lambda _:None))\nbar1 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar1\", halt=False, raise_error=False)))\nbar2 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar2\", halt=True, raise_error=False)))\nbar3 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar3\", halt=False, raise_error=True)))\napp = Pregel(\n    nodes={\n        \"foo\": foo,\n        \"bar1\": bar1,\n        \"bar2\": bar2,\n        \"bar3\": bar3\n    },\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer= InMemorySaver())\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\n\ntry:\n    app.invoke(input={\"foo\": \"begin\"},config=config)\nexcept Exception as e:\n    pass\n\nfor snapshot in app.get_state_history(config):\n    print(f\"\"\"\nvalues: {snapshot.values}\nnext: {snapshot.next}\ninterrupts: {snapshot.interrupts}   \ntasks:\"\"\")\n    for task in snapshot.tasks:\n        print(f\"\"\"  id: {task.id}\n    name: {task.name}\n    path: {task.path}\n    error: {task.error} \n    interrupts: {task.interrupts}\n    state: {task.state}\n    result: {task.result}\"\"\")\n</code></pre>\n<p>在完成了针对Pregel对象的调用后，我们采用相同的配置调用它的<code>get_state_history</code>方法得到完整的历史，并将承载历史片段的StateSnapshot信息打印出来。整个过程涉及三个Superstep，前两个成功完成的Superstep会提供两个Checkpoint，第三个尚未完成的Superstep只提供针对三个Node任务的Pending Write。</p>\n<pre><code class=\"language-json\">values: {'start': 'begin', 'bar': None}\nnext: ('bar1', 'bar2', 'bar3')\ninterrupts: (Interrupt(value='Manually be interrupted at bar2', \n    id='26f309d618c42ff31d2b3404369232e4'),)\ntasks:\n  id: dbb24ec5-f1ba-f845-7351-54e88f34db0f\n    name: bar1\n    path: ('__pregel_pull', 'bar1')\n    error: None\n    interrupts: ()\n    state: None\n    result: {}\n  id: 794fffda-2e6c-0685-0d44-3ed6c57ca366\n    name: bar2\n    path: ('__pregel_pull', 'bar2')\n    error: None\n    interrupts: (Interrupt(value='Manually be interrupted at bar2', \n        id='26f309d618c42ff31d2b3404369232e4'),)\n    state: None\n    result: None\n  id: 1055ec55-49dc-0629-86b5-661a2614f349\n    name: bar3\n    path: ('__pregel_pull', 'bar3')\n    error: Exception('Manually raised error at bar3')\n    interrupts: ()\n    state: None\n    result: None\n\nvalues: {'start': 'begin'}\nnext: ('foo',)\ninterrupts: ()\ntasks:\n  id: 88904475-3edc-733a-d84d-98aa6d3f5e80\n    name: foo\n    path: ('__pregel_pull', 'foo')\n    error: None\n    interrupts: ()\n    state: None\n    result: {'bar': None}\n</code></pre>\n<h2 id=\"3任务路径\">3.任务路径</h2>\n<p>还记得我们前面说个任务的两种创建方式，一种是站在Node的角度，通过查看订阅Channel的更新状态确定是否应该执行，我们称这种任务创建模式为<code>Pull模式</code>。与之相对的则是<code>Push模式</code>，Node利用写入<code>__pregel_tasks</code>这个特殊Channel的Send对象决定后续执行的Node，执行引擎会从此Channel读取Send对象的来创建对应的任务。任务路径的第一部分通常就反映了任务的驱动模式，对应的值为<code>__pregel_pull</code>和<code>__pregel_push</code>。</p>\n<p>由于前面演示的都是基于Channel订阅驱动的任务，所以路径采用(“__pregel_pull”,{node})的形式。如下的程序演示“Push任务”的路径，我们构建的Pregel由四个Node（foo、bar1、bar2和bar3）组成，节点foo的处理函数最终会生成三个针对其他Node的Send对象，并写入“__pregel_tasks”Channel以驱动它们并行执行。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.pregel._read import PregelNode\nfrom langgraph.pregel._write import ChannelWrite, ChannelWriteTupleEntry\nfrom langgraph.types import Send\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nentry = ChannelWriteTupleEntry(lambda args: [(\"__pregel_tasks\", args)])\nwriter = ChannelWrite(writes=[entry])\nfoo: PregelNode = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: [Send(node=node, arg=\"foo\") for node in [\"bar1\", \"bar2\", \"bar3\"]])\n).build()\nfoo.writers.append(writer)\n\nbars = {name: NodeBuilder() for name in [\"bar1\", \"bar2\", \"bar3\"]}\n\napp = Pregel(\n    nodes={\"foo\": foo, **bars},\n    channels={\n        \"foo\": LastValue(None),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer=InMemorySaver(),\n)\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke(input={\"foo\": None}, config=config, interrupt_before=\"bar2\")\nsnapshot = app.get_state(config)\nfor task in snapshot.tasks:\n    print(f\"{task.name}:{task.path}\")\n</code></pre>\n<p>为了能看到三个任务，我们在在最后一个Superstep中产生一个中断，为此我们在调用的时候通过指定<code>interrupt_before</code>参数在执行节点bar2前中断。我们随后调用Pregel的get_state方法得到描述最终状态的StateSnapshot，并输出所有任务的执行路径。从如下的输出可以看出，由于是三个基于Push模式的任务，所以组成路径的第一个部分内容为 <code>__pregel_push</code> 。每个任务由 <code>__pregel_tasks</code> Channel的Send对象构建而成，第二部分的数组代表对应的Send对象在Channel中的索引。由于整个程序只有唯一的Pregel对象，不设置子图调用，所以第三部分返回False。</p>\n<pre><code>bar1:('__pregel_push', 0, False)\nbar2:('__pregel_push', 1, False)\nbar3:('__pregel_push', 2, False)\n</code></pre>\n<h2 id=\"4状态嵌套\">4.状态嵌套</h2>\n<p>这里我们有必要提一下PregelTask类的<code>state</code>字段。从给出的定义可以看出，它可以返回一个RunnableConfig配置，也可以返回一个StateSnapshot对象。如果任务涉及子图的调用，并且在调用get_state/aget_state方法时将subgraphs参数设置为True，它的state字段就会返回一个描述子图当前状态的<code>StateSnapshot</code>对象。借助于反映执行链路和调用顺序的Checkpoint命名空间，就可以形成的嵌套层次结构（state =&gt;task=&gt;state）使我们可以可以看到一个任务完整的调用链条。</p>\n<p><img alt=\"Alternative Text\" class=\"lazyload\" /></p>\n<p>以如下这个验证程序为例。我们构建了两个具有单一Node的Pregel对象app和sub_graph，前者的节点main_node以子图调用的方式调用sub_graph，后者的Node命名为 “sub_node”。为了在StateSnapshot中将任务保留下来，我们在两个Node中引入了中断。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import interrupt\nfrom typing import Any\nfrom langgraph.types import StateSnapshot\n\nsub_node = (NodeBuilder()\n    .subscribe_to(\"start\")\n    .do(lambda _: interrupt(\"manual interrupt\"))\n)\nsub_graph = Pregel(\n    nodes={\"sub_node\": sub_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n)\n\ndef handle(args: dict[str, Any]) -&gt; None:\n    sub_graph.invoke(input={\"start\": \"begin\"})\n    interrupt(\"main graph interrupt\")\n\nmain_node = NodeBuilder().subscribe_to(\"start\").do(handle)\napp = Pregel(\n    nodes={\"main_node\": main_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n    checkpointer=InMemorySaver())\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\napp.invoke(input={\"start\": \"begin\"}, config=config)\nsnapshot = app.get_state(config, subgraphs=True)\n\nindent = -1\ndef print_snapshot(snapshot: StateSnapshot) -&gt; None:\n    global indent\n    indent += 1\n    config = snapshot.config[\"configurable\"]\n    print(f\"{'  ' * indent}checkpoint_ns: {config.get('checkpoint_ns', None)}\")\n    for task in snapshot.tasks:\n        print(f\"{'  ' * indent}task: {task.name}:{task.id}\")\n        if sub_snapshot := task.state:\n            print_snapshot(sub_snapshot)\n\nprint_snapshot(snapshot)\n</code></pre>\n<p>在完成调用后，我们调用作为主图的Pregel对象的<code>get_state</code>方法，并将参数subgraphs设置为True。我们调用print_snapshot函数输出StateSnapshot提供的Checkpoint命名空间和任务的名称与ID。如果描述任务的PregelTask对象的state字段也是一个StateSnapshot对象，那么继续递归调用此函数。从如下的输出可以看出，作为子图的Pregel将当前任务的名称和ID的组合作为Checkpoint命名空间，这样的结构确保了 “主图” 恢复的时候能够精准地加载 “子图” 的状态。</p>\n<pre><code>checkpoint_ns: \ntask: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    checkpoint_ns: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    task: sub_node:a483bfb8-bcc6-92b3-2f64-9f9e9f4fe158\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 07:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 学习笔记：Agent 的基础应用",
      "link": "https://www.cnblogs.com/owlman/p/19623216",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19623216\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 16:09\">\n    <span>AI 学习笔记：Agent 的基础应用</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记对应的是《[[关于 AI 的学习路线图]]》一文中所规划的第四个学习阶段。其中记录了我学习 AI Agent 的工作原理，并将其应用于实际工作场景的全过程，以及在该过程中所获得的心得体会。同样的，这些内容也将成为我 AI 系列笔记的一部分，被存储在本人 Github 上的<a href=\"https://github.com/owlman/CS_StudyNotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机学习笔记库</a>中，并予以长期维护。</p>\n</blockquote>\n<h2 id=\"ai-agent-简介\">AI Agent 简介</h2>\n<p>在理解了 LLM 在生产环境中所扮演的角色之后，初学者们接下来要思考的问题是：如何让它参与到自己的实际工作中？到目前为止（截至 2026 年 2 月），这个问题最具可行性的解决方案是：构建并使用 AI Agent。</p>\n<h3 id=\"为什么需要-ai-agent\">为什么需要 AI Agent</h3>\n<p>在早期，大多数用户是通过 Web 端或移动端的即时通信应用，主要以文本聊天的方式来使用 LLM 的（例如 ChatGPT、豆包等）。这类应用本质上是基于 HTTP API 构建的人机交互界面，其主要交互模式是“输入文本—生成文本”的往返过程。我们之前在《[[LLM 的部署与测试]]》一文中基于 PyTest 框架编写的测试用例，实际上模拟的就是这种交互模式。</p>\n<p>尽管，这类应用极大地降低了 LLM 的使用门槛，使其成为了一种能惠及普通用户的智能问答工具，但 AI 所能带来的生产力也在很大程度上被局限在了这种即时通信式的交互模式中。因为在这种交互模式下，LLM 只能根据用户当前的输入来生成文本结果，无法主动访问本地环境、调用系统资源或执行实际任务。更重要的是，LLM 在这种模式下并不处于一个持续运行的控制结构之中，它只在收到请求时做出一次性响应，无法负责具体的工作流程与状态管理。</p>\n<p>试想一下，如果 LLM 已经具备了复杂的任务规划与执行能力，我们却把它限制在聊天窗口中，这岂不是太浪费了？正是为了避免这种浪费，并赋予 LLM 在特定环境中“执行操作”的能力，AI 的研究者们重新审视了 AI Agent 这一在 20 世纪 80-90 年代就已经形成体系的概念，并在工程实践领域给了它全新的实现形式。</p>\n<p>关于 AI Agent 这个概念，读者可以参考我之前在《[[关于 AI 的学习路线图]]》中推荐的《人工智能：现代方法》一书给出的定义，原文如下：</p>\n<blockquote>\n<p>An agent is anything that can perceive its environment through sensors and act upon that environment through actuators.</p>\n<p>翻译过来就是：</p>\n<p>任何能够通过传感器感知环境，并通过执行器对环境产生影响的实体，都可以称为 Agent。</p>\n</blockquote>\n<p>这个定义成为了后来所有 AI Agent 应用的理论基础。由此也可以看出，AI Agent 的核心功能并不是提升 LLM 本身的智能水平，而是赋予它与外部系统交互的能力，使其能够参与到真实的工作流程之中。从本质上来说，这其实是 AI 应用在客户端方面的一次角色转变，它现在从单纯的答题工具被转变成了一个可以参与任务执行的系统组件。在特定的应用场景中，这种架构上的转变为工作流程的自动化提供了可行的工程路径。</p>\n<h3 id=\"ai-agent-的工作原理\">AI Agent 的工作原理</h3>\n<p>下面，让我们来了解一下 AI Agent 具体是怎么工作的。在传统聊天式的 AI 应用中，我们可以将其基本的执行模式简单概括为：</p>\n<blockquote>\n<p>用户输入 → 模型推理 → 输出结果 → 结束</p>\n</blockquote>\n<p>这种执行模式本质上是一次性的请求—响应（request-response）结构。即在这种执行模式下，LLM 会在接收到用户输入后生成文本，然后就立即退出当前工作流程，不再参与后续状态管理了。AI Agent 与这类应用的核心差异就在于：它在执行模式中引入了一个可持续运行的控制循环（control loop）。这种循环结构将 LLM 从被动接收用户输入的文本生成器，转变成了用于驱动整个程序执行结构的决策组件。换言之，Agent 的存在将 AI 应用的基本执行模式从“请求—响应”转变成了下面这样一个“感知—决策—执行”的循环结构：</p>\n<blockquote>\n<p>感知环境 → 生成决策 → 执行动作 → 更新环境状态 → 再次感知</p>\n</blockquote>\n<p>这个循环结构会持续运行下去，直到任务完成或满足终止条件。从该执行模式可以看出，一个典型的 AI Agent 应用通常包含以下几个核心组件：</p>\n<ul>\n<li><strong>LLM</strong>：该组件负责理解当前任务目标、分析上下文状态并生成下一步行动决策，不负责直接执行外部操作；</li>\n<li><strong>工具接口</strong>：该组件负责将 LLM 生成的结构化指令转换为实际可执行的操作，例如：调用 API、访问数据库、读写文件、执行系统命令、触发外部服务等。它们通常由开发者定义，并通过函数调用或插件机制暴露给模型；</li>\n<li><strong>状态管理</strong>：该组件负责维护任务的中间状态，例如：当前任务进度、已执行步骤、外部环境变化、历史决策记录等。这些状态通常会被存储在内存变量、数据库、向量存储、文件系统等介质中，如果缺乏有效的状态管理机制，我们就难以构建一个真正的 Agent 应用；</li>\n<li><strong>控制器</strong>：该组件负责驱动循环、判断是否继续执行、解析模型输出、调用对应工具、处理异常与失败重试。从架构角度来看，控制器可被视为 Agent 系统的“骨架”，而 LLM 只是其中的决策模块。</li>\n</ul>\n<p>基于以上核心组件，我们就可以简单地归纳出一个 Agent 应用的工作流程，其主要步骤如下：</p>\n<ol>\n<li>接收任务目标</li>\n<li>将目标与当前状态输入 LLM</li>\n<li>LLM 输出下一步行动计划（通常为结构化格式）</li>\n<li>控制器解析输出</li>\n<li>调用相应工具执行</li>\n<li>更新状态</li>\n<li>判断是否完成任务</li>\n<li>若未完成，则进入下一轮循环</li>\n</ol>\n<p>从工程角度来看，AI Agent 是一种新的系统架构模式，它通过持续运行的控制循环，使模型能够参与真实任务的执行过程，而不仅仅是生成文本结果。</p>\n<h2 id=\"ai-agent-的使用方法\">AI Agent 的使用方法</h2>\n<p>在了解了使用 AI Agent 的必要性及其工作原理之后，接下来就可以正式开始研究如何将它运用到自己的日常工作中了。而当我们要讨论 AI Agent 在实际工作中的使用方法时，首先需要回答的问题是“它运行在哪里、由谁控制、承担什么责任”。不同的运行形态，决定了它在工程系统中的角色边界。下面，让我们按照\"运行在哪里\"这个维度分三类来介绍 AI Agent 的使用方法，以及它们在这些应用场景中所承担的任务角色。</p>\n<h3 id=\"命令行工具型-agent\">命令行工具型 Agent</h3>\n<p>对于大多数开发者而言，以命令行工具的形式使用 AI Agent 是一种更符合工程直觉的方式。它运行在熟悉的终端环境中，可以直接访问文件系统与系统命令，因此看起来类似于自动化脚本。当然了，与传统脚本不同的是，AI Agent 的内部决策路径并非预先编写，而是由 LLM 在循环结构中动态生成。这类 AI Agent 应用的典型代表是 <a href=\"https://github.com/anthropics/claude-code\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code</a>，目前同类的主流应用还包括 <a href=\"https://github.com/anomalyco/opencode\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode</a>、<a href=\"https://github.com/openai/codex\" rel=\"noopener nofollow\" target=\"_blank\">Codex CLI</a>、<a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener nofollow\" target=\"_blank\">Gemini CLI</a>、<a href=\"https://github.com/iflow-ai/iflow-cli\" rel=\"noopener nofollow\" target=\"_blank\">iFlow CLI</a> 等。下面，我们首先要做的就是：先将这些工具安装到自己所在的操作系统中。</p>\n<h4 id=\"安装与配置\">安装与配置</h4>\n<p>命令行工具型 Agent 的安装方式其实是非常简单的。因为，虽然它们各自针对 MacOS/Linux/Windows 系统提供了不同的 bash/powershell 安装脚本，或者基于 homeberw/pacman/scoop 等针对不同操作系统平台的包管理器安装命令，但基本都提供了基于 NPM 这一包管理器的跨平台安装方式。所以，读者在大多数情况下都可以按照以下步骤来安装并使用这些工具：</p>\n<ol>\n<li>\n<p>确保自己所在的操作系统中已经安装了版本在 20.0.0 之上的 Node.js 运行环境，其中自带了 NPM 包管理器；</p>\n</li>\n<li>\n<p>在管理员权限下执行<code>npm install -g &lt;agent-name&gt;@&lt;version&gt;</code>命令，在这里，<code>&lt;agent-name&gt;</code>可以通过查询相关工具的官方网站来获得，而<code>&lt;version&gt;</code>则除了可以是我们在工具官网中查到的具体版本号之外，也可以用<code>latest</code>来表示最新版本。例如，如果我们需要安装最新版本的 OpenCode，就只需要在命令行终端中使用管理员权限执行<code>npm install -g opencode@latest</code>命令即可。</p>\n</li>\n</ol>\n<p>在安装完成之后，我们就可以用 CLI 和 TUI 两种方式来使用这种命令行工具型的 Agent 了。其中，TUI 的方式已经被大家所熟知，它实际上就是一个基于命令行界面的交互式程序，运作方式类似于 Python Shell 或 Node.js REPL，拥有属于自己的独立线程。例如在安装完 OpenCode 之后，我们只需要直接在命令行终端中输入<code>opencode</code>命令（如果想延续之前与 OpenCode 的会话，还在该命令后面加上一个<code>--continue</code>或<code>-c</code>参数），就可以启动它的 TUI 界面了，具体如图 1 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：OpenCode TUI 界面</p>\n<p>在初次进入上次界面时，我们可以对自己使用的 AI Agent 进行一些基本的配置，这些工具的配置方式基本上是大同小异的。一般来说，我们会先使用<code>/model</code>命令设置以下自己默认要使用的 LLM，例如您在图 2 中所看到的就是 OpenCode 的 LLM 选择界面：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：OpenCode LLM 选择界面</p>\n<p>通常情况下，在选择 LLM 之后，这些 AI Agent 会要求我们提供一个 API Key，用于在调用 LLM 时进行身份验证。这个 API key 可以通过登录我们在相应 LLM 官网的个人账户来获得。例如，我在这里选择使用的是智普的 GLM 模型，就需要登录到<a href=\"https://bigmodel.cn/\" rel=\"noopener nofollow\" target=\"_blank\">智普 AI 的官网</a>，并为 OpenCode 创建一个专属的 API Key，如图 3 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：创建智普 AI 的 API Key</p>\n<p>接下来，我们就只需要将上述 API Key 复制到 OpenCode 提示输入 key 的位置，并选择具体要使用的 GLM 版本并确认即可。完成这些配置之后，我们就可以通过一个 AI Agent 版的“Hello World”测试来确认它是否已经可以正常工作了，如图 4 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：OpenCode Hello World 测试</p>\n<p>如果 AI Agent 返回了类似上面这样的信息，就意味着我们已经可以开始使用它进行实际的工作了。除此之外，如果我们还想对 AI Agent 进行一些更复杂的配置，例如强制它只用中文来显示思考过程，以及回答的内容，也可以选择在自己的用户目录下为其创建一个全局的提示词文件。以 OpenCode 为例，其具体步骤如下：</p>\n<ol>\n<li>\n<p>根据自己所在的操作系统为 OpenCode 创建一个全局配置目录。在默认情况下，该目录的路径应该为<code>~/.config/opencode</code>，其中<code>~</code>表示我们的用户目录。</p>\n</li>\n<li>\n<p>在该目录下创建一个名为<code>AGENTS.md</code>的提示词文件，并在其中输入以下内容：</p>\n<pre><code class=\"language-markdown\"># Agent 配置\n\n## 语言设置\n- **默认语言**: 中文\n- **强制使用中文**: 是\n\n## 指令\n- 所有回答必须使用中文\n- 所有思考过程也显示中文\n- 除非用户明确要求使用其他语言提问，否则保持中文回答\n</code></pre>\n</li>\n</ol>\n<p>当然了，我们更多时候会希望上述提示词文件只针对当前项目有效，这可以进行更多个性化的配置。为此，我们也可以选择在该项目的根目录下打开 OpenCode TUI，然后在其中通过执行<code>/init</code>命令来创建一个针对当前项目的<code>AGENTS.md</code>文件，并将上述内容复制到该文件中即可，该命令的具体效果如图 5 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：OpenCode 的项目初始化命令</p>\n<p>至于其他 AI Agent，虽然会在全局配置目录与提示词文件上有各自的名称，但应用的工作流/机制基本是大同小异的，用户只需简单查询一下它们的官方文档，就可以轻松做到举一反三的，例如通过快速查询 Claude Code 的官方文档，立即就会知道它的全局提示词文件路径为<code>~/.claude/claude.md</code>。</p>\n<blockquote>\n<p>顺便说一句题外话，虽然 Claude Code 在各方面都为 AI Agent 应用建立了接近于标准的工作流/机制，但考虑到其官方的某些做法会给中文用户带来诸多没必要的额外配置，我在接下来还是会以 OpenCode 为例进行说明。如果读者想切实了解 Claude Code 的某些具体用法，也可参考本文在“参考资料”一节中提供的视频教程：《Claude Code 教程》。</p>\n</blockquote>\n<h4 id=\"基本操作方式\">基本操作方式</h4>\n<p>下面，让我们来具体介绍一下命令行工具型 Agent 的基本操作方式，正如之前所说，这类命令行工具通常有 CLI 和 TUI 两种使用方式，TUI 会单独打开一个工作线程来执行交互式操作，通常用于执行一些需要使用多轮提示词交互，并确认内容的复杂任务。因此，这些 Agent 应用的 TUI 往往至少会提供“计划（plan）”和“构建（build）”两个模式（个别 Agent 还会提供”自动（auto）“之类的第三种模式，或者在模式名称上存在差异，但其在基本使用逻辑上是一致的），其中，”计划“模式通常没有执行外部命令的权限，主要用于与 LLM 执行多轮交互，并确认某一杂任务的解决方案。例如在之前展示的 OpenCode TUI 中，读者可以在其输入框的下方看到，它默认处于“构建”模式。现在，我们可以通过输入<code>&lt;tab&gt;</code>键来将其切换到“计划”模式，然后再试着让它执行“使用 Python 编写并执行一个 hello world 程序”的操作，就会得到类似图 5 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：OpenCode 的计划模式</p>\n<p>正如读者所见，现在 OpenCode TUI 输入框下面提示其当前处于“计划”模式，并且告诉用户自己当前不能编辑文件和执行程序，然后开始与用户讨论任务的具体解决方案。而当我们切换到“构建”模式时，OpenCode 就会直接执行这个解决方案，并输出类似图 7 的结果：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：OpenCode 的构建模式</p>\n<p>当然了，就上面这种仅需一句简短的提示词就可以完成的任务而言，我们实际上更适合使用 CLI 的方式来执行。这种方式允许我们在 bash/powershell 这类命令行终端程序所在的当前线程中直接执行 AI Agent，并输出结果。例如，如果我们想使用 OpenCode CLI 的方式来编写并执行上面那个 Python 程序，可以直接在命令行终端中输入<code>opencode run \"使用 Python 编写并执行一个 hello world 程序\"</code>命令，并得到类似图 8 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：OpenCode 的 CLI 模式</p>\n<p>如读者所见，上述命令直接在 powershell 所在的当前线程中输出了 OpenCode 的执行结果。这样做的好处，除了避免因一些简单的任务反复启动和关闭 OpenCode TUI 之外，在必要情况下还可以使用 Shell/Python 这样的脚本语言来实现对 AI Agent 应用的批量调用，例如，如果我们想使用 Python 脚本批量调用 OpenCode CLI 来执行 5 个不同的任务，就可以像下面这样编写一个简单的 Python 脚本：</p>\n<pre><code class=\"language-python\">import subprocess\n\ntasks = [\n    \"使用 Python 编写并执行一个 hello world 程序\",\n    \"使用 Python 编写并执行一个计算斐波那契数列的程序\",\n    \"使用 Python 编写并执行一个计算阶乘的程序\",\n    \"使用 Python 编写并执行一个计算素数的程序\",\n    \"使用 Python 编写并执行一个计算回文数的程序\",\n]\n\nfor task in tasks:\n    try:\n        result = subprocess.run(\n            [\"opencode\", \"run\", task],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=120\n        )\n        print(f\"任务成功: {task}\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(f\"任务失败: {task}\")\n        print(e.stderr)\n    except subprocess.TimeoutExpired:\n        print(f\"任务超时: {task}\")\n</code></pre>\n<p>除了<code>opencode run</code>命令之外，我们还可以通过执行<code>opencode -h</code>命令来查看其他可用 CLI 方式执行的 OpenCode 操作，如图 9 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 9</strong>：OpenCode 的 CLI 帮助信息</p>\n<p>虽然，上面这种多次调用<code>opencode run</code>命令的做法，在某些特定的情况下并不是最佳的任务编排方式。例如在某些时候，先将所有的需求写入一个 Markdown 文档中，再将其作为提示词一次性发给 AI Agent 可能会是一种更合适的做法。但是，我们可以基于这一思路发展出许多更复杂的 AI Agent 工作流，例如利用部署在服务端的 Agent 来操作这些命令行工具型的 Agent。下面，就让我们基于 OpenClaw 这一可部署服务型的 AI Agent 来了解一下这一工作流的具体实现方式。</p>\n<h3 id=\"可部署服务型-agent\">可部署服务型 Agent</h3>\n<p>如果我们将命令行工具型的 AI Agent 视为一种增强型的自动化工具，那么以 OpenClaw 为代表的、可在服务端部署的 AI Agent 则就是一种系统级执行单元，二者的差异主要在于运行形态与系统边界。具体来说就是，命令行工具型 Agent 的运行方式通常是：</p>\n<ul>\n<li>被用户触发</li>\n<li>执行一轮或多轮任务</li>\n<li>输出结果</li>\n<li>退出进程</li>\n</ul>\n<p>而可部署服务型 Agent 则具有以下完全不同的特征：</p>\n<ul>\n<li>常驻运行</li>\n<li>通过 HTTP / RPC / WebSocket 等方式对外提供能力</li>\n<li>持续维护会话状态</li>\n<li>支持多用户并发访问</li>\n<li>可以被其他系统调用</li>\n</ul>\n<p>在这种形态下，Agent 就不再是一个功能类似于自动化脚本的增强型工具了，它成为了常驻在操作系统中的一个服务组件。具体来说，如果从程序架构的角度来看，这两种 Agent 的差别主要体现在以下几个方面：</p>\n<ol>\n<li>\n<p>生命周期管理：命令行工具型 Agent 的生命周期通常是一次性的，执行完成即销毁，而可部署服务型 Agent 则具有长生命周期，需要考虑健康检查、日志管理、异常恢复机制。</p>\n</li>\n<li>\n<p>会话与状态管理：命令行工具型 Agent 的状态通常也是一次性的，而可部署服务型 Agent 则需要维护会话状态，这意味着它需要支持用户级会话隔离、长期上下文存储、记忆机制（Memory）以及外部数据库支持。</p>\n</li>\n<li>\n<p>多 Agent 编排能力：一旦 Agent 以系统服务组件的形式存在，它就可以调用其他 Agent，被其他 Agent 调用，参与更复杂的任务链。例如像这样：</p>\n<pre><code class=\"language-plaintext\">用户请求\n↓\n调度 Agent\n↓\n分析 Agent → 代码生成 Agent → 测试 Agent\n↓\n结果汇总\n</code></pre>\n<p>这种执行结构显然已经不再是单纯的工具调用，它关注的实际上已经是任务的编排与调度了。这也就意味着，我们需要在服务型的 Agent 中引入任务队列、消息队列、异步任务调度系统等机制。</p>\n</li>\n</ol>\n<p>下面，让我们以 OpenClaw 为例来具体介绍一下使用这种服务型 Agent 的一些基本工作流。假设，我们现在想使用 OpenClaw 指挥 OpenCode 来完成一个简单的网站重构任务，通常需要按照以下步骤来完成。</p>\n<h4 id=\"步骤-1安装并配置一个-openclaw-服务\">步骤 1：安装并配置一个 OpenClaw 服务</h4>\n<p>正如之前所说，OpenClaw 本质上是一个系统服务，这意味着免不了要赋予它较大的操作权限，基于安全方面的考虑，我个人不建议用户将其安装在自己日常的工作设备上。另外，如果想最大限度地发挥 OpenClaw 的功能，最好要能让它长时间持续运行，并执行一定程度的实际设备管理能力。因此，我们在安装 OpenClaw 时通常需要执行的操作如下：</p>\n<ul>\n<li>\n<p>配置好一台可与我们日常工作设备相连通的独立计算机（如果仅用于学习目的，也可以是一台虚拟机），并在其中安装好操作系统与 Node.js 22.x 以上版本的运行环境。</p>\n</li>\n<li>\n<p>在这台独立计算机上打开命令行终端，并执行<code>npm install -g openclaw@latest</code>命令来安装 OpenClaw。当然了，这是使用跨平台的方式。如果读者不想使用 NPM，也可以通过直接执行 bash/powershell 的安装脚本来完成这个操作，相关命令如下：</p>\n<pre><code class=\"language-bash\"># MacOS/Linux 系统下使用 bash 脚本安装：\ncurl -fsSL https://openclaw.ai/install.sh | bash\n# Windows 系统下使用 powershell 脚本安装：\niwr -useb https://openclaw.ai/install.ps1 | iex\n</code></pre>\n</li>\n<li>\n<p>待安装完成之后，继续执行<code>openclaw onboard --install-daemon</code>命令来启动新手安装向导（如图 10 所示），进一步安装 OpenClaw 的服务端组件（例如飞书机器人、WhatsApp 机器人等），关于这方面的内容，读者可参考本文在“参考资料”一节中提供的视频教程：《OpenClaw +飞书的工具流搭建过程》。</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 10</strong>：OpenClaw 的安装向导</p>\n</li>\n<li>\n<p>在配置完相关服务端组件之后，我们还需要通过执行如下命令来配置 OpenClaw 的 Gateway 网关：</p>\n<pre><code class=\"language-bash\">openclaw channels login\nopenclaw gateway --port 18789\n</code></pre>\n<p>在这里，<code>--port</code>参数用于指定 OpenClaw Gateway 的监听端口，如果读者希望使用默认的 18789 端口，则可以省略该参数。</p>\n</li>\n<li>\n<p>待 Gateway 启动之后，我们就可以使用浏览器打开<code>http://localhost:18789</code>来访问 OpenClaw 的 Web 端了，如果我们能看到如图 11 所示的界面，就说明 OpenClaw 已经成功安装并完成了初步的配置工作。</p>\n  \n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 11</strong>：OpenClaw 的 Web 端</p>\n</li>\n</ul>\n<h4 id=\"步骤-2配置-openclaw-调用-opencode-的方式\">步骤 2：配置 OpenClaw 调用 OpenCode 的方式</h4>\n<p>截止到目前为止，我们主要有<strong>两种方式</strong>可以让 OpenClaw 使用 OpenCode 来连接 LLM 并执行指定的任务。如果用户已购买了 OpenCode 的官方模型服务（即 OpenCode Zen），可以选择直接使用 OpenClaw 自带的 Zen 插件来调用 OpenCode，这种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>先获取到 OpenCode Zen 的 API Key，然后通过执行如下命令之一，将其添加到 OpenClaw 的配置中：</p>\n<pre><code class=\"language-bash\"># 使用交互式命令，这需要根据该命令的提示输入你的 API Key\nopenclaw onboard --auth-choice opencode-zen\n# 或非交互式命令，直接将 API Key 作为参数传入\nopenclaw onboard --opencode-zen-api-key \"&lt;你的 API Key&gt;\"\n</code></pre>\n</li>\n<li>\n<p>如果需要的话，还可以通过执行如下命令来设置自己要使用的默认模型：</p>\n<pre><code class=\"language-bash\">openclaw config set agents.defaults.model.primary \"opencode/claude-opus-4-6\"\n</code></pre>\n</li>\n</ul>\n<p>当然了，选择上述方式需要用户不计较按量计费所带来的开销。如果我们想使用免费的 LLM 的话（譬如  kimi-k2.5-free），也可以通过给 OpenClaw 安装 <code>opencode-to-openai</code>这样的第三方插件来实现。这第二种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>安装<code>opencode-to-openai</code>插件，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/dxxzst/opencode-to-openai\ncd opencode-to-openai\nopenclaw plugins install .\n</code></pre>\n</li>\n<li>\n<p>安装完成后，需要执行如下命令来重启 OpenClaw，并确保插件已启用：</p>\n<pre><code class=\"language-bash\">openclaw gateway restart\n</code></pre>\n<p>在这里，如果我们在 OpenClaw 中启用了插件白名单，就还需要通过执行如下命令将该加入该白名单：</p>\n<pre><code class=\"language-bash\">openclaw config get plugins.allow --json\n# 假设返回 [\"a\",\"b\"]\n\nopenclaw config set plugins.allow '[\"a\",\"b\",\"opencode-to-openai\"]' --json\nopenclaw gateway restart\n</code></pre>\n</li>\n<li>\n<p>同步模型并认证 LLM 服务，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local\n</code></pre>\n<p>如果你想顺便设置默认模型：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local --set-default\n</code></pre>\n</li>\n<li>\n<p>选择模型，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models set opencode-to-openai/opencode/kimi-k2.5-free\n</code></pre>\n<p>在这里，如果担心对 LLM 的请求会被卡住，也可以用<code>useIsolatedHome=false</code>这个插件配置让 OpenCode 使用真实 HOME，具体配置命令如下：</p>\n<pre><code class=\"language-bash\">openclaw config set plugins.opencode-to-openai.useIsolatedHome false\n</code></pre>\n</li>\n</ul>\n<h4 id=\"步骤-3与-openclaw-进行对话\">步骤 3：与 OpenClaw 进行对话</h4>\n<p>如果上述操作一切顺利，我们就可以在步骤 1 中配置好的 Web 端或飞书之类的应用中打开与 OpenClaw 的对话窗口，通过发送提示词来调度 OpenCode 完成相关任务了，如图 12 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 12</strong>：与 OpenClaw 的对话窗口</p>\n<p>当然了，如果想让提示词发挥到最大的作用，并在生产环境中实际使用 OpenClaw/OpenCode 来完成具体的项目任务，我们还需要再配置一下 OpenClaw/OpenCode 所接入的 MCP 服务和 Agent Skills 机制了。关于这部分的内容，我将会在《[[Agent 的进阶应用]]》这一篇笔记中进行详细介绍。</p>\n<h2 id=\"结束语\">结束语</h2>\n<p>在完成了对 AI Agent 的学习与实践之后，我最为明显的体会之一是：Agent 并没有让系统变得更简单，反而让系统的边界变得更加清晰。与传统的自动化脚本或工具不同，Agent 并不是一组固定规则的集合，而是一个基于语言模型进行任务理解、规划与执行的系统组件。这意味着，在很多场景下，它所做的并不是“按预期运行”，而是“尽力完成任务”。</p>\n<p>正因如此，Agent 的引入并没有削弱人类在系统中的作用，反而对人的判断能力提出了更高要求：<br />\n我们需要能够理解 Agent 在做什么、为什么这么做，以及在什么情况下应该介入、修正甚至中止它的行为。从这个角度来看，学习和使用 AI Agent，并不意味着把控制权完全交给 AI，而是学会如何在一个由 AI 参与执行的系统中，重新定位人的职责与边界。这也正是本学习阶段的核心目标。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>\n<p>官方文档：</p>\n<ul>\n<li><a href=\"https://code.claude.com/docs/zh-CN/overview?utm_source=copilot.com\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code 官方文档</a></li>\n<li><a href=\"https://opencode.doczh.com/docs/\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode 官方文档</a></li>\n<li><a href=\"https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers\" rel=\"noopener nofollow\" target=\"_blank\">基于 Agent skills 和 MCP 服务的协同工作流</a></li>\n<li><a href=\"https://docs.openclaw.ai/zh-CN\" rel=\"noopener nofollow\" target=\"_blank\">OpenClaw 官方文档</a></li>\n</ul>\n</li>\n<li>\n<p>视频教程：</p>\n<ul>\n<li>Claude Code 教程：<a href=\"https://www.youtube.com/watch?v=AT4b9kLtQCQ\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV14rzQB9EJj\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n<li>OpenClaw +飞书的工具流搭建过程：<a href=\"https://www.youtube.com/watch?v=giv63OtX720\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV1rvcpzDEsH\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n</ul>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-18 16:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">91</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": ".NET 10 & C# 14 New Features 新增功能介绍-扩展成员Extension Members",
      "link": "https://www.cnblogs.com/tianqing/p/19622970",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tianqing/p/19622970\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 11:20\">\n    <span>.NET 10 &amp; C# 14 New Features 新增功能介绍-扩展成员Extension Members</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"p1\"><span class=\"s1\">C# 14 引入了对扩展成员（Extension Members）的增强支持，本质上是对传统“扩展方法”模型的一次语言级升级，使其可以定义的不再仅限于方法，</span></p>\n<p class=\"p1\"><span class=\"s1\">而是可以扩展更多成员形态（例如属性、运算符等）。</span></p>\n<p class=\"p1\"><strong><span class=\"s1\" style=\"font-size: 16px;\">一、从扩展方法到扩展成员</span></strong></p>\n<p class=\"p1\">早在 <a><span class=\"s1\">C# 3.0</span></a> 中，就引入了“扩展方法（Extension Methods）”，其底层机制是：</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">必须定义在 static class</span></p>\n</li>\n<li>\n<p class=\"p1\">方法必须是 <span class=\"s1\">static</span></p>\n</li>\n<li>\n<p class=\"p1\">第一个参数使用 <span class=\"s1\">this T</span></p>\n</li>\n</ul>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> StringExtensions\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsNullOrEmptyEx(<span style=\"color: rgba(0, 0, 255, 1);\">this</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\"> value)\n        </span>=&gt; <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">.IsNullOrEmpty(value);\n}</span></pre>\n</div>\n<p>从本质上看：</p>\n<blockquote>编译器在语法层面做“糖化处理”，最终仍然是静态方法调用。</blockquote>\n<p><span class=\"s1\">LINQ就是最大的应用场景。</span></p>\n<p><strong><span class=\"s1\" style=\"font-size: 16px;\">二、C# 14中引入扩展成员和示例说明</span></strong></p>\n<p class=\"p1\">C# 14 允许在更自然的语法结构中声明扩展成员，不再局限于“静态类 + this 参数”模式，而是支持类似：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Enumerable\n{\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension block</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension members for IEnumerable&lt;TSource&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsEmpty =&gt; !<span style=\"color: rgba(0, 0, 0, 1);\">source.Any();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, <span style=\"color: rgba(0, 0, 255, 1);\">bool</span>&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> predicate) { ... }\n    }\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension block, with a receiver type only</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension members for IEnumerable&lt;Source&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Combine(IEnumerable&lt;TSource&gt; first, IEnumerable&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> second) { ... }\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Identity =&gt; Enumerable.Empty&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static user defined operator:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; <span style=\"color: rgba(0, 0, 255, 1);\">operator</span> + (IEnumerable&lt;TSource&gt; left, IEnumerable&lt;TSource&gt; right) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> left.Concat(right);\n    }\n}</span></pre>\n</div>\n<p class=\"p1\"><span class=\"s1\">定义的是一个 extension block<span class=\"s1\">，目标类型是：IEnumerable&lt;TSource&gt;</span></span></p>\n<p class=\"p1\">代码分成两类 extension block：　　</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\"><strong>实例扩展成员</strong></p>\n</li>\n<li>\n<p class=\"p1\"><strong>静态扩展成员</strong></p>\n</li>\n</ol>\n<p>① 实例扩展成员：extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)&nbsp;</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">source 是接收者（receiver）</span></p>\n</li>\n<li>\n<p class=\"p1\"><span class=\"s1\">类似旧语法的 this IEnumerable&lt;TSource&gt; source</span></p>\n</li>\n<li>\n<p class=\"p1\">但语法更接近真正“为类型添加成员”</p>\n</li>\n</ul>\n<p>&nbsp;扩展属性：public bool IsEmpty =&gt; !source.Any();</p>\n<p class=\"p1\">&nbsp;编译器会生成：public static bool get_IsEmpty&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)</p>\n<p class=\"p1\">&nbsp;代码调用：list.IsEmpty</p>\n<p class=\"p1\">&nbsp;会被编译为：Enumerable.get_IsEmpty(list)</p>\n<p class=\"p1\">&nbsp;其本质仍然是：</p>\n<blockquote>静态方法 + 语法糖绑定</blockquote>\n<p class=\"p1\">但在语义层面：它已经不再是“工具方法”，而是“类型能力”。</p>\n<p class=\"p1\">扩展方法：public IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, bool&gt; predicate)</p>\n<p class=\"p1\">即增强原有LINQ的Where功能</p>\n<p class=\"p1\"><span class=\"s1\">如果系统中已有 System.Linq.Enumerable.Where<span class=\"s1\">：</span></span></p>\n<ul>\n<li>\n<p class=\"p1\">实例成员优先</p>\n</li>\n<li>\n<p class=\"p1\">然后才是 extension block</p>\n</li>\n<li>\n<p class=\"p1\">再是 using 引入的扩展方法</p>\n</li>\n</ul>\n<p>&nbsp;不会破坏已有 API，只是参与候选集。</p>\n<p class=\"p1\">② 静态扩展成员</p>\n<p class=\"p1\">extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;)</p>\n<p class=\"p1\">这里没有 receiver 变量名。</p>\n<blockquote>为类型本身添加“静态扩展成员”</blockquote>\n<p class=\"p1\">找一个静态扩展方法</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Combine(...)</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Combine(a, b);</p>\n<p class=\"p1\">编译器会转化为：Enumerable.Combine(a, b);</p>\n<p class=\"p1\">再看一个静态扩展属性</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Identity</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Identity</p>\n<p class=\"p1\">这在旧扩展方法体系中是无法表达的。</p>\n<p class=\"p1\">再看一个扩展运算符</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; operator +</p>\n<p class=\"p1\">这是 C# 14 的重大增强点。现在你可以写：</p>\n<p class=\"p1\">var result = list1 + list2;</p>\n<p class=\"p1\">等价于：Enumerable.op_Addition(list1, list2);</p>\n<p class=\"p1\"><strong><span style=\"font-size: 16px;\">三、底层编译机制</span></strong></p>\n<p class=\"p1\">&nbsp;<strong>不修改 CLR 元数据</strong></p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">不改变 IEnumerable&lt;T&gt;</span></p>\n</li>\n<li>\n<p class=\"p1\">不增加真实成员</p>\n</li>\n</ul>\n<p>&nbsp;<strong>IL 仍然是静态方法</strong></p>\n<p>&nbsp; &nbsp;所有成员都会生成：&nbsp;public static ...</p>\n<p class=\"p1\">&nbsp;<strong>语义绑定由编译器完成</strong></p>\n<p class=\"p1\">扩展成员解析规则：</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\">实例真实成员</p>\n</li>\n<li>\n<p class=\"p1\">同 namespace extension block</p>\n</li>\n<li>\n<p class=\"p1\">using 导入 extension block</p>\n</li>\n</ol>\n<p>&nbsp;<strong><span style=\"font-size: 16px;\">四、与传统扩展方法对比</span></strong></p>\n<p>&nbsp; &nbsp;<img alt=\"image\" height=\"246\" src=\"https://img2024.cnblogs.com/blog/23525/202602/23525-20260218111804828-477864692.png\" width=\"657\" /></p>\n<p>同时，零运行时开销。</p>\n<ul>\n<li>\n<p class=\"p1\">无反射</p>\n</li>\n<li>\n<p class=\"p1\">无动态代理</p>\n</li>\n<li>\n<p class=\"p1\">无装饰器</p>\n</li>\n<li>\n<p class=\"p1\">无运行时注入</p>\n</li>\n</ul>\n<p>&nbsp;完全编译期绑定。</p>\n<blockquote>编译器级语义增强，不改变运行时类型结构。</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;以上分享给大家。</p>\n<p>&nbsp;</p>\n<p>周国庆</p>\n<p>20260218</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 11:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tianqing\">Eric zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">128</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "这也行？按键动作模式识别也能用贝叶斯？",
      "link": "https://www.cnblogs.com/pie-o/p/19622890",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/pie-o/p/19622890\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:38\">\n    <span>这也行？按键动作模式识别也能用贝叶斯？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        基于朴素贝叶斯对按键动作进行模式识别的一次学习实验\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><a href=\"https://bbs.21ic.com/icview-3503975-1-1.html\" rel=\"noopener nofollow\" target=\"_blank\">首发于21ic论坛</a></p>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>之前学习了贝叶斯更新的相关内容，正好现在也在玩开发板，板子上面有几个小的单击按键，一般识别按键动作的做法就很简单，不是中断就是查询，基本都是靠边沿或者电平的状态来进行的，这一套就很无聊，没有实现的欲望，所以想用点不一样的方法。</p>\n<p>这就有了本片文章的出现，基于<code>朴素贝叶斯分类</code>，使用滑动窗口捕捉电平序列，提取特征进行模式识别，理想情况下识别效果杠杠的，但是出现边界以及混合的情况，效果一言难尽，目前水平不够，这应该也是后续需要解决的主要问题了。</p>\n<h2 id=\"技术要点\">技术要点</h2>\n<h3 id=\"核心原理\">核心原理</h3>\n<ol>\n<li>贝叶斯定理</li>\n</ol>\n<p>本文实现的方法基于朴素贝叶斯分类器，主要就是两方面内容：<code>贝叶斯定理</code>与<code>条件独立假设</code>，涉及的概念有<strong>先验概率</strong>、<strong>后验概率</strong>和<strong>条件概率</strong>，其中先验和条件概率都是提前准备好的，可以是主观经验的，也可以是统计量化的，而贝叶斯定理中的条件概率(不是后验概率)，又称为似然概率。</p>\n<p>这个方法的基本思想是：对于给定的待分类项(就是窗口中的电平序列)，求解当这个待分类项出现时，各个<strong>已经定义过</strong>的模式类别出现的概率，哪个概率最大，那么这个待分类项就属于哪个模式。</p>\n<p>在开始分类之前需要一些必要的准备工作：</p>\n<ul>\n<li>定义有哪些模式类别，这些模式边界要明确，不然不容易分析特征</li>\n<li>定义这些模式的特征属性，这些属性在不同模式下的表现是不同的，这是识别的关键，对应了贝叶斯定理中的似然概率</li>\n</ul>\n<ol start=\"2\">\n<li>滑动窗口</li>\n</ol>\n<p>这里的窗口是实时更新的窗口，老数据移出，新数据加入，滑动窗口确定电平序列数据的范围，只有处在窗口中的序列数据才会得到特征提取的机会，它的长度与序列的时间长度成比例，也就是说采样频率会影响到窗口时效性。</p>\n<p>它需要考虑的问题是怎么捕捉到完整的信号，对应于滑动的步长，以及特征提取的周期。</p>\n<h3 id=\"基本步骤\">基本步骤</h3>\n<p>通过以下步骤实现按键动作模式识别：</p>\n<ol>\n<li><strong>滑动窗口采集</strong>：使用固定大小的滑动窗口持续采集按键状态数据</li>\n<li><strong>特征提取</strong>：从窗口数据中提取多个维度的特征</li>\n<li><strong>概率计算</strong>：基于先验概率和<strong>似然概率</strong>计算后验概率</li>\n<li><strong>模式判断</strong>：根据后验概率和<strong>阈值</strong>确定当前按键模式</li>\n</ol>\n<h2 id=\"具体实现\">具体实现</h2>\n<p>为了验证设想的可行性，通过逻辑分析仪记录按键的引脚电平变化，低电平表示按键按下，高电平表示无按键动作，采样率1MHz，时长20s，在后面的实验中，认为序列是连续的，这就是电平序列的来源，具体序列如下图所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上面记录的数据可以作为一个样本，我通过观察和测量确定了几种模式，以及一些帮助识别的特征属性，在实验过程中使用<code>python</code>进行了方法验证。</p>\n<h3 id=\"模式定义\">模式定义</h3>\n<p>我在设计过程中定义了四种按键模式，分别如下：</p>\n<ul>\n<li><strong>无效</strong>：无有效按键动作</li>\n<li><strong>单击</strong>：单次短暂按键动作</li>\n<li><strong>双击</strong>：快速连续两次按键动作</li>\n<li><strong>长按</strong>：持续时间较长的按键动作</li>\n</ul>\n<p>动作的实施都是通过一个单按键来进行的，其中单击和双击涉及到电平的较快速变化，是识别的难点</p>\n<h3 id=\"特征选择\">特征选择</h3>\n<p>基于对提取的特征包括：</p>\n<ul>\n<li><strong>高电平占比</strong>：窗口内高电平信号的比例</li>\n<li><strong>上升沿数量</strong>：信号从低到高的转换次数</li>\n<li><strong>下降沿数量</strong>：信号从高到低的转换次数</li>\n<li><strong>最长连续高电平持续时间</strong>：窗口内持续高电平的最长时间</li>\n</ul>\n<h3 id=\"概率模型\">概率模型</h3>\n<ul>\n<li><strong>先验概率</strong>：初始假设四种模式等概率出现，即每个模式的先验都是0.25。并且和一般的贝叶斯方法不同的是，在实现过程中认为先验是不需要更新的，也就是在每一次识别时认为每个模式都是<strong>等概率</strong>出现的，没有转移概率或者历史因素影响</li>\n<li><strong>似然概率</strong>：基于<strong>特征分布参数</strong>计算观测到当前特征的概率，其中的分布参数是根据实际捕捉的序列数据来设计的，概率分布模型采用正态分布来<strong>近似</strong>，需要均值和标准差，统一使用<em>概率密度</em>表达似然结果\n<ul>\n<li>高电平占比的分布参数\n<ul>\n<li>无效：0.05，0.2</li>\n<li>单击：0.2，0.2</li>\n<li>双击：0.3，0.2</li>\n<li>长按：0.9，0.2</li>\n</ul>\n</li>\n<li>(上升沿/下降沿)数量的分布参数\n<ul>\n<li>无效：0.1，0.3</li>\n<li>单击：1，0.3</li>\n<li>双击：2，0.3</li>\n<li>长按：0.7，0.3</li>\n</ul>\n</li>\n<li>最长高电平持续时间的分布参数\n<ul>\n<li>无效：0，2</li>\n<li>单击：0.2，5</li>\n<li>双击：0.17，3</li>\n<li>长按：0.9，10</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>后验概率</strong>：使用贝叶斯公式计算各模式的后验概率，先计算提取的特征在每个模式下的<em>联合似然</em>，基于条件独立假设，可以直接相乘，然后计算后验并归一化可得最终的概率表</li>\n</ul>\n<h3 id=\"代码实现\">代码实现</h3>\n<ol>\n<li>数据采集与预处理</li>\n</ol>\n<p>把逻辑分析仪中的数据导出为csv文件，代码首先实现了&nbsp;read_sigrok_csv_simple&nbsp;函数，用于读取 sigrok CSV 格式的按键数据：</p>\n<pre><code class=\"language-python\">def&nbsp;read_sigrok_csv_simple(filename):\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data&nbsp;=&nbsp;[]\n&nbsp;&nbsp;&nbsp;&nbsp;signal_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;open(filename,&nbsp;'r',&nbsp;newline='')&nbsp;as&nbsp;csvfile:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reader&nbsp;=&nbsp;csv.reader(csvfile)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;row&nbsp;in&nbsp;reader:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过注释行和空行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;row&nbsp;or&nbsp;row[0].startswith(';'):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;确保行有两个列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(row)&nbsp;&gt;=&nbsp;2:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_val&nbsp;=&nbsp;float(row[0])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data_val&nbsp;=&nbsp;float(row[1])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_data.append(time_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;signal_data.append(data_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;except&nbsp;ValueError:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过无法转换为数字的行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;time_data,&nbsp;signal_data\n</code></pre>\n<p>该函数读取 CSV 文件中的时间戳和信号值，返回两个列表分别存储时间数据和信号数据，通过plot输出采样的数据图如下所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>识别器类设计</li>\n</ol>\n<p>核心实现是&nbsp;BayesianButtonRecognizer&nbsp;类，用于实现基于贝叶斯分类的按键模式识别：</p>\n<pre><code class=\"language-python\">class&nbsp;BayesianButtonRecognizer:\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"基于滑动窗口和贝叶斯更新的按键模式识别器\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;__init__(self,&nbsp;window_size=20,&nbsp;sample_interval=0.01,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.7):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;初始化识别器\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Args:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;window_size:&nbsp;滑动窗口大小\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_interval:&nbsp;采样间隔(秒)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;threshold:&nbsp;判定阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window_size&nbsp;=&nbsp;window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.sample_interval&nbsp;=&nbsp;sample_interval\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.threshold&nbsp;=&nbsp;threshold\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;滑动窗口存储最近的观测序列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window&nbsp;=&nbsp;deque(maxlen=window_size)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;模式类别\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.modes&nbsp;=&nbsp;['无效',&nbsp;'单击',&nbsp;'双击',&nbsp;'长按']\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;先验概率&nbsp;-&nbsp;初始等可能\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.prior&nbsp;=&nbsp;np.array([0.25,&nbsp;0.25,&nbsp;0.25,&nbsp;0.25])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征提取相关的参数(单位:采样点数)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.short_press_max&nbsp;=&nbsp;15&nbsp;&nbsp;#&nbsp;短按最大持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.long_press_min&nbsp;=&nbsp;30&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按最小持续时间&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.double_click_interval&nbsp;=&nbsp;10&nbsp;&nbsp;#&nbsp;双击间隔阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;初始化特征分布参数(基于物理理解预设)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self._init_feature_distributions()\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征权重\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.featwight={\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"无效\":np.array([1.2,0.8,0.8,1.2]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"单击\":np.array([1,1.2,1.2,1]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"双击\":np.array([1,1.2,1.2,0.8]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"长按\":np.array([1.2,0.8,0.8,1.2])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"3\">\n<li>特征分布初始化</li>\n</ol>\n<p>识别器初始化时设置了各模式下特征的概率分布参数：</p>\n<pre><code class=\"language-python\">def&nbsp;_init_feature_distributions(self):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"初始化各模式下特征的概率分布参数\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;高电平占比的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.high_ratio_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.05,&nbsp;&nbsp;&nbsp;#&nbsp;无效时高电平占比很低\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;0.2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有短暂高电平\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;0.3,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时高电平占比稍高\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按时高电平占比很高\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;上升沿数量的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.rise_count_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时几乎无上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时有2个上升沿&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;最长高电平持续时间的分布参数(正态分布:均值,标准差)\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.max_duration_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;(0,&nbsp;2),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时持续时间很短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;(0.2,&nbsp;5),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击中等持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;(0.17,&nbsp;3),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击每次按下时间短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;(0.9,&nbsp;10)&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按持续时间长\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"4\">\n<li>特征提取</li>\n</ol>\n<p>从滑动窗口数据中提取特征，其中高电平占比是通过求序列平均值来获得的，然后边沿计数对应了记录序列跳变数量，最长高电平时间通过记录连续高电平时长获取：</p>\n<pre><code class=\"language-python\">def&nbsp;extract_features(self,&nbsp;window_data):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"从滑动窗口数据中提取特征\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(window_data)&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;None\n\n&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;=&nbsp;np.array(window_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征1:&nbsp;高电平占比\n\n&nbsp;&nbsp;&nbsp;&nbsp;high_ratio&nbsp;=&nbsp;np.mean(data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征2:&nbsp;上升沿数量(0-&gt;1的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;0&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征3:&nbsp;下降沿数量(1-&gt;0的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;1&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征4:&nbsp;最长连续高电平持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;val&nbsp;in&nbsp;data:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;val&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;max(max_duration,&nbsp;current_duration)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'high_ratio':&nbsp;high_ratio,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'rise_count':&nbsp;rises,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'fall_count':&nbsp;falls,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'max_duration':&nbsp;max_duration\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"5\">\n<li>似然概率计算</li>\n</ol>\n<p>计算给定模式下观测到特征值的似然概率，即条件概率，通过上面定义的分布参数，使用<code>正态分布</code>近似，在python中通过<code>stats.norm.pdf</code>求特征对应每个模式的似然程度，然后基于条件独立的假设，求解联合似然，表示样本对某一模式的最终似然结果：</p>\n<pre><code class=\"language-python\">def&nbsp;calculate_likelihood(self,&nbsp;features,&nbsp;mode):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"计算给定模式下观测到特征值的似然概率\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;features&nbsp;is&nbsp;None:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1.0&nbsp;&nbsp;#&nbsp;无特征时返回中性似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用概率密度函数计算各特征的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;1.&nbsp;高电平占比的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_ratio&nbsp;=&nbsp;self.high_ratio_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用正态分布近似,&nbsp;标准差根据经验设定\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_ratio&nbsp;=&nbsp;stats.norm.pdf(features['high_ratio'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_ratio,&nbsp;0.2)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_ratio&nbsp;+&nbsp;1e-10)&nbsp;&nbsp;#&nbsp;避免零\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;2.&nbsp;上升沿数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_rises&nbsp;=&nbsp;stats.norm.pdf(features['rise_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_rises&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;3.&nbsp;下降沿(同上升沿)数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_falls&nbsp;=&nbsp;stats.norm.pdf(features['fall_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_falls&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;4.&nbsp;最长持续时间的似然(使用正态分布)\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur&nbsp;=&nbsp;self.max_duration_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur&nbsp;*=&nbsp;self.window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_duration&nbsp;=&nbsp;stats.norm.pdf(features['max_duration'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_duration&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;组合各特征的似然(假设特征条件独立)\n\n&nbsp;&nbsp;&nbsp;&nbsp;total_likelihood&nbsp;=&nbsp;np.prod(np.array(likelihoods))\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征在mode[%s]的似然：\"%{mode},likelihoods,\"最终联合似然:%.\n\n&nbsp;&nbsp;&nbsp;&nbsp;3f\"%total_likelihood)\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;total_likelihood\n</code></pre>\n<ol start=\"6\">\n<li>滑动窗口更新</li>\n</ol>\n<pre><code class=\"language-python\">def&nbsp;slide_window(self,io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;移除最旧的值\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.popleft()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;将新观测值加入滑动窗口\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.append(io_state)\n</code></pre>\n<ol start=\"7\">\n<li>信念更新与模式判断</li>\n</ol>\n<p>计算完样本对每个模式的似然后，就于先验概率相乘，就得到了后验概率，然后归一化得到最终结果，同时使用阈值判定机制，当最大后验超过判定阈值后，才会识别具体模式，否则就是不确定</p>\n<pre><code class=\"language-python\">def&nbsp;update_belief(self,&nbsp;io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"根据新观测值更新信念\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;提取当前窗口的特征\n\n&nbsp;&nbsp;&nbsp;&nbsp;features&nbsp;=&nbsp;self.extract_features(self.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征提取：\",features)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;计算各模式的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;np.array([self.calculate_likelihood(features,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;mode)&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;mode&nbsp;in&nbsp;self.modes])\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;贝叶斯更新:&nbsp;后验&nbsp;∝&nbsp;似然&nbsp;×&nbsp;先验\n\n&nbsp;&nbsp;&nbsp;&nbsp;unnormalized_posterior&nbsp;=&nbsp;likelihoods&nbsp;*&nbsp;self.prior\n\n&nbsp;&nbsp;&nbsp;&nbsp;evidence&nbsp;=&nbsp;np.sum(unnormalized_posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;evidence&nbsp;&gt;&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;unnormalized_posterior&nbsp;/&nbsp;evidence\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;self.prior.copy()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;更新先验(用于下一次迭代)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;self.prior&nbsp;=&nbsp;posterior\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;判断当前模式\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_mode_idx&nbsp;=&nbsp;np.argmax(posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_prob&nbsp;=&nbsp;posterior[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"后验：\",posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;best_prob&nbsp;&gt;&nbsp;self.threshold:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;self.modes[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;'不确定'\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;detected_mode,&nbsp;posterior\n</code></pre>\n<ol start=\"8\">\n<li>主函数与演示</li>\n</ol>\n<p>因为定义了高电平为有效电平，但实际中低电平，或者说下降沿是按键动作的反应，所以处理数据序列时做了相应的取反处理。</p>\n<pre><code class=\"language-python\">if&nbsp;__name__&nbsp;==&nbsp;\"__main__\":\n\n&nbsp;&nbsp;&nbsp;&nbsp;DeltaT&nbsp;=&nbsp;0.01 # 采样间隔\n\n&nbsp;&nbsp;&nbsp;&nbsp;UnitTime&nbsp;=&nbsp;1e-06 # 原始数据点的时基\n\n&nbsp;&nbsp;&nbsp;&nbsp;SampleInterval&nbsp;=&nbsp;math.floor(DeltaT&nbsp;/&nbsp;UnitTime)\n\n&nbsp;&nbsp;&nbsp;&nbsp;filename&nbsp;=&nbsp;\"key_data_20s_all.csv\"&nbsp;&nbsp;#&nbsp;逻辑分析仪导出的数据\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer&nbsp;=&nbsp;BayesianButtonRecognizer(window_size=100,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.8)\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer.reset()\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data,&nbsp;signal_data&nbsp;=&nbsp;read_sigrok_csv_simple(filename)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"成功读取数据，共&nbsp;{len(time_data)}&nbsp;个数据点\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"时间范围:&nbsp;{time_data[0]}s&nbsp;到&nbsp;{time_data[-1]}s\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;res_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_num&nbsp;=&nbsp;math.floor(len(signal_data)&nbsp;/&nbsp;SampleInterval)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"sample&nbsp;size&nbsp;is:\",sample_num)\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(sample_num-1):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_data.append(int(not&nbsp;signal_data[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;recognizer.slide_window(int(not&nbsp;signal_data\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;i%recognizer.window_size==0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res,postrior=recognizer.update_belief(i)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(res&nbsp;not&nbsp;in[\"不确定\",\"无效\"]):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res_data.append(res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(\"win[%d]:\"%i,res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(recognizer.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(sample_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(res_data)\n</code></pre>\n<p>当窗口中样本序列是理想情况时，识别效果相当好：</p>\n<p>无效样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个无效按键样本序列图，保持无效电平，没有边沿变化。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，高电平占比为0，边沿计数为0，最长高电平延时为0，在各个模式的似然列表中，给出了对应的似然结果，同时从列数据对比来看，也可以直接从数值上看出样本特征更偏向哪个模式，最终的后验结果，确实是无效模式的概率最高，即判定窗口中的序列为无效。</p>\n<p>单击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个单击按键样本序列图，有边沿变化，一个上升沿，一个下降沿，高电平占比大约0.2。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，最终的识别结果也是正确的</p>\n<p>双击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个双击样本的示例图，可以看到由两个高电平组成，下图给出识别过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出特征提取信息正确，有两个上升沿和两个下降沿，然后最终的后验概率中也是双击的概率最大，并且超过阈值判定正确。</p>\n<p>下面给出一些因为信号完整性缺失造成的误判示例。</p>\n<p>边界双击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图中可以看出很明显是一个双击的动作，但是由于窗口长度固定的原因，导致一部分序列缺失，下图给出识别结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征提取的信息倒是正确的，识别出下降沿只有1个，在计算似然过程中，相应位置的似然结果也反应了这一点，最终的后验表中可以看到前两个大的概率是单击和双击，但是都没超过阈值，所以判定为不确定</p>\n<p>边界单击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出这个情况像是单击，但是实际上是一段长按序列，下图给出识别过程：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征信息提取是正确的，然后似然结果都偏低，表示不偏向某一个模式，但在最终的后验结果中单击的后验概率异常的高，应该是在归一化过程中，单击概率占比比其他概率大很多导致的，这也是同样的问题，也就是信号完整性缺失导致了误判</p>\n<h2 id=\"总结\">总结</h2>\n<p>在这次实验中，基于朴素贝叶斯分类方法，通过<em>滑动窗口</em>采集数据、提取多维度特征、计算概率分布和应用贝叶斯更新，学到了不少，也融合了很多内容，算是一次不小的学习体验吧，虽然目前测试下来效果有限，还无法真正用在项目中，也总结了一些不足的地方。</p>\n<p>比如信号完整性保证不了，不同特征属性对不同模式的权重实际并不一致等，这些都是需要解决的问题，虽然对现在的我来说很困难，但探索新方法的过程还是蛮喜欢的，也可能是对现有方法的审美疲劳导致的吧。</p>\n<p>但有一说一，传统的方法，还是简单高效的，也不涉及到什么数学的内容，全凭逻辑加判断就可以搞定了，真是省时省力啊。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/pie-o/\" target=\"_blank\">pie_thn</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/pie-o/p/19622890\" target=\"_blank\">https://www.cnblogs.com/pie-o/p/19622890</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:38</span>&nbsp;\n<a href=\"https://www.cnblogs.com/pie-o\">pie_thn</a>&nbsp;\n阅读(<span id=\"post_view_count\">61</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]基于Checkpoint的持久化",
      "link": "https://www.cnblogs.com/jaydenai/p/19622525/checkpoint-persistent",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19622525/checkpoint-persistent\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 08:40\">\n    <span>[拆解LangChain执行引擎]基于Checkpoint的持久化</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Pregel基于Checkpoint的持久化机制是实现Agent应用`高可用性`和`长期记忆`的基础，它本质上是将 不断向前推进的图在“Superstep”之间将其状态固化的过程。和很多数据库持久化类似，Pregel采用`基于全量数据的状态快照+基于增量更新的操作日志`的持久化策略。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Pregel基于Checkpoint的持久化机制是实现Agent应用<code>高可用性</code>和<code>长期记忆</code>的基础，它本质上是将 不断向前推进的图在“Superstep”之间将其状态固化的过程。和很多数据库持久化类似，Pregel采用<code>基于全量数据的状态快照+基于增量更新的操作日志</code>的持久化策略。</p>\n<h2 id=\"1-持久化channel状态\">1. 持久化Channel状态</h2>\n<p>Pregel将状态“焊死”在Channel上，这使持久化变得很简单，它只要针对每个Superstep将每个Channel状态存下来就可以了。为了提高性能，它只需要考虑有过更新的Channel，而确Channel是否更新可以利用它的版本来决定。每个Channel都具有一个不断更新的版本，如果某个Channel在某个Superstep内有过更新，版本会往前更替。至于这个版本采用何种格式，具体如何管理，执行引擎将其下放到具体的Checkpointer实现中。</p>\n<p>作为Checkpointer的基类，<code>BaseCheckpointSaver</code>将基于更新快照的存储实现在如下所示的<code>put</code>方法中。待持久化的数据被封装在一个<code>Checkpoint</code>对象中以<code>checkpoint</code>参数传入该方法，<code>config</code>和<code>metadata</code>参数提供描述该Checkpoint的配置和元数据，而<code>new_versions</code>以一个字典的形式提供了涉及的每个Channel的版本。config参数提供的RunnableConfig主要提供标识当前调用会话的<code>Thread ID</code>和<code>Checkpoint命名空间</code>。方法会返回的RunnableConfig对象一般会携带<code>Thread ID</code>、<code>Checkpoint命名空间</code>和<code>Checkpoint ID</code>。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def put(\n        self,\n        config: RunnableConfig,\n        checkpoint: Checkpoint,\n        metadata: CheckpointMetadata,\n        new_versions: ChannelVersions,\n    ) -&gt; RunnableConfig\n\n    async def aput(\n        self,\n        config: RunnableConfig,\n        checkpoint: Checkpoint,\n        metadata: CheckpointMetadata,\n        new_versions: ChannelVersions,\n    ) -&gt; RunnableConfig\n    …\nChannelVersions = dict[str, str | int | float]\n</code></pre>\n<h3 id=\"11-checkpointmetadata\">1.1 CheckpointMetadata</h3>\n<p>描述Checkpoint元数据的<code>CheckpointMetadata</code>类型定义如下，其三个成员构成了图执行的谱系追踪（Lineage Tracking）和控制流导航的核心。它们不参与业务逻辑计算，但决定了如何管理、回溯和审计图的状态。</p>\n<pre><code class=\"language-python\">class CheckpointMetadata(TypedDict, total=False):\n    source: Literal[\"input\", \"loop\", \"update\", \"fork\"]\n    step: int\n    parents: dict[str, str]\n</code></pre>\n<p>CheckpointMetadata的<code>step</code>字段返回Superstep编号，代表当前Checkpoint在逻辑时间轴上的位置。<code>source</code>字段定义了当前这个Checkpoint是由哪种类型的操作触发生成的，它是理解图<code>生命历程</code>的关键，具体的选项包括：</p>\n<ul>\n<li>\n<p>input: 首次调用invoke或stream方法时触发，代表图的“创世点”。这是由外部初始数据输入产生的第一个Checkpoint（Superstep序号为 -1）；</p>\n</li>\n<li>\n<p>loop：内部根据 Node 和 Channel 的订阅关系进行迭代时触发，代表图在正常执行流程中的自动化流转。大多数中间步骤的 source 都是此值。</p>\n</li>\n<li>\n<p>update：用户手动调用了update_state方法时触发，代表一种“非自然”的状态变更。这通常用于人为干预、修正数据或在中断后注入信息。</p>\n</li>\n<li>\n<p>fork: 当用户从历史中的某个非最新Checkpoint重新启动执行时触发，代表图产生了分支。它标记了执行流从主线脱离，开启了一个独立的时间线。</p>\n</li>\n</ul>\n<p>CheckpointMetadata的<code>parents</code>字段返回一个字典，记录了当前Checkpoint与之前Checkpoint之间的拓扑关系，其结果通常为通常形式为dict[namespace, parent_checkpoint_id]。由于 采用增量持久化，当我们需要恢复一个完整的状态视图时，引擎必须知道去哪里找那些没变动的数据，parents字典提供了回溯路径。如果当前 Checkpoint 没有 某个Channel的值，引擎就会根据parents指引，跳转到父级Checkpoint去查找，直到找到该 Channel最近一次被更新的版本。</p>\n<p>在包含子图的复杂场景中，parents字段会记录父图命名空间对应的Checkpoint ID，确保父子图之间的状态逻辑能够跨层级对齐。当source为“fork”时，parents字段指向的是那个被分叉的历史点，而不是时间线上的物理前一个点。</p>\n<p>当我们查看一个CheckpointMetadata对象时，可以构建出如下逻辑：这个状态是由于<code>source</code>产生的，目前处于第<code>step</code>步。如果你想知道这个状态从何而来，或者想找回那些没变的数据，请根据<code>parents</code>列表向回追溯。</p>\n<h3 id=\"12-channel版本\">1.2 Channel版本</h3>\n<p>执行引擎将Channel版本的格式化权力下放给具体的Checkpointer实现，它们通过重写如下这个<code>get_next_version</code>方法提供某个Channel的下一个版本。如果表示当前版本的current参数为None，该方法会返回Channel的初始版本。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def get_next_version(self, current: V | None, channel: None) -&gt; V\n</code></pre>\n<p>以InMemorySaver为例，它会将Channel版本格式化成一个由51个字符组成的字符串，具体格式为<code>f\"{sequence:032}.{random:016}\"</code>。sequence从1开始递增，代表了“物理状态的演进顺序”。在顺序执行时反映了Superstep的进度，但是在遇到人为干预、中断、分叉或重试的情况下，物理序列号仅能反映“存盘的次数”。Superstep序号反映的是“算法迭代的深度”，所以不能将两者等同起来，前者是大于或等于Superstep序号的。</p>\n<p>“random”部分是一个0-1之间的随机数。如果说Channel版本前 32 位（第一部分）是时间轴上的<code>大刻度</code>，那么这第二部分就是确保状态在微观层面绝对唯一且可追溯的<code>防伪码</code>。由于 CPU 处理速度极快，多个并行任务可能在极短的微秒级时间内尝试触发写入。如果仅依靠前 32 位的递增序列号，在Superstep内部的多次写入可能会因为序列号来不及递增或在高并发下产生冲突。第二部分包含的随机数（源自浮点数的小数位）确保了即使第一部分相同，物理上的 Checkpoint ID 也是全球唯一的，这保证了UUID 级别的碰撞安全性。</p>\n<p>从支持<code>时间旅行</code>与<code>状态分叉</code>的角度来看，第二部分就显得更加重要了。当我们从某个历史点重启时流程时，假设从历史上的“00...001”处分叉出两条不同的执行路径，两条路径的序列号可能都会递增到“00...002”，但通过第二部分的随机随机值，系统能以如下形式物理隔离这两条路径。所以版本的第二部分的内容不仅仅为了解决冲突而存在，它使得持久化层可以同时存储同一逻辑步下的多个平行宇宙而不会发生覆盖。</p>\n<ul>\n<li>路径 A: 00...002.0.8494...</li>\n<li>路径 B: 00...002.0.1234...</li>\n</ul>\n<p>有的实现会严格采用类似于<code>{ sequence}.{step_index}.{random_entropy}</code>这样的三段式的版本格式化，第二部分通常包含了.0. 或.1.这样的前缀，它还兼具如下的功能：</p>\n<ul>\n<li>子图导航：当主图调用子图时，子图产生的Checkpoint会通过第二部分的特定位来标识它属于哪个父级任务的“逻辑分支”。</li>\n<li>任务索引：在同一个Superstep中，如果一个Node产生了多条Pending Write，第二部分可以用来索引这些写入的先后次序，确保在恢复合并时不会错位。</li>\n</ul>\n<h3 id=\"13-checkpoint\">1.3 Checkpoint</h3>\n<p>如下所示的是Checkpoint类型的定义。它的<code>v</code>字段表示决定Checkpoint结构的版本号，用于后向兼容性。如果未来改变了存储格式，运行时会根据这个值决定如何正确地反序列化旧数据。<code>id</code>和<code>ts</code>分别表示Checkpoint的唯一标识和生成时间戳。<code>updated_channels</code>字段返回的本Superstep内涉及更新的Channel列表。引擎根据订阅它们的Node来创建下一步执行的任务。<code>channel_values</code>字段存储了“涉及更新”的每个Channel的更新值。<code>channel_versions</code>字段返回所有Channel的版本。</p>\n<pre><code class=\"language-python\">class Checkpoint(TypedDict):\n    v : int\n    id : str\n    ts : str\t\t\n    channel_values : dict[str, Any]\n    channel_versions : ChannelVersions\n    versions_seen : dict[str, ChannelVersions]\n    updated_channels : list[str] | None\n</code></pre>\n<p>Node并不能实时观察到Channel的变化，<code>versions_seen</code>字段以<code>{ \"Node名\": { \"依赖Channel名\": \"版本ID\" } }</code>这样的结构返回每个Node执行时所能“看到”的Channel版本， 它记录了Node完成计算时的前置条件。在中断恢复时，引擎对比<code>versions_seen</code>，如果Node看到的输入版本没变，且它已经有了输出记录，那么就无需重复执行，所以这是实现因果一致性和幂等性的关键。如下的JSON是由Pregel生成的一个Checkpoint对象序列化后的结果。</p>\n<pre><code class=\"language-json\">{\n  \"v\": 4,\n  \"ts\": \"2026-01-18T13:42:07.542155+00:00\",\n  \"id\": \"1f0f4737-b4b1-6bbb-8001-1e44d720a9df\",\n  \"channel_versions\": {\n    \"foo\": \"00000000000000000000000000000001.0.6943525017042773\",\n    \"bar\": \"00000000000000000000000000000002.0.24038201058058928\",\n    \"baz\": \"00000000000000000000000000000003.0.8444674692332181\"\n  },\n\n  \"versions_seen\": {\n    \"__input__\": {},\n    \"foo\": { \"foo\": \"00000000000000000000000000000001.0.6943525017042773\" },\n    \"bar\": { \"bar\": \"00000000000000000000000000000002.0.24038201058058928\" }\n  },\n\n  \"updated_channels\": [ \"baz\" ],\n  \"channel_values\": {\n    \"foo\": \"begin\",\n    \"bar\": \"bar\",\n    \"baz\": \"baz\"\n  }\n}\n</code></pre>\n<h3 id=\"14存储结构\">1.4\t存储结构</h3>\n<p>接下来，我们以<code>InMemorySaver</code>为例看看Checkpoint会采用怎样的存储结构，以及以此结构基础的读取方式。InMemorySave针对Checkpoint的存储涉及两个字典。一个名为<code>blobs</code>的字典用于存储Channel的荷载内容（值），采用的Key是由<code>Thread ID</code>、<code>Checkpoint命名空间</code>、<code>Channel名称</code>和<code>版本</code>构成的四元组。另一个名为<code>storage</code>的字典时一个具有四层结构的字典，具体类型为<code>defaultdict[str, dict[str, dict[str, tuple[tuple[str, bytes], tuple[str, bytes], str | None]]]]</code>，每一层字典的Key顶如下。我们可以认为blobs用于存储数据，storage为索引表。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">层级</th>\n<th style=\"text-align: left;\">Key 类型</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">第一层</td>\n<td style=\"text-align: left;\">Thread_id</td>\n<td style=\"text-align: left;\">会话隔离，区分不同的用户或对话流</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">第二层</td>\n<td style=\"text-align: left;\">Checkpoint_ns</td>\n<td style=\"text-align: left;\">命名空间隔离，支持子图或不同模块的独立状态空间</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">第三层</td>\n<td style=\"text-align: left;\">checkpoint_id</td>\n<td style=\"text-align: left;\">版本隔离，用于定位特定版本的快照</td>\n</tr>\n</tbody>\n</table>\n<p>最后一层字典的值是一个三元组<code>tuple[tuple[str, bytes], tuple[str, bytes], str | None]</code>，它们将数据序列化后存储，以确保内存中的数据是不可变且易于复制的，三个部分包括：</p>\n<ul>\n<li>tuple[str, bytes]：前一部分表示的序列化类型（通常是json或msgpack），第二部分表示经过序列化后的Checkpoint对象（由于具体的值已经存储在blobs中了，所以此时的Checkpoint的channel_values字段已经被移除）。这里不再存储 Python 字典对象，而是存储字节流。这模拟了数据库存取过程，并防止了Node在内存中意外修改已存盘的状态，实现对象的深度隔离。</li>\n<li>tuple[str, bytes]：Checkpoint元数据，前一部分同样表示序列化类型，第二部分为经过序列化后的CheckpointMetadata对象。</li>\n<li>str | None：父级checkpoint_id（这里的Parent与是否以子图形式执行没有关系，这里代表作为调用者的Node），InMemorySaver可以通过这个 ID在内存中顺着链条向上追溯，从而在恢复时合并增量状态。</li>\n</ul>\n<h2 id=\"2-持久化pending-write\">2. 持久化Pending Write</h2>\n<p>Checkpoint是在Superstep成功结束时针对Channel状态创建的，它并不能反映一个尚未结束Superstep内的真实状态。Pregel在执行过程中可以能出现不可预期的错误，或者需要人为介入导致可预期的中断，并行执行的任务就会出现部分部分成功、部分失败和中断的情况。对于成功执行的操作，它们针对目标Channel的写入并没有通过一个Checkpoint固定下来，仅仅属于一个<code>Pending Write</code>。如果这种中间状态没有被持久化，等下次恢复执行的时候，本来已经成功执行的任务还会重复执行，这是无法接受的。</p>\n<p>如果某个任务涉及到多次人为中断，每次恢复执行都需要提供<code>Resume Value</code>。如果这些Resume Value没有持久化，那么每次恢复调用提供的Resume Value永远都会提供给第一个中断，多次中断根本就没法实现，所以提供的Resume Value也需要以Pending Write的形式存储下来。</p>\n<p>持久化不仅仅需要将Superstep完成时将Channel的状态以Checkpoint固定下来，还需要将涉及到的所有Pending Write按照先后顺序记录下来。Pending Write不仅仅限于描述成功任务针对目标Channel的写入和依序提供Resume Value，任务在执行中抛出的异常和中断也会以Pending Write的形式被记录下来。</p>\n<p>实际上这种基于全量基础数据和增量操作日志相结合的持久化形式，在很多内存数据库中得到了广泛的应用。以Redis为例，它会采用相应的策略每隔一段时间将当前时间点的内存快照以<code>RDB</code>形式固化下来，同时针对数据库所作的每个操作都会按照时间顺序以<code>AOL</code>的形式存储下来。对于Pregel来说，Checkpoint就是RDB，Pending Wrtes就是AOL。当Pregel以恢复形式执行的时候，它会先提取并应用指定的Checkpoint快照，然后对状态为成功执行的Pending Write进行重放就能恢复中断时的状态。</p>\n<p>针对Pending Write的持久化通过调用BaseCheckpointSaver如下所示的put_writes/aput_writes方法完成。Pending Write的持久化是基于任务进行的，所以我们需要指定任务的ID和路径。config参数提供RunnableConfig对象携带了所需的Thread ID， Checkpoint命名空间和Checkpoint ID。具体针对Channel的Pending Write由writes参数提供的， 这是一个由Channel名称和值的二元组组成的序列。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def put_writes(\n        self,\n        config: RunnableConfig,\n        writes: Sequence[tuple[str, Any]],\n        task_id: str,\n        task_path: str = \"\",\n    ) -&gt; None\n    async def aput_writes(\n        self,\n        config: RunnableConfig,\n        writes: Sequence[tuple[str, Any]],\n        task_id: str,\n        task_path: str = \"\",\n    ) -&gt; None\n</code></pre>\n<p>对于InMemorySaver来说，它将PendingWrite存储于一个结构为<code>defaultdict[tuple[str, str, str], dict[tuple[str, int], tuple[str, str, tuple[str, bytes], str]]]</code>的两层字典中。第一层字典的Key为<code>Thread ID</code>， <code>Checkpoint命名空间</code>和<code>Checkpoint ID</code>三元组。第二层元组的第一个部分为Task ID，第二部分是当前Pending Write在writes序列中的索引。真正存储的内容是由如下四部分组成的元组：</p>\n<ul>\n<li>task_id：冗余存储任务 ID，便于快速检索。</li>\n<li>channel： Channel的名称。</li>\n<li>tuple[str, bytes]：前部分表示序列化格式（如\"json\"或\"pickle\"）。后一部分为序列化后的字节。</li>\n<li>task_path：任务在图结构中的完整路径。</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 08:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">36</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Ubuntu ä¸Š ROS2 çš„å®‰è£",
      "link": "https://www.cnblogs.com/pycr/p/19622095",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/pycr/p/19622095\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 23:01\">\n    <span>Ubuntu 上 ROS2 的安装</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<center><font face=\"华文新魏\" size=\"7\">Ubuntu 上 ROS2 的安装</font></center>\n<h1 id=\"一前言\">一、前言</h1>\n<p>​\t最近至少配置了 4 次 ROS2 了，该踩的坑都踩过了，遂发一篇博客记录一下。其实 ROS2 的安装并没有想象中的那么难，可能只是出于未知便觉得不知所措，但是其实本质上就只有两步：添加源、然后安装。</p>\n<p>​\t但是在此之前，我觉得有必要说一下 Ubuntu 和 ROS2 的各个版本代号以及对应关系。众所周知，Ubuntu 的版本除了我们喜闻乐见的 20.04/22.04/24.04 之外，还有固定为「形容词 + 动物」的版本代号，最近的几个大版本如下：</p>\n<table>\n<thead>\n<tr>\n<th>Ubuntu 版本号</th>\n<th>英文代号</th>\n<th>中文俗称</th>\n<th>支持周期</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>16.04 LTS</td>\n<td>Xenial Xerus</td>\n<td>好客的非洲地松鼠</td>\n<td>2016-2021</td>\n</tr>\n<tr>\n<td>18.04 LTS</td>\n<td>Bionic Beaver</td>\n<td>仿生海狸</td>\n<td>2018-2023</td>\n</tr>\n<tr>\n<td>20.04 LTS</td>\n<td>Focal Fossa</td>\n<td>焦点猫鼬</td>\n<td>2020-2025</td>\n</tr>\n<tr>\n<td>22.04 LTS</td>\n<td>Jammy Jellyfish</td>\n<td>急躁的水母</td>\n<td>2022-2027</td>\n</tr>\n<tr>\n<td>24.04 LTS</td>\n<td>Noble Numbat</td>\n<td>高贵的袋食蚁兽</td>\n<td>2024-2029</td>\n</tr>\n</tbody>\n</table>\n<p>​\t而有些地方会直接用第一个单词来指代 Ubuntu 的版本，比如 Focal/Jammy/Noble 分别代表 20.04/22.04/24.04。</p>\n<p>​\t而 ROS2 也有自己的版本代号（ROS1基本上已经不支持了，所以我们默认直接略过 ROS1），比如 Humble/Jazzy（这里和 Ubuntu 的代号有点像注意别弄混了），而每个版本支持的 Ubuntu 版本也不尽相同，具体信息可以去 <a href=\"https://ros.org/\" rel=\"noopener nofollow\" target=\"_blank\">ROS 官网</a> 查看。以下教程只针对于截止目前相对较新的 22.04 和 24.04 来安装。</p>\n<h1 id=\"二安装\">二、安装</h1>\n<blockquote>\n<p>其实 Ubuntu 上的软件安装方式十分统一，统一到只需要同一个命令就行：<strong>apt</strong>。</p>\n<p>唯一的区别就是有的软件在系统自带的软件源里，而有的需要自己添加软件源。</p>\n</blockquote>\n<h2 id=\"1-终端配置-locale\">1. 终端配置 locale</h2>\n<p>​\tROS2 需要 UTF-8 编码支持，但是中文英文貌似都可以，目前来说还没有遇到什么由中文编码产生的问题。可以在终端运行一下 <code>locale</code> 来查看一下支持的语言，只要是 UTF-8 的比如 en_US.UTF-8 或者 zh_CN.UTF-8 暂时都行。如果不是 UTF-8 的得运行一下如下命令永久设置系统的全局 locale 环境变量：</p>\n<pre><code class=\"language-bash\">sudo apt install -y locales\nsudo locale-gen en_US en_US.UTF-8\nsudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8\nexport LANG=en_US.UTF-8\n</code></pre>\n<h2 id=\"2-添加-ros2-软件源\">2. 添加 ROS2 软件源</h2>\n<blockquote>\n<p>Ubuntu 默认源没有 ROS2，需要添加官方源。</p>\n</blockquote>\n<h3 id=\"21-导入-ros2-官方密钥\">2.1. 导入 ROS2 官方密钥</h3>\n<pre><code class=\"language-bash\"># 导入 ROS2 GPG 密钥\ncurl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key | sudo gpg --dearmor -o /usr/share/keyrings/ros-archive-keyring.gpg\n</code></pre>\n<p>​\t这一步的作用是将 ROS2 官方的密钥下载保存到 <code>/usr/share/keyrings/ros-archive-keyring.gpg</code>，防止下载的软件被恶意篡改。</p>\n<h3 id=\"22-配置-ros2-官方仓库\">2.2. 配置 ROS2 官方仓库</h3>\n<pre><code class=\"language-bash\"># 添加 ROS2 源到 sources.list.d\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n</code></pre>\n<p>​\t这一步的作用是将 ROS2 的官方仓库添加到 <code>apt</code> 的下载源中，从而保证能通过 <code>apt</code> 下载 ROS2。其中 <code>$(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME)</code> 的作用是自动识别 Ubuntu 版本（比如22.04 对应 <code>jammy</code>），无需手动修改，也可以用<code>$(lsb_release -cs)</code> 代替。</p>\n<p>​\t如果安装过程中遇到网络问题，可切换国内镜像源，如清华、中科大 ROS2 镜像。将上述地址换为中科大镜像地址即可：</p>\n<pre><code class=\"language-bash\">echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] https://mirrors.ustc.edu.cn/ros2/ubuntu/ $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n</code></pre>\n<h2 id=\"3-安装-ros2\">3. 安装 ROS2</h2>\n<p>​\t配置结束之后终于可以一键安装了，首先更新一下软件包索引：</p>\n<pre><code class=\"language-bash\">sudo apt update\n</code></pre>\n<p>​\t然后一键安装桌面完整版，包含 ROS2 核心库、可视化工具（RViz）、开发工具等，是最常用的版本：</p>\n<pre><code class=\"language-bash\">sudo apt install -y ros-jazzy-desktop\n</code></pre>\n<p>​\t如果只需要核心库（无可视化工具），可以安装精简版：</p>\n<pre><code class=\"language-bash\">sudo apt install -y ros-jazzy-ros-base\n</code></pre>\n<p>​\t<strong>注意：jazzy 对应的是 Ubuntu24.04，如果当前 Ubuntu 的版本是 22.04，请将上述命令中的 jazzy 替换为 humble。</strong></p>\n<h2 id=\"4-配置环境变量\">4. 配置环境变量</h2>\n<p>​\t安装完成后，需要让系统识别 ROS2 的命令，有两种配置方式：</p>\n<ol>\n<li>\n<p>临时配置（仅当前终端有效）：每次打开新终端都需要执行：</p>\n<pre><code class=\"language-bash\">source /opt/ros/jazzy/setup.bash\n</code></pre>\n</li>\n<li>\n<p>永久配置（写入配置文件）：将配置写入 <code>~/.bashrc</code>，每次打开终端自动生效：</p>\n<pre><code class=\"language-bash\">echo \"source /opt/ros/jazzy/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc # 立即生效\n</code></pre>\n</li>\n</ol>\n<h2 id=\"5-验证安装\">5. 验证安装</h2>\n<h3 id=\"1检查-ros2-版本\">（1）检查 ROS2 版本</h3>\n<pre><code class=\"language-bash\">ros2 --version\n</code></pre>\n<p>​\t如果输出类似 <code>ros2 jazzy</code> 的版本信息，说明基础安装成功。</p>\n<h3 id=\"2运行示例测试\">（2）运行示例测试</h3>\n<p>​\t打开两个终端：</p>\n<p>​\t终端 1 运行 ROS2 的示例话题发布节点：</p>\n<pre><code class=\"language-bash\">ros2 run demo_nodes_cpp talker\n</code></pre>\n<p>​\t终端 2 运行示例话题订阅节点：</p>\n<pre><code class=\"language-bash\">ros2 run demo_nodes_cpp listener\n</code></pre>\n<p>​\t如果终端 2 能看到终端 1 发布的 <code>Hello World</code> 信息，说明 ROS2 完整运行。</p>\n<h2 id=\"6-安装额外开发工具\">6. 安装额外开发工具</h2>\n<p>​\t有许多 ROS 开发中常用的开发工具可能并不在 ROS2 的安装包里，需要额外安装，比如 colcon。colcon 并不是 ROS2 安装包的默认组件，需要单独安装：</p>\n<pre><code class=\"language-bash\"># 安装 colcon 核心扩展包（ROS2 官方推荐）\nsudo apt install -y python3-colcon-common-extensions\n</code></pre>\n<p>​\trosdep也是：</p>\n<pre><code class=\"language-bash\">sudo apt install -y python3-rosdep\n# 初始化rosdep（解决依赖查找问题）\nsudo rosdep init\nrosdep update\n</code></pre>\n\n\n</div>\n<div id=\"MySignature\">\n    靡不有初，鲜克有终\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 23:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/pycr\">pycr</a>&nbsp;\n阅读(<span id=\"post_view_count\">73</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "凸优化数学基础笔记（三）：方向导数、梯度向量",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19621942",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19621942\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 20:18\">\n    <span>凸优化数学基础笔记（三）：方向导数、梯度向量</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        ​ 所谓方向导数的概念是作为偏导数的概念的前瞻数学概念而引入的，是矩阵微分的重要概念，其主要研究多元函数在变量空间沿任意方向的变化率。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1方向导数及曲线弧线导数\">1.方向导数及曲线弧线导数</h2>\n<p>​       所谓方向导数的概念是作为偏导数的概念的前瞻数学概念而引入的，是矩阵微分的重要概念，其主要研究多元函数在变量空间沿任意方向的变化率。</p>\n<p>​       <strong>Definition 1</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow\\mathbf{R}\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处可微，<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 是固定不变的非零向量，<span class=\"math inline\">\\(\\mathbf{e}\\)</span> 是方向<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 上的单位向量，则称极限</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X_0})}}{\\part{\\mathbf{P}}}=\\lim_{t\\rightarrow{0}^{+}}\\frac{f(\\mathbf{X}_0+t\\mathbf{e})-f(\\mathbf{X}_0)}{t} \\tag{1}\n\\]</div><p></p><p>为函数<span class=\"math inline\">\\(f(\\mathbf{X}_0)\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向的方向导数，式中<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X_0})}}{\\part{\\mathbf{P}}}\\)</span> 是其简单记。</p>\n<p>​       <strong>Definition 2</strong>  设<span class=\"math inline\">\\(f:\\mathbf{R}^{n}\\rightarrow\\mathbf{R}\\)</span> 是连续函数，<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>，<span class=\"math inline\">\\(\\mathbf{P}\\in\\mathbf{R}^n\\)</span>，且<span class=\"math inline\">\\(\\mathbf{P}\\neq{\\mathbf{0}}\\)</span>，若有存在<span class=\"math inline\">\\(\\delta&gt;0\\)</span>。当<span class=\"math inline\">\\(t\\in(0,\\delta)\\)</span> 时都有<span class=\"math inline\">\\(f(\\mathbf{X_0}+t\\mathbf{P})&lt;f(\\mathbf{X}_0)\\)</span> ，则称<span class=\"math inline\">\\(\\mathbf{P}\\)</span>为<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的下降方向。若<span class=\"math inline\">\\(f(\\mathbf{X}_0+t\\mathbf{P})&gt;f(\\mathbf{X}_0)\\)</span> ，则称<span class=\"math inline\">\\(\\mathbf{P}\\)</span>为<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处的上升方向。</p>\n<p>​       由此以上的两个定义可立刻得到如下的结论：</p>\n<ol>\n<li>若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}&lt;0\\)</span>，则多元函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 从<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 附近沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向是下降的；</li>\n<li>若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P_0}}}&gt;0\\)</span>，则多元函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 从<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 附近沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向是上升的；</li>\n</ol>\n<p>​      事实上，若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}&lt;0\\)</span>，则当<span class=\"math inline\">\\(\\exist t&gt;0\\)</span> ,必有如下的充分小，根据上式Definition必有如下表达：</p>\n<p></p><div class=\"math display\">\\[\\frac{f(\\mathbf{X}_0+t\\mathbf{e})-f(\\mathbf{X}_0)}{t}&lt;0 \\tag{2}\n\\]</div><p></p><p>即可得：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X})&lt;f(\\mathbf{X}_0)  \\tag{3}\n\\]</div><p></p><p>其中：<span class=\"math inline\">\\(\\mathbf{X}=\\mathbf{X}_0+t\\mathbf{e}\\)</span> 是从 <span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向上的点，说明<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 方向上是下降的点；同理可以说明，<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> ，则<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span>是上升的。</p>\n<p>​       在直角坐标系中，方向导数有如下定理给出的计算公式，以空间三维函数为例。</p>\n<p>​       <strong>定理 1</strong> 若三维多元函数<span class=\"math inline\">\\(f=f(x,y,z)\\)</span>在点<span class=\"math inline\">\\(M_0(x_0,y_0,z_0)\\)</span>处可微，<span class=\"math inline\">\\(\\cos(\\alpha),cos(\\beta),\\cos(\\gamma)\\)</span> 以<span class=\"math inline\">\\(l\\)</span>方向的方向余弦，则函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M_0\\)</span> 处沿<span class=\"math inline\">\\(l\\)</span> 方向导数必存在，且由如下公式给出</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f}}{\\part{l}}=\\frac{\\part{f}}{\\part{x}}\\cos(\\alpha)+\\frac{\\part{f}}{\\part{y}}\\cos{(\\beta)}+\\frac{\\part{f}}{\\part{z}}\\cos{(\\gamma)}  \\tag{4}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(\\frac{\\part{f}}{\\part{x}},\\frac{\\part{f}}{\\part{y}},\\frac{\\part{f}}{\\part{z}}\\)</span> 是在点<span class=\"math inline\">\\(M_0\\)</span> 处的偏导数。</p>\n<p><strong>证   明：</strong> 设在<span class=\"math inline\">\\(M_0(x,y,z)\\)</span>的<span class=\"math inline\">\\(\\delta-\\)</span>领域内存在动点<span class=\"math inline\">\\(M\\)</span>的坐标为<span class=\"math inline\">\\(M(x_0+\\Delta{x},y_0+\\Delta{y},z_0+\\Delta{z})\\)</span> 。因为<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M_0\\)</span> 可微，故有</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n \\Delta{f}&amp;=f(\\mathbf{M})-f(\\mathbf{M_0}) \\\\\n   &amp;=\\frac{\\part{f}}{\\part{x}}\\Delta{x}+\\frac{\\part{f}}{\\part{y}}\\Delta{y}+\\frac{\\part{f}}{\\part{z}}\\Delta{z}+o(r)\n   \n\\end{aligned}\n\\tag{5}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(r=\\sqrt{\\Delta{x}^2+\\Delta{y}^2+\\Delta{z}^2}\\)</span>， 将上式除以<span class=\"math inline\">\\(r\\)</span>:</p>\n<p></p><div class=\"math display\">\\[\\frac{\\Delta{f}}{r}=\\frac{\\part{f}}{\\part{x}}\\frac{\\Delta{x}}{r}+\\frac{\\part{f}}{\\part{y}}\\frac{\\Delta{y}}{r}+\\frac{\\part{f}}{\\part{z}}\\frac{\\Delta{z}}{r}+\\frac{o(r)}{r} \\tag{6}\n\\]</div><p></p><p>当<span class=\"math inline\">\\(r\\rightarrow{0}\\)</span> ,结合切线的定义可得：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f}}{\\part{l}}=\\frac{\\part{f}}{\\part{x}}\\cos{\\alpha}+\\frac{\\part{f}}{\\part{y}}\\cos{\\beta}+\\frac{\\part{f}}{\\part{z}}\\cos{\\gamma} \\tag{7}\n\\]</div><p></p><p>​        <strong>定理2</strong>   若存在有向曲线<span class=\"math inline\">\\(C\\)</span>上取一定的<span class=\"math inline\">\\(M_0\\)</span> ，作为计算弧长<span class=\"math inline\">\\(s\\)</span>的起点，并以<span class=\"math inline\">\\(C\\)</span>之正向作为<span class=\"math inline\">\\(s\\)</span>增大的方向；<span class=\"math inline\">\\(M\\)</span>为<span class=\"math inline\">\\(C\\)</span> 上的一点，在点<span class=\"math inline\">\\(M\\)</span> 处沿<span class=\"math inline\">\\(C\\)</span>之正向作一与<span class=\"math inline\">\\(C\\)</span>的相切射线<span class=\"math inline\">\\(l\\)</span>，则在点<span class=\"math inline\">\\(M\\)</span>处，当函数<span class=\"math inline\">\\(u\\)</span> 沿<span class=\"math inline\">\\(l\\)</span> 方向的方向导数就等于函数<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数，既有下式成立：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{\\part{u}}{\\part{s}} \\tag{8}\n\\]</div><p></p><p><strong>证  明：</strong> 设曲线<span class=\"math inline\">\\(C\\)</span>以<span class=\"math inline\">\\(s\\)</span>为参数的参数方程为：</p>\n<p></p><div class=\"math display\">\\[x=x(s),y=y(s),z=z(s) \\tag{9}\n\\]</div><p></p><p>则沿曲线<span class=\"math inline\">\\(C\\)</span>,函数</p>\n<p></p><div class=\"math display\">\\[u=u[x(s),y(s),z(s)] \\tag{10}\n\\]</div><p></p><p>又由于在点<span class=\"math inline\">\\(M\\)</span>处，函数<span class=\"math inline\">\\(u\\)</span>的可微、曲线<span class=\"math inline\">\\(C\\)</span>光滑，按照复合函数求导定理，得到<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数：</p>\n<p></p><div class=\"math display\">\\[\\frac{du}{ds}=\\frac{\\part{u}}{\\part{x}}\\frac{dx}{ds}+\\frac{\\part{u}}{\\part{y}}\\frac{dy}{ds}+\\frac{\\part{u}}{\\part{z}}\\frac{d{z}}{ds} \\tag{11}\n\\]</div><p></p><p>注意到<span class=\"math inline\">\\(\\frac{dx}{ds},\\frac{dy}{ds},\\frac{dz}{ds}\\)</span> 是曲线<span class=\"math inline\">\\(C\\)</span>的正方向切线<span class=\"math inline\">\\(l\\)</span>的方向余弦，若将其写成<span class=\"math inline\">\\(\\cos{(\\alpha)},\\cos{(\\beta)},\\cos{(\\gamma)}\\)</span> ，即得到<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数：</p>\n<p></p><div class=\"math display\">\\[\\frac{du}{ds}=\\frac{\\part{u}}{\\part{s}}\\cos(\\alpha)+\\frac{\\part{u}}{\\part{s}}\\cos(\\beta)+\\frac{\\part{u}}{\\part{s}}\\cos{(\\gamma)} \\tag{12}\n\\]</div><p></p><p>即知道，</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{du}{ds} \\tag{13}\n\\]</div><p></p><p>上面讲的是函数 <span class=\"math inline\">\\(u\\)</span>沿直线的方向导数。此外，有时还需要研究函数<span class=\"math inline\">\\(u\\)</span>沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数，其定义的如下：</p>\n<p>​       <strong>Definition 3</strong> 从点<span class=\"math inline\">\\(M\\)</span>出发沿<span class=\"math inline\">\\(C\\)</span>之正向取一点<span class=\"math inline\">\\(M_1\\)</span>, 记弧长 <span class=\"math inline\">\\(\\overset{\\LARGE{\\frown}}{MM_1}=\\Delta{s}\\)</span> ，若当<span class=\"math inline\">\\(M_1\\rightarrow{M}\\)</span>时，比式</p>\n<p></p><div class=\"math display\">\\[\\frac{\\Delta{u}}{\\Delta{s}}=\\frac{u(M_1)-u(M)}{|\\overset{\\LARGE{\\frown}}{MM_1}|} \\tag{14}\n\\]</div><p></p><p>的极限存在，则称此极限为函数<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M\\)</span>处沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数，记作<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span>，即：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds} \\tag{15}\n\\]</div><p></p><p><strong>定 理3</strong>  若在点<span class=\"math inline\">\\(M\\)</span>处函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M\\)</span> 处沿函数<span class=\"math inline\">\\(\\mathbf{C}\\)</span> (正向)的方向导数，记作<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span> ，则有</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds} \\tag{16}\n\\]</div><p></p><p><strong>证   明</strong>：由于在点<span class=\"math inline\">\\(M\\)</span>处函数<span class=\"math inline\">\\(u\\)</span> 可微，曲线<span class=\"math inline\">\\(C\\)</span>光滑，故有全导数<span class=\"math inline\">\\(\\frac{du}{ds}\\)</span>存在。而<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span> 按照定义实际上的是一个右极限</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\lim_{\\Delta{t}\\rightarrow{0}}\\frac{\\Delta{u}}{\\Delta{s}} \\tag{17}\n\\]</div><p></p><p>故当<span class=\"math inline\">\\(\\frac{du}{ds}=\\lim_{\\Delta{t}\\rightarrow{0}}\\frac{\\Delta{u}}{\\Delta{s}}\\)</span> 存在时，就有<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds}\\)</span>.</p>\n<p><strong>推  论</strong>：若在点<span class=\"math inline\">\\(\\mathbf{M}\\)</span>处函数<span class=\"math inline\">\\(u\\)</span> 可微、曲线<span class=\"math inline\">\\(C\\)</span>光滑，则有：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{\\part{u}}{\\part{l}} \\tag{18}\n\\]</div><p></p><p>换而言之：函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M\\)</span>处沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数与函数<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M\\)</span> 处沿切线方法（指向<span class=\"math inline\">\\(C\\)</span>的正向一侧）的方向导数相等。</p>\n<h2 id=\"2-梯度向量\">2. 梯度向量</h2>\n<p>​        方向导数解决了多元变量数性函数<span class=\"math inline\">\\(u(\\mathbf{M})\\)</span> 在给定点处沿某个方向的变化率描述问题，然而从变量空间中的定义点出发，有无穷多个方向，那么函数<span class=\"math inline\">\\(u(\\mathbf{M})\\)</span> 沿其中哪个方向的变化率最大？最大的变化率又是多少呢? 在科学技术中常常需要讨论的问题，为了解决这个问题，那么我们从方向导数计算公式（12）出发：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{\\part{u}}{\\part{x}}\\cos{\\alpha}+ \\frac{\\part{u}}{\\part{y}}\\cos{\\beta}+\\frac{\\part{u}}{\\part{z}}\\cos{\\gamma} \\tag{19}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(\\cos{\\alpha},\\cos{\\beta},\\cos{\\gamma}\\)</span> 为<span class=\"math inline\">\\(l\\)</span>方向的方向余弦，也就是这个方向上的单位矢量 <span class=\"math inline\">\\(\\boldsymbol{l}=\\cos{\\alpha}\\boldsymbol{i}+\\cos{\\beta}\\boldsymbol{j}+\\cos{\\gamma}\\boldsymbol{k}\\)</span> 的坐标，若把公式（19）右端可以写为<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 与<span class=\"math inline\">\\(\\boldsymbol{l}\\)</span> 的数量积：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\mathbf{G}\\cdot\\boldsymbol{l}=|\\mathbf{G}|\\cos(\\mathbf{G},\\boldsymbol{l}) \\tag{20}\n\\]</div><p></p><p>显然，<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 在给定点的处为一固定矢量，上式表示：<span class=\"math inline\">\\(\\mathbf{G}\\)</span>在<span class=\"math inline\">\\(l\\)</span>方向上的投影正好等于函数<span class=\"math inline\">\\(u\\)</span>在该方向上的方向导数，因此，当方向<span class=\"math inline\">\\(l\\)</span>与<span class=\"math inline\">\\(\\mathbf{G}\\)</span>的方向一致时，即<span class=\"math inline\">\\(cos(\\mathbf{G},\\boldsymbol{l})=1\\)</span> 时，方向导数取得最大值，其值为：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=|\\mathbf{G}| \\tag{21}\n\\]</div><p></p><p>由此可知，矢量<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 的方向就是函数<span class=\"math inline\">\\(u(M)\\)</span> 变化率最大的方向，其模也正好是这个最大变化率的数值。我们把<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 叫做函数<span class=\"math inline\">\\(u(M)\\)</span> 在给定点处的梯度。一般，有如下的定义。</p>\n<p><strong>Definition 4</strong>  以<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 的<span class=\"math inline\">\\(n\\)</span> 个偏导数为分量的向量称为<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 处的梯度，记为：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left[\\frac{\\part{f}}{\\part{x_1}},\\frac{\\part{f}}{\\part{x_2}},\\frac{\\part{f}}{\\part{x_3}},...,\\frac{\\part{f}}{\\part{x_n}}\\right]^T \\tag{22}\n\\]</div><p></p><p>梯度也可以称为函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于向量<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的一阶导数。</p>\n<p>由此，可以从定义给出梯度与方向导数之间的关系。</p>\n<p><strong>定 理 4</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow{\\mathbf{R}}\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处可微，则方向导数与梯度关系：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}=\\nabla{f(\\mathbf{X}_0)}^T\\mathbf{e} \\tag{23}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(\\mathbf{e}\\)</span> 是<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向上的单位向量。</p>\n<p>​\t由这个定理容易得到下列结论：</p>\n<p>​\t（1）若<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X}_0)^T\\mathbf{P}}&lt;0\\)</span>，则<span class=\"math inline\">\\(P\\)</span>的方向是函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的下降方向。</p>\n<p>​\t（2）若<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X}_0)}^T\\mathbf{P}&gt;0\\)</span> , 则<span class=\"math inline\">\\(P\\)</span>的方向是函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的上升方向。</p>\n<p>方向导数的正负决定了函数值的升降，而升降的快慢就由它的绝对值大小决定。绝对值越大，升降的速度就越快。根据式（19）到式（22）即：</p>\n<p></p><div class=\"math display\">\\[\\left|\\frac{\\part{f(X_0)}}{\\part{\\mathbf{P}}}\\right|=|\\nabla f(\\mathbf{X}_0)^T\\mathbf{e}|= |\\nabla{{f}(\\mathbf{X}_0)}|\\cdot|\\cos(\\nabla{f(\\mathbf{X}_0)},\\mathbf{e})|\\leq |\\nabla f(\\mathbf{X}_0)| \\tag{24} \n\\]</div><p></p><p>上式中的等号，当且仅当<span class=\"math inline\">\\(\\mathbf{e}\\)</span>的方向与<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X_0})}\\)</span> 的方向共线才成立。由此可知，得到如下重要结论：</p>\n<ol>\n<li>梯度向量是函数值的最速上升方向；</li>\n<li>函数在其梯度正交的方向上的变化率为零；</li>\n<li>函数在与其梯度成锐角方向上是上升的，而在成钝角的方向是下降的；</li>\n<li>梯度的反向是函数值最速下降方法；</li>\n</ol>\n<p>对于一个最优化问题，为了尽快得到最优解，在每一步迭代过程中选取的搜索方向<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 总是希望它等于或者是靠近于目标函数的负梯度（即<span class=\"math inline\">\\(-\\nabla{f(\\mathbf{X})}\\)</span>）的方向，这样才能使函数值下降的最快。</p>\n<p>梯度的性质及以下几个特殊类型的函数的常用梯度公式：</p>\n<p>（1）若 <span class=\"math inline\">\\(f(\\mathbf{X})=c\\)</span> (c为常数)，则 <span class=\"math inline\">\\(\\nabla f(\\mathbf{X})=0\\)</span>，即 <span class=\"math inline\">\\(\\nabla{c}=0\\)</span>;</p>\n<p>（2）<span class=\"math inline\">\\(\\nabla(cf(\\mathbf{x}))=c\\nabla(f(\\mathbf{x}))\\)</span> （其中<span class=\"math inline\">\\(c\\)</span>为常数）；</p>\n<p>（3）<span class=\"math inline\">\\(\\nabla(u\\pm v)=\\nabla(u)\\pm\\nabla(v)\\)</span>;</p>\n<p>(4) <span class=\"math inline\">\\(\\nabla(uv)=u\\nabla(v)+v\\nabla(u)\\)</span></p>\n<p>(5) <span class=\"math inline\">\\(\\nabla{\\frac{u}{v}}=\\frac{1}{v^2}(v\\nabla{u}-u\\nabla{v})\\)</span></p>\n<p>(6) <span class=\"math inline\">\\(\\nabla f(u)=f^{\\prime}(u)\\nabla{u}\\)</span></p>\n<p>（7）<span class=\"math inline\">\\(\\nabla(f(u,v))=\\frac{\\part{f}}{\\part{u}}\\nabla(u)+\\frac{\\part{f}}{\\part{v}}\\nabla{v}\\)</span></p>\n<p>(8) <span class=\"math inline\">\\(\\nabla{\\mathbf{b}^T\\mathbf{X}}=\\mathbf{b}\\)</span></p>\n<p>(9) <span class=\"math inline\">\\(\\nabla(\\mathbf{X}^T\\mathbf{X})=2\\mathbf{X}\\)</span></p>\n<p>(10) 若 <span class=\"math inline\">\\(Q\\)</span> 是对称矩阵矩阵，则 <span class=\"math inline\">\\(\\nabla(\\mathbf{X}^T\\mathbf{Q}\\mathbf{X})=2\\mathbf(QX)\\)</span></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 20:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">43</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "OpenClaw怎么做到不串台、能并行、还总回对群 ✅（含源码解析）--OpenClaw系列第1期",
      "link": "https://www.cnblogs.com/borui-coding-diary/p/19621811/openclaw-group-chats-concurrency-commercialization-barrier",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/borui-coding-diary/p/19621811/openclaw-group-chats-concurrency-commercialization-barrier\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 18:02\">\n    <span>OpenClaw怎么做到不串台、能并行、还总回对群 🤖✅（含源码解析）--OpenClaw系列第1期</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"OpenClaw怎么做到不串台、能并行、还总回对群 &amp;#129302;✅（含源码解析）--OpenClaw系列第1期\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3759702/202602/3759702-20260217175237028-512010576.png\" />\n        把 AI 放进群聊只是开始：真正卡住商业化的门槛，是并发下的“上下文不串、回对地方、权限可控、成本可收”。这篇用 OpenClaw 的实现把这道坎讲清楚。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"引子群里最可怕的不是答错是答到别的地方\">引子：群里最可怕的不是“答错”，是“答到别的地方”😵‍💫</h2>\n<p>你把 OpenClaw 部署进群，大家立刻把它当万能同事用：</p>\n<ul>\n<li>小王在 <strong>dev-team 群</strong>：<code>@bot 帮我写发布计划</code></li>\n<li>小李在同群<strong>线程</strong>：<code>@bot CI 为啥挂了？</code></li>\n<li>你在<strong>私聊</strong>：<code>这个别在群里说…</code></li>\n<li>还有人：<code>@bot 同时分析文档 A、B，再给我结论</code></li>\n</ul>\n<p>如果机器人只有“一份混在一起的对话记录”，就会出现社死级翻车：<br />\n<strong>A 群问、B 群回；线程问、主楼回；私聊的内容差点带进群。</strong></p>\n<p>OpenClaw 的思路很朴素：<br />\n<strong>先把不同地方的对话记录分开存 → 再支持后台并行 → 再保证后台回到同一个群/线程 → 最后用完就删（或留档）。</strong></p>\n<hr />\n<h2 id=\"1串台a-的话跑到-b-的对话里-\">1）串台：A 的话跑到 B 的对话里 🫠</h2>\n<p><strong>群友反应：</strong> 😨➡️💀➡️🧯（“别回错群啊！！救火！”）</p>\n<blockquote>\n<p>群友：<code>@bot 我在 dev-team 问的，你怎么把答案发到 release-squad 了？！</code></p>\n</blockquote>\n<p><strong>问题</strong>：不同对话的记录混在一起。<br />\n<strong>解决方法其实很简单</strong>：给每段对话一个“对话ID”，所有记录按这个 ID 分开存。（OpenClaw 内部叫 <code>sessionKey</code>，你可以理解成“对话ID”。）</p>\n<pre><code class=\"language-ts\">// 按“对话ID”分开存记录（概念代码）\nconst chats = new Map&lt;string, string[]&gt;();\n\nfunction add(chatId: string, msg: string) {\n  if (!chats.has(chatId)) chats.set(chatId, []);\n  chats.get(chatId)!.push(msg);\n}\n</code></pre>\n<p>✅ 结果：对话ID不同，记录天然不混。<br />\n<strong>但新的问题来了：</strong>同一个群里主楼+多个线程也会互相干扰 🤯</p>\n<hr />\n<h2 id=\"2同群混聊主楼和线程搅成一锅粥-\">2）同群混聊：主楼和线程搅成一锅粥 🧵</h2>\n<p><strong>群友反应：</strong> 🤨➡️🧵➡️😵‍💫（“我问线程你回主楼？脑子打结了？”）</p>\n<blockquote>\n<p>群友：<code>@bot 我在线程问 CI，你怎么把“今晚吃啥”也总结进来了？</code></p>\n</blockquote>\n<p><strong>问题</strong>：同一个群里多个话题并行发生。<br />\n<strong>解决方法其实也很简单</strong>：对话ID里把“群名/线程”也区分出来——<strong>主楼一份记录，线程一份记录</strong>。</p>\n<pre><code class=\"language-ts\">// 对话ID规则（概念）：群 vs 线程分开\ngroupChatId  = `discord:群:${groupId}`                 // 主楼\nthreadChatId = `discord:群:${groupId}:线程:${threadId}` // 线程\ndmChatId     = `discord:私聊:${peerId}`                 // 私聊\n</code></pre>\n<p>✅ 结果：你在<strong>哪个线程</strong>聊，就只影响<strong>那个线程</strong>的记录。<br />\n<strong>但新的问题来了：</strong>不混了，但任务多了会卡住（大家同时丢重活）⌛</p>\n<hr />\n<h2 id=\"3卡顿大家同时丢重活机器人开始排队-\">3）卡顿：大家同时丢重活，机器人开始排队 😤</h2>\n<p><strong>群友反应：</strong> ⏳➡️😤➡️📢（“别思考了！先回个收到！”）</p>\n<blockquote>\n<p>群友：<code>@bot 你别转圈圈了，先回一句“收到”也行啊！</code></p>\n</blockquote>\n<p><strong>问题</strong>：分析文档/汇总讨论这种重活，同时来好几个就会堵住。<br />\n<strong>解决方法其实很简单</strong>：重活不要在群里“现场算”，<strong>开一个后台任务去做</strong>，群里先继续聊。</p>\n<pre><code class=\"language-ts\">// 开后台任务（概念）：立刻返回 runId，不阻塞\nfunction startBackground(task: string) {\n  const jobId = crypto.randomUUID();         // runId\n  const workspace = `bg:${crypto.randomUUID()}`; // 后台独立空间\n  gatewayStart({ workspace, task, deliverNow: false });\n  return { status: \"accepted\", jobId, workspace };\n}\n</code></pre>\n<p>✅ 结果：群里体验变成“先收到 ✅，稍后给结果”。<br />\n<strong>但新的问题来了：</strong>后台做完了，<strong>怎么保证它一定回到同一个群/同一个线程</strong>？📍</p>\n<hr />\n<h2 id=\"4回错地方我在-dev-team-问的你别跑去别的群回-\">4）回错地方：我在 dev-team 问的，你别跑去别的群回 😵</h2>\n<p><strong>群友反应：</strong> 📍➡️🙅‍♂️➡️✅（“就！在！这！里！回！”）</p>\n<blockquote>\n<p>群友：<code>@bot 我是在 dev-team 的“CI排查线程”问的，你能不能就在那条线程里回？</code></p>\n</blockquote>\n<p><strong>问题</strong>：后台任务结束后，答案必须发回<strong>你当时提问的那个群/线程/私聊</strong>。<br />\n<strong>解决方法其实很简单</strong>：程序会记住你发消息的<strong>群名/线程</strong>（内部更稳的是记 <code>groupId/threadId</code>），后台结束就按这个信息回去发。</p>\n<pre><code class=\"language-ts\">type Where = { groupId?: string; groupName?: string; threadId?: string };\nconst jobs = new Map&lt;string, { where: Where; workspace: string }&gt;();\n\nfunction onAsk(ctx: any) {\n  const where = { groupId: ctx.group.id, groupName: ctx.group.name, threadId: ctx.thread?.id };\n  const { jobId, workspace } = startBackground(ctx.task);\n  jobs.set(jobId, { where, workspace });\n}\n\nasync function onDone(jobId: string) {\n  const { where, workspace } = jobs.get(jobId)!;\n  const result = await readResult(workspace);\n  sendMessage(where, result); // ✅ 群里问→回同群；线程问→回同线程\n}\n</code></pre>\n<p>✅ 读者只要记住一句话：<br />\n<strong>哪个群问的，就回哪个群；哪个线程问的，就回哪个线程。</strong><br />\n<strong>但新的问题来了：</strong>后台这么能干，会不会“乱翻记录/乱发消息/无限开后台”？😨</p>\n<hr />\n<h2 id=\"5越权套娃后台别乱来-\">5）越权/套娃：后台别乱来 🔒</h2>\n<p><strong>群友反应：</strong> 👀➡️🚫➡️🔒（“别乱看别乱开，锁上！”）</p>\n<blockquote>\n<p>群友：<code>@bot 你后台干活归干活，别偷偷翻别的群聊天记录啊…</code></p>\n</blockquote>\n<p><strong>问题</strong>：后台任务如果权限太大，可能越界；如果还能再开后台，就可能无限套娃。<br />\n<strong>解决方法其实很简单</strong>：后台默认“受限模式”——<strong>不许再开后台</strong>，也不许做敏感操作。</p>\n<pre><code class=\"language-ts\">// 后台受限（概念）\nif (ctx.isBackground) deny(\"startBackground\");  // 禁止后台再开后台\ndenyMany([\"listChats\", \"readHistory\", \"sendToOtherChats\", \"memorySearch\"]);\n</code></pre>\n<p>✅ 结果：后台只负责“把任务做完”，不乱看、不乱发、不无限分裂。<br />\n<strong>但新的问题来了：</strong>并行多了，后台任务空间会不会越攒越多？🗑️</p>\n<hr />\n<h2 id=\"6垃圾堆后台任务越跑越多像浏览器-300-个标签页-️\">6）垃圾堆：后台任务越跑越多，像浏览器 300 个标签页 🗑️</h2>\n<p><strong>群友反应：</strong> 🐌➡️🗑️➡️✨（“越用越慢？清一清立刻顺滑”）</p>\n<blockquote>\n<p>群友：<code>@bot 你怎么越用越慢了？是不是后台开了一堆任务没清理？</code> 😅</p>\n</blockquote>\n<p><strong>问题</strong>：并行多了，后台任务空间也会多。<br />\n<strong>解决方法其实很简单</strong>：结果发回群里后——<strong>默认用完就删</strong>；重要任务才“留档复盘”。</p>\n<pre><code class=\"language-ts\">async function finish(jobId: string, keep = false) {\n  const { where, workspace } = jobs.get(jobId)!;\n  sendMessage(where, await readResult(workspace));\n  if (!keep) await deleteWorkspace(workspace); // ✅ 用完就删\n}\n</code></pre>\n<p>✅ 结果：默认干净省资源；需要复盘时才保留。</p>\n<hr />\n<h2 id=\"一张图把全链路串起来-\">一张图把全链路串起来 🧩</h2>\n<pre><code>你在某个群/线程提问\n   ↓\n按“群/线程”生成对话ID → 对话记录分开存（不串台）\n   ↓\n重活？→ 开后台任务（群里先回“收到”）\n   ↓\n记住群名/线程 → 后台结束回同一个群/同一个线程发结果\n   ↓\n后台受限（不越权/不套娃）\n   ↓\n默认用完就删（或留档复盘）\n</code></pre>\n<p><strong>群友反应：</strong> 🧠➡️🧩➡️🫡（“懂了：分开记、后台跑、回原处、能收拾”）</p>\n<hr />\n<h3 id=\"tldr\">tldr;</h3>\n<p><strong>OpenClaw 的目标很简单：你在哪个群/线程问，它就在哪儿回；不同地方的对话记录各存各的；重活后台并行；后台不乱来；默认用完就删。</strong> ✅</p>\n<p>关注我，下一期继续整更硬核干货🔥🤖📌 敬请期待～✨</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 18:02</span>&nbsp;\n<a href=\"https://www.cnblogs.com/borui-coding-diary\">vibecoding日记</a>&nbsp;\n阅读(<span id=\"post_view_count\">99</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Linux下GNU Autotools工具基础教程",
      "link": "https://www.cnblogs.com/ttkwzyttk/p/19621799",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ttkwzyttk/p/19621799\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:24\">\n    <span>Linux下GNU Autotools工具基础教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本博客介绍了Linux下GNU Autotools工具的基础用法，涵盖了autoconf、automake等工具的功能及作用。通过实例演示，讲解了如何使用autoconf生成配置脚本，以及如何通过automake和Makefile.am定制构建过程。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>对于我们平时写的小的测试Demo程序，可能自己手动编写一个<code>Makefile</code>文件就可以编译整个项目了，但是对于一些大型的工程，包含多个源码文件夹、头文件文件夹、库文件文件夹，如果我们每个源码文件的<code>Makefile</code>文件都自己去编写会非常繁琐，所以这时候需要一些自动化工具来帮助我们简化项目的构建，这里比较主流的有两种工具一个是GNU下的Autotools工具，一个是CMake工具。</p>\n<p>Autotools工具是一些版本比较老的工具了，遗留了很多问题，包括他的语法复杂(m4宏语言)，涉及的工具种类太多，生成的<code>configure</code>脚本非常庞大等问题，在2000年后出现的新一代构建系统包括CMake、Meson、Ninja等能够有效解决Autotools的历史疑难杂症，并且语法更加现代化、生成速度更快。那我们为什么还要学习了解Autotools呢？因为历史原因，早年很多的开源软件都是使用的Autotools来构建的，并且Autotools目前在GNU体系中还是大量使用，并且在嵌入式Linux中非常常见，而且在一些老牌的C项目中也非常常见，所以还是非常有必要了解Autotools。</p>\n<p>这里给出官方的Autotools的文档连接 <a href=\"https://www.gnu.org/software/autoconf/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/software/autoconf/</a></p>\n<h1 id=\"一autotools工具详细介绍\">一、Autotools工具详细介绍</h1>\n<h2 id=\"11-autotools工具组成\">1.1 Autotools工具组成</h2>\n<p>GNU Autotools并不是一个工具，而是由一系列的工具合集组成，在现如今的Linux发行版中，大概率是自带这些工具的，如果没有可以自行下载</p>\n<ul>\n<li><code>autoscan</code>：这个工具主要是用来扫描查找源代码目录下的源文件用来生成<code>configure.scan</code>文件。<code>configure.scan</code>文件是自动生成的模板，里面包含了一些系统配置的基本选项都是一些宏定义，这些宏通过<code>autoconf</code>工具处理后会变成检查系统特性、环境变量的shell脚本，我们可以根据这个模板修改，最后将<code>configure.scan</code>重新命名为<code>configure.ac</code>文件</li>\n<li><code>aclocal</code>：这个工具是一个<code>perl</code>脚本程序，他主要用来根据上一步的<code>configure.ac</code>文件的内容，自动生成<code>aclocal.m4</code>文件</li>\n<li><code>autoconf</code>：这个工具会使用<code>configure.ac</code>文件来生成名称为<code>configure</code>的shell脚本文件用来检查系统特性与环境变量，运行这个脚本文件之后，就会生成<code>Makefile</code>文件，之后我们就可以执行<code>make</code>和<code>make install</code>命令了</li>\n<li><code>autoheader</code>：这个工具主要是用来自动生成<code>config.h.in</code>文件的，当我们执行了<code>./configure</code>之后，会生成一个<code>config.h</code>文件，在调用<code>autoheader</code>工具之后，就会生成<code>config.h.in</code>文件</li>\n<li><code>automake</code>：使用<code>automake</code>来产生<code>Makefile.in</code>文件，需要注意的是<code>Makefile.in</code>是由<code>Makefile.am</code>生成的这个需要我们手动来编写</li>\n</ul>\n<p>这里可以注意到，最后工具用到的文件都是以<code>.in</code>结尾的文件，这些文件相当于我们最后需要的目标文件的输入文件</p>\n<h2 id=\"12-configure脚本制作流程\">1.2 <code>configure</code>脚本制作流程</h2>\n<p>这块内容可以参考 <a href=\"https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html</a> 文档的第三章内容，详细阐述了<code>configure</code>脚本的制作流程，下面简单介绍一下，以下图流程图中，带<code>*</code>的是执行的命令，带<code>[]</code>的表示可选项</p>\n<p><img alt=\"Pasted image 20260216122316.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209097-1180976358.png\" /><br />\n首先根据文档中的这个流程图，可以看见用我们的源文件，通过<code>autoscan</code>命令生成<code>configure.scan</code>文件，然后我们再修改这个模板，生成我们的<code>configure.ac</code>文件，在通过<code>autoconf</code>命令生成<code>configure</code>脚本的时候，<code>aclocal.m4</code>和<code>acsite.m4</code>这两个文件为可选项，如果我们后续需要使用<code>automake</code>工具，那么还需要在执行<code>autoconf</code>前使用<code>aclocal</code>工具生成<code>aclocal.m4</code>文件</p>\n<p>在执行<code>autoconf</code>命令的同时，我们可以选择使用<code>autoheader</code>来生成<code>config.h.in</code>文件。这个文件的作用是为 configure 提供一个模板，告诉它哪些宏需要根据系统环境进行检测，从而生成最终的<code>config.h</code>文件，供代码在条件编译中使用，后需会详细讲解这部分内容。</p>\n<p>如果我们还需要使用<code>automake</code>工具来生成<code>Makefile.in</code>文件，那么需要在<code>autoscan</code>生成了<code>configure.ac</code>文件之后追加以下的流程<br />\n<img alt=\"Pasted image 20260216132616.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209304-1030423812.png\" /><br />\n第一步，我们需要使用<code>aclocal</code>命令来生成<code>aclocal.m4</code>文件，有了这个文件之后，我们在生成<code>configure</code>的时候会使用到这个文件，然后第二步我们需要自己编写一个<code>Makefile.am</code>文件，然后执行<code>automake</code>命令来生成<code>Makefile.in</code></p>\n<p>做完上述两个流程之后，我们就可以得到两个关键文件了一个是<code>configure</code>脚本文件，一个是<code>Makefile.in</code>模板文件，在通过以下流程，生成最后的<code>Makefile</code>文件<br />\n<img alt=\"Pasted image 20260216133225.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209082-1911362763.png\" /><br />\n直接执行<code>configure</code>脚本文件，脚本会去找<code>config.h.in</code>和<code>Makefile.in</code>文件进行文件生成，最后生成<code>config.h</code>和<code>Makefile</code>文件，之后我们就可以执行<code>make</code>命令来编译工程了</p>\n<p>可能这里三个图的关系比较混乱，后面会通过一个工程上的实例，来具体演示<code>Autotools</code>的使用以及流程</p>\n<h2 id=\"13-autoheader工具与confighin文件\">1.3 <code>autoheader</code>工具与<code>config.h.in</code>文件</h2>\n<p>前面我们提到了使用<code>autoconf</code>生成<code>configure</code>的同时，可以使用<code>autoheader</code>来生成<code>config.h.in</code>文件，这个文件到底是用来干什么的呢？这一小节详细讲解一下。</p>\n<p>例如，现在有一个场景：我们的应用代码需要跨平台，在 Linux 环境下，会使用到 <code>&lt;unistd.h&gt;</code> 头文件。不同系统可能是否存在这个头文件不同，因此我们希望通过自动化的方式进行检测和适配。我们需要先在<code>configure.ac</code>文件中添加配置项</p>\n<pre><code>AC_INIT([example], [1.0])\nAC_CONFIG_HEADERS([config.h])\nAC_CHECK_HEADERS([unistd.h])\nAC_OUTPUT\n</code></pre>\n<ul>\n<li><code>AC_CONFIG_HEADERS([config.h])</code>：告诉 Autotools 最终需要生成 <code>config.h</code> 文件</li>\n<li><code>AC_CHECK_HEADERS([unistd.h])</code>：告知 Autotools 需要检测系统是否有 <code>&lt;unistd.h&gt;</code>，并生成相应宏 <code>HAVE_UNISTD_H</code></li>\n</ul>\n<p>当我们在<code>configure.ac</code>中添加了这些选项之后，可以运行<code>autoheader</code>命令来生成<code>config.h.in</code>，这时的模板文件中会有以下这样的记录</p>\n<pre><code>/* Define to 1 if you have the &lt;unistd.h&gt; header file. */\n#undef HAVE_UNISTD_H\n</code></pre>\n<ul>\n<li>注意：<code>#undef HAVE_UNISTD_H</code> 只是占位宏，值还没有确定</li>\n<li>这个宏的名字是由 AC_CHECK_HEADERS 自动生成的</li>\n</ul>\n<p>有了<code>config.h.in</code>文件之后，如果我们运行了<code>./configure</code>后，工具会检测系统中是否有<code>&lt;unistd.h&gt;</code>根据最终结果来生成<code>config.h</code>头文件，如果包含有那么在<code>config.h</code>文件中，就会多出</p>\n<pre><code class=\"language-c\">#define HAVE_UNISTD_H 1\n\n//如果没有该头文件的话\n/* #undef HAVE_UNISTD_H */\n</code></pre>\n<p>后续我们就可以通过包含<code>config.h</code>文件来进行条件编译了，这样代码可以在不同平台上自动适配，而不需要手动修改</p>\n<pre><code class=\"language-c\">#include \"config.h\"\n\n#ifdef HAVE_UNISTD_H\n#include &lt;unistd.h&gt;\n#endif\n\nint main() {\n#ifdef HAVE_UNISTD_H\n    write(1, \"unistd.h exists\\n\", 16);\n#else\n    printf(\"unistd.h not found\\n\");\n#endif\n    return 0;\n}\n</code></pre>\n<p>总结：</p>\n<ul>\n<li><code>config.h.in</code> = <strong>模板文件</strong>，列出待检测的宏</li>\n<li><code>./configure</code> = <strong>系统检测器</strong>，把模板宏填上实际值</li>\n<li><code>config.h</code> = <strong>最终宏定义文件</strong>，代码条件编译使用</li>\n<li>条件编译语句 (<code>#ifdef</code>) 永远需要开发者在代码里自己写</li>\n</ul>\n<h1 id=\"二autotools实例分析\">二、Autotools实例分析</h1>\n<p>这一章节主要是对autotools的具体使用举例。</p>\n<p><strong>第一步</strong>：创建demo工程项目，新建了一个源码文件夹，创建一个c文件，编写了一个简单的代码。<br />\n<img alt=\"Pasted image 20260216140420.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209096-1334942740.png\" /></p>\n<p><strong>第二步</strong>：生成<code>configure.ac</code>文件。在源码路径下执行了<code>autoscan</code>命令之后，可以看见<code>configure.scan</code>文件已经生成出来了<br />\n<img alt=\"Pasted image 20260216141414.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209334-698108259.png\" /><br />\n可以打开这个文件查看，就是一些功能宏定义<br />\n<img alt=\"Pasted image 20260216141527.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209314-113774963.png\" /><br />\n宏解释：</p>\n<ul>\n<li><code>AC_PREREQ()</code>宏声明本文件要求的autoconf版本，本例使用的版本为2.71</li>\n<li><code>AC_INIT()</code>中分别的是: 软件包的名字，版本，作者的联系方式(一般是Email)</li>\n<li><code>AC_CONFIG_SRCDIR</code>宏用来侦测所指定的源码文件是否存在，来确定源码目录的有效性。此处为当前目录下的test.c，如果有多个源文件的话选择一个主要的文件，通常是 <code>main.c</code> 或其他代表源代码位置的文件。</li>\n<li><code>AC_CONFIG_HEADER</code>宏用于生成config.h文件，以便autoheader使用</li>\n<li><code>AC_PROG_CC</code>用来指定编译器，如果不指定，选用默认gcc。 比如: AC_PROG_CC(gcc)</li>\n<li><code>AC_OUTPUT</code>用来设定 configure 所要产生的文件，如果是makefile，configure会把它检查出来的结果带入makefile.in文件产生合适的makefile。使用Automake时，还需要一些其他的参数，这些额外的宏用aclocal工具产生</li>\n</ul>\n<p>这些宏可以直接到 <a href=\"https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html#Making-configure-Scripts\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html#Making-configure-Scripts</a> 官方文档中去查询</p>\n<p>最后修改这个模板文件，填入自己的软件信息，并将<code>configure.scan</code>重命名为<code>configure.ac</code>文件<br />\n<img alt=\"Pasted image 20260216160011.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209315-856118383.png\" /><br />\n这里有几点需要注意，第一就是注意填写好自己软件的信息，第二就是如果我们后续要使用<code>automake</code>工具的话，需要添加一行<code>AM_INIT_AUTOMAKE</code>，并且需要指定构建行为常用的选项为<code>[foreign]</code>如果不指定的话，就是<code>[gnu]</code>严格模式，会检查AUTHORS、NEWS、README、ChangeLog、COPYING、INSTALL等文件，如果缺失的话，后续使用<code>automake</code>就会报错，这是我踩的一个坑，对于现代的项目，大多数使用<code>git</code>代码管理，对于这些文件有一些是不必要的，所以这里可以关闭GNU strict模式，如果你需要使用GNU的严格模式的话，创建这些所需文件就可以解决报错。第三点就是记得添加输出文件列表的宏<code>AC_CONFIG_FILES([文件名])</code>这三点编辑好之后，一个基础的<code>configure.ac</code>就编辑好了</p>\n<p><strong>第三步</strong>：生成<code>aclocal.m4</code>文件，因为我们后续要使用到<code>automake</code>工具，需要依赖<code>aclocal.m4</code>文件，所以这一步通过<code>aclocal</code>来生成<code>aclocal.m4</code>文件<br />\n<img alt=\"Pasted image 20260216144207.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209281-1527369101.png\" /></p>\n<p>可以看见执行了<code>aclocal</code>之后，<code>aclocal.m4</code>文件成功输出了</p>\n<p><strong>第四步</strong>：生成<code>config.h.in</code>文件，因为我们在<code>configure</code>中使用了宏检查，需要输出<code>config.h</code>，所以我们需要先生成<code>config.h.in</code><br />\n<img alt=\"Pasted image 20260216144505.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209256-1503264093.png\" /><br />\n执行<code>autoheader</code>命令之后，<code>config.h.in</code>也成功生成了</p>\n<p><strong>第五步</strong>：生成<code>configure</code>文件，使用<code>autoconf</code>命令得到<code>configure</code>脚本文件<br />\n<img alt=\"Pasted image 20260216145556.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209281-1821923245.png\" /><br />\n如果这时候我们直接运行这个脚本，可以发现，缺少<code>install-sh</code>脚本，这个脚本就是通过<code>automake</code>来生成的<br />\n<img alt=\"Pasted image 20260216145731.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209052-662252426.png\" /></p>\n<p><strong>第六步</strong>：编写<code>Makefile.am</code>文件，执行<code>automake</code>命令。这里只写了一个比较简单的<code>Makefile.am</code>进行测试<br />\n<img alt=\"Pasted image 20260216161303.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209025-2002039184.png\" /><br />\n<code>Makefile.am</code>文件编写规范非常重要，这里指出我踩到的另外一个坑，<code>Makefile.am</code>文件中的这两个宏定义，必须得规范否则也会爆出错误或者警告。</p>\n<p><code>bin_PROGRAMS</code>的含义是生成一个可执行文件 test，并在 <code>make install</code> 时安装到<code>$(bindir)</code>，一般情况下<code>$(bindir) = /usr/local/bin</code><br />\n<code>test_SOURCES</code>的结构为<code>&lt;目标名&gt;_SOURCES</code>目标名必须和<code>bin_PROGRAMS</code>的程序名完全一致，否则 Automake 会报错</p>\n<p>除了<code>bin_PROGRAMS</code>还有其他Automake内部已经定义好的安装目录变量</p>\n<table>\n<thead>\n<tr>\n<th>变量</th>\n<th>安装目录</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bin_PROGRAMS</td>\n<td>$(bindir) → /usr/local/bin</td>\n</tr>\n<tr>\n<td>sbin_PROGRAMS</td>\n<td>$(sbindir)</td>\n</tr>\n<tr>\n<td>libexec_PROGRAMS</td>\n<td>$(libexecdir)</td>\n</tr>\n<tr>\n<td>noinst_PROGRAMS</td>\n<td>不安装，只编译</td>\n</tr>\n<tr>\n<td>check_PROGRAMS</td>\n<td>测试程序</td>\n</tr>\n<tr>\n<td>具体其他宏的功能，大家可以查看官方的文档，这篇文章主要是autotools工具的使用，这里就不深入剖析底层了</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>还有一个需要注意的点是，如果我们这时候直接使用<code>automake</code>命令，会提示报错，工具也对我们继续了提示需要加上<code>--add-missing</code>选项，添加选项--add-missing 可以让automake工具自动添加必要的脚本文件，这里也可以看见如果<code>AM_INIT_AUTOMAKE</code>没有关闭GNU的严格模式，会报出缺失必要文件的错误。这里是因为这张图是没有修改的时候截取的，修改之后我没有重新<code>automake</code><br />\n<img alt=\"Pasted image 20260216150528.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209349-1310847039.png\" /><br />\n加上该选项，并修改了<code>AM_INIT_AUTOMAKE</code>之后，再次执行<code>automake</code>命令执行成功，并成功生成<code>Makefile.in</code>文件和<code>install-sh</code>文件<br />\n<img alt=\"Pasted image 20260216151252.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209051-539778253.png\" /></p>\n<p><strong>第七步</strong>：执行<code>configure</code>脚本，更具<code>Makfile.in</code>、<code>config.h.in</code>生成最后的文件。<br />\n<img alt=\"Pasted image 20260216163034.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209360-2035713464.png\" /><br />\n可以看见成功生成了<code>config.status</code>以及<code>Makefile</code>文件，打开该<code>Makefile</code>文件，可以看见生成了700多行<br />\n<img alt=\"Pasted image 20260216164053.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209182-33307432.png\" /><br />\n我们非常简单的一个代码，<code>autotools</code>工具给我们生成了700多行的<code>Makefile</code>文件，其中大量的代码都是用来检测环境和编译器相关的内容。有了<code>Makefile</code>之后，我们就可以直接使用<code>make</code>命令来编译了<br />\n<img alt=\"Pasted image 20260216164308.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209147-1035686151.png\" /><br />\n并且生成了对应的可执行文件，同时我们可以执行<code>make install</code>进行系统安装，默认安装到<code>/user/local/bin</code>下，需要注意的是使用<code>make install</code>时需要权限。<br />\n<img alt=\"Pasted image 20260216164615.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209129-81980537.png\" /></p>\n<p>我们可以使用<code>make dist</code>用来生成一个源码压缩包，拿到这个包之后，我们就可以将工程发布给别人或者发布成release版本了<br />\n<img alt=\"Pasted image 20260216164748.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209359-157961370.png\" /><br />\n至此整个<code>Autotools</code>最基本的流程与用法就结束了，当然在实际开发当中，我们不可能只有一个源文件，之后的博客会对实际工程项目情况举例与分析。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:24</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ttkwzyttk\">ttkwzyttk</a>&nbsp;\n阅读(<span id=\"post_view_count\">49</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "零代码零基础！小红书MCP全自动化运营【保姆级安装教程】",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19621617",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19621617\" id=\"cb_post_title_url\" title=\"å‘å¸ƒäºŽ 2026-02-17 13:49\">\n    <span>é›¶ä»£ç é›¶åŸºç¡€ï¼å°çº¢ä¹¦MCPå…¨è‡ªåŠ¨åŒ–è¿è¥ã€ä¿å§†çº§å®‰è£…æ•™ç¨‹ã€‘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        å°çº¢ä¹¦MCPè‡ªåŠ¨åŒ–å·¥å…·éƒ¨ç½²æŒ‡å— æ‘˜è¦ï¼šæœ¬æ–‡è¯¦ç»†ä»‹ç»å¦‚ä½•å¿«é€Ÿéƒ¨ç½²å°çº¢ä¹¦MCPè‡ªåŠ¨åŒ–è¿è¥å·¥å…·ã€‚é€šè¿‡ä¸‹è½½é¢„ç¼–è¯‘å®‰è£…åŒ…ï¼Œå®ŒæˆNode.jsçŽ¯å¢ƒé…ç½®åŽï¼Œè¿è¡Œç™»å½•å·¥å…·èŽ·å–cookies.jsonè®¤è¯æ–‡ä»¶ï¼Œå¯åŠ¨MCPä¸»æœåŠ¡å¹¶éªŒè¯è¿žæŽ¥ã€‚æœ€åŽæŽ¥å…¥Cursorç¼–è¾‘å™¨å®žçŽ°è‡ªç„¶è¯­è¨€æŽ§åˆ¶ï¼Œæ¼”ç¤ºäº†è´¦å·çŠ¶æ€æ£€æŸ¥å’Œå›¾æ–‡å‘å¸ƒç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€å¤æ‚é…ç½®ï¼Œé€‚åˆæ–°æ‰‹å¿«é€Ÿå®žçŽ°å°çº¢ä¹¦å†…å®¹è‡ªåŠ¨åŒ–ç®¡ç†ã€‚\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>@</p><div class=\"toc\"><div class=\"toc-container-header\">ç›®å½•</div><ul><li><a href=\"#ä¸€å‰è¨€\" rel=\"noopener nofollow\">ä¸€ã€å‰è¨€</a></li><li><a href=\"#äºŒå‡†å¤‡å·¥ä½œ\" rel=\"noopener nofollow\">äºŒã€å‡†å¤‡å·¥ä½œ</a><ul><li><a href=\"#21-ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž\" rel=\"noopener nofollow\">2.1 ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž</a></li><li><a href=\"#22-å¿…è£…ä¾èµ–ä»…2ä¸ªæžç®€\" rel=\"noopener nofollow\">2.2 å¿…è£…ä¾èµ–ï¼ˆä»…2ä¸ªï¼Œæžç®€ï¼‰</a><ul><li><a href=\"#1nodejsç”¨äºŽmcpè¿žæŽ¥éªŒè¯\" rel=\"noopener nofollow\">ï¼ˆ1ï¼‰Node.jsï¼ˆç”¨äºŽMCPè¿žæŽ¥éªŒè¯ï¼‰</a></li><li><a href=\"#2ç½‘ç»œçŽ¯å¢ƒ\" rel=\"noopener nofollow\">ï¼ˆ2ï¼‰ç½‘ç»œçŽ¯å¢ƒ</a></li></ul></li><li><a href=\"#23-ä¸‹è½½å°çº¢ä¹¦mcpå®‰è£…åŒ\" rel=\"noopener nofollow\">2.3 ä¸‹è½½å°çº¢ä¹¦MCPå®‰è£…åŒ…</a></li></ul></li><li><a href=\"#ä¸‰éƒ¨ç½²å°çº¢ä¹¦mcpæœåŠ¡\" rel=\"noopener nofollow\">ä¸‰ã€éƒ¨ç½²å°çº¢ä¹¦MCPæœåŠ¡</a><ul><li><a href=\"#31-è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„\" rel=\"noopener nofollow\">3.1 è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„</a></li><li><a href=\"#32-è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯\" rel=\"noopener nofollow\">3.2 è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯</a></li><li><a href=\"#33-å¯åŠ¨mcpä¸»æœåŠ¡\" rel=\"noopener nofollow\">3.3 å¯åŠ¨MCPä¸»æœåŠ¡</a></li><li><a href=\"#34-éªŒè¯mcpæœåŠ¡æ˜¯å¦æ­£å¸¸\" rel=\"noopener nofollow\">3.4 éªŒè¯MCPæœåŠ¡æ˜¯å¦æ­£å¸¸</a></li></ul></li><li><a href=\"#å››æŽ¥å…¥cursorç¼–è¾‘å™¨\" rel=\"noopener nofollow\">å››ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨</a><ul><li><a href=\"#41-æ‰¾åˆ°cursorçš„mcpé…ç½®æ–‡ä»¶\" rel=\"noopener nofollow\">4.1 æ‰¾åˆ°Cursorçš„MCPé…ç½®æ–‡ä»¶</a></li><li><a href=\"#42-é…ç½®mcpè¿žæŽ¥ä¿¡æ¯\" rel=\"noopener nofollow\">4.2 é…ç½®MCPè¿žæŽ¥ä¿¡æ¯</a></li><li><a href=\"#43-éªŒè¯cursorä¸Žmcpçš„è¿žæŽ¥\" rel=\"noopener nofollow\">4.3 éªŒè¯Cursorä¸ŽMCPçš„è¿žæŽ¥</a></li></ul></li><li><a href=\"#äº”cursorä¸­ä½¿ç”¨å°çº¢ä¹¦mcpå®žæˆ˜\" rel=\"noopener nofollow\">äº”ã€Cursorä¸­ä½¿ç”¨å°çº¢ä¹¦MCPå®žæˆ˜</a><ul><li><a href=\"#51-åŸºç¡€åŠŸèƒ½æ£€æŸ¥ç™»å½•çŠ¶æ€\" rel=\"noopener nofollow\">5.1 åŸºç¡€åŠŸèƒ½ï¼šæ£€æŸ¥ç™»å½•çŠ¶æ€</a></li><li><a href=\"#52-æ ¸å¿ƒåŠŸèƒ½å‘å¸ƒå°çº¢ä¹¦å›¾æ–‡\" rel=\"noopener nofollow\">5.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å¸ƒå°çº¢ä¹¦å›¾æ–‡</a><ul><li><a href=\"#æ­¥éª¤1å‡†å¤‡å‘å¸ƒç´ æ\" rel=\"noopener nofollow\">æ­¥éª¤1ï¼šå‡†å¤‡å‘å¸ƒç´ æ</a></li><li><a href=\"#æ­¥éª¤2åœ¨cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤\" rel=\"noopener nofollow\">æ­¥éª¤2ï¼šåœ¨Cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤</a></li><li><a href=\"#æ­¥éª¤3æŸ¥çœ‹å‘å¸ƒç»“æžœ\" rel=\"noopener nofollow\">æ­¥éª¤3ï¼šæŸ¥çœ‹å‘å¸ƒç»“æžœ</a></li></ul></li><li><a href=\"#53-å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨\" rel=\"noopener nofollow\">5.3 å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨</a></li></ul></li><li><a href=\"#å…­å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ\" rel=\"noopener nofollow\">å…­ã€å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ</a><ul><li><a href=\"#é—®é¢˜1ç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—ä¸‹è½½æµè§ˆå™¨å¤±è´¥\" rel=\"noopener nofollow\">é—®é¢˜1ï¼šç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—/ä¸‹è½½æµè§ˆå™¨å¤±è´¥</a></li><li><a href=\"#é—®é¢˜2cursoræç¤ºæ— æ³•è¿žæŽ¥åˆ°mcpæœåŠ¡\" rel=\"noopener nofollow\">é—®é¢˜2ï¼šCursoræç¤ºã€Œæ— æ³•è¿žæŽ¥åˆ°MCPæœåŠ¡ã€</a></li><li><a href=\"#é—®é¢˜3å‘å¸ƒå›¾æ–‡æç¤ºå›¾ç‰‡è·¯å¾„é”™è¯¯\" rel=\"noopener nofollow\">é—®é¢˜3ï¼šå‘å¸ƒå›¾æ–‡æç¤ºã€Œå›¾ç‰‡è·¯å¾„é”™è¯¯ã€</a></li><li><a href=\"#é—®é¢˜4è´¦å·è¢«è¸¢ä¸‹çº¿\" rel=\"noopener nofollow\">é—®é¢˜4ï¼šè´¦å·è¢«è¸¢ä¸‹çº¿</a></li></ul></li><li><a href=\"#ä¸ƒæ€»ç»“\" rel=\"noopener nofollow\">ä¸ƒã€æ€»ç»“</a></li></ul></div><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><p></p>\n<h1 id=\"ä¸€å‰è¨€\">ä¸€ã€å‰è¨€</h1>\n<p>å°çº¢ä¹¦MCPï¼ˆxiaohongshu-mcpï¼‰æ˜¯ä¸€æ¬¾èƒ½å®žçŽ°å°çº¢ä¹¦è‡ªåŠ¨åŒ–è¿è¥çš„å·¥å…·ï¼Œæ”¯æŒç™»å½•éªŒè¯ã€å›¾æ–‡/è§†é¢‘å‘å¸ƒã€è¯„è®ºäº’åŠ¨ã€ç”¨æˆ·ä¿¡æ¯æŸ¥è¯¢ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚ç›¸æ¯”æºç ç¼–è¯‘ã€Dockeréƒ¨ç½²ï¼Œ<strong>ä¸‹è½½é¢„ç¼–è¯‘å®‰è£…åŒ…</strong>æ˜¯æœ€å¿«æ·çš„æ–¹å¼ï¼Œæ— éœ€é…ç½®å¼€å‘çŽ¯å¢ƒï¼Œæ–°æ‰‹ä¹Ÿèƒ½å¿«é€Ÿä¸Šæ‰‹ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>æœ¬æ–‡å°†å…¨ç¨‹åŸºäºŽã€Œå®‰è£…åŒ…ä¸‹è½½ã€çš„æ–¹å¼ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ å®Œæˆå°çº¢ä¹¦MCPçš„éƒ¨ç½²ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨ï¼Œå¹¶æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½çš„ä½¿ç”¨ï¼Œè®©ä½ è½»æ¾å®žçŽ°å°çº¢ä¹¦å†…å®¹çš„è‡ªåŠ¨åŒ–ç®¡ç†ã€‚</p>\n<h1 id=\"äºŒå‡†å¤‡å·¥ä½œ\">äºŒã€å‡†å¤‡å·¥ä½œ</h1>\n<h2 id=\"21-ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž\">2.1 ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž</h2>\n<p>æ”¯æŒçš„ç³»ç»Ÿç‰ˆæœ¬ï¼ˆè¯·å¯¹åº”ä¸‹è½½ï¼‰ï¼š</p>\n<ul>\n<li>macOSï¼šApple Siliconï¼ˆarm64ï¼‰/ Intelï¼ˆamd64ï¼‰</li>\n<li>Windowsï¼šx64ï¼ˆWindows 10/11 å‡å¯ï¼‰</li>\n<li>Linuxï¼šx64</li>\n</ul>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"22-å¿…è£…ä¾èµ–ä»…2ä¸ªæžç®€\">2.2 å¿…è£…ä¾èµ–ï¼ˆä»…2ä¸ªï¼Œæžç®€ï¼‰</h2>\n<h3 id=\"1nodejsç”¨äºŽmcpè¿žæŽ¥éªŒè¯\">ï¼ˆ1ï¼‰Node.jsï¼ˆç”¨äºŽMCPè¿žæŽ¥éªŒè¯ï¼‰</h3>\n<p>æ— è®ºå“ªä¸ªç³»ç»Ÿï¼Œå»ºè®®é€šè¿‡å®˜æ–¹æŽ¨èæ–¹å¼å®‰è£…Node.js LTSç‰ˆæœ¬ï¼Œç¡®ä¿çŽ¯å¢ƒå˜é‡è‡ªåŠ¨é…ç½®ï¼š</p>\n<ul>\n<li>Windowsï¼šæ‰“å¼€ã€Œç®¡ç†å‘˜å‘½ä»¤è¡Œã€æ‰§è¡Œ<pre><code class=\"language-bash\">winget install OpenJS.NodeJS.LTS\n</code></pre>\n</li>\n<li>macOS/Linuxï¼šå‚è€ƒ <a href=\"https://nodejs.org/zh-cn/download/\" rel=\"noopener nofollow\" target=\"_blank\">Node.jså®˜æ–¹ä¸‹è½½é¡µ</a> å®‰è£…LTSç‰ˆæœ¬</li>\n</ul>\n<h3 id=\"2ç½‘ç»œçŽ¯å¢ƒ\">ï¼ˆ2ï¼‰ç½‘ç»œçŽ¯å¢ƒ</h3>\n<p>é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆçº¦150MBï¼‰ï¼Œéœ€ç¡®ä¿ç½‘ç»œé€šç•…ï¼ŒåŽç»­æ— éœ€é‡å¤ä¸‹è½½ã€‚</p>\n<h2 id=\"23-ä¸‹è½½å°çº¢ä¹¦mcpå®‰è£…åŒ…\">2.3 ä¸‹è½½å°çº¢ä¹¦MCPå®‰è£…åŒ…</h2>\n<ol>\n<li>æ‰“å¼€ <a href=\"https://github.com/xpzouying/xiaohongshu-mcp/releases\" rel=\"noopener nofollow\" target=\"_blank\">xiaohongshu-mcpçš„GitHub Releasesé¡µé¢</a></li>\n<li>æ ¹æ®è‡ªå·±çš„ç³»ç»Ÿä¸‹è½½å¯¹åº”å®‰è£…åŒ…ï¼š\n<ul>\n<li>Windows x64ï¼š<code>xiaohongshu-mcp-windows-amd64.zip</code></li>\n<li>macOS Apple Siliconï¼š<code>xiaohongshu-mcp-darwin-arm64.zip</code></li>\n<li>macOS Intelï¼š<code>xiaohongshu-mcp-darwin-amd64.zip</code></li>\n<li>Linux x64ï¼š<code>xiaohongshu-mcp-linux-amd64.zip</code></li>\n</ul>\n</li>\n<li>ä¸‹è½½å®ŒæˆåŽï¼Œå°†åŽ‹ç¼©åŒ…è§£åŽ‹åˆ°ä»»æ„ç›®å½•ï¼ˆå»ºè®®è·¯å¾„ä¸å«ä¸­æ–‡/ç©ºæ ¼ï¼Œæ¯”å¦‚ <code>D:\\xiaohongshu-mcp</code> æˆ– <code>/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp</code>ï¼‰ã€‚</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>æ³¨æ„cookies.jsonæ˜¯ç™»å½•ä¹‹åŽæ‰ä¼šæœ‰çš„ï¼Œåˆšåˆšè§£åŽ‹å®Œåªä¼šæœ‰æˆ‘åœˆèµ·æ¥çš„è¿™ä¸¤ä¸ª</p>\n<h1 id=\"ä¸‰éƒ¨ç½²å°çº¢ä¹¦mcpæœåŠ¡\">ä¸‰ã€éƒ¨ç½²å°çº¢ä¹¦MCPæœåŠ¡</h1>\n<h2 id=\"31-è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„\">3.1 è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„</h2>\n<p>è§£åŽ‹åŽç›®å½•å†…ä¼šåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼ˆä»¥Windowsä¸ºä¾‹ï¼‰ï¼š</p>\n<ul>\n<li><code>xiaohongshu-login-windows-amd64.exe</code>ï¼šç™»å½•å·¥å…·ï¼ˆå¿…å…ˆè¿è¡Œï¼‰</li>\n<li><code>xiaohongshu-mcp-windows-amd64.exe</code>ï¼šMCPä¸»æœåŠ¡ç¨‹åº</li>\n</ul>\n<blockquote>\n<p>å…¶ä»–ç³»ç»Ÿå¯¹åº”æ–‡ä»¶ï¼šmacOSæ˜¯<code>xiaohongshu-login-darwin-arm64</code>/<code>xiaohongshu-mcp-darwin-arm64</code>ï¼ŒLinuxæ˜¯<code>xiaohongshu-login-linux-amd64</code>/<code>xiaohongshu-mcp-linux-amd64</code>ã€‚</p>\n</blockquote>\n<h2 id=\"32-è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯\">3.2 è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯</h2>\n<p>è¿™æ˜¯æ ¸å¿ƒæ­¥éª¤ï¼ŒMCPæœåŠ¡ä¾èµ–ç™»å½•åŽçš„Cookiesæ‰èƒ½æ­£å¸¸å·¥ä½œï¼š</p>\n<ol>\n<li>æ‰“å¼€ç»ˆç«¯/å‘½ä»¤è¡Œï¼Œè¿›å…¥è§£åŽ‹ç›®å½•ï¼š\n<ul>\n<li>Windowsï¼šåœ¨è§£åŽ‹æ–‡ä»¶å¤¹ç©ºç™½å¤„å³é”® â†’ ã€Œåœ¨ç»ˆç«¯ä¸­æ‰“å¼€ã€</li>\n<li>macOS/Linuxï¼šæ‰“å¼€ç»ˆç«¯ï¼Œæ‰§è¡Œ <code>cd /ä½ çš„è§£åŽ‹è·¯å¾„/xiaohongshu-mcp</code></li>\n</ul>\n</li>\n<li>è¿è¡Œç™»å½•å·¥å…·ï¼š\n<ul>\n<li>Windowsï¼š<pre><code class=\"language-bash\">./xiaohongshu-login-windows-amd64.exe\n</code></pre>\n</li>\n<li>macOS/Linuxï¼š<pre><code class=\"language-bash\">chmod +x xiaohongshu-login-darwin-arm64  # èµ‹äºˆæ‰§è¡Œæƒé™ï¼ˆä»…é¦–æ¬¡ï¼‰\n./xiaohongshu-login-darwin-arm64\n</code></pre>\n</li>\n</ul>\n</li>\n<li>ç™»å½•æµç¨‹ï¼š\n<ul>\n<li>è¿è¡ŒåŽä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆè€å¿ƒç­‰å¾…ï¼‰ï¼›</li>\n<li>å¼¹å‡ºå°çº¢ä¹¦ç™»å½•é¡µé¢ï¼ˆæ‰«ç /æ‰‹æœºå·ç™»å½•å‡å¯ï¼‰ï¼›</li>\n<li>ç™»å½•æˆåŠŸåŽï¼Œç»ˆç«¯ä¼šæç¤ºã€Œç™»å½•æˆåŠŸã€ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆ <code>cookies.json</code> æ–‡ä»¶ï¼ˆä¿å­˜åœ¨å½“å‰ç›®å½•ï¼Œåˆ‡å‹¿åˆ é™¤ï¼‰ã€‚</li>\n</ul>\n</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<blockquote>\n<p>âš ï¸ é‡è¦æé†’ï¼šå°çº¢ä¹¦è´¦å·ä¸å…è®¸å¤šç½‘é¡µç«¯ç™»å½•ï¼Œç™»å½•MCPåŽï¼Œä¸è¦åœ¨å…¶ä»–æµè§ˆå™¨ç™»å½•åŒä¸€è´¦å·ï¼Œå¦åˆ™ä¼šè¢«è¸¢ä¸‹çº¿ï¼ˆæ‰‹æœºAppç™»å½•ä¸å—å½±å“ï¼‰ã€‚</p>\n</blockquote>\n<h2 id=\"33-å¯åŠ¨mcpä¸»æœåŠ¡\">3.3 å¯åŠ¨MCPä¸»æœåŠ¡</h2>\n<p>ç™»å½•æˆåŠŸåŽï¼Œç»§ç»­åœ¨ç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨MCPæœåŠ¡ï¼š</p>\n<ul>\n<li>Windowsï¼š<pre><code class=\"language-bash\"># æ— å¤´æ¨¡å¼ï¼ˆæ— æµè§ˆå™¨ç•Œé¢ï¼ŒæŽ¨èç”Ÿäº§ä½¿ç”¨ï¼‰\n./xiaohongshu-mcp-windows-amd64.exe\n\n# éžæ— å¤´æ¨¡å¼ï¼ˆæœ‰æµè§ˆå™¨ç•Œé¢ï¼Œè°ƒè¯•ç”¨ï¼‰\n./xiaohongshu-mcp-windows-amd64.exe -headless=false\n</code></pre>\n</li>\n<li>macOS/Linuxï¼š<pre><code class=\"language-bash\">chmod +x xiaohongshu-mcp-darwin-arm64  # èµ‹äºˆæ‰§è¡Œæƒé™ï¼ˆä»…é¦–æ¬¡ï¼‰\n# æ— å¤´æ¨¡å¼\n./xiaohongshu-mcp-darwin-arm64\n# éžæ— å¤´æ¨¡å¼\n./xiaohongshu-mcp-darwin-arm64 -headless=false\n</code></pre>\n</li>\n</ul>\n<p>å¯åŠ¨æˆåŠŸçš„æ ‡å¿—ï¼šç»ˆç«¯æ— æŠ¥é”™ï¼Œä¸”æ˜¾ç¤ºã€ŒMCPæœåŠ¡å¯åŠ¨æˆåŠŸï¼Œç«¯å£ï¼š18060ã€ï¼ˆé»˜è®¤ç«¯å£18060ï¼Œè¯·å‹¿å ç”¨ï¼‰ã€‚<br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"34-éªŒè¯mcpæœåŠ¡æ˜¯å¦æ­£å¸¸\">3.4 éªŒè¯MCPæœåŠ¡æ˜¯å¦æ­£å¸¸</h2>\n<p>æ‰§è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯æœåŠ¡å¯ç”¨æ€§ï¼š</p>\n<pre><code class=\"language-bash\">npx @modelcontextprotocol/inspector\n</code></pre>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\nå·¦ä¸Šè§’<strong>Transport Type</strong>ä¸‹æ‹‰æ¡†ï¼ŒæŠŠSTDIOæ”¹æˆ<strong>Streamable HTTP</strong>ï¼›<br />\næ”¹å®ŒåŽç•Œé¢ä¼šå‡ºçŽ°URLè¾“å…¥æ¡†ï¼ŒæŠŠhttp://localhost:18060/mcpå¡«åˆ°è¿™ä¸ª <strong>URL æ¡†é‡Œ</strong>ï¼›<br />\nç‚¹å‡»å·¦ä¾§çš„<strong>Connect</strong>æŒ‰é’®ã€‚<br />\næˆåŠŸæ ‡å¿—ï¼š<strong>å·¦ä¸‹è§’æ˜¾ç¤ºConnected</strong><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>ç‚¹å‡»ä¸­é—´çš„List Tools<br />\nä¸­é—´åŒºåŸŸåŠ è½½å‡ºå°çº¢ä¹¦ MCP çš„æ‰€æœ‰å·¥å…· / èƒ½åŠ›åˆ—è¡¨ã€<br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h1 id=\"å››æŽ¥å…¥cursorç¼–è¾‘å™¨\">å››ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨</h1>\n<p>Cursoræ˜¯æ”¯æŒMCPåè®®çš„AIç¼–è¾‘å™¨ï¼ŒæŽ¥å…¥åŽå¯ç›´æŽ¥åœ¨Cursorä¸­é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨å°çº¢ä¹¦MCPçš„æ‰€æœ‰åŠŸèƒ½ï¼Œæ— éœ€æ‰‹åŠ¨å†™æŽ¥å£è¯·æ±‚ã€‚</p>\n<h2 id=\"41-æ‰¾åˆ°cursorçš„mcpé…ç½®æ–‡ä»¶\">4.1 æ‰¾åˆ°Cursorçš„MCPé…ç½®æ–‡ä»¶</h2>\n<ol>\n<li>æ‰“å¼€Cursorç¼–è¾‘å™¨ï¼›</li>\n<li>ç¡®è®¤Cursorçš„MCPé…ç½®ç›®å½•ï¼š\n<ul>\n<li>æ ¸å¿ƒé…ç½®æ–‡ä»¶è·¯å¾„å‚è€ƒï¼š<code>.cursor/mcp.json</code>ï¼ˆå¯åœ¨Cursorçš„ã€Œè®¾ç½®â†’MCPã€ä¸­æ‰¾åˆ°é…ç½®å…¥å£ï¼Œæˆ–ç›´æŽ¥åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºè¯¥æ–‡ä»¶ï¼‰ã€‚</li>\n</ul>\n</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"42-é…ç½®mcpè¿žæŽ¥ä¿¡æ¯\">4.2 é…ç½®MCPè¿žæŽ¥ä¿¡æ¯</h2>\n<p>åˆ›å»º/ç¼–è¾‘ <code>.cursor/mcp.json</code> æ–‡ä»¶ï¼Œå†™å…¥ä»¥ä¸‹å†…å®¹ï¼š</p>\n<pre><code class=\"language-json\">{\n    \"mcpServers\": {\n        \"xiaohongshu-mcp\": {\n            \"url\": \"http://localhost:18060/mcp\",\n            \"description\": \"å°çº¢ä¹¦å†…å®¹å‘å¸ƒæœåŠ¡ - MCP Streamable HTTP\"\n        }\n    }\n}\n</code></pre>\n<p>ä¿å­˜æ–‡ä»¶åŽï¼Œé‡å¯Cursorè®©é…ç½®ç”Ÿæ•ˆã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"43-éªŒè¯cursorä¸Žmcpçš„è¿žæŽ¥\">4.3 éªŒè¯Cursorä¸ŽMCPçš„è¿žæŽ¥</h2>\n<ol>\n<li>æ‰“å¼€Cursorï¼Œæ–°å»ºä¸€ä¸ªå¯¹è¯çª—å£ï¼›</li>\n<li>åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ï¼š<code>æ£€æŸ¥å°çº¢ä¹¦MCPçš„ç™»å½•çŠ¶æ€</code>ï¼›</li>\n<li>å‘é€æŒ‡ä»¤åŽï¼ŒCursorä¼šè‡ªåŠ¨è°ƒç”¨å°çº¢ä¹¦MCPçš„ã€Œæ£€æŸ¥ç™»å½•çŠ¶æ€ã€åŠŸèƒ½ï¼Œè¿”å›žã€Œå½“å‰è´¦å·å·²ç™»å½•ã€å³ä»£è¡¨æŽ¥å…¥æˆåŠŸã€‚</li>\n</ol>\n<h1 id=\"äº”cursorä¸­ä½¿ç”¨å°çº¢ä¹¦mcpå®žæˆ˜\">äº”ã€Cursorä¸­ä½¿ç”¨å°çº¢ä¹¦MCPå®žæˆ˜</h1>\n<h2 id=\"51-åŸºç¡€åŠŸèƒ½æ£€æŸ¥ç™»å½•çŠ¶æ€\">5.1 åŸºç¡€åŠŸèƒ½ï¼šæ£€æŸ¥ç™»å½•çŠ¶æ€</h2>\n<p>åœ¨Cursorå¯¹è¯æ¡†ä¸­è¾“å…¥ï¼š</p>\n<pre><code>æ£€æŸ¥æˆ‘çš„å°çº¢ä¹¦è´¦å·ç™»å½•çŠ¶æ€\n</code></pre>\n<p>å‘é€åŽï¼ŒMCPä¼šè¿”å›žå½“å‰è´¦å·çš„ç™»å½•çŠ¶æ€ï¼ˆå·²ç™»å½•/æœªç™»å½•ï¼‰ï¼Œå¦‚æžœæœªç™»å½•ï¼Œéœ€é‡æ–°è¿è¡Œç™»å½•å·¥å…·ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"52-æ ¸å¿ƒåŠŸèƒ½å‘å¸ƒå°çº¢ä¹¦å›¾æ–‡\">5.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å¸ƒå°çº¢ä¹¦å›¾æ–‡</h2>\n<h3 id=\"æ­¥éª¤1å‡†å¤‡å‘å¸ƒç´ æ\">æ­¥éª¤1ï¼šå‡†å¤‡å‘å¸ƒç´ æ</h3>\n<ul>\n<li>æœ¬åœ°å›¾ç‰‡ï¼šå°†å›¾ç‰‡æ”¾åˆ°MCPè§£åŽ‹ç›®å½•çš„ <code>images</code> æ–‡ä»¶å¤¹ï¼ˆæ²¡æœ‰åˆ™æ–°å»ºï¼‰ï¼›</li>\n<li>æ–‡æ¡ˆï¼šæ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰+ æ­£æ–‡ï¼ˆâ‰¤1000å­—ï¼‰+ æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰ã€‚</li>\n</ul>\n<h3 id=\"æ­¥éª¤2åœ¨cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤\">æ­¥éª¤2ï¼šåœ¨Cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤</h3>\n<pre><code>@xiaohongshu-mcp å‘å¸ƒä¸€ç¯‡å°çº¢ä¹¦å›¾æ–‡ï¼Œæ ‡é¢˜ï¼šã€Œæ–°æ‰‹å¿…çœ‹çš„MCPéƒ¨ç½²æ•™ç¨‹ã€ï¼Œæ­£æ–‡ï¼šã€Œæ— éœ€ç¼–è¯‘æºç ï¼Œä¸‹è½½å®‰è£…åŒ…å°±èƒ½éƒ¨ç½²å°çº¢ä¹¦MCPï¼Œé™„CursoræŽ¥å…¥å…¨æµç¨‹ï½žã€ï¼Œå›¾ç‰‡ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp/images/æ•™ç¨‹å°é¢.jpgï¼Œæ·»åŠ æ ‡ç­¾ï¼š#MCP #å°çº¢ä¹¦è‡ªåŠ¨åŒ– #Cursor\n</code></pre>\n<blockquote>\n<p>æ³¨æ„ï¼š</p>\n<ul>\n<li>å›¾ç‰‡è·¯å¾„éœ€å†™ç»å¯¹è·¯å¾„ï¼ˆWindowsç¤ºä¾‹ï¼š<code>D:\\xiaohongshu-mcp\\images\\æ•™ç¨‹å°é¢.jpg</code>ï¼‰ï¼›</li>\n<li>æ ‡é¢˜å’Œæ­£æ–‡éœ€ç¬¦åˆå°çº¢ä¹¦å­—æ•°é™åˆ¶ï¼ˆæ ‡é¢˜â‰¤20å­—ï¼Œæ­£æ–‡â‰¤1000å­—ï¼‰ã€‚</li>\n</ul>\n</blockquote>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h3 id=\"æ­¥éª¤3æŸ¥çœ‹å‘å¸ƒç»“æžœ\">æ­¥éª¤3ï¼šæŸ¥çœ‹å‘å¸ƒç»“æžœ</h3>\n<p>å‘é€æŒ‡ä»¤åŽï¼ŒCursorä¼šè¿”å›žå‘å¸ƒè¿›åº¦ï¼ŒæˆåŠŸåŽå¯åœ¨å°çº¢ä¹¦Appä¸­æŸ¥çœ‹å‘å¸ƒçš„ç¬”è®°ã€‚</p>\n<h2 id=\"53-å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨\">5.3 å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨</h2>\n<ul>\n<li>å‘å¸ƒè§†é¢‘ï¼š<pre><code>@xiaohongshu-mcp å‘å¸ƒå°çº¢ä¹¦è§†é¢‘ï¼Œæ ‡é¢˜ï¼šã€ŒMCPéƒ¨ç½²å®žæ“æ¼”ç¤ºã€ï¼Œæ­£æ–‡ï¼šã€Œæ‰‹æŠŠæ‰‹æ•™ä½ éƒ¨ç½²å°çº¢ä¹¦MCPï½žã€ï¼Œè§†é¢‘è·¯å¾„ï¼š/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp/videos/æ¼”ç¤º.mp4\n</code></pre>\n</li>\n<li>èŽ·å–ç”¨æˆ·ä¸ªäººä¸»é¡µï¼š<pre><code>@xiaohongshu-mcp èŽ·å–ç”¨æˆ·IDä¸º123456çš„å°çº¢ä¹¦ä¸ªäººä¸»é¡µä¿¡æ¯\n</code></pre>\n</li>\n<li>å‘è¡¨è¯„è®ºï¼š<pre><code>@xiaohongshu-mcp ç»™å¸–å­IDä¸º741852çš„å°çº¢ä¹¦ç¬”è®°å‘è¡¨è¯„è®ºï¼šã€Œæ•™ç¨‹è¶…å®žç”¨ï¼ã€\n</code></pre>\n</li>\n</ul>\n<h1 id=\"å…­å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ\">å…­ã€å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ</h1>\n<h2 id=\"é—®é¢˜1ç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—ä¸‹è½½æµè§ˆå™¨å¤±è´¥\">é—®é¢˜1ï¼šç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—/ä¸‹è½½æµè§ˆå™¨å¤±è´¥</h2>\n<ul>\n<li>åŽŸå› ï¼šç½‘ç»œé™åˆ¶æˆ–æƒé™ä¸è¶³ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>ç¡®ä¿ç½‘ç»œèƒ½è®¿é—®å¤–ç½‘ï¼Œæˆ–åˆ‡æ¢ç½‘ç»œé‡è¯•ï¼›</li>\n<li>Windowséœ€ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œç»ˆç«¯ï¼ŒmacOS/Linuxéœ€èµ‹äºˆæ–‡ä»¶æ‰§è¡Œæƒé™ï¼ˆ<code>chmod +x æ–‡ä»¶å</code>ï¼‰ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜2cursoræç¤ºæ— æ³•è¿žæŽ¥åˆ°mcpæœåŠ¡\">é—®é¢˜2ï¼šCursoræç¤ºã€Œæ— æ³•è¿žæŽ¥åˆ°MCPæœåŠ¡ã€</h2>\n<ul>\n<li>åŽŸå› ï¼šMCPæœåŠ¡æœªå¯åŠ¨/ç«¯å£è¢«å ç”¨/é…ç½®æ–‡ä»¶è·¯å¾„é”™è¯¯ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>æ£€æŸ¥MCPæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼ˆç»ˆç«¯æ˜¯å¦æ˜¾ç¤ºç«¯å£18060ï¼‰ï¼›</li>\n<li>ç¡®è®¤ <code>.cursor/mcp.json</code> ä¸­çš„URLæ˜¯ <code>http://localhost:18060/mcp</code>ï¼›</li>\n<li>æ£€æŸ¥18060ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼ˆWindowsï¼š<code>netstat -ano | findstr 18060</code>ï¼ŒmacOS/Linuxï¼š<code>lsof -i:18060</code>ï¼‰ï¼Œå ç”¨åˆ™å…³é—­å¯¹åº”è¿›ç¨‹ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜3å‘å¸ƒå›¾æ–‡æç¤ºå›¾ç‰‡è·¯å¾„é”™è¯¯\">é—®é¢˜3ï¼šå‘å¸ƒå›¾æ–‡æç¤ºã€Œå›¾ç‰‡è·¯å¾„é”™è¯¯ã€</h2>\n<ul>\n<li>åŽŸå› ï¼šå›¾ç‰‡è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„/æœªæ”¾åˆ°æŒ‡å®šç›®å½•ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ˆå¦‚ <code>D:\\xiaohongshu-mcp\\images\\test.jpg</code>ï¼‰ï¼›</li>\n<li>ç¡®ä¿å›¾ç‰‡æ–‡ä»¶å­˜åœ¨ï¼Œä¸”è·¯å¾„æ— ä¸­æ–‡/ç©ºæ ¼ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜4è´¦å·è¢«è¸¢ä¸‹çº¿\">é—®é¢˜4ï¼šè´¦å·è¢«è¸¢ä¸‹çº¿</h2>\n<ul>\n<li>åŽŸå› ï¼šåŒä¸€è´¦å·åœ¨å…¶ä»–ç½‘é¡µç«¯ç™»å½•ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>é€€å‡ºå…¶ä»–ç½‘é¡µç«¯çš„å°çº¢ä¹¦ç™»å½•ï¼›</li>\n<li>é‡æ–°è¿è¡Œç™»å½•å·¥å…·ï¼Œé‡æ–°ç”ŸæˆCookiesã€‚</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"ä¸ƒæ€»ç»“\">ä¸ƒã€æ€»ç»“</h1>\n<p>é€šè¿‡ã€Œä¸‹è½½å®‰è£…åŒ…ã€çš„æ–¹å¼éƒ¨ç½²å°çº¢ä¹¦MCPï¼Œå…¨ç¨‹æ— éœ€é…ç½®å¤æ‚çš„å¼€å‘çŽ¯å¢ƒï¼ˆå¦‚Golangã€Dockerï¼‰ï¼Œæ–°æ‰‹ä¹Ÿèƒ½åœ¨10åˆ†é’Ÿå†…å®Œæˆéƒ¨ç½²ã€‚æŽ¥å…¥CursoråŽï¼Œå¯ç›´æŽ¥é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨MCPçš„æ‰€æœ‰åŠŸèƒ½ï¼Œå®žçŽ°å°çº¢ä¹¦ç™»å½•éªŒè¯ã€å›¾æ–‡/è§†é¢‘å‘å¸ƒã€è¯„è®ºäº’åŠ¨ç­‰è‡ªåŠ¨åŒ–æ“ä½œã€‚</p>\n<p>âš ï¸ é£Žé™©æç¤ºï¼šè¯¥å·¥å…·ä»…ç”¨äºŽå­¦ä¹ å’Œä¸ªäººåˆæ³•è¿è¥ï¼Œè¯·å‹¿ç”¨äºŽè¿è§„æ“ä½œï¼›Cookiesè¿‡æœŸåŽéœ€é‡æ–°ç™»å½•ï¼Œæ­£å¸¸ä½¿ç”¨ä¸‹ä¸ä¼šå¯¼è‡´è´¦å·å°ç¦ã€‚</p>\n<p>å¦‚æžœåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯å‚è€ƒé¡¹ç›®çš„å®˜æ–¹æ–‡æ¡£ï¼ˆ<a href=\"https://github.com/xpzouying/xiaohongshu-mcp\" rel=\"noopener nofollow\" target=\"_blank\">xiaohongshu-mcp README</a>ï¼‰ï¼Œæˆ–åœ¨GitHub Issuesä¸­æé—®ã€‚</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 13:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\né˜…è¯»(<span id=\"post_view_count\">132</span>)&nbsp;\nè¯„è®º(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">æ”¶è—</a>&nbsp;\n<a href=\"\">ä¸¾æŠ¥</a>\n</div>"
    }
  ]
}