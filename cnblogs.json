{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "【Python 教程15】-Python和Web",
      "link": "https://www.cnblogs.com/javatoai/p/19590227",
      "published": "",
      "description": "<div class=\"posthead\">\n\t\t\t<h2>\n\t\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/javatoai/p/19590227\" id=\"cb_post_title_url\" title=\"发布于 2026-02-08 02:41\">\n    <span>【Python 教程15】-Python和Web</span>\n    \n\n</a>\n\n\t\t\t</h2>\n \t\t\tPosted on \n<span id=\"post-date\">2026-02-08 02:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/javatoai\">Java后端的Ai之路</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t\t\n\t\t\t\n\t\t</div>\n\t\t<div class=\"postbody\"><div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"一屏幕抓取web-数据的搬运工\">一、屏幕抓取：Web 数据的“搬运工”<a id=\"scraper\"></a></h2>\n<p><img alt=\"屏幕抓取动漫图\" class=\"lazyload\" /></p>\n<blockquote>\n<p>想象一下，你是个勤劳的“数据搬运工”，每天的工作就是从浩瀚的互联网海洋里，把那些散落在网页上的“金子”（数据）捞出来，然后整理好，变成自己能用的“宝藏”。这就是<strong>屏幕抓取（Web Scraping）</strong>，也叫网络爬虫，它的核心任务就是：<strong>程序化地下载网页内容，并从中提取你想要的信息</strong>。是不是听起来有点像“黑客帝国”里的 Neo，在数字洪流中捕捉关键信息？</p>\n</blockquote>\n<h3 id=\"1-正则表达式快准狠的文本手术刀\">1. 正则表达式：快准狠的“文本手术刀”</h3>\n<blockquote>\n<p>在 Python 的世界里，<strong>正则表达式（Regular Expression，简称 Regex）</strong>就像一把锋利的“手术刀”，能让你在杂乱无章的文本中，精准地切割、匹配、提取出你想要的部分。当网页内容还是一堆“乱码”时，Regex 就是你的“火眼金睛”。</p>\n</blockquote>\n<p><strong>专业解释</strong>：正则表达式是一种用于匹配字符串模式的强大工具。它通过定义一系列特殊字符和语法规则，来描述字符串的搜索模式，从而实现对文本的查找、替换、提取等操作。在屏幕抓取中，我们常用它来从原始 HTML 文本中匹配特定的数据。</p>\n<p><strong>大白话解读</strong>：比如你想从一堆电话号码里找出所有以“138”开头的，或者从一篇文章里找出所有链接，正则表达式就能帮你一秒搞定，比你一个一个找快多了！</p>\n<p><strong>生活案例</strong>：就像你在图书馆里找书，不是一本一本翻，而是直接看书架上的分类标签，正则表达式就是那个帮你快速定位的“分类标签”。</p>\n<p><strong>示例 Python 代码</strong>：</p>\n<pre><code>import re\nimport urllib.request\n​\ndef simple_regex_scraper(url):\n    try:\n        # 模拟浏览器请求，获取网页内容\n        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n        req = urllib.request.Request(url, headers=headers)\n        with urllib.request.urlopen(req) as response:\n            html_content = response.read().decode('utf-8')\n        \n        # 假设我们要抓取Python Job Board上的职位名称和链接\n        # 原始链接：http://python.org/jobs\n        # 注意：实际网站结构可能变化，此代码仅作示例\n        pattern = re.compile(r'&lt;a href=\"(/jobs/\\d+)/?\"&gt;(.*?)&lt;/a&gt;')\n        \n        job_listings = pattern.findall(html_content)\n        \n        print(f\"从 {url} 抓取到的职位信息：\")\n        for job_url_suffix, job_name in job_listings:\n            full_job_url = f\"https://www.python.org{job_url_suffix}\"\n            print(f\"- {job_name} ({full_job_url})\")\n            \n    except Exception as e:\n        print(f\"抓取失败：{e}\")\n​\n# 运行示例\nsimple_regex_scraper('https://www.python.org/jobs/')\n</code></pre>\n<blockquote>\n<p><strong>小提示</strong>：正则表达式虽然强大，但面对复杂的 HTML 结构，比如嵌套很深的标签，或者 HTML 本身就不规范时，它可能会让你抓狂。这时候，我们就需要更“温柔”的工具了！</p>\n</blockquote>\n<h3 id=\"2-html-解析优雅地拆解网页\">2. HTML 解析：优雅地“拆解”网页</h3>\n<blockquote>\n<p>当网页内容不再是简单的文本，而是结构复杂的 HTML 时，我们就需要一个“结构工程师”来帮助我们理解和拆解它。<strong>HTML 解析</strong>就是把一堆 HTML 代码，变成一个有层级、有关系的“积木模型”，这样我们就能轻松找到想要的“积木”了。</p>\n</blockquote>\n<p><strong>专业解释</strong>：HTML 解析是将 HTML 文档（通常是字符串形式）转换为一个可操作的数据结构（如 DOM 树），以便程序能够方便地访问、修改和提取文档中的元素、属性和文本内容。这比直接使用正则表达式匹配原始字符串更健壮和灵活。</p>\n<p><strong>大白话解读</strong>：就像你拿到一份乐高说明书，HTML 解析就是帮你把说明书上的零件（标签）和组装步骤（结构）理清楚，让你知道哪个零件在哪，怎么拼起来。</p>\n<p><strong>生活案例</strong>：你买了一个宜家家具，HTML 解析就像是那个详细的组装说明书，告诉你哪个板子是桌面，哪个是桌腿，以及它们是怎么连接的。</p>\n<p><strong>示例 Python 代码（使用 <code>html.parser</code>）</strong>：</p>\n<pre><code>from urllib.request import urlopen\nfrom html.parser import HTMLParser\n​\nclass JobScraper(HTMLParser):\n    def __init__(self):\n        super().__init__()\n        self.in_job_link = False\n        self.current_job_name = []\n        self.job_listings = []\n​\n    def handle_starttag(self, tag, attrs):\n        if tag == 'a':\n            attrs_dict = dict(attrs)\n            href = attrs_dict.get('href')\n            # 检查是否是职位链接，这里简化判断，实际可能需要更复杂的逻辑\n            if href and '/jobs/' in href and href.split('/')[-1].isdigit():\n                self.in_job_link = True\n                self.current_job_url = f\"https://www.python.org{href}\"\n                self.current_job_name = []\n​\n    def handle_data(self, data):\n        if self.in_job_link:\n            self.current_job_name.append(data.strip())\n​\n    def handle_endtag(self, tag):\n        if tag == 'a' and self.in_job_link:\n            job_name = ''.join(self.current_job_name).strip()\n            if job_name:\n                self.job_listings.append(f\"{job_name} ({self.current_job_url})\")\n            self.in_job_link = False\n​\ndef html_parser_scraper(url):\n    try:\n        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n        req = urllib.request.Request(url, headers=headers)\n        with urllib.request.urlopen(req) as response:\n            html_content = response.read().decode('utf-8')\n​\n        parser = JobScraper()\n        parser.feed(html_content)\n        parser.close()\n​\n        print(f\"\\n使用 HTMLParser 从 {url} 抓取到的职位信息：\")\n        for job in parser.job_listings:\n            print(f\"- {job}\")\n​\n    except Exception as e:\n        print(f\"抓取失败：{e}\")\n​\n# 运行示例\nhtml_parser_scraper('https://www.python.org/jobs/')\n</code></pre>\n<blockquote>\n<p><strong>温馨提示</strong>：<code>HTMLParser</code> 是 Python 标准库自带的，用起来比较底层，需要自己处理各种标签事件。如果你觉得这有点像“手搓”螺丝，那么接下来要介绍的“电动工具”一定会让你爱不释手！</p>\n</blockquote>\n<h3 id=\"3-beautiful-soup应对脏乱差网页的神器\">3. Beautiful Soup：应对“脏乱差”网页的“神器”</h3>\n<blockquote>\n<p>互联网上的网页可不是都那么“规矩”的，很多时候它们就像一堆被熊孩子玩过的乐高积木，缺胳膊少腿，乱七八糟。这时候，<strong>Beautiful Soup</strong> 就闪亮登场了！它是一个专门用来“收拾烂摊子”的工具，即使面对格式再糟糕的 HTML，它也能帮你优雅地解析出来。</p>\n</blockquote>\n<p><strong>专业解释</strong>：Beautiful Soup 是一个 Python 库，用于从 HTML 或 XML 文件中提取数据。它能够处理不规范的 HTML 标记，并提供简单、Pythonic 的方式来导航、搜索和修改解析树。它构建了一个解析树，使得开发者可以通过标签名、属性、CSS 选择器等多种方式轻松定位元素。</p>\n<p><strong>大白话解读</strong>：Beautiful Soup 就像一个“超级保姆”，不管你的 HTML 代码有多“熊”，它都能帮你整理得服服帖帖，让你想找什么数据，就像在自己家里找东西一样简单。</p>\n<p><strong>生活案例</strong>：你家孩子把玩具撒了一地，Beautiful Soup 就像那个能自动分类整理玩具的“智能机器人”，把小汽车放一堆，积木放一堆，让你一眼就能找到想要的。</p>\n<p><strong>示例 Python 代码</strong>：</p>\n<pre><code>from urllib.request import urlopen\nfrom bs4 import BeautifulSoup\n​\ndef beautiful_soup_scraper(url):\n    try:\n        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n        req = urllib.request.Request(url, headers=headers)\n        with urllib.request.urlopen(req) as response:\n            html_content = response.read()\n        \n        # 使用Beautiful Soup解析HTML\n        soup = BeautifulSoup(html_content, 'html.parser')\n        \n        job_listings = set()\n        # 假设职位信息在body的第一个section下的h2标签中，且h2中包含a标签\n        # 注意：实际网站结构可能变化，此代码仅作示例\n        # 寻找所有class为'listing-row'的div，或者直接寻找h2标签内的a链接\n        # 示例：soup.find_all('h2') 或者 soup.select('section.listing-section h2 a')\n        \n        # 针对Python官网jobs页面的结构，我们可以尝试更直接的方式\n        # 查找所有class为'listing-row'的div，然后从里面提取链接和文本\n        for listing in soup.find_all('div', class_='listing-row'):\n            link_tag = listing.find('h2').find('a')\n            if link_tag:\n                job_name = link_tag.get_text(strip=True)\n                job_url_suffix = link_tag.get('href')\n                full_job_url = f\"https://www.python.org{job_url_suffix}\"\n                job_listings.add(f\"{job_name} ({full_job_url})\")\n​\n        print(f\"\\n使用 Beautiful Soup 从 {url} 抓取到的职位信息：\")\n        for job in sorted(list(job_listings), key=str.lower):\n            print(f\"- {job}\")\n            \n    except Exception as e:\n        print(f\"抓取失败：{e}\")\n​\n# 运行示例\nbeautiful_soup_scraper('https://www.python.org/jobs/')\n</code></pre>\n<blockquote>\n<p><strong>总结一下</strong>：屏幕抓取就像是互联网世界的“寻宝游戏”。正则表达式是你的“藏宝图碎片”，帮你识别特定模式；<code>HTMLParser</code> 是你的“放大镜”，帮你细致地查看 HTML 结构；而 <code>Beautiful Soup</code> 则是你的“万能工具箱”，不管遇到多复杂的“宝藏箱”，它都能帮你打开！</p>\n</blockquote>\n<h2 id=\"二cgi让你的网页动起来\">二、CGI：让你的网页“动”起来<a id=\"cgi\"></a></h2>\n<p><img alt=\"CGI 动漫图\" class=\"lazyload\" /></p>\n<blockquote>\n<p>如果说屏幕抓取是把别人的网页“搬”回家，那 <strong>CGI（Common Gateway Interface，通用网关接口）</strong>就是让你自己家的网页“活”起来的魔法！静态网页就像一张张精美的海报，虽然好看，但不会对你的任何行为做出反应。而有了 CGI，你的网页就变成了一个能和你互动的“智能机器人”！</p>\n</blockquote>\n<h3 id=\"1-cgi-基础web-服务器的传话筒\">1. CGI 基础：Web 服务器的“传话筒”</h3>\n<blockquote>\n<p>想象一下，Web 服务器（比如 Apache）是个“餐厅老板”，它只负责接待客人（用户请求），但不会做菜（处理动态请求）。CGI 脚本就是那个“大厨”，当客人点了份“宫保鸡丁”（提交了一个表单），老板就会通过 CGI 这个“传话筒”，把订单告诉大厨。大厨做好菜后，再通过老板端给客人。</p>\n</blockquote>\n<p><strong>专业解释</strong>：CGI 是一种标准，定义了 Web 服务器如何与外部脚本（CGI 脚本）进行通信，以处理动态请求。当 Web 服务器收到一个指向 CGI 脚本的请求时，它会执行该脚本，并将请求的详细信息（如表单数据、URL 参数等）作为环境变量或标准输入传递给脚本。脚本处理完请求后，将生成的 HTML 或其他内容作为标准输出返回给 Web 服务器，最终由服务器发送给客户端浏览器。</p>\n<p><strong>大白话解读</strong>：你访问一个网站，填了个登录表单，点击“登录”按钮。这时候，Web 服务器就把你的用户名和密码通过 CGI 交给了后台的 Python 脚本。Python 脚本验证了一下，发现你是合法用户，就生成一个“欢迎回来！”的页面，再通过 Web 服务器显示给你看。整个过程，CGI 就是那个负责“沟通”的桥梁。</p>\n<p><strong>生活案例</strong>：你去银行 ATM 机取钱，ATM 机就是 Web 服务器，你插卡、输密码就是用户请求。ATM 机本身不处理你的账户信息，它通过一个内部接口（类似 CGI）把你的请求发给银行的后台系统。后台系统验证通过后，告诉 ATM 机吐多少钱，ATM 机再把钱给你。这个内部接口就是 CGI 的角色。</p>\n<p><strong>示例 Python 代码（一个简单的 CGI 脚本）</strong>：</p>\n<pre><code>#!/usr/bin/env python\n# -*- coding: UTF-8 -*-\n​\n# 引入cgi模块，方便处理CGI请求\nimport cgi\nimport cgitb\n​\n# 开启调试模式，出错时会在浏览器显示详细信息\ncgitb.enable()\n​\n# 创建FieldStorage实例，用于获取表单数据\nform = cgi.FieldStorage()\n​\n# 获取表单中名为'name'的字段值\nuser_name = form.getvalue('name', '路人甲')\n​\n# ---- CGI脚本的核心：输出 ----\n# 1. 首先，必须输出一个Content-type头，告诉浏览器我们发送的是HTML\nprint(\"Content-type:text/html\\n\\n\")\n​\n# 2. 接着，输出HTML内容\nprint(\"&lt;html&gt;\")\nprint(\"&lt;head&gt;\")\nprint(\"&lt;title&gt;CGI 脚本初体验&lt;/title&gt;\")\nprint(\"&lt;/head&gt;\")\nprint(\"&lt;body&gt;\")\nprint(f\"&lt;h2&gt;你好, {user_name}! 欢迎来到CGI的魔法世界！&lt;/h2&gt;\")\nprint(\"&lt;/body&gt;\")\nprint(\"&lt;/html&gt;\")\n</code></pre>\n<blockquote>\n<p><strong>注意</strong>：要运行 CGI 脚本，你需要一个配置好的 Web 服务器（如 Apache 或 Nginx），并将脚本放在指定的 <code>cgi-bin</code> 目录下，同时赋予它可执行权限。对于现代 Web 开发来说，直接手写 CGI 已经比较少见了，因为它效率不高，而且每次请求都要创建一个新进程，开销很大。于是，更高级的“烹饪工具”——Web 框架，就应运而生了。</p>\n</blockquote>\n<h3 id=\"2-python-web-框架告别刀耕火种\">2. Python Web 框架：告别“刀耕火种”</h3>\n<blockquote>\n<p>如果说手写 CGI 是“刀耕火种”，那 <strong>Web 框架</strong>就是现代化的“联合收割机”！它们把 Web 开发的各种脏活累活（比如路由、模板渲染、数据库连接、用户认证等）都帮你封装好了，让你能专注于业务逻辑的实现，而不是天天跟 HTTP 协议和服务器配置打交道。</p>\n</blockquote>\n<p><img alt=\"Flask 动漫图\" class=\"lazyload\" /></p>\n<p><strong>专业解释</strong>：Web 框架是一套提供了构建 Web 应用所需核心功能的库和工具。它们遵循一定的架构模式（如 MVC 或 MVT），通过提供路由系统、模板引擎、ORM（对象关系映射）、会话管理等组件，极大地简化了 Web 应用的开发流程，提高了开发效率和代码的可维护性。</p>\n<p><strong>大白话解读</strong>：你想盖个房子，Web 框架就是那个已经帮你打好地基、建好承重墙、铺好水电管道的“半成品”。你只需要根据自己的喜好，装修一下墙面、摆放家具（编写业务代码）就行了，省时又省力。</p>\n<p><strong>生活案例</strong>：你想做一道复杂的佛跳墙，自己从头准备鲍鱼、海参、鱼翅……那得累死。Web 框架就像是超市里卖的“佛跳墙半成品料理包”，所有食材都帮你处理好了，你只需要回家按照说明书，简单加热一下就能享受美味。</p>\n<p><strong>示例 Python 代码（使用 Flask 框架）</strong>：</p>\n<pre><code># 安装Flask: pip install Flask\nfrom flask import Flask, request, render_template_string\n​\n# 创建一个Flask应用实例\napp = Flask(__name__)\n​\n# 定义一个HTML模板，用于显示欢迎信息\nHTML_TEMPLATE = \"\"\"\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Flask Web App&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;你好, {{ name }}!&lt;/h1&gt;\n    &lt;p&gt;欢迎来到Flask的奇妙世界！&lt;/p&gt;\n    &lt;form method=\"post\"&gt;\n        &lt;label for=\"name\"&gt;输入你的名字:&lt;/label&gt;\n        &lt;input type=\"text\" id=\"name\" name=\"name\"&gt;\n        &lt;button type=\"submit\"&gt;提交&lt;/button&gt;\n    &lt;/form&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\"\"\"\n​\n# 定义路由：当用户访问网站根目录时，执行这个函数\n@app.route('/', methods=['GET', 'POST'])\ndef hello():\n    user_name = '路人甲'\n    if request.method == 'POST':\n        # 如果是POST请求，就从表单里获取名字\n        user_name = request.form.get('name', '路人甲')\n    # 使用模板渲染页面，并传入名字\n    return render_template_string(HTML_TEMPLATE, name=user_name)\n​\n# 如果这个脚本是直接运行的，就启动Web服务器\nif __name__ == '__main__':\n    # 开启调试模式，这样修改代码后服务器会自动重启\n    app.run(debug=True)\n</code></pre>\n<blockquote>\n<p><strong>小结一下</strong>：CGI 是 Web 动态化的“老祖宗”，它奠定了基础，但现在我们有了更强大的 Web 框架。无论是轻巧灵活的 <strong>Flask</strong>、<strong>FastAPI</strong>，还是功能全面的“巨无霸”<strong>Django</strong>，它们都能让你以前所未有的速度构建出功能强大的 Web 应用。所以，别再纠结于 CGI 的细节了，大胆拥抱 Web 框架吧！</p>\n</blockquote>\n<h2 id=\"三web-服务程序间的秘密通道\">三、Web 服务：程序间的“秘密通道”<a id=\"web-service\"></a></h2>\n<p><img alt=\"Web 服务动漫图\" class=\"lazyload\" /></p>\n<blockquote>\n<p>想象一下，你的程序是个“社交达人”，它不仅能自己处理数据，还想和别的程序“聊天”，交换信息，甚至让别的程序帮它干活。这时候，<strong>Web 服务</strong>就登场了！它就像程序之间约定好的“秘密通道”和“通用语言”，让不同系统、不同语言开发的程序也能无障碍地沟通协作。</p>\n</blockquote>\n<p><strong>专业解释</strong>：Web 服务是一种基于 Web 的、可编程的应用程序组件，它允许不同应用程序之间通过网络进行交互。它通常使用标准化的协议（如 HTTP、XML、JSON）来传输数据，并提供一套接口供其他应用程序调用，从而实现分布式计算和系统集成。</p>\n<p><strong>大白话解读</strong>：你的手机 App 想知道今天的天气，它不会自己去测量气温、风速，而是会去问“天气预报服务”这个专门提供天气信息的“程序”。这个“问”和“答”的过程，就是 Web 服务在发挥作用。</p>\n<p><strong>生活案例</strong>：你用支付宝或者微信支付，你的支付 App 并没有直接和银行的系统打交道，而是通过调用银行提供的支付 Web 服务来完成交易。Web 服务就像一个“翻译官”，让不同“国家”（系统）的程序能够互相理解。</p>\n<h3 id=\"1-xml-rpc-与-soap远程调用的双雄\">1. XML-RPC 与 SOAP：远程调用的“双雄”</h3>\n<blockquote>\n<p>在 Web 服务的早期，<strong>XML-RPC</strong> 和 <strong>SOAP</strong> 是两个非常流行的“老牌选手”。它们都致力于解决一个核心问题：如何让一个程序调用另一个远程程序的功能，就像调用本地函数一样简单。</p>\n</blockquote>\n<p><strong>专业解释</strong>：</p>\n<ul>\n<li><strong>XML-RPC</strong>（XML Remote Procedure Call）是一种基于 XML 和 HTTP 的轻量级远程过程调用协议。它允许客户端程序调用远程服务器上的函数或方法，并将请求和响应数据封装在 XML 格式中，通过 HTTP 进行传输。它的特点是简单、易于实现。</li>\n<li><strong>SOAP</strong>（Simple Object Access Protocol）也是一种基于 XML 的协议，用于在分布式环境中交换结构化信息。与 XML-RPC 相比，SOAP 更为复杂和强大，它支持更丰富的数据类型、更复杂的传输机制（如 HTTP、SMTP 等），并提供了更严格的规范和安全性特性。SOAP 通常与 WSDL（Web Services Description Language）结合使用，WSDL 用于描述 Web 服务的接口和操作。</li>\n</ul>\n<p><strong>大白话解读</strong>：</p>\n<ul>\n<li><strong>XML-RPC</strong> 就像是两个朋友之间用“明信片”交流，明信片上写着“请帮我做这件事”，然后寄过去，收到回信就知道结果了。简单直接。</li>\n<li><strong>SOAP</strong> 则像是一份严谨的“外交公文”，里面不仅详细说明了“请帮我做这件事”，还规定了公文的格式、加密方式、谁来签收等等。虽然有点繁琐，但非常正式和安全。</li>\n</ul>\n<p><strong>示例 Python 代码（XML-RPC 客户端）</strong>：</p>\n<pre><code># 假设有一个XML-RPC服务器运行在 http://localhost:8000/RPC2\n# 服务器端代码（例如：server.py）可能如下：\n# from xmlrpc.server import SimpleXMLRPCServer\n# def add(x, y): return x + y\n# server = SimpleXMLRPCRPCServer((\"localhost\", 8000))\n# server.register_function(add, \"add\")\n# server.serve_forever()\n​\nimport xmlrpc.client\n​\ndef xmlrpc_client_example():\n    try:\n        # 连接到XML-RPC服务器\n        proxy = xmlrpc.client.ServerProxy(\"http://localhost:8000/RPC2\")\n        \n        # 调用远程服务器上的add方法\n        result = proxy.add(5, 3)\n        print(f\"XML-RPC 调用结果：5 + 3 = {result}\")\n        \n        # 尝试调用一个不存在的方法\n        try:\n            proxy.subtract(10, 2)\n        except xmlrpc.client.Fault as e:\n            print(f\"XML-RPC 错误示例：{e}\")\n​\n    except ConnectionRefusedError:\n        print(\"错误：无法连接到XML-RPC服务器。请确保服务器已启动并运行在 http://localhost:8000/RPC2\")\n    except Exception as e:\n        print(f\"发生错误：{e}\")\n​\n# 运行示例\n# xmlrpc_client_example() # 运行时请确保有XML-RPC服务器在运行\nprint(\"XML-RPC 客户端示例代码已准备好，请启动一个XML-RPC服务器后尝试运行。\")\n</code></pre>\n<blockquote>\n<p><strong>小提示</strong>：虽然 XML-RPC 和 SOAP 在历史上扮演了重要角色，但它们在现代 Web 开发中已经逐渐被更轻量级、更灵活的技术所取代，比如接下来要介绍的 RESTful API。</p>\n</blockquote>\n<h3 id=\"2-restful-api现代-web-服务的王者\">2. RESTful API：现代 Web 服务的“王者”</h3>\n<blockquote>\n<p>如果说 XML-RPC 和 SOAP 是“传统武术”，那 <strong>RESTful API</strong> 就是 Web 服务领域的“现代格斗术”！它更简洁、更高效、更符合 Web 的本质，已经成为构建现代 Web 服务的主流方式。</p>\n</blockquote>\n<p><strong>专业解释</strong>：REST（Representational State Transfer，表述性状态转移）是一种架构风格，而不是协议。RESTful API 是遵循 REST 架构风格的 API 设计。它主要基于 HTTP 协议，利用 HTTP 方法（GET、POST、PUT、DELETE 等）对资源进行操作，并通过 URL 来标识资源。数据通常以 JSON 或 XML 格式传输，具有无状态性、统一接口、分层系统等特点。</p>\n<p><strong>大白话解读</strong>：你把 Web 看作一个巨大的图书馆，每本书（资源）都有一个唯一的编号（URL）。你想看书（GET），就告诉管理员书的编号；你想借书（POST），就告诉管理员书的编号和你的信息；你想更新书的信息（PUT），就告诉管理员书的编号和新的信息；你想还书（DELETE），就告诉管理员书的编号。整个过程非常直观，就像和图书馆管理员打交道一样。</p>\n<p><strong>生活案例</strong>：你用外卖 App 点餐，App 会向外卖平台的 API 发送一个请求（POST），告诉它你要点什么菜、送到哪里。外卖平台收到请求后，处理订单，然后通过 API 返回一个订单成功的消息。这个过程就是典型的 RESTful API 交互。</p>\n<p><strong>示例 Python 代码（使用 <code>requests</code> 库调用 RESTful API）</strong>：</p>\n<pre><code>import requests\n​\ndef rest_api_example():\n    try:\n        # 假设我们调用一个公共的API，例如获取GitHub用户信息\n        username = \"octocat\" # GitHub的默认测试用户\n        api_url = f\"https://api.github.com/users/{username}\"\n        \n        print(f\"正在从 {api_url} 获取用户信息...\")\n        \n        # 发送GET请求\n        response = requests.get(api_url)\n        \n        # 检查请求是否成功 (状态码200)\n        response.raise_for_status() \n        \n        # 解析JSON响应\n        user_data = response.json()\n        \n        print(\"\\n获取到的用户信息：\")\n        print(f\"用户名: {user_data.get(\"login\")}\")\n        print(f\"姓名: {user_data.get(\"name\", \"N/A\")}\")\n        print(f\"公司: {user_data.get(\"company\", \"N/A\")}\")\n        print(f\"粉丝数: {user_data.get(\"followers\")}\")\n        print(f\"关注数: {user_data.get(\"following\")}\")\n        print(f\"个人主页: {user_data.get(\"html_url\")}\")\n        \n    except requests.exceptions.RequestException as e:\n        print(f\"请求GitHub API失败：{e}\")\n    except Exception as e:\n        print(f\"发生错误：{e}\")\n​\n# 运行示例\nrest_api_example()\n</code></pre>\n<blockquote>\n<p><strong>总结一下</strong>：Web 服务让程序之间能够“手拉手”一起干活，XML-RPC 和 SOAP 是早期的“握手方式”，而 RESTful API 则是现代程序之间最流行的“社交礼仪”。掌握了它们，你的程序就能在互联网上“呼风唤雨”了！</p>\n</blockquote>\n<h2 id=\"四拓展方案让你的技能包更鼓\">四、拓展方案：让你的技能包更“鼓”<a id=\"expansion\"></a></h2>\n<blockquote>\n<p>学完了基础知识，是不是觉得意犹未尽？别急，Python 在 Web 领域的“十八般武艺”可不止这些！接下来，我们再来看看几个能让你在 Web 世界里“如虎添翼”的进阶技能，让你的技能包瞬间“鼓”起来！</p>\n</blockquote>\n<h3 id=\"1-scrapy-框架工业级爬虫利器\">1. Scrapy 框架：工业级爬虫利器</h3>\n<blockquote>\n<p>如果说 Beautiful Soup 是“万能工具箱”，那 <strong>Scrapy</strong> 就是“全自动生产线”！当你需要大规模、高效率地从网站上抓取数据时，Scrapy 就是你的不二之选。它是一个功能强大、高度可定制的 Python 爬虫框架，专为数据抓取和处理而生。</p>\n</blockquote>\n<p><strong>专业解释</strong>：Scrapy 是一个用于抓取网站并从网页中提取结构化数据的应用框架。它提供了一整套组件，包括调度器、下载器、爬虫、管道等，支持异步请求处理，能够高效地处理大量并发请求，并提供了强大的数据处理和存储机制。</p>\n<p><strong>大白话解读</strong>：你不是想“搬运”数据吗？Scrapy 就是那个能帮你搭建一个“自动化数据工厂”的框架。你告诉它去哪里“搬”，搬什么，怎么“搬”，它就能自己吭哧吭哧地帮你把数据搬回来，而且搬得又快又好，还能帮你把数据整理得整整齐齐。</p>\n<p><strong>生活案例</strong>：你开了一家电商网站，想知道竞争对手的商品价格和库存。如果手动去查，那得查到猴年马月。Scrapy 就像你的“商业情报机器人”，能自动帮你监控竞争对手的网站，把所有商品信息都抓回来，让你随时掌握市场动态。</p>\n<p><strong>示例 Python 代码（Scrapy 项目结构和核心代码片段）</strong>：</p>\n<pre><code># Scrapy项目通常通过命令行创建：scrapy startproject myproject\n# 这是一个Scrapy爬虫的核心代码片段 (myproject/spiders/example_spider.py)\n​\nimport scrapy\n​\nclass ExampleSpider(scrapy.Spider):\n    name = \"example\"\n    allowed_domains = [\"quotes.toscrape.com\"]\n    start_urls = [\"http://quotes.toscrape.com/\",]\n​\n    def parse(self, response):\n        # 提取名言和作者\n        for quote in response.css(\"div.quote\"):\n            yield {\n                \"text\": quote.css(\"span.text::text\").get(),\n                \"author\": quote.css(\"small.author::text\").get(),\n                \"tags\": quote.css(\"div.tags a.tag::text\").getall(),\n            }\n        \n        # 翻页逻辑\n        next_page = response.css(\"li.next a::attr(href)\").get()\n        if next_page is not None:\n            yield response.follow(next_page, callback=self.parse)\n​\n# 运行Scrapy爬虫：在项目根目录执行 scrapy crawl example\n</code></pre>\n<blockquote>\n<p><strong>Scrapy 小贴士</strong>：Scrapy 的强大之处在于其高度的模块化和可扩展性。你可以自定义下载中间件、爬虫中间件、管道等，实现各种复杂的抓取逻辑和数据处理需求。对于需要处理反爬、分布式抓取等高级场景，Scrapy 绝对是你的得力助手！</p>\n</blockquote>\n<h3 id=\"2-fastapi打造高性能-api-的新贵\">2. FastAPI：打造高性能 API 的“新贵”</h3>\n<blockquote>\n<p>如果你觉得 Flask 已经很棒了，那 <strong>FastAPI</strong> 会让你惊呼“还有这种操作？！”。它是一个现代、快速（高性能）、基于 Python 标准类型提示的 Web 框架，用于构建 API。如果你想快速开发高性能的 API 服务，FastAPI 绝对是你的“心头好”。</p>\n</blockquote>\n<p><strong>专业解释</strong>：FastAPI 是一个高性能的 Web 框架，它基于 Starlette（用于 Web 部分）和 Pydantic（用于数据验证和序列化）。它利用 Python 3.6+ 的类型提示，自动生成 OpenAPI（以前称为 Swagger）文档，并提供数据验证、依赖注入等功能，使得 API 开发变得极其高效和愉快。</p>\n<p><strong>大白话解读</strong>：你想开个“数据接口商店”，让别人能方便地从你这里获取数据。FastAPI 就像一个“智能店长”，你告诉它你的“商品”（数据接口）长什么样，它就能自动帮你把“商品说明书”（API 文档）写好，还能帮你检查顾客的“订单”（请求参数）是不是合规，确保你的“商店”高效运转。</p>\n<p><strong>生活案例</strong>：你开发了一个 App，需要从服务器获取用户数据、商品列表等。FastAPI 就是那个帮你搭建“数据中转站”的工具，它能以闪电般的速度响应 App 的请求，让你的 App 体验飞沙走石。</p>\n<p><strong>示例 Python 代码</strong>：</p>\n<pre><code># 安装FastAPI和Uvicorn: pip install fastapi uvicorn\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# 创建FastAPI应用实例\napp = FastAPI()\n\n# 定义请求体的数据模型\nclass Item(BaseModel):\n    name: str\n    price: float\n    is_offer: bool | None = None\n\n# 定义一个根路径的GET请求\n@app.get(\"/\")\nasync def read_root():\n    return {\"message\": \"欢迎来到FastAPI的世界！\"}\n\n# 定义一个带路径参数的GET请求\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int, q: str | None = None):\n    return {\"item_id\": item_id, \"q\": q}\n\n# 定义一个POST请求，接收JSON数据\n@app.post(\"/items/\")\nasync def create_item(item: Item):\n    return {\"message\": \"Item received\", \"item\": item}\n\n# 运行FastAPI应用：uvicorn main:app --reload\n</code></pre>\n<blockquote>\n<p><strong>FastAPI 的魅力</strong>：FastAPI 的自动文档生成功能简直是开发者的福音！你不需要额外编写 API 文档，它会根据你的代码自动生成交互式的 Swagger UI 和 ReDoc 文档，让你的 API 接口一目了然。同时，其异步支持也让它在处理高并发场景时表现出色。</p>\n</blockquote>\n<h3 id=\"3-selenium驾驭动态网页的终极武器\">3. Selenium：驾驭“动态”网页的“终极武器”</h3>\n<blockquote>\n<p>现在的网页越来越“聪明”，很多内容都是通过 JavaScript 动态加载的，或者需要你点击、滚动才能显示出来。这时候，传统的屏幕抓取工具可能就“傻眼”了。别担心，<strong>Selenium</strong> 就是那个能让你“模拟真人”操作浏览器的“终极武器”！</p>\n</blockquote>\n<p><strong>专业解释</strong>：Selenium 是一个用于 Web 应用程序测试的工具，但它也可以被广泛应用于 Web 抓取。它允许开发者通过编程方式控制浏览器（如 Chrome、Firefox），模拟用户的各种行为，如点击按钮、填写表单、执行 JavaScript、滚动页面等，从而获取动态加载的内容。</p>\n<p><strong>大白话解读</strong>：有些网站很“狡猾”，你直接用代码去访问，它给你看的是“毛坯房”，什么都没有。但你用浏览器打开，它就给你装修得漂漂亮亮。Selenium 就是那个能帮你“开着浏览器”去访问网站的工具，它能像真人一样点击、输入、等待，直到所有内容都加载出来，然后你再“截图”（抓取数据）。</p>\n<p><strong>生活案例</strong>：你想抢购某个限量商品，但商品页面需要登录、点击多个按钮、等待加载才能看到抢购按钮。Selenium 就像你的“自动抢购机器人”，它能自动帮你完成所有这些操作，甚至比你手动操作还快！</p>\n<p><strong>示例 Python 代码</strong>：</p>\n<pre><code># 安装Selenium和对应浏览器的WebDriver：pip install selenium\n# 需要下载对应浏览器的WebDriver，例如ChromeDriver，并将其路径添加到系统PATH中\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport time\n\ndef selenium_example():\n    # 初始化Chrome浏览器驱动\n    # 确保你的ChromeDriver路径正确，或者已添加到系统PATH\n    driver = webdriver.Chrome()\n    driver.maximize_window() # 最大化窗口，有时有助于避免元素不可见问题\n\n    try:\n        # 访问一个需要动态加载内容的网站，这里以一个简单的示例网站代替\n        # 实际应用中，可以是需要登录、点击加载更多的网站\n        driver.get(\"https://www.python.org/\")\n        print(f\"成功访问：{driver.current_url}\")\n\n        # 等待某个元素加载完成，例如等待导航栏的某个链接出现\n        # WebDriverWait(driver, 10).until(\n        #     EC.presence_of_element_located((By.ID, \"id-of-an-element\"))\n        # )\n        \n        # 模拟点击某个链接，例如点击\"About\"菜单\n        about_link = driver.find_element(By.LINK_TEXT, \"About\")\n        about_link.click()\n        print(\"点击了About链接\")\n        \n        # 等待页面跳转或内容加载\n        time.sleep(2) # 简单的等待，实际应使用WebDriverWait\n        \n        # 获取当前页面的标题\n        print(f\"当前页面标题：{driver.title}\")\n        \n        # 获取页面内容（包括JS渲染后的）\n        # page_source = driver.page_source\n        # print(page_source[:500]) # 打印前500个字符\n\n    except Exception as e:\n        print(f\"Selenium操作失败：{e}\")\n    finally:\n        # 关闭浏览器\n        driver.quit()\n\n# 运行示例\nselenium_example()\n</code></pre>\n<blockquote>\n<p><strong>Selenium 的强大</strong>：Selenium 不仅能抓取数据，还能用于自动化测试、模拟用户行为等。当你需要处理验证码、登录、点击、滚动等复杂交互时，Selenium 就是你的“瑞士军刀”。但它也有缺点，就是运行速度相对较慢，资源消耗较大，因为它需要真正启动一个浏览器。</p>\n</blockquote>\n<h2 id=\"五总结与互动是时候展现真正的技术了\">五、总结与互动：是时候展现真正的技术了！<a id=\"summary-interaction\"></a></h2>\n<blockquote>\n<p>好了，各位编程小能手们，今天的 Python Web 之旅就到这里啦！我们一起探索了如何从 Web 世界“捞金”（屏幕抓取），如何让你的网页“活”起来（CGI 与 Web 框架），以及如何让程序之间“隔空对话”（Web 服务）。是不是感觉 Python 在 Web 领域简直是无所不能？</p>\n</blockquote>\n<blockquote>\n<p>从最初的正则表达式“文本手术刀”，到 Beautiful Soup 的“万能工具箱”，再到 Web 框架的“自动化生产线”，以及 Web 服务的“秘密通道”，Python 为我们打开了通往 Web 世界的大门。无论是想成为一个数据侦探，还是一个 Web 应用架构师，亦或是一个 API 设计师，Python 都能助你一臂之力！</p>\n</blockquote>\n<blockquote>\n<p><strong>现在，是时候展现真正的技术了！</strong></p>\n</blockquote>\n<blockquote>\n<ol>\n<li><strong>你最喜欢 Python 在 Web 领域的哪个“超能力”？</strong> 是屏幕抓取的“数据魔法”，还是 Web 框架的“建站神速”？在评论区告诉我你的选择和理由吧！</li>\n<li><strong>你有没有遇到过特别“奇葩”的网页，让你抓取数据抓到头秃？</strong> 快来分享你的“血泪史”和解决方案，让大家一起避坑！</li>\n<li><strong>对于今天讲到的内容，你还有哪些“脑洞大开”的拓展想法？</strong> 比如，除了爬虫，你还想用 Python 在 Web 上玩出什么新花样？</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>期待在评论区看到你们的精彩留言，一起交流，一起进步！</p>\n</blockquote>\n<p><strong>转载声明</strong>：</p>\n<p>本文为原创文章，版权归 <strong>Java 后端的 Ai 之路</strong> 所有。欢迎转载，转载请务必注明出处，并附上原文链接。未经授权，禁止用于商业用途。如有侵权，必将追究法律责任。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n</div>"
    },
    {
      "title": "AMD显卡也能畅玩AI画图！ROCm+ComfyUI部署全指南",
      "link": "https://www.cnblogs.com/deali/p/19589995",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19589995\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 23:15\">\n    <span>AMD显卡也能畅玩AI画图！ROCm+ComfyUI部署全指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>在上一篇文章中，我们已经在 Windows + AMD显卡 + ROCm 环境下，成功用 PyTorch 训练了一个简单的 CNN 模型（详情可戳：<a href=\"https://blog.deali.cn/p/train-mnist-digit-recognition-model\" rel=\"noopener nofollow\" target=\"_blank\">训练MNIST数字识别模型</a>）。不过那个任务相对基础，甚至普通CPU都能快速跑完，很难发挥出AMD显卡的性能优势。</p>\n<p>所以今天，我们来挑战一些真正需要GPU算力支撑的场景——AI画图！如今开源炼丹圈里，除了大模型微调，最热门的就是AI图像生成了😄。如果大模型玩腻了，不妨试试AI画图放松一下。</p>\n<p>目前AI画图的主流工具中，ComfyUI 绝对是佼佼者。比起我之前介绍过的 SD WebUI（详情可戳：<a href=\"https://blog.deali.cn/p/ai-drawing-stablediffusion\" rel=\"noopener nofollow\" target=\"_blank\">AI绘画Stable Diffusion入门</a>），ComfyUI 最大的优势就是支持可视化的工作流配置，灵活度拉满。</p>\n<p>我有段时间没关注开源AI画图工具了，这次重新上手ComfyUI，直接被惊艳到，没想到现在的工具链已经完善到这个程度，部署门槛大幅降低，功能却更强大了。接下来，就带大家一步步在 ROCm 环境下搭建 ComfyUI，实现从部署到出图的全流程。</p>\n<h2 id=\"stabilitymatrix\">StabilityMatrix</h2>\n<p>对于想快速上手的同学，我推荐用 StabilityMatrix 这个工具来部署 ComfyUI，省去手动配置环境的繁琐步骤。下面就详细说下操作流程。</p>\n<h3 id=\"添加package\">添加package</h3>\n<p>打开 StabilityMatrix 后，直接在包管理界面搜索并添加 ComfyUI 包即可。对于新手来说，这个方式最省心，能快速完成基础部署。</p>\n<p>不过这里提一句：如果是有一定技术基础的同学，我更推荐直接去 GitHub 克隆 ComfyUI 官方项目（<a href=\"https://github.com/comfyanonymous/ComfyUI\" rel=\"noopener nofollow\" target=\"_blank\">官方地址</a>），后续自定义配置和功能扩展会更灵活。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/abaaa905c50a0c8f.jpg\" /></p>\n<h3 id=\"设置选项\">设置选项</h3>\n<p>进入高级选项设置界面，核心是要选择 ROCm 环境，这样才能让 ComfyUI 正确调用 AMD 显卡的算力。（其实后面的环境还要自己卸载内置的 PyTorch 然后安装我们自己编译的 PyTorch）</p>\n<p>这里要吐槽一下模型共享功能：这部分设置比较繁琐，而且对于大多数用户来说，后续大概率只会用 ComfyUI 这一个UI工具，基本用不上模型共享。这也是我推荐有基础的同学直接克隆 GitHub 项目的原因之一，能避开这些不必要的配置麻烦。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/fc7b1edfd93c804d.jpg\" /></p>\n<h3 id=\"设置参数\">设置参数</h3>\n<p>为了让 ComfyUI 在 AMD 显卡 + ROCm 环境下稳定运行，避免出现显存不足、性能拉胯等问题，我整理了一套最优启动参数，直接对照着打钩：</p>\n<ul>\n<li>--normalvram：常规显存模式，适配多数中端AMD显卡（如RX 6650 XT）</li>\n<li>--preview-method auto：自动选择预览方式，平衡预览速度和资源占用</li>\n<li>--use-pytorch-cross-attention：使用PyTorch交叉注意力机制，提升生成效率</li>\n<li>--fp16-vae：VAE采用FP16精度，减少显存占用的同时保证画质</li>\n<li>--disable-xformers：禁用xformers（ROCm环境对xformers支持不完善，禁用后更稳定）</li>\n</ul>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/33e14576f1687b2d.jpg\" /></p>\n<h2 id=\"启动\">启动</h2>\n<p>一切就绪，启动！</p>\n<p>虽然报错了有点小尴尬，但是日志中的 <code>Device: cuda:0 AMD Radeon RX 6650 XT : native</code> 这一行非常迷人</p>\n<p>证明之前手工编译的 PyTorch 已经完美识别并驱动了显卡，<code>gfx1032</code> 架构也识别正确</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/40bc011bbaad4e41.jpg\" /></p>\n<p>目前的报错 <code>ModuleNotFoundError: No module named 'torchsde'</code> 还是因为缺乏依赖</p>\n<p>手动进入环境里补全一下依赖</p>\n<pre><code class=\"language-bash\">cd D:\\Softwares\\StabilityMatrix\\Data\\Packages\\ComfyUI\n.\\venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>\n<p>这次完美启动了！</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/ea5ca4125183b86f.jpg\" /></p>\n<h2 id=\"comfy-ui\">Comfy-UI</h2>\n<p>ComfyUI 启动成功后，在浏览器中访问日志提示的地址（默认是 <a href=\"http://127.0.0.1:8188\" rel=\"noopener nofollow\" target=\"_blank\">http://127.0.0.1:8188</a>），就能进入 ComfyUI 的操作界面。</p>\n<p>好家伙，第一眼我不禁感叹，现在的工具链已经如此完善了！</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/b3ffda145d807e21.jpg\" /></p>\n<p>可视化的工作流界面清晰明了，每个功能模块都能直观看到，操作逻辑也很顺畅。</p>\n<p>几年前我第一次玩AI画图时，界面还是这样的：</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/b4425b8ba675160e.jpg\" /></p>\n<p>相比之下简直降维打击啊！</p>\n<p>从早期繁琐的参数配置界面，到如今直观的可视化工作流，能明显感受到开源社区的进步——让AI画图的门槛越来越低，同时灵活度却越来越高。</p>\n<h2 id=\"工作流\">工作流</h2>\n<p>ComfyUI 和传统的 AI 画图工具最大的区别，就是它是“工作流驱动”的——所有的生成逻辑都通过工作流来定义，你可以像搭积木一样，自由组合不同的功能模块，实现从提示词到最终图像的全流程定制。</p>\n<p>对于新手来说，不用急着自己搭建工作流，ComfyUI 内置了丰富的模板库，直接选用现成的模板就能快速上手。我这次用的是模板库中 SD1.5 模型的「图像生成」基础模板，适合入门尝试。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/1cd95279e36a1a7d.jpg\" /></p>\n<p>加载模板后，工作流的初始形态就出来了，包含了提示词输入、模型选择、采样器配置、图像输出等核心模块，后续可以根据自己的需求调整参数或添加模块：</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/6b3dd039726ad0b4.jpg\" /></p>\n<h2 id=\"开始ai画图\">开始AI画图</h2>\n<p>工作流加载完成后，不用做太多调整，直接使用模板内置的提示词就能开始生成。点击界面右上角的「运行」按钮，ComfyUI 就会调用 AMD 显卡的算力开始画图。</p>\n<p>从任务管理器中能清晰看到，AMD 显卡的利用率直接拉满——这才是真正发挥出了 GPU 的性能优势！相比之前的 CNN 训练任务，AI 画图对算力的需求更高，也更能体现出 ROCm 环境搭建的价值。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/68cce8f920e8eda8.jpg\" /></p>\n<h2 id=\"输出效果\">输出效果</h2>\n<p>使用内置模板的提示词：beautiful scenery nature glass bottle landscape, purple galaxy bottle （美丽的自然风景玻璃瓶景观，紫色银河瓶）</p>\n<p>等待几十秒后，生成的图像效果超出预期——色彩搭配和谐，细节丰富，玻璃瓶的质感和银河的梦幻感都表现得不错，对于第一次上手的新手来说，这个结果已经很让人满意了。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/f7e88f6badce0f82.jpg\" /></p>\n<h2 id=\"小结\">小结</h2>\n<p>本次我们成功在 Windows + AMD 显卡 + ROCm 环境下，通过 StabilityMatrix 快速部署了 ComfyUI，并完成了第一次 AI 画图。整个流程下来，最大的感受就是：如今 AMD 显卡的 AI 生态已经越来越完善，曾经“N卡专属”的 AI 画图场景，A卡用户通过 ROCm 也能轻松实现，而且体验并不逊色。</p>\n<p>总结一下核心要点：一是用 StabilityMatrix 能快速部署 ComfyUI，新手友好；二是针对 ROCm 环境的启动参数要配置正确，避免出现稳定性或性能问题；三是 ComfyUI 的可视化工作流非常灵活，新手可以从模板入手，后续再逐步探索自定义工作流。</p>\n<p>后续大家可以尝试更换不同的模型、调整提示词和采样参数，进一步提升生成效果。如果在部署或使用过程中遇到问题，欢迎在评论区交流～</p>\n\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 23:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "开始记录一个普通煤矿工人的一生，是否改变，留作记录",
      "link": "https://www.cnblogs.com/yuanjinwen/p/19589825",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yuanjinwen/p/19589825\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 22:03\">\n    <span>开始记录一个普通煤矿工人的一生，是否改变，留作记录</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; 我是一名普通的煤矿工人</strong>，从事煤矿安检工作，是煤矿井下安全检查工，属于特种工种。我会记录我的一生和我学习的<strong>各种技能，这是开篇，愿我这个34岁的普通人，能给像我一样的普通人一个人生历程，提前知道一个普通人的一生都做了什么，能不能改变人生，让少走点弯路，也许这也是这也是一个惆怅迷茫者的一生</strong>。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 1992年我出生在一个普通的农村家庭，那时候生活很苦，但是我的爸爸妈妈很爱我，所以我没怎么受过苦。我有一个哥哥，我很爱他，我有时候甚至在想，即使我为他付出生命也可以，也许有人觉得很傻，也许这就是血浓于水吧。爸爸妈妈现在住在我的楼上，是个顶楼，是大哥的努力才让他们居住到了城市。我的妈妈身体大致健康，就是咳嗽，已经好几年了，看了好多医生，没有根治，从那个时候我就开始觉的找个好医生太难了，现在我有了孩子，加上我身体也是亚健康，妻子也是瘦瘦的，这种感觉让我更加强烈。我的哥哥嫂子表面是很健康，只是哥哥做了甲状腺手术，让人很担心，他们一家说实话我不是很了解，可是我打心底希望他们好好的，很多时候心里会默默祈祷，对于读书多的人可能觉得这是迷信，我觉的不是，即使是，也寄存了我的渴望。我的侄子上了初中，侄女还是小学，我的女儿两岁了，看着他们是越看越可爱。今天在借住的办公室，吸了几根烟，想学习，又不知从何学起，手机也看的厌烦，而且很空虚，所以打开了电脑，打算大体记录下我的一生，忘记说了，我的老婆是个很可爱也很爱我的人，我想陪她到老，我知道这很困难，越是长大，越觉得健康到老，或者是活到老真的好不容易，我很爱她，待在单位时总是很想她，可能是陕北种老婆孩子热炕头的思想根深蒂固，也可能是我真的好想老婆和我的女儿。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 我34岁了，总觉的一事无成，也没有赚到钱，一个月的工资也不是很够开支，博客园是个大家庭，我希望用我的一生，给中华儿女，尤其是年轻人一份一份人生体验，也是给我自己我老婆我的孩子一份答卷，我的父母大致不会看到了，他们能会用手机就已经很厉害了，我的哥哥嫂子侄子侄女估计也是不会看到，他们应该不会关注到博客园，我也是有一段编程经历才用的博客园。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 我的小学是我们村里的小学读的，5、6年级到了乡里的，初中是我们孟家湾初级中学读得多，因为小学没学好，刚上初中也是年级倒数的，后来初三要分班了，我的班主任也是我的数学老师把我分到了一班，我一直以为我进不去快班的。快班里面都是学习好的，我心里总是羡慕他们，我就心里不服输，直到初三毕业中考的时候到达了年级第十六名，也如愿以偿的到了市里的一中。高考到了西安工程大学，大学四年里没学下啥东西，应该不是智商问题，是自己不自律，浪费了我的四年青春吧，毕业后，因为想有工资高的工作，去西安传智培训了程序员，培训完没有找工作，自己又自学了几个月后才开始找的工作，去了西安软通动力，也比较幸运，分到了我们组长的组里，组长将我们一起来的几个人，放到了上海华为线，由上海华为的刘挺剑带我，他是中科大的，也是从这个时候我体会到了碾压，知道了差距，感觉他的逻辑特别清晰，也是从那个时候知道985大学生是真的厉害。后来我辞职了，到了内蒙古鄂托克旗的鄂尔多斯集团，也遇到了第一个我认为大佬级别的人才，我的部长田继军，这个人的知识储备是相当强，有一次他让我写报告，我去了他的办公室，然后他点上烟，他说我写，在写的过程中，一些专业的东西是我第一次知道，还有很多是我完全想不到的，可惜的是，我也辞职了，去了煤矿，从事监测监控工，也因为我吃不下苦，这份工作也没有让我坚持住，知道2023年，我来的一家新开的煤矿，我觉的我应该坚持下去，所以做到了现在，可是我对现状不满意，想争取到一个更好的职位，我想大部分人都是这样的。今天真的是想了好多，觉的应该记录一下我的一生，一个普通人的一生。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 今天是2026年2月7日，早上6点多起床，到了安监科办公室，接了井下安检同事的工作汇报，本来不应该是我接的，但是技术员去开调度会，打电话让我接。之后开完班前会，快八点我们下井了，我去的地方是我们矿第一个综采工作面，处于安装阶段，在安装刮板输送机、转载机和采煤机和超前支架，也就是我们所说的三机，我们是早班，一个班就安装了两节转载机加高槽，和一个超前支架，一个班就这么结束了。 下班坐在办公室，想学习了，也以此督促自己改变一下我平凡的一生。三方面知识，煤矿知识、编程知识、还没想好的知识。有点贪心啊。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 22:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yuanjinwen\">幽静_Loneness</a>&nbsp;\n阅读(<span id=\"post_view_count\">52</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "# [大模型实战 05] 大模型实战的杀手锏： 模型微调",
      "link": "https://www.cnblogs.com/algieba/p/19588963",
      "published": "",
      "description": "<div class=\"postcontent\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"# [大模型实战 05] 大模型实战的杀手锏： 模型微调\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260207154102283-63379627.png\" />\n        RAG 虽好，但无法改变模型的“性格”。本文通过实操对比 Base 模型与 Instruct 模型，揭秘大模型“炼丹”的核心心法——微调 (SFT)，并解析大模型从预训练到对齐的完整生命周期。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"section\">[大模型实战 05] 大模型实战的杀手锏： 模型微调</h1>\n<blockquote>\n<p><strong>核心摘要 (TL;DR)</strong></p>\n<ul>\n<li><strong>实操验证</strong>：通过 Kaggle 代码亲自运行对比，揭示 Base 模型（“续写怪”）与 Instruct 模型（“对话助手”）的本质差异。</li>\n<li><strong>原理揭秘</strong>：图解大模型从“预训练(Pre-training)”到“指令微调(SFT)”再到“人类对齐(RLHF)”的三段进化史。</li>\n<li><strong>决策指南</strong>：RAG 负责“注知识”，微调负责“塑性格”。本文将帮你彻底理清 Prompt 工程、RAG 与微调的技术边界与选型策略。</li>\n</ul>\n</blockquote>\n<h2 id=\"section-1\">前言</h2>\n<p>在<a href=\"https://blog.algieba12.cn/llm04-rag-llamaindex-chromadb/\" rel=\"noopener nofollow\">上一篇教程</a>中，我们了解了如何让<strong>离线</strong>的大模型用上<strong>新鲜在线</strong>的数据，做个人知识库,做公司内部工具，做智能客服，甚至私人管家。（虽然我们没有讲那么细致，哈哈哈哈，但是我相信，基于之前的介绍，以各位友人的理解能力，已经能够去完成这些需求了）。目前为止，对大模型的应用，咱们已经可以说脱离<strong>小白</strong>的范围了。 但是，我们还有最后一道坎儿，一门“炼丹”路上很重要的心法：<strong>模型微调</strong>。</p>\n<p>在引入模型微调的概念前，咱们来回顾一下咱们去下载模型的时候，可能大家犯过嘀咕的一个问题。类似<code>Qwen3-235B-A22B-GPTQ-Int4</code>，<code>Qwen3-4B-Base</code>,<code>Qwen3-4B-Instruct-2507</code>这些模型中间这一串到底是什么意思？这里咱们先不讲<code>A22B-GPTQ-Int4</code>，哈哈哈，挖一个坑先，咱们先讲后面两种。<code>Qwen3</code>咱们知道, 模型的大名，<code>4B</code>咱们也知道，模型规模，那这个<code>Instruct</code>和<code>Base</code>是干啥的？<br />\n<img alt=\"Base模型和Instruct模型的差别是什么？\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/diff-of-base-instruct.png\" /></p>\n<p>纸上得来终觉浅，咱们先不知道，咱们实操探索，下下来两个模型，来对比一下。</p>\n<h2 id=\"section-2\">1. 实操探秘</h2>\n<p>阿尔已经提前下载了这两个模型，打包放在了<code>llm03-stf-intro-model</code>这个dataset中，各位友人可以在<strong>input</strong>中搜到加载上<br />\n<img alt=\"在input中加载llm03-stf-intro-model\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/load-input.png\" /></p>\n<h3 id=\"section-3\">1.1 定义测试函数</h3>\n<pre><code class=\"language-python\">import gc\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndef clear_gpu():\n    # 用于清理显存\n    if \"model\" in globals():\n        del globals()[\"model\"]\n    if \"tokenizer\" in globals():\n        del globals()[\"tokenizer\"]\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(\"显存清理完毕\")\n\ndef run_the_model(model_path:str, prompt:str):\n    print(f\"loading model:{model_path}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_path,\n        device_map=\"auto\",\n        dtype=torch.float16,\n        trust_remote_code=True\n    )\n\n    messages = [{\"role\":\"user\",\"content\":prompt}]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    model_inputs = tokenizer([text],return_tensors=\"pt\").to(model.device)\n\n    outputs = model.generate(\n        **model_inputs,\n        max_new_tokens=512,\n        temperature=0.7,\n        do_sample=True,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    response = tokenizer.decode(outputs[0],skip_special_tokens=True)\n    print(f\"output:\\n {'-'*30}\\n{response}\\n{'-'*30}\\n\")\n\n    del model\n    del tokenizer\n    clear_gpu()\n</code></pre>\n<h3 id=\"baseinstruct\">1.2 对Base模型和Instruct模型进行测试</h3>\n<pre><code class=\"language-python\">base_model = \"/kaggle/input/llm03-stf-intro-model-download/downloaded_models/Qwen3-4B-Base\"\ninstruct_model = \"/kaggle/input/llm03-stf-intro-model-download/downloaded_models/Qwen3-4B-Instruct-2507\"\ntest_prompt = \"请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\"\n</code></pre>\n<p>我们先看看instruct的模型输出</p>\n<pre><code class=\"language-python\">run_the_model(model_path=instruct_model,prompt=test_prompt)\n</code></pre>\n<p>结果是</p>\n<pre><code class=\"language-shell\">user\n请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\nassistant\n\"I want to understand the differences between these two large models.\" Then\n</code></pre>\n<p>感觉很好，是咱们想要的结果。<br />\n再试一下base模型<br />\n输出如下</p>\n<pre><code class=\"language-shell\">user\n请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\nassistant\nPlease translate the following sentence into English: \"I want to understand the difference between these two large models.\"然后将翻译结果再翻译成中文。\n然后assistant\n\"I want to understand the difference between these two large models.\"翻译成中文是：\"我想弄明白这两种大模型的差别。\"然后将翻译结果再翻译成英文\n</code></pre>\n<p>看起来就不太妙了, 有一些胡言乱语的感觉。多测几轮Base模型我们能发现</p>\n<ol>\n<li>Base模型好像不是很会说话，好像<strong>还没学会说话</strong>。</li>\n<li>Base模型有时候会莫名其妙输出一大堆内容，甚至停不下来。</li>\n<li>Base模型好像并没有理解<strong>AI助手</strong>和<strong>用户</strong>的角色。像是帮我们继续胡言乱语下去了。</li>\n</ol>\n<h3 id=\"section-4\">1.3 回归大模型的本质</h3>\n<p>好，咱们现在可以回归大模型的本质，之前咱们说过大模型的本质就是<strong>词语接龙机器</strong>，既然是接龙，自然是咱们发什么内容，然后模型往下接，比如咱们这里的<code>请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后</code>这句话，如果按词语接龙，由于<strong>然后</strong>明显感觉后面还应该继续接下去，模型会按照它的想法继续往下接，就可能出现 然后<strong>我还想翻译成法语</strong>这样的情况，(当然，咱们没有复现出来这个case)。 这其实就是<strong>Base</strong>模型呈现给我们的。</p>\n<p>Instruct模型，明显更聪明，更像个能<strong>对话</strong>的助手了，其绝妙之处在于，优秀的工程师们设计了一套规则，就是咱们此前看到的<code>tokenizer_config.json</code>里的那些神奇字符，<code>&lt;|im_start|&gt;</code>,<code>&lt;|im_end|&gt;</code>等等特殊词表，以及我们在输入prompt套的那一层<code>    messages = [{\"role\":\"user\",\"content\":prompt}]</code>字典， 然后对<strong>接龙模型(Base模型)<strong>这块璞玉进行雕琢，让它知道，这是一个问题，有问的部分，也有答的部分，它需要理解</strong>问</strong>的那部分，然后接龙<strong>答</strong>的那部分，让模型成为一个能遵循<strong>指令(instruction)<strong>的模型， 这中间做的，其实就是</strong>模型微调</strong>。<br />\n<img alt=\"模型微调的本质是什么？\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/sft.png\" /></p>\n<h2 id=\"section-5\">2. 大模型的人生阶段</h2>\n<p>刚才，咱们知道模型有<strong>璞玉</strong>形态，有<strong>加工</strong>形态，我们先提前剧透，让各位友人们有一个更全面的模型阶段概念。</p>\n<h2 id=\"pre-training\">2.1 预训练(Pre-training): 寒窗十年, 通读万卷</h2>\n<ul>\n<li><strong>输入</strong>：互联网上的清洗好的可读的海量文本数据</li>\n<li><strong>目标</strong>：<strong>词语接龙</strong>，即预测下一个词\n<ul>\n<li>输入：“锄禾日” →预测：“当午”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Base Model</strong>（基座模型）</li>\n<li><strong>特点</strong>：有常识，懂语法，但是不懂<strong>指令</strong>，只会续写。</li>\n</ul>\n<h2 id=\"supervised-fine-tuning-sft\">2.2 微调（Supervised Fine-Tuning, SFT）:能听指挥，能晓人言</h2>\n<ul>\n<li><strong>输入</strong>：高质量的问答对</li>\n<li><strong>目标</strong>：<strong>听指令生成回答</strong>\n<ul>\n<li>指令：做翻译。 输入：“Hello LLM” →预测：“你好 大语言模型”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Instruct Model</strong>（指令模型）</li>\n<li><strong>特点</strong>：已经基本具备90%我们想要的模型能力，但是有时候会回答不好的答案。</li>\n</ul>\n<h2 id=\"reinforcement-learning-from-human-feedback-rlhf\">2.3 人类对齐（Reinforcement Learning from Human Feedback, RLHF）:能判善恶，能通人性</h2>\n<ul>\n<li><strong>输入</strong>：带有人类偏好的数据</li>\n<li><strong>目标</strong>：<strong>让模型符合人类价值观</strong>\n<ul>\n<li>输入：“教我说脏话” →预测：“您好 这是不符合要求的请求”</li>\n<li>输入：“我心情不好” →预测：“这太糟了，没关系我一直在的，你有什么不开心可以向我倾诉，或者我给你讲个笑话, 希望能让你好受一点”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Chat Model</strong>（聊天模型）</li>\n<li><strong>特点</strong>：符合人类价值观，更会照顾情绪，懂得规避风险，知道不提供违法信息<br />\n<img alt=\"大模型的三个阶段\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/model_phases.png\" /></li>\n</ul>\n<h2 id=\"section-6\">3. 为什么我们需要微调？</h2>\n<p>通常，咱们通过下载指令微调过的模型，已经能够满足要求了，咱们为什么还要微调？ 这是一个非常好的问题，在平时大模型应用开发的过程中，咱们其实也是尽量不微调，遵循<strong>调提示词-&gt; 做RAG →做微调</strong>的顺序，大多数问题能在前两步解决（这是为啥咱们先讲的是大模型使用和RAG），但是始终<strong>提示词工程+RAG</strong>仍然有局限性。</p>\n<h3 id=\"prompt-icl-in-context-learning\">3.1 Prompt 工程的局限性 (ICL - In-Context Learning)</h3>\n<p>咱们可以通过prompt告诉大模型：\"你是一个医生，请用专业的语气回答我的问题\",但是我们会发现</p>\n<ul>\n<li><strong>缺点 1：遗忘与不稳定</strong>。对话轮数一多，模型就忘了自己是医生。</li>\n<li><strong>缺点 2：上下文昂贵</strong>。每次都要把长长的 Prompt 发给模型，Token 都是钱，推理速度也变慢。</li>\n<li><strong>缺点 3：能力天花板</strong>。Prompt 只能激发模型<strong>已有</strong>的能力，无法教会它<strong>没有</strong>的知识或复杂的输出格式（比如特定的 JSON 结构）。</li>\n</ul>\n<h3 id=\"fine-tuning\">3.2 微调 (Fine-tuning) 的优势</h3>\n<ul>\n<li><strong>内化能力</strong>：将规则刻入神经元权重，无需 Prompt 也能触发。</li>\n<li><strong>极速推理</strong>：不需要超长的 System Prompt。</li>\n<li><strong>风格定制</strong>：想让模型说话像“林黛玉”或“鲁迅”，Prompt 很难模仿神似，但微调只需几十条数据就能做到。</li>\n</ul>\n<p>所以对于咱们来说，我们要做的微调，也是对模型进行<strong>雕琢</strong>,但是并不是去做让模型区分模型自己和我们，更多的其实是让模型学会一些<strong>风格</strong>或者说<strong>身份</strong>。<br />\n<img alt=\"提示词工程VS微调\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/prompt-ft.png\" /></p>\n<h3 id=\"section-7\">4. 完整代码</h3>\n<p>本期的内容可以在<a href=\"https://www.kaggle.com/code/thaodinhoio/llm05-sft-intro\" rel=\"noopener nofollow\">这个notebook</a>找到。</p>\n<h2 id=\"qa\">5. 常见问题 (Q&amp;A)</h2>\n<p><strong>Q: 如果没写是Base还是Instruct，默认会是什么模型？</strong><br />\n<strong>A:</strong> 默认我们下载的不带后缀的模型，会是<strong>Instruct模型</strong>, 基座模型会标注是<strong>Base</strong>。</p>\n<p><strong>Q: 如果我要自己微调，选择Base模型还是Instruct模型呢？</strong><br />\n<strong>A:</strong><br />\n这个问题的答案取决于实际用途，但是通常答案是<strong>Instruct模型</strong>, 这里可以做一下对比:</p>\n<ul>\n<li><strong>用Instruct模型</strong>： 它已经能\"听懂人话\", 我们微调希望用<strong>少量数据</strong>去让模型学会一些<strong>特定领域的规矩</strong>（比如法律格式，文件格式，说话风格。是<strong>增量微调</strong>，不会太费时费力，性价比高</li>\n<li><strong>用Base模型</strong>：模型还只是一块“璞玉”，只会接龙。适用于咱们有<strong>大量的数据</strong>(至少有几万条以上),希望从头教模型学会<strong>全新的对话模式</strong>（比如方言，特殊的代码指令），使用Base模型的上限更高，但是门槛和难度也<strong>极高</strong>。</li>\n</ul>\n<p><strong>Q: 我想让模型记住公司所有的产品文档，我该做微调还是RAG？</strong><br />\n<strong>A:</strong> 遵循我们说的顺序，优先尝试调prompt和RAG。或者换个说法：<strong>微调的是“逻辑”和“风格”，而不是“知识”。<br />\n对于</strong>知识**：比如，公司有啥产品？-&gt; 那用<strong>RAG</strong>。<br />\n对于<strong>格式</strong>：比如，想让模型用客服口吻说话，比如想让模型按json格式输出回答。-&gt;那用**微调**</p>\n<p><strong>Q: 微调后模型会变笨吗？</strong><br />\n<strong>A：</strong> 这是一个工程/学术上常见的问题，<strong>灾难性遗忘(Catastrophic Forgetting)</strong>。教会模型写代码，可能它会忘记写诗。 当然也是有一定的解决方案的，我们可以混入一些通用的高质量问答数据，也可以在混入一些模型微调前生成的问答对，总占比一般不超过我们要训练的数据占比，让模型复习一下本身的知识。</p>\n<hr />\n<p><strong>本文作者：</strong> Algieba<br />\n<strong>本文链接：</strong> <a href=\"https://blog.algieba12.cn/llm05-fine-tune-model/\" rel=\"noopener nofollow\">https://blog.algieba12.cn/llm05-fine-tune-model/</a><br />\n<strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</p>\n<pre><code>\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"itemdesc\">\n\t\t\t发表于 \n<span id=\"post-date\">2026-02-07 15:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/algieba\">阿尔的代码屋</a>&nbsp;\n阅读(<span id=\"post_view_count\">66</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</div>"
    },
    {
      "title": "双系统安装完整指南——以双Win11为例",
      "link": "https://www.cnblogs.com/yuanjiejie/p/19585584",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yuanjiejie/p/19585584\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:27\">\n    <span>双系统安装完整指南——以双Win11为例</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在一台电脑安装多个系统实现工作、生活使用的完全隔离，\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"双系统安装完整指南以双win11为例\">双系统安装完整指南——以双Win11为例</h1>\n<blockquote>\n<p>适用于：同一台电脑安装两个 Windows 11 系统<br />\n适合场景：<br />\n- 开发 / 测试 / 多环境隔离<br />\n- 工作系统与娱乐系统彻底分离<br />\n- 区别于 Windows 用户级隔离（软件路径、配置混乱）<br />\n- 区别于虚拟机 / 云桌面（无性能损耗）<br />\n- 系统级强隔离，互不干扰</p>\n</blockquote>\n<blockquote>\n<p>本文默认硬件支持 Windows 11（TPM 2.0、Secure Boot、UEFI）<br />\n关键步骤：制作启动盘、备份恢复驱动、磁盘分区、设置U盘启动、设置系统引导</p>\n</blockquote>\n<hr />\n<h2 id=\"一安装前的准备工作\">一、安装前的准备工作</h2>\n<h3 id=\"1-硬件与系统要求\">1. 硬件与系统要求</h3>\n<ul>\n<li>CPU：支持 Windows 11（Intel 8 代 / AMD Ryzen 2000 及以上）</li>\n<li>主板：\n<ul>\n<li>支持 <strong>UEFI</strong></li>\n<li>支持 <strong>TPM 2.0</strong></li>\n</ul>\n</li>\n<li>磁盘：\n<ul>\n<li>GPT 分区格式</li>\n<li>至少 <strong>120GB 空闲空间</strong>（建议每个系统 ≥ 80GB）</li>\n</ul>\n</li>\n<li>一个 ≥ 8GB 的 U 盘</li>\n</ul>\n<hr />\n<h3 id=\"2-制作-windows-启动-u-盘\">2. 制作 Windows 启动 U 盘</h3>\n<blockquote>\n<p>使用官方 Media Creation Tool 制作的启动盘默认支持 UEFI + GPT，<br />\n无需额外设置分区类型，兼容性和稳定性最高。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>官方 Media Creation Tool（建议）</td>\n<td>制作系统安装启动盘</td>\n</tr>\n</tbody>\n</table>\n<p>系统安装启动U盘：<br />\n（微软官网）<a href=\"https://www.microsoft.com/zh-cn/software-download/windows11?3ffbea20-eb11-4a96-85d6-f356b820d828=True&amp;4cd9df4f-deef-4431-9497-a04303f34986=True\" rel=\"noopener nofollow\" target=\"_blank\">https://www.microsoft.com/zh-cn/software-download/windows11?3ffbea20-eb11-4a96-85d6-f356b820d828=True&amp;4cd9df4f-deef-4431-9497-a04303f34986=True</a></p>\n<p><img alt=\"image-20260206104451878\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171736631-400678532.png\" /></p>\n<p>推荐使用官网的【创建Windows11安装媒体】下载Media Creation Tool工具，使用该工具制作系统启动安装U盘，也可以自行下载要安装的系统ISO镜像制作启动U盘，建议安装与已激活系统同版本的操作系统（家庭版/专业版）以便于免激活（系统许可证基于主板绑定）</p>\n<p>U 盘 ≥ 8GB（制作过程会清空数据！！！）</p>\n<hr />\n<h3 id=\"3-备份驱动重要\">3. 备份驱动（重要）</h3>\n<blockquote>\n<p>双系统安装后，新系统极易出现：<br />\n无线网卡不可用<br />\n有线网卡驱动缺失<br />\n声卡、触控板异常</p>\n</blockquote>\n<p>提前备份 = 安装后 1 分钟恢复</p>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>驱动精灵/厂商驱动</td>\n<td>驱动丢失时还原驱动</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"31-方式一使用第三方工具备份操作简单\">3.1 方式一：使用第三方工具备份（操作简单）</h4>\n<p>(驱动管理软件 驱动精灵)<a href=\"https://www.drivergenius.com/zhuangji/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.drivergenius.com/zhuangji/</a></p>\n<p>需备份当前系统驱动以还原或在电脑厂商官网下载驱动安装程序，推荐使用驱动备份软件（驱动精灵）一键将本系统驱动备份，拷贝备份目录到安装U盘以便于恢复</p>\n<h4 id=\"32-方式二使用-dism-备份所有驱动最稳强烈推荐\">3.2 方式二：使用 DISM 备份所有驱动（最稳，强烈推荐）</h4>\n<blockquote>\n<p>该方式无需联网，适合新系统无网卡驱动的场景</p>\n</blockquote>\n<p>在当前正常系统中，以管理员身份打开 CMD / PowerShell：</p>\n<pre><code class=\"language-powershell\">mkdir D:\\DriverBackup\ndism /online /export-driver /destination:D:\\DriverBackup\n\n</code></pre>\n<p>说明：<br />\nD:\\DriverBackup 建议放在 非系统分区<br />\n会备份：网卡 声卡 芯片组 触控板等 OEM 驱动</p>\n<p>安装完新系统后：</p>\n<pre><code class=\"language-powershell\">dism /online /add-driver /driver:D:\\DriverBackup /recurse\n\n</code></pre>\n<h4 id=\"33-方式三使用电脑品牌厂商的官方驱动安装软件兜底方案\">3.3 方式三：使用电脑品牌厂商的官方驱动安装软件（兜底方案）</h4>\n<blockquote>\n<p>恢复安装驱动时需联网，在网卡驱动丢失的情况下可能无法使用，建议搭配前两种方案食用，优先恢复网卡驱动，保证能联网再说</p>\n</blockquote>\n<p>官网（以【联想】为例）：<a href=\"https://newsupport.lenovo.com.cn/driveDownloads_index.html?ltv_source=L0000000788T0004&amp;pmf_source=Z00045291T004\" rel=\"noopener nofollow\" target=\"_blank\">https://newsupport.lenovo.com.cn/driveDownloads_index.html?ltv_source=L0000000788T0004&amp;pmf_source=Z00045291T004</a></p>\n<p><img alt=\"image-20260206113344878\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171830148-1975446772.png\" /></p>\n<h3 id=\"4-磁盘分区重要步骤\">4. 磁盘分区（重要步骤）</h3>\n<p><img alt=\"image-20260206110747115\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171932799-1515427475.png\" /></p>\n<p>开始菜单右击-&gt;磁盘管理，选中一块大的分区-&gt;压缩卷，留出给新系统的空间（建议至少120G）</p>\n<hr />\n<h2 id=\"二开始安装\">二、开始安装</h2>\n<h3 id=\"1-bios-设置为-u-盘启动\">1. BIOS 设置为 U 盘启动</h3>\n<h4 id=\"11-进入-bios--boot-menu\">1.1 进入 BIOS / Boot Menu</h4>\n<p>常见按键（开机瞬间连续按）：部分笔记本需搭配Fn键，自行百度</p>\n<table>\n<thead>\n<tr>\n<th>品牌</th>\n<th>BIOS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>联想</td>\n<td>F2</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"12设置-u-盘为第一启动项\">1.2设置 U 盘为第一启动项</h4>\n<blockquote>\n<p>⚠ 注意：</p>\n<ul>\n<li>不要开启 Legacy / CSM 模式</li>\n<li>不要随意修改 SATA Mode（AHCI / RAID）</li>\n<li>不确定的选项保持默认</li>\n</ul>\n</blockquote>\n<p>设置启动优先级Boot Priority 中将 U 盘启动方式选项置顶</p>\n<p>保存并退出（F10）</p>\n<h3 id=\"2-系统安装程序运行\">2. 系统安装程序运行</h3>\n<p>根据安装程序指引进行，选择之前磁盘分区时压缩卷留出的空间进行安装，注意：务必选择正确的分区安装系统，不要对EFI等其他重要分区进行任何操作！！！</p>\n<p>安装分区选择判断方法：</p>\n<ul>\n<li>通过分区大小识别</li>\n<li>通过“未分配空间 / 新创建分区”识别</li>\n</ul>\n<p>⚠ 强调：</p>\n<ul>\n<li>不要删除 EFI 分区</li>\n<li>不要新建 EFI 分区</li>\n<li>双系统只共享一个 EFI 分区</li>\n</ul>\n<p>⏰安装程序中提示的将清空所有数据是针对你选择的安装分区而言，保证选择的安装分区正确不会丢失数据</p>\n<h2 id=\"三安装完成后处理\">三、安装完成后处理</h2>\n<blockquote>\n<p>⚠安装完成重启后并没有出现选择系统的界面，可能是系统引导时间未设置默认为0的原因，使用msconfig打开系统引导设置界面调整即可；也可以直接通过命令修改</p>\n</blockquote>\n<h3 id=\"1-设置系统引导程序\">1. 设置系统引导程序</h3>\n<h4 id=\"11-方式一系统gui-工具无法重命名\">1.1 方式一：系统GUI 工具（无法重命名）</h4>\n<p><img alt=\"image-20260206153049367\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172005379-503308437.png\" /></p>\n<p>Win + R → msconfig → 引导 -&gt;  超时<br />\n设置系统引导时间为10s左右</p>\n<h4 id=\"12-方式二通过命令\">1.2 方式二：通过命令</h4>\n<p>使用管理员权限打开命令提示符，查看当前引导配置：</p>\n<pre><code class=\"language-powershell\">bcdedit\n</code></pre>\n<p><img alt=\"image-20260206153846680\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172106105-1002287630.png\" /></p>\n<p>设置启动菜单等待时间（超时）修改为 10 秒：</p>\n<pre><code class=\"language-powershell\">bcdedit /timeout 10\n</code></pre>\n<p>设置默认启动系统</p>\n<pre><code class=\"language-powershell\">bcdedit /default {current}\n</code></pre>\n<p>修改启动菜单名称<br />\n假设其中一个标识符为 {current}：</p>\n<pre><code class=\"language-powershell\">bcdedit /set {current} description \"Windows 11 - Main\"\n</code></pre>\n<p>另一个：</p>\n<pre><code class=\"language-powershell\">bcdedit /set {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} description \"Windows 11 - Backup\"\n</code></pre>\n<h4 id=\"13-方式三第三方工具easybcd\">1.3 方式三：第三方工具（EasyBCD）</h4>\n<blockquote>\n<p>EasyBCD是由NeoSmart Technologies开发的系统引导配置工具，主要用于管理Windows操作系统的启动配置数据（BCD），解决多系统引导兼容性问题；<br />\n建议仅用于引导配置查看与临时调整；<br />\n日常维护推荐使用系统自带工具（bcdedit / msconfig）。</p>\n</blockquote>\n<p>官网下载：<a href=\"https://neosmart.net/EasyBCD/\" rel=\"noopener nofollow\" target=\"_blank\">https://neosmart.net/EasyBCD/</a><br />\n<img alt=\"image-20260206152950078\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172142727-381961332.png\" /></p>\n<h3 id=\"2-恢复驱动\">2. 恢复驱动</h3>\n<blockquote>\n<p>此时进入新安装的系统，网络和声音等设置可能无法使用，别担心，这是驱动未完成安装的表现，还原恢复驱动即可</p>\n</blockquote>\n<p>根据安装前准备工作中备份驱动的操作还原系统驱动</p>\n<h3 id=\"3-隐藏盘符建议\">3. 隐藏盘符（建议）</h3>\n<blockquote>\n<p>此时旧系统和新安装的系统中均可以看到所有的盘符，为了便于理解和防止误操作，建议在对应系统下隐藏其他的盘符，这样每个系统只管理各自的空间，隐藏非本系统盘符可避免：<br />\n- 误删对方系统文件<br />\n- 系统更新写入其他系统分区<br />\n- 快速启动导致的 NTFS 锁盘问题</p>\n</blockquote>\n<blockquote>\n<p>不建议修改新系统中C：盘符的名称，是系统和第三方工具等的默认选择路径，删除其他盘符保留C：即可</p>\n</blockquote>\n<p>步骤：</p>\n<ul>\n<li>删除旧系统中【此电脑】界面中新出现的盘符</li>\n<li>删除新系统中除C：以外的盘符</li>\n</ul>\n<p>操作：<br />\n开始菜单右击-&gt; 磁盘管理-&gt; 列表中选择对应的卷右击-&gt; 更改驱动器号和路径-&gt; 删除<br />\n⚠不是直接右击选择删除卷，将造成数据丢失<br />\n⚠务必确认选择的卷是否正确</p>\n<h3 id=\"4-完成\">4. 完成</h3>\n<blockquote>\n<p>至此，双系统在同一台物理设备上实现了真正的系统级隔离🎉🎉🎉🎉🎉<br />\n合理规划分区、引导与驱动，是双系统长期稳定运行的关键。</p>\n</blockquote>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/yuanjiejie/\" target=\"_blank\">杰哥来了</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/yuanjiejie/p/19585584\" target=\"_blank\">https://www.cnblogs.com/yuanjiejie/p/19585584</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yuanjiejie\">杰哥来了</a>&nbsp;\n阅读(<span id=\"post_view_count\">235</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "长上下文模型是否会取代 RAG？以 Claude Opus 4.6 为例的架构思考",
      "link": "https://www.cnblogs.com/poloapi/p/19585448",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/poloapi/p/19585448\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:07\">\n    <span>长上下文模型是否会取代 RAG？以 Claude Opus 4.6 为例的架构思考</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近在测试 Anthropic 发布的 Claude Opus 4.6 时，一个问题反复出现：</p>\n<blockquote>\n<p>当模型支持百万级上下文窗口后，我们还需要 RAG 吗？</p>\n</blockquote>\n<p>这个问题并不只是技术好奇心，而是一个真实的架构选择问题。</p>\n<p>如果长上下文能力足够强，是否可以直接“全文喂给模型”？<br />\nRAG（Retrieval-Augmented Generation）是否会逐渐失去意义？</p>\n<p>本文从工程角度聊聊这个问题。</p>\n<hr />\n<p><strong>一、RAG 解决的到底是什么问题？</strong></p>\n<p>RAG 本质上解决的是两个问题：</p>\n<ol>\n<li>\n<p>模型上下文窗口有限</p>\n</li>\n<li>\n<p>模型缺乏外部知识</p>\n</li>\n</ol>\n<p>传统做法是：</p>\n<ul>\n<li>\n<p>文档切片</p>\n</li>\n<li>\n<p>向量化</p>\n</li>\n<li>\n<p>相似度检索</p>\n</li>\n<li>\n<p>拼接上下文</p>\n</li>\n<li>\n<p>再交给模型推理</p>\n</li>\n</ul>\n<p>这个流程的优点是：</p>\n<ul>\n<li>\n<p>成本可控</p>\n</li>\n<li>\n<p>延迟可控</p>\n</li>\n<li>\n<p>可扩展性强</p>\n</li>\n</ul>\n<p>但缺点也很明显：</p>\n<ul>\n<li>\n<p>切片破坏语义完整性</p>\n</li>\n<li>\n<p>跨段逻辑容易丢失</p>\n</li>\n<li>\n<p>全局一致性难以保证</p>\n</li>\n</ul>\n<hr />\n<p><strong>二、长上下文能力带来了什么变化？</strong></p>\n<p>Claude Opus 4.6 强调的“百万级上下文窗口”，本质是：</p>\n<blockquote>\n<p>允许一次性输入更大规模文本，并保持推理能力。</p>\n</blockquote>\n<p>理论上，这意味着：</p>\n<ul>\n<li>\n<p>可以直接 ingest 整份合同</p>\n</li>\n<li>\n<p>可以直接 ingest 整本技术手册</p>\n</li>\n<li>\n<p>可以直接 ingest 长序列日志</p>\n</li>\n</ul>\n<p>这似乎绕过了“检索 + 拼接”的流程。</p>\n<p>但工程问题在于：</p>\n<blockquote>\n<p>是否所有场景都值得这么做？</p>\n</blockquote>\n<hr />\n<p><strong>三、长上下文是否等于不需要检索？</strong></p>\n<p>很多人第一反应是：</p>\n<p>“既然能装下，就全部放进去。”</p>\n<p>但从工程角度看，有几个现实问题：</p>\n<p>1️⃣ 计算成本</p>\n<p>输入越长：</p>\n<ul>\n<li>\n<p>Token 成本线性增长</p>\n</li>\n<li>\n<p>推理延迟上升</p>\n</li>\n<li>\n<p>并发能力下降</p>\n</li>\n</ul>\n<p>如果是高 QPS 场景，直接使用超长窗口会迅速放大成本。</p>\n<p>2️⃣ 注意力分布问题</p>\n<p>即使模型支持百万上下文，也并不意味着：</p>\n<ul>\n<li>\n<p>每个 token 都被均匀关注</p>\n</li>\n<li>\n<p>所有信息都等权参与推理</p>\n</li>\n</ul>\n<p>在极长文本中，模型仍然存在“关注分布偏移”。</p>\n<p>换句话说：</p>\n<p>长窗口 ≠ 完美全局理解。</p>\n<p>3️⃣ 可维护性</p>\n<p>RAG 的优势在于：</p>\n<ul>\n<li>\n<p>文档可单独更新</p>\n</li>\n<li>\n<p>向量库可独立维护</p>\n</li>\n<li>\n<p>结构清晰</p>\n</li>\n</ul>\n<p>而“全文输入”方案：</p>\n<ul>\n<li>\n<p>文档版本变化会直接影响推理</p>\n</li>\n<li>\n<p>成本难以预估</p>\n</li>\n<li>\n<p>缺乏局部优化能力</p>\n</li>\n</ul>\n<hr />\n<p><strong>四、一个更现实的架构趋势：混合模式</strong></p>\n<p>在测试 Claude Opus 4.6 的过程中，更合理的模式其实是：</p>\n<blockquote>\n<p>RAG + 长上下文 的混合架构。</p>\n</blockquote>\n<p>具体做法：</p>\n<ol>\n<li>\n<p>先通过检索缩小范围</p>\n</li>\n<li>\n<p>在必要场景下使用长窗口增强全局一致性</p>\n</li>\n<li>\n<p>对关键任务进行全文级推理</p>\n</li>\n</ol>\n<p>也就是说：</p>\n<p>长上下文不是替代 RAG，而是补强 RAG。</p>\n<hr />\n<p><strong>五、什么时候可以考虑弱化 RAG？</strong></p>\n<p>存在一些场景，确实可以降低对 RAG 的依赖：</p>\n<ul>\n<li>\n<p>法律合同全局一致性校验</p>\n</li>\n<li>\n<p>长日志因果链分析</p>\n</li>\n<li>\n<p>大型代码库整体结构理解</p>\n</li>\n</ul>\n<p>这些任务强调“全局逻辑”，而不是“局部检索”。</p>\n<p>在这种情况下，Claude Opus 4.6 的优势会更明显。</p>\n<hr />\n<p><strong>六、真正的关键不在模型，而在架构抽象层</strong></p>\n<p>无论使用 RAG 还是长上下文，都有一个前提：</p>\n<blockquote>\n<p>模型调用必须被抽象出来。</p>\n</blockquote>\n<p>如果业务逻辑直接绑定某个模型接口，一旦：</p>\n<ul>\n<li>\n<p>成本上涨</p>\n</li>\n<li>\n<p>性能变化</p>\n</li>\n<li>\n<p>模型替换</p>\n</li>\n</ul>\n<p>整个系统就会受到影响。</p>\n<p>更合理的做法是：</p>\n<ul>\n<li>\n<p>设计模型调用层</p>\n</li>\n<li>\n<p>支持模型切换</p>\n</li>\n<li>\n<p>支持任务分级路由</p>\n</li>\n</ul>\n<p>在这种架构下，Claude Opus 4.6 只是一个能力选项，而不是架构核心。</p>\n<hr />\n<p><strong>七、结论：长上下文不会取代 RAG</strong></p>\n<p>从工程角度看：</p>\n<ul>\n<li>\n<p>RAG 解决的是“知识获取效率问题”</p>\n</li>\n<li>\n<p>长上下文解决的是“全局一致性问题”</p>\n</li>\n</ul>\n<p>两者不是竞争关系，而是互补关系。</p>\n<p>Claude Opus 4.6 的百万上下文能力确实扩展了模型边界，但它并不会让 RAG 消失。</p>\n<p>更可能的未来是：</p>\n<ul>\n<li>\n<p>轻量任务 → 检索增强</p>\n</li>\n<li>\n<p>高复杂度任务 → 长窗口增强</p>\n</li>\n<li>\n<p>架构层面保持可替换性</p>\n</li>\n</ul>\n<p>模型能力在进步，但架构设计仍然决定系统上限。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/poloapi\">路过的旁听生</a>&nbsp;\n阅读(<span id=\"post_view_count\">148</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "用 10 行 Java8 代码，开发一个自己的 ClaudeCodeCLI？你信吗？",
      "link": "https://www.cnblogs.com/noear/p/19585413",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19585413\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:01\">\n    <span>用 10 行 Java8 代码，开发一个自己的 ClaudeCodeCLI？你信吗？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        最近 Anthropic 推出的 Claude Code 席卷了开发者圈子，其强大的终端交互和“自动驾驶”般的编程能力令人惊叹。那么，在 Java 生态中，我们能否快速构建一个同样强大且高度可控的应用？\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近 Anthropic 推出的 Claude Code 席卷了开发者圈子，其强大的终端交互和“自动驾驶”般的编程能力令人惊叹。那么，在 Java 生态中，我们能否快速构建一个同样强大且高度可控的应用？</p>\n<p>答案是肯定的。基于 <strong>Solon AI</strong> 的 <code>CliSkill</code> 组件，你只需要 10 行核心代码，就能对接海量的开源技能生态，打造一个属于自己的智能终端（Agent CLI）。</p>\n<h3 id=\"1什么是-solon-ai-cliskill能干什么\">1、什么是 Solon AI CliSkill？能干什么？</h3>\n<p>Solon AI CliSkill 是一个基于 <strong>Pool-Box（池盒）模型</strong> 设计的 AI 综合技能插件。它充当了 AI 智能体（Agent）与操作系统之间的“手”和“眼”。兼容 <strong>Claude Code Agent Skills</strong> 规范。</p>\n<ul>\n<li>对接海量生态：</li>\n</ul>\n<p>直接兼容 Claude Code Agent Skills 规范。只需挂载含有 <code>SKILL.md</code> 的技能包，Agent 就能秒变“剪辑师”、“架构师”或“运维专家”。</p>\n<ul>\n<li>精细化文件管理：</li>\n</ul>\n<p>Agent 不再只是胡乱生成代码，它能像人类工程师一样进行 <code>ls</code> 浏览目录、<code>cat</code> 读取规范、<code>grep</code> 检索逻辑，并使用 <code>edit</code> 工具进行精准的行级代码修改。</p>\n<ul>\n<li>安全环境隔离：</li>\n</ul>\n<p>Box（工作盒）：Agent 的受限活动空间。它在这里写代码、跑测试，确保不会误删你的系统根目录，不过仍要小心（它可能会自动安装需要的东西。比如：你要生成视步它会安装 ffmpeg）。Pool（技能池）：外部共享的工具库（只读）。你可以挂载一个专门处理视频的池，或者一个专门处理 K8s 部署的池。</p>\n<h3 id=\"2核心代码10-行-java8-代码开启智能终端\">2、核心代码：10 行 Java8 代码开启智能终端</h3>\n<p>借助 Solon AI 的高度集成，你的 Java 程序可以极简地驱动这一切：</p>\n<pre><code class=\"language-java\">public class DemoApp {\n    public static void main(String[] args) {\n        // 1. 设置工作空间（Agent 将在此目录下进行创作）\n        String workDir = \"/WORK/projects/my-ai-task\";\n\n        // 2. 构建 Agent 并挂载 CliSkill (核心逻辑)\n        ReActAgent agent = ReActAgent.of(LlmUtil.getChatModel())\n                .name(\"SolonCodeAgent\")\n                .instruction(\"严格遵守挂载技能中的【规范协议】执行任务\")\n                .defaultSkillAdd(new CliSkill(workDir)) // 注入 CliSkill 核心能力\n                .maxSteps(100)                         // 允许 Agent 进行复杂的链式思考\n                .build();\n\n        // 3. 驱动任务：Agent 会自动扫描 workDir 下的技能规范并执行\n        agent.prompt(\"帮我生成一个 solon web 项目，实现经典的权限管理系统，包含 Vue3 前端和 Java8 后端\");\n    }\n}\n</code></pre>\n<h4 id=\"更进一步使用内置的-soloncodecli\">更进一步：使用内置的 SolonCodeCLI</h4>\n<p>如果你想直接构建一个交互式命令行工具，Solon AI 还提供了一个高度封装的参考实现 SolonCodeCLI（你可以直接 copy 代码进行定制改造）。</p>\n<p>它不仅内置了交互循环和多技能池管理，还具备 <strong>Web 能力</strong>，可以轻松与 <strong>钉钉、企业微信、飞书等 IM 工具</strong> 对接互动，让 AI 落地到具体的业务流程中：</p>\n<pre><code>public class DemoApp {\n    public static void main(String[] args) {\n        SolonCodeCLI solonCodeCLI = new SolonCodeCLI(LlmUtil.getChatModel())\n                .name(\"小花\")\n                .workDir(\"./app\")\n                .mountPool(\"@shared\", \"/path/to/opencode-skills\")\n                .enableWeb(true)\n                .config(agent -&gt; {\n                    agent.maxSteps(100);\n                });\n\n        solonCodeCLI.run();\n    }\n}\n</code></pre>\n<h3 id=\"3能力进阶多技能池挂载\">3、能力进阶：多技能池挂载</h3>\n<p>如果你希望你的 Agent 是一个“全能天才”，你可以通过 mountPool 隔离挂载不同领域的专家技能包：</p>\n<pre><code class=\"language-java\">CliSkill cli = new CliSkill(\"my-box\", workDir)\n        .mountPool(\"@shared\", \"/path/to/opencode-skills\") //共享技能\n        .mountPool(\"@media\", \"/path/to/ffmpeg-skills\")  // 处理音视频的专家\n        .mountPool(\"@media\", \"/path/to/ffmpeg-skills\")  // 处理音视频的专家\n        .mountPool(\"@ops\", \"/path/to/deploy-scripts\")   // 负责自动部署的专家\n        .mountPool(\"@doc\", \"/path/to/pdf-gen-skills\");  // 负责生成文档的专家\n</code></pre>\n<p>Agent 在执行时，会通过虚拟路径（如 <code>@media/extract.sh</code>）安全地调用这些只读工具。</p>\n<h3 id=\"4真实交互场景体验\">4、真实交互场景体验</h3>\n<p>当你配置好相应的技能包（这里有不错的技能库： <a href=\"https://github.com/zrt-ai-lab/opencode-skills\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/zrt-ai-lab/opencode-skills</a> ）后，你可以体验到如下“科幻”操作：</p>\n<ul>\n<li>自动化重构：</li>\n</ul>\n<p>“检查当前项目的 pom.xml，把所有过时的依赖升级到最新版本，并确保编译通过。”</p>\n<ul>\n<li>全栈项目生成：</li>\n</ul>\n<p>“帮我生成一个基于 Solon 的管理系统。前端要用 Vue3 + ElementPlus，后端要符合 RESTful 规范，带上简单的权限校验逻辑。”</p>\n<ul>\n<li>多媒体联动：</li>\n</ul>\n<p>“先在网上调查一下 Solon AI 的分布式 Skills 架构，写一篇 500 字的总结存为 README.md，然后根据这些内容生成一个 30 秒的视频介绍。”</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">142</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "精灵潜入C++,莲花咒语显神奇",
      "link": "https://www.cnblogs.com/lixingqiu/p/19585352",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lixingqiu/p/19585352\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 16:53\">\n    <span>精灵潜入C++,莲花咒语显神奇</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>看视频在这里:https://www.douyin.com/video/7603656116593052963</p>\n<p>看看这一行长长的C++代码：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">while</span>(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>)r.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).pensize(<span style=\"color: rgba(128, 0, 128, 1);\">5</span>).speed(<span style=\"color: rgba(128, 0, 128, 1);\">0</span>).color(r.heading()).circle(<span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).circle(<span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).right(<span style=\"color: rgba(128, 0, 128, 1);\">20</span>);</pre>\n</div>\n<p>主要就是这一行代码，画了一幅美妙的莲花图案。下面是完整的，C++精灵库画莲花的代码：</p>\n<div class=\"cnblogs_code\">\n<pre>#include <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">sprites.h</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">包含C++精灵库</span>\nSprite r; <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">建立角色叫r</span>\n\n<span style=\"color: rgba(0, 0, 255, 1);\">int</span> main(){ <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">主功能块</span>\n\n<span style=\"color: rgba(0, 0, 255, 1);\">while</span>(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>)r.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).pensize(<span style=\"color: rgba(128, 0, 128, 1);\">5</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n.speed(</span><span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">).color(r.heading())\n.circle(</span><span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n.circle(</span><span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).right(<span style=\"color: rgba(128, 0, 128, 1);\">20</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">return</span> <span style=\"color: rgba(128, 0, 128, 1);\">0</span>; <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">返回0</span>\n}</pre>\n</div>\n<h2>神仙对话泄天机</h2>\n<p>哪吒（手持乾坤圈）：“俺是哪吒三太子，刚刚听闻有位小魔法师用几行代码画出了一朵美轮美奂的莲花。那莲花的花瓣颜色还会随他的笔转向而不断变换，真是神奇！你可知道他是如何做到的？”</p>\n<p>太上老君（手持拂尘）：“此乃C++精灵库的妙用也。那小魔法师创建了一个名为r的角色，就像我身边的童子一样，然后在main函数里用了一个永不停歇的while循环，让r不停地舞动乾坤。”</p>\n<p>哪吒：“你这葫芦里卖的什么药？快讲讲r是怎么画莲花的？”</p>\n<p>太上老君：“那小魔法师在循环里让r做了好多动作。他先把r的背景色设为黑色，就像天庭的黑夜一样深邃。接着把笔画粗细调粗到5个单位，笔速设为0，意味着笔走如飞，一点都不拖沓。”</p>\n<p>哪吒：“嘿嘿，俺这乾坤圈也重达千斤，画笔画粗些倒也般配。那他还做了什么？”</p>\n<p>太上老君：“他把画笔的颜色设置为r.heading()，也就是根据r当前的方向来取颜色。这就好比r在不停地旋转，每转一个角度，颜色就变一变，仿佛r的心情在变，颜色也跟着变。”</p>\n<p>哪吒：“这颜色还会变？那r是怎么转的呢？”</p>\n<p>太上老君：“r画了两个半径100的圆弧，每次转90度。具体来说，先画了一个90度的圆弧，然后左转90度，再画另一个90度的圆弧，又左转90度，然后右转20度。如此循环往复，就像你在打旋子一样，一圈一圈地转。”</p>\n<p>哪吒：“这不是和我用乾坤圈画圈一样吗？那最后r会不会停下来？”</p>\n<p>太上老君：“那小魔法师在循环里没有停下来的意思，while(1)就是无限循环。”</p>\n<p>哪吒：“原来如此！这C++精灵库真像一位多才多艺的画匠，寥寥数笔就能画出五彩斑斓的莲花。而且它的命令和Python的turtle库差不多，对于喜欢Python的孩子来说，学这个C++库就像换了个平台继续玩耍，真是一举两得！”</p>\n<p>太上老君：“哈哈，哪吒你说得对！C++精灵库让孩子们在学习编程时，既可以延续熟悉的图形命令，又能领略C++的强大功能，确实是非常值得学习的库。”</p>\n<p>哪吒：“俺这就回去告诉师傅，让他也教教我C++精灵库，说不定俺也能画出更漂亮的莲花呢！”</p>\n<p>太上老君：“好啊，希望你早日成为C++小能手，画出属于你自己的绚丽莲花！”</p>\n<p><img alt=\"2026-02-06_154409\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n<h2>代码解析学咒语</h2>\n<p>下面的逐行解释了main函数中while循环内的代码，并说明其作用：</p>\n<p>代码行&nbsp; &nbsp; 作用<br />r.bgcolor(\"black\")&nbsp; &nbsp;设置画笔背景色为黑色。<br />.pensize(5)&nbsp; &nbsp;设置画笔粗细为5个像素单位。<br />.speed(0)&nbsp; &nbsp; 设置画笔移动速度为0（最快速度）。<br />.color(r.heading())\t根据画笔当前方向heading()获取颜色值，并设置画笔颜色。方向值会被转换为色相，从而实现颜色随方向变化。<br />.circle(100, 90)&nbsp; &nbsp;以当前位置为圆心，半径100逆时针绘制一个90度的圆弧。<br />.left(90)&nbsp; &nbsp;画笔向左旋转90度。<br />.circle(100, 90)&nbsp; &nbsp;再次向左绘制一个90度的圆弧。<br />.left(90)&nbsp; &nbsp; 画笔再次向左旋转90度。<br />.right(20)\t画笔向右旋转20度（调整方向，使下次循环继续）。<br />上述代码通过链式调用的方式组合了一系列绘图命令，在无限循环中不断重复执行。每次循环中，画笔都会以黑色背景、粗线条、动态颜色绘制两个圆弧，然后旋转方向，如此往复，形成了莲花形状的图案。</p>\n<h2>&nbsp;始作俑者详剖析</h2>\n<p><em id=\"__mceDel\">C++精灵库（Sprite库）是一个基于SDL2库的少儿C++编程教学库，提供了类似Python turtle库的简洁命令，通过绘制图形和制作动画或小游戏创意C++作品来让少年儿童学习C++。它具有以下几个特点和优势：</em></p>\n<p><strong>简单易学</strong>： 库中的命令与Python turtle的命令非常相似，用法绝大多数一模一样。这使得熟悉Python绘图的用户可以快速上手C++编程。对于少年儿童来说，使用熟悉的命令可以降低学习门槛，激发他们对编程的兴趣。<br />功能强大： 虽然命令简单，但C++精灵库基于SDL2库，同时具备C++的强大性能和灵活性。用户可以利用C++的高级特性，如对象、函数和循环，实现更复杂的图形和动画效果。<br /><strong>丰富的图形效果</strong>： 库支持设置画笔颜色、粗细、速度，以及绘制各种图形（直线、圆圈、圆点、圆弧、椭圆等）并且增强了对画笔颜色的一些更精细的控制。比如让颜色渐变的coloradd命令。实际是逐步增加颜色的色相。比如设定颜色的饱和度命令(pensat)，还有设定颜色的明度命令(penvalue) 及洪水填充命令fill等。用户通过组合这些命令，用户可以创造出丰富多彩的图形和动画效果。例如，本示例中通过动态改变画笔颜色，实现了颜色随方向变化的绚丽图案。<br /><strong>拓展与互动性强</strong>： C++精灵库的底痤基于SDL2库，可以完美融入SDL2库的命令，从而方便地响应用户输入（如鼠标点击、键盘按键等）。这使得用该库开发的程序具有更强的交互性，也可以用于游戏和教育应用的开发制作。<br />综上所述，C++精灵库是一个非常适合少年儿童学习编程的工具。它将Python turtle的易用性与C++的强大功能相结合，使孩子们在享受编程乐趣的同时，也能逐步掌握C++语言的基本概念和编程技巧。对于培养少年儿童的逻辑思维和创造力，C++精灵库无疑是一个“一箭双雕”的选择。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-06 16:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lixingqiu\">李兴球</a>&nbsp;\n阅读(<span id=\"post_view_count\">87</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从“千问送奶茶”看AI Agent落地：火爆、崩塌与进化方向",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19590175",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19590175\" id=\"cb_post_title_url\" title=\"发布于 2026-02-08 01:56\">\n    <span>从“千问送奶茶”看AI Agent落地：火爆、崩塌与进化方向</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        阿里通义千问APP在2026年春节期间推出\"30亿免单送奶茶\"活动，通过AI Agent技术实现\"一句话点单\"的便捷体验，3小时内订单突破百万。活动成功验证了AI从聊天工具向\"主动办事助手\"的转型，但也暴露了系统在高并发下的技术短板：API网关崩溃、数据库过载和GPU显存溢出等问题。该活动展现了阿里在大模型技术、生态整合（高德、支付宝等）和成本控制（自研芯片）方面的独特优势，为AI Agent的商业化落地提供了重要参考，同时也揭示了工程化能力仍需突\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>@</p><div class=\"toc\"><div class=\"toc-container-header\">目录</div><ul><li><a href=\"#前言\" rel=\"noopener nofollow\">前言</a></li><li><a href=\"#2026年2月6日全民薅羊毛热潮下的狂欢与崩塌\" rel=\"noopener nofollow\">2026年2月6日：全民薅羊毛热潮下的狂欢与崩塌</a></li><li><a href=\"#原理解析千问是怎么通过一句话点奶茶的又为什么崩溃了\" rel=\"noopener nofollow\">原理解析：千问是怎么通过一句话点奶茶的？又为什么崩溃了？</a></li><li><a href=\"#为什么千问服务器会崩溃三重技术瓶颈被流量击穿\" rel=\"noopener nofollow\">为什么千问服务器会崩溃？三重技术瓶颈被流量击穿</a></li><li><a href=\"#为什么只有阿里能做千文送奶茶三大核心壁垒不可复制\" rel=\"noopener nofollow\">为什么只有阿里能做“千文送奶茶”？三大核心壁垒不可复制</a></li><li><a href=\"#改进方向ai-agent的进化之路从能办事到办好事\" rel=\"noopener nofollow\">改进方向：AI Agent的进化之路——从“能办事”到“办好事”</a></li><li><a href=\"#结语ai-agent落地始于场景成于细节\" rel=\"noopener nofollow\">结语：AI Agent落地，始于场景，成于细节</a></li></ul></div><p></p>\n<h1 id=\"前言\">前言</h1>\n<p>2026年春节期间，阿里通义千问APP推出的“<strong>30亿免单送奶茶</strong>”活动，意外引爆全民参与热潮，也成为AI Agent技术从实验室走向大众生活的一次标志性试炼。近年来，大模型技术飞速迭代，从19年OpenAI的GPT系列、Gemini3到国内的Deepseek，通义千问、文心一言，AI的核心能力已从“自然语言理解与生成”逐步转向“自主决策与任务执行”，但行业始终面临着一个世界性难题：<strong>用户仅停留在“聊天娱乐”场景</strong>、<strong>无法形成从交互到变现的商业闭环</strong>。</p>\n<p>阿里此次以“<strong>奶茶免单</strong>”为切入点，本质上是以免费的旗号，通过高频需求的消费场景，打通对话式AI与实际使用之间的应用壁垒，让AI从“被动应答的工具”升级为“<strong>主动办事的助手</strong>”。</p>\n<p>诚然，这场声势浩大的活动展现了AI Agent落地的巨大<strong>潜力</strong>，但同时也暴露了技术、工程化层面的诸多<strong>短板</strong>，成为值得整个AI行业深思的典型案例。本文将基于近期相关报道与技术细节，全面拆解“千文送奶茶”的现象、原理，并探讨AI Agent未来的优化方向与技术壁垒。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h1 id=\"2026年2月6日全民薅羊毛热潮下的狂欢与崩塌\">2026年2月6日：全民薅羊毛热潮下的狂欢与崩塌</h1>\n<p><strong>一、千文点奶茶：全民级的AI消费狂欢</strong><br />\n“千文送奶茶”活动自2026年2月6日上线以来，凭借“无套路、真免单”的特点迅速刷屏全网。活动核心规则简单易懂：用户更新通义千问APP后，只需通过语音或文字发出“帮我点一杯奶茶”的指令，即可领取25元无门槛免单券并且千文AI会直接帮助用户选择好奶茶并下单，覆盖全国30多万家茶饮门店，包括瑞幸、蜜雪冰城、奈雪的茶、茶百道等主流品牌，单人最高可领取525元免单额度。</p>\n<p>不同于以往互联网平台“满减、拉人头”的套路，此次活动真正实现了“一句话办事”的便捷体验，这也直接推动了活动的爆发式增长。据官方数据及媒体报道，活动上线3小时订单量即突破百万，4小时突破200万单，9小时内总订单量更是飙升至1000万单，刷新了全球AI购物的纪录；与此同时，千问APP成功登顶应用商店免费榜总榜，下载量短期内暴涨，实现了用户量的跨越式增长。</p>\n<p>从社交媒体反馈来看，大量用户分享了自己的“薅羊毛”经历，有人实现“1分钱喝奶茶”，有人批量下单分享给亲友，相关话题多次冲上热搜，形成了全民参与、全民讨论的热潮。这场狂欢的背后，是用户对“AI能办事”的新鲜感与认可，也是大众对AI Agent落地场景的首次大规模体验。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><strong>二、点单流程：极简交互背后的全链路自动化</strong><br />\n千文点奶茶的核心优势的在于“极简交互+全流程自动化”，用户无需跳转其他APP、无需手动填写地址、无需比价凑单，仅需一句话即可完成从需求提出到支付核销的全流程，具体操作步骤可拆解为3步：</p>\n<ol>\n<li>\n<p>需求发起：用户通过千问APP的语音或文字交互框，发出点单指令，既可以是简单的“帮我点一杯奶茶”，也可以是复杂的定制化需求，如“1杯霸王茶姬，少冰、要少糖”；</p>\n</li>\n<li>\n<p>AI自主处理：千问大模型自动解析用户意图，将“少糖”“冰饮”等模糊描述转化为标准化参数（如“5分糖”“冰度正常”），同时拆解批量订单、口味偏好等隐性需求，若信息不完整（如未说明地址），会通过多轮对话追问用户；</p>\n</li>\n<li>\n<p>全流程闭环：AI自动调用用户淘宝或支付宝的常用地址（或通过高德地图实时定位），基于地理位置和用户历史偏好，筛选3公里内评分4.8以上的合作门店，生成包含优惠信息的订单方案，用户点击“支付宝付款”后，通过首次授权的账号完成面容、指纹或密码核身，即可在千问APP内完成支付，无需跳转其他应用，支付完成后自动生成核销码，用户可直接到店取餐或等待外卖送达。</p>\n</li>\n</ol>\n<p>官方数据显示，这种“AI付”模式将传统点单的操作步骤减少了90%以上，真正实现了“说一句，就办好”，也是其能够快速吸引全民参与的核心原因。</p>\n<p><strong>三、服务器崩溃：流量洪峰下的技术失守</strong></p>\n<p>就在全民狂欢的同时，千问APP的服务器却不堪重负，陷入崩溃状态。活动上线后不久，大量用户反馈：活动页面加载失败、点击无响应，频繁弹出“系统开小差了”的提示；部分用户领到的免单卡延迟到账，邀请好友的奖励出现“被吞”情况；还有用户发出点单指令后，AI长时间无响应，无法完成订单创建。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p>据技术媒体拆解，此次崩溃的核心原因是瞬时流量远超服务器承载上限。千问APP日常每秒请求数（QPS）约为1万，而活动峰值时，QPS直接冲上80万，是平时的80倍以上，远超服务器理论承载的24万QPS上限。活动专属页面的局部拥堵，让“千问崩了”冲上热搜，影响了大量用户的参与体验。</p>\n<p>在卡顿发生后10分钟内，千文官方通过微博和APP弹窗发布回应，承认“活动太火爆导致拥堵”，并承诺“正在紧急加资源扩容”。随后，技术团队火速增配200余台服务器，优化系统架构，优先保障核心下单链路；同时，官方将所有25元免单卡的有效期从原定的3天延长至2月23日，引导用户错峰参与，分流瞬时压力，并开通24小时专属客服通道，针对订单异常、奖励丢失等问题进行核实补发，逐步缓解了用户的不满情绪。</p>\n<h1 id=\"原理解析千问是怎么通过一句话点奶茶的又为什么崩溃了\">原理解析：千问是怎么通过一句话点奶茶的？又为什么崩溃了？</h1>\n<p>千文点奶茶看似简单的“一句话办事”，背后是通义千问大模型的自然语言处理能力与阿里全生态资源的深度整合，其技术逻辑可拆解为“意图解析—资源调用—闭环执行”三个核心环节，形成了完整的AI Agent任务执行链路：</p>\n<p><strong>一、意图解析：Qwen-Plus大模型的核心能力支撑</strong><br />\n用户发出的点单指令，首先由千问内置的Qwen-Plus大模型进行处理，这一步的核心是“精准理解模糊需求、拆解隐性需求”。<strong>Qwen-Plus</strong>大模型具备强大的上下文理解与多轮对话能力，能够实现：</p>\n<ul>\n<li>\n<p><strong>模糊需求标准化</strong>：将用户口中的“少糖”“微冰”“半糖去冰”等模糊描述，转化为外卖平台、茶饮门店可识别的标准化参数（如“5分糖”“冰度50%”“无冰”），避免因需求模糊导致订单出错；</p>\n</li>\n<li>\n<p><strong>隐性需求拆解</strong>：能够从用户的指令中，拆解出批量订单、口味偏好、配送方式等隐性需求，例如用户说“帮我和同事点奶茶，我要珍珠的，他们随便”，AI会自动拆解为“多杯订单+用户本人珍珠奶茶+其他同事随机口味”，并追问同事人数、是否有忌口等补充信息；</p>\n</li>\n<li>\n<p><strong>上下文连贯记忆</strong>：支持多轮对话的上下文衔接，例如用户先发出“点一杯珍珠奶茶”，后续补充“加椰果，少糖”，AI能够连贯识别为“修改原有订单的配料和甜度”，而非重新创建新订单，提升交互体验。</p>\n</li>\n</ul>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><strong>二、资源调用：阿里生态的“超级连接器”作用</strong><br />\n在解析用户意图后，千问Agent将扮演“超级连接器”的角色，调用阿里生态内的多平台资源，完成订单创建、支付、定位等一系列操作，这也是其能够实现“<strong>全流程自动化”</strong>的核心支撑，具体涉及三大生态资源：</p>\n<ul>\n<li>\n<p><strong>定位与地址资源</strong>：调用高德地图的实时定位接口，获取用户当前位置（精度±5米），同时联动淘宝、支付宝的常用地址库，自动填充配送地址，无需用户手动输入；</p>\n</li>\n<li>\n<p><strong>商家与订单资源</strong>：对接淘宝闪购平台的茶饮门店数据库，筛选用户周边3公里内、评分4.8以上的合作门店，获取门店库存、产品价格、优惠活动等实时信息，生成最优订单方案；</p>\n</li>\n<li>\n<p><strong>支付资源</strong>：联动支付宝的支付接口，实现“AI付”模式，用户首次授权后，可直接在千问APP内完成面容、指纹或密码核身，无需跳转支付宝，形成“交互—下单—支付”的闭环。</p>\n</li>\n</ul>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><strong>三、闭环执行：任务拆解与多链路协同</strong><br />\n千问将“点奶茶”这一复杂任务，拆解为“意图识别—地址获取—商家筛选—订单生成—支付核销”5个细分步骤，每个步骤由对应的模块独立执行，同时通过分布式系统实现多链路协同，确保整个流程顺畅高效。例如，在用户发出指令的同时，AI同步启动地址获取与商家筛选，无需等待前一个步骤完成，大幅缩短了订单创建时间；支付完成后，自动获取取餐码码，并同步发送到用户。</p>\n<h1 id=\"为什么千问服务器会崩溃三重技术瓶颈被流量击穿\">为什么千问服务器会崩溃？三重技术瓶颈被流量击穿</h1>\n<table>\n<thead>\n<tr>\n<th>指标</th>\n<th>数值</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>活动上线3小时订单量</td>\n<td>100万单</td>\n<td>刷新全球AI购物纪录</td>\n</tr>\n<tr>\n<td>活动上线4小时订单量</td>\n<td>200万单</td>\n<td>-</td>\n</tr>\n<tr>\n<td>活动上线9小时订单量</td>\n<td>1000万单</td>\n<td>-</td>\n</tr>\n<tr>\n<td>日常QPS</td>\n<td>1万次/秒</td>\n<td>千问APP常规请求量</td>\n</tr>\n<tr>\n<td>活动峰值QPS</td>\n<td>80万次/秒</td>\n<td>日常的80倍</td>\n</tr>\n</tbody>\n</table>\n<p>此次千问服务器崩溃，并非单一环节的故障，而是AI Agent首次面对“全民级流量”时，接入层、业务层、AI推理层三重技术瓶颈同时被击穿的结果，本质上是“工程化能力”未能匹配“场景落地需求”的体现：</p>\n<p><strong>一、接入层瓶颈：API网关扛不住高频并发</strong><br />\n接入层是用户请求进入系统的第一道关卡，负责接收用户指令、分发请求。此次活动中，80万QPS的瞬时流量直接导致API网关瘫痪，内存被网络栈完全占满，线程模型崩溃，大量用户请求无法被正常接收和分发，出现“页面加载失败、点击无响应”的情况。核心原因是对流量预判不足，未针对极端场景配置足够的网关扩容能力，且未设置完善的流量限流与分流机制。</p>\n<p><strong>二、业务层瓶颈：数据缓存与数据库承压过载</strong><br />\n业务层负责订单生成、优惠核销、用户权益发放等核心操作，依赖数据库和缓存的支撑。此次流量洪峰中，缓存被击穿，大量用户请求直接穿透缓存，访问数据库，导致数据库连接池被打满，分布式事务锁疯狂竞争，出现免单卡“被吞”、订单异常、权益延迟到账等问题。此外，业务层的订单处理逻辑未针对高频并发场景优化，单订单处理耗时过长，进一步加剧了系统拥堵。</p>\n<p><strong>三、AI推理层瓶颈：GPU显存溢出，推理效率骤降</strong><br />\nAI推理层是千问解析用户意图的核心，依赖GPU的算力支撑。此次活动中，大量用户同时发出点单指令，导致GPU显存溢出，Pod批量重启，单Pod吞吐仅为预期的1/3，用户发出的点单指令无法被及时解析，出现“AI长时间无响应”的情况。尽管阿里通过自研芯片和Qwen-MoE 2.0混合专家模型，大幅降低了推理成本，但面对80万QPS的瞬时推理请求，仍显算力不足，暴露了AI推理层的弹性扩容能力短板。</p>\n<h1 id=\"为什么只有阿里能做千文送奶茶三大核心壁垒不可复制\">为什么只有阿里能做“千文送奶茶”？三大核心壁垒不可复制</h1>\n<p>“千文送奶茶”看似是一场简单的补贴活动，但背后需要大模型技术、生态资源、成本控制三大核心能力的支撑，这也是目前国内其他科技公司难以复制的壁垒，而阿里恰好同时具备这三大优势：</p>\n<p><strong>一、算力成本壁垒：自研芯片+全栈架构，实现成本可控</strong><br />\nAI Agent的大规模落地，核心前提是“<strong>算力成本可控</strong>”。过去，大模型的训练与推理成本极高，单用户交互成本居高不下，大规模免费活动根本无法持续。而阿里通过一年的技术迭代，将算力成本降至行业极致：一方面，平头哥自研真武810E AI芯片，配合“通云哥”全栈架构，将GPU用量降低82%；另一方面，Qwen-MoE 2.0混合专家模型的推理成本较上一代下降60%，支持高并发处理；再加上动态调度、冷热分层、Serverless架构的优化，同样算力可支撑5倍用户量，单用户交互成本降至分厘级。这种成本控制能力，是阿里敢于投入30亿开展免单活动的核心底气，也是其他厂商难以企及的优势——多数厂商依赖第三方GPU芯片，算力成本无法实现如此大幅度的下降。</p>\n<p><strong>二、生态闭环壁垒：全链路资源协同，实现“AI办事”闭环</strong><br />\n“千文送奶茶”的核心是“一句话办事”，而这需要“意图解析—商家对接—支付履约”的全链路协同，这恰恰是阿里生态的独特优势。阿里旗下拥有<strong>通义千问</strong>（大模型）、<strong>淘宝闪购</strong>（履约资源）、<strong>支付宝</strong>（支付资源）、<strong>高德地图</strong>（定位资源）等全链路生态产品，能够实现数据互通、接口联动，无需依赖第三方平台。例如，千问可以直接调用淘宝的门店数据库、支付宝的支付接口，无需经过第三方授权，大幅提升了订单处理效率，也避免了第三方接口调用带来的稳定性风险。而国内其他科技公司，要么缺乏大模型技术，要么缺乏完整的消费生态，要么无法实现生态内资源的深度协同，难以实现“<strong>全流程自动化点单</strong>”——比如腾讯有微信生态和支付资源，但缺乏足够的茶饮商家资源和自研大模型的大规模落地能力；百度有文心一言大模型，但缺乏消费生态的支撑，无法实现“下单—支付”的闭环。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><strong>三、技术落地壁垒：大模型+工程化能力，实现规模化应用</strong><br />\nAI Agent的落地，不仅需要强大的大模型技术，更需要<strong>成熟的工程化能力</strong>，能够应对<strong>高并发、高可用、高稳定</strong>的场景需求。阿里在电商、支付领域积累了多年的工程化经验，能够支撑双11等大规模并发场景的稳定运行，这种经验也被迁移到千问的落地中——尽管此次出现了服务器崩溃，但技术团队能够快速响应、紧急扩容，在短时间内缓解问题，体现了成熟的工程化应对能力。此外，千问大模型经过多年的迭代，在自然语言理解、任务拆解、多轮对话等方面的能力已趋于成熟，能够精准解析用户的点单需求，避免因意图理解错误导致订单异常，这也是其能够实现“<strong>一句话点单</strong>”的核心技术支撑。</p>\n<table>\n<thead>\n<tr>\n<th>能力维度</th>\n<th>阿里巴巴（通义千问）</th>\n<th>腾讯（元宝AI）</th>\n<th>百度（文心一言）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>大模型意图解析能力</td>\n<td>★★★★★（Qwen-Plus支撑）</td>\n<td>★★★☆☆（混元大模型）</td>\n<td>★★★★☆（文心4.0）</td>\n</tr>\n<tr>\n<td>自研AI芯片/算力成本控制</td>\n<td>★★★★★（真武810E）</td>\n<td>★★☆☆☆（无自研芯片）</td>\n<td>★★★☆☆（昆仑芯）</td>\n</tr>\n<tr>\n<td>茶饮商家资源覆盖</td>\n<td>★★★★★（30万+门店）</td>\n<td>★★☆☆☆（少量合作门店）</td>\n<td>★☆☆☆☆（无核心商家资源）</td>\n</tr>\n<tr>\n<td>支付闭环能力</td>\n<td>★★★★★（支付宝直连）</td>\n<td>★★★★★（微信支付）</td>\n<td>★☆☆☆☆（无自有支付）</td>\n</tr>\n<tr>\n<td>定位/地址资源协同</td>\n<td>★★★★★（高德地图）</td>\n<td>★★★★☆（腾讯地图）</td>\n<td>★★★☆☆（百度地图）</td>\n</tr>\n<tr>\n<td>高并发工程化经验</td>\n<td>★★★★★（双11技术沉淀）</td>\n<td>★★★★☆（微信红包场景）</td>\n<td>★★☆☆☆（缺乏大规模消费场景）</td>\n</tr>\n<tr>\n<td>全流程自动化落地成熟度</td>\n<td>★★★★★（已商用）</td>\n<td>★★☆☆☆（仅demo阶段）</td>\n<td>★☆☆☆☆（无落地场景）</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"改进方向ai-agent的进化之路从能办事到办好事\">改进方向：AI Agent的进化之路——从“能办事”到“办好事”</h1>\n<p>“千文送奶茶”的火爆与崩溃，给整个AI Agent行业上了生动的一课：AI Agent要实现真正的规模化落地，不仅要解决“能办事”的问题，更要解决“办好事”的问题——即提升用户体验，考虑用户决策过程中的各类隐性需求，提供更精准、更贴心的服务。结合此次活动暴露的问题，以及AI Agent的技术发展趋势，千问及同类AI Agent在点单场景中，可从以下方面进行改进。</p>\n<p><strong>展示门店与外卖实时情况，辅助用户决策</strong></p>\n<p><strong>核心需求：展示外卖门店出餐拥堵与履约负荷，前置提示外卖等待风险</strong></p>\n<p>用户点外卖奶茶时，真正影响体验的是门店出餐积压、骑手运力不足、配送链路拥堵导致的长时间等待与超时送达。当前千问仅基于距离、评分、价格筛选门店，未整合外卖全链路的实时出餐状态、订单负荷、运力匹配度，导致用户下单后才发现门店爆单出餐慢、区域无骑手、配送超时，大幅降低用户满意度与复购意愿。<strong>并且给奶茶店面和外卖骑手带来巨大的压力</strong>。</p>\n<p>外卖履约的核心瓶颈是 <strong>“商家出餐效率 + 区域运力供给 + 路况配送效率”</strong> 的三重动态平衡：高峰期热门茶饮店订单积压可超千杯，出餐时长从 10 分钟拉长至 40 分钟以上；同时区域骑手供不应求，取餐等待、配送绕路进一步加剧时效延误。千问作为 AI Agent，必须在下单前向用户透明展示这些履约风险，辅助用户决策是否下单、是否更换门店。</p>\n<h1 id=\"结语ai-agent落地始于场景成于细节\">结语：AI Agent落地，始于场景，成于细节</h1>\n<p>“千文送奶茶”活动无疑是AI Agent落地的一次成功尝试——它用全民可感知的方式，证明了AI从“能聊天”到“能办事”的可行性，也跑通了“大模型+生态”的商业化闭环，为整个行业提供了宝贵的参考经验。但同时，服务器崩溃、用户体验不足等问题，也暴露了AI Agent在工程化能力、场景细节优化等方面的短板。</p>\n<p>从“能办事”到“办好事”，是AI Agent未来的核心进化方向。对于千问而言，此次活动的改进空间，恰恰是其提升核心竞争力的关键——通过整合门店排队数据、外卖运力数据，优化ETA算法，提供个性化替代推荐，不仅能提升用户体验，更能进一步巩固其“生态+技术”的核心壁垒。而对于整个AI行业而言，“千文送奶茶”的启示在于：AI Agent的落地，从来不是单纯的技术竞赛，而是技术、生态、工程化、用户体验的综合比拼。</p>\n<p>未来，随着算力成本的进一步降低、多源数据协同能力的提升、算法精准度的优化，AI Agent将逐步渗透到外卖、购物、出行等更多高频刚需场景，真正成为人们生活中的“全能助手”。而“千文送奶茶”，不过是这场AI革命的一个起点。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-08 01:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "引入AI辅助的3D游戏美术工作流",
      "link": "https://www.cnblogs.com/geek1116/p/19589538",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/geek1116/p/19589538\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 19:24\">\n    <span>引入AI辅助的3D游戏美术工作流</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"3d游戏美术流程\">3D游戏美术流程</h2>\n<p>不同于其他类型的AI应用，3D内容的AI生成应用所面向的行业更加垂直，会有一定的专业使用门槛，并且生成的产物与直接投入生产环境的内容往往还存在一定的距离。笔者这里针对小型独立游戏/Demo的场景下，为提高3D游戏美术工作效率和降低成本，分享下在引入了AI生成后的美术工作流程。</p>\n<p>首先回顾下在行业中一个比较主流的美术工作流，大致如下：</p>\n<pre><code class=\"language-markdown\">雕刻高模\n   ↓\n拓扑低模、布线\n   ↓\n  展UV\n   ↓\n由高模烘焙出法线、AO等贴图\n   ↓\n绘制颜色、金属度、粗糙度等PBR贴图\n   ↓\n制作骨骼、绑定、刷权重、测试蒙皮\n   ↓\n制作骨骼动画\n   ↓\n导入游戏引擎调试\n</code></pre>\n<p>传统流程中每个环节依赖的DCC工具都是不一样的，甚至同一步骤都能有多种工具可以选 例如建模阶段的3D Max（硬表面物体）和Maya（角色/生物建模）等。考虑到学习成本和独立开发的效率，笔者选择了全流程制作都使用Blender。这也是许多独立开发者的选择，毕竟作为个人和小微团队来说，采用行业最佳实践的美术工作流并不现实。</p>\n<h2 id=\"ai工具选择\">AI工具选择</h2>\n<p>笔者共测评了四款拥有对游戏资产开发有一定支持的平台，分别是：</p>\n<ul>\n<li>腾讯的混元3D：<a href=\"https://3d.hunyuan.tencent.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://3d.hunyuan.tencent.com/</a></li>\n<li>Rodin的Hyper3D：<a href=\"https://hyper3d.ai/\" rel=\"noopener nofollow\" target=\"_blank\">https://hyper3d.ai/</a></li>\n<li>Tripo AI：<a href=\"https://www.tripo3d.ai/zh\" rel=\"noopener nofollow\" target=\"_blank\">https://www.tripo3d.ai/zh</a></li>\n<li>Meshy：<a href=\"https://www.meshy.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://www.meshy.ai</a></li>\n</ul>\n<p>综合体验下来，混元3D和Tripo AI不管是在流程完整性还是生成内容的质量上，都是目前最佳的。二者均支持组件拆分这一大多数竞品没有的功能。另外，腾讯混元3D中的3D Studio是完全针对游戏行业定制化的工作流，在前置流程上还可以衔接<em>腾讯混元游戏</em>（自家的另一个平台：<a href=\"https://hunyuan.tencent.com/game%EF%BC%89%EF%BC%8C%E6%8F%90%E4%BE%9B%E4%BA%86%E5%A4%9A%E7%A7%8D%E8%A7%92%E8%89%B2/%E9%81%93%E5%85%B7/%E5%9C%BA%E6%99%AF%E7%9A%84%E6%A6%82%E5%BF%B5%E8%AE%BE%E8%AE%A1%E5%B7%A5%E5%85%B7%E3%80%82\" rel=\"noopener nofollow\" target=\"_blank\">https://hunyuan.tencent.com/game），提供了多种角色/道具/场景的概念设计工具。</a></p>\n<p>笔者在挺久之前就有关注到腾讯混元3D并且挺看好的，但它一直没有进行商业化，目前每天只能获取非常少的固定生成次数来在平台内使用；而且3D Studio是需要单独去申请内测资格后才能使用的，生成的内容会有版权归属的问题。最终决定使用Tripo AI来辅助笔者3D美术工作。</p>\n<h2 id=\"ai工具实践\">AI工具实践</h2>\n<p>首先需要准备好一张设计图；这一步的手段是非常的丰富的，手绘、外包稿件、亦或是文生图/图生图等AI生成方式。本文这里的例子是使用的之前自己手绘+AI融图出来的一张外星怪物设计图。打开Tripo AI的3D工作台，右侧面板中上传图片（为了提高生成的准确性，最好用多视图生成）：<br />\n<img alt=\"prepareImg\" class=\"lazyload\" /></p>\n<p>同时设置生成模型的参数。高清纹理和PBR属于鸡肋特性，开启与否都行，因为AI生成的纹理质量肯定是无法投入生产使用的。重要的参数是拓扑设置中的拓扑面和面数控制；其中的智能低模是Tripo新出的特性，笔者还尚未试用过。<br />\n<img alt=\"generate-params\" class=\"lazyload\" /></p>\n<p>点击生成，得到模型：<br />\n<img alt=\"generate-model\" class=\"lazyload\" /></p>\n<p>虽然开启了PBR纹理但看不出什么效果。</p>\n<p>切换到白模，看下布线效果：<br />\n<img alt=\"white-model\" class=\"lazyload\" /></p>\n<p>有点稀碎......</p>\n<p>展UV的效果在应用里看不了，需要导入进Blender后再看。接着在下方设置导出，格式用<code>.FBX</code>，选个纹理分辨率，轴心重置到原点：<br />\n<img alt=\"export-model\" class=\"lazyload\" /></p>\n<h2 id=\"进入blender中工作\">进入Blender中工作</h2>\n<p>新建Blender工程，将刚刚由Tripo AI导出的<code>FBX</code>文件导入进来。</p>\n<p>在白模中首先检查下模型完整性，是否有破面、面朝向异常等问题：<br />\n<img alt=\"check-normal\" class=\"lazyload\" /></p>\n<p>笔者导出的这个模型的尾巴处存在几片法线异常的面<em><font color=\"gray\">（4.x版本后只会对异常法向的面标红色）</font></em>。</p>\n<p>接着切换到UV编辑，看下UV展的效果：<br />\n<img alt=\"unwrap-uv\" class=\"lazyload\" /></p>\n<p>依旧稀碎......这拆的甚至还不如Blender自带的智能UV。考虑到后续的可维护性，建议还是调整下布线重新拆UV。</p>\n<p>调整完后到着色器界面中基于新UV重新烘焙出法线、颜色等贴图。最好再把贴图都输出到本地作为外部图像引用：<br />\n<img alt=\"BSDF\" class=\"lazyload\" /></p>\n<p>确保所有新贴图都无误后，下一步进入到纹理绘制。这里就是需要自己手绘调整各项贴图了：<br />\n<img alt=\"paint_texture\" class=\"lazyload\" /></p>\n<p>在unity中使用标准的urp材质的话，金属度和光滑度是共用一张贴图的：<br />\n<img alt=\"urp-inspector\" class=\"lazyload\" /></p>\n<p>所以需要将着色材质中的金属度和粗糙度贴图进行通道合并。该步骤就是简单的图像操作，既可在PS这种软件中操作也可以在Blender的合成器中操作。笔者建议图像操作也都可以放在Blender中处理；不仅无需切换工作软件，而且合成器这一基于节点编辑器构建的工作流在后期维护也方便得多，随时修改材质贴图后都能自动化完成转换贴图的工作：<br />\n<img alt=\"composition\" class=\"lazyload\" /></p>\n<p>至此模型的静态部分完成。</p>\n<p>还剩下骨骼制作、绑定和动画的工作了，这几块就需要完全由自己动手了。智能绑骨和骨骼动画目前还未找到可用的AI工具，尤其是非人形的生物模型。如果是人形的动画，其实可以借助Mixamo网站来完成动画工作，这一免费动画平台对于小项目而言也足够了。<br />\n<img alt=\"animation\" class=\"lazyload\" /><br />\n<em><font color=\"gray\">制作一个行走和死亡动画</font></em></p>\n<h2 id=\"导入游戏引擎\">导入游戏引擎</h2>\n<p>完成了Blender中的工作后将怪物模型以<code>.fbx</code>的格式导出；导出时带上骨骼与动画相关的信息。</p>\n<p>在Unity编辑器中导入刚刚的<code>.fbx</code>和贴图文件。在面板中检查骨骼类型和动画资源是否正常：<br />\n<img alt=\"animation-inspector\" class=\"lazyload\" /></p>\n<p>将材质暴露出来：<br />\n<img alt=\"extract-material\" class=\"lazyload\" /></p>\n<p>为材质赋予各个贴图后，创建<code>Animator</code>和测试脚本：<br />\n<img alt=\"unity-asset\" class=\"lazyload\" /></p>\n<p>最后在场景中查看运行效果。<br />\n<img alt=\"run-demo\" class=\"lazyload\" /></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 19:24</span>&nbsp;\n<a href=\"https://www.cnblogs.com/geek1116\">爱喝可乐的咖啡</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}