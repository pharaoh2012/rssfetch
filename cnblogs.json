{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "wso2~通过三方IDP的token置换wso2的token",
      "link": "https://www.cnblogs.com/lori/p/19532862",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lori/p/19532862\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 16:25\">\n    <span>wso2~通过三方IDP的token置换wso2的token</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>参数：<a href=\"https://datatracker.ietf.org/doc/html/rfc7523\" rel=\"noopener nofollow\" target=\"_blank\">https://datatracker.ietf.org/doc/html/rfc7523</a></p>\n<h1 id=\"oauth20中的三方另类授权\">oauth2.0中的三方另类授权</h1>\n<p>了解OAuth 2.0中特定的授权类型（Grant Type）对于构建安全的认证流程至关重要。下面为你详细介绍这三种基于URN声明的扩展授权类型。</p>\n<h3 id=\"-设备代码授权-urnietfparamsoauthgrant-typedevice_code\">🔐 设备代码授权 (<code>urn:ietf:params:oauth:grant-type:device_code</code>)</h3>\n<p>这种授权模式专为输入能力受限或没有浏览器的设备设计，比如智能电视、游戏机、IoT设备或命令行工具（CLI）。</p>\n<ul>\n<li>\n<p><strong>工作原理</strong>：其核心是一个两步过程。</p>\n<ol>\n<li><strong>设备获取代码</strong>：设备上的应用首先向授权服务器（如 Microsoft Entra ID）的 <code>/devicecode</code> 端点发起请求。服务器会返回一组信息，包括一个简短的 <code>user_code</code>（用户代码）和一个 <code>verification_uri</code>（验证网址）。</li>\n<li><strong>用户授权</strong>：设备将 <code>user_code</code> 和 <code>verification_uri</code> 显示给用户，并提示用户在其他设备（如个人手机或电脑）上打开浏览器，访问该网址并输入代码。用户在授权服务器的正规页面上完成身份验证（可能包括多因素认证）并同意授权。在此期间，设备应用会定期轮询授权服务器的令牌端点，直到用户完成操作后获取访问令牌和刷新令牌。</li>\n</ol>\n</li>\n<li>\n<p><strong>安全风险与防御</strong>：需要注意的是，此流程可能被用于进行高迷惑性的网络钓鱼攻击（称为“设备代码钓鱼”）。攻击者会诱导用户在真实的微软登录页面输入由攻击者生成的设备代码，从而授权一个恶意应用。防御措施包括在服务器端严格限制应用同意策略、实施条件访问策略（如要求来自合规设备），以及对用户进行安全教育。</p>\n</li>\n</ul>\n<h3 id=\"-令牌交换授权-urnietfparamsoauthgrant-typetoken-exchange\">🔄 令牌交换授权 (<code>urn:ietf:params:oauth:grant-type:token-exchange</code>)</h3>\n<p>令牌交换授权提供了强大的 interoperability（互操作性），允许将一个凭证或令牌交换为另一个不同的令牌，常用于服务之间的安全调用或身份映射。</p>\n<ul>\n<li>\n<p><strong>核心概念</strong>：它遵循 OAuth Token Exchange 规范，使得客户端能够使用一个现有的 <code>subject_token</code>（主体令牌）来换取一个新的、针对不同受众或资源的 <code>access_token</code>（访问令牌）。</p>\n</li>\n<li>\n<p><strong>常见场景</strong>：</p>\n<ul>\n<li><strong>服务间调用</strong>：后端服务A可以使用自己持有的令牌，换取一个具有适当权限的、用于调用服务B的访问令牌。</li>\n<li><strong>权限降级</strong>：一个高权限的应用在需要调用一个低信任度的服务时，可以换一个权限受限的令牌，以提升安全性。</li>\n<li><strong>外部身份提供商集成</strong>：将外部IDP（如Google、Facebook）签发的令牌交换为内部系统的令牌，从而实现跨域身份联合。</li>\n<li><strong>用户模拟</strong>：在严格管控下，服务可以换取一个代表特定用户身份的令牌（即模拟用户）。</li>\n</ul>\n</li>\n<li>\n<p><strong>实施要点</strong>：令牌交换功能通常默认不开启，需要在服务器端（如Red Hat Single Sign-On）为客户端显式配置精细的权限策略。</p>\n</li>\n</ul>\n<h3 id=\"️-jwt持有者授权-urnietfparamsoauthgrant-typejwt-bearer\">⚙️ JWT持有者授权 (<code>urn:ietf:params:oauth:grant-type:jwt-bearer</code>)</h3>\n<p>这种授权类型允许客户端直接使用一个预先签名的JWT（JSON Web Token）作为断言（assertion）来获取访问令牌。</p>\n<ul>\n<li>\n<p><strong>基本流程</strong>：客户端向授权服务器的令牌端点发起POST请求，在请求体中，<code>grant_type</code> 参数设置为 <code>urn:ietf:params:oauth:grant-type:jwt-bearer</code>，并同时提供用作断言的 <code>assertion</code> 参数（即JWT本身）。授权服务器会验证该JWT的签名、有效期、颁发者等信息，验证通过后即颁发所请求的访问令牌。</p>\n</li>\n<li>\n<p><strong>典型应用场景</strong>：</p>\n<ul>\n<li><strong>服务账户认证</strong>：在机器对机器（M2M）的通信中，一个服务可以使用事先配置好的JWT（通常基于私钥签名）来获取访问令牌，无需用户交互。这在CI/CD流水线或后台服务中非常常见。</li>\n<li><strong>微服务架构</strong>：在微服务网络中，一个服务在收到访问令牌后，可以利用此流程向认证服务器换取一个范围（scope）更窄、专用于访问另一个特定微服务的令牌。</li>\n</ul>\n</li>\n</ul>\n<p>下面的表格清晰地对比了这三种授权类型的关键差异。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">设备代码授权 (<code>device_code</code>)</th>\n<th style=\"text-align: left;\">令牌交换授权 (<code>token-exchange</code>)</th>\n<th style=\"text-align: left;\">JWT持有者授权 (<code>jwt-bearer</code>)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>主要目的</strong></td>\n<td style=\"text-align: left;\">方便输入受限设备上的用户授权</td>\n<td style=\"text-align: left;\">实现令牌之间的安全转换和身份委托</td>\n<td style=\"text-align: left;\">客户端使用已有的JWT直接获取访问令牌</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>令牌流</strong></td>\n<td style=\"text-align: left;\">轮询机制</td>\n<td style=\"text-align: left;\">直接交换</td>\n<td style=\"text-align: left;\">断言式请求</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>典型应用</strong></td>\n<td style=\"text-align: left;\">智能电视、IoT设备、CLI工具</td>\n<td style=\"text-align: left;\">服务间调用、权限降级、身份联合</td>\n<td style=\"text-align: left;\">机器对机器通信、服务账户、微服务</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"处理流程\">处理流程</h3>\n<div class=\"mermaid\">sequenceDiagram\n    participant Client\n    participant WSO2APIM (Authorization Server)\n    participant Keycloak (External IdP)\n\n    Note over Client, Keycloak: 准备阶段\n    Client -&gt;&gt; Keycloak: 1. 通过Keycloak认证获取JWT\n    Keycloak --&gt;&gt; Client: 返回JWT（断言）\n\n    Note over Client, WSO2APIM: JWT Bearer Grant 流程\n    Client -&gt;&gt; WSO2APIM: 2. 令牌请求 (grant_type=jwt-bearer, assertion=JWT)\n    WSO2APIM -&gt;&gt; WSO2APIM: 3. 验证JWT签名、有效期、颁发者\n    WSO2APIM -&gt;&gt; WSO2APIM: 4. 提取身份/声明（如sub, aud）\n    WSO2APIM -&gt;&gt; WSO2APIM: 5. 根据JWT中的信息创建会话并颁发自身的访问令牌\n    WSO2APIM --&gt;&gt; Client: 6. 返回WSO2 APIM的访问令牌\n</div><h3 id=\"-总结与安全考量\">💎 总结与安全考量</h3>\n<p>选择哪种授权类型完全取决于你的具体应用场景。设备代码授权优化了受限设备的用户体验，令牌交换授权为复杂的服务间信任链提供了灵活性，而JWT持有者授权则是机器对机器通信的简洁高效方案。</p>\n<p>在实施这些授权流程时，务必关注以下安全最佳实践：</p>\n<ul>\n<li><strong>严格控制权限</strong>：遵循最小权限原则，只为应用授予其必需的最少权限。</li>\n<li><strong>验证与监控</strong>：服务器端必须严格验证所有令牌和断言（如JWT的签名和有效期），并建立日志审计和异常行为监控机制。</li>\n<li><strong>保护令牌</strong>：访问令牌和刷新令牌是敏感凭证，在传输和存储过程中必须加以保护。</li>\n</ul>\n<h1 id=\"wso2中的实战\">wso2中的实战</h1>\n<h2 id=\"wso2-sp的配置\">wso2 sp的配置</h2>\n<p>配置认证grant_type类型</p>\n<p><img alt=\"图片\" src=\"https://img2024.cnblogs.com/blog/118538/202601/118538-20260126132653488-1051084105.png\" /></p>\n<h2 id=\"keycloak-idp的配置\">keycloak idp的配置</h2>\n<blockquote>\n<p>keycloak中为客户端开启roles之后，如果有用户有客户端的角色，会在jwt中多出来aud数组字段，也可以为wso2客户端添加自定义的client scope，然后为它添加aud的cliams</p>\n</blockquote>\n<p>IDP名称必须与IDP中token的Issuer相同</p>\n<p><img alt=\"图片\" src=\"https://img2024.cnblogs.com/blog/118538/202601/118538-20260126162025923-968169912.png\" /></p>\n<h2 id=\"测试\">测试</h2>\n<pre><code>curl -X POST 'https://test-apim.xxx.com/oauth2/token' -H 'Content-Type: application/json' -H 'Content-Type: application/json' -u 'wso2-sp-client-id:wso2-sp-client-secret' --basic -d '{\n    \"grant_type\": \"urn:ietf:params:oauth:grant-type:jwt-bearer\",\n    \"assertion\": \"abc.abc.abc\",\n    \"scope\": \"openid apim:subscribe\"\n}'\n</code></pre>\n<p>如果keycloak_token过期，就返回这个400错误</p>\n<pre><code>{\n  \"error_description\": \"JSON Web Token is expired., Expiration Time(ms) : 1769413736000, TimeStamp Skew : 0, Current Time : 1769413748585. JWT Rejected and validation terminated\",\n  \"error\": \"invalid_grant\"\n}\n</code></pre>\n<p>如果成功，会返wso2平台的token</p>\n<pre><code>{\n  \"access_token\": \"8b23bf56-f8d2-33fa-9962-f298a797ce94\",\n  \"refresh_token\": \"aad2555-30b0-3591-8c70-b2cdc042cc41\",\n  \"scope\": \"apim:subscribe openid\",\n  \"id_token\": \"\",\n  \"token_type\": \"Bearer\",\n  \"expires_in\": 3185\n}\n</code></pre>\n<p>用户登录成功后，会初始化用户表，需要注意的是，这种<code>urn:ietf:params:oauth:grant-type:jwt-bearer</code>首次登录添加的用户，它位于<code>wso2am_db.idn_auth_user</code>表，user_name同样是三方社区token中的<code>sub</code>字段；而标准oauth的授权码认证后，除了在<code>wso2am_db.idn_auth_user</code>表初始化外，还在<code>wso2am_share_db.um_user</code>表也会添加一份用户数据。</p>\n\n</div>\n<div id=\"MySignature\">\n    <p></p>\n<div class=\"navgood\">\n<p>作者：仓储大叔，张占岭，<br />\n荣誉：微软MVP<br />QQ：853066980</p>\n\n<p><strong>支付宝扫一扫，为大叔打赏!</strong>\n<br /><img src=\"https://images.cnblogs.com/cnblogs_com/lori/237884/o_IMG_7144.JPG\" /></p>\n</div>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 16:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lori\">张占岭</a>&nbsp;\n阅读(<span id=\"post_view_count\">44</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "langchain 快速入门(五)：Langgraph应用，执行流程由线转图",
      "link": "https://www.cnblogs.com/ClownLMe/p/19533991",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ClownLMe/p/19533991\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 15:58\">\n    <span>langchain 快速入门(五)：Langgraph应用，执行流程由线转图</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"简介\">简介</h1>\n<p><strong>Langgraph</strong>是langchain框架提供的一个组件，langgraph能够解决AI执行流程中迭代、循环或者根据结果返回上一步，与之前讲的chain链相比，能够实现更加复杂的AI执行流。</p>\n<h1 id=\"langgraph\">langgraph</h1>\n<p>从chain转到langgraph从数学的角度上来讲，执行流从线性流程转到了流程图。</p>\n<p>langgraph的组成主要有三部分：<br />\nLanggraph=节点+边+状态<br />\n<strong>节点：</strong> 一个节点就是一个执行单元，相当于一次<strong>函数</strong>的调用。（可以是一次模型的调用，一次搜索，一次加密等等）<br />\n<strong>边：</strong> 边能够<strong>连接</strong>一个个节点，它决定了下一个应该去到哪个节点执行<br />\n<strong>状态：</strong> 实现数据共享，是实现AI<strong>短期记忆</strong>的灵魂</p>\n<blockquote>\n<p>乍一看好像有些云里雾里的，我打个比方：玩家（<strong>状态</strong>），在玩一个大富翁，每个<strong>节点</strong>和<strong>边</strong>组成地图，玩家初始资金（<strong>数据</strong>）有1000块钱，玩家每走一格可能会发生一些事件，比如说后退一步，被小偷偷300块钱，买房子等等，这些事件相当于<strong>节点</strong>，走的方向相当于<strong>边</strong>，最后玩家成功走到了<strong>终点END</strong>，你可以得知玩家（<strong>状态</strong>）最后还有多少钱，有多少资产。</p>\n</blockquote>\n<p>下面用一个示例来演示。</p>\n<h1 id=\"改造rag知识库\">改造RAG知识库</h1>\n<h3 id=\"示例\">示例</h3>\n<p>这个是之前文章中构建知识库的相关代码，本次用langgraph改造流程</p>\n<pre><code class=\"language-python\">import os\nimport operator\nfrom typing import TypedDict, Annotated\nfrom langchain_community.chat_models.tongyi import ChatTongyi\nfrom langchain_community.embeddings import DashScopeEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.messages import ToolMessage\nfrom langchain_core.tools import tool\nfrom langchain_core.messages import HumanMessage, ToolMessage, BaseMessage\nfrom langchain_core.documents import Document\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.prebuilt.tool_node import ToolNode\n\nos.environ[\"DASHSCOPE_API_KEY\"] = \"apikey\"\n\n@tool\ndef calculator(expression: str) -&gt; str:\n    \"\"\"\n    计算数学表达式。需要精确计算时使用。\n    参数:\n        expression: 数学算式，如 \"2 + 2\" 或 \"500 * 0.8\"。\n    返回:\n        str: 计算结果，如 \"4.0\" 或 \"400.0\"。\n    \"\"\"\n    print(f\"[🛠️ 工具调用] 计算器正在计算: {expression}\")\n    try:\n        return str(eval(expression))\n    except Exception as e:\n        return f\"计算错误: {e}\"\n\n@tool\ndef rag_search(query: str) -&gt; str:\n    \"\"\"\n    从数据库中搜索与查询公司内部相关的文档，包括公司计划名，代号，截止日期等详细信息。\n    参数:\n        query (str): 要搜索的查询字符串。\n    返回:\n        str: 与查询相关的文档内容。\n    \"\"\"\n\n    # 从RAG数据库中检索文档\n    raw_text = \"\"\"\n    【公司内部机密：代号“深蓝计划”】\n    1. 项目目标：开发一款能听懂猫语的翻译器。\n    2. 核心技术：基于Transformer的“喵声波”分析算法。\n    3. 团队暗号：如果有人问“今天天气怎么样？”，必须回答“我想吃鱼”。\n    4. 截止日期：2026年12月31日。\n    5. 经费预算：仅剩50元人民币，主要用于购买猫条。\n    \"\"\"\n    RAG_PATH = \"faiss_index\"\n\n    docs = [Document(page_content=raw_text)]\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=25, chunk_overlap=5)\n    split_docs = text_splitter.split_documents(docs)\n\n    embeddings = DashScopeEmbeddings(model=\"text-embedding-v1\")\n\n    if os.path.exists(RAG_PATH):\n        print(\"公司内部数据库已存在\")\n        ragdb = FAISS.load_local(RAG_PATH, embeddings, allow_dangerous_deserialization=True)\n    else:\n        print(\"创建公司内部数据库\")\n        ragdb = FAISS.from_documents(split_docs, embeddings)\n        ragdb.save_local(RAG_PATH)\n    \n    return \"\\n\\n\".join(doc.page_content for doc in ragdb.similarity_search(query, k=2))\n\n#构造agent流程图\n\ndef Init_Agent():\n    #初始化模型\n    tool_maps={\n        \"rag_search\": rag_search,\n        \"calculator\": calculator\n    }\n    llm = ChatTongyi(model_name=\"qwen-plus\")\n    tool_llm = llm.bind_tools(tools=list(tool_maps.values()))\n\n    #创建state\n    class TaskState(TypedDict):\n        messages: Annotated[list[BaseMessage], operator.add]\n    \n    #创建node\n    def agent_node(state: TaskState):\n        \"\"\"\n        节点：思考 (Think)\n        接收当前状态，调用 LLM，返回新消息\n        \"\"\"\n        messages = state[\"messages\"]\n        response = tool_llm.invoke(messages)\n        return {\"messages\": [response]}\n\n    #定义边\n    def condition_tools(state: TaskState):\n        \"\"\"\n        节点：工具 (Tool)\n        接收当前状态，调用工具，返回新消息\n        \"\"\"\n        messages = state[\"messages\"][-1]\n        if messages.tool_calls:\n            return \"tool_node\"\n        else:\n            return END\n    \n    #添加边\n    workflow = StateGraph(TaskState)\n    workflow.add_node(\"agent_node\", agent_node)\n    workflow.add_node(\"tool_node\", ToolNode(tool_maps.values()))\n    workflow.add_conditional_edges(\"agent_node\", condition_tools, {\n        \"tool_node\": \"tool_node\",\n        END: END\n    })\n    workflow.add_edge(\"tool_node\", \"agent_node\")\n    workflow.set_entry_point(\"agent_node\")\n    \n    return workflow.compile()\n\nif __name__ == \"__main__\":\n    app = Init_Agent()\n    input = \"公司的经费预算是多少，如果预算预算提高46%后多少\"\n    for event in app.stream({\"messages\": [HumanMessage(content=input)]}):\n        for key, value in event.items():\n            print(f\"\\n[{key}]\")\n            print(value[\"messages\"][-1].content)\n\n\n</code></pre>\n<h1 id=\"代码解释\">代码解释</h1>\n<p>本次代码中重点讲langgraph的构建，对于其他的细节，请看前面文章。<br />\n代码流程如下：<br />\n<strong>初始化工具集-&gt;定义状态，定义条件边，节点-&gt;构建节点-&gt;连接边-&gt;构建图-&gt;运行图</strong></p>\n<h3 id=\"初始化工具集\">初始化工具集</h3>\n<p>这个前面文章有，就不废话了。</p>\n<h3 id=\"定义状态定义条件边节点\">定义状态，定义条件边，节点</h3>\n<h5 id=\"状态\">状态</h5>\n<pre><code class=\"language-python\">#创建state\n    class TaskState(TypedDict):\n        messages: Annotated[list[BaseMessage], operator.add]\n</code></pre>\n<ul>\n<li>状态是<code>TypedDict</code>的子类（<strong>字典</strong>）。</li>\n<li>上面的<code>BaseMessage</code>是<code>ToolMessage</code>,<code>AIMessage</code>,<code>HumanMessage</code>等的父类，这个<code>list</code>主要用于存放每个节点的历史消息（短期记忆）</li>\n<li><code>Annotated[..., operator.add]</code>表示追加，将节点返回的消息追加到后面，而不是覆盖。<br />\n格式如下（可以创建多个自定义字段）：</li>\n</ul>\n<pre><code class=\"language-python\">class  StateName(TypedDict):\n\tfieldName: fieldType\n</code></pre>\n<h5 id=\"条件边\">条件边</h5>\n<pre><code class=\"language-python\">def condition_tools(state: TaskState):\n        \"\"\"\n        节点：工具 (Tool)\n        接收当前状态，调用工具，返回新消息\n        \"\"\"\n        messages = state[\"messages\"][-1]\n        if messages.tool_calls:\n            return \"tool_node\"\n        else:\n            return END\n</code></pre>\n<ul>\n<li>返回值<code>END</code>和<code>\"tool_node\"</code>表示定义的节点名称，<code>END</code>默认是结束节点<br />\n格式如下：</li>\n</ul>\n<pre><code class=\"language-python\">def EdgeName(state: StateClass)\n\treturn \"NextNode\"\n</code></pre>\n<h5 id=\"节点\">节点</h5>\n<pre><code class=\"language-python\">@tool\ndef calculator(expression: str) -&gt; str:\n    ......\n\n@tool\ndef rag_search(query: str) -&gt; str:\n    ......\n    \ndef agent_node(state: TaskState):\n    ......\n</code></pre>\n<p>节点可以是工具函数，也可以是普通函数（<strong>普通函数需要用state传入</strong>）</p>\n<h3 id=\"构建节点\">构建节点</h3>\n<pre><code class=\"language-python\">workflow = StateGraph(TaskState)\nworkflow.add_node(\"agent_node\", agent_node)\nworkflow.add_node(\"tool_node\", ToolNode(tool_maps.values()))\n</code></pre>\n<ul>\n<li><code>StateGraph(TaskState)</code>初始化图，将刚刚创建的状态传入</li>\n<li><code>add_node</code>方法是创建节点\"tool_node\"节点名称（自定义用于标识节点），<code>agent_node</code>创建的节点函数</li>\n<li><code>ToolNode</code>是langchain提供的创建工具节点的函数，帮我们完成了调用工具集，更新状态的全过程（不用这个需要我们自己手动创建工具循环节点，比较麻烦，参考之前文章）</li>\n</ul>\n<h3 id=\"连接边\">连接边</h3>\n<pre><code class=\"language-python\">workflow.add_conditional_edges(\"agent_node\", condition_tools, {\n        \"tool_node\": \"tool_node\",\n        END: END\n    })\n    workflow.add_edge(\"tool_node\", \"agent_node\")\n</code></pre>\n<ul>\n<li><code>add_conditional_edges</code>创建条件边方法（分支），根据返回内容决定节点走向</li>\n<li><code>add_edge</code>固定走向，如上<code>tool_node-&gt;agent_node</code></li>\n</ul>\n<h3 id=\"构建图\">构建图</h3>\n<pre><code class=\"language-python\">workflow.set_entry_point(\"agent_node\")\nworkflow.compile()\n</code></pre>\n<ul>\n<li><code>set_entry_point</code>确定图的入口</li>\n<li><code>compile</code>构建图</li>\n</ul>\n<h3 id=\"运行图\">运行图</h3>\n<pre><code class=\"language-python\">if __name__ == \"__main__\":\n    app = Init_Agent()\n    input = \"公司的经费预算是多少，如果预算预算提高46%后多少\"\n    for event in app.stream({\"messages\": [HumanMessage(content=input)]}):\n        for key, value in event.items():\n            print(f\"\\n[{key}]\")\n            print(value[\"messages\"][-1].content)\n</code></pre>\n<p>运行跟之前运行普通模型一样</p>\n<ul>\n<li><code>stream</code>方法会返回每个节点中的<strong>状态</strong>（上面定义的类）</li>\n<li><code>invoke</code>方法直接返回最终<strong>状态</strong></li>\n</ul>\n<p><strong>langgraph是实现多Agent协作的核心，下一篇文章会讲如何多agent协作</strong></p>\n<p><strong>如果❤喜欢❤本系列教程，就点个关注吧，后续不定期更新~</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 15:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ClownLMe\">ClownLMe</a>&nbsp;\n阅读(<span id=\"post_view_count\">93</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第二周：词嵌入（六）情绪分类和词嵌入除偏",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19533686",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19533686\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 15:36\">\n    <span>吴恩达深度学习课程五：自然语言处理  第二周：词嵌入（六）情绪分类和词嵌入除偏</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课的第二周内容，<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=164\" rel=\"noopener nofollow\" target=\"_blank\">2.2</a>、<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=171\" rel=\"noopener nofollow\" target=\"_blank\">2.9</a>和<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=172\" rel=\"noopener nofollow\" target=\"_blank\">2.10</a>内容，同时也是本周理论部分的最后一篇。</p>\n<hr />\n<p>本周为第五课的第二周内容，与 CV 相对应的，这一课所有内容的中心只有一个：<strong>自然语言处理（Natural Language Processing，NLP）</strong>。<br />\n应用在深度学习里，它是专门用来进行<strong>文本与序列信息建模</strong>的模型和技术，本质上是在全连接网络与统计语言模型基础上的一次“结构化特化”，也是人工智能中<strong>最贴近人类思维表达方式</strong>的重要研究方向之一。<br />\n<strong>这一整节课同样涉及大量需要反复消化的内容，横跨机器学习、概率统计、线性代数以及语言学直觉。</strong><br />\n语言不像图像那样“直观可见”，更多是抽象符号与上下文关系的组合，因此<strong>理解门槛反而更高</strong>。<br />\n因此，我同样会尽量补足必要的背景知识，尽可能用比喻和实例降低理解难度。<br />\n本周的内容关于词嵌入，是一种<strong>相对于独热编码，更能保留语义信息的文本编码方式</strong>。通过词嵌入，模型不再只是“记住”词本身，而是能够<strong>基于语义关系进行泛化</strong>，在一定程度上实现类似“<strong>举一反三</strong>”的效果。词嵌入是 NLP 领域中最重要的基础技术之一。</p>\n<p>本篇的内容关于<strong>情绪分类和词嵌入除偏</strong>，是对本周内容的最后补充。</p>\n<h2 id=\"1-词向量的使用\">1. 词向量的使用</h2>\n<p>在介绍完前面的内容后，你会发现，我们使用各种模型和技术，最终的目的都是为了得到可以合理刻画文本信息间语义关系的<strong>词向量</strong>。<br />\n而一旦这些词向量被训练出来，它们的价值并不会随着训练任务的结束而消失，反而<strong>真正的用武之地才刚刚开始</strong>。</p>\n<p>实际上，在词向量的使用中，<strong>最常见、也是最直接的方式，就是将训练好的词向量作为下游任务的输入表示。</strong><br />\n在文本分类、情绪分析、问答系统等任务中，我们不再使用独热编码这种“只区分身份、不包含语义”的表示方式，而是通过查表的方式，将每个词映射为一个稠密的词向量，再送入分类器或序列模型中进行处理。<br />\n也正是这种连续、可度量的语义空间，使得<strong>模型在还没有接触具体任务之前，就已经拥有了一定程度的语言理解能力。</strong><br />\n而且，你会发现这其实是一种非常典型的<strong>迁移学习</strong>思想：<br />\n词向量模型在大规模语料上学习到的是一种<strong>通用的语言结构与语义分布</strong>，而下游任务只需要在此基础上进行少量参数调整，就可以完成更具体的目标。</p>\n<p>更重要的是， NLP 中对词向量的迁移学习和我们之前介绍的 CV 内容有所不同，在 CV 任务中，迁移效果往往高度依赖于任务之间的相似性，例如用自然图片上训练得到的模型参数去处理医学影像，效果未必理想。<br />\n而在 NLP 领域中，由于语言本身具有极强的通用性，只要任务使用的是同一语言，<strong>将预训练词向量作为嵌入层矩阵的初始化方式，往往是一种“用了就不亏”的选择</strong>。<br />\n最终，从模型结构上看，这相当于模型的第一层不再从完全随机的参数开始学习，而是直接站在了一个已经组织好语义结构的空间中，再去完成具体任务。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152709307-555486151.png\" /></p>\n<p>也正是在这样的背景下，NLP 的各种应用百花齐放，其中最经典的应用之一，就是下面要介绍的情绪分类。</p>\n<h1 id=\"2-情绪分类sentiment-classification\">2. 情绪分类（Sentiment Classification）</h1>\n<h2 id=\"21-情绪分类原理\">2.1 情绪分类原理</h2>\n<p>情绪分类是自然语言处理领域中最早被系统研究、同时也最具代表性的任务之一。<br />\n其基本形式并不复杂：<strong>给定一段文本，判断其情绪倾向，例如正面、负面，或更细粒度的多类别情绪。</strong><br />\n简单举个例子：<br />\n对于两条酒店评论 <strong>“拉完了”</strong> 和 <strong>“夯爆了”</strong>，我们可以在不同的情绪粒度下，对它们给出不同形式的分类结果。</p>\n<ol>\n<li><strong>正负二分类</strong>：在最粗粒度的情绪分类任务中，我们只关心文本所表达的整体态度是正面还是负面。\n<ul>\n<li>“拉完了” → <strong>负面情绪</strong></li>\n<li>“夯爆了” → <strong>正面情绪</strong></li>\n</ul>\n</li>\n</ol>\n<p>在这一设定下，模型的目标非常明确：只需判断“喜欢”还是“不喜欢”，而<strong>不关心情绪强度或细节差异。</strong><br />\n2. <strong>星级五分类</strong>：如果进一步提高情绪刻画的精细程度，就可以将任务扩展为多类别分类，例如常见的 <strong>1～5 星评分预测</strong>。<br />\n- “拉完了” → ★☆☆☆☆<br />\n- “夯爆了” → ★★★★★</p>\n<p>在这一情况下，模型不仅需要识别情绪的正负，还需要理解<strong>情绪的强烈程度</strong>，相比二分类任务，五分类对语义表示的要求明显更高。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152958597-1831761240.png\" /><br />\n可以看出，<strong>情绪分类任务的核心难点并不在于模型结构本身，而在于如何让模型“理解”文本所蕴含的情绪语义</strong>。</p>\n<p>而这恰恰正是词向量发挥作用的地方：<strong>只有当“拉完了”“夯爆了”这样的词语在向量空间中被映射到合理的位置，后续的分类模型才有可能做出稳定、可靠的判断。</strong><br />\n而在句子中，情绪本身并不是由单个词独立决定的，而是由<strong>多个词在语义空间中的组合关系</strong>共同构成。<br />\n同样举例来说明，比如：</p>\n<ul>\n<li>“好” 和 “棒” 在语义空间中彼此接近。</li>\n<li>“糟糕” 和 “失望” 会聚集在另一片区域。</li>\n</ul>\n<p>因此，当文本被表示为一组词向量后，模型实际上是在判断：<strong>这些向量整体更靠近“正面情绪区域”，还是“负面情绪区域”。</strong><br />\n这也是为什么，在情绪分类任务中，<strong>词向量的质量往往直接决定了模型的上限</strong>。</p>\n<p>了解了基本原理后，我们来看看如何实现情绪分类。</p>\n<h2 id=\"22-情绪分类-10-平均词向量输入分类器\">2.2 情绪分类 1.0 ：平均词向量输入分类器</h2>\n<p>在最早期、也是最朴素的情绪分类实现中，我们并不会引入复杂的序列模型，而是采用一种<strong>几乎不关心词序</strong>的做法：<strong>将一句话中所有词的词向量取平均，作为整句文本的表示。</strong></p>\n<p>具体来说，假设一句话由 <span class=\"math inline\">\\(n\\)</span> 个词组成，其对应的词向量分别为 ：<span class=\"math inline\">\\(\\mathbf{w}_1, \\mathbf{w}_2, \\dots, \\mathbf{w}_n\\)</span>，那么句向量可以直接定义为：</p>\n<p></p><div class=\"math display\">\\[\\mathbf{s} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{w}_i  \n\\]</div><p></p><p>这个 <span class=\"math inline\">\\(\\mathbf{s}\\)</span> 就被视为整段文本在语义空间中的“位置”，随后只需要将它送入一个<strong>简单的分类器</strong>（如全连接层 + softmax），即可完成情绪预测。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152137630-1144988396.png\" /><br />\n这种方法理解起来很直观：<strong>这句话里，所有词语的“情绪方向”加起来，更偏向哪一边？</strong><br />\n如果一句话中大多数词的向量都靠近“正面情绪区域”，那么平均后的结果自然也会偏向正面；反之亦然。</p>\n<p>它的优点是实现简单，计算开销极低；不依赖复杂模型，对小数据集也较为友好，而且通过这种简单的方式也可以直观体现词向量质量对下游任务的影响。</p>\n<p>但它的缺点非常突出，我们常说：<strong>语言是有顺序的</strong>，这种方法<strong>完全忽略了词序信息，只看孤立的语义方向的堆叠，便极有可能产生相应的误解</strong>。<br />\n例如：“缺少好的服务，好的环境和好的餐食。”<br />\n这句话很明显是负面评价，分类器却可能因为出现了很多“好”而将其判断为正面评价。</p>\n<p>因此，<strong>平均词向量 + 分类器</strong> 只是情绪分类任务的入门解法，我们知道有这种方式即可。</p>\n<h2 id=\"23-情绪分类-20-使用循环神经网络\">2.3 情绪分类 2.0 ：使用循环神经网络</h2>\n<p>与直接取平均不同，<a href=\"https://www.cnblogs.com/Goblinscholar/p/19449622\" target=\"_blank\">RNN</a> 会<strong>按顺序逐词读取文本</strong>，并在每一步将当前词的信息与历史上下文进行融合。<br />\n而回顾之前介绍的<a href=\"https://www.cnblogs.com/Goblinscholar/p/19454021\" target=\"_blank\">语言模型</a>内容就会发现，不同于我们之前演示使用的命名实体识别，情绪分类是在读取完整句信息后输出一个分类结果，它是一个<strong>多对一模型</strong>，这类模型反而更符合我们的直觉，来看它的传播过程：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152136651-365514513.png\" /><br />\n对于一个词序列 <span class=\"math inline\">\\(w_1, w_2, \\dots, w_n\\)</span>，RNN 的核心计算可以抽象为：</p>\n<p></p><div class=\"math display\">\\[\\mathbf{a}_t = f(\\mathbf{w}_t, \\mathbf{a}_{t-1})  \n\\]</div><p></p><p>其中，<span class=\"math inline\">\\(\\mathbf{a}_t\\)</span> 表示模型在读到第 <span class=\"math inline\">\\(t\\)</span> 个词时，对“当前语义状态”的综合理解。<br />\n我们使用最后一个隐藏状态 <span class=\"math inline\">\\(\\mathbf{a}_n\\)</span> 作为整句文本的表示,再将得到的句向量输入分类器进行预测,得到最终的分类结果。</p>\n<p>这种方式带来的最大改变在于：<strong>情绪不再是词向量的简单叠加，而是一个随阅读过程逐步演化的结果。</strong></p>\n<p>举例来说：</p>\n<ul>\n<li>在读到“好”的时候，模型的情绪倾向可能偏正。</li>\n<li>但当随后读到“不”时，隐藏状态会被重新调整。</li>\n<li>最终输出的表示能够体现“否定”对整体情绪的修正。</li>\n</ul>\n<p>因此，RNN 在对语义的理解能力上明显优于简单的平均向量方法。当然，这也带来了梯度问题和训练成本的提升。</p>\n<p>情绪分类的相关技术同样在不断进步，如今，以 <strong>BERT</strong> 为代表的双向 Transformer 通过大规模语料预训练，能够捕获更精细的上下文语义关系，在情绪分类等判别任务上显著超越传统模型，而更前沿的做法是直接利用<strong>指令微调的大语言模型</strong>，通过 prompt 或少量样本即可完成情绪判断。<br />\n情绪分类正逐步从“专用模型任务”内化为“通用语言理解能力”的自然体现。</p>\n<p>下面，我们补充最后一部分内容：</p>\n<h1 id=\"3-词嵌入除偏word-embedding-debiasing\">3. 词嵌入除偏（Word Embedding Debiasing）</h1>\n<p>我们知道，词向量并不是从真空中学到的，它们来源于真实语料。而真实语料，本身就不可避免地携带着各种<strong>社会偏见和统计偏向</strong>。<br />\n由于词向量的训练目标是捕捉词与词的共现关系，如果某些刻板印象在语料中频繁出现，那么它们就会被“如实地”编码进向量空间中。<br />\n例如，在大量文本中，如果：</p>\n<ul>\n<li>“医生” 、“工程师”更频繁地与男性词汇共现。</li>\n<li>“护士” 、“保姆”更频繁地与女性词汇共现。</li>\n</ul>\n<p>那么训练出来的词向量空间中，就可能形成一条明显的“性别方向”，并在无意中强化这些关联。</p>\n<p>从模型角度看，这种行为是<strong>完全合理的统计学习结果</strong>，但从应用角度看，这种偏见在情绪分析、招聘筛选、推荐系统等场景中，可能带来严重问题。</p>\n<p><strong>这便是词嵌入除偏的目标：在尽量保留语义信息的前提下，削弱或移除特定维度上的偏见成分</strong>。</p>\n<p>2016 年, 论文 <a href=\"https://arxiv.org/pdf/1607.06520\" rel=\"noopener nofollow\" target=\"_blank\">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings </a>中，首次对<strong>词嵌入中的社会偏见</strong>进行了清晰的建模，并提出了一套可操作的除偏方法。它的主要观点是：<strong>偏见并不是“到处都是”的，而是主要集中在某些可解释的方向上。</strong></p>\n<p>我们分点来看看这一方法的实现逻辑：</p>\n<h2 id=\"31-定义偏见方向bias-direction\">3.1 定义偏见方向（Bias Direction）</h2>\n<p>论文的第一步，是显式地定义什么是“偏见方向”。<br />\n以性别偏见为例，我们并不凭主观判断去找偏见，而是构造一组<strong>成对的性别词</strong>，例如：</p>\n<ul>\n<li>(he, she)</li>\n<li>(man, woman)</li>\n<li>(king, queen)</li>\n</ul>\n<p><strong>对于每一组词对，都可以在词向量空间中计算其差向量。将这些差向量进行平均，便可得到一个代表“性别差异”的方向向量</strong>，就像这样：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126153405646-1690433377.png\" /><br />\n假定词向量拟合度较高，那么对于这个方向就可以理解为：<strong>沿着这条方向移动，语义主要在“男性 ↔ 女性”之间变化，而与其他语义因素关系不大。</strong></p>\n<p>这一步的意义在于将原本模糊、抽象的“偏见”问题，<strong>转化为向量空间中一个可操作的几何方向</strong>。，就像射击前需要先确定靶心一样，只有明确了偏见方向，后续才能有针对性地削弱或移除某些词在该方向上所携带的偏见成分。</p>\n<h2 id=\"32-区分中性词与性别词\">3.2 区分中性词与性别词</h2>\n<p>同样以性别偏见为例：接下来，我们将词汇分为两类：</p>\n<ol>\n<li><strong>性别中性词</strong>：如 <em>doctor, nurse, homeworker</em>，它们不应天然带有性别信息。</li>\n<li><strong>性别特定词</strong>：如 <em>man, woman, she, he</em>，要保留合理的性别信息。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152958836-1340196476.png\" /></li>\n</ol>\n<p>注意，这样区分并不代表我们不对特定词进行处理，而是<strong>对不同类型的词采取不同策略</strong>：</p>\n<ol>\n<li>对语义上应当与性别无关的中性词，应<strong>移除</strong>其性别方向上偏见。</li>\n<li>对本身就包含性别差异的词对，则在保留性别信息的前提下，强制其在性别维度上<strong>对称</strong>、在其他语义维度上对齐，从而避免偏见被不合理地放大。</li>\n</ol>\n<p>下面就来看看如何实现这些策略：</p>\n<h2 id=\"33-硬除偏hard-debias\">3.3 硬除偏（Hard Debias）</h2>\n<p>其实并不难理解，首先，我们处理中心词，这一步我们称之为<strong>去投影（Neutralize）：将中性词向量在性别方向上的分量直接移除，使其在该方向上的投影为 0。</strong><br />\n就像这样：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152629903-530152228.png\" /><br />\n通过这样调整词向量，让中性词在性别方向上的分量消失，自然就不会因为这个方向上的语义差异而产生偏见。</p>\n<p>继续，我们处理特定词，而这部分我们称为<strong>等距化（Equalize）：对于这类本应只在性别上不同的词对，强制它们在性别方向上的距离对称，而在其他语义维度上保持一致。</strong><br />\n就像这样：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260126152647475-1295451046.png\" /><br />\n这样做的道理很直观：对于“男”和“女”，在语义空间里，我们不希望出现“男只有一点点男性特征，而女则非常女性化”的不对称情况。<br />\n<strong>如果特定词在性别方向上不对称，不仅会模糊性别边界，还可能降低词向量的整体质量。</strong><br />\n通过等距化，特定词对在“性别以外”的语义上保持等价，但在性别方向上依然可以清晰区分，从而既消除偏见，又保留必要的性别信息。</p>\n<p>此外，既然有硬除偏，自然也有<strong>软除偏</strong>，在明白了硬除偏后，软除偏便不难理解：<br />\n简单来讲，<strong>软除偏只针对中性词</strong>，其处理逻辑和硬除偏也大体相同，不同的是<strong>软除偏将每类偏见中“让中性词在偏见方向上的分量最小化”的逻辑加入神经网络损失函数中作为一项进行迭代优化。</strong><br />\n这种方法更符合我们在深度学习领域的直觉，实际上在现代技术中也有继承软除偏思想、更先进的词嵌入除偏方法，这里就不再专门展开了。</p>\n<h1 id=\"4-总结\">4. 总结</h1>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>原理</th>\n<th>理解</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>词向量使用</strong></td>\n<td>将训练好的词向量作为下游任务输入，捕捉语义关系，支持迁移学习。</td>\n<td>模型第一层不再从零开始，而是“站在已整理好的语义空间上”。</td>\n</tr>\n<tr>\n<td><strong>情绪分类（Sentiment Classification）</strong></td>\n<td>给定文本判断情绪倾向，可二分类（正/负）或多分类（如 1~5 星）。</td>\n<td>文本中的词语向量整体靠近“正面区域”还是“负面区域”。</td>\n</tr>\n<tr>\n<td><strong>平均词向量 + 分类器</strong></td>\n<td>将句子中所有词向量取平均作为整句表示，再送入分类器。</td>\n<td>词语的“情绪方向”堆叠，哪边多就偏向哪边。</td>\n</tr>\n<tr>\n<td><strong>RNN 情绪分类</strong></td>\n<td>按顺序逐词读取文本，将当前词与历史上下文融合，输出最后隐藏状态作为句向量。</td>\n<td>情绪随着阅读过程逐步演化，如“好” → 正面，但遇到“不”被修正。</td>\n</tr>\n<tr>\n<td><strong>词嵌入偏见问题</strong></td>\n<td>词向量从真实语料中学习共现关系，容易捕捉社会偏见（如性别刻板印象）。</td>\n<td>统计规律“如实反映”，但可能强化偏见。</td>\n</tr>\n<tr>\n<td><strong>偏见方向（Bias Direction）</strong></td>\n<td>构造成对词（he/she, man/woman），计算差向量并平均得到偏见方向。</td>\n<td>在向量空间中，沿此方向语义主要在“男性 ↔ 女性”之间变化。</td>\n</tr>\n<tr>\n<td><strong>区分中性词与特定词</strong></td>\n<td>中性词移除偏见方向成分；特定词保持性别信息并等距化。</td>\n<td>中性词去除偏见就像去掉不必要的色彩，特定词对保持对称，就像男女形象保持平衡。</td>\n</tr>\n<tr>\n<td><strong>硬除偏（Hard Debias）</strong></td>\n<td>对中性词去投影使性别方向为 0，对特定词做等距化保持对称。</td>\n<td>用“刀子”切掉中性词性别成分，同时调整特定词对保持对称。</td>\n</tr>\n<tr>\n<td><strong>软除偏（Soft Debias）</strong></td>\n<td>只针对中性词，将“最小化偏见方向分量”的目标加入损失函数，通过迭代优化实现减弱偏见。</td>\n<td>温和压低偏见方向，而不是完全切掉，保留语义空间结构。</td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 15:36</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">71</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "如何用 Python 将 Markdown 转换为 Word 文档",
      "link": "https://www.cnblogs.com/jazz-z/p/19532573",
      "published": "",
      "description": "<div class=\"postcontent\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"p\">在当今的技术文档工作流中，Markdown 因其简洁的语法和版本控制友好的特性，已成为开发者和技术写作者的首选格式。然而，在企业环境中，Word 文档仍然是正式报告、客户交付物和标准化文档的主流格式。</p>\n<p class=\"p\">本文将分享如何使用 Free Spire.Doc for Python—一款免费的 Python 文档处理库，快速实现 Markdown 到 Word 的转换，涵盖基础转换、批量处理等实用场景，新手也能轻松上手。</p>\n<hr />\n<p class=\"p\">&nbsp;</p>\n<h2 class=\"h4\">一、环境准备</h2>\n<p class=\"p\">Free Spire.Doc for Python 是免费 Python 文档处理库，无需依赖 Microsoft Word，支持 Word 文档的创建、编辑、转换等操作，其中内置的 Markdown 解析能力，能高效实现 Markdown 到 Doc/Docx 格式的转换，且兼容常见的 Markdown 语法（标题、列表、图片、链接等）。</p>\n<p class=\"listitem\"><strong class=\"strong\">安装</strong>：<br />打开终端/命令提示符，执行以下pip安装命令：</p>\n<div class=\"cnblogs_code\">\n<pre>pip <span style=\"color: rgba(0, 0, 255, 1);\">install</span> Spire.Doc.Free</pre>\n</div>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<h2 class=\"h4\" id=\"3\">二、基础实现：单篇 Markdown 转 Word</h2>\n<h3 class=\"h5\" id=\"4\">场景1：将 Markdown 文本直接转换为 Word</h3>\n<p class=\"p\">适用于 Markdown 内容较短、无需读取文件的场景，核心代码如下：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">from</span> spire.doc <span style=\"color: rgba(0, 0, 255, 1);\">import</span> *\n<span style=\"color: rgba(0, 0, 255, 1);\">from</span> spire.doc.common <span style=\"color: rgba(0, 0, 255, 1);\">import</span> *\n\n<span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 1. 定义要转换的Markdown文本（涵盖常见语法）</span>\nmarkdown_text = <span style=\"color: rgba(128, 0, 0, 1);\">\"\"\"</span><span style=\"color: rgba(128, 0, 0, 1);\">\n# 一级标题：Markdown转Word测试\n## 二级标题：功能演示\n### 三级标题：基础语法支持\n\n#### 1. 段落与强调\n这是一段普通段落，支持**粗体**、*斜体*、`行内代码`，以及[超链接](https://www.google.com/)。\n\n#### 2. 列表\n- 无序列表项1\n- 无序列表项2\n  - 子列表项\n\n1. 有序列表项1\n2. 有序列表项2\n\n#### 3. 代码块\n```python\nprint(\"Hello, Markdown to Word!\")\na = 1 + 2\n```\n</span><span style=\"color: rgba(128, 0, 0, 1);\">\"\"\"</span>\n\n<span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 1. 将markdown文本写入md文档</span>\nmarkdown_path = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">input.md</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">\nwith open(markdown_path, </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">w</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>, encoding=<span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">utf-8</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">) as f:\n    f.write(markdown_text)\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 2. 创建Document对象</span>\ndoc =<span style=\"color: rgba(0, 0, 0, 1);\"> Document()\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 3. 加载md文档</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">doc.LoadFromFile(markdown_path, FileFormat.Markdown)\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 4. 保存为Word文档（支持.doc和.docx格式）</span>\noutput_path = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Markdown转Word.docx</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">\ndoc.SaveToFile(output_path, FileFormat.Docx)\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 5. 释放资源</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">doc.Close()\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">print</span>(f<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">转换完成！Word文档已保存至：{output_path}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>)</pre>\n</div>\n<p>&nbsp;</p>\n<h3 class=\"h5\" id=\"5\">场景2：读取 Markdown 文件转换为 Word</h3>\n<p class=\"p\">适用于已有.md文件的场景（如<code class=\"codespan\">test.md</code>），代码更简洁：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">from</span> spire.doc <span style=\"color: rgba(0, 0, 255, 1);\">import</span><span style=\"color: rgba(0, 0, 0, 1);\"> Document\n</span><span style=\"color: rgba(0, 0, 255, 1);\">from</span> spire.doc <span style=\"color: rgba(0, 0, 255, 1);\">import</span><span style=\"color: rgba(0, 0, 0, 1);\"> FileFormat\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 1. 创建Document对象</span>\ndoc =<span style=\"color: rgba(0, 0, 0, 1);\"> Document()\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 2. 直接加载Markdown文件（指定文件路径）</span>\nmarkdown_file_path = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">test.md</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">\ndoc.LoadFromFile(markdown_file_path, FileFormat.Markdown)\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 3. 保存为Word文档</span>\noutput_path = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Markdown转Word.docx</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">\ndoc.SaveToFile(output_path, FileFormat.Docx)\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 4. 释放资源</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">doc.Close()\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">print</span>(f<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">文件转换完成！路径：{output_path}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>)</pre>\n</div>\n<p>&nbsp;</p>\n<h5 class=\"h5\" id=\"6\">代码关键说明：</h5>\n<ul class=\"ul\">\n<li class=\"listitem\"><code class=\"codespan\">Document()</code>：创建一个空的 Word 文档对象，是所有操作的核心载体；</li>\n<li class=\"listitem\"><code class=\"codespan\">LoadFromFile()</code>：加载 Markdown 文件，第二个参数&nbsp;<code class=\"codespan\">FileFormat.Markdown</code>&nbsp;指定解析格式；</li>\n<li class=\"listitem\"><code class=\"codespan\">SaveToFile()</code>：接收输出路径和文件格式（<code class=\"codespan\">FileFormat.Docx</code>/<code class=\"codespan\">FileFormat.Doc</code>），完成保存；</li>\n<li class=\"listitem\"><code class=\"codespan\">Close()</code>：释放文档资源，避免内存占用。</li>\n</ul>\n<hr />\n<p>&nbsp;</p>\n<h2 class=\"h4\" id=\"7\">三、批量转换多个 Markdown 文件</h2>\n<p class=\"p\">Free Spire.Doc for Python 支持批量转换一个文件夹中的多个 Markdown 文档。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">import</span><span style=\"color: rgba(0, 0, 0, 1);\"> os\n</span><span style=\"color: rgba(0, 0, 255, 1);\">from</span> spire.doc <span style=\"color: rgba(0, 0, 255, 1);\">import</span><span style=\"color: rgba(0, 0, 0, 1);\"> Document\n</span><span style=\"color: rgba(0, 0, 255, 1);\">from</span> spire.doc <span style=\"color: rgba(0, 0, 255, 1);\">import</span><span style=\"color: rgba(0, 0, 0, 1);\"> FileFormat\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 1. 定义Markdown文件所在文件夹和输出文件夹</span>\nmd_folder = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">./markdown_files</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">\noutput_folder </span>= <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">./word_files</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>\n\n<span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 2. 创建输出文件夹（若不存在）</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">if</span> <span style=\"color: rgba(0, 0, 255, 1);\">not</span><span style=\"color: rgba(0, 0, 0, 1);\"> os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 3. 遍历文件夹中的所有.md文件</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">for</span> filename <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> os.listdir(md_folder):\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">if</span> filename.endswith(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">.md</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 拼接文件路径</span>\n        md_path =<span style=\"color: rgba(0, 0, 0, 1);\"> os.path.join(md_folder, filename)\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 生成输出Word文件名（替换后缀为.docx）</span>\n        output_filename = os.path.splitext(filename)[0] + <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">.docx</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">\n        output_path </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> os.path.join(output_folder, output_filename)\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 4. 转换逻辑</span>\n        doc =<span style=\"color: rgba(0, 0, 0, 1);\"> Document()\n        doc.LoadFromFile(md_path, FileFormat.Markdown)\n        doc.SaveToFile(output_path, FileFormat.Docx)\n        doc.Close()\n\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">print</span>(f<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">已转换：{filename} -&gt; {output_filename}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">print</span>(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">所有Markdown文件批量转换完成！</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>)</pre>\n</div>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<h2 class=\"h4\" id=\"8\">常见问题与注意事项</h2>\n<ol class=\"ol\">\n<li class=\"listitem\"><strong class=\"strong\">格式兼容问题</strong>：部分小众 Markdown 语法（如 Mermaid 流程图、LaTeX 公式）暂不支持，转换后可能显示异常，建议提前简化这类内容；</li>\n<li class=\"listitem\"><strong class=\"strong\">编码问题</strong>：若 Markdown 文件含中文，建议保存为 UTF-8 编码，避免转换后出现乱码；</li>\n<li class=\"listitem\"><strong class=\"strong\">免费版限制</strong>：Free Spire.Doc for Python 免费版对文档页数有限制，满足日常轻量使用。</li>\n</ol><hr />\n<h4 class=\"h4\" id=\"9\">&nbsp;</h4>\n<p class=\"p\">通过本文介绍的方法，我们可以通过几行 Python 代码实现 Markdown 转 Word 文档，同时支持批量处理等扩展功能，完美适配日常办公、文档交付等场景。相比其他转换工具，Free Spire.Doc 无需依赖第三方服务，本地运行更安全，且 Python 接口友好，新手易上手。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"itemdesc\">\n                发表于 \n<span id=\"post-date\">2026-01-26 12:00</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jazz-z\">LAYONTHEGROUND</a>&nbsp;\n阅读(<span id=\"post_view_count\">185</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n            </div>"
    },
    {
      "title": "如何正确的 DDD",
      "link": "https://www.cnblogs.com/xiaozhuang/p/19532510",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaozhuang/p/19532510\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 11:51\">\n    <span>如何正确的 DDD</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>在架构设计领域，DDD（领域驱动设计）被讨论得最多，也被误解得最深。很多公司所谓的“官方指导文件”其实是在南辕北辙。如果不纠正这些根源上的错误，所谓的架构优化只能是空中楼阁。</p>\n<p>以下是对当前行业内、甚至是某些大厂指导文件中典型错误做法的深度批判。</p>\n<hr />\n<h2>一、 批判：指导文件建议“不使用领域服务”</h2>\n<p><strong>【现状批判】</strong>：很多公司迷信“绝对充血模型”，要求逻辑必须全写在领域实体中。然而，现实中大量业务涉及<strong>同领域内多个实体的对比与关联校验</strong>（并非跨领域协作）。因为逻辑在单个实体里塞不进去，而指导文件又禁用了领域服务，程序员被迫将核心业务规则“偷渡”到<strong>应用层</strong>。</p>\n<p><strong>【正确方式】</strong>：<strong>领域服务是逻辑的指挥官。</strong> 凡是涉及本领域内多实体协作、业务主键查重、规则验证，必须由领域服务承载。它是领域层对外的唯一逻辑入口，守住领域核心逻辑。</p>\n<hr />\n<h2>二、 批判：在应用层加入“公共方法目录”</h2>\n<p><strong>【现状批判】</strong>：由于领域逻辑被驱逐到了应用层，为了复用，开发者只能在应用层搞一个 <code>Common</code> 或 <code>Util</code>。这本质上是由于领域逻辑无法归位而导致的“架构流产”。</p>\n<p><strong>【正确方式】</strong>：<strong>业务逻辑必须回归领域。</strong> 任何涉及规则的复用，必须沉淀在各自的领域服务中。应用层只负责调度流程，绝不负责存储业务规则。</p>\n<hr />\n<h2>三、 批判：指导文件明确“不使用聚合”</h2>\n<p><strong>【现状批判】</strong>：有些指导文档主张平铺实体。没有聚合，实体就像散沙，应用层可以随意绕过业务规则修改实体状态，导致一致性防线全面崩溃。</p>\n<p><strong>【正确方式】</strong>：<strong>每一个领域必须是一个聚合。</strong> 聚合根是唯一的入口。只有通过聚合根，才能保证业务规则（不变量）在任何时候都是有效的。聚合不是负担，而是保护业务逻辑的盔甲。</p>\n<hr />\n<h2>四、 批判：在应用层定义外部调用防腐接口</h2>\n<p><strong>【现状批判】</strong>：文档建议在应用层定义防腐接口，这会导致<strong>基础服务反向依赖应用层</strong>，造成严重的依赖环和逻辑污染。</p>\n<p><strong>【正确方式】</strong>：<strong>新建领域对象，在领域层定义接口。</strong> 应该在领域层创建接口契约，由基础架构层（Infrastructure）去实现细节。最后，将该能力封装成<strong>领域服务</strong>供应用层调用。确保领域层自持，基础架构层只负责“插件式”实现。</p>\n<hr />\n<h2>五、 批判：领域服务调用其它领域的仓储</h2>\n<p><strong>【现状批判】</strong>：在订单领域直接注入用户领域的 Repository。这种“跨界伸手段”让领域边界瞬间消失，两个领域在物理存储层面死死捆绑，未来根本无法拆分。</p>\n<p><strong>【正确方式】</strong>：<strong>领域间绝对零感知。</strong> 领域服务只能调用本领域的仓储。跨领域的交互必须上浮到应用层，由应用层担任“导演”进行编排。</p>\n<hr />\n<h2>六、 批判：把领域对象用来接收领域事件</h2>\n<p><strong>【现状批判】</strong>：让实体或领域对象去监听 MQ 消息。这不仅引入了技术噪音，最致命的是<strong>让领域之间形成了依赖</strong>。一旦领域 A 的对象去监听领域 B 的事件，领域 A 就不再孤立，它被迫感知了外部世界的变化，破坏了领域自治。</p>\n<p><strong>【正确方式】</strong>：<strong>应用层监听，领域服务处理。</strong> 应用层负责接收外部事件并将其“翻译”为本领域能理解的普通请求。领域对象应保持清静，它不该知道“事件”是从哪来的，更不该知道外部领域的存在。</p>\n<hr />\n<h2>领域对象设计原则：全业务封装与绝对隔离</h2>\n<ol start=\"1\">\n<li>\n<p><strong>领域必须封装本领域的所有业务</strong>：通过<strong>领域服务</strong>实现业务逻辑的完全闭环。领域外层（应用层）不需要知道领域内部是如何判决的。</p>\n</li>\n<li>\n<p><strong>领域之间必须绝对隔离</strong>：领域之间要达到“物理级”的互不感知。它们不知道彼此的存在，更不能直接通信。</p>\n</li>\n<li>\n<p><strong>应用层是唯一的导演</strong>：只有应用层才有资格编排各个领域。应用层指挥 A 领域判决、B 领域执行，而领域本身只专注于自己。</p>\n</li>\n</ol><hr />\n<h2>总结：正确 DDD 的标准化原则</h2>\n<ul>\n<li>\n<p><strong>1-1-N 模组结构</strong>：<strong>1 个仓储接口、1 个领域服务、N 个实体（构成 1 个聚合）</strong>。</p>\n</li>\n<li>\n<p><strong>契约自持</strong>：接口定义在领域层，拒绝反向依赖。</p>\n</li>\n<li>\n<p><strong>物理级隔离</strong>：领域间零感知，逻辑全封装，由应用层统一编排。</p>\n</li>\n<li>\n<p><strong>首错即断（Fail-fast）</strong>：领域内遇错直接抛出业务异常。</p>\n</li>\n</ul>\n<p><strong>只有正确的 DDD，才能正确的“微”服务。</strong></p>\n<p>微服务不是拆出来的，而是领域边界清晰后自然“长”出来的。</p>\n<hr />\n<p><strong>博主结语</strong>： 架构的优雅来自于对领域边界的极端克制。那些要求你“禁用领域服务”、“平铺实体”的指导文件，其实是在毁掉你的架构。拒绝虚伪的 DDD，守住领域层的尊严。</p>\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-26 11:51</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaozhuang\">小庄</a>&nbsp;\n阅读(<span id=\"post_view_count\">249</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Envoy 可观测性实战：日志、指标与链路追踪的完整落地",
      "link": "https://www.cnblogs.com/MrVolleyball/p/19532068",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/MrVolleyball/p/19532068\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 11:03\">\n    <span>Envoy 可观测性实战：日志、指标与链路追踪的完整落地</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        可观测性不是“装个 Prometheus 就完事”，而是日志、指标、链路追踪三位一体的系统工程。本文结合 Envoy 1.32 实际配置，详细讲解如何接入 Prometheus 和 Jaeger，以及 Envoy Admin 接口在观测中的作用，帮助你快速建立一套真正“能用”的 Envoy 可观测性方案\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>本节详细聊一下基于envoy的可观测性</p>\n<h2 id=\"日志\">日志</h2>\n<p>首先是日志，配置日志的方式也很简单</p>\n<pre><code>static_resources:\n  listeners:\n    - name: ingress_listener\n      address:\n        socket_address:\n          address: 0.0.0.0\n          port_value: 10000\n      filter_chains:\n        - filters:\n            - name: envoy.filters.network.http_connection_manager\n              typed_config:\n                \"@type\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\n                stat_prefix: ingress_http\n                ...\n                access_log:\n                - name: envoy.access_loggers.stdout\n                  typed_config:\n                    \"@type\": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog\n                    log_format:\n                      text_format: \"[%START_TIME%] \\\"%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\" %RESPONSE_CODE% %BYTES_SENT% %DURATION% %REQ(X-REQUEST-ID)% \\\"%REQ(USER-AGENT)%\\\" \\\"%REQ(X-FORWARDED-FOR)%\\\" %UPSTREAM_HOST% %UPSTREAM_CLUSTER% %RESPONSE_FLAGS%\\n\"\n\n</code></pre>\n<ul>\n<li>该配置是将日志输出在控制台，也可以直接输出为文件，然后通过工具采集走<code>path: /var/log/envoy/access.log</code></li>\n<li>也可以直接将日志输出至kafka，并且按比例采集、只采集4xx、5xx等都可以配置，这里就不在赘述了</li>\n</ul>\n<h2 id=\"admin管理页面\">admin管理页面</h2>\n<p>envoy有默认的admin页面，方便查看统计信息、打开某些功能的开关等</p>\n<pre><code>admin:\n  address:\n    socket_address:\n      address: 0.0.0.0\n      port_value: 9901\n\n</code></pre>\n<p>打开9901页面：</p>\n<p><img alt=\"watermarked-envoy_ob_1\" class=\"lazyload\" /></p>\n<p>可以查看相关的统计信息、也可以打开某些开关，功能还是很丰富的</p>\n<h2 id=\"merics接入prometheus\">merics接入prometheus</h2>\n<p>打开了admin之后，就默认提供了相关的prometheus stats <code>http://10.105.148.194:9901/stats/prometheus</code></p>\n<p>这时只需在k8s集群外弄一个prometheus，并且采集该envoy即可</p>\n<p>prometheus.yml</p>\n<pre><code>global:\n  scrape_interval: 5s\n  evaluation_interval: 5s\n\nrule_files:\n  - /etc/prometheus/*.rules\n\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n    - targets: ['localhost:9090']\n\n  - job_name: \"envoy\"\n    metrics_path: /stats/prometheus\n    static_configs:\n    - targets: [\"10.105.148.194:9901\"]\n\n</code></pre>\n<pre><code>docker run -d --name prometheus \\\n  -p 9090:9090 \\\n  -v ./prometheus.yml:/etc/prometheus/prometheus.yml \\\n  -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \\\n  registry.cn-beijing.aliyuncs.com/wilsonchai/prometheus:v3.5.0\n</code></pre>\n<h2 id=\"traces接入jaeger\">traces接入jaeger</h2>\n<p>jaeger的安装可以参考这里： <a href=\"https://mp.weixin.qq.com/s/SkoFwwcw84THbGOi7YaKCA\" rel=\"noopener nofollow\" target=\"_blank\">opentelemetry全链路初探--埋点与jaeger</a></p>\n<p>jaeger启动之后，改造一下envoy的配置，这里要特别注意，不同版本的配置不一样，我这里envoy的版本是：v1.32</p>\n<pre><code>static_resources:\n  listeners:\n    - name: ingress_listener\n      filter_chains:\n        - filters:\n            - name: envoy.filters.network.http_connection_manager\n              typed_config:\n                ...\n\n                tracing:\n\n                  provider:\n                    name: envoy.tracers.opentelemetry\n                    typed_config:\n                      \"@type\": type.googleapis.com/envoy.config.trace.v3.OpenTelemetryConfig\n                      service_name: envoy-proxy\n                      grpc_service:\n                        envoy_grpc:\n                          cluster_name: jaeger_otlp_collector\n                ...\n\n  clusters:\n    ...\n    - name: jaeger_otlp_collector\n      type: LOGICAL_DNS\n      connect_timeout: 5s\n      lb_policy: ROUND_ROBIN\n      http2_protocol_options: {}\n\n      load_assignment:\n        cluster_name: jaeger_otlp_collector\n        endpoints:\n        - lb_endpoints:\n          - endpoint:\n              address:\n                socket_address:\n                  address: 10.22.12.178\n                  port_value: 4317\n    ...\n\n</code></pre>\n<p>修改完成之后重启下envoy</p>\n<p>jaeger成功接收到了来自envoy的trace</p>\n<p><img alt=\"watermarked-envoy_ob_2\" class=\"lazyload\" /></p>\n<p><img alt=\"watermarked-envoy_ob_3\" class=\"lazyload\" /></p>\n<p>由于只在envoy配置了trace，没有和后端服务联动，所有只显示了envoy这一段的trace信息，如果要联动后端，可以参考这个系列的文章： <a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk1NzE0MDcwMg==&amp;action=getalbum&amp;album_id=4247181358063419407&amp;scene=126&amp;sessionid=1767595793922#wechat_redirect\" rel=\"noopener nofollow\" target=\"_blank\">全链路监控配置</a></p>\n<h2 id=\"小结\">小结</h2>\n<p>至此，logs、metrics、traces三大可观测的指标建设完成，envoy可观测性的建设也结束了</p>\n<h2 id=\"联系我\">联系我</h2>\n<ul>\n<li>联系我，做深入的交流</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" height=\"200\" width=\"500\" /></p>\n<hr />\n<p>至此，本文结束<br />\n在下才疏学浅，有撒汤漏水的，请各位不吝赐教...</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/MrVolleyball/\" target=\"_blank\">it排球君</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/MrVolleyball/p/19532068\" target=\"_blank\">https://www.cnblogs.com/MrVolleyball/p/19532068</a></p>\n<div>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须在文章页面给出原文连接，否则保留追究法律责任的权利。 </div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 11:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/MrVolleyball\">it排球君</a>&nbsp;\n阅读(<span id=\"post_view_count\">89</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "开源一个自己的作品浏览器插件ChaTab，一键提交Prompt到多个AI应用",
      "link": "https://www.cnblogs.com/jqbird/p/19531428/chatab",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jqbird/p/19531428/chatab\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 09:06\">\n    <span>开源一个自己的作品浏览器插件ChaTab，一键提交Prompt到多个AI应用</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"chatab-简介\">ChaTab 简介</h1>\n<p>好看也好用的chrome浏览器首页插件，已经在谷歌浏览器商店上架4个月了，代码调整到基本稳定状态了，所以打算把它开源出来。<br />\n每天在用各种AI工具，不同平台切换，非常烦人，所以就自己做了一个这样的工具给自己用，挺好用，所以分享给有类似痛点的用户。</p>\n<h1 id=\"开发工具\">开发工具</h1>\n<p>cursor + claude code</p>\n<p>现在软件开发的成本极大降低，再也不是手工业时代的一针一线的编码了，只要基础架构设计好，AI基本可以完成 90%的设计和编码工作，</p>\n<h1 id=\"插件功能说明\">插件功能说明</h1>\n<ol>\n<li>批量Prompt提交，一键快速批量发送提示词至 ChatGPT、DeepSeek 等多个 AI 应用，提升效率。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>智能背景切换 ， 随机更换 Chrome 启动页背景，让每次开启浏览器都有新鲜感。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>3.应用导航，下拉的时候点击icon快速链接到应用地址。</p>\n<p><img alt=\"2\" class=\"lazyload\" /></p>\n<ol start=\"4\">\n<li>左侧历史记录，点击可以快速填充历史记录到tab里的输入框中。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h1 id=\"使用说明\">使用说明</h1>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>1、谷歌浏览器商店搜索 \"chatab\"，或者复制链接地址安装：</p>\n<p><a href=\"https://chromewebstore.google.com/detail/chatab/gcbcmnekbambjebgfjnbgopmgcgcealn?hl=zh-CN&amp;utm_source=ext_sidebar\" rel=\"noopener nofollow\" target=\"_blank\">https://chromewebstore.google.com/detail/chatab/gcbcmnekbambjebgfjnbgopmgcgcealn?hl=zh-CN&amp;utm_source=ext_sidebar</a></p>\n<p>2、使用前请先在浏览器中登录 ChatGPT、DeepSeek 等相关平台。插件将为您提供一键提交、多平台切换的便捷体验。</p>\n<p>注意：这个插件会修改浏览器首页。</p>\n<h1 id=\"开源地址\">开源地址</h1>\n<ul>\n<li><a href=\"https://github.com/robotbird/chatab\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/robotbird/chatab</a></li>\n</ul>\n<h1 id=\"关于作者\">关于作者</h1>\n<p>产品经理，热爱哲学，个人博客 <a href=\"http://www.jqpress.com\" rel=\"noopener nofollow\" target=\"_blank\">jqpress.com</a>，微信公众号：产品经理随想曲</p>\n<p><img alt=\"产品经理随想曲\" class=\"lazyload\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 09:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jqbird\">叶鹏</a>&nbsp;\n阅读(<span id=\"post_view_count\">320</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "HagiCode 实践：如何利用 GitHub Actions 实现 Docusaurus 自动部署",
      "link": "https://www.cnblogs.com/newbe36524/p/19531383",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19531383\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 08:56\">\n    <span>HagiCode 实践：如何利用 GitHub Actions 实现 Docusaurus 自动部署</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"为-hagicode-添加-github-pages-自动部署支持\">为 HagiCode 添加 GitHub Pages 自动部署支持</h1>\n<blockquote>\n<p>本项目早期代号为 PCode，现已正式更名为 HagiCode。本文记录了如何为项目引入自动化静态站点部署能力，让内容发布像喝水一样简单。</p>\n</blockquote>\n\n<h2 id=\"背景引言\">背景/引言</h2>\n<p>在 HagiCode 的开发过程中，我们遇到了一个很现实的问题：随着文档和提案越来越多，如何高效地管理和展示这些内容成了当务之急。我们决定引入 GitHub Pages 来托管我们的静态站点，但是手动构建和部署实在是太麻烦了——每次改动都要本地构建、打包，然后手动推送到 <code>gh-pages</code> 分支。这不仅效率低下，还容易出错。</p>\n<p>为了解决这个问题（主要是为了偷懒），我们需要一套自动化的部署流程。本文将详细记录如何为 HagiCode 项目添加 GitHub Actions 自动部署支持，让我们只需专注于内容创作，剩下的交给自动化流程。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<blockquote>\n<p>嘿，介绍一下我们正在做的东西</p>\n</blockquote>\n<p>我们正在开发 <strong>HagiCode</strong>——一款 AI 驱动的代码智能助手，让开发体验变得更智能、更便捷、更有趣。</p>\n<p><strong>智能</strong>——AI 全程辅助，从想法到代码，让编码效率提升数倍。<strong>便捷</strong>——多线程并发操作，充分利用资源，开发流程顺畅无阻。<strong>有趣</strong>——游戏化机制和成就系统，让编码不再枯燥，充满成就感。</p>\n<p>项目正在快速迭代中，如果你对技术写作、知识管理或者 AI 辅助开发感兴趣，欢迎来 <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">GitHub</a> 看看～</p>\n<h2 id=\"目标分析\">目标分析</h2>\n<p>在动手之前，我们得先明确这次任务到底要干啥。毕竟磨刀不误砍柴工嘛。</p>\n<h3 id=\"核心需求\">核心需求</h3>\n<ol>\n<li><strong>自动化构建</strong>：当代码推送到 <code>main</code> 分支时，自动触发构建流程。</li>\n<li><strong>自动部署</strong>：构建成功后，自动将生成的静态文件部署到 GitHub Pages。</li>\n<li><strong>环境一致性</strong>：确保 CI 环境和本地构建环境一致，避免\"本地能跑，线上报错\"的尴尬。</li>\n</ol>\n<h3 id=\"技术选型\">技术选型</h3>\n<p>考虑到 HagiCode 是基于 Docusaurus 构建的（一种非常流行的 React 静态站点生成器），我们可以利用 GitHub Actions 来实现这一目标。</p>\n<h2 id=\"配置-github-actions-工作流\">配置 GitHub Actions 工作流</h2>\n<p>GitHub Actions 是 GitHub 提供的 CI/CD 服务。通过在代码仓库中定义 YAML 格式的工作流文件，我们可以定制各种自动化任务。</p>\n<h3 id=\"创建工作流文件\">创建工作流文件</h3>\n<p>我们需要在项目根目录下的 <code>.github/workflows</code> 文件夹中创建一个新的配置文件，比如叫 <code>deploy.yml</code>。如果文件夹不存在，记得先手动创建一下。</p>\n<p>这个配置文件的核心逻辑如下：</p>\n<ol>\n<li><strong>触发条件</strong>：监听 <code>main</code> 分支的 <code>push</code> 事件。</li>\n<li><strong>运行环境</strong>：最新版的 Ubuntu。</li>\n<li><strong>构建步骤</strong>：\n<ul>\n<li>检出代码</li>\n<li>安装 Node.js</li>\n<li>安装依赖 (<code>npm install</code>)</li>\n<li>构建静态文件 (<code>npm run build</code>)</li>\n</ul>\n</li>\n<li><strong>部署步骤</strong>：使用官方提供的 <code>action-gh-pages</code> 将构建产物推送到 <code>gh-pages</code> 分支。</li>\n</ol>\n<h3 id=\"关键配置代码\">关键配置代码</h3>\n<p>以下是我们最终采用的配置模板：</p>\n<pre><code class=\"language-yaml\">name: Deploy to GitHub Pages\n\n# 触发条件：当推送到 main 分支时\non:\n  push:\n    branches:\n      - main\n    # 可以根据需要添加路径过滤，比如只有文档变动才构建\n    # paths:\n    #   - 'docs/**'\n    #   - 'package.json'\n\n# 设置权限，这对于部署到 GitHub Pages 很重要\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# 并发控制：取消同一分支的旧构建\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        # 注意：必须设置 fetch-depth: 0，否则可能导致构建版本号不准确\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20 # 建议与本地开发环境保持一致\n          cache: 'npm'     # 启用缓存可以加速构建过程\n\n      - name: Install dependencies\n        run: npm ci\n        # 使用 npm ci 而不是 npm install，因为它更快、更严格，适合 CI 环境\n\n      - name: Build website\n        run: npm run build\n        env:\n          # 如果你的站点构建需要环境变量，在这里配置\n          # NODE_ENV: production\n          # PUBLIC_URL: /your-repo-name\n          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./build # Docusaurus 默认输出目录\n\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n</code></pre>\n<h2 id=\"实施过程中的坑点\">实施过程中的坑点</h2>\n<p>在实际操作中，我们遇到了一些问题，这里分享出来希望大家能避开（或者提前准备好解决方案）。</p>\n<h3 id=\"1-github-token-权限问题\">1. GitHub Token 权限问题</h3>\n<p>最开始配置的时候，部署总是报错 403 (Forbidden)。查了好久才发现，是因为 GitHub 默认的 <code>GITHUB_TOKEN</code> 并没有写入 Pages 的权限。</p>\n<p><strong>解决方案</strong>：在仓库的 <code>Settings</code> -&gt; <code>Actions</code> -&gt; <code>General</code> -&gt; <code>Workflow permissions</code> 中，务必选择 <strong>\"Read and write permissions\"</strong>。</p>\n<h3 id=\"2-构建目录路径错误\">2. 构建目录路径错误</h3>\n<p>Docusaurus 默认把构建好的静态文件放在 <code>build</code> 目录。但是有些项目（比如 Create React App 默认是 <code>build</code>，Vite 默认是 <code>dist</code>）可能配置不一样。如果在 Actions 中报错找不到文件，记得去 <code>docusaurus.config.js</code> 里检查一下输出路径配置。</p>\n<h3 id=\"3-子路径问题\">3. 子路径问题</h3>\n<p>如果你的仓库不是用户主页（即不是 <code>username.github.io</code>），而是项目主页（比如 <code>username.github.io/project-name</code>），你需要配置 <code>baseUrl</code>。</p>\n<p>在 <code>docusaurus.config.js</code> 中：</p>\n<pre><code class=\"language-javascript\">module.exports = {\n  // ...\n  url: 'https://HagiCode-org.github.io', // 你的 GitHub URL\n  baseUrl: '/site/', // 如果你的仓库叫 site，这里就填 /site/\n  // ...\n};\n</code></pre>\n<p>这一点很容易被忽略，配置不对会导致页面打开全是白屏，因为资源路径加载不到。</p>\n<h2 id=\"验证成果\">验证成果</h2>\n<p>配置完所有东西并推送代码后，我们就可以去 GitHub 仓库的 <strong>Actions</strong> 标签页看戏了。</p>\n<p>你会看到黄色的圆圈（工作流正在运行），变绿就代表成功啦！如果变红了，点击进去查看日志，通常都能排查出问题（大部分时候是拼写错误或者路径配置不对）。</p>\n<p>构建成功后，访问 <code>https://&lt;你的用户名&gt;.github.io/&lt;仓库名&gt;/</code> 就能看到崭新的站点了。</p>\n<h2 id=\"总结\">总结</h2>\n<p>通过引入 GitHub Actions，我们成功实现了 HagiCode 文档站的自动化部署。这不仅节省了手动操作的时间，更重要的是保证了发布流程的标准化。现在不管是哪位小伙伴更新了文档，只要合并到 <code>main</code> 分支，几分钟后就能在线上看到最新的内容。</p>\n<p><strong>核心收益</strong>：</p>\n<ul>\n<li><strong>效率提升</strong>：从\"手动打包、手动上传\"变成\"代码即发布\"。</li>\n<li><strong>降低错误</strong>：消除了人为操作失误的可能性。</li>\n<li><strong>体验优化</strong>：让开发者更专注于内容质量，而不是被繁琐的部署流程困扰。</li>\n</ul>\n<p>虽然配置 CI/CD 刚开始有点麻烦（尤其是各种权限和路径问题），但这是一次性投入，长期回报巨大的工作。强烈建议所有静态站点项目都接入类似的自动化流程。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://docs.github.com/en/actions\" rel=\"noopener nofollow\" target=\"_blank\">GitHub Actions 官方文档</a></li>\n<li><a href=\"https://docusaurus.io/docs/deployment\" rel=\"noopener nofollow\" target=\"_blank\">Docusaurus 部署指南</a></li>\n<li>[actions-gh-pages Action 使用说明](<a href=\"https://github.com\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com</a> peaceiris/actions-gh-pages)</li>\n</ul>\n<hr />\n<p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p>\n<p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p>\n<h2 id=\"元信息\">元信息</h2>\n<ul>\n<li><strong>本文作者:</strong> <a href=\"https://www.newbe.pro\" rel=\"noopener nofollow\" target=\"_blank\">newbe36524</a></li>\n<li><strong>本文链接:</strong> <a href=\"https://hagicode-org.github.io/site/blog/2026/01/25/docusaurus-auto-deployment-with-github-actions\" rel=\"noopener nofollow\" target=\"_blank\">https://hagicode-org.github.io/site/blog/2026/01/25/docusaurus-auto-deployment-with-github-actions</a></li>\n<li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 08:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">78</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "复刻 ChatGPT 高级数据分析！Sdcb Chats 1.10 重磅发布：能分析Excel、做PPT",
      "link": "https://www.cnblogs.com/sdcb/p/19528764/chats-1-10",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sdcb/p/19528764/chats-1-10\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 08:45\">\n    <span>复刻 ChatGPT 高级数据分析！Sdcb Chats 1.10 重磅发布：能分析Excel、做PPT</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Chats 1.10.0 发布了！这是一个我个人非常喜欢，也期待已久的版本。</p>\n<p>距离 1.9.0 发布（2025 年 11 月 27 日）已经过去了近两个月。这期间，我并不是在摸鱼，而是在憋一个“大招”——<strong>内置代码执行器（Code Interpreter）</strong>。</p>\n<blockquote>\n<p>如果你还不了解 <strong>Sdcb Chats</strong>：简单说，这是一个支持多家主流模型服务商的 AI 网关。它不只能让你在一个统一界面里聚合管理所有模型，同时也兼容标准 API 协议，支持 Docker 一键部署与多数据库支持。</p>\n</blockquote>\n<h2 id=\"为什么是代码执行器\">为什么是代码执行器？</h2>\n<p>Sdcb Chats 1.9发布之后，很多人好奇我下一步准备怎么走，我当时想的两个方向：</p>\n<p><strong>方向一：Dify 模式（Dify化）</strong><br />\n一种是支持发布成 App 的功能，比如通过一定的系统提示词、工具集选择、模型参数设置（如温度等），可以将这样的东西打包发布成一个像 App 一样的网页，或者是一个 js 入口。用户可以通过这个网页直接使用 Chats 的预定功能和 AI 大模型聊天、完成指定任务。打包成的 js 甚至可以嵌入用户（通常是企业用户）的网页中，这样一来用户就可以直接在自己的网站上使用定制化的 AI 助手了。这个方向很有商业潜力，很多客户都在问。</p>\n<p><strong>方向二：Code Interpreter 模式（ADA）</strong><br />\n另外一个方向就是实现内置的基于 Docker 的沙箱功能。因为我经常看到 ChatGPT 网站（或者像 Manus 一样）中可以执行一段 Python 脚本——或者经过一系列多步骤的过程，然后生成一张图片或者一个图表、Excel、PPT。这个功能之前 ChatGPT 叫作 Code Interpreter（代码执行器），后来为了显得更专业，改名叫“高级数据分析”（Advanced Data Analysis，ADA）。</p>\n<p>这个功能的核心在于：<strong>它可以让 AI 模型直接操作文件、生成各种格式的输出，而不需要用户手动去处理数据和文件。</strong></p>\n<p>我发现，目前市面上除了 OpenAI 提供了完整体验外，像 Gemini、Grok、Qwen（基于OpenWebUI）等都没有提供类似的功能支持。</p>\n<p><strong>我的选择</strong><br />\n从 Chats 的商业化角度来说，Dify 方向肯定更有“钱”景。但我个人对 ADA 方向更感兴趣一些，因为我觉得这个功能更“硬核”，也更能体现 AI 模型的能力和潜力。</p>\n<p>所以我最终选择了 ADA 方向作为 1.10 版本发布的核心功能。经过几周的努力，1.10 版本终于完成了内置 Docker Code Interpreter 的功能！现在用户可以在 Chats 中直接请 AI 创建一个 Docker 会话，上传文件，让 AI 模型执行代码、分析数据、生成 PPT 等，非常方便实用。</p>\n<h2 id=\"强大的-docker-沙箱不只是-python\">强大的 Docker 沙箱：不只是 Python</h2>\n<p>为了实现这个功能，我不仅仅是加了几个 API 那么简单。</p>\n<p>这个功能的 PoC 其实早在去年 11 月我就完成了，之后我陆续打磨，直到 2026 年元旦的时候我和 AI 做了多轮的设计，最终定稿并创建了 7 个内置工具：</p>\n<ul>\n<li><code>create_docker_session</code>：创建环境</li>\n<li><code>run_command</code>：执行命令</li>\n<li><code>read_file</code> / <code>write_file</code> / <code>patch_file</code>：文件操作</li>\n<li><code>download_chat_files</code>：文件流转</li>\n<li><code>destroy_session</code>：资源回收</li>\n</ul>\n<p>我还内置了一套 <strong>Artifact（工件）文件夹跟踪机制</strong>。简单来说，如果大模型操作命令行工具或者其它什么脚本将文件放到了指定的 artifact 文件夹，Chats 系统就会自动帮用户保存下来，用户在聊天界面可以直接点击下载。</p>\n<h3 id=\"专属镜像sdcbcode-interpreter\">专属镜像：sdcb/code-interpreter</h3>\n<p>为了让体验达到极致，我不想让大家每次都去拉取巨大的通用镜像，也不想让大家费劲去配置环境。因此，我专门构建了一个 docke 镜像：<code>sdcb/code-interpreter</code>。</p>\n<p>和 OpenAI 的 ADA 功能类似，这个镜像里预装了常用的工具链和依赖库：</p>\n<ul>\n<li><strong>语言环境</strong>：Python, .NET (Dotnet), Node.js, GCC</li>\n<li><strong>数据处理</strong>：SQLite3, Pandas, Numpy</li>\n<li><strong>文档办公</strong>：LibreOffice, Pandoc</li>\n<li><strong>多媒体</strong>：FFmpeg, ImageMagick</li>\n<li><strong>Web自动化</strong>：Playwright Chromium</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102326917-629370352.png\" /></p>\n<p>大模型在使用这个镜像时，会自动加载 <code>/app/skills.md</code> 这个文件，里面列出了镜像中预装的工具和库：</p>\n<pre><code class=\"language-md\">This environment is pre-configured with the following tools and libraries:\n* utilities: git, LibreOffice, Pandoc, Poppler (`pdftotext`, `pdfinfo`), sqlite3, file, FFmpeg {ffmpegVersion}, git, imagemagick, playwright[chromium]\n* dotnet {dotnetVersion}, commands: `dotnet build`, `dotnet run single-file.cs`, `dotnet add package`, pre-cached NuGet packages in `/opt/nuget-local`\n* python {pythonVersion}, commands: `python3 - &lt;&lt;'PY' ...`, `pip install --break-system-packages package-name`, IMPORTANT: Many packages are pre-installed, Always check with `pip list` BEFORE installing to avoid unnecessary waits.\n* C/C++ Toolchain (gcc {gccVersion}), tools: `gcc`, `g++`, `make`, `cmake`\n* node.js {nodeVersion}, commands: `node`, `npm`, IMPORTANT: Many packages are pre-installed globally. Always check with `npm -g ls` BEFORE installing.\n</code></pre>\n<p>大模型可以直接调用这些工具，非常方便。</p>\n<p>值得一提的是，作为一名 .NET 爱好者，这个镜像我是基于 .NET 做的（Base Image），因此碰巧你像我一样使用 .NET/C# 来验证一些东西的话，让大模型直接使用这个镜像就行了！</p>\n<h2 id=\"场景演示它能做什么\">场景演示：它能做什么？</h2>\n<p>光说不练假把式，我们来看看它在实际场景中的威力。</p>\n<h3 id=\"场景一分析-excel-并生成图表\">场景一：分析 Excel 并生成图表</h3>\n<p>以前我们让 AI 分析 Excel，通常是将数据格式发给AI，然后让它帮忙写代码，用户再自己运行代码生成图表。现在可以直接让 AI 在沙箱中操作 Excel 文件，生成图表。</p>\n<p>比如你有一个这样的excel：<a href=\"https://cv-public.sdcb.pub/2026/changsha_weather_2025.xlsx\" rel=\"noopener nofollow\" target=\"_blank\">https://cv-public.sdcb.pub/2026/changsha_weather_2025.xlsx</a><br />\n里面的数据是长沙 2025 年的每日天气记录：<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102327825-611206051.png\" /></p>\n<blockquote>\n<p><strong>用户</strong>：请帮我分析这个 Excel 文件，生成一个包含每月平均气温和降水量的报告，并附上图表。</p>\n</blockquote>\n<p>AI 会直接在 Docker 沙箱中运行 Python 代码，使用 Pandas 和 Matplotlib 生成图表，然后把结果打包成报告发给你（视频有加速）。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102328487-114968639.avif\" /></p>\n<h3 id=\"场景二一句话生成-ppt\">场景二：一句话生成 PPT</h3>\n<p>这是我最爱的功能之一。</p>\n<blockquote>\n<p><strong>用户</strong>：请根据上面的天气分析，帮我生成一份以“2025年长沙天气分析报告”为主题的PPT，包含封面、目录、数据分析、图表展示和结论五个部分。</p>\n</blockquote>\n<p>AI 会调用 <code>python-pptx</code> 库，在沙箱中生成 <code>.pptx</code> 文件，然后给你一个下载链接。你下载下来直接就可以去汇报了（当然最好还是微调一下）。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102329000-1999082053.png\" /></p>\n<p>这是原始 PPT 的下载链接，有兴趣的可以看看感受一下效果：<a href=\"https://cv-public.sdcb.pub/2026/changsha_weather_report_2025.pptx\" rel=\"noopener nofollow\" target=\"_blank\">https://cv-public.sdcb.pub/2026/changsha_weather_report_2025.pptx</a></p>\n<h3 id=\"场景三做实验\">场景三：做实验</h3>\n<p>这其实也是我最喜欢的一个场景。比如我想测试一个新的算法，或者验证一个代码片段，我可以直接让 AI 在沙箱中帮我跑代码。</p>\n<p>比如之前我写过两篇博客：</p>\n<ul>\n<li>《不服跑个分？.NET 10 大整数计算对阵 Java，结果令人意外》（博客园链接：<a href=\"https://www.cnblogs.com/sdcb/p/19484525/20261113-big-integer-dotnet-10-vs-java%EF%BC%89\" target=\"_blank\">https://www.cnblogs.com/sdcb/p/19484525/20261113-big-integer-dotnet-10-vs-java）</a></li>\n<li>《.NET 10了，HttpClient还是不能用using吗？我做了一个实验》（博客园链接：<a href=\"https://www.cnblogs.com/sdcb/p/19500792/20260119-using-httpclient%EF%BC%89\" target=\"_blank\">https://www.cnblogs.com/sdcb/p/19500792/20260119-using-httpclient）</a></li>\n</ul>\n<p>这里面有大量的代码、实验数据和图表，我可以直接让 AI 在沙箱中帮我跑这些代码，生成数据，然后帮我分析结果、生成图表，极大地提高了我的写作效率：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102329414-26338747.png\" /></p>\n<h2 id=\"其它重磅更新\">其它重磅更新</h2>\n<p>除了代码执行器，1.10 还有很多硬核更新：</p>\n<h3 id=\"1-交错思考改进\">1. 交错思考改进</h3>\n<p>在 1.9 版本中，我引入了交错思考（Interleaved Thinking）的概念，允许大模型在回答问题时分多步思考和行动。但只支持 Minimax-M2、Anthropic Claude等模型支持交错思考。</p>\n<p>在 1.10 版本中，我扩展了对更多模型的支持，包括 OpenAI Responses API、DeepSeek V3.2模型。</p>\n<p>比如你看下面的使用量统计（来自 Chats 的截图）：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102329774-510845930.png\" /></p>\n<p>我当时使用的模型是 OpenAI 的 gpt-5.2，它通过 Response API 的交错思考将思考信息回传，在总结 201K Tokens 的对话中，有 189K 触发了请求缓存，节省了大量的计算资源和费用，还提升了模型能力，这都依赖于交错思考的功能。</p>\n<p>到此，Sdcb Chats中已经有这些模型提供商确认支持完整的交错思考功能：</p>\n<table>\n<thead>\n<tr>\n<th>Id</th>\n<th>Name</th>\n<th>加入时间</th>\n<th>交错思考</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>Azure AI Foundry</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>2</td>\n<td>腾讯混元</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>3</td>\n<td>零一万物</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td></td>\n</tr>\n<tr>\n<td>4</td>\n<td>月之暗面</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>5</td>\n<td>OpenAI</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>6</td>\n<td>百度千帆</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>阿里百炼</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>8</td>\n<td>讯飞星火</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td></td>\n</tr>\n<tr>\n<td>9</td>\n<td>智谱AI</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>10</td>\n<td>DeepSeek</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/30db0079\" rel=\"noopener nofollow\" target=\"_blank\">2024-12-06</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>11</td>\n<td>x.ai</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/0d1cab20\" rel=\"noopener nofollow\" target=\"_blank\">2024-12-11</a></td>\n<td></td>\n</tr>\n<tr>\n<td>12</td>\n<td>Github Models</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/0d1cab20\" rel=\"noopener nofollow\" target=\"_blank\">2024-12-11</a></td>\n<td></td>\n</tr>\n<tr>\n<td>13</td>\n<td>谷歌AI</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/a4effc1b\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-10</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>14</td>\n<td>Ollama</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/6a5288e7\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-20</a></td>\n<td></td>\n</tr>\n<tr>\n<td>15</td>\n<td>MiniMax</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/6a5288e7\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-20</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>16</td>\n<td>火山方舟</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/843510ff\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-24</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>17</td>\n<td>硅基流动</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/889144cf\" rel=\"noopener nofollow\" target=\"_blank\">2025-02-08</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>18</td>\n<td>OpenRouter</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/15adedfe\" rel=\"noopener nofollow\" target=\"_blank\">2025-03-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>19</td>\n<td>小马算力</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/32e4a0d5\" rel=\"noopener nofollow\" target=\"_blank\">2025-11-07</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>20</td>\n<td>Anthropic</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/22ebef98\" rel=\"noopener nofollow\" target=\"_blank\">2025-11-24</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>21</td>\n<td>小米Mimo</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/026f1a4e\" rel=\"noopener nofollow\" target=\"_blank\">2025-12-17</a></td>\n<td>✅</td>\n</tr>\n</tbody>\n</table>\n<p>注：</p>\n<ul>\n<li>❓代表模型提供商使用了基于 Anthropic Messages API 的实现，按协议推断应该支持，但由于未做过端到端测试，因此不确定是否能实现完整的交错思考能力——我相当肯定不能简单地说“支持”，因为有些模型在实现上可能会有差异化。</li>\n<li>还有一些模型提供商基于 OpenAI Responses API 实现的，比如文心千帆，理论上只要支持 Responses API 也能实现交错思考，但我还没有做过测试，因此暂时不列入表格。</li>\n</ul>\n<h3 id=\"2-用户体验大升级\">2. 用户体验大升级</h3>\n<ul>\n<li>\n<p><strong>工具调用展示</strong>：为了配合 Code Interpreter，我重写了工具调用的 UI（<code>ToolCallBlock</code>）。现在可以看到实时的控制台输出流（Log Stream），体验就像自己在看终端一样爽。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102330184-33469646.avif\" /></p>\n</li>\n<li>\n<p><strong>拖拽上传</strong>：支持直接 Ctrl+V 粘贴文件，或者拖拽文件到输入框。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102330573-196654545.png\" /></p>\n</li>\n<li>\n<p><strong>生成信息统计</strong>：现在气泡上会显示 Step 数量、平均耗时等极客信息（如上已经有截图示例）。</p>\n</li>\n</ul>\n<h2 id=\"幕后花絮\">幕后花絮</h2>\n<h3 id=\"那个让人头秃的-ef-core-bug\">那个让人头秃的 EF Core Bug</h3>\n<p>开发后期有一个很烦人的 EF Core 问题，表现是会话追踪的数据有时候会莫名其妙地状态不对。当时我把日志丢给 AI 大模型，让它帮我分析了好久都没解决，给出的建议都在“隔靴搔痒”。</p>\n<p>后来没办法，我只能拿出传统的“调试器大法”，一步一步地断点调试，才发现是 EF Core 在处理并发更新时的状态跟踪（Change Tracking）导致了数据污染。果然，关键时刻还是得靠人类工程师的直觉和经验啊！😅</p>\n<h3 id=\"为什么迟到了\">为什么迟到了？</h3>\n<p>1.10 其实早在 <strong>2026-01-14</strong> 就发布了，为什么今天是 26 号我才发文章宣传？</p>\n<p>一方面是我自己在进行高强度的“狗粮测试”（Dogfooding），确保在这个 Docker 沙箱里跑 rm -rf / 不会把我的宿主机炸了（开玩笑的，有安全限制）。</p>\n<p>另一方面，我补了大量的文档。新功能的配置参数比较多，为了让大家能顺利部署，我花了几天时间重新梳理了 <a href=\"https://github.com/sdcb/chats/blob/main/README.md\" rel=\"noopener nofollow\" target=\"_blank\">README</a> 和 <a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/1.10.0.md\" rel=\"noopener nofollow\" target=\"_blank\">Release Note</a>，大家部署前一定要去看看。</p>\n<hr />\n<h2 id=\"结语\">结语</h2>\n<p>Chats 1.10 是一个里程碑，它让 Chats 从一个单纯的“聊天窗口”进化成了一个“生产力工场”。我非常期待看到大家用这个功能玩出什么花样！</p>\n<p>喜欢的朋友请给我的 GitHub 项目一个 star：<br />\n🌟 <strong><a href=\"https://github.com/sdcb/chats\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats</a></strong></p>\n<p>这是完整的更新日志：<br />\n<a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md</a></p>\n<p>有什么想法也欢迎在评论区留言交流，也欢迎加入我的新创建的微信群：</p>\n<p><img alt=\"微信群\" src=\"https://io.starworks.cc:88/cv-public/2026/chats-wxg-qr.png\" /></p>\n<p>如果你更习惯用 QQ 群或者上面的微信群链接失效的话，也可以加入 Chats QQ 群：<strong>498452653</strong>，我们一起探索更多 AI 技术硬核玩法。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 08:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sdcb\">.NET骚操作</a>&nbsp;\n阅读(<span id=\"post_view_count\">675</span>)&nbsp;\n评论(<span id=\"post_comment_count\">5</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "超详细！OFA 视觉问答（VQA）模型部署教学（避坑完整版）",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19535960",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19535960\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 01:04\">\n    <span>超详细！OFA 视觉问答（VQA）模型部署教学（避坑完整版）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文详细介绍了如何在Linux系统下部署OFA视觉问答(VQA)模型的全过程。主要内容包括：创建Python虚拟环境、配置清华PyPI源、安装指定版本的核心依赖(transformers 4.48.3等)、禁用ModelScope自动依赖安装以避免版本冲突、准备测试图片和运行脚本。文章特别强调了依赖版本匹配的重要性，并提供了经过验证的版本组合方案。同时针对输入格式适配和图片加载权限等常见问题给出了解决方案，附带可直接运行的测试脚本，帮助开发者快速上手部署这一多模态预训练模型。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>大家好～ 最近尝试部署 OFA 视觉问答（VQA）模型，过程中踩了无数个依赖版本、输入格式、权限相关的坑，耗时很久才成功运行并输出正确结果。为了避免大家重复踩坑，今天整理了一份完整、可复现的部署教学，从环境准备到脚本运行，每一步都标清细节，连遇到的坑都附带「<strong>现象+原因+解决方案</strong>」，新手也能轻松上手！</p>\n<h1 id=\"一前言什么是-ofa-vqa-模型\">一、前言：什么是 OFA VQA 模型？</h1>\n<p>OFA（One For All）是字节跳动提出的多模态预训练模型，支持视觉问答、图像描述、图像编辑等多种任务，其中视觉问答（VQA）是最常用的功能之一——输入一张图片和一个英文问题（该模型仅支持英文），模型就能输出对应的答案（比如输入“瓶子”图片+问题“What is the main subject?”，输出“a water bottle”）。</p>\n<p>本次部署使用 ModelScope 平台的 <code>iic/ofa_visual-question-answering_pretrain_large_en</code> 模型，基于 Python 虚拟环境（Miniconda）部署，全程在 Linux 环境下操作（Windows 可参考，命令略有差异）。</p>\n<h1 id=\"二前置准备\">二、前置准备</h1>\n<h2 id=\"1-环境基础\">1. 环境基础</h2>\n<ul>\n<li>\n<p>系统：Linux（Ubuntu/CentOS 均可，本次用 Ubuntu）</p>\n</li>\n<li>\n<p>工具：Miniconda（用于创建独立虚拟环境，避免环境污染）</p>\n</li>\n<li>\n<p>Python 版本：3.11（亲测兼容，3.9-3.11 均可，不建议 3.12+，部分依赖不支持）</p>\n</li>\n<li>\n<p>网络：能访问 ModelScope、PyPI 源（建议换清华源，提速）</p>\n</li>\n</ul>\n<h2 id=\"2-提前说明\">2. 提前说明</h2>\n<p>本次部署的核心难点的是「依赖版本匹配」——ModelScope 平台的 OFA 模型会硬编码依赖版本，运行时会自动卸载你安装的版本并强制安装指定版本，很容易导致版本冲突；其次是「输入格式适配」和「图片加载权限」问题，这两个坑也很容易卡壳，后面会详细说明。</p>\n<h1 id=\"三完整部署步骤一步都不能少\">三、完整部署步骤（一步都不能少）</h1>\n<h2 id=\"步骤-1创建并激活虚拟环境关键避免环境污染\">步骤 1：创建并激活虚拟环境（关键！避免环境污染）</h2>\n<p>为什么要创建虚拟环境？因为不同模型的依赖版本差异很大，比如本次 OFA 模型对 transformers、tokenizers 的版本要求很严格，和其他模型可能冲突，独立虚拟环境能隔离这些差异。</p>\n<p>打开终端，执行以下命令（全程复制即可）：</p>\n<pre><code class=\"language-bash\">\n# 1. 激活 Miniconda（如果没配置环境变量，先执行这个，具体路径根据自己的 Miniconda 安装位置修改）\nsource /opt/miniconda3/bin/activate\n\n# 2. 创建虚拟环境（环境名：torch27，Python 版本 3.11，可自定义环境名）\nconda create -n torch27 python=3.11 -y\n\n# 3. 激活创建好的虚拟环境（后续所有操作都要在这个环境里执行）\nconda activate torch27\n</code></pre>\n<p>执行成功后，终端前缀会显示 <code>(torch27)</code>，说明已经进入虚拟环境。</p>\n<h2 id=\"步骤-2配置清华-pypi-源提速避免下载依赖超时\">步骤 2：配置清华 PyPI 源（提速，避免下载依赖超时）</h2>\n<p>默认 PyPI 源在国外，下载依赖很慢，甚至会超时，建议配置清华源，执行以下命令：</p>\n<pre><code class=\"language-bash\">\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n</code></pre>\n<p>配置成功后，后续用 pip 安装依赖会自动走清华源，速度翻倍。</p>\n<h2 id=\"步骤-3创建工作目录下载模型相关文件\">步骤 3：创建工作目录，下载模型相关文件</h2>\n<p>创建一个单独的工作目录，用于存放脚本、图片等文件，避免文件混乱：</p>\n<pre><code class=\"language-bash\">\n# 1. 创建工作目录（路径可自定义，本次用 /root/workspace/ofa_visual-question-answering）\nmkdir -p /root/workspace/ofa_visual-question-answering\n\n# 2. 进入工作目录（后续所有操作都在这个目录下）\ncd /root/workspace/ofa_visual-question-answering\n</code></pre>\n<h2 id=\"步骤-4安装核心依赖重点版本必须完全匹配\">步骤 4：安装核心依赖（重点！版本必须完全匹配）</h2>\n<p>这是部署过程中最容易踩坑的一步！OFA 模型对依赖版本要求极高，尤其是 transformers、tokenizers、huggingface-hub 这三个库，版本不匹配会直接导致模型无法初始化，甚至报错。</p>\n<p>先给大家上「最终可用的依赖版本组合」（亲测可复现，避免踩坑）：</p>\n<ul>\n<li>\n<p>tensorboardX==2.6.4（模型日志相关，版本可兼容）</p>\n</li>\n<li>\n<p>huggingface-hub==0.25.2（ModelScope 硬编码要求，不能高也不能低）</p>\n</li>\n<li>\n<p>transformers==4.48.3（ModelScope 硬编码要求，对应 tokenizers 0.21.4）</p>\n</li>\n<li>\n<p>tokenizers==0.21.4（必须和 transformers 4.48.3 匹配，否则报错）</p>\n</li>\n<li>\n<p>modelscope（模型加载平台，直接安装最新版即可）</p>\n</li>\n<li>\n<p>Pillow、requests（图片加载相关，必备）</p>\n</li>\n</ul>\n<p>执行以下命令，一次性安装所有依赖（顺序不要乱，避免版本冲突）：</p>\n<pre><code class=\"language-bash\">\n# 1. 先安装 tensorboardX（无版本冲突，放心装）\npip install tensorboardX==2.6.4\n\n# 2. 安装 ModelScope 硬编码要求的核心依赖（重点！版本不能改）\npip install huggingface-hub==0.25.2 tokenizers==0.21.4 transformers==4.48.3\n\n# 3. 安装 modelscope（最新版即可，负责加载 OFA 模型）\npip install modelscope\n\n# 4. 安装图片加载相关依赖（Pillow 处理本地图片，requests 处理在线图片）\npip install Pillow requests\n</code></pre>\n<p>安装过程中如果出现「WARNING: Running pip as the 'root' user」警告，可忽略，不影响功能（这是提示用 root 用户运行 pip 可能有权限问题，但不影响模型部署）。</p>\n<p>安装完成后，验证一下版本是否正确（避免安装出错）：</p>\n<pre><code class=\"language-bash\">\npython -c \"import transformers, tokenizers, huggingface_hub; print(f'transformers: {transformers.__version__}'); print(f'tokenizers: {tokenizers.__version__}'); print(f'huggingface-hub: {huggingface_hub.__version__}')\"\n</code></pre>\n<p>正常输出如下（版本必须完全一致）：</p>\n<pre><code class=\"language-bash\">\ntransformers: 4.48.3\ntokenizers: 0.21.4\nhuggingface-hub: 0.25.2\n</code></pre>\n<p>如果输出的版本不一致，重新执行步骤 4 的安装命令，确保版本正确。</p>\n<h2 id=\"步骤-5禁用-modelscope-自动依赖安装核心避坑操作\">步骤 5：禁用 ModelScope 自动依赖安装（核心避坑操作）</h2>\n<p>这是最关键的避坑步骤！ModelScope 加载 OFA 模型时，会自动检查依赖版本，如果发现版本和它硬编码的要求不一致，会直接卸载你的版本并强制安装指定版本——哪怕你已经安装了正确的版本，也会被覆盖，导致之前的努力白费。</p>\n<p>所以，我们需要设置环境变量，禁用 ModelScope 自动安装/升级依赖，执行以下命令：</p>\n<pre><code class=\"language-bash\">\n# 禁用 ModelScope 自动安装依赖（临时生效，仅当前终端会话）\nexport MODELSCOPE_AUTO_INSTALL_DEPENDENCY='False'\nexport PIP_NO_INSTALL_UPGRADE=1\nexport PIP_NO_DEPENDENCIES=1\n</code></pre>\n<p>⚠️ 注意：如果后续新开终端、重新激活虚拟环境，需要重新执行上面的命令（临时生效）；如果想永久生效，执行以下命令（写入 bash 配置文件）：</p>\n<pre><code class=\"language-bash\">\n# 永久禁用自动依赖安装（重启终端、重新激活环境也生效）\necho \"export MODELSCOPE_AUTO_INSTALL_DEPENDENCY='False'\" &gt;&gt; ~/.bashrc\necho \"export PIP_NO_INSTALL_UPGRADE=1\" &gt;&gt; ~/.bashrc\necho \"export PIP_NO_DEPENDENCIES=1\" &gt;&gt; ~/.bashrc\n\n# 使配置生效\nsource ~/.bashrc\n</code></pre>\n<h2 id=\"步骤-6准备测试图片和运行脚本直观版新手友好\">步骤 6：准备测试图片和运行脚本（直观版，新手友好）</h2>\n<p>脚本是核心，之前踩过「输入格式错误」的坑，所以这里直接给大家整理好「可直接运行、输出简洁、容错性强」的脚本，只需修改图片路径和问题即可。</p>\n<h3 id=\"61-准备测试图片\">6.1 准备测试图片</h3>\n<p>将任意一张测试图片（jpg/png 格式均可）放到工作目录下，命名为 <code>test_image.jpg</code>（比如一张瓶子、猫、风景的图片）；如果没有本地图片，也可以用在线公开图片 URL（脚本已兼容）。</p>\n<h3 id=\"62-创建运行脚本testpy\">6.2 创建运行脚本（test.py）</h3>\n<p>在工作目录下创建 <code>test.py</code> 脚本，复制以下代码（注释清晰，可直接修改）：</p>\n<pre><code class=\"language-python\">\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nOFA 视觉问答（VQA）模型 运行脚本（直观版，新手友好）\n功能：输入本地图片/在线图片 + 英文问题，输出模型推理结果\n使用说明：只需修改【核心配置区】的图片路径和问题，无需修改其他代码\n\"\"\"\nimport os\nimport sys\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom modelscope.pipelines import pipeline\nfrom modelscope.utils.constant import Tasks\n\n# ======================== 核心配置区（只需改这里，新手重点关注）========================\n# 1. 图片来源：二选一（本地路径优先级更高，推荐用本地图片）\nLOCAL_IMAGE_PATH = \"./test_image.jpg\"  # 本地图片路径（工作目录下的图片，如：./cat.jpg、./bottle.png）\n# ONLINE_IMAGE_URL = \"https://picsum.photos/600/400\"  # 备用：公开测试图片URL（无需下载，直接加载）\n\n# 2. 问答问题（⚠️ 注意：该模型仅支持英文提问，中文问题会输出无意义结果）\nVQA_QUESTION = \"What is the main subject in the picture?\"  # 示例1：图片的主要物体是什么？\n# VQA_QUESTION = \"What color is the object?\"  # 示例2：物体是什么颜色？\n# VQA_QUESTION = \"How many objects are there in the picture?\"  # 示例3：图片中有多少个物体？\n\n# ======================== 工具函数（无需修改，封装好的功能）========================\ndef check_image_exists(path):\n    \"\"\"检查本地图片是否存在，避免路径错误导致加载失败\"\"\"\n    if not os.path.exists(path):\n        print(f\"❌ 错误：本地图片文件不存在 → {path}\")\n        print(\"请检查图片路径是否正确，或替换为有效的图片文件！\")\n        sys.exit(1)\n\ndef load_image(image_source):\n    \"\"\"加载图片（兼容本地路径和在线URL），返回PIL.Image对象（模型要求的输入格式）\"\"\"\n    try:\n        # 优先加载本地图片\n        if os.path.exists(image_source):\n            check_image_exists(image_source)\n            img = Image.open(image_source).convert('RGB')  # 转为RGB格式，避免灰度图报错\n            print(f\"✅ 成功加载本地图片 → {image_source}\")\n        # 加载在线图片（备用，避免本地图片缺失）\n        elif image_source.startswith(('http://', 'https://')):\n            response = requests.get(image_source, timeout=10)  # 超时时间10秒\n            response.raise_for_status()  # 检查URL是否可访问（避免403/404错误）\n            img = Image.open(BytesIO(response.content)).convert('RGB')\n            print(f\"✅ 成功加载在线图片 → {image_source}\")\n        else:\n            raise ValueError(\"❌ 图片来源错误：必须是本地路径或合法的HTTP/HTTPS URL！\")\n        return img\n    except Exception as e:\n        print(f\"❌ 图片加载失败：{str(e)}\")\n        sys.exit(1)\n\ndef init_vqa_model():\n    \"\"\"初始化OFA VQA模型管道，核心函数（无需修改）\"\"\"\n    try:\n        # 再次确认禁用自动依赖安装（双重保险，避免环境变量失效）\n        os.environ['MODELSCOPE_AUTO_INSTALL_DEPENDENCY'] = 'False'\n        os.environ['PIP_NO_INSTALL_UPGRADE'] = '1'\n        \n        # 创建VQA模型管道（⚠️ trust_remote_code=True必须加，适配OFA模型的自定义逻辑）\n        vqa_pipe = pipeline(\n            task=Tasks.visual_question_answering,  # 任务类型：视觉问答\n            model='iic/ofa_visual-question-answering_pretrain_large_en',  # 模型名称\n            model_revision='v1.0.0',  # 模型版本（固定v1.0.0，避免版本兼容问题）\n            trust_remote_code=True  # 关键参数：允许加载模型的自定义代码\n        )\n        print(\"✅ OFA VQA模型初始化成功！（首次运行会自动下载模型，耗时稍长，耐心等待）\")\n        return vqa_pipe\n    except Exception as e:\n        print(f\"❌ 模型初始化失败：{str(e)}\")\n        sys.exit(1)\n\n# ======================== 主逻辑（无需修改，执行推理）========================\nif __name__ == \"__main__\":\n    # 打印标题，直观区分输出\n    print(\"=\"*60)\n    print(\"📸 OFA 视觉问答（VQA）模型 - 运行工具\")\n    print(\"=\"*60)\n    \n    # 1. 初始化OFA VQA模型（首次运行会自动下载模型，约几百MB，耐心等待）\n    vqa_model = init_vqa_model()\n    \n    # 2. 确定图片来源（优先本地，本地不存在则用在线URL）\n    image_source = LOCAL_IMAGE_PATH if os.path.exists(LOCAL_IMAGE_PATH) else globals().get(\"ONLINE_IMAGE_URL\", \"\")\n    if not image_source:\n        print(\"❌ 错误：未配置有效的图片来源！请修改【核心配置区】的图片路径/URL\")\n        sys.exit(1)\n    \n    # 3. 加载图片（转为模型要求的PIL.Image对象）\n    img = load_image(image_source)\n    \n    # 4. 执行模型推理（核心步骤）\n    print(f\"\\n🤔 提问：{VQA_QUESTION}\")\n    print(\"🔍 模型推理中...（推理速度取决于电脑配置，约1-5秒）\")\n    try:\n        # 模型输入格式：(PIL.Image对象, 英文问题文本) → 元组格式（重点！不能用字典）\n        result = vqa_model((img, VQA_QUESTION))\n        \n        # 简化输出（只提取核心答案，去掉冗余信息，新手更直观）\n        answer = result.get(\"text\", [\"No answer found\"])[0]  # 提取最置信的第一个答案\n        print(\"\\n\" + \"=\"*60)\n        print(f\"✅ 推理成功！\")\n        print(f\"📷 图片：{image_source}\")\n        print(f\"🤔 问题：{VQA_QUESTION}\")\n        print(f\"✅ 答案：{answer}\")\n        print(\"=\"*60)\n        \n    except Exception as e:\n        print(f\"\\n❌ 推理失败：{type(e).__name__} - {str(e)}\")\n        sys.exit(1)\n</code></pre>\n<h2 id=\"步骤-7运行脚本查看推理结果\">步骤 7：运行脚本，查看推理结果</h2>\n<p>所有准备工作完成后，执行以下命令运行脚本：</p>\n<pre><code class=\"language-bash\">\npython test.py\n</code></pre>\n<p>⚠️ 注意：首次运行脚本时，模型会自动从 ModelScope 下载（约几百MB），耗时稍长，耐心等待即可；后续运行会复用已下载的模型，速度会很快。</p>\n<p>运行成功后，输出如下（直观简洁，新手能快速看到结果）：</p>\n<pre><code class=\"language-bash\">\n============================================================\n📸 OFA 视觉问答（VQA）模型 - 运行工具\n============================================================\n✅ OFA VQA模型初始化成功！（首次运行会自动下载模型，耗时稍长，耐心等待）\n✅ 成功加载本地图片 → ./test_image.jpg\n\n🤔 提问：What is the main subject in the picture?\n🔍 模型推理中...（推理速度取决于电脑配置，约1-5秒）\n\n============================================================\n✅ 推理成功！\n📷 图片：./test_image.jpg\n🤔 问题：What is the main subject in the picture?\n✅ 答案：a water bottle\n============================================================\n</code></pre>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p>到这里，OFA 视觉问答模型就部署成功并运行啦！</p>\n<h1 id=\"四部署过程中遇到的所有坑现象原因解决方案\">四、部署过程中遇到的所有坑（现象+原因+解决方案）</h1>\n<p>这部分是重点！我把部署过程中踩过的所有坑都整理出来，每个坑都对应「现象+原因+解决方案」，大家遇到相同问题时，直接对照解决即可，节省时间。</p>\n<h2 id=\"坑1依赖版本冲突最常见踩了3次\">坑1：依赖版本冲突（最常见，踩了3次）</h2>\n<h3 id=\"现象1importerror-tokenizers020021-is-required\">现象1：ImportError: tokenizers&gt;=0.20,&lt;0.21 is required...</h3>\n<pre><code class=\"language-bash\">\nImportError: tokenizers&gt;=0.20,&lt;0.21 is required for a normal functioning of this module, but found tokenizers==0.19.1.\n</code></pre>\n<p>原因：transformers 版本和 tokenizers 版本不匹配（比如 transformers 4.46.1 要求 tokenizers 0.20.x，而安装了 0.19.1）。</p>\n<p>解决方案：卸载当前 tokenizers，安装对应版本（比如 transformers 4.46.1 → tokenizers 0.20.1；transformers 4.48.3 → tokenizers 0.21.4），命令：</p>\n<pre><code class=\"language-bash\">\npip uninstall -y tokenizers\npip install tokenizers==0.21.4  # 对应transformers 4.48.3\n</code></pre>\n<h3 id=\"现象2importerror-cannot-import-name-gguf_config_mapping-from-transformersintegrations\">现象2：ImportError: cannot import name 'GGUF_CONFIG_MAPPING' from 'transformers.integrations'</h3>\n<pre><code class=\"language-bash\">\nImportError: OfaForAllTasks: cannot import name 'GGUF_CONFIG_MAPPING' from 'transformers.integrations'\n</code></pre>\n<p>原因：transformers 版本过低（比如 4.38.2），该版本的 integrations 模块中没有导出 GGUF_CONFIG_MAPPING，而模型代码引用了这个变量。</p>\n<p>解决方案：安装 transformers 4.48.3（ModelScope 硬编码要求，兼容 GGUF_CONFIG_MAPPING），命令：</p>\n<pre><code class=\"language-bash\">\npip uninstall -y transformers\npip install transformers==4.48.3\n</code></pre>\n<h3 id=\"现象3运行脚本时依赖被自动卸载并重新安装\">现象3：运行脚本时，依赖被自动卸载并重新安装</h3>\n<p>原因：没有禁用 ModelScope 自动依赖安装，ModelScope 检测到依赖版本和它硬编码的要求不一致，会自动卸载你的版本并强制安装指定版本。</p>\n<p>解决方案：设置环境变量，禁用自动依赖安装（参考步骤 5），临时生效或永久生效均可。</p>\n<h2 id=\"坑2图片加载失败403-forbidden-错误\">坑2：图片加载失败（403 Forbidden 错误）</h2>\n<h3 id=\"现象requestsexceptionshttperror-403-client-error-forbidden-for-url-\">现象：requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: ...</h3>\n<pre><code class=\"language-bash\">\nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/test/images/visual_question_answering.png\n</code></pre>\n<p>原因：使用了 ModelScope 官方的测试图片 URL，该 URL 权限变更或失效，无法访问（403 权限拒绝）。</p>\n<p>解决方案：替换为本地图片或公开可访问的在线图片 URL，脚本已兼容两种图片来源（参考步骤 6.1 和 6.2）。</p>\n<h2 id=\"坑3输入格式错误text-相关错误\">坑3：输入格式错误（'text' 相关错误）</h2>\n<h3 id=\"现象运行出错text-或-keyerror-text\">现象：运行出错：'text' 或 KeyError: 'text'</h3>\n<p>原因：模型输入格式不符合要求，OFA VQA 模型要求输入为「(PIL.Image对象, 英文问题文本)」的元组格式，而不是字典（比如 {'image': ..., 'question': ...}）。</p>\n<p>解决方案：按照脚本中的格式，将输入改为元组（PIL.Image对象 + 问题文本），脚本已封装好该逻辑，无需手动修改（参考步骤 6.2 中的主逻辑部分）。</p>\n<h2 id=\"坑4模型初始化失败缺少-trust_remote_codetrue\">坑4：模型初始化失败（缺少 trust_remote_code=True）</h2>\n<h3 id=\"现象模型初始化时报错无法加载自定义代码或模型结构不匹配\">现象：模型初始化时，报错“无法加载自定义代码”或“模型结构不匹配”</h3>\n<p>原因：OFA 模型有自定义的预处理和推理逻辑，创建 pipeline 时没有添加 trust_remote_code=True 参数，无法加载这些自定义代码。</p>\n<p>解决方案：创建 pipeline 时，添加 trust_remote_code=True 参数（参考步骤 6.2 中的 init_vqa_model 函数）。</p>\n<h2 id=\"坑5警告信息干扰非错误可忽略\">坑5：警告信息干扰（非错误，可忽略）</h2>\n<h3 id=\"现象运行脚本时出现以下警告信息\">现象：运行脚本时，出现以下警告信息</h3>\n<pre><code class=\"language-bash\">\n# 警告1：pkg_resources 弃用警告\nUserWarning: pkg_resources is deprecated as an API. See ...\n\n# 警告2：TRANSFORMERS_CACHE 弃用警告\nFutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers.\n\n# 警告3：TensorFlow 相关警告（cuDNN、cuFFT 等）\nE external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: ...\n</code></pre>\n<p>原因：这些都是非功能性警告，不影响模型运行——pkg_resources 弃用是 ModelScope 的依赖问题，TRANSFORMERS_CACHE 弃用是 transformers 的版本提示，TensorFlow 警告是缺少相关插件（不影响 CPU 推理）。</p>\n<p>解决方案：直接忽略，无需处理，不影响模型的推理功能。</p>\n<h1 id=\"五总结与后续优化建议\">五、总结与后续优化建议</h1>\n<h2 id=\"1-部署总结\">1. 部署总结</h2>\n<p>本次 OFA 视觉问答模型部署的核心要点：</p>\n<ul>\n<li>\n<p>环境隔离：必须用虚拟环境，避免依赖冲突；</p>\n</li>\n<li>\n<p>版本匹配：transformers4.48.3 + tokenizers0.21.4 + huggingface-hub==0.25.2，版本不能改；</p>\n</li>\n<li>\n<p>禁用自动依赖：设置环境变量，避免 ModelScope 自动覆盖依赖版本；</p>\n</li>\n<li>\n<p>输入格式：必须是（PIL.Image对象, 英文问题）的元组格式；</p>\n</li>\n<li>\n<p>图片来源：避免使用失效的 URL，优先用本地图片。</p>\n</li>\n</ul>\n<p>按照上面的步骤操作，就能成功部署并运行模型，输出正确的视觉问答结果。</p>\n<h2 id=\"2-后续优化建议\">2. 后续优化建议</h2>\n<ul>\n<li>\n<p>永久设置环境变量：将禁用自动依赖的命令写入 ~/.bashrc，避免每次新开终端都要重新执行；</p>\n</li>\n<li>\n<p>支持中文问答：本次使用的是英文模型，可替换为中文 OFA 模型（如 <code>iic/ofa_visual-question-answering_pretrain_large_zh</code>），问题可改为中文；</p>\n</li>\n<li>\n<p>优化推理速度：如果电脑有 GPU，可安装 CUDA、PyTorch GPU 版本，推理速度会比 CPU 快 5-10 倍；</p>\n</li>\n<li>\n<p>批量推理：修改脚本，支持批量输入图片和问题，批量输出结果，提高效率。</p>\n</li>\n</ul>\n<h1 id=\"六最后\">六、最后</h1>\n<p>以上就是 OFA 视觉问答模型部署的完整教学，从环境准备到脚本运行，再到避坑指南，每一步都详细标注，新手也能轻松复现。如果大家在部署过程中遇到其他问题，欢迎在评论区留言，我会及时回复～</p>\n<p>祝大家部署顺利，早日用上 OFA 模型实现视觉问答功能！🚀</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 01:04</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}