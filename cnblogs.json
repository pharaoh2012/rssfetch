{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "JuiceFS 2025：迈入千亿文件规模，开源第五年持续高速增长",
      "link": "https://www.cnblogs.com/JuiceData/p/19443029",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/JuiceData/p/19443029\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 14:58\">\n    <span>JuiceFS 2025：迈入千亿文件规模，开源第五年持续高速增长</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>又到了给大家汇报全年社区工作的时候。2025 年， JuiceFS 企业版发布的第九年，社区版的第五年。这一年，我们专注一如既往，打造一款高效易用的文件系统。</p>\n<p>各项使用指标延续了上一年的增长势头，<strong>社区版数据量增长 89%，超 1.3 EB；营收连续第三年 100% 增长</strong>，是我们持续投入社区的坚实保障。</p>\n<p>2025 年，JuiceFS 社区版继续聚焦通用性，尤其在支持各类  AI 场景的需求。发布了 Python SDK、增强 Windows 客户端可用性，并加强了对云原生生态的支持；此外，元数据引擎 SQL 和 TiKV 也进行了针对性优化。今年，团队与社区成员一道推动了 JuiceFS 的持续迭代，共有 60 位贡献者参与，新增了 305 个 Issue，合并了 601 个 PR。</p>\n<p>在企业版的开发过程中，团队今年面临的最大挑战来自于<strong>超大规模数据的管理</strong>。随着自动驾驶等 AI 技术逐渐融入日常生活，数据规模的增长是空前的，在千亿文件级别下，元数据管理、数据一致性等方面的管理复杂度指数级增加。为应对这些难题，企业版在元数据分区、网络性能等核心特性上进行了全面升级。<strong>上半年发布的企业版 5.2 已支持单卷千亿规模，即将发布的 5.3 版本更将支持 5,000 亿规模</strong>，让用户不必再为数据规模发愁，JuiceFS 的性能和稳定性也都能够稳妥保障。</p>\n<h2 id=\"01-社区版支持-python-sdk-windows-客户端可用性大幅提升\">01 社区版：支持 Python SDK、 Windows 客户端可用性大幅提升</h2>\n<p>JuiceFS 自开源以来已在企业生产环境中得到了长时间的验证，核心功能逐步趋于稳定。全年发布了 9 个版本，其中 1.3 版本是继 2021 年开源以来的第四个重要版本，并作为长期支持版本（LTS）。该版本的主要优化包括：</p>\n<ul>\n<li><strong>支持 Python SDK</strong> ，提升了 AI 和数据科学场景下的灵活性和性能；</li>\n<li><strong>Windows 客户端的优化</strong>，增强了工具支持和系统服务挂载能力；</li>\n<li><strong>备份机制优化</strong>，1 亿文件备份分钟级完成；</li>\n<li><strong>集成 Apache Ranger</strong>，JuiceFS 支持大数据场景中的细粒度的权限管理；</li>\n<li><strong>元数据引擎方面，SQL 和 TiKV 的性能提升</strong>，在超大规模场景下表现更加高效。</li>\n</ul>\n<p>下半年，团队开始积极筹备 1.4 ，计划新增多个特性，包括用户和用户组 Quota 支持、Redis 客户端缓存支持、LRU 缓存支持、SMB/CIFS 支持、Hadoop Kerberos 支持、S3 Gateway 优化、Sync 工具断点续传，数据商业算法加密支持，预读策略优化、批量删除优化和周边工具优化等 ，以进一步提升系统的性能和稳定性。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>JuiceFS CSI Driver 在过去一年发布了 18 个版本，持续优化 JuiceFS 在 Kubernetes 等环境中的存储效率和稳定性。新增功能包括卷路径健康状态检测、同一文件系统共享 Mount Pod 功能、支持 Kubernetes 原生 Sidecar，以及 Dashboard 的 CacheGroup 管理。此外，还进行了性能和可靠性优化，不仅提升了稳定性，同时改进了多 Pod 配置和容器化应用的兼容性。</p>\n<p>JuiceFS Operator，新增了定时缓存预热 功能，提升业务访问数据的性能；支持按副本部署的 CacheGroup，实现了缓存高可用性；并引入 Sync 功能，在 Kubernetes 环境中高效同步数据，确保一致性。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h2 id=\"02-企业版单卷千亿规模文件强劲性能与稳定性保障\">02 企业版：单卷千亿规模文件，强劲性能与稳定性保障</h2>\n<p>2025 年上半年，JuiceFS 企业版 5.2 版本发布，单个文件系统突破千亿文件的规模，并显著提升了超大规模集群的稳定性和分布式缓存的网络性能。为了实现这一目标，团队投入了大量时间和精力进行优化，特别是在处理超大数据集和高并发访问时的性能提升。<strong>该版本已在多个企业的生产环境中得到验证，单卷千亿文件规模下保持 1 毫秒元数据时延水平</strong>。同时，分布式缓存网络性能优化，TCP 网络下大幅减少 CPU 开销，同时提升网络带宽利用率。<strong>在 100 台 GCP 100Gbps 节点的环境下，聚合读带宽达到 1.2 TB/s，接近满负荷利用 TCP/IP 网络带宽</strong>。</p>\n<p>此外， Python SDK 实现了 fsspec 兼容、按需导入对象存储文件，可以更方便的访问对象存储存量数据、解决特殊场景中的读放大问题以及提升全局 QoS 能力，进一步增强了系统的灵活性和性能。</p>\n<p>多分区架构是 JuiceFS 应对千亿文件规模的关键技术之一，保证了系统的高扩展性和高并发处理能力。<strong>下半年我们的核心工作集中在 5.3 版本，对多分区架构进行了全面优化，分区限制从 256 个提升至 1,024 个，可实现单卷超过 5,000 亿文件的存储和访问需求</strong>。</p>\n<p>这背后是一系列复杂的工作，包括系统化整理跨分区链接实现，并实现后台自检机制，提升集群的可靠性与稳定性；开发热点监测与自动迁移工具，高效处理热点问题；优化分布式缓存管理，减少缓存冲突并提高并发性能；此外，为了进一步优化分布式网络的性能，在这个版本中首次引入了 RDMA 技术，目前处于实验阶段，测试结果显示其在稳定性和 CPU 使用率方面优于 TCP 协议。5.3 版本将于 1 月发布，更多细节，欢迎关注。</p>\n<h2 id=\"03-社区发展第-5-年高速成长数据总量超-13eb\">03 社区发展，第 5 年高速成长，数据总量超 1.3EB</h2>\n<p>目前，JuiceFS GitHub star 超 12.6K；JuiceFS 下载量突破了 5 万次，CSI Driver 的下载量超过了 500 万次；中文社区已经有 10 个微信群组，Slack 英文社区也达千人。</p>\n<p>社区版开源的第 5 年，也是快速增长的第 5 个年头。用户上报数据显示，JuiceFS 的各项关键数据延续了增长趋势：</p>\n<ul>\n<li>文件系统 590K+，增长 82%</li>\n<li>活跃客户端 150K+，增长 46%</li>\n<li>文件数量 4000 亿+，增长 43%</li>\n<li>数据总量 1.3EiB+，增长 89%</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>今年，我们在多个行业大会分享实践，KCD 、开源年会、CommunityOverCode Asia 等，感谢这些大会主办方对 JuiceFS 的认可；在海外行业会议也展露头脚，参与了 KubeCon+CloudNative Con North America、Opensource Summit Japan、SNIA Developer Conference 等。</p>\n<p>为了更好地为用户提供支持，我们定期举办 Office Hours，介绍新功能、解答疑问；同时，举办了 11 场 Meetup，帮助不同行业的用户更有信心地将 JuiceFS 应用于生产环境。案例涵盖自动驾驶、生成式 AI、AI 基础平台、量化投资、生命医药等多个领域。（查看所有<a href=\"https://juicefs.com/zh-cn/blog/user-stories\" rel=\"noopener nofollow\" target=\"_blank\">案例</a>）</p>\n<p>特别感谢以下今年参与分享的用户，他们的实践经验为社区提供了宝贵的参考：</p>\n<ol>\n<li>丁聪，Lepton AI，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/lepton-ai-build-multi-tenant-low-latency-cloud-storage-platform\" rel=\"noopener nofollow\" target=\"_blank\">加速 AI 训推：构建多租户、低延迟云存储平台 </a></li>\n<li>孙玮，中国科学院计算所，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/nfs-vs-juicefs-llm-storage\" rel=\"noopener nofollow\" target=\"_blank\">基于 JuiceFS 的大模型训推平台存储演进之路</a></li>\n<li>郑泽东，百图生科，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/biomap-juicefs-building-llm-storage\" rel=\"noopener nofollow\" target=\"_blank\">基于 JuiceFS 构建生命科学大模型存储平台，成本降 90%</a></li>\n<li>吴松林，携程，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/trip-10pb-level-llm-stroage-juicefs-practice\" rel=\"noopener nofollow\" target=\"_blank\">稳定且高性价比的大模型存储：携程 10PB 级 JuiceFS 工程实践</a></li>\n<li>唐义凡，合合信息，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/intsig-use-juicefs-build-unified-storage-support-pb-ai-training\" rel=\"noopener nofollow\" target=\"_blank\">基于 JuiceFS 构建统一存储，支撑 PB 级 AI 训练</a></li>\n<li>缪昌新，阶跃星辰，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/stepfun-ai-use-juicefs-create-multimodal-learning-storage-platform\" rel=\"noopener nofollow\" target=\"_blank\">如何利用 JuiceFS 打造高效经济的大模型存储平台</a></li>\n<li>可加，稿定科技，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/gaoding-ai-storage-challenges-multi-cloud-juicefs\" rel=\"noopener nofollow\" target=\"_blank\">多云架构下的 AI 存储挑战与 JuiceFS 实践</a></li>\n<li>邓君宇，九识智能，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/intsig-juicefs-autonomous-driving-multi-cloud-storage\" rel=\"noopener nofollow\" target=\"_blank\">基于 JuiceFS 的自动驾驶多云亿级文件存储</a></li>\n<li>高玉堂， Ariste AI，<a href=\"https://juicefs.com/zh-cn/blog/user-stories/juicefs-minio-ariste-ai-quant-storage\" rel=\"noopener nofollow\" target=\"_blank\">JuiceFS + MinIO：量化投资高性能存储实践</a></li>\n<li>李威宇，光影焕像，基于 JuiceFS 搭建 3D AIGC 存储平台，数据性能 2 倍提升</li>\n<li>刘道全，始智 AI，基于 JuiceFS 打造高性能、低成本 AI 模型管理存储平台</li>\n<li>高杨，酷睿程，自动驾驶百 PB 级云原生存储案例</li>\n<li>曾奥涵，智谱 AI，大模型训练基础设施落地实践</li>\n</ol>\n<p>亲爱的社区伙伴们，我们一起度过了充实的一年。JuiceFS 从一个开源新秀，成长为今天 AI 业务中备受信任的选择，衷心感谢每一位社区成员的参与与支持，感谢你们在群里解答问题、分享实践、贡献代码！</p>\n<p>新的一年里，JuiceFS 将继续为你的工作带来更高效、更轻松的体验。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 14:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/JuiceData\">JuiceFS</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "分表路由：为什么大神都用 & (n-1)，而不用 % ？一次给你讲透",
      "link": "https://www.cnblogs.com/xzqcsj/p/19442863",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzqcsj/p/19442863\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 14:30\">\n    <span>分表路由：为什么大神都用 &amp; (n-1)，而不用 % ？一次给你讲透</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>写在前面</strong></p>\n<p>\"分库分表\"大家都不陌生。当数据量激增时，我们习惯性地写下 <code>userId % tableCount</code> 来决定数据路由到哪张表。</p>\n<p>这段代码逻辑正确、简单直观。但在对性能要求极高的底层中间件开发中，这真的是最优解吗？</p>\n<p>如果我们翻开 <strong>JDK 1.8 的 HashMap 源码</strong>，会发现大神 Doug Lea 在计算数组下标时，刻意避开了 <code>%</code> 取模，而是使用了一行看起来更晦涩的 <code>&amp; (n - 1)</code>。</p>\n<p>今天，我们就把 HashMap 的这项底层“绝技”移植到业务系统的分表组件中，打造一个<strong>高性能、可扩展且具备防御性</strong>的路由工具。</p>\n</blockquote>\n<hr />\n<h2 id=\"一-从一次-code-review-说起\">一、 从一次 Code Review 说起</h2>\n<p>最近在审查新版分表中间件的代码时，看到了一段非常标准的分表路由逻辑：</p>\n<pre><code class=\"language-java\">// ❌ 常见的写法\npublic String getTableName(int userId) {\n    // 假设分32张表\n    int tableIndex =  userId % 32; \n    return \"t_order_\" + tableIndex;\n}\n</code></pre>\n<p>这段代码在功能上没有问题。但作为一个对底层细节有追求的工程师，我不禁想到了 HashMap 的实现。</p>\n<p>打开 JDK 源码，在 <code>HashMap.put</code> 方法中，计算节点落槽位置的代码是这样的：</p>\n<pre><code class=\"language-java\">// HashMap源码片段\nif ((p = tab[i = (n - 1) &amp; hash]) == null) ...\n</code></pre>\n<p>Doug Lea 并没有使用直观的 <code>hash % n</code>，而是使用了与运算 <code>&amp;</code>。</p>\n<p><strong>为什么？</strong><br />\n根本原因在于 CPU 的指令执行效率：</p>\n<ul>\n<li><strong>位运算（&amp;, |, ^, ~）</strong>：直接对应 CPU 底层指令，通常只需 <strong>1 个时钟周期</strong>。</li>\n<li><strong>取模运算（%）</strong>：涉及除法操作，在底层硬件实现上极其复杂，通常消耗 <strong>10-30 个时钟周期</strong>。</li>\n</ul>\n<p>虽然在普通的业务逻辑中，几十个时钟周期的差异可以忽略不计。但在<strong>高频触发</strong>的基础设施层（如网关路由、分表中间件、缓存寻址），这种微小的性能差异在高并发下会被显著放大。</p>\n<hr />\n<h2 id=\"二-揭秘位运算的物理意义\">二、 揭秘位运算的物理意义</h2>\n<p>HashMap 能用 <code>&amp;</code> 替代 <code>%</code>，有一个<strong>强制性的前提条件</strong>：</p>\n<blockquote>\n<p><strong>数组长度（或分表数）必须是 2 的 n 次幂</strong>（2, 4, 8, 16, 32, 64...）</p>\n</blockquote>\n<h3 id=\"1-数学原理\">1. 数学原理</h3>\n<p><strong>公式</strong>：<br />\n当 <code>n = 2^k</code> 时，<code>X % n</code> 等价于 <code>X &amp; (n - 1)</code></p>\n<p>这个公式背后的逻辑，从<strong>二进制</strong>视角来看会非常清晰。</p>\n<p>假设分表数 <code>n = 8</code>（即 2³）。<br />\n那么 <code>n - 1 = 7</code>。</p>\n<ul>\n<li><strong>8 的二进制</strong>：<code>... 0000 1000</code></li>\n<li><strong>7 的二进制</strong>：<code>... 0000 0111</code> （低三位全为1，高位全为0）</li>\n</ul>\n<p>当我们计算 <code>userId &amp; 7</code> 时，实际上是在进行<strong>位掩码（BitMask）</strong>操作。<br />\n因为 7 的高位全是 0，<code>&amp;</code> 运算会将 userId 的所有高位清零，只<strong>完整保留最后三位</strong>。</p>\n<p><strong>而一个数值的低 k 位，恰恰就是它对 2^k 取模的余数。</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">userId (十进制)</th>\n<th style=\"text-align: left;\">userId (二进制)</th>\n<th style=\"text-align: left;\">&amp; 0111 (掩码)</th>\n<th style=\"text-align: left;\">结果</th>\n<th style=\"text-align: left;\">% 8 结果</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>10</strong></td>\n<td style=\"text-align: left;\"><code>... 0000 1010</code></td>\n<td style=\"text-align: left;\"><code>0010</code></td>\n<td style=\"text-align: left;\"><strong>2</strong></td>\n<td style=\"text-align: left;\"><strong>2</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>15</strong></td>\n<td style=\"text-align: left;\"><code>... 0000 1111</code></td>\n<td style=\"text-align: left;\"><code>0111</code></td>\n<td style=\"text-align: left;\"><strong>7</strong></td>\n<td style=\"text-align: left;\"><strong>7</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>16</strong></td>\n<td style=\"text-align: left;\"><code>... 0001 0000</code></td>\n<td style=\"text-align: left;\"><code>0000</code></td>\n<td style=\"text-align: left;\"><strong>0</strong></td>\n<td style=\"text-align: left;\"><strong>0</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>17</strong></td>\n<td style=\"text-align: left;\"><code>... 0001 0001</code></td>\n<td style=\"text-align: left;\"><code>0001</code></td>\n<td style=\"text-align: left;\"><strong>1</strong></td>\n<td style=\"text-align: left;\"><strong>1</strong></td>\n</tr>\n</tbody>\n</table>\n<p><strong>结论</strong>：只要分表数是 2 的幂，<strong>位运算本质上就是一次高效的低位截取</strong>。它能在硬件层面以最快的速度得到我们想要的结果。</p>\n<hr />\n<h2 id=\"三-实战打造生产级路由工具\">三、 实战：打造生产级路由工具</h2>\n<p>原理虽然简单，但要落地到生产环境，必须考虑工程化问题：<strong>如何防止后续维护者错误配置分表数？如何保证代码的健壮性？</strong></p>\n<p>这里我们推荐使用 <strong>防御性编程 + 枚举约束</strong> 的方式。</p>\n<h3 id=\"1-定义分表策略枚举\">1. 定义分表策略枚举</h3>\n<p>我们通过枚举（Enum）将分表规则固定下来，并在枚举构造器中进行严格校验。</p>\n<pre><code class=\"language-java\">@Getter\n@AllArgsConstructor\npublic enum TableStrategyEnum {\n    /** 订单表：分32张 */\n    ORDER(\"t_order_\", 32),\n    \n    /** 支付流水表：分64张 */\n    PAYMENT(\"t_pay_flow_\", 64);\n\n    private final String prefix;\n    private final int count;\n    \n    // 构造时进行 Fail-Fast 检查\n    // 如果配置的不是 2 的幂，应用启动时就会直接抛错，阻止由于配置失误导致的上线事故\n    TableStrategyEnum(String prefix, int count) {\n        if (count &lt;= 0 || (count &amp; (count - 1)) != 0) {\n            throw new Error(\"配置错误：Strategy [\" + prefix + \"] 分表数必须是 2 的幂！\");\n        }\n        this.prefix = prefix;\n        this.count = count;\n    }\n}\n</code></pre>\n<h3 id=\"2-封装核心路由工具类\">2. 封装核心路由工具类</h3>\n<pre><code class=\"language-java\">public class DivTableUtils {\n\n    /**\n     * 获取目标表名\n     * @param bizId 业务主键（如 userId, orderId）\n     * @param strategy 分表策略\n     */\n    public static String getTableName(int bizId, TableStrategyEnum strategy) {\n        // 1. 基础校验\n        if (bizId &lt;= 0) {\n            throw new IllegalArgumentException(\"业务ID必须为正整数\");\n        }\n        \n        // 2. 核心位运算逻辑\n        // 因为枚举构造里已经保证了 count 是 2 的幂，这里可以安全使用位运算\n        int index = bizId &amp; (strategy.getCount() - 1);\n        \n        // 3. 拼接返回\n        return strategy.getPrefix() + index;\n    }\n}\n</code></pre>\n<p><strong>使用示例</strong>：</p>\n<pre><code class=\"language-java\">// 业务代码中调用，清晰且安全\nString tableName = DivTableUtils.getTableName(user.getId(), TableStrategyEnum.ORDER);\n// 输出：t_order_5\n</code></pre>\n<hr />\n<h2 id=\"四-深度思考为什么要强制-2-的幂\">四、 深度思考：为什么要强制 2 的幂？</h2>\n<p>肯定有人会问：</p>\n<blockquote>\n<p>“我的业务规模刚好适合分 100 张表，为了用位运算强行改成 128 张，是不是这就叫过早优化？”</p>\n</blockquote>\n<p>这个问题直击要害。<br />\n事实上，HashMap 以及我们推荐的分表策略，强制使用 2 的幂次方，<strong>性能提升只是表象，真正的核心价值在于——扩容的平滑性</strong>。</p>\n<h3 id=\"扩容时的-rehash-魔法\">扩容时的 \"Rehash\" 魔法</h3>\n<p>通常分表扩容时，我们会将表数量翻倍（例如 16 -&gt; 32）。<br />\n如果我们使用传统的 <code>hash % n</code>，当 n 变化时，几乎所有数据的路由结果都会发生改变，这意味着我们需要迁移绝大部分数据。</p>\n<p><strong>但如果我们遵循 2 的幂次方扩容：</strong><br />\n从二进制角度看，<code>n</code> 从 16 (10000) 变为 32 (100000)，仅仅意味着<strong>位掩码多取了一位</strong>。</p>\n<p>对于任何一个 ID，其路由结果只有两种可能：</p>\n<ol>\n<li><strong>保持不变</strong>：如果新增的那一位是 0。</li>\n<li><strong>平移固定量</strong>：如果新增的那一位是 1，新坐标 = <code>原坐标 + 原长度</code>。</li>\n</ol>\n<p>这就是 HashMap 扩容时 rehash 极其高效的秘密。反映到数据库分表扩容上，这意味着我们<strong>有一半的数据完全不需要移动</strong>，这一点对于海量数据的迁移至关重要。</p>\n<hr />\n<h2 id=\"五-结语在比特世界里寻找优雅\">五、 结语：在比特世界里寻找优雅</h2>\n<p>计算机科学里有一句名言：<strong>\"Simple is Better\"</strong>。</p>\n<p>但\"简单\"往往有两个层次：<br />\n一个是<strong>无知的简单</strong>：随手写下 <code>id % n</code>，不管不顾。<br />\n一个是<strong>透彻的简单</strong>：理解了二进制的规律，用 <code>id &amp; (n-1)</code> 驾驭复杂。</p>\n<p><code>DivideTableUtils</code> 这个小工具，虽然只有寥寥几行代码，却折射出了优秀架构设计的三个维度：</p>\n<ol>\n<li><strong>对原理的极致利用</strong>（位运算加速）。</li>\n<li><strong>对错误的零容忍</strong>（Fail-Fast 校验）。</li>\n<li><strong>对未来的深远规划</strong>（Rehash 扩容）。</li>\n</ol>\n<p><strong>可以预见的是，当你的业务流量洪峰到来时，那些藏在比特世界里的每一次优化，都将成为系统最坚实的护盾。</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 14:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzqcsj\">一旅人</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【Windows】如何加密共享文件夹 - 基于CHFS项目",
      "link": "https://www.cnblogs.com/minuhy/p/19442799",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/minuhy/p/19442799\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 14:21\">\n    <span>【Windows】如何加密共享文件夹 - 基于CHFS项目</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文介绍了使用CHFS工具在Windows上加密共享文件夹的方法。该方案支持多平台使用，提供密码保护和SSL/HTTPS等安全功能，可实现类似本地磁盘的便捷文件共享体验。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"在windows上如何加密共享文件夹---基于chfs项目\">在Windows上如何加密共享文件夹 - 基于CHFS项目</h1>\n<h2 id=\"零需求\">零、需求</h2>\n<p>某位做财务的姐姐说希望加密共享一个文件夹，要求输入密码才能看到被共享的文件夹内容，使之能够与另外一位同事同步工作。遂问豆包，豆包推荐了几种解决方案，经过比对和考量后，决定使用CHFS作为本需求的解决方案，因为我平常上课也用此软件共享文件给学生，对这个熟悉一些，而且单文件，简单好用。下面介绍如何通过CHFS加密共享本地文件夹。</p>\n<h2 id=\"壹软件下载\">壹、软件下载</h2>\n<h3 id=\"1介绍\">1、介绍</h3>\n<p>下面是网站<a href=\"http://iscute.cn/chfs\" rel=\"noopener nofollow\" target=\"_blank\">http://iscute.cn/chfs</a>对CHFS的介绍：</p>\n<blockquote>\n<p>CHFS（CuteHttpFileServer/chfs）是一个免费的、HTTP协议的文件共享服务器，使用浏览器可以快速访问。它具有以下特点：</p>\n<ul>\n<li>单个文件，核心功能无需其他文件</li>\n<li>跨平台运行，支持主流平台：Windows，Linux和Mac</li>\n<li>界面简洁，简单易用</li>\n<li>支持扫码下载和手机端访问，手机与电脑之间共享文件非常方便</li>\n<li>支持账户权限控制和地址过滤</li>\n<li>支持快速分享文字片段</li>\n<li>支持webdav协议</li>\n</ul>\n<p>与其他常用文件共享方式（如FTP，飞秋，网盘，自己建站）相比，具有使用简单，适用场景更多的优点，在个人使用以及共享给他人的场景中非常方便快捷。</p>\n</blockquote>\n<h3 id=\"2下载\">2、下载</h3>\n<p>为了简单方便地使用，我们需要下载带图形界面的CHFS，即“CHFS GUI”，下面是下载方式：</p>\n<ul>\n<li>可以到<a href=\"http://iscute.cn/chfs\" rel=\"noopener nofollow\" target=\"_blank\">http://iscute.cn/chfs</a>中获取最新的下载链接，或者到其项目主页<a href=\"https://github.com/docblue/chfsgui\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/docblue/chfsgui</a>拉取包、代码等。</li>\n</ul>\n<p><img alt=\"iscute.cn百度网盘分享下载方式\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105113925869-1322579696.png\" /></p>\n<ul>\n<li>或者通过我的分享链接下载<a href=\"https://pan.baidu.com/s/5wpLtEc1l_T81_F4-OIj_Iw\" rel=\"noopener nofollow\" target=\"_blank\">https://pan.baidu.com/s/5wpLtEc1l_T81_F4-OIj_Iw</a>：</li>\n</ul>\n<p><img alt=\"我的百度网盘分享下载方式\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105115147349-877442224.png\" /></p>\n<p>下载后解压，得到如下文件：</p>\n<p><img alt=\"CHFS软件\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105115314846-15829564.png\" /></p>\n<h2 id=\"贰配置软件\">贰、配置软件</h2>\n<h3 id=\"1打开软件\">1、打开软件</h3>\n<p>打开软件，见到如下主界面</p>\n<p><img alt=\"CHFS-GUI主界面\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105115609470-387487333.png\" /></p>\n<p>我们需要重点关注“共享目录”、“监听端口”、“账户控制”和“≡”。</p>\n<h3 id=\"2设置共享目录\">2、设置共享目录</h3>\n<p>首先需要设置共享目录，我在当前文件夹“E:\\CHFS”下面再建一个“加密共享文件夹”</p>\n<p><img alt=\"创建加密共享文件夹\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105115950373-625046180.png\" /><br />\n我们在“加密共享”中放置一张要共享图片方便我们验证软件功能：<br />\n<img alt=\"共享图片\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105124250689-1418068550.png\" /><br />\n然后再在“CHFS-GUI”中配置共享此文件夹</p>\n<p><img alt=\"设置共享目录\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105120815350-769725516.png\" /><br />\n这样，在软件开启服务后，“E:\\CHFS\\加密共享”目录将被共享。</p>\n<h3 id=\"3设置权限\">3、设置权限</h3>\n<p>我们在“账户控制”中，修改“访客”的权限，把权限全部取消掉，这样“访客”无法访问到我们的“加密共享”目录</p>\n<p><img alt=\"删除访客权限\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105121530607-2064452981.png\" /><br />\n然后再添加一个带有密码的账户，作为访问“加密共享”目录的凭据</p>\n<p><img alt=\"添加账户\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105121929387-2093785785.png\" /></p>\n<h3 id=\"4启动服务\">4、启动服务</h3>\n<p>为了避免端口冲突，我们把“监听端口”修改为“<code>801</code>”<br />\n<img alt=\"修改监听端口\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105122037549-1693685736.png\" /><br />\n修改好后，我们点击左上角的“▶”键来启动服务器<br />\n<img alt=\"启动服务\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105122324260-609472643.png\" /><br />\n显示类似于如下右上角的访问链接后即表示启动成功~<br />\n<em>注：因为我连了两个网络，所以有4条链接，一般正常情况下是两条链接的。</em><br />\n<img alt=\"服务器启动成功\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105122307589-979050760.png\" /><br />\n我们需要关注这几个地址，其中，Website后面的地址是可以通过浏览器访问的，Webdav后面的地址我们是可以作为远程磁盘使用的。下面分别介绍如何使用。</p>\n<h2 id=\"叁基于浏览器使用共享目录任何支持浏览器的设备\">叁、基于浏览器使用共享目录（任何支持浏览器的设备）</h2>\n<p>我们把我们的Website局域网链接（我的是<a href=\"http://192.168.31.219:801\" rel=\"noopener nofollow\" target=\"_blank\">http://192.168.31.219:801</a>）给到在同一个网络下的其他主机，其他主机利用此链接通过浏览器访问我们的共享目录。</p>\n<h3 id=\"1打开目录\">1、打开目录</h3>\n<p>其他主机在浏览器中输入局域网链接，打开共享目录主页<br />\n<img alt=\"访客看不到内容\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105124800274-1800937150.png\" /><br />\n默认作为访客进入，是啥也没得的，因为我们设置了权限。我们需要登录才能看到和操作被共享的内容。</p>\n<h3 id=\"2登录\">2、登录</h3>\n<p>点击登录按钮，输入我们刚刚添加的账户<br />\n<img alt=\"登录\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105124747789-1809338932.png\" /><br />\n登录成功后即可对目录内容进行操作<br />\n<img alt=\"登录成功\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105125118050-1404026676.png\" /></p>\n<h2 id=\"肆基于磁盘映射使用共享目录windows\">肆、基于磁盘映射使用共享目录（Windows）</h2>\n<p>有时候在浏览器操作不是很方便对吧，我们希望这个共享目录能够像本地文件一样很方便地进行读写等操作，此时我们可以把共享目录映射为磁盘。</p>\n<h3 id=\"1系统配置修改\">1、系统配置修改</h3>\n<p>因为Windows本身系统的限制，无法直接映射“http”开头的Webdav磁盘，我们需要修改一下注册表，允许http链接挂载。按Windows + R键，打开“运行”，输入“<code>regedit</code>”，回车，打开注册表编辑器。<br />\n<img alt=\"编辑注册表\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105133116090-1788775234.png\" /><br />\n在注册表路径栏，输入“<code>计算机\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WebClient\\Parameters</code>”，回车，打开对应的位置，找到“BasicAuthLevel”，双击打开，然后把数值改为“<code>2</code>”，确定。</p>\n<h3 id=\"2重启系统服务\">2、重启系统服务</h3>\n<p>按Windows + R键，打开“运行”，输入“<code>services.msc</code>”，回车，打开服务。<br />\n<img alt=\"重启服务\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105133707447-1298599420.png\" /><br />\n找到“WebClient”，右键，选择“重新启动”或“启动”，优先选择“重新启动”，稍等片刻即可。</p>\n<h3 id=\"3挂载网络磁盘\">3、挂载网络磁盘</h3>\n<p>打开此电脑，点击“…”，选择“映射网络驱动器”<br />\n<img alt=\"映射网络驱动器\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105134026085-38343443.png\" /><br />\n输入我们在“CHFS-GUI”中看到的Webdav地址，完成<br />\n<img alt=\"输入Webdav网络地址\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105134216543-1046056418.png\" /><br />\n输入账号密码访问，可以选保存密码<br />\n<img alt=\"输入账号密码\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105134400223-1173783259.png\" /><br />\n稍等片刻，就可以看到被共享的目录啦~<br />\n<img alt=\"查看被共享的目录\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105134659541-1026931976.png\" /><br />\n编辑和拖放文件也是跟本地文件夹用起来一样的~<br />\n<img alt=\"编辑文件夹内容\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105134819262-397641509.png\" /></p>\n<h2 id=\"伍基于磁盘映射使用共享目录mac\">伍、基于磁盘映射使用共享目录（Mac）</h2>\n<p>我们在Mac等其他系统的设备上也可以查看、编辑共享文件夹，这里以Mac为例介绍操作步骤。</p>\n<h3 id=\"1添加网络位置\">1、添加网络位置</h3>\n<p>我们在访达中点击“前往”菜单栏，选择“连接服务器……”<br />\n<img alt=\"连接服务器\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105135819803-1431835666.png\" /><br />\n输入同样的Webdav地址，点击“连接”，因为是http，所以会提示不安全，这个我们继续连接就好了<br />\n<img alt=\"输入连接地址\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105140030648-1450261355.png\" /><br />\n接着需要我们输入账号和密码，我们输入我们之前设置的账号密码，点“连接”<br />\n<img alt=\"输入账号和密码\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105140340262-1189758189.png\" /><br />\n连接完成后，我们也是能够查看、编辑、上传、下载啥的~<br />\n<img alt=\"查看\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105140510644-1516915555.png\" /><br />\n<img alt=\"上传\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105140558685-1504459744.png\" /><br />\n完成啦~</p>\n<h2 id=\"陆总结\">陆、总结</h2>\n<p>CHFS-GUI用起来很方便，而且它是多平台的，不只是Windows，也可以在其他系统上运行。另外Webdav也很好用，用起来就像本地磁盘一样。附带的浏览器访问也很方便~<br />\n另外，我们可以关注一下CHFS-GUI的一些实用功能，开机自动启动、启动后自动开启服务、SSL/HTTPS和密码保护等。<br />\n<img alt=\"其他功能\" src=\"https://img2024.cnblogs.com/blog/2010295/202601/2010295-20260105141844360-1936076221.png\" /></p>\n<h2 id=\"柒参考\">柒、参考</h2>\n<ol>\n<li>CuteHttpFileServer | iscute.cn：<a href=\"http://iscute.cn/chfs\" rel=\"noopener nofollow\" target=\"_blank\">http://iscute.cn/chfs</a></li>\n<li>windows10挂载webdav - 晴云孤魂 - 博客园：<a href=\"https://www.cnblogs.com/cnhack/articles/17101960.html\" target=\"_blank\">https://www.cnblogs.com/cnhack/articles/17101960.html</a></li>\n<li>GitHub - docblue/chfsgui: This is just a GUI WRAPPER for chfs(cute http file server)：<a href=\"https://github.com/docblue/chfsgui\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/docblue/chfsgui</a></li>\n</ol>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 14:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/minuhy\">清风来叙</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET 10 New feature 新增功能介绍-WebSocket功能增强",
      "link": "https://www.cnblogs.com/tianqing/p/19439916",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tianqing/p/19439916\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 14:02\">\n    <span>.NET 10 New feature 新增功能介绍-WebSocket功能增强</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>今天整理了.NET 10类库新增的几个常用功能，按老规矩，分享给大家：</p>\n<div>\n<p>.NET 10 新增了&nbsp;<a class=\"no-loc\" href=\"https://learn.microsoft.com/zh-cn/dotnet/api/system.net.websockets.websocketstream\" rel=\"noopener nofollow\">WebSocketStream</a>一个新的 API，用于简化 .NET 中一些最常见的<a class=\"no-loc\" href=\"https://learn.microsoft.com/zh-cn/dotnet/api/system.net.websockets.websocket\" rel=\"noopener nofollow\">WebSocket</a>&nbsp;的流式处理方案。</p>\n<p>传统&nbsp;<code>WebSocket</code>&nbsp;API 级别较低，需要大量的代码：处理缓冲和框架、重建消息、管理编码/解码以及编写自定义包装器以与流、通道或其他传输抽象集成。</p>\n<p>这些复杂性使得很难将 WebSocket 用作传输，尤其是对于具有流式处理或基于文本的协议或事件驱动的处理程序的应用。</p>\n<p><code>WebSocketStream</code>&nbsp;通过提供&nbsp;<a class=\"no-loc\" href=\"https://learn.microsoft.com/zh-cn/dotnet/api/system.io.stream\" rel=\"noopener nofollow\">Stream</a>基于 WebSocket 的抽象来解决这个难题。</p>\n<p>这样就可以与现有 API 无缝集成，以便读取、写入和分析数据，无论是二进制数据还是文本，并减少了手动管道的需求。</p>\n<p><code>WebSocketStream</code>&nbsp;为常见的 WebSocket 生产环境应用启用了高级高阶API。</p>\n<p class=\"p1\"><strong>WebSocketStream 到底解决了什么问题</strong></p>\n<p>在 .NET 10 之前：</p>\n<ul>\n<li>\n<p class=\"p1\">System.Net.WebSockets.WebSocket</p>\n<ul>\n<li>\n<p class=\"p1\"><strong>消息模型（Message-based）</strong></p>\n</li>\n<li>\n<p class=\"p1\">必须自己处理：</p>\n<ul>\n<li>\n<p class=\"p1\">分片（Fragment）</p>\n</li>\n<li>\n<p class=\"p1\">消息边界</p>\n</li>\n<li>\n<p class=\"p1\">循环 Receive / Send</p>\n</li>\n</ul>\n</li>\n<li>\n<p class=\"p1\"><strong>无法像 Stream 一样统一抽象</strong></p>\n</li>\n</ul>\n</li>\n</ul>\n<p class=\"p3\">结果是：</p>\n<ul>\n<li>\n<p class=\"p1\">WebSocket 写法 <span class=\"s1\"><strong>复杂、重复、易错</strong></span></p>\n</li>\n<li>\n<p class=\"p1\">很难和现有 <span class=\"s1\"><strong>Stream 生态</strong>（压缩、加密、管道、序列化）整合</span></p>\n</li>\n<li>\n<p class=\"p1\">WebSocket 和 TCP / NamedPipe / HTTP Body 的编程模型割裂</p>\n</li>\n</ul>\n<p class=\"p1\">&nbsp;<strong>WebSocketStream 的本质变化</strong></p>\n<p>&nbsp;<span class=\"s2\">.NET 10 提供的 WebSocketStream<span class=\"s2\">：</span></span></p>\n<blockquote><strong>把 WebSocket 连接抽象为一个真正的 Stream</strong></blockquote>\n<p class=\"p5\">这意味着：</p>\n<ul>\n<li>\n<p class=\"p1\">不再关心消息帧、分片、边界</p>\n</li>\n<li>\n<p class=\"p1\">可以直接：</p>\n<ul>\n<li>\n<p class=\"p1\">ReadAsync</p>\n</li>\n<li>\n<p class=\"p1\">WriteAsync</p>\n</li>\n</ul>\n</li>\n<li>\n<p class=\"p1\">能无缝接入：</p>\n<ul>\n<li>\n<p class=\"p1\">PipeReader / PipeWriter</p>\n</li>\n<li>\n<p class=\"p1\">System.IO.Stream<span class=\"s1\"> 全套中间件</span></p>\n</li>\n</ul>\n<p>&nbsp;<span class=\"s2\">这是一次<strong>模型级升级，而不是语法糖</strong><span class=\"s2\">。</span></span></p>\n</li>\n</ul>\n<p>&nbsp;给出一个示例代码：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Streaming binary protocol (for example, AMQP).</span>\nStream transportStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.Create(\n    connectedWebSocket,\n    WebSocketMessageType.Binary,\n    closeTimeout: TimeSpan.FromSeconds(</span><span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\">));\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> message.SerializeToStreamAsync(transportStream, cancellationToken);\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> receivePayload = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> <span style=\"color: rgba(0, 0, 255, 1);\">byte</span><span style=\"color: rgba(0, 0, 0, 1);\">[payloadLength];\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> transportStream.ReadExactlyAsync(receivePayload, cancellationToken);\ntransportStream.Dispose();\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> `Dispose` automatically handles closing handshake.</span></pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"streaming-text-protocol-for-example-stomp\">流式处理文本协议（例如 STOMP）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Streaming text protocol (for example, STOMP).</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">using</span> Stream transportStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.Create(\n    connectedWebSocket, \n    WebSocketMessageType.Text,\n    ownsWebSocket: </span><span style=\"color: rgba(0, 0, 255, 1);\">true</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Integration with Stream-based APIs.\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Don't close the stream, as it's also used for writing.</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">using</span> <span style=\"color: rgba(0, 0, 255, 1);\">var</span> transportReader = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> StreamReader(transportStream, leaveOpen: <span style=\"color: rgba(0, 0, 255, 1);\">true</span><span style=\"color: rgba(0, 0, 0, 1);\">); \n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> line = <span style=\"color: rgba(0, 0, 255, 1);\">await</span> transportReader.ReadLineAsync(cancellationToken); <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Automatic UTF-8 and new line handling.</span>\ntransportStream.Dispose(); <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Automatic closing handshake handling on `Dispose`.</span></pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"streaming-binary-protocol-for-example-amqp\">流式处理二进制协议（例如 AMQP）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Streaming binary protocol (for example, AMQP).</span>\nStream transportStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.Create(\n    connectedWebSocket,\n    WebSocketMessageType.Binary,\n    closeTimeout: TimeSpan.FromSeconds(</span><span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\">));\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> message.SerializeToStreamAsync(transportStream, cancellationToken);\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> receivePayload = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> <span style=\"color: rgba(0, 0, 255, 1);\">byte</span><span style=\"color: rgba(0, 0, 0, 1);\">[payloadLength];\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> transportStream.ReadExactlyAsync(receivePayload, cancellationToken);\ntransportStream.Dispose();\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> `Dispose` automatically handles closing handshake.</span></pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"read-a-single-message-as-a-stream-for-example-json-deserialization\">以流形式读取单个消息（例如 JSON 反序列化）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Text.Json;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Reading a single message as a stream (for example, JSON deserialization).</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">using</span> Stream messageStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.CreateReadableMessageStream(connectedWebSocket, WebSocketMessageType.Text);\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> JsonSerializer.DeserializeAsync reads until the end of stream.</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> appMessage = <span style=\"color: rgba(0, 0, 255, 1);\">await</span> JsonSerializer.DeserializeAsync&lt;AppMessage&gt;(messageStream);</pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"write-a-single-message-as-a-stream-for-example-binary-serialization\">将单个消息编写为流（例如，二进制序列化）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Writing a single message as a stream (for example, binary serialization).</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">async</span><span style=\"color: rgba(0, 0, 0, 1);\"> Task SendMessageAsync(AppMessage message, CancellationToken cancellationToken)\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">using</span> Stream messageStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.CreateWritableMessageStream(_connectedWebSocket, WebSocketMessageType.Binary);\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (ReadOnlyMemory&lt;<span style=\"color: rgba(0, 0, 255, 1);\">byte</span>&gt; chunk <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> message.SplitToChunks())\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> messageStream.WriteAsync(chunk, cancellationToken);\n    }\n} </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> EOM sent on messageStream.Dispose().</span></pre>\n</div>\n<p>总结：<strong>WebSocketStream 的真实应用场景</strong></p>\n<p><strong>场景一：实时数据流（Streaming Data）</strong></p>\n<p><strong>典型业务</strong></p>\n<ul>\n<li>\n<p class=\"p1\">充电站实时状态推送（功率、电流、电压）</p>\n</li>\n<li>\n<p class=\"p1\">实时监控大屏（指标流）</p>\n</li>\n<li>\n<p class=\"p1\">行情 / 订单流</p>\n</li>\n<li>\n<p class=\"p1\">日志 / Trace 实时订阅</p>\n</li>\n</ul>\n<p>&nbsp;<strong>使用 WebSocketStream 后</strong>WebSocket = <span class=\"s2\"><strong>一条持续的数据流</strong></span></p>\n<p class=\"p1\">&nbsp;<strong>场景二：AI / LLM 实时输出（Token Streaming）</strong></p>\n<p>&nbsp;<strong>典型业务</strong></p>\n<ul>\n<li>\n<p class=\"p1\">大模型推理流式返回</p>\n</li>\n<li>\n<p class=\"p1\">Copilot / Chat / Agent 推理过程</p>\n</li>\n<li>\n<p class=\"p1\">SSE + WebSocket 混合方案</p>\n</li>\n</ul>\n<p>&nbsp;<strong>场景三：大文件 / 二进制流实时传输</strong></p>\n<p>using var file = File.OpenRead(path);<br />await file.CopyToAsync(webSocketStream);</p>\n<p class=\"p1\">&nbsp;更像 TCP，但仍是 WebSocket</p>\n<p class=\"p1\">&nbsp;<strong>场景四：RPC / 协议隧道（Protocol Tunneling）</strong></p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">可以直接跑 <strong>已有 Stream 协议</strong></span></p>\n<ul>\n<li>\n<p class=\"p1\">gRPC-like</p>\n</li>\n<li>\n<p class=\"p1\">自定义 framing</p>\n</li>\n<li>\n<p class=\"p1\">设备通信协议</p>\n</li>\n</ul>\n<p>&nbsp;&nbsp;await protocolHandler.RunAsync(webSocketStream);</p>\n</li>\n</ul>\n<p><strong>场景五：与 System.IO.Pipelines 深度整合</strong></p>\n<p><strong>构建</strong><strong>高性能服务端</strong></p>\n<p>var reader = PipeReader.Create(webSocketStream);<br />var writer = PipeWriter.Create(webSocketStream);</p>\n<ul>\n<li>\n<p class=\"p1\">用 Pipelines 做：</p>\n<ul>\n<li>\n<p class=\"p1\">高性能解析</p>\n</li>\n<li>\n<p class=\"p1\">零拷贝处理</p>\n</li>\n</ul>\n</li>\n<li>\n<p class=\"p1\">和 Kestrel / gRPC / 自研协议一致</p>\n</li>\n</ul>\n<p class=\"p1\">&nbsp;<strong>适合：</strong></p>\n<ul>\n<li>\n<p class=\"p1\">高频实时通信</p>\n</li>\n<li>\n<p class=\"p1\">百万级连接服务</p>\n</li>\n<li>\n<p class=\"p1\">核心中枢服务</p>\n</li>\n</ul>\n<p>&nbsp;以上总结，分享给大家。</p>\n<p>&nbsp;</p>\n<p>周国庆</p>\n<p>2026/1/5</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 14:02</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tianqing\">Eric zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">69</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从安装到上线：一份 Nginx 实战指南，让你的 Web 应用稳建安全",
      "link": "https://www.cnblogs.com/ymtianyu/p/19442584",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19442584\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 13:40\">\n    <span>从安装到上线：一份 Nginx 实战指南，让你的 Web 应用稳建安全</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        这是一份面向开发者和运维新手的 Nginx 实战指南。文章详细讲解了在 Windows 和 Linux 系统下安装配置 Nginx 的步骤，提供了核心的安全加固配置，并重点演示了如何将 Nginx 作为反向代理与 Flask 或 FastAPI 等 Python Web 应用结合部署。同时，文中总结了常见的错误与排查方法，帮助你快速上手并避免常见陷阱。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>你有没有遇到过网站突然变卡，或者千辛万苦写好的 Flask/FastAPI 应用，却不知道怎么优雅地部署到公网？今天，我们就来聊聊那个在背后默默支撑全球近三分之一活跃网站的“无名英雄”——Nginx。</p>\n<p>对于很多开发者和运维新手来说，Nginx 的配置常常让人头疼：安装报错、配置文件复杂、安全设置无从下手……别担心，作为你的老朋友，这篇指南将用最直白的语言，带你从零开始，彻底搞定 Nginx 的安装、配置和实战应用。🎯</p>\n<hr />\n<h2>🎯 本文摘要</h2>\n<p>本文是一份面向实践的 Nginx 综合指南。你将系统学习到如何在 Windows 和 Linux 系统上安装与配置 Nginx，掌握核心的安全加固技巧，并学会将 Nginx 与 Flask 或 FastAPI 等 Python Web 框架无缝结合，用于生产环境部署。同时，文中提供了常见问题的排查思路，帮助你快速定位和解决难题。</p>\n<hr />\n<h2>🚀 Nginx：不只是个“发文件的”</h2>\n<p>很多人初识 Nginx，以为它只是个高性能的静态文件服务器。其实，它更像一个<strong style=\"color: rgba(186, 55, 42, 1);\">万能的“接线员”或“交通警察”</strong>。它能处理并发连接（事件驱动、异步非阻塞），能做反向代理（把你后端的应用“藏”起来），能负载均衡（把流量合理分发给多个后端），还能缓存内容、压缩数据、终结 SSL 加密……</p>\n<p>理解这一点，再看它的配置文件，你就会明白那些 <code style=\"color: rgba(186, 55, 42, 1);\">location</code>、<code style=\"color: rgba(186, 55, 42, 1);\">proxy_pass</code> 指令都是在指挥“交通”。</p>\n<hr />\n<h2>🔧 第一部分：安装与配置（Windows &amp; Linux）</h2>\n<h3>1. Linux 下安装（以 Ubuntu/Debian 为例）</h3>\n<p>Linux 是 Nginx 的主战场，安装最简单。</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 1. 更新包列表\nsudo apt update\n\n# 2. 安装 Nginx\nsudo apt install nginx -y\n\n# 3. 启动并设置开机自启\nsudo systemctl start nginx\nsudo systemctl enable nginx\n\n# 4. 检查状态\nsudo systemctl status nginx</code></pre>\n<p>安装完成后，浏览器访问你的服务器 IP，看到“Welcome to nginx!”页面，就说明成功了。</p>\n<h3>2. Windows 下安装</h3>\n<p>Windows 下通常用于开发测试。直接从官网下载压缩包：</p>\n<ul>\n<li>访问 <a href=\"https://nginx.org/en/download.html\" rel=\"noopener nofollow\">nginx.org/en/download.html</a></li>\n<li>下载 <code style=\"color: rgba(186, 55, 42, 1);\">nginx/Windows-x.x.x</code> 版本</li>\n<li>解压到任意目录（<strong style=\"color: rgba(186, 55, 42, 1);\">路径不要有中文或空格！</strong>）</li>\n</ul>\n<p>启动方法：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 进入解压目录，打开命令行\ncd C:\\你的路径\\nginx-1.xx.x\nstart nginx          # 启动（窗口一闪而过是正常的）\nnginx.exe -s stop    # 快速停止\nnginx.exe -s quit    # 优雅停止（处理完当前请求）\nnginx.exe -s reload  # 重新加载配置（最常用！）</code></pre>\n<p>如果启动后，未能正常访问，可查看解压后目录下的<code>logs</code>文件夹下日志记录以排查错误原因，如：80端口占用等</p>\n<hr />\n<h2>⚙️ 第二部分：核心配置与安全设置</h2>\n<p>Nginx 的核心是配置文件，通常位于：</p>\n<ul>\n<li>Linux: <code style=\"color: rgba(186, 55, 42, 1);\">/etc/nginx/nginx.conf</code></li>\n<li>Windows: <code style=\"color: rgba(186, 55, 42, 1);\">conf/nginx.conf</code></li>\n</ul>\n<h3>🎯 基础安全加固（必做项！）</h3>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 在 http{ } 或 server{ } 块中添加\n\n# 1. 隐藏 Nginx 版本号（避免信息泄露）\nserver_tokens off;\n\n# 2. 设置安全头部（防止一些常见 Web 攻击）\nadd_header X-Frame-Options \"SAMEORIGIN\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\n\n# 3. 限制请求方法（只允许常用的）\nif ($request_method !~ ^(GET|HEAD|POST)$ ) {\n    return 405;\n}\n\n# 4. 限制客户端请求体大小（防文件上传攻击）\nclient_max_body_size 10m;</code></pre>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">警告：</strong>修改配置文件后，务必使用 <code style=\"color: rgba(186, 55, 42, 1);\">nginx -t</code> 测试语法，确认无误后再 <code style=\"color: rgba(186, 55, 42, 1);\">nginx -s reload</code> 重载配置。</p>\n<hr />\n<h2>🚀 第三部分：与 Flask / FastAPI 结合（实战演示）</h2>\n<p>这是 Python 开发者最关心的部分。我们通常<strong style=\"color: rgba(186, 55, 42, 1);\">不直接让 Nginx 运行 Python</strong>，而是让 Nginx 作为<strong style=\"color: rgba(186, 55, 42, 1);\">反向代理</strong>，将动态请求转发给后端的 Python 应用服务器（如 Gunicorn 或 Uvicorn）。</p>\n<h3>🎯 部署架构图</h3>\n<p><span style=\"color: rgba(224, 62, 45, 1);\"><strong>用户 → Nginx (80/443端口) → 反向代理 → Gunicorn/Uvicorn (本地某个端口，如 8000) → 你的 Flask/FastAPI 应用</strong></span></p>\n<h3>1. 准备你的 Python 应用</h3>\n<p>假设你有一个 FastAPI 应用 <code style=\"color: rgba(186, 55, 42, 1);\">main.py</code>：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># main.py\nfrom fastapi import FastAPI\napp = FastAPI()\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}</code></pre>\n<p>使用 Uvicorn 启动它（监听本机 8000 端口）：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>uvicorn main:app --host 127.0.0.1 --port 8000</code></pre>\n<h3>2. 配置 Nginx 反向代理</h3>\n<p>在 <code style=\"color: rgba(186, 55, 42, 1);\">/etc/nginx/sites-available/</code>（Linux）或 <code style=\"color: rgba(186, 55, 42, 1);\">conf/</code> 目录下（Windows），创建一个配置文件，如 <code style=\"color: rgba(186, 55, 42, 1);\">myapp.conf</code>：<br />（建议直接复制<code>nginx.conf</code>建立复本，然后修改指定<code>server</code>部分即可，以防止未知的语法错误，如：分号缺失等）</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>server {\n    listen 80; # 监听80端口（HTTP）\n    server_name your_domain.com; # 你的域名或服务器IP\n\n    # 静态文件（可选，Nginx直接处理效率更高）\n    location /static {\n        alias /path/to/your/static/files;\n        expires 30d;\n    }\n\n    # 动态请求，全部代理给后端的 FastAPI 应用\n    location / {\n        # 后端应用服务器的地址\n        proxy_pass http://127.0.0.1:8000;\n\n        # 以下是关键代理设置，确保信息正确传递\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # 超时设置\n        proxy_connect_timeout 60s;\n        proxy_read_timeout 60s;\n    }\n}</code></pre>\n<p>在 Linux 上，需要创建符号链接启用该配置：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>sudo ln -s /etc/nginx/sites-available/myapp.conf /etc/nginx/sites-enabled/\nsudo nginx -t\nsudo systemctl reload nginx</code></pre>\n<p>在 Windows 上，同样需要重新指定配置文件路径：</p>\n<pre class=\"language-bash highlighter-hljs\"><code>.\\nginx.exe -t -c .\\conf\\myapp.conf\n.\\nginx.exe -s reload</code></pre>\n<p>现在，访问你的服务器 IP 或域名，Nginx 就会把请求透明地转发给运行在 8000 端口的 FastAPI 应用了！Flask 应用配置方法完全一致。</p>\n<hr />\n<h2>⚠️ 第四部分：常见问题与排查（踩坑指南）</h2>\n<h3>1. 访问出现 502 Bad Gateway</h3>\n<ul>\n<li><strong style=\"color: rgba(186, 55, 42, 1);\">原因99%：</strong>后端应用（Gunicorn/Uvicorn）没启动，或者端口没对上。</li>\n<li><strong>排查：</strong>检查后端服务是否在运行 (<code style=\"color: rgba(186, 55, 42, 1);\">ps aux | grep uvicorn</code>)，并确认 <code style=\"color: rgba(186, 55, 42, 1);\">proxy_pass</code> 的地址和端口是否正确。</li>\n</ul>\n<h3>2. 403 Forbidden</h3>\n<ul>\n<li><strong>排查：</strong>检查 Nginx 进程用户（通常是 <code style=\"color: rgba(186, 55, 42, 1);\">www-data</code> 或 <code style=\"color: rgba(186, 55, 42, 1);\">nginx</code>）是否有权限读取你配置的静态文件或目录。</li>\n</ul>\n<h3>3. 静态文件加载不了，CSS/JS 失效</h3>\n<ul>\n<li><strong>排查：</strong>检查 <code style=\"color: rgba(186, 55, 42, 1);\">location /static</code> 的 <code style=\"color: rgba(186, 55, 42, 1);\">alias</code> 路径是否正确，以及文件是否存在。</li>\n</ul>\n<h3>4. 配置修改后不生效</h3>\n<ul>\n<li><strong>牢记流程：</strong>改配置 → <code style=\"color: rgba(186, 55, 42, 1);\">nginx -t</code> 测试 → <code style=\"color: rgba(186, 55, 42, 1);\">nginx -s reload</code> 重载。</li>\n<li>如果还不生效，尝试重启 Nginx 服务，并检查错误日志：<code style=\"color: rgba(186, 55, 42, 1);\">tail -f /var/log/nginx/error.log</code>。</li>\n</ul>\n<hr />\n<h2>💎 总结与升华</h2>\n<p>Nginx 的学习曲线看似陡峭，但一旦理解了它的“交通警察”角色和配置文件的块结构（<code style=\"color: rgba(186, 55, 42, 1);\">http{}</code>, <code style=\"color: rgba(186, 55, 42, 1);\">server{}</code>, <code style=\"color: rgba(186, 55, 42, 1);\">location{}</code>），很多问题都会迎刃而解。</p>\n<p>记住，<strong style=\"color: rgba(186, 55, 42, 1);\">最好的学习方式是动手</strong>。先在本地虚拟机或测试环境折腾，从最简单的静态服务开始，再到反向代理一个本地应用，逐步加上 SSL（HTTPS）、负载均衡等高级功能。</p>\n<p>技术之路，坑总是要踩的。但希望我这篇“老友记”式的分享，能为你点亮一盏灯，让你在摸爬滚打时，少一分迷茫，多一份从容。如果在实践中遇到新问题，随时可以再来聊聊，咱们一起探讨。</p>\n<p>祝你配置顺利，上线大吉！🚀</p>\n<p style=\"text-align: center;\">---<strong>写在最后</strong>---<br />希望这份总结能帮你避开一些坑。如果觉得有用，不妨点个 赞👍 或 收藏⭐ 标记一下，方便随时回顾。也欢迎关注我，后续为你带来更多类似的实战解析。有任何疑问或想法，我们评论区见，一起交流开发中的各种心得与问题。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 13:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">80</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET+AI | 基于 Microsoft Agent Framework 一步步集成 Agent Skills，让你的 AI Agent 更智能",
      "link": "https://www.cnblogs.com/sheng-jie/p/19442149",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sheng-jie/p/19442149\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 11:50\">\n    <span>.NET+AI | 基于 Microsoft Agent Framework 一步步集成 Agent Skills，让你的 AI Agent 更智能</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"基于-microsoft-agent-framework-实现-agent-skills-集成\">基于 Microsoft Agent Framework 实现 Agent Skills 集成</h1>\n<h2 id=\"引言\">引言</h2>\n<p>随着 AI Agent 技术的快速发展，如何让 Agent 具备可复用、可扩展的专业能力成为一个重要课题。<a href=\"https://agentskills.io\" rel=\"noopener nofollow\" target=\"_blank\">Agent Skills</a> 规范提供了一种标准化的方式来定义和分发 Agent 技能，而 <a href=\"https://github.com/microsoft/ai-agents\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft Agent Framework (MAF)</a> 则提供了构建 AI Agent 的强大基础设施。</p>\n<p>本文将深入介绍如何基于 MAF 的上下文扩展（<code>AIContextProvider</code>）实现 Agent Skills 的集成，包括核心架构设计、关键组件实现以及实际应用示例。</p>\n<blockquote>\n<p>源码已上传至GitHub，文末扫码，<strong>加入「.NET+AI 社区群」，即可获取「.NET+AI 公开资料包」</strong>。</p>\n</blockquote>\n<hr />\n<h2 id=\"架构概述\">架构概述</h2>\n<h3 id=\"整体架构\">整体架构</h3>\n<p>Maf.AgentSkills 项目采用了 MAF 官方推荐的 <code>AIContextProviderFactory</code> 模式，实现了与 MAF 的无缝集成。整体架构如下：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837837-1484392163.png\" /></p>\n<h3 id=\"技术栈\">技术栈</h3>\n<ul>\n<li><strong>目标框架</strong>: .NET 10.0</li>\n<li><strong>核心依赖</strong>:\n<ul>\n<li><code>Microsoft.Agents.AI</code> - MAF 核心框架</li>\n<li><code>Microsoft.Extensions.AI</code> - AI 抽象层</li>\n<li><code>YamlDotNet</code> - YAML Frontmatter 解析</li>\n<li><code>Microsoft.Extensions.DependencyInjection</code> - 依赖注入支持</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"核心设计理念\">核心设计理念</h2>\n<h3 id=\"1-渐进式披露-progressive-disclosure\">1. 渐进式披露 (Progressive Disclosure)</h3>\n<p>Agent Skills 的核心理念之一是<strong>渐进式披露</strong>：Agent 首先只获取技能的元数据（名称和描述），只有在真正需要使用某个技能时，才加载完整的指令内容。</p>\n<p>这种设计有几个重要优势：</p>\n<ol>\n<li><strong>减少 Token 消耗</strong>：系统提示只包含简短的技能列表，而不是所有技能的完整内容</li>\n<li><strong>提高效率</strong>：Agent 可以快速判断哪些技能与当前任务相关</li>\n<li><strong>按需加载</strong>：详细指令仅在需要时获取，避免信息过载</li>\n</ol>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837828-1786264926.png\" /></p>\n<p><strong>信息获取流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837954-307200857.png\" /></p>\n<h3 id=\"2-符合-maf-设计模式\">2. 符合 MAF 设计模式</h3>\n<p>项目严格遵循 MAF 的 <code>AIContextProviderFactory</code> 模式，这是 MAF 推荐的上下文注入方式：</p>\n<pre><code class=\"language-csharp\">// MAF 标准模式\nAIAgent agent = chatClient.CreateAIAgent(new ChatClientAgentOptions\n{\n    AIContextProviderFactory = ctx =&gt; new MyContextProvider(\n        chatClient,\n        ctx.SerializedState,\n        ctx.JsonSerializerOptions)\n});\n</code></pre>\n<p>通过实现 <code>AIContextProvider</code> 抽象类，我们可以：</p>\n<ul>\n<li>在每次 Agent 调用前注入技能信息</li>\n<li>动态提供 Instructions、Messages 和 Tools</li>\n<li>支持线程状态的序列化和反序列化</li>\n</ul>\n<h3 id=\"3-安全第一\">3. 安全第一</h3>\n<p>技能系统涉及文件读取和可能的脚本执行，因此安全性是首要考虑：</p>\n<ul>\n<li><strong>路径遍历防护</strong>：所有文件操作都经过路径安全验证</li>\n<li><strong>符号链接检测</strong>：防止通过符号链接逃逸</li>\n<li><strong>脚本执行默认禁用</strong>：需要显式启用并配置白名单</li>\n<li><strong>命令执行白名单</strong>：只允许预定义的命令</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114838100-771593506.png\" /></p>\n<hr />\n<h2 id=\"关键组件详解\">关键组件详解</h2>\n<h3 id=\"1-skillscontextprovider---技能上下文提供器\">1. SkillsContextProvider - 技能上下文提供器</h3>\n<p><code>SkillsContextProvider</code> 是整个系统的核心，它继承自 MAF 的 <code>AIContextProvider</code> 抽象类：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillsContextProvider : AIContextProvider\n{\n    private readonly IChatClient _chatClient;\n    private readonly SkillLoader _skillLoader;\n    private readonly SkillsOptions _options;\n    private SkillsState _state;\n\n    // 构造函数1：创建新实例\n    public SkillsContextProvider(IChatClient chatClient, SkillsOptions? options = null)\n    {\n        _chatClient = chatClient;\n        _options = options ?? new SkillsOptions();\n        \n        var settings = new SkillsSettings(_options.AgentName, _options.ProjectRoot);\n        _skillLoader = new SkillLoader();\n        _state = new SkillsState();\n\n        // 自动加载技能\n        LoadSkills(settings);\n    }\n\n    // 构造函数2：从序列化状态恢复（支持线程持久化）\n    public SkillsContextProvider(\n        IChatClient chatClient,\n        JsonElement serializedState,\n        JsonSerializerOptions? jsonSerializerOptions = null)\n    {\n        // 反序列化恢复状态...\n    }\n\n    // 在 Agent 调用前注入技能上下文\n    public override ValueTask&lt;AIContext&gt; InvokingAsync(\n        InvokingContext context,\n        CancellationToken cancellationToken = default)\n    {\n        // 生成技能系统提示\n        var instructions = GenerateSkillsPrompt(_state.AllSkills);\n        \n        // 创建技能工具\n        var tools = CreateSkillsTools(_state);\n\n        return ValueTask.FromResult(new AIContext\n        {\n            Instructions = instructions,\n            Tools = tools\n        });\n    }\n\n    // 序列化状态以支持线程持久化\n    public override JsonElement Serialize(JsonSerializerOptions? jsonSerializerOptions = null)\n    {\n        var state = new { Options = _options, State = _state };\n        return JsonSerializer.SerializeToElement(state, jsonSerializerOptions);\n    }\n}\n</code></pre>\n<p><strong>关键设计点</strong>：</p>\n<ol>\n<li><strong>双构造函数模式</strong>：一个用于创建新实例，一个用于从序列化状态恢复</li>\n<li><strong>InvokingAsync</strong>：在每次 Agent 调用前被调用，返回 <code>AIContext</code> 注入技能信息</li>\n<li><strong>Serialize</strong>：支持将技能状态序列化，用于线程持久化场景</li>\n</ol>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837897-1781124143.png\" /></p>\n<h3 id=\"2-skillloader---技能加载器\">2. SkillLoader - 技能加载器</h3>\n<p><code>SkillLoader</code> 负责从文件系统发现和加载技能：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillLoader\n{\n    private readonly SkillParser _parser;\n\n    /// &lt;summary&gt;\n    /// 从指定目录加载所有技能\n    /// &lt;/summary&gt;\n    public IEnumerable&lt;SkillMetadata&gt; LoadSkillsFromDirectory(\n        string skillsDirectory, \n        SkillSource source)\n    {\n        if (!Directory.Exists(skillsDirectory))\n            yield break;\n\n        foreach (var skillDir in Directory.GetDirectories(skillsDirectory))\n        {\n            var skill = TryLoadSkill(skillDir, source);\n            if (skill is not null)\n                yield return skill;\n        }\n    }\n\n    private SkillMetadata? TryLoadSkill(string skillDirectory, SkillSource source)\n    {\n        var skillFilePath = Path.Combine(skillDirectory, \"SKILL.md\");\n\n        if (!File.Exists(skillFilePath))\n            return null;\n\n        // 安全检查：验证符号链接\n        if (PathSecurity.IsSymbolicLink(skillFilePath))\n        {\n            var realPath = PathSecurity.GetRealPath(skillFilePath);\n            if (!PathSecurity.IsPathSafe(realPath, skillDirectory))\n                return null;\n        }\n\n        return _parser.Parse(skillFilePath, source);\n    }\n}\n</code></pre>\n<p><strong>技能目录结构</strong>：</p>\n<pre><code>~/.maf/{agent-name}/skills/     # 用户级技能\n{project-root}/.maf/skills/     # 项目级技能（优先级更高）\n</code></pre>\n<p>每个技能是一个独立的目录，包含 <code>SKILL.md</code> 文件：</p>\n<pre><code>skills/\n├── web-research/\n│   ├── SKILL.md\n│   ├── search.py\n│   └── templates/\n│       └── report.md\n├── code-review/\n│   ├── SKILL.md\n│   └── checklist.md\n└── pdf-tools/\n    ├── SKILL.md\n    ├── split_pdf.py\n    └── merge_pdf.py\n</code></pre>\n<p><strong>技能加载流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114838125-1683611629.png\" /></p>\n<h3 id=\"3-skillparser---技能解析器\">3. SkillParser - 技能解析器</h3>\n<p><code>SkillParser</code> 负责解析 SKILL.md 文件的 YAML Frontmatter：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillParser\n{\n    private const string FrontmatterDelimiter = \"---\";\n\n    public SkillMetadata Parse(string skillFilePath, SkillSource source)\n    {\n        var content = File.ReadAllText(skillFilePath);\n        var skillDirectory = Path.GetDirectoryName(skillFilePath)!;\n        var directoryName = Path.GetFileName(skillDirectory);\n\n        // 提取 YAML Frontmatter\n        var frontmatter = ExtractFrontmatter(content);\n        if (frontmatter is null)\n            throw new SkillParseException(skillFilePath, \n                \"SKILL.md must have YAML frontmatter delimited by '---'.\");\n\n        // 解析 YAML\n        var yamlData = _yamlDeserializer.Deserialize&lt;SkillFrontmatter&gt;(frontmatter);\n\n        // 验证必需字段\n        if (string.IsNullOrWhiteSpace(yamlData.Name))\n            throw new SkillParseException(skillFilePath, \"Skill 'name' is required.\");\n\n        if (string.IsNullOrWhiteSpace(yamlData.Description))\n            throw new SkillParseException(skillFilePath, \"Skill 'description' is required.\");\n\n        // 验证名称格式和目录匹配\n        SkillValidator.ValidateName(yamlData.Name);\n        SkillValidator.ValidateNameMatchesDirectory(yamlData.Name, directoryName);\n\n        return new SkillMetadata(\n            Name: yamlData.Name,\n            Description: yamlData.Description,\n            Path: skillDirectory,\n            Source: source,\n            License: yamlData.License,\n            AllowedTools: AllowedTool.Parse(yamlData.AllowedTools)\n        );\n    }\n}\n</code></pre>\n<p><strong>SKILL.md 格式示例</strong>：</p>\n<pre><code class=\"language-markdown\">---\nname: web-research\ndescription: A skill for conducting comprehensive web research\nlicense: MIT\nallowed-tools: web_search fetch_url\n---\n\n# Web Research Skill\n\n## When to Use\nUse this skill when researching topics online...\n\n## Instructions\n1. Clarify the research scope\n2. Search strategically\n3. Synthesize information\n...\n</code></pre>\n<h3 id=\"4-skillstoolfactory---工具工厂\">4. SkillsToolFactory - 工具工厂</h3>\n<p><code>SkillsToolFactory</code> 根据配置创建技能相关的工具：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillsToolFactory\n{\n    public IReadOnlyList&lt;AITool&gt; CreateTools()\n    {\n        var tools = new List&lt;AITool&gt;();\n\n        // 默认启用的安全工具\n        if (_options.EnableReadSkillTool)\n            tools.Add(new ReadSkillTool(_loader, _stateProvider).ToAIFunction());\n\n        if (_options.EnableReadFileTool)\n            tools.Add(new ReadFileTool(_stateProvider).ToAIFunction());\n\n        if (_options.EnableListDirectoryTool)\n            tools.Add(new ListDirectoryTool(_loader, _stateProvider).ToAIFunction());\n\n        // 需要显式启用的高危工具\n        if (_options.EnableExecuteScriptTool)\n            tools.Add(new ExecuteScriptTool(_stateProvider, _options).ToAIFunction());\n\n        if (_options.EnableRunCommandTool &amp;&amp; _options.AllowedCommands.Count &gt; 0)\n            tools.Add(new RunCommandTool(_stateProvider, _options).ToAIFunction());\n\n        return tools;\n    }\n}\n</code></pre>\n<p><strong>内置工具</strong>：</p>\n<table>\n<thead>\n<tr>\n<th>工具名</th>\n<th>功能</th>\n<th>默认状态</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>read_skill</code></td>\n<td>读取 SKILL.md 完整内容</td>\n<td>✅ 启用</td>\n</tr>\n<tr>\n<td><code>read_skill_file</code></td>\n<td>读取技能目录中的文件</td>\n<td>✅ 启用</td>\n</tr>\n<tr>\n<td><code>list_skill_directory</code></td>\n<td>列出技能目录内容</td>\n<td>✅ 启用</td>\n</tr>\n<tr>\n<td><code>execute_skill_script</code></td>\n<td>执行技能中的脚本</td>\n<td>❌ 禁用</td>\n</tr>\n<tr>\n<td><code>run_skill_command</code></td>\n<td>运行白名单命令</td>\n<td>❌ 禁用</td>\n</tr>\n</tbody>\n</table>\n<p><strong>工具创建决策流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114838189-800056356.png\" /></p>\n<h3 id=\"5-chatclientextensions---便捷扩展方法\">5. ChatClientExtensions - 便捷扩展方法</h3>\n<p>为了简化使用，项目提供了 <code>ChatClient</code> 的扩展方法：</p>\n<pre><code class=\"language-csharp\">public static class ChatClientExtensions\n{\n    public static AIAgent CreateSkillsAgent(\n        this IChatClient chatClient,\n        Action&lt;SkillsOptions&gt;? configureSkills = null,\n        Action&lt;ChatClientAgentOptions&gt;? configureAgent = null)\n    {\n        var skillsOptions = new SkillsOptions();\n        configureSkills?.Invoke(skillsOptions);\n\n        var agentOptions = new ChatClientAgentOptions\n        {\n            AIContextProviderFactory = ctx =&gt;\n            {\n                // 检查是否从序列化状态恢复\n                if (ctx.SerializedState.ValueKind != JsonValueKind.Undefined)\n                {\n                    return new SkillsContextProvider(\n                        chatClient,\n                        ctx.SerializedState,\n                        ctx.JsonSerializerOptions);\n                }\n\n                // 创建新实例\n                return new SkillsContextProvider(chatClient, skillsOptions);\n            }\n        };\n\n        configureAgent?.Invoke(agentOptions);\n        return chatClient.CreateAIAgent(agentOptions);\n    }\n}\n</code></pre>\n<hr />\n<h2 id=\"实现细节\">实现细节</h2>\n<h3 id=\"agent-调用完整流程\">Agent 调用完整流程</h3>\n<p>以下是 Agent 执行任务时的完整调用流程：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837850-1773548166.png\" /></p>\n<h3 id=\"1-技能系统提示生成\">1. 技能系统提示生成</h3>\n<p>技能信息通过系统提示注入到 Agent 中。系统提示采用渐进式披露的设计：</p>\n<pre><code class=\"language-csharp\">public static class SkillsPromptTemplates\n{\n    public const string SystemPromptTemplate = \"\"\"\n        ## Skills System\n\n        You have access to a skills library that provides specialized capabilities.\n\n        {skills_locations}\n\n        **Available Skills:**\n\n        {skills_list}\n\n        ---\n\n        ### How to Use Skills (Progressive Disclosure) - CRITICAL\n\n        Skills follow a **progressive disclosure** pattern - you know they exist \n        (name + description above), but you **MUST read the full instructions \n        before using them**.\n\n        **MANDATORY Workflow:**\n\n        1. **Recognize when a skill applies**: Check if the user's task matches \n           any skill's description above\n        2. **Read the skill's full instructions FIRST**: Use `read_skill` tool \n           to get the complete SKILL.md content\n        3. **Follow the skill's instructions precisely**: SKILL.md contains \n           step-by-step workflows and examples\n        4. **Execute scripts only after reading**: Use the exact script paths \n           and argument formats from SKILL.md\n\n        **IMPORTANT RULES:**\n\n        ⚠️ **NEVER call `execute_skill_script` without first reading the skill \n           with `read_skill`**\n        \n        ✅ **Correct Workflow Example:**\n        ```\n        User: \"Split this PDF into pages\"\n        1. Recognize: \"split-pdf\" skill matches this task\n        2. Call: read_skill(\"split-pdf\") → Get full instructions\n        3. Learn: SKILL.md shows the actual script path and argument format\n        4. Execute: Use the exact command format from SKILL.md\n        ```\n\n        Remember: **Read first, then execute.** This ensures you use skills correctly!\n        \"\"\";\n}\n</code></pre>\n<h3 id=\"2-技能状态管理\">2. 技能状态管理</h3>\n<p>技能状态通过 <code>SkillsState</code> 类管理，支持序列化：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillsState\n{\n    public IReadOnlyList&lt;SkillMetadata&gt; UserSkills { get; init; } = [];\n    public IReadOnlyList&lt;SkillMetadata&gt; ProjectSkills { get; init; } = [];\n    public DateTimeOffset LastRefreshed { get; init; }\n\n    /// &lt;summary&gt;\n    /// 获取所有技能，项目级技能优先级更高\n    /// &lt;/summary&gt;\n    public IReadOnlyList&lt;SkillMetadata&gt; AllSkills\n    {\n        get\n        {\n            var projectSkillNames = ProjectSkills\n                .Select(s =&gt; s.Name)\n                .ToHashSet(StringComparer.OrdinalIgnoreCase);\n            \n            var userSkillsWithoutOverrides = UserSkills\n                .Where(s =&gt; !projectSkillNames.Contains(s.Name));\n            \n            return [.. ProjectSkills, .. userSkillsWithoutOverrides];\n        }\n    }\n\n    public SkillMetadata? GetSkill(string name)\n    {\n        return ProjectSkills.FirstOrDefault(s =&gt; \n                s.Name.Equals(name, StringComparison.OrdinalIgnoreCase))\n            ?? UserSkills.FirstOrDefault(s =&gt; \n                s.Name.Equals(name, StringComparison.OrdinalIgnoreCase));\n    }\n}\n</code></pre>\n<h3 id=\"3-路径安全验证\">3. 路径安全验证</h3>\n<p>所有文件操作都经过严格的路径安全验证：</p>\n<pre><code class=\"language-csharp\">public static class PathSecurity\n{\n    /// &lt;summary&gt;\n    /// 解析安全路径，防止路径遍历攻击\n    /// &lt;/summary&gt;\n    public static string? ResolveSafePath(string basePath, string relativePath)\n    {\n        var fullPath = Path.GetFullPath(Path.Combine(basePath, relativePath));\n        var normalizedBase = Path.GetFullPath(basePath);\n\n        // 确保解析后的路径仍在基础路径内\n        if (!fullPath.StartsWith(normalizedBase, StringComparison.OrdinalIgnoreCase))\n            return null;\n\n        return fullPath;\n    }\n\n    /// &lt;summary&gt;\n    /// 检查是否是符号链接\n    /// &lt;/summary&gt;\n    public static bool IsSymbolicLink(string path)\n    {\n        var fileInfo = new FileInfo(path);\n        return fileInfo.Attributes.HasFlag(FileAttributes.ReparsePoint);\n    }\n\n    /// &lt;summary&gt;\n    /// 验证路径是否安全\n    /// &lt;/summary&gt;\n    public static bool IsPathSafe(string targetPath, string allowedBasePath)\n    {\n        var normalizedTarget = Path.GetFullPath(targetPath);\n        var normalizedBase = Path.GetFullPath(allowedBasePath);\n        \n        return normalizedTarget.StartsWith(normalizedBase, StringComparison.OrdinalIgnoreCase);\n    }\n}\n</code></pre>\n<hr />\n<h2 id=\"使用方法\">使用方法</h2>\n<h3 id=\"基本用法\">基本用法</h3>\n<pre><code class=\"language-csharp\">using Maf.AgentSkills.Agent;\nusing OpenAI;\n\n// 创建 ChatClient\nvar chatClient = new OpenAIClient(apiKey)\n    .GetChatClient(\"gpt-4\")\n    .AsIChatClient();\n\n// 创建支持技能的 Agent\nvar agent = chatClient.CreateSkillsAgent(\n    configureSkills: options =&gt;\n    {\n        options.AgentName = \"my-assistant\";\n        options.ProjectRoot = Directory.GetCurrentDirectory();\n    },\n    configureAgent: options =&gt;\n    {\n        options.ChatOptions = new() \n        { \n            Instructions = \"You are a helpful assistant.\" \n        };\n    });\n\n// 使用 Agent\nvar thread = agent.GetNewThread();\nvar response = await agent.RunAsync(\"What skills do you have?\", thread);\nConsole.WriteLine(response.Text);\n</code></pre>\n<h3 id=\"线程序列化\">线程序列化</h3>\n<p>技能状态可以随线程一起序列化，支持持久化会话：</p>\n<pre><code class=\"language-csharp\">// 序列化线程\nvar serializedThread = thread.Serialize();\n\n// 保存到数据库或文件\nawait SaveThreadAsync(userId, serializedThread);\n\n// 稍后恢复并继续对话\nvar restoredThread = agent.DeserializeThread(serializedThread);\nvar response = await agent.RunAsync(\"Continue our chat\", restoredThread);\n</code></pre>\n<p><strong>序列化/反序列化流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837994-620347996.png\" /></p>\n<h3 id=\"依赖注入集成\">依赖注入集成</h3>\n<pre><code class=\"language-csharp\">var builder = Host.CreateApplicationBuilder(args);\n\n// 注册 ChatClient\nbuilder.Services.AddChatClient(sp =&gt;\n{\n    return new OpenAIClient(apiKey)\n        .GetChatClient(\"gpt-4\")\n        .AsIChatClient();\n});\n\n// 注册技能 Agent\nbuilder.Services.AddSingleton&lt;AIAgent&gt;(sp =&gt;\n{\n    var chatClient = sp.GetRequiredService&lt;IChatClient&gt;();\n    \n    return chatClient.CreateSkillsAgent(\n        configureSkills: options =&gt;\n        {\n            options.AgentName = \"di-agent\";\n            options.ProjectRoot = Directory.GetCurrentDirectory();\n            \n            options.ToolsOptions.EnableReadSkillTool = true;\n            options.ToolsOptions.EnableReadFileTool = true;\n        });\n});\n\nvar host = builder.Build();\nvar agent = host.Services.GetRequiredService&lt;AIAgent&gt;();\n\nvar thread = agent.GetNewThread();\n\nvar path = \"E:\\\\GitHub\\\\My\\\\dotnet-agent-skills\\\\NET+AI：技术栈全景解密.pdf\";\nvar response = await agent.RunAsync($\"请将指定目录：{path}的文件拆分前3页\", thread);\n</code></pre>\n<h3 id=\"启用脚本执行\">启用脚本执行</h3>\n<pre><code class=\"language-csharp\">var agent = chatClient.CreateSkillsAgent(\n    configureSkills: options =&gt;\n    {\n        options.AgentName = \"power-assistant\";\n        options.ProjectRoot = Directory.GetCurrentDirectory();\n        \n        // 启用脚本执行（需要显式开启）\n        options.ToolsOptions.EnableExecuteScriptTool = true;\n        options.ToolsOptions.AllowedScriptExtensions = [\".py\", \".ps1\", \".cs\"];\n        options.ToolsOptions.ScriptTimeoutSeconds = 60;\n        \n        // 启用命令执行（白名单模式）\n        options.ToolsOptions.EnableRunCommandTool = true;\n        options.ToolsOptions.AllowedCommands = [\"git\", \"npm\", \"dotnet\"];\n    });\n</code></pre>\n<hr />\n<h2 id=\"安全考量\">安全考量</h2>\n<h3 id=\"1-默认安全\">1. 默认安全</h3>\n<p>项目遵循\"默认安全\"原则：</p>\n<ul>\n<li><strong>脚本执行默认禁用</strong>：<code>EnableExecuteScriptTool = false</code></li>\n<li><strong>命令执行默认禁用</strong>：<code>EnableRunCommandTool = false</code></li>\n<li><strong>只读工具默认启用</strong>：<code>ReadSkill</code>, <code>ReadFile</code>, <code>ListDirectory</code></li>\n</ul>\n<h3 id=\"2-路径遍历防护\">2. 路径遍历防护</h3>\n<p>所有文件操作都限制在技能目录内：</p>\n<pre><code class=\"language-csharp\">// 读取文件时验证路径\nvar safePath = PathSecurity.ResolveSafePath(skill.Path, relativePath);\nif (safePath is null)\n{\n    return JsonSerializer.Serialize(new\n    {\n        success = false,\n        error = \"Path traversal attempt detected\"\n    });\n}\n</code></pre>\n<h3 id=\"3-脚本执行白名单\">3. 脚本执行白名单</h3>\n<p>即使启用了脚本执行，也只允许特定扩展名：</p>\n<pre><code class=\"language-csharp\">public class SkillsToolsOptions\n{\n    public List&lt;string&gt; AllowedScriptExtensions { get; set; } = [\".py\", \".ps1\", \".sh\", \".cs\"];\n    public int ScriptTimeoutSeconds { get; set; } = 30;\n    public int MaxOutputSizeBytes { get; set; } = 50 * 1024; // 50KB\n}\n</code></pre>\n<h3 id=\"4-命令执行白名单\">4. 命令执行白名单</h3>\n<p>命令执行采用严格的白名单机制：</p>\n<pre><code class=\"language-csharp\">options.AllowedCommands = [\"git\", \"npm\", \"dotnet\"]; // 只允许这些命令\n</code></pre>\n<hr />\n<h2 id=\"最佳实践\">最佳实践</h2>\n<h3 id=\"1-技能设计原则\">1. 技能设计原则</h3>\n<ul>\n<li><strong>单一职责</strong>：每个技能专注于一个领域</li>\n<li><strong>清晰描述</strong>：description 字段要足够描述技能用途</li>\n<li><strong>详细指令</strong>：SKILL.md 正文要包含完整的使用说明</li>\n<li><strong>示例驱动</strong>：提供具体的使用示例</li>\n</ul>\n<h3 id=\"2-目录组织\">2. 目录组织</h3>\n<pre><code># 推荐的技能目录结构\nmy-skill/\n├── SKILL.md              # 必需：技能定义文件\n├── README.md             # 可选：详细文档\n├── scripts/              # 脚本文件\n│   ├── main.py\n│   └── utils.py\n├── templates/            # 模板文件\n│   └── output.md\n└── config/               # 配置文件\n    └── settings.json\n</code></pre>\n<h3 id=\"3-skillmd-编写规范\">3. SKILL.md 编写规范</h3>\n<pre><code class=\"language-markdown\">---\nname: my-skill\ndescription: Brief description under 1024 characters\nlicense: MIT\nallowed-tools: web_search file_write\n---\n\n# Skill Name\n\n## Overview\nClear explanation of what this skill does.\n\n## When to Use\n- Situation 1\n- Situation 2\n\n## Prerequisites\n- Required tools or dependencies\n\n## Instructions\nStep-by-step workflow:\n\n1. First step\n2. Second step\n3. Third step\n\n## Available Scripts\n\n### script.py\n- **Purpose**: What it does\n- **Arguments**: `--input &lt;file&gt; --output &lt;file&gt;`\n- **Example**: `python script.py --input data.csv --output result.json`\n\n## Examples\n\n### Example 1: Basic Usage\n...\n</code></pre>\n<h3 id=\"4-项目级-vs-用户级技能\">4. 项目级 vs 用户级技能</h3>\n<ul>\n<li><strong>用户级技能</strong> (<code>~/.maf/{agent}/skills/</code>)：通用技能，适用于多个项目</li>\n<li><strong>项目级技能</strong> (<code>{project}/.maf/skills/</code>)：项目特定技能，可覆盖同名用户级技能</li>\n</ul>\n<hr />\n<h2 id=\"总结\">总结</h2>\n<p>Maf.AgentSkills 项目展示了如何基于 Microsoft Agent Framework 实现 Agent Skills 集成。</p>\n<p><strong>核心设计要点</strong>：</p>\n<ol>\n<li><strong>遵循 MAF 模式</strong>：使用 <code>AIContextProviderFactory</code> 实现无侵入式集成</li>\n<li><strong>渐进式披露</strong>：通过三层结构（元数据 → 指令 → 资源）优化 Token 使用</li>\n<li><strong>安全第一</strong>：默认禁用危险操作，采用白名单机制</li>\n<li><strong>线程序列化</strong>：完整支持会话持久化</li>\n<li><strong>依赖注入友好</strong>：易于集成到现有应用</li>\n</ol>\n<p>通过这套实现，开发者可以轻松为 AI Agent 添加可复用的专业技能，使 Agent 能够完成更复杂的任务。</p>\n<hr />\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://agentskills.io\" rel=\"noopener nofollow\" target=\"_blank\">Agent Skills 规范</a></li>\n<li><a href=\"https://github.com/microsoft/agent-framework\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft Agent Framework</a></li>\n<li><a href=\"https://github.com/dotnet/extensions\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft.Extensions.AI</a></li>\n</ul>\n<hr />\n\n</div>\n<div id=\"MySignature\">\n    <div style=\"display: block; border: 2px solid #6ecaa8; padding: 10px;\">  \n<img src=\"https://files.cnblogs.com/files/sheng-jie/maf-course-card-scan.bmp\" />\n<blockquote>\n<b>👆面向.NET开发者的AI Agent 开发课程【.NET+AI | 智能体开发进阶】已上线，欢迎扫码加入学习。👆</b>\n</blockquote>\n</div>\n\n<img src=\"https://files.cnblogs.com/files/sheng-jie/scan-follow.bmp\" />\n<blockquote>\n<b>\n关注我的公众号『向 AI 而行』，我们微信不见不散。\n<br />\n阅罢此文，如果您觉得本文不错并有所收获，请【打赏】或【推荐】，也可【评论】留下您的问题或建议与我交流。\n\n你的支持是我不断创作和分享的不竭动力！</b>\n</blockquote>\n\n<div id=\"AllanboltSignature\" style=\"display: block; border: 2px solid #6ecaa8; padding: 10px;\">    \n        <div>作者：<a href=\"http://www.jianshu.com/u/39ec0e6b1844\" target=\"_blank\">『圣杰』</a></div>\n        <div>出处：<a href=\"http://www.cnblogs.com/sheng-jie/\" target=\"_blank\">http://www.cnblogs.com/sheng-jie/</a></div>\n        <div>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。</div>  \n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 11:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sheng-jie\">「圣杰」</a>&nbsp;\n阅读(<span id=\"post_view_count\">156</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "基于openspec-cn的SDD规范驱动开发实战",
      "link": "https://www.cnblogs.com/shiningrise/p/19441876",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shiningrise/p/19441876\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 11:12\">\n    <span>基于openspec-cn的SDD规范驱动开发实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"规范驱动开发-简单介绍\">规范驱动开发 简单介绍</h2>\n<p>规范驱动开发（Specification Driven Development，简称 SDD 或 SpecDD）是一种以规范为核心的软件工程方法，既包含传统敏捷开发衍生出的混合型模式，也发展出适配 AI 时代的新型开发范式，核心是让规范成为开发全流程的核心指引与执行依据</p>\n<h1 id=\"新建项目二维码生成器英文名qrcodecreator\">新建项目：二维码生成器（英文名：QrcodeCreator）</h1>\n<h2 id=\"新建目录-qrcodecreator\">新建目录 QrcodeCreator</h2>\n<p>在QrcodeCreator目录打开cursor</p>\n<h2 id=\"步骤1全局安装cli\">步骤1：全局安装CLI</h2>\n<pre><code>npm install -g @studyzy/openspec-cn@latest\n</code></pre>\n<h2 id=\"步骤2在项目中初始化openspec\">步骤2：在项目中初始化OpenSpec</h2>\n<pre><code>openspec-cn init\n</code></pre>\n<p>选择cursor编辑器</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2025/20260105101011477.png\" /></p>\n<p>生成如下目录结构：</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105101532472.png\" /></p>\n<p>复制以下内容到cursor对话框</p>\n<pre><code>1. 填充您的项目上下文：\n   \"请阅读 openspec/project.md 并帮我填写\n    我的项目详情、技术栈和约定规范\"\n</code></pre>\n<p>修改：project.md</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105105705596.png\" /></p>\n<h2 id=\"新建提案\">新建提案</h2>\n<pre><code>AI对话框，我：我想创建一个规范提案:新增一张html页面,根据输入的网址生成二维码\n</code></pre>\n<p>生成如下文件</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105102929047.png\" /></p>\n<pre><code>修改提案：add-url-qrcode-generator  不使用python，仅使用html+javascript实现qrcode生成功能\n</code></pre>\n<h2 id=\"生成代码\">生成代码</h2>\n<pre><code>输入命令/openspec-apply 生成代码\n</code></pre>\n<h2 id=\"归档\">归档</h2>\n<pre><code>/openspec-archive add-url-qrcode-generator\n</code></pre>\n<h2 id=\"完成后的项目结构\">完成后的项目结构</h2>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105110141451.png\" /></p>\n<p>使用浏览器打开index.html</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105110229694.png\" /></p>\n<h1 id=\"openspec-cn项目网址\">openspec-cn项目网址</h1>\n<p><a href=\"https://github.com/studyzy/OpenSpec-cn\" rel=\"noopener nofollow\" target=\"_blank\">studyzy/OpenSpec-cn: OpenSpec汉化版</a></p>\n<p>项目完成展示网址：<br />\n<a href=\"https://qrcode.wxy.vip/\" rel=\"noopener nofollow\" target=\"_blank\">https://qrcode.wxy.vip/</a></p>\n\n</div>\n<div id=\"MySignature\">\n    欢迎光临:<font size=\"3\"><font size=\"3\"><a href=\"http://shiningrise.cnblogs.com/\" target=\"_blank\"><font size=\"3\"><font size=\"3\">http://shiningrise.cnblogs.com</font></font></a><br /><br /></font></font>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 11:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shiningrise\">shiningrise</a>&nbsp;\n阅读(<span id=\"post_view_count\">55</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从手动到自动：基于 Mutating Admission Webhook 实现 Envoy Sidecar 自动注入",
      "link": "https://www.cnblogs.com/MrVolleyball/p/19441540",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/MrVolleyball/p/19441540\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 11:04\">\n    <span>从手动到自动：基于 Mutating Admission Webhook 实现 Envoy Sidecar 自动注入</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在微服务规模不断扩大的场景下，手动为每个 Pod 注入 Envoy Sidecar 已经难以维护。本文从实际工程问题出发，详细讲解如何利用 Kubernetes 的 Mutating Admission Webhook 机制，实现 Envoy Sidecar 的自动注入。内容涵盖证书生成、Webhook 配置、注入服务实现，以及基于 Namespace / Pod Label 的精细化注入控制\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>上一小节我们详细讨论了如何做流量劫持，并且使用initContainers来做自动劫持的配置。但是目前还有一个问题，如果我们的系统有好几百个微服务，那作为重要的代理envoy，是手动注入的，难道每个微服务都要手动编辑一次 ？这显然是不可承受的，所以这一节，我们来详细讨论一下自动注入的问题</p>\n<h2 id=\"环境准备\">环境准备</h2>\n<p>由于本节只讨论容器注入，所以只需要准备一个普通的deployment就行了</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: backend\n  template:\n    metadata:\n      labels:\n        app: backend\n    spec:\n      containers:\n      - image: backend-service:v1\n        imagePullPolicy: Never\n        name: backend\n        ports:\n        - containerPort: 10000\n          protocol: TCP\n        resources: {}\n      restartPolicy: Always\n</code></pre>\n<h2 id=\"mutating-admission-webhooks\">mutating admission webhooks</h2>\n<p><img alt=\"auto_injection_1\" class=\"lazyload\" /></p>\n<p>简单来说，就是当pod重启的时候，会发起一系列的过程，其中在mutating admission controller 这里，k8s提供了一个webhooks，可以回调到指定的地方去，所以我们需要创建一个server来处理该回调，添加一个容器进去，完成容器注入的工作</p>\n<h4 id=\"创建相关证书\">创建相关证书</h4>\n<pre><code>cd /etc/kubernetes/pki\n</code></pre>\n<p>创建openssl.cnf</p>\n<pre><code>[ req ]\ndistinguished_name = req_distinguished_name\nreq_extensions = v3_req\nprompt = no\n\n[ req_distinguished_name ]\nCN = sidecar-webhook.default.svc\n\n[ v3_req ]\nkeyUsage = keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[ alt_names ]\nDNS.1 = sidecar-webhook\nDNS.2 = sidecar-webhook.default\nDNS.3 = sidecar-webhook.default.svc\n\n</code></pre>\n<p>从k8s根证书中创建证书</p>\n<pre><code>sudo openssl req -x509 -newkey rsa:2048 \\\n  -keyout tls.key \\\n  -out tls.crt \\\n  -days 365 -nodes \\\n  -config openssl.cnf \\\n  -extensions v3_req\n</code></pre>\n<h4 id=\"创建mutatingwebhookconfiguration\">创建MutatingWebhookConfiguration</h4>\n<pre><code>mytls=`cat tls.crt | base64 | tr -d '\\n'`\n\necho 'apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: sidecar-injector\nwebhooks:\n- name: sidecar.demo.io\n  clientConfig:\n    service:\n      name: sidecar-webhook\n      namespace: default\n      path: /mutate\n    caBundle: '$mytls'\n  rules:\n  - apiGroups: [\"\"]\n    apiVersions: [\"v1\"]\n    operations: [\"CREATE\"]\n    resources: [\"pods\"]\n  admissionReviewVersions: [\"v1\"]\n  sideEffects: None' | kubectl apply -f -\n\n</code></pre>\n<h4 id=\"创建服务来接收webhook\">创建服务来接收webhook</h4>\n<p><a href=\"https://github.com/wilsonchai8/myblog/blob/main/micro_service/injection/inject.go\" rel=\"noopener nofollow\" target=\"_blank\">自动注入服务</a></p>\n<p>这没什么可说的，需要注意的就是注入pod的配置直接写在了代码里面，并且注入了2个部分，首先是sidecar container，其次是sidecar的volumes配置（pod级别的）</p>\n<pre><code>        patch := []map[string]interface{}{\n                {\n                        \"op\":   \"add\",\n                        \"path\": \"/spec/containers/-\",\n                        \"value\": map[string]interface{}{\n                                \"image\":           \"registry.cn-beijing.aliyuncs.com/wilsonchai/envoy:v1.32-latest\",\n                                \"imagePullPolicy\": \"IfNotPresent\",\n                                \"name\":            \"envoy\",\n                                \"args\":            []string{\"-c\", \"/etc/envoy/envoy.yaml\"},\n                                \"volumeMounts\": []map[string]interface{}{\n                                        {\n                                                \"mountPath\": \"/etc/envoy\",\n                                                \"name\":      \"envoy-config\",\n                                        },\n                                },\n                        },\n                },\n                {\n                        \"op\":   \"add\",\n                        \"path\": \"/spec/volumes/-\",\n                        \"value\": map[string]interface{}{\n                                \"configMap\": map[string]interface{}{\n                                        \"defaultMode\": 420,\n                                        \"name\":        \"envoy-config\",\n                                },\n                                \"name\": \"envoy-config\",\n                        },\n                },\n        }\n\n</code></pre>\n<pre><code>▶ go run inject.go\n2025/12/29 14:58:19 Webhook listening on :8443\n\n</code></pre>\n<p>打开8443端口以便接收请求</p>\n<h4 id=\"创建访问路径\">创建访问路径</h4>\n<p>我们的服务在集群外，所以创建一个endpoint指向集群之外</p>\n<pre><code>echo 'apiVersion: v1\nkind: Service\nmetadata:\n  name: sidecar-webhook\nspec:\n  ports:\n  - port: 443\n    targetPort: 8443\n    protocol: TCP\n  type: ClusterIP\n\n---\n\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: sidecar-webhook\n  namespace: default\nsubsets:\n- addresses:\n  - ip: 10.22.12.178\n  ports:\n  - port: 8443\n    protocol: TCP' | kubectl apply -f -\n</code></pre>\n<h4 id=\"验证\">验证</h4>\n<p>重启backend服务，<code>kubectl rollout restart deploy backend</code></p>\n<pre><code>cannot bind '0.0.0.0:10000': Address already in use\n\n</code></pre>\n<p>出现了报错，这应该是由于envoy是监听10000端口，backend服务监听的也是10000端口，现在它们在一个net namespace，就肯定要报错了，所以改一下envoy的配置，监听另外一个端口吧，10000改成10001</p>\n<pre><code>      listeners:\n        - name: ingress_listener\n          address:\n            socket_address:\n              address: 0.0.0.0\n              port_value: 10001\n</code></pre>\n<p>再次重启查看pod状态</p>\n<pre><code>▶ kubectl get pod -owide -l app=backend\nNAME                       READY   STATUS    RESTARTS   AGE    IP             NODE     NOMINATED NODE   READINESS GATES\nbackend-6bdf5d484b-5czgx   2/2     Running   0          100s   10.244.0.184   wilson   &lt;none&gt;           &lt;none&gt;\n\n</code></pre>\n<p>查看详情</p>\n<p><img alt=\"auto_injection_2\" class=\"lazyload\" /></p>\n<p>自动注入了envoy容器</p>\n<p>至此，架构图如下：</p>\n<p><img alt=\"auto_injection_3\" class=\"lazyload\" /></p>\n<h2 id=\"精细化注入\">精细化注入</h2>\n<p>按照目前的配置，只要有pod create，就立刻回调集群外的注入服务，如果k8s集群的服务很多，并且频繁的create/destroy，那就会对注入服务产生较大的压力。如果在这些服务中，只有一些服务是需要使用自动注入功能的，那 就需要更精细化的注入管理</p>\n<h4 id=\"namespace打标签\">namespace打标签</h4>\n<p>首先要调整一下MutatingWebhookConfiguration</p>\n<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: sidecar-injector\nwebhooks:\n- name: sidecar.demo.io\n  namespaceSelector:\n    matchLabels:\n      sidecar-inject: \"true\"\n...\n</code></pre>\n<p>加上标签 <code>sidecar-inject: \"true\"</code>，只有满足这个标签，才会回调到外部的注入服务，这样就可以大大减轻注入服务的压力了</p>\n<p>再给namespace打上标签</p>\n<pre><code>kubectl label ns default sidecar-inject=true\n</code></pre>\n<p>default namespace里面所有的pod，都会回调至外部注入服务</p>\n<h4 id=\"pod-打标签\">pod 打标签</h4>\n<p>这次不在namespace下，而是基于某个pod label</p>\n<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: sidecar-injector\nwebhooks:\n- name: sidecar.demo.io\n  objectSelector:\n    matchLabels:\n      sidecar-inject-pod: \"true\"\n...\n</code></pre>\n<p>然后再给deployment打标签，这里要注意打的是pod的标签</p>\n<pre><code>kubectl patch deployment backend \\\n  --type='merge' \\\n  -p '{\n    \"spec\": {\n      \"template\": {\n        \"metadata\": {\n          \"labels\": {\n            \"sidecar-inject-pod\": \"true\"\n          }\n        }\n      }\n    }\n  }'\n</code></pre>\n<h2 id=\"小结\">小结</h2>\n<p>本文详细描述了怎么做自动注入：k8s配置修改+外部注入服务。其中需要注入的pod是写死在注入服务的，这部分可以抽出来，将配置写成configmap，或者在其他的配置中心中，这样就不用频繁的修改注入服务了</p>\n<p>另外mutating webhooks可以拦截大部分k8s支持的资源，并且发送到所配置的外部服务中进行需要的配置，这就不单单是pod自动注入，而是资源拦截。比如我需要拦截configmap</p>\n<pre><code>echo 'apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: callback-configmap\nwebhooks:\n- name: sidecar.demo.io\n  clientConfig:\n    service:\n      name: sidecar-webhook\n      namespace: default\n      path: /mutate\n    caBundle: '$mytls'\n  rules:\n  - apiGroups: [\"\"]\n    apiVersions: [\"v1\"]\n    operations: [\"CREATE\", \"UPDATE\"]\n    resources: [\"configmaps\"]\n  admissionReviewVersions: [\"v1\"]\n  sideEffects: None' | kubectl apply -f -\n</code></pre>\n<p>resources变更为configmap之后，就可以直接回调到外部服务。本章由于篇幅有限，就不对这个话题展开了，这个以后有需要再来详细讨论</p>\n<h2 id=\"联系我\">联系我</h2>\n<ul>\n<li>联系我，做深入的交流</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" height=\"200\" width=\"500\" /></p>\n<hr />\n<p>至此，本文结束<br />\n在下才疏学浅，有撒汤漏水的，请各位不吝赐教...</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/MrVolleyball/\" target=\"_blank\">it排球君</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/MrVolleyball/p/19441540\" target=\"_blank\">https://www.cnblogs.com/MrVolleyball/p/19441540</a></p>\n<div>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须在文章页面给出原文连接，否则保留追究法律责任的权利。 </div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 11:04</span>&nbsp;\n<a href=\"https://www.cnblogs.com/MrVolleyball\">it排球君</a>&nbsp;\n阅读(<span id=\"post_view_count\">36</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Volcano 社区发布 Kthena 子项目 | 重新定义大模型智能推理",
      "link": "https://www.cnblogs.com/huaweiyun/p/19441472",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/huaweiyun/p/19441472\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 10:15\">\n    <span>Volcano 社区发布 Kthena 子项目 | 重新定义大模型智能推理</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p align=\"center\" style=\"text-align: left;\">Volcano 是 CNCF 首个云原生智能调度引擎，由华为云发起开源并深度参与贡献。12月29日，Volcano 宣布社区迎来了一个新的子项目 Kthena！&nbsp;</p>\n<p><img alt=\"\" class=\"lazyload\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p>Kthena 是一个专为 Kubernetes 设计的云原生、高性能的 LLM 推理路由和编排、调度系统。它旨在解决在生产环境中大规模编排、部署和服务 LLM 所面临的核心挑战，通过其独特的 超节点拓扑感知的亲和性调度，KV Cache 感知的流量调度、Prefill/Decode 分离路由等高级功能，显著提升 GPU/NPU 资源利用率和吞吐，降低推理延迟，并赋予企业前所未有的灵活性和控制力。作为 Volcano 的子项目，Kthena将致力于帮助 Volcano 扩展除 AI 训练之外的边界，打造训推一体的完整解决方案。</p>\n<h2><strong>LLM 服务化的“最后一公里”困境</strong></h2>\n<p>大语言模型（LLM）正在以前所未有的速度重塑各行各业，但将其高效、经济地部署在生产环境中，特别是基于 Kubernetes 的云原生平台上，仍然困难重重。开发者们普遍面临以下挑战：</p>\n<ol>\n<li><strong>资源利用率低</strong>：LLM 推理，尤其是其独特的 KV Cache 机制，对 GPU、NPU 显存的占用是动态且巨大的。传统的负载均衡一般采用Round-Robin算法，无法感知这种负载特性，导致 GPU、NPU 资源闲置与请求排队并存，成本高昂。</li>\n<li><strong>延迟与吞吐量难以兼顾</strong>：LLM 推理分为“Prefill”（处理输入提示）和“Decode”（生成 Token）两个阶段，前者是计算密集型，后者是访存密集型。将两者混合调度，常常导致无法针对性优化，影响整体服务的响应速度和吞吐能力。因此PD分离的部署已经成为主流，但如何高效路由和调度，仍是一个难题。</li>\n<li><strong>多租户与多模型管理复杂</strong>：在企业环境中，通常需要同时提供多个不同模型、不同版本或经过 LoRA 微调的模型。如何实现请求的公平调度、优先级管理以及动态路由，是一个复杂的工程难题，业界甚至有些方案将AI网关与大模型一一对应。</li>\n<li><strong>缺乏K8s原生集成</strong>：许多现有的解决方案要么是外部系统，与 Kubernetes 生态割裂；要么过于复杂，无法满足生产级所需的简单易用性和灵活运维。</li>\n</ol>\n<p>&nbsp;</p>\n<h2><strong>Kthena：云原生 LLM 推理的智能大脑</strong></h2>\n<p>&nbsp;</p>\n<p>为了攻克上述难题，Kthena 应运而生。它并非要取代现有的 LLM 服务框架（如 vLLM, sgLang），而是作为它们上层的智能“交通枢纽”和“调度中心”，深度集成于 Kubernetes 之中。</p>\n<p>&nbsp;<img alt=\"\" class=\"lazyload\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p style=\"text-align: center;\">Kthena 架构图</p>\n<p>Kthena 的核心由两大组件构成：</p>\n<p>1)&nbsp;&nbsp;&nbsp; Kthena Router：一个独立、高性能面向多模型的router，负责接收所有推理请求，并根据 `ModelRoute` 规则，智能地将请求分发到后端的 `ModelServer`。</p>\n<p>2)&nbsp;&nbsp;&nbsp; Kthena Controller Manager：Kubernetes 控制平面的控制器，它主要包含多种控制器，负责 LLM 工作负载的编排与生命周期管理。它持续调谐并联动多类 CRD（如 `ModelBooster`、`ModelServing`、`AutoScalingPolicy`/`AutoScalingPolicyBinding`、以及 `ModelRoute`/`ModelServer`），将声明式API转化为运行时资源：ModelServing 控制器编排 `ServingGroup` 与 `Prefill/Decode` 角色分组；支持网络拓扑亲和调度和Gang调度、滚动升级与故障恢复；基于 `AutoScalingPolicy` 实现弹性扩缩容。</p>\n<p>这种架构使得 Kthena 成为连接用户请求与 LLM 模型的高度可编程的桥梁。</p>\n<h2><strong>核心特性与优势</strong></h2>\n<p>Kthena 的强大之处在于其专为 LLM 推理场景设计的核心功能：</p>\n<p><strong>1) 生产级推理编排（ModelServing）</strong></p>\n<p>&nbsp;<img alt=\"\" class=\"lazyload\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>LLM</strong><strong>工作负载三层架构设计</strong>：ModelServing -&gt; ServingGroup -&gt; Role，一个API，支持LLM原生部署、PD分离部署，乃至大EP部署等多种部署形态，简化管理多LWS的负担。例如对于PD分离的大规模部署，可用一个ModelServing表示，根据负载的大小每个ModelServing可以包含任意数目的 ServingGroup（xPyD 分组）， 每个ServingGroup包含多个角色（Prefill Decode，他们通常部署在同一个超节点内以提升推理性能），相同的角色可以等价为一个LeaderWorkerSet，支持TP/PP/EP等多节推理并行计算。</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>原生支持Prefill-Decode分离部署</strong>：将计算密集型的 Prefill 实例调度到配备高性能计算卡的节点组，而将访存密集型的 Decode 实例调度到配备高带宽显存的节点组，实现资源的最佳匹配和极致的端到端延迟优化。另可以独立伸缩，动态调整Prefill-Decode的比例，更灵活的应对各种复杂的业务场景（如长短句混合、实时推理等）。</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>多并行范式支持</strong>：TP/PP/DP/EP 等并行模式灵活配置，最大化提升资源利用率和SLO</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>内置拓扑感知、Gang 调度支持</strong>：Gang调度确保ServingGroup/Role“成组原子化”落地，避免资源浪费；拓扑感知调度通过将Role内的一组Pod调度到网络拓扑更优的节点，提升并行计算的数据传输时延。</p>\n<p><strong>2) 开箱即用的模型上线（ModelBooster）</strong></p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 针对主流的大模型，提供包括PD分离在内的多种部署范式模板，自动生成ModelRoute/ModelServer/ModelServing/Autoscaling等路由策略和生命周期管理资源</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 覆盖通用的部署场景，至于更灵活的编排可通过ModelServing进行细粒度的控制</p>\n<p><strong>3) </strong><strong>智能、模型感知的路由</strong><strong>（Kthena Router）</strong></p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>多模型路由</strong>：兼容OpenAI API，根据请求头或Body体内容，将流量调度到不同的基础模型。</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>插件化调度算法</strong>：提供最少请求、最小时延、KV Cache 感知、Prefix Cache 感知、LoRA 亲和、GPU 利用率感知、公平调度等多种负载均衡算法，满足用户不同业务场景和部署形态的需求</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>LoRA 模型热插拔无中断</strong>：感知推理引擎加载的LoRA 适配器，提供无中断的插拔和路由能力</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>丰富的流量治理策略</strong>：基于权重的模型路由，金丝雀发布、Token级流控、故障转移·</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>All-in-one实现架构</strong>，无需部署Envoy Gateway，原生支持PD分离的流量调度，将多层路由合并成一层，易于维护</p>\n<p><strong>4) 成本驱动的自动扩缩容（Autoscaler）</strong></p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>同构伸缩</strong>：支持稳定、突发双模式，按业务指标（CPU/GPU/内存/自定义）精准扩缩</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>异构部署优化</strong>：在多推理引擎/异构加速器组合中按“成本-能力”贪心分配，最大化性价比</p>\n<p><strong>5) 主流推理引擎与异构硬件支持</strong></p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 支持多种主流推理引擎vLLM、SGLang、Triton/TGI 等，统一API抽象、标准化指标</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>支持GPU/NPU 等异构混部</strong>，配合异构 Autoscaling 实现成本与 SLO 的动态平衡</p>\n<p><strong>6) 内置流量控制与公平性调度</strong></p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>公平调度</strong>：支持基于优先级和历史Token消耗的的公平调度，既兼顾用户的优先级，对高优先级用户提供更好的服务，又防止低优先级用户“饿死”</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>流量控制</strong>：支持按照用户、模型、token长度进行精细化流量控制</p>\n<h2><strong>极致的性能提升</strong></h2>\n<p>基于 Kthena Router 的调度插件架构，在长系统提示词场景（如 4096 tokens）下，采用“KV Cache 感知 + 最少请求”策略相较随机基线：</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 吞吐可提升约 2.73 倍</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TTFT 降低约 73.5%</p>\n<p>-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 端到端时延降低超过 60%</p>\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" style=\"width: 602px;\">\n<tbody>\n<tr>\n<td valign=\"top\" width=\"150\">\n<p>Plugin Configuration</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>Throughput (req/s)</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>&nbsp;TTFT (s)</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>&nbsp;E2E Latency (s)</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"150\">\n<p>Least Request + KVCacheAware</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p><strong>32.22</strong></p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p><strong>9.22</strong></p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p><strong>0.57</strong></p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"150\">\n<p>Least Request + Prefix Cache</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>23.87</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>12.47</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>0.83</p>\n</td>\n</tr>\n<tr>\n<td valign=\"top\" width=\"150\">\n<p>Random</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>11.81</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>25.23</p>\n</td>\n<td valign=\"top\" width=\"150\">\n<p>2.15</p>\n</td>\n</tr>\n</tbody>\n</table>\n<p>短提示词场景差距会随提示词长度收敛，但在多轮对话、模板化生成、前缀高度相似的业务中，KV Cache 感知策略优势显著。实际收益与模型规模、Prompt长短、硬件紧密相关，但“按需组合、按场景选型”已被验证有效。</p>\n<h2><strong>社区展望 / Call for Contribution</strong></h2>\n<p>Kthena 在项目规划和发展的初期便得到了部分社区用户单位的关注和支持，但这只是一个开始。我们计划在未来支持更高效的调度算法、更广泛的大模型最佳部署实践，并持续深耕 LLM 推理的大规模部署和性能优化。</p>\n<p>&nbsp;</p>\n<p>“开源是技术创新的源头活水，也是推动产业标准化的最强引擎。作为Volcano项目的发起单位，华为云很荣幸能够与社区其他伙伴一起推出全新的Kthena分布式推理项目。这不仅是Volcano社区技术演进重要里程碑，更是华为云在云原生AI领域长期投入与持续创新的有力见证。它将与华为云CCE（云容器引擎）、CCI（云容器实例）等基础设施深度结合，进一步释放包括昇腾（Ascend）在内的多元算力价值，为客户提供极致的算力性价比。我们希望通过Kthena，与全球开发者与伙伴，共建、共享一个开放、繁荣的云原生AI生态，为千行万业的智能化升级构筑最坚实的算力底座。”</p>\n<p align=\"right\">&nbsp; —— 祁小波，华为云通用计算服务产品部部长</p>\n<p>&nbsp;</p>\n<p>“Kthena进一步巩固了Volcano在智能计算调度领域的领先地位。我们的平台利用Volcano的统一调度与资源池化能力，一站式满足通用计算与智能计算中训练、推理等多类算力需求。这使得算力资源能够在不同场景间灵活流转，有效避免了资源割裂的问题。展望未来，我们期待 Kthena结合Volcano的弹性伸缩能力与Volcano Global的跨集群调度特性，共同推动算力资源利用率进一步提升！”</p>\n<p align=\"right\">—— 杨磊，中电信人工智能公司 PaaS研发总监杨磊</p>\n<p>&nbsp;</p>\n<p>“Volcano 项目自诞生之日起，便始终与社区以及各类 AI 场景深度共建、同频演进，逐步沉淀出一整套面向 AI 工作负载的调度与批处理生态。今天，Kthena 的出现，不仅将这条共建链路进一步拓展到大模型推理领域，把推理这一关键一环真正纳入 Volcano 生态之中，更是在统一编排与智能路由层面，将 Volcano 在调度、弹性伸缩以及多算力适配上的多年实践，凝练成一个令人振奋的里程碑式能力。借助既有的 Kubernetes / Volcano 生态，更多团队可以用更低的成本，获得更智能的调度决策和更高效的算力利用，并在开放协作的基础上持续演进。这不仅为道客解决了在推理场景中遇到的实际问题，也是我们所期待的云原生 AI 形态——一个足够开放、足够智能、值得我们长期投入和深度参与的社区方向。”</p>\n<p align=\"right\">—— 徐俊杰，DaoCloud 开源团队负责人、Kubernetes 社区指导委员会成员</p>\n<p>&nbsp;</p>\n<p>“自建大模型推理服务的生产级部署和运维难题，是一个覆盖推理服务全生命周期管理（部署、运维、弹性、故障恢复等），GPU集群稳定性，资源调度效率、推理服务性能提升，推理流量智能调度、AI可观测等领域的系统工程。而这也正是Kthena项目的技术定位。</p>\n<p>早在Kthena的规划阶段，小红书云原生团队就和Volcano贡献者做了深度的沟通，在推理流量智能调度方向，一起设计了多种流量调度策略和路由实现。未来，双方将继续在AI网关方向合作，结合小红书内部业务经验，一起为社区提供更精细化的AI流量智能调度能力，模型API管理能力，MCP协议支持等多种生产可用能力。”</p>\n<p align=\"right\">—— 空古(陈华昌)，小红书云原生业务网关负责人</p>\n<p>&nbsp;</p>\n<p>“在深入调研并试用Kthena这一云原生AI推理平台后，联通云对其展现出的前瞻能力印象深刻。我们尤为看好其与Volcano实现的联合调度特性，其网络拓扑感知与Gang Scheduling功能，能够有效解决大规模分布式模型推理场景下中，关于效率与可靠性的核心诉求，为破解复杂调度难题提供了极具潜力的解决方案。我们相信，Kthena卓越的低延迟、高吞吐与多模型智能路由能力，将为开源社区带来真正具备生产级的AI推理解决方案，助力开发者更高效地构建和管理云原生环境下的智能应用。”&nbsp;</p>\n<p align=\"right\">—— 卢照旭，联通云智算能力中心团队长</p>\n<p>&nbsp;</p>\n<p>“开放和协作是构建社区的未来、加速技术创新的核心动力。在CNCF，我们持续致力于推动基础设施向‘AI Native’演进，为整个云原生生态提供标准、中立且可扩展的基础能力。Volcano社区通过孵化Kthena子项目，将其在大规模批量计算和调度上积累的拓扑感知、Gang调度等核心经验，精准地应用到了LLM在线推理这一关键场景。Kthena的价值在于，它提供了一套专为大模型设计、可供业界参考和借鉴的云原生调度原语和抽象，如Prefill/Decode分离编排和KV Cache感知路由，这有助于将复杂的LLM推理工作负载，真正以Kubernetes原生的一等公民身份进行高效管理。这不仅是Volcano项目技术演进的重要一步，更是社区生态在解决AI规模化部署挑战中贡献的一份重要实践经验。我们诚挚邀请全球的开发者、研究人员和所有云原生爱好者加入，共同贡献智慧，完善这些关键AI基础设施，加速 AI Native 进程。”</p>\n<p align=\"right\">—— Kevin Wang,&nbsp; Volcano Maintainer、CNCF TOC 副主席</p>\n<p>&nbsp;</p>\n<h2><strong>立即开始探索 Kthena</strong></h2>\n<p><strong>GitHub 仓库</strong>: <a href=\"https://github.com/volcano-sh/kthena\" rel=\"noopener nofollow\">https://github.com/volcano-sh/kthena</a></p>\n<p><strong>官网</strong>:&nbsp; <a href=\"https://kthena.volcano.sh/\" rel=\"noopener nofollow\">https://kthena.volcano.sh/</a></p>\n<p><strong>社区</strong>: 加入我们的 Slack <a href=\"https://cloud-native.slack.com/archives/C011GJDQS0N\" rel=\"noopener nofollow\">https://cloud-native.slack.com/archives/C011GJDQS0N</a>&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 10:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/huaweiyun\">华为云开发者联盟</a>&nbsp;\n阅读(<span id=\"post_view_count\">42</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[微服务进阶场景实战] - “微服务数据依赖症”",
      "link": "https://www.cnblogs.com/yhup/p/19441312",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yhup/p/19441312\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 09:58\">\n    <span>[微服务进阶场景实战] - “微服务数据依赖症”</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"[微服务进阶场景实战] - “微服务数据依赖症”\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095759528-1147748526.png\" />\n        本文探讨了微服务架构中服务间数据依赖问题的解决方案。针对供应链系统中商品、订单、采购服务间的数据查询需求，传统跨服务调用方案存在性能低下、服务过载和依赖链雪崩三大问题。提出数据冗余方案，通过同步或异步方式更新冗余数据，但面临同步更新导致核心流程被绑架、消息异步更新带来订阅泛滥和逻辑重复等问题。最终采用基于Bifrost的数据同步方案，将商品主数据实时同步至下游服务数据库，实现业务逻辑解耦。该方案具有配置简单、维护成本低等优势，但需注意同步延迟、只读原则和监控等关键事项，避免在核心流程中依赖同步数据。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><font style=\"color: rgba(15, 17, 21, 1);\">在解决了数据一致性的麻烦后，我们转向微服务的另一个经典难题：</font><strong><font style=\"color: rgba(15, 17, 21, 1);\">服务间的数据依赖</font></strong><font style=\"color: rgba(15, 17, 21, 1);\">。这就像在一个团队里，每个人都需要频繁向某个同事询问信息，一旦他请假，整个工作就卡住了。</font>还是先来说说具体的业务场景。</p>\n<h1 id=\"1-业务场景如何解决微服务之间的数据依赖问题\">1 业务场景：如何解决微服务之间的数据依赖问题</h1>\n<p>在解决了数据一致性的麻烦后，我们转向微服务的另一个经典难题：<strong>服务间的数据依赖</strong>。这就像在一个团队里，每个人都需要频繁向某个同事询问信息，一旦他请假，整个工作就卡住了。</p>\n<p>以一个供应链系统为例，核心服务包括<strong>商品</strong>、<strong>订单</strong>和<strong>采购</strong>。它们的主要数据结构简化如下：</p>\n<ul>\n<li><strong>商品表</strong>：商品ID、名称、<strong>分类</strong>、<strong>型号</strong>、<strong>生产年份</strong>、<strong>编码</strong>。</li>\n<li><strong>订单表</strong>：订单ID、下单时间、客户、总金额。\n<ul>\n<li><strong>子订单表</strong>：子订单ID、<strong>商品ID</strong>、单价、数量。</li>\n</ul>\n</li>\n<li><strong>采购单表</strong>：采购单ID、下单时间、供应商、总金额。\n<ul>\n<li><strong>采购子订单表</strong>：采购子订单ID、<strong>商品ID</strong>、单价、数量。</li>\n</ul>\n</li>\n</ul>\n<p>业务上存在这样的查询需求：</p>\n<ol>\n<li>根据商品的<strong>型号、分类、生产年份</strong>等属性，查询相关订单。</li>\n<li>根据同样的商品属性，查询相关的采购单。</li>\n</ol>\n<p>订单的整个查询流程如图所示。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095648079-1760772106.png\" /></p>\n<p>起初，我们严格遵守微服务边界：</p>\n<ul>\n<li><strong>商品数据</strong>的存储与查询职责，完全归属于<strong>商品服务</strong>。</li>\n<li><strong>订单服务</strong>和<strong>采购服务</strong>各自管理自己的单据数据。</li>\n</ul>\n<p>那么，当需要在订单或采购单中按商品属性查询时，流程被迫变得复杂：</p>\n<ol>\n<li><strong>调用商品服务</strong>：首先，将商品属性（如“型号=A”）发送给商品服务，获取所有匹配的<strong>商品ID列表</strong>。</li>\n<li><strong>本地关联查询</strong>：接着，在订单或采购服务的数据库中，使用 <code>IN</code> 语句，通过上一步得到的商品ID列表，关联查询出最终的单据。</li>\n</ol>\n<p>整个查询流程如下图所示（此处为原流程图示意）。</p>\n<p><strong>这个方案很快暴露了三大问题：</strong></p>\n<ol>\n<li><strong>查询性能低下</strong>：随着商品数量增长，一次查询可能返回成千上万个商品ID。在订单/采购数据库中用庞大的 <code>IN (...)</code> 列表进行关联查询，效率急剧下降。</li>\n<li><strong>核心服务过载</strong>：商品服务成为瓶颈。几乎所有查询都依赖它，导致其负载过高，响应变慢，甚至频繁超时。</li>\n<li><strong>依赖链雪崩</strong>：一旦商品服务响应慢或失败，所有依赖它的订单、采购查询都会跟着失败或超时，用户体验极差。</li>\n</ol>\n<p>结果就是：业务人员一旦使用商品条件进行查询，系统就变得又慢又不稳定。于是，团队开始思考一个新方案——<strong>数据冗余</strong>。这正是我们接下来要详细探讨的解决方案。</p>\n<h1 id=\"2-数据冗余方案\">2 数据冗余方案</h1>\n<p>为了解决跨服务查询的效率与依赖问题，一个直接的思路是：<strong>在订单、采购等服务中，冗余存储必要的商品信息</strong>。调整后的数据结构如下：</p>\n<ul>\n<li><strong>商品表</strong>：商品ID、名称、分类、型号、生产批号ID、编码。（保持不变）</li>\n<li><strong>订单表</strong>与<strong>子订单表</strong>：在子订单表中，除了商品ID，<strong>额外冗余存储</strong>商品名称、商品分类ID、商品型号、生产批号ID。</li>\n<li><strong>采购单表</strong>与<strong>采购子订单表</strong>：做同样的冗余处理。</li>\n</ul>\n<p>这样一来，查询订单或采购单时，<strong>无需再实时调用商品服务</strong>，直接在本地库关联查询即可，性能与稳定性得到保障。</p>\n<p>但随之而来的核心问题是：<strong>当商品信息更新时，如何同步这些冗余数据？</strong> 通常有两种思路：</p>\n<ol>\n<li><strong>同步调用更新</strong>：商品服务在更新自身数据后，<strong>同步调用</strong>订单、采购等服务提供的接口，触发它们更新本地冗余数据。</li>\n<li><strong>消息异步更新</strong>：商品服务更新后，<strong>发布一条消息</strong>到消息队列（MQ），由订单、采购等服务各自订阅并异步更新。</li>\n</ol>\n<p>我们曾在数据一致性章节讨论过类似场景。那么，这两种方法各自存在什么问题？</p>\n<p><strong>先看第一种“同步调用更新”</strong>：这会让商品服务在每次更新时，都必须等待下游服务完成冗余数据更新。这带来两个突出问题：</p>\n<ol>\n<li><strong>核心流程被绑架</strong>：如果某个下游服务更新失败，理论上整个操作应该回滚。但商品服务的开发人员肯定会不乐意：冗余数据本非我的核心职责，为何要因为一个“边缘需求”的失败，而阻断我自身核心的商品更新流程？</li>\n<li><strong>依赖关系倒置与膨胀</strong>：商品服务本应是一个稳定的底层服务。但在此方案下，它反而需要<strong>主动依赖</strong>众多上游服务（订单、采购、库存、运营等）。依赖方越多，其稳定性和迭代速度受影响越大，这与设计初衷背道而驰。因此，该方案被直接否决。</li>\n</ol>\n<p><strong>再看第二种“消息异步更新”</strong>：这是更常见的做法，其优势明显：</p>\n<ul>\n<li>商品服务只需发布消息，无需关心下游谁消费、如何处理，职责清晰。</li>\n<li>即使消费失败，也可利用MQ的重试机制保证最终一致性。</li>\n</ul>\n<p>该方案的架构示意如图所示</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095648105-207718254.png\" /></p>\n<p>虽然这已是业界普遍做法，但它仍存在以下三个痛点：</p>\n<ol>\n<li><strong>订阅主题泛滥</strong>：要维护的数据远不止基础商品信息。例如，商品分类、生产批号等关联信息变更也需要同步。实践中，一个服务可能需要订阅近十种不同类型的消息，<strong>近乎将商品领域的一小半逻辑复制了过来</strong>。</li>\n<li><strong>逻辑重复实现</strong>：所有依赖商品数据的服务（订单、采购等），都需要<strong>独立实现一套几乎相同的消息监听、数据解析与更新逻辑</strong>，导致大量重复代码。</li>\n<li><strong>联调与运维复杂</strong>：基于消息的联调比接口联调更棘手。消息的生产、流转和消费节点不易追踪，为调试而临时修改代码的行为，常因忘记还原而引入线上问题。<strong>我们并不希望一个非核心的冗余需求，带来如此复杂的消息拓扑。</strong></li>\n</ol>\n<p>鉴于上述问题，项目组决定采用一个<strong>更彻底的数据同步方案</strong>来解耦业务逻辑。</p>\n<h1 id=\"3-解耦业务逻辑的数据同步方案\">3 解耦业务逻辑的数据同步方案</h1>\n<p>为根治服务间复杂的数据依赖，我们采用了一种更为彻底的方案，其核心在于<strong>将数据同步与业务逻辑完全解耦</strong>。设计思路清晰直接：</p>\n<ol>\n<li><strong>数据层实时同步</strong>：借助数据同步工具，将商品主数据及其关联表（如分类、生产批号、保修类型等）的<strong>全量及增量变更</strong>，实时同步至下游服务（如订单、采购）的数据库中，并保持表结构原封不动。</li>\n<li><strong>本地化关联查询</strong>：当下游服务需要查询时，直接在自己的数据库中<strong>关联这些同步过来的“副本表”</strong>，如同使用本地表一样高效、稳定。</li>\n<li><strong>严格的读写权限</strong>：明确规定，下游服务<strong>仅拥有对这些副本表的读取权限</strong>，禁止任何形式的修改，确保数据来源单一、权威。</li>\n</ol>\n<p>该方案的架构示意如图所示</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095648095-247437497.png\" /></p>\n<p>它一举解决了此前方案的核心痛点：</p>\n<ul>\n<li><strong>对上游商品服务</strong>：实现了“零依赖”与“零感知”。它既无需调用其他服务，也无需发布消息，同步成败与否均不影响其核心流程，彻底轻装上阵。</li>\n<li><strong>对下游订单/采购服务</strong>：实现了“零开发”。完全无需编写和维护任何数据同步或消息处理逻辑，只需像查询普通本地表一样使用即可。</li>\n</ul>\n<p>当然，此方案会增加下游数据库的存储空间，因为引入了额外的表。但这笔账算下来非常划算：</p>\n<ul>\n<li>在传统的字段冗余方案中，假设有1000万条订单记录，每条都需要存储一份完整的商品信息副本，即新增<strong>1000万条</strong>冗余数据记录。</li>\n<li>而在本方案中，仅需将约<strong>10万条</strong>商品主数据（及其关联表）同步至下游。<strong>实际增加的存储量远小于前者</strong>，在空间效率上反而是更优的选择。</li>\n</ul>\n<p>至此，一个清晰、低侵扰的方案已浮出水面。接下来最实际的问题是：<strong>如何可靠地实现这种跨数据库的实时表同步？</strong> 我们将在下一节揭晓具体的技术实现。</p>\n<h1 id=\"4-基于bifrost的数据同步方案\">4 基于Bifrost的数据同步方案</h1>\n<h2 id=\"41-技术选型\">4.1 技术选型</h2>\n<p>为解决实时数据同步问题，项目组决定引入一个开源中间件。我们为其设定了五个明确的筛选条件：</p>\n<ol>\n<li><strong>支持实时同步</strong>：延迟需在可接受范围内。</li>\n<li><strong>支持增量同步</strong>：避免每次全量复制，效率是关键。</li>\n<li><strong>无需编码业务逻辑</strong>：目标是“配置即用”，降低开发和维护负担。</li>\n<li><strong>支持MySQL到MySQL同步</strong>：匹配当前技术栈。</li>\n<li><strong>社区活跃度高</strong>：这通常意味着更好的问题响应和可持续性。</li>\n</ol>\n<p>根据这些标准，我们对比了Canal、Debezium、DataX、Databus、Flinkx及Bifrost等候选方案。综合评估后，<strong>Bifrost</strong>脱颖而出。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095648136-1918180865.png\" /></p>\n<p>尽管Bifrost相对年轻且<strong>不支持原生集群模式</strong>，但我们最终选择它，主要基于以下四个务实考量：</p>\n<ol>\n<li><strong>管理界面友好</strong>：提供Web控制台，配置、监控和管理直观便捷，降低了运维门槛。</li>\n<li><strong>架构简单可控</strong>：其核心逻辑清晰，若出现问题，团队有能力进行深度排查甚至自行维护，避免了在复杂黑盒系统前的无助感。</li>\n<li><strong>作者更新活跃</strong>：积极的提交记录和Issue处理让我们对项目生命力更有信心。</li>\n<li><strong>内置监控报警</strong>：开箱即用的监控功能，省去了自行搭建的麻烦。</li>\n</ol>\n<p>选定Bifrost后，整体方案架构如图所示。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095648120-652669355.png\" /></p>\n<h2 id=\"42-bifrost架构\">4.2 Bifrost架构</h2>\n<p>知其然也需知其所以然。Bifrost的工作原理并不复杂，其核心架构如图所示。</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202601/2428649-20260105095648073-984751999.png\" /></p>\n<p>简单来说，Bifrost将自己<strong>伪装成一个MySQL从库</strong>，通过读取并解析源数据库的Binlog（二进制日志）来捕获数据变更，随后将这些变更实时应用到目标数据库中。它支持多种目标数据源，而本项目正是用于实现MySQL到MySQL的同步。</p>\n<h2 id=\"43-注意事项\">4.3 注意事项</h2>\n<p>引入任何技术都需明确其边界。使用此方案，必须牢记以下几点：</p>\n<ol>\n<li><strong>正视同步延迟</strong>：该方案存在毫秒到秒级的固有延迟。因此，<strong>对时效性要求极高的业务逻辑（如实时库存校验）</strong>，不应依赖同步数据，而应直接调用服务接口。同步来的数据，主要应用于<strong>查询、展示和分析等非实时强一致性场景</strong>。</li>\n<li><strong>坚守只读原则</strong>：同步是<strong>单向的</strong>。目标库中同步过来的数据应视为“只读副本”，<strong>严禁在业务层对其进行修改</strong>。任何数据修正都必须回归源头系统，再经由同步链路分发，以保障数据权威性。</li>\n<li><strong>监控必须到位</strong>：鉴于Bifrost并非高可用设计，对其服务状态的监控至关重要。除了利用其内置告警，建议建立独立的健康检查机制（Bifrost提供了API便于集成），确保在服务异常时能第一时间被发现和处理。</li>\n<li><strong>核心逻辑避免依赖</strong>：基于延迟和可用性考虑，<strong>关键业务流程不应建立在同步数据之上</strong>。例如：\n<ul>\n<li><strong>防超卖库存检查</strong>：应直接调用库存服务，而非查询本地同步的库存快照。</li>\n<li><strong>权限校验</strong>：应实时对接权限中心，而非使用可能滞后的本地权限数据副本。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"5-小结\">5 小结</h1>\n<p>方案上线后，商品数据的同步稳定运行，达成了预期目标：</p>\n<ul>\n<li><strong>商品团队</strong>：只需专注核心领域，无需为数据消费者分心。</li>\n<li><strong>采购/订单团队</strong>：在查询时进行简单的表关联即可，彻底摆脱了同步逻辑的纠缠。可谓<strong>双赢</strong>。</li>\n</ul>\n<p>唯一的遗憾是Bifrost的<strong>单点架构</strong>。然而在实践中，反而是那些设计为多节点高可用的业务服务更常出现故障。Bifrost作者在其文档(<a href=\"https://wiki.xbifrost.com/other/cluster_why_not/\" rel=\"noopener nofollow\" target=\"_blank\">开发者文档</a>)中解释了他对“高可用”的谨慎态度，认为过早引入复杂的分布式设计可能增加故障排查难度，并对生产环境保持敬畏。我们部分认同这一观点——在实践中确实遇到过一些号称“高可用”的系统在故障时表现更糟。</p>\n<p>当然，这绝非否定高可用的价值，而是特定场景下的权衡。项目组为此准备了应急预案和深度监控，并随时准备在必要时为Bifrost增加灾备能力。</p>\n<p>无论如何，我们成功地为“服务间数据依赖”这一痛点找到了一个简洁有效的解决方案。接下来，我们将挑战下一个更复杂的问题：<strong>服务间业务流程与逻辑的耦合</strong>。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 09:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yhup\">yihuiComeOn</a>&nbsp;\n阅读(<span id=\"post_view_count\">71</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}