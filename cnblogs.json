{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "51单片机__LED相关",
      "link": "https://www.cnblogs.com/WIRO/p/19452806",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/WIRO/p/19452806\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 16:06\">\n    <span>51单片机__LED相关</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"51单片机__led相关\">51单片机__LED相关</h1>\n<h2 id=\"单片机介绍\">单片机介绍</h2>\n<p>单片机，英文Micro Controller Unit，简称MCU<br />\n内部集成了CPU、RAM、ROM、定时器、中断系统、通讯接口等一系列电脑的常用硬件功能<br />\n单片机的任务是信息采集（依靠传感器）、处理（依靠CPU）和硬件设备（例如电机，LED等）的控制<br />\n单片机跟计算机相比，单片机算是一个袖珍版计算机，一个芯片就能构成完整的计算机系统。但在性能上，与计算机相差甚远，但单片机成本低、体积小、结构简单，在生活和工业控制领域大有所用<br />\n同时，学习使用单片机是了解计算机原理与结构的最佳选择</p>\n<h2 id=\"单片机应用\">单片机应用</h2>\n<p>单片机的使用领域已十分广泛，如智能仪表、实时工控、通讯设备、导航系统、家用电器等。各种产品一旦用上了单片机，就能起到使产品升级换代的功效，常在产品名称前冠以形容词——“智能型”，如智能型洗衣机等。</p>\n<p><img alt=\"image-20260107113142288\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519528-2082922721.png\" /></p>\n<h2 id=\"stc89c52单片机\">STC89C52单片机</h2>\n<p><img alt=\"image-20260107113244328\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519123-1391531477.png\" /></p>\n<p><img alt=\"image-20260107113324739\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519527-1511351430.png\" /></p>\n<p><img alt=\"image-20260107113519962\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519188-402559776.png\" /></p>\n<p><img alt=\"image-20260107113540042\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519297-1849899687.png\" /></p>\n<p><img alt=\"image-20260107113612706\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519274-1889121421.png\" /></p>\n<h2 id=\"开发板原理图和复位单路\">开发板原理图和复位单路</h2>\n<p><img alt=\"image-20260107113715018\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519312-2037859992.png\" /></p>\n<p><img alt=\"image-20260107114043371\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519369-1523164322.png\" /></p>\n<p><img alt=\"image-20260107114127756\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519480-912853277.png\" /></p>\n<h1 id=\"创建工程并实现led控制\">创建工程并实现LED控制</h1>\n<h2 id=\"1点亮led灯\">1）点亮LED灯</h2>\n<p><img alt=\"image-20260107115032547\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519089-1326428079.png\" /></p>\n<p>观察原理图，LED灯低电平点亮，下面开始编写代码：</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n\nvoid main()\n{\n\tP2 = 0;\n}\n\n// 现象:所有LED灯均被点亮\n</code></pre>\n<h2 id=\"2实现led_1灯闪烁\">2）实现LED_1灯闪烁</h2>\n<p><strong>延时方法与实现：</strong></p>\n<p>通过单片机驱动外围显示电路，为了能够让人眼识别到所显示内容的变化，需要保证所显示的内容有所停留。在单片机中，实现这一效果有两种方式，一种是通过C语言编写一段延时效果的程序或者子程序，实现该目的。另一种是调用单片机自带的定式/计数器，这里暂时使用第一种方式。</p>\n<p>使用单片机烧录软件AiCube-ISP-v6.96A，生成一段500ms的延时函数。</p>\n<pre><code class=\"language-c\">// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n</code></pre>\n<p><img alt=\"image-20260107120433086\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519161-1654264043.png\" /></p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\nvoid main()\n{\n\twhile(1)\n\t{\t\n\t\tP2 = 0xFE;     // 1111 1110\n\t\tDelay500ms();  // 延时0.5s\n\t\tP2 = 0xFF;     // 1111 1111\n\t\tDelay500ms();  // 延时0.5s\n\t}\n}\n\n// 现象: LED_1 闪烁，其他LED灯不亮\n</code></pre>\n<h2 id=\"3实现led流水灯\">3）实现LED流水灯</h2>\n<h3 id=\"第一种方式使用数组实现流水灯效果\"><strong>第一种方式：使用数组实现流水灯效果</strong></h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\n// 定义流水灯数组\nunsigned char LedCode[] = {0xFE,0xFD,0xFB,0xF7,0Xef,0xDF,0xBF,0x7F};\n\nvoid main()\n{\n\tunsigned char i;\n\twhile(1)\n\t{\t\n\t\tfor(i = 0;i &lt; 8;i ++)\n\t\t{\n\t\t\tP2 = LedCode[i];\n\t\t\tDelay500ms();\n\t\t}\n\t}\n}\n\n// 现象：LED灯从低到高依次点亮\n\n//附加内容：\n//0xFE  1111 1110\n//0xFD  1111 1101\n//0xFB  1111 1011\n//0xF7  1111 0111\n//0Xef  1110 1111\n//0xDF  1101 1111\n//0xBF  1011 1111\n//0x7F  0111 1111\n</code></pre>\n<h3 id=\"第二种方式左右移运算符实现\"><strong>第二种方式：左右移运算符实现</strong></h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\n\nvoid main() {\n    unsigned char Led = 0x01; // 0000 0001\n    \n    while(1) {\n        P2 = ~Led;      // 取反，输出到P2端口\n        Delay500ms();   // 延时500ms\n        \n        // 使用左移运算符\n        Led = Led &lt;&lt; 1;\n        \n        // 如果移到最右边，重新从最左边开始\n        if(Led == 0x00) {\n            Led = 0x01;\n        }\n    }\n}\n\n// 现象：LED灯从低到高依次点亮\n</code></pre>\n<h3 id=\"第三种方式循环左右移函数的调用\"><strong>第三种方式：循环左右移函数的调用</strong></h3>\n<h3 id=\"1-cror---循环右移函数\">1. <strong><em>cror</em>() - 循环右移函数</strong></h3>\n<p><strong>头文件：</strong> <code>#include &lt;intrins.h&gt;</code><br />\n<strong>原型：</strong> <code>unsigned char _cror_(unsigned char val, unsigned char n);</code></p>\n<p><strong>功能：</strong> 将 8 位数据循环右移 n 位，移出的位从左边补入</p>\n<p><strong>示例：</strong></p>\n<pre><code class=\"language-c\">unsigned char data = 0x81;  // 二进制：10000001\ndata = _cror_(data, 1);     // 结果：0xC0 (11000000)\n// 原：10000001 → 右移1位 → 11000000\n</code></pre>\n<p><img alt=\"image-20260107153044727\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519436-108965670.png\" /></p>\n<h3 id=\"2-crol---循环左移函数\">2. <strong><em>crol</em>() - 循环左移函数</strong></h3>\n<p><strong>头文件：</strong> <code>#include &lt;intrins.h&gt;</code><br />\n<strong>原型：</strong> <code>unsigned char _crol_(unsigned char val, unsigned char n);</code></p>\n<p><strong>功能：</strong> 将 8 位数据循环左移 n 位，移出的位从右边补入</p>\n<p><strong>示例：</strong></p>\n<pre><code class=\"language-c\">unsigned char data = 0x81;  // 二进制：10000001\ndata = _crol_(data, 1);     // 结果：0x03 (00000011)\n// 原：10000001 → 左移1位 → 00000011\n</code></pre>\n<p><img alt=\"image-20260107153844168\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260107160519302-1190082079.png\" /></p>\n<p>流水灯应用示例：</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 解决 _nop_ 报错\n\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\n\nvoid main() \n\t{\n\t\tunsigned char aa;\n\t\taa = 0xFE;  // 1111 1110\n\t\t\n\t\twhile(1)\n\t\t{\n\t\t\tP2 = aa;\n\t\t\tDelay500ms();\n\t\t\taa = _crol_(aa,1);  // 循环左移函数\n\t\t}\n\n\t}\n\n// 现象：LED灯从低到高依次点亮\n</code></pre>\n<p><strong>注意：</strong> 这两个函数是 C51 编译器特有，仅适用于 51 单片机开发。</p>\n<h2 id=\"综合练习双向流水灯\">综合练习：双向流水灯</h2>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include &lt;INTRINS.H&gt;  // 包含移位函数头文件\n\n// 延时500ms\nvoid Delay500ms(void)\t//@11.0592MHz\n{\n\tunsigned char data i, j, k;\n\n\t_nop_();\n\ti = 4;\n\tj = 129;\n\tk = 119;\n\tdo\n\t{\n\t\tdo\n\t\t{\n\t\t\twhile (--k);\n\t\t} while (--j);\n\t} while (--i);\n}\n\nvoid main() \n{\n    unsigned char aa;\n    unsigned char direction = 0;  // 0:左移, 1:右移\n    unsigned char counter = 0;    // 计数左移/右移的次数\n    \n    aa = 0xFE;  // 1111 1110，第一个灯亮\n    \n    while(1)\n    {\n        P2 = aa;\n        Delay500ms();\n        \n        // 左移8次后改为右移\n        if(direction == 0)\n        {\n            aa = _crol_(aa, 1);  // 循环左移\n            counter++;\n            \n            if(counter &gt;= 7)  // 左移7次后（共8个状态）\n            {\n                direction = 1;  // 改为右移方向\n                counter = 0;    // 计数器清零\n            }\n        }\n        // 右移8次后改为左移\n        else\n        {\n            aa = _cror_(aa, 1);  // 循环右移\n            counter++;\n            \n            if(counter &gt;= 7)  // 右移7次后（共8个状态）\n            {\n                direction = 0;  // 改为左移方向\n                counter = 0;    // 计数器清零\n            }\n        }\n    }\n}\n\n// 现象：LED左右依次点亮\n</code></pre>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 16:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/WIRO\">Q&amp;25</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "XAML Studio 已正式开源",
      "link": "https://www.cnblogs.com/shanyou/p/19452660",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shanyou/p/19452660\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:46\">\n    <span>XAML Studio 已正式开源</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>微软开发者博客于 2026 年 1 月 6 日正式宣布(<a href=\"https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/\" rel=\"noopener nofollow\" title=\"https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/\">https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/</a>)，<b>XAML Studio 已正式开源</b>，并成为了 .NET 基金会（.NET Foundation）旗下的一个种子项目。</p><h5><font face=\"微软雅黑 Light\" size=\"3\">1. 什么是 XAML Studio？</font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">XAML Studio 是一款专为 <b>WinUI</b> 开发者打造的辅助工具，最初是 Microsoft Garage（微软车库）的一个项目。它允许开发者在不创建完整工程的情况下，快速进行 XAML 界面原型设计和交互调试。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">其核心功能包括：</font></p><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>实时编辑与预览</b>：即时查看 XAML 代码的效果。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>绑定调试器 (Binding Debugger)</b>：直观排查数据绑定问题。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>数据上下文编辑器</b>：快速模拟测试数据。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>IntelliSense 与文档工具箱</b>：提供代码补全和控件查阅。</font></font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\">2. 开源背景与现状</font></h5><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>项目历程</b>：该项目始于 8 年前，一直计划开源，如今终于实现。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>V2 版本</b>：目前开源的是正在开发中的 <b>XAML Studio v2</b>。相比商店里的 1.1 版本，v2 采用了全新的界面，并针对 WinUI 3 进行了优化。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>社区贡献</b>：XAML Studio 的许多核心组件早已回馈给社区，例如 <b>Windows Community Toolkit (WCT)</b> 中的 <code>SwitchPresenter</code>、<code>Sizer</code> 控件（如 <code>GridSplitter</code> 的改进版）以及实验性的 <b>Adorners（装饰器）</b> 功能，最初都源于 XAML Studio。</font></font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\">3. 未来计划</font></h5><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>开发分支</b>：开发者目前可以从 GitHub 的 <code>dev</code> 分支获取 v2 版本的源代码并自行构建。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>正式发布</b>：开发团队计划在 2026 年晚些时候在 Microsoft Store 发布 v2 的正式稳定版。</font></font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>参与方式</b>：微软鼓励开发者通过 GitHub 提交反馈、建议或直接贡献代码。</font></font></p></li></ul><p><b><font face=\"微软雅黑 Light\" size=\"3\">相关资源：</font></b></p><ul><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>GitHub 仓库</b>：</font></font><a href=\"https://www.google.com/search?q=https://github.com/microsoft/XamlStudio\" rel=\"noopener nofollow\"><font face=\"微软雅黑 Light\" size=\"3\">microsoft/XamlStudio</font></a><font face=\"微软雅黑 Light\" size=\"3\">（或通过 .NET Foundation 查找）。</font></p></li><li><p><font face=\"微软雅黑 Light\"><font size=\"3\"><b>官方博客全文</b>：</font></font><a href=\"https://devblogs.microsoft.com/ifdef-windows/xaml-studio-is-now-open-sourced/\" rel=\"noopener nofollow\"><font face=\"微软雅黑 Light\" size=\"3\">XAML Studio is now Open Sourced</font></a></p></li></ul><p>这对 WinUI 开发者来说是一个重要的里程碑，不仅工具本身变得透明、可定制，也预示着 WinUI 生态系统的进一步开放。</p>\n</div>\n<div id=\"MySignature\">\n    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>\n<img src=\"https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg\" width=\"170\" />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 15:46</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shanyou\">张善友</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【终极踩坑指南】Windows 10上MsQuic证书加载失败？坑不在证书，而在Schannel！",
      "link": "https://www.cnblogs.com/haibindev/p/19452652",
      "published": "",
      "description": "<div class=\"postTitle\">\n\t\t<h1><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/haibindev/p/19452652\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:45\">\n    <span>【终极踩坑指南】Windows 10上MsQuic证书加载失败？坑不在证书，而在Schannel！</span>\n    \n\n</a>\n</h1>\n\t</div>\n\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        摘要：如果你在Windows 10上被 ConfigurationLoadCredential failed, 0x80070490 或 E_NOINTERFACE 错误折磨良久，试遍所有证书方案仍无解，那么恭喜，本文就是你的终点站。真正原因极可能是：新版MsQuic已默认放弃对Windows 10上Schannel的支持。无需再折腾证书，切换至OpenSSL后端即可一键解决。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"终极踩坑指南windows-10上msquic证书加载失败坑不在证书而在schannel\">【终极踩坑指南】Windows 10上MsQuic证书加载失败？坑不在证书，而在Schannel！</h1>\n<blockquote>\n<p><strong>摘要</strong>：如果你在Windows 10上被 <code>ConfigurationLoadCredential failed, 0x80070490</code> 或 <code>E_NOINTERFACE</code> 错误折磨良久，试遍所有证书方案仍无解，那么恭喜，本文就是你的终点站。真正原因极可能是：<strong>新版MsQuic已默认放弃对Windows 10上Schannel的支持</strong>。无需再折腾证书，切换至OpenSSL后端即可一键解决。</p>\n</blockquote>\n<h3 id=\"一问题现象一个极具迷惑性的错误\"><strong>一、问题现象：一个极具迷惑性的错误</strong></h3>\n<p>环境：Windows 10 22H2，使用GitHub主线版本MsQuic编译QUIC Server。</p>\n<p>在调用 <code>MsQuic-&gt;ConfigurationLoadCredential(...)</code> 时，稳定失败，返回错误：</p>\n<pre><code>ConfigurationLoadCredential failed, 0x80070490\n</code></pre>\n<p>或者：</p>\n<pre><code>E_NOINTERFACE\n</code></pre>\n<p><strong>所有迹象都指向证书问题</strong>，于是开始了漫长的“踩坑”之旅。</p>\n<h3 id=\"二排查弯路我被证书问题带偏的全过程\"><strong>二、排查弯路：我被“证书问题”带偏的全过程</strong></h3>\n<p>以下是我的排查流水账，几乎试遍了Windows下所有证书方案：</p>\n<ol>\n<li>\n<p><strong>证书哈希（官方推荐）</strong></p>\n<pre><code class=\"language-cpp\">QUIC_CERTIFICATE_HASH CertHash{};\nmemcpy(CertHash.ShaHash, hashbuf_.data(), 20);\nCredConfig.Type = QUIC_CREDENTIAL_TYPE_CERTIFICATE_HASH;\n</code></pre>\n<p><strong>结果</strong>：<code>HRESULT_FROM_WIN32(ERROR_NOT_FOUND)</code>。确认证书在本地计算机存储、有私钥、验证通过，但就是不行。</p>\n</li>\n<li>\n<p><strong>哈希存储（显式指定仓库）</strong></p>\n<pre><code class=\"language-cpp\">strcpy_s(CertHashStore.StoreName, \"LocalMachine\\\\My\");\nCredConfig.Type = QUIC_CREDENTIAL_TYPE_CERTIFICATE_HASH_STORE;\n</code></pre>\n<p><strong>结果</strong>：<code>E_INVALIDARG</code>。</p>\n</li>\n<li>\n<p><strong>怀疑证书生成方式</strong><br />\n怀疑OpenSSL生成的证书不行，换用PowerShell生成“纯正”的CNG证书：</p>\n<pre><code class=\"language-powershell\">New-SelfSignedCertificate -Provider \"Microsoft Software Key Storage Provider\" ...\n</code></pre>\n<p><strong>结果</strong>：失败依旧。</p>\n</li>\n<li>\n<p><strong>终极尝试：PFX文件</strong></p>\n<pre><code class=\"language-cpp\">CredConfig.Type = QUIC_CREDENTIAL_TYPE_CERTIFICATE_FILE_PROTECTED;\n</code></pre>\n<p><strong>结果</strong>：熟悉的 <code>E_NOINTERFACE</code>。</p>\n</li>\n<li>\n<p><strong>关键转折点：官方示例也挂了</strong><br />\n当怀疑人生时，直接测试MsQuic自带的 <code>quicsample.exe</code>：</p>\n<pre><code class=\"language-bash\">quicsample.exe -server -cert_hash:&lt;your_thumbprint&gt;\n</code></pre>\n<p><strong>同样失败！</strong> 这证明问题与我的代码无关，是<strong>环境或库本身的问题</strong>。</p>\n</li>\n</ol>\n<h3 id=\"三真相揭露不是证书的锅是schannel掉了链子\"><strong>三、真相揭露：不是证书的锅，是Schannel掉了链子</strong></h3>\n<p>所有排查都失效后，我将目光从证书移开，最终锁定核心矛盾：</p>\n<blockquote>\n<p><strong>当前较新版本的MsQuic，在Windows 10系统上，其默认的Schannel TLS后端可能已无法正常加载服务器证书。</strong></p>\n</blockquote>\n<p>这是一个<strong>官方文档未明确标注、但实际存在的兼容性断点</strong>。错误 <code>0x80070490</code> (找不到元素) 和 <code>E_NOINTERFACE</code> 极具误导性，让你在证书的迷宫里无限打转，而真正的出口是：<strong>更换TLS后端</strong>。</p>\n<h3 id=\"四一行命令解决切换到openssl后端\"><strong>四、一行命令解决：切换到OpenSSL后端</strong></h3>\n<p><strong>解决方案简单到令人发指：</strong></p>\n<ol>\n<li>\n<p><strong>使用OpenSSL后端重新编译MsQuic</strong>：</p>\n<pre><code class=\"language-bash\"># 在MsQuic仓库目录下执行\n.\\scripts\\build.ps1 -Config Debug -Arch x64 -Tls openssl\n</code></pre>\n</li>\n<li>\n<p><strong>使用OpenSSL生成的证书</strong>（如PEM或PFX格式）。</p>\n</li>\n<li>\n<p>再次运行你的程序或 <code>quicsample</code>：</p>\n<pre><code class=\"language-bash\">quicsample.exe -server -cert_file:server.pfx -key_file:key.pem\n</code></pre>\n<p><strong>✅ 服务器顺利启动，问题解决。</strong></p>\n</li>\n</ol>\n<h3 id=\"五为什么会有这个坑深度分析\"><strong>五、为什么会有这个坑？（深度分析）</strong></h3>\n<p>这个问题在 <strong>Windows 11 或 Windows Server 2022</strong> 上通常不会出现，因为它们内置了完整的、支持最新QUIC规范的Schannel实现。</p>\n<p>而 <strong>Windows 10</strong>（尤其是某些版本）的Schannel对MsQuic新版本所需功能的支持可能不完整或存在缺陷。MsQuic在更新过程中，可能默认启用了某些Windows 10上Schannel无法满足的特性或API，导致证书加载路径从根源上失败。</p>\n<p><strong>因此，这本质上是一个平台兼容性断档问题。</strong> 对于开发者而言，表象是证书错误，根因是系统组件落后于开发库的演进。</p>\n<h3 id=\"六总结与建议\"><strong>六、总结与建议</strong></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">场景</th>\n<th style=\"text-align: left;\">推荐动作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>在Windows 10上开发/部署MsQuic</strong></td>\n<td style=\"text-align: left;\"><strong>直接使用OpenSSL后端</strong>，一劳永逸。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">遇到<code>0x80070490</code>或<code>E_NOINTERFACE</code>错误</td>\n<td style=\"text-align: left;\">首要怀疑<strong>TLS后端兼容性</strong>，而非证书本身。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">需要跨平台（Windows/Linux）一致性</td>\n<td style=\"text-align: left;\">选择OpenSSL后端更能保证行为一致。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>目标环境为Windows 11/Server 2022+</strong></td>\n<td style=\"text-align: left;\">可放心使用默认Schannel，性能更佳。</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<p><strong>拓展思考</strong>：对于从事<strong>视频流传输</strong>（如基于QUIC优化RTMP、HLS延迟）的开发者来说，理解底层网络库的这些平台细微差别至关重要。一次成功的协议升级，往往从顺利编译和部署开始。希望这篇踩坑记录能助你畅通无阻。</p>\n<p>（本文基于Windows 10 22H2家庭中文版、x64架构、MsQuic GitHub主线版本测试验证）</p>\n<p><img alt=\"\" src=\"https://img2023.cnblogs.com/blog/254714/202307/254714-20230701143418754-1351786962.jpg\" /></p>\n<p><strong>合作请加WX：hbstream</strong><br />\n<strong>合作请加作者hbstream（<a href=\"http://haibindev.cnblogs.com\" target=\"_blank\">http://haibindev.cnblogs.com</a>），转载请注明作者和出处</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-07 15:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/haibindev\">haibindev</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "NIVIDIA高性能计算CUDA笔记（三） cuFFT的简介及实现案例",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19452487",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19452487\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:21\">\n    <span>NIVIDIA高性能计算CUDA笔记（三） cuFFT的简介及实现案例</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        cuFFT是NVIDIA提供的GPU加速的Fourier变换FFT库，能极大提升涉及FFT计算的科学计算、信号处理和深度学习等任务的速度。本笔记就cufft进行简单介绍并给出一个一维信号的fft变换示例\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"nividia高性能计算cuda笔记三-cufft的简介及实现案例\">NIVIDIA高性能计算CUDA笔记（三） cuFFT的简介及实现案例</h1>\n<h2 id=\"1-cufft库的简介introduction-of-cufft-libaray\">1. cuFFT库的简介（Introduction of cuFFT libaray）</h2>\n<p>​      Fourier变换是数字信号处理领域一个很重要的数学变换，它用来实现将信号实现将信号从时域到频域的变换，在物理学、数论、组合数学、信号处理、概率、统计、密码学、声学、光学等领域有广泛的应用。离散傅里叶变换(Discrete Fourier Transform，DFT)是连续傅里叶变换在离散系统中的表示形式，由于DFT的计算量很大，因此在很长一段时间内其应用受到了很大的限制。20世纪60年代（1965年）由Cooley和Tukey提出了快速傅里叶变换(Fast Fourier Transform，FFT)算法，它是DFT的快速算法，使得离散傅里叶变换和卷积这类难度很大的计算工作的复杂度从N2量级降到了Nlog2N量级，大大提高了DFT的运算速度，从而使DFT在实际应用中得到了广泛的应用。</p>\n<p>​       cuFFT是NVIDIA提供的GPU加速的Fourier变换FFT库，能极大提升涉及FFT计算的科学计算、信号处理和深度学习等任务的速度。下表概括了器主要特征和应用场景：</p>\n<table>\n<thead>\n<tr>\n<th>cuFFT的特征</th>\n<th>具体描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>基本功能</td>\n<td>提供GPU加速的1D、2D、3D复数/实数FFT计算</td>\n</tr>\n<tr>\n<td>核心优势</td>\n<td>相比CPU实现，利用GPU并行性可获得显著加速</td>\n</tr>\n<tr>\n<td>编程接口</td>\n<td>提供类似的FFTW的API，便于熟悉CPU FFT的用户迁移</td>\n</tr>\n<tr>\n<td>高级功能</td>\n<td>支持批量执行、流异步、半/单/双精度、多GPU计算</td>\n</tr>\n<tr>\n<td>主要应用领域</td>\n<td>深度学习、计算物理学、医学成像、信号处理等</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"2-基于cufft库的fourier变换步骤workflow-of-fourier-transform-based-cufft\">2. 基于cuFFT库的Fourier变换步骤（workflow of Fourier Transform based cuFFT）</h2>\n<p>在CUDA上进行傅里叶变换一般需要做以下几步工作：</p>\n<ol>\n<li>在主机端，准备输入数据；</li>\n<li>在GPU设备端上分配内存，并将数据从主机复制到设备；（<code>cudaMalloc</code>,<code>cudaMemcpy</code>的接口 ）</li>\n<li>创建一个<span class=\"math inline\">\\(plan\\)</span>, 调用函数<span class=\"math inline\">\\(cufftPlane1D/cufftPlane2D/cufftPlan3D\\)</span> 可以创建一个简单的Fourier变换。调用函数<span class=\"math inline\">\\(cufftPlanMany\\)</span> 则可以创建支持更多配置操作的变换计划。\n<ul>\n<li><span class=\"math inline\">\\(cufftPlan1d()\\)</span>: 针对单个1维信号</li>\n<li><span class=\"math inline\">\\(cufftPlan2d()\\)</span>:针对单个2维信号</li>\n<li><span class=\"math inline\">\\(cufftPlan3d()\\)</span>:针对单个3维信号</li>\n</ul>\n</li>\n<li>执行<span class=\"math inline\">\\(plane\\)</span>。这一步可以使用<span class=\"math inline\">\\(cufftExecC2C()\\)</span>、<span class=\"math inline\">\\(cufftExecR2C()\\)</span>或<span class=\"math inline\">\\(cufftExecC2R()\\)</span>等函数完成上一步完成<span class=\"math inline\">\\(plane\\)</span>的计算任务。</li>\n<li>执行完成以下若不再需要该<span class=\"math inline\">\\(plan\\)</span>，则调用<span class=\"math inline\">\\(cufftDestroy()\\)</span>函数销毁该<span class=\"math inline\">\\(plan\\)</span> 及为其分配的计算资源。</li>\n</ol>\n<h2 id=\"3-cufft的傅里叶变换api接口类型fourier-transform-types\">3. cuFFT的傅里叶变换API接口类型（Fourier Transform Types）</h2>\n<p>​        <span class=\"math inline\">\\(cuFFT\\)</span> 库实现了三种不同类型的Fourier变换接口分为：<span class=\"math inline\">\\(C2C\\)</span>(复数变换到复数)，<span class=\"math inline\">\\(C2R\\)</span>(复数到实数),  <span class=\"math inline\">\\(R2C\\)</span> (实数到复数)。本质上，这三种转换都可以被看做是复数域到复数域的变换，之所以这样划分，其最主要的考量是性能因素。例如，在一般的数字信号处理中，输入数据是一些离散的实数域上的采样点，这时候对它们做Fourier变换实际上就是<span class=\"math inline\">\\(R2C\\)</span>，根据埃尔米特对称性（Hermitian symmetry)，变换<span class=\"math inline\">\\(X_k=X_{N-k}^{*}\\)</span>, <span class=\"math inline\">\\(*\\)</span> 代表共轭复数。<span class=\"math inline\">\\(cuFFT\\)</span> 的傅里叶变换则利用了这些冗余，将计算量降到最低。</p>\n<p>​       变换执行函数的单精度和双精度版本分别定义如下：</p>\n<table>\n<thead>\n<tr>\n<th>API</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span class=\"math inline\">\\(cufftExecC2C()/cufftExecZ2Z()\\)</span></td>\n<td>单精度/双精度浮点数复数域到复数域的傅里叶变换</td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(cufftExecR2C()/cufftExecD2Z()\\)</span></td>\n<td>单精度/双精度浮点数实数域到复数域的傅里叶变换（正变换）</td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(cufftExecC2R()/cufftExecZ2D()\\)</span></td>\n<td>单精度/双精度浮点数复数域到实数域的傅里叶变换（逆变换）</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"4-数据布局data-layout\">4. 数据布局(Data Layout)</h2>\n<p>​       <span class=\"math inline\">\\(CUFFT\\)</span>库保含若干种数据类型，对于复数有<span class=\"math inline\">\\(cufftComplex/cufftDoubleComplex\\)</span> 两种数据类型，对于实数则分别有<span class=\"math inline\">\\(cufftReal/cufftDouble\\)</span> 两种数据类型 。</p>\n<p>​         根据转换结果的存储位置不同，<span class=\"math inline\">\\(FFT\\)</span>变换可分为就地变换(<span class=\"math inline\">\\(in-place\\)</span>)和外部变换（<span class=\"math inline\">\\(out-place\\)</span>)，前者直接在输入数据进行变换，而后者则会将变换后结果存入新的存储器地址。</p>\n<p>​         就地转换(<span class=\"math inline\">\\(in-place\\)</span>) 支持数据的两种布局：<span class=\"math inline\">\\(native\\)</span> 和 <span class=\"math inline\">\\(padded\\)</span>，前者用于获取最佳性能，而后者则用于与FFTW兼容。</p>\n<p>​         在<span class=\"math inline\">\\(padded\\)</span>布局中输出信号的开始地址与输入信号一样，换句话说，实数域到复数域变换的输入数据和复数域到实数域的输出数据必须被填充。在native布局中则没有填入要求。</p>\n<p>​         输入数据和输出数据的尺寸总结如下：</p>\n<table>\n<thead>\n<tr>\n<th>FFT type</th>\n<th>input data size</th>\n<th>output data size</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span class=\"math inline\">\\(C2C\\)</span></td>\n<td><span class=\"math inline\">\\(X \\space cufftComplex\\)</span></td>\n<td><span class=\"math inline\">\\(X \\space cufftComplex\\)</span></td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(C2R\\)</span></td>\n<td><span class=\"math inline\">\\([\\frac{X}{2}]+1 \\space cufftComplex\\)</span></td>\n<td><span class=\"math inline\">\\(X\\)</span> <span class=\"math inline\">\\(cufftReal\\)</span></td>\n</tr>\n<tr>\n<td><span class=\"math inline\">\\(R2C^{*}\\)</span></td>\n<td><span class=\"math inline\">\\(X\\)</span> <span class=\"math inline\">\\(cufftReal\\)</span></td>\n<td><span class=\"math inline\">\\([\\frac{X}{2}]+1 \\space cufftComplex\\)</span></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5-单个一维信号的fft变换代码实现one-dimension-signal-fft-transfrom\">5. 单个一维信号的FFT变换代码实现（One Dimension SIgnal FFT Transfrom）</h2>\n<p>在本次测试代码中：首先生成一维的随机信号，利用cufft 先进行正变换，然后逆变换，并判定逆变换后结果与原输入信号判断是否相等。</p>\n<pre><code class=\"language-C\">#include &lt;iostream&gt;\n#include &lt;time.h&gt;\n#include \"cuda_runtime.h\"\n#include \"device_launch_parameters.h\"\n#include &lt;cufft.h&gt;\n\n#define NX 3335 // 有效数据个数\n#define N 5335 // 补0之后的数据长度\n#define BATCH 1\n#define BLOCK_SIZE 1024\nusing std::cout;\nusing std::endl;\n\n\n/**\n* 功能：判断两个 cufftComplex 数组的是否相等\n* 输入：idataA 输入数组A的头指针\n* 输入：idataB 输出数组B的头指针\n* 输入：size 数组的元素个数\n* 返回：true | false\n*/\nbool IsEqual(cufftComplex *idataA, cufftComplex *idataB, const int size)\n{\n    for (int i = 0; i &lt; size; i++)\n    {\n        if (abs(idataA[i].x - idataB[i].x) &gt; 0.000001 || abs(idataA[i].y - idataB[i].y) &gt; 0.000001)\n            return false;\n    }\n\n    return true;\n}\n\n\n\n/**\n* 功能：实现 cufftComplex 数组的尺度缩放，也就是乘以一个数\n* 输入：idata 输入数组的头指针\n* 输出：odata 输出数组的头指针\n* 输入：size 数组的元素个数\n* 输入：scale 缩放尺度\n*/\nstatic __global__ void cufftComplexScale(cufftComplex *idata, cufftComplex *odata, const int size, float scale)\n{\n    const int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (threadID &lt; size)\n    {\n        odata[threadID].x = idata[threadID].x * scale;\n        odata[threadID].y = idata[threadID].y * scale;\n    }\n}\n\nint main()\n{\n    cufftComplex *data_dev; // 设备端数据头指针\n    cufftComplex *data_Host = (cufftComplex*)malloc(NX*BATCH * sizeof(cufftComplex)); // 主机端数据头指针\n    cufftComplex *resultFFT = (cufftComplex*)malloc(N*BATCH * sizeof(cufftComplex)); // 正变换的结果\n    cufftComplex *resultIFFT = (cufftComplex*)malloc(NX*BATCH * sizeof(cufftComplex)); // 先正变换后逆变换的结果\n\n    // 初始数据\n    for (int i = 0; i &lt; NX; i++)\n    {\n        data_Host[i].x = float((rand() * rand()) % NX) / NX;\n        data_Host[i].y = float((rand() * rand()) % NX) / NX;\n    }\n\n\n    dim3 dimBlock(BLOCK_SIZE); // 线程块\n    dim3 dimGrid((NX + BLOCK_SIZE - 1) / dimBlock.x); // 线程格\n\n    cufftHandle plan; // 创建cuFFT句柄\n    cufftPlan1d(&amp;plan, N, CUFFT_C2C, BATCH);\n\n    // 计时\n    clock_t start, stop;\n    double duration;\n    start = clock();\n\n    cudaMalloc((void**)&amp;data_dev, sizeof(cufftComplex)*N*BATCH); // 开辟设备内存\n    cudaMemset(data_dev, 0, sizeof(cufftComplex)*N*BATCH); // 初始为0\n    cudaMemcpy(data_dev, data_Host, NX * sizeof(cufftComplex), cudaMemcpyHostToDevice); // 从主机内存拷贝到设备内存\n\n    cufftExecC2C(plan, data_dev, data_dev, CUFFT_FORWARD); // 执行 cuFFT，正变换\n    cudaMemcpy(resultFFT, data_dev, N * sizeof(cufftComplex), cudaMemcpyDeviceToHost); // 从设备内存拷贝到主机内存\n\n    cufftExecC2C(plan, data_dev, data_dev, CUFFT_INVERSE); // 执行 cuFFT，逆变换\n    cufftComplexScale &lt;&lt; &lt;dimGrid, dimBlock &gt;&gt; &gt; (data_dev, data_dev, N, 1.0f / N); // 乘以系数\n    cudaMemcpy(resultIFFT, data_dev, NX * sizeof(cufftComplex), cudaMemcpyDeviceToHost); // 从设备内存拷贝到主机内存\n\n    stop = clock();\n    duration = (double)(stop - start) * 1000 / CLOCKS_PER_SEC;\n    cout &lt;&lt; \"时间为 \" &lt;&lt; duration &lt;&lt; \" ms\" &lt;&lt; endl;\n\n    cufftDestroy(plan); // 销毁句柄\n    cudaFree(data_dev); // 释放空间\n\n    cout &lt;&lt; IsEqual(data_Host, resultIFFT, NX) &lt;&lt; endl;\n\n    return 0;\n}\n</code></pre>\n<p>其中<code>cufftPlan1d()</code> :</p>\n<ul>\n<li>第一个参数就是要配置的<span class=\"math inline\">\\(cuFFT\\)</span>句柄；</li>\n<li>第二个参数就是要进行fft的信号的长度；</li>\n<li>第三个<code>CUFFT_C2C</code> 为要执行<span class=\"math inline\">\\(fft\\)</span> 的信号输入类型及输出类型复数；<code>CUFFT_C2R</code>表示输入复数，输出实数；<code>CUFFT_R2C</code>表示输入实数，输出复数；<code>CUFFT_R2R</code> 表示输入实数，输出实数；</li>\n<li>第四个参数<code>BATCH</code>表示要执行fft的信号的个数，新版的已经使用<code>cufftPlanMany()</code>来同时完成多个信号的fft；</li>\n</ul>\n<p><code>cufftExecC2C()</code>:</p>\n<ul>\n<li>第一个参数就是配置好的 cuFFT 句柄；</li>\n<li>第二个参数为输入信号的首地址；</li>\n<li>第三个参数为输出信号的首地址；</li>\n<li>第四个参数为<code>CUFFT_FORWARD</code>表示执行的是<span class=\"math inline\">\\(fft\\)</span>正变换；<code>CUFFT_INVERSE</code>表示执行<span class=\"math inline\">\\(fft\\)</span>逆变换</li>\n</ul>\n<p>需要注意的是，执行完<span class=\"math inline\">\\(fft\\)</span>之后，要对信号中的每个值乘以<span class=\"math inline\">\\(1/N\\)</span>;</p>\n<p>输出结果：</p>\n<p><img alt=\"cufft\" class=\"lazyload\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 15:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "IQR四分位数法是什么？",
      "link": "https://www.cnblogs.com/sun-10387834/p/19386427",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19386427\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 15:06\">\n    <span>IQR四分位数法是什么？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>IQR（Interquartile Range，四分位距）四分位数法是一种统计学中用于描述数据离散程度、识别异常值的重要工具。它通过数据的四分位数（Quartiles）来刻画数据的分布特征，尤其适用于非正态分布或存在离群点的场景。以下从核心概念、计算方法、应用场景和理解要点展开说明：</p>\n<h3 id=\"一核心概念四分位数与iqr\"><strong>一、核心概念：四分位数与IQR</strong></h3>\n<h4 id=\"1-四分位数quartiles\">1. 四分位数（Quartiles）</h4>\n<p>将一组有序数据（从小到大排列）划分为4个相等部分的三个关键分割点，分别记为：</p>\n<ul>\n<li><strong>Q1（第一四分位数，25%分位数）</strong>：数据中25%的数值小于或等于它（即第25百分位数）。</li>\n<li><strong>Q2（第二四分位数，中位数）</strong>：数据中50%的数值小于或等于它（即第50百分位数，Median）。</li>\n<li><strong>Q3（第三四分位数，75%分位数）</strong>：数据中75%的数值小于或等于它（即第75百分位数）。</li>\n</ul>\n<p>例如，数据集 [1, 3, 5, 7, 9, 11, 13] 的中位数是7（Q2）；前半部分 [1,3,5] 的中位数是3（Q1），后半部分 [9,11,13] 的中位数是11（Q3）。</p>\n<h4 id=\"2-iqr四分位距\">2. IQR（四分位距）</h4>\n<p><strong>IQR = Q3 - Q1</strong>，表示中间50%数据的分布范围（即数据在Q1到Q3之间的“宽度”）。它是衡量数据离散程度的稳健指标（不受极端值影响）。</p>\n<h3 id=\"二iqr四分位数法的核心作用识别异常值\"><strong>二、IQR四分位数法的核心作用：识别异常值</strong></h3>\n<p>IQR法最常用的是通过“箱线图（Box Plot）”或“Tukey’s Fences”规则识别异常值（Outliers）。具体步骤如下：</p>\n<h4 id=\"1-计算上下边界\">1. 计算上下边界</h4>\n<p>以IQR为基准，定义数据的“正常范围”：</p>\n<ul>\n<li><strong>下边界（Lower Bound）</strong>：Q1 - 1.5×IQR</li>\n<li><strong>上边界（Upper Bound）</strong>：Q3 + 1.5×IQR</li>\n</ul>\n<h4 id=\"2-判定异常值\">2. 判定异常值</h4>\n<ul>\n<li><strong>温和异常值（Mild Outliers）</strong>：小于下边界或大于上边界的数据点（通常用1.5×IQR界定）。</li>\n<li><strong>极端异常值（Extreme Outliers）</strong>：小于Q1 - 3×IQR 或大于Q3 + 3×IQR 的数据点（更严格的阈值）。</li>\n</ul>\n<p><strong>逻辑</strong>：正常数据应集中在中间50%（Q1到Q3），而超出1.5倍IQR的点被视为“偏离较远的异常”。1.5倍的选择是经验性的（基于正态分布假设下约覆盖99.3%的数据，剩余0.7%视为异常）。</p>\n<h3 id=\"三应用场景\"><strong>三、应用场景</strong></h3>\n<ol>\n<li><strong>数据清洗</strong>：识别并验证离群点（如传感器误差、输入错误）。</li>\n<li><strong>可视化分析</strong>：箱线图的核心组件（箱体表示Q1到Q3，触须延伸至非异常值的最远点，异常值单独标记）。</li>\n<li><strong>统计描述</strong>：替代标准差（SD）衡量离散程度（尤其当数据非正态时，IQR更稳健）。</li>\n</ol>\n<h3 id=\"四如何理解iqr法的优势与局限\"><strong>四、如何理解IQR法的优势与局限</strong></h3>\n<h4 id=\"优势\">优势：</h4>\n<ul>\n<li><strong>稳健性</strong>：仅依赖中间50%的数据，不受极端值干扰（标准差易受异常值影响）。</li>\n<li><strong>普适性</strong>：适用于任何分布（无需假设数据正态）。</li>\n<li><strong>直观性</strong>：通过四分位数直接反映数据的集中与分散趋势。</li>\n</ul>\n<h4 id=\"局限\">局限：</h4>\n<ul>\n<li><strong>主观性</strong>：1.5倍IQR是经验阈值，不同领域可能调整（如金融风控可能用3倍）。</li>\n<li><strong>小样本偏差</strong>：样本量过小时（如n&lt;10），四分位数估计可能不稳定。</li>\n<li><strong>无法反映分布形态</strong>：仅描述离散程度，不体现数据的对称性或峰度。</li>\n</ul>\n<h3 id=\"五示例说明\"><strong>五、示例说明</strong></h3>\n<p>假设数据集：[12, 15, 17, 19, 20, 22, 24, 28, 30, 35, 40, 100]（已排序）。</p>\n<ol>\n<li>\n<p>计算四分位数：</p>\n<ul>\n<li>n=12，中位数Q2是第6和第7个数的平均：(22+24)/2=23。</li>\n<li>Q1是前6个数的中位数：(17+19)/2=18（前6数：12,15,17,19,20,22）。</li>\n<li>Q3是后6个数的中位数：(30+35)/2=32.5（后6数：24,28,30,35,40,100）。</li>\n</ul>\n</li>\n<li>\n<p>计算IQR：IQR=Q3-Q1=32.5-18=14.5。</p>\n</li>\n<li>\n<p>确定边界：</p>\n<ul>\n<li>下边界=18 - 1.5×14.5=18-21.75=-3.75</li>\n<li>上边界=32.5 + 1.5×14.5=32.5+21.75=54.25</li>\n</ul>\n</li>\n<li>\n<p>识别异常值：数据中100&gt;54.25，因此100是异常值；其他数据点均在[-3.75, 54.25]范围内。</p>\n</li>\n</ol>\n<h3 id=\"总结\"><strong>总结</strong></h3>\n<p>IQR四分位数法通过“中间50%数据的范围”（IQR）量化离散程度，并通过1.5倍IQR的边界识别异常值。它的核心是<strong>关注数据的主体分布，忽略极端干扰</strong>，是探索性数据分析（EDA）中简单却强大的工具。理解其逻辑的关键在于把握“四分位数划分数据、IQR衡量主体波动、边界外视为异常”这一链条。</p>\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19386427\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19386427</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 15:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "第一篇笔记窗口函数（Window Function），记录我学习sql的命苦笔记",
      "link": "https://www.cnblogs.com/gloria0311/p/19452264",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/gloria0311/p/19452264\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 14:49\">\n    <span>第一篇笔记窗口函数（Window Function），记录我学习sql的命苦笔记</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>窗口函数（Window Function）是：在不减少数据行数的前提下，对数据进行排名/计算/统计。。。<br />\n区分与group by：<br />\nSELECT category, SUM(total_sales)<br />\nFROM sales<br />\nGROUP BY category;<br />\n如果caegory 1 里面有好几个单品，用group by 不会告诉你每个单品的total——sales是多少，它会把category 1里面的所有sales都加起来。<br />\n而窗口不合并行，只“算数”。原来几行 → 还是几行。每一行多了一个“计算结果”。适合：排名、占比、累计、对比</p>\n<p>SELECT category, SUM(total_sales) AS cat_sales<br />\nFROM sales<br />\nGROUP BY category;</p>\n<table>\n<thead>\n<tr>\n<th>category</th>\n<th>cat_sales</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>C1</td>\n<td>19</td>\n</tr>\n<tr>\n<td>C2</td>\n<td>36</td>\n</tr>\n<tr>\n<td>C3</td>\n<td>24</td>\n</tr>\n</tbody>\n</table>\n<p>SELECT<br />\nproduct_id,<br />\ncategory,<br />\ntotal_sales,<br />\nSUM(total_sales) OVER (PARTITION BY category) AS cat_sales<br />\nFROM sales;</p>\n<table>\n<thead>\n<tr>\n<th>product_id</th>\n<th>category</th>\n<th>total_sales</th>\n<th>cat_sales</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>C1</td>\n<td>12</td>\n<td>19</td>\n</tr>\n<tr>\n<td>2</td>\n<td>C1</td>\n<td>7</td>\n<td>19</td>\n</tr>\n<tr>\n<td>3</td>\n<td>C2</td>\n<td>14</td>\n<td>36</td>\n</tr>\n<tr>\n<td>4</td>\n<td>C2</td>\n<td>22</td>\n<td>36</td>\n</tr>\n<tr>\n<td>5</td>\n<td>C3</td>\n<td>24</td>\n<td>24</td>\n</tr>\n</tbody>\n</table>\n<p>窗口函数的标准结构：<br />\n函数名() OVER (<br />\nPARTITION BY 分组规则<br />\nORDER BY 排序规则<br />\n)<br />\n函数名：你要“算什么”？</p>\n<p>ROW_NUMBER()：强制唯一名次（1,2,3…）</p>\n<p>RANK()：并列会跳号（1,2,2,4）</p>\n<p>DENSE_RANK()：并列不跳号（1,2,2,3）</p>\n<p>PARTITION BY：在哪些“范围”里算：<br />\nPARTITION BY category （每个category单独算）<br />\nPARTITION BY ≠ GROUP BY，回到我前面说过的</p>\n<p>用 GROUP BY 的典型问题</p>\n<p>“每个类别的总销量是多少？”<br />\n“每个部门的人数是多少？”<br />\n“每个用户的平均评分是多少？”</p>\n<p>特点：每组只要一行答案</p>\n<p>用 PARTITION BY 的典型问题</p>\n<p>“每个商品在类内的排名？”<br />\n“每一行占本组总量的比例？”<br />\n“每一行与本组平均值差多少？”</p>\n<p>特点：答案必须仍然按行存在（因为你要给每个商品/订单一个排名或对比）</p>\n<p>ORDER BY：决定计算顺序<br />\nORDER BY total_sales DESC, product_id ASC （先按销量高的排前面，销量一样，用 product_id 打破平局）<br />\n注意：这是给窗口函数用的排序，和查询最后的 ORDER BY 是两回事</p>\n<p>例题：牛客刷题SQL48 每个商品的销售总额</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 14:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/gloria0311\">GloriaQi</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "SQL 性能避坑：为什么阿里强制禁用 ORDER BY RAND()？",
      "link": "https://www.cnblogs.com/xzqcsj/p/19452232",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzqcsj/p/19452232\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 14:43\">\n    <span>SQL 性能避坑：为什么阿里强制禁用 ORDER BY RAND()？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"SQL 性能避坑：为什么阿里强制禁用 ORDER BY RAND()？\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3703499/202601/3703499-20260107144026422-1062364965.png\" />\n        如果你翻阅过《阿里巴巴 Java 开发手册》，在 MySQL 数据库规约中，一定见过这条醒目的“红线”：【强制】不得在 database 中使用 ORDER BY RAND() 进行随机排序。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzYyMzM2MjA2OA==&amp;action=getalbum&amp;album_id=4252891456433995787#wechat_redirect\" rel=\"noopener nofollow\" target=\"_blank\">MySQL专栏</a></p>\n<p>如果你翻阅过《阿里巴巴 Java 开发手册》，在 MySQL 数据库规约中，一定见过这条醒目的“红线”：</p>\n<blockquote>\n<p><strong>【强制】不得在 database 中使用 ORDER BY RAND() 进行随机排序。</strong></p>\n</blockquote>\n<p>很多人第一反应是：“不就随机查几条数据吗？MySQL 既然提供了这个内置函数，为什么不让用？”</p>\n<p>事实上，这可能是 MySQL 里最“坑爹”的内置函数之一。在数据量只有几百条时，它是省时省力的小甜甜；一旦数据量突破十万级，它立马变身吸干 CPU 的“牛夫人”，分分钟让你的数据库报警。</p>\n<p>今天我们就来扒一扒，为什么这个函数是性能杀手，以及在海量数据下，我们该如何<strong>优雅且高性能</strong>地实现“<strong>随机推荐</strong>”功能。</p>\n</blockquote>\n<p><img alt=\"874681b40ba63432d5615fd64ad878f4\" class=\"lazyload\" /></p>\n<h2 id=\"案发现场一条-sql-引发的血案\">案发现场：一条 SQL 引发的血案</h2>\n<p>那个让 DBA 暴跳如雷的 SQL 长这样：</p>\n<pre><code class=\"language-sql\">-- 看起来人畜无害，实则剧毒无比\nSELECT * FROM product ORDER BY RAND() LIMIT 3;\n</code></pre>\n<p>如果你的商品表只有几百条数据，怎么玩都行。但当数据量达到 <strong>几万、几十万甚至上百万</strong> 时，这条 SQL 就是一颗定时炸弹。</p>\n<h3 id=\"为什么它这么慢\">为什么它这么慢？</h3>\n<p>我在测试环境重现了一下，顺手敲了个 <code>EXPLAIN</code>。好家伙，<code>Extra</code> 字段里赫然写着：</p>\n<blockquote>\n<p><strong>Using temporary; Using filesort</strong></p>\n</blockquote>\n<p>这简直是 MySQL 性能杀手界的“卧龙凤雏”！</p>\n<p><code>ORDER BY RAND()</code> 的执行流程大致是这样的：</p>\n<ol>\n<li><strong>全表扫描</strong>：MySQL 需要为每一行数据生成一个随机值。</li>\n<li><strong>创建临时表</strong>：把<strong>查询列</strong>和<strong>对应的随机值</strong>塞进临时表（如果内存不够，还会用到磁盘临时表）。</li>\n<li><strong>全局排序</strong>：对临时表里的随机值进行排序。</li>\n<li><strong>取出前几条</strong>：这就好比你要从一袋米里随机挑 3 粒，却先把整袋米倒出来，给每粒米编个号，排个序，再挑前 3 个。</li>\n</ol>\n<p>这不崩谁崩？</p>\n<hr />\n<h2 id=\"深入剖析五种高性能替代方案\">深入剖析：五种高性能替代方案</h2>\n<p>既然 <code>ORDER BY RAND()</code> 不能用，那怎么实现“随机推荐”？其实思路很简单：<strong>把“计算随机”的压力从 Database 转移到 Application（应用层）</strong>，或者<strong>减少数据库的扫描行数</strong>。</p>\n<h3 id=\"方案一应用层随机法application-shuffle\">方案一：应用层随机法（Application Shuffle）</h3>\n<p><strong>适用场景</strong>：数据量不大（例如 &lt; 10万），内存不值钱。</p>\n<p><strong>核心思想</strong>：既然数据库随机排序慢，那我把 ID 全拿出来，在 Java 代码里洗牌行不行？</p>\n<h4 id=\"代码实现\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 查出所有商品ID（只查ID，速度飞快）\n// SQL: SELECT id FROM product;\nList&lt;Integer&gt; allProductIds = productMapper.selectAllIds();\n\n// 2. 利用 Java 的 Collections 工具类进行洗牌\nCollections.shuffle(allProductIds);\n\n// 3. 截取前3个\nList&lt;Integer&gt; randomIds = allProductIds.subList(0, 3);\n\n// 4. 回表批量查询详情\n// SQL: SELECT * FROM product WHERE id IN (..., ..., ...);\nList&lt;Product&gt; results = productMapper.selectByIds(randomIds);\n</code></pre>\n<h4 id=\"优缺点点评\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：真・随机，由于用了 <code>Collections.shuffle</code>，随机分布非常均匀；逻辑简单粗暴。</li>\n<li><strong>缺点</strong>：太占内存。如果表里有 1000 万条 ID，全拉到内存里，JVM 直接 OOM 教做人。</li>\n<li><strong>避坑</strong>：一定要给 ID 列表加缓存（Redis 或本地缓存），别每次请求都去查全量 ID，那跟直接攻击数据库没区别。</li>\n</ul>\n<hr />\n<h3 id=\"方案二limit-偏移法limit-offset\">方案二：Limit 偏移法（Limit Offset）</h3>\n<p><strong>适用场景</strong>：数据量大（百万级以上），对随机性要求没那么严苛。</p>\n<p><strong>核心思想</strong>：给所有数据编个号，随机生成一个“偏移量”，直接跳到那里去拿。</p>\n<h4 id=\"代码实现-1\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 先查询总数（可以走缓存）\n// SQL: SELECT COUNT(*) FROM product;\nint totalCount = productMapper.count();\n\n// 2. 随机生成一个偏移量\n// 注意：totalCount - 3 是为了防止 limit 越界，确保能取够3条\nint offset = new Random().nextInt(totalCount - 3);\n\n// 3. 直接利用 LIMIT 偏移量查询\n// SQL: SELECT * FROM product LIMIT #{offset}, 3;\nList&lt;Product&gt; results = productMapper.selectByOffset(offset, 3);\n</code></pre>\n<h4 id=\"优缺点点评-1\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：性能极佳！大部分情况下只需要扫描 <code>offset + 3</code> 行 ，count值可以放缓存中，定期更新。</li>\n<li><strong>缺点</strong>：\n<ol>\n<li><strong>伪随机</strong>：你取出来的 3 条数据是<strong>物理上连续</strong>的。比如正好取出了“iPhone 13, iPhone 14, iPhone 15”，看起来不够随机。</li>\n<li><strong>深分页问题</strong>：如果随机到的 <code>offset</code> 很大（比如 900万），<code>LIMIT 9000000, 3</code> 的性能也会下降，因为 MySQL 要先扫过前 900 万行扔掉。</li>\n</ol>\n</li>\n</ul>\n<hr />\n<h3 id=\"方案三多次查询法multiple-queries\">方案三：多次查询法（Multiple Queries）</h3>\n<p><strong>适用场景</strong>：数据量大，且要求高质量随机。</p>\n<p><strong>核心思想</strong>：既然方案二取出的数据是连续的，那我多随机几次，每次取 1 条，拼凑出 3 条不就行了？</p>\n<h4 id=\"代码实现-2\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 获取总数\nint total = productMapper.count();\n\n// 2. 生成3个不重复的随机下标（Java 8 Stream 写法）\nList&lt;Integer&gt; randomOffsets = new Random()\n        .ints(0, total) // 生成无限流\n        .distinct()     // 去重\n        .limit(3)       // 截取前3个\n        .boxed()\n        .collect(Collectors.toList());\n\n// 3. 循环查询（或者拼接 SQL 用 UNION ALL）\nList&lt;Product&gt; result = new ArrayList&lt;&gt;();\nfor (Integer offset : randomOffsets) {\n    // SQL: SELECT * FROM product LIMIT #{offset}, 1\n    result.add(productMapper.selectByLimit(offset, 1));\n}\n</code></pre>\n<p>其实这就是 <strong>MySQL 45讲</strong> 里推荐的优化思路。相比于方案二，它打散了连续性。</p>\n<h4 id=\"优缺点点评-2\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：既避免了全表排序，又保证了较好的随机性。</li>\n<li><strong>缺点</strong>：要与数据库交互多次（N 次查询）。不过对于高并发应用，一般都是多次查询 + 缓存，这点开销完全可以接受。</li>\n</ul>\n<h3 id=\"方案四主键范围法index-random\">方案四：主键范围法（Index Random）</h3>\n<p><strong>适用场景</strong>：ID 必须这是连续的（或空洞很少），追求极致性能。</p>\n<p><strong>核心思想</strong>：既然 <code>LIMIT N, M</code> 越往后越慢，那我直接算出随机 ID，用主键索引“跳”过去不就完事了？</p>\n<h4 id=\"代码实现-3\">代码实现</h4>\n<p><strong>Java 逻辑处理：</strong></p>\n<pre><code class=\"language-java\">// 1. 获取 ID 范围（minId 和 maxId）\n// SQL: SELECT MIN(id), MAX(id) FROM product;\nlong minId = productMapper.selectMinId();\nlong maxId = productMapper.selectMaxId();\n\n// 2. 计算随机起点\n// 注意：maxId - minId - 3 是为了保证起点的 id 后面至少还有 3 条数据（假设 ID 连续）\n// 如果 ID 极其稀疏，这个范围可能需要预留更大\nlong range = maxId - minId - 3; \nlong randomId = minId + (long)(Math.random() * range);\n\n// 3. 执行查询\nList&lt;Product&gt; products = productMapper.selectGtId(randomId, 3);\n</code></pre>\n<p><strong>SQL 实现：</strong></p>\n<pre><code class=\"language-sql\">SELECT * FROM product \nWHERE id &gt;= #{randomId} \nLIMIT 3;\n</code></pre>\n<h4 id=\"优缺点点评-3\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：速度快到飞起！复杂度直接降为 $O(\\log N)$（主键查找），完全没有 <code>LIMIT</code> 深分页的性能衰减。</li>\n<li><strong>缺点</strong>：<strong>非常挑食！</strong> 它假设 ID 是连续的。如果你的商品表里因为删删改改导致 ID 中间空洞很大，这类 SQL 会导致分布严重不均（空洞前的那条数据被选中的概率会暴增），甚至可能取不到数据。</li>\n</ul>\n<hr />\n<h3 id=\"方案五redis-预处理法redis-set\">方案五：Redis 预处理法（Redis Set）</h3>\n<p><strong>适用场景</strong>：高并发、高性能、大数据量，标准的互联网大厂打法。</p>\n<p><strong>核心思想</strong>：既然 MySQL 不擅长做随机，那就别难为它了，交给最擅长的 Redis。</p>\n<h4 id=\"代码实现-4\">代码实现</h4>\n<pre><code class=\"language-java\">// 1. 初始化（只需做一次）：把所有商品ID丢进 Redis Set\n// Redis Key: \"all_product_ids\"\n\n// 2. 利用 Redis 原生命令随机获取 ID\n// 命令：SRANDMEMBER key count\n// 时间复杂度：O(N)，N是你取的数量，极快\nList&lt;Integer&gt; randomIds = redisTemplate.opsForSet().randomMembers(\"all_product_ids\", 3);\n\n// 3. 回表 MySQL 查详情（这里全是主键查询，性能无压力）\nList&lt;Product&gt; products = productMapper.selectByIds(randomIds);\n</code></pre>\n<h4 id=\"优缺点点评-4\">优缺点点评</h4>\n<ul>\n<li><strong>优点</strong>：<strong>天花板级别的性能</strong>。无论你有多少数据，Redis 都基本能在几毫秒内吐出随机 ID。</li>\n<li><strong>缺点</strong>：架构变复杂了。你需要维护 Redis 和 MySQL 的数据同步（也就是经典的缓存一致性问题）。</li>\n</ul>\n<hr />\n<h2 id=\"最终总结选型指南\">最终总结：选型指南</h2>\n<p>那这几种方案怎么选？</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">你的场景</th>\n<th style=\"text-align: left;\">推荐方案</th>\n<th style=\"text-align: left;\">理由</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &lt; 10W</strong></td>\n<td style=\"text-align: left;\"><strong>方案一（应用层 Shuffle）</strong></td>\n<td style=\"text-align: left;\">开发最快，逻辑最简单，随机性最完美。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &gt; 10W，ID连续</strong></td>\n<td style=\"text-align: left;\"><strong>方案四（索引跳跃）</strong></td>\n<td style=\"text-align: left;\">既不用维护缓存，又能享受极致性能。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &gt; 10W，允许连续</strong></td>\n<td style=\"text-align: left;\"><strong>方案二（Limit Offset）</strong></td>\n<td style=\"text-align: left;\">性能不错，通用性强，是个老实人。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据量 &gt; 10W，要求打散</strong></td>\n<td style=\"text-align: left;\"><strong>方案三（多次查询）</strong></td>\n<td style=\"text-align: left;\">在性能和随机性之间找到了平衡点。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>高并发 / 追求极致</strong></td>\n<td style=\"text-align: left;\"><strong>方案五（Redis Set）</strong></td>\n<td style=\"text-align: left;\">工业界标准答案，虽然稍微麻烦点，但真香。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>想被辞退</strong></td>\n<td style=\"text-align: left;\"><strong>ORDER BY RAND()</strong></td>\n<td style=\"text-align: left;\">只要你敢用，P0 故障随时带回家。</td>\n</tr>\n</tbody>\n</table>\n<p><strong>最后多嘴一句</strong>：<br />\n如果你的业务可以接受“伪随机”（比如每个人看到的随机列表在 1 小时内是一样的），<strong>强烈建议把算好的随机结果丢进 Redis</strong>。毕竟，<strong>最好的 SQL 优化就是不执行 SQL</strong>。</p>\n<p>别让你写的代码，成为深夜报警的罪魁祸首。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 14:43</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzqcsj\">一旅人</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "三大 Agent-UI 协议深度剖析：AG-UI、A2UI 与 MCP-UI 的设计哲学与工程实践",
      "link": "https://www.cnblogs.com/madtom/p/19452209",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/madtom/p/19452209\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 14:36\">\n    <span>三大 Agent-UI 协议深度剖析：AG-UI、A2UI 与 MCP-UI 的设计哲学与工程实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        随着大模型从\"对话框\"演进为\"自主智能体\"，如何让 Agent 具备富交互能力成为关键挑战。本文基于项目实战，结合 AG-UI、A2UI、MCP-UI 三大协议的源码深度分析，系统阐述它们的设计哲学、核心机制、实现方案及对接方式，并探讨协议组合使用的最佳实践。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>摘要</strong>：随着大模型从\"对话框\"演进为\"自主智能体\"，如何让 Agent 具备富交互能力成为关键挑战。本文基于项目实战，结合 AG-UI、A2UI、MCP-UI 三大协议的源码深度分析，系统阐述它们的设计哲学、核心机制、实现方案及对接方式，并探讨协议组合使用的最佳实践。</p>\n</blockquote>\n<p><img alt=\"占位符：文章封面图 - 三大协议的技术架构全景图\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"目录\">目录</h2>\n<ol>\n<li><a href=\"#1-%E5%BC%95%E8%A8%80%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-agent-ui-%E5%8D%8F%E8%AE%AE\" rel=\"noopener nofollow\">引言：为什么需要 Agent-UI 协议？</a></li>\n<li><a href=\"#2-ag-ui%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E4%BA%A4%E4%BA%92%E5%8D%8F%E8%AE%AE\" rel=\"noopener nofollow\">AG-UI：事件驱动的智能体交互协议</a></li>\n<li><a href=\"#3-a2ui%E5%A3%B0%E6%98%8E%E5%BC%8F-ui-%E7%9A%84%E9%9B%B6%E4%BF%A1%E4%BB%BB%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E\" rel=\"noopener nofollow\">A2UI：声明式 UI 的零信任渲染引擎</a></li>\n<li><a href=\"#4-mcp-uimcp-%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E6%89%A9%E5%B1%95%E5%B1%82\" rel=\"noopener nofollow\">MCP-UI：MCP 协议的可视化扩展层</a></li>\n<li><a href=\"#5-%E5%8D%8F%E8%AE%AE%E7%BB%84%E5%90%88ag-ui--a2ui-%E7%9A%84%E5%8D%8F%E5%90%8C%E6%9E%B6%E6%9E%84\" rel=\"noopener nofollow\">协议组合：AG-UI + A2UI 的协同架构</a></li>\n<li><a href=\"#6-%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%E5%86%B3%E7%AD%96%E6%A1%86%E6%9E%B6\" rel=\"noopener nofollow\">技术选型决策框架</a></li>\n<li><a href=\"#7-demo-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E8%A7%A3%E6%9E%90\" rel=\"noopener nofollow\">Demo 项目实战解析</a></li>\n<li><a href=\"#8-%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B\" rel=\"noopener nofollow\">总结与展望</a></li>\n</ol>\n<hr />\n<h2 id=\"1-引言为什么需要-agent-ui-协议\">1. 引言：为什么需要 Agent-UI 协议？</h2>\n<h3 id=\"11-传统-chatbot-的局限性\">1.1 传统 Chatbot 的局限性</h3>\n<p>传统的 AI 聊天机器人采用简单的 <strong>Request-Response</strong> 模式：用户输入文本，模型返回文本。这种模式在面对复杂业务场景时暴露出严重不足：</p>\n<pre><code>用户 → \"帮我订一家北京的川菜馆\"\n传统 Bot → \"好的，我找到了以下餐厅：1. 川办餐厅... 2. 眉州东坡...\"\n</code></pre>\n<p><strong>问题</strong>：</p>\n<ul>\n<li>❌ 无法展示餐厅图片、评分、价格等结构化信息</li>\n<li>❌ 用户需要手动复制餐厅名称再去搜索</li>\n<li>❌ 无法直接在对话中完成预订操作</li>\n</ul>\n<h3 id=\"12-agent-时代的新需求\">1.2 Agent 时代的新需求</h3>\n<p>当 AI 从 Chatbot 升级为 Agent 后，交互模式发生了本质变化：</p>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>Chatbot</th>\n<th>Agent</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>运行时间</strong></td>\n<td>短（毫秒级）</td>\n<td>长（秒/分钟级）</td>\n</tr>\n<tr>\n<td><strong>输出类型</strong></td>\n<td>纯文本</td>\n<td>文本 + 结构化数据 + UI 控制</td>\n</tr>\n<tr>\n<td><strong>状态管理</strong></td>\n<td>无状态</td>\n<td>复杂状态机</td>\n</tr>\n<tr>\n<td><strong>交互模式</strong></td>\n<td>单轮 Q&amp;A</td>\n<td>多轮工具调用 + 人机协作</td>\n</tr>\n</tbody>\n</table>\n<div class=\"mermaid\">flowchart TB\n    subgraph Chatbot[\"🤖 传统 Chatbot\"]\n        direction TB\n        U1[\"👤 用户\"] --&gt;|\"文本输入\"| B1[\"💬 Bot\"]\n        B1 --&gt;|\"文本输出\"| U1\n    end\n    \n    subgraph Agent[\"🦾 智能体 Agent\"]\n        direction TB\n        U2[\"👤 用户\"] --&gt;|\"多模态输入\"| A[\"🧠 Agent\"]\n        A --&gt;|\"状态事件\"| SM[\"📊 状态机\"]\n        SM --&gt;|\"UI 更新\"| UI[\"🖥️ 富交互 UI\"]\n        A &lt;--&gt;|\"工具调用\"| T[\"🔧 Tools\"]\n        UI --&gt;|\"用户操作\"| A\n    end\n    \n    Chatbot -.-&gt;|\"演进\"| Agent\n</div><h3 id=\"13-三种协议的定位\">1.3 三种协议的定位</h3>\n<p>业界给出了三种截然不同的解决方案：</p>\n<table>\n<thead>\n<tr>\n<th>协议</th>\n<th>来源</th>\n<th>核心定位</th>\n<th>一句话概括</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>AG-UI</strong></td>\n<td>CopilotKit</td>\n<td>事件驱动的状态同步协议</td>\n<td>\"让前端实时感知 Agent 的每一步思考\"</td>\n</tr>\n<tr>\n<td><strong>A2UI</strong></td>\n<td>Google</td>\n<td>声明式 UI 组件规范</td>\n<td>\"Agent 描述意图，客户端负责渲染\"</td>\n</tr>\n<tr>\n<td><strong>MCP-UI</strong></td>\n<td>社区</td>\n<td>MCP 工具的可视化扩展</td>\n<td>\"让工具调用结果具备可视化能力\"</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"2-ag-ui事件驱动的智能体交互协议\">2. AG-UI：事件驱动的智能体交互协议</h2>\n<h3 id=\"21-设计哲学\">2.1 设计哲学</h3>\n<p>AG-UI（Agent-User Interaction Protocol）的核心理念可以概括为：</p>\n<blockquote>\n<p><strong>\"UI 是前端的领域，Agent 只负责广播状态变化\"</strong></p>\n</blockquote>\n<p>AG-UI 认为：Agent 不应该知道\"按钮是圆的还是方的\"，不应该知道\"当前是 React 还是 Vue\"。Agent 只需要告诉前端：\"我正在调用搜索工具\"、\"搜索参数是 XXX\"、\"搜索结果是 YYY\"。至于如何渲染这些信息，完全由前端决定。</p>\n<p>这种设计带来了几个核心优势：</p>\n<ol>\n<li><strong>前端自由度最大化</strong>：同一个 Agent 可以对接 Web、Mobile、CLI 等不同客户端</li>\n<li><strong>实时性极强</strong>：基于流式事件，用户能看到 Agent 思考的每一步</li>\n<li><strong>与现有应用深度集成</strong>：Agent 可以驱动现有 UI 的状态变化</li>\n</ol>\n<div class=\"mermaid\">flowchart LR\n    subgraph Backend[\"🔙 Agent Backend\"]\n        LLM[\"🧠 LLM\"] --&gt; EP[\"Event Producer\"]\n        Tools[\"🔧 Tools\"] --&gt; EP\n    end\n    \n    subgraph Transport[\"📡 传输层\"]\n        EP --&gt;|\"SSE Stream\"| SSE[\"text/event-stream\"]\n    end\n    \n    subgraph Frontend[\"🖥️ Frontend\"]\n        SSE --&gt; Parser[\"Event Parser\"]\n        Parser --&gt; SM[\"State Machine\"]\n        SM --&gt; |\"TEXT_MESSAGE\"| Chat[\"💬 聊天区\"]\n        SM --&gt; |\"TOOL_CALL\"| TC[\"🔧 工具卡片\"]\n        SM --&gt; |\"STATE_DELTA\"| App[\"📊 应用状态\"]\n    end\n</div><h3 id=\"22-核心机制事件类型系统\">2.2 核心机制：事件类型系统</h3>\n<p>AG-UI 定义了一套完整的事件类型体系（约 20+ 种），按功能可分为四大类：</p>\n<h4 id=\"221-生命周期事件\">2.2.1 生命周期事件</h4>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/sdks/typescript/packages/core/src/events.ts\n\nenum EventType {\n  // 运行生命周期\n  RUN_STARTED = \"RUN_STARTED\",      // Agent 开始执行\n  RUN_FINISHED = \"RUN_FINISHED\",    // Agent 执行完成\n  RUN_ERROR = \"RUN_ERROR\",          // Agent 执行出错\n  \n  // 步骤生命周期\n  STEP_STARTED = \"STEP_STARTED\",    // 开始执行某个步骤\n  STEP_FINISHED = \"STEP_FINISHED\",  // 步骤执行完成\n}\n</code></pre>\n<h4 id=\"222-消息流事件\">2.2.2 消息流事件</h4>\n<pre><code class=\"language-typescript\">enum EventType {\n  // 文本消息（流式）\n  TEXT_MESSAGE_START = \"TEXT_MESSAGE_START\",\n  TEXT_MESSAGE_CONTENT = \"TEXT_MESSAGE_CONTENT\",  // delta: 增量文本\n  TEXT_MESSAGE_END = \"TEXT_MESSAGE_END\",\n  TEXT_MESSAGE_CHUNK = \"TEXT_MESSAGE_CHUNK\",      // 批量模式\n  \n  // 思考过程（可选暴露）\n  THINKING_TEXT_MESSAGE_START = \"THINKING_TEXT_MESSAGE_START\",\n  THINKING_TEXT_MESSAGE_CONTENT = \"THINKING_TEXT_MESSAGE_CONTENT\",\n  THINKING_TEXT_MESSAGE_END = \"THINKING_TEXT_MESSAGE_END\",\n}\n</code></pre>\n<h4 id=\"223-工具调用事件\">2.2.3 工具调用事件</h4>\n<pre><code class=\"language-typescript\">enum EventType {\n  // 工具调用生命周期\n  TOOL_CALL_START = \"TOOL_CALL_START\",   // 包含 toolCallId, toolCallName\n  TOOL_CALL_ARGS = \"TOOL_CALL_ARGS\",      // 流式参数：delta 字段\n  TOOL_CALL_END = \"TOOL_CALL_END\",\n  TOOL_CALL_RESULT = \"TOOL_CALL_RESULT\",  // 工具执行结果\n  TOOL_CALL_CHUNK = \"TOOL_CALL_CHUNK\",    // 批量模式\n}\n</code></pre>\n<h4 id=\"224-状态同步事件\">2.2.4 状态同步事件</h4>\n<pre><code class=\"language-typescript\">enum EventType {\n  // 状态管理\n  STATE_SNAPSHOT = \"STATE_SNAPSHOT\",      // 完整状态快照\n  STATE_DELTA = \"STATE_DELTA\",            // 增量状态（JSON Patch RFC 6902）\n  MESSAGES_SNAPSHOT = \"MESSAGES_SNAPSHOT\", // 完整消息历史\n  \n  // 活动状态（用于 UI 展示）\n  ACTIVITY_SNAPSHOT = \"ACTIVITY_SNAPSHOT\",\n  ACTIVITY_DELTA = \"ACTIVITY_DELTA\",\n}\n</code></pre>\n<h3 id=\"23-实现方案传输层与客户端\">2.3 实现方案：传输层与客户端</h3>\n<h4 id=\"231-传输层sse--http-binary\">2.3.1 传输层：SSE + HTTP Binary</h4>\n<p>AG-UI 支持多种传输方式，其中 SSE（Server-Sent Events）是最常用的：</p>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/sdks/typescript/packages/client/src/agent/http.ts\n\nexport class HttpAgent extends AbstractAgent {\n  protected requestInit(input: RunAgentInput): RequestInit {\n    return {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Accept: \"text/event-stream\",  // 关键：请求 SSE 格式\n      },\n      body: JSON.stringify(input),\n    };\n  }\n\n  run(input: RunAgentInput): Observable&lt;BaseEvent&gt; {\n    // 1. 发起 HTTP 请求获取 SSE 流\n    const httpEvents = runHttpRequest(this.url, this.requestInit(input));\n    // 2. 转换为 AG-UI 事件流\n    return transformHttpEventStream(httpEvents);\n  }\n}\n</code></pre>\n<p>传输层数据格式示例：</p>\n<pre><code>event: TEXT_MESSAGE_START\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"msg_001\",\"role\":\"assistant\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"msg_001\",\"delta\":\"我来帮您\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"msg_001\",\"delta\":\"搜索餐厅...\"}\n\nevent: TOOL_CALL_START\ndata: {\"type\":\"TOOL_CALL_START\",\"toolCallId\":\"call_001\",\"toolCallName\":\"search_restaurants\"}\n\nevent: TOOL_CALL_ARGS\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_001\",\"delta\":\"{\\\"cuisine\\\":\\\"川菜\\\"}\"}\n</code></pre>\n<h4 id=\"232-客户端observable--中间件架构\">2.3.2 客户端：Observable + 中间件架构</h4>\n<p>AG-UI 客户端采用 <strong>RxJS Observable</strong> 模式处理事件流，并支持中间件扩展：</p>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/sdks/typescript/packages/client/src/agent/agent.ts\n\nexport abstract class AbstractAgent {\n  private middlewares: Middleware[] = [];\n  \n  // 订阅者模式：支持多个消费者\n  public subscribe(subscriber: AgentSubscriber) {\n    this.subscribers.push(subscriber);\n    return { unsubscribe: () =&gt; { /* ... */ } };\n  }\n  \n  // 中间件注册\n  public use(...middlewares: (Middleware | MiddlewareFunction)[]): this {\n    this.middlewares.push(...normalizedMiddlewares);\n    return this;\n  }\n  \n  // 抽象方法：具体 Agent 实现事件流\n  abstract run(input: RunAgentInput): Observable&lt;BaseEvent&gt;;\n}\n</code></pre>\n<h3 id=\"24-对接方式\">2.4 对接方式</h3>\n<h4 id=\"241-服务端对接python-示例\">2.4.1 服务端对接（Python 示例）</h4>\n<pre><code class=\"language-python\"># Demo 项目：demo-agent-ui-protocols/agents/ag-ui-agent/server.py\n\nfrom sse_starlette.sse import EventSourceResponse\n\nasync def generate_events() -&gt; AsyncGenerator[str, None]:\n    # 1. 发送 RUN_STARTED\n    yield create_event(EventType.RUN_STARTED, {\n        \"threadId\": thread_id,\n        \"runId\": run_id\n    })\n    \n    # 2. 流式调用 LLM\n    async for chunk in llm_stream:\n        if chunk.choices[0].delta.content:\n            yield create_event(EventType.TEXT_MESSAGE_CONTENT, {\n                \"messageId\": msg_id,\n                \"delta\": chunk.choices[0].delta.content\n            })\n        \n        if chunk.choices[0].delta.tool_calls:\n            # 处理工具调用...\n            yield create_event(EventType.TOOL_CALL_START, {...})\n    \n    # 3. 发送 RUN_FINISHED\n    yield create_event(EventType.RUN_FINISHED, {\n        \"threadId\": thread_id,\n        \"runId\": run_id\n    })\n\n@app.post(\"/run\")\nasync def run(request: RunRequest):\n    return EventSourceResponse(generate_events())\n</code></pre>\n<h4 id=\"242-前端对接react-示例\">2.4.2 前端对接（React 示例）</h4>\n<pre><code class=\"language-tsx\">// Demo 项目：demo-agent-ui-protocols/apps/web/src/app/ag-ui-demo/page.tsx\n\nconst handleSendMessage = async (content: string) =&gt; {\n  const response = await fetch('http://localhost:8001/run', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ messages: [{ role: 'user', content }] }),\n  });\n  \n  const reader = response.body.getReader();\n  const decoder = new TextDecoder();\n  \n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) break;\n    \n    // 解析 SSE 事件\n    const events = parseSSE(decoder.decode(value));\n    \n    for (const event of events) {\n      switch (event.type) {\n        case 'TEXT_MESSAGE_CONTENT':\n          // 更新消息内容（流式）\n          setMessages(prev =&gt; updateMessageContent(prev, event));\n          break;\n        case 'TOOL_CALL_START':\n          // 显示工具调用 UI\n          setMessages(prev =&gt; addToolCall(prev, event));\n          break;\n        case 'TOOL_CALL_RESULT':\n          // 渲染工具结果\n          setMessages(prev =&gt; updateToolResult(prev, event));\n          break;\n      }\n    }\n  }\n};\n</code></pre>\n<div class=\"mermaid\">stateDiagram-v2\n    [*] --&gt; Idle: 初始化\n    \n    Idle --&gt; Running: RUN_STARTED\n    \n    state Running {\n        [*] --&gt; Streaming\n        Streaming --&gt; ToolCalling: TOOL_CALL_START\n        ToolCalling --&gt; Streaming: TOOL_CALL_RESULT\n        Streaming --&gt; Streaming: TEXT_MESSAGE_CONTENT\n    }\n    \n    Running --&gt; Idle: RUN_FINISHED\n    Running --&gt; Error: RUN_ERROR\n    Error --&gt; Idle: 重试\n</div><hr />\n<h2 id=\"3-a2ui声明式-ui-的零信任渲染引擎\">3. A2UI：声明式 UI 的零信任渲染引擎</h2>\n<h3 id=\"31-设计哲学\">3.1 设计哲学</h3>\n<p>A2UI（Agent-to-User Interface）由 Google 推出，其核心理念是：</p>\n<blockquote>\n<p><strong>\"Safe like data, expressive like code\"</strong>（像数据一样安全，像代码一样有表现力）</p>\n</blockquote>\n<p>与 AG-UI 的\"前端主导\"不同，A2UI 采用\"<strong>后端主导</strong>\"的思路：Agent 不仅发送数据，还发送 <strong>UI 结构描述</strong>。但为了安全，A2UI 绝对不允许 Agent 发送可执行代码（HTML/JS），而是发送一种<strong>声明式的组件描述 JSON</strong>。</p>\n<h4 id=\"311-安全性设计\">3.1.1 安全性设计</h4>\n<p>A2UI 的安全模型基于\"白名单组件库\"（Catalog）机制：</p>\n<pre><code>Agent 只能说：\"我要渲染一个 Card 组件，ID 是 123，标题是 XXX\"\nAgent 不能说：\"&lt;script&gt;alert('XSS')&lt;/script&gt;\"\n</code></pre>\n<p>这种设计完全杜绝了 LLM 生成恶意代码的风险。</p>\n<h4 id=\"312-跨平台设计\">3.1.2 跨平台设计</h4>\n<p>由于 A2UI 发送的是抽象组件描述而非具体实现，同一套协议可以：</p>\n<ul>\n<li>在 <strong>Web</strong> 端渲染为 DOM 元素</li>\n<li>在 <strong>iOS</strong> 端渲染为 SwiftUI View</li>\n<li>在 <strong>Android</strong> 端渲染为 Compose 组件</li>\n<li>在 <strong>Flutter</strong> 中渲染为 Widget</li>\n</ul>\n<div class=\"mermaid\">flowchart TB\n    subgraph Agent[\"🧠 Agent\"]\n        LLM[\"LLM\"] --&gt; Gen[\"A2UI Generator\"]\n    end\n    \n    subgraph Protocol[\"📦 A2UI JSON\"]\n        Gen --&gt; JSON[\"{“updateComponents”: ...}\"]\n    end\n    \n    subgraph Renderers[\"🌐 各平台渲染器\"]\n        JSON --&gt; Web[\"🌐 Web\\nLit/React\"]\n        JSON --&gt; iOS[\"🍎 iOS\\nSwiftUI\"]\n        JSON --&gt; Android[\"🤖 Android\\nCompose\"]\n        JSON --&gt; Flutter[\"🐦 Flutter\\nWidget\"]\n    end\n    \n    subgraph Output[\"📱 原生 UI\"]\n        Web --&gt; O1[\"🖥️ DOM\"]\n        iOS --&gt; O2[\"📱 UIKit View\"]\n        Android --&gt; O3[\"📱 Compose UI\"]\n        Flutter --&gt; O4[\"📱 Widget Tree\"]\n    end\n</div><h3 id=\"32-核心机制邻接表组件模型\">3.2 核心机制：邻接表组件模型</h3>\n<h4 id=\"321-为什么不用嵌套-json\">3.2.1 为什么不用嵌套 JSON？</h4>\n<p>传统的 UI 描述通常采用嵌套结构：</p>\n<pre><code class=\"language-json\">// ❌ 传统嵌套结构 - 对 LLM 不友好\n{\n  \"type\": \"Column\",\n  \"children\": [\n    {\n      \"type\": \"Text\",\n      \"text\": \"Hello\"\n    },\n    {\n      \"type\": \"Button\",\n      \"children\": [{ \"type\": \"Text\", \"text\": \"Click\" }]\n    }\n  ]\n}\n</code></pre>\n<p><strong>问题</strong>：</p>\n<ul>\n<li>LLM 必须一次性生成完美嵌套，容易出错</li>\n<li>难以增量更新（需要重新发送整个树）</li>\n<li>深层嵌套难以流式生成</li>\n</ul>\n<h4 id=\"322-邻接表模型\">3.2.2 邻接表模型</h4>\n<p>A2UI 采用<strong>邻接表</strong>（Adjacency List）结构，将组件树\"拍平\"为列表：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/docs/concepts/components.md\n\n// ✅ A2UI 邻接表结构 - LLM 友好\n{\n  \"surfaceUpdate\": {\n    \"surfaceId\": \"main\",\n    \"components\": [\n      {\"id\": \"root\", \"component\": {\"Column\": {\"children\": {\"explicitList\": [\"greeting\", \"buttons\"]}}}},\n      {\"id\": \"greeting\", \"component\": {\"Text\": {\"text\": {\"literalString\": \"Hello\"}}}},\n      {\"id\": \"buttons\", \"component\": {\"Row\": {\"children\": {\"explicitList\": [\"cancel-btn\", \"ok-btn\"]}}}},\n      {\"id\": \"cancel-btn\", \"component\": {\"Button\": {\"child\": \"cancel-text\", \"action\": {\"name\": \"cancel\"}}}},\n      {\"id\": \"cancel-text\", \"component\": {\"Text\": {\"text\": {\"literalString\": \"Cancel\"}}}},\n      {\"id\": \"ok-btn\", \"component\": {\"Button\": {\"child\": \"ok-text\", \"action\": {\"name\": \"ok\"}}}},\n      {\"id\": \"ok-text\", \"component\": {\"Text\": {\"text\": {\"literalString\": \"OK\"}}}}\n    ]\n  }\n}\n</code></pre>\n<p><strong>优势</strong>：</p>\n<ul>\n<li>✅ LLM 可以逐个生成组件，无需考虑嵌套</li>\n<li>✅ 增量更新：只发送变化的组件</li>\n<li>✅ 天然支持流式传输（JSONL 格式）</li>\n</ul>\n<h3 id=\"33-消息类型体系\">3.3 消息类型体系</h3>\n<p>A2UI 定义了四种核心消息类型：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/specification/0.9/json/server_to_client.json\n\n{\n  \"oneOf\": [\n    { \"$ref\": \"#/$defs/CreateSurfaceMessage\" },     // 创建 UI 表面\n    { \"$ref\": \"#/$defs/UpdateComponentsMessage\" },  // 更新组件\n    { \"$ref\": \"#/$defs/UpdateDataModelMessage\" },   // 更新数据模型\n    { \"$ref\": \"#/$defs/DeleteSurfaceMessage\" }      // 删除 UI 表面\n  ]\n}\n</code></pre>\n<h4 id=\"331-createsurface初始化-ui-表面\">3.3.1 createSurface：初始化 UI 表面</h4>\n<pre><code class=\"language-json\">{\n  \"createSurface\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"catalogId\": \"a2ui.dev:standard\"  // 声明使用的组件库\n  }\n}\n</code></pre>\n<h4 id=\"332-updatecomponents发送组件定义\">3.3.2 updateComponents：发送组件定义</h4>\n<pre><code class=\"language-json\">{\n  \"updateComponents\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"components\": [\n      {\n        \"id\": \"root\",\n        \"component\": {\n          \"Column\": {\n            \"children\": {\"explicitList\": [\"header\", \"list\"]}\n          }\n        }\n      },\n      {\n        \"id\": \"header\",\n        \"component\": {\n          \"Text\": {\n            \"text\": {\"literalString\": \"推荐餐厅\"},\n            \"usageHint\": \"h1\"\n          }\n        }\n      }\n      // ... 更多组件\n    ]\n  }\n}\n</code></pre>\n<h4 id=\"333-updatedatamodel数据与-ui-分离\">3.3.3 updateDataModel：数据与 UI 分离</h4>\n<p>A2UI 的一个重要设计是<strong>数据模型与组件结构分离</strong>。组件可以通过 <code>path</code> 绑定数据：</p>\n<pre><code class=\"language-json\">// 1. 组件定义（结构）\n{\n  \"updateComponents\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"components\": [{\n      \"id\": \"restaurant-name\",\n      \"component\": {\n        \"Text\": {\n          \"text\": {\"path\": \"/restaurants/0/name\"}  // 数据绑定\n        }\n      }\n    }]\n  }\n}\n\n// 2. 数据更新（内容）\n{\n  \"updateDataModel\": {\n    \"surfaceId\": \"restaurant-list\",\n    \"path\": \"/restaurants/0\",\n    \"op\": \"replace\",\n    \"value\": {\n      \"name\": \"川办餐厅\",\n      \"rating\": 4.8,\n      \"price\": \"$$\"\n    }\n  }\n}\n</code></pre>\n<p><strong>优势</strong>：</p>\n<ul>\n<li>更新数据无需重新发送组件结构</li>\n<li>多个组件可以绑定同一数据路径</li>\n<li>LLM 可以分步生成结构和数据</li>\n</ul>\n<h3 id=\"34-标准组件库catalog\">3.4 标准组件库（Catalog）</h3>\n<p>A2UI 定义了一套标准组件库，涵盖常见 UI 需求：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/specification/0.9/json/standard_catalog_definition.json\n\n{\n  \"$defs\": {\n    \"anyComponent\": {\n      \"oneOf\": [\n        // 展示类\n        { \"$ref\": \"#/$defs/Text\" },\n        { \"$ref\": \"#/$defs/Image\" },\n        { \"$ref\": \"#/$defs/Icon\" },\n        { \"$ref\": \"#/$defs/Video\" },\n        { \"$ref\": \"#/$defs/AudioPlayer\" },\n        \n        // 布局类\n        { \"$ref\": \"#/$defs/Row\" },\n        { \"$ref\": \"#/$defs/Column\" },\n        { \"$ref\": \"#/$defs/List\" },\n        \n        // 容器类\n        { \"$ref\": \"#/$defs/Card\" },\n        { \"$ref\": \"#/$defs/Tabs\" },\n        { \"$ref\": \"#/$defs/Modal\" },\n        { \"$ref\": \"#/$defs/Divider\" },\n        \n        // 交互类\n        { \"$ref\": \"#/$defs/Button\" },\n        { \"$ref\": \"#/$defs/CheckBox\" },\n        { \"$ref\": \"#/$defs/TextField\" },\n        { \"$ref\": \"#/$defs/DateTimeInput\" },\n        { \"$ref\": \"#/$defs/ChoicePicker\" },\n        { \"$ref\": \"#/$defs/Slider\" }\n      ]\n    }\n  }\n}\n</code></pre>\n<h3 id=\"35-客户端渲染器renderer\">3.5 客户端渲染器（Renderer）</h3>\n<p>A2UI 提供了多种渲染器实现：</p>\n<pre><code class=\"language-typescript\">// 源码位置：A2UI/renderers/lit/src/0.8/core.ts\n\nexport * as Events from \"./events/events.js\";\nexport * as Types from \"./types/types.js\";\n\nimport { create as createSignalA2uiMessageProcessor } from \"./data/signal-model-processor.js\";\nimport { A2uiMessageProcessor } from \"./data/model-processor.js\";\n\nexport const Data = {\n  createSignalA2uiMessageProcessor,  // 响应式数据处理\n  A2uiMessageProcessor,               // 消息处理器\n  Guards,\n};\n</code></pre>\n<p>渲染流程：</p>\n<ol>\n<li><strong>解析消息</strong>：将 JSONL 解析为消息对象</li>\n<li><strong>构建组件树</strong>：根据邻接表重建树结构</li>\n<li><strong>数据绑定</strong>：将 dataModel 注入组件</li>\n<li><strong>原生渲染</strong>：调用平台原生组件库</li>\n</ol>\n<div class=\"mermaid\">flowchart LR\n    subgraph Input[\"📥 输入\"]\n        JSONL[\"JSONL Stream\"]\n    end\n    \n    subgraph Process[\"⚙️ 处理流程\"]\n        JSONL --&gt; Parse[\"1️⃣ 解析消息\"]\n        Parse --&gt; Build[\"2️⃣ 构建组件树\"]\n        Build --&gt; Bind[\"3️⃣ 数据绑定\"]\n        Bind --&gt; Render[\"4️⃣ 原生渲染\"]\n    end\n    \n    subgraph Output[\"📱 输出\"]\n        Render --&gt; UI[\"原生 UI 组件\"]\n    end\n    \n    subgraph DataFlow[\"📊 数据流\"]\n        DM[(\"DataModel\")] -.-&gt;|\"/path/to/data\"| Bind\n    end\n</div><h3 id=\"36-用户交互action-回传\">3.6 用户交互：Action 回传</h3>\n<p>当用户点击按钮等交互时，客户端发送 <code>userAction</code> 消息：</p>\n<pre><code class=\"language-json\">// 源码位置：A2UI/specification/0.9/json/client_to_server.json\n\n{\n  \"userAction\": {\n    \"name\": \"book_restaurant\",           // action 名称\n    \"surfaceId\": \"restaurant-list\",\n    \"sourceComponentId\": \"book-btn\",\n    \"timestamp\": \"2024-01-07T10:30:00Z\",\n    \"context\": {                         // 上下文数据\n      \"restaurantId\": \"rest_001\",\n      \"restaurantName\": \"川办餐厅\"\n    }\n  }\n}\n</code></pre>\n<h3 id=\"37-对接方式\">3.7 对接方式</h3>\n<h4 id=\"371-服务端对接python-示例\">3.7.1 服务端对接（Python 示例）</h4>\n<pre><code class=\"language-python\"># Demo 项目：demo-agent-ui-protocols/agents/a2ui-agent/server.py\n\nclass A2UIGenerator:\n    @staticmethod\n    def surface_update(surface_id: str, components: list) -&gt; dict:\n        return {\"surfaceUpdate\": {\"surfaceId\": surface_id, \"components\": components}}\n\n    @staticmethod\n    def data_model_update(surface_id: str, path: str, value: any) -&gt; dict:\n        return {\n            \"updateDataModel\": {\n                \"surfaceId\": surface_id,\n                \"path\": path,\n                \"op\": \"replace\",\n                \"value\": value\n            }\n        }\n\nasync def generate_ui(restaurants: list):\n    # 1. 创建 Surface\n    yield json.dumps({\"createSurface\": {\"surfaceId\": \"main\", \"catalogId\": \"standard\"}})\n    \n    # 2. 发送组件结构\n    components = create_restaurant_list_components()\n    yield json.dumps(A2UIGenerator.surface_update(\"main\", components))\n    \n    # 3. 发送数据\n    for i, restaurant in enumerate(restaurants):\n        yield json.dumps(A2UIGenerator.data_model_update(\n            \"main\", \n            f\"/restaurants/{i}\", \n            restaurant\n        ))\n</code></pre>\n<h4 id=\"372-前端对接react-示例\">3.7.2 前端对接（React 示例）</h4>\n<pre><code class=\"language-tsx\">// Demo 项目：demo-agent-ui-protocols/apps/web/src/app/a2ui-demo/A2UIRenderer.tsx\n\nconst A2UIRenderer = ({ messages }: { messages: A2UIMessage[] }) =&gt; {\n  const [components, setComponents] = useState&lt;Map&lt;string, ComponentDef&gt;&gt;();\n  const [dataModel, setDataModel] = useState&lt;Record&lt;string, any&gt;&gt;({});\n  \n  useEffect(() =&gt; {\n    for (const msg of messages) {\n      if (msg.updateComponents) {\n        // 更新组件 Map\n        msg.updateComponents.components.forEach(comp =&gt; {\n          setComponents(prev =&gt; new Map(prev).set(comp.id, comp));\n        });\n      }\n      if (msg.updateDataModel) {\n        // 更新数据模型\n        setDataModel(prev =&gt; ({\n          ...prev,\n          [msg.updateDataModel.path]: msg.updateDataModel.value\n        }));\n      }\n    }\n  }, [messages]);\n  \n  // 递归渲染组件树\n  const renderComponent = (id: string) =&gt; {\n    const comp = components.get(id);\n    if (!comp) return null;\n    \n    // 根据组件类型映射到 React 组件\n    switch (Object.keys(comp.component)[0]) {\n      case 'Text':\n        const textValue = resolveValue(comp.component.Text.text, dataModel);\n        return &lt;span key={id}&gt;{textValue}&lt;/span&gt;;\n      case 'Column':\n        return (\n          &lt;div key={id} className=\"flex flex-col\"&gt;\n            {comp.component.Column.children.explicitList.map(renderComponent)}\n          &lt;/div&gt;\n        );\n      // ... 其他组件\n    }\n  };\n  \n  return renderComponent('root');\n};\n</code></pre>\n<hr />\n<h2 id=\"4-mcp-uimcp-协议的可视化扩展层\">4. MCP-UI：MCP 协议的可视化扩展层</h2>\n<h3 id=\"41-设计哲学\">4.1 设计哲学</h3>\n<p>MCP-UI 是社区基于 Anthropic 的 <strong>Model Context Protocol (MCP)</strong> 开发的 UI 扩展。其核心理念是：</p>\n<blockquote>\n<p><strong>\"让工具调用结果具备可视化能力\"</strong></p>\n</blockquote>\n<p>与 AG-UI、A2UI 不同，MCP-UI 不试图定义新的协议，而是<strong>复用现有的 MCP 协议</strong>，在工具返回值中添加 <code>UIResource</code> 字段。</p>\n<h4 id=\"411-与-mcp-的关系\">4.1.1 与 MCP 的关系</h4>\n<pre><code>MCP 协议：\n  - Tool Definition（工具定义）\n  - Tool Call（工具调用）\n  - Tool Result（工具结果） ← MCP-UI 在这里扩展\n</code></pre>\n<p>MCP-UI 的创新在于：工具不仅可以返回文本/JSON 数据，还可以返回<strong>可交互的 UI 片段</strong>。</p>\n<h3 id=\"42-核心机制uiresource\">4.2 核心机制：UIResource</h3>\n<h4 id=\"421-uiresource-数据结构\">4.2.1 UIResource 数据结构</h4>\n<pre><code class=\"language-typescript\">// 源码位置：mcp-ui/sdks/typescript/server/src/types.ts\n\ninterface UIResource {\n  type: 'resource';\n  resource: {\n    uri: string;       // 唯一标识，如 ui://component/booking-form\n    mimeType: MimeType; // 内容类型\n    text?: string;      // 内联内容\n    blob?: string;      // Base64 编码内容\n    _meta?: Record&lt;string, unknown&gt;;\n  };\n}\n\ntype MimeType =\n  | 'text/html'                           // 内联 HTML\n  | 'text/uri-list'                       // 外部 URL\n  | 'application/vnd.mcp-ui.remote-dom+javascript; framework=react'\n  | 'application/vnd.mcp-ui.remote-dom+javascript; framework=webcomponents';\n</code></pre>\n<h4 id=\"422-三种渲染模式\">4.2.2 三种渲染模式</h4>\n<p>MCP-UI 支持三种不同的 UI 资源类型：</p>\n<p><strong>1. Raw HTML（内联 HTML）</strong></p>\n<pre><code class=\"language-typescript\">{\n  uri: \"ui://restaurant/card\",\n  mimeType: \"text/html\",\n  text: `\n    &lt;div class=\"restaurant-card\"&gt;\n      &lt;h2&gt;川办餐厅&lt;/h2&gt;\n      &lt;button onclick=\"window.parent.postMessage({type:'tool',payload:{toolName:'book'}},'*')\"&gt;\n        预订\n      &lt;/button&gt;\n    &lt;/div&gt;\n  `\n}\n</code></pre>\n<p><strong>2. External URL（外部页面）</strong></p>\n<pre><code class=\"language-typescript\">{\n  uri: \"ui://restaurant/detail\",\n  mimeType: \"text/uri-list\",\n  text: \"https://restaurant.example.com/embed/123\"\n}\n</code></pre>\n<p><strong>3. Remote DOM（远程 DOM）</strong></p>\n<p>这是 MCP-UI 最强大的模式，基于 Shopify 的 <a href=\"https://github.com/Shopify/remote-dom\" rel=\"noopener nofollow\" target=\"_blank\">remote-dom</a> 技术：</p>\n<pre><code class=\"language-typescript\">{\n  uri: \"ui://restaurant/form\",\n  mimeType: \"application/vnd.mcp-ui.remote-dom+javascript; framework=react\",\n  text: `\n    // 这段 JS 在沙箱中执行，通过 JSON 消息与宿主通信\n    const form = document.createElement('ui-form');\n    form.addEventListener('submit', (e) =&gt; {\n      window.postMessage({ type: 'tool', payload: { toolName: 'submit_booking', params: e.detail } });\n    });\n    document.body.appendChild(form);\n  `\n}\n</code></pre>\n<div class=\"mermaid\">flowchart TB\n    subgraph Server[\"🔧 MCP Server\"]\n        Tool[\"Tool Result\"] --&gt; UIRes[\"UIResource\"]\n    end\n    \n    UIRes --&gt; Type{\"mimeType?\"}\n    \n    subgraph Mode1[\"📄 Raw HTML\"]\n        Type --&gt;|\"text/html\"| HTML[\"iframe srcDoc\"]\n        HTML --&gt; Sandbox1[\"🔒 沙箱渲染\"]\n    end\n    \n    subgraph Mode2[\"🌐 External URL\"]\n        Type --&gt;|\"text/uri-list\"| URL[\"iframe src\"]\n        URL --&gt; Sandbox2[\"🔒 外部页面\"]\n    end\n    \n    subgraph Mode3[\"🖥️ Remote DOM\"]\n        Type --&gt;|\"remote-dom\"| Script[\"JS Script\"]\n        Script --&gt; Worker[\"🔒 沙箱执行\"]\n        Worker --&gt;|\"JSON Patch\"| Host[\"🏠 宿主渲染\"]\n    end\n    \n    Sandbox1 &amp; Sandbox2 &amp; Host --&gt; Actions[\"📤 postMessage\"]\n    Actions --&gt; Client[\"📱 客户端处理\"]\n</div><h3 id=\"43-客户端渲染器\">4.3 客户端渲染器</h3>\n<h4 id=\"431-uiresourcerenderer-组件\">4.3.1 UIResourceRenderer 组件</h4>\n<pre><code class=\"language-tsx\">// 源码位置：mcp-ui/sdks/typescript/client/src/components/UIResourceRenderer.tsx\n\nexport const UIResourceRenderer = (props: UIResourceRendererProps) =&gt; {\n  const { resource, onUIAction, supportedContentTypes } = props;\n  const contentType = getContentType(resource);\n\n  switch (contentType) {\n    case 'rawHtml':\n    case 'externalUrl':\n      // 使用 iframe 沙箱渲染\n      return &lt;HTMLResourceRenderer resource={resource} onUIAction={onUIAction} /&gt;;\n      \n    case 'remoteDom':\n      // 使用 Remote DOM 渲染（更安全、更灵活）\n      return &lt;RemoteDOMResourceRenderer resource={resource} onUIAction={onUIAction} /&gt;;\n      \n    default:\n      return &lt;p&gt;Unsupported resource type.&lt;/p&gt;;\n  }\n};\n</code></pre>\n<h4 id=\"432-remote-dom-渲染器\">4.3.2 Remote DOM 渲染器</h4>\n<p>Remote DOM 模式下，UI 逻辑在 iframe 沙箱中执行，但 DOM 变化通过 JSON 消息同步到宿主：</p>\n<pre><code class=\"language-tsx\">// 源码位置：mcp-ui/sdks/typescript/client/src/components/RemoteDOMResourceRenderer.tsx\n\nconst RemoteDOMResourceRenderer: React.FC&lt;RemoteDOMResourceProps&gt; = ({\n  resource, library, onUIAction\n}) =&gt; {\n  const iframeRef = useRef&lt;HTMLIFrameElement&gt;(null);\n  \n  // 1. 创建 Remote Receiver（接收 DOM 变化）\n  const { receiver, components } = useMemo(() =&gt; {\n    const reactReceiver = new RemoteReceiver();\n    // 将组件库映射为 Remote Components\n    // ...\n    return { receiver: reactReceiver, components: componentMap };\n  }, [library]);\n  \n  // 2. 监听 iframe 消息（UI Action）\n  useEffect(() =&gt; {\n    const handleMessage = (event: MessageEvent) =&gt; {\n      if (event.source === iframeRef.current?.contentWindow) {\n        onUIAction?.(event.data as UIActionResult);\n      }\n    };\n    window.addEventListener('message', handleMessage);\n    return () =&gt; window.removeEventListener('message', handleMessage);\n  }, [onUIAction]);\n  \n  // 3. iframe 加载后注入代码\n  const handleIframeLoad = () =&gt; {\n    const thread = new ThreadIframe&lt;SandboxAPI&gt;(iframeRef.current);\n    thread.imports.render({ code: resource.text, ... }, receiver.connection);\n  };\n  \n  return (\n    &lt;&gt;\n      &lt;iframe ref={iframeRef} srcDoc={IFRAME_SRC_DOC} onLoad={handleIframeLoad} /&gt;\n      {/* Remote DOM 渲染结果 */}\n      &lt;RemoteRootRenderer receiver={receiver} components={components} /&gt;\n    &lt;/&gt;\n  );\n};\n</code></pre>\n<h3 id=\"44-ui-action-系统\">4.4 UI Action 系统</h3>\n<p>MCP-UI 定义了五种 UI 交互类型：</p>\n<pre><code class=\"language-typescript\">// 源码位置：mcp-ui/sdks/typescript/client/src/types.ts\n\nexport type UIActionResult =\n  | { type: 'tool', payload: { toolName: string, params: Record&lt;string, unknown&gt; } }\n  | { type: 'prompt', payload: { prompt: string } }\n  | { type: 'link', payload: { url: string } }\n  | { type: 'intent', payload: { intent: string, params: Record&lt;string, unknown&gt; } }\n  | { type: 'notify', payload: { message: string } };\n</code></pre>\n<p><strong>使用场景</strong>：</p>\n<ul>\n<li><code>tool</code>：触发工具调用（如\"预订\"按钮）</li>\n<li><code>prompt</code>：发送新的用户消息</li>\n<li><code>link</code>：打开外部链接</li>\n<li><code>intent</code>：触发应用内意图</li>\n<li><code>notify</code>：显示通知消息</li>\n</ul>\n<h3 id=\"45-对接方式\">4.5 对接方式</h3>\n<h4 id=\"451-服务端对接python-示例\">4.5.1 服务端对接（Python 示例）</h4>\n<pre><code class=\"language-python\"># Demo 项目：demo-agent-ui-protocols/agents/mcp-ui-agent/server.py\n\ndef create_restaurant_card_ui(restaurants: list) -&gt; dict:\n    html = f\"\"\"\n    &lt;div class=\"restaurant-list\"&gt;\n        {''.join([f'''\n        &lt;div class=\"restaurant-card\" data-id=\"{r['id']}\"&gt;\n            &lt;img src=\"{r['image']}\" /&gt;\n            &lt;h3&gt;{r['name']}&lt;/h3&gt;\n            &lt;p&gt;评分: {r['rating']} | 价格: {r['price']}&lt;/p&gt;\n            &lt;button onclick=\"window.parent.postMessage({{\n                type: 'tool',\n                payload: {{\n                    toolName: 'show_booking_form',\n                    params: {{ restaurant_name: '{r['name']}' }}\n                }}\n            }}, '*')\"&gt;预订&lt;/button&gt;\n        &lt;/div&gt;\n        ''' for r in restaurants])}\n    &lt;/div&gt;\n    \"\"\"\n    \n    return {\n        \"type\": \"ui_resource\",\n        \"resource\": {\n            \"uri\": \"ui://restaurant/list\",\n            \"mimeType\": \"text/html\",\n            \"text\": html\n        }\n    }\n\n@app.post(\"/run\")\nasync def run(request: RunRequest):\n    if request.tool_call:\n        # 直接执行工具调用\n        result = execute_tool(request.tool_call.name, request.tool_call.params)\n        return result\n    else:\n        # 让 LLM 决定调用哪个工具\n        response = await call_llm_with_tools(request.messages)\n        return response\n</code></pre>\n<h4 id=\"452-前端对接react-示例\">4.5.2 前端对接（React 示例）</h4>\n<pre><code class=\"language-tsx\">// Demo 项目：demo-agent-ui-protocols/apps/web/src/app/mcp-ui-demo/page.tsx\n\nconst MCPUIDemo = () =&gt; {\n  const [currentUI, setCurrentUI] = useState&lt;UIResource | null&gt;(null);\n  \n  // 处理来自 UI 的 Action\n  useEffect(() =&gt; {\n    const handleMessage = async (event: MessageEvent) =&gt; {\n      const { type, payload } = event.data;\n      \n      if (type === 'tool') {\n        // 调用后端工具\n        const response = await fetch('http://localhost:8003/run', {\n          method: 'POST',\n          body: JSON.stringify({ tool_call: payload }),\n        });\n        const result = await response.json();\n        \n        if (result.type === 'ui_resource') {\n          setCurrentUI(result.resource);\n        }\n      }\n    };\n    \n    window.addEventListener('message', handleMessage);\n    return () =&gt; window.removeEventListener('message', handleMessage);\n  }, []);\n  \n  return (\n    &lt;div&gt;\n      {currentUI &amp;&amp; (\n        &lt;UIResourceRenderer \n          resource={currentUI.resource}\n          onUIAction={handleToolCallback}\n        /&gt;\n      )}\n    &lt;/div&gt;\n  );\n};\n</code></pre>\n<hr />\n<h2 id=\"5-协议组合ag-ui--a2ui-的协同架构\">5. 协议组合：AG-UI + A2UI 的协同架构</h2>\n<h3 id=\"51-为什么要组合使用\">5.1 为什么要组合使用？</h3>\n<p>三种协议并非互斥关系，它们可以<strong>协同工作</strong>，发挥各自优势。特别是 <strong>AG-UI + A2UI</strong> 的组合，在 A2UI 官方文档中被明确提及：</p>\n<blockquote>\n<p>\"AG UI translates from A2UI messages to AG UI messages, and handles transport and state sync automatically.\"</p>\n<p>— <a href=\"A2UI/docs/transports.md\" rel=\"noopener nofollow\" target=\"_blank\">A2UI Transports 文档</a></p>\n</blockquote>\n<h3 id=\"52-ag-ui-作为-a2ui-的传输层\">5.2 AG-UI 作为 A2UI 的传输层</h3>\n<p>在这种架构下：</p>\n<ul>\n<li><strong>A2UI</strong> 负责：UI 结构定义、组件规范、数据模型</li>\n<li><strong>AG-UI</strong> 负责：消息传输、状态同步、事件路由</li>\n</ul>\n<div class=\"mermaid\">flowchart TB\n    subgraph Frontend[\"🖥️ Frontend\"]\n        Client[\"AG-UI Client\\n(Events)\"] --&gt; A2UIMsg[\"A2UI Messages\\n(JSON)\"]\n        A2UIMsg --&gt; Renderer[\"A2UI Renderer\\n(Components)\"]\n    end\n    \n    subgraph Transport[\"📡 Transport\"]\n        Client &lt;-.-&gt;|\"SSE Events\"| Server\n    end\n    \n    subgraph Agent[\"🤖 Agent\"]\n        Server[\"AG-UI Server\\n(SSE Stream)\"] --&gt; Generator[\"A2UI Generator\\n(JSONL)\"]\n        Generator --&gt; LLM[\"LLM / Tools\"]\n    end\n    \n    style Frontend fill:#e3f2fd\n    style Transport fill:#fff3e0\n    style Agent fill:#f3e5f5\n</div><h3 id=\"53-实现方式将-a2ui-消息包装为-ag-ui-事件\">5.3 实现方式：将 A2UI 消息包装为 AG-UI 事件</h3>\n<pre><code class=\"language-typescript\">// 伪代码：AG-UI + A2UI 集成\n\n// 1. Agent 生成 A2UI 消息\nconst a2uiMessages = generateA2UIComponents(restaurants);\n\n// 2. 包装为 AG-UI 的 CUSTOM 或 ACTIVITY_SNAPSHOT 事件\nfor (const msg of a2uiMessages) {\n  yield {\n    type: EventType.ACTIVITY_SNAPSHOT,\n    messageId: `a2ui-${Date.now()}`,\n    activityType: \"a2ui\",  // 标记为 A2UI 消息\n    content: msg,          // A2UI 原始消息\n  };\n}\n\n// 3. 前端根据 activityType 路由到 A2UI 渲染器\nagent.subscribe({\n  onActivitySnapshot: (event) =&gt; {\n    if (event.activityType === \"a2ui\") {\n      a2uiRenderer.processMessage(event.content);\n    }\n  }\n});\n</code></pre>\n<h3 id=\"54-ag-ui--mcp-ui-的组合\">5.4 AG-UI + MCP-UI 的组合</h3>\n<p>AG-UI 官方提供了 <code>@ag-ui/mcp-apps-middleware</code>，可以将 MCP-UI 的 UI 资源集成到 AG-UI 事件流中：</p>\n<pre><code class=\"language-typescript\">// 源码位置：ag-ui/middlewares/mcp-apps-middleware/README.md\n\nimport { MCPAppsMiddleware } from \"@ag-ui/mcp-apps-middleware\";\n\nconst agent = new YourAgent().use(\n  new MCPAppsMiddleware({\n    mcpServers: [\n      { type: \"http\", url: \"http://localhost:3001/mcp\" }\n    ],\n  })\n);\n\n// 中间件自动：\n// 1. 发现 MCP Server 的 UI-enabled Tools\n// 2. 将工具注入 Agent 的工具列表\n// 3. 执行工具调用并获取 UIResource\n// 4. 发射 ACTIVITY_SNAPSHOT 事件（activityType: \"mcp-apps\"）\n</code></pre>\n<h3 id=\"55-三协议融合架构\">5.5 三协议融合架构</h3>\n<p>在复杂场景下，三种协议可以同时使用：</p>\n<div class=\"mermaid\">flowchart TB\n    subgraph Frontend[\"🖥️ Frontend\"]\n        subgraph Router[\"AG-UI Event Router\"]\n            TextR[\"📝 Text/Tool\\nRenderer\"]\n            A2UIR[\"📱 A2UI Renderer\\n(a2ui type)\"]\n            MCPR[\"🔧 MCP-UI Renderer\\n(mcp-apps type)\"]\n        end\n    end\n    \n    Router &lt;-.-&gt;|\"SSE Events\"| Server\n    \n    subgraph Agent[\"🤖 Agent\"]\n        subgraph ServerLayer[\"AG-UI Server + Middlewares\"]\n            LLMAdapter[\"LLM Adapter\"]\n            A2AMW[\"A2A Middleware\"]\n            MCPMW[\"MCP-Apps Middleware\"]\n        end\n        \n        LLMAdapter --&gt; LLM[(\"🧠 LLM\\n(OpenAI)\")]\n        A2AMW --&gt; SubAgents[(\"🤝 A2A Agents\\n(Sub-agents)\")]\n        MCPMW --&gt; MCPServers[(\"🔌 MCP Servers\\n(Tools+UI)\")]\n    end\n    \n    style Frontend fill:#e3f2fd\n    style Agent fill:#f3e5f5\n    style Router fill:#e8f5e9\n    style ServerLayer fill:#fff3e0\n</div><p><strong>各协议职责</strong>：</p>\n<ul>\n<li><strong>AG-UI</strong>：作为\"总线\"，负责事件路由和状态同步</li>\n<li><strong>A2UI</strong>：负责复杂的、跨平台的声明式 UI</li>\n<li><strong>MCP-UI</strong>：负责工具级别的快速 UI 扩展</li>\n</ul>\n<hr />\n<h2 id=\"6-技术选型决策框架\">6. 技术选型决策框架</h2>\n<h3 id=\"61-维度对比表\">6.1 维度对比表</h3>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>AG-UI</th>\n<th>A2UI</th>\n<th>MCP-UI</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>核心理念</strong></td>\n<td>事件驱动的状态同步</td>\n<td>声明式 UI 组件规范</td>\n<td>MCP 工具的 UI 扩展</td>\n</tr>\n<tr>\n<td><strong>UI 控制权</strong></td>\n<td>前端主导</td>\n<td>后端主导（结构）</td>\n<td>后端主导（内容）</td>\n</tr>\n<tr>\n<td><strong>安全模型</strong></td>\n<td>依赖前端实现</td>\n<td><strong>最高</strong>（白名单组件）</td>\n<td>中等（iframe 沙箱）</td>\n</tr>\n<tr>\n<td><strong>跨平台能力</strong></td>\n<td>弱（需各端适配）</td>\n<td><strong>最强</strong>（抽象组件）</td>\n<td>中等（Web 优先）</td>\n</tr>\n<tr>\n<td><strong>实时性</strong></td>\n<td><strong>最强</strong>（流式事件）</td>\n<td>中等（JSONL 流）</td>\n<td>弱（Request-Response）</td>\n</tr>\n<tr>\n<td><strong>开发复杂度</strong></td>\n<td>前端复杂</td>\n<td>架构复杂</td>\n<td><strong>最简单</strong></td>\n</tr>\n<tr>\n<td><strong>生态兼容性</strong></td>\n<td>CopilotKit 生态</td>\n<td>Google 生态</td>\n<td>MCP 生态</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"62-场景-协议匹配指南\">6.2 场景-协议匹配指南</h3>\n<h4 id=\"场景-a企业级-copilot-系统\">场景 A：企业级 Copilot 系统</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>需要与现有复杂业务系统深度集成</li>\n<li>Agent 需要操作现有 UI 状态（如高亮表格行、填写表单）</li>\n<li>需要实时展示 Agent 思考过程</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>AG-UI 为主</strong></p>\n<pre><code class=\"language-typescript\">// AG-UI 可以驱动现有 UI 状态\nagent.subscribe({\n  onStateDelta: (event) =&gt; {\n    // 增量更新应用状态\n    applyJsonPatch(appState, event.delta);\n  },\n  onToolCallStart: (event) =&gt; {\n    // 高亮相关 UI 区域\n    highlightUIRegion(event.toolCallName);\n  }\n});\n</code></pre>\n<h4 id=\"场景-b跨平台消费级-app\">场景 B：跨平台消费级 App</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>同时支持 Web、iOS、Android</li>\n<li>对安全性要求极高（防止 XSS、幻觉输出）</li>\n<li>需要统一的设计语言</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>A2UI 为主</strong></p>\n<pre><code class=\"language-json\">// A2UI 一次定义，多端渲染\n{\n  \"updateComponents\": {\n    \"components\": [\n      {\"id\": \"card\", \"component\": {\"Card\": {...}}}\n    ]\n  }\n}\n\n// Web 端：渲染为 &lt;div class=\"card\"&gt;\n// iOS 端：渲染为 SwiftUI Card\n// Android 端：渲染为 Compose Card\n</code></pre>\n<h4 id=\"场景-c开发者工具--ide-插件\">场景 C：开发者工具 / IDE 插件</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>需要快速为现有工具添加 UI</li>\n<li>希望第三方开发者能贡献 UI 插件</li>\n<li>不需要复杂的跨平台支持</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>MCP-UI 为主</strong></p>\n<pre><code class=\"language-typescript\">// MCP Server 返回 UI\nserver.tool(\"show_code_diff\", () =&gt; ({\n  type: \"ui_resource\",\n  resource: {\n    uri: \"ui://diff/viewer\",\n    mimeType: \"text/html\",\n    text: generateDiffHTML(changes)\n  }\n}));\n</code></pre>\n<h4 id=\"场景-d复杂多-agent-系统\">场景 D：复杂多 Agent 系统</h4>\n<p><strong>需求特征</strong>：</p>\n<ul>\n<li>多个 Agent 协作</li>\n<li>既需要实时状态同步，又需要丰富 UI</li>\n<li>需要调用外部 MCP 工具</li>\n</ul>\n<p><strong>推荐方案</strong>：<strong>AG-UI + A2UI + MCP-UI 组合</strong></p>\n<pre><code class=\"language-typescript\">const agent = new OrchestrationAgent()\n  .use(new A2AMiddleware({ agentUrls: [...] }))    // 连接子 Agent\n  .use(new MCPAppsMiddleware({ mcpServers: [...] })) // 连接 MCP 工具\n  .use(new A2UIMiddleware({ catalog: 'standard' })); // 支持 A2UI 渲染\n</code></pre>\n<h3 id=\"63-决策流程图\">6.3 决策流程图</h3>\n<div class=\"mermaid\">flowchart TB\n    Start([\"🚀 开始选型\"]) --&gt; Q1{\"是否需要&lt;br/&gt;跨平台原生渲染？\"}\n    \n    Q1 --&gt;|\"✅ Yes\"| A2UI[\"📱 A2UI 为主&lt;br/&gt;&lt;i&gt;统一定义，多端原生&lt;/i&gt;\"]\n    Q1 --&gt;|\"❌ No\"| Q2{\"是否需要&lt;br/&gt;实时状态同步？\"}\n    \n    Q2 --&gt;|\"✅ Yes\"| AGUI[\"⚡ AG-UI 为主&lt;br/&gt;&lt;i&gt;事件驱动，状态透明&lt;/i&gt;\"]\n    Q2 --&gt;|\"❌ No\"| Q3{\"是否复用&lt;br/&gt;MCP 生态？\"}\n    \n    Q3 --&gt;|\"✅ Yes\"| MCPUI[\"🔧 MCP-UI 为主&lt;br/&gt;&lt;i&gt;工具即 UI，渐进增强&lt;/i&gt;\"]\n    Q3 --&gt;|\"❌ No\"| Custom[\"🎨 自定义方案&lt;br/&gt;&lt;i&gt;根据需求定制&lt;/i&gt;\"]\n    \n    subgraph Combinations[\"💡 组合方案\"]\n        AGUI --&gt; Combo1[\"AG-UI + A2UI&lt;br/&gt;&lt;i&gt;事件传输 + 声明式UI&lt;/i&gt;\"]\n        AGUI --&gt; Combo2[\"AG-UI + MCP-UI&lt;br/&gt;&lt;i&gt;事件传输 + 工具UI&lt;/i&gt;\"]\n        A2UI --&gt; Combo1\n    end\n    \n    style Start fill:#e1f5fe\n    style A2UI fill:#c8e6c9\n    style AGUI fill:#fff3e0\n    style MCPUI fill:#f3e5f5\n    style Custom fill:#ffecb3\n</div><hr />\n<h2 id=\"7-demo-项目实战解析\">7. Demo 项目实战解析</h2>\n<h3 id=\"71-项目结构\">7.1 项目结构</h3>\n<p><code>demo-agent-ui-protocols</code> 项目通过一个统一的\"餐厅搜索\"场景，同时演示三种协议：</p>\n<pre><code>demo-agent-ui-protocols/\n├── apps/web/                 # Next.js 前端\n│   └── src/app/\n│       ├── ag-ui-demo/       # AG-UI 演示页面\n│       ├── a2ui-demo/        # A2UI 演示页面\n│       └── mcp-ui-demo/      # MCP-UI 演示页面\n│\n├── agents/\n│   ├── ag-ui-agent/          # AG-UI Python Agent (port 8001)\n│   ├── a2ui-agent/           # A2UI Python Agent (port 8002)\n│   └── mcp-ui-agent/         # MCP-UI Python Agent (port 8003)\n│\n└── packages/shared/          # 共享类型定义\n</code></pre>\n<h3 id=\"72-同一场景的三种实现对比\">7.2 同一场景的三种实现对比</h3>\n<h4 id=\"721-用户输入\">7.2.1 用户输入</h4>\n<blockquote>\n<p>\"帮我找一家北京的川菜馆\"</p>\n</blockquote>\n<h4 id=\"722-ag-ui-实现\">7.2.2 AG-UI 实现</h4>\n<pre><code>[SSE Stream]\nevent: RUN_STARTED\ndata: {\"runId\":\"run_001\",\"threadId\":\"thread_001\"}\n\nevent: TEXT_MESSAGE_START\ndata: {\"messageId\":\"msg_001\",\"role\":\"assistant\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"messageId\":\"msg_001\",\"delta\":\"好的，我来帮您\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"messageId\":\"msg_001\",\"delta\":\"搜索北京的川菜馆...\"}\n\nevent: TOOL_CALL_START\ndata: {\"toolCallId\":\"call_001\",\"toolCallName\":\"search_restaurants\"}\n\nevent: TOOL_CALL_ARGS\ndata: {\"toolCallId\":\"call_001\",\"delta\":\"{\\\"cuisine\\\":\\\"川菜\\\",\\\"location\\\":\\\"北京\\\"}\"}\n\nevent: TOOL_CALL_RESULT\ndata: {\"toolCallId\":\"call_001\",\"result\":\"[{\\\"name\\\":\\\"川办餐厅\\\",...}]\"}\n\nevent: TEXT_MESSAGE_CONTENT\ndata: {\"messageId\":\"msg_001\",\"delta\":\"为您找到以下餐厅：\"}\n\nevent: RUN_FINISHED\ndata: {\"runId\":\"run_001\"}\n</code></pre>\n<p><strong>前端效果</strong>：实时展示打字效果 + 工具调用卡片</p>\n<h4 id=\"723-a2ui-实现\">7.2.3 A2UI 实现</h4>\n<pre><code>[JSONL Stream]\n{\"createSurface\":{\"surfaceId\":\"results\",\"catalogId\":\"standard\"}}\n\n{\"updateComponents\":{\"surfaceId\":\"results\",\"components\":[\n  {\"id\":\"root\",\"component\":{\"Column\":{\"children\":{\"explicitList\":[\"header\",\"list\"]}}}},\n  {\"id\":\"header\",\"component\":{\"Text\":{\"text\":{\"literalString\":\"推荐餐厅\"},\"usageHint\":\"h1\"}}},\n  {\"id\":\"list\",\"component\":{\"List\":{\"children\":{\"template\":{\"dataBinding\":\"/restaurants\",\"componentId\":\"card-template\"}}}}}\n]}}\n\n{\"updateDataModel\":{\"surfaceId\":\"results\",\"path\":\"/restaurants\",\"value\":[\n  {\"name\":\"川办餐厅\",\"rating\":4.8,\"price\":\"$$\",\"image\":\"...\"},\n  {\"name\":\"眉州东坡\",\"rating\":4.5,\"price\":\"$$$\",\"image\":\"...\"}\n]}}\n</code></pre>\n<p><strong>前端效果</strong>：原生组件渲染的餐厅卡片列表</p>\n<h4 id=\"724-mcp-ui-实现\">7.2.4 MCP-UI 实现</h4>\n<pre><code class=\"language-json\">// Request\n{ \"messages\": [{ \"role\": \"user\", \"content\": \"帮我找一家北京的川菜馆\" }] }\n\n// Response\n{\n  \"role\": \"assistant\",\n  \"content\": \"好的，这是搜索结果：\",\n  \"ui_resource\": {\n    \"type\": \"resource\",\n    \"resource\": {\n      \"uri\": \"ui://restaurant/list\",\n      \"mimeType\": \"text/html\",\n      \"text\": \"&lt;div class='restaurant-list'&gt;...\"\n    }\n  }\n}\n</code></pre>\n<p><strong>前端效果</strong>：iframe 内嵌的 HTML 卡片</p>\n<h3 id=\"73-运行-demo\">7.3 运行 Demo</h3>\n<pre><code class=\"language-bash\"># 1. 克隆项目\ngit clone https://github.com/MadLongTom/demo-agent-ui-protocols\ncd demo-agent-ui-protocols\n\n# 2. 配置环境变量\ncp .env.example .env\n# 编辑 .env 填入 OPENAI_API_KEY 等\n\n# 3. 安装依赖\n./install.sh\n\n# 4. 启动所有服务\n./run.sh\n\n# 5. 访问 Demo\n# AG-UI:  http://localhost:3000/ag-ui-demo\n# A2UI:   http://localhost:3000/a2ui-demo\n# MCP-UI: http://localhost:3000/mcp-ui-demo\n</code></pre>\n<p><img alt=\"AG-UI\" class=\"lazyload\" /><br />\n<img alt=\"A2UI\" class=\"lazyload\" /><br />\n<img alt=\"MCP-UI\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"8-总结与展望\">8. 总结与展望</h2>\n<h3 id=\"81-核心观点回顾\">8.1 核心观点回顾</h3>\n<ol>\n<li>\n<p><strong>AG-UI</strong> 是\"事件总线\"：它不关心 UI 长什么样，只负责把 Agent 的状态变化广播出去。适合需要<strong>深度集成</strong>和<strong>实时反馈</strong>的场景。</p>\n</li>\n<li>\n<p><strong>A2UI</strong> 是\"UI 契约\"：它定义了一套抽象的组件语言，让 Agent 能够\"描述 UI 意图\"而不是\"生成 UI 代码\"。适合<strong>跨平台</strong>和<strong>高安全性</strong>场景。</p>\n</li>\n<li>\n<p><strong>MCP-UI</strong> 是\"UI 插件\"：它让 MCP 工具能够直接返回可视化结果，无需修改宿主应用。适合<strong>快速扩展</strong>和<strong>插件生态</strong>场景。</p>\n</li>\n<li>\n<p><strong>组合使用</strong>是最佳实践：AG-UI 可以作为 A2UI 的传输层，MCP-UI 可以通过中间件集成到 AG-UI。</p>\n</li>\n</ol>\n<h3 id=\"82-未来展望\">8.2 未来展望</h3>\n<table>\n<thead>\n<tr>\n<th>趋势</th>\n<th>预期发展</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>协议融合</strong></td>\n<td>AG-UI 和 A2UI 可能会进一步整合，形成统一的 Agent-UI 标准</td>\n</tr>\n<tr>\n<td><strong>语音交互</strong></td>\n<td>多模态支持（语音输入、语音输出）将成为标配</td>\n</tr>\n<tr>\n<td><strong>边缘计算</strong></td>\n<td>轻量级协议支持设备端 Agent（手机、IoT）</td>\n</tr>\n<tr>\n<td><strong>安全增强</strong></td>\n<td>更完善的沙箱隔离、权限控制机制</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"83-参考资源\">8.3 参考资源</h3>\n<table>\n<thead>\n<tr>\n<th>协议</th>\n<th>官方仓库</th>\n<th>文档</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AG-UI</td>\n<td><a href=\"https://github.com/ag-ui-protocol/ag-ui\" rel=\"noopener nofollow\" target=\"_blank\">github.com/ag-ui-protocol/ag-ui</a></td>\n<td><a href=\"https://docs.ag-ui.com\" rel=\"noopener nofollow\" target=\"_blank\">docs.ag-ui.com</a></td>\n</tr>\n<tr>\n<td>A2UI</td>\n<td><a href=\"https://github.com/google/A2UI\" rel=\"noopener nofollow\" target=\"_blank\">github.com/google/A2UI</a></td>\n<td><a href=\"https://a2ui.dev\" rel=\"noopener nofollow\" target=\"_blank\">a2ui.org</a></td>\n</tr>\n<tr>\n<td>MCP-UI</td>\n<td><a href=\"https://github.com/idosal/mcp-ui\" rel=\"noopener nofollow\" target=\"_blank\">github.com/idosal/mcp-ui</a></td>\n<td>[mcpui.dev]</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<p><em>本文基于 <code>demo-agent-ui-protocols</code> 项目源码分析，建议读者下载运行体验。如有问题或建议，欢迎交流讨论。</em></p>\n<p><a href=\"https://github.com/MadLongTom/demo-agent-ui-protocols\" rel=\"noopener nofollow\">https://github.com/MadLongTom/demo-agent-ui-protocols</a></p>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/madtom/\" target=\"_blank\">MadLongTom</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/madtom/p/19452209\" target=\"_blank\">https://www.cnblogs.com/madtom/p/19452209</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 14:36</span>&nbsp;\n<a href=\"https://www.cnblogs.com/madtom\">MadLongTom</a>&nbsp;\n阅读(<span id=\"post_view_count\">18</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "FastAPI + TinyDB并发陷阱与实战：告别数据错乱的解决方案",
      "link": "https://www.cnblogs.com/ymtianyu/p/19450340",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19450340\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 08:54\">\n    <span>FastAPI + TinyDB并发陷阱与实战：告别数据错乱的解决方案</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文针对在FastAPI框架下使用TinyDB（JSON文件数据库）时，因多人同时读写导致的并发数据冲突问题，进行了深度剖析。文章通过生动的比喻解释了问题根源，并详细提供了文件锁、内存操作队列和应用层乐观锁三种由浅入深的实战解决方案，附有可直接整合的代码示例。同时，明确了各方案的适用场景与局限性，为开发者在轻量级与生产级应用之间提供平滑过渡的思路。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">你的FastAPI应用在多人同时修改数据时，会不会出现数据错乱或丢失？</strong></p>\n<p>试像一下，团队里一个用于管理内部资源的工具突然“抽风”了。几个同事同时提交申请，结果后台数据显示，有的申请记录神秘消失，有的资源数量对不上。一查日志，发现大家都在同一秒对同一个<code style=\"color: rgba(186, 55, 42, 1);\">db.json</code>文件进行了读写。这就是为了轻量而选用TinyDB（一个纯Python的、以JSON文件为存储的数据库）后，最有可能真切地感受到“并发”带来的痛。🎯</p>\n<p>这篇文章，我将和你一起拆解这个问题，并分享如何用几个轻量级方案，让这个基于FastAPI和TinyDB的应用稳定地支撑起了日均数千次的并发请求。它不是一套放之四海而皆准的架构，但绝对是你在原型开发、小型工具或特定轻量场景下，性价比最高的解决方案。</p>\n<h2>📖 核心摘要</h2>\n<p>本文针对在FastAPI框架下使用TinyDB（JSON文件数据库）时遇到的并发写入数据冲突、错乱问题，深入浅出地解释了问题根源，并提供了从“文件锁”到“内存队列”再到“乐观锁”的三种由浅入深的实战解决方案，帮助你根据实际场景选择，确保数据一致性。</p>\n<h2>🚶‍♀️ 主要内容脉络</h2>\n<div>\n<p>🔍 一、问题根源：为什么简单的JSON文件会“打架”？</p>\n<p>🛠️ 二、解决方案：从“锁”到“队列”的三层防御</p>\n<p>- 方案一：文件锁（fcntl / portalocker）—— 给文件上个“请勿打扰”牌</p>\n<p>- 方案二：内存操作队列（asyncio.Queue）—— 让请求排好队，一个一个来</p>\n<p>- 方案三：应用层乐观锁（版本号校验）—— “我改的时候，东西还是原来的样子吗？”</p>\n<p>💻 三、实战代码：将方案融入FastAPI依赖项与路由</p>\n<p>⚠️ 四、重要提醒与边界探讨：这不是银弹</p>\n</div>\n<h2>🔍 第一部分：问题与背景</h2>\n<p>想象一下，TinyDB的<code style=\"color: rgba(186, 55, 42, 1);\">db.json</code>文件就是一个共享的笔记本。FastAPI的每个工作进程（Worker）就像一个快速记录员。</p>\n<p>当用户A的请求到来时，记录员1打开笔记本，读到某个值（比如库存为5），准备将其改为4。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">就在这“读到”和“改写”的毫秒之间</strong>，用户B的请求也来了。记录员2也打开了同一个笔记本，他读到的库存<strong>仍然是5</strong>（因为记录员1还没写回去），然后他也计算，将库存改为3。</p>\n<p>结果就是，无论谁最后保存，另一个人的修改都会被完全覆盖。这就是典型的“并发写冲突”。在高并发的Web API场景下，这个问题会被急剧放大。</p>\n<h2>🛠️ 第二部分：核心原理与步骤</h2>\n<h3>🎯 方案一：文件锁（最直接的物理隔离）</h3>\n<p>原理：在读写文件前，先给这个文件加一把系统级的锁。其他进程尝试加锁时，会被阻塞或失败，直到锁被释放。这就像给笔记本的房间门上了锁，一次只进一个人。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">适用场景：</strong> 低并发（如内部工具）、读写不那么频繁的场景。</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 安装：pip install portalocker\nimport portalocker\n\ndef safe_update_db():\n    with open('db.json', 'r+') as f:\n        portalocker.lock(f, portalocker.LOCK_EX)  # 获取独占锁\n        # 在这里安全地读取和修改数据\n        data = json.load(f)\n        data['counter'] += 1\n        f.seek(0)\n        json.dump(data, f)\n        f.truncate()\n        # 退出with块时，锁会自动释放</code></pre>\n<h3>🎯 方案二：内存操作队列（单进程内的秩序维护者）</h3>\n<p>原理：利用Python的<code style=\"color: rgba(186, 55, 42, 1);\">asyncio.Queue</code>，将所有对TinyDB的写操作封装成任务，放入一个队列。由一个单独的“消费者”协程从队列中依次取出任务执行。这样，无论外部请求多么并发，对数据库的写操作都是<strong>串行化</strong>的。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">优点：</strong> 完全在内存中操作，速度极快，避免了文件锁可能带来的死锁或跨平台问题。非常适合FastAPI的异步模式。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">关键警告：</strong> 此方案仅在<u>单个服务进程</u>内有效。如果你使用多个工作进程（如<span style=\"color: rgba(186, 55, 42, 1);\"><code>Uvicorn with --workers 4</code></span>），每个进程有自己的内存和队列，冲突依然会发生。此时需搭配方案一或方案三。</p>\n<h3>🎯 方案三：应用层乐观锁（基于版本的冲突检测）</h3>\n<p>原理：不阻止“读”，只在“写”的时候检查冲突。为每条数据增加一个<code style=\"color: rgba(186, 55, 42, 1);\">version</code>字段。每次读取数据时，连带版本号一起读出。修改后写回时，检查当前文件中的版本号是否和自己读到的版本号一致。如果一致，则写入，并将版本号+1；如果不一致，则说明在此期间数据已被他人修改，本次操作失败，需要提示用户重试。</p>\n<p>这就像两个人编辑在线文档，系统会提示你“在你编辑期间，文档已被他人更新”。</p>\n<h2>💻 第三部分：实战演示（整合方案二与三）</h2>\n<p>下面是一个在FastAPI中整合<strong>内存队列</strong>与<strong>乐观锁</strong>的核心示例：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>from fastapi import FastAPI, Depends, HTTPException\nfrom contextlib import asynccontextmanager\nimport asyncio\nfrom tinydb import TinyDB, Query\nimport json\nfrom pydantic import BaseModel\n\napp = FastAPI()\nwrite_queue = asyncio.Queue()\ndb_path = 'db.json'\n\n# 数据模型\nclass ItemUpdate(BaseModel):\n    item_id: int\n    new_value: str\n    read_version: int  # 客户端传来的读取时的版本号\n\n# 启动时启动写任务消费者\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # 启动时\n    asyncio.create_task(db_write_consumer())\n    yield\n    # 关闭时...\n\napp = FastAPI(lifespan=lifespan)\n\nasync def db_write_consumer():\n    \"\"\"写操作消费者，常驻后台，串行处理写队列\"\"\"\n    while True:\n        task_data = await write_queue.get()\n        await _perform_safe_write(task_data)\n        write_queue.task_done()\n\nasync def _perform_safe_write(task_data: dict):\n    \"\"\"执行带乐观锁检查的写入\"\"\"\n    with TinyDB(db_path) as db:\n        Item = Query()\n        record = db.get(Item.id == task_data['item_id'])\n        if not record:\n            # 处理记录不存在的情况...\n            return\n        # 乐观锁检查！！！\n        if record['version'] != task_data['read_version']:\n            raise ValueError(f\"数据版本冲突。当前版本{record['version']}，提交版本{task_data['read_version']}\")\n        # 通过检查，执行更新\n        db.update({\n            'value': task_data['new_value'],\n            'version': record['version'] + 1  # 版本号递增\n        }, Item.id == task_data['item_id'])\n\n@app.put(\"/update_item/\")\nasync def update_item(update: ItemUpdate):\n    \"\"\"更新接口\"\"\"\n    try:\n        # 将写操作封装成任务，放入队列，等待消费者处理\n        await write_queue.put(update.dict())\n        # 这里可以返回一个任务ID，让客户端轮询结果，或者使用WebSocket推送\n        return {\"message\": \"更新请求已加入队列\"}\n    except asyncio.QueueFull:\n        raise HTTPException(status_code=429, detail=\"系统繁忙，请稍后重试\")\n\n@app.get(\"/get_item/{item_id}\")\nasync def get_item(item_id: int):\n    \"\"\"读取接口，返回数据和当前版本号\"\"\"\n    with TinyDB(db_path) as db:\n        Item = Query()\n        record = db.get(Item.id == item_id)\n        if record:\n            return {\"value\": record['value'], \"version\": record['version']}\n        raise HTTPException(status_code=404, detail=\"Item not found\")</code></pre>\n<h2>⚠️ 第四部分：注意事项与进阶思考</h2>\n<div>\n<p>🚨 <strong style=\"color: rgba(186, 55, 42, 1);\">重要提醒：</strong></p>\n<p>1. <strong>性能瓶颈：</strong> 所有方案的核心都是“串行化写”。这意味着你的数据库写吞吐量存在上限。对于超高并发写入场景，JSON文件本身就会成为瓶颈。</p>\n<p>2. <strong>多进程限制：</strong> 内存队列方案在单进程内完美，多进程需配合分布式锁（如Redis锁）或回归到数据库方案。</p>\n<p>3. <strong>故障恢复：</strong> 队列中的任务在服务重启时会丢失。对数据一致性要求极高的场景，需要引入持久化消息队列（如RabbitMQ）或直接使用真正的数据库。</p>\n</div>\n<p><strong>升华思考：</strong> 技术选型永远是权衡的艺术。TinyDB的优点是极致简单、无需外部服务。但当你的并发和一致性要求增长到一定阶段时，就是考虑升级到SQLite（支持更完善的事务和并发控制）、PostgreSQL等更强大数据库的时候了。本次实战的方案，是你从“玩具项目”平稳过渡到“生产系统”的一座关键桥梁。</p>\n<p style=\"text-align: center;\">---<strong>写在最后</strong>---<br />希望这份总结能帮你避开一些坑。如果觉得有用，不妨点个 赞👍 或 收藏⭐ 标记一下，方便随时回顾。也欢迎关注我，后续为你带来更多类似的实战解析。有任何疑问或想法，我们评论区见，一起交流开发中的各种心得与问题。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 08:54</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">42</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "PHP 异步与多线程 从 TrueAsync 展望未来",
      "link": "https://www.cnblogs.com/catchadmin/p/19450129",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/catchadmin/p/19450129\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 07:12\">\n    <span>PHP 异步与多线程 从 TrueAsync 展望未来</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"php-异步与多线程-从-trueasync-展望未来\">PHP 异步与多线程 从 TrueAsync 展望未来</h1>\n<p>RFC TrueAsync 1.7 讨论中有个问题：这个提议会如何与 PHP 核心未来的变化互动？要设计好语言的长期演进，至少得对 PHP 的发展方向有基本判断。本文试图回答这个问题。</p>\n<p>TrueAsync 项目不仅是 PHP 核心的 async 改动，还包括回答以下问题所需的其他研究：</p>\n<ul>\n<li>PHP 能在多大程度上向多线程方向发展？</li>\n<li>是否存在根本性限制？</li>\n<li>实现真正的多线程可能需要哪些核心改动？</li>\n<li>可以实现哪些语言抽象？</li>\n</ul>\n<p>本文不是 PHP 多线程的详尽综述，也不追求每个细节的技术精确性或大众可读性。但希望它对 PHP 开发者有参考价值，能为后续讨论提供方向。</p>\n<p><a href=\"https://catchadmin.com/post/2026-01/multithreading-in-php-looking-to-the-future\" rel=\"noopener nofollow\" target=\"_blank\">原文 PHP 异步与多线程 从 TrueAsync 展望未来</a></p>\n<h2 id=\"历史\">历史</h2>\n<p>几年前要给 PHP 应用加高容量遥测，我说做不到。看到 Swoole 架构后想测试一下。能不能做一个 API，生成和处理大量数据的同时不拖慢客户端？</p>\n<p>我们给 PHP 做了个优化的 OpenTelemetry，分批写数据，收集成大块再发到中间遥测服务器。数据压缩，JSON 结构用 MessagePack 序列化。</p>\n<p>假设是：用单线程协程逐步构建遥测数据，定时或达到阈值时发送。没有跨线程交互，代码应该快。真的吗？</p>\n<p>实验结果：遥测让 API 吞吐量减半。假设错了。为什么？概念上看起来没问题。Swoole 已经让 PHP 函数非阻塞，协程应该高效才对。哪里出错了？</p>\n<p>第二版改成：遥测只在一个请求期间收集，立即扔给作业进程去聚合、压缩、发送。这版性能好多了。但不应该啊？进程间数据走管道，一端序列化另一端反序列化。管道在内存里，但系统调用开销不小。</p>\n<p>后来找到原因：遥测数据量大，压缩相对 API 请求处理吃掉太多 CPU。Swoole 协程对 I/O 高效，但帮不了 CPU 密集型任务。</p>\n<p>这个案例说明单线程协程解决不了所有问题。也说明多线程能补充协程，给更多问题提供工具。</p>\n<h2 id=\"单线程--offload\">单线程 + offload</h2>\n<p>把 CPU 密集型工作卸载到单独进程不是什么新发明。这个模式在不同语言和框架中独立出现，叫 <code>Single-threaded + offload</code>。</p>\n<p>打个比方：一个人快速分拣信件（每小时几千封），重包裹由其他员工用卡车装走。分拣员要是自己去搬包裹，信件队列就堆到天花板了。</p>\n<p><code>Single-threaded + offload</code> 模型把任务分两类：</p>\n<ul>\n<li><strong>I/O-bound 任务</strong> — 读文件、网络调用、数据库访问。大部分时间在等外部世界。通过并发 async（协程、<code>await</code>），一个线程能容纳几千个这类操作。</li>\n<li><strong>CPU-bound 任务</strong> — 压缩、加密、解析、计算。CPU 满负荷跑，光靠并发不够，得上更多核心。</li>\n</ul>\n<p>模型在物理上分离这两类任务：主线程（<code>Event Loop</code>）只管 I/O，CPU 任务扔给单独的线程或进程（<code>Workers</code>）。</p>\n<p>Node.js 靠单线程 <code>Event Loop</code> 出名，很适合网络应用。但开发者要是在请求处理器里直接处理图像或压缩视频，服务器就变南瓜了。后来加了 <code>Worker Threads</code>，专门跑 CPU 密集型操作。</p>\n<p>Python 走了类似路线。<code>asyncio</code> 出来后，I/O-bound 代码有了好工具，但 GIL（全局解释器锁）挡着，单进程内没法真正 CPU 并行（写这篇文章时问题已解决）。阻塞操作有 <code>loop.run_in_executor()</code> 和 <code>asyncio.to_thread()</code>（Python 3.9+），把重活卸载到线程池或进程池。<code>Event Loop</code> 保持响应，计算并行跑。</p>\n<p>PHP/Swoole 也是这个架构：<code>Request Workers</code> 用协程处理 HTTP 请求，<code>Task Workers</code> 跑重计算。通过 UnixSocket 或管道通信，单进程能处理每秒约 10 万次操作。</p>\n<h3 id=\"模型的优势\">模型的优势</h3>\n<p><strong>1. 资源效率</strong></p>\n<p>单线程 <code>Event Loop</code> 能以极小开销服务几千个并发 I/O 操作。协程任务间切换比操作系统线程上下文切换便宜得多。CPU-bound 任务在多核上真正并行——每个 worker 占一个核心，互不干扰。</p>\n<p><strong>2. 开发简单</strong></p>\n<p><code>Event Loop</code> 里的代码不用互斥锁、信号量这些多线程编程的玩意儿。单线程模型一次只跑一个任务，竞态条件不可能出现。<code>Workers</code> 并行跑，但只要遵循 <code>Shared Nothing</code>，同步问题就不存在。</p>\n<p>多线程代码和单线程 async 代码的复杂度差距很大。现代语言和框架都奔着单线程 async 去，不走经典多线程。</p>\n<p><strong>3. 编译器/运行时更简单</strong></p>\n<p>单线程模型的 async 函数对编译器和运行时简单得多。好的多线程语言需要自己的代码生成管道。PHP 有个硬约束：部分代码用 C 写的，没法对线程、内存管理、参数传递做高效的字节码级优化。Go 的设计复杂出名：专有栈、复杂 GC，都是高效 goroutines 和 channels 必需的。PHP 的 GC 后面会讲，先别放松。</p>\n<p><strong>4. 手动负载分配</strong></p>\n<p>开发者可以主动在请求处理代码和 worker 池之间分配负载。手动控制能从硬件榨出理论最大值。但这也是缺点。</p>\n<h3 id=\"模型的劣势\">模型的劣势</h3>\n<p><strong>1. 手动负载分配</strong></p>\n<p>手动分配是双刃剑。开发者可以针对特定任务优化，也可能误判什么该放 I/O 代码、什么该放 workers。I/O 代码塞了重活会过载，响应变慢、延迟上升。</p>\n<p>这个模型要求 PHP 开发者有足够技能，或者依赖框架作者提供的现成方案。</p>\n<p><strong>2. 不适合所有任务</strong></p>\n<p><code>Single-threaded + offload</code> 很适合 Web 服务器、API、微服务——主要负载是数据库、文件系统、网络调用这些 I/O。但每一步都要密集计算的场景——科学计算、渲染、机器学习——这个模型效果就差了。那些场景更适合完全多线程。</p>\n<p>你可能说：能接受！准备好了！但 PHP 本身准备好多线程了吗？</p>\n<h2 id=\"php-准备好多线程了吗\">PHP 准备好多线程了吗？</h2>\n<p>开发 TrueAsync 时，最难的讨论之一是\"为什么 PHP 没有 async\"。解释 PHP 为什么还没准备好多线程可能同样难。不过先聊聊多线程本身。我们为什么需要它？或者换个问法：我们为什么不需要它？</p>\n<p><strong>多线程不是并行执行代码的必要条件。</strong></p>\n<p>\"并行必须多线程\"这个想法早就刻在程序员脑子里了，就像\"黑洞会吸东西\"刻在流行文化里一样。</p>\n<p>并行执行完全可以用进程，进程彼此隔离（80386 架构就有了）。进程通过 IPC 通信，完成状态通过信号（操作系统事件）跟踪。那为什么还要线程？</p>\n<p>要老实回答这个问题，得穿越回去请当年做决定的人解释：Edsger Dijkstra、Fernando Corbató、Barbara Liskov、Richard Rashid。办个脱口秀挺好。但就算他们都来了，可能也说不出直接答案。</p>\n<p>下面这个说法是错的：</p>\n<blockquote>\n<p>线程是为了让并行代码不用额外工具就能共享内存。</p>\n</blockquote>\n<p>进程也能共享内存，但得把段映射到地址空间（额外工具）。线程默认共享所有内存。线程 A 能访问的变量 <code>x</code>，线程 B 在同一地址也能访问，不用任何技巧……但等等！多个线程没法在不加额外工具的情况下安全使用共享变量。</p>\n<p>更准确的说法是：</p>\n<blockquote>\n<p>线程是为了在任务间传递内存时没有额外开销。</p>\n</blockquote>\n<p>如果线程用内存传消息，保证同一时间只有一个线程能访问某块内存区域，那在内存和 CPU 两方面都是最高效的。线程刻意避免共享内存。这个模型叫 <code>Shared Nothing</code>。</p>\n<p><strong>线程是为了在任务间高效传数据。</strong> 跟\"黑洞不吸东西\"一样是事实。</p>\n<h2 id=\"php-内存模型\">PHP 内存模型</h2>\n<p>PHP 怎么处理内存？简化的抽象模型：</p>\n<ul>\n<li>代码</li>\n<li>数据</li>\n<li>PHP VM 状态</li>\n</ul>\n<p>线程间共享 PHP 代码已经能做到（PHP JIT 解决了）。其他组件紧密耦合，拆不开。比如 PHP 用一个全局 <code>object_store</code> 存所有创建对象的引用。PHP 内存管理器是给单个 PHP VM 的对象设计的，不面向多线程。PHP 垃圾收集器处理不了不同线程的数据，甚至要完全停掉 VM，因为它直接改对象的 <code>refcount</code>。</p>\n<p>所以 <strong>PHP 是严格的单线程模型，带 stop-the-world GC</strong>。</p>\n<h2 id=\"在线程间移动-php-vm\">在线程间移动 PHP VM</h2>\n<p>PHP 用线程局部存储（<code>Thread-Local Storage</code>，TLS）保存每个线程的 VM 状态。这对 ZTS（Zend Thread Safety）模式下线程间隔离很关键。</p>\n<p>现代 PHP 构建用 C11 标准的 <code>__thread</code>（MSVC 里是 <code>__declspec(thread)</code>）获取 VM 状态指针。速度很快，x86_64 上就是从 FS 或 GS 寄存器的基址读一个偏移量。</p>\n<pre><code class=\"language-asm\">; offset - 编译时计算的常量偏移量\n; fs - 内存段的基地址\nmov rax, QWORD PTR fs:offset\n</code></pre>\n<p>FS/GS 对每个线程唯一（操作系统保证），读出来的总是正确的 VM 状态指针。</p>\n<p>能在线程间移动 VM 状态，就能实现类似 Go 协程或 actors 的功能。现代 VM 通过自定义代码生成传上下文，用 CPU 寄存器传 VM 状态。PHP 做不到这个，因为底层用 C 函数，C 没法给每个函数传隐式上下文参数。在线程间移动 PHP VM 状态会损失一定性能。</p>\n<p>但如果只移动执行代码需要的那一小部分 VM 状态呢？比如 PHP Fiber 切换时会复制指向全局结构（<code>zend_executor_globals</code>）的部分指针。</p>\n<p>如果把 PHP VM 概念上分成两部分：</p>\n<ul>\n<li><strong>PHP VM shared</strong>。类、函数、常量、ini 指令、可执行代码。</li>\n<li><strong>PHP VM movable</strong>。需要移动的 VM 部分。</li>\n</ul>\n<p><img alt=\"PHP Memory Model\" class=\"lazyload\" /></p>\n<p>有些结构可以标记为共享，有些标记为可移动；<code>Executor Globals</code> 甚至可以拆成共享和可移动两部分，实现线程间高效的 VM 状态移动。扩展全局结构不会因为多一层间接而损失性能，因为它们本来就在用间接访问。</p>\n<p>问题出在代码编译相关的结构上。PHP 通过 <code>include</code>/<code>require</code>、<code>eval</code> 和自动加载是动态的，这让 VM 状态很难有效拆成共享和可移动两部分。如果能解决这个问题，PHP 就能以很小的开销在线程间移动部分 VM 状态。</p>\n<h2 id=\"在线程间传递对象\">在线程间传递对象</h2>\n<p>PHP 要改什么才能安全地在线程间传递对象？怎么做？</p>\n<p>从语言层面看。假设 <code>$obj</code> 里有个 <code>SomeObject</code> 实例，要发到另一个线程。能做到吗？</p>\n<pre><code class=\"language-php\">$obj = new SomeObject();\n\n$thread = new Thread(function () use ($obj) {\n    echo $obj-&gt;someMethod();\n});\n\n$thread-&gt;join();\n</code></pre>\n<p><code>SomeObject</code> 只属于 <code>$obj</code>，可以安全地把地址从一个线程移到另一个。主线程的 <code>$obj</code> 会被销毁：</p>\n<pre><code class=\"language-php\">$obj = new SomeObject();\n$thread = new Thread(function () use ($obj) {\n    echo $obj-&gt;someMethod();\n});\n\n// $obj 在这里未定义\n$thread-&gt;join();\n</code></pre>\n<p>上面的代码跟 C++ 和 Rust 的移动语义完全一样。这种线程间传内存的方式：</p>\n<ul>\n<li><strong>安全</strong>。只有一个线程拥有对象。</li>\n<li><strong>没有复制或序列化开销</strong>。</li>\n</ul>\n<p>为了让行为可预测、静态分析器能读懂，应该加特殊的移动语法：</p>\n<pre><code class=\"language-php\">$obj = new SomeObject();\n\n// consume $obj 表示移动对象\n$thread = new Thread(function () use (consume $obj) {\n    echo $obj-&gt;someMethod();\n});\n\n// $obj 在这里未定义。在 PHP9 中应该在这里报告错误。\necho $obj;\n</code></pre>\n<p>看着不错？</p>\n<p>但移动 <code>refcount = 1</code> 的对象有问题。</p>\n<p>看个分类树的例子：</p>\n<pre><code class=\"language-php\">$electronics = new CategoryNode('Electronics');\n$categoriesTree = new Tree();\n$categoriesTree-&gt;addToPath('/products/electronics', $electronics);\n$categoriesTree-&gt;addToPath('/popular/electronics', $electronics);  \n// 同一个分类！\n</code></pre>\n<p><code>$electronics</code> 在树里出现两次（<code>refcount = 2</code>）。把 <code>$categoriesTree</code> 移到另一个线程会怎样？</p>\n<p>要安全移动，必须保证图里所有对象都没有外部引用：</p>\n<pre><code class=\"language-php\">$node = new CategoryNode('Electronics');\n$categoriesTree = new Tree();\n$categoriesTree-&gt;addToPath('/products/electronics', $node);\n\n$favourites = [$node];  // 外部引用！\n$thread = new Thread(function () use ($categoriesTree) {\n    // $categoriesTree 被移动\n});\n\n// $favourites[0] 现在指向另一个线程中的内存\n// 悬空指针！\n</code></pre>\n<p>安全移动需要：</p>\n<ul>\n<li><strong>完整图遍历</strong>：检查所有嵌套对象。</li>\n<li><strong>Refcount 检查</strong>：图里每个对象都要查。</li>\n<li><strong>身份保留</strong>：图内的重复项得保持重复。</li>\n</ul>\n<p>可以为此设计算法，叫深拷贝。简单实现大概这样：</p>\n<pre><code class=\"language-php\">// 深拷贝伪代码\n// 线程 A 中的源图\n$node = new Node('A');        // addr: 0x1000\n$tree-&gt;left = $node;          // addr: 0x1000\n$tree-&gt;right = $node;         // addr: 0x1000 (相同引用)\n\n// 深拷贝到线程 B（带 MM 的伪代码）\n$copied_map = [];  // 哈希表: addr_source -&gt; addr_target\nfunction deepCopyToThread(object $obj, Thread $target_thread_mm) \n{\n    $source_addr = get_object_address($obj);\n    if (isset($copied_map[$source_addr])) {\n        return $copied_map[$source_addr];  // 已经复制！\n    }\n    // 在另一个线程的 MM 中分配内存\n    $new_addr = $target_thread_mm-&gt;allocate(sizeof($obj));\n    $copied_map[$source_addr] = $new_addr;\n    // 复制对象数据\n    memcpy($new_addr, $source_addr, sizeof($obj));\n    // 遍历属性\n    foreach ($obj-&gt;properties as $prop) {\n        if (is_object($prop)) {\n            $new_prop_addr = deepCopyToThread($prop, $target_thread_mm);\n            // 更新新对象中的指针\n            update_property($new_addr, $prop, $new_prop_addr);\n        }\n    }\n    return $new_addr;\n}\n// 线程 B 中的结果：\n// $newTree-&gt;left (addr: 0x2500) === $newTree-&gt;right (addr: 0x2500)\n// 身份保留！\n</code></pre>\n<p>深拷贝时间复杂度 O(N + E)，N 是对象数，E 是引用数。空间复杂度 O(N)——哈希表 + 新对象 + 递归栈。</p>\n<p>比序列化快，因为不用转换传输格式，但收益取决于数据形状和图大小。也可以混合：<code>refcount = 1</code> 的移动，其他的深拷贝。</p>\n<p>结果：</p>\n<ul>\n<li>PHP 开发者不用管对象怎么传到另一个线程。</li>\n<li>最好情况：内存直接移动（<code>refcount = 1</code>）。</li>\n<li>最坏情况：深拷贝，保留身份（<code>refcount &gt; 1</code>）。</li>\n</ul>\n<p>看着还行：</p>\n<ul>\n<li>PHP 语法改动最小</li>\n<li>可以逐步改</li>\n<li>多线程能用了</li>\n</ul>\n<p>但核心层面没那么美好。要让对象移动成真，PHP 需要跨线程的内存管理机制。现在做不到。</p>\n<h2 id=\"多线程-php-内存管理器\">多线程 PHP 内存管理器</h2>\n<p>PHP 内存管理器类似 jemalloc 或 tcmalloc 这些现代分配器。区别是：它没有从另一个线程释放内存的正确算法。</p>\n<p>场景：</p>\n<ul>\n<li>线程 A 创建对象。</li>\n<li>移动（原样）给线程 B。</li>\n<li>B 不再需要，要释放。</li>\n</ul>\n<p>每个 PHP 线程有自己的内存管理器（<code>Memory Manager</code>，MM）。B 想释放 A 分配的内存就出问题了。B 的 MM 不认识 A 的内存，释放会出错。B 直接访问 A 的 MM 结构也不行，需要同步。现代高性能多线程分配器用延迟释放（<code>deferred free</code>）解决这个问题。</p>\n<p>延迟释放的思路：</p>\n<ul>\n<li>B 的 MM 看到一个不认识的指针。</li>\n<li>找到哪个 MM 拥有它，给那个 MM 的队列发消息说可以释放了。</li>\n<li>A 的 MM 处理队列，在自己的上下文里释放。</li>\n</ul>\n<p><img alt=\"Cross thread deferred free\" class=\"lazyload\" /></p>\n<p>用现代无锁结构，这个算法吞吐量高，不同线程能并行释放内存，几乎不用锁。</p>\n<p>多线程 PHP 内存管理器为以前不可能的改动打开了门。</p>\n<h2 id=\"共享对象\">共享对象</h2>\n<p>能用最少操作把内存从一个线程传到另一个很好，但如果能创建一开始就设计成跨线程共享的对象呢？</p>\n<p>很多服务可以构建成不可变对象，应该能在进程间共享，省内存、加快 worker 启动。</p>\n<p>但 <code>refcount</code> 挡着，它让所有 PHP 对象实际上都是可变的。能绕过吗？</p>\n<h3 id=\"代理对象\">代理对象</h3>\n<p>第一种方法是代理对象，引用存在所有线程可访问的共享内存池里的真实对象。代理只存标识符或指针，加上访问数据的方法。缺点：</p>\n<ul>\n<li>访问数据/属性变慢</li>\n<li>Reflection API 和类型检查更复杂</li>\n</ul>\n<p>PHP 已经有强大的代理机制。代理共享对象在某些场景不错，比如计数器表或 Swoole/Table 这样的数据表。</p>\n<h3 id=\"带有-gc_share-标志的共享对象\">带有 GC_SHARE 标志的共享对象</h3>\n<p>PHP 有个内置机制通过 <code>GC_IMMUTABLE</code> 标志实现不可变元素，用于：</p>\n<ul>\n<li>内部字符串（<code>IS_STR_INTERNED</code>）——整个 PHP 进程存在的字符串常量</li>\n<li>不可变数组（<code>IS_ARRAY_IMMUTABLE</code>）——比如 <code>zend_empty_array</code></li>\n<li>opcache 里的常量——带常量数据的编译代码</li>\n</ul>\n<p><code>GC_IMMUTABLE</code> 让引擎跳过这些结构的 <code>refcount</code> 修改：</p>\n<pre><code class=\"language-c\">// Zend/zend_types.h\n// 为 zend_refcounted_h 增加 refcount 的函数\nstatic zend_always_inline void zend_gc_try_addref(zend_refcounted_h *p) {\n    if (!(p-&gt;u.type_info &amp; GC_IMMUTABLE)) {\n        ZEND_RC_MOD_CHECK(p);\n        ++p-&gt;refcount;\n    }\n}\n</code></pre>\n<p>类似机制可以支持 <code>SharedObjects</code>，比如加个 <code>GC_SHARE</code> 标志。</p>\n<p>性能分析显示，检查 <code>GC_SHARE</code> 给单独的 <code>refcount++</code> 加了 +34% 开销（微基准测试）。实际应用里 <code>refcount</code> 操作只占总工作一小部分，影响几乎看不出来：</p>\n<ul>\n<li>真实操作（数组/对象）：+3–9%</li>\n<li>实际应用：+0.05–0.5%</li>\n</ul>\n<p>这解决了一半问题；另一半是给这些对象设计 GC。用原子 <code>refcount</code> 不理想，多线程访问同一对象时会变慢。延迟释放算法可能更合适。</p>\n<h2 id=\"基于区域的内存\">基于区域的内存</h2>\n<p>基于区域的内存（<code>Region-based memory</code>）在面向 Web 的语言里越来越流行。</p>\n<p>思路：给特定任务或线程在单独区域分配内存，不需要时整体释放。避免了逐个对象管理的复杂性，GC 也简单了。</p>\n<p>比如 PHP MM 可以保证对象在绑定到特定 PHP 对象的区域里创建。区域生命周期等于对象生命周期。</p>\n<p>对象销毁时整个区域直接释放，不用遍历子对象。这种对象要\"移动\"到另一个线程，可以避免深拷贝。</p>\n<p>PHP VM 实现基于区域的内存有问题：比如全局对象列表、操作码缓存。但高效实现的机会不是零，值得继续研究。</p>\n<p>有效的基于区域的内存算法能为 actors 打开门——有隔离内存的特殊对象。</p>\n<p><strong>Actors 是多线程编程里最方便、最强大、最安全的工具。</strong></p>\n<h2 id=\"协程和线程协作\">协程和线程协作</h2>\n<p>从协程角度看，<code>Thread</code> 是个 <code>Awaitable</code> 对象。协程可以等 <code>Thread</code> 结果而不阻塞其他协程。一个线程能托管很多等重任务的协程。服务它们的线程对新请求保持快速响应，因为等 <code>Thread</code> 不阻塞 <code>Event Loop</code>。</p>\n<pre><code class=\"language-php\">use Async\\await;\nuse Async\\Thread;\n\n$thread = new Thread(function() {\n    // 硬件密集型任务在这里\n    return 42;\n});\n\n$result = await($thread); \n// 协程在这里暂停，直到 Thread 完成\n</code></pre>\n<p>这种方式能实现有 CPU 密集型任务和简单业务逻辑的聊天场景。<br />\n<img alt=\"协程和线程协作\" class=\"lazyload\" /></p>\n<p>图里是个示例架构。应用有两个线程池：带并发多任务的请求处理线程，和跑 CPU 密集型任务的 worker 线程。协程处理请求，worker 跑重任务时可以完全暂停，跑完继续。</p>\n<pre><code class=\"language-php\">use Async\\await;\nuse Async\\ThreadPool;\n\nfinal readonly class ImageDto\n{\n    public function __construct(\n    public int $width,\n    public int $height,\n    public string $text,\n) {}\n}\n\n$pool = new ThreadPool(2);\n$dto = new ImageDto(\n    width: 200,\n    height: 200,\n    text: 'Hello TrueAsync!'\n);\n\n$image = $pool-&gt;enqueue(function (ImageDto $dto) {\n    $img = imagecreatetruecolor($dto-&gt;width, $dto-&gt;height);\n\n    $white = imagecolorallocate($img, 255, 255, 255);\n    $black = imagecolorallocate($img, 0, 0, 0);\n\n    imagefill($img, 0, 0, $white);\n    imagestring($img, 5, 20, 90, $dto-&gt;text, $black);\n\n    ob_start();\n    imagepng($img);\n    imagedestroy($img);\n    return ob_get_clean();\n}, $dto);\n\n$response-&gt;setHeader('Content-Type', 'image/png');\n$response-&gt;write($image);\n$response-&gt;end();\n</code></pre>\n<p>协程代码是顺序的，读起来像普通代码，<code>ThreadPool::enqueue</code> 像在同一线程调用回调一样。DTO 跨线程传，结果字符串不会在内存里复制两次。</p>\n<h2 id=\"垃圾收集器和有状态模式\">垃圾收集器和有状态模式</h2>\n<p>现代化 PHP 内存管理器不是改进多线程环境唯一要做的事。没有高效 GC，多线程 PHP 会有性能问题和循环引用导致的内存泄漏。</p>\n<p>PHP GC 用两种算法：引用计数做主要内存管理，并发循环收集（Concurrent Cycle Collection，Bacon-Rajan，2001）处理循环。引用计数每次赋值都递增/递减，没同步的话多线程不安全。每次赋值用原子操作开销太大；不同步就有竞态和泄漏。循环收集器虽然叫\"并发\"，但只在单线程内工作，用颜色标记（PURPLE → GREY → WHITE/BLACK）找循环，也不是线程安全的。</p>\n<p>好消息是：当前 GC 实现在多线程环境能工作，因为它跟内存管理器分开，不依赖内存在哪分配。</p>\n<p>但 PHP 要进入有状态应用的多线程时代，GC 得适应：</p>\n<ul>\n<li>在单独线程并行跑，不影响业务代码。</li>\n<li>尽快释放资源。</li>\n<li>提供泄漏检测、日志、遥测的额外工具（长时间运行的应用特别需要）。</li>\n</ul>\n<p>循环收集器可以改成在多线程环境工作，在单独线程处理引用，提高整体响应性。这可能够用了！</p>\n<h2 id=\"actors\">Actors</h2>\n<p><code>ThreadPool</code> 和线程间传对象有用，但需要开发者的注意力、技能和精力。有个更好的多线程编程抽象，藏住线程/内存复杂性，完美契合业务逻辑：actors。</p>\n<p><strong>Actors 是并发并行编程模型，计算的基本单元是 actor。</strong></p>\n<p>每个 actor：</p>\n<ul>\n<li>有自己的隔离状态</li>\n<li>顺序处理消息</li>\n<li>只通过消息跟其他 actors 交互</li>\n<li>可能在单独线程跑</li>\n</ul>\n<p>可以把 actor 想成对象，这让多线程 PHP 能用熟悉的 OOP 模式。</p>\n<p>想象一个有很多房间的聊天服务器。每个房间是单独的对象。</p>\n<pre><code class=\"language-php\">use Async\\Actor;\n\nclass ChatRoom extends Actor\n{\n    private array $messages = [];\n    private string $name;\n\n    public function __construct(string $name)\n    {\n        $this-&gt;name = $name;\n    }\n\n    public function postMessage(string $user, string $text): void\n    {\n        $this-&gt;messages[] = [\n            'user' =&gt; $user,\n            'text' =&gt; $text,\n            'time' =&gt; time()\n        ];\n    }\n\n    public function getMessages(): array\n    {\n        return $this-&gt;messages;\n    }\n}\n\nspawn(function() {\n   $room = new ChatRoom('general');\n   $room-&gt;postMessage('Alice', 'Hello!');  // 在另一个线程中运行，暂停协程！\n   $messages = $room-&gt;getMessages();       // 在另一个线程中运行，暂停协程！\n   echo json_encode($messages);\n});\n</code></pre>\n<p><code>ChatRoom</code> 对象特殊。它们的数据和 PHP VM 状态本地化了，方便在线程间移动。每个方法在自己的线程跑，但任何时刻只有一个线程能执行给定 actor 的方法。</p>\n<p>语义上，基类 <code>Actor</code> 定义了 PHP VM 和内存管理器的工作方式，让 <code>ChatRoom</code> 对象能安全地在单独线程跑。类类型不只\"存\"方法和属性信息，还存 MM 和 GC 该怎么操作这类对象。Rust、C++ 也有类似做法。好处：不改语法，符合 OOP 哲学。</p>\n<p>示例看起来像协程里跑的普通顺序代码。但 <code>postMessage</code> 和 <code>getMessages</code> 在另一个线程跑，不会直接执行。协程给 actor 队列发消息，进入等待，actor 在另一个线程跑完方法返回结果后才恢复。</p>\n<p>这跟熟悉的 PHP OOP 不冲突：<code>Actor</code> 重写 <code>__call</code>：</p>\n<pre><code class=\"language-php\">class Actor \n{\n    private $threadPool;\n\n    public function __call(string $name, array $arguments): mixed\n    {\n        if(current_thread_id() === $this-&gt;threadPool-&gt;getThreadIdForActor($this)) {\n            // 如果我们在同一个线程中，直接运行方法\n            return $this-&gt;$name(...$arguments);\n        }\n    \n        // 否则将调用排队给 actor\n        return $this-&gt;threadPool-&gt;enqueueActorMethod($this, $name, $arguments);\n    }\n}\n</code></pre>\n<p><code>enqueueActorMethod</code> 把 <code>postMessage</code> 加到 actor 队列，订阅结果事件，调用 <code>Async\\suspend()</code> 暂停协程。</p>\n<p>Actor 代码顺序执行，解决竞态条件，多线程开发对开发者透明。</p>\n<p>并行性靠每个 <code>ChatRoom</code> actor 能在单独线程跑来实现：</p>\n<pre><code class=\"language-php\">spawn(function() {\n   $room = new ChatRoom('room1');\n   $room-&gt;postMessage('Alice', 'Hello!');\n   $messages = $room-&gt;getMessages();\n   echo json_encode($messages);\n});\n\nspawn(function() {\n   $room = new ChatRoom('room2');\n   $room-&gt;postMessage('Bob', 'Hi there!');\n   $messages = $room-&gt;getMessages();\n   echo json_encode($messages);\n});\n</code></pre>\n<p><code>ChatRoom</code> 实例能在不同线程并行跑，因为每个 actor 有自己的执行线程、唯一的 PHP VM 状态和内存。</p>\n<p>创建 100 个聊天室：</p>\n<pre><code class=\"language-php\">use Async\\Actor;\n\n$rooms = [\n    'general' =&gt; new ChatRoom('general'),\n    'random'  =&gt; new ChatRoom('random'),\n    'tech'    =&gt; new ChatRoom('tech'),\n    // ... 97 个更多房间\n];\n\n// 处理请求的协程\nHttpServer::onRequest(function(Request $request, Response $response) use ($rooms) {\n   // HTTP 请求处理\n   $roomName = $request-&gt;getQueryParam('room');\n   $room = $rooms[$roomName] ?? null;\n   \n   if (!$room) {\n      $response-&gt;setStatus(404);\n      $response-&gt;write('Room not found');\n      $response-&gt;end();\n      return;\n   }\n   \n   // 调用看起来是同步的，但在另一个线程中运行！\n   $room-&gt;postMessage($request-&gt;getQueryParam('user'), $request-&gt;getQueryParam('text'));\n   $messages = $room-&gt;getMessages();\n   \n   $response-&gt;setHeader('Content-Type',  'application/json');  \n   $response-&gt;write(json_encode($messages));\n   $response-&gt;end();\n});\n</code></pre>\n<p>每个聊天室顺序处理消息，跟其他房间并行。</p>\n<p>Actors 不需要互斥锁、锁、复杂同步或手动线程池交互。它们是现成的高级并行化方案。</p>\n<p>一个聊天室要给另一个发消息也行，因为 actors 是 <code>SharedObject</code>，能跨线程交互：</p>\n<pre><code class=\"language-php\">class Rooms extends Actor\n{\n    private array $rooms = [];\n    \n    public function __construct(string ...$roomNames)\n    {\n       foreach ($roomNames as $name) {\n           $this-&gt;rooms[$name] = new ChatRoom($name);\n       }\n    }\n    \n    public function broadcastMessage(string $fromRoom, string $user, string $text): void\n    {\n        foreach ($this-&gt;rooms as $name =&gt; $room) {\n            if ($name !== $fromRoom) {\n                // 非阻塞调用\n                $room-&gt;postMessageAsync($user, $text);\n            }\n        }\n    }\n}\n\nspawn(function() {\n   $rooms = new Rooms('general', 'room1', 'room2', 'room3');\n   $rooms-&gt;broadcastMessage('general', 'Alice', 'Hello!');\n});\n</code></pre>\n<h3 id=\"actor-内部\">Actor 内部</h3>\n<p>PHP VM 保证 actor 内所有对象：</p>\n<ul>\n<li>要么只属于该 actor，在其唯一区域分配</li>\n<li>要么从其他区域或线程移动过来</li>\n<li>要么是另一个 <code>SharedObject</code> 或另一个 actor</li>\n</ul>\n<p>Actor 要么拥有自己的区域，要么只用显式共享的不可变对象；否则竞态还是会有。</p>\n<p>内存管理器保证 actor 方法内所有内存操作自动绑定到与 actor 关联的区域。</p>\n<p>方法通过 <code>Scheduler</code> 服务的 MPMC 消息队列执行。<code>Scheduler</code> 在 actors 间分配 CPU 时间，提供并发和并行执行。</p>\n<p><img alt=\"Actor 内部\" class=\"lazyload\" /></p>\n<h2 id=\"结论\">结论</h2>\n<p>这些听着都不错，但什么时候能真正用上？</p>\n<p><code>Single-threaded + offload</code> 模型可能很快出现，很多组件已经就绪。TrueAsync 单线程协程已到 beta 版。实验性的多线程内存管理器和创建线程的 API 已经实现。</p>\n<p>Actors 需要更多开发时间，因为涉及 PHP 核心很多部分，但仍是 PHP 9 的现实目标，给市场提供一种安全的多线程编程语言。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 07:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/catchadmin\">JaguarJack</a>&nbsp;\n阅读(<span id=\"post_view_count\">15</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}