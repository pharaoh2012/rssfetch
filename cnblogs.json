{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "凸优化数学基础笔记（三）：方向导数、梯度向量",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19621942",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19621942\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 20:18\">\n    <span>凸优化数学基础笔记（三）：方向导数、梯度向量</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        ​ 所谓方向导数的概念是作为偏导数的概念的前瞻数学概念而引入的，是矩阵微分的重要概念，其主要研究多元函数在变量空间沿任意方向的变化率。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1方向导数及曲线弧线导数\">1.方向导数及曲线弧线导数</h2>\n<p>​       所谓方向导数的概念是作为偏导数的概念的前瞻数学概念而引入的，是矩阵微分的重要概念，其主要研究多元函数在变量空间沿任意方向的变化率。</p>\n<p>​       <strong>Definition 1</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow\\mathbf{R}\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处可微，<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 是固定不变的非零向量，<span class=\"math inline\">\\(\\mathbf{e}\\)</span> 是方向<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 上的单位向量，则称极限</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X_0})}}{\\part{\\mathbf{P}}}=\\lim_{t\\rightarrow{0}^{+}}\\frac{f(\\mathbf{X}_0+t\\mathbf{e})-f(\\mathbf{X}_0)}{t} \\tag{1}\n\\]</div><p></p><p>为函数<span class=\"math inline\">\\(f(\\mathbf{X}_0)\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向的方向导数，式中<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X_0})}}{\\part{\\mathbf{P}}}\\)</span> 是其简单记。</p>\n<p>​       <strong>Definition 2</strong>  设<span class=\"math inline\">\\(f:\\mathbf{R}^{n}\\rightarrow\\mathbf{R}\\)</span> 是连续函数，<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>，<span class=\"math inline\">\\(\\mathbf{P}\\in\\mathbf{R}^n\\)</span>，且<span class=\"math inline\">\\(\\mathbf{P}\\neq{\\mathbf{0}}\\)</span>，若有存在<span class=\"math inline\">\\(\\delta&gt;0\\)</span>。当<span class=\"math inline\">\\(t\\in(0,\\delta)\\)</span> 时都有<span class=\"math inline\">\\(f(\\mathbf{X_0}+t\\mathbf{P})&lt;f(\\mathbf{X}_0)\\)</span> ，则称<span class=\"math inline\">\\(\\mathbf{P}\\)</span>为<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的下降方向。若<span class=\"math inline\">\\(f(\\mathbf{X}_0+t\\mathbf{P})&gt;f(\\mathbf{X}_0)\\)</span> ，则称<span class=\"math inline\">\\(\\mathbf{P}\\)</span>为<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处的上升方向。</p>\n<p>​       由此以上的两个定义可立刻得到如下的结论：</p>\n<ol>\n<li>若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}&lt;0\\)</span>，则多元函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 从<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 附近沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向是下降的；</li>\n<li>若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P_0}}}&gt;0\\)</span>，则多元函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 从<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 附近沿<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向是上升的；</li>\n</ol>\n<p>​      事实上，若<span class=\"math inline\">\\(\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}&lt;0\\)</span>，则当<span class=\"math inline\">\\(\\exist t&gt;0\\)</span> ,必有如下的充分小，根据上式Definition必有如下表达：</p>\n<p></p><div class=\"math display\">\\[\\frac{f(\\mathbf{X}_0+t\\mathbf{e})-f(\\mathbf{X}_0)}{t}&lt;0 \\tag{2}\n\\]</div><p></p><p>即可得：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X})&lt;f(\\mathbf{X}_0)  \\tag{3}\n\\]</div><p></p><p>其中：<span class=\"math inline\">\\(\\mathbf{X}=\\mathbf{X}_0+t\\mathbf{e}\\)</span> 是从 <span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 出发在<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向上的点，说明<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 方向上是下降的点；同理可以说明，<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> ，则<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span>是上升的。</p>\n<p>​       在直角坐标系中，方向导数有如下定理给出的计算公式，以空间三维函数为例。</p>\n<p>​       <strong>定理 1</strong> 若三维多元函数<span class=\"math inline\">\\(f=f(x,y,z)\\)</span>在点<span class=\"math inline\">\\(M_0(x_0,y_0,z_0)\\)</span>处可微，<span class=\"math inline\">\\(\\cos(\\alpha),cos(\\beta),\\cos(\\gamma)\\)</span> 以<span class=\"math inline\">\\(l\\)</span>方向的方向余弦，则函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M_0\\)</span> 处沿<span class=\"math inline\">\\(l\\)</span> 方向导数必存在，且由如下公式给出</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f}}{\\part{l}}=\\frac{\\part{f}}{\\part{x}}\\cos(\\alpha)+\\frac{\\part{f}}{\\part{y}}\\cos{(\\beta)}+\\frac{\\part{f}}{\\part{z}}\\cos{(\\gamma)}  \\tag{4}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(\\frac{\\part{f}}{\\part{x}},\\frac{\\part{f}}{\\part{y}},\\frac{\\part{f}}{\\part{z}}\\)</span> 是在点<span class=\"math inline\">\\(M_0\\)</span> 处的偏导数。</p>\n<p><strong>证   明：</strong> 设在<span class=\"math inline\">\\(M_0(x,y,z)\\)</span>的<span class=\"math inline\">\\(\\delta-\\)</span>领域内存在动点<span class=\"math inline\">\\(M\\)</span>的坐标为<span class=\"math inline\">\\(M(x_0+\\Delta{x},y_0+\\Delta{y},z_0+\\Delta{z})\\)</span> 。因为<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M_0\\)</span> 可微，故有</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n \\Delta{f}&amp;=f(\\mathbf{M})-f(\\mathbf{M_0}) \\\\\n   &amp;=\\frac{\\part{f}}{\\part{x}}\\Delta{x}+\\frac{\\part{f}}{\\part{y}}\\Delta{y}+\\frac{\\part{f}}{\\part{z}}\\Delta{z}+o(r)\n   \n\\end{aligned}\n\\tag{5}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(r=\\sqrt{\\Delta{x}^2+\\Delta{y}^2+\\Delta{z}^2}\\)</span>， 将上式除以<span class=\"math inline\">\\(r\\)</span>:</p>\n<p></p><div class=\"math display\">\\[\\frac{\\Delta{f}}{r}=\\frac{\\part{f}}{\\part{x}}\\frac{\\Delta{x}}{r}+\\frac{\\part{f}}{\\part{y}}\\frac{\\Delta{y}}{r}+\\frac{\\part{f}}{\\part{z}}\\frac{\\Delta{z}}{r}+\\frac{o(r)}{r} \\tag{6}\n\\]</div><p></p><p>当<span class=\"math inline\">\\(r\\rightarrow{0}\\)</span> ,结合切线的定义可得：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f}}{\\part{l}}=\\frac{\\part{f}}{\\part{x}}\\cos{\\alpha}+\\frac{\\part{f}}{\\part{y}}\\cos{\\beta}+\\frac{\\part{f}}{\\part{z}}\\cos{\\gamma} \\tag{7}\n\\]</div><p></p><p>​        <strong>定理2</strong>   若存在有向曲线<span class=\"math inline\">\\(C\\)</span>上取一定的<span class=\"math inline\">\\(M_0\\)</span> ，作为计算弧长<span class=\"math inline\">\\(s\\)</span>的起点，并以<span class=\"math inline\">\\(C\\)</span>之正向作为<span class=\"math inline\">\\(s\\)</span>增大的方向；<span class=\"math inline\">\\(M\\)</span>为<span class=\"math inline\">\\(C\\)</span> 上的一点，在点<span class=\"math inline\">\\(M\\)</span> 处沿<span class=\"math inline\">\\(C\\)</span>之正向作一与<span class=\"math inline\">\\(C\\)</span>的相切射线<span class=\"math inline\">\\(l\\)</span>，则在点<span class=\"math inline\">\\(M\\)</span>处，当函数<span class=\"math inline\">\\(u\\)</span> 沿<span class=\"math inline\">\\(l\\)</span> 方向的方向导数就等于函数<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数，既有下式成立：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{\\part{u}}{\\part{s}} \\tag{8}\n\\]</div><p></p><p><strong>证  明：</strong> 设曲线<span class=\"math inline\">\\(C\\)</span>以<span class=\"math inline\">\\(s\\)</span>为参数的参数方程为：</p>\n<p></p><div class=\"math display\">\\[x=x(s),y=y(s),z=z(s) \\tag{9}\n\\]</div><p></p><p>则沿曲线<span class=\"math inline\">\\(C\\)</span>,函数</p>\n<p></p><div class=\"math display\">\\[u=u[x(s),y(s),z(s)] \\tag{10}\n\\]</div><p></p><p>又由于在点<span class=\"math inline\">\\(M\\)</span>处，函数<span class=\"math inline\">\\(u\\)</span>的可微、曲线<span class=\"math inline\">\\(C\\)</span>光滑，按照复合函数求导定理，得到<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数：</p>\n<p></p><div class=\"math display\">\\[\\frac{du}{ds}=\\frac{\\part{u}}{\\part{x}}\\frac{dx}{ds}+\\frac{\\part{u}}{\\part{y}}\\frac{dy}{ds}+\\frac{\\part{u}}{\\part{z}}\\frac{d{z}}{ds} \\tag{11}\n\\]</div><p></p><p>注意到<span class=\"math inline\">\\(\\frac{dx}{ds},\\frac{dy}{ds},\\frac{dz}{ds}\\)</span> 是曲线<span class=\"math inline\">\\(C\\)</span>的正方向切线<span class=\"math inline\">\\(l\\)</span>的方向余弦，若将其写成<span class=\"math inline\">\\(\\cos{(\\alpha)},\\cos{(\\beta)},\\cos{(\\gamma)}\\)</span> ，即得到<span class=\"math inline\">\\(u\\)</span>对<span class=\"math inline\">\\(s\\)</span>的全导数：</p>\n<p></p><div class=\"math display\">\\[\\frac{du}{ds}=\\frac{\\part{u}}{\\part{s}}\\cos(\\alpha)+\\frac{\\part{u}}{\\part{s}}\\cos(\\beta)+\\frac{\\part{u}}{\\part{s}}\\cos{(\\gamma)} \\tag{12}\n\\]</div><p></p><p>即知道，</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{du}{ds} \\tag{13}\n\\]</div><p></p><p>上面讲的是函数 <span class=\"math inline\">\\(u\\)</span>沿直线的方向导数。此外，有时还需要研究函数<span class=\"math inline\">\\(u\\)</span>沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数，其定义的如下：</p>\n<p>​       <strong>Definition 3</strong> 从点<span class=\"math inline\">\\(M\\)</span>出发沿<span class=\"math inline\">\\(C\\)</span>之正向取一点<span class=\"math inline\">\\(M_1\\)</span>, 记弧长 <span class=\"math inline\">\\(\\overset{\\LARGE{\\frown}}{MM_1}=\\Delta{s}\\)</span> ，若当<span class=\"math inline\">\\(M_1\\rightarrow{M}\\)</span>时，比式</p>\n<p></p><div class=\"math display\">\\[\\frac{\\Delta{u}}{\\Delta{s}}=\\frac{u(M_1)-u(M)}{|\\overset{\\LARGE{\\frown}}{MM_1}|} \\tag{14}\n\\]</div><p></p><p>的极限存在，则称此极限为函数<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M\\)</span>处沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数，记作<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span>，即：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds} \\tag{15}\n\\]</div><p></p><p><strong>定 理3</strong>  若在点<span class=\"math inline\">\\(M\\)</span>处函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M\\)</span> 处沿函数<span class=\"math inline\">\\(\\mathbf{C}\\)</span> (正向)的方向导数，记作<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span> ，则有</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds} \\tag{16}\n\\]</div><p></p><p><strong>证   明</strong>：由于在点<span class=\"math inline\">\\(M\\)</span>处函数<span class=\"math inline\">\\(u\\)</span> 可微，曲线<span class=\"math inline\">\\(C\\)</span>光滑，故有全导数<span class=\"math inline\">\\(\\frac{du}{ds}\\)</span>存在。而<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}\\)</span> 按照定义实际上的是一个右极限</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\lim_{\\Delta{t}\\rightarrow{0}}\\frac{\\Delta{u}}{\\Delta{s}} \\tag{17}\n\\]</div><p></p><p>故当<span class=\"math inline\">\\(\\frac{du}{ds}=\\lim_{\\Delta{t}\\rightarrow{0}}\\frac{\\Delta{u}}{\\Delta{s}}\\)</span> 存在时，就有<span class=\"math inline\">\\(\\frac{\\part{u}}{\\part{s}}=\\frac{du}{ds}\\)</span>.</p>\n<p><strong>推  论</strong>：若在点<span class=\"math inline\">\\(\\mathbf{M}\\)</span>处函数<span class=\"math inline\">\\(u\\)</span> 可微、曲线<span class=\"math inline\">\\(C\\)</span>光滑，则有：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{s}}=\\frac{\\part{u}}{\\part{l}} \\tag{18}\n\\]</div><p></p><p>换而言之：函数<span class=\"math inline\">\\(u\\)</span>在点<span class=\"math inline\">\\(M\\)</span>处沿曲线<span class=\"math inline\">\\(C\\)</span>(正向)的方向导数与函数<span class=\"math inline\">\\(u\\)</span> 在点<span class=\"math inline\">\\(M\\)</span> 处沿切线方法（指向<span class=\"math inline\">\\(C\\)</span>的正向一侧）的方向导数相等。</p>\n<h2 id=\"2-梯度向量\">2. 梯度向量</h2>\n<p>​        方向导数解决了多元变量数性函数<span class=\"math inline\">\\(u(\\mathbf{M})\\)</span> 在给定点处沿某个方向的变化率描述问题，然而从变量空间中的定义点出发，有无穷多个方向，那么函数<span class=\"math inline\">\\(u(\\mathbf{M})\\)</span> 沿其中哪个方向的变化率最大？最大的变化率又是多少呢? 在科学技术中常常需要讨论的问题，为了解决这个问题，那么我们从方向导数计算公式（12）出发：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\frac{\\part{u}}{\\part{x}}\\cos{\\alpha}+ \\frac{\\part{u}}{\\part{y}}\\cos{\\beta}+\\frac{\\part{u}}{\\part{z}}\\cos{\\gamma} \\tag{19}\n\\]</div><p></p><p>其中<span class=\"math inline\">\\(\\cos{\\alpha},\\cos{\\beta},\\cos{\\gamma}\\)</span> 为<span class=\"math inline\">\\(l\\)</span>方向的方向余弦，也就是这个方向上的单位矢量 <span class=\"math inline\">\\(\\boldsymbol{l}=\\cos{\\alpha}\\boldsymbol{i}+\\cos{\\beta}\\boldsymbol{j}+\\cos{\\gamma}\\boldsymbol{k}\\)</span> 的坐标，若把公式（19）右端可以写为<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 与<span class=\"math inline\">\\(\\boldsymbol{l}\\)</span> 的数量积：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=\\mathbf{G}\\cdot\\boldsymbol{l}=|\\mathbf{G}|\\cos(\\mathbf{G},\\boldsymbol{l}) \\tag{20}\n\\]</div><p></p><p>显然，<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 在给定点的处为一固定矢量，上式表示：<span class=\"math inline\">\\(\\mathbf{G}\\)</span>在<span class=\"math inline\">\\(l\\)</span>方向上的投影正好等于函数<span class=\"math inline\">\\(u\\)</span>在该方向上的方向导数，因此，当方向<span class=\"math inline\">\\(l\\)</span>与<span class=\"math inline\">\\(\\mathbf{G}\\)</span>的方向一致时，即<span class=\"math inline\">\\(cos(\\mathbf{G},\\boldsymbol{l})=1\\)</span> 时，方向导数取得最大值，其值为：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{u}}{\\part{l}}=|\\mathbf{G}| \\tag{21}\n\\]</div><p></p><p>由此可知，矢量<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 的方向就是函数<span class=\"math inline\">\\(u(M)\\)</span> 变化率最大的方向，其模也正好是这个最大变化率的数值。我们把<span class=\"math inline\">\\(\\mathbf{G}\\)</span> 叫做函数<span class=\"math inline\">\\(u(M)\\)</span> 在给定点处的梯度。一般，有如下的定义。</p>\n<p><strong>Definition 4</strong>  以<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 的<span class=\"math inline\">\\(n\\)</span> 个偏导数为分量的向量称为<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 处的梯度，记为：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left[\\frac{\\part{f}}{\\part{x_1}},\\frac{\\part{f}}{\\part{x_2}},\\frac{\\part{f}}{\\part{x_3}},...,\\frac{\\part{f}}{\\part{x_n}}\\right]^T \\tag{22}\n\\]</div><p></p><p>梯度也可以称为函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于向量<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的一阶导数。</p>\n<p>由此，可以从定义给出梯度与方向导数之间的关系。</p>\n<p><strong>定 理 4</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow{\\mathbf{R}}\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span>处可微，则方向导数与梯度关系：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{\\mathbf{P}}}=\\nabla{f(\\mathbf{X}_0)}^T\\mathbf{e} \\tag{23}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(\\mathbf{e}\\)</span> 是<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 方向上的单位向量。</p>\n<p>​\t由这个定理容易得到下列结论：</p>\n<p>​\t（1）若<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X}_0)^T\\mathbf{P}}&lt;0\\)</span>，则<span class=\"math inline\">\\(P\\)</span>的方向是函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的下降方向。</p>\n<p>​\t（2）若<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X}_0)}^T\\mathbf{P}&gt;0\\)</span> , 则<span class=\"math inline\">\\(P\\)</span>的方向是函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的上升方向。</p>\n<p>方向导数的正负决定了函数值的升降，而升降的快慢就由它的绝对值大小决定。绝对值越大，升降的速度就越快。根据式（19）到式（22）即：</p>\n<p></p><div class=\"math display\">\\[\\left|\\frac{\\part{f(X_0)}}{\\part{\\mathbf{P}}}\\right|=|\\nabla f(\\mathbf{X}_0)^T\\mathbf{e}|= |\\nabla{{f}(\\mathbf{X}_0)}|\\cdot|\\cos(\\nabla{f(\\mathbf{X}_0)},\\mathbf{e})|\\leq |\\nabla f(\\mathbf{X}_0)| \\tag{24} \n\\]</div><p></p><p>上式中的等号，当且仅当<span class=\"math inline\">\\(\\mathbf{e}\\)</span>的方向与<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X_0})}\\)</span> 的方向共线才成立。由此可知，得到如下重要结论：</p>\n<ol>\n<li>梯度向量是函数值的最速上升方向；</li>\n<li>函数在其梯度正交的方向上的变化率为零；</li>\n<li>函数在与其梯度成锐角方向上是上升的，而在成钝角的方向是下降的；</li>\n<li>梯度的反向是函数值最速下降方法；</li>\n</ol>\n<p>对于一个最优化问题，为了尽快得到最优解，在每一步迭代过程中选取的搜索方向<span class=\"math inline\">\\(\\mathbf{P}\\)</span> 总是希望它等于或者是靠近于目标函数的负梯度（即<span class=\"math inline\">\\(-\\nabla{f(\\mathbf{X})}\\)</span>）的方向，这样才能使函数值下降的最快。</p>\n<p>梯度的性质及以下几个特殊类型的函数的常用梯度公式：</p>\n<p>（1）若 <span class=\"math inline\">\\(f(\\mathbf{X})=c\\)</span> (c为常数)，则 <span class=\"math inline\">\\(\\nabla f(\\mathbf{X})=0\\)</span>，即 <span class=\"math inline\">\\(\\nabla{c}=0\\)</span>;</p>\n<p>（2）<span class=\"math inline\">\\(\\nabla(cf(\\mathbf{x}))=c\\nabla(f(\\mathbf{x}))\\)</span> （其中<span class=\"math inline\">\\(c\\)</span>为常数）；</p>\n<p>（3）<span class=\"math inline\">\\(\\nabla(u\\pm v)=\\nabla(u)\\pm\\nabla(v)\\)</span>;</p>\n<p>(4) <span class=\"math inline\">\\(\\nabla(uv)=u\\nabla(v)+v\\nabla(u)\\)</span></p>\n<p>(5) <span class=\"math inline\">\\(\\nabla{\\frac{u}{v}}=\\frac{1}{v^2}(v\\nabla{u}-u\\nabla{v})\\)</span></p>\n<p>(6) <span class=\"math inline\">\\(\\nabla f(u)=f^{\\prime}(u)\\nabla{u}\\)</span></p>\n<p>（7）<span class=\"math inline\">\\(\\nabla(f(u,v))=\\frac{\\part{f}}{\\part{u}}\\nabla(u)+\\frac{\\part{f}}{\\part{v}}\\nabla{v}\\)</span></p>\n<p>(8) <span class=\"math inline\">\\(\\nabla{\\mathbf{b}^T\\mathbf{X}}=\\mathbf{b}\\)</span></p>\n<p>(9) <span class=\"math inline\">\\(\\nabla(\\mathbf{X}^T\\mathbf{X})=2\\mathbf{X}\\)</span></p>\n<p>(10) 若 <span class=\"math inline\">\\(Q\\)</span> 是对称矩阵矩阵，则 <span class=\"math inline\">\\(\\nabla(\\mathbf{X}^T\\mathbf{Q}\\mathbf{X})=2\\mathbf(QX)\\)</span></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 20:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "春晚机器人与中国未来100年发展",
      "link": "https://www.cnblogs.com/xdesigner/p/19621864",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xdesigner/p/19621864\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 19:03\">\n    <span>春晚机器人与中国未来100年发展</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"postText\">    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        未来一百年，中国会走一条：人口适度、科技强大、产业高效、养老普惠的道路。科技让生活更安稳，让养老更有尊严，让国家发展更可持续。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><span style=\"font-size: 14pt;\">春<span>晚机器人与中国未来</span>100<span>年发展</span>（袁永福）</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>从</span>2026<span>年春晚的机器人武术表演，看懂中国未来一百年的发展。</span>本文案作者袁永福。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">先简单说一句春晚的机器人节目。</span></p>\n<p><span style=\"font-size: 14pt;\">舞台上，几台机器人打拳、舞剑，动作整齐、平衡稳、配合默契。</span></p>\n<p><span style=\"font-size: 14pt;\">就这么一段表演，已经说明，咱们的智能科技，真的开始走进现实生活了。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">节目一播出，网上讨论特别多。</span></p>\n<p><span style=\"font-size: 14pt;\">我看到很多年轻人都在说：以后不生小孩了，把养孩子的钱存起来，等二三十年以后，直接买机器人给自己养老。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">这句话听起来像一句玩笑，但其实一点都不搞笑。</span></p>\n<p><span style=\"font-size: 14pt;\">它背后，是整个社会结构正在发生的巨大变化，关系到人口、养老、产业，更关系到中国未来一百年，能不能稳得住、能不能持续高质量发展。</span></p>\n<p><span style=\"font-size: 14pt;\">可以说，从春晚这几台机器人，我们就能看见一个国家，未来一百年的路。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">首先大家要明白，春晚机器人不是为了好看。</span></p>\n<p><span style=\"font-size: 14pt;\">它真正的意义，是这些技术，以后都能用在养老上。</span></p>\n<p><span style=\"font-size: 14pt;\">机器人能走路、能保持平衡、能精准操作，放到养老场景里，就是扶老人、防跌倒、喂饭喂药、做康复、紧急呼救、监测健康。</span></p>\n<p><span style=\"font-size: 14pt;\">这才是最关键的价值。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">现在大家都能感受到，中国老龄化越来越严重。</span></p>\n<p><span style=\"font-size: 14pt;\">失能、半失能老人越来越多，专业护工缺口很大，人工成本也越来越高。</span></p>\n<p><span style=\"font-size: 14pt;\">传统的家庭养老、社区养老、机构养老，压力都非常大，很难长期撑下去。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">而机器人技术的成熟，刚好给养老问题，提供了一个根本解决方案。</span></p>\n<p><span style=\"font-size: 14pt;\">它可以大规模替代人工，降低成本，扩大服务范围，服务更稳定。</span></p>\n<p><span style=\"font-size: 14pt;\">也正因为这样，年轻人才会真心觉得：存钱买机器人养老，是一条很理性、很靠谱的路。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">但是这里必须讲清楚：个人这么选，非常合理。</span></p>\n<p><span style=\"font-size: 14pt;\">可整个社会，不能所有人都不生孩子。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">因为机器人不会自己研发，不会自己制造，不会自己维修，更不会自己升级。</span></p>\n<p><span style=\"font-size: 14pt;\">所有科技产业的根基，还是人，是年轻人、工程师、技术人员、产业工人。</span></p>\n<p><span style=\"font-size: 14pt;\">一个国家想要稳稳当当发展一百年，必须守住最基本的人口底线。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>传统社会里，生育率要达到</span>2.1<span>，才能一代换一代，人口不萎缩。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>未来，机器人和</span>AI<span>可以替代</span><span style=\"font-family: Calibri;\">70%</span><span>到</span><span style=\"font-family: Calibri;\">80%</span><span>的基础劳动，这个标准可以大幅降低。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>综合来看，中国未来一百年，生育率保持在</span>1.2<span>到</span><span style=\"font-family: Calibri;\">1.3</span><span>，就是安全线。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>如果低于</span>1.0<span>，人口会快速减少，创新能力枯竭，社会结构都会出问题。</span></span></p>\n<p><span style=\"font-size: 14pt;\">这是未来百年，最底层的逻辑。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">未来社会的劳动力，会分成三层：</span></p>\n<p><span style=\"font-size: 14pt;\">5%<span>的人，做核心技术研发和创新；</span></span></p>\n<p><span style=\"font-size: 14pt;\">20%<span>到</span><span style=\"font-family: Calibri;\">25%</span><span>的人，负责机器人运维、人机协作、服务管理；</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>剩下</span>70%<span>到</span><span style=\"font-family: Calibri;\">75%</span><span>的人，主要就是生活、消费、参与社会。</span></span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">这意味着，只要守住人口底线，就算劳动人口减少，有机器人补上缺口，社会照样能高效运转。</span></p>\n<p><span style=\"font-size: 14pt;\">人负责动脑、创新、决策，机器负责出力、重复、执行，形成稳定的人机协同社会。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">接下来，我们把未来一百年，直接分成三个阶段来讲，每一步都很清晰。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>第一个阶段，</span>2026<span>年到</span><span style=\"font-family: Calibri;\">2050</span><span>年，机器人普及期和社会转型期。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>这一阶段，生育率大概在</span>1.1<span>到</span><span style=\"font-family: Calibri;\">1.2</span><span>，接近安全底线。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>人口从</span>14<span>亿慢慢回落到</span><span style=\"font-family: Calibri;\">12</span><span>亿左右，老龄化压力比较明显。</span></span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>机器人会先在工业、农业、物流领域普及，替代</span>30%<span>到</span><span style=\"font-family: Calibri;\">50%</span><span>的劳动力。</span></span></p>\n<p><span style=\"font-size: 14pt;\">养老机器人以辅助型为主，陪伴、监测、简单护理，慢慢进入家庭和养老机构。</span></p>\n<p><span style=\"font-size: 14pt;\">养老金会有阶段性压力，但机器人服务会不断降低养老成本，弥补护工缺口。</span></p>\n<p><span style=\"font-size: 14pt;\"><span>到</span>2050<span>年，机器人养老，会从可选服务，变成基础服务。</span></span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>第二个阶段，</span>2050<span>年到</span><span style=\"font-family: Calibri;\">2080</span><span>年，机器人成熟期和社会稳定期。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>生育率回升到</span>1.2<span>到</span><span style=\"font-family: Calibri;\">1.3</span><span>的安全区间，人口稳定在</span><span style=\"font-family: Calibri;\">9</span><span>亿到</span><span style=\"font-family: Calibri;\">10</span><span>亿，结构更均衡。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>机器人对基础劳动的替代率，提升到</span>70%<span>到</span><span style=\"font-family: Calibri;\">80%</span><span>。</span></span></p>\n<p><span style=\"font-size: 14pt;\">人形机器人可以完成全流程照护：生活照料、康复、急救、健康管理，全都能做。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">虽然劳动人口数量下降，但人机协同，会让社会总生产能力大幅提升。</span></p>\n<p><span style=\"font-size: 14pt;\">养老服务实现标准化、普惠化、智能化。</span></p>\n<p><span style=\"font-size: 14pt;\">养老金主要用来支付机器人服务，养老不再是家庭的沉重负担。</span></p>\n<p><span style=\"font-size: 14pt;\">整个社会，进入高效、稳定、繁荣的阶段。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>第三个阶段，</span>2080<span>年到</span><span style=\"font-family: Calibri;\">2126</span><span>年，智能文明期和高质量发展期。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>生育率保持在</span>1.0<span>到</span><span style=\"font-family: Calibri;\">1.2</span><span>，人口稳定在</span><span style=\"font-family: Calibri;\">6</span><span>亿到</span><span style=\"font-family: Calibri;\">8</span><span>亿，小规模、高质量、高寿命。</span></span></p>\n<p><span style=\"font-size: 14pt;\"><span>机器人和通用</span>AI<span>深度融合，替代</span><span style=\"font-family: Calibri;\">90%</span><span>以上的重复性劳动。</span></span></p>\n<p><span style=\"font-size: 14pt;\">人类从体力劳动中彻底解放，专注创新、决策、文化、情感交流。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">养老也进入最高级阶段：机器人不只照顾身体，还能精神陪伴、提前预判健康问题、联动医疗。</span></p>\n<p><span style=\"font-size: 14pt;\">靠存款、养老金、保险来支付机器人服务，会成为最主流、最可靠的养老模式。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">支撑这一切的，是机器人产业。</span></p>\n<p><span style=\"font-size: 14pt;\">这不是小概念，而是十万亿级别的超级产业，会带动制造业、农业、服务业、养老业全面升级。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\"><span>现在，中国养老机器人市场已经超过</span>500<span>亿。</span></span></p>\n<p><span style=\"font-size: 14pt;\">2030<span>年有望突破</span><span style=\"font-family: Calibri;\">2000</span><span>亿，</span><span style=\"font-family: Calibri;\">2040</span><span>年进入万亿级别。</span></span></p>\n<p><span style=\"font-size: 14pt;\">规模上来以后，成本会大幅下降。</span></p>\n<p><span style=\"font-size: 14pt;\"><span>现在人形机器人十几万、几十万一台，</span>2030<span>年能降到</span><span style=\"font-family: Calibri;\">5</span><span>万以内，</span><span style=\"font-family: Calibri;\">2040</span><span>年普及后，可能只要</span><span style=\"font-family: Calibri;\">1</span><span>万到</span><span style=\"font-family: Calibri;\">3</span><span>万一台，或者月租两三千块钱。</span></span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">未来养老的逻辑非常简单：</span></p>\n<p><span style=\"font-size: 14pt;\">养老金决定你的购买力，机器人决定服务力。</span></p>\n<p><span style=\"font-size: 14pt;\">个人存款、基本养老保险、商业养老金融，最后都会用来支付机器人服务。</span></p>\n<p><span style=\"font-size: 14pt;\">机器人产业越成熟，养老成本越低，社会负担越小，科技进步的红利，会真正落到每一个普通人身上。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">最后我们要理清一个观念：</span></p>\n<p><span style=\"font-size: 14pt;\"><span>年轻人说</span>“不生娃、存钱买机器人养老”，是新时代里非常理性的个人选择，不应该被指责，也不等于社会危机。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">只要国家守住人口安全底线，坚持科技创新，这种模式完全可以持续。</span></p>\n<p><span style=\"font-size: 14pt;\">未来中国，会是多元共生的格局：</span></p>\n<p><span style=\"font-size: 14pt;\">一部分家庭生育，守住人口基础；</span></p>\n<p><span style=\"font-size: 14pt;\">一部分人储蓄，享受科技养老；</span></p>\n<p><span style=\"font-size: 14pt;\">机器人填补劳动力缺口，提升社会效率。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">个人选择和国家长期发展，不是对立的，而是互补的。</span></p>\n<p><span style=\"font-size: 14pt;\">两者一起，构成稳定、健康、有活力的社会结构。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">回过头再看，春晚那一段机器人武术表演，看似只是一个节目，其实打开了未来百年的窗口。</span></p>\n<p><span style=\"font-size: 14pt;\">它预示着一个由科技驱动、效率支撑、资金保障、人口托底的新时代。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">未来一百年，中国会走一条：人口适度、科技强大、产业高效、养老普惠的道路。</span></p>\n<p><span style=\"font-size: 14pt;\">从舞台上的表演机器人，到家庭里的养老助手；</span></p>\n<p><span style=\"font-size: 14pt;\">从年轻人的人生选择，到国家的百年战略；</span></p>\n<p><span style=\"font-size: 14pt;\">一切都在指向同一个未来：</span></p>\n<p><span style=\"font-size: 14pt;\">科技让生活更安稳，让养老更有尊严，让国家发展更可持续。</span></p>\n<p><span style=\"font-size: 14pt;\">&nbsp;</span></p>\n<p><span style=\"font-size: 14pt;\">这就是我们从一台春晚机器人，所能看见的，中国未来一百年可能的发展路径。</span></p>\n\n</div>\n<div class=\"clear\"></div>\n</div>\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-02-17 19:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xdesigner\">袁永福 电子病历，医疗信息化</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "OpenClaw怎么做到不串台、能并行、还总回对群 ✅（含源码解析）--OpenClaw系列第1期",
      "link": "https://www.cnblogs.com/borui-coding-diary/p/19621811/openclaw-group-chats-concurrency-commercialization-barrier",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/borui-coding-diary/p/19621811/openclaw-group-chats-concurrency-commercialization-barrier\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 18:02\">\n    <span>OpenClaw怎么做到不串台、能并行、还总回对群 🤖✅（含源码解析）--OpenClaw系列第1期</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"OpenClaw怎么做到不串台、能并行、还总回对群 &amp;#129302;✅（含源码解析）--OpenClaw系列第1期\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3759702/202602/3759702-20260217175237028-512010576.png\" />\n        把 AI 放进群聊只是开始：真正卡住商业化的门槛，是并发下的“上下文不串、回对地方、权限可控、成本可收”。这篇用 OpenClaw 的实现把这道坎讲清楚。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"引子群里最可怕的不是答错是答到别的地方\">引子：群里最可怕的不是“答错”，是“答到别的地方”😵‍💫</h2>\n<p>你把 OpenClaw 部署进群，大家立刻把它当万能同事用：</p>\n<ul>\n<li>小王在 <strong>dev-team 群</strong>：<code>@bot 帮我写发布计划</code></li>\n<li>小李在同群<strong>线程</strong>：<code>@bot CI 为啥挂了？</code></li>\n<li>你在<strong>私聊</strong>：<code>这个别在群里说…</code></li>\n<li>还有人：<code>@bot 同时分析文档 A、B，再给我结论</code></li>\n</ul>\n<p>如果机器人只有“一份混在一起的对话记录”，就会出现社死级翻车：<br />\n<strong>A 群问、B 群回；线程问、主楼回；私聊的内容差点带进群。</strong></p>\n<p>OpenClaw 的思路很朴素：<br />\n<strong>先把不同地方的对话记录分开存 → 再支持后台并行 → 再保证后台回到同一个群/线程 → 最后用完就删（或留档）。</strong></p>\n<hr />\n<h2 id=\"1串台a-的话跑到-b-的对话里-\">1）串台：A 的话跑到 B 的对话里 🫠</h2>\n<p><strong>群友反应：</strong> 😨➡️💀➡️🧯（“别回错群啊！！救火！”）</p>\n<blockquote>\n<p>群友：<code>@bot 我在 dev-team 问的，你怎么把答案发到 release-squad 了？！</code></p>\n</blockquote>\n<p><strong>问题</strong>：不同对话的记录混在一起。<br />\n<strong>解决方法其实很简单</strong>：给每段对话一个“对话ID”，所有记录按这个 ID 分开存。（OpenClaw 内部叫 <code>sessionKey</code>，你可以理解成“对话ID”。）</p>\n<pre><code class=\"language-ts\">// 按“对话ID”分开存记录（概念代码）\nconst chats = new Map&lt;string, string[]&gt;();\n\nfunction add(chatId: string, msg: string) {\n  if (!chats.has(chatId)) chats.set(chatId, []);\n  chats.get(chatId)!.push(msg);\n}\n</code></pre>\n<p>✅ 结果：对话ID不同，记录天然不混。<br />\n<strong>但新的问题来了：</strong>同一个群里主楼+多个线程也会互相干扰 🤯</p>\n<hr />\n<h2 id=\"2同群混聊主楼和线程搅成一锅粥-\">2）同群混聊：主楼和线程搅成一锅粥 🧵</h2>\n<p><strong>群友反应：</strong> 🤨➡️🧵➡️😵‍💫（“我问线程你回主楼？脑子打结了？”）</p>\n<blockquote>\n<p>群友：<code>@bot 我在线程问 CI，你怎么把“今晚吃啥”也总结进来了？</code></p>\n</blockquote>\n<p><strong>问题</strong>：同一个群里多个话题并行发生。<br />\n<strong>解决方法其实也很简单</strong>：对话ID里把“群名/线程”也区分出来——<strong>主楼一份记录，线程一份记录</strong>。</p>\n<pre><code class=\"language-ts\">// 对话ID规则（概念）：群 vs 线程分开\ngroupChatId  = `discord:群:${groupId}`                 // 主楼\nthreadChatId = `discord:群:${groupId}:线程:${threadId}` // 线程\ndmChatId     = `discord:私聊:${peerId}`                 // 私聊\n</code></pre>\n<p>✅ 结果：你在<strong>哪个线程</strong>聊，就只影响<strong>那个线程</strong>的记录。<br />\n<strong>但新的问题来了：</strong>不混了，但任务多了会卡住（大家同时丢重活）⌛</p>\n<hr />\n<h2 id=\"3卡顿大家同时丢重活机器人开始排队-\">3）卡顿：大家同时丢重活，机器人开始排队 😤</h2>\n<p><strong>群友反应：</strong> ⏳➡️😤➡️📢（“别思考了！先回个收到！”）</p>\n<blockquote>\n<p>群友：<code>@bot 你别转圈圈了，先回一句“收到”也行啊！</code></p>\n</blockquote>\n<p><strong>问题</strong>：分析文档/汇总讨论这种重活，同时来好几个就会堵住。<br />\n<strong>解决方法其实很简单</strong>：重活不要在群里“现场算”，<strong>开一个后台任务去做</strong>，群里先继续聊。</p>\n<pre><code class=\"language-ts\">// 开后台任务（概念）：立刻返回 runId，不阻塞\nfunction startBackground(task: string) {\n  const jobId = crypto.randomUUID();         // runId\n  const workspace = `bg:${crypto.randomUUID()}`; // 后台独立空间\n  gatewayStart({ workspace, task, deliverNow: false });\n  return { status: \"accepted\", jobId, workspace };\n}\n</code></pre>\n<p>✅ 结果：群里体验变成“先收到 ✅，稍后给结果”。<br />\n<strong>但新的问题来了：</strong>后台做完了，<strong>怎么保证它一定回到同一个群/同一个线程</strong>？📍</p>\n<hr />\n<h2 id=\"4回错地方我在-dev-team-问的你别跑去别的群回-\">4）回错地方：我在 dev-team 问的，你别跑去别的群回 😵</h2>\n<p><strong>群友反应：</strong> 📍➡️🙅‍♂️➡️✅（“就！在！这！里！回！”）</p>\n<blockquote>\n<p>群友：<code>@bot 我是在 dev-team 的“CI排查线程”问的，你能不能就在那条线程里回？</code></p>\n</blockquote>\n<p><strong>问题</strong>：后台任务结束后，答案必须发回<strong>你当时提问的那个群/线程/私聊</strong>。<br />\n<strong>解决方法其实很简单</strong>：程序会记住你发消息的<strong>群名/线程</strong>（内部更稳的是记 <code>groupId/threadId</code>），后台结束就按这个信息回去发。</p>\n<pre><code class=\"language-ts\">type Where = { groupId?: string; groupName?: string; threadId?: string };\nconst jobs = new Map&lt;string, { where: Where; workspace: string }&gt;();\n\nfunction onAsk(ctx: any) {\n  const where = { groupId: ctx.group.id, groupName: ctx.group.name, threadId: ctx.thread?.id };\n  const { jobId, workspace } = startBackground(ctx.task);\n  jobs.set(jobId, { where, workspace });\n}\n\nasync function onDone(jobId: string) {\n  const { where, workspace } = jobs.get(jobId)!;\n  const result = await readResult(workspace);\n  sendMessage(where, result); // ✅ 群里问→回同群；线程问→回同线程\n}\n</code></pre>\n<p>✅ 读者只要记住一句话：<br />\n<strong>哪个群问的，就回哪个群；哪个线程问的，就回哪个线程。</strong><br />\n<strong>但新的问题来了：</strong>后台这么能干，会不会“乱翻记录/乱发消息/无限开后台”？😨</p>\n<hr />\n<h2 id=\"5越权套娃后台别乱来-\">5）越权/套娃：后台别乱来 🔒</h2>\n<p><strong>群友反应：</strong> 👀➡️🚫➡️🔒（“别乱看别乱开，锁上！”）</p>\n<blockquote>\n<p>群友：<code>@bot 你后台干活归干活，别偷偷翻别的群聊天记录啊…</code></p>\n</blockquote>\n<p><strong>问题</strong>：后台任务如果权限太大，可能越界；如果还能再开后台，就可能无限套娃。<br />\n<strong>解决方法其实很简单</strong>：后台默认“受限模式”——<strong>不许再开后台</strong>，也不许做敏感操作。</p>\n<pre><code class=\"language-ts\">// 后台受限（概念）\nif (ctx.isBackground) deny(\"startBackground\");  // 禁止后台再开后台\ndenyMany([\"listChats\", \"readHistory\", \"sendToOtherChats\", \"memorySearch\"]);\n</code></pre>\n<p>✅ 结果：后台只负责“把任务做完”，不乱看、不乱发、不无限分裂。<br />\n<strong>但新的问题来了：</strong>并行多了，后台任务空间会不会越攒越多？🗑️</p>\n<hr />\n<h2 id=\"6垃圾堆后台任务越跑越多像浏览器-300-个标签页-️\">6）垃圾堆：后台任务越跑越多，像浏览器 300 个标签页 🗑️</h2>\n<p><strong>群友反应：</strong> 🐌➡️🗑️➡️✨（“越用越慢？清一清立刻顺滑”）</p>\n<blockquote>\n<p>群友：<code>@bot 你怎么越用越慢了？是不是后台开了一堆任务没清理？</code> 😅</p>\n</blockquote>\n<p><strong>问题</strong>：并行多了，后台任务空间也会多。<br />\n<strong>解决方法其实很简单</strong>：结果发回群里后——<strong>默认用完就删</strong>；重要任务才“留档复盘”。</p>\n<pre><code class=\"language-ts\">async function finish(jobId: string, keep = false) {\n  const { where, workspace } = jobs.get(jobId)!;\n  sendMessage(where, await readResult(workspace));\n  if (!keep) await deleteWorkspace(workspace); // ✅ 用完就删\n}\n</code></pre>\n<p>✅ 结果：默认干净省资源；需要复盘时才保留。</p>\n<hr />\n<h2 id=\"一张图把全链路串起来-\">一张图把全链路串起来 🧩</h2>\n<pre><code>你在某个群/线程提问\n   ↓\n按“群/线程”生成对话ID → 对话记录分开存（不串台）\n   ↓\n重活？→ 开后台任务（群里先回“收到”）\n   ↓\n记住群名/线程 → 后台结束回同一个群/同一个线程发结果\n   ↓\n后台受限（不越权/不套娃）\n   ↓\n默认用完就删（或留档复盘）\n</code></pre>\n<p><strong>群友反应：</strong> 🧠➡️🧩➡️🫡（“懂了：分开记、后台跑、回原处、能收拾”）</p>\n<hr />\n<h3 id=\"tldr\">tldr;</h3>\n<p><strong>OpenClaw 的目标很简单：你在哪个群/线程问，它就在哪儿回；不同地方的对话记录各存各的；重活后台并行；后台不乱来；默认用完就删。</strong> ✅</p>\n<p>关注我，下一期继续整更硬核干货🔥🤖📌 敬请期待～✨</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 18:02</span>&nbsp;\n<a href=\"https://www.cnblogs.com/borui-coding-diary\">vibecoding日记</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Mihon/Tachiyomi漫画插件分析(侧重目前插件现状分析和英文插件推荐)",
      "link": "https://www.cnblogs.com/xuhe2/p/19621760",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xuhe2/p/19621760\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:35\">\n    <span>Mihon/Tachiyomi漫画插件分析(侧重目前插件现状分析和英文插件推荐)</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>我之前做过插件推荐(包含中文和英文)有不错的阅读量. 现在重新记录一下内容, 主要是因为半年多前, 包含各种国内的漫画平台都出了自己的App, 避免用户从网页版上查看漫画内容.</p>\n<blockquote>\n<p>tachiyomi/mihon漫画插件推荐: <a href=\"https://www.cnblogs.com/xuhe2/p/18823091\" target=\"_blank\">https://www.cnblogs.com/xuhe2/p/18823091</a><br />\ntachiyomi/mihon插件推荐(英文版): <a href=\"https://www.cnblogs.com/xuhe2/p/18879823\" target=\"_blank\">https://www.cnblogs.com/xuhe2/p/18879823</a></p>\n</blockquote>\n<p>Github插件汇总仓库: <a href=\"https://github.com/keiyoushi/extensions\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/keiyoushi/extensions</a></p>\n<p>插件查询: <a href=\"https://keiyoushi.github.io/extensions/\" rel=\"noopener nofollow\" target=\"_blank\">https://keiyoushi.github.io/extensions/</a></p>\n<h1 id=\"现状分析\">现状分析</h1>\n<p>半年多前, 包含各种国内的漫画平台都出了自己的App, App一般使用跨平台的Flutter进行开发, 导致逆向成本很高, 之前那些插件都是放弃进行维护了.</p>\n<blockquote>\n<p>例如, COLAMANGA, BaoZi</p>\n</blockquote>\n<p>目前我认为国内的漫画资源基本已经很有限了, 而且对比国外英文资源的更新速度基本也是慢上几个章节的速度.</p>\n<blockquote>\n<p>所以, 目前推荐英文资源或者直接配合OCR阅读原版本的内容</p>\n</blockquote>\n<p>即使是英文资源插件, 最近也有挺多没了的, 比如很出名的comick(这个我很喜欢, 之前一直在使用, 支持多语言内容, 甚至有中文). 所以, 我记录一下目前还可以使用的插件, 或者我通过查看国外论坛获得的可行的选项的可能性.</p>\n<h1 id=\"英文资源插件推荐\">(英文资源)插件推荐</h1>\n<p>精简版本</p>\n<blockquote>\n<p>由于国内漫画平台转向 Flutter 开发导致插件维护停滞，目前的“最优解”是放弃资源落后的国内源，转向更新更快、稳定性更高的英文插件（如 MangaFire），并配合 OCR 插件跨越语言壁垒。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th><strong>插件/网站名称</strong></th>\n<th><strong>资源语言</strong></th>\n<th><strong>插件状态 (Mihon)</strong></th>\n<th><strong>推荐理由 / 现状</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>MangaFire</strong></td>\n<td>英文</td>\n<td>✅ <strong>可用</strong></td>\n<td>更新速度极快，体验超过国内源，主力推荐。</td>\n</tr>\n<tr>\n<td><strong>MangaBuddy</strong></td>\n<td>英文</td>\n<td>✅ <strong>可用</strong></td>\n<td>热门作品覆盖全，更新频率与 MangaFire 持平。</td>\n</tr>\n<tr>\n<td><strong>ManhwaWeb</strong></td>\n<td>英文</td>\n<td>❌ <strong>无插件</strong></td>\n<td>Reddit 社区高分推荐，目前仅限网页版观看。</td>\n</tr>\n<tr>\n<td><strong>MangaPark</strong></td>\n<td>英文</td>\n<td>❌ <strong>无插件</strong></td>\n<td>老牌社区，内容丰富，但目前需等待第三方开发适配。</td>\n</tr>\n<tr>\n<td><strong>Comick</strong></td>\n<td>多语言</td>\n<td>⚠️ <strong>已关停</strong></td>\n<td>曾经的“全能王”，目前已失效，需寻找替代品。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"mangafire-有插件-可用\">MangaFire (有插件, 可用)</h2>\n<p>官网: <a href=\"https://mangafire.to/home\" rel=\"noopener nofollow\" target=\"_blank\">https://mangafire.to/home</a><br />\n插件: <a href=\"https://keiyoushi.github.io/extensions/#all.mangafire\" rel=\"noopener nofollow\" target=\"_blank\">https://keiyoushi.github.io/extensions/#all.mangafire</a></p>\n<p>可以使用, 正在使用中, 比国内的资源进度也快</p>\n<h2 id=\"mangabuddy-有插件-可用\">mangabuddy (有插件, 可用)</h2>\n<p>插件: <a href=\"https://keiyoushi.github.io/extensions/#en.mangabuddy\" rel=\"noopener nofollow\" target=\"_blank\">https://keiyoushi.github.io/extensions/#en.mangabuddy</a></p>\n<p>和MangaFire一样的更新进度基本上, 有名的漫画基本都有</p>\n<h2 id=\"manhwaweb没有插件-但是reddit有人推荐\">manhwaweb(没有插件, 但是Reddit有人推荐)</h2>\n<blockquote>\n<p>Reddit帖子: <a href=\"https://www.reddit.com/r/manhwarecommendations/comments/1nii3gv/title_comickio_got_shut_down_what_are_yalls/?tl=zh-hans\" rel=\"noopener nofollow\" target=\"_blank\">https://www.reddit.com/r/manhwarecommendations/comments/1nii3gv/title_comickio_got_shut_down_what_are_yalls/?tl=zh-hans</a><br />\n有一个人一直在推荐很多次, 但是没有插件</p>\n</blockquote>\n<p>官网: <a href=\"https://www.manhwaweb.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.manhwaweb.com/</a></p>\n<h2 id=\"mangapark没有插件-但是reddit有人推荐\">mangapark(没有插件, 但是Reddit有人推荐)</h2>\n<p>官网: mangapark.io</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:35</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xuhe2\">xuhe2</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战",
      "link": "https://www.cnblogs.com/han5562877/p/19621722/overcoming-tencent-tcaptcha-208tlo",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/han5562877/p/19621722/overcoming-tencent-tcaptcha-208tlo\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:25\">\n    <span>攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文记录了一次对腾讯 TCaptcha 滑块验证码的完整逆向工程实践，以粉笔教育登录流程为研究对象，通过纯 HTTP 协议实现了全自动化破解，通过率达到 100%。\n核心挑战包括：三阶段协议完整还原、NCC 模板匹配算法优化、PoW 工作量证明高效求解，以及 TDC.js 混淆虚拟机的执行与行为轨迹仿真。\n逆向从 HAR 抓包入手，梳理出风控触发后业务系统返回 contextId、前端加载腾讯验证码 iframe、用户验证成功后获取 ticket 和 randstr、再提交 captcha/check 解除风控的完整链路。验证码系统与业务系统解耦，可独立攻克 TCaptcha 后将凭证提交业务接口即可。\n同时还原了发送短信验证码接口所需的 RSA/ECB/PKCS#1 v1.5 加密 info 字段（手机号+时间戳），并用纯 Python 实现了标准填充的加密过程。\n本文为后续协议分析、图像处理、算法设计和虚拟机执行等环节奠定了基础，最终构建出一套稳定、可复用的纯 HTTP 自动化解决方案。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"攻克腾讯-tcaptcha-滑块验证码纯-http-协议逆向实战\">攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战</h1>\n<p>本文记录了一次完整的验证码逆向工程实践，从协议分析、图像处理、算法设计到 JavaScript VM 执行，最终实现了对腾讯 TCaptcha 滑块验证码的全自动化破解，通过率达到 100%。</p>\n<h2 id=\"一技术挑战概述\">一、技术挑战概述</h2>\n<p>腾讯 TCaptcha 是国内主流的滑块验证码方案，被广泛应用于各大互联网平台的风控系统中。本项目以粉笔教育的登录流程为研究对象，核心目标是在不依赖 Selenium 或 Playwright 等浏览器自动化工具的前提下，通过纯 HTTP 协议模拟实现验证码的自动化破解。这要求我们不仅要实现亚像素级别的拼图块位置计算，还需要绕过设备指纹、行为轨迹等多维度的检测机制，最终构建出一套稳定、可复用的工程化解决方案。</p>\n<p>整个项目面临的核心技术难点包括 TCaptcha 三阶段协议的完整还原、NCC 模板匹配算法的优化与实现、PoW 工作量证明的高效求解，以及最困难的 TDC.js 混淆虚拟机的执行与轨迹仿真。这些挑战环环相扣，任何一个环节的失败都会导致整个验证流程无法通过。</p>\n<h2 id=\"二前置准备业务流程逆向\">二、前置准备：业务流程逆向</h2>\n<h3 id=\"21-har-抓包与协议分析\">2.1 HAR 抓包与协议分析</h3>\n<p>一切从 Chrome DevTools 的网络抓包开始。通过录制完整的登录流程，我们发现当服务端检测到异常请求时，发送短信验证码的接口会返回 HTTP 430 状态码，响应体中包含一个 contextId 字段。这个 contextId 是后续验证码校验的会话标识，前端会弹出 iframe 加载腾讯验证码页面。用户完成滑块验证后，前端会获得 ticket 和 randstr 两个凭证，然后调用 captcha/check 接口提交这两个凭证来解除风控，最后带着 contextId 重试发送短信请求。</p>\n<p>完整的风控触发链路如下：</p>\n<pre><code>POST /users/phone/verification\n  ↓ 返回 HTTP 430\n  {\n    \"contextId\": \"abc123...\"\n  }\n  ↓\n[前端弹出 TCaptcha iframe]\n  ↓ 用户完成滑块验证\n  {\n    \"ticket\": \"t123...\",\n    \"randstr\": \"r456...\"\n  }\n  ↓\nPOST /users/captcha/check\n  Body: {\n    \"contextId\": \"abc123...\",\n    \"tencentticket\": \"t123...\",\n    \"tencentrandstr\": \"r456...\"\n  }\n  ↓ 返回 200 OK\nPOST /users/phone/verification?abxContextId=abc123...\n  ↓ 返回 200 OK，短信发送成功\n</code></pre>\n<p>这个流程揭示了一个关键点：验证码系统与业务系统是解耦的。业务系统只负责触发风控和校验凭证，真正的验证码交互完全发生在腾讯的域名下。这意味着我们可以独立地攻克 TCaptcha 验证码，然后将获得的 ticket 和 randstr 提交给业务系统即可。</p>\n<h3 id=\"22-rsa-加密参数还原\">2.2 RSA 加密参数还原</h3>\n<p>在分析 HAR 文件时，我们注意到发送短信验证码的接口需要一个名为 info 的字段。通过搜索前端打包后的 JavaScript 代码，我们在 main-es2015.js 中找到了加密逻辑：</p>\n<pre><code class=\"language-javascript\">// 前端加密逻辑（ref/js/main-es2015.*.js）\nfunction encryptPhone(phone) {\n    var publicKey = \"ANKi9PWuvDOsagwIVvrPx77mXNV0APmjySsYjB1/GtUT...\";\n    var timestamp = new Date().getTime();\n    var plaintext = phone + \":\" + timestamp;\n    return encrypt(publicKey, plaintext);\n}\n</code></pre>\n<p>这个 info 字段是对手机号和时间戳的 RSA 加密结果，格式为 <code>encrypt(publicKey, \"{phone}:{timestamp_ms}\")</code>。公钥模数以 Base64 格式硬编码在前端代码中，指数固定为 0x10001，加密算法是标准的 RSA/ECB/PKCS#1 v1.5。</p>\n<p>为了避免引入额外的密码学库依赖，我们用纯 Python 实现了这个加密过程。PKCS#1 v1.5 padding 的格式是 <code>0x00 || 0x02 || PS || 0x00 || M</code>​，其中 PS 是非零随机字节序列，长度为 <code>k - len(M) - 3</code>，k 是模长。实现代码如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/utils/rsa_encrypt.py\n\nimport base64\nimport secrets\nfrom dataclasses import dataclass\n\nRSA_EXPONENT_65537 = 0x10001\n\ndef _nonzero_random_bytes(n: int, randfunc) -&gt; bytes:\n    \"\"\"生成 n 个非 0 随机字节（PKCS#1 v1.5 padding 需要）。\"\"\"\n    out = bytearray()\n    while len(out) &lt; n:\n        chunk = bytearray(randfunc(n - len(out)))\n        chunk = bytearray(b for b in chunk if b != 0)\n        out.extend(chunk)\n    return bytes(out[:n])\n\n@dataclass(frozen=True)\nclass RsaPublicKey:\n    n: int  # 模数\n    e: int = RSA_EXPONENT_65537  # 指数\n    \n    @property\n    def k(self) -&gt; int:\n        \"\"\"模长（字节）。\"\"\"\n        return (self.n.bit_length() + 7) // 8\n\ndef rsa_encrypt_pkcs1_v1_5_base64(key: RsaPublicKey, plaintext: str) -&gt; str:\n    \"\"\"RSA/ECB/PKCS#1 v1.5 加密，并输出 Base64 字符串。\"\"\"\n    m = plaintext.encode(\"utf-8\")\n    k = key.k\n    \n    if len(m) &gt; k - 11:\n        raise ValueError(\"明文过长，无法进行 PKCS#1 v1.5 padding\")\n    \n    # PKCS#1 v1.5 padding: 0x00 || 0x02 || PS(非零随机) || 0x00 || M\n    ps_len = k - len(m) - 3\n    ps = _nonzero_random_bytes(ps_len, secrets.token_bytes)\n    em = b\"\\x00\\x02\" + ps + b\"\\x00\" + m\n    \n    # RSA 加密：c = m^e mod n\n    em_int = int.from_bytes(em, \"big\")\n    c_int = pow(em_int, key.e, key.n)\n    c = c_int.to_bytes(k, \"big\")\n    \n    return base64.b64encode(c).decode(\"ascii\")\n\ndef build_phone_verification_info(public_key_b64: str, phone: str, timestamp_ms: int) -&gt; str:\n    \"\"\"生成 /users/phone/verification 所需的 info 字段。\"\"\"\n    key = RsaPublicKey.from_fenbi_public_key_b64(public_key_b64)\n    return rsa_encrypt_pkcs1_v1_5_base64(key, f\"{phone}:{timestamp_ms}\")\n</code></pre>\n<p>这个实现有几个关键点。第一，PKCS#1 v1.5 padding 要求填充字节必须非零，我们使用 <code>secrets.token_bytes</code>​ 生成密码学安全的随机数，然后过滤掉所有的 0 字节。第二，大整数运算使用 Python 内置的 <code>pow(m, e, n)</code> 实现模幂运算，这是 Python 标准库提供的高效实现，无需引入第三方库。第三，整个实现不到 80 行代码，完全不依赖 PyCrypto、cryptography 等密码学库。</p>\n<p>至此，业务层的协议已经完全还原。接下来的核心挑战是如何自动化通过腾讯 TCaptcha 滑块验证码。</p>\n<h2 id=\"三tcaptcha-协议逆向三阶段攻防\">三、TCaptcha 协议逆向：三阶段攻防</h2>\n<h3 id=\"31-协议架构分析\">3.1 协议架构分析</h3>\n<p>TCaptcha 的交互流程涉及三个核心接口，全部位于 turing.captcha.qcloud.com 域名下。第一个接口是 cap_union_prehandle，负责初始化会话并获取图片配置和安全参数。第二个接口是 cap_union_new_getcapbysig，用于下载背景图和前景精灵图。第三个接口是 cap_union_new_verify，用于提交答案并获取最终的 ticket 和 randstr 凭证。</p>\n<h4 id=\"阶段一prehandle-会话初始化\">阶段一：prehandle 会话初始化</h4>\n<p>prehandle 接口的请求参数包含了业务方的 TCaptcha APP_ID、协议类型、客户端类型、语言设置等信息。其中 User-Agent 需要进行 Base64 编码，subsid 参数表示重试次数，每次失败后需要递增。完整的请求参数如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef prehandle(aid: str, entry_url: str = \"\", *, subsid: int = 1) -&gt; CaptchaLayout:\n    \"\"\"调用 TCaptcha prehandle 接口，初始化验证会话。\"\"\"\n    ua_b64 = base64.b64encode(_UA.encode()).decode()\n    \n    params = {\n        \"aid\": aid,                    # 业务方的 TCaptcha APP_ID\n        \"protocol\": \"https\",\n        \"accver\": \"1\",\n        \"showtype\": \"embed\",\n        \"ua\": ua_b64,                  # User-Agent Base64 编码\n        \"noheader\": \"1\",\n        \"fb\": \"0\",\n        \"aged\": \"0\",\n        \"enableAged\": \"0\",\n        \"enableDarkMode\": \"0\",\n        \"grayscale\": \"1\",\n        \"clientype\": \"2\",              # 客户端类型（2=Web）\n        \"cap_cd\": \"\",\n        \"uid\": \"\",\n        \"lang\": \"zh-cn\",\n        \"entry_url\": entry_url,\n        \"elder_captcha\": \"0\",\n        \"js\": \"/tcaptcha-frame.5bae14dd.js\",\n        \"login_appid\": \"\",\n        \"wb\": \"2\",\n        \"subsid\": str(subsid),         # 重试次数（失败后递增）\n        \"callback\": \"_aq_000001\",      # JSONP 回调函数名\n        \"sess\": \"\",\n    }\n    \n    url = f\"{_BASE}/cap_union_prehandle?{urllib.parse.urlencode(params)}\"\n    raw = _get(opener, url).decode(\"utf-8\")\n    data = _parse_jsonp(raw)  # 解析 JSONP 响应\n    \n    # 提取关键配置信息\n    sess = data.get(\"sess\", \"\")\n    dyn = data[\"data\"][\"dyn_show_info\"]\n    comm_cfg = data[\"data\"][\"comm_captcha_cfg\"]\n    \n    return CaptchaLayout(\n        sess=sess,\n        bg_img_url=dyn[\"bg_elem_cfg\"][\"img_url\"],\n        fg_elem_list=parse_fg_elements(dyn[\"fg_elem_list\"]),\n        pow_cfg=parse_pow_config(comm_cfg.get(\"pow_cfg\")),\n        tdc_path=comm_cfg.get(\"tdc_path\", \"\")\n    )\n</code></pre>\n<p>响应是 JSONP 格式，需要先去除回调函数包裹，然后解析 JSON。响应中最关键的是 sess 字段，这是会话标识，贯穿整个验证流程。dyn_show_info 部分包含了背景图和前景元素的配置信息：</p>\n<pre><code class=\"language-json\">{\n  \"sess\": \"0a1b2c3d4e5f...\",\n  \"data\": {\n    \"dyn_show_info\": {\n      \"bg_elem_cfg\": {\n        \"img_url\": \"/cap_union_new_getcapbysig?image=xxx&amp;sess=xxx\",\n        \"width\": 672,\n        \"height\": 390\n      },\n      \"fg_elem_list\": [\n        {\n          \"id\": 1,\n          \"sprite_pos\": [10, 20],      // 在精灵图中的裁剪位置 (x, y)\n          \"size_2d\": [68, 68],         // 拼图块尺寸 (width, height)\n          \"init_pos\": [30, 161],       // 初始坐标（滑块起点）\n          \"move_cfg\": {\"direction\": 0} // 移动方向（0=水平，1=垂直）\n        }\n      ]\n    },\n    \"comm_captcha_cfg\": {\n      \"pow_cfg\": {\n        \"prefix\": \"1:3FhYxv:\",\n        \"md5\": \"a1b2c3d4e5f6...\"\n      },\n      \"tdc_path\": \"/TDC_1.0.3.js\"\n    }\n  }\n}\n</code></pre>\n<p>fg_elem_list 描述了拼图块在精灵图中的位置和初始坐标。sprite_pos 是裁剪起点，size_2d 是裁剪尺寸，init_pos 是拼图块在背景图上的初始位置。这些信息对于后续的 NCC 模板匹配至关重要。</p>\n<h4 id=\"阶段二图片下载与精灵图裁剪\">阶段二：图片下载与精灵图裁剪</h4>\n<p>背景图和前景精灵图通过同一个接口下载，用 img_index 参数区分。img_index=1 表示背景图，这是一张 672×390 的 RGB PNG 图片，包含了缺口的阴影。img_index=0 表示前景精灵图，这是一张 682×620 的 RGBA PNG 图片，包含了拼图块和滑块按钮。</p>\n<p>前景精灵图是一张 sprite sheet，需要根据 fg_elem_list 中的 sprite_pos 和 size_2d 字段裁剪出拼图块。裁剪逻辑如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef download_images(layout: CaptchaLayout, opener) -&gt; CaptchaImages:\n    \"\"\"下载背景图和前景精灵图，并裁剪出拼图块。\"\"\"\n    # 下载背景图（img_index=1）\n    bg_bytes = _get(opener, layout.bg_img_url)\n    \n    # 下载前景精灵图（img_index=0）\n    # 构造 fg_img_url：与 bg_img_url 同 image/sess，但 img_index=0\n    image_id = _extract_image_id_from_url(layout.bg_img_url)\n    qs = urllib.parse.parse_qs(urllib.parse.urlparse(layout.bg_img_url).query)\n    sess_val = qs.get(\"sess\", [\"\"])[0]\n    fg_img_url = f\"{_BASE}/cap_union_new_getcapbysig?img_index=0&amp;image={image_id}&amp;sess={sess_val}\"\n    fg_bytes = _get(opener, fg_img_url)\n    \n    # 从精灵图中裁剪拼图块\n    fg_img = Image.open(io.BytesIO(fg_bytes))\n    piece = layout.piece_elem\n    px, py = piece.sprite_pos  # 裁剪起点\n    pw, ph = piece.size_2d     # 裁剪尺寸\n    \n    # 裁剪：crop((left, top, right, bottom))\n    piece_img = fg_img.crop((px, py, px + pw, py + ph))\n    \n    return CaptchaImages(\n        bg_bytes=bg_bytes,\n        fg_bytes=fg_bytes,\n        piece_rgba=np.array(piece_img),  # 转为 NumPy 数组供 NCC 使用\n        layout=layout\n    )\n</code></pre>\n<p>裁剪后的拼图块是一张 RGBA 图片，包含透明通道。这个透明通道在后续的 NCC 模板匹配中非常重要，我们会用它作为掩码，只匹配不透明区域。</p>\n<h4 id=\"阶段三verify-答案提交\">阶段三：verify 答案提交</h4>\n<p>verify 提交阶段是最复杂的部分。POST body 需要包含七个字段，每个字段都有严格的格式要求：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef submit_verify(\n    layout: CaptchaLayout,\n    ans: str,\n    pow_answer: str,\n    pow_calc_time: int,\n    *,\n    collect: str,\n    tlg: int,\n    eks: str,\n    opener\n) -&gt; VerifyResult:\n    \"\"\"提交验证答案到 TCaptcha verify 接口。\"\"\"\n    body = {\n        \"ans\": ans,                    # 答案 JSON\n        \"sess\": layout.sess,           # 会话标识\n        \"pow_answer\": pow_answer,      # PoW 答案（prefix+nonce）\n        \"pow_calc_time\": str(pow_calc_time),  # PoW 计算耗时（毫秒）\n        \"collect\": collect,            # tdc.js 生成的设备指纹+轨迹\n        \"tlg\": str(tlg),               # 滑动总耗时（毫秒）\n        \"eks\": eks,                    # tdc.js 内嵌的加密签名\n    }\n    \n    url = f\"{_BASE}/cap_union_new_verify\"\n    response = _post(opener, url, urllib.parse.urlencode(body))\n    data = json.loads(response.decode(\"utf-8\"))\n    \n    return VerifyResult(\n        ok=(data.get(\"errorCode\") == 0),\n        ticket=data.get(\"ticket\", \"\"),\n        randstr=data.get(\"randstr\", \"\"),\n        error_code=data.get(\"errorCode\"),\n        error_msg=data.get(\"errMsg\", \"\")\n    )\n</code></pre>\n<p>ans 字段的格式是一个 JSON 数组，包含 elem_id、type 和 data 三个字段：</p>\n<pre><code class=\"language-python\">def build_ans(elem_id: int, target_x: int, target_y: int) -&gt; str:\n    \"\"\"构造 verify 请求的 ans 字段。\"\"\"\n    ans = [\n        {\n            \"elem_id\": elem_id,              # 元素 ID（从 fg_elem_list 获取）\n            \"type\": \"DynAnswerType_POS\",     # 答案类型（位置）\n            \"data\": f\"{target_x},{target_y}\" # 目标坐标（逗号分隔）\n        }\n    ]\n    return json.dumps(ans, separators=(\",\", \":\"))\n</code></pre>\n<p>这七个字段缺一不可，任何一个字段的错误都会导致验证失败。其中 ans 需要精确计算拼图块的目标坐标（误差 &gt; 5px 会失败），pow_answer 需要暴力搜索 MD5 碰撞，collect 和 eks 由混淆的 tdc.js 生成，无法直接模拟。接下来我们将逐一攻克这些难点。</p>\n<h3 id=\"32-核心算法ncc-模板匹配求解滑块位移\">3.2 核心算法：NCC 模板匹配求解滑块位移</h3>\n<p>滑块验证码的本质问题是：给定背景图（含缺口）和拼图块，求出拼图块需要水平移动多少像素才能填入缺口。这个问题看似简单，但要达到亚像素级的精度并不容易。</p>\n<h4 id=\"方案选型ncc-vs-深度学习\">方案选型：NCC vs 深度学习</h4>\n<p>在方案选型阶段，我们面临两个选择：深度学习模型或传统的模板匹配算法。深度学习模型的优势是泛化能力强，可以处理各种变形和噪声，但需要大量标注样本进行训练，还需要 GPU 进行推理。更重要的是，深度学习模型的精度通常在 2-5 像素左右，这对于 TCaptcha 这种要求精确匹配的场景来说可能不够。</p>\n<p>相比之下，NCC（归一化互相关）模板匹配算法虽然对图片变化敏感，但在 TCaptcha 这种图片质量稳定、缺口形状规则的场景下，可以达到亚像素级的精度。而且 NCC 算法无需训练，只需要 CPU 就能运行，单次求解耗时约 0.3 秒，非常适合服务端部署。我们选择 NCC 的原因是：TCaptcha 的图片质量稳定（固定分辨率 672×390、无噪声干扰）、缺口形状规则（标准拼图块）、NCC 是像素级精确匹配而深度学习是特征级近似匹配。</p>\n<h4 id=\"ncc-算法原理\">NCC 算法原理</h4>\n<p>NCC 算法的核心思路是在背景图上滑动拼图块，计算每个位置的相似度，找到相似度最大的位置。相似度的计算公式是归一化互相关系数：</p>\n<pre><code>NCC(x, y) = Σ[(T - T̄) · (I - Ī)] / √[Σ(T - T̄)² · Σ(I - Ī)²]\n</code></pre>\n<p>其中 T 是模板（拼图块）的像素值，I 是背景图在 (x, y) 位置的区域像素值，T̄ 和 Ī 分别是均值。NCC 的值域是 [-1, 1]，越接近 1 表示越相似。这个公式的本质是计算两个向量的余弦相似度，归一化后不受亮度变化的影响。</p>\n<h4 id=\"实现细节alpha-通道掩码\">实现细节：Alpha 通道掩码</h4>\n<p>在实现过程中，我们遇到的第一个问题是拼图块是 RGBA 图片，包含透明区域。如果直接用所有像素参与匹配，透明区域会干扰结果。解决方案是使用 Alpha 通道作为掩码，只让不透明区域（alpha &gt; 128）参与匹配：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/solver.py\n\ndef _ncc_match(self, bg_arr: np.ndarray, piece_rgba: np.ndarray, \n               init_y: int, pw: int, ph: int) -&gt; Tuple[int, float]:\n    \"\"\"使用 NCC 模板匹配找到拼图块在背景图中的位置。\n    \n    Args:\n        bg_arr: 背景图 NumPy 数组 (H, W, 3)\n        piece_rgba: 拼图块 NumPy 数组 (ph, pw, 4)\n        init_y: 初始 Y 坐标（prehandle 给出）\n        pw, ph: 拼图块宽度和高度\n    \n    Returns:\n        (best_x, best_ncc): 最佳 X 坐标和对应的 NCC 系数\n    \"\"\"\n    # 提取 RGB 和 Alpha 通道\n    piece_rgb = piece_rgba[:, :, :3].astype(np.float32)\n    piece_alpha = piece_rgba[:, :, 3]\n    \n    # 创建掩码：只匹配不透明区域\n    mask = piece_alpha &gt; 128\n    \n    if mask.sum() &lt; 100:  # 不透明像素太少，无法匹配\n        return 0, -1.0\n    \n    # 只提取不透明区域的像素值\n    piece_flat = piece_rgb[mask]\n    piece_centered = piece_flat - piece_flat.mean()\n    piece_norm = float(np.sqrt((piece_centered**2).sum())) + 1e-8\n    \n    bg_f32 = bg_arr[:, :, :3].astype(np.float32)\n    \n    # 两阶段搜索...\n</code></pre>\n<p>这个掩码机制非常关键。拼图块的透明区域在背景图上对应的是任意内容，如果参与匹配会引入大量噪声。通过 Alpha 通道掩码，我们只匹配拼图块的实际形状，大大提高了匹配精度。</p>\n<h4 id=\"性能优化两阶段搜索\">性能优化：两阶段搜索</h4>\n<p>如果对背景图的每个像素都计算一次 NCC，672×390 的图片需要计算 262,080 次，耗时会达到 250 秒。我们采用了两阶段搜索策略：</p>\n<pre><code class=\"language-python\">    # 阶段一：粗搜，stride=4，只在 init_y 行扫描\n    y_min = max(0, init_y - self.y_search_range)\n    y_max = min(bg_arr.shape[0] - ph, init_y + self.y_search_range)\n    x_max = bg_arr.shape[1] - pw\n    \n    coarse_best_x = 0\n    coarse_best_ncc = -2.0\n    \n    for x in range(0, x_max, 4):  # 每隔 4 像素采样一次\n        region_vals = bg_f32[init_y:init_y+ph, x:x+pw][mask]\n        rc = region_vals - region_vals.mean()\n        rn = float(np.sqrt((rc**2).sum())) + 1e-8\n        ncc = float((piece_centered * rc).sum() / (piece_norm * rn))\n        \n        if ncc &gt; coarse_best_ncc:\n            coarse_best_ncc = ncc\n            coarse_best_x = x\n    \n    # 阶段二：精搜，在粗搜结果 ±6px，y 方向 ±5px\n    fine_x_min = max(0, coarse_best_x - 6)\n    fine_x_max = min(x_max, coarse_best_x + 7)\n    \n    best_x = 0\n    best_ncc = -2.0\n    \n    for y in range(y_min, y_max + 1):\n        for x in range(fine_x_min, fine_x_max):\n            region_vals = bg_f32[y:y+ph, x:x+pw][mask]\n            rc = region_vals - region_vals.mean()\n            rn = float(np.sqrt((rc**2).sum())) + 1e-8\n            ncc = float((piece_centered * rc).sum() / (piece_norm * rn))\n            \n            if ncc &gt; best_ncc:\n                best_ncc = ncc\n                best_x = x\n    \n    return best_x, best_ncc\n</code></pre>\n<p>第一阶段粗搜以 stride=4 的步长在 init_y 行上扫描，快速定位大致位置。计算量为 672/4 = 168 次。第二阶段精搜在粗搜结果的 ±6 像素范围内逐像素搜索，同时在 Y 方向也搜索 ±5 像素范围（因为 prehandle 给出的 init_y 可能有微小偏移）。计算量为 13×11 = 143 次。总计算量从 262,080 次降低到 311 次，性能提升了 842 倍，实际耗时从 250 秒降低到 0.3 秒。</p>\n<h4 id=\"测试结果\">测试结果</h4>\n<p>在 20 个真实 TCaptcha 样本上测试，平均绝对误差（MAE）为 0.10 像素，最大误差为 0.5 像素。这个精度已经远超人类手动操作（人类误差通常在 3-5 像素），足以通过 TCaptcha 的校验。误差主要来源于缺口边缘的抗锯齿效果、JPEG 压缩导致的像素值微小变化，以及拼图块与缺口的轻微形状差异。</p>\n<p>完整的求解流程封装在 SliderSolver 类中：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/solver.py\n\nclass SliderSolver:\n    \"\"\"基于 NCC 模板匹配的滑块验证码求解器。\"\"\"\n    \n    def __init__(self, *, y_search_range: int = 5):\n        self.y_search_range = y_search_range\n    \n    def solve(self, images: CaptchaImages) -&gt; SolveResult:\n        \"\"\"求解滑块验证码，返回位移和置信度。\"\"\"\n        bg = np.array(Image.open(io.BytesIO(images.bg_bytes)).convert(\"RGB\"))\n        piece = images.piece_rgba\n        \n        piece_elem = images.layout.piece_elem\n        init_x, init_y = piece_elem.init_pos\n        pw, ph = piece_elem.size_2d\n        \n        # NCC 模板匹配\n        gap_x, ncc = self._ncc_match(bg, piece, init_y, pw, ph)\n        dx = gap_x - init_x  # 需要移动的像素数\n        \n        return SolveResult(\n            dx=dx,\n            gap_x=gap_x,\n            gap_y=init_y,\n            confidence=ncc,\n            piece_init_x=init_x,\n            piece_init_y=init_y\n        )\n</code></pre>\n<p>使用时只需创建 SliderSolver 实例，调用 solve 方法即可获得位移 dx 和置信度 confidence。</p>\n<h3 id=\"33-powproof-of-work求解\">3.3 PoW（Proof of Work）求解</h3>\n<p>TCaptcha 要求客户端完成一个 MD5 工作量证明挑战，用于防止暴力破解和机器人攻击。prehandle 响应中包含 pow_cfg 字段，包含一个 prefix 和一个 target_md5。客户端需要找到一个 nonce，使得 <code>MD5(prefix + nonce)</code>​ 等于 target_md5。例如，如果 prefix 是 \"1:3FhYxv:\"，target_md5 是 \"a1b2c3d4e5f6...\"，那么我们需要找到一个数字 nonce，使得 <code>MD5(\"1:3FhYxv:42857\")</code> 等于目标哈希值。</p>\n<p>实现上采用简单的暴力搜索，从 0 开始递增 nonce，每次计算 MD5 哈希并与目标值比较。为了避免无限循环，我们设置了最大搜索次数为 100 万次。实际测试中，我们对 100 次真实请求进行了统计，发现平均 nonce 值为 347，最大 nonce 值为 1823，平均耗时 0.8 毫秒，最大耗时 4.2 毫秒。这说明 TCaptcha 的 PoW 难度设置得很低，nonce 通常在几百以内就能找到，对整体性能影响可以忽略不计。这也说明 PoW 主要是象征性的防护，TCaptcha 真正的防御重点在设备指纹和行为轨迹。</p>\n<h3 id=\"34-tdcjs-逆向设备指纹与轨迹仿真\">3.4 TDC.js 逆向：设备指纹与轨迹仿真</h3>\n<p>这是整个项目最困难的部分。verify 请求中的 collect 和 eks 字段由腾讯的 tdc.js 生成，这是一个经过深度混淆的字节码虚拟机，内部标识为 <code>__TENCENT_CHAOS_VM</code>。TDC 是 Tencent Device Collection 的缩写，负责采集三类数据。</p>\n<p>第一类是设备指纹，包括浏览器特征（User-Agent、屏幕分辨率、颜色深度、时区）、Canvas 指纹（绘制特定图形后的像素哈希）、WebGL 指纹（GPU 渲染器信息）、字体列表、插件列表、音频上下文指纹等。这些信息组合起来可以唯一标识一个设备，即使用户清除 Cookie 也无法改变。</p>\n<p>第二类是行为轨迹，包括滑动轨迹坐标序列（x 坐标随时间变化）、鼠标移动速度和加速度、滑动总耗时等。这些数据用于判断用户是否是真人操作，机器人的轨迹通常过于规则或过于随机。</p>\n<p>第三类是加密签名，eks 字段是 tdc.js 内嵌的密钥签名，用于验证 tdc.js 的完整性，防止客户端篡改或伪造 collect 数据。</p>\n<p>我们尝试在 Python 中模拟 tdc.js 的输出，但很快发现这几乎不可能。tdc.js 使用自定义字节码虚拟机执行，逆向成本极高，估计需要 2-3 周时间。而且 tdc.js 的路径和版本号会变化，每次更新都需要重新逆向。tdc.js 还会检测 window、document、navigator 等浏览器对象，如果环境不对会拒绝执行。最困难的是 Canvas 指纹，需要真实的 Canvas API 才能生成正确的指纹，纯 Python 无法模拟。</p>\n<p>我们的解决方案是在 Node.js 的 jsdom 环境中执行真实的 tdc.js。jsdom 是一个纯 JavaScript 实现的 DOM 和 HTML 标准，可以在 Node.js 中模拟浏览器环境。我们的架构是 Python 主程序通过 subprocess 调用 Node.js 执行 tdc_executor.js，tdc_executor.js 在 jsdom 中加载并执行 tdc.js，最后将 collect 和 eks 返回给 Python。</p>\n<p>在 tdc_executor.js 中，我们首先创建一个虚拟 DOM 环境，设置 URL 为腾讯验证码的域名，User-Agent 设置为标准的 Chrome，pretendToBeVisual 设置为 true 让 jsdom 模拟可视化环境，runScripts 设置为 \"dangerously\" 允许执行动态注入的脚本。然后我们模拟浏览器环境，设置 screen 对象的宽度、高度、颜色深度等属性，设置 innerWidth、innerHeight、devicePixelRatio 等全局变量。接着我们创建一个 script 元素，将 tdc.js 的代码注入到 DOM 中。等待 300 毫秒让 tdc.js 初始化完成后，我们调用 TDC.setData 传入滑动轨迹数据，调用 TDC.getData 获取 collect，调用 TDC.getInfo 获取 eks。</p>\n<p>为了让 tdc.js 生成合理的轨迹数据，我们实现了一个 ease-in-out cubic 的仿真轨迹生成器，模拟人类滑动的加速-匀速-减速过程。如果用户没有指定滑动耗时，我们随机生成 800-2000 毫秒，这是人类滑动的正常范围。然后我们根据耗时计算采样点数量，每 30 毫秒采样一次。对于每个采样点，我们用 ease-in-out cubic 缓动函数计算当前进度，前半段使用 <code>4 * t³</code>​ 实现加速，后半段使用 <code>1 - ((-2t + 2)³) / 2</code> 实现减速。为了模拟手部微颤，我们在 10%-90% 的时间段内添加 ±1 像素的随机抖动。最后确保最后一个点精确到达目标位置。</p>\n<p>这种方案的优势是无需逆向 tdc.js，直接执行原始代码，避免了混淆虚拟机的逆向成本。而且 tdc.js 更新后无需修改代码，自动适配新版本。jsdom 提供的浏览器环境足够真实，能通过 tdc.js 的检测。潜在风险是 tdc.js 可能检测 jsdom 特有的属性（如 navigator.webdriver），或者检测 Canvas 指纹的统计学异常。但实测结果显示，目前 TCaptcha 未检测 jsdom 环境，通过率 100%。</p>\n<h3 id=\"35-端到端自动化流程\">3.5 端到端自动化流程</h3>\n<p>所有组件组装在 automation.py 中，形成完整的验证码破解流水线。整个流程从调用 solve_captcha 函数开始，这个函数接受 TCaptcha APP_ID 和最大重试次数作为参数。函数内部创建一个 SliderSolver 实例用于 NCC 计算，然后进入重试循环。</p>\n<p>每次循环首先调用 fetch_challenge 获取验证码图片和配置信息，这个函数内部会调用 prehandle 初始化会话，然后下载背景图和前景精灵图。获取到图片后，我们调用 solver.solve 进行 NCC 模板匹配，计算出拼图块需要移动的像素数 dx。根据 dx 和拼图块的初始坐标，我们可以计算出目标坐标 target_x 和 target_y。</p>\n<p>接下来调用 solve_pow 求解工作量证明，这个函数会暴力搜索 MD5 碰撞，返回 pow_answer 和计算耗时 pow_calc_time。然后调用 build_ans 构造答案 JSON，格式为包含 elem_id、type 和 data 的数组。</p>\n<p>最关键的一步是调用 get_tdc_data 生成设备指纹和轨迹数据。这个函数内部会先调用 generate_slide_trajectory 生成仿真轨迹，然后通过 subprocess 调用 Node.js 执行 tdc_executor.js，在 jsdom 环境中运行 tdc.js，最后返回 collect、eks 和 tlg。</p>\n<p>最后调用 submit_verify 提交所有数据到 TCaptcha 服务器。如果 verify 响应的 ok 字段为 true，说明验证通过，我们返回包含 ticket 和 randstr 的成功结果。如果失败，进入下一次重试循环，subsid 参数会递增，TCaptcha 会返回新的验证码图片。</p>\n<p>整个流程的时序是：prehandle 耗时约 0.5 秒，下载图片耗时约 0.3 秒，NCC 求解耗时约 0.3 秒，PoW 求解耗时不到 1 毫秒，生成轨迹和 TDC 执行耗时约 0.5 秒，verify 提交耗时约 0.3 秒。总耗时约 5.6 秒，其中网络请求占 1.1 秒，算法计算占 0.8 秒，TDC 执行占 0.5 秒。在 5 次实时测试中，通过率达到 100%，没有一次失败。</p>\n<h2 id=\"四工程化实现与架构设计\">四、工程化实现与架构设计</h2>\n<h3 id=\"41-项目架构\">4.1 项目架构</h3>\n<p>整个项目采用模块化设计，核心验证码模块位于 fenbi_auth/captcha 目录下。tcaptcha_client.py 负责 TCaptcha 协议的实现，包括 prehandle 会话初始化、download_images 图片下载与解析、solve_pow 工作量证明求解、submit_verify 答案提交等功能。solver.py 实现了 NCC 两阶段模板匹配求解器，这是整个系统的核心算法。tdc_executor.py 是 Python 到 Node.js 的桥接层，负责调用 tdc_executor.js 执行 tdc.js，同时包含轨迹生成算法。automation.py 是对外的统一入口，提供 solve_captcha 函数封装整个验证码破解流程。</p>\n<p>工具层包含 tdc_executor.js，这是一个 Node.js 脚本，使用 jsdom 创建虚拟浏览器环境来执行腾讯的 tdc.js。业务层包含 fenbi_login.py，实现了粉笔登录服务，包括发送短信验证码、提交验证码凭证、快速登录等功能。工具类包含 rsa_encrypt.py，实现了纯 Python 的 RSA/PKCS#1 v1.5 加密，用于生成 info 字段。http_client.py 提供了无依赖的 HTTP 客户端，支持 cookiejar 管理。</p>\n<h3 id=\"42-设计原则\">4.2 设计原则</h3>\n<p>传统的验证码自动化方案通常依赖 Selenium 或 Playwright 驱动真实浏览器，但这种方案存在明显的问题。每个浏览器实例占用 200-500MB 内存，冷启动需要 3-5 秒，而且 navigator.webdriver 等特征容易被检测，单机并发数通常小于 10。我们的方案是纯 HTTP 协议模拟，使用 Python 标准库 urllib 实现 HTTP 客户端，完全不依赖浏览器。只在必要时（tdc.js 执行）调用 Node.js 加 jsdom，单次验证码求解只需 30MB 内存，支持单机 100 以上的并发。</p>\n<p>模块化设计是另一个重要原则。协议层只负责 HTTP 通信，调用 tcaptcha_client.prehandle 返回 CaptchaLayout 对象。算法层只负责图像处理，调用 solver.solve 返回 SolveResult 对象，包含 dx 和 confidence。执行层只负责 tdc.js 调用，调用 tdc_executor.get_tdc_data 返回包含 collect 和 eks 的字典。编排层组装所有组件，调用 automation.solve_captcha 返回 CaptchaPassResult 对象，包含 ok、ticket 和 randstr。这种设计使得每个模块职责单一，便于测试和维护。</p>\n<p>核心验证码模块只依赖 numpy 用于 NCC 计算，Pillow 用于图片解析，Node.js 加 jsdom 用于 tdc.js 执行。我们不依赖 TensorFlow 或 PyTorch 等深度学习框架，不依赖 OpenCV 图像处理库，不依赖 Selenium 或 Playwright 浏览器自动化工具，也不依赖任何第三方验证码识别服务。这使得项目部署简单，依赖少，维护成本低。</p>\n<h3 id=\"43-使用示例\">4.3 使用示例</h3>\n<p>如果只需要验证码破解功能，可以单独使用验证码模块。导入 solve_captcha 函数，传入 TCaptcha APP_ID，函数会自动完成整个验证码破解流程，返回包含 ticket 和 randstr 的结果对象。如果 result.ok 为 true，说明验证通过，可以从 result.ticket 和 result.randstr 获取凭证。如果为 false，可以从 result.error 获取错误信息。</p>\n<p>如果需要集成到登录流程，可以结合 FenbiLoginService 使用。首先创建 CookieHttpClient 和 FenbiLoginService 实例，然后调用 send_sms_code 发送短信验证码。如果返回的 r1.ok 为 false 且 r1.context_id 存在，说明触发了风控。此时调用 solve_captcha 自动过验证码，如果 cap.ok 为 true，调用 captcha_check 提交 ticket 和 randstr 放行风控，然后带着 context_id 重试发送短信。最后输入短信验证码调用 quicklogin 完成登录。</p>\n<h2 id=\"五技术总结与反思\">五、技术总结与反思</h2>\n<h3 id=\"51-关键数据\">5.1 关键数据</h3>\n<p>在 20 个真实 TCaptcha 样本上测试 NCC 求解精度，平均绝对误差为 0.10 像素，最大误差为 0.5 像素。在 5 次实时请求中，验证码通过率达到 100%，没有一次失败。单次求解总耗时约 5.6 秒，其中 NCC 计算耗时 0.3 秒，PoW 求解耗时小于 1 毫秒，TDC 执行耗时 0.5 秒。内存占用方面，单次验证码求解峰值为 30 MB，远低于浏览器自动化方案的 200-500 MB。外部依赖只有 numpy、Pillow 和 Node.js，核心模块完全不依赖深度学习框架。</p>\n<h3 id=\"52-技术亮点\">5.2 技术亮点</h3>\n<p>NCC 算法在滑块验证码场景下展现出了相比深度学习的优越性。在精度对比上，NCC 达到了 0.10 像素的平均绝对误差，这是亚像素级的精度，而深度学习模型通常只能达到 2-5 像素的精度。这是因为 TCaptcha 的图片质量稳定，分辨率固定，没有噪声干扰，缺口形状规则，是标准的拼图块。在这种场景下，NCC 是像素级的精确匹配，而深度学习是特征级的近似匹配，前者天然具有精度优势。当然，如果图片变化大、需要泛化能力，深度学习会更有优势，但对于 TCaptcha 这种特定场景，NCC 是最优选择。</p>\n<p>jsdom 执行 tdc.js 的方案体现了工程上的巧妙性。直接逆向 tdc.js 的混淆虚拟机成本极高，估计需要 2-3 周时间，而 jsdom 方案只需 1 天即可实现。关键洞察是 tdc.js 的目的是采集设备指纹，而非实现加密算法，jsdom 提供的浏览器环境足够真实，能通过大部分检测。即使 tdc.js 更新版本，也无需修改代码，自动适配新版本。当然，潜在风险是 jsdom 的 Canvas 指纹与真实浏览器有细微差异，未来 TCaptcha 可能增加 jsdom 特征检测。应对策略是定期监控通过率，一旦下降立即分析原因，准备 Plan B 使用 Puppeteer 在真实浏览器中执行 tdc.js。</p>\n<p>两阶段搜索的性能优化将计算量从 O(W×H) 降低到 O(W/4 + 13×11)。全图搜索需要 672×390 等于 262,080 次 NCC 计算，而两阶段搜索只需要 672 除以 4 加上 13×11，等于 168 加 143，总共 311 次 NCC 计算。性能提升了 262,080 除以 311，约等于 842 倍。实际耗时从理论上的 250 秒降低到 0.3 秒，这使得 NCC 算法在实时场景下完全可用。</p>\n<h3 id=\"53-反检测技术\">5.3 反检测技术</h3>\n<p>TCaptcha 的检测维度包括设备指纹、滑动轨迹、滑动耗时、PoW 计算时间、答案精度、HTTP 请求特征等多个方面。我们的应对策略是：设备指纹方面，使用 jsdom 模拟真实浏览器环境，目前已通过检测。滑动轨迹方面，使用 ease-in-out cubic 缓动函数加微抖动，模拟人类滑动的加速-匀速-减速过程，目前已通过检测。滑动耗时方面，随机生成 800-2000 毫秒，符合人类滑动的正常范围，目前已通过检测。PoW 计算时间方面，真实计算不伪造，目前已通过检测。答案精度方面，NCC 达到亚像素级精度，远超人类水平，目前已通过检测。HTTP 请求特征方面，完全模拟浏览器 Headers，目前已通过检测。</p>\n<p>未来可能的检测点包括 jsdom 特有的 navigator 属性、Canvas 指纹的统计学异常、高频请求的 IP 封禁等。对于 jsdom 特征检测，我们可以在 jsdom 环境中删除或修改特有属性。对于 Canvas 指纹异常，我们可以收集真实浏览器的 Canvas 指纹，在 jsdom 中伪造相同的指纹。对于 IP 封禁，我们可以使用代理池分散请求。</p>\n<h3 id=\"54-局限性与改进方向\">5.4 局限性与改进方向</h3>\n<p>当前方案的局限性主要有三点。第一是依赖 Node.js，tdc.js 执行需要 Node.js 环境，增加了部署复杂度。第二是单线程 NCC，未使用多核并行计算，有优化空间。第三是固定 APP_ID，只测试了粉笔的 TCaptcha，其他业务方可能有差异。</p>\n<p>改进方向包括纯 Python 实现 tdc.js、GPU 加速 NCC、深度学习混合方案等。纯 Python 实现 tdc.js 需要逆向 <code>__TENCENT_CHAOS_VM</code> 字节码格式，用 Python 实现 VM 解释器，难度极高，但可彻底去除 Node.js 依赖。GPU 加速 NCC 可以使用 CuPy 或 PyTorch 实现 NCC，理论上可将耗时从 0.3 秒降低到 0.05 秒，但需要 GPU 环境，不适合服务端部署。深度学习混合方案可以用 CNN 粗定位缺口区域降低搜索范围，用 NCC 精确计算位移保证精度，可能将耗时降低到 0.1 秒。</p>\n<h3 id=\"55-伦理与法律声明\">5.5 伦理与法律声明</h3>\n<p>本项目仅用于技术研究和学习目的，展示了验证码逆向工程的完整技术链路。请勿将本技术用于任何非法用途，如批量注册、刷单、爬虫等。验证码是网站的安全防护措施，绕过验证码可能违反服务条款。使用本技术造成的任何法律后果由使用者自行承担。合法使用场景包括自动化测试（测试自己的网站）、辅助功能（帮助视障用户）、学术研究（验证码安全性分析）等。</p>\n<h2 id=\"六结语\">六、结语</h2>\n<p>本项目从零开始，完整实现了对腾讯 TCaptcha 滑块验证码的自动化破解，涉及的技术栈包括协议逆向（HAR 分析、JSONP 解析、HTTP 协议模拟）、密码学（RSA/PKCS#1 v1.5 加密、MD5 PoW）、图像处理（NCC 模板匹配、Alpha 通道掩码、两阶段搜索）、JavaScript 逆向（tdc.js 混淆 VM、jsdom 沙箱执行）、算法设计（ease-in-out cubic 轨迹仿真、微抖动模拟）等多个领域。</p>\n<p>最终实现了 100% 通过率、5.6 秒求解、零深度学习依赖的工程化方案。这个项目证明了在特定场景下，传统算法（NCC）加工程技巧（jsdom）可以达到甚至超越深度学习的效果。希望本文能为验证码逆向、图像处理、反爬虫对抗等领域的研究者提供参考。</p>\n<p>‍</p>\n\n\n</div>\n<div id=\"MySignature\">\n    每天好一点点\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/han5562877\">嚯嚯歪</a>&nbsp;\n阅读(<span id=\"post_view_count\">22</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Linux下GNU Autotools工具基础教程",
      "link": "https://www.cnblogs.com/ttkwzyttk/p/19621799",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ttkwzyttk/p/19621799\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:24\">\n    <span>Linux下GNU Autotools工具基础教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本博客介绍了Linux下GNU Autotools工具的基础用法，涵盖了autoconf、automake等工具的功能及作用。通过实例演示，讲解了如何使用autoconf生成配置脚本，以及如何通过automake和Makefile.am定制构建过程。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>对于我们平时写的小的测试Demo程序，可能自己手动编写一个<code>Makefile</code>文件就可以编译整个项目了，但是对于一些大型的工程，包含多个源码文件夹、头文件文件夹、库文件文件夹，如果我们每个源码文件的<code>Makefile</code>文件都自己去编写会非常繁琐，所以这时候需要一些自动化工具来帮助我们简化项目的构建，这里比较主流的有两种工具一个是GNU下的Autotools工具，一个是CMake工具。</p>\n<p>Autotools工具是一些版本比较老的工具了，遗留了很多问题，包括他的语法复杂(m4宏语言)，涉及的工具种类太多，生成的<code>configure</code>脚本非常庞大等问题，在2000年后出现的新一代构建系统包括CMake、Meson、Ninja等能够有效解决Autotools的历史疑难杂症，并且语法更加现代化、生成速度更快。那我们为什么还要学习了解Autotools呢？因为历史原因，早年很多的开源软件都是使用的Autotools来构建的，并且Autotools目前在GNU体系中还是大量使用，并且在嵌入式Linux中非常常见，而且在一些老牌的C项目中也非常常见，所以还是非常有必要了解Autotools。</p>\n<p>这里给出官方的Autotools的文档连接 <a href=\"https://www.gnu.org/software/autoconf/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/software/autoconf/</a></p>\n<h1 id=\"一autotools工具详细介绍\">一、Autotools工具详细介绍</h1>\n<h2 id=\"11-autotools工具组成\">1.1 Autotools工具组成</h2>\n<p>GNU Autotools并不是一个工具，而是由一系列的工具合集组成，在现如今的Linux发行版中，大概率是自带这些工具的，如果没有可以自行下载</p>\n<ul>\n<li><code>autoscan</code>：这个工具主要是用来扫描查找源代码目录下的源文件用来生成<code>configure.scan</code>文件。<code>configure.scan</code>文件是自动生成的模板，里面包含了一些系统配置的基本选项都是一些宏定义，这些宏通过<code>autoconf</code>工具处理后会变成检查系统特性、环境变量的shell脚本，我们可以根据这个模板修改，最后将<code>configure.scan</code>重新命名为<code>configure.ac</code>文件</li>\n<li><code>aclocal</code>：这个工具是一个<code>perl</code>脚本程序，他主要用来根据上一步的<code>configure.ac</code>文件的内容，自动生成<code>aclocal.m4</code>文件</li>\n<li><code>autoconf</code>：这个工具会使用<code>configure.ac</code>文件来生成名称为<code>configure</code>的shell脚本文件用来检查系统特性与环境变量，运行这个脚本文件之后，就会生成<code>Makefile</code>文件，之后我们就可以执行<code>make</code>和<code>make install</code>命令了</li>\n<li><code>autoheader</code>：这个工具主要是用来自动生成<code>config.h.in</code>文件的，当我们执行了<code>./configure</code>之后，会生成一个<code>config.h</code>文件，在调用<code>autoheader</code>工具之后，就会生成<code>config.h.in</code>文件</li>\n<li><code>automake</code>：使用<code>automake</code>来产生<code>Makefile.in</code>文件，需要注意的是<code>Makefile.in</code>是由<code>Makefile.am</code>生成的这个需要我们手动来编写</li>\n</ul>\n<p>这里可以注意到，最后工具用到的文件都是以<code>.in</code>结尾的文件，这些文件相当于我们最后需要的目标文件的输入文件</p>\n<h2 id=\"12-configure脚本制作流程\">1.2 <code>configure</code>脚本制作流程</h2>\n<p>这块内容可以参考 <a href=\"https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html</a> 文档的第三章内容，详细阐述了<code>configure</code>脚本的制作流程，下面简单介绍一下，以下图流程图中，带<code>*</code>的是执行的命令，带<code>[]</code>的表示可选项</p>\n<p><img alt=\"Pasted image 20260216122316.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209097-1180976358.png\" /><br />\n首先根据文档中的这个流程图，可以看见用我们的源文件，通过<code>autoscan</code>命令生成<code>configure.scan</code>文件，然后我们再修改这个模板，生成我们的<code>configure.ac</code>文件，在通过<code>autoconf</code>命令生成<code>configure</code>脚本的时候，<code>aclocal.m4</code>和<code>acsite.m4</code>这两个文件为可选项，如果我们后续需要使用<code>automake</code>工具，那么还需要在执行<code>autoconf</code>前使用<code>aclocal</code>工具生成<code>aclocal.m4</code>文件</p>\n<p>在执行<code>autoconf</code>命令的同时，我们可以选择使用<code>autoheader</code>来生成<code>config.h.in</code>文件。这个文件的作用是为 configure 提供一个模板，告诉它哪些宏需要根据系统环境进行检测，从而生成最终的<code>config.h</code>文件，供代码在条件编译中使用，后需会详细讲解这部分内容。</p>\n<p>如果我们还需要使用<code>automake</code>工具来生成<code>Makefile.in</code>文件，那么需要在<code>autoscan</code>生成了<code>configure.ac</code>文件之后追加以下的流程<br />\n<img alt=\"Pasted image 20260216132616.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209304-1030423812.png\" /><br />\n第一步，我们需要使用<code>aclocal</code>命令来生成<code>aclocal.m4</code>文件，有了这个文件之后，我们在生成<code>configure</code>的时候会使用到这个文件，然后第二步我们需要自己编写一个<code>Makefile.am</code>文件，然后执行<code>automake</code>命令来生成<code>Makefile.in</code></p>\n<p>做完上述两个流程之后，我们就可以得到两个关键文件了一个是<code>configure</code>脚本文件，一个是<code>Makefile.in</code>模板文件，在通过以下流程，生成最后的<code>Makefile</code>文件<br />\n<img alt=\"Pasted image 20260216133225.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209082-1911362763.png\" /><br />\n直接执行<code>configure</code>脚本文件，脚本会去找<code>config.h.in</code>和<code>Makefile.in</code>文件进行文件生成，最后生成<code>config.h</code>和<code>Makefile</code>文件，之后我们就可以执行<code>make</code>命令来编译工程了</p>\n<p>可能这里三个图的关系比较混乱，后面会通过一个工程上的实例，来具体演示<code>Autotools</code>的使用以及流程</p>\n<h2 id=\"13-autoheader工具与confighin文件\">1.3 <code>autoheader</code>工具与<code>config.h.in</code>文件</h2>\n<p>前面我们提到了使用<code>autoconf</code>生成<code>configure</code>的同时，可以使用<code>autoheader</code>来生成<code>config.h.in</code>文件，这个文件到底是用来干什么的呢？这一小节详细讲解一下。</p>\n<p>例如，现在有一个场景：我们的应用代码需要跨平台，在 Linux 环境下，会使用到 <code>&lt;unistd.h&gt;</code> 头文件。不同系统可能是否存在这个头文件不同，因此我们希望通过自动化的方式进行检测和适配。我们需要先在<code>configure.ac</code>文件中添加配置项</p>\n<pre><code>AC_INIT([example], [1.0])\nAC_CONFIG_HEADERS([config.h])\nAC_CHECK_HEADERS([unistd.h])\nAC_OUTPUT\n</code></pre>\n<ul>\n<li><code>AC_CONFIG_HEADERS([config.h])</code>：告诉 Autotools 最终需要生成 <code>config.h</code> 文件</li>\n<li><code>AC_CHECK_HEADERS([unistd.h])</code>：告知 Autotools 需要检测系统是否有 <code>&lt;unistd.h&gt;</code>，并生成相应宏 <code>HAVE_UNISTD_H</code></li>\n</ul>\n<p>当我们在<code>configure.ac</code>中添加了这些选项之后，可以运行<code>autoheader</code>命令来生成<code>config.h.in</code>，这时的模板文件中会有以下这样的记录</p>\n<pre><code>/* Define to 1 if you have the &lt;unistd.h&gt; header file. */\n#undef HAVE_UNISTD_H\n</code></pre>\n<ul>\n<li>注意：<code>#undef HAVE_UNISTD_H</code> 只是占位宏，值还没有确定</li>\n<li>这个宏的名字是由 AC_CHECK_HEADERS 自动生成的</li>\n</ul>\n<p>有了<code>config.h.in</code>文件之后，如果我们运行了<code>./configure</code>后，工具会检测系统中是否有<code>&lt;unistd.h&gt;</code>根据最终结果来生成<code>config.h</code>头文件，如果包含有那么在<code>config.h</code>文件中，就会多出</p>\n<pre><code class=\"language-c\">#define HAVE_UNISTD_H 1\n\n//如果没有该头文件的话\n/* #undef HAVE_UNISTD_H */\n</code></pre>\n<p>后续我们就可以通过包含<code>config.h</code>文件来进行条件编译了，这样代码可以在不同平台上自动适配，而不需要手动修改</p>\n<pre><code class=\"language-c\">#include \"config.h\"\n\n#ifdef HAVE_UNISTD_H\n#include &lt;unistd.h&gt;\n#endif\n\nint main() {\n#ifdef HAVE_UNISTD_H\n    write(1, \"unistd.h exists\\n\", 16);\n#else\n    printf(\"unistd.h not found\\n\");\n#endif\n    return 0;\n}\n</code></pre>\n<p>总结：</p>\n<ul>\n<li><code>config.h.in</code> = <strong>模板文件</strong>，列出待检测的宏</li>\n<li><code>./configure</code> = <strong>系统检测器</strong>，把模板宏填上实际值</li>\n<li><code>config.h</code> = <strong>最终宏定义文件</strong>，代码条件编译使用</li>\n<li>条件编译语句 (<code>#ifdef</code>) 永远需要开发者在代码里自己写</li>\n</ul>\n<h1 id=\"二autotools实例分析\">二、Autotools实例分析</h1>\n<p>这一章节主要是对autotools的具体使用举例。</p>\n<p><strong>第一步</strong>：创建demo工程项目，新建了一个源码文件夹，创建一个c文件，编写了一个简单的代码。<br />\n<img alt=\"Pasted image 20260216140420.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209096-1334942740.png\" /></p>\n<p><strong>第二步</strong>：生成<code>configure.ac</code>文件。在源码路径下执行了<code>autoscan</code>命令之后，可以看见<code>configure.scan</code>文件已经生成出来了<br />\n<img alt=\"Pasted image 20260216141414.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209334-698108259.png\" /><br />\n可以打开这个文件查看，就是一些功能宏定义<br />\n<img alt=\"Pasted image 20260216141527.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209314-113774963.png\" /><br />\n宏解释：</p>\n<ul>\n<li><code>AC_PREREQ()</code>宏声明本文件要求的autoconf版本，本例使用的版本为2.71</li>\n<li><code>AC_INIT()</code>中分别的是: 软件包的名字，版本，作者的联系方式(一般是Email)</li>\n<li><code>AC_CONFIG_SRCDIR</code>宏用来侦测所指定的源码文件是否存在，来确定源码目录的有效性。此处为当前目录下的test.c，如果有多个源文件的话选择一个主要的文件，通常是 <code>main.c</code> 或其他代表源代码位置的文件。</li>\n<li><code>AC_CONFIG_HEADER</code>宏用于生成config.h文件，以便autoheader使用</li>\n<li><code>AC_PROG_CC</code>用来指定编译器，如果不指定，选用默认gcc。 比如: AC_PROG_CC(gcc)</li>\n<li><code>AC_OUTPUT</code>用来设定 configure 所要产生的文件，如果是makefile，configure会把它检查出来的结果带入makefile.in文件产生合适的makefile。使用Automake时，还需要一些其他的参数，这些额外的宏用aclocal工具产生</li>\n</ul>\n<p>这些宏可以直接到 <a href=\"https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html#Making-configure-Scripts\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html#Making-configure-Scripts</a> 官方文档中去查询</p>\n<p>最后修改这个模板文件，填入自己的软件信息，并将<code>configure.scan</code>重命名为<code>configure.ac</code>文件<br />\n<img alt=\"Pasted image 20260216160011.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209315-856118383.png\" /><br />\n这里有几点需要注意，第一就是注意填写好自己软件的信息，第二就是如果我们后续要使用<code>automake</code>工具的话，需要添加一行<code>AM_INIT_AUTOMAKE</code>，并且需要指定构建行为常用的选项为<code>[foreign]</code>如果不指定的话，就是<code>[gnu]</code>严格模式，会检查AUTHORS、NEWS、README、ChangeLog、COPYING、INSTALL等文件，如果缺失的话，后续使用<code>automake</code>就会报错，这是我踩的一个坑，对于现代的项目，大多数使用<code>git</code>代码管理，对于这些文件有一些是不必要的，所以这里可以关闭GNU strict模式，如果你需要使用GNU的严格模式的话，创建这些所需文件就可以解决报错。第三点就是记得添加输出文件列表的宏<code>AC_CONFIG_FILES([文件名])</code>这三点编辑好之后，一个基础的<code>configure.ac</code>就编辑好了</p>\n<p><strong>第三步</strong>：生成<code>aclocal.m4</code>文件，因为我们后续要使用到<code>automake</code>工具，需要依赖<code>aclocal.m4</code>文件，所以这一步通过<code>aclocal</code>来生成<code>aclocal.m4</code>文件<br />\n<img alt=\"Pasted image 20260216144207.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209281-1527369101.png\" /></p>\n<p>可以看见执行了<code>aclocal</code>之后，<code>aclocal.m4</code>文件成功输出了</p>\n<p><strong>第四步</strong>：生成<code>config.h.in</code>文件，因为我们在<code>configure</code>中使用了宏检查，需要输出<code>config.h</code>，所以我们需要先生成<code>config.h.in</code><br />\n<img alt=\"Pasted image 20260216144505.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209256-1503264093.png\" /><br />\n执行<code>autoheader</code>命令之后，<code>config.h.in</code>也成功生成了</p>\n<p><strong>第五步</strong>：生成<code>configure</code>文件，使用<code>autoconf</code>命令得到<code>configure</code>脚本文件<br />\n<img alt=\"Pasted image 20260216145556.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209281-1821923245.png\" /><br />\n如果这时候我们直接运行这个脚本，可以发现，缺少<code>install-sh</code>脚本，这个脚本就是通过<code>automake</code>来生成的<br />\n<img alt=\"Pasted image 20260216145731.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209052-662252426.png\" /></p>\n<p><strong>第六步</strong>：编写<code>Makefile.am</code>文件，执行<code>automake</code>命令。这里只写了一个比较简单的<code>Makefile.am</code>进行测试<br />\n<img alt=\"Pasted image 20260216161303.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209025-2002039184.png\" /><br />\n<code>Makefile.am</code>文件编写规范非常重要，这里指出我踩到的另外一个坑，<code>Makefile.am</code>文件中的这两个宏定义，必须得规范否则也会爆出错误或者警告。</p>\n<p><code>bin_PROGRAMS</code>的含义是生成一个可执行文件 test，并在 <code>make install</code> 时安装到<code>$(bindir)</code>，一般情况下<code>$(bindir) = /usr/local/bin</code><br />\n<code>test_SOURCES</code>的结构为<code>&lt;目标名&gt;_SOURCES</code>目标名必须和<code>bin_PROGRAMS</code>的程序名完全一致，否则 Automake 会报错</p>\n<p>除了<code>bin_PROGRAMS</code>还有其他Automake内部已经定义好的安装目录变量</p>\n<table>\n<thead>\n<tr>\n<th>变量</th>\n<th>安装目录</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bin_PROGRAMS</td>\n<td>$(bindir) → /usr/local/bin</td>\n</tr>\n<tr>\n<td>sbin_PROGRAMS</td>\n<td>$(sbindir)</td>\n</tr>\n<tr>\n<td>libexec_PROGRAMS</td>\n<td>$(libexecdir)</td>\n</tr>\n<tr>\n<td>noinst_PROGRAMS</td>\n<td>不安装，只编译</td>\n</tr>\n<tr>\n<td>check_PROGRAMS</td>\n<td>测试程序</td>\n</tr>\n<tr>\n<td>具体其他宏的功能，大家可以查看官方的文档，这篇文章主要是autotools工具的使用，这里就不深入剖析底层了</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>还有一个需要注意的点是，如果我们这时候直接使用<code>automake</code>命令，会提示报错，工具也对我们继续了提示需要加上<code>--add-missing</code>选项，添加选项--add-missing 可以让automake工具自动添加必要的脚本文件，这里也可以看见如果<code>AM_INIT_AUTOMAKE</code>没有关闭GNU的严格模式，会报出缺失必要文件的错误。这里是因为这张图是没有修改的时候截取的，修改之后我没有重新<code>automake</code><br />\n<img alt=\"Pasted image 20260216150528.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209349-1310847039.png\" /><br />\n加上该选项，并修改了<code>AM_INIT_AUTOMAKE</code>之后，再次执行<code>automake</code>命令执行成功，并成功生成<code>Makefile.in</code>文件和<code>install-sh</code>文件<br />\n<img alt=\"Pasted image 20260216151252.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209051-539778253.png\" /></p>\n<p><strong>第七步</strong>：执行<code>configure</code>脚本，更具<code>Makfile.in</code>、<code>config.h.in</code>生成最后的文件。<br />\n<img alt=\"Pasted image 20260216163034.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209360-2035713464.png\" /><br />\n可以看见成功生成了<code>config.status</code>以及<code>Makefile</code>文件，打开该<code>Makefile</code>文件，可以看见生成了700多行<br />\n<img alt=\"Pasted image 20260216164053.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209182-33307432.png\" /><br />\n我们非常简单的一个代码，<code>autotools</code>工具给我们生成了700多行的<code>Makefile</code>文件，其中大量的代码都是用来检测环境和编译器相关的内容。有了<code>Makefile</code>之后，我们就可以直接使用<code>make</code>命令来编译了<br />\n<img alt=\"Pasted image 20260216164308.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209147-1035686151.png\" /><br />\n并且生成了对应的可执行文件，同时我们可以执行<code>make install</code>进行系统安装，默认安装到<code>/user/local/bin</code>下，需要注意的是使用<code>make install</code>时需要权限。<br />\n<img alt=\"Pasted image 20260216164615.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209129-81980537.png\" /></p>\n<p>我们可以使用<code>make dist</code>用来生成一个源码压缩包，拿到这个包之后，我们就可以将工程发布给别人或者发布成release版本了<br />\n<img alt=\"Pasted image 20260216164748.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209359-157961370.png\" /><br />\n至此整个<code>Autotools</code>最基本的流程与用法就结束了，当然在实际开发当中，我们不可能只有一个源文件，之后的博客会对实际工程项目情况举例与分析。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:24</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ttkwzyttk\">ttkwzyttk</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "零代码零基础！小红书MCP全自动化运营【保姆级安装教程】",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19621617",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19621617\" id=\"cb_post_title_url\" title=\"å‘å¸ƒäºŽ 2026-02-17 13:49\">\n    <span>é›¶ä»£ç é›¶åŸºç¡€ï¼å°çº¢ä¹¦MCPå…¨è‡ªåŠ¨åŒ–è¿è¥ã€ä¿å§†çº§å®‰è£…æ•™ç¨‹ã€‘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        å°çº¢ä¹¦MCPè‡ªåŠ¨åŒ–å·¥å…·éƒ¨ç½²æŒ‡å— æ‘˜è¦ï¼šæœ¬æ–‡è¯¦ç»†ä»‹ç»å¦‚ä½•å¿«é€Ÿéƒ¨ç½²å°çº¢ä¹¦MCPè‡ªåŠ¨åŒ–è¿è¥å·¥å…·ã€‚é€šè¿‡ä¸‹è½½é¢„ç¼–è¯‘å®‰è£…åŒ…ï¼Œå®ŒæˆNode.jsçŽ¯å¢ƒé…ç½®åŽï¼Œè¿è¡Œç™»å½•å·¥å…·èŽ·å–cookies.jsonè®¤è¯æ–‡ä»¶ï¼Œå¯åŠ¨MCPä¸»æœåŠ¡å¹¶éªŒè¯è¿žæŽ¥ã€‚æœ€åŽæŽ¥å…¥Cursorç¼–è¾‘å™¨å®žçŽ°è‡ªç„¶è¯­è¨€æŽ§åˆ¶ï¼Œæ¼”ç¤ºäº†è´¦å·çŠ¶æ€æ£€æŸ¥å’Œå›¾æ–‡å‘å¸ƒç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€å¤æ‚é…ç½®ï¼Œé€‚åˆæ–°æ‰‹å¿«é€Ÿå®žçŽ°å°çº¢ä¹¦å†…å®¹è‡ªåŠ¨åŒ–ç®¡ç†ã€‚\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>@</p><div class=\"toc\"><div class=\"toc-container-header\">ç›®å½•</div><ul><li><a href=\"#ä¸€å‰è¨€\" rel=\"noopener nofollow\">ä¸€ã€å‰è¨€</a></li><li><a href=\"#äºŒå‡†å¤‡å·¥ä½œ\" rel=\"noopener nofollow\">äºŒã€å‡†å¤‡å·¥ä½œ</a><ul><li><a href=\"#21-ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž\" rel=\"noopener nofollow\">2.1 ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž</a></li><li><a href=\"#22-å¿…è£…ä¾èµ–ä»…2ä¸ªæžç®€\" rel=\"noopener nofollow\">2.2 å¿…è£…ä¾èµ–ï¼ˆä»…2ä¸ªï¼Œæžç®€ï¼‰</a><ul><li><a href=\"#1nodejsç”¨äºŽmcpè¿žæŽ¥éªŒè¯\" rel=\"noopener nofollow\">ï¼ˆ1ï¼‰Node.jsï¼ˆç”¨äºŽMCPè¿žæŽ¥éªŒè¯ï¼‰</a></li><li><a href=\"#2ç½‘ç»œçŽ¯å¢ƒ\" rel=\"noopener nofollow\">ï¼ˆ2ï¼‰ç½‘ç»œçŽ¯å¢ƒ</a></li></ul></li><li><a href=\"#23-ä¸‹è½½å°çº¢ä¹¦mcpå®‰è£…åŒ\" rel=\"noopener nofollow\">2.3 ä¸‹è½½å°çº¢ä¹¦MCPå®‰è£…åŒ…</a></li></ul></li><li><a href=\"#ä¸‰éƒ¨ç½²å°çº¢ä¹¦mcpæœåŠ¡\" rel=\"noopener nofollow\">ä¸‰ã€éƒ¨ç½²å°çº¢ä¹¦MCPæœåŠ¡</a><ul><li><a href=\"#31-è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„\" rel=\"noopener nofollow\">3.1 è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„</a></li><li><a href=\"#32-è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯\" rel=\"noopener nofollow\">3.2 è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯</a></li><li><a href=\"#33-å¯åŠ¨mcpä¸»æœåŠ¡\" rel=\"noopener nofollow\">3.3 å¯åŠ¨MCPä¸»æœåŠ¡</a></li><li><a href=\"#34-éªŒè¯mcpæœåŠ¡æ˜¯å¦æ­£å¸¸\" rel=\"noopener nofollow\">3.4 éªŒè¯MCPæœåŠ¡æ˜¯å¦æ­£å¸¸</a></li></ul></li><li><a href=\"#å››æŽ¥å…¥cursorç¼–è¾‘å™¨\" rel=\"noopener nofollow\">å››ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨</a><ul><li><a href=\"#41-æ‰¾åˆ°cursorçš„mcpé…ç½®æ–‡ä»¶\" rel=\"noopener nofollow\">4.1 æ‰¾åˆ°Cursorçš„MCPé…ç½®æ–‡ä»¶</a></li><li><a href=\"#42-é…ç½®mcpè¿žæŽ¥ä¿¡æ¯\" rel=\"noopener nofollow\">4.2 é…ç½®MCPè¿žæŽ¥ä¿¡æ¯</a></li><li><a href=\"#43-éªŒè¯cursorä¸Žmcpçš„è¿žæŽ¥\" rel=\"noopener nofollow\">4.3 éªŒè¯Cursorä¸ŽMCPçš„è¿žæŽ¥</a></li></ul></li><li><a href=\"#äº”cursorä¸­ä½¿ç”¨å°çº¢ä¹¦mcpå®žæˆ˜\" rel=\"noopener nofollow\">äº”ã€Cursorä¸­ä½¿ç”¨å°çº¢ä¹¦MCPå®žæˆ˜</a><ul><li><a href=\"#51-åŸºç¡€åŠŸèƒ½æ£€æŸ¥ç™»å½•çŠ¶æ€\" rel=\"noopener nofollow\">5.1 åŸºç¡€åŠŸèƒ½ï¼šæ£€æŸ¥ç™»å½•çŠ¶æ€</a></li><li><a href=\"#52-æ ¸å¿ƒåŠŸèƒ½å‘å¸ƒå°çº¢ä¹¦å›¾æ–‡\" rel=\"noopener nofollow\">5.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å¸ƒå°çº¢ä¹¦å›¾æ–‡</a><ul><li><a href=\"#æ­¥éª¤1å‡†å¤‡å‘å¸ƒç´ æ\" rel=\"noopener nofollow\">æ­¥éª¤1ï¼šå‡†å¤‡å‘å¸ƒç´ æ</a></li><li><a href=\"#æ­¥éª¤2åœ¨cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤\" rel=\"noopener nofollow\">æ­¥éª¤2ï¼šåœ¨Cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤</a></li><li><a href=\"#æ­¥éª¤3æŸ¥çœ‹å‘å¸ƒç»“æžœ\" rel=\"noopener nofollow\">æ­¥éª¤3ï¼šæŸ¥çœ‹å‘å¸ƒç»“æžœ</a></li></ul></li><li><a href=\"#53-å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨\" rel=\"noopener nofollow\">5.3 å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨</a></li></ul></li><li><a href=\"#å…­å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ\" rel=\"noopener nofollow\">å…­ã€å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ</a><ul><li><a href=\"#é—®é¢˜1ç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—ä¸‹è½½æµè§ˆå™¨å¤±è´¥\" rel=\"noopener nofollow\">é—®é¢˜1ï¼šç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—/ä¸‹è½½æµè§ˆå™¨å¤±è´¥</a></li><li><a href=\"#é—®é¢˜2cursoræç¤ºæ— æ³•è¿žæŽ¥åˆ°mcpæœåŠ¡\" rel=\"noopener nofollow\">é—®é¢˜2ï¼šCursoræç¤ºã€Œæ— æ³•è¿žæŽ¥åˆ°MCPæœåŠ¡ã€</a></li><li><a href=\"#é—®é¢˜3å‘å¸ƒå›¾æ–‡æç¤ºå›¾ç‰‡è·¯å¾„é”™è¯¯\" rel=\"noopener nofollow\">é—®é¢˜3ï¼šå‘å¸ƒå›¾æ–‡æç¤ºã€Œå›¾ç‰‡è·¯å¾„é”™è¯¯ã€</a></li><li><a href=\"#é—®é¢˜4è´¦å·è¢«è¸¢ä¸‹çº¿\" rel=\"noopener nofollow\">é—®é¢˜4ï¼šè´¦å·è¢«è¸¢ä¸‹çº¿</a></li></ul></li><li><a href=\"#ä¸ƒæ€»ç»“\" rel=\"noopener nofollow\">ä¸ƒã€æ€»ç»“</a></li></ul></div><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><p></p>\n<h1 id=\"ä¸€å‰è¨€\">ä¸€ã€å‰è¨€</h1>\n<p>å°çº¢ä¹¦MCPï¼ˆxiaohongshu-mcpï¼‰æ˜¯ä¸€æ¬¾èƒ½å®žçŽ°å°çº¢ä¹¦è‡ªåŠ¨åŒ–è¿è¥çš„å·¥å…·ï¼Œæ”¯æŒç™»å½•éªŒè¯ã€å›¾æ–‡/è§†é¢‘å‘å¸ƒã€è¯„è®ºäº’åŠ¨ã€ç”¨æˆ·ä¿¡æ¯æŸ¥è¯¢ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚ç›¸æ¯”æºç ç¼–è¯‘ã€Dockeréƒ¨ç½²ï¼Œ<strong>ä¸‹è½½é¢„ç¼–è¯‘å®‰è£…åŒ…</strong>æ˜¯æœ€å¿«æ·çš„æ–¹å¼ï¼Œæ— éœ€é…ç½®å¼€å‘çŽ¯å¢ƒï¼Œæ–°æ‰‹ä¹Ÿèƒ½å¿«é€Ÿä¸Šæ‰‹ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>æœ¬æ–‡å°†å…¨ç¨‹åŸºäºŽã€Œå®‰è£…åŒ…ä¸‹è½½ã€çš„æ–¹å¼ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ å®Œæˆå°çº¢ä¹¦MCPçš„éƒ¨ç½²ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨ï¼Œå¹¶æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½çš„ä½¿ç”¨ï¼Œè®©ä½ è½»æ¾å®žçŽ°å°çº¢ä¹¦å†…å®¹çš„è‡ªåŠ¨åŒ–ç®¡ç†ã€‚</p>\n<h1 id=\"äºŒå‡†å¤‡å·¥ä½œ\">äºŒã€å‡†å¤‡å·¥ä½œ</h1>\n<h2 id=\"21-ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž\">2.1 ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž</h2>\n<p>æ”¯æŒçš„ç³»ç»Ÿç‰ˆæœ¬ï¼ˆè¯·å¯¹åº”ä¸‹è½½ï¼‰ï¼š</p>\n<ul>\n<li>macOSï¼šApple Siliconï¼ˆarm64ï¼‰/ Intelï¼ˆamd64ï¼‰</li>\n<li>Windowsï¼šx64ï¼ˆWindows 10/11 å‡å¯ï¼‰</li>\n<li>Linuxï¼šx64</li>\n</ul>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"22-å¿…è£…ä¾èµ–ä»…2ä¸ªæžç®€\">2.2 å¿…è£…ä¾èµ–ï¼ˆä»…2ä¸ªï¼Œæžç®€ï¼‰</h2>\n<h3 id=\"1nodejsç”¨äºŽmcpè¿žæŽ¥éªŒè¯\">ï¼ˆ1ï¼‰Node.jsï¼ˆç”¨äºŽMCPè¿žæŽ¥éªŒè¯ï¼‰</h3>\n<p>æ— è®ºå“ªä¸ªç³»ç»Ÿï¼Œå»ºè®®é€šè¿‡å®˜æ–¹æŽ¨èæ–¹å¼å®‰è£…Node.js LTSç‰ˆæœ¬ï¼Œç¡®ä¿çŽ¯å¢ƒå˜é‡è‡ªåŠ¨é…ç½®ï¼š</p>\n<ul>\n<li>Windowsï¼šæ‰“å¼€ã€Œç®¡ç†å‘˜å‘½ä»¤è¡Œã€æ‰§è¡Œ<pre><code class=\"language-bash\">winget install OpenJS.NodeJS.LTS\n</code></pre>\n</li>\n<li>macOS/Linuxï¼šå‚è€ƒ <a href=\"https://nodejs.org/zh-cn/download/\" rel=\"noopener nofollow\" target=\"_blank\">Node.jså®˜æ–¹ä¸‹è½½é¡µ</a> å®‰è£…LTSç‰ˆæœ¬</li>\n</ul>\n<h3 id=\"2ç½‘ç»œçŽ¯å¢ƒ\">ï¼ˆ2ï¼‰ç½‘ç»œçŽ¯å¢ƒ</h3>\n<p>é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆçº¦150MBï¼‰ï¼Œéœ€ç¡®ä¿ç½‘ç»œé€šç•…ï¼ŒåŽç»­æ— éœ€é‡å¤ä¸‹è½½ã€‚</p>\n<h2 id=\"23-ä¸‹è½½å°çº¢ä¹¦mcpå®‰è£…åŒ…\">2.3 ä¸‹è½½å°çº¢ä¹¦MCPå®‰è£…åŒ…</h2>\n<ol>\n<li>æ‰“å¼€ <a href=\"https://github.com/xpzouying/xiaohongshu-mcp/releases\" rel=\"noopener nofollow\" target=\"_blank\">xiaohongshu-mcpçš„GitHub Releasesé¡µé¢</a></li>\n<li>æ ¹æ®è‡ªå·±çš„ç³»ç»Ÿä¸‹è½½å¯¹åº”å®‰è£…åŒ…ï¼š\n<ul>\n<li>Windows x64ï¼š<code>xiaohongshu-mcp-windows-amd64.zip</code></li>\n<li>macOS Apple Siliconï¼š<code>xiaohongshu-mcp-darwin-arm64.zip</code></li>\n<li>macOS Intelï¼š<code>xiaohongshu-mcp-darwin-amd64.zip</code></li>\n<li>Linux x64ï¼š<code>xiaohongshu-mcp-linux-amd64.zip</code></li>\n</ul>\n</li>\n<li>ä¸‹è½½å®ŒæˆåŽï¼Œå°†åŽ‹ç¼©åŒ…è§£åŽ‹åˆ°ä»»æ„ç›®å½•ï¼ˆå»ºè®®è·¯å¾„ä¸å«ä¸­æ–‡/ç©ºæ ¼ï¼Œæ¯”å¦‚ <code>D:\\xiaohongshu-mcp</code> æˆ– <code>/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp</code>ï¼‰ã€‚</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>æ³¨æ„cookies.jsonæ˜¯ç™»å½•ä¹‹åŽæ‰ä¼šæœ‰çš„ï¼Œåˆšåˆšè§£åŽ‹å®Œåªä¼šæœ‰æˆ‘åœˆèµ·æ¥çš„è¿™ä¸¤ä¸ª</p>\n<h1 id=\"ä¸‰éƒ¨ç½²å°çº¢ä¹¦mcpæœåŠ¡\">ä¸‰ã€éƒ¨ç½²å°çº¢ä¹¦MCPæœåŠ¡</h1>\n<h2 id=\"31-è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„\">3.1 è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„</h2>\n<p>è§£åŽ‹åŽç›®å½•å†…ä¼šåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼ˆä»¥Windowsä¸ºä¾‹ï¼‰ï¼š</p>\n<ul>\n<li><code>xiaohongshu-login-windows-amd64.exe</code>ï¼šç™»å½•å·¥å…·ï¼ˆå¿…å…ˆè¿è¡Œï¼‰</li>\n<li><code>xiaohongshu-mcp-windows-amd64.exe</code>ï¼šMCPä¸»æœåŠ¡ç¨‹åº</li>\n</ul>\n<blockquote>\n<p>å…¶ä»–ç³»ç»Ÿå¯¹åº”æ–‡ä»¶ï¼šmacOSæ˜¯<code>xiaohongshu-login-darwin-arm64</code>/<code>xiaohongshu-mcp-darwin-arm64</code>ï¼ŒLinuxæ˜¯<code>xiaohongshu-login-linux-amd64</code>/<code>xiaohongshu-mcp-linux-amd64</code>ã€‚</p>\n</blockquote>\n<h2 id=\"32-è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯\">3.2 è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯</h2>\n<p>è¿™æ˜¯æ ¸å¿ƒæ­¥éª¤ï¼ŒMCPæœåŠ¡ä¾èµ–ç™»å½•åŽçš„Cookiesæ‰èƒ½æ­£å¸¸å·¥ä½œï¼š</p>\n<ol>\n<li>æ‰“å¼€ç»ˆç«¯/å‘½ä»¤è¡Œï¼Œè¿›å…¥è§£åŽ‹ç›®å½•ï¼š\n<ul>\n<li>Windowsï¼šåœ¨è§£åŽ‹æ–‡ä»¶å¤¹ç©ºç™½å¤„å³é”® â†’ ã€Œåœ¨ç»ˆç«¯ä¸­æ‰“å¼€ã€</li>\n<li>macOS/Linuxï¼šæ‰“å¼€ç»ˆç«¯ï¼Œæ‰§è¡Œ <code>cd /ä½ çš„è§£åŽ‹è·¯å¾„/xiaohongshu-mcp</code></li>\n</ul>\n</li>\n<li>è¿è¡Œç™»å½•å·¥å…·ï¼š\n<ul>\n<li>Windowsï¼š<pre><code class=\"language-bash\">./xiaohongshu-login-windows-amd64.exe\n</code></pre>\n</li>\n<li>macOS/Linuxï¼š<pre><code class=\"language-bash\">chmod +x xiaohongshu-login-darwin-arm64  # èµ‹äºˆæ‰§è¡Œæƒé™ï¼ˆä»…é¦–æ¬¡ï¼‰\n./xiaohongshu-login-darwin-arm64\n</code></pre>\n</li>\n</ul>\n</li>\n<li>ç™»å½•æµç¨‹ï¼š\n<ul>\n<li>è¿è¡ŒåŽä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆè€å¿ƒç­‰å¾…ï¼‰ï¼›</li>\n<li>å¼¹å‡ºå°çº¢ä¹¦ç™»å½•é¡µé¢ï¼ˆæ‰«ç /æ‰‹æœºå·ç™»å½•å‡å¯ï¼‰ï¼›</li>\n<li>ç™»å½•æˆåŠŸåŽï¼Œç»ˆç«¯ä¼šæç¤ºã€Œç™»å½•æˆåŠŸã€ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆ <code>cookies.json</code> æ–‡ä»¶ï¼ˆä¿å­˜åœ¨å½“å‰ç›®å½•ï¼Œåˆ‡å‹¿åˆ é™¤ï¼‰ã€‚</li>\n</ul>\n</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<blockquote>\n<p>âš ï¸ é‡è¦æé†’ï¼šå°çº¢ä¹¦è´¦å·ä¸å…è®¸å¤šç½‘é¡µç«¯ç™»å½•ï¼Œç™»å½•MCPåŽï¼Œä¸è¦åœ¨å…¶ä»–æµè§ˆå™¨ç™»å½•åŒä¸€è´¦å·ï¼Œå¦åˆ™ä¼šè¢«è¸¢ä¸‹çº¿ï¼ˆæ‰‹æœºAppç™»å½•ä¸å—å½±å“ï¼‰ã€‚</p>\n</blockquote>\n<h2 id=\"33-å¯åŠ¨mcpä¸»æœåŠ¡\">3.3 å¯åŠ¨MCPä¸»æœåŠ¡</h2>\n<p>ç™»å½•æˆåŠŸåŽï¼Œç»§ç»­åœ¨ç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨MCPæœåŠ¡ï¼š</p>\n<ul>\n<li>Windowsï¼š<pre><code class=\"language-bash\"># æ— å¤´æ¨¡å¼ï¼ˆæ— æµè§ˆå™¨ç•Œé¢ï¼ŒæŽ¨èç”Ÿäº§ä½¿ç”¨ï¼‰\n./xiaohongshu-mcp-windows-amd64.exe\n\n# éžæ— å¤´æ¨¡å¼ï¼ˆæœ‰æµè§ˆå™¨ç•Œé¢ï¼Œè°ƒè¯•ç”¨ï¼‰\n./xiaohongshu-mcp-windows-amd64.exe -headless=false\n</code></pre>\n</li>\n<li>macOS/Linuxï¼š<pre><code class=\"language-bash\">chmod +x xiaohongshu-mcp-darwin-arm64  # èµ‹äºˆæ‰§è¡Œæƒé™ï¼ˆä»…é¦–æ¬¡ï¼‰\n# æ— å¤´æ¨¡å¼\n./xiaohongshu-mcp-darwin-arm64\n# éžæ— å¤´æ¨¡å¼\n./xiaohongshu-mcp-darwin-arm64 -headless=false\n</code></pre>\n</li>\n</ul>\n<p>å¯åŠ¨æˆåŠŸçš„æ ‡å¿—ï¼šç»ˆç«¯æ— æŠ¥é”™ï¼Œä¸”æ˜¾ç¤ºã€ŒMCPæœåŠ¡å¯åŠ¨æˆåŠŸï¼Œç«¯å£ï¼š18060ã€ï¼ˆé»˜è®¤ç«¯å£18060ï¼Œè¯·å‹¿å ç”¨ï¼‰ã€‚<br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"34-éªŒè¯mcpæœåŠ¡æ˜¯å¦æ­£å¸¸\">3.4 éªŒè¯MCPæœåŠ¡æ˜¯å¦æ­£å¸¸</h2>\n<p>æ‰§è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯æœåŠ¡å¯ç”¨æ€§ï¼š</p>\n<pre><code class=\"language-bash\">npx @modelcontextprotocol/inspector\n</code></pre>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\nå·¦ä¸Šè§’<strong>Transport Type</strong>ä¸‹æ‹‰æ¡†ï¼ŒæŠŠSTDIOæ”¹æˆ<strong>Streamable HTTP</strong>ï¼›<br />\næ”¹å®ŒåŽç•Œé¢ä¼šå‡ºçŽ°URLè¾“å…¥æ¡†ï¼ŒæŠŠhttp://localhost:18060/mcpå¡«åˆ°è¿™ä¸ª <strong>URL æ¡†é‡Œ</strong>ï¼›<br />\nç‚¹å‡»å·¦ä¾§çš„<strong>Connect</strong>æŒ‰é’®ã€‚<br />\næˆåŠŸæ ‡å¿—ï¼š<strong>å·¦ä¸‹è§’æ˜¾ç¤ºConnected</strong><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>ç‚¹å‡»ä¸­é—´çš„List Tools<br />\nä¸­é—´åŒºåŸŸåŠ è½½å‡ºå°çº¢ä¹¦ MCP çš„æ‰€æœ‰å·¥å…· / èƒ½åŠ›åˆ—è¡¨ã€<br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h1 id=\"å››æŽ¥å…¥cursorç¼–è¾‘å™¨\">å››ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨</h1>\n<p>Cursoræ˜¯æ”¯æŒMCPåè®®çš„AIç¼–è¾‘å™¨ï¼ŒæŽ¥å…¥åŽå¯ç›´æŽ¥åœ¨Cursorä¸­é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨å°çº¢ä¹¦MCPçš„æ‰€æœ‰åŠŸèƒ½ï¼Œæ— éœ€æ‰‹åŠ¨å†™æŽ¥å£è¯·æ±‚ã€‚</p>\n<h2 id=\"41-æ‰¾åˆ°cursorçš„mcpé…ç½®æ–‡ä»¶\">4.1 æ‰¾åˆ°Cursorçš„MCPé…ç½®æ–‡ä»¶</h2>\n<ol>\n<li>æ‰“å¼€Cursorç¼–è¾‘å™¨ï¼›</li>\n<li>ç¡®è®¤Cursorçš„MCPé…ç½®ç›®å½•ï¼š\n<ul>\n<li>æ ¸å¿ƒé…ç½®æ–‡ä»¶è·¯å¾„å‚è€ƒï¼š<code>.cursor/mcp.json</code>ï¼ˆå¯åœ¨Cursorçš„ã€Œè®¾ç½®â†’MCPã€ä¸­æ‰¾åˆ°é…ç½®å…¥å£ï¼Œæˆ–ç›´æŽ¥åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºè¯¥æ–‡ä»¶ï¼‰ã€‚</li>\n</ul>\n</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"42-é…ç½®mcpè¿žæŽ¥ä¿¡æ¯\">4.2 é…ç½®MCPè¿žæŽ¥ä¿¡æ¯</h2>\n<p>åˆ›å»º/ç¼–è¾‘ <code>.cursor/mcp.json</code> æ–‡ä»¶ï¼Œå†™å…¥ä»¥ä¸‹å†…å®¹ï¼š</p>\n<pre><code class=\"language-json\">{\n    \"mcpServers\": {\n        \"xiaohongshu-mcp\": {\n            \"url\": \"http://localhost:18060/mcp\",\n            \"description\": \"å°çº¢ä¹¦å†…å®¹å‘å¸ƒæœåŠ¡ - MCP Streamable HTTP\"\n        }\n    }\n}\n</code></pre>\n<p>ä¿å­˜æ–‡ä»¶åŽï¼Œé‡å¯Cursorè®©é…ç½®ç”Ÿæ•ˆã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"43-éªŒè¯cursorä¸Žmcpçš„è¿žæŽ¥\">4.3 éªŒè¯Cursorä¸ŽMCPçš„è¿žæŽ¥</h2>\n<ol>\n<li>æ‰“å¼€Cursorï¼Œæ–°å»ºä¸€ä¸ªå¯¹è¯çª—å£ï¼›</li>\n<li>åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ï¼š<code>æ£€æŸ¥å°çº¢ä¹¦MCPçš„ç™»å½•çŠ¶æ€</code>ï¼›</li>\n<li>å‘é€æŒ‡ä»¤åŽï¼ŒCursorä¼šè‡ªåŠ¨è°ƒç”¨å°çº¢ä¹¦MCPçš„ã€Œæ£€æŸ¥ç™»å½•çŠ¶æ€ã€åŠŸèƒ½ï¼Œè¿”å›žã€Œå½“å‰è´¦å·å·²ç™»å½•ã€å³ä»£è¡¨æŽ¥å…¥æˆåŠŸã€‚</li>\n</ol>\n<h1 id=\"äº”cursorä¸­ä½¿ç”¨å°çº¢ä¹¦mcpå®žæˆ˜\">äº”ã€Cursorä¸­ä½¿ç”¨å°çº¢ä¹¦MCPå®žæˆ˜</h1>\n<h2 id=\"51-åŸºç¡€åŠŸèƒ½æ£€æŸ¥ç™»å½•çŠ¶æ€\">5.1 åŸºç¡€åŠŸèƒ½ï¼šæ£€æŸ¥ç™»å½•çŠ¶æ€</h2>\n<p>åœ¨Cursorå¯¹è¯æ¡†ä¸­è¾“å…¥ï¼š</p>\n<pre><code>æ£€æŸ¥æˆ‘çš„å°çº¢ä¹¦è´¦å·ç™»å½•çŠ¶æ€\n</code></pre>\n<p>å‘é€åŽï¼ŒMCPä¼šè¿”å›žå½“å‰è´¦å·çš„ç™»å½•çŠ¶æ€ï¼ˆå·²ç™»å½•/æœªç™»å½•ï¼‰ï¼Œå¦‚æžœæœªç™»å½•ï¼Œéœ€é‡æ–°è¿è¡Œç™»å½•å·¥å…·ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"52-æ ¸å¿ƒåŠŸèƒ½å‘å¸ƒå°çº¢ä¹¦å›¾æ–‡\">5.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å¸ƒå°çº¢ä¹¦å›¾æ–‡</h2>\n<h3 id=\"æ­¥éª¤1å‡†å¤‡å‘å¸ƒç´ æ\">æ­¥éª¤1ï¼šå‡†å¤‡å‘å¸ƒç´ æ</h3>\n<ul>\n<li>æœ¬åœ°å›¾ç‰‡ï¼šå°†å›¾ç‰‡æ”¾åˆ°MCPè§£åŽ‹ç›®å½•çš„ <code>images</code> æ–‡ä»¶å¤¹ï¼ˆæ²¡æœ‰åˆ™æ–°å»ºï¼‰ï¼›</li>\n<li>æ–‡æ¡ˆï¼šæ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰+ æ­£æ–‡ï¼ˆâ‰¤1000å­—ï¼‰+ æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰ã€‚</li>\n</ul>\n<h3 id=\"æ­¥éª¤2åœ¨cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤\">æ­¥éª¤2ï¼šåœ¨Cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤</h3>\n<pre><code>@xiaohongshu-mcp å‘å¸ƒä¸€ç¯‡å°çº¢ä¹¦å›¾æ–‡ï¼Œæ ‡é¢˜ï¼šã€Œæ–°æ‰‹å¿…çœ‹çš„MCPéƒ¨ç½²æ•™ç¨‹ã€ï¼Œæ­£æ–‡ï¼šã€Œæ— éœ€ç¼–è¯‘æºç ï¼Œä¸‹è½½å®‰è£…åŒ…å°±èƒ½éƒ¨ç½²å°çº¢ä¹¦MCPï¼Œé™„CursoræŽ¥å…¥å…¨æµç¨‹ï½žã€ï¼Œå›¾ç‰‡ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp/images/æ•™ç¨‹å°é¢.jpgï¼Œæ·»åŠ æ ‡ç­¾ï¼š#MCP #å°çº¢ä¹¦è‡ªåŠ¨åŒ– #Cursor\n</code></pre>\n<blockquote>\n<p>æ³¨æ„ï¼š</p>\n<ul>\n<li>å›¾ç‰‡è·¯å¾„éœ€å†™ç»å¯¹è·¯å¾„ï¼ˆWindowsç¤ºä¾‹ï¼š<code>D:\\xiaohongshu-mcp\\images\\æ•™ç¨‹å°é¢.jpg</code>ï¼‰ï¼›</li>\n<li>æ ‡é¢˜å’Œæ­£æ–‡éœ€ç¬¦åˆå°çº¢ä¹¦å­—æ•°é™åˆ¶ï¼ˆæ ‡é¢˜â‰¤20å­—ï¼Œæ­£æ–‡â‰¤1000å­—ï¼‰ã€‚</li>\n</ul>\n</blockquote>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h3 id=\"æ­¥éª¤3æŸ¥çœ‹å‘å¸ƒç»“æžœ\">æ­¥éª¤3ï¼šæŸ¥çœ‹å‘å¸ƒç»“æžœ</h3>\n<p>å‘é€æŒ‡ä»¤åŽï¼ŒCursorä¼šè¿”å›žå‘å¸ƒè¿›åº¦ï¼ŒæˆåŠŸåŽå¯åœ¨å°çº¢ä¹¦Appä¸­æŸ¥çœ‹å‘å¸ƒçš„ç¬”è®°ã€‚</p>\n<h2 id=\"53-å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨\">5.3 å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨</h2>\n<ul>\n<li>å‘å¸ƒè§†é¢‘ï¼š<pre><code>@xiaohongshu-mcp å‘å¸ƒå°çº¢ä¹¦è§†é¢‘ï¼Œæ ‡é¢˜ï¼šã€ŒMCPéƒ¨ç½²å®žæ“æ¼”ç¤ºã€ï¼Œæ­£æ–‡ï¼šã€Œæ‰‹æŠŠæ‰‹æ•™ä½ éƒ¨ç½²å°çº¢ä¹¦MCPï½žã€ï¼Œè§†é¢‘è·¯å¾„ï¼š/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp/videos/æ¼”ç¤º.mp4\n</code></pre>\n</li>\n<li>èŽ·å–ç”¨æˆ·ä¸ªäººä¸»é¡µï¼š<pre><code>@xiaohongshu-mcp èŽ·å–ç”¨æˆ·IDä¸º123456çš„å°çº¢ä¹¦ä¸ªäººä¸»é¡µä¿¡æ¯\n</code></pre>\n</li>\n<li>å‘è¡¨è¯„è®ºï¼š<pre><code>@xiaohongshu-mcp ç»™å¸–å­IDä¸º741852çš„å°çº¢ä¹¦ç¬”è®°å‘è¡¨è¯„è®ºï¼šã€Œæ•™ç¨‹è¶…å®žç”¨ï¼ã€\n</code></pre>\n</li>\n</ul>\n<h1 id=\"å…­å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ\">å…­ã€å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ</h1>\n<h2 id=\"é—®é¢˜1ç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—ä¸‹è½½æµè§ˆå™¨å¤±è´¥\">é—®é¢˜1ï¼šç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—/ä¸‹è½½æµè§ˆå™¨å¤±è´¥</h2>\n<ul>\n<li>åŽŸå› ï¼šç½‘ç»œé™åˆ¶æˆ–æƒé™ä¸è¶³ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>ç¡®ä¿ç½‘ç»œèƒ½è®¿é—®å¤–ç½‘ï¼Œæˆ–åˆ‡æ¢ç½‘ç»œé‡è¯•ï¼›</li>\n<li>Windowséœ€ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œç»ˆç«¯ï¼ŒmacOS/Linuxéœ€èµ‹äºˆæ–‡ä»¶æ‰§è¡Œæƒé™ï¼ˆ<code>chmod +x æ–‡ä»¶å</code>ï¼‰ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜2cursoræç¤ºæ— æ³•è¿žæŽ¥åˆ°mcpæœåŠ¡\">é—®é¢˜2ï¼šCursoræç¤ºã€Œæ— æ³•è¿žæŽ¥åˆ°MCPæœåŠ¡ã€</h2>\n<ul>\n<li>åŽŸå› ï¼šMCPæœåŠ¡æœªå¯åŠ¨/ç«¯å£è¢«å ç”¨/é…ç½®æ–‡ä»¶è·¯å¾„é”™è¯¯ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>æ£€æŸ¥MCPæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼ˆç»ˆç«¯æ˜¯å¦æ˜¾ç¤ºç«¯å£18060ï¼‰ï¼›</li>\n<li>ç¡®è®¤ <code>.cursor/mcp.json</code> ä¸­çš„URLæ˜¯ <code>http://localhost:18060/mcp</code>ï¼›</li>\n<li>æ£€æŸ¥18060ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼ˆWindowsï¼š<code>netstat -ano | findstr 18060</code>ï¼ŒmacOS/Linuxï¼š<code>lsof -i:18060</code>ï¼‰ï¼Œå ç”¨åˆ™å…³é—­å¯¹åº”è¿›ç¨‹ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜3å‘å¸ƒå›¾æ–‡æç¤ºå›¾ç‰‡è·¯å¾„é”™è¯¯\">é—®é¢˜3ï¼šå‘å¸ƒå›¾æ–‡æç¤ºã€Œå›¾ç‰‡è·¯å¾„é”™è¯¯ã€</h2>\n<ul>\n<li>åŽŸå› ï¼šå›¾ç‰‡è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„/æœªæ”¾åˆ°æŒ‡å®šç›®å½•ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ˆå¦‚ <code>D:\\xiaohongshu-mcp\\images\\test.jpg</code>ï¼‰ï¼›</li>\n<li>ç¡®ä¿å›¾ç‰‡æ–‡ä»¶å­˜åœ¨ï¼Œä¸”è·¯å¾„æ— ä¸­æ–‡/ç©ºæ ¼ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜4è´¦å·è¢«è¸¢ä¸‹çº¿\">é—®é¢˜4ï¼šè´¦å·è¢«è¸¢ä¸‹çº¿</h2>\n<ul>\n<li>åŽŸå› ï¼šåŒä¸€è´¦å·åœ¨å…¶ä»–ç½‘é¡µç«¯ç™»å½•ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>é€€å‡ºå…¶ä»–ç½‘é¡µç«¯çš„å°çº¢ä¹¦ç™»å½•ï¼›</li>\n<li>é‡æ–°è¿è¡Œç™»å½•å·¥å…·ï¼Œé‡æ–°ç”ŸæˆCookiesã€‚</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"ä¸ƒæ€»ç»“\">ä¸ƒã€æ€»ç»“</h1>\n<p>é€šè¿‡ã€Œä¸‹è½½å®‰è£…åŒ…ã€çš„æ–¹å¼éƒ¨ç½²å°çº¢ä¹¦MCPï¼Œå…¨ç¨‹æ— éœ€é…ç½®å¤æ‚çš„å¼€å‘çŽ¯å¢ƒï¼ˆå¦‚Golangã€Dockerï¼‰ï¼Œæ–°æ‰‹ä¹Ÿèƒ½åœ¨10åˆ†é’Ÿå†…å®Œæˆéƒ¨ç½²ã€‚æŽ¥å…¥CursoråŽï¼Œå¯ç›´æŽ¥é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨MCPçš„æ‰€æœ‰åŠŸèƒ½ï¼Œå®žçŽ°å°çº¢ä¹¦ç™»å½•éªŒè¯ã€å›¾æ–‡/è§†é¢‘å‘å¸ƒã€è¯„è®ºäº’åŠ¨ç­‰è‡ªåŠ¨åŒ–æ“ä½œã€‚</p>\n<p>âš ï¸ é£Žé™©æç¤ºï¼šè¯¥å·¥å…·ä»…ç”¨äºŽå­¦ä¹ å’Œä¸ªäººåˆæ³•è¿è¥ï¼Œè¯·å‹¿ç”¨äºŽè¿è§„æ“ä½œï¼›Cookiesè¿‡æœŸåŽéœ€é‡æ–°ç™»å½•ï¼Œæ­£å¸¸ä½¿ç”¨ä¸‹ä¸ä¼šå¯¼è‡´è´¦å·å°ç¦ã€‚</p>\n<p>å¦‚æžœåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯å‚è€ƒé¡¹ç›®çš„å®˜æ–¹æ–‡æ¡£ï¼ˆ<a href=\"https://github.com/xpzouying/xiaohongshu-mcp\" rel=\"noopener nofollow\" target=\"_blank\">xiaohongshu-mcp README</a>ï¼‰ï¼Œæˆ–åœ¨GitHub Issuesä¸­æé—®ã€‚</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 13:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\né˜…è¯»(<span id=\"post_view_count\">16</span>)&nbsp;\nè¯„è®º(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">æ”¶è—</a>&nbsp;\n<a href=\"\">ä¸¾æŠ¥</a>\n</div>"
    },
    {
      "title": "热烈庆祝Ctorch RC1发布！",
      "link": "https://www.cnblogs.com/SilverGo/p/19621604",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/SilverGo/p/19621604\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 13:31\">\n    <span>热烈庆祝Ctorch RC1发布！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"-新年快乐ctorch-rc1-正式发布\">🎉 新年快乐！CTorch RC1 正式发布！</h2>\n<p>值此辞旧迎新之际，我们很高兴地宣布 <strong>CTorch RC1</strong> 正式发布！这是笙歌@ShengFlow 团队数月开发的成果，一个从零开始构建的深度学习框架，旨在提供轻量、高效、易扩展的自动微分与张量计算能力。</p>\n<blockquote>\n<p><strong>RC1 是早期版本</strong>，核心功能已就绪，但仍在快速迭代中，欢迎社区试用与反馈！</p>\n</blockquote>\n<hr />\n<h3 id=\"-已实现核心功能\">✨ 已实现核心功能</h3>\n<ul>\n<li><strong>基础张量系统</strong>：支持多维张量创建、索引、运算，内存管理基础。</li>\n<li><strong>核心算子库</strong>：涵盖加减乘除、矩阵乘法、激活函数、损失函数（如交叉熵）等基础操作。</li>\n<li><strong>自动微分引擎</strong>：基于动态计算图，已通过单元测试及 <strong>MNIST 真实任务验证</strong>。</li>\n<li><strong>日志与调试</strong>：分级日志输出（INFO/WARN/ERROR/FATAL），支持终端颜色标识。</li>\n</ul>\n<h3 id=\"-可用示例mnist-手写数字识别\">🧪 可用示例：MNIST 手写数字识别</h3>\n<p>我们以经典的 MNIST 数据集作为演示，在默认配置下（网络 784→128→64→10，SGD 优化器，学习率 0.01，batch size 128），仅需 <strong>5 个 epoch 即可达到 92.24% 的测试准确率</strong>。这验证了自动微分、计算图及优化器的正确性与实用性。</p>\n<blockquote>\n<p>示例代码已集成在 <code>mnist</code> 中，欢迎尝试并调整超参数以获得更高准确率！</p>\n</blockquote>\n<hr />\n<h3 id=\"-rc2-版本规划预计-2026-q1-发布\">🔮 RC2 版本规划（预计 2026 Q1 发布）</h3>\n<ul>\n<li><strong>多后端支持</strong>：CUDA、Apple MPS、AMX 加速（<strong>测试性</strong>）</li>\n<li><strong>算子库扩充</strong>：35+ 常用算子（卷积、池化、归一化等）</li>\n<li><strong>QIA 支持</strong>：实验性的量化推理加速</li>\n<li><strong>nn 模块</strong>：常用网络层（Linear、Conv2d、Dropout 等）</li>\n<li><strong>C++20 模块支持</strong>：实验性的模块化编译</li>\n<li><strong>性能优化</strong>：线程池、内存池，提升训练与推理效率</li>\n</ul>\n<hr />\n<h3 id=\"-如何获取与参与\">📦 如何获取与参与</h3>\n<ul>\n<li>编译指南：请参考 <code>README.md</code></li>\n<li>问题反馈：欢迎提交 [Issues] 或参与讨论</li>\n<li>贡献代码：任何 PR 都将是推动 CTorch 成长的宝贵力量！</li>\n</ul>\n<hr />\n<p><strong>CTorch 还很年轻，但充满潜力。期待与你一起见证它的成长！</strong> 🚀</p>\n<p>—— 笙歌@ShengFlow 团队</p>\n<p>项目链接：<br />\n<a href=\"https://github.com/ShengFlow/CTorch\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/ShengFlow/CTorch</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 13:31</span>&nbsp;\n<a href=\"https://www.cnblogs.com/SilverGo\">Ghost-Face</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]静态上下文在Pregel中的应用",
      "link": "https://www.cnblogs.com/jaydenai/p/19621105/static-context-in-pregel",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19621105/static-context-in-pregel\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 08:23\">\n    <span>[拆解LangChain执行引擎]静态上下文在Pregel中的应用</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在 Pregel 模型中，静态上下文是一个专门设计的依赖注入容器。它的出现是为了解决在复杂的图计算中，如何优雅地处理“不属于图状态，但Node运行又必须依赖的外部环境信息”这一痛点。这些数据具有一个共同的性质，那就是在整个运行生命周期内只读且固定。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在 Pregel 模型中，静态上下文是一个专门设计的依赖注入容器。它的出现是为了解决在复杂的图计算中，如何优雅地处理“不属于图状态，但Node运行又必须依赖的外部环境信息”这一痛点。这些数据具有一个共同的性质，那就是在整个运行生命周期内只读且固定，比如：</p>\n<ul>\n<li>身份信息：当前发起请求的user_id、org_id。</li>\n<li>外部客户端：已实例化的db_connection、redis_client、vector_store。</li>\n<li>策略约束：当前任务的safety_level或budget_limit。</li>\n</ul>\n<p>静态上下文是 Pregel 运行时提供的一个类型安全的环境变量容器。它将执行环境（Context）与业务轨迹（State）物理隔离，使得大型 Agent 系统的架构更加模块化，也更容易在复杂的生产环境下进行测试和调试。</p>\n<p>不同于以往字典形式的配置，静态上下文采用强类型 Schema 定义方法。由于其静态只读的特性，它在整个生命周期内保持一致性。静态上下文具有<code>单次运行锁定</code>机制，这保证Pregel对象一旦被调用，上下文对象在所有Node、所有 Superstep中引用的是同一个内存地址。它的<code>非持久化</code>特性进一步确保它不会被写入Checkpoint，所以当Pregel因为错误停止并从断点恢复时，我们必须重新提供一个相同的上下文对象。综上所示，静态上下文作为非序列化的、运行时的<code>旁路注入</code>而存在。</p>\n<p>静态上下文在Pregel被作为<code>Runtime</code>的一部分来传递的。如下所示的Runtime类的泛型参数ConextT指的就是静态上下文数据类型。除了返回该上下文的<code>context</code>字段，Runtime还具有额外三个字段分别返回用于长期存储的<code>store</code>字段（返回一个BaseStore对象）、实现“custom”流模式的<code>stream_writer</code>字段（返回一个StreamWriter对象），以及提供当前会话上一个返回值的<code>previous</code>字段。</p>\n<pre><code class=\"language-python\">@dataclass(**_DC_KWARGS)\nclass Runtime(Generic[ContextT]):\n    context: ContextT = field(default=None\n    store: BaseStore | None = field(default=None)\n    stream_writer: StreamWriter = field(default=_no_op_stream_writer)\n    previous: Any = field(default=None)\n</code></pre>\n<p>Pregel节点的处理函数读取静态上下文比较繁琐，以为除了承载输入的参数（一般是一个字典），我们只能额外定义一个<code>RunnableConfig</code>类型的参数，意味着基本上出原始输入外的其他任务信息都得从这个RunnableConfig配置中提取。RunnableConfig是一个字典，所以我们要提取所需数据的前提是得预先知道对用得Key。这样设计也能理解，因为LangGraph.Prege在整个<code>LangChain宇宙</code>中作为<code>执行引擎</code>而存在，它相当于LangChain体系的<code>内核</code>。Pregel提供的API本就不是针对Agent应用开发者，对开发者友好不是Pregel得设计目标，保持这个内核足够简洁更重要。</p>\n<p>RunnableConfig对象会贯穿整个Pregel引擎的执行，上游流程利用这个它像下游传递所需的组件和控制信息，传递的信息大都被至于<code>configurable</code>子节点下。如果对应的Key以<code>__pregel_</code>作为前缀，表示该条目其实是由Pregel内部使用的。Runtime对应的Key为<code>__pregel_runtime</code>。</p>\n<p>如下这个例子演示了如何声明、指定和读取静态上下文。我们定义一个承载基本用户信息的UserInfo数据类型作为静态上下文的Schema。作为Pregel唯一的Node，其处理函数提供了一个<code>RunnableConfig</code>类型的参数，我们从中提供作为运行时的Runtime对象，进而得到作为静态上下文的UserInfo对象。</p>\n<pre><code class=\"language-python\">from langchain_core.runnables import RunnableConfig\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom typing import Any, Literal\nfrom langgraph.channels import LastValue\nfrom langgraph.runtime import Runtime\nfrom dataclasses import dataclass\n\n@dataclass\nclass UserInfo:\n    id: str\n    name: str\n    gender: Literal[\"male\", \"female\"]\n\ndef handle(args: dict[str, Any], config: RunnableConfig) -&gt; str:\n    runtime: Runtime = config[\"configurable\"][\"__pregel_runtime\"]\n    return runtime.context.__repr__()\n\nnode = (NodeBuilder()\n    .subscribe_only(\"start\")\n    .write_to(\"output\")\n    .do(handle))\n    \napp = Pregel(\n    nodes={\"body\": node},\n    channels={\"start\": LastValue(None), \"output\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[\"output\"],\n    context_schema=UserInfo,\n)\n\nuser = UserInfo(id=\"123\", name=\"Alice\", gender=\"female\")\nresult = app.invoke(input={\"start\": None}, context=user)\nassert result[\"output\"] == user.__repr__()\n</code></pre>\n<p>在创建Pregel对象的时候，作为静态上下文的UserInfo类型直接以构造函数的<code>context_schema</code>参数进行声明。在调用其<code>invoke</code>方法的时候就通过context参数将指定的UserInfo对象作为静态上下文传递。静态上下文的设计初衷就是为了规避序列化的限制。它允许我们将复杂的、重量级的、带有外部依赖的对象的直接注入，而不会破坏 Pregel 模型对<code>状态一致性</code>和<code>可持久化</code>的要求。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 08:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">36</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【网络】AC控制器上AP换新并上线命令笔记##2",
      "link": "https://www.cnblogs.com/boluo0423/p/19620604",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/boluo0423/p/19620604\" id=\"cb_post_title_url\" title=\"发布于 2026-02-16 22:35\">\n    <span>【网络】AC控制器上AP换新并上线命令笔记##2</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"网络ac控制器上ap换新并上线命令笔记2\">【网络】AC控制器上AP换新并上线命令笔记##2</h1>\n<hr />\n<p>--作者：李菠萝的多样空间</p>\n<p>--创建时间：2024-12-22</p>\n<p>--更新时间：2026-2-16，修改了重复内容，修改了一些错误，调整了格式。</p>\n<hr />\n<h1 id=\"环境\">环境：</h1>\n<p>远程设备：RG-WS7880，RG-MAP852-SF</p>\n<p>远程工具：SecureCRT</p>\n<p>系统版本：Windows 10</p>\n<hr />\n<h1 id=\"视频讲解\">视频讲解：</h1>\n<p>讲解链接：</p>\n<p><a href=\"https://www.bilibili.com/video/BV1LM411S75g/\" rel=\"noopener nofollow\" target=\"_blank\">【解决方法】AC控制器上将 AP换新并上线 ##2_哔哩哔哩_bilibili</a></p>\n<hr />\n<h1 id=\"命令列表\">命令列表：</h1>\n<p><u>注释：</u></p>\n<p><u>一下命令为锐捷设备，其他厂商同理，命令稍微变化。</u></p>\n<p><u>下列的命令的顺序和日常使用中的顺序基本一致。</u></p>\n<h2 id=\"show-ap-config-summary\">show ap-config summary</h2>\n<p>列出所有创建的 AP 的配置摘要，可用“|”管道符过滤内容</p>\n<p>show ap-config summary</p>\n<p>show ap-config summary | include 1F-2</p>\n<p>show ap-config summary | include 1082.3d07.df4c</p>\n<p>我们可以通过 ap 大致的名称或 Mac 地址查到之前的配置，网络规划中 ap 的名称是有规律的，并且装维人员在通知需要更换时都会给出房间位置，我们可以通过管道符过滤这个名称进行检索，见下图：</p>\n<p><img alt=\"\" src=\"https://picx.zhimg.com/80/v2-263ad9ec8be5d15090e0bf49de11fde3_720w.png?source=ccfced1a\" /></p>\n<p>也可以通过检索原来的 ap 的 Mac 地址，来查询 ap 的名称，从而进行 ap 的配置，见下图：</p>\n<p><img alt=\"\" src=\"https://picx.zhimg.com/80/v2-a19b8a445012ef0a6b00edd1feadba39_720w.png?source=ccfced1a\" /></p>\n<h2 id=\"no-ap-config\">no ap-config</h2>\n<p>删除原先的 ap 配置</p>\n<p>no ap-config 南苑1D_206</p>\n<p><img alt=\"\" src=\"https://picx.zhimg.com/80/v2-3d96d84fc906eb0796f65bb1fe6ba7e3_720w.png?source=ccfced1a\" /></p>\n<h2 id=\"ap-config\">ap-config</h2>\n<p>创建或者进入已经存在的 ap 配置</p>\n<p>ap-config 南苑1D_206 //通过名称进入配置</p>\n<p>ap-config 1082.3d07.df4c //推荐，通过Mac进入配置</p>\n<p>提示：推荐使用 ap 的 Mac 地址进行创建，保证唯一性。若该 ap 的 Mac 地址已经被 某个 ap 的配置摘要绑定，那么使用 ap-config Mac 会自动进入已经绑定该 Mac 的 ap 配置里面。见下图：</p>\n<p><img alt=\"\" src=\"https://pica.zhimg.com/80/v2-0d5de9af041723fb9a8174f7d089a5bf_720w.png?source=ccfced1a\" /></p>\n<h2 id=\"ap-name\">ap-name</h2>\n<p>修改 ap 配置摘要的名称</p>\n<p>ap-name 南苑1D_206</p>\n<p><img alt=\"\" src=\"https://pic1.zhimg.com/80/v2-f624ae55af8902c28725ccf0ea3b8796_720w.png?source=ccfced1a\" /></p>\n<h2 id=\"show-ap-group-summary\">show ap-group summary</h2>\n<p>查看所有已经创建的 ap 组</p>\n<p>show ap-group summary</p>\n<p><img alt=\"\" src=\"https://picx.zhimg.com/80/v2-4db7cabce75ef2b2533f253720e2ed0c_720w.png?source=ccfced1a\" /></p>\n<h2 id=\"ap-group\">ap-group</h2>\n<p>将该 ap 移动到该 ap 组中</p>\n<p>ap-group 南苑1D</p>\n<p><img alt=\"\" src=\"https://pic1.zhimg.com/80/v2-56160f63c54a79ccf968620a45d9e0c2_720w.png?source=ccfced1a\" /></p>\n<hr />\n<h1 id=\"总结\">总结：</h1>\n<p>先将旧AP的配置删除，再以AP-Mac创建一个配置。</p>\n<p>进入配置模式后，改名、改AP组等等。</p>\n<p>当state状态为Run，则成功上线。</p>\n<p>当然也可以用其他的办法，可以自行探索。</p>\n<p><img alt=\"\" src=\"https://pic1.zhimg.com/80/v2-6b2b47faa4ee8e7d27266b58d110701b_720w.png?source=ccfced1a\" /></p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/boluo0423/\" target=\"_blank\">李菠萝的多样空间</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/boluo0423/p/19620604\" target=\"_blank\">https://www.cnblogs.com/boluo0423/p/19620604</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-16 22:35</span>&nbsp;\n<a href=\"https://www.cnblogs.com/boluo0423\">李菠萝的多样空间</a>&nbsp;\n阅读(<span id=\"post_view_count\">48</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}