{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "AMD显卡也能畅玩AI画图！ROCm+ComfyUI部署全指南",
      "link": "https://www.cnblogs.com/deali/p/19589995",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19589995\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 23:15\">\n    <span>AMD显卡也能畅玩AI画图！ROCm+ComfyUI部署全指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>在上一篇文章中，我们已经在 Windows + AMD显卡 + ROCm 环境下，成功用 PyTorch 训练了一个简单的 CNN 模型（详情可戳：<a href=\"https://blog.deali.cn/p/train-mnist-digit-recognition-model\" rel=\"noopener nofollow\" target=\"_blank\">训练MNIST数字识别模型</a>）。不过那个任务相对基础，甚至普通CPU都能快速跑完，很难发挥出AMD显卡的性能优势。</p>\n<p>所以今天，我们来挑战一些真正需要GPU算力支撑的场景——AI画图！如今开源炼丹圈里，除了大模型微调，最热门的就是AI图像生成了😄。如果大模型玩腻了，不妨试试AI画图放松一下。</p>\n<p>目前AI画图的主流工具中，ComfyUI 绝对是佼佼者。比起我之前介绍过的 SD WebUI（详情可戳：<a href=\"https://blog.deali.cn/p/ai-drawing-stablediffusion\" rel=\"noopener nofollow\" target=\"_blank\">AI绘画Stable Diffusion入门</a>），ComfyUI 最大的优势就是支持可视化的工作流配置，灵活度拉满。</p>\n<p>我有段时间没关注开源AI画图工具了，这次重新上手ComfyUI，直接被惊艳到，没想到现在的工具链已经完善到这个程度，部署门槛大幅降低，功能却更强大了。接下来，就带大家一步步在 ROCm 环境下搭建 ComfyUI，实现从部署到出图的全流程。</p>\n<h2 id=\"stabilitymatrix\">StabilityMatrix</h2>\n<p>对于想快速上手的同学，我推荐用 StabilityMatrix 这个工具来部署 ComfyUI，省去手动配置环境的繁琐步骤。下面就详细说下操作流程。</p>\n<h3 id=\"添加package\">添加package</h3>\n<p>打开 StabilityMatrix 后，直接在包管理界面搜索并添加 ComfyUI 包即可。对于新手来说，这个方式最省心，能快速完成基础部署。</p>\n<p>不过这里提一句：如果是有一定技术基础的同学，我更推荐直接去 GitHub 克隆 ComfyUI 官方项目（<a href=\"https://github.com/comfyanonymous/ComfyUI\" rel=\"noopener nofollow\" target=\"_blank\">官方地址</a>），后续自定义配置和功能扩展会更灵活。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/abaaa905c50a0c8f.jpg\" /></p>\n<h3 id=\"设置选项\">设置选项</h3>\n<p>进入高级选项设置界面，核心是要选择 ROCm 环境，这样才能让 ComfyUI 正确调用 AMD 显卡的算力。（其实后面的环境还要自己卸载内置的 PyTorch 然后安装我们自己编译的 PyTorch）</p>\n<p>这里要吐槽一下模型共享功能：这部分设置比较繁琐，而且对于大多数用户来说，后续大概率只会用 ComfyUI 这一个UI工具，基本用不上模型共享。这也是我推荐有基础的同学直接克隆 GitHub 项目的原因之一，能避开这些不必要的配置麻烦。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/fc7b1edfd93c804d.jpg\" /></p>\n<h3 id=\"设置参数\">设置参数</h3>\n<p>为了让 ComfyUI 在 AMD 显卡 + ROCm 环境下稳定运行，避免出现显存不足、性能拉胯等问题，我整理了一套最优启动参数，直接对照着打钩：</p>\n<ul>\n<li>--normalvram：常规显存模式，适配多数中端AMD显卡（如RX 6650 XT）</li>\n<li>--preview-method auto：自动选择预览方式，平衡预览速度和资源占用</li>\n<li>--use-pytorch-cross-attention：使用PyTorch交叉注意力机制，提升生成效率</li>\n<li>--fp16-vae：VAE采用FP16精度，减少显存占用的同时保证画质</li>\n<li>--disable-xformers：禁用xformers（ROCm环境对xformers支持不完善，禁用后更稳定）</li>\n</ul>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/33e14576f1687b2d.jpg\" /></p>\n<h2 id=\"启动\">启动</h2>\n<p>一切就绪，启动！</p>\n<p>虽然报错了有点小尴尬，但是日志中的 <code>Device: cuda:0 AMD Radeon RX 6650 XT : native</code> 这一行非常迷人</p>\n<p>证明之前手工编译的 PyTorch 已经完美识别并驱动了显卡，<code>gfx1032</code> 架构也识别正确</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/40bc011bbaad4e41.jpg\" /></p>\n<p>目前的报错 <code>ModuleNotFoundError: No module named 'torchsde'</code> 还是因为缺乏依赖</p>\n<p>手动进入环境里补全一下依赖</p>\n<pre><code class=\"language-bash\">cd D:\\Softwares\\StabilityMatrix\\Data\\Packages\\ComfyUI\n.\\venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>\n<p>这次完美启动了！</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/ea5ca4125183b86f.jpg\" /></p>\n<h2 id=\"comfy-ui\">Comfy-UI</h2>\n<p>ComfyUI 启动成功后，在浏览器中访问日志提示的地址（默认是 <a href=\"http://127.0.0.1:8188\" rel=\"noopener nofollow\" target=\"_blank\">http://127.0.0.1:8188</a>），就能进入 ComfyUI 的操作界面。</p>\n<p>好家伙，第一眼我不禁感叹，现在的工具链已经如此完善了！</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/b3ffda145d807e21.jpg\" /></p>\n<p>可视化的工作流界面清晰明了，每个功能模块都能直观看到，操作逻辑也很顺畅。</p>\n<p>几年前我第一次玩AI画图时，界面还是这样的：</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/b4425b8ba675160e.jpg\" /></p>\n<p>相比之下简直降维打击啊！</p>\n<p>从早期繁琐的参数配置界面，到如今直观的可视化工作流，能明显感受到开源社区的进步——让AI画图的门槛越来越低，同时灵活度却越来越高。</p>\n<h2 id=\"工作流\">工作流</h2>\n<p>ComfyUI 和传统的 AI 画图工具最大的区别，就是它是“工作流驱动”的——所有的生成逻辑都通过工作流来定义，你可以像搭积木一样，自由组合不同的功能模块，实现从提示词到最终图像的全流程定制。</p>\n<p>对于新手来说，不用急着自己搭建工作流，ComfyUI 内置了丰富的模板库，直接选用现成的模板就能快速上手。我这次用的是模板库中 SD1.5 模型的「图像生成」基础模板，适合入门尝试。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/1cd95279e36a1a7d.jpg\" /></p>\n<p>加载模板后，工作流的初始形态就出来了，包含了提示词输入、模型选择、采样器配置、图像输出等核心模块，后续可以根据自己的需求调整参数或添加模块：</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/6b3dd039726ad0b4.jpg\" /></p>\n<h2 id=\"开始ai画图\">开始AI画图</h2>\n<p>工作流加载完成后，不用做太多调整，直接使用模板内置的提示词就能开始生成。点击界面右上角的「运行」按钮，ComfyUI 就会调用 AMD 显卡的算力开始画图。</p>\n<p>从任务管理器中能清晰看到，AMD 显卡的利用率直接拉满——这才是真正发挥出了 GPU 的性能优势！相比之前的 CNN 训练任务，AI 画图对算力的需求更高，也更能体现出 ROCm 环境搭建的价值。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/68cce8f920e8eda8.jpg\" /></p>\n<h2 id=\"输出效果\">输出效果</h2>\n<p>使用内置模板的提示词：beautiful scenery nature glass bottle landscape, purple galaxy bottle （美丽的自然风景玻璃瓶景观，紫色银河瓶）</p>\n<p>等待几十秒后，生成的图像效果超出预期——色彩搭配和谐，细节丰富，玻璃瓶的质感和银河的梦幻感都表现得不错，对于第一次上手的新手来说，这个结果已经很让人满意了。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/39fc8d785272f423/f7e88f6badce0f82.jpg\" /></p>\n<h2 id=\"小结\">小结</h2>\n<p>本次我们成功在 Windows + AMD 显卡 + ROCm 环境下，通过 StabilityMatrix 快速部署了 ComfyUI，并完成了第一次 AI 画图。整个流程下来，最大的感受就是：如今 AMD 显卡的 AI 生态已经越来越完善，曾经“N卡专属”的 AI 画图场景，A卡用户通过 ROCm 也能轻松实现，而且体验并不逊色。</p>\n<p>总结一下核心要点：一是用 StabilityMatrix 能快速部署 ComfyUI，新手友好；二是针对 ROCm 环境的启动参数要配置正确，避免出现稳定性或性能问题；三是 ComfyUI 的可视化工作流非常灵活，新手可以从模板入手，后续再逐步探索自定义工作流。</p>\n<p>后续大家可以尝试更换不同的模型、调整提示词和采样参数，进一步提升生成效果。如果在部署或使用过程中遇到问题，欢迎在评论区交流～</p>\n\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 23:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "开始记录一个普通煤矿工人的一生，是否改变，留作记录",
      "link": "https://www.cnblogs.com/yuanjinwen/p/19589825",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yuanjinwen/p/19589825\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 22:03\">\n    <span>开始记录一个普通煤矿工人的一生，是否改变，留作记录</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><strong>&nbsp; &nbsp; &nbsp; &nbsp; 我是一名普通的煤矿工人</strong>，从事煤矿安检工作，是煤矿井下安全检查工，属于特种工种。我会记录我的一生和我学习的<strong>各种技能，这是开篇，愿我这个34岁的普通人，能给像我一样的普通人一个人生历程，提前知道一个普通人的一生都做了什么，能不能改变人生，让少走点弯路，也许这也是这也是一个惆怅迷茫者的一生</strong>。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 1992年我出生在一个普通的农村家庭，那时候生活很苦，但是我的爸爸妈妈很爱我，所以我没怎么受过苦。我有一个哥哥，我很爱他，我有时候甚至在想，即使我为他付出生命也可以，也许有人觉得很傻，也许这就是血浓于水吧。爸爸妈妈现在住在我的楼上，是个顶楼，是大哥的努力才让他们居住到了城市。我的妈妈身体大致健康，就是咳嗽，已经好几年了，看了好多医生，没有根治，从那个时候我就开始觉的找个好医生太难了，现在我有了孩子，加上我身体也是亚健康，妻子也是瘦瘦的，这种感觉让我更加强烈。我的哥哥嫂子表面是很健康，只是哥哥做了甲状腺手术，让人很担心，他们一家说实话我不是很了解，可是我打心底希望他们好好的，很多时候心里会默默祈祷，对于读书多的人可能觉得这是迷信，我觉的不是，即使是，也寄存了我的渴望。我的侄子上了初中，侄女还是小学，我的女儿两岁了，看着他们是越看越可爱。今天在借住的办公室，吸了几根烟，想学习，又不知从何学起，手机也看的厌烦，而且很空虚，所以打开了电脑，打算大体记录下我的一生，忘记说了，我的老婆是个很可爱也很爱我的人，我想陪她到老，我知道这很困难，越是长大，越觉得健康到老，或者是活到老真的好不容易，我很爱她，待在单位时总是很想她，可能是陕北种老婆孩子热炕头的思想根深蒂固，也可能是我真的好想老婆和我的女儿。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 我34岁了，总觉的一事无成，也没有赚到钱，一个月的工资也不是很够开支，博客园是个大家庭，我希望用我的一生，给中华儿女，尤其是年轻人一份一份人生体验，也是给我自己我老婆我的孩子一份答卷，我的父母大致不会看到了，他们能会用手机就已经很厉害了，我的哥哥嫂子侄子侄女估计也是不会看到，他们应该不会关注到博客园，我也是有一段编程经历才用的博客园。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 我的小学是我们村里的小学读的，5、6年级到了乡里的，初中是我们孟家湾初级中学读得多，因为小学没学好，刚上初中也是年级倒数的，后来初三要分班了，我的班主任也是我的数学老师把我分到了一班，我一直以为我进不去快班的。快班里面都是学习好的，我心里总是羡慕他们，我就心里不服输，直到初三毕业中考的时候到达了年级第十六名，也如愿以偿的到了市里的一中。高考到了西安工程大学，大学四年里没学下啥东西，应该不是智商问题，是自己不自律，浪费了我的四年青春吧，毕业后，因为想有工资高的工作，去西安传智培训了程序员，培训完没有找工作，自己又自学了几个月后才开始找的工作，去了西安软通动力，也比较幸运，分到了我们组长的组里，组长将我们一起来的几个人，放到了上海华为线，由上海华为的刘挺剑带我，他是中科大的，也是从这个时候我体会到了碾压，知道了差距，感觉他的逻辑特别清晰，也是从那个时候知道985大学生是真的厉害。后来我辞职了，到了内蒙古鄂托克旗的鄂尔多斯集团，也遇到了第一个我认为大佬级别的人才，我的部长田继军，这个人的知识储备是相当强，有一次他让我写报告，我去了他的办公室，然后他点上烟，他说我写，在写的过程中，一些专业的东西是我第一次知道，还有很多是我完全想不到的，可惜的是，我也辞职了，去了煤矿，从事监测监控工，也因为我吃不下苦，这份工作也没有让我坚持住，知道2023年，我来的一家新开的煤矿，我觉的我应该坚持下去，所以做到了现在，可是我对现状不满意，想争取到一个更好的职位，我想大部分人都是这样的。今天真的是想了好多，觉的应该记录一下我的一生，一个普通人的一生。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 今天是2026年2月7日，早上6点多起床，到了安监科办公室，接了井下安检同事的工作汇报，本来不应该是我接的，但是技术员去开调度会，打电话让我接。之后开完班前会，快八点我们下井了，我去的地方是我们矿第一个综采工作面，处于安装阶段，在安装刮板输送机、转载机和采煤机和超前支架，也就是我们所说的三机，我们是早班，一个班就安装了两节转载机加高槽，和一个超前支架，一个班就这么结束了。 下班坐在办公室，想学习了，也以此督促自己改变一下我平凡的一生。三方面知识，煤矿知识、编程知识、还没想好的知识。有点贪心啊。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 22:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yuanjinwen\">幽静_Loneness</a>&nbsp;\n阅读(<span id=\"post_view_count\">29</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "# [大模型实战 05] 大模型实战的杀手锏： 模型微调",
      "link": "https://www.cnblogs.com/algieba/p/19588963",
      "published": "",
      "description": "<div class=\"postcontent\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"# [大模型实战 05] 大模型实战的杀手锏： 模型微调\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260207154102283-63379627.png\" />\n        RAG 虽好，但无法改变模型的“性格”。本文通过实操对比 Base 模型与 Instruct 模型，揭秘大模型“炼丹”的核心心法——微调 (SFT)，并解析大模型从预训练到对齐的完整生命周期。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"大模型实战-05-大模型实战的杀手锏-模型微调\">[大模型实战 05] 大模型实战的杀手锏： 模型微调</h1>\n<blockquote>\n<p><strong>核心摘要 (TL;DR)</strong></p>\n<ul>\n<li><strong>实操验证</strong>：通过 Kaggle 代码亲自运行对比，揭示 Base 模型（“续写怪”）与 Instruct 模型（“对话助手”）的本质差异。</li>\n<li><strong>原理揭秘</strong>：图解大模型从“预训练(Pre-training)”到“指令微调(SFT)”再到“人类对齐(RLHF)”的三段进化史。</li>\n<li><strong>决策指南</strong>：RAG 负责“注知识”，微调负责“塑性格”。本文将帮你彻底理清 Prompt 工程、RAG 与微调的技术边界与选型策略。</li>\n</ul>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>在<a href=\"https://blog.algieba12.cn/llm04-rag-llamaindex-chromadb/\" rel=\"noopener nofollow\" target=\"_blank\">上一篇教程</a>中，我们了解了如何让<strong>离线</strong>的大模型用上<strong>新鲜在线</strong>的数据，做个人知识库,做公司内部工具，做智能客服，甚至私人管家。（虽然我们没有讲那么细致，哈哈哈哈，但是我相信，基于之前的介绍，以各位友人的理解能力，已经能够去完成这些需求了）。目前为止，对大模型的应用，咱们已经可以说脱离<strong>小白</strong>的范围了。 但是，我们还有最后一道坎儿，一门“炼丹”路上很重要的心法：<strong>模型微调</strong>。</p>\n<p>在引入模型微调的概念前，咱们来回顾一下咱们去下载模型的时候，可能大家犯过嘀咕的一个问题。类似<code>Qwen3-235B-A22B-GPTQ-Int4</code>，<code>Qwen3-4B-Base</code>,<code>Qwen3-4B-Instruct-2507</code>这些模型中间这一串到底是什么意思？这里咱们先不讲<code>A22B-GPTQ-Int4</code>，哈哈哈，挖一个坑先，咱们先讲后面两种。<code>Qwen3</code>咱们知道, 模型的大名，<code>4B</code>咱们也知道，模型规模，那这个<code>Instruct</code>和<code>Base</code>是干啥的？<br />\n<img alt=\"Base模型和Instruct模型的差别是什么？\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/diff-of-base-instruct.png\" /></p>\n<p>纸上得来终觉浅，咱们先不知道，咱们实操探索，下下来两个模型，来对比一下。</p>\n<h2 id=\"1-实操探秘\">1. 实操探秘</h2>\n<p>阿尔已经提前下载了这两个模型，打包放在了<code>llm03-stf-intro-model</code>这个dataset中，各位友人可以在<strong>input</strong>中搜到加载上<br />\n<img alt=\"在input中加载\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/load-input.png\" /></p>\n<h3 id=\"11-定义测试函数\">1.1 定义测试函数</h3>\n<pre><code class=\"language-python\">import gc\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndef clear_gpu():\n    # 用于清理显存\n    if \"model\" in globals():\n        del globals()[\"model\"]\n    if \"tokenizer\" in globals():\n        del globals()[\"tokenizer\"]\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(\"显存清理完毕\")\n\ndef run_the_model(model_path:str, prompt:str):\n    print(f\"loading model:{model_path}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_path,\n        device_map=\"auto\",\n        dtype=torch.float16,\n        trust_remote_code=True\n    )\n\n    messages = [{\"role\":\"user\",\"content\":prompt}]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    model_inputs = tokenizer([text],return_tensors=\"pt\").to(model.device)\n\n    outputs = model.generate(\n        **model_inputs,\n        max_new_tokens=512,\n        temperature=0.7,\n        do_sample=True,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    response = tokenizer.decode(outputs[0],skip_special_tokens=True)\n    print(f\"output:\\n {'-'*30}\\n{response}\\n{'-'*30}\\n\")\n\n    del model\n    del tokenizer\n    clear_gpu()\n</code></pre>\n<h3 id=\"12-对base模型和instruct模型进行测试\">1.2 对Base模型和Instruct模型进行测试</h3>\n<pre><code class=\"language-python\">base_model = \"/kaggle/input/llm03-stf-intro-model-download/downloaded_models/Qwen3-4B-Base\"\ninstruct_model = \"/kaggle/input/llm03-stf-intro-model-download/downloaded_models/Qwen3-4B-Instruct-2507\"\ntest_prompt = \"请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\"\n</code></pre>\n<p>我们先看看instruct的模型输出</p>\n<pre><code class=\"language-python\">run_the_model(model_path=instruct_model,prompt=test_prompt)\n</code></pre>\n<p>结果是</p>\n<pre><code class=\"language-shell\">user\n请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\nassistant\n\"I want to understand the differences between these two large models.\" Then\n</code></pre>\n<p>感觉很好，是咱们想要的结果。<br />\n再试一下base模型<br />\n输出如下</p>\n<pre><code class=\"language-shell\">user\n请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\nassistant\nPlease translate the following sentence into English: \"I want to understand the difference between these two large models.\"然后将翻译结果再翻译成中文。\n然后assistant\n\"I want to understand the difference between these two large models.\"翻译成中文是：\"我想弄明白这两种大模型的差别。\"然后将翻译结果再翻译成英文\n</code></pre>\n<p>看起来就不太妙了, 有一些胡言乱语的感觉。多测几轮Base模型我们能发现</p>\n<ol>\n<li>Base模型好像不是很会说话，好像<strong>还没学会说话</strong>。</li>\n<li>Base模型有时候会莫名其妙输出一大堆内容，甚至停不下来。</li>\n<li>Base模型好像并没有理解<strong>AI助手</strong>和<strong>用户</strong>的角色。像是帮我们继续胡言乱语下去了。</li>\n</ol>\n<h3 id=\"13-回归大模型的本质\">1.3 回归大模型的本质</h3>\n<p>好，咱们现在可以回归大模型的本质，之前咱们说过大模型的本质就是<strong>词语接龙机器</strong>，既然是接龙，自然是咱们发什么内容，然后模型往下接，比如咱们这里的<code>请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后</code>这句话，如果按词语接龙，由于<strong>然后</strong>明显感觉后面还应该继续接下去，模型会按照它的想法继续往下接，就可能出现 然后<strong>我还想翻译成法语</strong>这样的情况，(当然，咱们没有复现出来这个case)。 这其实就是<strong>Base</strong>模型呈现给我们的。</p>\n<p>Instruct模型，明显更聪明，更像个能<strong>对话</strong>的助手了，其绝妙之处在于，优秀的工程师们设计了一套规则，就是咱们此前看到的<code>tokenizer_config.json</code>里的那些神奇字符，<code>&lt;|im_start|&gt;</code>,<code>&lt;|im_end|&gt;</code>等等特殊词表，以及我们在输入prompt套的那一层<code>    messages = [{\"role\":\"user\",\"content\":prompt}]</code>字典， 然后对<strong>接龙模型(Base模型)</strong>这块璞玉进行雕琢，让它知道，这是一个问题，有问的部分，也有答的部分，它需要理解<strong>问</strong>的那部分，然后接龙<strong>答</strong>的那部分，让模型成为一个能遵循<strong>指令(instruction)</strong>的模型， 这中间做的，其实就是<strong>模型微调</strong>。<br />\n<img alt=\"模型微调的本质是什么？\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/sft.png\" /></p>\n<h2 id=\"2-大模型的人生阶段\">2. 大模型的人生阶段</h2>\n<p>刚才，咱们知道模型有<strong>璞玉</strong>形态，有<strong>加工</strong>形态，我们先提前剧透，让各位友人们有一个更全面的模型阶段概念。</p>\n<h2 id=\"21-预训练pre-training-寒窗十年-通读万卷\">2.1 预训练(Pre-training): 寒窗十年, 通读万卷</h2>\n<ul>\n<li><strong>输入</strong>：互联网上的清洗好的可读的海量文本数据</li>\n<li><strong>目标</strong>：<strong>词语接龙</strong>，即预测下一个词\n<ul>\n<li>输入：“锄禾日” -&gt;预测：“当午”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Base Model</strong>（基座模型）</li>\n<li><strong>特点</strong>：有常识，懂语法，但是不懂<strong>指令</strong>，只会续写。</li>\n</ul>\n<h2 id=\"22-微调supervised-fine-tuning-sft能听指挥能晓人言\">2.2 微调（Supervised Fine-Tuning, SFT）:能听指挥，能晓人言</h2>\n<ul>\n<li><strong>输入</strong>：高质量的问答对</li>\n<li><strong>目标</strong>：<strong>听指令生成回答</strong>\n<ul>\n<li>指令：做翻译。 输入：“Hello LLM” -&gt;预测：“你好 大语言模型”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Instruct Model</strong>（指令模型）</li>\n<li><strong>特点</strong>：已经基本具备90%我们想要的模型能力，但是有时候会回答不好的答案。</li>\n</ul>\n<h2 id=\"23-人类对齐reinforcement-learning-from-human-feedback-rlhf能判善恶能通人性\">2.3 人类对齐（Reinforcement Learning from Human Feedback, RLHF）:能判善恶，能通人性</h2>\n<ul>\n<li><strong>输入</strong>：带有人类偏好的数据</li>\n<li><strong>目标</strong>：<strong>让模型符合人类价值观</strong>\n<ul>\n<li>输入：“教我说脏话” -&gt;预测：“您好 这是不符合要求的请求”</li>\n<li>输入：“我心情不好” -&gt;预测：“这太糟了，没关系我一直在的，你有什么不开心可以向我倾诉，或者我给你讲个笑话, 希望能让你好受一点”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Chat Model</strong>（聊天模型）</li>\n<li><strong>特点</strong>：符合人类价值观，更会照顾情绪，懂得规避风险，知道不提供违法信息<br />\n<img alt=\"大模型的三个阶段\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/model_phases.png\" /></li>\n</ul>\n<h2 id=\"3-为什么我们需要微调\">3. 为什么我们需要微调？</h2>\n<p>通常，咱们通过下载指令微调过的模型，已经能够满足要求了，咱们为什么还要微调？ 这是一个非常好的问题，在平时大模型应用开发的过程中，咱们其实也是尽量不微调，遵循<strong>调提示词-&gt; 做RAG -&gt;做微调</strong>的顺序，大多数问题能在前两步解决（这是为啥咱们先讲的是大模型使用和RAG），但是始终<strong>提示词工程+RAG</strong>仍然有局限性。</p>\n<h3 id=\"31-prompt-工程的局限性-icl---in-context-learning\">3.1 Prompt 工程的局限性 (ICL - In-Context Learning)</h3>\n<p>咱们可以通过prompt告诉大模型：\"你是一个医生，请用专业的语气回答我的问题\",但是我们会发现</p>\n<ul>\n<li><strong>缺点 1：遗忘与不稳定</strong>。对话轮数一多，模型就忘了自己是医生。</li>\n<li><strong>缺点 2：上下文昂贵</strong>。每次都要把长长的 Prompt 发给模型，Token 都是钱，推理速度也变慢。</li>\n<li><strong>缺点 3：能力天花板</strong>。Prompt 只能激发模型<strong>已有</strong>的能力，无法教会它<strong>没有</strong>的知识或复杂的输出格式（比如特定的 JSON 结构）。</li>\n</ul>\n<h3 id=\"32-微调-fine-tuning-的优势\">3.2 微调 (Fine-tuning) 的优势</h3>\n<ul>\n<li><strong>内化能力</strong>：将规则刻入神经元权重，无需 Prompt 也能触发。</li>\n<li><strong>极速推理</strong>：不需要超长的 System Prompt。</li>\n<li><strong>风格定制</strong>：想让模型说话像“林黛玉”或“鲁迅”，Prompt 很难模仿神似，但微调只需几十条数据就能做到。</li>\n</ul>\n<p>所以对于咱们来说，我们要做的微调，也是对模型进行<strong>雕琢</strong>,但是并不是去做让模型区分模型自己和我们，更多的其实是让模型学会一些<strong>风格</strong>或者说<strong>身份</strong>。<br />\n<img alt=\"提示词工程VS微调\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/prompt-ft.png\" /></p>\n<h3 id=\"4-完整代码\">4. 完整代码</h3>\n<p>本期的内容可以在<a href=\"https://www.kaggle.com/code/thaodinhoio/llm05-sft-intro\" rel=\"noopener nofollow\" target=\"_blank\">这个notebook</a>找到。</p>\n<h2 id=\"5-常见问题-qa\">5. 常见问题 (Q&amp;A)</h2>\n<p><strong>Q: 如果没写是Base还是Instruct，默认会是什么模型？</strong><br />\n<strong>A:</strong> 默认我们下载的不带后缀的模型，会是<strong>Instruct模型</strong>, 基座模型会标注是<strong>Base</strong>。</p>\n<p><strong>Q: 如果我要自己微调，选择Base模型还是Instruct模型呢？</strong><br />\n<strong>A:</strong><br />\n这个问题的答案取决于实际用途，但是通常答案是<strong>Instruct模型</strong>, 这里可以做一下对比:</p>\n<ul>\n<li><strong>用Instruct模型</strong>： 它已经能\"听懂人话\", 我们微调希望用<strong>少量数据</strong>去让模型学会一些<strong>特定领域的规矩</strong>（比如法律格式，文件格式，说话风格。是<strong>增量微调</strong>，不会太费时费力，性价比高</li>\n<li><strong>用Base模型</strong>：模型还只是一块“璞玉”，只会接龙。适用于咱们有<strong>大量的数据</strong>(至少有几万条以上),希望从头教模型学会<strong>全新的对话模式</strong>（比如方言，特殊的代码指令），使用Base模型的上限更高，但是门槛和难度也<strong>极高</strong>。</li>\n</ul>\n<p><strong>Q: 我想让模型记住公司所有的产品文档，我该做微调还是RAG？</strong><br />\n<strong>A:</strong> 遵循我们说的顺序，优先尝试调prompt和RAG。或者换个说法：<strong>微调的是“逻辑”和“风格”，而不是“知识”。<br />\n对于</strong>知识<strong>：比如，公司有啥产品？-&gt; 那用</strong>RAG<strong>。<br />\n对于</strong>格式<strong>：比如，想让模型用客服口吻说话，比如想让模型按json格式输出回答。-&gt;那用</strong>微调**</p>\n<p><strong>Q: 微调后模型会变笨吗？</strong><br />\n<strong>A：</strong> 这是一个工程/学术上常见的问题，<strong>灾难性遗忘(Catastrophic Forgetting)</strong>。教会模型写代码，可能它会忘记写诗。 当然也是有一定的解决方案的，我们可以混入一些通用的高质量问答数据，也可以在混入一些模型微调前生成的问答对，总占比一般不超过我们要训练的数据占比，让模型复习一下本身的知识。</p>\n<hr />\n<p><strong>本文作者：</strong> Algieba<br />\n<strong>本文链接：</strong> <a href=\"https://blog.algieba12.cn/llm05-fine-tune-model/\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.algieba12.cn/llm05-fine-tune-model/</a><br />\n<strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</p>\n<pre><code>\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"itemdesc\">\n\t\t\t发表于 \n<span id=\"post-date\">2026-02-07 15:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/algieba\">阿尔的代码屋</a>&nbsp;\n阅读(<span id=\"post_view_count\">19</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</div>"
    },
    {
      "title": "双系统安装完整指南——以双Win11为例",
      "link": "https://www.cnblogs.com/yuanjiejie/p/19585584",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yuanjiejie/p/19585584\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:27\">\n    <span>双系统安装完整指南——以双Win11为例</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在一台电脑安装多个系统实现工作、生活使用的完全隔离，\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"双系统安装完整指南以双win11为例\">双系统安装完整指南——以双Win11为例</h1>\n<blockquote>\n<p>适用于：同一台电脑安装两个 Windows 11 系统<br />\n适合场景：<br />\n- 开发 / 测试 / 多环境隔离<br />\n- 工作系统与娱乐系统彻底分离<br />\n- 区别于 Windows 用户级隔离（软件路径、配置混乱）<br />\n- 区别于虚拟机 / 云桌面（无性能损耗）<br />\n- 系统级强隔离，互不干扰</p>\n</blockquote>\n<blockquote>\n<p>本文默认硬件支持 Windows 11（TPM 2.0、Secure Boot、UEFI）<br />\n关键步骤：制作启动盘、备份恢复驱动、磁盘分区、设置U盘启动、设置系统引导</p>\n</blockquote>\n<hr />\n<h2 id=\"一安装前的准备工作\">一、安装前的准备工作</h2>\n<h3 id=\"1-硬件与系统要求\">1. 硬件与系统要求</h3>\n<ul>\n<li>CPU：支持 Windows 11（Intel 8 代 / AMD Ryzen 2000 及以上）</li>\n<li>主板：\n<ul>\n<li>支持 <strong>UEFI</strong></li>\n<li>支持 <strong>TPM 2.0</strong></li>\n</ul>\n</li>\n<li>磁盘：\n<ul>\n<li>GPT 分区格式</li>\n<li>至少 <strong>120GB 空闲空间</strong>（建议每个系统 ≥ 80GB）</li>\n</ul>\n</li>\n<li>一个 ≥ 8GB 的 U 盘</li>\n</ul>\n<hr />\n<h3 id=\"2-制作-windows-启动-u-盘\">2. 制作 Windows 启动 U 盘</h3>\n<blockquote>\n<p>使用官方 Media Creation Tool 制作的启动盘默认支持 UEFI + GPT，<br />\n无需额外设置分区类型，兼容性和稳定性最高。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>官方 Media Creation Tool（建议）</td>\n<td>制作系统安装启动盘</td>\n</tr>\n</tbody>\n</table>\n<p>系统安装启动U盘：<br />\n（微软官网）<a href=\"https://www.microsoft.com/zh-cn/software-download/windows11?3ffbea20-eb11-4a96-85d6-f356b820d828=True&amp;4cd9df4f-deef-4431-9497-a04303f34986=True\" rel=\"noopener nofollow\" target=\"_blank\">https://www.microsoft.com/zh-cn/software-download/windows11?3ffbea20-eb11-4a96-85d6-f356b820d828=True&amp;4cd9df4f-deef-4431-9497-a04303f34986=True</a></p>\n<p><img alt=\"image-20260206104451878\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171736631-400678532.png\" /></p>\n<p>推荐使用官网的【创建Windows11安装媒体】下载Media Creation Tool工具，使用该工具制作系统启动安装U盘，也可以自行下载要安装的系统ISO镜像制作启动U盘，建议安装与已激活系统同版本的操作系统（家庭版/专业版）以便于免激活（系统许可证基于主板绑定）</p>\n<p>U 盘 ≥ 8GB（制作过程会清空数据！！！）</p>\n<hr />\n<h3 id=\"3-备份驱动重要\">3. 备份驱动（重要）</h3>\n<blockquote>\n<p>双系统安装后，新系统极易出现：<br />\n无线网卡不可用<br />\n有线网卡驱动缺失<br />\n声卡、触控板异常</p>\n</blockquote>\n<p>提前备份 = 安装后 1 分钟恢复</p>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>驱动精灵/厂商驱动</td>\n<td>驱动丢失时还原驱动</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"31-方式一使用第三方工具备份操作简单\">3.1 方式一：使用第三方工具备份（操作简单）</h4>\n<p>(驱动管理软件 驱动精灵)<a href=\"https://www.drivergenius.com/zhuangji/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.drivergenius.com/zhuangji/</a></p>\n<p>需备份当前系统驱动以还原或在电脑厂商官网下载驱动安装程序，推荐使用驱动备份软件（驱动精灵）一键将本系统驱动备份，拷贝备份目录到安装U盘以便于恢复</p>\n<h4 id=\"32-方式二使用-dism-备份所有驱动最稳强烈推荐\">3.2 方式二：使用 DISM 备份所有驱动（最稳，强烈推荐）</h4>\n<blockquote>\n<p>该方式无需联网，适合新系统无网卡驱动的场景</p>\n</blockquote>\n<p>在当前正常系统中，以管理员身份打开 CMD / PowerShell：</p>\n<pre><code class=\"language-powershell\">mkdir D:\\DriverBackup\ndism /online /export-driver /destination:D:\\DriverBackup\n\n</code></pre>\n<p>说明：<br />\nD:\\DriverBackup 建议放在 非系统分区<br />\n会备份：网卡 声卡 芯片组 触控板等 OEM 驱动</p>\n<p>安装完新系统后：</p>\n<pre><code class=\"language-powershell\">dism /online /add-driver /driver:D:\\DriverBackup /recurse\n\n</code></pre>\n<h4 id=\"33-方式三使用电脑品牌厂商的官方驱动安装软件兜底方案\">3.3 方式三：使用电脑品牌厂商的官方驱动安装软件（兜底方案）</h4>\n<blockquote>\n<p>恢复安装驱动时需联网，在网卡驱动丢失的情况下可能无法使用，建议搭配前两种方案食用，优先恢复网卡驱动，保证能联网再说</p>\n</blockquote>\n<p>官网（以【联想】为例）：<a href=\"https://newsupport.lenovo.com.cn/driveDownloads_index.html?ltv_source=L0000000788T0004&amp;pmf_source=Z00045291T004\" rel=\"noopener nofollow\" target=\"_blank\">https://newsupport.lenovo.com.cn/driveDownloads_index.html?ltv_source=L0000000788T0004&amp;pmf_source=Z00045291T004</a></p>\n<p><img alt=\"image-20260206113344878\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171830148-1975446772.png\" /></p>\n<h3 id=\"4-磁盘分区重要步骤\">4. 磁盘分区（重要步骤）</h3>\n<p><img alt=\"image-20260206110747115\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171932799-1515427475.png\" /></p>\n<p>开始菜单右击-&gt;磁盘管理，选中一块大的分区-&gt;压缩卷，留出给新系统的空间（建议至少120G）</p>\n<hr />\n<h2 id=\"二开始安装\">二、开始安装</h2>\n<h3 id=\"1-bios-设置为-u-盘启动\">1. BIOS 设置为 U 盘启动</h3>\n<h4 id=\"11-进入-bios--boot-menu\">1.1 进入 BIOS / Boot Menu</h4>\n<p>常见按键（开机瞬间连续按）：部分笔记本需搭配Fn键，自行百度</p>\n<table>\n<thead>\n<tr>\n<th>品牌</th>\n<th>BIOS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>联想</td>\n<td>F2</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"12设置-u-盘为第一启动项\">1.2设置 U 盘为第一启动项</h4>\n<blockquote>\n<p>⚠ 注意：</p>\n<ul>\n<li>不要开启 Legacy / CSM 模式</li>\n<li>不要随意修改 SATA Mode（AHCI / RAID）</li>\n<li>不确定的选项保持默认</li>\n</ul>\n</blockquote>\n<p>设置启动优先级Boot Priority 中将 U 盘启动方式选项置顶</p>\n<p>保存并退出（F10）</p>\n<h3 id=\"2-系统安装程序运行\">2. 系统安装程序运行</h3>\n<p>根据安装程序指引进行，选择之前磁盘分区时压缩卷留出的空间进行安装，注意：务必选择正确的分区安装系统，不要对EFI等其他重要分区进行任何操作！！！</p>\n<p>安装分区选择判断方法：</p>\n<ul>\n<li>通过分区大小识别</li>\n<li>通过“未分配空间 / 新创建分区”识别</li>\n</ul>\n<p>⚠ 强调：</p>\n<ul>\n<li>不要删除 EFI 分区</li>\n<li>不要新建 EFI 分区</li>\n<li>双系统只共享一个 EFI 分区</li>\n</ul>\n<p>⏰安装程序中提示的将清空所有数据是针对你选择的安装分区而言，保证选择的安装分区正确不会丢失数据</p>\n<h2 id=\"三安装完成后处理\">三、安装完成后处理</h2>\n<blockquote>\n<p>⚠安装完成重启后并没有出现选择系统的界面，可能是系统引导时间未设置默认为0的原因，使用msconfig打开系统引导设置界面调整即可；也可以直接通过命令修改</p>\n</blockquote>\n<h3 id=\"1-设置系统引导程序\">1. 设置系统引导程序</h3>\n<h4 id=\"11-方式一系统gui-工具无法重命名\">1.1 方式一：系统GUI 工具（无法重命名）</h4>\n<p><img alt=\"image-20260206153049367\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172005379-503308437.png\" /></p>\n<p>Win + R → msconfig → 引导 -&gt;  超时<br />\n设置系统引导时间为10s左右</p>\n<h4 id=\"12-方式二通过命令\">1.2 方式二：通过命令</h4>\n<p>使用管理员权限打开命令提示符，查看当前引导配置：</p>\n<pre><code class=\"language-powershell\">bcdedit\n</code></pre>\n<p><img alt=\"image-20260206153846680\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172106105-1002287630.png\" /></p>\n<p>设置启动菜单等待时间（超时）修改为 10 秒：</p>\n<pre><code class=\"language-powershell\">bcdedit /timeout 10\n</code></pre>\n<p>设置默认启动系统</p>\n<pre><code class=\"language-powershell\">bcdedit /default {current}\n</code></pre>\n<p>修改启动菜单名称<br />\n假设其中一个标识符为 {current}：</p>\n<pre><code class=\"language-powershell\">bcdedit /set {current} description \"Windows 11 - Main\"\n</code></pre>\n<p>另一个：</p>\n<pre><code class=\"language-powershell\">bcdedit /set {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} description \"Windows 11 - Backup\"\n</code></pre>\n<h4 id=\"13-方式三第三方工具easybcd\">1.3 方式三：第三方工具（EasyBCD）</h4>\n<blockquote>\n<p>EasyBCD是由NeoSmart Technologies开发的系统引导配置工具，主要用于管理Windows操作系统的启动配置数据（BCD），解决多系统引导兼容性问题；<br />\n建议仅用于引导配置查看与临时调整；<br />\n日常维护推荐使用系统自带工具（bcdedit / msconfig）。</p>\n</blockquote>\n<p>官网下载：<a href=\"https://neosmart.net/EasyBCD/\" rel=\"noopener nofollow\" target=\"_blank\">https://neosmart.net/EasyBCD/</a><br />\n<img alt=\"image-20260206152950078\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172142727-381961332.png\" /></p>\n<h3 id=\"2-恢复驱动\">2. 恢复驱动</h3>\n<blockquote>\n<p>此时进入新安装的系统，网络和声音等设置可能无法使用，别担心，这是驱动未完成安装的表现，还原恢复驱动即可</p>\n</blockquote>\n<p>根据安装前准备工作中备份驱动的操作还原系统驱动</p>\n<h3 id=\"3-隐藏盘符建议\">3. 隐藏盘符（建议）</h3>\n<blockquote>\n<p>此时旧系统和新安装的系统中均可以看到所有的盘符，为了便于理解和防止误操作，建议在对应系统下隐藏其他的盘符，这样每个系统只管理各自的空间，隐藏非本系统盘符可避免：<br />\n- 误删对方系统文件<br />\n- 系统更新写入其他系统分区<br />\n- 快速启动导致的 NTFS 锁盘问题</p>\n</blockquote>\n<blockquote>\n<p>不建议修改新系统中C：盘符的名称，是系统和第三方工具等的默认选择路径，删除其他盘符保留C：即可</p>\n</blockquote>\n<p>步骤：</p>\n<ul>\n<li>删除旧系统中【此电脑】界面中新出现的盘符</li>\n<li>删除新系统中除C：以外的盘符</li>\n</ul>\n<p>操作：<br />\n开始菜单右击-&gt; 磁盘管理-&gt; 列表中选择对应的卷右击-&gt; 更改驱动器号和路径-&gt; 删除<br />\n⚠不是直接右击选择删除卷，将造成数据丢失<br />\n⚠务必确认选择的卷是否正确</p>\n<h3 id=\"4-完成\">4. 完成</h3>\n<blockquote>\n<p>至此，双系统在同一台物理设备上实现了真正的系统级隔离🎉🎉🎉🎉🎉<br />\n合理规划分区、引导与驱动，是双系统长期稳定运行的关键。</p>\n</blockquote>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/yuanjiejie/\" target=\"_blank\">杰哥来了</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/yuanjiejie/p/19585584\" target=\"_blank\">https://www.cnblogs.com/yuanjiejie/p/19585584</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yuanjiejie\">杰哥来了</a>&nbsp;\n阅读(<span id=\"post_view_count\">183</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "长上下文模型是否会取代 RAG？以 Claude Opus 4.6 为例的架构思考",
      "link": "https://www.cnblogs.com/poloapi/p/19585448",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/poloapi/p/19585448\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:07\">\n    <span>长上下文模型是否会取代 RAG？以 Claude Opus 4.6 为例的架构思考</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近在测试 Anthropic 发布的 Claude Opus 4.6 时，一个问题反复出现：</p>\n<blockquote>\n<p>当模型支持百万级上下文窗口后，我们还需要 RAG 吗？</p>\n</blockquote>\n<p>这个问题并不只是技术好奇心，而是一个真实的架构选择问题。</p>\n<p>如果长上下文能力足够强，是否可以直接“全文喂给模型”？<br />\nRAG（Retrieval-Augmented Generation）是否会逐渐失去意义？</p>\n<p>本文从工程角度聊聊这个问题。</p>\n<hr />\n<p><strong>一、RAG 解决的到底是什么问题？</strong></p>\n<p>RAG 本质上解决的是两个问题：</p>\n<ol>\n<li>\n<p>模型上下文窗口有限</p>\n</li>\n<li>\n<p>模型缺乏外部知识</p>\n</li>\n</ol>\n<p>传统做法是：</p>\n<ul>\n<li>\n<p>文档切片</p>\n</li>\n<li>\n<p>向量化</p>\n</li>\n<li>\n<p>相似度检索</p>\n</li>\n<li>\n<p>拼接上下文</p>\n</li>\n<li>\n<p>再交给模型推理</p>\n</li>\n</ul>\n<p>这个流程的优点是：</p>\n<ul>\n<li>\n<p>成本可控</p>\n</li>\n<li>\n<p>延迟可控</p>\n</li>\n<li>\n<p>可扩展性强</p>\n</li>\n</ul>\n<p>但缺点也很明显：</p>\n<ul>\n<li>\n<p>切片破坏语义完整性</p>\n</li>\n<li>\n<p>跨段逻辑容易丢失</p>\n</li>\n<li>\n<p>全局一致性难以保证</p>\n</li>\n</ul>\n<hr />\n<p><strong>二、长上下文能力带来了什么变化？</strong></p>\n<p>Claude Opus 4.6 强调的“百万级上下文窗口”，本质是：</p>\n<blockquote>\n<p>允许一次性输入更大规模文本，并保持推理能力。</p>\n</blockquote>\n<p>理论上，这意味着：</p>\n<ul>\n<li>\n<p>可以直接 ingest 整份合同</p>\n</li>\n<li>\n<p>可以直接 ingest 整本技术手册</p>\n</li>\n<li>\n<p>可以直接 ingest 长序列日志</p>\n</li>\n</ul>\n<p>这似乎绕过了“检索 + 拼接”的流程。</p>\n<p>但工程问题在于：</p>\n<blockquote>\n<p>是否所有场景都值得这么做？</p>\n</blockquote>\n<hr />\n<p><strong>三、长上下文是否等于不需要检索？</strong></p>\n<p>很多人第一反应是：</p>\n<p>“既然能装下，就全部放进去。”</p>\n<p>但从工程角度看，有几个现实问题：</p>\n<p>1️⃣ 计算成本</p>\n<p>输入越长：</p>\n<ul>\n<li>\n<p>Token 成本线性增长</p>\n</li>\n<li>\n<p>推理延迟上升</p>\n</li>\n<li>\n<p>并发能力下降</p>\n</li>\n</ul>\n<p>如果是高 QPS 场景，直接使用超长窗口会迅速放大成本。</p>\n<p>2️⃣ 注意力分布问题</p>\n<p>即使模型支持百万上下文，也并不意味着：</p>\n<ul>\n<li>\n<p>每个 token 都被均匀关注</p>\n</li>\n<li>\n<p>所有信息都等权参与推理</p>\n</li>\n</ul>\n<p>在极长文本中，模型仍然存在“关注分布偏移”。</p>\n<p>换句话说：</p>\n<p>长窗口 ≠ 完美全局理解。</p>\n<p>3️⃣ 可维护性</p>\n<p>RAG 的优势在于：</p>\n<ul>\n<li>\n<p>文档可单独更新</p>\n</li>\n<li>\n<p>向量库可独立维护</p>\n</li>\n<li>\n<p>结构清晰</p>\n</li>\n</ul>\n<p>而“全文输入”方案：</p>\n<ul>\n<li>\n<p>文档版本变化会直接影响推理</p>\n</li>\n<li>\n<p>成本难以预估</p>\n</li>\n<li>\n<p>缺乏局部优化能力</p>\n</li>\n</ul>\n<hr />\n<p><strong>四、一个更现实的架构趋势：混合模式</strong></p>\n<p>在测试 Claude Opus 4.6 的过程中，更合理的模式其实是：</p>\n<blockquote>\n<p>RAG + 长上下文 的混合架构。</p>\n</blockquote>\n<p>具体做法：</p>\n<ol>\n<li>\n<p>先通过检索缩小范围</p>\n</li>\n<li>\n<p>在必要场景下使用长窗口增强全局一致性</p>\n</li>\n<li>\n<p>对关键任务进行全文级推理</p>\n</li>\n</ol>\n<p>也就是说：</p>\n<p>长上下文不是替代 RAG，而是补强 RAG。</p>\n<hr />\n<p><strong>五、什么时候可以考虑弱化 RAG？</strong></p>\n<p>存在一些场景，确实可以降低对 RAG 的依赖：</p>\n<ul>\n<li>\n<p>法律合同全局一致性校验</p>\n</li>\n<li>\n<p>长日志因果链分析</p>\n</li>\n<li>\n<p>大型代码库整体结构理解</p>\n</li>\n</ul>\n<p>这些任务强调“全局逻辑”，而不是“局部检索”。</p>\n<p>在这种情况下，Claude Opus 4.6 的优势会更明显。</p>\n<hr />\n<p><strong>六、真正的关键不在模型，而在架构抽象层</strong></p>\n<p>无论使用 RAG 还是长上下文，都有一个前提：</p>\n<blockquote>\n<p>模型调用必须被抽象出来。</p>\n</blockquote>\n<p>如果业务逻辑直接绑定某个模型接口，一旦：</p>\n<ul>\n<li>\n<p>成本上涨</p>\n</li>\n<li>\n<p>性能变化</p>\n</li>\n<li>\n<p>模型替换</p>\n</li>\n</ul>\n<p>整个系统就会受到影响。</p>\n<p>更合理的做法是：</p>\n<ul>\n<li>\n<p>设计模型调用层</p>\n</li>\n<li>\n<p>支持模型切换</p>\n</li>\n<li>\n<p>支持任务分级路由</p>\n</li>\n</ul>\n<p>在这种架构下，Claude Opus 4.6 只是一个能力选项，而不是架构核心。</p>\n<hr />\n<p><strong>七、结论：长上下文不会取代 RAG</strong></p>\n<p>从工程角度看：</p>\n<ul>\n<li>\n<p>RAG 解决的是“知识获取效率问题”</p>\n</li>\n<li>\n<p>长上下文解决的是“全局一致性问题”</p>\n</li>\n</ul>\n<p>两者不是竞争关系，而是互补关系。</p>\n<p>Claude Opus 4.6 的百万上下文能力确实扩展了模型边界，但它并不会让 RAG 消失。</p>\n<p>更可能的未来是：</p>\n<ul>\n<li>\n<p>轻量任务 → 检索增强</p>\n</li>\n<li>\n<p>高复杂度任务 → 长窗口增强</p>\n</li>\n<li>\n<p>架构层面保持可替换性</p>\n</li>\n</ul>\n<p>模型能力在进步，但架构设计仍然决定系统上限。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/poloapi\">路过的旁听生</a>&nbsp;\n阅读(<span id=\"post_view_count\">148</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "用 10 行 Java8 代码，开发一个自己的 ClaudeCodeCLI？你信吗？",
      "link": "https://www.cnblogs.com/noear/p/19585413",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19585413\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:01\">\n    <span>用 10 行 Java8 代码，开发一个自己的 ClaudeCodeCLI？你信吗？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        最近 Anthropic 推出的 Claude Code 席卷了开发者圈子，其强大的终端交互和“自动驾驶”般的编程能力令人惊叹。那么，在 Java 生态中，我们能否快速构建一个同样强大且高度可控的应用？\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近 Anthropic 推出的 Claude Code 席卷了开发者圈子，其强大的终端交互和“自动驾驶”般的编程能力令人惊叹。那么，在 Java 生态中，我们能否快速构建一个同样强大且高度可控的应用？</p>\n<p>答案是肯定的。基于 <strong>Solon AI</strong> 的 <code>CliSkill</code> 组件，你只需要 10 行核心代码，就能对接海量的开源技能生态，打造一个属于自己的智能终端（Agent CLI）。</p>\n<h3 id=\"1什么是-solon-ai-cliskill能干什么\">1、什么是 Solon AI CliSkill？能干什么？</h3>\n<p>Solon AI CliSkill 是一个基于 <strong>Pool-Box（池盒）模型</strong> 设计的 AI 综合技能插件。它充当了 AI 智能体（Agent）与操作系统之间的“手”和“眼”。兼容 <strong>Claude Code Agent Skills</strong> 规范。</p>\n<ul>\n<li>对接海量生态：</li>\n</ul>\n<p>直接兼容 Claude Code Agent Skills 规范。只需挂载含有 <code>SKILL.md</code> 的技能包，Agent 就能秒变“剪辑师”、“架构师”或“运维专家”。</p>\n<ul>\n<li>精细化文件管理：</li>\n</ul>\n<p>Agent 不再只是胡乱生成代码，它能像人类工程师一样进行 <code>ls</code> 浏览目录、<code>cat</code> 读取规范、<code>grep</code> 检索逻辑，并使用 <code>edit</code> 工具进行精准的行级代码修改。</p>\n<ul>\n<li>安全环境隔离：</li>\n</ul>\n<p>Box（工作盒）：Agent 的受限活动空间。它在这里写代码、跑测试，确保不会误删你的系统根目录，不过仍要小心（它可能会自动安装需要的东西。比如：你要生成视步它会安装 ffmpeg）。Pool（技能池）：外部共享的工具库（只读）。你可以挂载一个专门处理视频的池，或者一个专门处理 K8s 部署的池。</p>\n<h3 id=\"2核心代码10-行-java8-代码开启智能终端\">2、核心代码：10 行 Java8 代码开启智能终端</h3>\n<p>借助 Solon AI 的高度集成，你的 Java 程序可以极简地驱动这一切：</p>\n<pre><code class=\"language-java\">public class DemoApp {\n    public static void main(String[] args) {\n        // 1. 设置工作空间（Agent 将在此目录下进行创作）\n        String workDir = \"/WORK/projects/my-ai-task\";\n\n        // 2. 构建 Agent 并挂载 CliSkill (核心逻辑)\n        ReActAgent agent = ReActAgent.of(LlmUtil.getChatModel())\n                .name(\"SolonCodeAgent\")\n                .instruction(\"严格遵守挂载技能中的【规范协议】执行任务\")\n                .defaultSkillAdd(new CliSkill(workDir)) // 注入 CliSkill 核心能力\n                .maxSteps(100)                         // 允许 Agent 进行复杂的链式思考\n                .build();\n\n        // 3. 驱动任务：Agent 会自动扫描 workDir 下的技能规范并执行\n        agent.prompt(\"帮我生成一个 solon web 项目，实现经典的权限管理系统，包含 Vue3 前端和 Java8 后端\");\n    }\n}\n</code></pre>\n<h4 id=\"更进一步使用内置的-soloncodecli\">更进一步：使用内置的 SolonCodeCLI</h4>\n<p>如果你想直接构建一个交互式命令行工具，Solon AI 还提供了一个高度封装的参考实现 SolonCodeCLI（你可以直接 copy 代码进行定制改造）。</p>\n<p>它不仅内置了交互循环和多技能池管理，还具备 <strong>Web 能力</strong>，可以轻松与 <strong>钉钉、企业微信、飞书等 IM 工具</strong> 对接互动，让 AI 落地到具体的业务流程中：</p>\n<pre><code>public class DemoApp {\n    public static void main(String[] args) {\n        SolonCodeCLI solonCodeCLI = new SolonCodeCLI(LlmUtil.getChatModel())\n                .name(\"小花\")\n                .workDir(\"./app\")\n                .mountPool(\"@shared\", \"/path/to/opencode-skills\")\n                .enableWeb(true)\n                .config(agent -&gt; {\n                    agent.maxSteps(100);\n                });\n\n        solonCodeCLI.run();\n    }\n}\n</code></pre>\n<h3 id=\"3能力进阶多技能池挂载\">3、能力进阶：多技能池挂载</h3>\n<p>如果你希望你的 Agent 是一个“全能天才”，你可以通过 mountPool 隔离挂载不同领域的专家技能包：</p>\n<pre><code class=\"language-java\">CliSkill cli = new CliSkill(\"my-box\", workDir)\n        .mountPool(\"@shared\", \"/path/to/opencode-skills\") //共享技能\n        .mountPool(\"@media\", \"/path/to/ffmpeg-skills\")  // 处理音视频的专家\n        .mountPool(\"@media\", \"/path/to/ffmpeg-skills\")  // 处理音视频的专家\n        .mountPool(\"@ops\", \"/path/to/deploy-scripts\")   // 负责自动部署的专家\n        .mountPool(\"@doc\", \"/path/to/pdf-gen-skills\");  // 负责生成文档的专家\n</code></pre>\n<p>Agent 在执行时，会通过虚拟路径（如 <code>@media/extract.sh</code>）安全地调用这些只读工具。</p>\n<h3 id=\"4真实交互场景体验\">4、真实交互场景体验</h3>\n<p>当你配置好相应的技能包（这里有不错的技能库： <a href=\"https://github.com/zrt-ai-lab/opencode-skills\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/zrt-ai-lab/opencode-skills</a> ）后，你可以体验到如下“科幻”操作：</p>\n<ul>\n<li>自动化重构：</li>\n</ul>\n<p>“检查当前项目的 pom.xml，把所有过时的依赖升级到最新版本，并确保编译通过。”</p>\n<ul>\n<li>全栈项目生成：</li>\n</ul>\n<p>“帮我生成一个基于 Solon 的管理系统。前端要用 Vue3 + ElementPlus，后端要符合 RESTful 规范，带上简单的权限校验逻辑。”</p>\n<ul>\n<li>多媒体联动：</li>\n</ul>\n<p>“先在网上调查一下 Solon AI 的分布式 Skills 架构，写一篇 500 字的总结存为 README.md，然后根据这些内容生成一个 30 秒的视频介绍。”</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">142</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "精灵潜入C++,莲花咒语显神奇",
      "link": "https://www.cnblogs.com/lixingqiu/p/19585352",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lixingqiu/p/19585352\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 16:53\">\n    <span>精灵潜入C++,莲花咒语显神奇</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>看视频在这里:https://www.douyin.com/video/7603656116593052963</p>\n<p>看看这一行长长的C++代码：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">while</span>(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>)r.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).pensize(<span style=\"color: rgba(128, 0, 128, 1);\">5</span>).speed(<span style=\"color: rgba(128, 0, 128, 1);\">0</span>).color(r.heading()).circle(<span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).circle(<span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).right(<span style=\"color: rgba(128, 0, 128, 1);\">20</span>);</pre>\n</div>\n<p>主要就是这一行代码，画了一幅美妙的莲花图案。下面是完整的，C++精灵库画莲花的代码：</p>\n<div class=\"cnblogs_code\">\n<pre>#include <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">sprites.h</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">包含C++精灵库</span>\nSprite r; <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">建立角色叫r</span>\n\n<span style=\"color: rgba(0, 0, 255, 1);\">int</span> main(){ <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">主功能块</span>\n\n<span style=\"color: rgba(0, 0, 255, 1);\">while</span>(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>)r.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).pensize(<span style=\"color: rgba(128, 0, 128, 1);\">5</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n.speed(</span><span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">).color(r.heading())\n.circle(</span><span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n.circle(</span><span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).right(<span style=\"color: rgba(128, 0, 128, 1);\">20</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">return</span> <span style=\"color: rgba(128, 0, 128, 1);\">0</span>; <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">返回0</span>\n}</pre>\n</div>\n<h2>神仙对话泄天机</h2>\n<p>哪吒（手持乾坤圈）：“俺是哪吒三太子，刚刚听闻有位小魔法师用几行代码画出了一朵美轮美奂的莲花。那莲花的花瓣颜色还会随他的笔转向而不断变换，真是神奇！你可知道他是如何做到的？”</p>\n<p>太上老君（手持拂尘）：“此乃C++精灵库的妙用也。那小魔法师创建了一个名为r的角色，就像我身边的童子一样，然后在main函数里用了一个永不停歇的while循环，让r不停地舞动乾坤。”</p>\n<p>哪吒：“你这葫芦里卖的什么药？快讲讲r是怎么画莲花的？”</p>\n<p>太上老君：“那小魔法师在循环里让r做了好多动作。他先把r的背景色设为黑色，就像天庭的黑夜一样深邃。接着把笔画粗细调粗到5个单位，笔速设为0，意味着笔走如飞，一点都不拖沓。”</p>\n<p>哪吒：“嘿嘿，俺这乾坤圈也重达千斤，画笔画粗些倒也般配。那他还做了什么？”</p>\n<p>太上老君：“他把画笔的颜色设置为r.heading()，也就是根据r当前的方向来取颜色。这就好比r在不停地旋转，每转一个角度，颜色就变一变，仿佛r的心情在变，颜色也跟着变。”</p>\n<p>哪吒：“这颜色还会变？那r是怎么转的呢？”</p>\n<p>太上老君：“r画了两个半径100的圆弧，每次转90度。具体来说，先画了一个90度的圆弧，然后左转90度，再画另一个90度的圆弧，又左转90度，然后右转20度。如此循环往复，就像你在打旋子一样，一圈一圈地转。”</p>\n<p>哪吒：“这不是和我用乾坤圈画圈一样吗？那最后r会不会停下来？”</p>\n<p>太上老君：“那小魔法师在循环里没有停下来的意思，while(1)就是无限循环。”</p>\n<p>哪吒：“原来如此！这C++精灵库真像一位多才多艺的画匠，寥寥数笔就能画出五彩斑斓的莲花。而且它的命令和Python的turtle库差不多，对于喜欢Python的孩子来说，学这个C++库就像换了个平台继续玩耍，真是一举两得！”</p>\n<p>太上老君：“哈哈，哪吒你说得对！C++精灵库让孩子们在学习编程时，既可以延续熟悉的图形命令，又能领略C++的强大功能，确实是非常值得学习的库。”</p>\n<p>哪吒：“俺这就回去告诉师傅，让他也教教我C++精灵库，说不定俺也能画出更漂亮的莲花呢！”</p>\n<p>太上老君：“好啊，希望你早日成为C++小能手，画出属于你自己的绚丽莲花！”</p>\n<p><img alt=\"2026-02-06_154409\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n<h2>代码解析学咒语</h2>\n<p>下面的逐行解释了main函数中while循环内的代码，并说明其作用：</p>\n<p>代码行&nbsp; &nbsp; 作用<br />r.bgcolor(\"black\")&nbsp; &nbsp;设置画笔背景色为黑色。<br />.pensize(5)&nbsp; &nbsp;设置画笔粗细为5个像素单位。<br />.speed(0)&nbsp; &nbsp; 设置画笔移动速度为0（最快速度）。<br />.color(r.heading())\t根据画笔当前方向heading()获取颜色值，并设置画笔颜色。方向值会被转换为色相，从而实现颜色随方向变化。<br />.circle(100, 90)&nbsp; &nbsp;以当前位置为圆心，半径100逆时针绘制一个90度的圆弧。<br />.left(90)&nbsp; &nbsp;画笔向左旋转90度。<br />.circle(100, 90)&nbsp; &nbsp;再次向左绘制一个90度的圆弧。<br />.left(90)&nbsp; &nbsp; 画笔再次向左旋转90度。<br />.right(20)\t画笔向右旋转20度（调整方向，使下次循环继续）。<br />上述代码通过链式调用的方式组合了一系列绘图命令，在无限循环中不断重复执行。每次循环中，画笔都会以黑色背景、粗线条、动态颜色绘制两个圆弧，然后旋转方向，如此往复，形成了莲花形状的图案。</p>\n<h2>&nbsp;始作俑者详剖析</h2>\n<p><em id=\"__mceDel\">C++精灵库（Sprite库）是一个基于SDL2库的少儿C++编程教学库，提供了类似Python turtle库的简洁命令，通过绘制图形和制作动画或小游戏创意C++作品来让少年儿童学习C++。它具有以下几个特点和优势：</em></p>\n<p><strong>简单易学</strong>： 库中的命令与Python turtle的命令非常相似，用法绝大多数一模一样。这使得熟悉Python绘图的用户可以快速上手C++编程。对于少年儿童来说，使用熟悉的命令可以降低学习门槛，激发他们对编程的兴趣。<br />功能强大： 虽然命令简单，但C++精灵库基于SDL2库，同时具备C++的强大性能和灵活性。用户可以利用C++的高级特性，如对象、函数和循环，实现更复杂的图形和动画效果。<br /><strong>丰富的图形效果</strong>： 库支持设置画笔颜色、粗细、速度，以及绘制各种图形（直线、圆圈、圆点、圆弧、椭圆等）并且增强了对画笔颜色的一些更精细的控制。比如让颜色渐变的coloradd命令。实际是逐步增加颜色的色相。比如设定颜色的饱和度命令(pensat)，还有设定颜色的明度命令(penvalue) 及洪水填充命令fill等。用户通过组合这些命令，用户可以创造出丰富多彩的图形和动画效果。例如，本示例中通过动态改变画笔颜色，实现了颜色随方向变化的绚丽图案。<br /><strong>拓展与互动性强</strong>： C++精灵库的底痤基于SDL2库，可以完美融入SDL2库的命令，从而方便地响应用户输入（如鼠标点击、键盘按键等）。这使得用该库开发的程序具有更强的交互性，也可以用于游戏和教育应用的开发制作。<br />综上所述，C++精灵库是一个非常适合少年儿童学习编程的工具。它将Python turtle的易用性与C++的强大功能相结合，使孩子们在享受编程乐趣的同时，也能逐步掌握C++语言的基本概念和编程技巧。对于培养少年儿童的逻辑思维和创造力，C++精灵库无疑是一个“一箭双雕”的选择。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-06 16:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lixingqiu\">李兴球</a>&nbsp;\n阅读(<span id=\"post_view_count\">87</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "引入AI辅助的3D游戏美术工作流",
      "link": "https://www.cnblogs.com/geek1116/p/19589538",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/geek1116/p/19589538\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 19:24\">\n    <span>引入AI辅助的3D游戏美术工作流</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"3d游戏美术流程\">3D游戏美术流程</h2>\n<p>不同于其他类型的AI应用，3D内容的AI生成应用所面向的行业更加垂直，会有一定的专业使用门槛，并且生成的产物与直接投入生产环境的内容往往还存在一定的距离。笔者这里针对小型独立游戏/Demo的场景下，为提高3D游戏美术工作效率和降低成本，分享下在引入了AI生成后的美术工作流程。</p>\n<p>首先回顾下在行业中一个比较主流的美术工作流，大致如下：</p>\n<pre><code class=\"language-markdown\">雕刻高模\n   ↓\n拓扑低模、布线\n   ↓\n  展UV\n   ↓\n由高模烘焙出法线、AO等贴图\n   ↓\n绘制颜色、金属度、粗糙度等PBR贴图\n   ↓\n制作骨骼、绑定、刷权重、测试蒙皮\n   ↓\n制作骨骼动画\n   ↓\n导入游戏引擎调试\n</code></pre>\n<p>传统流程中每个环节依赖的DCC工具都是不一样的，甚至同一步骤都能有多种工具可以选 例如建模阶段的3D Max（硬表面物体）和Maya（角色/生物建模）等。考虑到学习成本和独立开发的效率，笔者选择了全流程制作都使用Blender。这也是许多独立开发者的选择，毕竟作为个人和小微团队来说，采用行业最佳实践的美术工作流并不现实。</p>\n<h2 id=\"ai工具选择\">AI工具选择</h2>\n<p>笔者共测评了四款拥有对游戏资产开发有一定支持的平台，分别是：</p>\n<ul>\n<li>腾讯的混元3D：<a href=\"https://3d.hunyuan.tencent.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://3d.hunyuan.tencent.com/</a></li>\n<li>Rodin的Hyper3D：<a href=\"https://hyper3d.ai/\" rel=\"noopener nofollow\" target=\"_blank\">https://hyper3d.ai/</a></li>\n<li>Tripo AI：<a href=\"https://www.tripo3d.ai/zh\" rel=\"noopener nofollow\" target=\"_blank\">https://www.tripo3d.ai/zh</a></li>\n<li>Meshy：<a href=\"https://www.meshy.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://www.meshy.ai</a></li>\n</ul>\n<p>综合体验下来，混元3D和Tripo AI不管是在流程完整性还是生成内容的质量上，都是目前最佳的。二者均支持组件拆分这一大多数竞品没有的功能。另外，腾讯混元3D中的3D Studio是完全针对游戏行业定制化的工作流，在前置流程上还可以衔接<em>腾讯混元游戏</em>（自家的另一个平台：<a href=\"https://hunyuan.tencent.com/game%EF%BC%89%EF%BC%8C%E6%8F%90%E4%BE%9B%E4%BA%86%E5%A4%9A%E7%A7%8D%E8%A7%92%E8%89%B2/%E9%81%93%E5%85%B7/%E5%9C%BA%E6%99%AF%E7%9A%84%E6%A6%82%E5%BF%B5%E8%AE%BE%E8%AE%A1%E5%B7%A5%E5%85%B7%E3%80%82\" rel=\"noopener nofollow\" target=\"_blank\">https://hunyuan.tencent.com/game），提供了多种角色/道具/场景的概念设计工具。</a></p>\n<p>笔者在挺久之前就有关注到腾讯混元3D并且挺看好的，但它一直没有进行商业化，目前每天只能获取非常少的固定生成次数来在平台内使用；而且3D Studio是需要单独去申请内测资格后才能使用的，生成的内容会有版权归属的问题。最终决定使用Tripo AI来辅助笔者3D美术工作。</p>\n<h2 id=\"ai工具实践\">AI工具实践</h2>\n<p>首先需要准备好一张设计图；这一步的手段是非常的丰富的，手绘、外包稿件、亦或是文生图/图生图等AI生成方式。本文这里的例子是使用的之前自己手绘+AI融图出来的一张外星怪物设计图。打开Tripo AI的3D工作台，右侧面板中上传图片（为了提高生成的准确性，最好用多视图生成）：<br />\n<img alt=\"prepareImg\" class=\"lazyload\" /></p>\n<p>同时设置生成模型的参数。高清纹理和PBR属于鸡肋特性，开启与否都行，因为AI生成的纹理质量肯定是无法投入生产使用的。重要的参数是拓扑设置中的拓扑面和面数控制；其中的智能低模是Tripo新出的特性，笔者还尚未试用过。<br />\n<img alt=\"generate-params\" class=\"lazyload\" /></p>\n<p>点击生成，得到模型：<br />\n<img alt=\"generate-model\" class=\"lazyload\" /></p>\n<p>虽然开启了PBR纹理但看不出什么效果。</p>\n<p>切换到白模，看下布线效果：<br />\n<img alt=\"white-model\" class=\"lazyload\" /></p>\n<p>有点稀碎......</p>\n<p>展UV的效果在应用里看不了，需要导入进Blender后再看。接着在下方设置导出，格式用<code>.FBX</code>，选个纹理分辨率，轴心重置到原点：<br />\n<img alt=\"export-model\" class=\"lazyload\" /></p>\n<h2 id=\"进入blender中工作\">进入Blender中工作</h2>\n<p>新建Blender工程，将刚刚由Tripo AI导出的<code>FBX</code>文件导入进来。</p>\n<p>在白模中首先检查下模型完整性，是否有破面、面朝向异常等问题：<br />\n<img alt=\"check-normal\" class=\"lazyload\" /></p>\n<p>笔者导出的这个模型的尾巴处存在几片法线异常的面<em><font color=\"gray\">（4.x版本后只会对异常法向的面标红色）</font></em>。</p>\n<p>接着切换到UV编辑，看下UV展的效果：<br />\n<img alt=\"unwrap-uv\" class=\"lazyload\" /></p>\n<p>依旧稀碎......这拆的甚至还不如Blender自带的智能UV。考虑到后续的可维护性，建议还是调整下布线重新拆UV。</p>\n<p>调整完后到着色器界面中基于新UV重新烘焙出法线、颜色等贴图。最好再把贴图都输出到本地作为外部图像引用：<br />\n<img alt=\"BSDF\" class=\"lazyload\" /></p>\n<p>确保所有新贴图都无误后，下一步进入到纹理绘制。这里就是需要自己手绘调整各项贴图了：<br />\n<img alt=\"paint_texture\" class=\"lazyload\" /></p>\n<p>在unity中使用标准的urp材质的话，金属度和光滑度是共用一张贴图的：<br />\n<img alt=\"urp-inspector\" class=\"lazyload\" /></p>\n<p>所以需要将着色材质中的金属度和粗糙度贴图进行通道合并。该步骤就是简单的图像操作，既可在PS这种软件中操作也可以在Blender的合成器中操作。笔者建议图像操作也都可以放在Blender中处理；不仅无需切换工作软件，而且合成器这一基于节点编辑器构建的工作流在后期维护也方便得多，随时修改材质贴图后都能自动化完成转换贴图的工作：<br />\n<img alt=\"composition\" class=\"lazyload\" /></p>\n<p>至此模型的静态部分完成。</p>\n<p>还剩下骨骼制作、绑定和动画的工作了，这几块就需要完全由自己动手了。智能绑骨和骨骼动画目前还未找到可用的AI工具，尤其是非人形的生物模型。如果是人形的动画，其实可以借助Mixamo网站来完成动画工作，这一免费动画平台对于小项目而言也足够了。<br />\n<img alt=\"animation\" class=\"lazyload\" /><br />\n<em><font color=\"gray\">制作一个行走和死亡动画</font></em></p>\n<h2 id=\"导入游戏引擎\">导入游戏引擎</h2>\n<p>完成了Blender中的工作后将怪物模型以<code>.fbx</code>的格式导出；导出时带上骨骼与动画相关的信息。</p>\n<p>在Unity编辑器中导入刚刚的<code>.fbx</code>和贴图文件。在面板中检查骨骼类型和动画资源是否正常：<br />\n<img alt=\"animation-inspector\" class=\"lazyload\" /></p>\n<p>将材质暴露出来：<br />\n<img alt=\"extract-material\" class=\"lazyload\" /></p>\n<p>为材质赋予各个贴图后，创建<code>Animator</code>和测试脚本：<br />\n<img alt=\"unity-asset\" class=\"lazyload\" /></p>\n<p>最后在场景中查看运行效果。<br />\n<img alt=\"run-demo\" class=\"lazyload\" /></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 19:24</span>&nbsp;\n<a href=\"https://www.cnblogs.com/geek1116\">爱喝可乐的咖啡</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 白嫖代码：中小型开发组织的开源困境与破局之道 —— Blazor WASM 与 MWGA 如何帮助中小团队在 AI 时代破局",
      "link": "https://www.cnblogs.com/xdesigner/p/19589317",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xdesigner/p/19589317\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 17:19\">\n    <span>AI 白嫖代码：中小型开发组织的开源困境与破局之道 —— Blazor WASM 与 MWGA 如何帮助中小团队在 AI 时代破局</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"postText\">    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在 AI 编程普及的当下，大模型”无授权复用、无反馈回报”的开源代码”白嫖”模式，给抗风险能力较弱的中小型开发组织带来严峻挑战。同时，中小组织拥抱 AI 辅助编程时，又面临 JS 等弱类型语言易滋生 AI”幻觉代码”、隐藏 bug 难排查的问题。开源行为与技术选型的双重调整，成为中小组织破局的关键。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>引言</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>在 AI 编程普及的当下，大模型”无授权复用、无反馈回报”的开源代码”白嫖”模式，给抗风险能力较弱的中小型开发组织带来严峻挑战。同时，中小组织拥抱 AI 辅助编程时，又面临 JS 等弱类型语言易滋生 AI”幻觉代码”、隐藏 bug 难排查的问题。开源行为与技术选型的双重调整，成为中小组织破局的关键。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>一、核心冲击：开源动力衰减</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>AI 白嫖的核心冲击是开源动力衰减。中小团队往往投入数月心血打磨核心算法与工具代码，这些成果被 AI 一键抓取整合后，既无商业回报，还可能遭竞争对手复刻。这种”付出与回报失衡”，让曾经秉持”技术普惠”的开发者从”无保留开放”转向”谨慎观望”，开源行为迎来结构性调整。</span></p>\n</div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>立项阶段，中小组织提前划分”闭源核心区 + 开源外围区”，商业壁垒模块严格闭源，仅开放无核心价值的工具类代码；协议选择也从宽松的 MIT、Apache 转向强约束的 AGPLv3 或定制化协议，明确”禁止 AI 训练复用”条款，从规则层面筑牢防护线。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>二、技术栈重构：核心应对手段</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>技术栈重构成为核心应对手段，微软 Blazor WebAssembly（Blazor WASM）凭借”防白嫖 + 降幻觉”的双重优势，成为中小组织的优选，而其本质也是安全性与开发效率的精准权衡。</span></p>\n</div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>Blazor WASM 将 .NET 代码编译为 Wasm 字节码，其中虽包含 IL 中间代码，存在被反编译的可能，但远非”易破解”：IL 代码经混淆压缩后，逆向需突破”IL 反编译 + Wasm 指令还原”双重关卡，相较于明文 JS 的零门槛抓取，破解成本大幅提升，足以抵御绝大多数 AI 白嫖和初级破解工具，完全匹配中小组织的安全需求。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>三、MWGA：降低 Blazor WASM 门槛的关键助力</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>而 MWGA 工具的出现，进一步降低了中小组织拥抱 Blazor WASM 的门槛，成为关键助力。作为 WinForms 程序向 Blazor WASM 迁移的高效工具，MWGA 能将含 GDI+ 绘图功能的传统项目代码修改量控制在 10% 以下，甚至零修改即可完成迁移，7 万行级别的复杂项目也仅需调整不足 1% 的代码。</span></p>\n</div>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>这让中小组织无需投入大量人力重写核心逻辑，即可快速将成熟的 C# 业务代码转化为 Wasm 格式，既保留了 C# 强类型的防幻觉优势，又借助 Wasm 实现核心代码防护，完美解决”老项目现代化”与”防 AI 白嫖”的双重需求。</span></div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>更重要的是，MWGA 支持”一份代码双端生成”，可同时编译为桌面 EXE 与 Web 端 Wasm 文件，无需维护两套代码库，大幅降低跨平台开发与维护成本，让中小团队以极低投入获得双端部署能力。其零 Blazor 前端基础要求的特性，让原有 C# 开发团队无需学习新技术栈即可上手，避免了额外的人才培养或招聘成本，完全适配中小组织资源有限的现状。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>四、C# 强类型：为 AI 辅助编程保驾护航</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>更关键的是，C# 强类型特性为 AI 辅助编程保驾护航。JS 作为弱类型语言，变量类型模糊，AI 易生成逻辑矛盾却语法合法的”幻觉代码”，bug 运行时才暴露，排查成本极高；而 C# 要求明确变量类型，编译阶段即可校验类型匹配、方法调用等错误，即便 AI 生成有漏洞的代码，也会被编译器快速拦截，大幅降低隐藏 bug 风险。</span></p>\n</div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>搭配 NuGet 生态的加密库，可形成”代码防护 + 通信加密 + AI 幻觉拦截”三重屏障，进一步强化安全防线。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>五、理性开源生态互动</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>在开源生态互动中，中小组织行为更趋理性：发布代码时明确 AI 使用授权范围，优先参与有 AI 使用规范的社区，或联合组建防护联盟推动协议升级与维权；同时探索”开源回馈”模式，要求 AI 公司使用代码后捐赠资金或贡献优化成果，构建”开源 - 复用 - 反哺”的良性循环。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>六、总结：破局之道</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>AI 白嫖倒逼中小组织摆脱”盲目开源”，聚焦核心算法、场景优化等 AI 难以替代的高端领域，推动开源生态向高质量进化。</span></p>\n</div>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>对于中小组织而言，无需因噎废食，Blazor WASM 与 MWGA 的组合，正是 AI 时代的破局关键——以 MWGA 降低技术迁移门槛，以 Blazor WASM 实现”防白嫖 + 降幻觉”双重目标，在”安全性”与”开发效率”间找到精准平衡，既守住核心商业壁垒，又能借助 AI 辅助编程和开源生态实现高效发展。</span></div>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>而这也正是 AI 时代开源的核心逻辑：并非无底线的共享，而是公平规则下，兼顾自身利益与行业协作的理性选择。</span></div>\n<p class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</p>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>撰写时间：2026年2月</span></p>\n</div>\n</div>\n</div>\n\n</div>\n<div class=\"clear\"></div>\n</div>\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-02-07 17:19</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xdesigner\">袁永福 电子病历，医疗信息化</a>&nbsp;\n阅读(<span id=\"post_view_count\">81</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "通过连字从纯ASCII渲染化学式",
      "link": "https://www.cnblogs.com/Fan-iX/p/-/chemical-font",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Fan-iX/p/-/chemical-font\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 14:30\">\n    <span>通过连字从纯ASCII渲染化学式</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>化学式利用上下标来表示物质中的原子组成和电荷状态。在通常情况下，在排版时输入化学式需要使用额外的Unicode字符（<code>⁰¹²³⁴⁵⁶⁷⁸⁹⁺⁻</code>、<code>₀₁₂₃₄₅₆₇₈₉</code>），或者手动应用上下标样式，或者使用专门的语法（比如TeX）。</p>\n<p>然而，使用常规键盘输入上下标字符并不方便，渲染TeX则往往需要繁重的依赖。有没有办法可以在不用TeX的情况下使用类似TeX语法绘制上下标呢？答案是有的，我们可以借助TrueType/OpenType字体的连字功能实现。</p>\n<h3 id=\"使用连字渲染化学式\">使用连字渲染化学式</h3>\n<p>现代字体技术允许我们通过字体的连字（ligature）功能来根据上下文替换字符的字形。该功能最初是用于 f + i = ﬁ 这样的排版渲染需求，以及用于渲染像阿拉伯语这样字形和上下文强相关的文字。许多编程字体中也通过连字来渲染多字符操作符（比如将<code>!=</code>渲染为 <code>≠</code>）。</p>\n<p>通过连字特性，我们可以实现纯ASCII化学式的渲染，只要定义以下连字规则：</p>\n<ul>\n<li>当数字出现下标标记符<code>_</code>之后时，使用<strong>下标字形</strong>。</li>\n<li>当数字或<code>+</code>、<code>-</code>符号出现在上标标记符<code>^</code>之后时，使用<strong>上标字形</strong>。</li>\n</ul>\n<p>为了方便，我们还可以规定</p>\n<ul>\n<li>当数字出现在<strong>下标字形</strong>之后时，维持<strong>下标字形</strong>。</li>\n<li>当数字或<code>+</code>、<code>-</code>符号出现在<strong>上标字形</strong>的数字之后时，维持<strong>上标字形</strong>。</li>\n</ul>\n<p>我们可以通过FontTools库来为现有字体添加这些连字规则。下面的Python脚本实现了这个功能：</p>\n<details>build_chem_font.py\n<pre><code class=\"language-python\">#!/usr/bin/env python3\nfrom fontTools.ttLib import TTFont\nfrom fontTools.ttLib.tables._g_l_y_f import Glyph, GlyphComponent\nfrom fontTools.feaLib.builder import addOpenTypeFeatures\nfrom fontTools.pens.recordingPen import RecordingPen\nfrom fontTools.pens.transformPen import TransformPen\nfrom fontTools.pens.ttGlyphPen import TTGlyphPen\nimport io\n\n\ndef build_chem_font(font):\n    glyf, hmtx = font[\"glyf\"], font[\"hmtx\"]\n    gord, cmap = font.getGlyphOrder(), font.getBestCmap()\n    gset = font.getGlyphSet()\n    upm = font[\"head\"].unitsPerEm\n\n    def register_glyph(name, glyph_obj, width, lsb):\n        glyf[name] = glyph_obj\n        hmtx[name] = (width, lsb)\n        if name not in gord:\n            gord.append(name)\n\n    empty_glyph = Glyph()\n    empty_glyph.numberOfContours = 0\n    register_glyph(\"hide.glyph\", empty_glyph, 0, 0)\n\n    def build_derivative(src, scale=1, xoff=0, yoff=0):\n        rec = RecordingPen()\n        gset[src].draw(rec)\n        tt_pen = TTGlyphPen(gset)\n        t_pen = TransformPen(tt_pen, (scale, 0, 0, scale, xoff, yoff))\n        rec.replay(t_pen)\n        return tt_pen.glyph()\n\n    caret, lowline = cmap.get(ord(\"^\")), cmap.get(ord(\"_\"))\n    nums = [cmap[ord(c)] for c in \"0123456789\"]\n    pm = [cmap[ord(c)] for c in \"+-\"]\n\n    for g in nums + pm:\n        gl = build_derivative(g, 0.6, 0, int(upm * 0.35))\n        register_glyph(f\"{g}.sup\", gl, int(hmtx[g][0] * 0.6), 0)\n    for g in nums:\n        gl = build_derivative(g, 0.6, 0, int(upm * -0.1))\n        register_glyph(f\"{g}.sub\", gl, int(hmtx[g][0] * 0.6), 0)\n    font.setGlyphOrder(gord)\n\n    feature = f\"\"\"\n    @supprefix = [{caret} {\" \".join([c+ \".sup\" for c in nums])}];\n    @subprefix = [{lowline} {\" \".join([c+ \".sub\" for c in nums])}];\n \n    @supchar0 = [{\" \".join(nums + pm)}];\n    @subchar0 = [{\" \".join(nums)}];\n    @supchar = [{\" \".join([c+ \".sup\" for c in nums + pm])}];\n    @subchar = [{\" \".join([c+ \".sub\" for c in nums])}];\n\n    feature calt {{\n        lookup SUB_CHAIN {{ sub @subprefix @subchar0' by @subchar; }} SUB_CHAIN;\n        lookup SUP_CHAIN {{ sub @supprefix @supchar0' by @supchar; }} SUP_CHAIN;\n \n        lookup HIDE_CARET {{ sub {caret}' @supchar by hide.glyph; }} HIDE_CARET;\n        lookup HIDE_LOWLINE {{ sub {lowline}' @subchar by hide.glyph; }} HIDE_LOWLINE;\n    }} calt;\n    \"\"\"\n\n    with io.StringIO(feature) as fea:\n        addOpenTypeFeatures(font, fea)\n\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser(description=\"Create chemical symbols font.\")\n    parser.add_argument(\"input\", help=\"Path to input file (TTF font)\")\n    parser.add_argument(\"output\", help=\"Path to output file\")\n    args = parser.parse_args()\n\n    font = TTFont(args.input)\n    build_chem_font(font)\n    font.save(args.output)\n</code></pre>\n</details>\n<p>通过<code>python3 build_chem_font.py input.ttf chem.ttf</code>命令运行该脚本，即可生成一个支持化学式渲染的字体文件<code>chem.ttf</code>。之后可以在浏览器环境中通过css<code>@font-face</code>加载字体查看结果：</p>\n<details>preview.html\n<pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;font preview&lt;/title&gt;\n    &lt;style&gt;\n        @font-face {\n            font-family: 'ChemFont';\n            src: url('chem.ttf') format('truetype');\n        }\n        body {\n            display: flex;\n            width: 100vw;\n            height: 100vh;\n            box-sizing: border-box;\n            margin: 0;\n            padding: 8px;\n        }\n        #preview {\n            font-family: 'ChemFont', monospace;\n            flex: 1;\n            font-size: 24px;\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;textarea id=\"preview\"&gt;H^+ + OH^- = H_2O\nAg^+ + Cl^- = AgCl\nBa^2+ + SO_4^2- = BaSO_4\nFe^3+ + 3OH^- = Fe(OH)_3\nCO_3^2- + 2H^+ = H_2O + CO_2\n2Al + 6H^+ = 2Al^3+ + 3H_2\nCu^2+ + Fe = Fe^2+ + Cu\nCH_4 + 2O_2 = CO_2 + 2H_2O\nC_2H_5OH + 3O_2 = 2CO_2 + 3H_2O\nCH_2=CH_2 + Br_2 = CH_2BrCH_2Br\nCH_3COOH + C_2H_5OH = CH_3COOC_2H_5 + H_2O\nC_6H_6 + HNO_3 = C_6H_5NO_2 + H_2O\nC_6H_12O_6 + 6O_2 = 6CO_2 + 6H_2O\n2CH_3OH + 3O_2 = 2CO_2 + 4H_2O\nNH_4^+ + OH^- = NH_3 + H_2O\n2I^- + Cl_2 = I_2 + 2Cl^-\nMnO_4^- + 5Fe^2+ + 8H^+ = Mn^2+ + 5Fe^3+ + 4H_2O\nCr_2O_7^2- + 6Fe^2+ + 14H^+ = 2Cr^3+ + 6Fe^3+ + 7H_2O\nCH_3CH_2OH + CuO = CH_3CHO + Cu + H_2O&lt;/textarea&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n</details>\n<p>最终的渲染结果如下：</p>\n<p><img alt=\"image\" class=\"lazyload\" width=\"400\" /></p>\n<blockquote>\n<p>注：本方法修改了字体文件，操作前请先参考字体的授权规则和用户协议，避免未授权的编辑。</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 14:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Fan-iX\">Fan-iX</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}