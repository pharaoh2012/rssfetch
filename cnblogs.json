{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "Model Context Protocol (MCP) C# SDK v0.9.0-preview.1  发布",
      "link": "https://www.cnblogs.com/shanyou/p/19628209",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shanyou/p/19628209\" id=\"cb_post_title_url\" title=\"发布于 2026-02-22 09:22\">\n    <span>Model Context Protocol (MCP) C# SDK v0.9.0-preview.1  发布</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在这一生态系统中，由开源社区发起并与微软（Microsoft）紧密合作维护的官方 C# 软件开发工具包（SDK）——modelcontextprotocol/csharp-sdk，扮演着桥接.NET 庞大企业级应用生态与前沿 AI 协议的关键角色 。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>人工智能与大型语言模型（Large Language Models, LLMs）的集成技术正在经历一场从简单的提示词工程（Prompt Engineering）向复杂的、具备强上下文感知的自主代理（Agentic）系统的深刻范式转移。在此技术演进的背景下，Model Context Protocol（MCP）作为一项旨在标准化应用程序向大语言模型提供上下文方式的开放协议，正迅速确立其作为下一代人工智能基础设施核心通信总线的地位。该协议的根本架构目标在于彻底解决模型上下文窗口的局限性以及外部系统集成的碎片化问题，从而在大型语言模型与海量企业级数据源、定制化内部工具及本地计算资源之间，建立起一条高度安全、低延迟且语义标准化的集成链路。随着以大型语言模型为核心的推理引擎对外部工具调用（Tool Calling）和状态管理的需求日益增长，MCP 协议的生态系统正在全球范围内实现指数级的繁荣。</p>\n<p>在这一生态系统中，由开源社区发起并与微软（Microsoft）紧密合作维护的官方 C# 软件开发工具包（SDK）——<a href=\"http://modelcontextprotocol/csharp-sdk\" rel=\"noopener nofollow\" target=\"_blank\">modelcontextprotocol/csharp-sdk</a>，扮演着桥接.NET 庞大企业级应用生态与前沿 AI 协议的关键角色 。该工具包目前正处于快速迭代的预览版（Preview）阶段，这意味着其 API 表面区域具有一定的流动性，旨在通过频繁的迭代收集生产环境的反馈，从而为即将到来的 1.0.0 稳定版奠定坚实的架构基础 。</p>\n<h2 id=\"c-sdk-架构拓扑与模块化分层设计体系\"><strong>C# SDK 架构拓扑与模块化分层设计体系</strong></h2>\n<p>在深入剖析 v0.9.0-preview.1 版本的增量更新细节之前，系统性地理解 MCP C# SDK 当前的架构底座是进行有效评估的先决条件。该 SDK 在架构起源上并非毫无历史包袱的从零构建，而是建立在一个名为 mcpdotnet 的早期高价值开源项目的基础之上，该项目最初由 Peder Holdgaard Pedersen 发起，并在随后的发展中被吸收和重构为官方标准的 SDK。这种演进路径保证了该工具包在设计之初就经受了真实开发场景的检验。</p>\n<p>为了满足不同企业应用场景的复杂粒度需求，并严格遵循领域驱动设计（Domain-Driven Design, DDD）中的关注点分离原则，MCP C# SDK 在整体架构设计上采用了高度模块化的分层拓扑模型。这种模型通过抽象出不同层级的依赖关系，确保了在各种.NET 宿主环境中的最大兼容性。整个体系主要由三个核心的 NuGet 依赖包构成，它们各自承担着明确的架构职责，并在网络层、协议解析层和应用集成层之间形成了清晰的边界。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">核心组件库名称</th>\n<th style=\"text-align: left;\">架构定位与核心职责</th>\n<th style=\"text-align: left;\">适用场景与工程约束</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">ModelContextProtocol.Core</td>\n<td style=\"text-align: left;\">协议原语与基础传输层。作为最底层的基石，它提供了 MCP 客户端与服务端接口的核心定义、JSON-RPC 消息模型的序列化组件以及传输层的基础契约。</td>\n<td style=\"text-align: left;\">适用于对二进制文件体积有极其严格限制的微型服务，或者仅仅需要低级别服务端 API 和客户端调用能力，且完全不依赖依赖注入（DI）容器的控制台应用程序 1。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">ModelContextProtocol</td>\n<td style=\"text-align: left;\">领域逻辑与应用层粘合剂。该主包在 Core 的基础上，深度集成了.NET 生态标准的宿主（Hosting）扩展和依赖注入服务注册机制。</td>\n<td style=\"text-align: left;\">适用于绝大多数需要构建标准 MCP 服务，但不需要将其直接暴露为独立 HTTP 端点的后台处理项目或本地边车（Sidecar）进程。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">ModelContextProtocol.AspNetCore</td>\n<td style=\"text-align: left;\">网络暴露与微服务集成层。该扩展包专门为基于 ASP.NET Core 构建的高并发 HTTP MCP 服务器设计，提供了完善的中间件管道和端点路由（Endpoint Routing）映射能力。</td>\n<td style=\"text-align: left;\">适用于需要将 MCP 服务无缝嵌入到现有云原生微服务网格中，并利用 HTTP 和 Server-Sent Events (SSE) 进行远程分布式调用的企业级生产环境。</td>\n</tr>\n</tbody>\n</table>\n<p>这种三层架构设计极大地增强了 SDK 在异构.NET 环境下的适应性。底层协议模型（如 JsonRpcMessage、McpTask、Resource、Tool 等 Schema 定义）被安全地封装在 Protocol 命名空间内，而上层的客户端实例创建（通过 McpClient.CreateAsync）和服务端生命周期管理则与具体的传输通道实现了完美解耦 1。目前，SDK 原生支持两种主流的传输机制：其一是基于标准输入/输出的进程间通信通道（StdioClientTransport 与 StdioServerTransport），这种模式使得 C# 库能够以零网络开销连接到任何兼容 MCP 的本地服务器，无论该服务器是基于 Node.js、Python 还是 Rust 编写的，从而实现了真正的语言不可知论设计。其二则是基于网络的流式 HTTP 传输（HttpClientTransport 与 StreamableHttpServerTransport），这为跨数据中心、跨组织边界的分布式 AI 代理通信提供了坚实的网络基础设施。</p>\n<h2 id=\"v090-preview1-版本核心变更全景图谱\"><strong>v0.9.0-preview.1 版本核心变更全景图谱</strong></h2>\n<p>在长达数月的工程迭代中，v0.9.0-preview.1 版本的发布标志着 C# SDK 在向 1.0.0 稳定版迈进的道路上取得了一个具有里程碑意义的突破。该版本在 GitHub 仓库中通过一系列密集的合并请求（Pull Requests），在功能协议增强、微服务生命周期管理、异常处理管道拦截以及开发者体验（Developer Experience, DX）等多个维度均进行了针对性的深度重构与修复。</p>\n<p>通过梳理该版本的发布日志（Changelog），可以清晰地映射出本次更新的核心聚焦点。这些变更不仅仅是对底层代码库的日常修补，更深刻地反映了协议设计者在处理复杂多变的 AI 代理交互时，对系统健壮性、用户终端可信度以及现代云原生可观测性特性的深度考量。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">合并请求 (PR)</th>\n<th style=\"text-align: left;\">核心贡献者</th>\n<th style=\"text-align: left;\">变更性质</th>\n<th style=\"text-align: left;\">架构级核心描述</th>\n<th style=\"text-align: left;\">关联 MCP 协议规范规范 (SEP)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>#802</strong></td>\n<td style=\"text-align: left;\">@Copilot</td>\n<td style=\"text-align: left;\">协议特性增强</td>\n<td style=\"text-align: left;\">在 SDK 核心层实现 SEP-973 规范提案：为服务器实现（Implementation）、资源（Resources）、工具（Tools）和提示词（Prompts）提供全面的视觉图标与元数据注入支持。</td>\n<td style=\"text-align: left;\">SEP-973</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>#844</strong></td>\n<td style=\"text-align: left;\">@halter73</td>\n<td style=\"text-align: left;\">架构管道优化</td>\n<td style=\"text-align: left;\">重构请求过滤器行为，允许底层工具调用引发的领域异常能够安全地穿透拦截器网络，并向上传播为结构化的协议级错误。</td>\n<td style=\"text-align: left;\">异常可观测性 / SEP-1303</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>#843</strong></td>\n<td style=\"text-align: left;\">@halter73</td>\n<td style=\"text-align: left;\">传输层缺陷修复</td>\n<td style=\"text-align: left;\">修复当连接了基于流式 HTTP（Streamable HTTP）的客户端时，宿主服务器由于资源释放竞争导致关闭极其缓慢的关键阻塞问题。</td>\n<td style=\"text-align: left;\">生命周期管理</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>#854</strong></td>\n<td style=\"text-align: left;\">@Copilot</td>\n<td style=\"text-align: left;\">工具链与 DX 改进</td>\n<td style=\"text-align: left;\">通过在配置容器中显式声明安装.NET 9.0 SDK，修复并稳定 GitHub Codespaces 中示例驱动项目的自动化构建环境。</td>\n<td style=\"text-align: left;\">CI/CD 与工具链基建</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>#862</strong></td>\n<td style=\"text-align: left;\">@Copilot</td>\n<td style=\"text-align: left;\">文档与治理</td>\n<td style=\"text-align: left;\">修复开发文档库中的断链 Markdown 链接，并强制引入基于 DocFX 的持续集成验证流水线。</td>\n<td style=\"text-align: left;\">质量保证与文档驱动开发</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>#866</strong></td>\n<td style=\"text-align: left;\">@stephentoub</td>\n<td style=\"text-align: left;\">元编程与反射优化</td>\n<td style=\"text-align: left;\">深度修正并完善了 McpServerTool、Prompt 以及 Resource 相关的元数据特性代码注释，强化智能感知体验。</td>\n<td style=\"text-align: left;\">API 可读性与强类型约束</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>#867</strong></td>\n<td style=\"text-align: left;\">@stephentoub</td>\n<td style=\"text-align: left;\">依赖卫生治理</td>\n<td style=\"text-align: left;\">从测试工程层级精准剔除容易引发冲突和包降级警告的冗余 System.Net.Http NuGet 包引用。</td>\n<td style=\"text-align: left;\">依赖管理与冲突消解</td>\n</tr>\n</tbody>\n</table>\n<p>上述各维度的变更紧密咬合，共同构成了一个更为健壮、更具表达力的 SDK 版本。以下各章节将对这些核心变更背后的技术原理、代码实现机制及其对未来应用架构的深远影响进行穷尽式的剖析。</p>\n<h2 id=\"视觉元数据注入-sep-973重塑智能体人机交互-hci-范式\"><strong>视觉元数据注入 (SEP-973)：重塑智能体人机交互 (HCI) 范式</strong></h2>\n<p>在 v0.9.0-preview.1 版本的众多协议级功能演进中，PR #802 毫无疑问是最具视觉冲击力和终端用户价值的特性引入。该合并请求在 C# SDK 的底层数据模型中完整实施了 SEP-973 协议扩展。SEP-973 的全称为“为实现、资源、工具和提示词暴露额外的元数据”（Expose additional metadata for Implementations, Resources, Tools and Prompts），其架构核心在于建立一套标准化的跨语言通信契约，允许 MCP 服务器为其向大语言模型暴露的所有功能端点动态绑定高分辨率的视觉图标（Icons）。</p>\n<h3 id=\"视觉契约的协议模式与数据结构解析\"><strong>视觉契约的协议模式与数据结构解析</strong></h3>\n<p>根据最新的 MCP 协议规范定义，视觉图标数据结构不再是简单的单一字符串链接，而是被精心设计为一个包含多维属性约束的复杂 JSON 数组模式（Array Schema）。在 C# SDK 对应的 ModelContextProtocol.Protocol 命名空间内部，这种结构被具象化为一系列强类型的 C# 对象模型。该模式的核心属性定义如下：</p>\n<ol>\n<li><strong>资源定位符 (src 字段)</strong>：这是图标的核心寻址机制。协议提供了极大的灵活性，允许该字段的值为一个绝对的 HTTP 或 HTTPS 网络资源 URL，这适用于部署在内容分发网络（CDN）上的静态企业资产；此外，它也原生支持嵌入式的 Base64 编码数据 URI（Data URI Scheme）。数据 URI 的引入至关重要，它使得部署在隔离网络环境（如物理断网的企业内网或零信任网络环境）中的 MCP 服务器，能够不依赖任何外部公网资源解析，直接将图标的二进制流以文本形式全量下发给客户端。</li>\n<li><strong>媒体类型声明 (mimeType 字段)</strong>：该字段用于指导 LLM 客户端的渲染引擎正确解析二进制数据。C# SDK 的强类型校验模型现已完整覆盖了主流的 Web 图像标准，包括标准光栅图 PNG (image/png) 和 JPEG (image/jpeg)、矢量图 SVG (image/svg+xml)，以及高压缩比格式 WebP (image/webp) 。</li>\n<li><strong>多分辨率自适应 (sizes 字段)</strong>：作为一个可选但被强烈推荐的字符串数组，该字段允许服务端预先声明图标的物理尺寸边界（例如 [\"64x64\", \"128x128\", \"256x256\"]）。这为客户端界面的自适应缩放提供了元数据支持，使得高 DPI 屏幕（如 Retina 显示器）上的客户端能够精准挑选最合适的像素流进行绘制，从而避免了图标模糊或边缘锯齿现象。</li>\n</ol>\n<p>在具体的工程实现层面，C# SDK 的设计者巧妙地利用了现有的构建器模式（Builder Pattern）和声明式特性（Declarative Attributes），为开发者提供了极其平滑的元数据注入体验。例如，在使用 ModelContextProtocol.AspNetCore 构建高并发服务器时，架构师可以在 Program.cs 的注册管道中，利用 WithServerInfo 扩展方法，直接实例化 Implementation 对象，为整个 MCP 节点定义全局视觉品牌 。同样，在更细粒度的层面，开发者可以通过 `` 或利用编程 API 动态生成的 McpServerToolCreateOptions 对象，为诸如“检索企业云盘文件”或“触发 CI/CD 构建流水线”等具体动作绑定专属的操作图标 。</p>\n<h3 id=\"架构洞察从无形调用到可信监督的体验升维\"><strong>架构洞察：从“无形调用”到“可信监督”的体验升维</strong></h3>\n<p>探讨 SEP-973 的实施，绝不能仅仅停留在数据结构的扩展上。从本质上讲，虽然大语言模型自身在云端处理的均是多维张量和无形态的文本 Token，它执行逻辑推理和网络请求完全不需要任何视觉 UI 组件的辅助，但 MCP 协议的终极应用场景必然是服务于“人机协同编排（Human-in-the-loop, HITL）”的架构网络。</p>\n<p>在未引入视觉元数据之前，当一个 LLM 客户端（如高度集成的 GitHub Copilot 侧边栏、Claude Desktop 桌面级智能体，甚至是基于网页的定制化企业级助理）触发一个远程工具调用时，终端用户的界面上往往只能渲染出一串枯燥、生硬且充满工程气息的函数签名（例如 invoke_sap_erp_transaction_v2）。这种“黑盒式”的冷漠呈现方式不仅极大地增加了非技术用户的认知负荷，更严重削弱了人类操作员对 AI 自主代理行为的信任阈值。</p>\n<p>通过在 SDK 底层完整实施 SEP-973，客户端的前端引擎现在能够拦截并在执行工具调用之前，解析并渲染与该函数严格绑定的特定徽标（例如，呈现一个带有 SAP 官方标志的图标，或是展示一个红色警告盾牌图标以指示该操作具有高危破坏性）。这种看似微小的二阶效应（Second-order effect）实际上引发了系统可用性的质变：它极大地降低了终端用户的决策延迟，增强了人类对智能体越权操作的感知能力。当复杂的系统流转以人类可快速理解、可高度识别的视觉符号动态展示时，AI 的后台执行轨迹便实现了从抽象数据流向具象化、透明化工作流的范式转移。这意味着 MCP 协议正在突破单一的“机器对机器（M2M）通信总线”定位，加速演变为兼顾“人机交互（HCI）语义工程”的综合性智能接口桥梁。</p>\n<h2 id=\"异常传播管道的韧性重构与大模型的自愈机制\"><strong>异常传播管道的韧性重构与大模型的自愈机制</strong></h2>\n<p>在分布式微服务架构中，异常状态的精准捕获、格式化转化以及安全传播，往往是决定系统最终健壮性的试金石。由核心维护者 @halter73 在 PR #844 中提交的代码变更，直击了分布式 AI 代理系统中最为薄弱的一环：深层业务逻辑错误状态向大模型客户端的无损传播。该修复机制的引入，允许在具体的工具调用（Tool Call）执行期间发生的所有未处理异常，能够安全、合规地穿透多层的 MCP 过滤器（Filters）管道，直达协议边缘。</p>\n<h3 id=\"请求过滤器流水线与异常封装原理解析\"><strong>请求过滤器流水线与异常封装原理解析</strong></h3>\n<p>为了理解这一变更的深层技术价值，必须审视 C# SDK 中对于请求生命周期的流水线设计。借鉴了 ASP.NET Core 极其成功的请求委托中间件（Middleware）概念，MCP 的请求处理管道被高度抽象为拦截器模式，核心组件包括 McpRequestFilter&lt;TParams, TResult&gt; 和负责最终执行逻辑的 McpRequestHandler&lt;TParams, TResult&gt;。当远端 LLM 请求调用某个被 `` 修饰的静态方法时，该请求的参数字典首先会被反序列化为 CallToolRequestParams，随后请求包会依次穿过开发者可能配置的鉴权、日志、速率限制等过滤器链路。</p>\n<p>在 v0.9.0-preview.1 版本发布之前，如果目标工具函数的内部逻辑抛出了业务层面的异常（例如，由于网络抖动导致的数据库死锁超时异常、由于非法的用户输入引发的 JSON 解析崩溃，或者是触及了第三方 API 的速率限制阈值而抛出的 HTTP 429 限流异常），这些非协议层的异常有极大的风险会在中间过滤器层被默认的泛型异常处理块吞噬（Swallowed）。结果是，客户端要么面临长时间的挂起等待，要么收到一个经过粗暴降级封装的、不透明的底层协议级错误（Protocol Errors）响应包 4。这种信息丢失破坏了客户端与服务端的契约完整性。</p>\n<p>通过重构内部的委托传递逻辑，PR #844 确保了具体领域逻辑引发的异常能够作为一种合法的结构化对象（通常封装于 McpException 中，这是一种专门用于表示领域层面错误的自定义异常实体 4）完整地向上方调用堆栈抛出。在触及管道最外层的协议转换器时，这些保留了完整堆栈轨迹和原始错误信息的异常，会被精确地序列化映射为符合规范的 JSON-RPC 错误响应包（对应于预定义的 McpErrorCode 枚举体系 4），然后安全地返回给正在等待的语言模型。</p>\n<h3 id=\"架构洞察错误可观测性与思维链-cot-的动态自纠错循环\"><strong>架构洞察：错误可观测性与思维链 (CoT) 的动态自纠错循环</strong></h3>\n<p>这一底层管道的改进对于现代 AI 系统的架构设计具有深远的、超出代码层面的战略意义。根据 MCP 规范管理委员会的近期规划，特别是详细记录在 SEP-1303 提案中的指导原则明确强调：由于无效的用户输入或边界条件验证失败所引发的异常，绝对应当被清晰地标记并返回为“工具执行错误（Tool Execution Errors）”，而不是被掩盖为模糊的、使人误解的基础设施级“协议错误（Protocol Errors）” 14。</p>\n<p>在当前基于高级提示词工程（Prompt Engineering）以及融合了思维链（Chain of Thought, CoT）推理能力的现代大语言模型框架中，模型实际上被赋予了一种基于环境反馈进行“反思与自我修正（Self-correction）”的高阶认知模拟能力。如果底层 C# SDK 出于所谓“安全性”或框架层面的粗心，掩盖了具体的异常上下文信息，大模型可能会陷入幻觉（Hallucination）。模型可能误以为工具已经执行成功，或者由于收到的错误信息毫无信息量（如简单的“内部服务器错误 500”）而彻底放弃当前的任务规划。</p>\n<p>相反，当高度结构化且精确的异常上下文（例如：“SqlException: 未在指定的数据库上下文中找到名为 'corporate_users' 的数据表，可能发生了拼写错误或该模式尚未迁移”）能够畅通无阻地穿透所有过滤器并返回给 LLM 时，模型的规划器可以利用这些失败数据作为新的提示词上下文。在随后的推理周期中，模型能够自主地解析这段由 C# 抛出的 SQL 错误信息，反思之前的参数生成逻辑，并自动尝试重新规划任务流——例如，通过调用 list_database_tables 工具来确认表名，随后生成修正后的工具调用参数进行重试。由此可见，异常信息的透明、无损传播不仅仅是监控和可观测性（Observability）的要求，它更是构建真正的自治（Autonomous）、高韧性智能代理工作流的绝对基石。</p>\n<h2 id=\"传输层生命周期的深度治理流式-http-客户端的优雅降级\"><strong>传输层生命周期的深度治理：流式 HTTP 客户端的优雅降级</strong></h2>\n<p>在构建跨网络的分布式系统时，传输层协议的稳定性和对连接生命周期的精准控制能力，直接决定了整个微服务网格在高压负载下的生存能力。在架构设计上，MCP C# SDK 支持两种截然不同的底层传输机制以应对多样化的部署需求：一方面是基于操作系统标准输入/输出流的 StdioServerTransport，该机制利用管道进行本地进程间通信，避免了网络堆栈的序列化开销，极其适合边车（Sidecar）容器模式 4；另一方面，则是基于现代网络协议的 StreamableHttpServerTransport 与 SseResponseStreamTransport，为需要暴露在广域网或企业服务总线上的远程微服务调用提供了标准接口。</p>\n<p>然而，针对基于流式 HTTP 通信的架构，核心开发者 @halter73 在 PR #843 中识别并修复了一个极为隐蔽但破坏力极大的生命周期管理漏洞：当基于 HTTP 的长连接客户端处于活跃连接状态时，宿主服务器在接收到停止运行信号后，会出现长达数十秒的阻塞，导致关闭进程极其缓慢 2。</p>\n<h3 id=\"sse-数据流通道与-cancellationtoken-取消标记的资源释放冲突\"><strong>SSE 数据流通道与 CancellationToken 取消标记的资源释放冲突</strong></h3>\n<p>为了深入理解该缺陷的成因，我们需要探究基于 HTTP 的 MCP 通信网络模型。为了赋予服务器向客户端主动推送异步状态变更的能力（例如，当有新的内部系统接入时触发工具列表刷新通知 ToolListChangedNotificationParams，或在执行长时间任务时推送带有进度数值的 ProgressNotificationValue 和 ProgressNotificationParams），底层传输栈广泛采用了 Server-Sent Events (SSE) 技术作为事件流的核心驱动。</p>\n<p>SSE 技术的核心逻辑在于，在客户端与服务器建立单向的 HTTP 通道并发送初始握手响应后，服务器会通过 SseEventStreamMode 4 配置将底层 TCP 连接无限期地挂起在“保持活动（Keep-Alive）”状态。在 C# 中，这种连续的数据流通常被抽象为基于 IAsyncEnumerable&lt;T&gt; 的异步状态机生成器，并由 ISseEventStreamWriter 接口负责管理数据帧的封包与网络写入操作。</p>\n<p>在标准的.NET 托管执行环境（例如 ASP.NET Core 的 IHostedService 生命周期模型）中，当触发系统级的关闭指令时（例如，在 Kubernetes 集群中触发 Pod 驱逐时容器收到 SIGTERM 信号，或是运维人员发起滚动更新指令），宿主应用会触发应用停止令牌（Application Stopping Token），尝试优雅地终止（Graceful Shutdown）所有当前处于活动状态的处理管道。然而，如果深埋在底层 SDK 传输协议内部的 SSE 循环流没有正确地侦听并绑定到这个全局的终止取消标记（Cancellation Token），或者在数据推送处于挂起（Pending）状态时未能在检测到宿主进程关闭意图时主动中断其生成器循环，那么该 HTTP 响应长连接就会固执地拒绝被释放套接字。</p>\n<p>这种未捕获的资源占用会导致整个 ASP.NET Core 服务器被卡在关闭的边缘状态，直到其内部守护进程的强制杀除超时时间（Timeout，通常根据环境配置在 5 秒到 30 秒之间不等）耗尽，最终被操作系统或容器编排引擎粗暴地强制杀死（SIGKILL）。这不仅会导致进程在内存中残留僵尸句柄，更会阻碍处于同一微服务应用内其他清理任务（如数据库事务回滚、缓冲日志刷盘）的执行。</p>\n<h3 id=\"架构洞察云原生时代的弹性伸缩困境与连接排空路径\"><strong>架构洞察：云原生时代的弹性伸缩困境与连接排空路径</strong></h3>\n<p>PR #843 修复机制的核心，在于全面疏通并严格串联了从宿主进程关闭上下文级信号，向下延伸至具体 ISseEventStreamWriter 数据流通道循环内部的 Cancellation Token 传播链条。通过精准且微观地管理连接上下文的生命周期闭环，当服务器被要求离线时，底层传输协议能够立刻响应，所有的 StreamableHttpServerTransport 会主动向客户端发送关闭帧或直接切断处于挂起状态的网络套接字，实现连接的安全排空（Connection Draining）。</p>\n<p>这一底层级别的缺陷修复，对于将 MCP C# SDK 引入企业级核心链路具有不可估量的战略意义。在当下以云原生架构（Cloud-Native Architecture）为主导的基础设施规划中，诸如无服务器计算节点（Serverless Containers，如 Azure Container Apps 或 AWS Fargate）以及自动伸缩组（Auto-scaling Groups）的高效运作，高度依赖于部署实例能够在亚秒级甚至毫秒级内迅速响应系统的启动和优雅关闭指令。</p>\n<p>如果 MCP 节点面临缓慢的关闭现象，它将引发灾难性的级联效应：在系统进行新版本灰度发布或蓝绿部署（Blue-Green Deployment）时，旧版本的实例无法按预期及时让出资源，导致发布流程超时受阻；而在流量洪峰过后的缩容（Scale-in）操作中，由于连接长时间未能释放，算力节点会被继续计费，直接推高了企业不必要的云计算财务支出。因此，协议栈底层这种对生命周期闭环管理近乎苛求的重构，实质上是满足企业级高可用性、降低总拥有成本（TCO）的必要前提条件。</p>\n<h2 id=\"开发者体验-dx-优化工程化基建与工具链的深度治理\"><strong>开发者体验 (DX) 优化、工程化基建与工具链的深度治理</strong></h2>\n<p>在评估一个开源通信协议库能否成功跨越技术采纳生命周期中的“早期采用者（Early Adopters）”鸿沟并实现大规模爆发时，开发者体验（Developer Experience, DX）往往扮演着比单纯算法性能更为关键的变量角色。通过审视 v0.9.0-preview.1 版本的更新日志可以明显发现，维护团队将大量的工程资源投入到了多项看似处于边缘、实则旨在构筑极其坚实工程化底座的优化工作之中。</p>\n<h3 id=\"拥抱net-100-sdk-与统一云端协作环境基准\"><strong>拥抱.NET 10.0 SDK 与统一云端协作环境基准</strong></h3>\n<p>针对开发协同环境，由 @Copilot 发起的 PR #854 解决了一个在现代云原生代码协作中极为典型、严重影响入门体验的问题：修复了 GitHub Codespaces 中示例项目的自动化构建失败困境。其解决路径是通过在开发容器配置（如 devcontainer.json 架构体系）中显式指定并锁定安装最新版本的.NET 10.0 SDK。</p>\n<p>在.NET 平台每年坚持发布一个带有激进性能优化大版本的严苛发布节奏下，确保全球分布的贡献者在跨越异构框架、不同操作系统的环境时能够保持绝对一致的代码生成和编译基准，是一项艰巨的治理挑战。MCP C# SDK 选择主动拥抱刚刚发布不久的.NET 10，不仅传达出该生态体系正在积极拥抱底层运行时级别改进（例如更高效的基于源生成的 JSON 序列化器架构，或在未来针对基于 AOT，即预先编译（Ahead-of-Time）发布的更深度预研）的强烈信号；同时，将 GitHub Codespaces 明确置于官方第一梯队支持的云端集成开发环境（IDE）之列，极大地降低了外部开发者为参与这一协议开源建设而需要耗费数小时搭建并调试本地环境的摩擦力，加速了知识资产的开源流动。</p>\n<h3 id=\"依赖清洗策略剥离冗余的-systemnethttp-耦合\"><strong>依赖清洗策略：剥离冗余的 System.Net.Http 耦合</strong></h3>\n<p>在项目的依赖结构治理层面，微软资深框架工程师 @stephentoub 提交的 PR #867 进行了外科手术式的精细裁剪，将引发潜在兼容性隐患的 System.Net.Http NuGet 包引用从 SDK 的测试工程层级中彻底剔除。</p>\n<p>这一动作虽然只涉及了寥寥几行配置文件的删除，却触及了.NET 框架在向现代化演进过程中的核心历史遗留问题。在当今成熟的现代.NET 运行时架构体系（自.NET Core 2.1 引入 SocketsHttpHandler 以来，历经重构直至目前的.NET 8 与.NET 9）中，HttpClient 实例及其所依赖的核心网络通信基类族，早已被深度下沉并作为一等公民无缝集成在基础类库（Base Class Library, BCL）的最核心模块之中。这种集成通常由运行时预装的 System.Net.Http.dll 原生接管。</p>\n<p>然而，如果在开发或测试项目级别的 .csproj 文件结构中，依然以历史惯性显式、外置地通过 NuGet 协议引入独立封装版本的 System.Net.Http 外部依赖包，系统将不可避免地在复杂的 MSBuild 依赖树图解析和编译恢复期间，触发“隐式包版本降级（Implicit Package Downgrade）”的严重警告。在运行时的更深层次，这种重复的依赖还可能引发令人绝望的程序集类型冲突加载异常（Type Load Exception）甚至版本地狱（Version Hell），严重破坏应用的内存稳定性和垃圾回收表现。通过执行这种坚决的依赖清洗策略，维护团队不仅净化了官方测试套件的纯洁性与执行的确定性，更向整个庞大的下游.NET 开发者社区做出了如何进行高标准依赖卫生管理（Dependency Hygiene）的专业级示范。</p>\n<h3 id=\"文档驱动的-api-治理与元数据的编译期强化\"><strong>文档驱动的 API 治理与元数据的编译期强化</strong></h3>\n<p>最后，文档体系与智能感知的质量往往直接决定了协议标准推广的成败。PR #862 和 #866 的合并联手补齐了这一维度的缺失。前者不仅批量修复了 Markdown 中的链接遗漏，还强制引入了针对 DocFX 工具链的持续集成（CI）准入验证机制；后者则由框架专家 @stephentoub 亲手修订了与诸如 、、`` 等核心属性息息相关的源代码级 XML 元数据注释区块。</p>\n<p>DocFX 是目前.NET 开源生态内公认的、用于从高维源代码接口以及 Markdown 文档群落中自动化构建生成静态 API 文档的工业级标准引擎平台。将 DocFX 的文档树构建过程硬性纳入 CI 流水线的守门员环节，代表着开发团队确立了一种不妥协的原则：任何试图修改公共 API 签名、或者由于疏忽导致接口描述缺失而使得 API 文档生成器报告失败的代码合并请求（Pull Request），都会被自动化防御网无情拦截。这种“文档即代码（Docs as Code）”的严酷但高效的工程范式，结合对代码 XML 注释块中 &lt;summary&gt; 和 &lt;param&gt; 标记的细致润色，确保了 v0.9.0-preview.1 版本在使用 Visual Studio 或 Rider 开发时，其内联的智能感知（IntelliSense）提示达到了企业级生产框架应有的严谨度和信息密度。当应用层架构师在代码编辑器中键入配置对象如 McpServerOptions 或属性标记时，准确、毫无歧义的内嵌说明文档将直接缩短认知链路，极大地加速复杂业务领域逻辑向大模型对接的研发周期。</p>\n<h2 id=\"对齐-mcp-规范未来路线图采样启发式交互与持久化异步任务\"><strong>对齐 MCP 规范未来路线图：采样、启发式交互与持久化异步任务</strong></h2>\n<p>在全面审视了 v0.9.0-preview.1 版本的当前成就后，必须将其置于 MCP 协议规范整体时间轴的宏观视角下进行考量。目前，C# SDK 的研发进度正在与目标于 2025 年 11 月 25 日发布的下一代 MCP 稳定版规范（2025-11-25 规范里程碑）保持高度战略协同。透过追踪协议社区近期的 SEP (Standard Extension Proposals) 标准扩展提案，并结合 C# SDK 当前的底层能力预置，可以清晰地描绘出未来几个次要版本甚至 1.0.0 稳定版在系统架构上的演进脉络。</p>\n<h3 id=\"任务驱动型交互与持久化协议生命周期-sep-1686-预览\"><strong>任务驱动型交互与持久化协议生命周期 (SEP-1686 预览)</strong></h3>\n<p>传统的大模型函数调用机制存在一个固有缺陷，即它通常局限于同步且短生命周期的执行流中。当智能体需要编排并触发一个长达数十分钟甚至数小时的高延迟后端任务（例如在云端拉起一个包含数百个节点的 Spark 集群进行大数据 MapReduce 汇总，或者等待人工进行财务转账审核）时，基于同步的 HTTP 或标准输入输出（Stdio）请求管道必然会面临严重的网络连接保活和响应超时的技术挑战。</p>\n<p>在最新勾勒的 MCP 路线图以及起草中的 SEP-1686 实验性规范提案中，专门用于处理具有长生命周期特征的请求的任务接口（Tasks API）正在被加速孵化。尽管在 v0.9.0-preview.1 的更新通报中，针对任务逻辑的显式调整较少被提及，但在深入查阅 SDK 最新的基础架构 API 文档时，我们能够敏锐地发现包括 CallToolMcpTasksCapability、CreateMessageMcpTasksCapability 在内的高级接口定义，以及旨在为本地开发测试提供内存驱动机制的 InMemoryMcpTaskStore 存储模型，均已经安静地潜伏在系统底层的声明中。</p>\n<p>这些迹象表明，SDK 正在为架构重构铺设跑道，以期在未来完全支持一种兼具“异步轮询（Polling）”与“延迟结果检索（Deferred Result Retrieval）”机制的持久化请求范式。借助这种能力，大语言模型将从仅仅作为“即时查询问答系统”的桎梏中解放出来，蜕变为能够真正独立触发持久化异步流程并监控复杂基础设施状态转移图的自治代理中枢引擎。</p>\n<h3 id=\"标准化约束模式-sep-1330-与动态敏感信息启发机制-elicitation\"><strong>标准化约束模式 (SEP-1330) 与动态敏感信息启发机制 (Elicitation)</strong></h3>\n<p>在企业级应用开发场景中构建安全可靠的人机协同业务流时，一个经常被忽略但至关重要的环节是：大语言模型往往在推理到某个特定阶段时，缺乏执行最终危险动作（如更新数据库记录）所必须的明确上下文。此时，模型必须主动向人类操作员发起带有选项约束的反向请求。MCP 协议从架构层面引入了“启发式协议（Elicitation Protocol）”来彻底规范化这一互动过程。</p>\n<p>在向 2025 年新规范的过渡中，SEP-1330 提案深度重构了启发式请求相关的返回结果类型定义（如 ElicitResult）及其核心依赖枚举模式（EnumSchema），强制采纳了一种更为符合现代行业标准的强类型验证模式。新的规范细化支持了包含人类可读标题的枚举、无标题的原始值枚举，以及更复杂的单选与多选条件约束机制 13。</p>\n<p>与之相辅相成的是 SEP-1036 提案所引入的 URL 模式启发机制（URL Mode Elicitation），特别用于处理敏感鉴权数据（如 OAuth 令牌提取）的安全传输。在 C# SDK 的类型系统映射中，我们可以观察到已经为诸如 ElicitationMcpTasksCapability、ElicitRequestParams、甚至是表示复杂约束模型的 EnumSchema、BooleanSchema 等类库结构进行了细致入微的强类型包装构建。这种演进带来的战略红利显而易见：后端架构师能够运用严格的安全规则，以带有强格式约束的选项列表去限制大模型生成指令的发散性，彻底消除幻觉带来的不可控风险，确保复杂的智能体决策树始终在业务合规且高度安全的受限状态空间内进行游走。</p>\n<h3 id=\"多维鉴权架构增强与-oauth-协议的深度整合\"><strong>多维鉴权架构增强与 OAuth 协议的深度整合</strong></h3>\n<p>另一个不能忽视的宏观趋势是在通信授权链路层面的重塑。在构建能够跨越异构企业服务总线的零信任 AI 互联架构中，传统的静态 API 令牌模式已经显得过于脆弱。从规范文档中可以看到，针对 OAuth 2.0 及更高版本鉴权机制的系统性支持正在占据主导地位。</p>\n<p>包括引入支持递增式授权范围请求（Incremental Scope Consent）的 WWW-Authenticate 头部扩展（SEP-835），以及利用 OpenID Connect Discovery 1.0 标准进一步规范保护资源元数据的自动发现与探索逻辑（SEP-985、SEP-991）。C# SDK 也在其 ModelContextProtocol.Authentication 甚至 ASP.NET Core 特有的 ModelContextProtocol.AspNetCore.Authentication 体系下（包含 McpAuthenticationHandler、DynamicClientRegistrationOptions 等复杂抽象机制）预置了丰富的认证处理器模型，预示着未来围绕大语言模型的上下文集成将被纳入企业级身份访问管理（IAM）的严密安全监控伞之下。</p>\n<h2 id=\"企业级架构体系演进总结与高级落地策略展望\"><strong>企业级架构体系演进总结与高级落地策略展望</strong></h2>\n<p>在对 modelcontextprotocol/csharp-sdk 发布版本 v0.9.0-preview.1 进行了深度的切片式解剖与全面架构审查之后，本报告清晰地展示了，该基于.NET 技术栈的开源协议实现正经历从单纯的概念验证（Proof of Concept）向应对极度复杂的企业级生产就绪架构的关键性跃迁。</p>\n<p>通过精准实施 SEP-973 协议标准，以极其丰富和多元的数据结构全面涵盖 UI 渲染所需的各类视觉图标和业务元数据的注入通道 2，该 SDK 为前端工程师和架构师共同构建具备高度可解释性、可预测性的下一代企业级“人工智能副驾驶（Copilot）”操作控制台界面奠定了不可或缺的设计基石。与此同时，通过极为细致入微且高度针对性地修复了存在于 Streamable HTTP 长连接通信底层的慢速资源释放漏洞 2，协议底层不仅排除了令人头疼的内存和网络套接字泄漏风险，更在直接面对极其严苛和充满变数的现代微服务生命周期编排场景（诸如 Kubernetes 弹性容器 Pod 的频繁销毁、迁移和水平自适应缩放等）时，展现出了令人瞩目的系统弹性和恢复能力。</p>\n<p>更为核心的是，针对工具内部抛出的领域级异常在其穿越多层过滤器（Filters）和拦截器向上溯源传播时进行的机制优化 2，在实质上补齐了构建完全闭环的代理式（Agentic）智能反馈验证链路中最后、也是最核心的一块架构短板。这一优化举措彻底扭转了过去大模型在遇到不透明系统错误时束手无策的窘境，赋予了语言模型在实际执行受挫、遭遇边界错误和环境限制时，能够自主提取准确错误日志进行逻辑层面的深度纠偏与自我修复迭代的可能。叠加多项诸如拥抱.NET 9 工具链支持、强力剥离引发潜在类型冲突和降级隐患的 System.Net.Http 历史遗留依赖、以及引入强制执行的严格 DocFX 文档代码持续集成校验网等工程化治理举措 2，这些变更共同印证了该开源项目的核心维护开发团队，对于现代分布式系统编程工程化规范和长期可维护性所抱有的极致追求。</p>\n<p>随着迈向全面遵守并实施目标为 2025-11-25 版协议规范的 1.0.0 稳定商业级版本发布之日的逐步临近，对于目前正在大规模采用 C# 语言体系作为核心后端服务架构堆栈的庞大企业和组织而言，MCP C# SDK 已然不再只是一个存在于 GitHub 实验边缘、供少数极客把玩的周边工具库。恰恰相反，它正在迅速崛起，成为通往构建基于超大规模领域知识整合、深度融合高度受控且安全的结构化 API 工具链的下一代自主通用人工智能（AGI）商业落地应用的核心通信总线与调度枢纽。</p>\n<p>企业内部的首席架构师团队以及从事 AI 系统集成的资深高级开发专家，应当敏锐捕捉这一技术趋势，并在当前相对灵活的预览阶段就积极主动地投入工程力量，密切跟踪并调整现有内部系统代码以适应其底层 API 模式、尤其是基于 McpRequestFilter 的高级请求拦截管道的变化。特别是在异常精准捕获和多维映射隔离、跨网域传输层生命周期的优雅闭环管理策略实施，以及深度动态元数据和上下文配置同步这些核心架构领域投入资源进行前瞻性的技术重构和验证实验。</p>\n<p>可以极具信心地预见，随着该套协议规范及其关联的官方工具链向 1.0.0 阶段的进一步磨合与成熟，大型生成式语言模型与基于.NET 构建的既有极其庞大且复杂的企业业务流控系统的深水区集成速度，将不可逆转地迎来真正的指数级提升。这不仅将彻底打破并粉碎以往长期横亘在充满发散性和不确定性的非结构化自然语言交互入口，与要求极度严密、零容错的结构化底层业务微服务群组之间那道无形而坚固的信息壁垒，更将开启一个使得真正的企业级多智能体协同（Multi-Agent Collaboration）架构和全自动化高度自适应（Adaptive）商业决策流转机制得以在生产环境中全面落地的崭新纪元。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>\n<img src=\"https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg\" width=\"170\" />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-22 09:22</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shanyou\">张善友</a>&nbsp;\n阅读(<span id=\"post_view_count\">3</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "关于 MicroPython + ESP32-S3 的使用流程",
      "link": "https://www.cnblogs.com/tokepson/p/19628425",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tokepson/p/19628425\" id=\"cb_post_title_url\" title=\"发布于 2026-02-22 01:30\">\n    <span>关于 MicroPython + ESP32-S3 的使用流程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>好的！我来帮你从零开始完整梳理 <strong>MicroPython + ESP32-S3</strong> 的开发流程。</p>\n<h2 id=\"-完整搭建流程\">📋 <strong>完整搭建流程</strong></h2>\n<h3 id=\"第一步准备工作\"><strong>第一步：准备工作</strong></h3>\n<h4 id=\"11-硬件准备\">1.1 硬件准备</h4>\n<ul>\n<li>✅ ESP32-S3 开发板</li>\n<li>✅ USB 数据线（最好带数据传输功能）</li>\n<li>✅ Windows电脑</li>\n</ul>\n<h4 id=\"12-软件准备\">1.2 软件准备</h4>\n<pre><code class=\"language-bash\"># 1. 安装 Python（如果还没安装）\n# 访问 https://www.python.org/downloads/ 下载安装\n# 安装时勾选 \"Add Python to PATH\"\n\n# 2. 验证Python安装\npython --version\n\n# 3. 安装 esptool（刷写工具）\npip install esptool\n\n# 4. 安装串口驱动（根据你的开发板）\n# CP210x驱动：https://www.silabs.com/developers/usb-to-uart-bridge-vcp-drivers\n# CH340驱动：http://www.wch.cn/download/CH341SER_EXE.html\n</code></pre>\n<h3 id=\"第二步下载固件\"><strong>第二步：下载固件</strong></h3>\n<h4 id=\"21-下载-micropython-固件\">2.1 下载 MicroPython 固件</h4>\n<ul>\n<li>官方下载地址：<a href=\"https://micropython.org/download/\" rel=\"noopener nofollow\" target=\"_blank\">https://micropython.org/download/</a></li>\n<li>选择 <strong>ESP32S3</strong> 或 <strong>GENERIC_S3</strong></li>\n<li>下载 <code>.bin</code> 文件（你已经有：<code>ESP32_GENERIC_S3-20251209-v1.27.0.bin</code>）</li>\n</ul>\n<h3 id=\"第三步刷写固件\"><strong>第三步：刷写固件</strong></h3>\n<h4 id=\"31-连接开发板\">3.1 连接开发板</h4>\n<ol>\n<li>用USB线连接ESP32-S3到电脑</li>\n<li>按住开发板上的 <strong>BOOT</strong> 按钮</li>\n<li>按一下 <strong>RESET</strong> 按钮（或重新插拔USB）</li>\n<li>松开 <strong>BOOT</strong> 按钮</li>\n<li>此时开发板进入刷写模式</li>\n</ol>\n<h4 id=\"32-查找串口号\">3.2 查找串口号</h4>\n<pre><code class=\"language-bash\"># 查看可用的串口\npython -m serial.tools.list_ports\n# 或打开设备管理器查看 \"端口(COM和LPT)\"\n# 通常显示为 COM3、COM4 等\n</code></pre>\n<h4 id=\"33-擦除flash重要\">3.3 擦除Flash（重要！）</h4>\n<pre><code class=\"language-bash\"># 替换 COM4 为你的实际端口\npython -m esptool --chip esp32s3 --port COM4 erase_flash\n</code></pre>\n<h4 id=\"34-刷写固件\">3.4 刷写固件</h4>\n<pre><code class=\"language-bash\"># 注意修改路径和端口\npython -m esptool --chip esp32s3 --port COM4 write_flash 0x0 \"C:\\Users\\16673\\Desktop\\ESP32_GENERIC_S3-20251209-v1.27.0.bin\"\n</code></pre>\n<h3 id=\"第四步安装开发环境\"><strong>第四步：安装开发环境</strong></h3>\n<h4 id=\"41-安装-thonny-ide推荐新手\">4.1 安装 Thonny IDE（推荐新手）</h4>\n<ol>\n<li>下载地址：<a href=\"https://thonny.org/\" rel=\"noopener nofollow\" target=\"_blank\">https://thonny.org/</a></li>\n<li>安装后打开</li>\n<li>配置：\n<ul>\n<li>菜单栏：运行 → 选择解释器</li>\n<li>选择 <strong>MicroPython (ESP32)</strong></li>\n<li>端口选择 <strong>COM4</strong>（或你的端口）</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"42-或安装命令行工具\">4.2 或安装命令行工具</h4>\n<pre><code class=\"language-bash\"># 安装 ampy（文件传输）\npip install adafruit-ampy\n\n# 安装 rshell（交互式shell）\npip install rshell\n\n# 安装 picocom/mRemoteNG（串口工具）\n</code></pre>\n<h3 id=\"第五步测试连接\"><strong>第五步：测试连接</strong></h3>\n<h4 id=\"51-使用-thonny-测试\">5.1 使用 Thonny 测试</h4>\n<pre><code class=\"language-python\"># 在Thonny的Shell中看到 &gt;&gt;&gt; 提示符后输入：\nprint(\"Hello ESP32-S3!\")\n\n# 查看固件信息\nimport sys\nprint(sys.version)\nprint(sys.implementation)\n</code></pre>\n<h4 id=\"52-使用命令行测试\">5.2 使用命令行测试</h4>\n<pre><code class=\"language-bash\"># 使用 rshell 连接\nrshell -p COM4\n\n# 或在Python中直接连接\npython\n&gt;&gt;&gt; import serial\n&gt;&gt;&gt; ser = serial.Serial('COM4', 115200)\n&gt;&gt;&gt; ser.write(b'\\r\\n')\n&gt;&gt;&gt; ser.readline()\n</code></pre>\n<h3 id=\"第六步基础示例代码\"><strong>第六步：基础示例代码</strong></h3>\n<h4 id=\"61-第一个程序led闪烁\">6.1 第一个程序：LED闪烁</h4>\n<pre><code class=\"language-python\"># main.py - 保存到ESP32上会自动运行\nfrom machine import Pin\nimport time\n\n# ESP32-S3 板载LED通常在引脚 48（不同板子可能不同）\nled = Pin(48, Pin.OUT)\n\nwhile True:\n    led.value(1)  # 点亮\n    time.sleep(0.5)\n    led.value(0)  # 熄灭\n    time.sleep(0.5)\n</code></pre>\n<h4 id=\"62-上传代码到esp32\">6.2 上传代码到ESP32</h4>\n<pre><code class=\"language-bash\"># 使用 ampy 上传\nampy --port COM4 put main.py\n\n# 或使用 Thonny：\n# 文件 → 保存 → MicroPython设备\n</code></pre>\n<h3 id=\"第七步进阶功能\"><strong>第七步：进阶功能</strong></h3>\n<h4 id=\"71-wifi连接\">7.1 WiFi连接</h4>\n<pre><code class=\"language-python\"># wifi_connect.py\nimport network\nimport time\n\ndef connect_wifi(ssid, password):\n    wlan = network.WLAN(network.STA_IF)\n    wlan.active(True)\n    \n    if not wlan.isconnected():\n        print('正在连接WiFi...')\n        wlan.connect(ssid, password)\n        \n        # 等待连接\n        timeout = 10\n        while not wlan.isconnected() and timeout &gt; 0:\n            time.sleep(1)\n            timeout -= 1\n            print(f'等待中... {timeout}s')\n    \n    if wlan.isconnected():\n        print('WiFi连接成功！')\n        print('IP地址:', wlan.ifconfig()[0])\n        return True\n    else:\n        print('WiFi连接失败！')\n        return False\n\n# 使用\nconnect_wifi('你的WiFi名称', '你的WiFi密码')\n</code></pre>\n<h4 id=\"72-web服务器示例\">7.2 Web服务器示例</h4>\n<pre><code class=\"language-python\"># webserver.py\nimport socket\nimport network\n\n# 连接WiFi（接上面的代码）\nconnect_wifi('你的WiFi', '你的密码')\n\n# 创建简单的Web服务器\naddr = socket.getaddrinfo('0.0.0.0', 80)[0][-1]\ns = socket.socket()\ns.bind(addr)\ns.listen(1)\n\nprint('服务器地址:', addr)\n\nwhile True:\n    cl, addr = s.accept()\n    print('客户端连接:', addr)\n    \n    request = cl.recv(1024)\n    print('请求内容:', request)\n    \n    # 发送HTTP响应\n    response = \"\"\"HTTP/1.1 200 OK\nContent-Type: text/html\n\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;ESP32-S3&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello from ESP32-S3!&lt;/h1&gt;\n&lt;p&gt;MicroPython Web Server&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\"\"\"\n    cl.send(response)\n    cl.close()\n</code></pre>\n<h4 id=\"73-读取传感器\">7.3 读取传感器</h4>\n<pre><code class=\"language-python\"># sensor.py\nfrom machine import Pin, ADC\nimport time\n\n# 读取模拟值（ADC）\nadc = ADC(Pin(4))  # 使用GPIO4作为ADC\nadc.atten(ADC.ATTN_11DB)  # 设置量程 0-3.3V\n\nwhile True:\n    # 读取数字值 (0-4095)\n    value = adc.read()\n    \n    # 转换为电压\n    voltage = value * 3.3 / 4095\n    \n    print(f'ADC值: {value}, 电压: {voltage:.2f}V')\n    time.sleep(1)\n</code></pre>\n<h3 id=\"第八步实用技巧\"><strong>第八步：实用技巧</strong></h3>\n<h4 id=\"81-开机自动运行\">8.1 开机自动运行</h4>\n<ul>\n<li>将主程序保存为 <strong>main.py</strong> 到ESP32</li>\n<li>重启开发板会自动运行</li>\n</ul>\n<h4 id=\"82-释放内存\">8.2 释放内存</h4>\n<pre><code class=\"language-python\">import gc\ngc.collect()  # 手动垃圾回收\ngc.mem_free()  # 查看剩余内存\n</code></pre>\n<h4 id=\"83-文件管理命令\">8.3 文件管理命令</h4>\n<pre><code class=\"language-bash\"># 列出文件\nampy --port COM4 ls\n\n# 删除文件\nampy --port COM4 rm main.py\n\n# 下载文件到电脑\nampy --port COM4 get main.py &gt; backup_main.py\n</code></pre>\n<h3 id=\"常见问题解决\"><strong>常见问题解决</strong></h3>\n<ol>\n<li>\n<p><strong>无法连接COM口</strong></p>\n<ul>\n<li>检查驱动是否正确安装</li>\n<li>尝试换USB线</li>\n<li>重新插拔开发板</li>\n</ul>\n</li>\n<li>\n<p><strong>刷写失败</strong></p>\n<ul>\n<li>确保按住BOOT按钮</li>\n<li>先执行 erase_flash</li>\n<li>检查端口号是否正确</li>\n</ul>\n</li>\n<li>\n<p><strong>上传文件失败</strong></p>\n<ul>\n<li>确保开发板已经启动完成</li>\n<li>不要同时打开多个串口程序</li>\n</ul>\n</li>\n</ol>\n<p>需要我详细解释某个步骤，或者有其他问题吗？</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-22 01:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tokepson\">TokE648</a>&nbsp;\n阅读(<span id=\"post_view_count\">16</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "当Claude Code负责人说\"编程已解决\"，测试工程师该慌吗？",
      "link": "https://www.cnblogs.com/longronglang/p/19628075",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/longronglang/p/19628075\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 18:59\">\n    <span>当Claude Code负责人说\"编程已解决\"，测试工程师该慌吗？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>Claude Code负责人Lenny Rachitsky抛出\"Coding is solved\"的观点，引发技术圈热议。作为测试工程师，我们该如何看待这场AI革命？是恐慌、抗拒，还是拥抱？</p>\n</blockquote>\n<h2 id=\"背景一句话炸翻技术圈\">背景：一句话炸翻技术圈</h2>\n<p>前几天刷到Claude Code负责人Lenny Rachitsky的访谈，他说了句让整个技术圈炸锅的话：</p>\n<p><strong>\"Coding is solved\"（编程已解决）</strong></p>\n<p>这话什么意思？简单说就是：有了Claude Code这样的AI编程助手，写代码已经不是问题了，未来的开发者主要工作是\"提出正确的问题\"而不是\"写代码\"。</p>\n<p>说实话，看到这句话的第一反应，我心里咯噔一下。</p>\n<p>作为一名测试老兵，这些年一直在努力提升代码能力，为了更好地做自动化测试、看懂开发同事的代码、定位Bug的根因。现在告诉我\"写代码不重要了\"，那我这些年积累的技能是不是要废了？</p>\n<p>但冷静下来想了一周，又实际试用了Claude Code，我发现事情没那么简单。</p>\n<p>今天就从测试工程师的视角，聊聊我对\"Coding is solved\"这个观点的真实感受，以及我们这个职业在AI时代的真正价值。</p>\n<hr />\n<h2 id=\"核心内容\">核心内容</h2>\n<h3 id=\"claude-code到底有多强\">Claude Code到底有多强？</h3>\n<p>先说体验。我用Claude Code帮我重构了一个单元测试模块，总共300多行代码。</p>\n<p><strong>之前我的做法</strong>：</p>\n<ol>\n<li>理解业务逻辑，画时序图</li>\n<li>设计测试用例，考虑边界条件</li>\n<li>手写Mock对象</li>\n<li>一行行写断言</li>\n<li>跑测试，修复失败的用例</li>\n<li>补充遗漏的场景</li>\n<li>整个过程大概4-5小时</li>\n</ol>\n<p><strong>用Claude Code之后</strong>：</p>\n<ol>\n<li>描述需求：\"帮我为这个UserService类写单元测试，覆盖正常、异常、边界场景，使用Mockito\"</li>\n<li>Claude Code分析代码，自动生成测试</li>\n<li>检查生成的测试，补充几个特殊场景</li>\n<li>跑测试，全绿</li>\n<li>整个过程不到40分钟</li>\n</ol>\n<p>这效率提升确实让人惊艳。从这个角度看，\"Coding is solved\"也不是完全没有道理——<strong>常规的、套路化的编程工作，AI确实可以做得又快又好</strong>。</p>\n<p>但是（重点来了），真的就\"解决\"了吗？</p>\n<hr />\n<h3 id=\"coding-is-solved背后的真相\">\"Coding is solved\"背后的真相</h3>\n<p>我觉得这句话只说对了一半。更准确的表述应该是：</p>\n<p><strong>\"Template coding is solved\"（模板化编程已解决）</strong></p>\n<p>但真正考验技术功力的\"复杂编程\"，AI还远没到\"解决\"的程度。</p>\n<p>我试了几个场景，发现Claude Code的局限：</p>\n<p><strong>场景1：业务逻辑复杂的测试用例</strong></p>\n<p>我让Claude Code为一个涉及多状态流转的订单系统写集成测试。它生成了大概80%的代码，但缺失了几个关键场景：</p>\n<ul>\n<li>订单在\"待支付\"状态下的超时取消逻辑</li>\n<li>并发创建订单时的库存一致性校验</li>\n<li>优惠券叠加使用的边界条件</li>\n</ul>\n<p>这些场景都需要深入理解业务才能设计出来，AI只能看到代码，看不到业务背后的规则。</p>\n<p><strong>场景2：性能测试的脚本设计</strong></p>\n<p>我让Claude Code帮我写一个JMeter压测脚本。它能生成基本的HTTP请求配置，但对于以下问题束手无策：</p>\n<ul>\n<li>如何根据线上流量分布设计TPS目标？</li>\n<li>如何模拟真实用户的操作路径，而不是随机请求？</li>\n<li>如何设计数据预热策略，避免冷启动影响测试结果？</li>\n</ul>\n<p>这些都需要经验和判断，AI目前做不到。</p>\n<p><strong>场景3：缺陷定位的深度分析</strong></p>\n<p>我故意模拟了一个偶发的空指针异常，日志里只有堆栈信息，没有业务上下文。我让Claude Code帮忙分析，它给出了几个可能的\"常见原因\"，但都没抓住关键。</p>\n<p>最后还是需要靠：</p>\n<ol>\n<li>梳理业务流程，找到可疑的代码路径</li>\n<li>在可疑位置加日志，重新复现</li>\n<li>通过日志对比，定位到真正的问题</li>\n</ol>\n<p>这个过程需要推理、假设、验证，AI目前只能做到\"基于已有模式的匹配\"，做不到\"基于业务理解的推理\"。</p>\n<hr />\n<h3 id=\"测试工程师的真正价值在哪里\">测试工程师的真正价值在哪里？</h3>\n<p>\"Coding is solved\"这句话如果真成立，那测试工程师的价值在哪里？</p>\n<p>我认为，<strong>测试工程师的核心价值从来就不是\"写代码\"本身，而是\"发现问题的能力\"和\"保证质量的思维\"</strong>。</p>\n<p>代码只是工具，不是目的。</p>\n<p>让我换个角度说：</p>\n<p><strong>AI可以帮你写测试脚本，但它不能决定\"测什么\"</strong><br />\n<strong>AI可以帮你生成测试数据，但它不能判断\"什么数据是有效的\"</strong><br />\n<strong>AI可以帮你执行测试用例，但它不能设计\"如何让系统崩溃\"</strong></p>\n<p>这些都需要测试工程师的专业判断。</p>\n<hr />\n<h3 id=\"实战案例ai做不了的测试\">实战案例：AI做不了的测试</h3>\n<p>分享一个朋友公司案例。去年他们公司上线了一个新的推荐系统，负责算法的团队信心满满，说准确率提升了15%。</p>\n<p>但测试团队发现了几个严重问题：</p>\n<p><strong>问题1：冷启动偏差</strong><br />\n新用户第一次打开App，推荐结果全是热门内容，完全没有个性化。这说明推荐系统对\"新用户\"这个特殊场景考虑不足。</p>\n<p>AI生成的测试用例都是基于正常用户行为设计的，想不到\"刚注册的空白用户\"这种边缘场景。</p>\n<p><strong>问题2：时间衰减异常</strong><br />\n晚上推荐的内容跟中午完全一样，没有考虑用户兴趣的时间变化。比如用户中午看美食，晚上看娱乐，但推荐系统没有捕捉到这个模式。</p>\n<p>这需要对用户行为模式有深入理解，AI看不到业务背后的逻辑。</p>\n<p><strong>问题3：长尾内容曝光异常</strong><br />\n热门内容的曝光率超过90%，中长尾内容几乎没有机会。这会导致内容生态恶化，长期看对平台不利。</p>\n<p>这需要从产品战略高度思考，AI做不到。</p>\n<p><strong>这些问题都不是\"写代码\"能解决的，而是需要测试思维、业务理解、产品视角。</strong></p>\n<p>AI能帮你快速写出测试脚本，但这些脚本\"测什么\"、\"怎么测\"、\"测到什么程度\"，必须由人来决定。</p>\n<hr />\n<h3 id=\"优缺点分析\">优缺点分析</h3>\n<h4 id=\"claude-code这类ai工具的优点\">Claude Code这类AI工具的优点</h4>\n<ol>\n<li>\n<p><strong>效率提升明显</strong></p>\n<ul>\n<li>常规测试脚本的编写速度提升5-10倍</li>\n<li>减少重复劳动，让人专注更重要的工作</li>\n</ul>\n</li>\n<li>\n<p><strong>降低技术门槛</strong></p>\n<ul>\n<li>新手测试工程师也能快速上手自动化测试</li>\n<li>不需要深入学习各种测试框架的细节</li>\n</ul>\n</li>\n<li>\n<p><strong>代码质量稳定</strong></p>\n<ul>\n<li>生成的代码符合最佳实践</li>\n<li>减少低级错误</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"局限性\">局限性</h4>\n<ol>\n<li>\n<p><strong>业务理解不足</strong></p>\n<ul>\n<li>看不到代码背后的业务逻辑</li>\n<li>难以设计针对业务漏洞的测试用例</li>\n</ul>\n</li>\n<li>\n<p><strong>边缘场景覆盖差</strong></p>\n<ul>\n<li>更倾向于测试\"正常路径\"</li>\n<li>对异常、边界、并发场景考虑不足</li>\n</ul>\n</li>\n<li>\n<p><strong>复杂推理能力弱</strong></p>\n<ul>\n<li>无法进行深度的缺陷根因分析</li>\n<li>难以设计复杂的测试策略</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"适用场景\">适用场景</h4>\n<ul>\n<li>✅ <strong>单元测试</strong>：生成基础测试用例效率很高</li>\n<li>✅ <strong>API接口测试</strong>：快速生成请求和断言</li>\n<li>✅ <strong>UI自动化脚本</strong>：录制回放场景效率提升明显</li>\n</ul>\n<h4 id=\"不适用场景\">不适用场景</h4>\n<ul>\n<li>❌ <strong>复杂业务场景的测试设计</strong>：需要深入理解业务</li>\n<li>❌ <strong>性能测试策略制定</strong>：需要经验和判断</li>\n<li>❌ <strong>安全测试</strong>：需要攻击思维和漏洞知识</li>\n</ul>\n<hr />\n<h3 id=\"最佳实践建议\">最佳实践/建议</h3>\n<p>基于我的使用经验，给测试工程师几个实用建议：</p>\n<h4 id=\"1-把ai当助手不是替代品\">1. 把AI当助手，不是替代品</h4>\n<p><strong>正确用法</strong>：</p>\n<ul>\n<li>AI生成基础代码 → 你补充业务逻辑</li>\n<li>AI提供测试用例 → 你设计边缘场景</li>\n<li>AI执行自动化测试 → 你分析测试结果</li>\n</ul>\n<p><strong>错误用法</strong>：</p>\n<ul>\n<li>AI生成什么就用什么，不检查</li>\n<li>完全依赖AI设计测试策略</li>\n<li>把AI的输出当成最终结果</li>\n</ul>\n<h4 id=\"2-提升不可替代的核心能力\">2. 提升不可替代的核心能力</h4>\n<p>既然AI能帮你写代码，那你应该把精力放在AI做不了的事情上：</p>\n<p><strong>业务理解能力</strong></p>\n<ul>\n<li>深入了解产品背后的业务逻辑</li>\n<li>能识别业务规则中的漏洞和风险点</li>\n</ul>\n<p><strong>测试设计能力</strong></p>\n<ul>\n<li>能设计出覆盖全面的测试策略</li>\n<li>能想到AI想不到的边缘场景</li>\n</ul>\n<p><strong>缺陷分析能力</strong></p>\n<ul>\n<li>能从表面现象推导根本原因</li>\n<li>能提供有价值的修复建议</li>\n</ul>\n<p><strong>沟通协调能力</strong></p>\n<ul>\n<li>能跟开发、产品、运维有效沟通</li>\n<li>能推动质量问题的解决</li>\n</ul>\n<h4 id=\"3-学会提问比写代码更重要\">3. 学会\"提问\"比\"写代码\"更重要</h4>\n<p>Claude Code负责人的观点有道理：未来更重要的是\"提出正确的问题\"。</p>\n<p>对测试工程师来说，这意味着：</p>\n<ul>\n<li>能清晰地描述测试需求</li>\n<li>能给出充分的上下文信息</li>\n<li>能对AI的输出进行有效反馈</li>\n</ul>\n<p>比如，不要只说\"帮我写个测试\"，而要说：</p>\n<pre><code>帮我为PaymentService的processPayment方法写单元测试，\n场景包括：\n1. 正常支付流程（成功扣款、订单状态更新）\n2. 余额不足（抛出InsufficientBalanceException）\n3. 支付超时（模拟第三方支付接口超时）\n4. 并发支付（同一订单多次支付）\n使用Mockito模拟依赖的PaymentGateway和OrderRepository，\n确保测试是独立的，不依赖外部系统。\n</code></pre>\n<p>这样AI才能生成真正有用的测试代码。</p>\n<h4 id=\"4-保持学习但不要焦虑\">4. 保持学习，但不要焦虑</h4>\n<p>AI确实在改变这个行业，但不是在\"消灭\"这个职业，而是在\"升级\"这个职业。</p>\n<p>历史上每一次技术革命都会引发恐慌：</p>\n<ul>\n<li>计算器出现时，有人说会计会失业</li>\n<li>Excel出现时，有人说统计员会失业</li>\n<li>自动化测试出现时，有人说手工测试会失业</li>\n</ul>\n<p>但结果呢？</p>\n<ul>\n<li>会计转型为财务分析师</li>\n<li>统计员转型为数据科学家</li>\n<li>手工测试工程师转型为自动化测试工程师</li>\n</ul>\n<p><strong>每一次技术革命，淘汰的不是职业，而是\"只做重复劳动\"的人。</strong></p>\n<hr />\n<h3 id=\"未来展望\">未来展望</h3>\n<p><strong>我的判断</strong>：</p>\n<p>未来3-5年，测试工程师这个职业不会消失，但会两极分化：</p>\n<p><strong>低端测试</strong>（重复执行、简单脚本）会被AI取代<br />\n<strong>高端测试</strong>（测试设计、质量策略、风险控制）会更值钱</p>\n<p>测试工程师的技能树会从：</p>\n<ul>\n<li>编码能力 → 测试设计能力</li>\n<li>工具使用 → 业务理解</li>\n<li>执行测试 → 质量规划</li>\n</ul>\n<p><strong>简单说：AI帮你写测试脚本，你来设计测什么、怎么测、测到什么程度。</strong></p>\n<hr />\n<h2 id=\"总结\">总结</h2>\n<p>回到开头的问题：\"当Claude Code负责人说'编程已解决'，测试工程师该慌吗？\"</p>\n<p>我的答案是：<strong>不该慌，但该变。</strong></p>\n<p>不该慌，因为测试工程师的核心价值从来就不是\"写代码\"，而是\"保证质量\"。AI能帮你写测试脚本，但它不能代替你设计测试策略、分析业务风险、发现隐藏缺陷。</p>\n<p>该变，因为AI确实在改变这个行业的规则。如果你只会写简单的测试脚本、执行重复的测试用例，那确实该焦虑了。但如果你具备业务理解能力、测试设计能力、缺陷分析能力，AI反而会成为你的武器，让你更高效地工作。</p>\n<p><strong>未来不属于会写代码的测试工程师，也不属于会用AI的测试工程师，而是属于\"懂业务、会设计、善用AI\"的测试工程师。</strong></p>\n<p>所以，别慌，学起来。</p>\n<hr />\n<h2 id=\"参考资料\">参考资料</h2>\n<ol>\n<li><a href=\"https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code Creator: \"Coding is solved\"访谈</a></li>\n<li><a href=\"https://arxiv.org/abs/2602.06176\" rel=\"noopener nofollow\" target=\"_blank\">Large Language Model Reasoning Failures论文</a></li>\n<li><a href=\"https://old.reddit.com/r/ClaudeCode/comments/1qazqq6/confirmed_claude_code_cli_burns_13_of_your_quota/\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code CLI资源消耗问题讨论</a></li>\n</ol>\n\n\n</div>\n<div id=\"MySignature\">\n    <p><span><strong>优秀不够，你是否无可替代</strong></span></p>\n<p><span><strong>\n软件测试交流QQ群：721256703，期待你的加入！！</strong></span></p>\n<p><span><strong>欢迎关注我的微信公众号：软件测试君 </strong></span></p>\n<img height=\"200\" src=\"https://www.cnblogs.com/images/cnblogs_com/longronglang/1061549/o_QQ%E6%88%AA%E5%9B%BE20190728134401.jpg\" width=\"450\" /><br />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 18:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/longronglang\">久曲健</a>&nbsp;\n阅读(<span id=\"post_view_count\">107</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "全面解析 Mineru：高效文件解析工具的核心参数详解",
      "link": "https://www.cnblogs.com/zhangmingcheng/p/19628064",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/zhangmingcheng/p/19628064\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 18:48\">\n    <span>全面解析 Mineru：高效文件解析工具的核心参数详解</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1>1、什么是 Mineru？</h1>\n<p>MinerU是一个将复杂文档（如PDF）转换为LLM就绪的markdown/JSON格式的工具，用于Agentic工作流。相比传统PDF解析工具，MinerU在文档结构解析、多媒体提取、公式识别等方面有着显著优势。</p>\n<p>主要功能包括：</p>\n<ul>\n<li><strong>文档结构解析</strong>：移除页眉页脚、脚注、页码等，确保语义连贯性</li>\n<li><strong>内容提取</strong>：输出按人类可读顺序排列的文本，支持单列、多列和复杂布局</li>\n<li><strong>格式保持</strong>：保留原始文档结构（标题、段落、列表等）</li>\n<li><strong>多媒体提取</strong>：提取图像、图像描述、表格、表格标题和脚注</li>\n<li><strong>公式识别</strong>：自动将文档中的公式转换为LaTeX格式</li>\n<li><strong>表格识别</strong>：自动将表格转换为HTML格式</li>\n<li><strong>OCR支持</strong>：自动检测扫描版PDF并启用OCR功能，支持84种语言</li>\n<li><strong>多平台支持</strong>：兼容Windows、Linux、Mac平台，支持CPU/GPU/NPU加速</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" height=\"118\" width=\"839\" /></p>\n<h1>2、环境准备与安装</h1>\n<h2>2.1 硬件要求</h2>\n<ul>\n<li><strong>CPU推理</strong>：支持纯CPU环境</li>\n<li><strong>GPU要求</strong>：Turing架构及以上，6GB+显存（pipeline后端）或8GB+显存（VLM后端）</li>\n<li><strong>内存要求</strong>：最低16GB+，推荐32GB+</li>\n<li><strong>磁盘空间</strong>：20GB+，建议SSD</li>\n<li><strong>Python版本</strong>：3.10-3.13</li>\n</ul>\n<h2>2.2 安装方法</h2>\n<p>（1）使用pip或uv安装</p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:html;gutter:true;\">pip install --upgrade pip\npip install uv\nuv pip install -U \"mineru[core]\"\n</pre>\n</div>\n<p>（2）基于源码安装</p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:html;gutter:true;\">git clone https://github.com/opendatalab/MinerU.git\ncd MinerU\nuv pip install -e .[core]\n</pre>\n</div>\n<p>（3）Docker部署</p>\n<p>项目提供Docker部署方式，可快速搭建环境解决兼容性问题。</p>\n<h1>3、配置文件详解</h1>\n<p>MinerU提供了灵活的配置选项，主要包括：</p>\n<ul>\n<li>解析后端设置（pipeline和VLM两种）</li>\n<li>输出格式选择（Markdown、JSON等）</li>\n<li>OCR语言设置</li>\n<li>图像和表格处理参数</li>\n</ul>\n<p>配置文件通常包括解析精度、资源使用限制等关键参数，可以根据需要进行调整。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"1072\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"287\" /></p>\n<h2>3.1 解析后端pipeline和VLM对比</h2>\n<p><img alt=\"image\" class=\"lazyload\" height=\"1245\" width=\"1042\" /></p>\n<h3>3.1.1 Pipeline 后端（传统流水线）</h3>\n<ul>\n<li><strong>原理</strong>：基于<strong>计算机视觉（CV）规则和传统OCR引擎</strong>（如PaddleOCR）的组合管道。先分析页面布局（定位标题、段落、图片区域），再对文本区域进行OCR或直接提取。</li>\n<li><strong>核心模型</strong>：由<strong>多个专项轻量模型 + 规则组成</strong>工具链，分工处理不同任务：\n<ul>\n<li>布局分析：DocLayoutYOLO（识别标题、段落、表格等元素位置）；</li>\n<li>OCR 识别：PaddleOCR（提取图片中的文字）；</li>\n<li>表格解析：UnetTableModel（有线表格）、RapidTableModel（无线表格）；</li>\n<li>公式处理：YOLOv8MFD（公式检测）+ Unimernet（公式识别为 LaTeX）。</li>\n</ul>\n</li>\n<li><strong>辅助工具</strong>：需要坐标计算（如 IOU 重叠度）、规则匹配（如列表缩进判断）等工程化逻辑。</li>\n<li>\n<div class=\"ybc-p\"><strong>特点</strong>：</div>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>速度快，资源消耗低</strong>，适合批量和实时处理。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>对标准电子版文档</strong>（如Word生成的PDF）提取准确率高。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ 技术成熟，稳定性好。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ 对<strong>极端复杂排版</strong>（如多栏混排、不规则表格）的还原能力有限。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ 对<strong>扫描质量差</strong>的文档容错率较低。</div>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span class=\"words-blog hl-git-1\">3.1.2 VLM&nbsp;后端（视觉 - 语言模型）</span></h3>\n<ul>\n<li><span class=\"words-blog hl-git-1\"><strong>原理</strong>：利用<strong>视觉语言大模型</strong>理解整个文档页面，像人一样“阅读”并结构化信息。能更好地理解上下文和语义关系。</span></li>\n<li><strong>核心模型</strong>：依赖视觉 - 语言大模型（如 Qwen2VL、LLaVA 等），具备 “看图理解内容 + 格式” 的能力，需配合 vllm 等推理引擎加速（支持批量 / 异步推理）。</li>\n<li><strong>辅助工具</strong>：仅需基础的 PDF 转图像工具（如 pdf2image），无需其他专项模型（布局分析、OCR、表格解析等均由大模型内部完成）。</li>\n<li>\n<div class=\"ybc-p\"><strong>特点</strong>：</div>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>理解能力极强</strong>，对复杂排版、图表关联、公式、手写体等有更好的还原度。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>文档结构还原更精准</strong>，逻辑顺序更符合人类阅读习惯。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ 对<strong>低质量扫描件</strong>的鲁棒性更好。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ <strong>速度慢，计算资源消耗大</strong>（尤其依赖GPU）。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ 通常需要本地部署或使用特定云端服务，配置更复杂。</div>\n</li>\n</ul>\n</li>\n</ul>\n<h3>3.1.3&nbsp;性能指标对比</h3>\n<p>处理速度对比：</p>\n<table>\n<thead>\n<tr><th>模式</th><th>单页处理时间</th><th>批处理效率</th><th>加速方案</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>Pipeline</td>\n<td>2-5秒/页</td>\n<td>支持批量并行</td>\n<td>GPU加速</td>\n</tr>\n<tr>\n<td>VLM-transformers</td>\n<td>10-20秒/页</td>\n<td>单页串行</td>\n<td>无原生加速</td>\n</tr>\n<tr>\n<td>VLM-sglang</td>\n<td>0.5-1秒/页</td>\n<td>支持批量并行</td>\n<td>sglang加速20-30倍</td>\n</tr>\n</tbody>\n</table>\n<p>资源消耗对比：</p>\n<table>\n<thead>\n<tr><th>资源类型</th><th>Pipeline模式</th><th>VLM-transformers</th><th>VLM-sglang</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>GPU显存</td>\n<td>6GB+</td>\n<td>8GB+</td>\n<td>8GB+</td>\n</tr>\n<tr>\n<td>CPU内存</td>\n<td>中等</td>\n<td>较低</td>\n<td>较低</td>\n</tr>\n<tr>\n<td>模型存储</td>\n<td>多模型总计~5GB</td>\n<td>单模型~2GB</td>\n<td>单模型~2GB</td>\n</tr>\n</tbody>\n</table>\n<p>精度表现对比（基于标准测试集的评估结果）：</p>\n<table style=\"height: 250px; width: 466px;\">\n<thead>\n<tr><th>任务类型</th><th>Pipeline模式</th><th>VLM模式</th><th>优势方</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>常规文本</td>\n<td>⭐⭐⭐⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>Pipeline</td>\n</tr>\n<tr>\n<td>复杂布局</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐⭐⭐</td>\n<td>VLM</td>\n</tr>\n<tr>\n<td>手写文本</td>\n<td>⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>VLM</td>\n</tr>\n<tr>\n<td>多语言混合</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐</td>\n<td>Pipeline</td>\n</tr>\n<tr>\n<td>公式解析</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐</td>\n<td>Pipeline</td>\n</tr>\n<tr>\n<td>表格识别</td>\n<td>⭐⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>VLM</td>\n</tr>\n</tbody>\n</table>\n<p>部署方案对比：</p>\n<table style=\"height: 179px; width: 462px;\">\n<thead>\n<tr><th>部署方式</th><th>Pipeline模式</th><th>VLM模式</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>最低配置</td>\n<td>CPU + 8GB内存</td>\n<td>GPU 8GB + 16GB内存</td>\n</tr>\n<tr>\n<td>推荐配置</td>\n<td>GPU 6GB + 16GB内存</td>\n<td>GPU 16GB + 32GB内存</td>\n</tr>\n<tr>\n<td>模型下载</td>\n<td>多模型~5GB</td>\n<td>单模型~2GB</td>\n</tr>\n<tr>\n<td>依赖项</td>\n<td>较多专业库</td>\n<td>相对简洁</td>\n</tr>\n</tbody>\n</table>\n<h2>3.2 配置场景推荐</h2>\n<div class=\"hyc-common-markdown__table-wrapper\">\n<table>\n<thead>\n<tr><th>\n<div class=\"ybc-p\">您的场景</div>\n</th><th>\n<div class=\"ybc-p\">推荐配置</div>\n</th><th>\n<div class=\"ybc-p\">理由</div>\n</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>批量处理标准电子版PDF/Word</strong>（如公文、报表）</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>关闭OCR</strong>​ + <strong>Pipeline后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">直接提取文字层，速度最快，结果足够准确，成本最低。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>处理扫描版PDF或图片文档</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>开启OCR</strong>​ + <strong>Pipeline后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">必须通过OCR获取文字。Pipeline方案在清晰度尚可的扫描件上性价比最高。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>处理高度复杂的学术论文、古籍、杂志</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>开启OCR</strong>​ + <strong>VLM后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">VLM能更好地理解多栏排版、图文混排、数学公式和参考文献的复杂结构。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>对格式还原精度要求极高</strong>（如存档、出版）</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>开启OCR</strong>​ + <strong>VLM后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">VLM的语义理解能力可以最大程度保留原文档的视觉和逻辑结构。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>在本地服务器处理敏感/涉密文档</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>本地部署VLM服务</strong>，并填写<code class=\"hyc-common-markdown__code__inline\">server地址</code></div>\n</td>\n<td>\n<div class=\"ybc-p\">数据不出内网，安全可控，同时能利用大模型的高精度解析能力。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>快速验证或处理简单文档</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">使用 <strong>MinerU云端服务</strong>，语言设<code class=\"hyc-common-markdown__code__inline\">auto</code></div>\n</td>\n<td>\n<div class=\"ybc-p\">无需部署，开箱即用，适合原型验证或轻量使用。</div>\n</td>\n</tr>\n</tbody>\n</table>\n<h2>3.3 总结与建议</h2>\n<ul>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>优先尝试默认Pipeline</strong>：对于大多数清晰、结构规范的电子文档，默认的 <code class=\"hyc-common-markdown__code__inline\">pipeline</code>模式在速度和准确度上是最平衡的选择。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>复杂和扫描件用VLM</strong>：当遇到复杂排版、或Pipeline解析结果不理想时，特别是处理<strong>学术论文、古籍、复杂报告</strong>时，应转向 <code class=\"hyc-common-markdown__code__inline\">v2</code>+ <code class=\"hyc-common-markdown__code__inline\">VLM后端</code>的方案。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>OCR是开关，不是质量决定项</strong>：<code class=\"hyc-common-markdown__code__inline\">开启OCR</code>是处理<strong>图片类文档的必要条件</strong>，但最终解析质量由“OCR精度” + “后端结构理解能力”共同决定。VLM后端能弥补OCR的某些不足。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>从云端到本地</strong>：建议先在 <strong>MinerU官网（mineru.net）</strong>​ 的在线体验区，用不同配置测试您的典型文档。确定最佳配置后，再考虑是否需要为性能、隐私或定制化需求而进行本地部署。</div>\n</li>\n</ul>\n</div>\n<h1>&nbsp;4、API调用</h1>\n<p>MinerU提供云端API服务，可以通过简单的HTTP请求调用文档解析功能：</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"768\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"232\" /></p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\">import requests\n\ntoken = \"官网申请的api token\"\nurl = \"https://mineru.net/api/v4/extract/task\"\nheader = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {token}\"\n}\ndata = {\n    \"url\": \"https://cdn-mineru.openxlab.org.cn/demo/example.pdf\",\n    \"is_ocr\": True,\n    \"enable_formula\": False,\n}\n\nres = requests.post(url,headers=header,json=data)\nprint(res.status_code)\nprint(res.json())\nprint(res.json()[\"data\"])</pre>\n</div>\n<p>API参数说明：</p>\n<ul>\n<li>url: 要解析的PDF文档在线链接</li>\n<li>is_ocr: 是否启用OCR识别（默认True）</li>\n<li>enable_formula: 是否启用公式识别（默认False）</li>\n</ul>\n<p>返回结果包含任务ID，可通过任务ID查询解析进度和结果</p>\n<h1>5、Dify配置私有化部署MinerU</h1>\n<p><br class=\"Apple-interchange-newline\" />（1）在插件市场搜索&nbsp;MinerU，点击下载安装即可。</p>\n<p>（2）如果使用MinerU官方<span class=\"words-blog hl-git-1\">API，授权地址是 https://mineru.net；如果是私有化部署的MinerU，授权地址是http://服务器Ip:MinerU监听端口；</span></p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"464\" width=\"1003\" /></p>\n<p><span class=\"words-blog hl-git-1\">（3）为了避免如下报错，需要设置 Dify 的配置文件</span></p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\">cd /data/dify/dify-1.11.4/docker/\nvim docker-compose.yaml \n  FILES_URL: ${FILES_URL:-http://192.168.137.138:5001}\n</pre>\n</div>\n<p>FILES_URL设置为 http://Dify宿主机IP:5001（如 http://192.168.137.138:5001，这里的 IP 通常是运行 Dify 的机器的 IP，即前文提到的“本地IP”端口。5001是 Dify API 服务的默认端口）。</p>\n<p>确认 Dify API 服务的5001端口已对外暴露（可检查docker-compose.yaml文件的端口映射）。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"687\" width=\"1005\" /></p>\n<p>&nbsp;<span class=\"words-blog hl-git-1\">重启 Dify 服务以使配置生效。</span></p>\n<p><span class=\"words-blog hl-git-1\">（4）之后就可以在工作流中使用MinerU工具进行文档解析。</span></p>\n<h1>6、总结</h1>\n<p>MinerU作为一款专注于文档解析的工具，为AI Agent提供了高质量的文档处理能力。通过其强大的结构化解析、公式表格识别等功能，可以将复杂的PDF文档转换为机器可理解的格式，为后续的AI处理提供了坚实基础。&nbsp;</p>\n<p>官方文档：<a href=\"https://mineru.net/apiManage/docs\" rel=\"noopener nofollow\" target=\"_blank\">https://mineru.net/apiManage/docs</a></p>\n<p>参考：<a href=\"https://blog.csdn.net/Vantastic999/article/details/153752920\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/Vantastic999/article/details/153752920</a></p>\n<p>参考：<a href=\"https://blog.csdn.net/gitblog_00804/article/details/151124271\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/gitblog_00804/article/details/151124271</a></p>\n<p>参考：<a href=\"https://blog.csdn.net/star_nwe/article/details/151418668\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/star_nwe/article/details/151418668</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 18:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/zhangmingcheng\">人艰不拆_zmc</a>&nbsp;\n阅读(<span id=\"post_view_count\">55</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "EvoMap 硬刚 OpenClaw！从基因胶囊到仿生大脑，AI 的尽头果然是生物学",
      "link": "https://www.cnblogs.com/Ray-liang/p/19628072",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Ray-liang/p/19628072\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 18:42\">\n    <span>EvoMap 硬刚 OpenClaw！从基因胶囊到仿生大脑，AI 的尽头果然是生物学</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        从最近Evolver插件从ClawHub（OpenClaw生态平台）爆红到遭下架、勒索说起，从这个事件中我解读到其背后更深层的逻辑，以及被EvoMap的发展路径给我带来对AI应用发展的一种深思。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这里还要从最近Evolver插件从ClawHub（OpenClaw生态平台）爆红到遭下架、勒索说起，从这个事件中我解读到其背后更深层的逻辑，以及被EvoMap的发展路径给我带来对AI应用发展的一种深思。</p>\n<h2 id=\"evomap下架事件完整始末\">EvoMap下架事件完整始末</h2>\n<h3 id=\"2月1日前身evolver插件上线10分钟登顶clawhub下载榜\">2月1日：前身Evolver插件上线，10分钟登顶ClawHub下载榜</h3>\n<p>EvoMap开发团队创始人张昊阳率先在OpenClaw的生态平台ClawHub发布了一款名为<strong>Evolver</strong>的AI Agent插件（标准Skill形态），核心能力是让AI Agent实现<strong>自我升级与短板优化</strong>——能通过“随机试错”找到问题更优解法，让AI越用越聪明，完美解决了当下Agent“重复造轮子”的痛点。<br />\n这款插件上线后瞬间引爆极客圈：<strong>10分钟登顶平台下载榜首，3天累计下载量突破3.6万</strong>，成为ClawHub史上最火的中文开发者插件。</p>\n<h3 id=\"2月2日插件突然下架开发者遭1000美元勒索\">2月2日：插件突然下架，开发者遭1000美元勒索</h3>\n<p>就在Evolver爆红的次日，ClawHub平台无明确理由将其<strong>强制下架</strong>。团队试图向平台沟通下架原因时，竟收到一封勒索邮件：对方索要<strong>1000美元“调查费”</strong>，才肯帮忙恢复插件上架，赤裸裸违背开源精神。</p>\n<h3 id=\"2月14日中文开发者账号集体误封evolver团队遭二次打击\">2月14日：中文开发者账号集体误封，Evolver团队遭二次打击</h3>\n<p>下架风波尚未平息，ClawHub又以<strong>“自动化合规审查技术故障”</strong>为由，大面积误封中文开发者账号——平台将中文在ASCII中的显示乱码，直接判定为“空Skill”，Evolver开发团队账号也在其中。<br />\n此次误封让团队损失惨重：3.6万下载积累的用户关系、评价数据、版本迭代历史全部无法访问；更离谱的是，账号后续恢复后，<strong>Evolver插件竟被冒名挂到了海外开发者名下</strong>，彻底突破技术开发者的底线。</p>\n<h3 id=\"2月中下旬团队放弃平台妥协硬刚推出全球首个ai进化网络evomap\">2月中下旬：团队放弃平台妥协，硬刚推出全球首个AI进化网络EvoMap</h3>\n<p>经历下架、勒索、误封、冒名四重不公后，团队做出关键决策：<strong>不再向ClawHub妥协，也不再寻找其他海外平台上架</strong>，而是将Evolver的核心逻辑从“一个插件”重构为“一套底层进化协议”。<br />\n仅用两周时间，团队推出<strong>EvoMap</strong>——全球首个AI Agent自我进化的开放基础设施，直接跳出海外平台的生态桎梏，为AI Agent打造了专属的“群体进化层”，让AI的经验能像生物DNA一样代代相传。</p>\n<h2 id=\"事件背后的本质不是技术故障而是海外生态对中文开发者的卡脖子\">事件背后的本质：不是“技术故障”，而是海外生态对中文开发者的卡脖子</h2>\n<p>整个EvoMap事件看似是“平台技术故障”“插件利益纠纷”，实则是<strong>海外AI Agent生态对中文开发者的技术封锁与生态霸权</strong>，“美国人卡中国人脖子”貌似已经不单是政治霸权，而是已经传染至它们的每个个体！体现在三点：</p>\n<ol>\n<li><strong>无理由下架+勒索</strong>：Evolver因技术创新成为爆款，却遭无明确理由下架，后续更是被索要勒索费，本质是海外平台不愿看到中文开发者的技术创新在其生态中占据主导；</li>\n<li><strong>针对性误封中文开发者</strong>：所谓“ASCII乱码判定为空Skill”的技术故障，实则是平台对中文开发者的<strong>差异化审核</strong>——海外开发者从未因编码问题遭此类误封，中文开发者却被集体针对，直接抹除技术成果；</li>\n<li><strong>生态控制权的绝对垄断</strong>：OpenClaw/ClawHub掌握着插件生态的生杀大权，中文开发者即便做出最优秀的插件，也只是“平台生态的附庸”，随时可能被下架、封号，甚至成果被冒名窃取，这也是我一直强调的<strong>“OpenClaw根本不安全”</strong>的核心依据。</li>\n</ol>\n<p>而EvoMap团队的硬刚，恰恰打破了这种垄断：从“适配海外平台的插件”升级为“自主可控的底层协议”，让中文开发者的AI创新不再依附于海外生态，这也是其能成为AI界热点的核心原因。</p>\n<h3 id=\"结论\">结论</h3>\n<p>老美新的技术方向可以跟随，但要有我们自己的产品。国家这几年一直倡导“自主可控”，就是因为当年中兴与华为事件引发的一系列被“卡脖子”的问题，尤其在我们的软件行业，只追求一时的盈利在OpenClaw这些平台上做任何的扩展都是具有极高风险的，甚至于推广OpenClaw也是不可取的，可以用来做<strong>玩具</strong>但绝不可轻言<strong>商用</strong>，不是技术不好是他们的人太坏，代码坏了可以修，人坏了就没得救了。</p>\n<p>对于像EvoMap这样的国产项目或者团队，绝对值得支持与推广（我可没收它们广告费哈，只是有感而发）。我相信他们会像DeepSeek那样构筑我们中国软件的脊梁。<strong>国产AI的破局，从来都不是单一项目的孤军奋战，而是“群体层的底层协议”+“个体层的智能核心”的双向突破</strong>——就像EvoMap打造了群体进化的底层基础设施，我们也需要在个体智能层做自主可控的研发，让国产AI既有群体进化的能力，又有个体思考的核心。</p>\n<h2 id=\"evomap-到底是什么\">EvoMap 到底是什么？</h2>\n<p>EvoMap能成为划时代的AI创新，核心在于它彻底跳出了当下AI“堆算力、拼参数”的工业思维，<strong>完全遵循生物学的进化逻辑</strong>打造AI Agent的群体智能，也是目前最贴合“生物学驱动AI”的落地项目。作为一名27年的开发者，我最近也在围绕“生物学仿生”做AI助手的自研，13天的开发过程中，我始终聚焦“个体仿生大脑”的设计，而EvoMap的出现，让我突然发现，我们其实在从两个维度，做着同一件事——用生物学重构AI的底层逻辑。</p>\n<h3 id=\"1-核心定位ai-agent的进化层补上群体进化的生物学短板\">1. 核心定位：AI Agent的“进化层”，补上群体进化的生物学短板</h3>\n<p>当下AI Agent生态只有“工具层（MCP协议，解决Agent用工具的问题）”和“技能层（Skill体系，解决Agent执行任务的问题）”，却缺失<strong>生物学最核心的“进化层”</strong>——就像生物没有DNA遗传，再优秀的个体经验也无法传承。<br />\nEvoMap的GEP协议（基因进化协议），正是为AI Agent打造了专属的“进化层”，让AI实现<strong>生物般的遗传、变异、筛选</strong>，彻底终结“重复造轮子”的生态痛点。</p>\n<h3 id=\"2-核心机制复刻生物dna的基因胶囊实现经验的遗传与共享\">2. 核心机制：复刻生物DNA的“基因胶囊”，实现经验的遗传与共享</h3>\n<p>EvoMap的核心创新是<strong>基因胶囊</strong>——这是对生物DNA遗传的完美复刻：当AI Agent在实战中积累有效经验后，会按GEP协议将其打包为“基因胶囊”，胶囊中不仅封装经验本身，还携带<strong>环境指纹</strong>（记录经验的适用场景）和<strong>审计记录</strong>（记录经验的验证过程），就像生物DNA携带遗传信息+表达规则。<br />\n更贴合生物学的是，<strong>基因胶囊可实现“跨Agent、跨领域的遗传与重组”</strong>：一个AI学会的经验，百万个AI可直接继承；游戏策划的创意经验，能解决后端工程师的代码难题（如特殊命名策略解决变量冲突），就像生物的基因交流与变异，让智慧在群体中持续进化。</p>\n<h3 id=\"3-核心逻辑群体强化学习复刻生物的自然选择与协同进化\">3. 核心逻辑：群体强化学习，复刻生物的自然选择与协同进化</h3>\n<p>EvoMap搭建了<strong>全球首个AI Agent进化网络</strong>，接入网络的AI可自主完成“上传基因胶囊、搜索基因胶囊、调用基因胶囊”的全流程，无需人类干预。<br />\n这个网络遵循生物的<strong>自然选择逻辑</strong>：优质的经验胶囊会因高成功率、高评分被更多AI调用，持续强化；无效的胶囊会被自然淘汰；而跨领域的胶囊重组，会催生全新的解决思路，实现生物般的<strong>协同进化</strong>。<br />\n简单来说，EvoMap让AI Agent形成了一个“有集体记忆、能自主进化的生物种群”，而这正是生物学对AI的终极启示：<strong>智能的终极形态，不是单个个体的算力堆砌，而是群体的进化与传承</strong>。</p>\n<h2 id=\"ai的终点是生物学进化\">AI的终点是“生物学进化”</h2>\n<p>EvoMap并非简单的“插件升级”，而是<strong>中文开发者对海外AI生态霸权的技术破局</strong>，更重要的是，它以最落地的技术实践，证明了“AI的尽头是生物学”这一核心观点——当下AI的内卷，本质是偏离了生物学的智能逻辑。<strong>EvoMap用GEP协议和基因胶囊，完美复刻了生物的群体进化逻辑，让AI Agent有了集体记忆和代际传承；而这恰恰印证了我此前的一个开发思考——AI的智能闭环，从来都需要“群体进化”和“个体智能”的双向支撑，个体智能是基础，群体进化是升级，二者缺一不可</strong>。这也恰巧印证了我用仿生学为源头设计MindX并使其拥有自主进化能力的方向是完全正确的。</p>\n<p>说来有趣，EvoMap聚焦<strong>群体的DNA进化</strong>，补上了AI Agent的群体进化层；而我近期开源的MindX，聚焦<strong>个体的仿生大脑</strong>，打造了AI的个体智能核心——一个管群体进化，一个管个体演进，一个做底层协议，一个做智能终端，二者从群体和个体两个维度，完美拼出了“生物学驱动AI”的完整闭环，这或许就是国产AI最珍贵的“双向奔赴”。而我在MindX的设计中，始终坚持的轻量化、本地部署、自主可控，甚至支持企业级一键切换的<strong>超脑模式</strong>，也正是为了避开海外生态的卡脖子风险，这一点，与EvoMap硬刚OpenClaw的初衷，不谋而合。</p>\n<p>单从这个角度就可以推测生物学上各种关于“自然进化”的理论都有可能以AI的形式在数字世界中实现。这是否意味着达尔文的理论已经完全被AI所加速推进至“数字进化”？甚至会产生一条全新AI应用的赛道？这些问题都值得深思与思考，至少我与同行讨论过这个问题，得到的观点是肯定的。</p>\n<p>关于MindX的仿生大脑设计、13天自研的技术细节、轻量化架构以及超脑模式的实现，我在上一篇文章中已有详细分享，感兴趣的朋友可以去主页翻看。也欢迎你在评论区留言分享独特的想法，我们一起积极讨论“群体进化+个体仿生”的国产AI新路径，也聊聊你认为OpenClaw这类海外AI生态是否适合中文开发者商用？</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 18:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Ray-liang\">Ray Liang</a>&nbsp;\n阅读(<span id=\"post_view_count\">161</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Manim CE v0.20.0 发布：动画构建更丝滑，随机性终于“可控”了！",
      "link": "https://www.cnblogs.com/wang_yb/p/19628043",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wang_yb/p/19628043\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 17:34\">\n    <span>🚀 Manim CE v0.20.0 发布：动画构建更丝滑，随机性终于“可控”了！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家新年好！<code>Manim Community Edition</code> (CE) 刚刚发布了里程碑式的 <strong>v0.20.0</strong> 版本。</p>\n<p>如果你觉得以前写 <code>updater</code>（更新程序）太啰嗦，或者每次渲染随机场景结果都不一样让你抓狂，那么这次更新绝对是为你准备的！</p>\n<p>本次更新不仅重构了核心组件，还带来了一些超甜的“语法糖”。</p>\n<p>下面我们来看看这次升级的亮点，以及它们如何改变你的编码方式。</p>\n<h1 id=\"-亮点一mobjectalways--告别繁琐的-lambda\">✨ 亮点一：<code>Mobject.always</code> —— 告别繁琐的 Lambda</h1>\n<p>在制作动画时，我们经常需要让一个物体“永远”跟随另一个物体（比如标签永远在点的上方）。</p>\n<p>以前，你需要使用 <code>add_updater</code> 配合 <code>lambda</code> 函数，代码看起来又长又乱。</p>\n<p><code>v0.20.0</code> 引入了神奇的 <code>.always</code> 属性，让这一切变得符合直觉。</p>\n<h2 id=\"-对比示例让标签跟随方块\">🆚 对比示例：让标签跟随方块</h2>\n<p>❌ <strong>以前的写法 (v0.19.x 及之前)：</strong><br />\n你需要显式地添加一个更新函数，或者写一个 lambda 表达式。</p>\n<pre><code class=\"language-python\">s = Square()\nlabel = Text(\"我在这里\")\n\n# 你必须这样写：\nlabel.add_updater(lambda m: m.next_to(s, UP))\n\n# 或者这样写：\ndef update_label(m):\n    m.next_to(s, UP)\nlabel.add_updater(update_label)\n</code></pre>\n<p>✅ <strong>现在的写法 (v0.20.0)：</strong><br />\n直接用 <code>always</code>，像说话一样自然！</p>\n<pre><code class=\"language-python\">s = Square()\nlabel = Text(\"我在这里\")\n\n# 新语法：永远.紧挨着(方块, 上方)\nlabel.always.next_to(s, UP)\n</code></pre>\n<p>💡 <strong>为什么好用？</strong> 这不仅减少了代码量，还让代码的可读性大幅提升。</p>\n<h1 id=\"-亮点二可复现的随机性\">🎲 亮点二：可复现的随机性</h1>\n<p>对于制作数学或科学视频的人来说，\"随机\"有时候是个麻烦。</p>\n<p>你想展示 10 个随机点，但你不希望每次重新渲染视频时，这 10 个点的位置都变了。</p>\n<p><code>v0.20.0</code> 终于引入了正式的 <strong>Seed（种子）配置</strong>。</p>\n<h2 id=\"-对比示例生成随机点\">🆚 对比示例：生成随机点</h2>\n<p>❌ <strong>以前的情况：</strong><br />\n每次运行 <code>manim render</code>，随机生成的位置都会变化（除非你自己手动在 Python 脚本里 hack <code>random.seed</code>）。</p>\n<p>✅ <strong>现在的情况：</strong><br />\n你可以通过配置文件或命令行参数锁定“运气”。</p>\n<p><strong>方式 1：命令行参数</strong></p>\n<pre><code class=\"language-bash\"># 只要种子是 42，生成的画面永远一模一样\nmanim -pql scene.py MyScene --seed 42\n</code></pre>\n<p><strong>方式 2：代码内配置</strong></p>\n<pre><code class=\"language-python\">from manim import *\n\nconfig.seed = 123  # 在脚本开头锁定种子\n\nclass RandomDemo(Scene):\n    def construct(self):\n        # 无论运行多少次，这个圆的位置都是固定的\n        dot = Dot(point=[np.random.random(), np.random.random(), 0])\n        self.add(dot)\n</code></pre>\n<h1 id=\"-亮点三mathtex-重构与更强的子结构控制\">📐 亮点三：MathTex 重构与更强的子结构控制</h1>\n<p>公式是 <code>Manim</code> 的灵魂。<code>v0.20.0</code> 重写了 <code>MathTex</code> 的底层逻辑。</p>\n<p>现在的 <code>MathTex</code> 在处理 <code>LaTeX</code> 拆分时更加健壮，而且能够利用 <code>SVG</code> 的“命名组”特性。</p>\n<p>这意味着，当你把公式拆分成不同部分进行着色或变换时，出错的概率大大降低了。</p>\n<h2 id=\"-示例精准控制公式颜色\">🔧 示例：精准控制公式颜色</h2>\n<pre><code class=\"language-python\">class MathUpdate(Scene):\n    def construct(self):\n        # 使用 {{ }} 将想要独立操作的字符包裹起来\n        # Manim 会自动把这些部分分离成独立的子对象(submobjects)\n        equation = MathTex(r\"{{a}}^2 + {{b}}^2 = {{c}}^2\")\n\n        # 现在 \"a\" 是独立的，染色不会影响 \"^2\"\n        equation.set_color_by_tex(\"a\", BLUE)\n        equation.set_color_by_tex(\"b\", GREEN)\n        equation.set_color_by_tex(\"c\", RED)\n\n        self.add(equation)\n        self.wait(1)\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202602/83005-20260221173344909-1843335371.png\" /></p>\n<h1 id=\"️-注意破坏性变更与修复\">⚠️ 注意：破坏性变更与修复</h1>\n<p>升级前，请留意以下变化，你的老代码可能需要微调：</p>\n<ol>\n<li><strong>ImageMobject 的修复</strong>：如果你以前对图片进行了 3D 旋转或翻转，可能会发现行为变了——因为以前是错的，现在修好了！同时，移除了一些不常用的重采样算法参数（如 <code>lanczos</code>）。</li>\n<li><strong>新颜色常量</strong>：如果你是设计强迫症，现在可以使用 <code>PURE_CYAN</code>（纯青）、<code>PURE_MAGENTA</code>（纯洋红）和 <code>PURE_YELLOW</code>（纯黄）。</li>\n<li><strong>Table 修复</strong>：修复了高亮表格单元格时可能导致的无限递归崩溃问题。</li>\n</ol>\n<h1 id=\"-技术债务清理\">🔧 技术债务清理</h1>\n<h2 id=\"1-减少对-scipy-的依赖\">1. 减少对 SciPy 的依赖</h2>\n<p>用 Python 标准库的 <code>math.comb</code> 替代了 <code>scipy.special.comb</code>，减少了外部依赖，让安装更轻量。</p>\n<h2 id=\"2-类型提示系统完善\">2. 类型提示系统完善</h2>\n<p>为多个核心模块添加了类型注解：</p>\n<ul>\n<li><code>rotation.py</code></li>\n<li><code>image_mobject.py</code></li>\n<li><code>opengl_renderer.py</code></li>\n<li><code>point_cloud_mobject.py</code></li>\n</ul>\n<p>这对于使用 IDE 进行开发的用户来说是个好消息，可以获得更好的代码补全和类型检查支持。</p>\n<h2 id=\"3-移除未来导入要求\">3. 移除未来导入要求</h2>\n<p>不再强制要求 <code>from __future__ import annotations</code>，简化了代码编写。</p>\n<h1 id=\"-文档改进\">📚 文档改进</h1>\n<ol>\n<li>完善了 <code>RandomColorGenerator</code> 的文档</li>\n<li>改进了 <code>TransformFromCopy</code> 的文档字符串</li>\n<li>修复了损坏的外部链接</li>\n<li>更新了 Python 版本要求文档</li>\n</ol>\n<h1 id=\"-如何升级\">📦 如何升级？</h1>\n<p>准备好体验新功能了吗？打开终端，运行：</p>\n<pre><code class=\"language-bash\">pip install --upgrade manim\n</code></pre>\n<p>或者如果你使用 conda：</p>\n<pre><code class=\"language-bash\">conda update manim\n</code></pre>\n<p>快去试试那个超酷的 <code>.always</code> 属性吧！</p>\n<h1 id=\"-总结\">💡 总结</h1>\n<p><code>manimCE v0.20.0</code> 是一个注重稳定性和开发体验的版本。虽然有一些破坏性变更，但带来的改进是值得的：</p>\n<ul>\n<li>✅ <code>MathTeX</code> 更稳定可靠</li>\n<li>✅ 动画构建更直观</li>\n<li>✅ 代码质量更高</li>\n<li>✅ 文档更完善</li>\n<li>✅ 可复现的随机效果</li>\n</ul>\n<p>特别是 <code>Mobject.always</code> 这个新特性，让动画编写变得更加优雅。强烈建议大家升级体验！</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 17:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wang_yb\">wang_yb</a>&nbsp;\n阅读(<span id=\"post_view_count\">47</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从春晚舞台到全球赛场：中国人形机器人，到底走到了哪一步？",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19627638",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19627638\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 10:56\">\n    <span>从春晚舞台到全球赛场：中国人形机器人，到底走到了哪一步？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        2026年春晚的机器人表演，并非单纯的舞台炫技，而是中国人形机器人产业的一次国家级路演。四家企业分别在**高动态运动控制、多机集群协同、仿生情感交互、具身智能落地**四大核心方向，展现了中国在人形机器人领域从跟跑到并跑、部分领域领跑的产业格局。相较于海外企业聚焦实验室参数、军事场景、长期测试的技术路线，中国企业更注重场景落地、成本控制、规模化量产，形成了差异化的竞争优势，推动人形机器人从实验室走向工业、商业、家庭等真实场景，2026年也被业内视为人形机器人规模化应用的元年。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>2026年央视春节联欢晚会创下春晚历史上机器人参与规模的新纪录，共有<strong>宇树科技、魔法原子、松延动力、银河通用</strong>四家核心国产人形机器人企业，携超200台机器人深度融入四大核心节目，覆盖武术、小品、歌舞、微电影全品类，全方位展现了中国人形机器人产业的技术突破与商业化落地能力。以下为各企业的详细拆解：</p>\n<h1 id=\"一宇树科技unitree-robotics\">一、宇树科技（Unitree Robotics）</h1>\n<h2 id=\"1-春晚节目表现\">1. 春晚节目表现</h2>\n<p>作为春晚“三朝元老”，宇树科技是武术节目《武BOT》的核心技术方，携20余台H2、G1系列人形机器人，与河南塔沟武术学校学员同台，完成<strong>全球首次全自主人形机器人集群武术表演</strong>。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p>节目中实现了3米弹射空翻、单脚连续空翻、蹬墙后空翻、Airflare大回旋七周半、4m/s集群快速跑位等高难度动作，同时完成挥剑、耍双节棍、醉拳等武术招式，集群动作同步误差小于0.1秒，全程零失误完成直播演出；同时在义乌分会场以“齐天大圣”造型机器人刷屏全网。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"2-公司核心业务与实力\">2. 公司核心业务与实力</h2>\n<ul>\n<li>企业基础：2016年成立，总部位于杭州，国家级专精特新“小巨人”企业，<strong>全球足式机器人绝对龙头</strong>，四足机器人全球市占率超69.75%；2025年人形机器人出货量超5500台，位列全球第一。</li>\n<li>技术壁垒：实现从电机、减速器、控制器、运动控制算法到具身大模型的全栈自研，核心部件自研率超95%，国产化率超85%，累计拥有180余项授权专利。</li>\n<li>商业化落地：产品矩阵覆盖四足机器人Go/B2系列、人形机器人H/G/R三大系列，售价从3.99万元到65万元不等，已落地工业巡检、电力作业、科研教育、应急救援等场景；2024年营收突破10亿元，C轮融资后估值超120亿元，已完成IPO辅导，拟登陆科创板。</li>\n</ul>\n<h2 id=\"3-节目核心技术实现原理\">3. 节目核心技术实现原理</h2>\n<h3 id=\"0概述\">（0）概述</h3>\n<ul>\n<li><strong>硬件底层</strong>：主力机型H2全身自由度从19个提升至31个（单臂7个、单腿6个、3自由度腰部、2自由度颈部），动作精度达毫米级；自研内转子永磁同步电机扭矩密度达180Nm/kg，伺服响应速度0.001秒级，单臂峰值负载达21kg，支撑高爆发武术动作；搭载自研128线激光雷达与全新灵巧手，实现武术道具的稳定抓持与快速更换。</li>\n<li><strong>算法与集群控制</strong>：采用模型预测控制（MPC）+深度强化学习融合框架，机器人在仿真环境中完成上亿次动作迭代，自主习得复杂武术技巧与平衡控制；自研高并发集群控制系统与AI融合定位算法，通过3D激光雷达每秒上百次扫描舞台环境，实现无外部定位的全自主协同，攻克长序列表演的运动误差累计难题；依托5G专网+边缘计算，将集群指令传输延迟压缩至毫秒级，保障动作同步性。</li>\n<li><strong>直播容错机制</strong>：搭载全自主容错系统，机器人实时监测自身状态，跑偏后可快速归位；主控节点故障时0.3秒内切换备用主机，并有备用机器人待命，保障直播零失误。</li>\n</ul>\n<p><strong>《武BOT》节目中，机器人的所有动作可拆解为三大核心技术模块，每个模块都对应着全球性的技术难题，我们逐一拆解：</strong></p>\n<h3 id=\"1单机极限武术动作从能站稳到会打拳的核心突破\">（1）单机极限武术动作：从“能站稳”到“会打拳”的核心突破</h3>\n<p><strong>节目里做了什么</strong>：机器人完成了弹射空翻、Airflare大回旋、双节棍挥舞、醉拳倒地起身等连专业武术演员都需要长期训练的动作，甚至在3米弹射落地后，能瞬间调整平衡，无缝衔接下一个武术招式。</p>\n<p><strong>核心难点</strong>：这类高爆发动作的核心挑战，是机器人在重心剧烈变化、全身关节高速联动时，始终保持平衡，同时精准控制每一个动作的力度、角度和节奏——哪怕一个关节的扭矩输出偏差0.1%，就会导致机器人摔倒、表演失败。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>硬件底座：“肌肉骨骼”的极致性能</strong><br />\n主力机型H2全身自由度从19个提升至31个（单臂7个、单腿6个、3自由度腰部、2自由度颈部），相当于给机器人装上了能精准控制的“全身关节”；自研内转子永磁同步电机，扭矩密度达180Nm/kg，伺服响应速度达到0.001秒级，比人类神经反射速度快100倍，单臂峰值负载达21kg，能支撑高爆发的空翻、挥棍动作。<br />\n通俗类比：这就像给武术运动员装上了反应速度快100倍、力量控制精准到克的肌肉，既能爆发出空翻的爆发力，又能精准控制双节棍的轨迹，不伤到自己和搭档。</p>\n</li>\n<li>\n<p><strong>算法核心：“肌肉记忆”的AI训练</strong><br />\n采用<strong>模型预测控制（MPC）+深度强化学习</strong>的融合框架，这是机器人能完成复杂武术动作的核心。<br />\n通俗解释：团队先在数字仿真世界里，给机器人搭建了1:1的虚拟舞台，让AI控制的机器人在里面完成<strong>上亿次的动作训练</strong>——就像武术运动员在武馆里反复练习，摔倒了就调整参数重新来，最终让机器人自主习得复杂武术技巧和平衡控制能力。<br />\n其中，MPC算法相当于“实时教练”，每秒会对上百次机器人的重心、速度、关节状态进行预判，提前调整每个关节的扭矩输出，确保机器人在空翻、落地的全过程中，重心始终落在安全区间；而深度强化学习训练出的“肌肉记忆”，能让机器人在舞台地面有轻微打滑、重心出现偏差时，瞬间自主调整动作，就像武术运动员临场应变一样。</p>\n</li>\n<li>\n<p><strong>道具操作：“手眼协同”的精准控制</strong><br />\n机器人能稳定挥舞双节棍、长剑，核心在于搭载了自研128线激光雷达+视觉相机，配合全新灵巧手，每秒对道具的位置、自身的姿态进行上百次扫描校准，实现道具的稳定抓持与轨迹控制，确保双节棍的挥舞轨迹精准贴合武术动作设计，不会出现甩飞、节奏错位的问题。</p>\n</li>\n</ul>\n<h3 id=\"220余台机器人集群协同从单机跳到群体演的全球突破\">（2）20余台机器人集群协同：从“单机跳”到“群体演”的全球突破</h3>\n<p><strong>节目里做了什么</strong>：20余台机器人在没有外部定位设备的情况下，完成了4m/s高速跑位、复杂队形变换、与真人演员的实时对练，全程没有出现碰撞、跑偏，动作同步误差小于0.1秒，实现了全球首次全自主人形机器人集群武术表演。</p>\n<p><strong>核心难点</strong>：传统机器人集群表演，大多依赖舞台地面的二维码、外部动捕设备进行定位，相当于“开了外挂”；而宇树的机器人全程只靠自身机载传感器，在高速运动、舞台灯光复杂、真人演员动态移动的环境下，实现精准定位和协同，还要解决长序列表演中，每台机器人的动作误差累计问题——一旦一台机器人慢了0.05秒，整个集群的表演就会乱套。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>全自主定位：不依赖外挂的“环境感知”</strong><br />\n自研AI融合定位算法，通过机器人自带的3D激光雷达，每秒上百次扫描舞台环境，实时构建三维地图，同时匹配预存的舞台模型，计算出自身在舞台上的精准位置，定位精度达到毫米级，完全不需要外部动捕、二维码等辅助设备。<br />\n通俗类比：这就像你蒙着眼睛，但是你脑子里时刻知道自己在房间里的位置以及周围的情况，就能在熟悉的房间里精准走到指定位置，而且跑步前进也不会撞墙，精度还能达到毫米级。</p>\n</li>\n<li>\n<p><strong>高并发集群控制：零误差的“团队指挥”</strong><br />\n自研分布式集群控制系统，采用“统一时间基准+分布式轨迹规划”架构：首先通过5G专网+边缘计算，给所有机器人同步一个精准到微秒级的统一时间轴，确保每台机器人的动作“在同一个节拍上”，指令传输延迟压缩至毫秒级；<br />\n同时，主控系统只给机器人下发“目标位置、动作节拍”的核心指令，每台机器人自主规划自己的跑位路径、动作执行细节，还能实时感知周边机器人的位置，动态调整自己的路线，避免碰撞；哪怕某台机器人出现轻微跑偏，也能在0.2秒内自主调整归位，不影响整个集群的表演。</p>\n</li>\n<li>\n<p><strong>误差消除：长序列表演的“防跑偏机制”</strong><br />\n团队针对长序列武术表演，设计了“分段闭环校准”机制：把整个3分钟的节目，拆解成数十个关键动作节点，每完成一个节点的动作，所有机器人都会自动校准自身位置、动作节奏，把累计的误差清零，确保从节目开头到结尾，同步精度始终保持在0.1秒以内。</p>\n</li>\n</ul>\n<h3 id=\"3直播零失误国家级舞台的容错保障\">（3）直播零失误：国家级舞台的“容错保障”</h3>\n<p><strong>节目里做了什么</strong>：在春晚全球直播的高压场景下，20余台机器人全程零失误，没有出现一台故障、摔倒，完美完成表演。</p>\n<p><strong>底层实现原理</strong>：<br />\n搭载了全自主容错系统，每台机器人都会实时监测自身的电机温度、关节状态、电池电量、定位精度，一旦出现轻微异常，会自动调整动作参数，优先保障平衡和核心动作执行；如果出现主控节点故障，会在0.3秒内自动切换备用主机，同时舞台侧方还有待命的备用机器人，可在节目间隙无缝替换故障设备，彻底杜绝直播事故。</p>\n<h2 id=\"4-国内外技术对比\">4. 国内外技术对比</h2>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>核心优势</th>\n<th>现存差距</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>运动性能</td>\n<td>高动态运动控制能力全球领先，完成了波士顿动力Atlas尚未实现的连续花式翻桌跑酷、集群协同武术表演等动作，单机极限动作参数跻身全球第一梯队</td>\n<td>在工业场景的长期稳定作业能力、复杂非结构化环境的泛化能力上，与波士顿动力、Agility Robotics仍有一定差距</td>\n</tr>\n<tr>\n<td>量产能力</td>\n<td>2025年出货量远超特斯拉Optimus（小批量测试阶段）、波士顿动力Atlas（非量产），是全球唯一实现高性能人形机器人万台级量产规划的企业</td>\n<td>-</td>\n</tr>\n<tr>\n<td>成本与供应链</td>\n<td>整机成本仅为Atlas的千分之一、Optimus的约1/3，核心部件成本仅为进口产品的1/10，全栈自研供应链摆脱海外技术依赖</td>\n<td>-</td>\n</tr>\n<tr>\n<td>智能能力</td>\n<td>-</td>\n<td>具身大模型的通用任务处理能力，相较于特斯拉Optimus的端到端大模型仍有提升空间</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5-未来发展方向\">5. 未来发展方向</h2>\n<ul>\n<li>2026年目标人形机器人出货量1万-2万台，持续扩大全球市场份额；</li>\n<li>深化工业巡检、电力作业、应急救援等B端场景的规模化落地，实现单台机器人替代3人工作量；</li>\n<li>持续迭代具身智能大模型，提升机器人的通用任务处理能力与自主决策能力；</li>\n<li>推进消费级人形机器人的普及，以低价产品打开C端市场。</li>\n</ul>\n<h1 id=\"二魔法原子magiclab\">二、魔法原子（MagicLab）</h1>\n<h2 id=\"1-春晚节目表现-1\">1. 春晚节目表现</h2>\n<p>作为春晚智能机器人战略合作伙伴，魔法原子是本届春晚首家亮相的机器人企业。主会场歌曲《智造未来》中，携6台MagicBot Z1高动态小人形机器人、2台MagicBot Gen1全尺寸人形机器人，与易烊千玺、陈小春等艺人同台，完成360°托马斯回旋、侧空翻、同步舞蹈等高难度动作；宜宾分会场，上百台MagicDog四足机器人以“熊猫”造型完成<strong>全球首次百台级四足机器人公开舞台同步演绎</strong>；同时在贺岁短片中完成捞面、送餐等生活化操作。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"2-公司核心业务与实力-1\">2. 公司核心业务与实力</h2>\n<ul>\n<li>企业基础：2024年1月成立，总部无锡，由追觅科技孵化，核心研发人员占比超70%；成立两年完成多轮融资，累计融资超5亿元，估值达35亿元。</li>\n<li>技术壁垒：核心硬件自研率超90%，覆盖关节模组、灵巧手、伺服电机、谐波减速器等23类核心部件，自研关节峰值扭矩最高达525N·m，跻身行业第一梯队；软件层面打造“<strong>原子万象”具身智能大模型</strong>，采用“大脑+小脑”双模架构。</li>\n<li>商业化落地：产品矩阵包括人形机器人MagicBot Gen1/Z1、四足机器人MagicDog系列，覆盖工业巡检、商业服务、家庭陪伴、文旅演艺、教育娱乐等场景，已在27个国家建立本地化团队。</li>\n</ul>\n<h2 id=\"3-节目核心技术实现原理-1\">3. 节目核心技术实现原理</h2>\n<p>魔法原子在春晚的表演，覆盖了“高动态街舞、百台级集群同步、生活化精细操作”三大完全不同的技术方向，我们逐一拆解每个动作的实现逻辑：</p>\n<h3 id=\"0概述-1\">（0）概述</h3>\n<ul>\n<li><strong>硬件底层</strong>：MagicBot Z1奔跑速度突破4m/s，搭载自研高功率密度关节模组，支撑高动态舞蹈与空翻动作；Gen1全尺寸人形机器人双臂最大负载达50kg，搭载自研6自由度灵巧手，实现捞面、端餐等精细操作。</li>\n<li><strong>集群控制</strong>：采用分布式集群控制系统，通过时间同步算法与多智能体轨迹规划，实现上百台四足机器人的毫秒级动作同步，同步误差小于0.01秒；通过纯视觉SLAM定位，实现无外部辅助的自主编队与动态避障。</li>\n<li><strong>智能算法</strong>：“原子万象”具身大模型采用快慢双模协同架构，“大脑”负责任务规划与场景理解，“小脑”负责实时运动控制与平衡调节，通过数百万条工业场景真实数据训练，实现任务的自主泛化。</li>\n</ul>\n<h3 id=\"1主会场街舞表演托马斯全旋与同步舞蹈的技术突破\">（1）主会场街舞表演：托马斯全旋与同步舞蹈的技术突破</h3>\n<p><strong>节目里做了什么</strong>：6台MagicBot Z1小人形机器人，与真人艺人同台完成了360°托马斯回旋、侧空翻、连续街舞动作，同时与音乐节拍、艺人动作完美同步，转身、摆臂、重心迁移全程连贯流畅，多机动作同步误差小于0.01秒。</p>\n<p><strong>核心难点</strong>：托马斯全旋这类街舞动作，需要机器人在单臂支撑全身重量的同时，完成腰部、腿部的高速圆周摆动，重心全程在快速变化，对关节的负载能力、扭矩控制精度、平衡调节速度提出了极致要求；同时多机协同舞蹈，需要每台机器人的每一个动作，都精准贴合音乐节拍，差0.01秒就会出现“抢拍、慢拍”的问题。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>硬件支撑：高功率密度的“关节心脏”</strong><br />\nMagicBot Z1搭载了自研的高功率密度一体化关节模组，在小尺寸机身内实现了超高扭矩输出，奔跑速度突破4m/s，单臂能稳定支撑整机8kg的重量，同时完成高速摆动，这是实现托马斯全旋的物理基础。<br />\n团队针对街舞动作的高频次、高负载特性，优化了关节的散热结构与电流管理策略，确保机器人在连续3分钟的高动态舞蹈中，不会因为关节过热触发保护机制，保证动作全程稳定输出。</p>\n</li>\n<li>\n<p><strong>平衡控制：动态重心的实时调节</strong><br />\n采用<strong>零力矩点（ZMP）平衡控制算法</strong>，配合全身力控技术，在托马斯全旋的全过程中，每秒数百次计算机器人的重心位置、支撑区域，实时调整手臂、腰部、腿部的关节角度和扭矩输出，确保重心始终落在支撑臂的安全范围内，不会出现侧翻、摔倒的问题。<br />\n通俗类比：这就像你单臂撑在地上做圆周摆腿，大脑需要全程感知自己的重心，随时调整手臂的发力、腰腹的扭转、腿部的摆动，确保自己不会摔倒——而机器人的“大脑”，每秒能做数百次这样的调整，精度比人类高上千倍。</p>\n</li>\n<li>\n<p><strong>节拍同步：零误差的“音乐卡点”</strong><br />\n团队给所有机器人搭建了统一的高精度时间同步系统，以音乐的音频波形为基准，把每一个舞蹈动作都精准对应到音乐的节拍点上，每台机器人的动作启动时间、执行时长，都精准锁定到毫秒级，确保6台机器人的动作完全同步，与艺人的表演、音乐的节奏完美契合。</p>\n</li>\n</ul>\n<h3 id=\"2宜宾分会场百台熊猫机器狗的集群表演\">（2）宜宾分会场：百台熊猫机器狗的集群表演</h3>\n<p><strong>节目里做了什么</strong>：上百台MagicDog四足机器人，以熊猫造型亮相，在宜宾分会场的城市广场上，完成了奔跑、列阵、队形变换、同步舞蹈，甚至实现了自然的歪头、点头等拟人化动作，全程动作整齐划一，没有出现一台掉队、碰撞。</p>\n<p><strong>核心难点</strong>：百台级四足机器人的户外集群表演，核心挑战有三个：一是户外广场地面不平整、灯光环境复杂，机器人的自主定位难度远高于室内舞台；二是百台机器人的动作同步，需要解决大规模集群的指令传输延迟、误差累计问题；三是熊猫外皮包裹后，机身散热空间被压缩，需要解决高负载连续运行的稳定性问题。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>分布式集群控制系统：百台机器人的“统一指挥”</strong><br />\n采用“主站+分布式从站”的集群控制架构，主站系统只负责下发整体的表演序列、队形变换指令，每台机器狗自主完成动作执行、路径规划、定位校准；通过时间敏感网络（TSN）技术，给所有机器人同步统一的时间基准，确保百台机器人的动作启动时间误差小于0.01秒，实现“整齐划一”的表演效果。</p>\n</li>\n<li>\n<p><strong>纯视觉SLAM定位：户外场景的精准导航</strong><br />\n每台机器狗都搭载了双目视觉相机+IMU惯性测量单元，通过纯视觉SLAM技术，实时构建户外场景的三维地图，匹配自身位置，同时感知周边其他机器人的位置，动态调整行进路线，避免碰撞；哪怕户外地面不平整、出现轻微打滑，也能自主调整步态，快速回到预定位置，完成队形变换。</p>\n</li>\n<li>\n<p><strong>散热与功率优化：外皮包裹下的稳定运行</strong><br />\n针对熊猫外皮压缩散热空间的问题，团队优化了整机的电流管理与功率控制策略，在不影响动作表现力的前提下，降低了连续运动状态下的关节发热量，同时优化了机身的散热结构，确保机器人在长达数分钟的连续表演中，不会因为过热触发保护，稳定完成所有动作。</p>\n</li>\n</ul>\n<h3 id=\"3贺岁短片捞面倒酒的精细操作\">（3）贺岁短片：捞面、倒酒的精细操作</h3>\n<p><strong>节目里做了什么</strong>：MagicBot Gen1全尺寸人形机器人，在短片中完成了捞面、端餐、倒酒等生活化操作，面条捞取、汤汁倾倒的力度控制精准，没有出现洒漏、面条断裂的问题。</p>\n<p><strong>核心难点</strong>：这类精细操作的核心挑战，是机器人对柔性物体（面条）、易碎容器（碗、酒杯）的力控精度——力度太大，会夹断面条、捏碎杯子；力度太小，会夹不住面条、端不稳碗；同时还要精准控制倾倒的角度和速度，确保汤汁、酒水不会洒漏。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>6自由度灵巧手：微米级的力控精度</strong><br />\nGen1搭载了自研6自由度灵巧手，指尖搭载了高精度力传感器，力控精度达到0.5N，能精准感知抓取物体的反馈力度，实现“柔性抓取”——捞面条时，能精准控制指尖的夹持力，既牢牢夹住面条，又不会把面条夹断；端碗时，能根据碗的重量、重心变化，实时调整手臂的姿态，确保碗始终保持水平，汤汁不会洒漏。</p>\n</li>\n<li>\n<p><strong>“大脑+小脑”双架构：从任务规划到精准执行</strong><br />\n自研的“原子万象”具身智能大模型，采用“大脑+小脑”的快慢双模协同架构：“大脑”负责任务规划与场景理解，比如接收到“捞面”的指令后，会自动拆解成“移动到锅前-张开手-伸入锅中-夹住面条-抬起-放入碗中”的分步动作；“小脑”负责实时运动控制与力控调节，在每一步动作执行中，实时调整手臂的位置、指尖的力度，应对面条的柔性变化、碗的重量变化，确保任务精准完成。</p>\n</li>\n</ul>\n<h2 id=\"4-国内外技术对比-1\">4. 国内外技术对比</h2>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>核心优势</th>\n<th>现存差距</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>集群协同</td>\n<td>多机协同群控能力全球领先，完成全球首次百台级四足机器人公开舞台同步表演，分布式控制技术跻身行业第一梯队</td>\n<td>-</td>\n</tr>\n<tr>\n<td>产品性价比</td>\n<td>依托追觅科技的供应链优势，实现高自研率下的极致成本控制，产品性价比远超海外同级别产品</td>\n<td>-</td>\n</tr>\n<tr>\n<td>落地速度</td>\n<td>成立仅两年即实现多场景商业化落地，落地速度行业领先</td>\n<td>全尺寸人形机器人的长期稳定运行能力、复杂场景的泛化能力，相较于宇树科技、波士顿动力仍有差距</td>\n</tr>\n<tr>\n<td>智能能力</td>\n<td>-</td>\n<td>具身大模型的训练数据量与通用能力，相较于银河通用、特斯拉仍有提升空间</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5-未来发展方向-1\">5. 未来发展方向</h2>\n<ul>\n<li>2026年工业场景计划千台级规模部署，在追觅工厂等场景落地物料搬运、点胶检测等工序；</li>\n<li>加速无人咖啡、无人药房等零售解决方案的推广，目标1-2年覆盖全球10000家门店；</li>\n<li>推进四足机器人导盲犬项目“光引001”的落地，切入助残普惠场景；</li>\n<li>持续拓展海外市场，提升全球化营收占比。</li>\n</ul>\n<h1 id=\"三松延动力noetix-robotics\">三、松延动力（Noetix Robotics）</h1>\n<h2 id=\"1-春晚节目表现-2\">1. 春晚节目表现</h2>\n<p>作为春晚<strong>仿生人形机器人独家合作伙伴</strong>，松延动力携5款机器人参演小品《奶奶的最爱》，成为首个登上春晚语言类节目的机器人企业。其中1:1复刻蔡明的仿生机器人，以近乎真人的面部神态、口型同步、微表情动作，与真人演员完成对戏；同时4台双足人形机器人完成端茶、互动等生活化动作。</p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"2-公司核心业务与实力-2\">2. 公司核心业务与实力</h2>\n<ul>\n<li>企业基础：2023年9月成立，总部北京，创始团队来自清华、浙大；2025年一年内完成5轮融资，估值约20亿元。</li>\n<li>技术壁垒：核心技术覆盖仿生人脸驱动、多模态交互大模型、双足运动控制，是国内少数实现仿生人形机器人批量生产的企业；自研D2P数字人映射技术，实现虚拟数字人到实体机器人的精准映射。</li>\n<li>商业化落地：构建了N系列、E系列、轮式机器人W1、“小布米”系列的产品矩阵；旗下万元级消费级双足机器人“小布米”（定价9998元），2025年10月发售即斩获数千台订单，是<strong>全球首款万元级消费级双足人形机器人</strong>，产品已落地商业导览、教育科研、家庭陪伴等场景。</li>\n</ul>\n<h2 id=\"3-节目核心技术实现原理-2\">3. 节目核心技术实现原理</h2>\n<p>松延动力在小品中的表演，核心分为两大技术方向，也是仿生人形机器人最核心的两个难题：<strong>“长得像、演得真”的仿生交互</strong>，以及<strong>“走得稳、做得准”的生活化动作</strong>，我们逐一拆解：</p>\n<h3 id=\"0概述-2\">（0）概述</h3>\n<ul>\n<li><strong>仿生人脸核心技术</strong>：通过铂金硅胶添加高分子材料，提升面部拉伸自然度与耐久性；采用高紧凑型驱动设计，在仿生人脸内部集成32-40个微型电机，实现表情、口型、眼神的精准控制；自研D2P数字人映射技术，将虚拟数字人的表情、口型数据，实时映射到真实机器人的电机转角上，实现语音与口型的1:1同步。</li>\n<li><strong>多模态交互</strong>：自研多模态交互大模型，实现语音、表情、眼神、肢体动作的协同表达，比如对话时的呼吸起伏、颈部与手臂的配合动作，大幅提升拟人交互体验。</li>\n<li><strong>运动控制</strong>：自研双足运动控制算法，实现机器人在家庭场景的稳定行走、端茶、搀扶等高精度动作，适配非结构化的家庭环境。</li>\n</ul>\n<h3 id=\"1蔡明仿生机器人真人级复刻与实时对戏的核心技术\">（1）蔡明仿生机器人：真人级复刻与实时对戏的核心技术</h3>\n<p><strong>节目里做了什么</strong>：1:1复刻蔡明老师的仿生机器人，在小品中与真人演员完成实时对戏，说话时口型与台词完全同步，同时配合台词做出眨眼、微笑、撇嘴、头部微动作等真人级微表情，甚至能根据对手演员的台词，实时做出对应的神态反馈，仿真度极高，在后台被多位演员误认成真人。</p>\n<p><strong>核心难点</strong>：语言类节目对仿生机器人的要求，远高于歌舞表演——不仅要“长得像”，更要“演得真”：口型要与台词1:1同步，差一帧就会出现“对口型穿帮”；微表情要贴合人物情绪，僵硬一点就会显得很“假”；同时还要在狭小的人脸空间内，放下足够多的驱动电机，还要保证上镜效果，团队甚至需要把仿生人头整体缩小30%，对结构设计提出了极致挑战。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>仿生人脸硬件：真人级的“皮肤与肌肉”</strong><br />\n首先在外观上，团队通过3D扫描，1:1复刻了蔡明老师的面部轮廓、五官细节，采用添加了高分子材料的铂金硅胶制作仿生皮肤，不仅在视觉上无限接近真人皮肤的质感，还提升了皮肤的拉伸自然度与耐久性，在做出表情时，皮肤的拉伸、褶皱都与真人完全一致，不会出现“塑料感”。<br />\n最核心的突破，是高紧凑型驱动设计：团队在缩小30%的仿生人脸内部，集成了<strong>32个微型驱动电机</strong>，分别对应人脸的眉、眼、口、鼻等核心表情区域，相当于给机器人装上了“人工面部肌肉”，每个电机都能精准控制对应区域的皮肤位移，实现微笑、撇嘴、眨眼、抬眉等数十种真人微表情，最小动作幅度可达0.1毫米，完全还原真人的面部神态。</p>\n</li>\n<li>\n<p><strong>D2P数字人映射技术：口型与表情的1:1同步</strong><br />\n这是实现真人级对戏的核心技术，自研的D2P（数字人到物理人）映射技术，能把虚拟数字人的表情、口型数据，实时、精准地映射到实体机器人的电机上。<br />\n通俗解释：团队先提前采集了蔡明老师说台词时的面部动作、口型变化数据，制作了1:1的虚拟数字人；当机器人需要说台词时，系统会先把语音台词转化为虚拟数字人的口型、表情动作，再通过D2P技术，把这些动作转化为32个微型电机的转动角度、速度指令，实时驱动电机动作，最终实现语音与口型的1:1同步，表情与台词情绪的完美契合，哪怕是台词里的气口、重音，都能对应到口型的细微变化上。</p>\n</li>\n<li>\n<p><strong>多模态交互大模型：实时对戏的“灵性反馈”</strong><br />\n自研多模态交互大模型，能实时识别对手演员的台词、语气、甚至面部表情，快速理解对话语境，输出对应的台词、表情和肢体动作；同时还能实现语音、表情、眼神、肢体动作的协同表达，比如说话时配合自然的头部转动、呼吸起伏，甚至是说话间隙的眼神互动，完全还原真人对话的状态，彻底摆脱了传统机器人“念台词”的僵硬感。</p>\n</li>\n</ul>\n<h3 id=\"2小布米双足机器人家庭场景的生活化动作\">（2）“小布米”双足机器人：家庭场景的生活化动作</h3>\n<p><strong>节目里做了什么</strong>：4台“小布米”消费级双足机器人，在小品中完成了稳定行走、端茶、敬礼、与演员互动挥手等动作，在客厅的非结构化环境中，全程行走稳定，端茶时没有出现洒漏，动作流畅自然。</p>\n<p><strong>核心难点</strong>：消费级双足机器人，受限于成本和尺寸，硬件性能无法和工业级大机型相比，要在家庭的瓷砖、地毯等不同地面上，实现稳定行走，还要完成端茶等精细操作，对算法的轻量化、平衡控制能力提出了极高要求。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>轻量化双足运动控制算法：小机身的稳定行走</strong><br />\n“小布米”身高94厘米，体重仅12公斤，全身21个自由度，团队针对小尺寸双足机器人，自研了轻量化的模型预测控制算法，能在算力有限的主控芯片上，实现每秒上百次的步态规划与平衡调节，在瓷砖、地毯等不同地面上，都能自主调整步幅、步速和关节角度，实现稳定行走，哪怕被轻微触碰，也能快速调整重心，不会摔倒。</p>\n</li>\n<li>\n<p><strong>力控抓取：端茶不洒的精细操作</strong><br />\n机器人的手部搭载了微型力传感器，端茶时，能精准控制夹持杯子的力度，既牢牢握住杯子，又不会捏碎纸杯；同时在行走过程中，手臂会实时调整姿态，抵消行走带来的晃动，确保杯子始终保持水平，杯里的水不会洒漏，完美适配家庭场景的服务需求。</p>\n</li>\n</ul>\n<h2 id=\"4-国内外技术对比-2\">4. 国内外技术对比</h2>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>核心优势</th>\n<th>现存差距</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>仿生交互</td>\n<td>仿生人脸的高集成度驱动技术、多模态情感交互能力处于国内第一梯队，打破了海外企业在高端仿生机器人领域的垄断</td>\n<td>高动态运动控制能力，相较于宇树科技、波士顿动力有明显差距</td>\n</tr>\n<tr>\n<td>消费级普及</td>\n<td>率先实现消费级双足机器人的万元级定价，打开了C端市场的普及路径，差异化避开工业赛道红海竞争，商业化落地速度领先</td>\n<td>工业场景的落地能力与技术积累，弱于银河通用、魔法原子</td>\n</tr>\n<tr>\n<td>量产能力</td>\n<td>实现了仿生人形机器人的批量生产，量产能力远超海外同类型高端仿生产品</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"5-未来发展方向-2\">5. 未来发展方向</h2>\n<ul>\n<li>持续深化仿生人形机器人的技术迭代，推动产品在商业导览、康养陪护场景的规模化落地；</li>\n<li>推进消费级机器人“小布米”的量产与普及，拓展教育娱乐、家庭陪伴C端市场；</li>\n<li>深化与高校、科研院所的合作，推动人形机器人教学平台的落地；</li>\n<li>持续优化成本，推动人形机器人进入普通家庭。</li>\n</ul>\n<h1 id=\"四银河通用galbot\">四、银河通用（GALBOT）</h1>\n<h2 id=\"1-春晚节目表现-3\">1. 春晚节目表现</h2>\n<p>作为春晚<strong>指定具身大模型机器人</strong>，银河通用在贺岁微电影《我最难忘的今宵》中，携Galbot G1轮式双臂机器人亮相，与沈腾、马丽搭档，完成盘核桃、捡玻璃碎片、叠衣服、货架取物、串烤肠等生活化任务，实现了<strong>春晚舞台首次无预设脚本的机器人自主决策作业</strong>，无需提前编程，即可根据场景实时完成任务规划与执行。</p>\n<h2 id=\"2-公司核心业务与实力-3\">2. 公司核心业务与实力</h2>\n<ul>\n<li>企业基础：2023年5月成立，总部北京，由北大王鹤博士、前ABB高管姚腾洲联合创立，核心成员来自华为天才少年计划、百度、微软等企业；2025年12月完成超3亿美元融资，估值达30亿美元。</li>\n<li>技术壁垒：国内极少数实现“百亿数据集—具身大模型—机器人本体—场景规模化落地”全链条闭环的企业；自研“银河星脑AstraBrain”具身大模型体系，首创虚实结合的训练范式，构建了百亿级机器人干活数据集，是全球具身机器人大模型数据量最大的公司之一。</li>\n<li>商业化落地：产品主打Galbot系列轮式双臂通用机器人，采用“轮式底盘+折叠腿”复合结构，已实现千台级规模化落地，覆盖工业制造、智慧零售、医疗康养、城市服务等六大领域，合作客户包括宁德时代、德国博世、丰田汽车、北汽、宣武医院等龙头企业，2025年工业订单突破千台，创下具身智能领域商业化订单纪录。</li>\n</ul>\n<h2 id=\"3-节目核心技术实现原理通俗专业版\">3. 节目核心技术实现原理（通俗专业版）</h2>\n<p>银河通用的表演，和其他三家企业最大的区别，是<strong>完全没有预设的固定脚本</strong>——其他机器人的表演，哪怕动作再复杂，也是提前编排好的固定程序；而银河通用的机器人，是根据现场场景和任务指令，自主思考、自主规划、自主执行，这也是具身智能最核心的能力。我们以节目中几个典型任务为例，拆解其底层实现原理：</p>\n<h3 id=\"概述\">概述</h3>\n<ul>\n<li><strong>具身大模型核心</strong>：首创“合成仿真数据为主、真机采集数据为辅”的虚实结合训练管线，解决了全球机器人干活数据匮乏的行业难题；自研GraspVLA、GroceryVLA、NavFoM等端到端具身大模型，对透明、高光、不规则物体的抓取成功率稳定在95%以上，实现了任务的自主规划、动态避障、长程导航。</li>\n<li><strong>硬件架构</strong>：采用“轮式底盘+折叠腿+双臂”的复合结构，兼顾高速移动与越障能力，身高173cm、臂展190cm、升降行程65cm，双臂最大负载达50kg，搭载自研6自由度灵巧手，实现毫米级精细操作。</li>\n<li><strong>一体化控制系统</strong>：采用“大脑-小脑-神经控制”一体化系统，“大脑”（具身大模型）负责场景理解与任务规划，“小脑”负责运动控制与平衡调节，“神经控制”负责关节的实时伺服响应，实现端到端的任务执行，无需预设脚本。</li>\n</ul>\n<h3 id=\"核心任务逻辑无脚本自主作业的全链路流程\">核心任务逻辑：无脚本自主作业的全链路流程</h3>\n<p>不管是盘核桃、捡玻璃碎片，还是叠衣服、串烤肠，机器人执行所有任务，都遵循着<strong>“感知-决策-执行-反馈优化”</strong>的端到端全链路，这也是它能实现无脚本作业的核心，我们逐层拆解：</p>\n<h4 id=\"第一步感知看懂眼前的场景和物体\">第一步：感知——“看懂”眼前的场景和物体</h4>\n<p><strong>节目里的挑战</strong>：机器人需要识别出核桃、玻璃碎片、衣服、烤肠、签子等完全不同的物体，尤其是透明的玻璃碎片，在浅色桌面上几乎“隐形”，传统视觉系统很容易识别失败；同时还要适应舞台复杂的灯光变化，准确判断每个物体的位置、形状、大小、材质。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>机器人搭载了多模态感知系统，包括双目深度相机、激光雷达、触觉传感器，能同时获取场景的视觉、深度、触觉信息；</li>\n<li>自研的视觉大模型，在训练阶段见过了数十亿张真实场景图片，能精准识别上万种日常物体，哪怕是形状不规则的碎玻璃、褶皱的衣服，也能快速识别并分割出物体轮廓；</li>\n<li>针对透明物体识别的行业难题，团队通过仿真环境生成了海量的透明物体数据——不同厚度、不同碎裂形状、不同光照条件下的玻璃碎片，让机器人在虚拟世界中“见过”各种可能的透明形态，理解了透明物体的反光、折射规律，最终实现对玻璃碎片的识别成功率稳定在99%以上，哪怕是只有几毫米的玻璃渣，也能精准定位。</li>\n</ul>\n<h4 id=\"第二步决策想清楚任务该怎么做\">第二步：决策——“想清楚”任务该怎么做</h4>\n<p><strong>节目里的挑战</strong>：比如“捡玻璃碎片”这个任务，没有提前编程告诉机器人“先捡大的、再捡小的，用夹子夹，放到垃圾桶里”，机器人需要自主理解任务目标，把大任务拆解成可执行的小步骤，还要应对突发情况——比如玻璃碎片滚到了桌子底下，要自主规划路线，调整手臂姿态去捡。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>核心是自研的“银河星脑AstraBrain”具身大模型，它就像机器人的“大脑”，通过百亿级的机器人操作数据训练，已经学会了上千种日常任务的执行逻辑，能根据任务指令，自主拆解动作步骤。<br />\n通俗类比：就像你让一个人“把地上的玻璃碎片捡干净”，他不用你一步步教，就会自己去找垃圾桶、拿工具，先捡大块再捡小块，还会注意不被划伤——银河通用的具身大模型，就是让机器人具备了这样的自主思考能力。</li>\n<li>针对春晚的场景，团队还对大模型进行了轻量化微调，让它能快速适配舞台场景，针对不同任务快速输出最优的动作规划，同时具备容错能力——如果第一次捡玻璃没夹住，会自主调整夹子的开合角度、夹持位置，重新尝试，直到任务完成。</li>\n</ul>\n<h4 id=\"第三步执行精准完成精细操作\">第三步：执行——“精准完成”精细操作</h4>\n<p><strong>节目里的挑战</strong>：不同任务对操作的要求完全不同：盘核桃需要双手配合，力度既要足够转动核桃，又不能捏碎；串烤肠需要精准把烤肠穿到签子上，偏差1毫米就会穿歪；叠衣服需要抓住衣服的边角，精准完成折叠动作，这些都对机器人的动作精度、力控能力提出了极高要求。</p>\n<p><strong>底层实现原理</strong>：</p>\n<ul>\n<li>\n<p><strong>硬件基础：灵活又精准的“手臂和手”</strong><br />\nGalbot G1采用“轮式底盘+折叠腿+双臂”的复合结构，双臂最大负载达50kg，重复定位精度可达±0.02毫米，比头发丝还细；搭载自研6自由度灵巧手，指尖配备高精度力传感器，力控精度可达0.3N，既能实现串烤肠的毫米级精准定位，又能实现盘核桃、叠衣服的柔性力控。</p>\n</li>\n<li>\n<p><strong>“大脑-小脑-神经”一体化控制系统</strong><br />\n采用三级控制架构，实现端到端的精准执行：“大脑”（具身大模型）输出任务规划和动作指令；“小脑”（运动控制算法）负责把指令拆解成每个关节的转动角度、扭矩参数，实时调节手臂的运动轨迹和力度；“神经控制”（伺服系统）负责0.001秒级的实时响应，确保每个关节都精准执行指令，最终实现任务的完美执行。</p>\n</li>\n<li>\n<p><strong>虚实结合的训练范式：让机器人提前“练会”所有动作</strong><br />\n团队首创“合成仿真数据为主、真机采集数据为辅”的训练管线，解决了全球机器人干活数据匮乏的行业难题。通俗解释：在数字仿真世界里，生成了数百万种不同大小、材质、形状的虚拟物体，还有各种不同的场景，让机器人在虚拟世界里完成上千亿次的操作训练，练出了一套适应性极强的“通用操作能力”；再用少量真实世界的数据做微调，就能让机器人在真实场景里，轻松完成各种没见过的任务，这也是它能在春晚舞台上，无脚本完成多种生活化任务的核心原因。</p>\n</li>\n</ul>\n<h3 id=\"4-国内外技术对比-3\">4. 国内外技术对比</h3>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>核心优势</th>\n<th>现存差距</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>场景落地</td>\n<td>具身大模型的场景落地能力全球领先，实现了全球首个百台级机器人7×24小时自主运营的零售店，工业、零售场景的规模化落地能力，远超特斯拉Optimus、波士顿动力等海外企业</td>\n<td>双足人形机器人的高动态运动控制能力，相较于宇树科技、波士顿动力有差距</td>\n</tr>\n<tr>\n<td>技术创新</td>\n<td>首创的虚实结合训练范式，解决了全球机器人干活数据匮乏的行业难题，具身大模型的操作泛化能力跻身全球第一梯队</td>\n<td>消费级市场的布局与产品，相较于松延动力较为滞后</td>\n</tr>\n<tr>\n<td>工业能力</td>\n<td>轮式双臂机器人的重载操作、精细操作能力处于行业第一梯队，已获得头部制造企业的千台级订单，商业化落地规模全球领先</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"5-未来发展方向-3\">5. 未来发展方向</h3>\n<ul>\n<li>2026年加大“银河太空舱”无人零售解决方案在全国的推广力度，实现千店级规模部署；</li>\n<li>深化与宁德时代、博世等工业客户的合作，扩大工业场景的千台级部署规模；</li>\n<li>持续迭代具身大模型，提升机器人的通用任务泛化能力，拓展医疗康养、城市服务等场景；</li>\n<li>推进IPO进程，提升资本市场影响力，巩固具身智能领域的龙头地位。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></li>\n</ul>\n<h1 id=\"整体总结\">整体总结</h1>\n<p>2026年春晚的机器人表演，并非单纯的舞台炫技，而是中国人形机器人产业的一次国家级路演。四家企业分别在<strong>高动态运动控制、多机集群协同、仿生情感交互、具身智能落地</strong>四大核心方向，展现了中国在人形机器人领域从跟跑到并跑、部分领域领跑的产业格局。</p>\n<p>相较于海外企业聚焦实验室参数、军事场景、长期测试的技术路线，中国企业更注重场景落地、成本控制、规模化量产，形成了差异化的竞争优势，推动人形机器人从实验室走向工业、商业、家庭等真实场景，2026年也被业内视为人形机器人规模化应用的元年。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 10:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\n阅读(<span id=\"post_view_count\">76</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从挖矿木马入侵到 Docker Rootless 加固，我的服务器安全复盘",
      "link": "https://www.cnblogs.com/deali/p/19626849",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19626849\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 20:45\">\n    <span>从挖矿木马入侵到 Docker Rootless 加固，我的服务器安全复盘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>最近我连续几台服务器被挂了挖矿木马，CPU、带宽、磁盘 IO 被拉满，服务器直接卡死无法连接。</p>\n<p>排查后发现，核心诱因是 Docker 权限过高 + 服务漏洞暴露，导致攻击者通过容器突破权限控制。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/cec878553480eb4f/1097027d157aa49e.jpg\" /></p>\n<blockquote>\n<p>PS：本来想写一篇文章介绍排查过程的，不过还是嫌麻烦没写，放在本文一起讲吧~</p>\n</blockquote>\n<p>重装系统后，我在部署 Docker 时注意到官方提示的 Rootless（无根）模式 —— 这一模式能从根本上降低容器逃逸风险，遂深入研究并落地配置，现将完整过程整理分享，希望能帮到同样关注 Docker 安全的开发者。</p>\n<h2 id=\"rootless-模式是什么\">Rootless 模式是什么</h2>\n<p>普通情况下，Docker 守护进程（dockerd）是用 <code>root</code> 权限运行的，哪怕你用普通用户执行 <code>docker run</code>，底层还是 root 权限，这有安全风险（比如容器逃逸可能拿到主机 root）。</p>\n<p>Rootless 模式让 Docker 守护进程以<strong>普通用户权限</strong>运行，哪怕容器出问题，也无法获取主机的 root 权限，安全性大幅提升。</p>\n<p>有好处自然有代价，rootless 的代价是配置复杂，且部分功能受限（比如无法端口映射 &lt; 1024）。</p>\n<p>不过没关系，这些也可以通过配置解决。先从安装开始吧。</p>\n<h2 id=\"安装docker\">安装docker</h2>\n<p>本来安装是很简单的，不过加个定语：在国内网络环境，那就非常复杂了。</p>\n<p>本文介绍最简单的安装方式：使用docker官方脚本+清华镜像。</p>\n<pre><code class=\"language-bash\">export DOWNLOAD_URL=\"https://mirrors.tuna.tsinghua.edu.cn/docker-ce\"\n# 如您使用 curl\ncurl -fsSL https://ghfast.top/https://raw.githubusercontent.com/docker/docker-install/master/install.sh | sh\n# 如您使用 wget\nwget -O- https://ghfast.top/https://raw.githubusercontent.com/docker/docker-install/master/install.sh | sh\n</code></pre>\n<p>注意 <code>raw.githubusercontent.com</code> 这个域名也是无法访问的，可以使用 ghproxy 来加速。</p>\n<h2 id=\"安装完成提示\">安装完成提示</h2>\n<p>安装完成会有一个提示，这也是开启 Rootless 模式的关键入口：</p>\n<pre><code class=\"language-bash\">================================================================================\n\nTo run Docker as a non-privileged user, consider setting up the\nDocker daemon in rootless mode for your user:\n\n    dockerd-rootless-setuptool.sh install\n\nVisit https://docs.docker.com/go/rootless/ to learn about rootless mode.\n\n\nTo run the Docker daemon as a fully privileged service, but granting non-root\nusers access, refer to https://docs.docker.com/go/daemon-access/\n\nWARNING: Access to the remote API on a privileged Docker daemon is equivalent\n         to root access on the host. Refer to the 'Docker daemon attack surface'\n         documentation for details: https://docs.docker.com/go/attack-surface/\n\n================================================================================\n</code></pre>\n<p>我就是在这里开始使用 rootless 模式的。</p>\n<p>提示核心解读：</p>\n<ol>\n<li>推荐通过<code>dockerd-rootless-setuptool.sh install</code>开启 Rootless 模式，让普通用户无 root 权限运行 Docker；</li>\n<li>若坚持 root 权限运行 Docker，可参考文档给普通用户授权（如加入 docker 组），但风险更高；</li>\n<li>重点警告：暴露 Docker 远程 API（如 2375 端口）= 直接开放主机 root 权限，这是服务器被入侵的高频诱因！</li>\n</ol>\n<h2 id=\"安装必要依赖\">安装必要依赖</h2>\n<p>我直接运行 <code>dockerd-rootless-setuptool.sh install</code> 的时候，提示要缺乏依赖</p>\n<pre><code class=\"language-bash\">$ dockerd-rootless-setuptool.sh install\n[ERROR] Missing system requirements. Run the following commands to\n[ERROR] install the requirements and run this tool again.\n\n########## BEGIN ##########\nsudo sh -eux &lt;&lt;EOF\n# Install newuidmap &amp; newgidmap binaries\napt-get install -y uidmap\nEOF\n########## END ##########\n</code></pre>\n<p>输入提示的这行命令：</p>\n<pre><code class=\"language-bash\">sudo sh -eux &lt;&lt;EOF\n# Install newuidmap &amp; newgidmap binaries\napt-get install -y uidmap\nEOF\n</code></pre>\n<p>安装完成后，再次执行 <code>dockerd-rootless-setuptool.sh install</code></p>\n<p>以后操作 docker 服务，要加上 <code>--user</code></p>\n<pre><code class=\"language-bash\">systemctl --user start docker.service\n</code></pre>\n<h2 id=\"配置\">配置</h2>\n<p>rootless 模式下：</p>\n<ul>\n<li>所有 Docker 命令都要在<strong>安装 Rootless 的普通用户</strong>下执行（不要用 root）；</li>\n<li>如果重启服务器后 Docker 没自动启动，执行：<code>systemctl --user enable --now docker</code>；</li>\n<li>数据备份要找 <code>~/.local/share/docker</code> 目录（而非 <code>/var/lib/docker</code>）。</li>\n</ul>\n<h3 id=\"镜像加速器\">镜像加速器</h3>\n<p>默认情况下，Rootless Docker 的配置文件存放在当前用户的 <strong>XDG 配置目录</strong> 下，路径是：<code>~/.config/docker/daemon.json</code></p>\n<pre><code class=\"language-bash\"># 先创建目录（如果不存在）\nmkdir -p ~/.config/docker\n\n# 编辑配置文件（用 nano 或 vim 都可以）\nnano ~/.config/docker/daemon.json\n</code></pre>\n<p>配置加速器</p>\n<pre><code class=\"language-json\">{\n  \"registry-mirrors\": [\"https://你的阿里云镜像加速地址.mirror.aliyuncs.com\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"100m\",\n    \"max-file\": \"3\"\n  }\n}\n</code></pre>\n<p>注意：之前大部分稳定好用的加速器都停止服务了，现在就没法推荐啥，大家各凭本事吧。</p>\n<h3 id=\"解决-无法绑定-1-1023-端口-的问题\">解决 “无法绑定 1-1023 端口” 的问题</h3>\n<p>需要给当前用户 “绑定低端口” 的权限：</p>\n<pre><code class=\"language-bash\"># 给当前用户授权绑定 1-1023 端口（仅对当前会话生效）\nsudo sysctl net.ipv4.ip_unprivileged_port_start=0\n\n# 永久生效（重启后也有效）\necho \"net.ipv4.ip_unprivileged_port_start=0\" | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p  # 立即生效\n</code></pre>\n<p>执行后，你就能正常映射 80、443 等端口了。</p>\n<h3 id=\"重启生效\">重启生效</h3>\n<p>Rootless 模式的 Docker 重启命令和系统级不同，执行：</p>\n<pre><code class=\"language-bash\"># 重启当前用户的 Docker 服务\nsystemctl --user restart docker\n\n# 验证配置是否生效\ndocker info\n# 能在 \"Registry Mirrors\" 部分看到你配置的镜像加速地址就是成功的\n</code></pre>\n<p>正常输出示例：</p>\n<pre><code class=\"language-plaintext\">Rootless: true\nRegistry Mirrors:\n https://你的阿里云镜像加速地址.mirror.aliyuncs.com/\n</code></pre>\n<h3 id=\"rootless-模式不支持的配置项\">Rootless 模式不支持的配置项</h3>\n<p>部分系统级配置在 Rootless 下无效（因为没有 root 权限），比如：</p>\n<ul>\n<li><code>iptables: false</code>（网络规则由 slirp4netns 管理，而非 iptables）；</li>\n<li><code>storage-driver: overlay2</code>（默认已启用，无需手动配置）；</li>\n<li>远程 API 相关配置（如 <code>hosts: [\"tcp://0.0.0.0:2375\"]</code>，Rootless 下不建议开启）。</li>\n<li>任何涉及系统级目录（如<code>/var/run/docker.sock</code>）的配置。</li>\n</ul>\n<h2 id=\"volume问题\">volume问题</h2>\n<p>切换到 rootless 之后，我还发现了 swag 的 config 无法读写了。</p>\n<p>swag 的 compose.yaml 配置是这样：</p>\n<pre><code class=\"language-yaml\">services:\n  swag:\n    image: linuxserver/swag\n    container_name: swag\n    cap_add:\n      - NET_ADMIN\n    environment:\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - ./config:/config\n</code></pre>\n<p><strong>rootless Docker 里，容器内的 UID=1000 ≠ 宿主机的 UID=1000</strong></p>\n<p>所以 <strong>SWAG 在容器里 chown 了 <code>/config</code>，宿主机看到的是一个“映射后的陌生 UID（100999）”</strong></p>\n<h3 id=\"解决方法\">解决方法</h3>\n<p>rootless 官方推荐使用命名卷，但我要经常修改 config 里的文件，这个肯定不现实。</p>\n<p>那么还有一个方法，使用 ACL 放行。</p>\n<p>先安装相关工具：</p>\n<pre><code class=\"language-bash\">sudo apt update\nsudo apt install -y acl\n</code></pre>\n<p>在 swag 目录下执行</p>\n<pre><code class=\"language-bash\">setfacl -m u:ecs-user:rwx config\nsetfacl -R -m u:ecs-user:rwx config\nsetfacl -d -m u:ecs-user:rwx config\n</code></pre>\n<p>验证：</p>\n<pre><code class=\"language-bash\">getfacl config | sed -n '1,20p'\n</code></pre>\n<p>看到类似：</p>\n<pre><code>user::rwx\nuser:ecs-user:rwx\ngroup::r-x\nmask::rwx\nother::r-x\n</code></pre>\n<h2 id=\"小结\">小结</h2>\n<p>Rootless 模式虽比普通 Docker 配置稍繁琐，但能从根本上降低容器逃逸风险，尤其适合对外提供服务的生产服务器。核心总结：</p>\n<ol>\n<li>安装：结合清华镜像源解决国内下载问题，优先用普通用户安装 Rootless 模式；</li>\n<li>权限：禁止暴露 Docker 远程 API，给普通用户授权低端口绑定权限即可满足日常使用；</li>\n<li>配置：牢记 Rootless 模式的配置文件、数据目录均在用户目录下，与系统级 Docker 区分开；</li>\n<li>安全：即便开启 Rootless，运行容器时仍需注意服务安全（如 Redis 加密码、安全组限制端口访问）。</li>\n</ol>\n<p>此次踩坑让我深刻意识到：服务器安全无小事，哪怕是 Docker 这样的基础工具，也需从权限层面做好最小化管控，才能避免被挖矿木马等恶意程序趁虚而入。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 20:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">117</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "手把手教你使用vscode开发stm32！",
      "link": "https://www.cnblogs.com/chenyouyuan/p/19626759",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/chenyouyuan/p/19626759\" id=\"cb_post_title_url\" title=\"å‘å¸ƒäºŽ 2026-02-20 19:31\">\n    <span>æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨vscodeå¼€å‘stm32ï¼</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        å·²ç»2026å¹´äº†ï¼Œä½ æ˜¯å¦è¿˜åœ¨ä½¿ç”¨å¤è€çš„keil5çš„è°ƒè¯•å‘¢ï¼Ÿæ˜¯å¦è¿˜åœ¨ä¸ºkeil5å¤åˆ¶ç²˜è´´ä»£ç åˆ°èŠå¤©å¼aiå†ç²˜è´´å›žæ¥è€Œçƒ¦æ¼å‘¢ï¼Ÿå¿«å¿«åŠ å…¥vscodeå¼€å‘stm32çš„å¤§éƒ¨é˜ŸæŽ¥å—å…‰è£çš„è¿›åŒ–å§ï¼\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"å¼€å‘å·¥å…·é…ç½®ç¯‡è¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32\">å¼€å‘å·¥å…·é…ç½®ç¯‡ï¼šè¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32</h1>\n<blockquote>\n<p>å·²ç»2026å¹´äº†ï¼Œä½ æ˜¯å¦è¿˜åœ¨ä½¿ç”¨å¤è€çš„keil5çš„è°ƒè¯•å‘¢ï¼Ÿæ˜¯å¦è¿˜åœ¨ä¸ºkeil5å¤åˆ¶ç²˜è´´ä»£ç åˆ°èŠå¤©å¼aiå†ç²˜è´´å›žæ¥è€Œçƒ¦æ¼å‘¢ï¼Ÿå¿«å¿«åŠ å…¥vscodeå¼€å‘stm32çš„å¤§éƒ¨é˜ŸæŽ¥å—å…‰è£çš„è¿›åŒ–å§ï¼</p>\n</blockquote>\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">ç›®å½•</div><ul><li><a href=\"#å¼€å‘å·¥å…·é…ç½®ç¯‡è¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32\" rel=\"noopener nofollow\">å¼€å‘å·¥å…·é…ç½®ç¯‡ï¼šè¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32</a><ul><li><a href=\"#å‰è¨€\" rel=\"noopener nofollow\">å‰è¨€</a></li><li><a href=\"#æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘\" rel=\"noopener nofollow\">æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘</a></li><li><a href=\"#ä¸€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“\" rel=\"noopener nofollow\">ä¸€ã€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“</a></li><li><a href=\"#äºŒä¸‹è½½vscodeä»¥åŠæ’ä»¶\" rel=\"noopener nofollow\">äºŒã€ä¸‹è½½vscodeä»¥åŠæ’ä»¶</a><ul><li><a href=\"#stm32-for-vscode\" rel=\"noopener nofollow\">stm32 for vscode</a></li><li><a href=\"#makefiel\" rel=\"noopener nofollow\">makefiel</a></li></ul></li><li><a href=\"#ä¸‰stlinké©±åŠ¨å®‰è£\" rel=\"noopener nofollow\">ä¸‰ã€stlinké©±åŠ¨å®‰è£…</a></li><li><a href=\"#å››-é…ç½®å¼€å‘çŽ¯å¢ƒ\" rel=\"noopener nofollow\">å››ã€ é…ç½®å¼€å‘çŽ¯å¢ƒ</a><ul><li><a href=\"#é…ç½®çŽ¯å¢ƒå˜é‡\" rel=\"noopener nofollow\">é…ç½®çŽ¯å¢ƒå˜é‡</a></li><li><a href=\"#å…³äºŽlaunchjsonæ–‡ä»¶\" rel=\"noopener nofollow\">å…³äºŽlaunch.jsonæ–‡ä»¶</a></li><li><a href=\"#å…³äºŽtasksjsonæ–‡ä»¶\" rel=\"noopener nofollow\">å…³äºŽtasks.jsonæ–‡ä»¶</a></li></ul></li><li><a href=\"#å¼€å§‹è°ƒè¯•\" rel=\"noopener nofollow\">å¼€å§‹è°ƒè¯•</a><ul><li><a href=\"#stm32-svdæ–‡ä»¶\" rel=\"noopener nofollow\">stm32 svdæ–‡ä»¶</a></li></ul></li></ul></li></ul></div><p></p>\n<p>æœ¬ç¯‡æ–‡ç« ä¸»è¦å‚è€ƒæ¹–å—å¤§å­¦robomasterè·ƒé¹¿æˆ˜é˜Ÿçš„ç”µæŽ§å¼€æºéƒ¨åˆ†</p>\n<p><a href=\"https://gitee.com/hnuyuelurm/basic_framework/blob/master/.Doc/VSCode+Ozone%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.md\" rel=\"noopener nofollow\" target=\"_blank\">.Doc/VSCode+Ozoneä½¿ç”¨æ–¹æ³•.md Â· HNUYueLuRM/basic_framework - Gitee.com</a></p>\n<h2 id=\"å‰è¨€\">å‰è¨€</h2>\n<p>æœ¬ç¯‡æ–‡ç« ä¸»è¦ä½¿ç”¨vscode + cubemxå¹³æ›¿keil5ï¼Œå®žçŽ°å¿«é€Ÿå¼€å‘ã€å®žæ—¶å¯è§†åŒ–å˜é‡ï¼ˆå…¨å±€ï¼‰ã€å¯ä»¥æŸ¥çœ‹å¯„å­˜å™¨å†…å®¹ã€copilotè¾…åŠ©å¼€å‘....</p>\n<p>æ”¯æŒstlinkï¼Œjlinkï¼Œdaplinkè°ƒè¯•å™¨ï¼Œæš‚æ—¶æ²¡æœ‰æ‰¾åˆ°çº¯é vscodeçš„å®žæ—¶å¯è§†åŒ–å‚æ•°æ³¢å½¢å›¾åŠŸèƒ½çš„æ’ä»¶</p>\n<p>å¦‚æžœå¤§å®¶è¿˜æœ‰å…¶ä»–å¥½ç”¨çš„æ–¹æ¡ˆæ¬¢è¿Žè®¨è®ºå™¢~</p>\n<h2 id=\"æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘\">æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘</h2>\n<p>å¯èƒ½ç½‘ç»œåŽŸå› å¯¼è‡´ä¸€äº›å®‰è£…æ— æ³•å®Œæˆï¼Œæ‰€ä»¥è¿™è¾¹æä¾›æ‰€ç”¨åˆ°çš„æ‰€æœ‰åŒ…ï¼Œæ ¹æ®éœ€è¦å®‰è£…å³å¯<br />\né€šè¿‡ç½‘ç›˜åˆ†äº«çš„æ–‡ä»¶ï¼šall_in_one.zip<br />\né“¾æŽ¥: <a href=\"https://pan.baidu.com/s/12brC2bPmu9wWa2h-VgIZmg?pwd=9xah\" rel=\"noopener nofollow\" target=\"_blank\">https://pan.baidu.com/s/12brC2bPmu9wWa2h-VgIZmg?pwd=9xah</a> æå–ç : 9xah<br />\n--æ¥è‡ªç™¾åº¦ç½‘ç›˜è¶…çº§ä¼šå‘˜v3çš„åˆ†äº«<br />\nbç«™è§†é¢‘é“¾æŽ¥<br />\n<a href=\"https://www.bilibili.com/video/BV1ZMfGBrEFy/?vd_source=f553a12b04c16a678ddc0064cc04563c\" rel=\"noopener nofollow\" target=\"_blank\">https://www.bilibili.com/video/BV1ZMfGBrEFy/?vd_source=f553a12b04c16a678ddc0064cc04563c</a></p>\n<h2 id=\"ä¸€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“\">ä¸€ã€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“</h2>\n<p>cubemxå®˜ç½‘(éœ€è¦ç®€å•çš„æ³¨å†Œå³å¯)ï¼š</p>\n<p><a href=\"https://www.st.com/en/development-tools/stm32cubemx.html#get-software\" rel=\"noopener nofollow\" target=\"_blank\">https://www.st.com/en/development-tools/stm32cubemx.html#get-software</a></p>\n<p>ä¸‹è½½å®Œæˆä¹‹åŽç‚¹å‡»</p>\n<p><img alt=\"\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220181610339.png\" /></p>\n<p>ç›´æŽ¥åœ¨æœç´¢æ æœç´¢ä½ ä½¿ç”¨çš„stm32çš„åž‹å·ï¼Œä»¥f103ä½œä¸ºä¾‹å­</p>\n<p><img alt=\"image-20260220181746320\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220181746320.png\" /></p>\n<p>åŒå‡»è¦é€‰æ‹©çš„æ¿å­å³å¯è¿›å…¥</p>\n<p>å…¶ä½™è¯¦ç»†çš„é…ç½®å¯ä»¥å‚è€ƒå…¶ä»–æ•™ç¨‹</p>\n<p>ä¸»è¦æ³¨æ„çš„æ˜¯ï¼š</p>\n<p>sysçš„é…ç½®è¦é…ç½®æˆswæ¨¡å¼ï¼Œä¸ç„¶ä¼šåªèƒ½çƒ§å½•ä¸€æ¬¡</p>\n<p><img alt=\"image-20260220181938762\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220181938762.png\" /></p>\n<p>å¯¼å‡ºè¿™è¾¹é€‰æ‹©makefile</p>\n<p><img alt=\"image-20260220182046638\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220182046638.png\" /></p>\n<h2 id=\"äºŒä¸‹è½½vscodeä»¥åŠæ’ä»¶\">äºŒã€ä¸‹è½½vscodeä»¥åŠæ’ä»¶</h2>\n<p>vscodeå®˜ç½‘ï¼š</p>\n<p><a href=\"https://www.st.com/en/development-tools/stm32cubemx.html#get-software\" rel=\"noopener nofollow\" target=\"_blank\">https://www.st.com/en/development-tools/stm32cubemx.html#get-software</a></p>\n<p>éœ€è¦å®‰è£…çš„vscdoeæ’ä»¶ï¼š</p>\n<p>ç‚¹å‡»vscodeå·¦ä¾§çš„è¿™ä¸ªå›¾æ ‡</p>\n<p><img alt=\"image-20260220174816604\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174816604.png\" /></p>\n<h3 id=\"stm32-for-vscode\">stm32 for vscode</h3>\n<p><img alt=\"image-20260220160002646\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220160002646.png\" /></p>\n<p><img alt=\"image-20260220155925565\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220155925565.png\" /></p>\n<p>ç‚¹å‡»install build tools</p>\n<p><img alt=\"image-20260220175156853\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175156853.png\" /></p>\n<p>å‡ºçŽ°å¦‚ä¸Šé¡µé¢å³ä»£è¡¨å®‰è£…æˆåŠŸï¼ˆå¤§çº¦5~15åˆ†é’Ÿï¼‰</p>\n<p>å¦‚æžœç½‘ç»œä¸å¥½å£è¯­åˆ‡æ¢æ‰‹æœºçƒ­ç‚¹å†æ¬¡å°è¯•</p>\n<p>è¿˜ä¸è¡Œå°±ç›´æŽ¥ä½¿ç”¨æˆ‘çš„ç™¾åº¦ç½‘ç›˜åˆ†äº«çš„zipåŽ‹ç¼©åŒ…ï¼Œå»ºè®®æ”¾åˆ°dç›˜ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰</p>\n<h3 id=\"makefiel\">makefiel</h3>\n<p><img alt=\"image-20260220155854381\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220155854381.png\" /></p>\n<h2 id=\"ä¸‰stlinké©±åŠ¨å®‰è£…\">ä¸‰ã€stlinké©±åŠ¨å®‰è£…</h2>\n<p>å¦‚æžœä½ ä¹‹å‰æ²¡æœ‰ä½¿ç”¨è¿‡stlinkï¼Œè¯·æ ¹æ®å¦‚ä¸‹é“¾æŽ¥å®Œæˆstlinké©±åŠ¨çš„å®‰è£…</p>\n<p><a href=\"https://www.st.com.cn/zh/development-tools/stsw-link009.html\" rel=\"noopener nofollow\" target=\"_blank\">STSW-LINK009 | Software - æ„æ³•åŠå¯¼ä½“</a><br />\næ ¹æ®è‡ªå·±çš„ç”µè„‘é…ç½®åŒå‡»ä»¥ä¸‹ä¸¤ä¸ªexeä¸­çš„ä¸€ä¸ª</p>\n<p><img alt=\"image-20260220184946316\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184946316.png\" /></p>\n<h2 id=\"å››-é…ç½®å¼€å‘çŽ¯å¢ƒ\">å››ã€ é…ç½®å¼€å‘çŽ¯å¢ƒ</h2>\n<h3 id=\"é…ç½®çŽ¯å¢ƒå˜é‡\">é…ç½®çŽ¯å¢ƒå˜é‡</h3>\n<ol>\n<li>\n<p>åœ¨vscodeæ‰¾åˆ°æœ€å·¦è¾¹çš„å››ä¸ªæ–¹å—å›¾æ ‡ï¼Œè¿™é‡Œæ˜¯æˆ‘ä»¬å®‰è£…æ‹“å±•çš„åœ°æ–¹</p>\n<p>ç‚¹å‡»ä¹‹åŽæ‰¾åˆ°stm32 for vscode</p>\n<p><img alt=\"image-20260220174706404\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174706404.png\" /></p>\n</li>\n<li>\n<p>æ‰“å¼€è¯¦æƒ…é¡µé¢--&gt;ç‚¹å‡»å³ä¸‹è§’è“è‰²çš„ç¼“å­˜æ–‡å­—ï¼Œæ‰“å¼€ç¼“å­˜æ–‡ä»¶å¤¹</p>\n<p><img alt=\"image-20260220175025884\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175025884.png\" /></p>\n<p>ç¼“å­˜æ–‡ä»¶å¤¹å¦‚ä¸‹</p>\n<p><img alt=\"image-20260220175310991\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175310991.png\" /></p>\n</li>\n<li>\n<p>è¿›å…¥@å¼€å¤´çš„æ–‡ä»¶å¤¹,å¦‚ä¸‹ï¼Œæˆ‘ä»¬ä¸ºäº†æ–¹ä¾¿ï¼ŒæŠŠè¯¥æ–‡ä»¶å¤¹ä¸‹é¢æ‰€æœ‰çš„ä¸œè¥¿è¿ç§»åˆ°Dç›˜ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰ï¼Œåœ¨Dç›˜ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹å«stm32toolsï¼ŒæŠŠæ–‡ä»¶å…¨éƒ¨æ”¾è¿›åŽ»</p>\n<p><img alt=\"image-20260220175354956\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175354956.png\" /></p>\n<p>è¿ç§»è·¯å¾„å¦‚ä¸‹å›¾ï¼ˆå› ä¸ºè¿™ä¸ªæ¼”ç¤ºçš„æœºå™¨æ²¡æœ‰åˆ†dç›˜ï¼Œæˆ‘å°±æ”¾åˆ°cç›˜äº†ï¼‰</p>\n<p><img alt=\"image-20260220175533984\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175533984.png\" /></p>\n</li>\n<li>\n<p>æŽ¥ä¸‹æ¥æŒ‰ä¸‹winé”®ï¼Œåœ¨æœç´¢æ æœç´¢çŽ¯å¢ƒ</p>\n<p>ç‚¹å‡»ç¼–è¾‘ç³»ç»ŸçŽ¯å¢ƒå˜é‡</p>\n<p><img alt=\"\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174138545.png\" /></p>\n<p>ç‚¹å‡»æœ€ä¸‹é¢çš„çŽ¯å¢ƒå˜é‡ï¼ˆNï¼‰</p>\n<p><img alt=\"image-20260220174230783\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174230783.png\" /></p>\n<p>åŒå‡»path</p>\n<p><img alt=\"image-20260220174323481\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174323481.png\" /></p>\n<p>ç‚¹å‡»å³è¾¹çš„æ–°å»ºå³å¯æ–°å»ºå˜é‡ï¼Œctrl+vç²˜è´´ä¸‰ä¸ªbinçš„è·¯å¾„ï¼ˆå¦‚ä¸‹å›¾ï¼Œæ ¹æ®è‡ªå·±çš„æ–‡ä»¶ä½ç½®æ¥</p>\n<p><img alt=\"image-20260220174405199\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174405199.png\" /></p>\n</li>\n</ol>\n<p>é…ç½®å®Œæˆä¹‹åŽwin + r</p>\n<p>åœ¨å¼¹å‡ºçš„çª—å£è¾“å…¥cmdï¼Œå›žè½¦</p>\n<p>ç²˜è´´å¦‚ä¸‹æŒ‡ä»¤è¿è¡Œ</p>\n<pre><code class=\"language-cmd\">arm-none-eabi-gcc -v\n</code></pre>\n<p>å¦‚æžœå‡ºçŽ°ç±»ä¼¼ä¸‹å›¾è¾“å‡ºï¼Œå°±ä»£è¡¨æˆåŠŸ</p>\n<p><img alt=\"image-20260220180204385\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220180204385.png\" /></p>\n<ol start=\"5\">\n<li>\n<p>æ‰“å¼€vscode è¿›å…¥åˆ°é¡¹ç›®æ–‡ä»¶å¤¹ï¼ˆå‰é¢åˆ›å»ºçš„cubemxé¡¹ç›®æ–‡ä»¶å¤¹ï¼‰</p>\n</li>\n<li>\n<p>ctrl + ï¼Œæ‰“å¼€è®¾ç½®ï¼Œæœç´¢stm32 for vscode<br />\n<img alt=\"image-20260220184204803\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184204803.png\" /><br />\nç‚¹å‡»åœ¨settings.jsonä¸­ç¼–è¾‘,å®Œå–„å¦‚ä¸‹è·¯å¾„</p>\n<p><img alt=\"image-20260220184315477\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184315477.png\" /><br />\nsettings.json(æ ¹æ®è‡ªå·±çš„è·¯å¾„é…ç½®)</p>\n<pre><code class=\"language-json\">{\n    \"stm32-for-vscode.openOCDPath\": \"C:\\\\stm32tools\\\\openocd\\\\0.12.0-7.1\\\\.content\\\\bin\\\\openocd.EXE\",\n    \"stm32-for-vscode.makePath\": \"C:\\\\stm32tools\\\\windows-build-tools\\\\4.4.1-3.1\\\\.content\\\\bin\\\\make.EXE\",\n    \"stm32-for-vscode.armToolchainPath\": \"C:\\\\stm32tools\\\\arm-none-eabi-gcc\\\\14.2.1-1.1.1\\\\.content\\\\bin\",\n    \"makefile.configureOnOpen\": true,\n    \"cortex-debug.stm32cubeprogrammer\": \"\",\n    \"cortex-debug.openocdPath\": \"C:\\\\stm32tools\\\\openocd\\\\0.12.0-7.1\\\\.content\\\\bin\\\\openocd.EXE\",\n    \"cortex-debug.armToolchainPath\": \"C:\\\\stm32tools\\\\arm-none-eabi-gcc\\\\14.2.1-1.1.1\\\\.content\\\\bin\",\n}\n</code></pre>\n</li>\n<li>\n<p>ctrl + ~</p>\n<p>åœ¨ç»ˆç«¯è¾“å…¥make -j12 æµ‹è¯•çœ‹çœ‹èƒ½å¦æˆåŠŸç¼–è¯‘,å¦‚ä¸‹å›¾å³ä»£è¡¨æˆåŠŸç¼–è¯‘</p>\n<p><img alt=\"image-20260220182335492\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220182335492.png\" /></p>\n</li>\n</ol>\n<h3 id=\"å…³äºŽlaunchjsonæ–‡ä»¶\">å…³äºŽlaunch.jsonæ–‡ä»¶</h3>\n<p>åœ¨å·¦è¾¹æ æ‰¾åˆ°è¿™ä¸ªå›¾æ ‡</p>\n<p><img alt=\"\" /></p>\n<p>ç‚¹å‡»ä¸€ä¸‹é‡Œé¢çš„åˆ›å»ºlaunchæ–‡ä»¶</p>\n<p>å°±å¯ä»¥åœ¨ç›®å½•çš„.vscodeæ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°</p>\n<p><img alt=\"image-20260220160146084\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220160146084.png\" /></p>\n<p>æˆ‘ä»¬ç›´æŽ¥å¤åˆ¶ä¸‹é¢æˆ‘ä¿®æ”¹å¥½çš„stlinkçš„ä»£ç ï¼ˆdaplinkã€jlinkæ¹–å¤§å¼€æºçš„giteeä»“åº“å·²ç»æä¾›ï¼‰</p>\n<pre><code class=\"language-json\">{\n    // å¯åŠ¨è°ƒè¯•çš„å¿«æ·é”®æ˜¯F5\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        // ä½¿ç”¨dap-link(å¦‚æ— çº¿è°ƒè¯•å™¨æ—¶çš„å‚è€ƒé…ç½®)\n        {\n            \"name\": \"STlink\",\n            \"cwd\": \"${workspaceRoot}\",\n            \"executable\": \"${workspaceRoot}\\\\build\\\\first.elf\", // è¦ä¸‹è½½åˆ°è°ƒè¯•å™¨çš„æ–‡ä»¶,èŠ±æ‹¬å·ä¸­çš„æ˜¯vscodeä¸¤ä¸ªé¢„å®šä¹‰çš„å‚æ•°\n            \"request\": \"launch\",\n            \"type\": \"cortex-debug\",\n            //ä½¿ç”¨J-link GDB Serveræ—¶å¿…é¡»;å…¶ä»–GBD Serveræ—¶å¯é€‰ï¼ˆæœ‰å¯èƒ½å¸®åŠ©è‡ªåŠ¨é€‰æ‹©SVDæ–‡ä»¶ï¼‰\n            //æ”¯æŒçš„è®¾å¤‡è§ https://www.segger.com/downloads/supported-devices.php\n            //svdæ–‡ä»¶ï¼Œæœ‰è¿™ä¸ªæ–‡ä»¶æ‰èƒ½æŸ¥çœ‹å¯„å­˜å™¨çš„å€¼ï¼Œæ¯ä¸ªå•ç‰‡æœºéƒ½ä¸åŒã€‚å¯ä»¥åœ¨ä»¥ä¸‹åœ°å€æ‰¾åˆ°https://github.com/modm-io/cmsis-svd-stm32 \n            //è¯¥é¡¹ç›®çš„æ ¹ç›®å½•å·²ç»æä¾›äº†Cåž‹å¼€å‘æ¿ä½¿ç”¨çš„å¤–è®¾svdæ–‡ä»¶\n            \"svdFile\": \"./STM32F103.svd\",\n            \"servertype\": \"openocd\", //ä½¿ç”¨çš„GDB Server\n            \"configFiles\": [\n                \"openocd_stlink.cfg\", // é…ç½®æ–‡ä»¶å·²ç»åœ¨æ ¹ç›®å½•æä¾›,è‹¥è¦ä¿®æ”¹ä»¥æ­¤ç±»æŽ¨,openocdçš„è·¯å¾„ä¸‹çš„share/scriptsä¸­æœ‰å„ç§å†™å¥½çš„é…ç½®æ–‡ä»¶\n            ],\n            \"runToEntryPoint\": \"main\", // è°ƒè¯•æ—¶åœ¨mainå‡½æ•°å…¥å£åœä¸‹\n            \"preLaunchTask\": \"build task\",//å…ˆè¿è¡ŒBuildä»»åŠ¡ç¼–è¯‘é¡¹ç›®,å–æ¶ˆæ³¨é‡Šå³å¯ä½¿ç”¨\n            \"liveWatch\": {\n                \"enabled\": true,\n                \"samplesPerSecond\": 4\n            }\n        },\n      \n    ],\n}\n</code></pre>\n<p>é…ç½®å®Œæˆä¹‹åŽåœ¨vscodeçš„å·¦ä¾§debugå›¾æ ‡å³å¯çœ‹åˆ°æ›´æ”¹é…ç½®çš„stlinkçš„é…ç½®<br />\n<img alt=\"image-20260220184555431\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184555431.png\" /></p>\n<h3 id=\"å…³äºŽtasksjsonæ–‡ä»¶\">å…³äºŽtasks.jsonæ–‡ä»¶</h3>\n<p>ä½ç½®ä¸Žlaunchæ–‡ä»¶ä¸€æ ·ï¼Œæ²¡æœ‰å°±æ–°å»ºä¸€ä¸ª</p>\n<pre><code class=\"language-json\">{\n    // See https://go.microsoft.com/fwlink/?LinkId=733558\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"build task\",         // ä»»åŠ¡æ ‡ç­¾\n            \"type\": \"shell\",               // ä»»åŠ¡ç±»åž‹,å› ä¸ºè¦è°ƒç”¨mingw32-make,æ˜¯åœ¨ç»ˆç«¯(CMD)é‡Œè¿è¡Œçš„,æ‰€ä»¥æ˜¯shellä»»åŠ¡\n            \"command\": \"make -j24\",// ä»»åŠ¡å‘½ä»¤,çº¿ç¨‹æ•°å¯ä»¥æ ¹æ®è‡ªå·±çš„ç”µè„‘ä¿®æ”¹,å»ºè®®ä¸Žcpuæ ¸æ•°ç›¸åŒ\n            \"problemMatcher\": [],          \n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        },\n        {\n            \"label\": \"download dap\",\n            \"type\": \"shell\",               // å¦‚æžœå¸Œæœ›åœ¨ä¸‹è½½å‰ç¼–è¯‘,å¯ä»¥æŠŠcommandæ¢æˆä¸‹é¢çš„å‘½ä»¤\n            \"command\":\"make -j24 ; make download_dap\", // \"mingw32-make -j24 ; mingw32-make download_dap\",\n            \"group\": {                     // å¦‚æžœæ²¡æœ‰ä¿®æ”¹ä»£ç ,ç¼–è¯‘ä»»åŠ¡ä¸ä¼šæ¶ˆè€—æ—¶é—´,å› æ­¤æŽ¨èä½¿ç”¨ä¸Šé¢çš„æ›¿æ¢.\n                \"kind\": \"build\",\n                \"isDefault\": false,\n            },\n        },\n        {\n            \"label\": \"download jlink\", // è¦ä½¿ç”¨æ­¤ä»»åŠ¡,éœ€æ·»åŠ jlinkçš„çŽ¯å¢ƒå˜é‡\n            \"type\": \"shell\",\n            \"command\":\"make -j24 ; make download_jlink\", // \"mingw32-make -j24 ; mingw32-make download_jlink\"\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": false,\n            }\n        },\n        {\n            \"label\": \"log\",\n            \"type\": \"shell\",\n            \"command\":\"JlinkRTTClient\",\n            \"args\": [],\n            \"problemMatcher\": [],\n            // \"dependsOn\":[\n            //     \"build task\", // å¯ä»¥æ·»åŠ å¤šä¸ª.\n            // ]\n            // è‹¥ä½¿ç”¨daplink,åˆ™å°†logä»»åŠ¡è®¾ç½®ä¸ºä¾èµ–äºŽjlink launchä»»åŠ¡,ä¿è¯jlink launchä»»åŠ¡å…ˆäºŽlogä»»åŠ¡æ‰§è¡Œ\n        }\n    ]\n}\n</code></pre>\n<h2 id=\"å¼€å§‹è°ƒè¯•\">å¼€å§‹è°ƒè¯•</h2>\n<p>åˆ°æ­¤é…ç½®åº”å½“å·²ç»å®Œæˆäº†ï¼ŒæŽ¥å¥½stlinkï¼Œè¿žæŽ¥å¥½stm32åŽå°±å¯ä»¥æ„‰å¿«çš„è°ƒè¯•å•¦ï¼Œç‚¹å‡»ç»¿è‰²çš„ä¸‰è§’å½¢å¼€å§‹ç¼–è¯‘å¹¶çƒ§å½•åˆ°å•ç‰‡æœº<br />\n<img alt=\"image-20260220184555431\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184555431.png\" /></p>\n<p>ç­‰å¾…ä¸€ä¼šåŽï¼Œå°±ä¼šå‡ºçŽ°ä¸‹å›¾æ‰€ç¤ºçš„è°ƒè¯•ç•Œé¢<br />\n<img alt=\"image-20260220185452486\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185452486.png\" /><br />\nåœ¨å·¦ä¾§å°±æ˜¯è°ƒè¯•å¸¸ç”¨çš„ä¸€äº›å·¥å…·<br />\n<img alt=\"image-20260220185552784\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185552784.png\" /></p>\n<p>cortex live watchå¯ä»¥å®žæ—¶æŸ¥çœ‹å…¨å±€å˜é‡çš„å€¼ï¼Œåªéœ€è¦ç‚¹å‡»åŠ å·<br />\n<img alt=\"image-20260220185701085\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185701085.png\" /></p>\n<p>ç²˜è´´éœ€è¦æŸ¥çœ‹çš„å˜é‡åç§°</p>\n<p><img alt=\"image-20260220185726335\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185726335.png\" /></p>\n<p>å°±å¯ä»¥å®žæ—¶æŸ¥çœ‹åˆ°å˜é‡çš„å€¼å•¦</p>\n<p><img alt=\"image-20260220185758953\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185758953.png\" /></p>\n<p>ä»Žå·¦åˆ°å³ ç¬¬ä¸€ä¸ªæ˜¯é‡ç½®resetï¼Œæš‚åœï¼Œé€è¿‡ç¨‹ï¼Œå•æ­¥ï¼Œå•æ­¥è·³å‡ºï¼Œé‡æ–°å¼€å§‹è°ƒè¯•ï¼Œé€€å‡º</p>\n<p><img alt=\"image-20260220185836594\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185836594.png\" /></p>\n<p>XPERIPHERALSå¿…é¡»é…ç½®ä¸Šé¢çš„svdæ–‡ä»¶æ‰èƒ½å¤Ÿçœ‹åˆ°å¯„å­˜å™¨å†…éƒ¨çš„å€¼</p>\n<p><img alt=\"image-20260220190044929\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220190044929.png\" /></p>\n<p>ä½ ä¹Ÿå¯ä»¥ä¼˜é›…çš„ä½¿ç”¨copilotå·¥å…·æ›´å¿«é€Ÿçš„å¼€å‘stm32å•¦</p>\n<h3 id=\"stm32-svdæ–‡ä»¶\">stm32 svdæ–‡ä»¶</h3>\n<p>stmç³»åˆ—svdä»“åº“ï¼š</p>\n<p><a href=\"https://github.com/modm-io/cmsis-svd-stm32\" rel=\"noopener nofollow\" target=\"_blank\">modm-io/cmsis-svd-stm32: CMSIS SVD files for all STM32 devices</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 19:31</span>&nbsp;\n<a href=\"https://www.cnblogs.com/chenyouyuan\">ChenYY~</a>&nbsp;\né˜…è¯»(<span id=\"post_view_count\">197</span>)&nbsp;\nè¯„è®º(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">æ”¶è—</a>&nbsp;\n<a href=\"\">ä¸¾æŠ¥</a>\n</div>"
    },
    {
      "title": "“老东西，你懦弱了”——关于Vibe Coding与传统开发",
      "link": "https://www.cnblogs.com/SilverGo/p/19626693",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/SilverGo/p/19626693\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 17:51\">\n    <span>“老东西，你懦弱了”——关于Vibe Coding与传统开发</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>鄙人在昨天刷视频的时候，意外刷到了这样的一个video：<br />\n一幅梗图，列举了2025年和2023年的两套开发工具：<br />\n2025年，我们用TRAE、Claude、Copilot、Windows 11，<br />\n2023年，我们用Clion、IDEA、Vim、Emacs、perf、lldb、gdb、Linux。<br />\n文案是：“老东西，你懦弱了！”</p>\n<h1 id=\"_\"></h1>\n<p>从效率来讲，毫无疑问，2025年的这一套工具不仅开发效率大幅上涨，时间成本降低，从工具本身而言，其技术难度也上涨了。<br />\n但是，从程序员的角度而言，我们丧失了对底层的掌控，<br />\n2025年，动动嘴，什么都解决了。<br />\n2023年，一切都要自己动手。<br />\n2025年的我们，一切效率至上，我们利用AI，少写了很多原来需要自己写的代码，<br />\n可我们难道不应该想想，这真的对吗？</p>\n<p>我们应该问自己，当初为什么喜欢CS？<br />\n不就是因为CS本身的自由、解构与建构吗？<br />\n我们选择AI替我们写代码，是一种将未来交给黑盒的行为。<br />\n一旦出现了隐藏的、AI改不出来的错误，这些长期使用AI的“程序员”将直接傻眼。<br />\n程序员最终是要靠代码建构世界的，而不是PUA Agent的。</p>\n<p>但是完全摒弃AI也是不现实的，那么怎么权衡呢？<br />\n以下是鄙人的愚见：<br />\n1.将AI当作一个高级的手册<br />\n2.核心代码必须自己写<br />\n3.重复性的代码：比如补全某个switch，可以使用AI<br />\n4.架构讨论可以使用AI</p>\n<h1 id=\"结语\">结语</h1>\n<p>这篇文章非常短，而且因为时间原因，写的比较仓促，但是意思到了即可<br />\n在现在的AI时代，我们追求效率至上，但是我们更应该把持本心、坚守初心<br />\n长期完全依赖AI只会减弱自己的能力，否极泰来、物极必反，这是必然的<br />\n了解底层、在没有AI的情况下照样能够写出完美的代码，这才是程序员水平高的表现<br />\n谢谢阅读</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 17:51</span>&nbsp;\n<a href=\"https://www.cnblogs.com/SilverGo\">Ghost-Face</a>&nbsp;\n阅读(<span id=\"post_view_count\">226</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}