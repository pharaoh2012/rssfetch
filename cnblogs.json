{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "一天一个Python库：fsspec - 统一文件系统接口，轻松访问数据",
      "link": "https://www.cnblogs.com/min2k/p/19568453",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/min2k/p/19568453\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 12:00\">\n    <span>一天一个Python库：fsspec - 统一文件系统接口，轻松访问数据</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"fsspec---统一文件系统接口轻松访问数据\">fsspec - 统一文件系统接口，轻松访问数据</h1>\n<h2 id=\"一什么是fsspec\">一、什么是fsspec？</h2>\n<p><strong>fsspec</strong> 是一个用于提供统一文件系统接口的 Python 库。它抽象了各种文件系统（如本地文件系统、S3、GCS、HDFS等）的细节，让你可以用统一的方式操作文件。<br />\n它可以帮助你：</p>\n<ul>\n<li>以相同的方式读写本地文件、远程存储桶中的文件。</li>\n<li>无缝集成不同的存储后端而无需修改核心代码。</li>\n<li>创建自定义的文件系统实现。</li>\n</ul>\n<h2 id=\"二应用场景\">二、应用场景</h2>\n<p><strong>fsspec</strong> 广泛应用于以下实际场景：</p>\n<ul>\n<li><strong>大数据处理</strong>: 在DataFrames或数组中直接处理来自S3或HDFS的数据。</li>\n<li><strong>云存储</strong>: 轻松与AWS S3、Google Cloud Storage、Azure Blob Storage等云服务进行交互。</li>\n<li><strong>数据管道</strong>: 构建可以接收来自多种数据源的输入并写入到多种目的地的管道。</li>\n</ul>\n<h2 id=\"三如何安装\">三、如何安装</h2>\n<ol>\n<li>使用 pip 安装</li>\n</ol>\n<pre><code class=\"language-bash\">pip install fsspec\n\n# 如果安装慢的话，推荐使用国内镜像源\npip install fsspec -i https://www.python64.cn/pypi/simple/\n</code></pre>\n<ol start=\"2\">\n<li>使用 <a href=\"https://www.min2k.com/tools/python-run/\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a> 在线运行代码（无需本地安装）</li>\n</ol>\n<h2 id=\"四示例代码\">四、示例代码</h2>\n<p>检查文件或目录是否存在并列出内容</p>\n<pre><code class=\"language-python\">import fsspec\nimport os\n\n# 定义一个本地路径，可以是文件或目录\nlocal_path = \"fsspec_test_dir\"\n\n# 创建一个本地文件系统实例\nfs = fsspec.filesystem(\"file\")\n\n# 检查路径是否存在\nif not fs.exists(local_path):\n    # 如果不存在，则创建目录\n    fs.mkdir(local_path)\n    print(f\"Directory '{local_path}' created.\")\n    \n    # 在新目录中创建一些测试文件\n    with fs.open(os.path.join(local_path, \"file1.txt\"), \"w\") as f:\n        f.write(\"Hello from file1!\")\n    with fs.open(os.path.join(local_path, \"file2.txt\"), \"w\") as f:\n        f.write(\"Hello from file2!\")\n    print(f\"Two files created in '{local_path}'.\")\nelse:\n    print(f\"Path '{local_path}' already exists.\")\n\n# 列出目录内容\nprint(f\"\\nListing contents of '{local_path}':\")\ncontents = fs.ls(local_path)\nfor item in contents:\n    # 检查是否为文件\n    if fs.isfile(item):\n        print(f\"  - File: {item}\")\n    else:\n        print(f\"  - Directory: {item}\")\n\n# 清理（可选，但对于测试很有用）\n# fs.rm(local_path, recursive=True)\n# print(f\"\\nDirectory '{local_path}' removed.\")\n</code></pre>\n<p>使用 <a href=\"https://www.min2k.com/tools/python-run/?code=import%20fsspec%0Aimport%20os%0A%0A%23%20%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E6%9C%AC%E5%9C%B0%E8%B7%AF%E5%BE%84%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%98%AF%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%0Alocal_path%20%3D%20%22fsspec_test_dir%22%0A%0A%23%20%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E4%BE%8B%0Afs%20%3D%20fsspec.filesystem%28%22file%22%29%0A%0A%23%20%E6%A3%80%E6%9F%A5%E8%B7%AF%E5%BE%84%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%0Aif%20not%20fs.exists%28local_path%29%3A%0A%20%20%20%20%23%20%E5%A6%82%E6%9E%9C%E4%B8%8D%E5%AD%98%E5%9C%A8%EF%BC%8C%E5%88%99%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95%0A%20%20%20%20fs.mkdir%28local_path%29%0A%20%20%20%20print%28f%22Directory%20'%7Blocal_path%7D'%20created.%22%29%0A%20%20%20%20%0A%20%20%20%20%23%20%E5%9C%A8%E6%96%B0%E7%9B%AE%E5%BD%95%E4%B8%AD%E5%88%9B%E5%BB%BA%E4%B8%80%E4%BA%9B%E6%B5%8B%E8%AF%95%E6%96%87%E4%BB%B6%0A%20%20%20%20with%20fs.open%28os.path.join%28local_path%2C%20%22file1.txt%22%29%2C%20%22w%22%29%20as%20f%3A%0A%20%20%20%20%20%20%20%20f.write%28%22Hello%20from%20file1!%22%29%0A%20%20%20%20with%20fs.open%28os.path.join%28local_path%2C%20%22file2.txt%22%29%2C%20%22w%22%29%20as%20f%3A%0A%20%20%20%20%20%20%20%20f.write%28%22Hello%20from%20file2!%22%29%0A%20%20%20%20print%28f%22Two%20files%20created%20in%20'%7Blocal_path%7D'.%22%29%0Aelse%3A%0A%20%20%20%20print%28f%22Path%20'%7Blocal_path%7D'%20already%20exists.%22%29%0A%0A%23%20%E5%88%97%E5%87%BA%E7%9B%AE%E5%BD%95%E5%86%85%E5%AE%B9%0Aprint%28f%22%5CnListing%20contents%20of%20'%7Blocal_path%7D'%3A%22%29%0Acontents%20%3D%20fs.ls%28local_path%29%0Afor%20item%20in%20contents%3A%0A%20%20%20%20%23%20%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E4%B8%BA%E6%96%87%E4%BB%B6%0A%20%20%20%20if%20fs.isfile%28item%29%3A%0A%20%20%20%20%20%20%20%20print%28f%22%20%20-%20File%3A%20%7Bitem%7D%22%29%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20print%28f%22%20%20-%20Directory%3A%20%7Bitem%7D%22%29%0A%0A%23%20%E6%B8%85%E7%90%86%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%8C%E4%BD%86%E5%AF%B9%E4%BA%8E%E6%B5%8B%E8%AF%95%E5%BE%88%E6%9C%89%E7%94%A8%EF%BC%89%0A%23%20fs.rm%28local_path%2C%20recursive%3DTrue%29%0A%23%20print%28f%22%5CnDirectory%20'%7Blocal_path%7D'%20removed.%22%29\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a> 在线运行这段代码，结果如下：</p>\n<pre><code class=\"language-text\">Path 'fsspec_test_dir' already exists.\n\nListing contents of 'fsspec_test_dir':\n  - File: /code/fsspec_test_dir/file1.txt\n  - File: /code/fsspec_test_dir/file2.txt\n</code></pre>\n<p>使用 <a href=\"https://www.min2k.com/tools/mermaid/?code=flowchart%20TD%0A%20%20%20%20A%5B%E5%BC%80%E5%A7%8B%5D%20--%3E%20B%7B%E6%9C%AC%E5%9C%B0%E8%B7%AF%E5%BE%84%20'fsspec_test_dir'%20%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%3F%7D%3B%0A%20%20%20%20B%20--%20%E5%90%A6%20--%3E%20C%5B%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95%20'fsspec_test_dir'%5D%3B%0A%20%20%20%20C%20--%3E%20D%5B%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%20'file1.txt'%20%E5%92%8C%20'file2.txt'%20%E5%9C%A8%E6%96%B0%E7%9B%AE%E5%BD%95%E4%B8%AD%5D%3B%0A%20%20%20%20D%20--%3E%20E%5B%E6%89%93%E5%8D%B0%E7%9B%AE%E5%BD%95%E5%88%9B%E5%BB%BA%E5%8F%8A%E6%96%87%E4%BB%B6%E5%88%9B%E5%BB%BA%E4%BF%A1%E6%81%AF%5D%3B%0A%20%20%20%20B%20--%20%E6%98%AF%20--%3E%20F%5B%E6%89%93%E5%8D%B0%E8%B7%AF%E5%BE%84%E5%B7%B2%E5%AD%98%E5%9C%A8%E4%BF%A1%E6%81%AF%5D%3B%0A%20%20%20%20F%20--%3E%20G%5B%E5%88%97%E5%87%BA%E7%9B%AE%E5%BD%95%20'fsspec_test_dir'%20%E7%9A%84%E5%86%85%E5%AE%B9%5D%3B%0A%20%20%20%20E%20--%3E%20G%3B%0A%20%20%20%20G%20--%3E%20H%7B%E9%81%8D%E5%8E%86%E6%AF%8F%E4%B8%AA%E9%A1%B9%E7%9B%AE%7D%3B%0A%20%20%20%20H%20--%20%E6%98%AF%E6%96%87%E4%BB%B6%3F%20--%3E%20I%5B%E6%89%93%E5%8D%B0%20'%E6%96%87%E4%BB%B6%3A%20%E9%A1%B9%E7%9B%AE%E5%90%8D'%5D%3B%0A%20%20%20%20H%20--%20%E5%90%A6%20--%3E%20J%5B%E6%89%93%E5%8D%B0%20'%E7%9B%AE%E5%BD%95%3A%20%E9%A1%B9%E7%9B%AE%E5%90%8D'%5D%3B%0A%20%20%20%20I%20--%3E%20K%5B%E7%BB%93%E6%9D%9F%5D%3B%0A%20%20%20%20J%20--%3E%20K%3B\" rel=\"noopener nofollow\" target=\"_blank\">MermaidGo</a> 绘制示例代码的流程图，结果如下：</p>\n<p><img alt=\"MermerGo的fsspec流程图\" class=\"lazyload\" /></p>\n<h2 id=\"五学习资源\">五、学习资源</h2>\n<ol>\n<li>开源项目：<a href=\"https://github.com/fsspec/filesystem_spec\" rel=\"noopener nofollow\" target=\"_blank\">fsspec</a></li>\n<li>中文自述：<a href=\"https://www.python64.cn/readme/fsspec/\" rel=\"noopener nofollow\" target=\"_blank\">REMDME</a></li>\n<li>在线运行：<a href=\"https://www.min2k.com/tools/python-run/\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a></li>\n</ol>\n<blockquote>\n<p>如果这篇文章对你有帮助，欢迎点赞、收藏、转发！<br />\n学习过程中有任何问题，欢迎在评论区留言交流～</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 12:00</span>&nbsp;\n<a href=\"https://www.cnblogs.com/min2k\">敏编程</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "vLLM、SGLang 融资背后，AI 推理正在走向系统化与治理",
      "link": "https://www.cnblogs.com/gpustack/p/19568201",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/gpustack/p/19568201\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 11:25\">\n    <span>vLLM、SGLang 融资背后，AI 推理正在走向系统化与治理</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近，推理引擎领域出现了两件具有标志意义的事件：vLLM 和 SGLang 相继走向公司化。<strong>vLLM 核心团队成立 Inferact</strong>，完成 1.5 亿美元融资，估值达 8 亿美元：</p>\n<p><img alt=\"Inferact 团队\" class=\"lazyload\" /></p>\n<p>图源：Inferact</p>\n<p><strong>SGLang 团队也成立了 RadixArk</strong>，同样获得融资，估值达到 4 亿美元：</p>\n<p><img alt=\"image-20260128212509136\" class=\"lazyload\" /></p>\n<p>图源：RadixArk</p>\n<p>这并不是两起孤立的创业故事，而是在同一个时间点，对同一件事情给出了市场层面的确认：<strong>推理已经正式进入 AI 基础设施的核心层</strong>，而不再是模型之后的附属环节。</p>\n<p>如果把过去几年 AI 的发展理解为<strong>模型能力竞赛</strong>，那么现在正在发生的，是一场<strong>系统工程能力竞赛</strong>。模型决定上限，推理系统决定规模化能力。一个模型是否有商业价值，越来越取决于它是否能被<strong>低成本、稳定、可持续地运行</strong>。</p>\n<p>vLLM 和 SGLang 的融资，本质上是在为<strong>推理层</strong>重新定价。</p>\n<h2 id=\"一推理引擎已经从工具升级为基础设施内核\">一、推理引擎已经从工具升级为基础设施内核</h2>\n<p>早期的推理引擎更像是工具链的一部分，目标很简单：把模型跑起来，并尽量提升吞吐和降低延迟。它们解决的是局部性能问题，而不是系统性问题。</p>\n<p>但今天的 vLLM 已经完全不同。它必须同时面对两条不断加速的演化曲线：</p>\n<p>一条来自模型侧：<strong>Dense、MoE、多模态、Agent、超长上下文不断出现</strong>；</p>\n<p>一条来自硬件侧：<strong>GPU、NPU、定制加速器、不同 CUDA/驱动/编译链并存</strong>。</p>\n<p>在工程上，这意味着推理引擎被迫承担一个新的角色：</p>\n<p><strong>成为模型与硬件之间的通用适配层。</strong></p>\n<p>当一个系统需要同时满足：</p>\n<ul>\n<li>支持大量模型架构</li>\n<li>覆盖多种异构硬件</li>\n<li>承载从科研验证到大规模生产负载</li>\n</ul>\n<p>它的属性就已经不再是“工具”，而是基础设施内核。</p>\n<p>SGLang 从另一个方向推动了同一件事。它把推理从“函数调用”扩展为“可编程执行流程”，特别适合 Agent、强化学习和复杂工作流场景。这说明推理系统正在同时向两个方向演进：</p>\n<p><strong>一方面更像操作系统内核，负责资源与性能；</strong></p>\n<p><strong>另一方面更像运行时与编程模型，负责表达能力。</strong></p>\n<p>这两种属性叠加，正是基础设施系统的典型特征。</p>\n<h2 id=\"二推理成本已经成为-ai-商业化的决定性因素\">二、推理成本已经成为 AI 商业化的决定性因素</h2>\n<p>在真实工程中，一个简单的事实越来越清晰：</p>\n<p><strong>训练决定模型能不能出现，</strong></p>\n<p><strong>推理决定模型能不能活下去。</strong></p>\n<p>对绝大多数公司来说：</p>\n<ul>\n<li>训练是阶段性成本</li>\n<li>推理是长期、持续、不可回避的成本</li>\n</ul>\n<p>随着模型规模扩大、调用频率上升，推理成本已经从“次要支出”变成“核心账单项”。很多场景里，推理成本远高于训练成本。</p>\n<p>这使推理系统具备了极强的经济敏感性：</p>\n<ul>\n<li>5% 的吞吐提升</li>\n<li>10% 的显存利用率优化</li>\n<li>一点点调度效率提升</li>\n</ul>\n<p>都会直接反映为真实的资金节省。</p>\n<p>因此，推理引擎的价值不再只是“技术好不好”，而是“能不能直接影响 AI 服务的成本结构”。</p>\n<p>这也是资本真正愿意为其高估值买单的原因。</p>\n<h2 id=\"三推理系统的复杂性已经不可逆转\">三、推理系统的复杂性已经不可逆转</h2>\n<p>推理问题越来越难，并不是因为模型“更大”，而是因为系统维度在急剧膨胀：</p>\n<ul>\n<li><strong>模型形态更加复杂</strong>：Dense、MoE、多模态、Agent</li>\n<li><strong>推理形态更加复杂</strong>：长上下文、推理时计算、RL 循环</li>\n<li><strong>硬件环境更加碎片化</strong>：多 GPU、多 NPU、多编译链</li>\n</ul>\n<p>工程上已经出现一个明显现象：</p>\n<p>很多模型在理论上“可以跑”，</p>\n<p>但系统在现实中“跑不动、跑不稳、跑不起”。</p>\n<p>Inferact 提出的愿景非常关键：</p>\n<p>部署前沿模型应该像创建一个 Serverless 数据库一样简单。</p>\n<p>这句话的真实含义是：</p>\n<p>推理系统必须吞掉所有复杂性，而不是把复杂性留给使用者。</p>\n<h2 id=\"四推理系统治理问题会持续放大\">四、推理系统治理问题会持续放大</h2>\n<p>当 vLLM、SGLang 进入快速演进之后，一个确定会发生的变化是：</p>\n<p>新模型适配、新硬件支持、新优化策略都会更频繁进入主线版本。这对行业是好事，但对使用者来说，复杂度反而会上升。</p>\n<p>在真实工程中很快会遇到这些问题：</p>\n<ul>\n<li>同一模型在不同引擎版本下表现差异明显</li>\n<li>不同硬件对引擎版本的支持程度不一致</li>\n<li>升级引擎可能带来性能提升，也可能带来稳定性风险</li>\n</ul>\n<p>推理引擎不再是“选一次就结束”的组件，而是进入持续治理阶段。</p>\n<h2 id=\"五多引擎并存是工程必然而不是选择题\">五、多引擎并存是工程必然，而不是选择题</h2>\n<p>现实生产环境中几乎不可能存在<strong>万能引擎</strong>：</p>\n<ul>\n<li>有的模型适合 vLLM</li>\n<li>有的模型适合 SGLang</li>\n<li>有的场景适合 TRT-LLM</li>\n<li>有的设备只能跑 llama.cpp</li>\n</ul>\n<p>多引擎并存不是过渡状态，而是长期结构。</p>\n<p>如果没有统一治理层，系统最终一定会退化为：</p>\n<ul>\n<li>脚本堆叠</li>\n<li>手工配置</li>\n<li>版本失控</li>\n<li>故障不可回溯</li>\n</ul>\n<p>这是大型系统必然的退化路径。</p>\n<h2 id=\"六gpustack-的本质推理系统的控制平面\">六、GPUStack 的本质：推理系统的控制平面</h2>\n<p>GPUStack 并不是另一个推理引擎，它解决的是“引擎治理问题”。</p>\n<p>在 GPUStack 的视角里：</p>\n<ul>\n<li>引擎是可插拔资源</li>\n<li>引擎版本是可调度对象</li>\n<li>模型实例是可编排单元</li>\n</ul>\n<p>推理引擎从“写死在系统里的依赖”，变成了“运行时可切换的能力”。</p>\n<p>这在工程上的意义非常大：</p>\n<ul>\n<li>可以并行运行多个引擎与版本</li>\n<li>可以灰度升级</li>\n<li>可以快速回滚</li>\n<li>可以做真实可控的性能对比</li>\n</ul>\n<p><strong>支持自定义使用任意推理引擎</strong>：</p>\n<p><img alt=\"image-20260128214023530\" class=\"lazyload\" /></p>\n<p><strong>自由切换任意推理引擎</strong>：</p>\n<p><img alt=\"image-20260128214143994\" class=\"lazyload\" /></p>\n<p><strong>自由切换推理引擎版本</strong>：</p>\n<p><img alt=\"image-20260128212811154\" class=\"lazyload\" /></p>\n<p><strong>推理系统开始具备云原生系统应有的治理能力。</strong></p>\n<h2 id=\"七引擎与版本切换本质是-ai-推理世界的运行时治理\">七、引擎与版本切换，本质是 AI 推理世界的运行时治理</h2>\n<p>当推理引擎成为基础设施之后：</p>\n<p>“要不要升级”不再是问题，</p>\n<p><strong>“如何安全升级、如何可控回退”才是问题</strong>。</p>\n<p>这在工程上与：</p>\n<ul>\n<li>数据库内核升级</li>\n<li>容器运行时升级</li>\n<li>Kubernetes 升级</li>\n</ul>\n<p>是完全同一类问题。</p>\n<p>GPUStack 做的事情，本质是把这种“运行时治理”能力引入推理系统。</p>\n<h2 id=\"八真正的信号不是融资而是系统层级的改变\">八、真正的信号不是融资，而是系统层级的改变</h2>\n<p>vLLM 与 SGLang 的融资，不是某两个项目的成功，而是行业完成了一次角色确认：</p>\n<p>推理层已经从“模型附属组件”，升级为 <strong>AI Infra 核心层</strong>。</p>\n<p>而 GPUStack 的出现，也不是产品机会，而是工程必然：</p>\n<p><strong>当底层能力高速进化、多引擎并存成为常态，没有控制平面的系统一定会失控。</strong></p>\n<p>从工程视角看，GPUStack 把推理系统从“项目级资产”升级为“平台级资产”；</p>\n<p>从组织视角看，它让推理能力不再依赖少数专家，而成为团队可复用的基础能力。</p>\n<p><strong>这正是推理基础设施真正成熟的标志。</strong></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 11:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/gpustack\">GPUStack</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "前特斯拉 AI 总监：AI 编程最大的谎言，是 “提效”",
      "link": "https://www.cnblogs.com/yupi/p/19568098",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yupi/p/19568098\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 11:08\">\n    <span>前特斯拉 AI 总监：AI 编程最大的谎言，是 “提效”</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"前特斯拉 AI 总监：AI 编程最大的谎言，是 “提效”\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2225420/202602/2225420-20260203102512118-1547421356.png\" />\n        前两天，前特斯拉 AI 总监 Andrej Karpathy 在 X 上发了一条长帖子，内容是他最近几周大量使用 Claude 编程的感悟。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"md-end-block md-heading\"><span class=\"md-plain\">大家好，我是程序员鱼皮。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">前两天，前特斯拉 AI 总监 Andrej Karpathy 在 X 上发了一条长帖子，内容是他最近几周大量使用 Claude 编程的感悟。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">结果这条帖子直接爆了，阅读量超过 600 万。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">先简单介绍一下『卡帕西』这位大佬：斯坦福 AI 博士，师从李飞飞；OpenAI 创始成员之一；后来去特斯拉当了 AI 总监，负责自动驾驶的视觉系统。2024 年离开特斯拉后，他创办了 Eureka Labs，专注用 AI 做教育。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">不夸张地说，他可能是全球最懂 AI、又最能写代码的人之一。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">在 2023 年 1 月的时候，他就提出过：未来最热门的新编程语言是自然语言。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">你现在回过头来看这句话，就知道这哥们有多牛皮了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">所以我每次看他分享的内容时，都会先沐浴更衣，让自己能够进入深度思考状态。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">进入正题，这条帖子里有很多干货，但让我印象最深的是这句话：</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我不太清楚如何衡量 AI 带来的加速。我感觉做事确实快了，<span class=\"md-pair-s \"><strong>但主要的效果是我做的比原计划多得多</strong><span class=\"md-plain\">。</span></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">卡帕西说，现在他可以随手写一些以前 “不值得写” 的小工具，也敢去碰以前因为技术栈不熟而不敢碰的代码了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>所以 AI 编程带来的核心变化不是加速，而是扩展。</strong></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我觉得这个观察太准了！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">之前很多人问我：AI 编程能提效多少倍？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">其实这个问题本身就问错了。AI 带来的真正变化不是 “同一件事做得更快”，而是 “你开始做以前根本不会做的事”。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这就像你以前骑自行车，现在换了辆车。你不会说自己骑车快了 10 倍，而是会说自己能去更远的地方了。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">人比不过 AI 的一点</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">帖子里还有几个点挺有意思的，跟大家分享一下。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">卡帕西说，看 AI 在一个 Bug 上死磕 30 分钟，不放弃、不气馁，最后真的搞定了 —— 这是他感受 AGI 的时刻。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我看到这段就想起自己大学刚学编程时改 Bug 的经历。已经是凌晨一两点，试了好几种方法都没用，我的心态已经崩了，甚至有点儿心绞痛，于是想着明天再说吧，狗命要紧……</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但 AI 不会这样，只要你的 Tokens 足够，它会一直跟 Bug 死磕。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \"><strong>耐力这件事，正在从人类的瓶颈变成 AI 的优势。</strong></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">当然，代价就是烧 Token。所以程序员的基本功还是很重要的，至少你得能判断这个 Bug 值不值得让 AI 花半小时去磕，怎么通过指引 AI 让它更快更省地解决问题。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">编程变得更有趣了？</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">卡帕西说：用 AI 编程之后，那些填空式的苦差事没了，剩下的都是创造性的部分。所以反而觉得更好玩了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但他也提到，有些程序员会觉得失去了乐趣。因为对他们来说，写代码本身就是快感来源。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这可能是一个分水岭：<span class=\"md-pair-s \"><strong>主要享受 “写代码” 的人，和主要享受 “造东西” 的人，体验会很不一样。</strong></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我看到一位 AI 圈的大 V 把这点称为 “程序员正在分裂成两个物种”。不过我倒觉得，这两类人其实一直都存在。有的人享受代码本身的优雅，追求技术的深度和细节，写出漂亮的代码会有成就感；有的人更在乎东西能不能跑起来、能不能解决问题，代码只是实现想法的工具。AI 只是把这个差异放大了而已 —— 前者可能会有点失落，后者则迎来了黄金时代。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">我正在失去写代码的能力，但是…</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">卡帕西说：自己手动写代码的能力正在慢慢退化。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但是从他的话中能感受到，他对此的态度是 “已经不太在乎了”。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">他给了一个有意思的视角，写代码（生成）和读代码（判别）是大脑里不同的能力。就像你可能写不出一首好诗，但能看出一首诗写得好不好。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">编程也是一样。其实想想看，以前没有 AI 的时候，那些语法细节、API 用法，我们不也是靠查文档、利用编辑器的提示吗？真正需要记在脑子里的从来就不多。现在 AI 把这部分接管了，但代码的设计思路对不对、架构合不合理，还是得靠你自己判断。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">所以未来程序员的角色，可能更像是 “技术导演” 而不是 “码农”。你负责把控方向、做出决策，AI 负责执行细节、填补空白。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">2026 年垃圾内容会爆发，但是…</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">卡帕西还提到了一个词：<span class=\"md-pair-s\"><code>Slopacolypse</code></span></span></p>\n<p class=\"md-end-block md-p md-focus\"><span class=\"md-plain md-expand\">我搜了一下，发现这其实是最近 AI 圈流行起来的一个 “slop 系列” 造词。Slop 指的是那些用 AI 批量生成的低质量内容，Slopacolypse 就是 Slop + Apocalypse，我理解是 “垃圾内容末日” 的意思。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">他预测 2026 年，GitHub、各种社交媒体都会被 AI 生成的低质量内容淹没。当生产内容的门槛大幅降低，注意力反而会变得更稀缺。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但他也说，真正的改进也在同步发生。AI 的智能部分已经跑在前面了，现在反而是工具、流程、组织这些东西还没跟上。<span class=\"md-pair-s \"><strong>2026 年，整个行业会花大量精力去消化这波新能力。</strong></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">说到这里，我想起自己身边的情况。AI 领域几乎每天都有新工具、新模型、新玩法冒出来，但真正意识到这些变化、真正去用这些新东西的人，又有多少呢？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我经常听到有人说 “再等几个月，等出了更好的再学”、“现在的还不够成熟”。但问题是，在你等待的这几个月里，已经有人用 AI 做出了以前做不到的东西，拉开了差距。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">所以对于我们程序员来说，一方面必须要利用 AI 提升开发效率和优化工作流程。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">另外一方面，不妨打开思路，多想一想：<span class=\"md-pair-s \"><strong>有了 AI，你能做到哪些以前做不到的事？</strong></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">以前不敢碰的技术栈，现在敢试了；以前觉得不值得做的小工具，现在随手就能搞定；以前卡住就放弃的 bug，现在有个不知疲倦的助手帮你死磕。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这才是 AI 编程真正的红利 —— <span class=\"md-pair-s \"><strong>不是让你更快，是让你更大。</strong></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">如果你还没开始用 AI 编程，或者想系统学习怎么用的更好，可以看看我最新免费开源的 <span class=\"md-meta-i-c  md-link\"><a href=\"https://github.com/liyupi/ai-guide\" rel=\"noopener nofollow\"><span class=\"md-plain\">《AI 编程零基础入门教程》</span></a><span class=\"md-plain\">，从 0 开始带你用 AI 编程做出项目，包含各种工具用法、实战技巧、编程资源、甚至是产品变现经验全都有。希望能帮你更快地拥抱这个新时代，一起变得更大、更强！</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">更多编程学习资源</span></h2>\n<ul class=\"ul-list\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course\" rel=\"noopener nofollow\"><span class=\"md-plain\">Java前端程序员必做项目实战教程+毕设网站</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费编程学习交流社区（自学必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course/cv\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员保姆级求职写简历指南（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.mianshiya.com/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费面试刷题网站工具（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640584449888772098\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Java零基础入门学习路线 + Java教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586673306091521\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Python零基础入门学习路线 + Python教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586014108303362\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新前端零基础入门学习路线 + 前端教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586867363954689\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据结构和算法零基础入门学习路线 + 算法教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1644279832026075138\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新C++零基础入门学习路线、C++教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641797333479903234\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据库零基础入门学习路线 + 数据库教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640589994284695553\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Redis零基础入门学习路线 + Redis教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641035880439271426\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机基础入门学习路线 + 计算机基础教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641366118197153793\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新小程序入门学习路线 + 小程序开发教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"http://sqlmother.yupi.icu/\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新SQL零基础入门学习路线 + SQL教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586295529324545\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Linux零基础入门学习路线 + Linux教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588753362108417\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Git/GitHub零基础入门学习路线 + Git教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640587909942099969\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新操作系统零基础入门学习路线 + 操作系统教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588119619551233\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机网络零基础入门学习路线 + 计算机网络教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588392073150465\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新设计模式零基础入门学习路线 + 设计模式教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c md-link\"><a href=\"https://www.code-nav.cn/post/1640648711119892481\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新软件工程零基础入门学习路线 + 软件工程教程</span></a></span></p>\n</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 11:08</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yupi\">程序员鱼皮</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MonkeyCode 兼容海外工具，开发者习惯无需改变",
      "link": "https://www.cnblogs.com/cybersirenthebest/p/19568030",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/cybersirenthebest/p/19568030\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 11:00\">\n    <span>MonkeyCode 兼容海外工具，开发者习惯无需改变</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"长亭monkeycode-ai开发平台上线免费算力赋能ai助力全场景工程级研发落地\">长亭MonkeyCode AI开发平台上线：免费算力赋能，AI助力全场景工程级研发落地</h1>\n<p>当前AI编程工具层出不穷，但多数仅能应对“代码撰写、Demo运行”的基础场景，难以匹配真实工程研发的复杂诉求。长亭科技全新推出的AI开发平台MonkeyCode，成功突破这一行业瓶颈——平台以企业级研发标准构建，让AI深度参与从需求梳理到Review验收的全研发链路，更配套注册即赠免费算力的专属福利，助力开发者在各类实际场景中高效落地真实项目。</p>\n<h2 id=\"一平台定位不止是编程工具更是工程研发的核心基石\">一、平台定位：不止是编程工具，更是工程研发的核心基石</h2>\n<p>MonkeyCode是长亭科技为专业开发者与研发团队量身打造的企业级AI开发平台，与普通AI编程工具的核心差异的在于：它不局限于“辅助编写代码”的基础功能，而是让AI以研发参与者身份深度渗透全流程，攻克传统工具在真实项目中存在的“代码不可靠、流程无追溯、项目易失控”三大核心痛点，可灵活适配团队协作、复杂项目迭代、私有仓库开发等多元工程化场景。</p>\n<h2 id=\"二上线福利200元等额算力免费申领全场景实操零阻碍\">二、上线福利：200元等额算力免费申领，全场景实操零阻碍</h2>\n<p>为让开发者快速解锁企业级AI开发能力，MonkeyCode特推出上线专属活动：自2025年12月18日起，新用户完成注册登录，就能即刻申领价值200元的等额算力（共计20000点）。该算力无任何使用限制，可广泛覆盖各类研发场景：</p>\n<ul>\n<li>\n<p>搭建专属在线开发空间，满足个人代码调试、团队协同研发等场景需求；</p>\n</li>\n<li>\n<p>调用平台内置的多类大模型能力，充分匹配不同技术栈的开发诉求；</p>\n</li>\n<li>\n<p>推进完整AI开发任务，覆盖需求落地、Bug排查修复、技术文档撰写等真实场景，彻底打破仅能开展Demo测试的局限。</p>\n</li>\n</ul>\n<p><img alt=\"屏幕截图 2026-01-16 144506\" class=\"lazyload\" /></p>\n<h2 id=\"三核心优势适配多元场景革新工程研发逻辑\">三、核心优势：适配多元场景，革新工程研发逻辑</h2>\n<h3 id=\"1-规范驱动开发复杂项目场景可控可追溯\">1. 规范驱动开发，复杂项目场景可控可追溯</h3>\n<p>面向复杂项目迭代场景，MonkeyCode内置SDD规范驱动开发体系，要求AI严格遵循“原始需求→产品设计→技术设计→任务列表”的标准化流程推进，杜绝跳过设计环节直接编码的情况。每一步操作均支持回溯查阅与灵活调整，有效规避复杂项目中AI编程“失控”问题，精准契合团队协作的流程规范。</p>\n<h3 id=\"2-工具模型全兼容多技术栈场景无缝衔接\">2. 工具模型全兼容，多技术栈场景无缝衔接</h3>\n<p>平台无需重构AI编码代理，可实现OpenAI Codex、Claude Code等成熟开发工具的一键无缝接入，用户无需更改原有使用习惯，就能轻松实现使用衔接。同时，平台全面兼容GPT、Deepseek、GLM、Kimi等主流大模型及本地部署模型，无论是偏好海外工具的开发者，还是依赖国产大模型的企业团队，都能在同一套研发流程中自由切换，适配多元技术栈场景。</p>\n<h3 id=\"3-环境隔离保障安全并行开发场景无干扰\">3. 环境隔离保障安全，并行开发场景无干扰</h3>\n<p>针对多任务并行、团队协作开发场景，MonkeyCode会为每项AI开发任务自动生成专属虚拟环境，所有操作均严格限定在该环境内。多项任务可同步推进、互不干扰，即便出现误操作等意外，也不会影响真实开发环境的安全稳定，失败任务可直接丢弃重启，大幅规避团队协作与多任务开发的潜在风险。</p>\n<p><img alt=\"屏幕截图 2025-12-24 160639\" class=\"lazyload\" /></p>\n<h3 id=\"4-盘活人力效能重复编码场景效率倍增\">4. 盘活人力效能，重复编码场景效率倍增</h3>\n<p>日常研发中，AI可全面承接重复、机械性的编码工作，让工程师脱离繁琐的基础劳作，将精力集中于架构设计、技术方案评审、代码合并决策、系统可维护性把控等核心环节。无论是个人开发者处理重复业务逻辑，还是团队应对批量编码需求，都能借助平台实现研发效率的大幅提升。</p>\n<h2 id=\"四快速上手3步开启全场景ai研发\">四、快速上手：3步开启全场景AI研发</h2>\n<h3 id=\"1-一键注册快速登录\">1. 一键注册快速登录</h3>\n<p>访问官方地址，凭借“百智云账号”就能快速登录，平台自动同步完成注册手续，无需复杂配置，个人与团队用户均可轻松上手操作。</p>\n<p><img alt=\"屏幕截图 2025-12-31 111249\" class=\"lazyload\" /></p>\n<h3 id=\"2-灵活配置适配场景\">2. 灵活配置适配场景</h3>\n<p>用户可直接启用平台内置的标准化能力，也可根据自身研发场景自定义配置：</p>\n<ul>\n<li>\n<p>接入个人开发设备，适配本地调试场景；</p>\n</li>\n<li>\n<p>关联自有大模型API，满足企业私有化部署需求；</p>\n</li>\n<li>\n<p>配置专属系统镜像，适配特定技术栈开发场景；</p>\n</li>\n<li>\n<p>设置Git身份凭证，便捷对接私有仓库，适配企业内部项目开发场景。</p>\n</li>\n</ul>\n<p><img alt=\"屏幕截图 2025-12-24 160639\" class=\"lazyload\" /></p>\n<h3 id=\"3-场景化任务快速发起\">3. 场景化任务快速发起</h3>\n<p>进入“智能任务”页面后，仅需3步即可启动AI开发流程，适配各类场景需求：</p>\n<ol>\n<li>\n<p>用自然语言清晰描述场景化需求（如“修复移动端页面布局错乱Bug”“为多语言仓库撰写详细README文档”）；</p>\n</li>\n<li>\n<p>选定目标Git仓库；</p>\n</li>\n<li>\n<p>启动任务后，实时追踪AI对需求的拆解、执行计划、文件变动及完整流程，全程透明且支持随时介入调整。</p>\n</li>\n</ol>\n<h2 id=\"五适用场景与总结\">五、适用场景与总结</h2>\n<p>无论你是处理独立项目的个人开发者、协同推进复杂工程的团队成员，还是搭建企业私有化研发体系的管理者，MonkeyCode都能精准匹配场景需求：从单一功能开发、紧急Bug修复，到多模块项目迭代、跨团队协同研发，它都能凭借规范流程、安全隔离、高效协作的核心优势，成为可靠的AI研发伙伴。</p>\n<p>立即访问，领取免费算力，在实际研发场景中亲身解锁AI工程级开发的全新可能。若想交流场景化使用经验、获取最新活动资讯，欢迎加入MonkeyCode微信交流群，与行业同仁共探高效研发新路径。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 11:00</span>&nbsp;\n<a href=\"https://www.cnblogs.com/cybersirenthebest\">赛博女妖</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "回文自动机 PAM 学习笔记",
      "link": "https://www.cnblogs.com/xzyNOIP/p/19567406",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzyNOIP/p/19567406\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 09:32\">\n    <span>回文自动机 PAM 学习笔记</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"回文自动机\">回文自动机</h2>\n<p>zeb 于 2026.2.2 讲解，做一个笔记。</p>\n<h3 id=\"1-引入\">1. 引入</h3>\n<p>回文树，或者说，回文自动机 PAM（Palindromic Automaton），是一种可以存储一个串中<strong>所有本质不同回文子串</strong>的数据结构。</p>\n<p>由于这个算法就是从其它字符串相关自动机借鉴而来，因此于其它自动机有许多相似之处。在这个回文自动机中，每一个状态（即节点）都对应了原串中的一个子串。而不同的是，转移边上的字符，指的是在原状态上两侧分别加上一个这个字符，所形成的回文子串。</p>\n<p>例如</p>\n<p><img alt=\"\" src=\"https://cdn.luogu.com.cn/upload/image_hosting/5vme40l0.png\" /></p>\n<p>你就会发现一个问题，我们这样只能得到偶数长度的子串，那该怎么办呢？也像 <span class=\"math inline\">\\(\\text{Manacher}\\)</span> 那样加入间隔字符？</p>\n<p>我们考虑一个巧妙而快捷的方法——我们建两棵根，一个是<strong>奇根</strong>，下面挂所有长度为奇数的回文子串；一个是<strong>偶根</strong>，下面挂所有长度为偶数的回文子串。</p>\n<h3 id=\"2-构造\">2. 构造</h3>\n<p>对每个状态，我们会储存以下内容：</p>\n<ul>\n<li>对应字符串长度 <span class=\"math inline\">\\(\\mathtt{len_u}\\)</span>；</li>\n<li>对应字符串所有出边指向的结点 <span class=\"math inline\">\\(\\mathtt{trie_{u,c}}\\)</span>；</li>\n<li>状态的失配指针 <span class=\"math inline\">\\(\\mathtt{fail_u}\\)</span>（含义在下文）。</li>\n</ul>\n<p>对于奇根和偶根，我们分别定义它们的长度为 <span class=\"math inline\">\\(-1\\)</span> 和 <span class=\"math inline\">\\(0\\)</span>。这样可以保持统一性，在一个状态后加入一个后继状态时，它所对应的长度就直接设为它父亲长度加 <span class=\"math inline\">\\(2\\)</span> 即可。</p>\n<p>对于 <span class=\"math inline\">\\(\\text{PAM}\\)</span> 的构造，我们类似于 <span class=\"math inline\">\\(\\text{SAM}\\)</span> 采用<strong>增量构造</strong>，即每加入一个字符，我们都可以实时更新这个回文自动机。</p>\n<p>那么，不妨设我们现在要加入的这个点是第 <span class=\"math inline\">\\(i\\)</span> 个字符，前 <span class=\"math inline\">\\(i-1\\)</span> 个字符对应的 <span class=\"math inline\">\\(\\text{PAM}\\)</span> 已经构造好。</p>\n<p>我们考虑加入这个字符串会产生的新的回文子串，即以第 <span class=\"math inline\">\\(i\\)</span> 位为结尾的回文子串。在这么多的回文子串中，我们每个都要新建节点吗？并非，事实上，我们只需要新建<strong>最长的一个后缀回文子串</strong>对应状态即可。因为可以保证，比它短的以前一定已经出现过了，比如说这个例子：</p>\n<p>对于子串 <span class=\"math inline\">\\(\\mathtt{abaccaba}\\)</span>，后缀回文子串共有三个，<span class=\"math inline\">\\(\\mathtt{abaccaba,aba,a}\\)</span>。</p>\n<p>其中你会发现，如果一个后缀回文子串不是最长的，那么它一定可以被最长的那一个后缀回文子串<strong>翻转过去</strong>，比如说这里的 <span class=\"math inline\">\\(\\mathtt{aba}\\)</span>，就可以通过整个子串找到一个对称位置上同样的 <span class=\"math inline\">\\(\\mathtt{aba}\\)</span>，这也就是为什么我们至多只需要新建最长回文后缀对应节点就可以了。</p>\n<p>现在我们的任务，就是找到这个新节点该建立在哪里。你会发现，这个节点的父亲，即将这个最长回文后缀掐头去尾，一定也是一个回文串，且就是 <span class=\"math inline\">\\(i-1\\)</span> 位置上的一个后缀回文子串。于是这个任务就转化成了，找到一个对应子串最长的节点 <span class=\"math inline\">\\(u\\)</span> 满足</p>\n<ul>\n<li>它对应的子串是 <span class=\"math inline\">\\(i-1\\)</span> 的一个后缀回文子串；</li>\n<li><span class=\"math inline\">\\(s_{i-\\mathtt{len_u}-1}=s_i\\)</span>。</li>\n</ul>\n<p>我们记录 <span class=\"math inline\">\\(i-1\\)</span> 位置最长回文后缀对应状态节点编号为 <span class=\"math inline\">\\(\\mathtt{last}\\)</span>。如果这个节点已经满足这个条件了，很好，我们直接把新节点连在 <span class=\"math inline\">\\(\\mathtt{last}\\)</span> 下面即可。但如果不行呢？因此，我们这里类似 <span class=\"math inline\">\\(\\text{ACAM}\\)</span>，引入 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 失配指针。<span class=\"math inline\">\\(\\mathtt{fail_u}\\)</span> 表示的含义是，状态 <span class=\"math inline\">\\(u\\)</span> 对应的回文子串的<strong>最长回文后缀</strong>对应的状态。</p>\n<p>那么可以发现，<span class=\"math inline\">\\(\\mathtt{last},\\mathtt{fail_{last}},\\mathtt{fail_{fail_{last}}},\\dots\\)</span> 就对应了以 <span class=\"math inline\">\\(i-1\\)</span> 结尾的所有后缀回文子串！</p>\n<p>因此在这里，我们只需要不断往上跳 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 指针即可。那么如果一直找都找不到，怎么办？这时候我们考虑把偶根的 <span class=\"math inline\">\\(\\mathtt{fail_0}\\)</span> 连到奇根上去。这样跳 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 时，由于奇根的 <span class=\"math inline\">\\(\\mathtt{len_1}=-1\\)</span>，因此 <span class=\"math inline\">\\(i-\\mathtt{len_1}-1=i\\)</span>，即对于 <span class=\"math inline\">\\(s_i\\)</span> 这个单字符的回文串，二条件一定成立，很自然的就会连到奇根下面。这一方面揭示了设奇根长度为 <span class=\"math inline\">\\(-1\\)</span> 的另一好处，同时也说明了，为什么 <span class=\"math inline\">\\(\\mathtt{fail_0}\\leftarrow 1\\)</span>。</p>\n<p>那么找到了父亲，我们接下来就是要为这一点也连一条 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 指针出去。</p>\n<p>其实也很简单，这条 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 指针，连向的其实就是以 <span class=\"math inline\">\\(i\\)</span> 结尾的第二长的回文后缀。那么我们只需要继续从 <span class=\"math inline\">\\(\\mathtt{fail_{last}}\\)</span> 开始跳，再找到第一个符合二条件的就可以了。</p>\n<p>下面是实现。</p>\n<pre><code class=\"language-cpp\">int last,tot=1,fail[N],len[N],trie[N][30];\n//last 最开始挂在偶根\n//tot 记得要赋初值为 1\nint getfail(int u,int id){\n    while(s[id]!=s[id-len[u]-1]) u=fail[u]; //不满足二条件就一直跳\n    return u;\n}\nvoid pamConstruct(){\n    fail[0]=1,len[1]=-1;\n    //初始化 偶根的 fail 指向奇根，奇根的长度为 -1\n    for(int i=1;i&lt;=n;i++){\n\t\tint fa=getfail(last,i);\n        //找到 i-1 的回文后缀中最长的那个符合二条件的，作为其父亲\n\t\tif(!trie[fa][s[i]-'a']){\n\t\t\tfail[++tot]=trie[getfail(fail[fa],i)][s[i]-'a'];\n            //从 fail[fa] 开始，是因为我们找的是真后缀\n\t\t\ttrie[fa][s[i]-'a']=tot;\n            //先找 fail 再连边！！\n\t\t\tlen[tot]=len[fa]+2;\n\t\t}\n\t\tlast=trie[fa][s[i]-'a'];\n\t}\n}\n</code></pre>\n<p>有关复杂度，首先，由代码也可以看出，状态最多只有 <span class=\"math inline\">\\(n\\)</span> 个，因此空间复杂度是 <span class=\"math inline\">\\(O(n\\Sigma)\\)</span> 的。</p>\n<p>时间复杂度，首先除了跳 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 都是 <span class=\"math inline\">\\(O(n)\\)</span> 的。</p>\n<p>每次跳 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 时，每一条 Fail 边至多被经过一次，而增添 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 指针时，最多新添一条 Fail 边。因此跳 <span class=\"math inline\">\\(\\text{Fail}\\)</span> 的次数至多就是 <span class=\"math inline\">\\(O(n)\\)</span> 的，因此总时间复杂度是 <span class=\"math inline\">\\(O(n)\\)</span>。</p>\n<h3 id=\"3-应用\">3. 应用</h3>\n<p><strong>求以某位置结尾的回文子串个数，强制在线</strong></p>\n<p>即 P5496，分析一下，其实就是它在 Fail 树上的深度嘛。</p>\n<p>代码</p>\n<pre><code class=\"language-cpp\">const int N=5e5+10;\nstring s;\nint n,lastans;\nint last,tot=1,fail[N],len[N],trie[N][30];\nint dep[N];\nint getfail(int u,int id){\n\twhile(s[id]!=s[id-len[u]-1]) u=fail[u];\n\treturn u;\n}\nint main(){\n\tios::sync_with_stdio(false);\n\tcin.tie(0);cout.tie(0);\n\tcin&gt;&gt;s; n=s.length();\n\ts=\" \"+s;\n\tfail[0]=1,len[1]=-1;\n\tfor(int i=1;i&lt;=n;i++){\n\t\ts[i]=(s[i]-97+lastans)%26+97;\n\t\tint fa=getfail(last,i);\n\t\tif(!trie[fa][s[i]-'a']){\n\t\t\tfail[++tot]=trie[getfail(fail[fa],i)][s[i]-'a'];\n\t\t\ttrie[fa][s[i]-'a']=tot;\n\t\t\tlen[tot]=len[fa]+2;\n\t\t\tdep[tot]=dep[fail[tot]]+1;\n\t\t}\n\t\tlast=trie[fa][s[i]-'a'];\n\t\tlastans=dep[last];\n\t\tcout&lt;&lt;lastans&lt;&lt;\" \";\n\t}\n\tcout&lt;&lt;\"\\n\";\n\treturn 0;\n}\n</code></pre>\n<p><strong>求某个回文子串的出现次数</strong></p>\n<p>你会发现在 Fail 树上，一个状态的后代所对应的子串全都包含它。因此我们记录 <span class=\"math inline\">\\(\\mathtt{cnt_u}\\)</span> 表示 <span class=\"math inline\">\\(u\\)</span> 状态在构建时被抵达了多少次，最后一个节点答案就应该是子树和。</p>\n<p>P3649 代码如下</p>\n<pre><code class=\"language-cpp\">const int N=3e5+10;\nstring s;\nint n;\nll ans;\nint tot=1,last,len[N],siz[N],fail[N],trie[N][30];\nvector&lt;int&gt; T[N];\nint getfail(int u,int id){\n\twhile(s[id]!=s[id-len[u]-1]) u=fail[u];\n\treturn u;\n}\nvoid dfs(int u){\n\tfor(auto v:T[u]) dfs(v),siz[u]+=siz[v];\n\tans=max(ans,1ll*len[u]*siz[u]);\n}\nint main(){\n\tios::sync_with_stdio(false);\n\tcin.tie(0);cout.tie(0);\n\tcin&gt;&gt;s; n=s.length();\n\ts=\" \"+s;\n\tlen[1]=-1,fail[0]=1;\n\tT[1].push_back(0);\n\tfor(int i=1;i&lt;=n;i++){\n\t\tint fa=getfail(last,i);\n\t\tif(!trie[fa][s[i]-'a']){\n\t\t\tfail[++tot]=trie[getfail(fail[fa],i)][s[i]-'a'];\n\t\t\tT[fail[tot]].push_back(tot);\n\t\t\ttrie[fa][s[i]-'a']=tot;\n\t\t\tlen[tot]=len[fa]+2;\n\t\t}\n\t\tlast=trie[fa][s[i]-'a'];\n\t\tsiz[last]++;\n\t}\n\tdfs(1);\n\tcout&lt;&lt;ans&lt;&lt;\"\\n\";\n\treturn 0;\n}\n</code></pre>\n<p><strong>前端插入</strong></p>\n<p>是的，<span class=\"math inline\">\\(\\text{PAM}\\)</span> 支持前端插入，这得益于回文串良好的对称性质。</p>\n<p>假设我们要在位置 <span class=\"math inline\">\\(l\\)</span> 新增一个字符，我们就要找到 <span class=\"math inline\">\\(l+1\\)</span> 的最长回文前缀中，第一个合法的。那我们要额外建立另一颗 Fail 树吗？并不用，因为你会发现一个回文串的回文前缀，一定也是这个回文串的回文后缀，因此 Fail 完全可以共用。</p>\n<p>唯一要改变的是，我们原先是一个 <span class=\"math inline\">\\(\\mathtt{last}\\)</span>，在这里我们要用两个，<span class=\"math inline\">\\(\\mathtt{pre}\\)</span> 和 <span class=\"math inline\">\\(\\mathtt{suf}\\)</span>，分别表示 <span class=\"math inline\">\\(l\\)</span> 最长回文前缀对应的状态，和 <span class=\"math inline\">\\(r\\)</span> 最长回文后缀对应的状态。什么时候两者可能会相互影响呢？你会发现，只有当整个串都变成了一个回文串，两者就会相互影响了，此时要将它们统一设成最后一个状态。</p>\n<p>HDU5421 代码如下。</p>\n<pre><code class=\"language-cpp\">const int N=2e5+10;\nchar s[N];\nint q,L,R;\nll ans;\nint tot,fail[N],trie[N][30],len[N],dep[N];\nint pre,suf;\nvoid init(){\n\ttot=1,ans=0;\n\tpre=0,suf=0;\n\tL=1e5+1,R=L-1;\n\tmemset(fail,0,sizeof(fail));\n\tmemset(trie,0,sizeof(trie));\n\tmemset(len,0,sizeof(len));\n\tmemset(dep,0,sizeof(dep));\n\tmemset(s,0,sizeof(s));\n\tfail[0]=1,len[1]=-1;\n}\nint getfail(int u,int id,int op){\n\twhile(s[id]!=s[id-op*(len[u]+1)]) u=fail[u];\n\treturn u;\n}\nvoid insert(char c,int pos,int &amp;last,int op){\n\tint fa=getfail(last,pos,op);\n\tif(!trie[fa][c-'a']){\n\t\tfail[++tot]=trie[getfail(fail[fa],pos,op)][c-'a'];\n\t\ttrie[fa][c-'a']=tot;\n\t\tlen[tot]=len[fa]+2,dep[tot]=dep[fail[tot]]+1;\n\t}\n\tlast=trie[fa][c-'a'];\n\tans+=dep[last];\n\tif(len[last]==R-L+1) pre=suf=last;\n}\nint main(){\n\tios::sync_with_stdio(false);\n\tcin.tie(0);cout.tie(0);\n\twhile(cin&gt;&gt;q){\n\t\tinit();\n\t\twhile(q--){\n\t\t\tint op; char c;\n\t\t\tcin&gt;&gt;op;\n\t\t\tif(op==1){\n\t\t\t\tcin&gt;&gt;c; s[--L]=c;\n\t\t\t\tinsert(c,L,pre,-1);\n\t\t\t}\n\t\t\telse if(op==2){\n\t\t\t\tcin&gt;&gt;c; s[++R]=c;\n\t\t\t\tinsert(c,R,suf,1);\n\t\t\t}\n\t\t\telse if(op==3) cout&lt;&lt;tot-1&lt;&lt;\"\\n\";\n\t\t\telse cout&lt;&lt;ans&lt;&lt;\"\\n\";\n\t\t}\n\t}\n\treturn 0;\n}\n\n</code></pre>\n<p><strong>回文自动机上 dp</strong></p>\n<p>一道例题：P4762 Virus synthesis</p>\n<blockquote>\n<p>初始有一个空串，利用下面的操作构造定串 <span class=\"math inline\">\\(S\\)</span>。</p>\n<ul>\n<li>串开头或末尾添加一个字符；</li>\n<li>翻转字符串，添加到在开头或末尾。</li>\n</ul>\n<p>求最小的操作数，<span class=\"math inline\">\\(|S|\\le 10^5\\)</span>，字符集为 <span class=\"math inline\">\\(\\{A,T,C,G \\}\\)</span>。</p>\n</blockquote>\n<p>可以先去玩一下样例。</p>\n<p>二操作是一个很好的东西，它可以减省很多时间。因此，我们考虑<strong>最后一次使用二操作</strong>所形成的字符串，设其所需操作次数为 <span class=\"math inline\">\\(f(T)\\)</span>，那么剩下的暴力操作非常好计算，总次数就是 <span class=\"math inline\">\\(n-|T|+f(T)\\)</span>，在所有偶回文子串中选一个最小的就可以了，这些回文子串都可以在 <span class=\"math inline\">\\(\\text{PAM}\\)</span> 上存储。问题转化为如何计算一个偶回文子串的最小操作次数。</p>\n<p>首先对于这个偶回文子串，最后一步<strong>一定是翻转</strong>，没的说。考虑怎么转移来。</p>\n<ul>\n<li>从同心的回文子串转移来：即从其在 <span class=\"math inline\">\\(\\text{PAM}\\)</span> 上的父亲的操作次数加一，<span class=\"math inline\">\\(f(\\mathtt{fa_u})+1\\)</span>；</li>\n<li>从不同心的回文子串转移来：我们跳 Fail 链，找到第一个 <span class=\"math inline\">\\(\\mathtt{len}\\)</span> 值小于等于当前串一半的，设这个为 <span class=\"math inline\">\\(\\mathtt{trans_u}\\)</span>，答案就是 <span class=\"math inline\">\\(f(\\mathtt{trans_u})+\\dfrac {\\mathtt{len_u}}{2}-\\mathtt{len_{trans_u}}+1\\)</span>。</li>\n</ul>\n<p>求 <span class=\"math inline\">\\(\\mathtt{trans}\\)</span> 的方法与 Fail 树类似。时间复杂度 <span class=\"math inline\">\\(O(n)\\)</span>。</p>\n<pre><code class=\"language-cpp\">const int N=1e5+10;\nstring s;\nint n;\nint tot,trie[N][4],len[N],fail[N];\nint trans[N];\nint dp[N];\nint last;\nint getid(char c){\n\tif(c=='A') return 0;\n\telse if(c=='G') return 1;\n\telse if(c=='C') return 2;\n\telse return 3;\n}\nint getfail(int u,int id){\n\twhile(s[id]!=s[id-len[u]-1]) u=fail[u];\n\treturn u;\n}\nvoid solve(){\n\tcin&gt;&gt;s; n=s.length();\n\tfor(int i=0;i&lt;=n;i++) dp[i]=INF;\n    //注意 dp 值初始都设为极大\n\ts=\" \"+s;\n\ttot=1,last=0;\n\tlen[1]=-1,fail[0]=1;\n\tint ans=n;\n\tdp[0]=1; //先把翻转的代价算上，不然像转移一那种就计算不到\n\tfor(int i=1;i&lt;=n;i++){\n\t\tint fa=getfail(last,i);\n\t\tif(!trie[fa][getid(s[i])]){\n\t\t\tfail[++tot]=trie[getfail(fail[fa],i)][getid(s[i])];\n\t\t\ttrie[fa][getid(s[i])]=tot;\n\t\t\tlen[tot]=len[fa]+2;\n            //下面求 trans\n\t\t\tif(len[tot]&lt;=2) trans[tot]=fail[tot];\n\t\t\telse if(len[tot]%2==0){\n\t\t\t\tint tmp=trans[fa];// 很重要 保证时间复杂度\n                // 这样可以保证 Fail 边不会被大量重复走过\n\t\t\t\twhile(s[i-1-len[tmp]]!=s[i]||(len[tmp]+2)*2&gt;len[tot]) tmp=fail[tmp];\n\t\t\t\ttrans[tot]=trie[tmp][getid(s[i])];\n\t\t\t}\n\t\t\tif(len[tot]%2==0){\n\t\t\t\tdp[tot]=min(dp[fa]+1,dp[trans[tot]]+len[tot]/2-len[trans[tot]]+1);\n\t\t\t\tans=min(ans,dp[tot]+n-len[tot]);\n\t\t\t}\n\t\t}\n\t\tlast=trie[fa][getid(s[i])];\n\t}\n\tcout&lt;&lt;ans&lt;&lt;\"\\n\"; \n\tfor(int i=0;i&lt;=tot;i++){\n\t\tfor(int j=0;j&lt;4;j++) trie[i][j]=0;\n\t}\n}\n</code></pre>\n<p>参考文章</p>\n<ul>\n<li>\n<p><a href=\"https://www.luogu.com.cn/article/ntc6yyfd\" rel=\"noopener nofollow\" target=\"_blank\">PAM 题解 by 功在不舍</a></p>\n</li>\n<li>\n<p><a href=\"https://oi-wiki.org/string/pam/\" rel=\"noopener nofollow\" target=\"_blank\">oi-wiki</a></p>\n</li>\n<li>\n<p><a href=\"https://www.luogu.com.cn/user/387585\" rel=\"noopener nofollow\" target=\"_blank\">来自 zeb 的讲解</a></p>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 09:32</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzyNOIP\">xzy_sf</a>&nbsp;\n阅读(<span id=\"post_view_count\">29</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET Core 双数据库实战：优雅融合 PostgreSQL 与 SQLite 的最佳实践",
      "link": "https://www.cnblogs.com/newbe36524/p/19567317",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19567317\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 09:11\">\n    <span>.NET Core 双数据库实战：优雅融合 PostgreSQL 与 SQLite 的最佳实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"net-core-双数据库实战让-postgresql-与-sqlite-和平共处\">.NET Core 双数据库实战：让 PostgreSQL 与 SQLite 和平共处</h1>\n<blockquote>\n<p>在构建现代化应用时，我们经常面临这样的抉择：开发环境渴望轻量便捷，而生产环境则需要高并发与高可用。本文将分享如何在 .NET Core 项目中优雅地同时支持 PostgreSQL 和 SQLite，实现“开发用 SQLite，生产用 PG”的最佳实践。</p>\n</blockquote>\n\n<h2 id=\"背景\">背景</h2>\n<p>在软件开发中，环境差异化一直是困扰开发团队的难题之一。以我们正在构建的 <strong>HagiCode</strong> 平台为例，这是一个基于 ASP.NET Core 10 和 React 的 AI 辅助开发系统，内部集成了 Orleans 进行分布式状态管理，技术栈相当现代且复杂。</p>\n<p>在项目初期，我们遇到了一个典型的工程痛点：开发人员希望本地环境能够“开箱即用”，不希望安装和配置繁重的 PostgreSQL 数据库；但在生产环境中，我们需要处理高并发写入和复杂的 JSON 查询，这时轻量级的 SQLite 又显得力不从心。</p>\n<p>如何在保持代码库统一的前提下，让应用既能像客户端软件一样利用 SQLite 的便携性，又能像企业级服务一样发挥 PostgreSQL 的强悍性能？这就是本文要探讨的核心问题。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<p>本文分享的双数据库适配方案，直接来源于我们在 <strong>HagiCode</strong> 项目中的实战经验。HagiCode 是一个集成了 AI 提示词管理和 OpenSpec 工作流的下一代开发平台。正是为了兼顾开发者的体验和生产环境的稳定性，我们探索出了这套行之有效的架构模式。</p>\n<p>欢迎访问我们的 GitHub 仓库了解项目全貌：<a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">HagiCode-org/site</a>。</p>\n<h2 id=\"核心内容一架构设计与统一抽象\">核心内容一：架构设计与统一抽象</h2>\n<p>要在 .NET Core 中实现双数据库支持，核心思想是“依赖抽象而非具体实现”。我们需要把数据库的选择权从业务代码中剥离出来，交给配置层决定。</p>\n<h3 id=\"设计思路\">设计思路</h3>\n<ol>\n<li><strong>统一接口</strong>：所有的业务逻辑都应依赖于 <code>DbContext</code> 基类或自定义的接口，而不是具体的 <code>PostgreSqlDbContext</code>。</li>\n<li><strong>配置驱动</strong>：通过 <code>appsettings.json</code> 中的配置项，在应用启动时动态决定加载哪个数据库提供程序。</li>\n<li><strong>特性隔离</strong>：针对 PostgreSQL 特有的功能（如 JSONB）进行适配处理，确保在 SQLite 中也能降级运行。</li>\n</ol>\n<h3 id=\"代码实现动态上下文配置\">代码实现：动态上下文配置</h3>\n<p>在 ASP.NET Core 的 <code>Program.cs</code> 中，我们不应硬编码 <code>UseNpgsql</code> 或 <code>UseSqlite</code>。相反，我们应该读取配置来动态决定。</p>\n<p>首先，定义配置类：</p>\n<pre><code class=\"language-csharp\">public class DatabaseSettings\n{\n    public const string SectionName = \"Database\";\n    \n    // 数据库类型：PostgreSQL 或 SQLite\n    public string DbType { get; set; } = \"PostgreSQL\"; \n    \n    // 连接字符串\n    public string ConnectionString { get; set; } = string.Empty;\n}\n</code></pre>\n<p>然后，在 <code>Program.cs</code> 中根据配置注册服务：</p>\n<pre><code class=\"language-csharp\">// 读取配置\nvar databaseSettings = builder.Configuration.GetSection(DatabaseSettings.SectionName).Get&lt;DatabaseSettings&gt;();\n\n// 注册 DbContext\nbuilder.Services.AddDbContext&lt;ApplicationDbContext&gt;(options =&gt;\n{\n    if (databaseSettings?.DbType?.ToLower() == \"sqlite\")\n    {\n        // SQLite 配置\n        options.UseSqlite(databaseSettings.ConnectionString);\n        \n        // SQLite 的并发写入限制处理\n        // 注意：在生产环境中建议开启 WAL 模式以提高并发性能\n    }\n    else\n    {\n        // PostgreSQL 配置（默认）\n        options.UseNpgsql(databaseSettings.ConnectionString, npgsqlOptions =&gt;\n        {\n            // 开启 JSONB 支持，这在处理 AI 对话记录时非常有用\n            npgsqlOptions.UseJsonNet(); \n        });\n        \n        // 配置连接池重连策略\n        options.EnableRetryOnFailure(3);\n    }\n});\n</code></pre>\n<h2 id=\"核心内容二处理差异性与迁移策略\">核心内容二：处理差异性与迁移策略</h2>\n<p>PostgreSQL 和 SQLite 虽然都支持 SQL 标准，但在具体特性和行为上存在显著差异。如果不处理好这些差异，很可能会出现“本地跑得通，上线就报错”的尴尬情况。</p>\n<h3 id=\"1-json-类型的处理\">1. JSON 类型的处理</h3>\n<p>在 HagiCode 中，我们需要存储大量的提示词和 AI 元数据，这通常涉及 JSON 列。</p>\n<ul>\n<li><strong>PostgreSQL</strong>：拥有原生的 <code>JSONB</code> 类型，查询性能极佳。</li>\n<li><strong>SQLite</strong>：没有原生的 JSON 类型（新版本有 JSON1 扩展，但对象映射上仍有差异），通常存储为 TEXT。</li>\n</ul>\n<p><strong>解决方案</strong>：<br />\n在 EF Core 的实体映射中，我们将其配置为可转换的类型。</p>\n<pre><code class=\"language-csharp\">protected override void OnModelCreating(ModelBuilder modelBuilder)\n{\n    base.OnModelCreating(modelBuilder);\n\n    // 配置实体\n    modelBuilder.Entity&lt;PromptTemplate&gt;(entity =&gt; \n    {\n        entity.Property(e =&gt; e.Metadata)\n              .HasColumnType(\"jsonb\") // PG 使用 jsonb\n              .HasConversion(\n                  v =&gt; JsonSerializer.Serialize(v, (JsonSerializerOptions)null),\n                  v =&gt; JsonSerializer.Deserialize&lt;Dictionary&lt;string, object&gt;&gt;(v, (JsonSerializerOptions)null)\n              ); \n    });\n}\n</code></pre>\n<p>当使用 SQLite 时，虽然 <code>HasColumnType(\"jsonb\")</code> 会被忽略或产生警告，但由于配置了 <code>HasConversion</code>，数据会被正确地序列化和反序列化为字符串存入 TEXT 字段，从而保证了兼容性。</p>\n<h3 id=\"2-迁移策略的分离\">2. 迁移策略的分离</h3>\n<p>绝对不要试图让同一套 Migration 脚本同时适配 PG 和 SQLite。由于主键生成策略、索引语法等的不同，这必然会导致失败。</p>\n<p><strong>推荐实践</strong>：<br />\n维护两个迁移分支或项目。在 HagiCode 的开发流中，我们是这样处理的：</p>\n<ol>\n<li><strong>开发阶段</strong>：主要在 SQLite 下工作。使用 <code>Add-Migration Init_Sqlite -OutputDir Migrations/Sqlite</code>。</li>\n<li><strong>适配阶段</strong>：开发完一段功能后，切换连接字符串指向 PostgreSQL，执行 <code>Add-Migration Init_Postgres -OutputDir Migrations/Postgres</code>。</li>\n<li><strong>自动化脚本</strong>：编写一个简单的 PowerShell 或 Bash 脚本，根据当前环境变量自动应用对应的迁移。</li>\n</ol>\n<pre><code class=\"language-bash\"># 简单的部署逻辑伪代码\nif [ \"$DATABASE_PROVIDER\" = \"PostgreSQL\" ]; then\n    dotnet ef database update --project Migrations.Postgres\nelse\n    dotnet ef database update --project Migrations.Sqlite\nfi\n</code></pre>\n<h2 id=\"核心内容三hagicode-的实战经验总结\">核心内容三：HagiCode 的实战经验总结</h2>\n<p>在将 <strong>HagiCode</strong> 从单一数据库重构为双数据库支持的过程中，我们踩过一些坑，也总结了一些关键的经验，希望能给大家避坑。</p>\n<h3 id=\"1-并发与事务的区别\">1. 并发与事务的区别</h3>\n<p>PostgreSQL 是服务端-客户端架构，支持高并发写入，事务隔离级别非常强大。而 SQLite 是文件锁机制，写入操作会锁定整个数据库文件（除非开启 WAL 模式）。</p>\n<p><strong>建议</strong>：<br />\n在编写涉及频繁写入的业务逻辑时（例如实时保存用户的编辑状态），一定要考虑到 SQLite 的锁机制。在设计 <strong>HagiCode</strong> 的 OpenSpec 协作模块时，我们引入了“写前合并”机制，减少数据库的直接写入频率，从而在两种数据库下都能保持高性能。</p>\n<h3 id=\"2-连接字符串的生命周期管理\">2. 连接字符串的生命周期管理</h3>\n<p>PostgreSQL 的连接建立成本较高，依赖连接池。而 SQLite 连接非常轻量，但如果不及时释放，文件锁可能会导致后续操作超时。</p>\n<p>在 <code>Program.cs</code> 中，我们可以针对不同数据库做精细化调整：</p>\n<pre><code class=\"language-csharp\">if (databaseSettings?.DbType?.ToLower() == \"sqlite\")\n{\n    // SQLite：保持连接开启能提升性能，但要注意文件锁\n    options.UseSqlite(connectionString, sqliteOptions =&gt;\n    {\n        // 设置命令超时时间\n        sqliteOptions.CommandTimeout(30);\n    });\n}\nelse\n{\n    // PG：利用连接池\n    options.UseNpgsql(connectionString, npgsqlOptions =&gt;\n    {\n        npgsqlOptions.MaxBatchSize(100);\n        npgsqlOptions.CommandTimeout(30);\n    });\n}\n</code></pre>\n<h3 id=\"3-测试覆盖的重要性\">3. 测试覆盖的重要性</h3>\n<p>很多开发者（包括我们团队早期的成员）容易犯一个错误：只在开发环境（通常是 SQLite）跑单元测试。</p>\n<p>我们在 HagiCode 的 CI/CD 流水线中强制加入了 GitHub Action 步骤，确保每次 Pull Request 都要跑过 PostgreSQL 的集成测试。</p>\n<pre><code class=\"language-yaml\"># .github/workflows/test.yml 示例片段\n- name: Run Integration Tests (PostgreSQL)\n  run: |\n    docker-compose up -d db_postgres\n    dotnet test --filter \"Category=Integration\"\n</code></pre>\n<p>这帮我们拦截了无数次关于 SQL 语法差异、大小写敏感性的 Bug。</p>\n<h2 id=\"总结\">总结</h2>\n<p>通过引入抽象层和配置驱动的依赖注入，我们在 <strong>HagiCode</strong> 项目中成功实现了 PostgreSQL 和 SQLite 的“双轨制”运行。这不仅极大降低了新开发者的上手门槛（不需要装 PG），也为生产环境提供了坚实的性能保障。</p>\n<p>回顾一下关键点：</p>\n<ol>\n<li><strong>抽象至上</strong>：业务代码不依赖具体数据库实现。</li>\n<li><strong>配置分离</strong>：开发和生产使用不同的 <code>appsettings.json</code>。</li>\n<li><strong>迁移分离</strong>：不要尝试一套 Migration 走天下。</li>\n<li><strong>特性降级</strong>：在 SQLite 中以兼容性优先，在 PostgreSQL 中以性能优先。</li>\n</ol>\n<p>这种架构模式不仅适用于 HagiCode，也适用于任何需要在轻量级开发和重量级生产之间寻找平衡的 .NET 项目。</p>\n<hr />\n<p>如果本文对你有帮助，欢迎来 GitHub 给个 Star，或者直接体验 <strong>HagiCode</strong> 带来的高效开发流程：</p>\n<ul>\n<li>来 GitHub 给个 Star：<a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">github.com/HagiCode-org/site</a></li>\n<li>访问官网了解更多：<a href=\"https://hagicode-org.github.io/site\" rel=\"noopener nofollow\" target=\"_blank\">hagicode-org.github.io/site</a></li>\n<li>观看 30 分钟实战演示：<a href=\"https://www.bilibili.com/video/BV1pirZBuEzq/\" rel=\"noopener nofollow\" target=\"_blank\">www.bilibili.com/video/BV1pirZBuEzq/</a></li>\n<li>一键安装体验：<a href=\"https://hagicode-org.github.io/site/docs/installation/docker-compose\" rel=\"noopener nofollow\" target=\"_blank\">hagicode-org.github.io/site/docs/installation/docker-compose</a></li>\n</ul>\n<p>公测已开始，欢迎安装体验！</p>\n<hr />\n<p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p>\n<p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p>\n<ul>\n<li><strong>本文作者:</strong> <a href=\"https://www.newbe.pro\" rel=\"noopener nofollow\" target=\"_blank\">newbe36524</a></li>\n<li><strong>本文链接:</strong> <a href=\"https://hagicode-org.github.io/site/blog/2026-02-01-dotnet-core-dual-database-postgresql-sqlite/\" rel=\"noopener nofollow\" target=\"_blank\">https://hagicode-org.github.io/site/blog/2026-02-01-dotnet-core-dual-database-postgresql-sqlite/</a></li>\n<li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 09:11</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">57</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "FastAPI部署实战：聊聊CORS跨域那些坑",
      "link": "https://www.cnblogs.com/ymtianyu/p/19567261",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19567261\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 08:49\">\n    <span>FastAPI部署实战：聊聊CORS跨域那些坑</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        FastAPI部署时，CORS跨域问题是常见拦路虎。本文以程序员的实战视角，生动比喻解析CORS原理，提供从开发到生产环境的阶梯式配置方案，并揭露了通配符与凭证同用、中间件顺序、反向代理冲突等常见陷阱，帮助你一次性正确配置，避免安全风险。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><em>摘要：当你把精心开发的FastAPI应用部署上线，却发现前端页面死活调不通接口，浏览器控制台一片飘红……别慌，这八成是CORS（跨域资源共享）在作祟。本文带你彻底搞懂CORS原理，分享FastAPI中从“允许所有”到“精细化配置”的实战代码，并针对开发、测试、生产不同环境给出方案，最后聊聊那些文档里没写的安全陷阱和常见坑点。</em></p>\n<p>🎯 你的前端应用突然无法调用后端API了？报错里满是“CORS”？别急着怀疑人生，这几乎是每个全栈工程师部署时的“成人礼”。我当年第一次遇到时，也以为服务器炸了，对着日志研究了半天……结果就是个配置项。</p>\n<p>更真实的是，根据经验，<strong style=\"color: rgba(186, 55, 42, 1);\">超过70%的初次部署问题都与CORS配置不当有关</strong>。而且很多人即便配通了，也是简单粗暴地允许所有来源（<code style=\"color: rgba(186, 55, 42, 1);\">allow_origins=[\"*\"]</code>），为后续安全漏洞埋下伏笔。</p>\n<h2>📖 主要内容脉络</h2>\n<div>\n<p>👉 1. 什么是CORS？用“餐厅订位”的比喻秒懂</p>\n<p>👉 2. 浏览器究竟在背后干了啥？（预检请求详解）</p>\n<p>👉 3. FastAPI中CORS配置的“三段式”实战代码</p>\n<p>👉 4. 开发/测试/生产环境，配置怎么变？</p>\n<p>👉 5. 那些我踩过的坑和深夜警报</p>\n</div>\n<h2>🍽️ 第一部分：CORS不是错误，是浏览器的“保安”</h2>\n<p>想象一下，你的FastAPI后端是一家只接受预约的高级餐厅（API服务器），而前端应用是想要来吃饭的客人（运行在浏览器里）。</p>\n<p>如果客人直接从餐厅官网（同源）预约，没问题。但如果客人是从某个外卖平台（不同源）跳转过来想订位，餐厅的保安（浏览器）就会站出来：“且慢！我得先问问餐厅老板，接不接受从你这个平台来的客人。”</p>\n<p>这一问一答的过程，就是CORS机制。<strong style=\"color: rgba(186, 55, 42, 1);\">CORS本身不是错误，而是浏览器实施的一种安全策略</strong>，目的是防止恶意网站随意读取你的数据。服务器拥有最终决定权：“我允许谁（Origin）、用什么方法（Methods）、带什么凭证（Credentials）来访问我。”</p>\n<h2>🔍 第二部分：重点！那个多出来的OPTIONS请求是啥？</h2>\n<p>好，咱们先来聊聊最让人迷惑的“预检请求”（Preflight Request）。你是不是在浏览器开发者工具里，经常看到一个比你真正的API请求先发出的<code style=\"color: rgba(186, 55, 42, 1);\">OPTIONS</code>请求？</p>\n<p>这就是浏览器在“正式点餐”前，先递上一份“用餐需求清单”。</p>\n<div>\n<p>- 客人：“老板，我打算带5个人（自定义头部），用支付宝（非简单方法）来吃，行不行？”</p>\n<p>- 餐厅（服务器）：“行，来吧。”（响应中携带允许的规则）</p>\n<p>- 客人收到许可，才发出真正的携带数据和方法的POST/GET请求。</p>\n</div>\n<p>哪些情况会触发预检？简单说就是“不简单”的请求：比如用了<code style=\"color: rgba(186, 55, 42, 1);\">PUT</code>、<code style=\"color: rgba(186, 55, 42, 1);\">DELETE</code>方法，或者自定义了请求头（如<code style=\"color: rgba(186, 55, 42, 1);\">Authorization</code>），或者<code style=\"color: rgba(186, 55, 42, 1);\">Content-Type</code>是<code style=\"color: rgba(186, 55, 42, 1);\">application/json</code>。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">关键中的关键</strong>：你的服务器<strong>必须能正确处理这个OPTIONS请求</strong>，并返回正确的CORS响应头。否则，后续真正的请求就会被浏览器直接拦下。</p>\n<h2>⚙️ 第三部分：上代码！FastAPI CORS配置三段论</h2>\n<p>接下来重点来了，怎么在FastAPI里配置？官方推荐使用<code style=\"color: rgba(186, 55, 42, 1);\">fastapi.middleware.cors</code>中的<code style=\"color: rgba(186, 55, 42, 1);\">CORSMiddleware</code>。下面是我总结的“基础版”、“常见版”和“生产谨慎版”。</p>\n<h3>🎯 1. 基础版：快速让前端连上（用于本地开发）</h3>\n<p>这是最常见的写法，但<strong>仅建议用于本地开发环境</strong>。</p>\n<pre class=\"language-python highlighter-hljs\"><code>from fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI()\n\n# 在添加路由之前，先添加CORS中间件！\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # 允许所有来源，危险！\n    allow_credentials=True,\n    allow_methods=[\"*\"],  # 允许所有方法\n    allow_headers=[\"*\"],  # 允许所有头部\n)\n\n@app.get(\"/\")\nasync def main():\n    return {\"message\": \"Hello World\"}</code></pre>\n<p>“偷懒一时爽，上线火葬场。” 这个配置虽然能快速解决问题，但<code style=\"color: rgba(186, 55, 42, 1);\">allow_origins=[\"*\"]</code>和<code style=\"color: rgba(186, 55, 42, 1);\">allow_credentials=True</code>是<strong style=\"color: rgba(186, 55, 42, 1);\">绝对不能同时在生产环境使用的</strong>！这会导致严重的凭据泄露风险。</p>\n<h3>🎯 2. 常见版：指定前端来源（用于测试/预发布）</h3>\n<p>更安全的做法是明确列出你信任的前端应用地址。</p>\n<pre class=\"language-python highlighter-hljs\"><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        \"http://localhost:3000\",        # 本地开发\n        \"https://test.yourfrontend.com\", # 测试环境\n        \"https://staging.yourfrontend.com\",\n    ],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"], # 明确列出\n    allow_headers=[\"Authorization\", \"Content-Type\", \"Accept\"], # 明确列出\n    max_age=600, # 预检请求结果缓存时间（秒），减轻服务器压力\n)</code></pre>\n<p>看，这样是不是清晰多了？浏览器来自这些地址的请求才会被放行。</p>\n<h3>🎯 3. 动态配置版（适合多环境）</h3>\n<p>实际项目中，不同环境的前端地址不同。我习惯通过环境变量来动态配置。</p>\n<pre class=\"language-python highlighter-hljs\"><code>import os\nfrom typing import List\n\n# 从环境变量读取，用逗号分隔多个origin\nALLOWED_ORIGINS: List[str] = os.getenv(\"ALLOWED_ORIGINS\", \"\").split(\",\")\n# 如果没配置，本地开发默认允许localhost\nif not ALLOWED_ORIGINS or ALLOWED_ORIGINS == ['']:\n    ALLOWED_ORIGINS = [\"http://localhost:3000\", \"http://127.0.0.1:3000\"]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=ALLOWED_ORIGINS,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)</code></pre>\n<p>然后在生产环境的<code style=\"color: rgba(186, 55, 42, 1);\">.env</code>或配置文件中设置：<code style=\"color: rgba(186, 55, 42, 1);\">ALLOWED_ORIGINS=https://www.yourproduct.com,https://admin.yourproduct.com</code></p>\n<h2>🚨 第四部分：我踩过的坑，希望你绕过去</h2>\n<p>再说个容易翻车的点。<strong style=\"color: rgba(186, 55, 42, 1);\">顺序！中间件的顺序很重要！</strong></p>\n<p>一定要在<code style=\"color: rgba(186, 55, 42, 1);\">app.add_middleware(CORSMiddleware, ...)</code>之后再添加你的自定义中间件或路由。否则，你的自定义中间件可能会在处理请求时因为CORS头还没设置而遇到问题。</p>\n<p>另外，当你的前端使用了<code style=\"color: rgba(186, 55, 42, 1);\">axios</code>等库，并且请求携带了<code style=\"color: rgba(186, 55, 42, 1);\">withCredentials: true</code>（比如发送Cookie或Authorization头）时，后端的<code style=\"color: rgba(186, 55, 42, 1);\">allow_origins</code> <strong>不能是通配符<code style=\"color: rgba(186, 55, 42, 1);\">\"*\"</code></strong>，必须明确指定域名，否则浏览器会报错。这是安全规范。</p>\n<p>还有一个隐藏坑：<strong>Nginx/Apache等反向代理的配置</strong>。有时候你明明在FastAPI里配对了，但请求还是被挡。这时候记得检查一下你的反向代理层（比如Nginx）是否也添加了CORS相关的响应头，造成冲突或覆盖。通常我们只在应用层（FastAPI）处理CORS就够了。</p>\n<p>最后啰嗦一句，CORS是<strong>浏览器</strong>的策略。如果你用<code style=\"color: rgba(186, 55, 42, 1);\">curl</code>、<code style=\"color: rgba(186, 55, 42, 1);\">postman</code>直接测试API，是<strong>看不到CORS错误的</strong>。测试时一定要通过浏览器环境！</p>\n<hr />\n<p>好了，关于FastAPI的CORS，我的经验差不多都倒出来了。别再因为一个通配符配置引发安全事件，希望这篇能帮你省下几个熬夜debug的晚上。</p>\n<p>如果你在部署时还遇到过其他奇怪的“拦路虎”，或者有更优雅的配置方案，<strong>一定在下面分享出来啊</strong>！技术人的成长，不就是靠这样一次次“踩坑”和“填坑”的接力嘛。收藏这篇文章，下次部署前翻出来对照一下，大概率能帮你平稳落地。</p>\n<p>— 你的技术老朋友，一名程序媛</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 08:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">47</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Mac专享！喂饭级教程：手把手带你用MiniMax 2.1与Discord部署个人AI助手OpenClaw",
      "link": "https://www.cnblogs.com/weipo0105/p/19567203",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/weipo0105/p/19567203\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 08:30\">\n    <span>Mac专享！喂饭级教程：手把手带你用MiniMax 2.1与Discord部署个人AI助手OpenClaw</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"Mac专享！喂饭级教程：手把手带你用MiniMax 2.1与Discord部署个人AI助手OpenClaw\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1205021/202602/1205021-20260203082925520-94146276.png\" />\n        这篇教程详细讲解如何在Mac上部署开源AI助手OpenClaw。我们将使用MiniMax 2.1作为AI大脑，并以Discord作为交互平台，手把手带你完成从环境准备、安装配置到最终打通的完整流程。跟随步骤，你就能在Discord中指挥专属AI助手处理任务。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>上一篇文章中，我为大家详细介绍了如何在 Windows 上部署 <strong>OpenClaw</strong> 并接入飞书：<a href=\"https://mp.weixin.qq.com/s/JGd4u8g-Fti4sRcJcSiOLQ\" rel=\"noopener nofollow\" target=\"_blank\">【保姆级教程】手把手教你安装 OpenClaw 并接入飞书，让 AI 在聊天软件里帮你干活</a>。</p>\n<p>不少朋友询问是否有 Mac 版的部署教程。今天，教程就来啦！其实在 Mac 上部署 OpenClaw 与 Windows 步骤基本一致。</p>\n<p>本次教程除了从零完成 OpenClaw 的部署外，最大的不同在于交互平台换成了 <strong>Discord</strong>。接下来，就跟着我一步步完成部署吧！</p>\n<h1 id=\"一什么是-openclaw\">一、什么是 OpenClaw</h1>\n<p><strong>OpenClaw</strong>（原名 ClawdBot）是一个开源的个人 AI 助手平台，运行在你自己的设备上。它支持通过 WhatsApp、Telegram、Slack、Discord、飞书、钉钉、QQ、企业微信等多个平台与你互动。</p>\n<p>其特点包括：</p>\n<ul>\n<li><strong>本地优先</strong>：运行在本地设备，数据完全由自己掌控</li>\n<li><strong>多平台支持</strong>：支持 macOS、Linux、Windows（WSL2）</li>\n<li><strong>多通道连接</strong>：可接入 WhatsApp、Telegram、Slack、Discord、Google Chat、Signal、iMessage 等</li>\n<li><strong>24/7 在线</strong>：以后台服务形式持续运行</li>\n<li><strong>高度可定制</strong>：支持技能扩展与自定义配置</li>\n</ul>\n<hr />\n<h1 id=\"二基本要求\">二、基本要求</h1>\n<ul>\n<li><strong>Node.js</strong>：版本 ≥ 22.0.0（必需）</li>\n<li><strong>npm</strong>：版本 ≥ 9.0.0（随 Node.js 安装）</li>\n<li><strong>一个 AI 模型的 API Key</strong>（本教程使用 MiniMax M2.1）</li>\n</ul>\n<hr />\n<h1 id=\"三安装前准备\">三、安装前准备</h1>\n<h2 id=\"第一步检查-nodejs-版本\">第一步：检查 Node.js 版本</h2>\n<p>打开 <strong>终端（Terminal）</strong>，按 <code>Cmd + Space</code> 输入 “Terminal” 并回车。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>执行以下命令检查 Node.js 版本：</p>\n<pre><code class=\"language-bash\">node --version\n</code></pre>\n<p><strong>预期输出</strong>：显示版本号，只要高于 v22.x.x 即可。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>如果未安装 Node.js 或版本过低，请继续下一步。</p>\n<h2 id=\"第二步安装-nodejs如需\">第二步：安装 Node.js（如需）</h2>\n<h3 id=\"方法一使用官方安装包推荐新手\">方法一：使用官方安装包（推荐新手）</h3>\n<ol>\n<li>访问 Node.js 官网：<a href=\"https://nodejs.org/zh-cn/download\" rel=\"noopener nofollow\" target=\"_blank\">https://nodejs.org/zh-cn/download</a></li>\n<li>下载 LTS 版本（推荐 22.x 或更高）</li>\n<li>双击下载的 <code>.pkg</code> 文件，按提示完成安装</li>\n<li>安装后重启终端，执行 <code>node --version</code> 验证</li>\n</ol>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"方法二使用-homebrew推荐开发者\">方法二：使用 Homebrew（推荐开发者）</h3>\n<pre><code class=\"language-bash\"># 安装 Homebrew（如未安装）\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# 使用 Homebrew 安装 Node.js\nbrew install node\n\n# 验证安装\nnode --version\nnpm --version\n</code></pre>\n<h2 id=\"第三步准备-ai-模型-api-key\">第三步：准备 AI 模型 API Key</h2>\n<p>OpenClaw 需要连接 AI 模型才能工作。国内推荐使用 <strong>MiniMax M2.1</strong>。</p>\n<h4 id=\"获取-minimax-api-key\">获取 MiniMax API Key：</h4>\n<p>1、注册或登录账号</p>\n<p>访问官网：<a href=\"https://platform.minimaxi.com/subscribe/coding-plan?code=FSXNO2PNQ1&amp;source=link\" rel=\"noopener nofollow\" target=\"_blank\">https://platform.minimaxi.com/subscribe/coding-plan?code=FSXNO2PNQ1&amp;source=link</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>2、选择适合的订阅套餐</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>3、获取API Key</p>\n<p>进入 <strong>Coding plan</strong> 页面，找到 API Key，点击重置并复制。妥善保存复制的 API Key<br />\n直达地址：<a href=\"https://platform.minimaxi.com/user-center/payment/coding-plan\" rel=\"noopener nofollow\" target=\"_blank\">https://platform.minimaxi.com/user-center/payment/coding-plan</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h1 id=\"四安装-openclaw\">四、安装 OpenClaw</h1>\n<h2 id=\"一自动脚本安装推荐\">一）自动脚本安装（推荐）</h2>\n<p>这是最简单、最标准的安装方式。</p>\n<pre><code class=\"language-bash\"># 使用官方脚本安装 OpenClaw\ncurl -fsSL https://openclaw.ai/install.sh | bash\n</code></pre>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"二初始化配置\">二）初始化配置</h2>\n<p>运行自动脚本安装完成后，会自动进入配置向导，引导你完成以下设置：</p>\n<h4 id=\"1-风险告知\">1. 风险告知</h4>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h4 id=\"2-引导面板模式选择快速开始\">2. 引导面板模式：选择“快速开始”</h4>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h4 id=\"3-设置-ai-模型\">3. 设置 AI 模型</h4>\n<p>选择 AI 提供商：这里我们选择 <strong>MiniMax</strong>。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>选择模型：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>输入 API Key：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>选择默认模型：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h4 id=\"4-配置与-openclaw-通信的渠道\">4. 配置与 OpenClaw 通信的渠道</h4>\n<p>这里我们<strong>先选择跳过</strong>。本教程后续将使用 <strong>Discord</strong> 与 OpenClaw 通信。由于 Discord 配置稍显繁琐，后面会单独用一节详细讲解如何接入 Discord 机器人。你需要提前下载并注册好 Discord。如果觉得困难，也可选择飞书，详细配置可参考我上一篇文章：<a href=\"https://mp.weixin.qq.com/s/JGd4u8g-Fti4sRcJcSiOLQ\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/JGd4u8g-Fti4sRcJcSiOLQ</a>。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h4 id=\"5-配置-skills\">5. 配置 Skills</h4>\n<p>Skills 也先跳过，后续可通过 Web UI 界面配置：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h4 id=\"6-配置-hooks\">6. 配置 Hooks</h4>\n<p>Hooks 我们暂不需要配置。使用上下箭头选择 <strong>Skip for now</strong>，按下 <strong>空格键</strong> 选中，然后回车。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>此时开始自动安装 <strong>Gateway</strong> 服务：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>稍等片刻，Gateway 服务安装完成，开始选择启动机器人的方式：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>完成后，OpenClaw 会自动通过默认浏览器打开 Web UI 页面：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h1 id=\"五配置-discord-即时通信平台\">五、配置 Discord 即时通信平台</h1>\n<p>OpenClaw 支持多种通讯平台，本教程我们选择 <strong>Discord</strong>。</p>\n<h2 id=\"一注册账号并登录\">一）注册账号并登录</h2>\n<blockquote>\n<p>注意：你需要自行解决上网问题。</p>\n</blockquote>\n<p>官方地址：<a href=\"https://discord.com\" rel=\"noopener nofollow\" target=\"_blank\">https://discord.com</a></p>\n<h2 id=\"二创建一个服务器\">二）创建一个服务器</h2>\n<h3 id=\"1-点击添加服务器\">1. 点击“添加服务器”</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"2-选择亲自创建\">2. 选择“亲自创建”</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"3-选择仅供我和我的朋友使用\">3. 选择“仅供我和我的朋友使用”</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"4-自定义服务器名称\">4. 自定义服务器名称</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"三进入开发者后台\">三）进入开发者后台</h2>\n<p>访问地址：<a href=\"https://discord.com/developers/applications\" rel=\"noopener nofollow\" target=\"_blank\">https://discord.com/developers/applications</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"四创建应用\">四）创建应用</h2>\n<h3 id=\"1-点击创建应用\">1. 点击“创建应用”</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"2-输入应用名称\">2. 输入应用名称</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"3-自动跳转到通用信息页面\">3. 自动跳转到“通用信息”页面</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"4-获取-token\">4. 获取 Token</h3>\n<p>点击 <strong>Bot</strong> 菜单，然后点击 <strong>重置 Token</strong>。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"5-重置完成后复制你的-token\">5. 重置完成后，复制你的 Token</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"6-在当前页面继续向下滚动找到-message-content-intent-并启用\">6. 在当前页面继续向下滚动，找到 <code>Message Content Intent</code> 并启用</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"7-进入-oauth2-配置页面勾选-bot\">7. 进入 <strong>OAuth2</strong> 配置页面，勾选 <strong>Bot</strong></h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"8-继续向下滚动找到-bot-permissions勾选-send-messages-和-read-message-history\">8. 继续向下滚动，找到 <strong>Bot Permissions</strong>，勾选 <strong>Send Messages</strong> 和 <strong>Read Message History</strong></h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"9-滚动到底部复制生成的-bot-链接\">9. 滚动到底部，复制生成的 Bot 链接</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"10-将-bot-加入服务器\">10. 将 Bot 加入服务器</h3>\n<p>在浏览器中打开刚才复制的链接，选择一个服务器（相当于将创建的机器人加入该服务器），选择前面创建的自定义服务器。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>点击“授权”：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>授权成功：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>现在，你可以在自己创建的服务器中 @ 刚才添加的机器人了：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"五将-discord-接入-openclaw\">五）将 Discord 接入 OpenClaw</h2>\n<h3 id=\"1-进入-openclaw-配置\">1. 进入 OpenClaw 配置</h3>\n<p>执行以下命令：</p>\n<pre><code class=\"language-bash\">openclaw config\n</code></pre>\n<p>进入设置，选择“本地”：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>选择“渠道”：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>选择“配置连接”：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>选择 <strong>Discord</strong>：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>填入前面获取的 Bot Token：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>允许所有频道：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>选择“完成”：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>访问策略保持默认：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>配对模式也保持默认：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"2-启动网关服务\">2. 启动网关服务</h3>\n<p>执行以下命令启动网关服务：</p>\n<pre><code class=\"language-bash\">openclaw gateway\n</code></pre>\n<p>如果之前已启动过，请先执行 <code>openclaw gateway stop</code> 停止，再执行以上命令。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"3-将-discord-与-openclaw-配对\">3. 将 Discord 与 OpenClaw 配对</h3>\n<p>回到 Discord 创建的频道，点击右上角的“显示成员”，可以看到当前频道成员。点击我们添加的 Bot：OpenClaw。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>你会看到一个私聊输入框，可以试着发送一句话：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>此时会跳转到私信聊天界面，并显示一个<strong>配对码</strong>。复制这个配对码。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>打开一个新的终端窗口，输入以下命令：</p>\n<pre><code class=\"language-bash\">openclaw pairing approve discord &lt;Pairing code&gt;\n</code></pre>\n<p>将 <code>&lt;Pairing code&gt;</code> 替换为刚才复制的配对码。<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"4-重启网关服务\">4. 重启网关服务</h3>\n<p>回到启动网关的命令行窗口，按下 <code>Ctrl + C</code> 停止服务，然后重新启动：</p>\n<pre><code class=\"language-bash\">openclaw gateway\n</code></pre>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>请注意，这个命令行窗口不能关闭，否则服务会停止。如果希望后台静默运行（即使关闭窗口也不受影响），可以执行：</p>\n<pre><code class=\"language-bash\">nohup openclaw gateway --port 18789 --verbose &gt; /dev/null 2&gt;&amp;1 &amp;\n</code></pre>\n<h3 id=\"5-测试\">5. 测试</h3>\n<p>现在回到 Discord 的服务器频道，在频道中 @ 你创建的机器人：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>查看桌面文档的实际内容（示例）：<br />\n<img alt=\"\" class=\"lazyload\" /></p>\n<p>Discord 拥有多平台客户端，你也可以在手机上安装 Discord，通过手机指挥 OpenClaw 工作。</p>\n<p>至此，OpenClaw 已成功与 Discord 打通。现在你可以在 Discord 中通过与 Bot 对话的方式，指挥 OpenClaw 操控你的电脑了！</p>\n<h1 id=\"六常用命令\">六、常用命令</h1>\n<h3 id=\"gateway-管理\">Gateway 管理</h3>\n<pre><code class=\"language-bash\"># 启动 Gateway\nopenclaw gateway\n\n# 启动并显示详细日志\nopenclaw gateway --verbose\n\n# 指定端口启动\nopenclaw gateway --port 18789\n</code></pre>\n<h3 id=\"配置管理\">配置管理</h3>\n<pre><code class=\"language-bash\"># 运行配置向导\nopenclaw onboard\n\n# 系统健康检查\nopenclaw doctor\n\n# 查看配置\ncat ~/.openclaw/openclaw.json\n</code></pre>\n<h3 id=\"更新管理\">更新管理</h3>\n<pre><code class=\"language-bash\"># 更新到最新版本\nopenclaw update\n\n# 切换到特定频道\nopenclaw update --channel stable    # 稳定版\nopenclaw update --channel beta      # 测试版\nopenclaw update --channel dev       # 开发版\n</code></pre>\n<h1 id=\"结语\">结语</h1>\n<p>要想让 OpenClaw 出色地帮我们完成各种任务，还需要为它安装各种 Skills。<strong>点击头像关注我</strong>，接下来我会逐步分享 OpenClaw 的更多进阶玩法。</p>\n<p>也欢迎通过主页找到我，加入 <strong>OpenClaw 实战交流群</strong>，与更多创作者一起碰撞灵感、探索新奇玩法！</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 08:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/weipo0105\">阿坡RPA</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Laravel AI SDK 在 Laracon India 2026 首次亮相",
      "link": "https://www.cnblogs.com/catchadmin/p/19567163",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/catchadmin/p/19567163\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 07:40\">\n    <span>Laravel AI SDK 在 Laracon India 2026 首次亮相</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"laravel-ai-sdk-在-laracon-india-2026-首次亮相\">Laravel AI SDK 在 Laracon India 2026 首次亮相</h1>\n<p>2026 年 1 月 31 日，Taylor Otwell 在 Laracon India 2026 上首次公开展示了 Laravel AI SDK。这套他已开发数月的全新工具集，有望彻底改变 Laravel 应用中的 AI 集成方式。</p>\n<h2 id=\"什么是-laravel-ai-sdk\">什么是 Laravel AI SDK？</h2>\n<p>Laravel AI SDK 旨在大幅简化与各类 AI 服务商的交互，支持以下操作：</p>\n<ul>\n<li>获取类似 ChatGPT 的聊天机器人响应</li>\n<li>通过 embeddings 实现数据库语义搜索</li>\n<li>生成视频、音频和转录文本</li>\n<li>以及更多功能</li>\n</ul>\n<p>Taylor Otwell 的目标是提供优雅的 Laravel 语法和简洁的 API，无论你选择哪个 AI 服务商。实际使用时，只需调用 <code>agent()-&gt;prompt('你的请求...')</code> 即可获得结果。</p>\n<h2 id=\"配置-ai-服务商\">配置 AI 服务商</h2>\n<p>配置过程非常简单。在 <code>config/ai.php</code> 文件中，你可以为不同的服务商配置 API 密钥，如 Anthropic、OpenAI、Cohere、ElevenLabs 或 Gemini。</p>\n<p>SDK 还允许根据操作类型设置默认服务商：</p>\n<ul>\n<li><code>default</code> → openai</li>\n<li><code>default_for_images</code> → gemini</li>\n<li><code>default_for_audio</code> → openai</li>\n<li><code>default_for_transcription</code> → openai</li>\n<li><code>default_for_embeddings</code> → openai</li>\n<li><code>default_for_reranking</code> → cohere</li>\n</ul>\n<h2 id=\"基础用法调用-agent\">基础用法：调用 Agent</h2>\n<p>最简单的示例展示了这种极简方式的强大：</p>\n<pre><code class=\"language-php\">Route::get('/agent', function () {\n    $response = agent(\n        instructions: 'You are a helpful assistant.'\n    )-&gt;prompt('Tell me about Laravel in one sentence.');\n});\n</code></pre>\n<p>响应返回包含调用元数据的完整结构，包括使用的 token 数、服务商、模型，当然还有响应内容。</p>\n<h2 id=\"jsonschema-自定义数据结构\">JsonSchema 自定义数据结构</h2>\n<p>你可以通过提供 JSON Schema 精确定义返回结果的格式。这让你能够获得可直接在应用中使用的结构化数据。</p>\n<h2 id=\"队列处理与流式响应\">队列处理与流式响应</h2>\n<p>由于 LLM 响应可能需要一些时间，SDK 提供了两种优雅的选项：</p>\n<ul>\n<li><strong>队列处理</strong>：将请求委托给 Laravel Job</li>\n<li><strong>流式响应</strong>：逐字显示响应，就像传统聊天机器人一样</li>\n</ul>\n<p>这种灵活性与现有的 Laravel 生态系统完美集成。</p>\n<h2 id=\"图像生成\">图像生成</h2>\n<p>Laravel 的「开箱即用」理念在这里体现得淋漓尽致。你可以将 AI SDK 的新功能与 Laravel 现有功能（如队列和文件系统）结合使用。</p>\n<p>生成图像变得如此简单：</p>\n<pre><code class=\"language-php\">agent()-&gt;generateImage('prompt here')-&gt;store('path');\n</code></pre>\n<p>你甚至可以通过添加新的 AI 提示词来修改现有图像。</p>\n<h2 id=\"音频与转录\">音频与转录</h2>\n<p>与图像类似，SDK 允许通过 ElevenLabs 等服务商处理音频，无论是生成音频还是转录现有内容。</p>\n<h2 id=\"embeddings-与语义搜索\">Embeddings 与语义搜索</h2>\n<p>最令人印象深刻的功能之一是在项目中实现语义搜索的便捷性。</p>\n<p>例如，搜索 \"big boats\" 可以找到电影 \"Titanic\"，即使其描述中没有包含 \"boat\" 这个词。这就是 embeddings 的魔力。</p>\n<p>虽然底层实现复杂，但控制器端的代码依然简洁优雅。这个功能配合 PostgreSQL 效果最佳，因为 PostgreSQL 具有原生向量搜索功能，已在 Laravel 12 中新增支持。</p>\n<h2 id=\"agent-类\">Agent 类</h2>\n<p>SDK 将支持通过命令生成专用的 Agent 类：</p>\n<pre><code class=\"language-shell\">php artisan make:agent\n</code></pre>\n<p>这些类提供了丰富的配置选项，比如 <code>UseCheapestModel</code> 属性可以自动选择各服务商最经济的模型（haiku、nano 等）。</p>\n<p>Taylor 还展示了其他可配置的功能：</p>\n<ul>\n<li>Middleware</li>\n<li>自定义配置</li>\n<li>数据结构</li>\n<li>带 Schema 的工具</li>\n<li>网页搜索</li>\n</ul>\n<h2 id=\"发布计划\">发布计划</h2>\n<p>Laravel AI SDK 计划于本周四正式发布。这套全新工具集有望让 Laravel 应用中的 AI 集成变得像框架的其他部分一样简单优雅。</p>\n<p>这次演示再次证明了 Laravel 生态系统适应新技术的能力，同时保持其核心理念：让 Web 开发变得愉快且高效！</p>\n<p><a href=\"https://catchadmin.com/post/2026-02/laravel-ai-sdk\" rel=\"noopener nofollow\" target=\"_blank\">Laravel AI SDK 在 Laracon India 2026 首次亮相</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 07:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/catchadmin\">JaguarJack</a>&nbsp;\n阅读(<span id=\"post_view_count\">17</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "通过 DeepFlow 查询函数在 CPU 上消耗的时间（CPU 性能剖析）",
      "link": "https://www.cnblogs.com/manuscript/p/19565142",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/manuscript/p/19565142\" id=\"cb_post_title_url\" title=\"发布于 2026-02-03 05:07\">\n    <span>通过 DeepFlow 查询函数在 CPU 上消耗的时间（CPU 性能剖析）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>本文主要介绍 DeepFlow 的 AutoProfiling（on-cpu）持续性能剖析功能的配置与使用。该能力与 DeepFlow 的部署方式无关。自 v6.6.3 起，deepflow-agent 的配置格式有较大调整，本文使用新版本配置格式，建议使用 v7.0 LTS 或后续 LTS 版本。</p>\n<h1 id=\"cpu-剖析的配置与应用\">CPU 剖析的配置与应用</h1>\n<h2 id=\"前置条件\">前置条件</h2>\n<p>需要内核版本支持 eBPF 能力，DeepFlow 中开启 eBPF 能力（默认开启）所需内核版本要求如下：</p>\n<table>\n<thead>\n<tr>\n<th>体系架构</th>\n<th>发行版</th>\n<th>内核版本</th>\n<th>kprobe [1]</th>\n<th>Golang uprobe</th>\n<th>OpenSSL uprobe</th>\n<th>perf</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>X86</td>\n<td>CentOS 7.9</td>\n<td>3.10.0-940+ <strong>[2]</strong></td>\n<td>Y</td>\n<td>Y <strong>[3]</strong></td>\n<td>Y <strong>[3]</strong></td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>RedHat 7.6</td>\n<td>3.10.0-940+ <strong>[2]</strong></td>\n<td>Y</td>\n<td>Y <strong>[3]</strong></td>\n<td>Y <strong>[3]</strong></td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>*</td>\n<td>4.14 <strong>[4]</strong></td>\n<td>Y</td>\n<td>Y <strong>[3]</strong></td>\n<td>-</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>*</td>\n<td>4.15</td>\n<td>Y</td>\n<td>Y <strong>[3]</strong></td>\n<td>-</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>*</td>\n<td>4.16</td>\n<td>Y</td>\n<td>Y</td>\n<td>-</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>*</td>\n<td>4.17+</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>SUSE 12 SP5</td>\n<td>4.12 [5]</td>\n<td>Y</td>\n<td>Y</td>\n<td>-</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>ARM</td>\n<td>CentOS 8</td>\n<td>4.18</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>EulerOS</td>\n<td>5.10+</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>麒麟 KylinOS V10 SP1</td>\n<td>4.19.90-23 [6]</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>麒麟 KylinOS V10 SP2</td>\n<td>4.19.90-25.24+ [7]</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>麒麟 KylinOS V10 SP3</td>\n<td>4.19.90-52.24+</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td></td>\n<td>其他发行版</td>\n<td>5.8+</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n</tbody>\n</table>\n<p>对内核版本的补充说明：</p>\n<ul>\n<li>[1]：在 Linux 启用了 BTF（BPF Type Format）的情况下，X86 架构内核版本大于等于 <a href=\"https://github.com/torvalds/linux/commit/f1b9509c2fb0ef4db8d22dac9aef8e856a5d81f6\" rel=\"noopener nofollow\" target=\"_blank\">5.5</a>、ARM 架构内核版本大于等于 <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?h=linux-6.0.y&amp;id=efc9909fdce00a827a37609628223cd45bf95d0b\" rel=\"noopener nofollow\" target=\"_blank\">6.0</a> 时，agent 将自动使用 fentry/fexit 替代 kprobe/kretprobe，可获得约 15% 的性能提升。</li>\n<li>[2]：CentOS 7.9、RedHat 7.6 向 3.10 内核中<a href=\"https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7\" rel=\"noopener nofollow\" target=\"_blank\">移植了一部分 eBPF 能力</a>。\n<ul>\n<li>在这两个发行版中，DeepFlow 支持的详细内核版本如下（<a href=\"https://github.com/deepflowio/deepflow/blob/main/agent/src/ebpf/docs/probes-and-maps.md\" rel=\"noopener nofollow\" target=\"_blank\">依赖的 Hook 点</a>）：\n<ul>\n<li>3.10.0-957.el7.x86_64</li>\n<li>3.10.0-1062.el7.x86_64</li>\n<li>3.10.0-1127.el7.x86_64</li>\n<li>3.10.0-1160.el7.x86_64</li>\n</ul>\n</li>\n<li>注意 RedHat 的声明：\n<blockquote>\n<p>The eBPF in Red Hat Enterprise Linux 7.6 is provided as Tech Preview and thus doesn't come with full support and is not suitable for deployment in production. It is provided with the primary goal to gain wider exposure, and potentially move to full support in the future. eBPF in Red Hat Enterprise Linux 7.6 is enabled only for tracing purposes, which allows attaching eBPF programs to probes, tracepoints and perf events.</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>[3]：容器内的 Golang/OpenSSL 进程不支持。</li>\n<li>[4]：在内核 4.14 中，一个 tracepoint 不能被多个 eBPF program attach（例如不能同时运行两个或多个 deepflow-agent）。其他版本不存在该问题。</li>\n<li>[5]：目前支持 SUSE 12 SP5 4.12.14，但 Linux 社区的 4.12 版本依然不支持。</li>\n<li>[6]：KylinOS V10 SP1 部分内核（例如 4.19.90-23.48.v2101.ky10.aarch64）可正常运行，但不确保 KylinOS V10 SP1 所有 aarch64 架构内核都能正常运行 deepflow-agent。</li>\n<li>[7]：KylinOS V10 SP2 某些内核（如 4.19.90-24.4.v2101.ky10.aarch64）由于不支持 <code>bpf_probe_read_user()</code>，无法读取用户态数据，因此不支持 AutoTracing；但支持持续剖析和文件读写追踪功能。</li>\n</ul>\n<h2 id=\"支持语言\">支持语言</h2>\n<table>\n<thead>\n<tr>\n<th>类型</th>\n<th>支持语言/库</th>\n<th>社区版</th>\n<th>企业版</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>on-cpu</td>\n<td>Java</td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>C/C++</td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Rust</td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Golang</td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Python <code>***</code></td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>CUDA</td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Lua <code>*</code></td>\n<td>✔</td>\n<td>✔</td>\n</tr>\n<tr>\n<td>off-cpu</td>\n<td>Java</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>C/C++</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Rust</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Golang</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Python <code>***</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>CUDA</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Lua <code>*</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td>on-gpu</td>\n<td>CUDA <code>*</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td>mem-alloc</td>\n<td>Java <code>**</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Rust</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Golang <code>*</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td></td>\n<td>Python <code>*</code> <code>***</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td>mem-inuse</td>\n<td>Rust</td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td>hbm-alloc</td>\n<td>CUDA <code>*</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td>hbm-inuse</td>\n<td>CUDA <code>*</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n<tr>\n<td>rdma</td>\n<td>C/C++ <code>*</code></td>\n<td></td>\n<td>✔</td>\n</tr>\n</tbody>\n</table>\n<p>说明：</p>\n<ul>\n<li><code>*</code>：开发中的功能（尚未正式发布）</li>\n<li><code>**</code>：运行 Java 程序的 JVM 必须包含符号表，参考下文的 JVM 符号表检查</li>\n<li><code>***</code>：当前支持版本为 Python 3.10</li>\n<li>语言分类：\n<ul>\n<li>编译为 ELF 格式可执行文件的语言：Golang、Rust、C/C++</li>\n<li>使用 JVM 虚拟机的语言：Java</li>\n<li>解释型语言：Python</li>\n</ul>\n</li>\n</ul>\n<p>获取 Profiling 数据需满足两个前提条件：</p>\n<ul>\n<li>应用进程需要开启 Frame Pointer，或启用 Agent 的 DWARF 栈回溯能力\n<ul>\n<li>应用进程开启 Frame Pointer（帧指针寄存器）：\n<ul>\n<li>编译 C/C++：<code>gcc -fno-omit-frame-pointer</code></li>\n<li>编译 Rust：<code>RUSTFLAGS=\"-C force-frame-pointers=yes\"</code></li>\n<li>编译 Golang：默认开启，无需额外编译参数</li>\n<li>运行 Java：<code>-XX:+PreserveFramePointer</code>\n<ul>\n<li>开启该参数会禁用某些编译器优化，不过根据 <a href=\"https://netflixtechblog.com/java-in-flames-e763b3d32166\" rel=\"noopener nofollow\" target=\"_blank\">Netflix</a> 和 <a href=\"https://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html\" rel=\"noopener nofollow\" target=\"_blank\">Brendan Gregg</a> 的实测结果，通常只会引入 &lt;1% 的性能损耗。Netflix 早在 2015 年起已在生产环境大规模使用，以支撑其 Java 程序的日常性能分析。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>启用 Agent 的 DWARF 栈回溯能力请参考<a href=\"https://www.deepflow.io/docs/zh/configuration/agent/#inputs.ebpf.profile.unwinding\" rel=\"noopener nofollow\" target=\"_blank\">文档</a></li>\n</ul>\n</li>\n<li>对于编译型语言的应用进程，编译时需要注意保留符号表</li>\n</ul>\n<h3 id=\"jvm-符号表检查\">JVM 符号表检查</h3>\n<pre><code class=\"language-bash\"># 1) 查找需要进行内存剖析的 Java 进程号，记为 $pid\n\n# 2) 查看进程加载的 libjvm.so 所在位置，记为 $path\ngrep libjvm.so /proc/$pid/maps\n\n# 3) 检查该文件是否包含符号表\nreadelf -WS $path | grep symtab\n</code></pre>\n<h2 id=\"配置方式\">配置方式</h2>\n<p>配置前需要注意：<a href=\"https://github.com/deepflowio/deepflow/blob/main/agent/config/deepflow-agent.yaml\" rel=\"noopener nofollow\" target=\"_blank\" title=\"deepflow-agent\">deepflow-agent</a> 的 ConfigMap 仅用于 agent 向 server 注册；而下方的 agent 自身配置需要通过 <a href=\"https://www.deepflow.io/docs/zh/best-practice/agent-advanced-config/\" rel=\"noopener nofollow\" target=\"_blank\" title=\"deepflow-ctl\">deepflow-ctl</a> 下发。</p>\n<blockquote>\n<p>注：CPU 剖析还有一些未出现在下方示例中的参数。如果你不确定修改后会产生什么影响，建议保持默认值。</p>\n</blockquote>\n<pre><code class=\"language-yaml\">inputs:\n  proc:\n    enabled: true\n    process_matcher:\n      # 功能列表，默认开关参考链接中的详细描述：\n      # https://www.deepflow.io/docs/zh/configuration/agent/#inputs.proc.process_matcher.enabled_features\n      - enabled_features:\n          - ebpf.profile.on_cpu\n          - proc.gprocess_info\n        # Rust 正则规则：\n        # https://regex101.com/\n        match_regex: \\bjava( +\\S+)* +-jar +(\\S*/)*([^ /]+\\.jar)\n        # 匹配形式，参考详细描述：\n        # https://www.deepflow.io/docs/zh/configuration/agent/#inputs.proc.process_matcher\n        match_type: cmdline_with_args\n        # 是否仅匹配容器内的进程：\n        # https://www.deepflow.io/docs/zh/configuration/agent/#inputs.proc.process_matcher.only_in_container\n        only_in_container: false\n        # 将匹配到的第三段 ([^ /]+\\.jar) 内容作为名称（一般为 jar 包名）\n        # 例如：shop-web-0.0.1-SNAPSHOT.jar\n        rewrite_name: $3\n      - enabled_features:\n          - ebpf.profile.on_cpu\n          - proc.gprocess_info\n          - proc.socket_list\n        match_regex: ^(cartservice|checkoutservice|shippingservice|coredns|mysqld|deepflow-server|deepflow-agent|stress-ng|cpu-demo)\n        only_in_container: false\n</code></pre>\n<h2 id=\"校验结果\">校验结果</h2>\n<ol>\n<li>\n<p>查看当前的 Java Demo PID</p>\n<pre><code class=\"language-bash\">root@ce-demo-1:~# kubectl get pods -n deepflow-otel-spring-demo web-shop-7c48fd68dc-szchh -o wide\nNAME                        READY   STATUS    RESTARTS   AGE   IP               NODE        NOMINATED NODE   READINESS GATES\nweb-shop-7c48fd68dc-szchh   1/1     Running   0          83d   10.244.228.165   ce-demo-2   &lt;none&gt;           &lt;none&gt;\n\nroot@ce-demo-1:~# kubectl exec -n deepflow-otel-spring-demo web-shop-7c48fd68dc-szchh -c web-shop -- ps aux\nPID   USER     TIME  COMMAND\n  1   root     0:00  sh /home/docker-entrypoint.sh -javaagent:/sidecar/agent/opentelemetry-javaagent.jar -Dotel.resource.attributes=service.name=shop-web -Dotel.traces.exporter=otlp -Dotel.metrics.exporter=none -jar /home/shop-web-0.0.1-SNAPSHOT.jar\n  7   root     1d13  java -javaagent:/sidecar/agent/opentelemetry-javaagent.jar -Dotel.resource.attributes=service.name=shop-web -Dotel.traces.exporter=otlp -Dotel.metrics.exporter=none -jar /home/shop-web-0.0.1-SNAPSHOT.jar\n\nroot@ce-demo-1:~# ssh ce-demo-2 'ps aux | grep shop-web-0.0.1-SNAPSHOT.jar'\nroot     2684642  2.0  2.4 8348252 406656 ?      Sl    2025 2430:21 java -javaagent:/sidecar/agent/opentelemetry-javaagent.jar -Dotel.resource.attributes=service.name=shop-web -Dotel.traces.exporter=otlp -Dotel.metrics.exporter=none -jar /home/shop-web-0.0.1-SNAPSHOT.jar\n</code></pre>\n</li>\n<li>\n<p>在 ClickHouse 中通过上一步的 PID 查询 DeepFlow 标签信息</p>\n<pre><code class=\"language-sql\">root@ce-demo-1:~# kubectl exec -it -n deepflow deepflow-clickhouse-0 -c clickhouse -- bash\nroot@deepflow-clickhouse-0:/# clickhouse client\nClickHouse client version 23.10.4.25 (official build).\nConnecting to localhost:9000 as user default.\nConnected to ClickHouse server version 23.10.4 revision 54466.\n\ndeepflow-clickhouse-0.deepflow-clickhouse-headless.deepflow.svc.cluster.local :)\n\n-- 通过 PID 查询对应进程在 DeepFlow 中的 tag 信息\nSELECT gprocess_id, app_service\nFROM `profile`.`in_process`\nWHERE process_id = 2684642\nLIMIT 1;\n\n┌─gprocess_id─┬─app_service─┐\n│         123 │ java        │\n└─────────────┴─────────────┘\n\n-- 通过 gprocess_id 查询 rewrite_name 是否生效\nSELECT *\nFROM `flow_tag`.`gprocess_map`\nWHERE id = 123\nLIMIT 1;\n\n┌──id─┬─name────────────────────────┬─icon_id─┬─chost_id─┬─l3_epc_id─┬─team_id─┬─domain_id─┬─sub_domain_id─┐\n│ 123 │ shop-web-0.0.1-SNAPSHOT.jar │       0 │        2 │         1 │       1 │         1 │             0 │\n└─────┴─────────────────────────────┴─────────┴──────────┴───────────┴─────────┴───────────┴───────────────┘\n</code></pre>\n</li>\n<li>\n<p>查看 Continuous Profiling Dashboard 中对应 Demo 的剖析效果</p>\n<p><img alt=\"img_v3_02uh_57e28e17-0461-40f0-80ff-04c08ff61a2g\" src=\"https://img2024.cnblogs.com/blog/3735354/202602/3735354-20260202154119936-1275480608.png\" /></p>\n<p>字段说明：</p>\n<ul>\n<li>auto_service：举例说明，目前业务部署方式为 Deployment，此处依据 k8s svc name &gt; deployment name 填写</li>\n</ul>\n</li>\n<li>\n<p>函数类型对应关系</p>\n<table>\n<thead>\n<tr>\n<th>Function Type</th>\n<th>含义</th>\n<th>Profile Event Type</th>\n<th>特征</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>O</td>\n<td>对象类型</td>\n<td><code>mem-*</code></td>\n<td>Memory Profile 的叶子节点</td>\n</tr>\n<tr>\n<td>H</td>\n<td>云主机</td>\n<td><code>*</code></td>\n<td>等于 <code>Total</code> 的根节点</td>\n</tr>\n<tr>\n<td>P</td>\n<td>进程</td>\n<td><code>*</code></td>\n<td>以 <code>[p]</code> 开头，且不等于 <code>Total</code> 的根节点</td>\n</tr>\n<tr>\n<td>T</td>\n<td>线程</td>\n<td><code>*</code></td>\n<td>以 <code>[t]</code> 开头</td>\n</tr>\n<tr>\n<td>K</td>\n<td>内核函数</td>\n<td><code>*</code></td>\n<td>以 <code>[k]</code> 开头</td>\n</tr>\n<tr>\n<td>C</td>\n<td>CUDA 驱动函数</td>\n<td><code>*</code></td>\n<td>以 <code>[c]</code> 开头</td>\n</tr>\n<tr>\n<td>L</td>\n<td>动态链接库函数</td>\n<td><code>*</code></td>\n<td>以 <code>[l]</code> 开头</td>\n</tr>\n<tr>\n<td>?</td>\n<td>未知函数</td>\n<td><code>*</code></td>\n<td>其他以 <code>[</code> 开头</td>\n</tr>\n<tr>\n<td>A</td>\n<td>应用函数</td>\n<td><code>*</code></td>\n<td>除以上之外的函数</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>\n<p>通过 API 查询数据</p>\n<p>参考 DeepFlow <a href=\"https://www.deepflow.io/docs/zh/features/continuous-profiling/data/#api\" rel=\"noopener nofollow\" target=\"_blank\" title=\"官方文档\">官方文档</a>中 API 的使用方式。</p>\n</li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-03 05:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/manuscript\">怎么还在写代码</a>&nbsp;\n阅读(<span id=\"post_view_count\">20</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}