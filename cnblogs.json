{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "凸优化数学基础笔记（四）：Hessian 矩阵及 Taylor 展开",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19624189",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19624189\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 09:48\">\n    <span>凸优化数学基础笔记（四）：Hessian 矩阵及 Taylor 展开</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        上一节说过，梯度 $\\nabla f(\\mathbf{X})$ 是$f(\\mathbf{X})$ 关于$\\mathbf{X}$ 的一阶导数，现在一个问题$f(\\mathbf{X})$ 关于 $\\mathbf{X}$ 的二阶导数是什么？Hessian 矩阵（海森矩阵）是一个多变量实值函数$f(\\mathbf{X})$的二阶导数构成得方阵，其几何意义是描述了一个多元函数或场函数的局部曲率。在机器学习、优化问题和物理反演问题中，Hessian矩阵扮演着重要的角色，尤其是在寻找函数的极值点（如损失函数或目标函数的最小值）和分析系统的稳定性。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1hessian矩阵定义及性质\">1.Hessian矩阵定义及性质</h2>\n<p>​\t在上一节说过，梯度 <span class=\"math inline\">\\(\\nabla f(\\mathbf{X})\\)</span> 是<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的一阶导数，现在一个问题<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于 <span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的二阶导数是什么？Hessian 矩阵（海森矩阵）是一个多变量实值函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span>的二阶导数构成得方阵，其几何意义是描述了一个多元函数或场函数的局部曲率。在机器学习、优化问题和物理反演问题中，Hessian矩阵扮演着重要的角色，尤其是在寻找函数的极值点（如损失函数或目标函数的最小值）和分析系统的稳定性。下面是关于Hessian矩阵的详细介绍：</p>\n<p>​\t<strong>Definition 4.1.1</strong>  设<span class=\"math inline\">\\(f:\\mathbb{R}^n\\rightarrow{\\mathbb{R}}\\)</span> , <span class=\"math inline\">\\(\\mathbf{X}\\in{R}^n\\)</span> ,如果<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处对于自变量<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的各个分量<span class=\"math inline\">\\(x_i,x_j\\)</span> 的二阶偏导</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{x_i}\\part{x_j}} \t\t\\hspace{2em} (i,j=1,2,...,n)\n\\]</div><p></p><p>都存在，则称函数<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处二阶可导，并且称矩阵：</p>\n<p></p><div class=\"math display\">\\[\\nabla^2f(\\mathbf{X}_0)=\\left(\\begin{matrix}\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1^2}},&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1}\\part{x_2}},&amp;\\cdots,&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1}\\part{x_n}}\\\\ \n\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1}\\part{x_2}},&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_2^2}},&amp;\\cdots,&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_2}\\part{x_n}}\\\\\n\\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots \\\\\n\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_n}\\part{x_1}},&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_n}\\part{x_2}},&amp;\\cdots,&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_n}^2}\n\\end{matrix}\\right)\n\\tag{2}\n\\]</div><p></p><p>是<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的<strong>Hessian矩阵</strong>，记为<span class=\"math inline\">\\(\\mathbf{H}_{ij}=\\frac{\\part^2{f}}{\\part{x_i}\\part{x_j}}\\)</span>。</p>\n<p>​\t在数学分析中已经知道，当<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的所有二阶偏导数为连续时有：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_i}\\part{x_j}}=\\frac{\\part^2{f(\\mathbf{X}_0)}}{\\part{x_j}\\part{x_i}} \\tag{3}\n\\]</div><p></p><p>因此，在这种情况下Hessian矩阵是<strong>对称矩阵</strong>。</p>\n<p><strong>推论 1</strong> 设<span class=\"math inline\">\\(\\mathbf{a}\\in{\\mathbf{R}^n},\\mathbf{X}\\in{\\mathbf{R}^n},b\\in{R}\\)</span>，求线性函数：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X})=\\mathbf{a}^T\\mathbf{X}+b\\tag{4}\n\\]</div><p></p><p>在任意点<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 处的梯度向量和Hessian矩阵：</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n&amp;\\nabla{f(\\mathbf{X})}=\\mathbf{a}\\\\\n&amp;\\nabla^2{f(\\mathbf{X})}=\\mathbf{0}\n\\end{aligned}\n\\tag{5}\n\\]</div><p></p><p><strong>证  明：</strong> 设<span class=\"math inline\">\\(\\mathbf{a}=[a_1,a_2,\\cdots,a_n]^{T},\\mathbf{X}=[x_1,x_2,\\cdots,x_n]^{T}\\)</span> 则：</p>\n<p></p><div class=\"math display\">\\[f(x_1,x_2,\\cdots,x_n)=\\sum^{n}_{i=1}a_ix_i+b \\tag{6}\n\\]</div><p></p><p>根据梯度向量<span class=\"math inline\">\\(\\nabla{f}\\)</span>的定义：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\frac{\\part{f}}{\\part{x_i}}=a_i \\hspace{2em} (i=1,2,\\cdots,n) \\tag{7}\n\\]</div><p></p><p>由式（7）可知，</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=[a_1,a_2,\\cdots,a_n]^T=\\mathbf{a} \\tag{8}\n\\]</div><p></p><p>根据式（2）的<span class=\"math inline\">\\(Hessian\\)</span>矩阵的定义：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part^2{f}}{\\part{x_i}\\part{x_j}}=0, \\hspace{2em} i,j=1,2,\\cdots,n \\tag{9}\n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[\\nabla^2{f(\\mathbf{X})}=\\mathbf{0} \\tag{10}\n\\]</div><p></p><p><strong>推论  2</strong>  设<span class=\"math inline\">\\(\\mathbf{A}\\in{R^{n\\times{n}}}\\)</span> 是对称实方阵，<span class=\"math inline\">\\(\\mathbf{b}\\in{\\mathbf{R}^n},c\\in\\mathbf{R}^1\\)</span> ,其二次函数<span class=\"math inline\">\\(f(\\mathbf{X})=\\frac{1}{2}\\mathbf{X}^T\\mathbf{A}\\mathbf{X}+\\mathbf{b}^T\\mathbf{X}+c\\)</span> ,在任意点处的梯度向量<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X})}\\)</span> 及Hessian矩阵 <span class=\"math inline\">\\(\\nabla^2f(\\mathbf{X})\\)</span> 为如下形式：</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n&amp;\\nabla{f}=\\mathbf{AX+b} \\\\\n&amp;\\nabla^2{f}=\\mathbf{A}\n\\end{aligned}\n\\tag{11}\n\\]</div><p></p><p><strong>证 明：</strong> 设<span class=\"math inline\">\\(\\mathbf{A}=[a_{ij}]_{n\\times{n}}\\)</span> ,<span class=\"math inline\">\\(\\mathbf{X}=[x_1,x_2,...,x_n]^T\\)</span>, <span class=\"math inline\">\\(\\mathbf{b}=[b_1,b_2,...,b_n]^T\\)</span> ,二次函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 可以写成如下形式：</p>\n<p></p><div class=\"math display\">\\[f(x_1,x_2,\\cdots,x_n)=\\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}a_{ij}x_ix_j+\\sum_{i=1}^{n}b_ix_i+c \\tag{12}\n\\]</div><p></p><p>将它对各个变量 <span class=\"math inline\">\\(x_i\\)</span> (<span class=\"math inline\">\\(i=1,\\cdots,n\\)</span>) 求偏导数，得到：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left( \\begin{matrix} \\sum_{j=1}^n a_{1j}x_j+b_1\\\\\n\\vdots \\\\\\sum_{j=1}^{n}a_{n_j}x_j+b_n \\end{matrix} \\right)= \\left(\\begin{matrix}\\sum_{j=1}^{n}a_{1j}x_j\\\\\\vdots\\\\\\sum_{j=1}^na_{nj}x_j\\end{matrix}\\right)+\\left(\\begin{matrix}b_1\\\\ \\vdots \\\\b_n\\end{matrix}\\right) \\tag{13}\n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\mathbf{AX+b} \\tag{14}\n\\]</div><p></p><p>再对它们的求偏导数是：</p>\n<p></p><div class=\"math display\">\\[ \\frac{\\part{f(\\mathbf{X})}}{\\part{x_i}\\part{x_j}}=a_{ij} \\tag{15}\n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[\\nabla^2f(\\mathbf{X})=\\mathbf{A} \\tag{16}\n\\]</div><p></p><p>以上两个例子说明，<span class=\"math inline\">\\(n\\)</span>元函数求导与一元函数求导在形式上一致的，即线性函数的一阶导数的求导为常向量，其二阶导数为零矩阵；而二次函数的一阶导数为线性向量函数， 其二阶导数为常矩阵。</p>\n<p>​\t在此介绍在今后的计算中要用到的向量函数的导数。</p>\n<p>​\t<strong>Definition 4.1.2</strong> 设一个向量函数<span class=\"math inline\">\\(h:R^{n}\\rightarrow{R^m}，\\mathbf{X}_0\\in{R^n}\\)</span>，记<span class=\"math inline\">\\(h(\\mathbf{X})=\\{h_1(\\mathbf{X}),h_2(\\mathbf{X}),\\cdots,h_m(\\mathbf{X})\\}^T\\)</span>，如果<span class=\"math inline\">\\(h_i(i=1,2,\\cdots,m)\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处对于自变量<span class=\"math inline\">\\(\\mathbf{X}=[x_1,x_2,x_3,\\cdots,x_n]^T\\)</span> 的各分量的偏导数<span class=\"math inline\">\\(\\frac{\\part{h_i(\\mathbf{X}_0)}}{\\part{x_j}}\\space(j=1,2,3,\\cdots,m)\\)</span> 都存在，则称向量函数<span class=\"math inline\">\\(h(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处是一阶可导的，并且称矩阵：</p>\n<p></p><div class=\"math display\">\\[\\nabla_{m\\times{n}}h(\\mathbf{X}_0)=\\left[\\begin{matrix} \\frac{\\part{h_1(\\mathbf{X}_0)}}{\\part{x_1}} &amp;\\frac{\\part{h_1(\\mathbf{X}_0)}}{\\part{x_2}} &amp;\\cdots &amp;\\frac{\\part{h_1(\\mathbf{X}_0)}}{\\part{x_n}} \\\\ \\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_1}} &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_2}} &amp;\\cdots &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_n}}\\\\ \\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots \\\\ \\frac{\\part{h_m(\\mathbf{X}_0)}}{\\part{x_1}}   &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_2}} &amp;\\cdots &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_n}} \\end{matrix}\\right] \\tag{17}\n\\]</div><p></p><p>是<span class=\"math inline\">\\(h\\)</span>在点<span class=\"math inline\">\\(X_0\\)</span> 处的一阶导数或Jacobi 矩阵，简记为</p>\n<p></p><div class=\"math display\">\\[\\nabla{\\mathbf{h}(\\mathbf{X}_0)}=\\nabla_{m\\times{n}}\\mathbf{h}(\\mathbf{X}_0) \\tag{18}\n\\]</div><p></p><p>由于<span class=\"math inline\">\\(n\\)</span>元函数<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow \\mathbf{R}^1\\)</span> 的梯度是向量函数:</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left[\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}},...,\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right]^T \n\\tag{19}\n\\]</div><p></p><p>所以<span class=\"math inline\">\\(\\nabla f(\\mathbf{X})\\)</span> 的一阶导数或Jacobi 矩阵为：</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n\\nabla_{n\\times{n}}\\nabla{f(\\mathbf{X})}&amp;=\\left[\\begin{matrix}\\frac{\\part}{\\part{x_1}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}}\\right) &amp;\\frac{\\part}{\\part{x_2}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}}\\right) &amp;\\cdots &amp;\\frac{\\part}{\\part{x_n}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}}\\right)\\\\\n\\frac{\\part}{\\part{x_1}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_2}}\\right) &amp;\\frac{\\part}{\\part{x_2}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_2}}\\right) &amp;\\cdots &amp;\\frac{\\part}{\\part{x_n}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_2}}\\right)\\\\\n\\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots \\\\\n\\frac{\\part}{\\part{x_1}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right) &amp;\\frac{\\part}{\\part{x_2}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right) &amp;\\cdots &amp;\\frac{\\part}{\\part{x_n}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right)\n\\end{matrix}\\right]\\\\\n&amp;=\\left[\\begin{matrix}\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1^2}} &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_2}} &amp;\\cdots &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_n}}\\\\\n\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_2}} &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_2^2}} &amp;\\cdots &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_2x_n}}\\\\\n\\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots\\\\\n\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_n}} &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_2x_n}} &amp;\\cdots &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_n^2}}\n\\end{matrix}\\right]\\\\\n&amp;=\\nabla^2{f(\\mathbf{X})}\n\\end{aligned}\n\\tag{20}\n\\]</div><p></p><p>即：</p>\n<p></p><div class=\"math display\">\\[\\nabla_{n\\times{n}}\\nabla{f(\\mathbf{X})}=\\nabla^2f(\\mathbf{X}) \\tag{21}\n\\]</div><p></p><p>据此，从上式的得知，函数梯度的Jacobi的矩阵为此函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 的Hessian矩阵。</p>\n<p>下面给出常用Jacobi矩阵的几个公式和推论：</p>\n<ol>\n<li><span class=\"math inline\">\\(\\nabla{\\mathbf{c}_{n\\times1}}=\\mathbf{0}_{n\\times{n}}\\)</span> ，其中<span class=\"math inline\">\\(\\mathbf{c}\\)</span> 是分量全部为常量的<span class=\"math inline\">\\(n\\)</span>维向量，<span class=\"math inline\">\\(\\mathbf{0}\\)</span> 是<span class=\"math inline\">\\(n\\times{n}\\)</span> 阶零向量；</li>\n<li><span class=\"math inline\">\\(\\nabla{\\mathbf{X}}=\\mathbf{I}\\)</span>，其中<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 是<span class=\"math inline\">\\(n\\)</span>维向量，<span class=\"math inline\">\\(I\\)</span> 为<span class=\"math inline\">\\(n\\times{n}\\)</span> 阶单位矩阵；</li>\n<li><span class=\"math inline\">\\(\\nabla{\\mathbf{AX}}=\\mathbf{A}^T\\)</span>，其中<span class=\"math inline\">\\(\\mathbf{A}\\)</span>是<span class=\"math inline\">\\(m\\times{n}\\)</span>阶矩阵；</li>\n<li>设 <span class=\"math inline\">\\(\\phi{(t)}=f(\\mathbf{X}_0+t\\mathbf{P})\\)</span>，其中<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow\\mathbf{R}^{1}\\)</span>, <span class=\"math inline\">\\(\\phi:\\mathbf{R}\\rightarrow\\mathbf{R}\\)</span>，则<span class=\"math inline\">\\(\\phi^{\\prime}(t)=\\nabla f(\\mathbf{X}_0+t\\mathbf{P})^T\\mathbf{P}\\)</span>, <span class=\"math inline\">\\(\\phi^{\\prime\\prime}=\\mathbf{P}^T\\nabla^2{f(\\mathbf{X}_0+t\\mathbf{P})}\\mathbf{P}\\)</span></li>\n</ol>\n<h2 id=\"2多元函数的taylor展开\">2.多元函数的Taylor展开</h2>\n<p>​\t多元函数的Taylor展开式在最优化方法中是十分重要的，许多方法及其收敛方法的证明是从其出发，这里给出Taylor展开定理及其证明。Taylor展开近似可以有效地将复杂函数化为二次函数。</p>\n<p>​\t<strong>定 理 4.2.1</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^{n}\\rightarrow\\mathbf{R}\\)</span> 具有二阶连续偏导数，则</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X}+\\mathbf{P})=f(\\mathbf{X})+\\nabla{f(\\mathbf{X})}^T\\mathbf{P}+\\frac{1}{2}\\mathbf{P}^T\\nabla^2f(\\overline{\\mathbf{X}})\\mathbf{P} \\tag{22}\n\\]</div><p></p><p>其中：<span class=\"math inline\">\\(\\overline{\\mathbf{X}}=\\mathbf{X}+\\theta\\mathbf{P}(\\theta\\in{(0,1)})\\)</span>。</p>\n<p><strong>证  明</strong>：设 <span class=\"math inline\">\\(\\psi(t)=f(\\mathbf{X}+t\\mathbf{P})\\)</span> 其中 <span class=\"math inline\">\\(t\\in[0,1]\\)</span>:</p>\n<p></p><div class=\"math display\">\\[\\psi(0)=f(\\mathbf{X}) ， \\psi(1)=f(\\mathbf{X}+\\mathbf{P}) \\tag{23}\n\\]</div><p></p><p>对<span class=\"math inline\">\\(\\psi(t)\\)</span> 按照一元函数在<span class=\"math inline\">\\(t=0\\)</span>点展开，得到下式：</p>\n<p></p><div class=\"math display\">\\[   \\psi(t)=\\psi(0)+\\psi^{\\prime}(0)t+\\frac{1}{2}\\psi^{\\prime\\prime}(\\theta t)t^2 \\tag{24}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(\\theta\\in(0,1)\\)</span>。令<span class=\"math inline\">\\(t=1\\)</span>，于是</p>\n<p></p><div class=\"math display\">\\[\\psi(1)=\\psi(0)+\\psi^{\\prime}(0)+\\frac{1}{2}\\psi^{\\prime\\prime}(\\theta) \\tag{25}\n\\]</div><p></p><p>又因为上节中 <span class=\"math inline\">\\(\\psi^{\\prime}(\\theta)=\\nabla{f(\\mathbf{X})}^T\\mathbf{P},\\psi^{\\prime\\prime}(\\theta)=\\mathbf{P}^T\\nabla^2f(\\mathbf{X}+\\theta{\\mathbf{P}})\\mathbf{P}\\)</span> ，代入式（25）中得到：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X}+\\mathbf{P})=f(\\mathbf{X})+\\nabla{f(\\mathbf{X})}^T\\mathbf{P}+\\frac{1}{2}\\mathbf{P}^T\\nabla^2f(\\mathbf{X}+\\theta\\mathbf{P})\\mathbf{P} \\tag{26}\n\\]</div><p></p><p>式（26）还可以写成：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X}+\\mathbf{P})=f(\\mathbf{X})+\\nabla{f(\\mathbf{X})}^{T}\\mathbf{P}+\\frac{1}{2}\\mathbf{P}^T\\nabla^2f(\\mathbf{X})\\mathbf{P}+o(||\\mathbf{P}||^2) \\tag{27}\n\\]</div><p></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 09:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从春晚机器人，看中国未来百年的养老之路",
      "link": "https://www.cnblogs.com/xdesigner/p/19621864",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xdesigner/p/19621864\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 19:03\">\n    <span>从春晚机器人，看中国未来百年的养老之路</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"postText\">    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        未来一百年，中国会走一条：人口适度、科技强大、产业高效、养老普惠的道路。科技让生活更安稳，让养老更有尊严，让国家发展更可持续。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"从春晚机器人看中国未来百年的养老之路\">从春晚机器人，看中国未来百年的养老之路</h1>\n<p>2026年春晚的武术机器人节目，整齐划一的动作、稳定的平衡能力，让人印象深刻。节目播出后，社交媒体上出现大量热议。一个突出的声音是，不少年轻人留言并相互回复讨论：“以后不生小孩了，把钱存起来，等老了直接买机器人养老。”</p>\n<p>这话乍听像玩笑，细想却很有深意。它触及了一个正在发生的根本变化：当科技足够先进，传统的“养儿防老”模式，正在被一种新的可能所替代。但这种替代不会一蹴而就——在机器人真正普及之前，中国将面临一个10到20年的“危险平衡期”。</p>\n<h2 id=\"一未富先老我们面临的现实压力\">一、未富先老：我们面临的现实压力</h2>\n<p>春晚机器人展示的运动控制和精准操作能力，恰恰是养老场景中最需要的技术。但问题的紧迫性在于，老龄化正在加速，而机器人技术尚未完全成熟。</p>\n<p>一组数据可以说明现状：目前我国60岁及以上人口已达3.1亿，占总人口的22%。其中失能老人约3500万，而专业护理员的缺口超过500万人。预计到2030年，60岁以上人口将增至3.9亿，老龄化水平接近28%。</p>\n<p>与发达国家“先富后老”不同，中国是“未富先老”——人均GDP刚突破1.2万美元，就迎来了深度老龄化。这意味着，社会财富积累不足，养老金体系压力巨大，而可用的年轻劳动力正在减少。</p>\n<h2 id=\"二最危险的十年2026-2035年的动态平衡\">二、最危险的十年：2026-2035年的动态平衡</h2>\n<p>这是整个百年进程中最关键的阶段，也是一个脆弱的平衡期。</p>\n<p><strong>压力来自三个方面：</strong><br />\n第一，1960-1975年出生的人口高峰正在集中进入退休和需要照护的阶段，养老服务需求爆发式增长。<br />\n第二，机器人技术尚未成熟。目前的人形机器人成本在10万-20万元一台，且只能完成辅助性工作，无法替代复杂护理。大规模普及至少要等到2030年以后。<br />\n第三，生育率已经跌破1.1，进入全球最低行列。这意味着后续劳动人口补给严重不足。</p>\n<p><strong>这个阶段的风险在于：</strong></p>\n<ul>\n<li>养老金收支缺口扩大，部分地区可能面临支付压力</li>\n<li>护理人力短缺导致服务质量下降，失能老人照护出现真空</li>\n<li>年轻人既要赡养老人，又面临就业压力，生育意愿进一步走低</li>\n<li>机器人服务成本仍然偏高，普通家庭难以负担</li>\n</ul>\n<p>这是一个动态平衡：机器人开始进入养老场景，但替代率不足；人口老龄化加速，但社会转型尚未完成。稍有应对失当，就可能出现系统性压力。</p>\n<h2 id=\"三度过危险期未来百年的三阶段演进\">三、度过危险期：未来百年的三阶段演进</h2>\n<h3 id=\"2035-2050机器人普及期\">2035-2050：机器人普及期</h3>\n<p>生育率预计在1.1-1.2之间，总人口从14亿逐步回落至12亿左右。养老机器人市场已进入快速增长通道：从2023年的66亿元，预计到2029年增至159亿元，2030年后增速进一步加快。这一阶段的机器人从辅助走向主力——2035年前后，成本有望降至5万元以内，月租模式开始普及。机器人服务开始实质性分担养老压力。</p>\n<h3 id=\"2050-2080机器人成熟期\">2050-2080：机器人成熟期</h3>\n<p>生育率回升至1.2-1.3的安全区间，人口稳定在9亿-10亿。机器人替代70%-80%的基础劳动，人形机器人可以完成全流程照护。市场规模进入万亿级别，单台机器人成本降至1万-3万元，或者月租两三千元。长期护理保险全面覆盖，养老服务实现标准化、普惠化。</p>\n<h3 id=\"2080-2126智能文明期\">2080-2126：智能文明期</h3>\n<p>生育率保持在1.0-1.2，人口稳定在6亿-8亿。机器人替代90%以上的重复性劳动，与通用AI深度融合，不仅能照顾身体，还能精神陪伴、预判健康问题。机器人即服务（RaaS）模式普及，个人存款、养老金、商业保险共同支付机器人服务，养老成本进一步降低。</p>\n<h2 id=\"四十万亿级产业支撑养老闭环\">四、十万亿级产业，支撑养老闭环</h2>\n<p>这一切的根基是机器人产业。目前智能巡检机器人市场规模已超230亿元，核心零部件国产化率超60%，成本持续下降。养老机器人产业链与人形机器人高度协同，远期潜在市场空间超万亿元。</p>\n<p>支付端也在逐步完善：基本养老保险、长期护理保险、商业养老金融构成三重保障。机器人产业越成熟，养老成本越低，科技进步的红利最终会落到普通人身上。</p>\n<h2 id=\"五守住底线个人选择与国家战略的平衡\">五、守住底线：个人选择与国家战略的平衡</h2>\n<p>回到开头那些年轻人的热议——“不生娃、存钱买机器人养老”。从个人角度，这是一个理性的选择，不值得指责。但国家必须守住一条底线：生育率需要维持在1.2左右，确保有足够的人口支撑研发、运维和创新。</p>\n<p>度过未来十年的危险平衡期，需要三管齐下：一是加快机器人技术研发和成本下降，二是完善长期护理保险和养老金体系，三是适当鼓励生育守住人口安全线。</p>\n<p>未来的社会，将是多元共生的格局：一部分家庭生育，守住人口基础；一部分人储蓄，享受科技红利；机器人填补劳动力缺口。个人选择与国家发展不是对立的，而是互补的。</p>\n<p>春晚那几个打拳舞剑的机器人，打开的不仅是一个节目的窗口。它预示着一个由科技驱动、效率支撑、资金保障、人口托底的新时代。但通向这个时代的路上，有十年左右的艰难平衡期需要跨越。跨过去，就是科技让生活更安稳、让养老更有尊严、让国家发展更可持续的未来。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n</div>\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-02-17 19:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xdesigner\">袁永福 电子病历，医疗信息化</a>&nbsp;\n阅读(<span id=\"post_view_count\">252</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战",
      "link": "https://www.cnblogs.com/han5562877/p/19621722/overcoming-tencent-tcaptcha-208tlo",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/han5562877/p/19621722/overcoming-tencent-tcaptcha-208tlo\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:25\">\n    <span>攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文记录了一次对腾讯 TCaptcha 滑块验证码的完整逆向工程实践，以粉笔教育登录流程为研究对象，通过纯 HTTP 协议实现了全自动化破解，通过率达到 100%。\n核心挑战包括：三阶段协议完整还原、NCC 模板匹配算法优化、PoW 工作量证明高效求解，以及 TDC.js 混淆虚拟机的执行与行为轨迹仿真。\n逆向从 HAR 抓包入手，梳理出风控触发后业务系统返回 contextId、前端加载腾讯验证码 iframe、用户验证成功后获取 ticket 和 randstr、再提交 captcha/check 解除风控的完整链路。验证码系统与业务系统解耦，可独立攻克 TCaptcha 后将凭证提交业务接口即可。\n同时还原了发送短信验证码接口所需的 RSA/ECB/PKCS#1 v1.5 加密 info 字段（手机号+时间戳），并用纯 Python 实现了标准填充的加密过程。\n本文为后续协议分析、图像处理、算法设计和虚拟机执行等环节奠定了基础，最终构建出一套稳定、可复用的纯 HTTP 自动化解决方案。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"攻克腾讯-tcaptcha-滑块验证码纯-http-协议逆向实战\">攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战</h1>\n<p>本文记录了一次完整的验证码逆向工程实践，从协议分析、图像处理、算法设计到 JavaScript VM 执行，最终实现了对腾讯 TCaptcha 滑块验证码的全自动化破解，通过率达到 100%。</p>\n<h2 id=\"一技术挑战概述\">一、技术挑战概述</h2>\n<p>腾讯 TCaptcha 是国内主流的滑块验证码方案，被广泛应用于各大互联网平台的风控系统中。本项目以粉笔教育的登录流程为研究对象，核心目标是在不依赖 Selenium 或 Playwright 等浏览器自动化工具的前提下，通过纯 HTTP 协议模拟实现验证码的自动化破解。这要求我们不仅要实现亚像素级别的拼图块位置计算，还需要绕过设备指纹、行为轨迹等多维度的检测机制，最终构建出一套稳定、可复用的工程化解决方案。</p>\n<p>整个项目面临的核心技术难点包括 TCaptcha 三阶段协议的完整还原、NCC 模板匹配算法的优化与实现、PoW 工作量证明的高效求解，以及最困难的 TDC.js 混淆虚拟机的执行与轨迹仿真。这些挑战环环相扣，任何一个环节的失败都会导致整个验证流程无法通过。</p>\n<h2 id=\"二前置准备业务流程逆向\">二、前置准备：业务流程逆向</h2>\n<h3 id=\"21-har-抓包与协议分析\">2.1 HAR 抓包与协议分析</h3>\n<p>一切从 Chrome DevTools 的网络抓包开始。通过录制完整的登录流程，我们发现当服务端检测到异常请求时，发送短信验证码的接口会返回 HTTP 430 状态码，响应体中包含一个 contextId 字段。这个 contextId 是后续验证码校验的会话标识，前端会弹出 iframe 加载腾讯验证码页面。用户完成滑块验证后，前端会获得 ticket 和 randstr 两个凭证，然后调用 captcha/check 接口提交这两个凭证来解除风控，最后带着 contextId 重试发送短信请求。</p>\n<p>完整的风控触发链路如下：</p>\n<pre><code>POST /users/phone/verification\n  ↓ 返回 HTTP 430\n  {\n    \"contextId\": \"abc123...\"\n  }\n  ↓\n[前端弹出 TCaptcha iframe]\n  ↓ 用户完成滑块验证\n  {\n    \"ticket\": \"t123...\",\n    \"randstr\": \"r456...\"\n  }\n  ↓\nPOST /users/captcha/check\n  Body: {\n    \"contextId\": \"abc123...\",\n    \"tencentticket\": \"t123...\",\n    \"tencentrandstr\": \"r456...\"\n  }\n  ↓ 返回 200 OK\nPOST /users/phone/verification?abxContextId=abc123...\n  ↓ 返回 200 OK，短信发送成功\n</code></pre>\n<p>这个流程揭示了一个关键点：验证码系统与业务系统是解耦的。业务系统只负责触发风控和校验凭证，真正的验证码交互完全发生在腾讯的域名下。这意味着我们可以独立地攻克 TCaptcha 验证码，然后将获得的 ticket 和 randstr 提交给业务系统即可。</p>\n<h3 id=\"22-rsa-加密参数还原\">2.2 RSA 加密参数还原</h3>\n<p>在分析 HAR 文件时，我们注意到发送短信验证码的接口需要一个名为 info 的字段。通过搜索前端打包后的 JavaScript 代码，我们在 main-es2015.js 中找到了加密逻辑：</p>\n<pre><code class=\"language-javascript\">// 前端加密逻辑（ref/js/main-es2015.*.js）\nfunction encryptPhone(phone) {\n    var publicKey = \"ANKi9PWuvDOsagwIVvrPx77mXNV0APmjySsYjB1/GtUT...\";\n    var timestamp = new Date().getTime();\n    var plaintext = phone + \":\" + timestamp;\n    return encrypt(publicKey, plaintext);\n}\n</code></pre>\n<p>这个 info 字段是对手机号和时间戳的 RSA 加密结果，格式为 <code>encrypt(publicKey, \"{phone}:{timestamp_ms}\")</code>。公钥模数以 Base64 格式硬编码在前端代码中，指数固定为 0x10001，加密算法是标准的 RSA/ECB/PKCS#1 v1.5。</p>\n<p>为了避免引入额外的密码学库依赖，我们用纯 Python 实现了这个加密过程。PKCS#1 v1.5 padding 的格式是 <code>0x00 || 0x02 || PS || 0x00 || M</code>​，其中 PS 是非零随机字节序列，长度为 <code>k - len(M) - 3</code>，k 是模长。实现代码如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/utils/rsa_encrypt.py\n\nimport base64\nimport secrets\nfrom dataclasses import dataclass\n\nRSA_EXPONENT_65537 = 0x10001\n\ndef _nonzero_random_bytes(n: int, randfunc) -&gt; bytes:\n    \"\"\"生成 n 个非 0 随机字节（PKCS#1 v1.5 padding 需要）。\"\"\"\n    out = bytearray()\n    while len(out) &lt; n:\n        chunk = bytearray(randfunc(n - len(out)))\n        chunk = bytearray(b for b in chunk if b != 0)\n        out.extend(chunk)\n    return bytes(out[:n])\n\n@dataclass(frozen=True)\nclass RsaPublicKey:\n    n: int  # 模数\n    e: int = RSA_EXPONENT_65537  # 指数\n    \n    @property\n    def k(self) -&gt; int:\n        \"\"\"模长（字节）。\"\"\"\n        return (self.n.bit_length() + 7) // 8\n\ndef rsa_encrypt_pkcs1_v1_5_base64(key: RsaPublicKey, plaintext: str) -&gt; str:\n    \"\"\"RSA/ECB/PKCS#1 v1.5 加密，并输出 Base64 字符串。\"\"\"\n    m = plaintext.encode(\"utf-8\")\n    k = key.k\n    \n    if len(m) &gt; k - 11:\n        raise ValueError(\"明文过长，无法进行 PKCS#1 v1.5 padding\")\n    \n    # PKCS#1 v1.5 padding: 0x00 || 0x02 || PS(非零随机) || 0x00 || M\n    ps_len = k - len(m) - 3\n    ps = _nonzero_random_bytes(ps_len, secrets.token_bytes)\n    em = b\"\\x00\\x02\" + ps + b\"\\x00\" + m\n    \n    # RSA 加密：c = m^e mod n\n    em_int = int.from_bytes(em, \"big\")\n    c_int = pow(em_int, key.e, key.n)\n    c = c_int.to_bytes(k, \"big\")\n    \n    return base64.b64encode(c).decode(\"ascii\")\n\ndef build_phone_verification_info(public_key_b64: str, phone: str, timestamp_ms: int) -&gt; str:\n    \"\"\"生成 /users/phone/verification 所需的 info 字段。\"\"\"\n    key = RsaPublicKey.from_fenbi_public_key_b64(public_key_b64)\n    return rsa_encrypt_pkcs1_v1_5_base64(key, f\"{phone}:{timestamp_ms}\")\n</code></pre>\n<p>这个实现有几个关键点。第一，PKCS#1 v1.5 padding 要求填充字节必须非零，我们使用 <code>secrets.token_bytes</code>​ 生成密码学安全的随机数，然后过滤掉所有的 0 字节。第二，大整数运算使用 Python 内置的 <code>pow(m, e, n)</code> 实现模幂运算，这是 Python 标准库提供的高效实现，无需引入第三方库。第三，整个实现不到 80 行代码，完全不依赖 PyCrypto、cryptography 等密码学库。</p>\n<p>至此，业务层的协议已经完全还原。接下来的核心挑战是如何自动化通过腾讯 TCaptcha 滑块验证码。</p>\n<h2 id=\"三tcaptcha-协议逆向三阶段攻防\">三、TCaptcha 协议逆向：三阶段攻防</h2>\n<h3 id=\"31-协议架构分析\">3.1 协议架构分析</h3>\n<p>TCaptcha 的交互流程涉及三个核心接口，全部位于 turing.captcha.qcloud.com 域名下。第一个接口是 cap_union_prehandle，负责初始化会话并获取图片配置和安全参数。第二个接口是 cap_union_new_getcapbysig，用于下载背景图和前景精灵图。第三个接口是 cap_union_new_verify，用于提交答案并获取最终的 ticket 和 randstr 凭证。</p>\n<h4 id=\"阶段一prehandle-会话初始化\">阶段一：prehandle 会话初始化</h4>\n<p>prehandle 接口的请求参数包含了业务方的 TCaptcha APP_ID、协议类型、客户端类型、语言设置等信息。其中 User-Agent 需要进行 Base64 编码，subsid 参数表示重试次数，每次失败后需要递增。完整的请求参数如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef prehandle(aid: str, entry_url: str = \"\", *, subsid: int = 1) -&gt; CaptchaLayout:\n    \"\"\"调用 TCaptcha prehandle 接口，初始化验证会话。\"\"\"\n    ua_b64 = base64.b64encode(_UA.encode()).decode()\n    \n    params = {\n        \"aid\": aid,                    # 业务方的 TCaptcha APP_ID\n        \"protocol\": \"https\",\n        \"accver\": \"1\",\n        \"showtype\": \"embed\",\n        \"ua\": ua_b64,                  # User-Agent Base64 编码\n        \"noheader\": \"1\",\n        \"fb\": \"0\",\n        \"aged\": \"0\",\n        \"enableAged\": \"0\",\n        \"enableDarkMode\": \"0\",\n        \"grayscale\": \"1\",\n        \"clientype\": \"2\",              # 客户端类型（2=Web）\n        \"cap_cd\": \"\",\n        \"uid\": \"\",\n        \"lang\": \"zh-cn\",\n        \"entry_url\": entry_url,\n        \"elder_captcha\": \"0\",\n        \"js\": \"/tcaptcha-frame.5bae14dd.js\",\n        \"login_appid\": \"\",\n        \"wb\": \"2\",\n        \"subsid\": str(subsid),         # 重试次数（失败后递增）\n        \"callback\": \"_aq_000001\",      # JSONP 回调函数名\n        \"sess\": \"\",\n    }\n    \n    url = f\"{_BASE}/cap_union_prehandle?{urllib.parse.urlencode(params)}\"\n    raw = _get(opener, url).decode(\"utf-8\")\n    data = _parse_jsonp(raw)  # 解析 JSONP 响应\n    \n    # 提取关键配置信息\n    sess = data.get(\"sess\", \"\")\n    dyn = data[\"data\"][\"dyn_show_info\"]\n    comm_cfg = data[\"data\"][\"comm_captcha_cfg\"]\n    \n    return CaptchaLayout(\n        sess=sess,\n        bg_img_url=dyn[\"bg_elem_cfg\"][\"img_url\"],\n        fg_elem_list=parse_fg_elements(dyn[\"fg_elem_list\"]),\n        pow_cfg=parse_pow_config(comm_cfg.get(\"pow_cfg\")),\n        tdc_path=comm_cfg.get(\"tdc_path\", \"\")\n    )\n</code></pre>\n<p>响应是 JSONP 格式，需要先去除回调函数包裹，然后解析 JSON。响应中最关键的是 sess 字段，这是会话标识，贯穿整个验证流程。dyn_show_info 部分包含了背景图和前景元素的配置信息：</p>\n<pre><code class=\"language-json\">{\n  \"sess\": \"0a1b2c3d4e5f...\",\n  \"data\": {\n    \"dyn_show_info\": {\n      \"bg_elem_cfg\": {\n        \"img_url\": \"/cap_union_new_getcapbysig?image=xxx&amp;sess=xxx\",\n        \"width\": 672,\n        \"height\": 390\n      },\n      \"fg_elem_list\": [\n        {\n          \"id\": 1,\n          \"sprite_pos\": [10, 20],      // 在精灵图中的裁剪位置 (x, y)\n          \"size_2d\": [68, 68],         // 拼图块尺寸 (width, height)\n          \"init_pos\": [30, 161],       // 初始坐标（滑块起点）\n          \"move_cfg\": {\"direction\": 0} // 移动方向（0=水平，1=垂直）\n        }\n      ]\n    },\n    \"comm_captcha_cfg\": {\n      \"pow_cfg\": {\n        \"prefix\": \"1:3FhYxv:\",\n        \"md5\": \"a1b2c3d4e5f6...\"\n      },\n      \"tdc_path\": \"/TDC_1.0.3.js\"\n    }\n  }\n}\n</code></pre>\n<p>fg_elem_list 描述了拼图块在精灵图中的位置和初始坐标。sprite_pos 是裁剪起点，size_2d 是裁剪尺寸，init_pos 是拼图块在背景图上的初始位置。这些信息对于后续的 NCC 模板匹配至关重要。</p>\n<h4 id=\"阶段二图片下载与精灵图裁剪\">阶段二：图片下载与精灵图裁剪</h4>\n<p>背景图和前景精灵图通过同一个接口下载，用 img_index 参数区分。img_index=1 表示背景图，这是一张 672×390 的 RGB PNG 图片，包含了缺口的阴影。img_index=0 表示前景精灵图，这是一张 682×620 的 RGBA PNG 图片，包含了拼图块和滑块按钮。</p>\n<p>前景精灵图是一张 sprite sheet，需要根据 fg_elem_list 中的 sprite_pos 和 size_2d 字段裁剪出拼图块。裁剪逻辑如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef download_images(layout: CaptchaLayout, opener) -&gt; CaptchaImages:\n    \"\"\"下载背景图和前景精灵图，并裁剪出拼图块。\"\"\"\n    # 下载背景图（img_index=1）\n    bg_bytes = _get(opener, layout.bg_img_url)\n    \n    # 下载前景精灵图（img_index=0）\n    # 构造 fg_img_url：与 bg_img_url 同 image/sess，但 img_index=0\n    image_id = _extract_image_id_from_url(layout.bg_img_url)\n    qs = urllib.parse.parse_qs(urllib.parse.urlparse(layout.bg_img_url).query)\n    sess_val = qs.get(\"sess\", [\"\"])[0]\n    fg_img_url = f\"{_BASE}/cap_union_new_getcapbysig?img_index=0&amp;image={image_id}&amp;sess={sess_val}\"\n    fg_bytes = _get(opener, fg_img_url)\n    \n    # 从精灵图中裁剪拼图块\n    fg_img = Image.open(io.BytesIO(fg_bytes))\n    piece = layout.piece_elem\n    px, py = piece.sprite_pos  # 裁剪起点\n    pw, ph = piece.size_2d     # 裁剪尺寸\n    \n    # 裁剪：crop((left, top, right, bottom))\n    piece_img = fg_img.crop((px, py, px + pw, py + ph))\n    \n    return CaptchaImages(\n        bg_bytes=bg_bytes,\n        fg_bytes=fg_bytes,\n        piece_rgba=np.array(piece_img),  # 转为 NumPy 数组供 NCC 使用\n        layout=layout\n    )\n</code></pre>\n<p>裁剪后的拼图块是一张 RGBA 图片，包含透明通道。这个透明通道在后续的 NCC 模板匹配中非常重要，我们会用它作为掩码，只匹配不透明区域。</p>\n<h4 id=\"阶段三verify-答案提交\">阶段三：verify 答案提交</h4>\n<p>verify 提交阶段是最复杂的部分。POST body 需要包含七个字段，每个字段都有严格的格式要求：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef submit_verify(\n    layout: CaptchaLayout,\n    ans: str,\n    pow_answer: str,\n    pow_calc_time: int,\n    *,\n    collect: str,\n    tlg: int,\n    eks: str,\n    opener\n) -&gt; VerifyResult:\n    \"\"\"提交验证答案到 TCaptcha verify 接口。\"\"\"\n    body = {\n        \"ans\": ans,                    # 答案 JSON\n        \"sess\": layout.sess,           # 会话标识\n        \"pow_answer\": pow_answer,      # PoW 答案（prefix+nonce）\n        \"pow_calc_time\": str(pow_calc_time),  # PoW 计算耗时（毫秒）\n        \"collect\": collect,            # tdc.js 生成的设备指纹+轨迹\n        \"tlg\": str(tlg),               # 滑动总耗时（毫秒）\n        \"eks\": eks,                    # tdc.js 内嵌的加密签名\n    }\n    \n    url = f\"{_BASE}/cap_union_new_verify\"\n    response = _post(opener, url, urllib.parse.urlencode(body))\n    data = json.loads(response.decode(\"utf-8\"))\n    \n    return VerifyResult(\n        ok=(data.get(\"errorCode\") == 0),\n        ticket=data.get(\"ticket\", \"\"),\n        randstr=data.get(\"randstr\", \"\"),\n        error_code=data.get(\"errorCode\"),\n        error_msg=data.get(\"errMsg\", \"\")\n    )\n</code></pre>\n<p>ans 字段的格式是一个 JSON 数组，包含 elem_id、type 和 data 三个字段：</p>\n<pre><code class=\"language-python\">def build_ans(elem_id: int, target_x: int, target_y: int) -&gt; str:\n    \"\"\"构造 verify 请求的 ans 字段。\"\"\"\n    ans = [\n        {\n            \"elem_id\": elem_id,              # 元素 ID（从 fg_elem_list 获取）\n            \"type\": \"DynAnswerType_POS\",     # 答案类型（位置）\n            \"data\": f\"{target_x},{target_y}\" # 目标坐标（逗号分隔）\n        }\n    ]\n    return json.dumps(ans, separators=(\",\", \":\"))\n</code></pre>\n<p>这七个字段缺一不可，任何一个字段的错误都会导致验证失败。其中 ans 需要精确计算拼图块的目标坐标（误差 &gt; 5px 会失败），pow_answer 需要暴力搜索 MD5 碰撞，collect 和 eks 由混淆的 tdc.js 生成，无法直接模拟。接下来我们将逐一攻克这些难点。</p>\n<h3 id=\"32-核心算法ncc-模板匹配求解滑块位移\">3.2 核心算法：NCC 模板匹配求解滑块位移</h3>\n<p>滑块验证码的本质问题是：给定背景图（含缺口）和拼图块，求出拼图块需要水平移动多少像素才能填入缺口。这个问题看似简单，但要达到亚像素级的精度并不容易。</p>\n<h4 id=\"方案选型ncc-vs-深度学习\">方案选型：NCC vs 深度学习</h4>\n<p>在方案选型阶段，我们面临两个选择：深度学习模型或传统的模板匹配算法。深度学习模型的优势是泛化能力强，可以处理各种变形和噪声，但需要大量标注样本进行训练，还需要 GPU 进行推理。更重要的是，深度学习模型的精度通常在 2-5 像素左右，这对于 TCaptcha 这种要求精确匹配的场景来说可能不够。</p>\n<p>相比之下，NCC（归一化互相关）模板匹配算法虽然对图片变化敏感，但在 TCaptcha 这种图片质量稳定、缺口形状规则的场景下，可以达到亚像素级的精度。而且 NCC 算法无需训练，只需要 CPU 就能运行，单次求解耗时约 0.3 秒，非常适合服务端部署。我们选择 NCC 的原因是：TCaptcha 的图片质量稳定（固定分辨率 672×390、无噪声干扰）、缺口形状规则（标准拼图块）、NCC 是像素级精确匹配而深度学习是特征级近似匹配。</p>\n<h4 id=\"ncc-算法原理\">NCC 算法原理</h4>\n<p>NCC 算法的核心思路是在背景图上滑动拼图块，计算每个位置的相似度，找到相似度最大的位置。相似度的计算公式是归一化互相关系数：</p>\n<pre><code>NCC(x, y) = Σ[(T - T̄) · (I - Ī)] / √[Σ(T - T̄)² · Σ(I - Ī)²]\n</code></pre>\n<p>其中 T 是模板（拼图块）的像素值，I 是背景图在 (x, y) 位置的区域像素值，T̄ 和 Ī 分别是均值。NCC 的值域是 [-1, 1]，越接近 1 表示越相似。这个公式的本质是计算两个向量的余弦相似度，归一化后不受亮度变化的影响。</p>\n<h4 id=\"实现细节alpha-通道掩码\">实现细节：Alpha 通道掩码</h4>\n<p>在实现过程中，我们遇到的第一个问题是拼图块是 RGBA 图片，包含透明区域。如果直接用所有像素参与匹配，透明区域会干扰结果。解决方案是使用 Alpha 通道作为掩码，只让不透明区域（alpha &gt; 128）参与匹配：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/solver.py\n\ndef _ncc_match(self, bg_arr: np.ndarray, piece_rgba: np.ndarray, \n               init_y: int, pw: int, ph: int) -&gt; Tuple[int, float]:\n    \"\"\"使用 NCC 模板匹配找到拼图块在背景图中的位置。\n    \n    Args:\n        bg_arr: 背景图 NumPy 数组 (H, W, 3)\n        piece_rgba: 拼图块 NumPy 数组 (ph, pw, 4)\n        init_y: 初始 Y 坐标（prehandle 给出）\n        pw, ph: 拼图块宽度和高度\n    \n    Returns:\n        (best_x, best_ncc): 最佳 X 坐标和对应的 NCC 系数\n    \"\"\"\n    # 提取 RGB 和 Alpha 通道\n    piece_rgb = piece_rgba[:, :, :3].astype(np.float32)\n    piece_alpha = piece_rgba[:, :, 3]\n    \n    # 创建掩码：只匹配不透明区域\n    mask = piece_alpha &gt; 128\n    \n    if mask.sum() &lt; 100:  # 不透明像素太少，无法匹配\n        return 0, -1.0\n    \n    # 只提取不透明区域的像素值\n    piece_flat = piece_rgb[mask]\n    piece_centered = piece_flat - piece_flat.mean()\n    piece_norm = float(np.sqrt((piece_centered**2).sum())) + 1e-8\n    \n    bg_f32 = bg_arr[:, :, :3].astype(np.float32)\n    \n    # 两阶段搜索...\n</code></pre>\n<p>这个掩码机制非常关键。拼图块的透明区域在背景图上对应的是任意内容，如果参与匹配会引入大量噪声。通过 Alpha 通道掩码，我们只匹配拼图块的实际形状，大大提高了匹配精度。</p>\n<h4 id=\"性能优化两阶段搜索\">性能优化：两阶段搜索</h4>\n<p>如果对背景图的每个像素都计算一次 NCC，672×390 的图片需要计算 262,080 次，耗时会达到 250 秒。我们采用了两阶段搜索策略：</p>\n<pre><code class=\"language-python\">    # 阶段一：粗搜，stride=4，只在 init_y 行扫描\n    y_min = max(0, init_y - self.y_search_range)\n    y_max = min(bg_arr.shape[0] - ph, init_y + self.y_search_range)\n    x_max = bg_arr.shape[1] - pw\n    \n    coarse_best_x = 0\n    coarse_best_ncc = -2.0\n    \n    for x in range(0, x_max, 4):  # 每隔 4 像素采样一次\n        region_vals = bg_f32[init_y:init_y+ph, x:x+pw][mask]\n        rc = region_vals - region_vals.mean()\n        rn = float(np.sqrt((rc**2).sum())) + 1e-8\n        ncc = float((piece_centered * rc).sum() / (piece_norm * rn))\n        \n        if ncc &gt; coarse_best_ncc:\n            coarse_best_ncc = ncc\n            coarse_best_x = x\n    \n    # 阶段二：精搜，在粗搜结果 ±6px，y 方向 ±5px\n    fine_x_min = max(0, coarse_best_x - 6)\n    fine_x_max = min(x_max, coarse_best_x + 7)\n    \n    best_x = 0\n    best_ncc = -2.0\n    \n    for y in range(y_min, y_max + 1):\n        for x in range(fine_x_min, fine_x_max):\n            region_vals = bg_f32[y:y+ph, x:x+pw][mask]\n            rc = region_vals - region_vals.mean()\n            rn = float(np.sqrt((rc**2).sum())) + 1e-8\n            ncc = float((piece_centered * rc).sum() / (piece_norm * rn))\n            \n            if ncc &gt; best_ncc:\n                best_ncc = ncc\n                best_x = x\n    \n    return best_x, best_ncc\n</code></pre>\n<p>第一阶段粗搜以 stride=4 的步长在 init_y 行上扫描，快速定位大致位置。计算量为 672/4 = 168 次。第二阶段精搜在粗搜结果的 ±6 像素范围内逐像素搜索，同时在 Y 方向也搜索 ±5 像素范围（因为 prehandle 给出的 init_y 可能有微小偏移）。计算量为 13×11 = 143 次。总计算量从 262,080 次降低到 311 次，性能提升了 842 倍，实际耗时从 250 秒降低到 0.3 秒。</p>\n<h4 id=\"测试结果\">测试结果</h4>\n<p>在 20 个真实 TCaptcha 样本上测试，平均绝对误差（MAE）为 0.10 像素，最大误差为 0.5 像素。这个精度已经远超人类手动操作（人类误差通常在 3-5 像素），足以通过 TCaptcha 的校验。误差主要来源于缺口边缘的抗锯齿效果、JPEG 压缩导致的像素值微小变化，以及拼图块与缺口的轻微形状差异。</p>\n<p>完整的求解流程封装在 SliderSolver 类中：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/solver.py\n\nclass SliderSolver:\n    \"\"\"基于 NCC 模板匹配的滑块验证码求解器。\"\"\"\n    \n    def __init__(self, *, y_search_range: int = 5):\n        self.y_search_range = y_search_range\n    \n    def solve(self, images: CaptchaImages) -&gt; SolveResult:\n        \"\"\"求解滑块验证码，返回位移和置信度。\"\"\"\n        bg = np.array(Image.open(io.BytesIO(images.bg_bytes)).convert(\"RGB\"))\n        piece = images.piece_rgba\n        \n        piece_elem = images.layout.piece_elem\n        init_x, init_y = piece_elem.init_pos\n        pw, ph = piece_elem.size_2d\n        \n        # NCC 模板匹配\n        gap_x, ncc = self._ncc_match(bg, piece, init_y, pw, ph)\n        dx = gap_x - init_x  # 需要移动的像素数\n        \n        return SolveResult(\n            dx=dx,\n            gap_x=gap_x,\n            gap_y=init_y,\n            confidence=ncc,\n            piece_init_x=init_x,\n            piece_init_y=init_y\n        )\n</code></pre>\n<p>使用时只需创建 SliderSolver 实例，调用 solve 方法即可获得位移 dx 和置信度 confidence。</p>\n<h3 id=\"33-powproof-of-work求解\">3.3 PoW（Proof of Work）求解</h3>\n<p>TCaptcha 要求客户端完成一个 MD5 工作量证明挑战，用于防止暴力破解和机器人攻击。prehandle 响应中包含 pow_cfg 字段，包含一个 prefix 和一个 target_md5。客户端需要找到一个 nonce，使得 <code>MD5(prefix + nonce)</code>​ 等于 target_md5。例如，如果 prefix 是 \"1:3FhYxv:\"，target_md5 是 \"a1b2c3d4e5f6...\"，那么我们需要找到一个数字 nonce，使得 <code>MD5(\"1:3FhYxv:42857\")</code> 等于目标哈希值。</p>\n<p>实现上采用简单的暴力搜索，从 0 开始递增 nonce，每次计算 MD5 哈希并与目标值比较。为了避免无限循环，我们设置了最大搜索次数为 100 万次。实际测试中，我们对 100 次真实请求进行了统计，发现平均 nonce 值为 347，最大 nonce 值为 1823，平均耗时 0.8 毫秒，最大耗时 4.2 毫秒。这说明 TCaptcha 的 PoW 难度设置得很低，nonce 通常在几百以内就能找到，对整体性能影响可以忽略不计。这也说明 PoW 主要是象征性的防护，TCaptcha 真正的防御重点在设备指纹和行为轨迹。</p>\n<h3 id=\"34-tdcjs-逆向设备指纹与轨迹仿真\">3.4 TDC.js 逆向：设备指纹与轨迹仿真</h3>\n<p>这是整个项目最困难的部分。verify 请求中的 collect 和 eks 字段由腾讯的 tdc.js 生成，这是一个经过深度混淆的字节码虚拟机，内部标识为 <code>__TENCENT_CHAOS_VM</code>。TDC 是 Tencent Device Collection 的缩写，负责采集三类数据。</p>\n<p>第一类是设备指纹，包括浏览器特征（User-Agent、屏幕分辨率、颜色深度、时区）、Canvas 指纹（绘制特定图形后的像素哈希）、WebGL 指纹（GPU 渲染器信息）、字体列表、插件列表、音频上下文指纹等。这些信息组合起来可以唯一标识一个设备，即使用户清除 Cookie 也无法改变。</p>\n<p>第二类是行为轨迹，包括滑动轨迹坐标序列（x 坐标随时间变化）、鼠标移动速度和加速度、滑动总耗时等。这些数据用于判断用户是否是真人操作，机器人的轨迹通常过于规则或过于随机。</p>\n<p>第三类是加密签名，eks 字段是 tdc.js 内嵌的密钥签名，用于验证 tdc.js 的完整性，防止客户端篡改或伪造 collect 数据。</p>\n<p>我们尝试在 Python 中模拟 tdc.js 的输出，但很快发现这几乎不可能。tdc.js 使用自定义字节码虚拟机执行，逆向成本极高，估计需要 2-3 周时间。而且 tdc.js 的路径和版本号会变化，每次更新都需要重新逆向。tdc.js 还会检测 window、document、navigator 等浏览器对象，如果环境不对会拒绝执行。最困难的是 Canvas 指纹，需要真实的 Canvas API 才能生成正确的指纹，纯 Python 无法模拟。</p>\n<p>我们的解决方案是在 Node.js 的 jsdom 环境中执行真实的 tdc.js。jsdom 是一个纯 JavaScript 实现的 DOM 和 HTML 标准，可以在 Node.js 中模拟浏览器环境。我们的架构是 Python 主程序通过 subprocess 调用 Node.js 执行 tdc_executor.js，tdc_executor.js 在 jsdom 中加载并执行 tdc.js，最后将 collect 和 eks 返回给 Python。</p>\n<p>在 tdc_executor.js 中，我们首先创建一个虚拟 DOM 环境，设置 URL 为腾讯验证码的域名，User-Agent 设置为标准的 Chrome，pretendToBeVisual 设置为 true 让 jsdom 模拟可视化环境，runScripts 设置为 \"dangerously\" 允许执行动态注入的脚本。然后我们模拟浏览器环境，设置 screen 对象的宽度、高度、颜色深度等属性，设置 innerWidth、innerHeight、devicePixelRatio 等全局变量。接着我们创建一个 script 元素，将 tdc.js 的代码注入到 DOM 中。等待 300 毫秒让 tdc.js 初始化完成后，我们调用 TDC.setData 传入滑动轨迹数据，调用 TDC.getData 获取 collect，调用 TDC.getInfo 获取 eks。</p>\n<p>为了让 tdc.js 生成合理的轨迹数据，我们实现了一个 ease-in-out cubic 的仿真轨迹生成器，模拟人类滑动的加速-匀速-减速过程。如果用户没有指定滑动耗时，我们随机生成 800-2000 毫秒，这是人类滑动的正常范围。然后我们根据耗时计算采样点数量，每 30 毫秒采样一次。对于每个采样点，我们用 ease-in-out cubic 缓动函数计算当前进度，前半段使用 <code>4 * t³</code>​ 实现加速，后半段使用 <code>1 - ((-2t + 2)³) / 2</code> 实现减速。为了模拟手部微颤，我们在 10%-90% 的时间段内添加 ±1 像素的随机抖动。最后确保最后一个点精确到达目标位置。</p>\n<p>这种方案的优势是无需逆向 tdc.js，直接执行原始代码，避免了混淆虚拟机的逆向成本。而且 tdc.js 更新后无需修改代码，自动适配新版本。jsdom 提供的浏览器环境足够真实，能通过 tdc.js 的检测。潜在风险是 tdc.js 可能检测 jsdom 特有的属性（如 navigator.webdriver），或者检测 Canvas 指纹的统计学异常。但实测结果显示，目前 TCaptcha 未检测 jsdom 环境，通过率 100%。</p>\n<h3 id=\"35-端到端自动化流程\">3.5 端到端自动化流程</h3>\n<p>所有组件组装在 automation.py 中，形成完整的验证码破解流水线。整个流程从调用 solve_captcha 函数开始，这个函数接受 TCaptcha APP_ID 和最大重试次数作为参数。函数内部创建一个 SliderSolver 实例用于 NCC 计算，然后进入重试循环。</p>\n<p>每次循环首先调用 fetch_challenge 获取验证码图片和配置信息，这个函数内部会调用 prehandle 初始化会话，然后下载背景图和前景精灵图。获取到图片后，我们调用 solver.solve 进行 NCC 模板匹配，计算出拼图块需要移动的像素数 dx。根据 dx 和拼图块的初始坐标，我们可以计算出目标坐标 target_x 和 target_y。</p>\n<p>接下来调用 solve_pow 求解工作量证明，这个函数会暴力搜索 MD5 碰撞，返回 pow_answer 和计算耗时 pow_calc_time。然后调用 build_ans 构造答案 JSON，格式为包含 elem_id、type 和 data 的数组。</p>\n<p>最关键的一步是调用 get_tdc_data 生成设备指纹和轨迹数据。这个函数内部会先调用 generate_slide_trajectory 生成仿真轨迹，然后通过 subprocess 调用 Node.js 执行 tdc_executor.js，在 jsdom 环境中运行 tdc.js，最后返回 collect、eks 和 tlg。</p>\n<p>最后调用 submit_verify 提交所有数据到 TCaptcha 服务器。如果 verify 响应的 ok 字段为 true，说明验证通过，我们返回包含 ticket 和 randstr 的成功结果。如果失败，进入下一次重试循环，subsid 参数会递增，TCaptcha 会返回新的验证码图片。</p>\n<p>整个流程的时序是：prehandle 耗时约 0.5 秒，下载图片耗时约 0.3 秒，NCC 求解耗时约 0.3 秒，PoW 求解耗时不到 1 毫秒，生成轨迹和 TDC 执行耗时约 0.5 秒，verify 提交耗时约 0.3 秒。总耗时约 5.6 秒，其中网络请求占 1.1 秒，算法计算占 0.8 秒，TDC 执行占 0.5 秒。在 5 次实时测试中，通过率达到 100%，没有一次失败。</p>\n<h2 id=\"四工程化实现与架构设计\">四、工程化实现与架构设计</h2>\n<h3 id=\"41-项目架构\">4.1 项目架构</h3>\n<p>整个项目采用模块化设计，核心验证码模块位于 fenbi_auth/captcha 目录下。tcaptcha_client.py 负责 TCaptcha 协议的实现，包括 prehandle 会话初始化、download_images 图片下载与解析、solve_pow 工作量证明求解、submit_verify 答案提交等功能。solver.py 实现了 NCC 两阶段模板匹配求解器，这是整个系统的核心算法。tdc_executor.py 是 Python 到 Node.js 的桥接层，负责调用 tdc_executor.js 执行 tdc.js，同时包含轨迹生成算法。automation.py 是对外的统一入口，提供 solve_captcha 函数封装整个验证码破解流程。</p>\n<p>工具层包含 tdc_executor.js，这是一个 Node.js 脚本，使用 jsdom 创建虚拟浏览器环境来执行腾讯的 tdc.js。业务层包含 fenbi_login.py，实现了粉笔登录服务，包括发送短信验证码、提交验证码凭证、快速登录等功能。工具类包含 rsa_encrypt.py，实现了纯 Python 的 RSA/PKCS#1 v1.5 加密，用于生成 info 字段。http_client.py 提供了无依赖的 HTTP 客户端，支持 cookiejar 管理。</p>\n<h3 id=\"42-设计原则\">4.2 设计原则</h3>\n<p>传统的验证码自动化方案通常依赖 Selenium 或 Playwright 驱动真实浏览器，但这种方案存在明显的问题。每个浏览器实例占用 200-500MB 内存，冷启动需要 3-5 秒，而且 navigator.webdriver 等特征容易被检测，单机并发数通常小于 10。我们的方案是纯 HTTP 协议模拟，使用 Python 标准库 urllib 实现 HTTP 客户端，完全不依赖浏览器。只在必要时（tdc.js 执行）调用 Node.js 加 jsdom，单次验证码求解只需 30MB 内存，支持单机 100 以上的并发。</p>\n<p>模块化设计是另一个重要原则。协议层只负责 HTTP 通信，调用 tcaptcha_client.prehandle 返回 CaptchaLayout 对象。算法层只负责图像处理，调用 solver.solve 返回 SolveResult 对象，包含 dx 和 confidence。执行层只负责 tdc.js 调用，调用 tdc_executor.get_tdc_data 返回包含 collect 和 eks 的字典。编排层组装所有组件，调用 automation.solve_captcha 返回 CaptchaPassResult 对象，包含 ok、ticket 和 randstr。这种设计使得每个模块职责单一，便于测试和维护。</p>\n<p>核心验证码模块只依赖 numpy 用于 NCC 计算，Pillow 用于图片解析，Node.js 加 jsdom 用于 tdc.js 执行。我们不依赖 TensorFlow 或 PyTorch 等深度学习框架，不依赖 OpenCV 图像处理库，不依赖 Selenium 或 Playwright 浏览器自动化工具，也不依赖任何第三方验证码识别服务。这使得项目部署简单，依赖少，维护成本低。</p>\n<h3 id=\"43-使用示例\">4.3 使用示例</h3>\n<p>如果只需要验证码破解功能，可以单独使用验证码模块。导入 solve_captcha 函数，传入 TCaptcha APP_ID，函数会自动完成整个验证码破解流程，返回包含 ticket 和 randstr 的结果对象。如果 result.ok 为 true，说明验证通过，可以从 result.ticket 和 result.randstr 获取凭证。如果为 false，可以从 result.error 获取错误信息。</p>\n<p>如果需要集成到登录流程，可以结合 FenbiLoginService 使用。首先创建 CookieHttpClient 和 FenbiLoginService 实例，然后调用 send_sms_code 发送短信验证码。如果返回的 r1.ok 为 false 且 r1.context_id 存在，说明触发了风控。此时调用 solve_captcha 自动过验证码，如果 cap.ok 为 true，调用 captcha_check 提交 ticket 和 randstr 放行风控，然后带着 context_id 重试发送短信。最后输入短信验证码调用 quicklogin 完成登录。</p>\n<h2 id=\"五技术总结与反思\">五、技术总结与反思</h2>\n<h3 id=\"51-关键数据\">5.1 关键数据</h3>\n<p>在 20 个真实 TCaptcha 样本上测试 NCC 求解精度，平均绝对误差为 0.10 像素，最大误差为 0.5 像素。在 5 次实时请求中，验证码通过率达到 100%，没有一次失败。单次求解总耗时约 5.6 秒，其中 NCC 计算耗时 0.3 秒，PoW 求解耗时小于 1 毫秒，TDC 执行耗时 0.5 秒。内存占用方面，单次验证码求解峰值为 30 MB，远低于浏览器自动化方案的 200-500 MB。外部依赖只有 numpy、Pillow 和 Node.js，核心模块完全不依赖深度学习框架。</p>\n<h3 id=\"52-技术亮点\">5.2 技术亮点</h3>\n<p>NCC 算法在滑块验证码场景下展现出了相比深度学习的优越性。在精度对比上，NCC 达到了 0.10 像素的平均绝对误差，这是亚像素级的精度，而深度学习模型通常只能达到 2-5 像素的精度。这是因为 TCaptcha 的图片质量稳定，分辨率固定，没有噪声干扰，缺口形状规则，是标准的拼图块。在这种场景下，NCC 是像素级的精确匹配，而深度学习是特征级的近似匹配，前者天然具有精度优势。当然，如果图片变化大、需要泛化能力，深度学习会更有优势，但对于 TCaptcha 这种特定场景，NCC 是最优选择。</p>\n<p>jsdom 执行 tdc.js 的方案体现了工程上的巧妙性。直接逆向 tdc.js 的混淆虚拟机成本极高，估计需要 2-3 周时间，而 jsdom 方案只需 1 天即可实现。关键洞察是 tdc.js 的目的是采集设备指纹，而非实现加密算法，jsdom 提供的浏览器环境足够真实，能通过大部分检测。即使 tdc.js 更新版本，也无需修改代码，自动适配新版本。当然，潜在风险是 jsdom 的 Canvas 指纹与真实浏览器有细微差异，未来 TCaptcha 可能增加 jsdom 特征检测。应对策略是定期监控通过率，一旦下降立即分析原因，准备 Plan B 使用 Puppeteer 在真实浏览器中执行 tdc.js。</p>\n<p>两阶段搜索的性能优化将计算量从 O(W×H) 降低到 O(W/4 + 13×11)。全图搜索需要 672×390 等于 262,080 次 NCC 计算，而两阶段搜索只需要 672 除以 4 加上 13×11，等于 168 加 143，总共 311 次 NCC 计算。性能提升了 262,080 除以 311，约等于 842 倍。实际耗时从理论上的 250 秒降低到 0.3 秒，这使得 NCC 算法在实时场景下完全可用。</p>\n<h3 id=\"53-反检测技术\">5.3 反检测技术</h3>\n<p>TCaptcha 的检测维度包括设备指纹、滑动轨迹、滑动耗时、PoW 计算时间、答案精度、HTTP 请求特征等多个方面。我们的应对策略是：设备指纹方面，使用 jsdom 模拟真实浏览器环境，目前已通过检测。滑动轨迹方面，使用 ease-in-out cubic 缓动函数加微抖动，模拟人类滑动的加速-匀速-减速过程，目前已通过检测。滑动耗时方面，随机生成 800-2000 毫秒，符合人类滑动的正常范围，目前已通过检测。PoW 计算时间方面，真实计算不伪造，目前已通过检测。答案精度方面，NCC 达到亚像素级精度，远超人类水平，目前已通过检测。HTTP 请求特征方面，完全模拟浏览器 Headers，目前已通过检测。</p>\n<p>未来可能的检测点包括 jsdom 特有的 navigator 属性、Canvas 指纹的统计学异常、高频请求的 IP 封禁等。对于 jsdom 特征检测，我们可以在 jsdom 环境中删除或修改特有属性。对于 Canvas 指纹异常，我们可以收集真实浏览器的 Canvas 指纹，在 jsdom 中伪造相同的指纹。对于 IP 封禁，我们可以使用代理池分散请求。</p>\n<h3 id=\"54-局限性与改进方向\">5.4 局限性与改进方向</h3>\n<p>当前方案的局限性主要有三点。第一是依赖 Node.js，tdc.js 执行需要 Node.js 环境，增加了部署复杂度。第二是单线程 NCC，未使用多核并行计算，有优化空间。第三是固定 APP_ID，只测试了粉笔的 TCaptcha，其他业务方可能有差异。</p>\n<p>改进方向包括纯 Python 实现 tdc.js、GPU 加速 NCC、深度学习混合方案等。纯 Python 实现 tdc.js 需要逆向 <code>__TENCENT_CHAOS_VM</code> 字节码格式，用 Python 实现 VM 解释器，难度极高，但可彻底去除 Node.js 依赖。GPU 加速 NCC 可以使用 CuPy 或 PyTorch 实现 NCC，理论上可将耗时从 0.3 秒降低到 0.05 秒，但需要 GPU 环境，不适合服务端部署。深度学习混合方案可以用 CNN 粗定位缺口区域降低搜索范围，用 NCC 精确计算位移保证精度，可能将耗时降低到 0.1 秒。</p>\n<h3 id=\"55-伦理与法律声明\">5.5 伦理与法律声明</h3>\n<p>本项目仅用于技术研究和学习目的，展示了验证码逆向工程的完整技术链路。请勿将本技术用于任何非法用途，如批量注册、刷单、爬虫等。验证码是网站的安全防护措施，绕过验证码可能违反服务条款。使用本技术造成的任何法律后果由使用者自行承担。合法使用场景包括自动化测试（测试自己的网站）、辅助功能（帮助视障用户）、学术研究（验证码安全性分析）等。</p>\n<h2 id=\"六结语\">六、结语</h2>\n<p>本项目从零开始，完整实现了对腾讯 TCaptcha 滑块验证码的自动化破解，涉及的技术栈包括协议逆向（HAR 分析、JSONP 解析、HTTP 协议模拟）、密码学（RSA/PKCS#1 v1.5 加密、MD5 PoW）、图像处理（NCC 模板匹配、Alpha 通道掩码、两阶段搜索）、JavaScript 逆向（tdc.js 混淆 VM、jsdom 沙箱执行）、算法设计（ease-in-out cubic 轨迹仿真、微抖动模拟）等多个领域。</p>\n<p>最终实现了 100% 通过率、5.6 秒求解、零深度学习依赖的工程化方案。这个项目证明了在特定场景下，传统算法（NCC）加工程技巧（jsdom）可以达到甚至超越深度学习的效果。希望本文能为验证码逆向、图像处理、反爬虫对抗等领域的研究者提供参考。</p>\n<p>‍</p>\n\n\n</div>\n<div id=\"MySignature\">\n    每天好一点点\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/han5562877\">嚯嚯歪</a>&nbsp;\n阅读(<span id=\"post_view_count\">104</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2023年电赛国赛经历",
      "link": "https://www.cnblogs.com/badboy02/p/19623709",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/badboy02/p/19623709\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 14:06\">\n    <span>2023年电赛国赛经历</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"2023年电赛国赛经历\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3763221/202602/3763221-20260219000428689-1446099918.png\" />\n        2023年全国大学生电子设计竞赛经历，D题信号题，国赛二等奖。\n一些比赛经历和经验技巧\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>--- markdown描述<br />\ntitle: 电赛2023国赛D题比赛经历<br />\ndate: 2023/8/15 11:52:25<br />\ncover: true<br />\nmathjax: false<br />\nsummary: 比赛过程和一些准备工作的碎碎念<br />\ncategories: Note<br />\ntags:</p>\n<ul>\n<li>电赛</li>\n<li>信号</li>\n</ul>\n<hr />\n<h2 id=\"补档声明\">补档声明</h2>\n<p>由于我的博客服务器和备案到期，所以选择转移到博客园平台来进行保存和记录。以后也有可能会在上面不定期更新一些技术类博客。</p>\n<h2 id=\"写在前面\">写在前面</h2>\n<p>🪓突然意识到自己已经8个月没更新博客了，这段时间其实也没遇上啥太复杂的事，大概就是一些沉淀之类的，决定了之后的学业去向，推免了本校的研究生。进一步认识了一群未来志同道合的的同门，激情爽玩塞尔达旷野之息和王国之泪，狠狠地治愈了一阵子的电子阳痿，以及开始健身（存疑）。<br />\n当然，电赛什么的也是有在准备的，由于团队其他两个都是硬件佬，他们承受着画板与焊接调试的水深火热，我只需要安安静静的写代码就足够了（笑），每天实验室上下班，把自己的部分搞定，然后去健身房锻炼一会，回来美美加个餐洗个澡，然后打打机去睡觉，也算是某种意义上的平静的生活，求之不得。毕竟当初决定打电赛说到底也只是为了提升自己，探索一下电子世界的奥妙，这么久走过来也是重在坚持，也希望最后能有一个好结果。<br />\n截止到写博客的时候，我们组的成绩省赛以省一并列第一出线，综合测评应该也能过线，山东大学国测复测不出意外的话，应该是国二以上。</p>\n<p>这篇博客会分为上下两部分，上篇主要是比赛的过程和一些前置的准备(没有营养的碎碎念)，下篇主要是一些算法具体的实现(一些情急之下的灵机一动，大佬轻锤)。</p>\n<h2 id=\"比赛过程\">比赛过程</h2>\n<ol>\n<li>准备阶段</li>\n</ol>\n<p>我们队伍一直以来训练的是仪表和高频题，一开始侧重FPGA高速信号采集和数字域处理这一块，但是后面逐渐意识到，对于电赛的指标范围内好像也不需要这么高的频率，高载波带来的高采样率问题可以通过下混频缓解，而高频直采带来是的FIR滤波器的资源消耗成倍增加，以及数字域处理带来的资源占用和量化噪声问题。</p>\n<p><img alt=\"ZYNQ7100平台\" class=\"lazyload\" /><br />\n这是我们准备的ZYNQ7100的平台，可以外接高速ADDA，板载DDR3.<br />\n但是吧，ZYNQ平台的综合速度和固化难度以及Verilog代码的验证难度，在分秒必争的竞赛里，如果没有长期的训练和准备，在比赛那四天着急上头去写，恐怕会翻车。</p>\n<p>于是在训练后期又重回STM32H743的单片机平台，侧重模块叠加后的健壮性和代码的可复用性。</p>\n<p>从训练开始，🪓就有意识地把一些算法，尤其是FFT分析这一块，写成了独立的函数去进行一些参数的分析，然后把其他的像是屏幕显示，按键输入，外设驱动，都封装成主循环中的函数，用参数和标志位去控制。不得不说在电赛的信号分析题中还是一种很好用的代码架构。</p>\n<p><img alt=\"Main函数截图\" class=\"lazyload\" /></p>\n<p>本次代码的组织结构，可以清楚的看到，是首先进行ADC采集，FFT计算，然后将参数传入Judge_ModeType函数计算出调制类型，然后进入相应的部分去进行分析和显示。</p>\n<p>2.正式开始</p>\n<p>比赛的那几天，第一天上午8点队友一拿到题目基本上就确定了是D题，然后就开始画系统框图，找模块，搭系统。<br />\n🪓是九点钟到的实验室。然后一看题，哦豁，Ma和Mf！ 这不是老朋友吗，去年省赛这两位重量级，特别是Mf，让无数队伍刹羽而归。<br />\n其奇妙的多值和莫名其妙的算不准问题，难到了一大批电赛壬。<br />\n不过算法方面🪓早有应对，具体请看后文分析。<br />\n队友把混频模块弄好，确定好中频频率后，把混频后的信号通入ADC模块，此时🪓进行了简单的测试，确定了ADC采样率。<br />\n然后就开始了算法的编写。在第一天的中午就把Ma的计算搞定了，精度误差大概在0.05左右。<br />\n然后下午把Mf的算法也基本调试正确了，精度误差在0.2左右，有少量的多值问题，这时候时间已经是第一天晚上的8点，🪓进行了第一次备份。（时常备份真是好习惯）<br />\n<img alt=\"备份截图\" class=\"lazyload\" /><br />\n这是工程的几次备份图，可以看到从7月17日确定了基本平台之后，就是几天一备份，在比赛那几天更是一天备份几次。<br />\n为什么没有使用git之类的版本控制工具呢，因为我不会（其实是懒得建仓库+没找到合适的托管平台，github连不上，gitee不想用）<br />\n然后就是ASK，FSK，PSK的判别、解调以及FSK的h参数计算问题，总的说来，这个花费了🪓一番功夫，也算是最核心的代码部分。<br />\n第二天的中午完成了模拟调制和数字调制两大类的初步判断，下午进一步完成了模拟的AM，FM，CW的进一步判断，以及数字的ASK，FSK，PSK的进一步判断和解调。(充实的一天)<br />\n<img alt=\"PSK解调\" class=\"lazyload\" /><br />\n第二天晚上回寝室的时候🪓在和队友闲扯的时候突然想到了FSK的h参数计算方法，然后在小本本上记了下来。<br />\n第三天，🪓一到实验室就开始着手验证自己的想法，发现完全可以，直接芜湖起飞。<br />\n然后下午的时间就是加入射频开关和滤波器，放大器等原件，完成了系统的整体级联和最后解调波形的实时切换。<br />\n第三天的晚上其实整个系统已经级联并且测试好了。<br />\n最后一天就是一些锦上添花的功能，比如实时频谱显示和QPSK的判断以及高频载波下的解调以及准度的修正，在下午三点左右完成了最后的测试和封箱。<br />\n<img alt=\"封箱\" class=\"lazyload\" /><br />\n总的来说这几天的流程还是稳扎稳打，逐步推进的。我们团队一直以来配合的也很不错，效率贼高，最后呈现出来的效果就是电赛这三天每天晚上11点都回寝室睡觉了，第二天9点再到实验室，也还能完成所有的基础和提高指标并做出3项其他指标。不知不觉中完成了我们团队刚开始接触电赛的时的一个玩笑-希望以后能不熬夜就打完电赛。<br />\n<img alt=\"交作品\" class=\"lazyload\" /><br />\n作为东道主，半夜交作品也是很合理的罢。</p>\n<p>3.省赛测评</p>\n<p>封箱后的第二天就是省测了，总的来说还是蛮顺利的，所有功能都演示出来了，测评表的指标也没有很难的点。<br />\n测完直接和朋友出去快乐吃喝，等待综合测评名单。</p>\n<p>4.综合测评<br />\n由于🪓理论上是纯软件队员(其实🪓也会画板子和焊板子，这就是EEer的素养)，综合测评的硬件大业当然就交给我的两位大爹队友了，🪓只需要在旁边写个报告算个参数就好。<br />\n在准备硬件测评器件，我们测试了各种555电路，二极管检波，微分积分器，加法器，带通滤波器的电路图。<br />\n综合测评那天，一进现场，发现题目竟然是模拟计算器，用来解一个微分方程。<br />\n不过稍加分析，就会发现其本质是文氏桥正弦发生器，三角波发生器，两个积分器，一个微分器，一个加法器的组合。<br />\n这一里面的每一项单独拎出来都很简单，但是在当时时间比较紧促的情况下，我们虽然把电路全部级联出来了，但是在零状态的时候，并没有像计算的那样，产生一个33Hz的自激波形。<br />\n也许是中间的某项RC常数没有配置正确，也许是某一段未修正相差，也许是某一段的偏置需要消除，总是零状态的时候就是妹有出波形。<br />\n说到模拟计算电路，其实这是个展开来讲有非常多可以讲的话题，想进一步研究的同学可以移步CNPP大佬的模拟计算 <a href=\"https://hackaday.io/project/191142-analog-lorenz-attractor-computer/details\" rel=\"noopener nofollow\" target=\"_blank\">https://hackaday.io/project/191142-analog-lorenz-attractor-computer/details</a><br />\n我们也就停止了后面的输入激励。静待比赛时间结束，毕竟这只是一个达标测试，就不冒进去做进一步的冒险了。</p>\n<p>有一说一中午学校提供的饭菜还可以，菜品有土豆烧牛肉，木耳炒蛋，水煮虾，还有酸奶和水果，我TM吃吃吃。</p>\n<p>4.国赛评测</p>\n<p>等🪓玩回来更新</p>\n<h2 id=\"题目分析\">题目分析</h2>\n<p><img alt=\"题目描述1\" class=\"lazyload\" /></p>\n<p><img alt=\"题目描述2\" class=\"lazyload\" /></p>\n<p><strong>题目分析（*的数量为重要程度）</strong></p>\n<ul>\n<li>题目的输入信号有100mv，属于一个比较大的信号，从信号源直出，通过SMA线输入，<strong>信噪比非常高，不需要考虑信号在无线传输过程中被干扰和多径效应等问题</strong></li>\n<li>载波频率2MHz，说实话，是一个比较微妙的频率，刚好超过了市面上单片机内置ADC的最大采样频率，但是对于FPGA外挂的50M左右的高速ADC来说(AD9225:没错正是在下)，又看上去是一个很合适的频率。所以使用单片机的组一般会<strong>选择下混频</strong>，而使用FPGA的组如果选择直采，经过我们当时的分析，可能会遇到一些问题问题，比如FFT后频率分辨率不够，FIR资源消耗大带来的综合慢，数字下混频相位不对齐造成的失真和误差(更别提Vivado的FFT的IP核要想用好其实并不容易，定点FFT很容易产生很大的舍入误差)。肯定有FPGA佬能想到规避或者解决的办法。但是受限与我们当时知识理解的程度，我们还是选择了单片机平台。所以从这也可以看出电赛的出题并不一味地要求好的器件，而更多的是<strong>因地制宜选择方案</strong></li>\n<li><strong>要计算调幅度Ma，这就要求获得调制后信号的频谱，也就是要做FFT</strong>。这就要求ADC的采样频率能够高于中心频点+最大频偏之和的两倍。当然，实际上为了频谱的可读性和频率精确度的考量，一般选择4至6倍的采样频率*</li>\n<li>要计算调频度Mf和最大频偏Δf，同上，还涉及到一些算法的<strong>多值问题</strong>，在后面详细讨论</li>\n<li>要进行模拟调制的解调，可以先通过混频**把信号混到10.7M高中频，使用ADL5511 ，NE564等芯片进行解调</li>\n<li>要识别ASK，FSK，PSK等调制方式，这就要求<strong>把它们的频谱差异提取出来并做好特征区分，以及对于某些非常相似情况下引入多重判断维度来进行区分</strong> 。</li>\n<li>要通过频谱进行FSK的h参数的计算，其实在单片机里做是很难的，但是我们可以<strong>通过FM和FSK的相似性，来进行一些取巧的操作</strong>，这个后面详细讨论**</li>\n<li>要识别待调制波的频率，其实就是<strong>计算调制后波形的FFT相邻频点之间的间隔</strong>，这一点是由调制的性质所导致的，所有调制方式都能通过这种方式判断待调制波的频率*</li>\n<li>要进行数字调制波形的解调，<strong>要结合不同调制方式的特点，混合使用模拟模块和数字域判决的方式来进行解调</strong>，比如ASK使用的是先通过模拟AD8310检波后通过直流量高低来判断0，1波形。FSK使用了数字FIR把频率转变为包络的变化，进行0，1的判决。而PSK使用了先数字域下混频和FIR的方式，把相位的跳变导致的相乘后的包络变化通过滤波器检出</li>\n<li>要综合上述的识别和计算，通<strong>过模拟开关将解调结果通过一个通道显示</strong>在示波器上，并通过AGC等手段，保证电压大于1Vpp*</li>\n</ul>\n<h2 id=\"系统架构\">系统架构</h2>\n<p><img alt=\"系统架构\" class=\"lazyload\" /></p>\n<p>本系统硬件框图如图所示，乍一看非常复杂(实际上也确实很复杂，最后数了一下，作品上一共有26块板子)。别急，让我们慢慢来，一步步分析，<br />\n由于输入信号的峰峰值是100mV，换算一下也就是-16dbm，所以首先经过24dB增益的低噪放ERA-3SM进行放大。<br />\n此时的信号幅度有8dbm，也就是峰峰值1.5Vpp，正好适合后面的各种器件的电压范围。<br />\n然后将信号通过功分器，同时混频到50kHz中频和10.7MHz中频。这是为了一路用来分析，一路用来模拟解调。<br />\n50kHz 的中频信号，经过滤波、放大和电平搬移后，一路经过ADS8688变为数字信号送入单片机。另一路经过检波器 AD8310 和滤波器 UAF42 后检出 ASK 的直流，并送给单片机进一步完成 ASK 信号的定时抽判。<br />\n10.7MHz 的中频信号经过陶瓷滤波器、放大器和射频开关后，分别进行基于 ADL5511 的 AM 包络检波解调和基于 NE564 的FM 解调.<br />\n最后通过 MCU 控制的模拟开关TMUX1109，将解调结果送给示波器显示。在单片机内，通过对 50kHz 的中频信号的频谱分析，得到调制信号类型和调制参数，<br />\n以及FSK和PSK的解调结果的输出，并控制其他模块完成最后结果的汇总输出，以及控制液晶屏显示识别结果和参数。</p>\n<h2 id=\"一些准备工作和小寄巧\">一些准备工作和小寄巧</h2>\n<h3 id=\"电压和dbm的换算\">电压和dbm的换算</h3>\n<p>在射频电路中，为了表示比较小的电压，一般采用对数形式，其中dbm是一个常用的单位，它是在某一阻抗匹配系统下，功率相对于1mW的比值，而由于已经射频电路阻抗一般是50欧姆，所以相当于也知道了电压。<br />\n不过由于功率的计算还涉及到波形的有效值啥的，方波1，正弦0.707，三角波0.57，实际中一般不会自己去算，都是使用这种在线计算器。<br />\n可以记忆一下一些常见的值</p>\n<table>\n<thead>\n<tr>\n<th>正弦波</th>\n<th>50欧姆阻抗下</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-116dbm</td>\n<td>1uVpp</td>\n</tr>\n<tr>\n<td>-56dbm</td>\n<td>1mVpp</td>\n</tr>\n<tr>\n<td>-36dbm</td>\n<td>10mVpp</td>\n</tr>\n<tr>\n<td>-16dbm</td>\n<td>100mVpp</td>\n</tr>\n<tr>\n<td>0dbm</td>\n<td>632mVpp</td>\n</tr>\n<tr>\n<td>4dbm</td>\n<td>1Vpp</td>\n</tr>\n<tr>\n<td>14dbm</td>\n<td>3.3Vpp</td>\n</tr>\n</tbody>\n</table>\n<p>实用小工具 电压和dbm的换算<br />\n<a href=\"https://www.analog.com/cn/design-center/interactive-design-tools/dbconvert.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.analog.com/cn/design-center/interactive-design-tools/dbconvert.html</a></p>\n<p><img alt=\"ADI电压换算工具\" class=\"lazyload\" /><br />\n注意这里的VPeak是峰值，换算成峰峰值的话要乘以2</p>\n<h3 id=\"adc的一些准备工作\">ADC的一些准备工作</h3>\n<p><img alt=\"ADS8688手册\" class=\"lazyload\" /></p>\n<h4 id=\"adc选型\">ADC选型</h4>\n<p>我们本次使用的是ADS8688A作为系统的ADC，它是一个16bit，500KSPS采样率的SAR型ADC。<br />\n它的特点有双极性输入，可配置动态范围，内部基准，八通道MUX采样，误差和漂移都很低，对于本题来说肯定是够用的。<br />\n我们用它主要还是看上了它支持双极性输入和可变动态范围这一点，这样就不用自己做前级的搬移和放大。<br />\n而且自带过压保护，比较耐造。<br />\nPS.我们的STM32H743平台的内置ADC，在某次测试的时候，对单频大幅值信号采样做FFT后，其二次谐波值会大的超出常理，理论上来说是不会有这么大的。<br />\n怀疑内置SAR积分电路被过压橄榄了😓<br />\n所以换用了这个外置的ADC，以后可以开一篇文章讲一下ADC的各种参数，以及这种失真是怎么来的，此时就要请出另一位小信号领域的expert，FloydFish🐟<br />\n可以移步<a href=\"https://www.emoe.xyz/opamp-noise-analyze/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.emoe.xyz/opamp-noise-analyze/</a> ，以及相关的小信号测量。</p>\n<p>驱动代码<br />\n这个的驱动我已经打包好了，下载下来改一下管脚直接用就可以了 <a href=\"https://megrez-hong.oss-cn-shanghai.aliyuncs.com/blogs/ADS8688_Driver.zip\" rel=\"noopener nofollow\" target=\"_blank\">https://megrez-hong.oss-cn-shanghai.aliyuncs.com/blogs/ADS8688_Driver.zip</a><br />\n<strong>ADC的驱动要注意的两点是，一是这个ADC的数据Latch和吐出是根据SPI的速率来的</strong><br />\n所以为了控制采样速率，需要自己控制其中的IO操作后的Delay函数，经过测试，在ARMCC6编译器，O2水平的优化下，使用volatile参数，下面这种delay方法依然可以达到延时效果。</p>\n<p><img alt=\"Delay的实现\" class=\"lazyload\" /></p>\n<p><img alt=\"ADS8688的采样函数\" class=\"lazyload\" /><br />\n二是采样的时候需要关闭中断响应，因为我们不希望采样的时候定时器中断什么的把采样操作打扰了。</p>\n<p>这里的采样率根据实测大概在250K左右，达不到官方的标称的500K。应该是已经达到了软件SPI的IO速度上限了，250kSPS*16bit = 4Mbit的速度了。</p>\n<p>如果要更快一点，可以使用硬件SPI+DMA的方式，但是比赛当前，就不折腾花活了，能用就好。</p>\n<p>另外一点是STM32的H7系列的软SPI的会有的一个毛病，在CubeMX中需要把这些个管脚(CLK,MISO,MOSI,CS)的最大频率设置成Low，否则如果设置为High之类的。</p>\n<p>较大的驱动电流会造成信号的过冲和振铃，造成读出的数据有时是对的，有时读出的会是全1或者全0。</p>\n<p>这一点我是在调试RDA5820的时候发现的，之前用STM32U5驱动RDA5820是正常的，同样的代码在H7下就会有时正确有时不能读出。后来在思考信号完整性链路的时候有了新的想法。</p>\n<p>我个人的看法是，可能由于是H7的驱动电流能力比较强，IO翻转的上升沿相比F1，F7这些要陡峭很多，而数字信号链路是通过一段比较长的XH2.54线接到了外部的模块上，<br />\n根据传输线模型的推论，当传输线长度和1/6上升沿波长可以相比拟时，就有可能造成信号完整性问题。<br />\n所以这时IO驱出来的数字波形会有过冲和振铃等信号完整性问题也是可以理解的。</p>\n<p>验证ADC采集时候，一般会串口打印波形，再使用SerialPlot查看，是不是和理论符合，比如下图就是ASK波形的采样结果。</p>\n<p><img alt=\"ASK的采集到的波形\" class=\"lazyload\" /></p>\n<h3 id=\"fft的准备工作\">FFT的准备工作</h3>\n<ul>\n<li>使用Cmsis DSP库，在Keil的包管理里面勾选即可，最新版本有窗函数的需要从官网上下载（怎么感觉有点似曾相识，我去年暑假好像也写过）</li>\n</ul>\n<p><img alt=\"Keil添加Pack\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>在Keil的设置里面，加入ARM_MATH_CM7, ARM_MATH_LOOPUNROLL这两条宏定义，前面是Cortex版本，需要是MCU的内核版本，可以是CM1，CM4，CM7,后面的是控制数学舍入的，一般来说不用动。<br />\n<img alt=\"keil的编译设置\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>然后在include的地方加入 #include \"arm_math.h\"   和  #include \"arm_const_structs.h\"，然后开辟一个fft的全局数组，就可以愉快的调用啦。</p>\n</li>\n<li>\n<p><strong>FFT的调用</strong>**</p>\n</li>\n</ul>\n<pre><code class=\"language-C\">/* ADC采样并做FFT 结果放在全局数组fft_outputbuf中 */\n/* 做FFT 结果放在全局数组fft_outputbuf中 一次4096个点 */\nvoid FFT(unsigned short *ADC_Buffer, unsigned int SampleRate, unsigned int len, int debug, int serialplot)\n{\n    for(int i=0;i&lt;Sampling_CNT;i++)\n    Global_ADC_Value[i] = ADC_Buffer[i]*3.3/4096;   // 将采样结果转化到0-3.3V\n    \n    for(int i=0;i &lt; FFT_LENGTH;i++)   \n    {\n    fft_inputbuf[i*2] = Global_ADC_Value[i];  // 按手册要求的实部虚部交替的方法填充数组\n    fft_inputbuf[2*i +1] = 0;\n    }\n\n    arm_cfft_f32(&amp;arm_cfft_sR_f32_len4096,fft_inputbuf,0,1); // 执行FFT变换，arm_cfft_sR_f32_len4096为宏，定义旋转因子\n    arm_cmplx_mag_f32(fft_inputbuf,fft_outputbuf,FFT_LENGTH);    // 把运算结果复数求模得幅值\n\n    /* Debug打印区 */\n    \n    if(debug == 1)\n     for(int i=0;i &lt; FFT_LENGTH/2;i++)       // 是否打印FFT每个频点的幅值信息\n       printf(\"%d  %.3lf KHz Mag %.3f\\n\", i,SampleRate*1.0/len*i, fft_outputbuf[i] );\n    \n    if(serialplot == 1)\n     for(int i=0;i &lt; FFT_LENGTH;i++)       //  是否打印fft结果到到SerialPlot\n        printf(\"%.3f\\n\", fft_outputbuf[i]);\n\n}\n</code></pre>\n<p>做完FFT后，我们一般会通过SerialPlot软件来查看FFT的结果和和理论估计是否符合。<br />\n下图是1KHz载波，3KHz频偏的FM频谱的实测图<br />\n<img alt=\"FM的频谱\" class=\"lazyload\" /></p>\n<h3 id=\"代码组织的思路\">代码组织的思路</h3>\n<p>这题是一个经典的测量-分析-显示的题目，所以采用的思路就是先采集，判断调制类型后，进一步去对应的部分进行进一步的分析和显示。<br />\n由于FFT分析后给的参数值不止一个，所以使用了函数传地址的办法。<br />\n<img alt=\"函数传参参数\" class=\"lazyload\" /><br />\n而且由于Keil没有比较方便的代码补全和快捷提示功能，如果所有的算法都在main中实现，会导致代码实现那一段到下面的main函数的里调用段，有一段非常长的距离，所以我个人的建议是把一些更基础的算法代码另外封装到一个Algorithm文件里。<br />\n<img alt=\"Algorithm.c截图\" class=\"lazyload\" /></p>\n<h3 id=\"下节预告鸽了实际上因为神秘赛制的原因我们没有去到比赛现场但是还是国赛二等奖就不献丑了\">下节预告（鸽了，实际上因为神秘赛制的原因，我们没有去到比赛现场，但是还是国赛二等奖，就不献丑了）</h3>\n<ul>\n<li>模拟调制和数字调制两个大类的区分(中心载频与相邻频点之间的距离)</li>\n<li>三种模拟调制的区分(CW, AM, FM)</li>\n<li>三种数字调制的区分(ASK, FSK, PSK)</li>\n<li>各种调制载波频率的计算(频谱最近相邻谱线的距离)</li>\n<li>AM调制的Ma的计算(寻峰算法)</li>\n<li>FM调制的Mf的计算(基于模式匹配的思想)</li>\n<li>FSK调制的h参数的计算(基于和FM的相似带来的模式复用)</li>\n<li>ASK的抽判(基于直流量的定时抽判)</li>\n<li>FSK的抽判(两路FIR后的抽判)</li>\n<li>PSK的抽判(满足特定频率的相位突变点抽判法)</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 14:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/badboy02\">Badboy02</a>&nbsp;\n阅读(<span id=\"post_view_count\">3</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从零开始学Flink：实时数仓与维表时态Join实战",
      "link": "https://www.cnblogs.com/daimajiangxin/p/19624638",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/daimajiangxin/p/19624638\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 12:58\">\n    <span>从零开始学Flink：实时数仓与维表时态Join实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"从零开始学Flink：实时数仓与维表时态Join实战\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3365149/202602/3365149-20260219125729266-340455730.png\" />\n        以电商订单实时数仓为例，演示如何在 Flink SQL 中通过维表时态 Join 将事实流与维度数据关联，构建带用户属性的明细宽表，并结合 Kafka 与 MySQL 环境完成一套可落地的实时数仓入门实践。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在前一篇 <a href=\"https://mp.weixin.qq.com/s/kLxoo6mHi49HvrrmaOdTsA\" rel=\"noopener nofollow\" target=\"_blank\">《Flink 双流 JOIN 实战详解》</a> 中，我们用「订单流 + 支付流」搞懂了事实双流之间的时间关联。</p>\n<p>但在真实的实时数仓项目里，光有事实流还不够，业务同学更关心的是：</p>\n<ul>\n<li>下单用户是新客还是老客</li>\n<li>用户当前的等级、城市、渠道</li>\n<li>商品所属品类、类目层级</li>\n</ul>\n<p>这些信息通常存放在 <strong>维度表</strong>（维表）中，例如 MySQL 的 <code>dim_user</code>、<code>dim_product</code> 等。我们希望在实时计算时，能把「事实流」和「维表」在时间维度上正确地关联起来，构建一张带有完整业务属性的<strong>明细宽表</strong>。</p>\n<p>这就是 <strong>维表时态 Join（Temporal Table Join）</strong> 要解决的问题。</p>\n<p>本文我们就以「订单事实流 + 用户维表」为例，完成一个从 Kafka 到 MySQL 的简易实时数仓 Demo，并重点理解 Flink SQL 中维表时态 Join 的语法和注意事项。</p>\n<h2 id=\"一业务场景与数仓目标\">一、业务场景与数仓目标</h2>\n<p>设想一个简化的电商业务场景：</p>\n<ul>\n<li>Kafka 中有实时写入的 <code>orders</code> 订单事实流</li>\n<li>MySQL 中维护一张 <code>dim_user</code> 用户维表，包含用户等级、所属城市、注册渠道等信息</li>\n</ul>\n<p>我们想要在 Flink 中构建一张「<strong>订单明细宽表</strong>」，字段大致包括：</p>\n<ul>\n<li>订单信息：订单号、下单用户、下单金额、下单时间</li>\n<li>用户属性：用户昵称、等级、城市、注册渠道</li>\n</ul>\n<p>并且要求：</p>\n<ul>\n<li>当我们回看 10 分钟前的某条订单时，看到的是 <strong>当时</strong> 用户的等级和城市，而不是被后续变更“冲掉”的最新值</li>\n</ul>\n<p>这正是 <strong>时态 Join</strong> 和「实时数仓」的关键：<strong>按事件发生时刻回放维度视图</strong>。</p>\n<h2 id=\"二环境前提与依赖准备\">二、环境前提与依赖准备</h2>\n<h3 id=\"1-基础组件\">1. 基础组件</h3>\n<p>本篇默认你已经完成前几篇中的环境准备：</p>\n<ul>\n<li>Flink 1.20.1（WSL2 Ubuntu 下部署）</li>\n<li>Kafka 集群已启动，且能正常写入 / 读取 Topic</li>\n<li>Flink SQL Client 可以正常连接集群</li>\n</ul>\n<p>在此基础上，我们还需要：</p>\n<ul>\n<li>一套可访问的 MySQL（本地或远程均可）</li>\n<li>Flink 的 JDBC Connector JAR 包</li>\n</ul>\n<h3 id=\"2-安装-flink-jdbc-connector\">2. 安装 Flink JDBC Connector</h3>\n<p>和 Kafka 一样，JDBC 连接器也需要以 JAR 包形式放到 Flink 的 <code>lib</code> 目录中。</p>\n<p>以 Flink 1.20.x 对应的 <code>flink-connector-jdbc</code> 为例：</p>\n<ol>\n<li>\n<p>确认 Flink 安装目录（假设为 <code>/opt/flink</code>）：</p>\n<pre><code class=\"language-bash\">export FLINK_HOME=/opt/flink\n</code></pre>\n</li>\n<li>\n<p>下载 JDBC Connector JAR 到 Flink 的 <code>lib</code> 目录：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME/lib\nwget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc/3.3.0-1.20/flink-connector-jdbc-3.3.0-1.20.jar\n</code></pre>\n</li>\n<li>\n<p>如果你使用的是独立集群或远程集群，需要重启 Flink 集群，让新 JAR 在 JobManager/TaskManager 上生效：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME\nbin/stop-cluster.sh\nbin/start-cluster.sh\n</code></pre>\n</li>\n<li>\n<p>重启 Flink SQL Client，使用新 Connector：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME\nbin/sql-client.sh\n</code></pre>\n</li>\n</ol>\n<p>如果你在 Windows + WSL2 上部署，只需在 WSL2 内执行上述命令即可；或者手动下载 JAR 后拷贝到 <code>lib</code> 目录，步骤完全一致。</p>\n<h2 id=\"三准备-mysql-用户维度表-dim_user\">三、准备 MySQL 用户维度表 dim_user</h2>\n<p>首先在 MySQL 中准备一张简单的用户维度表，用来存用户的基础属性。</p>\n<p>在 MySQL 中执行：</p>\n<pre><code class=\"language-sql\">CREATE DATABASE IF NOT EXISTS realtime_dwh;\nUSE realtime_dwh;\n\nCREATE TABLE dim_user (\n  user_id      VARCHAR(32)  PRIMARY KEY,\n  user_name    VARCHAR(64),\n  user_level   VARCHAR(16),\n  city         VARCHAR(64),\n  register_time DATETIME\n);\n\nINSERT INTO dim_user (user_id, user_name, user_level, city, register_time) VALUES\n('u_1', '张三', 'VIP1', '北京', '2025-12-01 10:00:00'),\n('u_2', '李四', 'VIP2', '上海', '2025-12-05 11:00:00'),\n('u_3', '王五', 'VIP1', '广州', '2025-12-10 12:00:00');\n</code></pre>\n<p>为了演示「时态」效果，你可以在后续实验中手动更新某个用户的等级或城市，例如：</p>\n<pre><code class=\"language-sql\">UPDATE dim_user\nSET user_level = 'VIP3'\nWHERE user_id = 'u_2';\n</code></pre>\n<p>这样我们在 Flink 里做时态 Join 时，就能观察“变更前后”的区别。</p>\n<h2 id=\"四在-flink-中注册事实流与维表\">四、在 Flink 中注册事实流与维表</h2>\n<p>接下来回到 Flink SQL Client，把 Kafka 中的订单事实流和 MySQL 中的维表都注册成 Flink 表。</p>\n<h3 id=\"1-kafka-订单事实表-orders\">1. Kafka 订单事实表 orders</h3>\n<p>和上一篇双流 JOIN 类似，我们假设 Kafka 中有一个 <code>orders</code> Topic，写入订单事实数据。</p>\n<p>在 Flink SQL Client 中执行：</p>\n<pre><code class=\"language-sql\">CREATE TABLE orders (\n  order_id     STRING,\n  user_id      STRING,\n  order_amount DECIMAL(10, 2),\n  order_time   TIMESTAMP_LTZ(3),\n  WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND,\n  proc_time AS PROCTIME()\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'orders',\n  'properties.bootstrap.servers' = '127.0.0.1:9092',\n  'properties.group.id' = 'flink-orders-dim',\n  'scan.startup.mode' = 'earliest-offset',\n  'format' = 'json',\n  'json.timestamp-format.standard' = 'ISO-8601'\n);\n</code></pre>\n<p>你可以沿用上一篇中 Kafka 造数的方式，用 <code>kafka-console-producer.sh</code> 发送 JSON 订单数据，只需要保证字段名一致。</p>\n<h3 id=\"2-mysql-用户维表-dim_userjdbc-lookup-表\">2. MySQL 用户维表 dim_user（JDBC Lookup 表）</h3>\n<p>然后把刚才在 MySQL 中建好的 <code>dim_user</code> 注册为 Flink 的 JDBC 表：</p>\n<pre><code class=\"language-sql\">CREATE TABLE dim_user (\n  user_id       STRING,\n  user_name     STRING,\n  user_level    STRING,\n  city          STRING,\n  register_time TIMESTAMP(3),\n  PRIMARY KEY (user_id) NOT ENFORCED\n) WITH (\n  'connector' = 'jdbc',\n  'url' = 'jdbc:mysql://127.0.0.1:3306/realtime_dwh',\n  'table-name' = 'dim_user',\n  'driver' = 'com.mysql.cj.jdbc.Driver',\n  'username' = 'root',\n  'password' = '1qaz@WSX'\n);\n</code></pre>\n<p>注意几点：</p>\n<ul>\n<li><code>PRIMARY KEY (user_id) NOT ENFORCED</code> 告诉 Flink 这是一张以 <code>user_id</code> 为主键的表，是做时态 Join 的前提</li>\n<li>这里使用的是典型的 JDBC Lookup 模式，Flink 会在 Join 时按需去 MySQL 查维度信息</li>\n</ul>\n<p>在生产环境中，你可以把 MySQL 作为维度存储，或者通过 CDC 把维表变更同步到 Kafka，构造成 changelog 流，这些都可以和 Temporal Join 结合使用。</p>\n<h2 id=\"五维表时态-join把订单打上用户维度\">五、维表时态 Join：把订单打上用户维度</h2>\n<p>有了订单事实表 <code>orders</code> 和维度表 <code>dim_user</code>，就可以通过时态 Join 来构建订单明细宽表。</p>\n<h3 id=\"1-基础时态-join-语法\">1. 基础时态 Join 语法</h3>\n<p>Flink SQL 中的 Temporal Table Join 对于 JDBC 这类 <strong>外部维表</strong>，通常采用「处理时间（Processing Time）」语义来做 Lookup Join，典型写法如下：</p>\n<pre><code class=\"language-sql\">SELECT\n  o.order_id,\n  o.user_id,\n  d.user_name,\n  d.user_level,\n  d.city,\n  o.order_amount,\n  o.order_time\nFROM orders AS o\nLEFT JOIN dim_user FOR SYSTEM_TIME AS OF o.proc_time AS d\nON o.user_id = d.user_id;\n</code></pre>\n<p><img alt=\"FlinkJoin\" class=\"lazyload\" /><br />\n这里有几个关键点：</p>\n<ul>\n<li><code>proc_time AS PROCTIME()</code> 是在 <code>orders</code> 上定义的处理时间字段</li>\n<li><code>FOR SYSTEM_TIME AS OF o.proc_time</code> 表示“以 Flink 处理这条订单记录的当前时间，去查维表的一个快照”，这是 JDBC Lookup 支持的典型用法</li>\n<li>Join 条件依然是 <code>user_id</code> 等值关联</li>\n<li>使用 <code>LEFT JOIN</code> 可以保留找不到维度的订单，并用空值来表示“维度缺失”</li>\n</ul>\n<p>在 SQL Client 中执行这段查询，会看到实时流式刷新的结果，每一行订单都带上了对应的用户属性。</p>\n<h3 id=\"2-验证时态效果修改维表再观察-join\">2. 验证时态效果：修改维表再观察 Join</h3>\n<p>为了验证这是“时态 Join”而不是“始终查最新维度”，可以按下面步骤操作：</p>\n<ol>\n<li>\n<p>先往 Kafka 的 <code>orders</code> Topic 写入几条订单数据，例如用户 <code>u_2</code> 下单的记录</p>\n</li>\n<li>\n<p>观察 Flink SQL 中 Join 后的结果，此时 <code>u_2</code> 的等级是 <code>VIP2</code></p>\n</li>\n<li>\n<p>回到 MySQL，执行：</p>\n<pre><code class=\"language-sql\">UPDATE dim_user\nSET user_level = 'VIP3'\nWHERE user_id = 'u_2';\n</code></pre>\n</li>\n<li>\n<p>再写入一批新的订单，仍然是用户 <code>u_2</code></p>\n</li>\n</ol>\n<pre><code class=\"language-bash\">bin/kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic orders\n</code></pre>\n<p>在命令行中输入一条 JSON 数据（按回车发送一条）：</p>\n<pre><code class=\"language-json\">{\"order_id\":\"o_3\",\"user_id\":\"u_2\",\"order_amount\":200.00,\"order_time\":\"2026-02-19T14:42:00Z\"}\n</code></pre>\n<p><img alt=\"FlinkJoin\" class=\"lazyload\" /><br />\n这时你会看到：</p>\n<ul>\n<li>变更前的订单，维度字段仍然显示 <code>VIP2</code></li>\n<li>变更后的订单，维度字段变成了 <code>VIP3</code></li>\n</ul>\n<p>这就说明 Flink 的时态 Join 确实是“按订单发生时刻去回放维度视图”的，而不是简单查当前最新值。</p>\n<h2 id=\"六把结果写回-kafka-或-mysql形成实时数仓明细层\">六、把结果写回 Kafka 或 MySQL，形成实时数仓明细层</h2>\n<p>在真实项目中，我们不会只在 SQL Client 里 <code>SELECT</code> 一下就结束，而是要把 Join 后的订单明细宽表，写回到下游存储，形成实时数仓的一个层级。</p>\n<p>例如，可以把结果写回 Kafka，作为 DWD 层的订单宽表：</p>\n<pre><code class=\"language-sql\">CREATE TABLE dwd_order_user_wide (\n  order_id     STRING,\n  user_id      STRING,\n  user_name    STRING,\n  user_level   STRING,\n  city         STRING,\n  order_amount DECIMAL(10, 2),\n  order_time   TIMESTAMP_LTZ(3),\n  WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'dwd_order_user_wide',\n  'properties.bootstrap.servers' = '127.0.0.1:9092',\n  'properties.group.id' = 'flink-dwd-order-wide',\n  'scan.startup.mode' = 'earliest-offset',\n  'format' = 'json',\n  'json.timestamp-format.standard' = 'ISO-8601'\n);\n\nINSERT INTO dwd_order_user_wide\nSELECT\n  o.order_id,\n  o.user_id,\n  d.user_name,\n  d.user_level,\n  d.city,\n  o.order_amount,\n  o.order_time\nFROM orders AS o\nLEFT JOIN dim_user FOR SYSTEM_TIME AS OF o.proc_time AS d\nON o.user_id = d.user_id;\n</code></pre>\n<p>这样，下游的实时应用或 BI 查询就可以直接订阅 <code>dwd_order_user_wide</code> 这个 Topic，拿到已经打好用户标签的订单明细数据。</p>\n<p>你也可以把结果同步到 MySQL、ClickHouse 等分析型数据库中，构建实时明细表，为报表和可视化提供数据。</p>\n<h2 id=\"七小结与下一步建议\">七、小结与下一步建议</h2>\n<p>通过这篇文章，我们完成了这样一件事：</p>\n<ul>\n<li>在 Kafka 中维护订单事实流 <code>orders</code></li>\n<li>在 MySQL 中维护用户维度表 <code>dim_user</code></li>\n<li>使用 Flink SQL 的 JDBC Connector 把 MySQL 注册为维表</li>\n<li>利用 <code>FOR SYSTEM_TIME AS OF</code> 语法做维表时态 Join</li>\n<li>将 Join 结果写回 Kafka，形成实时数仓中的一张订单明细宽表</li>\n</ul>\n<p>这背后有几个非常重要的实时数仓设计理念：</p>\n<ul>\n<li>事实流是不断追加的事件序列，维表是相对缓慢变更的业务视图</li>\n<li>时态 Join 让你能够“按事件发生的时间点”，回看当时的维度快照</li>\n<li>实时数仓的 DWD 层，往往就是「事实表 + 多个维表时态 Join」后形成的明细宽表</li>\n</ul>\n<p>在后续的文章中，我们可以继续沿着这个方向深入：</p>\n<ul>\n<li>在一个任务里同时关联多张维表，构建更宽的明细表</li>\n<li>引入 CDC，把维表变更实时同步到 Kafka，再在 Flink 中构建 changelog 维表</li>\n<li>把实时数仓的明细层、汇总层（DWS）、指标主题层（ADS）串起来，做一个端到端的实时数仓小项目</li>\n</ul>\n<p>如果你已经跑通了本文的 Demo，不妨试着自己设计一张商品维表 <code>dim_product</code>，再给订单打上商品品类维度，体验一下“事实 + 多维表时态 Join”在 Flink SQL 里的完整味道。</p>\n<hr />\n<p><a href=\"http://blog.daimajiangxin.com.cn\" rel=\"noopener nofollow\" target=\"_blank\">原文来自:http://blog.daimajiangxin.com.cn</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 12:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/daimajiangxin\">代码匠心</a>&nbsp;\n阅读(<span id=\"post_view_count\">13</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "赋予 AI Agent “无限续航”：语义保护型上下文压缩技术解析",
      "link": "https://www.cnblogs.com/noear/p/19624614",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19624614\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 12:21\">\n    <span>赋予 AI Agent “无限续航”：语义保护型上下文压缩技术解析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Solon AI框架的SummarizationInterceptor创新性地解决了AI长对话中的\"上下文窗口爆炸\"问题。这套智能记忆管理系统通过四步策略：锁定核心任务指令、确保行动-结果完整性、保持语义连贯性、添加系统提示，实现了优雅的记忆压缩。其采用插件式设计，支持层级压缩、关键信息提取和向量库归档等策略组合，让AI既能记住核心目标，又能处理超长任务。这种\"有逻辑地遗忘\"机制，有效避免了传统粗暴裁剪导致的逻辑混乱，为AI处理复杂任务提供了\"无限续航\"\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>想象一下，你正在指挥一个超级聪明的AI助手（我们称之为Agent）帮你完成一项复杂任务，比如策划一次跨国旅行。一开始，它记得你的所有要求：想去哪些国家、预算多少、喜欢什么类型的酒店。但随着任务的进行，它需要查询航班、比较酒店、查看天气……每一次查询和思考都会增加它的“记忆负担”。</p>\n<p>如果它“记性”不好，聊到一半就会忘了最开始的要求，或者陷入混乱的逻辑中，这就是开发者常说的“上下文窗口爆炸”问题。</p>\n<p>Solon AI 框架里有一个秘密武器——<code>SummarizationInterceptor</code>（智能记忆压缩器），它能让AI助手像人一样，<strong>既不会忘记初心，又能轻装上阵，实现真正的“无限续航”</strong>。它不是简单粗暴地“断片”，而是一套优雅的“记忆管理大师”。</p>\n<h3 id=\"1为什么不能简单粗暴地断片\">1、为什么不能简单粗暴地“断片”？</h3>\n<p>处理长对话，最直接的想法是：对话太长？那就删掉前面一半吧！但这种“暴力裁剪”对AI来说，会带来两个致命伤：</p>\n<ul>\n<li><strong>忘本（失去初心）：</strong> AI Agent 最开头的系统设定和你交给它的第一个任务，如果被删掉，它就会像无头苍蝇一样，完全不知道自己要干嘛了。</li>\n<li><strong>断片（逻辑断层）：</strong> AI Agent 的工作模式通常是“思考 -&gt; 行动 -&gt; 观察结果”（ReAct）。如果你恰好把它的某个“行动”和对应的“观察结果”给拆散了，它看到结果却不知道为什么会有这个结果，逻辑瞬间混乱，甚至陷入死循环，无法自拔。</li>\n</ul>\n<p>所以，忘记也是一门艺术，需要有策略地忘记。</p>\n<h3 id=\"2智能记忆压缩器是如何工作的\">2、智能记忆压缩器是如何工作的？</h3>\n<p><code>SummarizationInterceptor</code> 就像一个聪明的图书管理员，它不会随意丢弃书籍，而是按照一套精密的流程来整理书架。它的工作分为四步：</p>\n<h4 id=\"第一步锁死初心锚点锁定\">第一步：锁死“初心”（锚点锁定）</h4>\n<p>无论后面的对话有多长，管理员都会第一时间找到两样东西并永久保留：</p>\n<ul>\n<li><strong>任务指令：</strong> 你第一次给AI布置的任务（UserMessage），这是它的“初心”。</li>\n<li><strong>基本守则：</strong> AI的系统设定（SystemMessage），这是它的“行为准则”。</li>\n</ul>\n<p>这两样东西被牢牢锁定，确保AI永不迷失方向。</p>\n<h4 id=\"第二步禁止断片原子对齐\">第二步：禁止“断片”（原子对齐）</h4>\n<p>这是整个机制最核心的“黑科技”。当管理员决定要清理一部分旧内容时，他不会直接动手。他会仔细检查，确保永远不会把 <strong>“行动”</strong> 和 <strong>“结果”</strong> 这对“连体婴儿”给拆散。</p>\n<ul>\n<li><strong>智能检查：</strong> 如果发现准备清理的起点正好落在一个“观察结果”（<code>ToolMessage</code>）或者一个“行动指令”（<code>AssistantMessage</code>）上，管理员会立刻把清理起点向后挪，直到确保每一对“行动-结果”都完整地保留下来。</li>\n</ul>\n<h4 id=\"第三步让记忆更连贯语义补齐\">第三步：让记忆更连贯（语义补齐）</h4>\n<p>为了让你和AI的对话读起来更通顺，管理员还会再多做一步“人情味”的检查。如果清理后的第一条记录是一个“行动结果”，管理员会看看它前面是不是紧跟着一条AI的“思考过程”（Thought）。如果是，他会把这条“思考”也一并留下。这样一来，AI看到的历史永远是从一个思考片段开始的，理解起来更自然。</p>\n<h4 id=\"第四步贴个便利贴提醒断裂感知\">第四步：贴个“便利贴”提醒（断裂感知）</h4>\n<p>在永久保存的“初心”和压缩后的“最近记忆”之间，管理员会贴上一张醒目的 <strong>“小贴士”</strong>：</p>\n<pre><code>--- [系统提示：中间部分历史对话已优化压缩，请根据当前计划和剩余历史继续任务...] ---\n</code></pre>\n<p>这张“小贴士”非常重要，它用AI能理解的语言告诉它：“别担心，中间有些细节我帮你精简了，你专注眼前的任务和核心目标就好。”这能有效防止AI因为记忆断层而产生困惑和幻觉。</p>\n<h3 id=\"3如何实现无限续航\">3、如何实现“无限续航”？</h3>\n<p>通过这套“记忆管理术”，SummarizationInterceptor 把AI的内存变成了一个动态的“新陈代谢系统”：</p>\n<ul>\n<li><strong>内存恒定：</strong> 无论AI运行了10步还是1000步，它一次“思考”所需要处理的信息量（Token数）始终维持在一个安全的范围内。</li>\n<li><strong>逻辑清晰：</strong> 因为“原子对齐”机制，AI看到的每一段记忆都是完整的“思考-行动-反馈”闭环，逻辑链条非常稳固。</li>\n<li><strong>目标永存：</strong> “系统设定”和“用户任务”这两大核心目标永远在线，AI永远不会忘记“我是谁”和“我要去哪”。</li>\n</ul>\n<h3 id=\"4更强大的组合插件式的记忆策略\">4、更强大的组合：插件式的记忆策略</h3>\n<p>这个“记忆管理器”最妙的地方在于，它采用了 <strong>策略模式</strong>，就像手机可以安装不同的APP来扩展功能一样，你可以给它接入不同的“记忆处理插件”。框架已经为我们准备了几款强大的插件：</p>\n<ul>\n<li><strong>层级压缩器：</strong> 它会像滚雪球一样，把旧的记忆摘要和新的对话历史不断融合、压缩，生成一个始终更新的“全局进度摘要”，让记忆像洋葱一样层层包裹，永不丢失核心。</li>\n<li><strong>关键信息提取器：</strong> 它像一个信息审计员，只从对话中提取最核心的“干货”，比如用户要求、获取到的数据、已经失败的尝试等，过滤掉那些啰嗦的思考过程。</li>\n<li><strong>向量库记忆师：</strong> 它会将被清理的详细对话“归档”到一个巨大的知识库里（向量数据库）。当AI需要回忆某个细节时，可以通过一个专门的“召回历史”工具，像用搜索引擎一样把它找回来。</li>\n</ul>\n<p>你可以把这些插件组合起来使用，比如先归档，再提纯，最后压缩，打造一个最适合你AI助手的记忆管理方案。</p>\n<p>应用示例：</p>\n<pre><code class=\"language-java\">import org.noear.solon.ai.agent.react.ReActAgent;\nimport org.noear.solon.ai.agent.react.intercept.SummarizationInterceptor;\nimport org.noear.solon.ai.agent.react.intercept.summarize.*;\nimport org.noear.solon.ai.agent.session.InMemoryAgentSession;\nimport org.noear.solon.ai.chat.ChatModel;\n\nCompositeSummarizationStrategy compositeStrategy = new CompositeSummarizationStrategy();\ncompositeStrategy.addStrategy(new KeyInfoExtractionStrategy(chatModel));\ncompositeStrategy.addStrategy(new HierarchicalSummarizationStrategy(chatModel));\nSummarizationInterceptor summarizationInterceptor = new SummarizationInterceptor(12, compositeStrategy);\n\nReActAgent agent = ReActAgent.of(chatModel)\n        .defaultInterceptorAdd(summarizationInterceptor)\n        .build();\n</code></pre>\n<h3 id=\"5总结\">5、总结</h3>\n<p><code>SummarizationInterceptor</code> 的设计哲学是：<strong>有尊严地裁剪，有逻辑地遗忘</strong>。</p>\n<p>它不仅仅是一个节省计算资源的工具，更是AI能够保持逻辑连贯、处理超长复杂任务的“护航者”。有了它，开发者可以放心地让AI助手去处理那些需要几个小时甚至几天才能完成的、真正复杂和智能化的工作，而不用担心它会中途“失忆”或“精神错乱”。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 12:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">8</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]持久化状态的提取",
      "link": "https://www.cnblogs.com/jaydenai/p/19623976/read-state",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19623976/read-state\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 07:58\">\n    <span>[拆解LangChain执行引擎]持久化状态的提取</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        前面以`写入`的角度介绍了BaseCheckpointSaver的`put/aput`和`put_writes/aput_writes`方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面以<code>写入</code>的角度介绍了BaseCheckpointSaver的<code>put/aput</code>和<code>put_writes/aput_writes</code>方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。</p>\n<h2 id=\"1-读取checkpoint和pinding-write\">1. 读取Checkpoint和Pinding Write</h2>\n<p>如下这个<code>CheckpointTuple</code>用来表示Checkpoint和Pending Write的结合体。除了这两个核心成员，它还包括当前的执行配置（config和parent_config）和元数据。具体的Pending Write由Task ID、Channel名称和写入数组组成的三元组PendingWrite表示。</p>\n<pre><code class=\"language-python\">class CheckpointTuple(NamedTuple):\n    config: RunnableConfig\n    checkpoint: Checkpoint\n    metadata: CheckpointMetadata\n    parent_config: RunnableConfig | None = None\n    pending_writes: list[PendingWrite] | None = None\nPendingWrite = tuple[str, str, Any]\n</code></pre>\n<p>BaseCheckpointSaver提供了用于读取CheckpointTuple的<code>get_tuple/aget_tuple</code>方法。作为参数的RunnableConfig对象需要提供Thread ID（必需）和Checkpoint 命名空间（可选）。如果没有提供Checkpoint ID，方法会返回最终的状态，如果尚未完成，得到的CheckpointTuple元组可能包含Pending Write。如果提供了Checkpoint ID, 只有在此ID对应最新的Checkpoint且后一Superstep尚未完成，返回的CheckpointTuple元组才有可能包含Pending Write。对于实现在BaseCheckpointSaver中的另一组方法<code>get/aget</code>，会在内部调用<code>get_tuple/aget_tuple</code>方法，并返回CheckpointTuple元组封装的Checkpoint对象。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):    \n    def get(self, config: RunnableConfig) -&gt; Checkpoint | None\n    async def aget(self, config: RunnableConfig) -&gt; Checkpoint | None\n\n    def get_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n    async def aget_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n\n    def list(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[CheckpointTuple]:\n    async def alist(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[CheckpointTuple]\n</code></pre>\n<p>对于InMemorySaver来说，它的get_tuple/aget_tuple方法会从RunnableConfig配置中提取Thread ID和Checkpoint命名空间，如果指定了Checkpoint ID，它们会利用这三个值从storage和blobs字典中提取相应数据组成返回的CheckpointTuple对象。如果没有指定Checkpoint ID，就选择最近的那一个Checkpoint的ID。</p>\n<p>BaseCheckpointSaver的alist方法会列出并检索与指定条件匹配的所有CheckpointTuple，这些元组构成了一段 “历史” 。该方法主要用于会话管理、审计历史轨迹以及状态回溯，它具有如下的参数：</p>\n<ul>\n<li>config：如果RunnableConfig如果提供了Thread ID，该方法将仅返回该特定线程下的Checkpoint。如果不提供，在某些实现中会列出所有线程的最新Checkpoint（取决于具体的实现逻辑）。</li>\n<li>filter：提供基于元数据的过滤功能，例如 {\"status\": \"completed”} ，这在需要筛选特定业务状态的Checkpoint时非常有用。</li>\n<li>before：以RunnableConfig对象的形式提供Checkpoint ID，返回在此 之前创建的记录。这对于实现 “时间旅行” 功能至关重要，允许你查看图执行历史中的旧版本。</li>\n<li>limit：用于限制返回数据的数量。</li>\n</ul>\n<p>我们通过如下的实例演示来进一步了解持久化。我们构建了一个由foo、bar1和bar2这三个Node组成的Pregel，启动的时候利用输入针对通道foo的写入驱动执行节点foo，后者完成后写入通道bar驱动节点bar1和bar2并行执行。三个Node的处理函数都是handle，它会将传入的Node名称写入一个BinaryOperatorAggregate类型Channel（nodes），由此确定成功执行的Node。如果调用handle函数将interrupt参数指定为True，它会通过抛出一个GraphInterrupt异常模拟一个中断。在我们的演示实例中，节点foo和bar2会执行成功，中断会发生在节点bar1上。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue, BinaryOperatorAggregate\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.errors import GraphInterrupt\nimport operator, json\n\ndef handle(node_name: str, interrupt: bool = False) -&gt; list[str]:\n    if interrupt:\n        raise GraphInterrupt(\"manual interrupt\")\n    return [node_name]\n\nfoo = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: handle(\"foo\"))\n    .write_to(nodes=lambda x: x, bar=lambda _: \"triggered by foo\")\n)\n\nbar1 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar1\", interrupt=True))\n    .write_to(\"nodes\")\n)\n\nbar2 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar2\", interrupt=False))\n    .write_to(\"nodes\")\n)\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar1\": bar1, \"bar2\": bar2},\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n        \"nodes\": BinaryOperatorAggregate(list, operator.add),\n    },\n    checkpointer=InMemorySaver(),\n    input_channels=[\"foo\"],\n    output_channels=[\"nodes\"],\n)\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke({\"foo\": \"triggered by user\"}, config=config)\nassert result[\"nodes\"] == [\"foo\", \"bar2\"]\n\n(config, checkpoint, metadata, parent_config, pending_writes) = (\n    app.checkpointer.get_tuple(config)\n)\nprint(f\"config:\\n{json.dumps(config, indent=4)}\")\nprint(f\"checkpoint:\\n{json.dumps(checkpoint, indent=4)}\")\nprint(f\"metadata:\\n{json.dumps(metadata, indent=4)}\")\nprint(f\"parent_config:\\n{json.dumps(parent_config, indent=4)}\")\nprint(f\"pending_writes:\\n{json.dumps(pending_writes, indent=4)}\")\n</code></pre>\n<p>我们为创建的Pregel对象提供了一个InMemorySaver作为它的Checkpointer，并在调用时利用提供的RunnableConfig设置了Thread ID。由于我们将通道nodes作为输出，所以调用结果会反映三个Node的执行状态（只有节点foo和bar2成功执行）。我们随后传入相同的配置调用Checkpointer的get_tuple方法，并将得到的CheckpointTuple元组进行拆包输出。</p>\n<pre><code class=\"language-json\">config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\"\n    }\n}\ncheckpoint:\n{\n    \"v\": 4,\n    \"ts\": \"2026-01-19T10:17:07.498064+00:00\",\n    \"id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\",\n    \"channel_versions\": {\n        \"foo\": \"00000000000000000000000000000001.0.06769883673554666\",\n        \"nodes\": \"00000000000000000000000000000002.0.3174924500871408\",\n        \"bar\": \"00000000000000000000000000000002.0.3174924500871408\"\n    },\n    \"versions_seen\": {\n        \"__input__\": {},\n        \"foo\": {\n            \"foo\": \"00000000000000000000000000000001.0.06769883673554666\"\n        }\n    },\n    \"updated_channels\": [\n        \"bar\",\n        \"nodes\"\n    ],\n    \"channel_values\": {\n        \"foo\": \"triggered by user\",\n        \"nodes\": [\n            \"foo\"\n        ],\n        \"bar\": \"triggered by foo\"\n    }\n}\nmetadata:\n{\n    \"source\": \"loop\",\n    \"step\": 0,\n    \"parents\": {}\n}\nparent_config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24ee-671f-bfff-2e9f3ca91778\"\n    }\n}\npending_writes:\n[\n    [\n        \"30b17cb1-76f1-3c5a-0d32-33f544fcabdf\",\n        \"nodes\",\n        [\n            \"bar2\"\n        ]\n    ],\n    [\n        \"e126d089-c354-0ac8-bb9e-b12bbe3f20b8\",\n        \"__interrupt__\",\n        \"manual interrupt\"\n    ]\n]\n</code></pre>\n<p>整个执行过程涉及三个Superstep，会创建两个Checkpoint。第一个Checkpoint的创建发生在调用invoke方法的时候，此时提供的输入被写入Channel，首批待执行的Node（foo）准备就绪，此时创建的Checkpoint 记录了 <code>接收到了初始任务，但尚未开始执行任何Node</code> 的状态。此时对应的Superstep序号为-1，输出结果的parent_config部分提供了此Checkpoint的ID。</p>\n<p>第二个Checkpoint是为序号为0的Superstep创建的，此时节点foo成功执行，执行结果最终被输入目标Channel，创建的Checkpoint反映的就是的状态，config部分提供了此Checkpoint的ID。上面的输出还提供了这个Checkpoint的时间戳、Channel的版本和值、涉及Node的可见Channel（f和版本，以及涉及更新的Channel列表。</p>\n<p>由于最后一个Superstep（序号为1）没有完全结束，它们会利用对应的Pending Write来描述。上面输出的第一个Pending Write表示成功执行的节点bar针对通道nodes的写入，第二个针对特殊系统Channel <code>__interrupt__</code>的写入很明显就是因为节点bar1的中断导致。</p>\n<h2 id=\"2-读取状态快照\">2. 读取状态快照</h2>\n<p>BaseCheckpointSaver提供了get_tuple/aget_tuple方法以Checkpoint_Tuple的形式返回最新或者基于过去时间点的状态。对于CheckpointTuple这个五元组，除了Checkpoint和PendingWrite列表，还包括Checkpoint的元数据和相关配置。这个元组主要由执行引擎内部使用的，针对最终开发者来说可读性差点，所以Pregel类定义了如下所示的<code>get_state/aget_state</code>方法，它们提供的StateSnapshot类型更具可读性。</p>\n<pre><code class=\"language-python\">class Pregel(\n    PregelProtocol[StateT, ContextT, InputT, OutputT],\n    Generic[StateT, ContextT, InputT, OutputT]): \n\n    def get_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n    async def aget_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n\n    def get_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[StateSnapshot]\n    async def aget_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[StateSnapshot]\n</code></pre>\n<p>当我们调用Pregel对象的<code>get_state/aget_state</code>方法的时候，它会将指定的RunnableConfig对象作为参数调用Checkpointer的<code>get_tuple/aget_tuple</code>方法，并利用返回的Checkpoint_Tuple元组生成StateSnapshot对象。StateSnapshot的<code>values</code>字段提供的值来源于Checkpoint对象的channel_values字段，它的<code>metadata</code>字段表示的CheckpointMetadata 直接来源于Checkpoint_Tuple的同名字段，而<code>config</code>和<code>parent_config</code>返回的RunnableConfig则是由Checkpoint_Tuple同名字段于元数据合并而成。表示快照创建时间的<code>created_at</code>对应于Checkpoint_Tuple表示时间戳的ts字段，而interrupts返回的Interrupt列表是根据中断类型的PendingWrite构建的。</p>\n<pre><code class=\"language-python\">class StateSnapshot(NamedTuple):\n    values: dict[str, Any] | Any\n    next: tuple[str, ...]\n    config: RunnableConfig\n    metadata: CheckpointMetadata | None\n    created_at: str | None\n    parent_config: RunnableConfig | None\n    tasks: tuple[PregelTask, ...]\n    interrupts: tuple[Interrupt, ...]\n\nclass PregelTask(NamedTuple):\n    id: str\n    name: str\n    path: tuple[str | int | tuple, ...]\n    error: Exception | None = None\n    interrupts: tuple[Interrupt, ...] = ()\n    state: None | RunnableConfig | StateSnapshot = None\n    result: Any | None = None\n</code></pre>\n<p>StateSnapshot的<code>tasks</code>字段返回一组PregelTask对象，它们表示根据Checkpoint创建的待执行任务，<code>next</code>字段以元组的形式返回这些任务的Node名称。对于最新的Checkpoint，若下一个Superstep尚未完成，PregelTask的信息还会利用对应的Pending Write进一步完善。我们可以利用PregelTask对象得到每个任务的ID、Node名称、执行路径、抛出的异常和中断（根据异常和中断类型的PendingWrite创建），而<code>state</code>和<code>result</code>分别承载这任务的状态和输出结果。如果整个执行流程结束，自然就没有所谓后续任务的说法，此时StateSnapshot的tasks字段为空。</p>\n<p>除了返回一个具体的状态快照，Pregel类还定义了<code>get_state_history/aget_state_history</code>，它们的参数列表与BaseCheckpointSaver的<code>list/alist</code>方法完全一致。当这两个方法被调用的时候，Pregel会调用Checkpointer的<code>list/alist</code>方法，并将得到Checkpoint_Tuple元组转换成StateSnapshot对象。<code>get_state_history/aget_state_history</code>方法返回的迭代器以时间逆序的方式返回对应的状态快照。</p>\n<p>如下这个程序演示了一个具体的Pregel对象的历史由哪些快照组成，每个快照又反映当时的状态。我们构建的Pregel对象由四个Node组成，调用时指定通道foo会驱动执行节点foo，它执行结束后写入通道bar驱动bar1、bar2和bar3并行执行。除了bar1能够顺利执行外，我们为bar2设置了一个中断，让bar3抛出异常。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.checkpoint.memory import  InMemorySaver\nfrom langgraph.types import interrupt\n    \ndef handle(node_name: str, halt : bool, raise_error: bool) -&gt; None:\n    if halt:\n        _ = interrupt(f\"Manually be interrupted at {node_name}\")\n    if raise_error:\n        raise Exception(f\"Manually raised error at {node_name}\")\n\nfoo = (NodeBuilder()\n       .subscribe_to(\"foo\", read=False)\n       .do(lambda _: handle(\"foo\", halt=False, raise_error=False))\n       .write_to(bar = lambda _:None))\nbar1 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar1\", halt=False, raise_error=False)))\nbar2 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar2\", halt=True, raise_error=False)))\nbar3 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar3\", halt=False, raise_error=True)))\napp = Pregel(\n    nodes={\n        \"foo\": foo,\n        \"bar1\": bar1,\n        \"bar2\": bar2,\n        \"bar3\": bar3\n    },\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer= InMemorySaver())\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\n\ntry:\n    app.invoke(input={\"foo\": \"begin\"},config=config)\nexcept Exception as e:\n    pass\n\nfor snapshot in app.get_state_history(config):\n    print(f\"\"\"\nvalues: {snapshot.values}\nnext: {snapshot.next}\ninterrupts: {snapshot.interrupts}   \ntasks:\"\"\")\n    for task in snapshot.tasks:\n        print(f\"\"\"  id: {task.id}\n    name: {task.name}\n    path: {task.path}\n    error: {task.error} \n    interrupts: {task.interrupts}\n    state: {task.state}\n    result: {task.result}\"\"\")\n</code></pre>\n<p>在完成了针对Pregel对象的调用后，我们采用相同的配置调用它的<code>get_state_history</code>方法得到完整的历史，并将承载历史片段的StateSnapshot信息打印出来。整个过程涉及三个Superstep，前两个成功完成的Superstep会提供两个Checkpoint，第三个尚未完成的Superstep只提供针对三个Node任务的Pending Write。</p>\n<pre><code class=\"language-json\">values: {'start': 'begin', 'bar': None}\nnext: ('bar1', 'bar2', 'bar3')\ninterrupts: (Interrupt(value='Manually be interrupted at bar2', \n    id='26f309d618c42ff31d2b3404369232e4'),)\ntasks:\n  id: dbb24ec5-f1ba-f845-7351-54e88f34db0f\n    name: bar1\n    path: ('__pregel_pull', 'bar1')\n    error: None\n    interrupts: ()\n    state: None\n    result: {}\n  id: 794fffda-2e6c-0685-0d44-3ed6c57ca366\n    name: bar2\n    path: ('__pregel_pull', 'bar2')\n    error: None\n    interrupts: (Interrupt(value='Manually be interrupted at bar2', \n        id='26f309d618c42ff31d2b3404369232e4'),)\n    state: None\n    result: None\n  id: 1055ec55-49dc-0629-86b5-661a2614f349\n    name: bar3\n    path: ('__pregel_pull', 'bar3')\n    error: Exception('Manually raised error at bar3')\n    interrupts: ()\n    state: None\n    result: None\n\nvalues: {'start': 'begin'}\nnext: ('foo',)\ninterrupts: ()\ntasks:\n  id: 88904475-3edc-733a-d84d-98aa6d3f5e80\n    name: foo\n    path: ('__pregel_pull', 'foo')\n    error: None\n    interrupts: ()\n    state: None\n    result: {'bar': None}\n</code></pre>\n<h2 id=\"3任务路径\">3.任务路径</h2>\n<p>还记得我们前面说个任务的两种创建方式，一种是站在Node的角度，通过查看订阅Channel的更新状态确定是否应该执行，我们称这种任务创建模式为<code>Pull模式</code>。与之相对的则是<code>Push模式</code>，Node利用写入<code>__pregel_tasks</code>这个特殊Channel的Send对象决定后续执行的Node，执行引擎会从此Channel读取Send对象的来创建对应的任务。任务路径的第一部分通常就反映了任务的驱动模式，对应的值为<code>__pregel_pull</code>和<code>__pregel_push</code>。</p>\n<p>由于前面演示的都是基于Channel订阅驱动的任务，所以路径采用(“__pregel_pull”,{node})的形式。如下的程序演示“Push任务”的路径，我们构建的Pregel由四个Node（foo、bar1、bar2和bar3）组成，节点foo的处理函数最终会生成三个针对其他Node的Send对象，并写入“__pregel_tasks”Channel以驱动它们并行执行。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.pregel._read import PregelNode\nfrom langgraph.pregel._write import ChannelWrite, ChannelWriteTupleEntry\nfrom langgraph.types import Send\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nentry = ChannelWriteTupleEntry(lambda args: [(\"__pregel_tasks\", args)])\nwriter = ChannelWrite(writes=[entry])\nfoo: PregelNode = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: [Send(node=node, arg=\"foo\") for node in [\"bar1\", \"bar2\", \"bar3\"]])\n).build()\nfoo.writers.append(writer)\n\nbars = {name: NodeBuilder() for name in [\"bar1\", \"bar2\", \"bar3\"]}\n\napp = Pregel(\n    nodes={\"foo\": foo, **bars},\n    channels={\n        \"foo\": LastValue(None),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer=InMemorySaver(),\n)\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke(input={\"foo\": None}, config=config, interrupt_before=\"bar2\")\nsnapshot = app.get_state(config)\nfor task in snapshot.tasks:\n    print(f\"{task.name}:{task.path}\")\n</code></pre>\n<p>为了能看到三个任务，我们在在最后一个Superstep中产生一个中断，为此我们在调用的时候通过指定<code>interrupt_before</code>参数在执行节点bar2前中断。我们随后调用Pregel的get_state方法得到描述最终状态的StateSnapshot，并输出所有任务的执行路径。从如下的输出可以看出，由于是三个基于Push模式的任务，所以组成路径的第一个部分内容为 <code>__pregel_push</code> 。每个任务由 <code>__pregel_tasks</code> Channel的Send对象构建而成，第二部分的数组代表对应的Send对象在Channel中的索引。由于整个程序只有唯一的Pregel对象，不设置子图调用，所以第三部分返回False。</p>\n<pre><code>bar1:('__pregel_push', 0, False)\nbar2:('__pregel_push', 1, False)\nbar3:('__pregel_push', 2, False)\n</code></pre>\n<h2 id=\"4状态嵌套\">4.状态嵌套</h2>\n<p>这里我们有必要提一下PregelTask类的<code>state</code>字段。从给出的定义可以看出，它可以返回一个RunnableConfig配置，也可以返回一个StateSnapshot对象。如果任务涉及子图的调用，并且在调用get_state/aget_state方法时将subgraphs参数设置为True，它的state字段就会返回一个描述子图当前状态的<code>StateSnapshot</code>对象。借助于反映执行链路和调用顺序的Checkpoint命名空间，就可以形成的嵌套层次结构（state =&gt;task=&gt;state）使我们可以可以看到一个任务完整的调用链条。</p>\n<p><img alt=\"Alternative Text\" class=\"lazyload\" /></p>\n<p>以如下这个验证程序为例。我们构建了两个具有单一Node的Pregel对象app和sub_graph，前者的节点main_node以子图调用的方式调用sub_graph，后者的Node命名为 “sub_node”。为了在StateSnapshot中将任务保留下来，我们在两个Node中引入了中断。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import interrupt\nfrom typing import Any\nfrom langgraph.types import StateSnapshot\n\nsub_node = (NodeBuilder()\n    .subscribe_to(\"start\")\n    .do(lambda _: interrupt(\"manual interrupt\"))\n)\nsub_graph = Pregel(\n    nodes={\"sub_node\": sub_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n)\n\ndef handle(args: dict[str, Any]) -&gt; None:\n    sub_graph.invoke(input={\"start\": \"begin\"})\n    interrupt(\"main graph interrupt\")\n\nmain_node = NodeBuilder().subscribe_to(\"start\").do(handle)\napp = Pregel(\n    nodes={\"main_node\": main_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n    checkpointer=InMemorySaver())\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\napp.invoke(input={\"start\": \"begin\"}, config=config)\nsnapshot = app.get_state(config, subgraphs=True)\n\nindent = -1\ndef print_snapshot(snapshot: StateSnapshot) -&gt; None:\n    global indent\n    indent += 1\n    config = snapshot.config[\"configurable\"]\n    print(f\"{'  ' * indent}checkpoint_ns: {config.get('checkpoint_ns', None)}\")\n    for task in snapshot.tasks:\n        print(f\"{'  ' * indent}task: {task.name}:{task.id}\")\n        if sub_snapshot := task.state:\n            print_snapshot(sub_snapshot)\n\nprint_snapshot(snapshot)\n</code></pre>\n<p>在完成调用后，我们调用作为主图的Pregel对象的<code>get_state</code>方法，并将参数subgraphs设置为True。我们调用print_snapshot函数输出StateSnapshot提供的Checkpoint命名空间和任务的名称与ID。如果描述任务的PregelTask对象的state字段也是一个StateSnapshot对象，那么继续递归调用此函数。从如下的输出可以看出，作为子图的Pregel将当前任务的名称和ID的组合作为Checkpoint命名空间，这样的结构确保了 “主图” 恢复的时候能够精准地加载 “子图” 的状态。</p>\n<pre><code>checkpoint_ns: \ntask: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    checkpoint_ns: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    task: sub_node:a483bfb8-bcc6-92b3-2f64-9f9e9f4fe158\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 07:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 学习笔记：Agent 的基础应用",
      "link": "https://www.cnblogs.com/owlman/p/19623216",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19623216\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 16:09\">\n    <span>AI 学习笔记：Agent 的基础应用</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记对应的是《[[关于 AI 的学习路线图]]》一文中所规划的第四个学习阶段。其中记录了我学习 AI Agent 的工作原理，并将其应用于实际工作场景的全过程，以及在该过程中所获得的心得体会。同样的，这些内容也将成为我 AI 系列笔记的一部分，被存储在本人 Github 上的<a href=\"https://github.com/owlman/CS_StudyNotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机学习笔记库</a>中，并予以长期维护。</p>\n</blockquote>\n<h2 id=\"ai-agent-简介\">AI Agent 简介</h2>\n<p>在理解了 LLM 在生产环境中所扮演的角色之后，初学者们接下来要思考的问题是：如何让它参与到自己的实际工作中？到目前为止（截至 2026 年 2 月），这个问题最具可行性的解决方案是：构建并使用 AI Agent。</p>\n<h3 id=\"为什么需要-ai-agent\">为什么需要 AI Agent</h3>\n<p>在早期，大多数用户是通过 Web 端或移动端的即时通信应用，主要以文本聊天的方式来使用 LLM 的（例如 ChatGPT、豆包等）。这类应用本质上是基于 HTTP API 构建的人机交互界面，其主要交互模式是“输入文本—生成文本”的往返过程。我们之前在《[[LLM 的部署与测试]]》一文中基于 PyTest 框架编写的测试用例，实际上模拟的就是这种交互模式。</p>\n<p>尽管，这类应用极大地降低了 LLM 的使用门槛，使其成为了一种能惠及普通用户的智能问答工具，但 AI 所能带来的生产力也在很大程度上被局限在了这种即时通信式的交互模式中。因为在这种交互模式下，LLM 只能根据用户当前的输入来生成文本结果，无法主动访问本地环境、调用系统资源或执行实际任务。更重要的是，LLM 在这种模式下并不处于一个持续运行的控制结构之中，它只在收到请求时做出一次性响应，无法负责具体的工作流程与状态管理。</p>\n<p>试想一下，如果 LLM 已经具备了复杂的任务规划与执行能力，我们却把它限制在聊天窗口中，这岂不是太浪费了？正是为了避免这种浪费，并赋予 LLM 在特定环境中“执行操作”的能力，AI 的研究者们重新审视了 AI Agent 这一在 20 世纪 80-90 年代就已经形成体系的概念，并在工程实践领域给了它全新的实现形式。</p>\n<p>关于 AI Agent 这个概念，读者可以参考我之前在《[[关于 AI 的学习路线图]]》中推荐的《人工智能：现代方法》一书给出的定义，原文如下：</p>\n<blockquote>\n<p>An agent is anything that can perceive its environment through sensors and act upon that environment through actuators.</p>\n<p>翻译过来就是：</p>\n<p>任何能够通过传感器感知环境，并通过执行器对环境产生影响的实体，都可以称为 Agent。</p>\n</blockquote>\n<p>这个定义成为了后来所有 AI Agent 应用的理论基础。由此也可以看出，AI Agent 的核心功能并不是提升 LLM 本身的智能水平，而是赋予它与外部系统交互的能力，使其能够参与到真实的工作流程之中。从本质上来说，这其实是 AI 应用在客户端方面的一次角色转变，它现在从单纯的答题工具被转变成了一个可以参与任务执行的系统组件。在特定的应用场景中，这种架构上的转变为工作流程的自动化提供了可行的工程路径。</p>\n<h3 id=\"ai-agent-的工作原理\">AI Agent 的工作原理</h3>\n<p>下面，让我们来了解一下 AI Agent 具体是怎么工作的。在传统聊天式的 AI 应用中，我们可以将其基本的执行模式简单概括为：</p>\n<blockquote>\n<p>用户输入 → 模型推理 → 输出结果 → 结束</p>\n</blockquote>\n<p>这种执行模式本质上是一次性的请求—响应（request-response）结构。即在这种执行模式下，LLM 会在接收到用户输入后生成文本，然后就立即退出当前工作流程，不再参与后续状态管理了。AI Agent 与这类应用的核心差异就在于：它在执行模式中引入了一个可持续运行的控制循环（control loop）。这种循环结构将 LLM 从被动接收用户输入的文本生成器，转变成了用于驱动整个程序执行结构的决策组件。换言之，Agent 的存在将 AI 应用的基本执行模式从“请求—响应”转变成了下面这样一个“感知—决策—执行”的循环结构：</p>\n<blockquote>\n<p>感知环境 → 生成决策 → 执行动作 → 更新环境状态 → 再次感知</p>\n</blockquote>\n<p>这个循环结构会持续运行下去，直到任务完成或满足终止条件。从该执行模式可以看出，一个典型的 AI Agent 应用通常包含以下几个核心组件：</p>\n<ul>\n<li><strong>LLM</strong>：该组件负责理解当前任务目标、分析上下文状态并生成下一步行动决策，不负责直接执行外部操作；</li>\n<li><strong>工具接口</strong>：该组件负责将 LLM 生成的结构化指令转换为实际可执行的操作，例如：调用 API、访问数据库、读写文件、执行系统命令、触发外部服务等。它们通常由开发者定义，并通过函数调用或插件机制暴露给模型；</li>\n<li><strong>状态管理</strong>：该组件负责维护任务的中间状态，例如：当前任务进度、已执行步骤、外部环境变化、历史决策记录等。这些状态通常会被存储在内存变量、数据库、向量存储、文件系统等介质中，如果缺乏有效的状态管理机制，我们就难以构建一个真正的 Agent 应用；</li>\n<li><strong>控制器</strong>：该组件负责驱动循环、判断是否继续执行、解析模型输出、调用对应工具、处理异常与失败重试。从架构角度来看，控制器可被视为 Agent 系统的“骨架”，而 LLM 只是其中的决策模块。</li>\n</ul>\n<p>基于以上核心组件，我们就可以简单地归纳出一个 Agent 应用的工作流程，其主要步骤如下：</p>\n<ol>\n<li>接收任务目标</li>\n<li>将目标与当前状态输入 LLM</li>\n<li>LLM 输出下一步行动计划（通常为结构化格式）</li>\n<li>控制器解析输出</li>\n<li>调用相应工具执行</li>\n<li>更新状态</li>\n<li>判断是否完成任务</li>\n<li>若未完成，则进入下一轮循环</li>\n</ol>\n<p>从工程角度来看，AI Agent 是一种新的系统架构模式，它通过持续运行的控制循环，使模型能够参与真实任务的执行过程，而不仅仅是生成文本结果。</p>\n<h2 id=\"ai-agent-的使用方法\">AI Agent 的使用方法</h2>\n<p>在了解了使用 AI Agent 的必要性及其工作原理之后，接下来就可以正式开始研究如何将它运用到自己的日常工作中了。而当我们要讨论 AI Agent 在实际工作中的使用方法时，首先需要回答的问题是“它运行在哪里、由谁控制、承担什么责任”。不同的运行形态，决定了它在工程系统中的角色边界。下面，让我们按照\"运行在哪里\"这个维度分三类来介绍 AI Agent 的使用方法，以及它们在这些应用场景中所承担的任务角色。</p>\n<h3 id=\"命令行工具型-agent\">命令行工具型 Agent</h3>\n<p>对于大多数开发者而言，以命令行工具的形式使用 AI Agent 是一种更符合工程直觉的方式。它运行在熟悉的终端环境中，可以直接访问文件系统与系统命令，因此看起来类似于自动化脚本。当然了，与传统脚本不同的是，AI Agent 的内部决策路径并非预先编写，而是由 LLM 在循环结构中动态生成。这类 AI Agent 应用的典型代表是 <a href=\"https://github.com/anthropics/claude-code\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code</a>，目前同类的主流应用还包括 <a href=\"https://github.com/anomalyco/opencode\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode</a>、<a href=\"https://github.com/openai/codex\" rel=\"noopener nofollow\" target=\"_blank\">Codex CLI</a>、<a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener nofollow\" target=\"_blank\">Gemini CLI</a>、<a href=\"https://github.com/iflow-ai/iflow-cli\" rel=\"noopener nofollow\" target=\"_blank\">iFlow CLI</a> 等。下面，我们首先要做的就是：先将这些工具安装到自己所在的操作系统中。</p>\n<h4 id=\"安装与配置\">安装与配置</h4>\n<p>命令行工具型 Agent 的安装方式其实是非常简单的。因为，虽然它们各自针对 MacOS/Linux/Windows 系统提供了不同的 bash/powershell 安装脚本，或者基于 homeberw/pacman/scoop 等针对不同操作系统平台的包管理器安装命令，但基本都提供了基于 NPM 这一包管理器的跨平台安装方式。所以，读者在大多数情况下都可以按照以下步骤来安装并使用这些工具：</p>\n<ol>\n<li>\n<p>确保自己所在的操作系统中已经安装了版本在 20.0.0 之上的 Node.js 运行环境，其中自带了 NPM 包管理器；</p>\n</li>\n<li>\n<p>在管理员权限下执行<code>npm install -g &lt;agent-name&gt;@&lt;version&gt;</code>命令，在这里，<code>&lt;agent-name&gt;</code>可以通过查询相关工具的官方网站来获得，而<code>&lt;version&gt;</code>则除了可以是我们在工具官网中查到的具体版本号之外，也可以用<code>latest</code>来表示最新版本。例如，如果我们需要安装最新版本的 OpenCode，就只需要在命令行终端中使用管理员权限执行<code>npm install -g opencode@latest</code>命令即可。</p>\n</li>\n</ol>\n<p>在安装完成之后，我们就可以用 CLI 和 TUI 两种方式来使用这种命令行工具型的 Agent 了。其中，TUI 的方式已经被大家所熟知，它实际上就是一个基于命令行界面的交互式程序，运作方式类似于 Python Shell 或 Node.js REPL，拥有属于自己的独立线程。例如在安装完 OpenCode 之后，我们只需要直接在命令行终端中输入<code>opencode</code>命令（如果想延续之前与 OpenCode 的会话，还在该命令后面加上一个<code>--continue</code>或<code>-c</code>参数），就可以启动它的 TUI 界面了，具体如图 1 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：OpenCode TUI 界面</p>\n<p>在初次进入上次界面时，我们可以对自己使用的 AI Agent 进行一些基本的配置，这些工具的配置方式基本上是大同小异的。一般来说，我们会先使用<code>/model</code>命令设置以下自己默认要使用的 LLM，例如您在图 2 中所看到的就是 OpenCode 的 LLM 选择界面：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：OpenCode LLM 选择界面</p>\n<p>通常情况下，在选择 LLM 之后，这些 AI Agent 会要求我们提供一个 API Key，用于在调用 LLM 时进行身份验证。这个 API key 可以通过登录我们在相应 LLM 官网的个人账户来获得。例如，我在这里选择使用的是智普的 GLM 模型，就需要登录到<a href=\"https://bigmodel.cn/\" rel=\"noopener nofollow\" target=\"_blank\">智普 AI 的官网</a>，并为 OpenCode 创建一个专属的 API Key，如图 3 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：创建智普 AI 的 API Key</p>\n<p>接下来，我们就只需要将上述 API Key 复制到 OpenCode 提示输入 key 的位置，并选择具体要使用的 GLM 版本并确认即可。完成这些配置之后，我们就可以通过一个 AI Agent 版的“Hello World”测试来确认它是否已经可以正常工作了，如图 4 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：OpenCode Hello World 测试</p>\n<p>如果 AI Agent 返回了类似上面这样的信息，就意味着我们已经可以开始使用它进行实际的工作了。除此之外，如果我们还想对 AI Agent 进行一些更复杂的配置，例如强制它只用中文来显示思考过程，以及回答的内容，也可以选择在自己的用户目录下为其创建一个全局的提示词文件。以 OpenCode 为例，其具体步骤如下：</p>\n<ol>\n<li>\n<p>根据自己所在的操作系统为 OpenCode 创建一个全局配置目录。在默认情况下，该目录的路径应该为<code>~/.config/opencode</code>，其中<code>~</code>表示我们的用户目录。</p>\n</li>\n<li>\n<p>在该目录下创建一个名为<code>AGENTS.md</code>的提示词文件，并在其中输入以下内容：</p>\n<pre><code class=\"language-markdown\"># Agent 配置\n\n## 语言设置\n- **默认语言**: 中文\n- **强制使用中文**: 是\n\n## 指令\n- 所有回答必须使用中文\n- 所有思考过程也显示中文\n- 除非用户明确要求使用其他语言提问，否则保持中文回答\n</code></pre>\n</li>\n</ol>\n<p>当然了，我们更多时候会希望上述提示词文件只针对当前项目有效，这可以进行更多个性化的配置。为此，我们也可以选择在该项目的根目录下打开 OpenCode TUI，然后在其中通过执行<code>/init</code>命令来创建一个针对当前项目的<code>AGENTS.md</code>文件，并将上述内容复制到该文件中即可，该命令的具体效果如图 5 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：OpenCode 的项目初始化命令</p>\n<p>至于其他 AI Agent，虽然会在全局配置目录与提示词文件上有各自的名称，但应用的工作流/机制基本是大同小异的，用户只需简单查询一下它们的官方文档，就可以轻松做到举一反三的，例如通过快速查询 Claude Code 的官方文档，立即就会知道它的全局提示词文件路径为<code>~/.claude/claude.md</code>。</p>\n<blockquote>\n<p>顺便说一句题外话，虽然 Claude Code 在各方面都为 AI Agent 应用建立了接近于标准的工作流/机制，但考虑到其官方的某些做法会给中文用户带来诸多没必要的额外配置，我在接下来还是会以 OpenCode 为例进行说明。如果读者想切实了解 Claude Code 的某些具体用法，也可参考本文在“参考资料”一节中提供的视频教程：《Claude Code 教程》。</p>\n</blockquote>\n<h4 id=\"基本操作方式\">基本操作方式</h4>\n<p>下面，让我们来具体介绍一下命令行工具型 Agent 的基本操作方式，正如之前所说，这类命令行工具通常有 CLI 和 TUI 两种使用方式，TUI 会单独打开一个工作线程来执行交互式操作，通常用于执行一些需要使用多轮提示词交互，并确认内容的复杂任务。因此，这些 Agent 应用的 TUI 往往至少会提供“计划（plan）”和“构建（build）”两个模式（个别 Agent 还会提供”自动（auto）“之类的第三种模式，或者在模式名称上存在差异，但其在基本使用逻辑上是一致的），其中，”计划“模式通常没有执行外部命令的权限，主要用于与 LLM 执行多轮交互，并确认某一杂任务的解决方案。例如在之前展示的 OpenCode TUI 中，读者可以在其输入框的下方看到，它默认处于“构建”模式。现在，我们可以通过输入<code>&lt;tab&gt;</code>键来将其切换到“计划”模式，然后再试着让它执行“使用 Python 编写并执行一个 hello world 程序”的操作，就会得到类似图 5 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：OpenCode 的计划模式</p>\n<p>正如读者所见，现在 OpenCode TUI 输入框下面提示其当前处于“计划”模式，并且告诉用户自己当前不能编辑文件和执行程序，然后开始与用户讨论任务的具体解决方案。而当我们切换到“构建”模式时，OpenCode 就会直接执行这个解决方案，并输出类似图 7 的结果：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：OpenCode 的构建模式</p>\n<p>当然了，就上面这种仅需一句简短的提示词就可以完成的任务而言，我们实际上更适合使用 CLI 的方式来执行。这种方式允许我们在 bash/powershell 这类命令行终端程序所在的当前线程中直接执行 AI Agent，并输出结果。例如，如果我们想使用 OpenCode CLI 的方式来编写并执行上面那个 Python 程序，可以直接在命令行终端中输入<code>opencode run \"使用 Python 编写并执行一个 hello world 程序\"</code>命令，并得到类似图 8 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：OpenCode 的 CLI 模式</p>\n<p>如读者所见，上述命令直接在 powershell 所在的当前线程中输出了 OpenCode 的执行结果。这样做的好处，除了避免因一些简单的任务反复启动和关闭 OpenCode TUI 之外，在必要情况下还可以使用 Shell/Python 这样的脚本语言来实现对 AI Agent 应用的批量调用，例如，如果我们想使用 Python 脚本批量调用 OpenCode CLI 来执行 5 个不同的任务，就可以像下面这样编写一个简单的 Python 脚本：</p>\n<pre><code class=\"language-python\">import subprocess\n\ntasks = [\n    \"使用 Python 编写并执行一个 hello world 程序\",\n    \"使用 Python 编写并执行一个计算斐波那契数列的程序\",\n    \"使用 Python 编写并执行一个计算阶乘的程序\",\n    \"使用 Python 编写并执行一个计算素数的程序\",\n    \"使用 Python 编写并执行一个计算回文数的程序\",\n]\n\nfor task in tasks:\n    try:\n        result = subprocess.run(\n            [\"opencode\", \"run\", task],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=120\n        )\n        print(f\"任务成功: {task}\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(f\"任务失败: {task}\")\n        print(e.stderr)\n    except subprocess.TimeoutExpired:\n        print(f\"任务超时: {task}\")\n</code></pre>\n<p>除了<code>opencode run</code>命令之外，我们还可以通过执行<code>opencode -h</code>命令来查看其他可用 CLI 方式执行的 OpenCode 操作，如图 9 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 9</strong>：OpenCode 的 CLI 帮助信息</p>\n<p>虽然，上面这种多次调用<code>opencode run</code>命令的做法，在某些特定的情况下并不是最佳的任务编排方式。例如在某些时候，先将所有的需求写入一个 Markdown 文档中，再将其作为提示词一次性发给 AI Agent 可能会是一种更合适的做法。但是，我们可以基于这一思路发展出许多更复杂的 AI Agent 工作流，例如利用部署在服务端的 Agent 来操作这些命令行工具型的 Agent。下面，就让我们基于 OpenClaw 这一可部署服务型的 AI Agent 来了解一下这一工作流的具体实现方式。</p>\n<h3 id=\"可部署服务型-agent\">可部署服务型 Agent</h3>\n<p>如果我们将命令行工具型的 AI Agent 视为一种增强型的自动化工具，那么以 OpenClaw 为代表的、可在服务端部署的 AI Agent 则就是一种系统级执行单元，二者的差异主要在于运行形态与系统边界。具体来说就是，命令行工具型 Agent 的运行方式通常是：</p>\n<ul>\n<li>被用户触发</li>\n<li>执行一轮或多轮任务</li>\n<li>输出结果</li>\n<li>退出进程</li>\n</ul>\n<p>而可部署服务型 Agent 则具有以下完全不同的特征：</p>\n<ul>\n<li>常驻运行</li>\n<li>通过 HTTP / RPC / WebSocket 等方式对外提供能力</li>\n<li>持续维护会话状态</li>\n<li>支持多用户并发访问</li>\n<li>可以被其他系统调用</li>\n</ul>\n<p>在这种形态下，Agent 就不再是一个功能类似于自动化脚本的增强型工具了，它成为了常驻在操作系统中的一个服务组件。具体来说，如果从程序架构的角度来看，这两种 Agent 的差别主要体现在以下几个方面：</p>\n<ol>\n<li>\n<p>生命周期管理：命令行工具型 Agent 的生命周期通常是一次性的，执行完成即销毁，而可部署服务型 Agent 则具有长生命周期，需要考虑健康检查、日志管理、异常恢复机制。</p>\n</li>\n<li>\n<p>会话与状态管理：命令行工具型 Agent 的状态通常也是一次性的，而可部署服务型 Agent 则需要维护会话状态，这意味着它需要支持用户级会话隔离、长期上下文存储、记忆机制（Memory）以及外部数据库支持。</p>\n</li>\n<li>\n<p>多 Agent 编排能力：一旦 Agent 以系统服务组件的形式存在，它就可以调用其他 Agent，被其他 Agent 调用，参与更复杂的任务链。例如像这样：</p>\n<pre><code class=\"language-plaintext\">用户请求\n↓\n调度 Agent\n↓\n分析 Agent → 代码生成 Agent → 测试 Agent\n↓\n结果汇总\n</code></pre>\n<p>这种执行结构显然已经不再是单纯的工具调用，它关注的实际上已经是任务的编排与调度了。这也就意味着，我们需要在服务型的 Agent 中引入任务队列、消息队列、异步任务调度系统等机制。</p>\n</li>\n</ol>\n<p>下面，让我们以 OpenClaw 为例来具体介绍一下使用这种服务型 Agent 的一些基本工作流。假设，我们现在想使用 OpenClaw 指挥 OpenCode 来完成一个简单的网站重构任务，通常需要按照以下步骤来完成。</p>\n<h4 id=\"步骤-1安装并配置一个-openclaw-服务\">步骤 1：安装并配置一个 OpenClaw 服务</h4>\n<p>正如之前所说，OpenClaw 本质上是一个系统服务，这意味着免不了要赋予它较大的操作权限，基于安全方面的考虑，我个人不建议用户将其安装在自己日常的工作设备上。另外，如果想最大限度地发挥 OpenClaw 的功能，最好要能让它长时间持续运行，并执行一定程度的实际设备管理能力。因此，我们在安装 OpenClaw 时通常需要执行的操作如下：</p>\n<ul>\n<li>\n<p>配置好一台可与我们日常工作设备相连通的独立计算机（如果仅用于学习目的，也可以是一台虚拟机），并在其中安装好操作系统与 Node.js 22.x 以上版本的运行环境。</p>\n</li>\n<li>\n<p>在这台独立计算机上打开命令行终端，并执行<code>npm install -g openclaw@latest</code>命令来安装 OpenClaw。当然了，这是使用跨平台的方式。如果读者不想使用 NPM，也可以通过直接执行 bash/powershell 的安装脚本来完成这个操作，相关命令如下：</p>\n<pre><code class=\"language-bash\"># MacOS/Linux 系统下使用 bash 脚本安装：\ncurl -fsSL https://openclaw.ai/install.sh | bash\n# Windows 系统下使用 powershell 脚本安装：\niwr -useb https://openclaw.ai/install.ps1 | iex\n</code></pre>\n</li>\n<li>\n<p>待安装完成之后，继续执行<code>openclaw onboard --install-daemon</code>命令来启动新手安装向导（如图 10 所示），进一步安装 OpenClaw 的服务端组件（例如飞书机器人、WhatsApp 机器人等），关于这方面的内容，读者可参考本文在“参考资料”一节中提供的视频教程：《OpenClaw +飞书的工具流搭建过程》。</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 10</strong>：OpenClaw 的安装向导</p>\n</li>\n<li>\n<p>在配置完相关服务端组件之后，我们还需要通过执行如下命令来配置 OpenClaw 的 Gateway 网关：</p>\n<pre><code class=\"language-bash\">openclaw channels login\nopenclaw gateway --port 18789\n</code></pre>\n<p>在这里，<code>--port</code>参数用于指定 OpenClaw Gateway 的监听端口，如果读者希望使用默认的 18789 端口，则可以省略该参数。</p>\n</li>\n<li>\n<p>待 Gateway 启动之后，我们就可以使用浏览器打开<code>http://localhost:18789</code>来访问 OpenClaw 的 Web 端了，如果我们能看到如图 11 所示的界面，就说明 OpenClaw 已经成功安装并完成了初步的配置工作。</p>\n  \n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 11</strong>：OpenClaw 的 Web 端</p>\n</li>\n</ul>\n<h4 id=\"步骤-2配置-openclaw-调用-opencode-的方式\">步骤 2：配置 OpenClaw 调用 OpenCode 的方式</h4>\n<p>截止到目前为止，我们主要有<strong>两种方式</strong>可以让 OpenClaw 使用 OpenCode 来连接 LLM 并执行指定的任务。如果用户已购买了 OpenCode 的官方模型服务（即 OpenCode Zen），可以选择直接使用 OpenClaw 自带的 Zen 插件来调用 OpenCode，这种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>先获取到 OpenCode Zen 的 API Key，然后通过执行如下命令之一，将其添加到 OpenClaw 的配置中：</p>\n<pre><code class=\"language-bash\"># 使用交互式命令，这需要根据该命令的提示输入你的 API Key\nopenclaw onboard --auth-choice opencode-zen\n# 或非交互式命令，直接将 API Key 作为参数传入\nopenclaw onboard --opencode-zen-api-key \"&lt;你的 API Key&gt;\"\n</code></pre>\n</li>\n<li>\n<p>如果需要的话，还可以通过执行如下命令来设置自己要使用的默认模型：</p>\n<pre><code class=\"language-bash\">openclaw config set agents.defaults.model.primary \"opencode/claude-opus-4-6\"\n</code></pre>\n</li>\n</ul>\n<p>当然了，选择上述方式需要用户不计较按量计费所带来的开销。如果我们想使用免费的 LLM 的话（譬如  kimi-k2.5-free），也可以通过给 OpenClaw 安装 <code>opencode-to-openai</code>这样的第三方插件来实现。这第二种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>安装<code>opencode-to-openai</code>插件，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/dxxzst/opencode-to-openai\ncd opencode-to-openai\nopenclaw plugins install .\n</code></pre>\n</li>\n<li>\n<p>安装完成后，需要执行如下命令来重启 OpenClaw，并确保插件已启用：</p>\n<pre><code class=\"language-bash\">openclaw gateway restart\n</code></pre>\n<p>在这里，如果我们在 OpenClaw 中启用了插件白名单，就还需要通过执行如下命令将该加入该白名单：</p>\n<pre><code class=\"language-bash\">openclaw config get plugins.allow --json\n# 假设返回 [\"a\",\"b\"]\n\nopenclaw config set plugins.allow '[\"a\",\"b\",\"opencode-to-openai\"]' --json\nopenclaw gateway restart\n</code></pre>\n</li>\n<li>\n<p>同步模型并认证 LLM 服务，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local\n</code></pre>\n<p>如果你想顺便设置默认模型：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local --set-default\n</code></pre>\n</li>\n<li>\n<p>选择模型，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models set opencode-to-openai/opencode/kimi-k2.5-free\n</code></pre>\n<p>在这里，如果担心对 LLM 的请求会被卡住，也可以用<code>useIsolatedHome=false</code>这个插件配置让 OpenCode 使用真实 HOME，具体配置命令如下：</p>\n<pre><code class=\"language-bash\">openclaw config set plugins.opencode-to-openai.useIsolatedHome false\n</code></pre>\n</li>\n</ul>\n<h4 id=\"步骤-3与-openclaw-进行对话\">步骤 3：与 OpenClaw 进行对话</h4>\n<p>如果上述操作一切顺利，我们就可以在步骤 1 中配置好的 Web 端或飞书之类的应用中打开与 OpenClaw 的对话窗口，通过发送提示词来调度 OpenCode 完成相关任务了，如图 12 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 12</strong>：与 OpenClaw 的对话窗口</p>\n<p>当然了，如果想让提示词发挥到最大的作用，并在生产环境中实际使用 OpenClaw/OpenCode 来完成具体的项目任务，我们还需要再配置一下 OpenClaw/OpenCode 所接入的 MCP 服务和 Agent Skills 机制了。关于这部分的内容，我将会在《[[Agent 的进阶应用]]》这一篇笔记中进行详细介绍。</p>\n<h2 id=\"结束语\">结束语</h2>\n<p>在完成了对 AI Agent 的学习与实践之后，我最为明显的体会之一是：Agent 并没有让系统变得更简单，反而让系统的边界变得更加清晰。与传统的自动化脚本或工具不同，Agent 并不是一组固定规则的集合，而是一个基于语言模型进行任务理解、规划与执行的系统组件。这意味着，在很多场景下，它所做的并不是“按预期运行”，而是“尽力完成任务”。</p>\n<p>正因如此，Agent 的引入并没有削弱人类在系统中的作用，反而对人的判断能力提出了更高要求：<br />\n我们需要能够理解 Agent 在做什么、为什么这么做，以及在什么情况下应该介入、修正甚至中止它的行为。从这个角度来看，学习和使用 AI Agent，并不意味着把控制权完全交给 AI，而是学会如何在一个由 AI 参与执行的系统中，重新定位人的职责与边界。这也正是本学习阶段的核心目标。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>\n<p>官方文档：</p>\n<ul>\n<li><a href=\"https://code.claude.com/docs/zh-CN/overview?utm_source=copilot.com\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code 官方文档</a></li>\n<li><a href=\"https://opencode.doczh.com/docs/\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode 官方文档</a></li>\n<li><a href=\"https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers\" rel=\"noopener nofollow\" target=\"_blank\">基于 Agent skills 和 MCP 服务的协同工作流</a></li>\n<li><a href=\"https://docs.openclaw.ai/zh-CN\" rel=\"noopener nofollow\" target=\"_blank\">OpenClaw 官方文档</a></li>\n</ul>\n</li>\n<li>\n<p>视频教程：</p>\n<ul>\n<li>Claude Code 教程：<a href=\"https://www.youtube.com/watch?v=AT4b9kLtQCQ\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV14rzQB9EJj\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n<li>OpenClaw +飞书的工具流搭建过程：<a href=\"https://www.youtube.com/watch?v=giv63OtX720\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV1rvcpzDEsH\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n</ul>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-18 16:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">146</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": ".NET 10 & C# 14 New Features 新增功能介绍-扩展成员Extension Members",
      "link": "https://www.cnblogs.com/tianqing/p/19622970",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tianqing/p/19622970\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 11:20\">\n    <span>.NET 10 &amp; C# 14 New Features 新增功能介绍-扩展成员Extension Members</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"p1\"><span class=\"s1\">C# 14 引入了对扩展成员（Extension Members）的增强支持，本质上是对传统“扩展方法”模型的一次语言级升级，使其可以定义的不再仅限于方法，</span></p>\n<p class=\"p1\"><span class=\"s1\">而是可以扩展更多成员形态（例如属性、运算符等）。</span></p>\n<p class=\"p1\"><strong><span class=\"s1\" style=\"font-size: 16px;\">一、从扩展方法到扩展成员</span></strong></p>\n<p class=\"p1\">早在 <a><span class=\"s1\">C# 3.0</span></a> 中，就引入了“扩展方法（Extension Methods）”，其底层机制是：</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">必须定义在 static class</span></p>\n</li>\n<li>\n<p class=\"p1\">方法必须是 <span class=\"s1\">static</span></p>\n</li>\n<li>\n<p class=\"p1\">第一个参数使用 <span class=\"s1\">this T</span></p>\n</li>\n</ul>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> StringExtensions\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsNullOrEmptyEx(<span style=\"color: rgba(0, 0, 255, 1);\">this</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\"> value)\n        </span>=&gt; <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">.IsNullOrEmpty(value);\n}</span></pre>\n</div>\n<p>从本质上看：</p>\n<blockquote>编译器在语法层面做“糖化处理”，最终仍然是静态方法调用。</blockquote>\n<p><span class=\"s1\">LINQ就是最大的应用场景。</span></p>\n<p><strong><span class=\"s1\" style=\"font-size: 16px;\">二、C# 14中引入扩展成员和示例说明</span></strong></p>\n<p class=\"p1\">C# 14 允许在更自然的语法结构中声明扩展成员，不再局限于“静态类 + this 参数”模式，而是支持类似：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Enumerable\n{\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension block</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension members for IEnumerable&lt;TSource&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsEmpty =&gt; !<span style=\"color: rgba(0, 0, 0, 1);\">source.Any();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, <span style=\"color: rgba(0, 0, 255, 1);\">bool</span>&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> predicate) { ... }\n    }\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension block, with a receiver type only</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension members for IEnumerable&lt;Source&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Combine(IEnumerable&lt;TSource&gt; first, IEnumerable&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> second) { ... }\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Identity =&gt; Enumerable.Empty&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static user defined operator:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; <span style=\"color: rgba(0, 0, 255, 1);\">operator</span> + (IEnumerable&lt;TSource&gt; left, IEnumerable&lt;TSource&gt; right) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> left.Concat(right);\n    }\n}</span></pre>\n</div>\n<p class=\"p1\"><span class=\"s1\">定义的是一个 extension block<span class=\"s1\">，目标类型是：IEnumerable&lt;TSource&gt;</span></span></p>\n<p class=\"p1\">代码分成两类 extension block：　　</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\"><strong>实例扩展成员</strong></p>\n</li>\n<li>\n<p class=\"p1\"><strong>静态扩展成员</strong></p>\n</li>\n</ol>\n<p>① 实例扩展成员：extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)&nbsp;</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">source 是接收者（receiver）</span></p>\n</li>\n<li>\n<p class=\"p1\"><span class=\"s1\">类似旧语法的 this IEnumerable&lt;TSource&gt; source</span></p>\n</li>\n<li>\n<p class=\"p1\">但语法更接近真正“为类型添加成员”</p>\n</li>\n</ul>\n<p>&nbsp;扩展属性：public bool IsEmpty =&gt; !source.Any();</p>\n<p class=\"p1\">&nbsp;编译器会生成：public static bool get_IsEmpty&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)</p>\n<p class=\"p1\">&nbsp;代码调用：list.IsEmpty</p>\n<p class=\"p1\">&nbsp;会被编译为：Enumerable.get_IsEmpty(list)</p>\n<p class=\"p1\">&nbsp;其本质仍然是：</p>\n<blockquote>静态方法 + 语法糖绑定</blockquote>\n<p class=\"p1\">但在语义层面：它已经不再是“工具方法”，而是“类型能力”。</p>\n<p class=\"p1\">扩展方法：public IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, bool&gt; predicate)</p>\n<p class=\"p1\">即增强原有LINQ的Where功能</p>\n<p class=\"p1\"><span class=\"s1\">如果系统中已有 System.Linq.Enumerable.Where<span class=\"s1\">：</span></span></p>\n<ul>\n<li>\n<p class=\"p1\">实例成员优先</p>\n</li>\n<li>\n<p class=\"p1\">然后才是 extension block</p>\n</li>\n<li>\n<p class=\"p1\">再是 using 引入的扩展方法</p>\n</li>\n</ul>\n<p>&nbsp;不会破坏已有 API，只是参与候选集。</p>\n<p class=\"p1\">② 静态扩展成员</p>\n<p class=\"p1\">extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;)</p>\n<p class=\"p1\">这里没有 receiver 变量名。</p>\n<blockquote>为类型本身添加“静态扩展成员”</blockquote>\n<p class=\"p1\">找一个静态扩展方法</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Combine(...)</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Combine(a, b);</p>\n<p class=\"p1\">编译器会转化为：Enumerable.Combine(a, b);</p>\n<p class=\"p1\">再看一个静态扩展属性</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Identity</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Identity</p>\n<p class=\"p1\">这在旧扩展方法体系中是无法表达的。</p>\n<p class=\"p1\">再看一个扩展运算符</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; operator +</p>\n<p class=\"p1\">这是 C# 14 的重大增强点。现在你可以写：</p>\n<p class=\"p1\">var result = list1 + list2;</p>\n<p class=\"p1\">等价于：Enumerable.op_Addition(list1, list2);</p>\n<p class=\"p1\"><strong><span style=\"font-size: 16px;\">三、底层编译机制</span></strong></p>\n<p class=\"p1\">&nbsp;<strong>不修改 CLR 元数据</strong></p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">不改变 IEnumerable&lt;T&gt;</span></p>\n</li>\n<li>\n<p class=\"p1\">不增加真实成员</p>\n</li>\n</ul>\n<p>&nbsp;<strong>IL 仍然是静态方法</strong></p>\n<p>&nbsp; &nbsp;所有成员都会生成：&nbsp;public static ...</p>\n<p class=\"p1\">&nbsp;<strong>语义绑定由编译器完成</strong></p>\n<p class=\"p1\">扩展成员解析规则：</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\">实例真实成员</p>\n</li>\n<li>\n<p class=\"p1\">同 namespace extension block</p>\n</li>\n<li>\n<p class=\"p1\">using 导入 extension block</p>\n</li>\n</ol>\n<p>&nbsp;<strong><span style=\"font-size: 16px;\">四、与传统扩展方法对比</span></strong></p>\n<p>&nbsp; &nbsp;<img alt=\"image\" height=\"246\" src=\"https://img2024.cnblogs.com/blog/23525/202602/23525-20260218111804828-477864692.png\" width=\"657\" /></p>\n<p>同时，零运行时开销。</p>\n<ul>\n<li>\n<p class=\"p1\">无反射</p>\n</li>\n<li>\n<p class=\"p1\">无动态代理</p>\n</li>\n<li>\n<p class=\"p1\">无装饰器</p>\n</li>\n<li>\n<p class=\"p1\">无运行时注入</p>\n</li>\n</ul>\n<p>&nbsp;完全编译期绑定。</p>\n<blockquote>编译器级语义增强，不改变运行时类型结构。</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;以上分享给大家。</p>\n<p>&nbsp;</p>\n<p>周国庆</p>\n<p>20260218</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 11:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tianqing\">Eric zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">128</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "OpenClaw+OpenViking + NVIDIA API 配置教程",
      "link": "https://www.cnblogs.com/swizard/p/19622926",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/swizard/p/19622926\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:56\">\n    <span>OpenClaw+OpenViking + NVIDIA API 配置教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>本教程介绍如何在 OpenClaw 环境中配置 OpenViking，使用 NVIDIA NIM API 作为 Embedding 和 VLM 后端。</p>\n</blockquote>\n<h2 id=\"什么是-openviking\">什么是 OpenViking？</h2>\n<p>OpenViking 是火山引擎开源的 <strong>AI Agent 上下文数据库</strong>。它用\"虚拟文件系统\"的方式管理 Agent 的记忆、资源和技能，提供：</p>\n<ul>\n<li><strong>分层上下文</strong>：L0摘要 / L1概览 / L2全文，按需加载节省 Token</li>\n<li><strong>语义搜索</strong>：融合目录定位与向量检索</li>\n<li><strong>自动摘要</strong>：VLM 自动生成文档摘要和概览</li>\n<li><strong>会话记忆</strong>：自动提取对话中的长期记忆</li>\n</ul>\n<p>GitHub: <a href=\"https://github.com/volcengine/OpenViking\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/volcengine/OpenViking</a></p>\n<h2 id=\"前置条件\">前置条件</h2>\n<ul>\n<li>Python 3.9+</li>\n<li>NVIDIA NIM API Key（<a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">免费注册</a>）</li>\n<li>稳定的网络连接</li>\n</ul>\n<hr />\n<h2 id=\"第一步安装-openviking\">第一步：安装 OpenViking</h2>\n<pre><code class=\"language-bash\">pip install openviking\n</code></pre>\n<hr />\n<h2 id=\"第二步创建配置文件\">第二步：创建配置文件</h2>\n<p>创建目录和配置文件：</p>\n<pre><code class=\"language-bash\">mkdir -p ~/.openviking\n</code></pre>\n<p>编辑 <code>~/.openviking/ov.conf</code>：</p>\n<pre><code class=\"language-json\">{\n  \"embedding\": {\n    \"dense\": {\n      \"api_base\": \"https://integrate.api.nvidia.com/v1\",\n      \"api_key\": \"你的NVIDIA_API_KEY\",\n      \"provider\": \"openai\",\n      \"dimension\": 4096,\n      \"model\": \"nvidia/nv-embed-v1\"\n    }\n  },\n  \"vlm\": {\n    \"api_base\": \"https://integrate.api.nvidia.com/v1\",\n    \"api_key\": \"你的NVIDIA_API_KEY\",\n    \"provider\": \"openai\",\n    \"model\": \"meta/llama-3.3-70b-instruct\"\n  }\n}\n</code></pre>\n<h3 id=\"配置说明\">配置说明</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>api_base</code></td>\n<td>NVIDIA NIM API 端点</td>\n</tr>\n<tr>\n<td><code>api_key</code></td>\n<td>从 NVIDIA Build 平台获取</td>\n</tr>\n<tr>\n<td><code>dimension</code></td>\n<td>Embedding 维度，nv-embed-v1 固定为 4096</td>\n</tr>\n<tr>\n<td><code>embedding.model</code></td>\n<td>推荐使用 <code>nvidia/nv-embed-v1</code>（对称模型，不需要 input_type 参数）</td>\n</tr>\n<tr>\n<td><code>vlm.model</code></td>\n<td>用于生成摘要的语言模型，推荐 <code>meta/llama-3.3-70b-instruct</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"为什么不用-kimi-k25\">为什么不用 kimi-k2.5？</h3>\n<p>NVIDIA 上的推理模型（如 kimi-k2.5）返回的 <code>content</code> 字段为空，内容在 <code>reasoning</code> 字段里。OpenViking 期望标准的 <code>message.content</code> 格式，所以要用非推理模型。</p>\n<h3 id=\"如何获取-nvidia-api-key\">如何获取 NVIDIA API Key</h3>\n<ol>\n<li>访问 <a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://build.nvidia.com/</a></li>\n<li>登录/注册账号</li>\n<li>点击右上角用户名 → API Keys → Generate Key</li>\n<li>复制保存（只显示一次）</li>\n</ol>\n<hr />\n<h2 id=\"第三步设置环境变量\">第三步：设置环境变量</h2>\n<pre><code class=\"language-bash\">export OPENVIKING_CONFIG_FILE=~/.openviking/ov.conf\n</code></pre>\n<p>建议添加到 <code>~/.bashrc</code>：</p>\n<pre><code class=\"language-bash\">echo 'export OPENVIKING_CONFIG_FILE=~/.openviking/ov.conf' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>\n<hr />\n<h2 id=\"第四步验证安装\">第四步：验证安装</h2>\n<p>创建测试脚本 <code>test_openviking.py</code>：</p>\n<pre><code class=\"language-python\">import openviking as ov\n\n# 初始化客户端，数据存储在当前目录的 openviking_data 文件夹\nclient = ov.SyncOpenViking(path=\"./openviking_data\")\n\ntry:\n    client.initialize()\n    print(\"✅ OpenViking 初始化成功！\")\n    \n    # 添加一个测试文件\n    result = client.add_resource(path=\"./your_file.md\")\n    print(f\"添加文件: {result}\")\n    \n    # 等待处理完成\n    print(\"等待处理...\")\n    client.wait_processed()\n    print(\"✅ 处理完成！\")\n    \n    # 搜索测试\n    results = client.find(\"测试关键词\", limit=3)\n    print(f\"\\n搜索结果:\")\n    for r in results.resources:\n        print(f\"  {r.uri} (score: {r.score:.4f})\")\n    \n    client.close()\n    print(\"\\n🎉 OpenViking 配置成功！\")\n\nexcept Exception as e:\n    print(f\"错误: {e}\")\n    import traceback\n    traceback.print_exc()\n</code></pre>\n<p>运行：</p>\n<pre><code class=\"language-bash\">python test_openviking.py\n</code></pre>\n<hr />\n<h2 id=\"第五步核心-api-用法\">第五步：核心 API 用法</h2>\n<h3 id=\"添加资源\">添加资源</h3>\n<pre><code class=\"language-python\"># 添加单个文件\nresult = client.add_resource(path=\"./docs/readme.md\")\n\n# 添加 URL\nresult = client.add_resource(path=\"https://example.com/article.html\")\n</code></pre>\n<h3 id=\"目录浏览\">目录浏览</h3>\n<pre><code class=\"language-python\"># 列出根目录\nls_result = client.ls(\"viking://resources\")\n\n# 列出子目录\nls_result = client.ls(\"viking://resources/my_project\")\n</code></pre>\n<h3 id=\"语义搜索\">语义搜索</h3>\n<pre><code class=\"language-python\"># 搜索相关内容\nresults = client.find(\"如何配置 embedding\", limit=5)\n\nfor r in results.resources:\n    print(f\"URI: {r.uri}\")\n    print(f\"Score: {r.score}\")\n    print(f\"Content: {client.read(r.uri)[:200]}...\")\n</code></pre>\n<h3 id=\"获取摘要概览\">获取摘要/概览</h3>\n<pre><code class=\"language-python\"># L0 层：一句话摘要\nabstract = client.abstract(\"viking://resources/my_project\")\n\n# L1 层：详细概览\noverview = client.overview(\"viking://resources/my_project\")\n</code></pre>\n<h3 id=\"读取内容\">读取内容</h3>\n<pre><code class=\"language-python\"># 读取完整内容（L2 层）\ncontent = client.read(\"viking://resources/my_project/readme.md\")\n</code></pre>\n<hr />\n<h2 id=\"常见问题\">常见问题</h2>\n<h3 id=\"q-embedding-维度不匹配\">Q: Embedding 维度不匹配</h3>\n<p><strong>错误</strong>: <code>Dense vector dimension mismatch: expected 2048, got 4096</code></p>\n<p><strong>解决</strong>: 在配置文件中明确指定 <code>dimension: 4096</code>，匹配 <code>nvidia/nv-embed-v1</code> 的输出维度。</p>\n<h3 id=\"q-vlm-返回-nonetype-错误\">Q: VLM 返回 NoneType 错误</h3>\n<p><strong>错误</strong>: <code>'NoneType' object is not subscriptable</code></p>\n<p><strong>原因</strong>: 使用了推理模型（如 kimi-k2.5），其返回格式与 OpenViking 不兼容。</p>\n<p><strong>解决</strong>: 换用标准模型如 <code>meta/llama-3.3-70b-instruct</code>。</p>\n<h3 id=\"q-nvidia-api-报错-input_type-required\">Q: NVIDIA API 报错 input_type required</h3>\n<p><strong>错误</strong>: <code>'input_type' parameter is required for asymmetric models</code></p>\n<p><strong>原因</strong>: 某些 Embedding 模型（如 nv-embedqa-e5-v5）是非对称模型，需要指定 query 或 document。</p>\n<p><strong>解决</strong>: 使用对称模型 <code>nvidia/nv-embed-v1</code>，不需要 input_type。</p>\n<h3 id=\"q-文件名冲突\">Q: 文件名冲突</h3>\n<p><strong>错误</strong>: <code>directory already exists: /resources/第01章</code></p>\n<p><strong>原因</strong>: OpenViking 用文件名（不含路径）作为 URI，不同目录下的同名文件会冲突。</p>\n<p><strong>解决</strong>:</p>\n<ul>\n<li>方案一：重命名文件，使用唯一名称</li>\n<li>方案二：分批导入，避免同时添加同名文件</li>\n<li>方案三：等待官方修复此设计问题</li>\n</ul>\n<hr />\n<h2 id=\"为什么用-openviking替代-openclaw-默认的-qmd-记忆后端\">为什么用 OpenViking？——替代 OpenClaw 默认的 qmd 记忆后端</h2>\n<h3 id=\"openclaw-现有记忆方案的局限\">OpenClaw 现有记忆方案的局限</h3>\n<p>OpenClaw 默认使用 <code>qmd</code> 作为记忆后端，配合手动维护的 <code>MEMORY.md</code> 和 <code>memory/*.md</code> 文件。这套方案够用，但有几个痛点：</p>\n<ol>\n<li><strong>搜索精度有限</strong> — qmd 基于简单向量匹配，缺乏层次化理解</li>\n<li><strong>手动维护成本高</strong> — 记忆文件需要人工整理，容易遗漏</li>\n<li><strong>缺乏自动摘要</strong> — Agent 需要读取整个文件才能了解内容</li>\n<li><strong>无法管理大量文档</strong> — 当 workspace 文件很多时，qmd 不够用</li>\n</ol>\n<h3 id=\"openviking-的优势\">OpenViking 的优势</h3>\n<table>\n<thead>\n<tr>\n<th>能力</th>\n<th>qmd</th>\n<th>OpenViking</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>语义搜索</td>\n<td>✅ 基础</td>\n<td>✅ 目录递归 + 语义融合</td>\n</tr>\n<tr>\n<td>自动摘要</td>\n<td>❌</td>\n<td>✅ L0/L1/L2 三层</td>\n</tr>\n<tr>\n<td>结构化浏览</td>\n<td>❌</td>\n<td>✅ 虚拟文件系统</td>\n</tr>\n<tr>\n<td>Token 节省</td>\n<td>❌</td>\n<td>✅ 按需加载</td>\n</tr>\n<tr>\n<td>会话记忆自动提取</td>\n<td>❌</td>\n<td>✅ 自动提取长期记忆</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"集成方式\">集成方式</h3>\n<h4 id=\"方式一作为-openclaw-的补充记忆推荐\">方式一：作为 OpenClaw 的补充记忆（推荐）</h4>\n<p>保留 qmd 作为日常轻量记忆，用 OpenViking 管理大型文档库：</p>\n<pre><code class=\"language-python\"># 把 workspace 里的书籍、项目文档等大型资源导入 OpenViking\nimport glob, openviking as ov\n\nclient = ov.SyncOpenViking(path=\"./openviking_data\")\nclient.initialize()\n\nfor f in glob.glob(\"./books/**/*.md\", recursive=True):\n    client.add_resource(path=f)\n\nfor f in glob.glob(\"./docs/**/*.md\", recursive=True):\n    client.add_resource(path=f)\n\nclient.wait_processed()\nclient.close()\n</code></pre>\n<p>Agent 工作流：</p>\n<ol>\n<li>日常对话 → qmd 记忆（轻量、快速）</li>\n<li>需要查阅文档 → OpenViking 语义搜索（精准、分层）</li>\n<li>Sub-agent 写作/研究 → OpenViking 提供上下文（节省 Token）</li>\n</ol>\n<h4 id=\"方式二完全替代-qmd\">方式二：完全替代 qmd</h4>\n<p>将 OpenClaw 的所有记忆文件也导入 OpenViking：</p>\n<pre><code class=\"language-python\"># 导入记忆文件\nfor f in glob.glob(\"./memory/*.md\"):\n    client.add_resource(path=f)\n\n# 导入 workspace 所有 markdown\nfor f in glob.glob(\"./**/*.md\", recursive=True):\n    client.add_resource(path=f)\n</code></pre>\n<blockquote>\n<p>⚠️ 目前 OpenViking 还不能直接作为 OpenClaw 的 <code>memory.backend</code> 配置项。需要通过 skill 的 CLI 工具间接调用。未来如果 OpenClaw 支持自定义记忆后端插件，可以更深度集成。</p>\n</blockquote>\n<h4 id=\"方式三给-sub-agent-提供上下文\">方式三：给 Sub-agent 提供上下文</h4>\n<p>写书、做研究等任务时，sub-agent 可以先搜索 OpenViking 获取相关上下文，而不是把整本书塞进 prompt：</p>\n<pre><code class=\"language-bash\"># Sub-agent 先搜索相关内容\npython3 scripts/viking.py search \"武松的性格分析\" --limit 3\n\n# 然后只读取最相关的段落\npython3 scripts/viking.py read viking://resources/第01章/张三的叙事.md\n</code></pre>\n<p>这样一个 sub-agent 只需要加载几千 token 的相关内容，而不是整本书的 10 万+ token。</p>\n<h3 id=\"已封装的-openclaw-skill\">已封装的 OpenClaw Skill</h3>\n<p>我们已经把 OpenViking 封装为 OpenClaw skill，安装后 Agent 可以直接使用：</p>\n<pre><code class=\"language-bash\"># 安装 skill\ngit clone https://github.com/swizardlv/openclaw_openviking_skill.git\ncp -r openclaw_openviking_skill/openviking ~/.openclaw/workspace/skills/\n</code></pre>\n<p>Skill 提供的命令：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>viking.py add &lt;file&gt;</code></td>\n<td>索引文件</td>\n</tr>\n<tr>\n<td><code>viking.py add-dir &lt;dir&gt;</code></td>\n<td>批量索引目录</td>\n</tr>\n<tr>\n<td><code>viking.py search &lt;query&gt;</code></td>\n<td>语义搜索</td>\n</tr>\n<tr>\n<td><code>viking.py ls [uri]</code></td>\n<td>浏览资源</td>\n</tr>\n<tr>\n<td><code>viking.py abstract &lt;uri&gt;</code></td>\n<td>获取摘要</td>\n</tr>\n<tr>\n<td><code>viking.py overview &lt;uri&gt;</code></td>\n<td>获取概览</td>\n</tr>\n<tr>\n<td><code>viking.py read &lt;uri&gt;</code></td>\n<td>读取全文</td>\n</tr>\n<tr>\n<td><code>viking.py info</code></td>\n<td>查看配置状态</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"附录可用的-nvidia-embedding-模型\">附录：可用的 NVIDIA Embedding 模型</h2>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>维度</th>\n<th>类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>nvidia/nv-embed-v1</code></td>\n<td>4096</td>\n<td>对称</td>\n<td>✅ 推荐，无需 input_type</td>\n</tr>\n<tr>\n<td><code>nvidia/nv-embedqa-e5-v5</code></td>\n<td>1024</td>\n<td>非对称</td>\n<td>需要 input_type 参数</td>\n</tr>\n<tr>\n<td><code>nvidia/llama-3.2-nv-embedqa-1b-v2</code></td>\n<td>2048</td>\n<td>非对称</td>\n<td>需要 input_type 参数</td>\n</tr>\n<tr>\n<td><code>nvidia/nv-embedcode-7b-v1</code></td>\n<td>4096</td>\n<td>对称</td>\n<td>适合代码</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"附录可用的-nvidia-chat-模型用于-vlm\">附录：可用的 NVIDIA Chat 模型（用于 VLM）</h2>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>meta/llama-3.3-70b-instruct</code></td>\n<td>✅ 推荐，标准格式</td>\n</tr>\n<tr>\n<td><code>meta/llama-3.1-70b-instruct</code></td>\n<td>稳定版本</td>\n</tr>\n<tr>\n<td><code>meta/llama-3.1-8b-instruct</code></td>\n<td>轻量版</td>\n</tr>\n<tr>\n<td><code>mistralai/mistral-large</code></td>\n<td>Mistral 系列</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>⚠️ 避免使用推理模型（如 kimi-k2.5、deepseek-r1），它们返回的格式与 OpenViking 不兼容。</p>\n</blockquote>\n<hr />\n<h2 id=\"参考链接\">参考链接</h2>\n<ul>\n<li>OpenViking 官网: <a href=\"https://www.openviking.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://www.openviking.ai</a></li>\n<li>OpenViking GitHub: <a href=\"https://github.com/volcengine/OpenViking\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/volcengine/OpenViking</a></li>\n<li>NVIDIA NIM API: <a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://build.nvidia.com/</a></li>\n<li>NVIDIA API 文档: <a href=\"https://docs.api.nvidia.com/nim/\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.api.nvidia.com/nim/</a></li>\n</ul>\n<hr />\n<p><em>本教程基于 OpenViking 0.1.17 和 NVIDIA NIM API 测试通过。</em></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/swizard\">Swizard</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}