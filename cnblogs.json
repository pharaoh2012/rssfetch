{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "MySQL性能优化：从底层原理到实战落地的全维度方案",
      "link": "https://www.cnblogs.com/liuziyi1/p/19489439",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/liuziyi1/p/19489439\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 22:26\">\n    <span>MySQL性能优化：从底层原理到实战落地的全维度方案</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在数据驱动的业务场景中，MySQL作为主流开源关系型数据库，其性能直接决定系统响应速度、吞吐量与运维成本。尤其对于高并发、大数据量的平台（如DeepSeek这类AI服务场景），慢查询与不合理索引设计可能引发系统卡顿甚至雪崩。MySQL性能优化并非零散的“调参改SQL”，而是基于底层原理的系统性工程——既要掌握可落地的实战技巧，更要理解优化背后的核心逻辑，才能实现从“治标”到“治本”的突破。本文将融合底层理论与实战经验，构建“原理认知-问题定位-优化实施-工程保障”的完整体系，助力开发者实现MySQL性能的精准提升。</p>\n<h1 id=\"-一底层逻辑mysql性能的核心支撑与失衡本质\"># 一、底层逻辑：MySQL性能的核心支撑与失衡本质</h1>\n<p>MySQL性能的底层核心是“资源消耗与结构设计的平衡”，所有慢查询与性能瓶颈，本质都是存储结构、资源分配或执行逻辑出现了失衡。</p>\n<h2 id=\"-11-存储引擎核心b树与磁盘io的底层关联\">## 1.1 存储引擎核心：B+树与磁盘IO的底层关联</h2>\n<p>InnoDB作为MySQL默认存储引擎，其核心存储结构为B+树，性能优劣直接由“磁盘IO次数”决定。B+树的设计特性决定了查询效率的上限：</p>\n<ul>\n<li>\n<p>- 结构特性：B+树为平衡树，叶子节点存储全量数据，非叶子节点仅存储索引键与指针；单页大小默认16KB，高度通常为1-3层，高度3的B+树可存储约2000万行数据。</p>\n</li>\n<li>\n<p>- IO成本：每次查询的IO次数=B+树高度+回表次数（非覆盖索引场景）。全表扫描需遍历所有叶子节点，IO次数飙升至百万级，是慢查询的核心诱因。</p>\n</li>\n<li>\n<p>- 缓存价值：InnoDB缓冲池（innodb_buffer_pool）可缓存数据页与索引页，命中率理想值需超过99%，缓存命中可直接避免磁盘IO，大幅提升查询速度。</p>\n</li>\n</ul>\n<h2 id=\"-12-性能核心维度四大资源的消耗平衡\">## 1.2 性能核心维度：四大资源的消耗平衡</h2>\n<p>MySQL性能瓶颈最终可归结为CPU、磁盘IO、内存、锁四大资源的消耗失衡，其中磁盘IO占比最高，是优化的核心靶点：</p>\n<ul>\n<li>\n<p>- CPU：用于SQL解析、排序、分组、函数计算等操作，低效排序与复杂计算易导致CPU过载。</p>\n</li>\n<li>\n<p>- 磁盘IO：数据页/索引页的读取与写入，全表扫描、索引失效是IO消耗激增的主要原因。</p>\n</li>\n<li>\n<p>- 内存：缓冲池缓存数据页，内存不足会导致缓存命中率下降，被迫频繁读取磁盘。</p>\n</li>\n<li>\n<p>- 锁：行锁/表锁引发的查询等待，如更新操作阻塞查询、高并发下的锁竞争，会间接拉长查询耗时。</p>\n</li>\n</ul>\n<h2 id=\"-13-慢查询的本质执行逻辑与资源消耗的双重失衡\">## 1.3 慢查询的本质：执行逻辑与资源消耗的双重失衡</h2>\n<p>慢查询并非“执行时间长”的表面现象，而是底层执行逻辑与资源消耗的双重问题：一是执行计划不合理（如全表扫描、索引失效），导致IO次数过多；二是资源竞争（如锁等待、缓存失效），导致有效执行时间被拉长。优化慢查询，本质就是优化执行计划、减少资源消耗、化解资源竞争。</p>\n<h1 id=\"-二问题定位从慢查询捕捉到执行计划解析\"># 二、问题定位：从慢查询捕捉到执行计划解析</h1>\n<p>精准定位问题是优化的前提，核心依赖“慢查询日志捕捉+执行计划分析”，实现从“发现问题”到“定位根源”的闭环。</p>\n<h2 id=\"-21-慢查询日志性能瓶颈的第一重捕捉\">## 2.1 慢查询日志：性能瓶颈的第一重捕捉</h2>\n<p>慢查询日志是记录低效SQL的核心工具，需合理配置阈值与存储路径，确保精准捕捉关键问题SQL。</p>\n<h3 id=\"-211-日志配置临时生效永久固化\">### 2.1.1 日志配置（临时生效+永久固化）</h3>\n<p>临时配置（重启MySQL后失效，适用于快速排查）：</p>\n<pre><code class=\"language-sql\">-- 设置慢查询阈值（单位：秒，生产环境建议0.5-1秒，平衡灵敏度与日志量）\nSET GLOBAL long_query_time = 0.5; \n-- 开启慢查询日志\nSET GLOBAL slow_query_log = 'ON';\n-- 指定日志文件路径（需确保MySQL有写入权限）\nSET GLOBAL slow_query_log_file = '/var/log/mysql/slow.log';\n-- 记录未使用索引的查询（辅助定位索引失效场景）\nSET GLOBAL log_queries_not_using_indexes = 'ON';\n</code></pre>\n<p>永久配置（修改my.cnf文件，重启后生效，适用于生产环境常态化监控）：</p>\n<pre><code class=\"language-ini\">[mysqld]\nslow_query_log = 1\nslow_query_log_file = /var/log/mysql/slow.log\nlong_query_time = 0.5\nlog_queries_not_using_indexes = 1\n</code></pre>\n<h3 id=\"-212-日志分析工具提取核心问题sql\">### 2.1.2 日志分析工具：提取核心问题SQL</h3>\n<p>慢查询日志需通过工具解析，才能快速定位高频、高耗的核心SQL，常用工具分为两类：</p>\n<ul>\n<li>\n<p>- pt-query-digest（Percona Toolkit）：分析维度最全面，支持输出执行次数、平均耗时、扫描行数、锁等待时间等指标，适合复杂场景： <code>pt-query-digest /var/log/mysql/slow.log &gt; slow_report.txt</code></p>\n</li>\n<li>\n<p>- mysqldumpslow（MySQL自带工具）：轻量便捷，适合快速提取TopN慢查询： <code>-- 提取耗时最多的10条SELECT语句</code> <code>mysqldumpslow -s t -t 10 -g 'select' /var/log/mysql/slow.log</code></p>\n</li>\n</ul>\n<p>分析报告需重点关注“执行次数多+平均耗时长”“扫描行数多”“锁等待时间长”三类SQL，这类SQL对整体性能影响最大，优先纳入优化清单。</p>\n<h2 id=\"-22-explain执行计划读懂mysql的执行逻辑\">## 2.2 EXPLAIN执行计划：读懂MySQL的执行逻辑</h2>\n<p>捕捉到慢查询后，需通过EXPLAIN关键字分析执行计划，判断索引是否生效、查询是否存在低效操作，核心是读懂MySQL的“执行思路”。</p>\n<h3 id=\"-221-核心字段解读\">### 2.2.1 核心字段解读</h3>\n<p>执行<code>EXPLAIN SELECT * FROM orders WHERE user_id = 100 AND status = 'PAID';</code>后，重点关注以下字段：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>字段</td>\n<td>核心意义</td>\n<td>优化判断标准</td>\n</tr>\n<tr>\n<td>type</td>\n<td>访问类型，反映查询效率</td>\n<td>从优到劣：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL；需避免ALL（全表扫描）</td>\n</tr>\n<tr>\n<td>key</td>\n<td>实际使用的索引</td>\n<td>NULL表示未使用索引，需排查索引失效原因</td>\n</tr>\n<tr>\n<td>rows</td>\n<td>预估扫描行数</td>\n<td>数值越大，IO消耗越高，需通过索引缩小范围</td>\n</tr>\n<tr>\n<td>Extra</td>\n<td>附加执行信息</td>\n<td>Using filesort/Using temporary需优化；Using index为理想状态（覆盖索引）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"-222-关键判断逻辑\">### 2.2.2 关键判断逻辑</h3>\n<p>通过执行计划可快速定位核心问题：若type为ALL（全表扫描），优先排查索引是否缺失或失效；若Extra出现Using filesort，说明排序未使用索引，需优化排序字段；若rows远大于实际返回行数，说明索引选择性差，需调整索引设计。</p>\n<h1 id=\"-三核心优化索引设计与失效规避的实战指南\"># 三、核心优化：索引设计与失效规避的实战指南</h1>\n<p>索引是MySQL性能优化的核心手段，其本质是“基于B+树的有序数据结构”，目的是减少磁盘IO次数。优化索引需同时兼顾“设计合理性”与“避免失效”，遵循底层逻辑与实战原则。</p>\n<h2 id=\"-31-索引设计的三大核心原则\">## 3.1 索引设计的三大核心原则</h2>\n<p>索引设计并非“越多越好”，而是要在“查询效率”与“维护成本”之间找到平衡，核心遵循三大原则：</p>\n<h3 id=\"-311-选择性优先原则\">### 3.1.1 选择性优先原则</h3>\n<p>索引选择性=唯一值数量/总行数，选择性越高，索引定位精度越强，IO次数越少。设计时需将高选择性字段（如用户ID、订单号）放在联合索引前列，低选择性字段（如性别、状态，选择性&lt;0.1）尽量不单独建索引，避免优化器放弃使用。</p>\n<h3 id=\"-312-三星索引原则实战核心\">### 3.1.2 三星索引原则（实战核心）</h3>\n<p>三星索引是理想的索引设计标准，可最大化减少IO与计算消耗：</p>\n<ul>\n<li>\n<p>- 一星：WHERE条件列纳入索引，缩小扫描范围；</p>\n</li>\n<li>\n<p>- 二星：ORDER BY/GROUP BY列纳入索引，利用索引有序性避免排序（Using filesort）；</p>\n</li>\n<li>\n<p>- 三星：SELECT查询列被索引覆盖，避免回表操作（Extra显示Using index）。</p>\n</li>\n</ul>\n<p>示例：查询<code>SELECT user_id, username FROM users WHERE email = 'user@deepseek.com';</code>，设计覆盖索引<code>ALTER TABLE users ADD INDEX idx_email_cover (email, user_id, username);</code>，可实现无回表、无排序的高效查询。</p>\n<h3 id=\"-313-最小维护成本原则\">### 3.1.3 最小维护成本原则</h3>\n<p>索引会增加插入、更新、删除操作的维护成本（需调整B+树结构），设计时需：</p>\n<ul>\n<li>\n<p>- 控制单表索引数在5个以内，避免冗余索引（如已有(a,b)联合索引，单独a索引为冗余）；</p>\n</li>\n<li>\n<p>- 大文本、Blob字段不建索引，避免索引体积过大；</p>\n</li>\n<li>\n<p>- 联合索引需覆盖高频查询场景，减少重复索引。</p>\n</li>\n</ul>\n<h3 id=\"-314-联合索引的字段顺序技巧\">### 3.1.4 联合索引的字段顺序技巧</h3>\n<p>联合索引遵循“最左前缀原则”，本质是基于B+树的有序存储特性，设计时需遵循：</p>\n<ul>\n<li>\n<p>- 等值查询字段在前，范围查询字段在后（如(a,b)联合索引，a=1 AND b&gt;10可走索引，b&gt;10则不可）；</p>\n</li>\n<li>\n<p>- 高频查询字段在前，低频字段在后，确保更多查询能命中索引前缀。</p>\n</li>\n</ul>\n<p>示例：查询<code>SELECT * FROM sales WHERE region='Asia' AND category='Tech' AND sale_date BETWEEN '2023-01-01' AND '2023-12-31' ORDER BY revenue DESC;</code>，最优联合索引为<code>idx_region_category_date (region, category, sale_date)</code>。</p>\n<h2 id=\"-32-索引失效的十大典型场景与解决方案\">## 3.2 索引失效的十大典型场景与解决方案</h2>\n<p>索引失效是慢查询的主要诱因，本质是破坏了B+树的有序性或定位规则，以下是实战中最常见的场景及优化方案：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>失效场景</td>\n<td>错误示例</td>\n<td>优化方案</td>\n</tr>\n<tr>\n<td>索引列参与计算/函数</td>\n<td>SELECT * FROM users WHERE YEAR(create_time) = 2023;</td>\n<td>SELECT * FROM users WHERE create_time BETWEEN '2023-01-01' AND '2023-12-31';</td>\n</tr>\n<tr>\n<td>隐式类型转换</td>\n<td>SELECT * FROM logs WHERE user_id = '123'（user_id为INT）;</td>\n<td>SELECT * FROM logs WHERE user_id = 123（匹配字段类型）;</td>\n</tr>\n<tr>\n<td>LIKE以%开头</td>\n<td>SELECT * FROM user WHERE userId LIKE '%123';</td>\n<td>改用覆盖索引或LIKE '123%';</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-01-15 22:26</span>&nbsp;\n<a href=\"https://www.cnblogs.com/liuziyi1\">刘子毅</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "CLAUDE.md 全方位指南：构建高效 AI 开发上下文",
      "link": "https://www.cnblogs.com/didispace/p/19489098",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/didispace/p/19489098\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 20:09\">\n    <span>CLAUDE.md 全方位指南：构建高效 AI 开发上下文</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>如果你是 Claude 的日常用户，你一定熟悉这个场景：每次开启一个新的对话，都必须不厌其烦地重复设置项目背景、编码规范和特定的指令。这不仅耗时，也容易出错。当你忘记提醒某个关键细节时，就不得不花更多时间去修复那些不符合规范的代码。</p>\n<p>CLAUDE.md 文件正是解决这一痛点的关键。它就像 Claude 的项目专属记忆，让 AI 在每次对话开始前自动加载并记住你的所有偏好。这是一个简单而强大的功能，但大多数用户仅仅停留在基础层面。</p>\n<p>事实上，要真正释放 CLAUDE.md 的威力，需要掌握一些更深刻、甚至有些违反直觉的技巧。本文将为你揭示其中最关键的五个，帮助你将这个简单的配置文件，转变为一个能够持续进化的项目知识库。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"1-你的-claudemd-应该是一个活的文档而不是一次性配置\">1. 你的 CLAUDE.md 应该是一个“活的文档”，而不是“一次性配置”</h2>\n<p>许多人认为 CLAUDE.md 文件只需在项目开始时配置一次，然后就可以置之不理。这是一个巨大的误区。最有效的 CLAUDE.md 应该随着项目的演进而持续更新和优化。</p>\n<p>最佳的维护方式是在日常工作中“有机地”构建它。例如，当 Claude 做出了一个需要纠正的假设——比如它建议使用 console.log 进行调试，而你的团队规范是使用特定的日志库——不要只是临时修正。直接告诉 Claude：“将‘总是使用日志库而不是 console.log’这条规则添加到我的 CLAUDE.md 文件中。” 这样，你的修正就会沉淀下来，在未来的所有会话中生效。值得注意的是，早期版本的 Claude 有一个 # 快捷键来添加指令，但在 2.0.70 版本后已被移除。目前，直接请求 Claude 进行修改是官方推荐的最佳实践。</p>\n<p>这种做法的价值在于，它能实时捕捉并固化工作流程中的隐性知识。正如一个精妙的比喻所说：</p>\n<p>这就像在会议中做笔记，不同的是，这些笔记真的会被使用。</p>\n<p>更高级的维护方法是将其与团队协作流程结合。在代码审查（Code Review）中发现的未被文档化的规范，正是更新 CLAUDE.md 的绝佳时机。一个由 Boris Cherny 分享的高效工作流是：通过 GitHub Action，你甚至可以直接在 PR 评论中 @claude，让它将新规范添加到 CLAUDE.md 文件中。这创建了一个强大的反馈循环，将团队的集体智慧源源不断地沉淀到这个核心文件中。</p>\n<h2 id=\"2-少即是多上下文是宝贵资源精简至上\">2. 少即是多：上下文是宝贵资源，精简至上</h2>\n<p>人们普遍认为，提供给 AI 的上下文越多，结果就越好。然而在使用 CLAUDE.md 时，这个直觉可能是错误的。</p>\n<p>核心论点是：“上下文是宝贵的（Context is precious）”。CLAUDE.md 中的每一行内容，都在与你当前的工作指令竞争 AI 的注意力。一个臃肿、充满冗余信息的文件，反而可能稀释掉最关键的指令，导致 AI 抓不住重点。<br />\n因此，精简至上。一个很好的起点是使用 /init 命令，它会根据你的项目结构和技术栈生成一个初始文件。我的建议是，以此为基础，然后删除所有你不需要的内容。从现有内容中删除比从零开始创建要容易得多。</p>\n<p>一般建议将文件长度保持在 300 行以下。当然，这并非硬性规定。对于一些具有复杂约定或非寻常模式的 codebase，一个更长的 CLAUDE.md 反而能通过预先加载足够的上下文，有效防止 Claude 做出错误假设。关键在于，文件中的每一行都应该有其明确的价值。毫不留情地删除那些显而易见的废话（例如“请编写高质量代码”）或没有实际指导意义的“填充”信息。</p>\n<p>精简的 CLAUDE.md 迫使你仔细思考并只保留最重要的指令。这不仅能节省宝贵的上下文空间，更能确保 AI 在处理你的请求时，能够更准确地聚焦于核心要求，而不是在大量无关信息中迷失方向。</p>\n<h2 id=\"3-超越单个文件用模块化结构管理复杂性\">3. 超越单个文件：用模块化结构管理复杂性</h2>\n<p>许多用户只知道在项目根目录下创建一个 CLAUDE.md 文件。这对于小型项目来说足够了，但对于大型或结构复杂的项目，存在着更优雅、更强大的模块化管理方式。</p>\n<ul>\n<li>@imports 语法 你可以使用 @path/to/file 语法，从主 CLAUDE.md 文件中引用其他文件的内容。这能让主文件保持简洁，同时将详细的规范拆分到独立的文档中。例如，你可以将复杂的 API 设计模式放在 docs/api-patterns.md 中，然后在主文件里用 @docs/api-patterns.md 引用它。</li>\n<li>.claude/rules/ 目录 这是一个非常适合大型团队的结构。所有放在 .claude/rules/ 目录下的 .md 文件都会被 Claude 自动加载，无需手动 @import。这使得不同领域的团队可以独立维护各自的规则文件，例如，前端团队维护 code-style.md，安全团队维护 security.md。大家各司其职，有效避免了在单个大文件中频繁产生合并冲突。</li>\n<li>子目录中的 CLAUDE.md 对于 Monorepo（单一代码库）项目，这是一个绝佳的解决方案。你可以在项目的特定子目录（例如 api/ 或 packages/ui/）中放置 CLAUDE.md 文件。这些文件非常特殊：它们并不会在会话启动时加载，而只在 Claude 主动处理该特定子目录中的内容时才会被包含进来。这使得你可以为项目的不同模块定义截然不同的规范，实现真正精细化的上下文管理。<br />\n• 个人配置 CLAUDE.local.md 还有一个关键文件：CLAUDE.local.md。它用于存放那些不应提交到版本控制中的个人偏好，例如你习惯的编辑器 quirks 或偏好的代码冗余度。由于这是个人专属的，请务必将其添加到 .gitignore 文件中，以避免将个人配置泄露给整个团队。</li>\n</ul>\n<h2 id=\"4-魔鬼在细节中文件名是区分大小写的\">4. 魔鬼在细节中：文件名是区分大小写的</h2>\n<p>这是一个极其微小但至关重要的技术细节，也是最容易被忽略的陷阱之一：CLAUDE.md 这个文件名是区分大小写的。</p>\n<p>正确的文件名必须是“CLAUDE.md”——CLAUDE 部分为大写，.md 扩展名为小写。如果你将其命名为 claude.md、Claude.md 或其他任何变体，Claude 的系统将无法识别并加载它。</p>\n<p>这个细节之所以重要，是因为它是一个典型的“陷阱”（gotcha）。有趣的是，这一点在官方文档中并未明确说明。我是通过询问官方文档的 AI 助手才最终确认了这一规则。一旦出错，你可能会花费大量时间排查为什么自己精心编写的指令完全没有生效，最终才发现问题出在一个简单的大小写错误上。这个看似微不足道的细节，恰恰体现了与 AI 高效协作时，精确配置的重要性。</p>\n<h2 id=\"5-让-ai-优化-ai定期请-claude-审查自己的说明书\">5. 让 AI 优化 AI：定期请 Claude 审查自己的“说明书”</h2>\n<p>这是一个非常巧妙的“元认知”技巧：定期让 Claude 自己来审查和优化它的“说明书”——CLAUDE.md 文件。</p>\n<p>随着时间的推移，CLAUDE.md 中不可避免地会积累一些过时、冗余甚至相互冲突的指令。通过一个简单的提示，例如“请审查这个 CLAUDE.md 文件，并提出改进建议以使其更清晰、更高效”，你可以利用 Claude 自身的能力来发现这些问题。它可能会建议你合并重复的规则，或澄清模糊的表述。</p>\n<p>对于那些绝对不能违反的关键规则，你可以使用强调词来引起 Claude 的注意，比如 IMPORTANT: 或 YOU MUST。这能提高 Claude 遵循这些指令的概率，但请务必谨慎使用。正如一句古老的建议所说：如果所有东西都被标记为重要，那就没有什么是重要的了。</p>\n<p>诚然，这需要一些维护成本，但其回报是巨大的。正如源文所说：<br />\n这听起来像是维护开销。确实是。但它比在每个会话中重复自己的话，或修复那些忽略了你的规范的代码要省事得多。</p>\n<p>这不仅仅是一种文件维护策略，更是一种与 AI 协作的新范式。我们不再仅仅是 AI 的使用者，更是其成长过程中的引导者，让工具本身参与到自我完善的流程中，形成一个持续改进的良性循环。</p>\n<h2 id=\"结论\">结论</h2>\n<p>CLAUDE.md 远不止一个简单的配置文件。通过本文分享的五个高级技巧——将其视为活文档、保持精简、模块化管理、注意大小写，以及让 AI 自我优化——你可以将其从一个静态的指令列表，转变为一个强大的、与项目共同成长的动态知识库。</p>\n<p>这些策略代表了一种更深层次的思维方式：将你的 AI 上下文本身视为一个“代码库”。它也需要像代码一样被重构、被审查、被持续改进。你的 CLAUDE.md 值得你如此对待。现在，不妨思考一下：你的 CLAUDE.md 中沉淀了多少团队智慧？或许，现在就是开始构建它的最佳时机。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 20:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/didispace\">程序猿DD</a>&nbsp;\n阅读(<span id=\"post_view_count\">29</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。",
      "link": "https://www.cnblogs.com/xiaohui666/p/19489060",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaohui666/p/19489060\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 19:56\">\n    <span>使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。</p>\n<p>&nbsp;</p>\n<p>打开任务管理器查看到 刚启动就 300M 左右，此时页面还正常流畅使用</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115192758334-1287855783.png\" /></p>\n<p>&nbsp;</p>\n<p>当打开浏览器F12控制台时 ，页面卡顿，内存占用直接到达惊人的1547M ,百思不得其解</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193120944-1363009300.png\" /></p>\n<p>&nbsp;</p>\n<p>打开内存面板，查找原因，此时用了706M</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193422895-368120997.png\" /></p>\n<p>&nbsp;</p>\n<p>筛选一下，发现是样式导入重复</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193617511-1308370927.png\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;查看代码有三处地方引用</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193908039-480362363.png\" /></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193912528-202535441.png\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193917151-2133524706.png\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;先注释&nbsp;vite.config.ts 里的</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115194950450-306480391.png\" /></p>\n<p>&nbsp;</p>\n<p>发现内存明显下降，问题解决</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115195104234-699812157.png\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115195120872-371187655.png\" /></p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 19:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaohui666\">小辉。</a>&nbsp;\n阅读(<span id=\"post_view_count\">34</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘",
      "link": "https://www.cnblogs.com/chengzp/p/19488966/stock-dashboard",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/chengzp/p/19488966/stock-dashboard\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 19:06\">\n    <span>我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1265396/202601/1265396-20260115190434191-202601803.png\" />\n        这篇博客介绍了我用 stock-sdk 搭建的 A 股股票看板 stock-dashboard：基于 React + TypeScript + Vite 的纯前端项目，不依赖后端或定时脚本，直接在页面侧拉取行情并完成展示与筛选。文章从数据层封装（SDK 单例、重试、TTL 缓存、服务层统一出口）讲起，再按功能拆解搜索、Dashboard、热力图、板块/个股详情、自选、信号扫描与设置等模块。最后重点分享“一日持股法（尾盘选股）”的全市场扫描思路：先批量拉取 5000+ 行情做基础过滤，再分批拉分时计算强度指标并排序输出候选。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"这是个啥\">这是个啥</h2>\n<p>背景故事很简单：作为一个日常关注行情的“韭菜”，我有一个不太高效的习惯——同时打开无数个看盘软件和网页，在混乱的窗口切换中迷失自我，最终收获的往往只有焦虑，外加浏览器那令人窒息的标签页堆叠。为了彻底治愈这种低效，我决定动手打造一个专属工具：<strong>在一个页面内集成所有高频功能，涵盖实时行情、板块动态、分时走势、K 线分析、资金流向以及筛选器</strong>。</p>\n<p>这就诞生了 <code>stock-dashboard</code>：一个完全基于 React + TypeScript + Vite 技术栈的前端大屏。所有数据直接由 <a href=\"https://stock-sdk.linkdiary.cn/\" rel=\"noopener nofollow\" target=\"_blank\">stock-sdk</a> 驱动，这意味着项目完全摒弃了后端服务，不需要运行任何 Python 定时任务，也不依赖什么“神秘朋友的高端服务器”。纯前端直连数据源，所见即所得，一切都安排得井井有条。</p>\n<p>直接上在线演示链接：<a href=\"https://chengzuopeng.github.io/stock-dashboard/\" rel=\"noopener nofollow\" target=\"_blank\">stock-dashboard</a> （友情提示：摸鱼期间请谨慎使用，建议配合小窗口模式）。<br />\n<img alt=\"stock-overview\" class=\"lazyload\" /></p>\n<h2 id=\"核心解密数据层架构设计\">核心解密：数据层架构设计</h2>\n<p>为了保持代码整洁，我将所有针对 <code>stock-sdk</code> 的调用逻辑都封装在了 <code>src/services/sdk.ts</code> 中。</p>\n<p>这里主要实施了三个既实用又不矫情的工程化策略：</p>\n<ol>\n<li>\n<p><strong>全局单例与自动重试机制</strong><br />\n通过 <code>new StockSDK({ timeout, retry })</code> 初始化实例。面对网络波动或接口偶尔抽风的情况，SDK 内置的自动重试机制（支持最大 3 次重试及指数退避算法）能完美兜底。</p>\n</li>\n<li>\n<p><strong>智能内存缓存（TTL 策略）</strong><br />\n对于行业或概念列表这类变动频率极低的数据（毕竟它们不会在几秒内发生剧变），直接上缓存减少无效请求；而对于实时行情，则设置了 2~3 秒的生存期（TTL），既保证了数据的时效性，又避免了无意义的高频请求轰炸接口。</p>\n</li>\n<li>\n<p><strong>分层隔离：页面仅对接服务层</strong><br />\n翻阅 <code>src/pages/**</code> 下的代码，你几乎找不到 <code>new StockSDK()</code> 的身影。UI 层只负责调用诸如 <code>getFullQuotes / getTodayTimeline / getKlineWithIndicators</code> 等经过二次封装的业务方法，而类型定义则直接复用 <code>stock-sdk</code> 的导出。</p>\n</li>\n</ol>\n<p>顺便展示两段核心代码骨架，后续的所有功能模块皆构建于此基础之上：</p>\n<pre><code class=\"language-ts\">// src/services/sdk.ts\nexport const sdk = new StockSDK({ timeout: 30000, retry: { maxRetries: 3, baseDelay: 1000, maxDelay: 10000, backoffMultiplier: 2 } });\n\nexport async function getFullQuotes(codes: string[], useCache = true) {\n  const key = getCacheKey('getFullQuotes', codes);\n  if (useCache) {\n    return withCache(key, DEFAULT_TTL.quotes, () =&gt; sdk.getFullQuotes(codes));\n  }\n  return sdk.getFullQuotes(codes);\n}\n</code></pre>\n<pre><code class=\"language-ts\">// src/services/sdk.ts\nexport async function getAllAShareQuotes(options?: { batchSize?: number; concurrency?: number; onProgress?: (completed: number, total: number) =&gt; void }) {\n  return sdk.getAllAShareQuotes(options);\n}\n</code></pre>\n<hr />\n<h2 id=\"功能拆解各模块如何玩转-stock-sdk-数据\">功能拆解：各模块如何玩转 stock-sdk 数据？</h2>\n<p>路由配置位于 <code>src/router/index.tsx</code>，而各个功能页面则模块化地分布在 <code>src/pages/*</code> 目录下。接下也就是大家最关心的——按“用户交互路径”来逐一复盘。</p>\n<h3 id=\"1-全局搜索告别手动翻代码的痛苦\">1) 全局搜索：告别手动翻代码的痛苦</h3>\n<p>搜索栏组件位于 <code>src/components/layout/Header.tsx</code>，其背后的魔法仅需一行代码：</p>\n<ul>\n<li><code>search(keyword)</code> 映射到 <code>stock-sdk</code> 的 <code>sdk.search(keyword)</code></li>\n</ul>\n<p>为了优化体验，我添加了 300ms 的输入防抖处理。搜索结果完美支持个股与板块的混合查询，点击即达：</p>\n<ul>\n<li>行业板块跳转至：<code>/boards/industry/:code</code></li>\n<li>概念板块跳转至：<code>/boards/concept/:code</code></li>\n<li>个股详情跳转至：<code>/s/:code</code></li>\n</ul>\n<p>顺手还利用 localStorage 实现了一个简单的历史记录功能（<code>src/services/storage.ts</code>），毕竟很多时候，我们寻找的不是新标的，而是昨天没看完的那个它。</p>\n<hr />\n<h3 id=\"2-仪表盘-dashboard行情概览与自选速览\">2) 仪表盘 Dashboard：行情概览与自选速览</h3>\n<p>对应页面文件：<code>src/pages/Dashboard/Dashboard.tsx</code>。</p>\n<p>数据获取逻辑非常直白粗暴：</p>\n<ul>\n<li>指数行情：调用 <code>getFullQuotes(MAIN_INDICES)</code> 一次性获取上证、深成指、科创 50 等关键指数。</li>\n<li>板块概况：并行调用 <code>getIndustryList()</code> 和 <code>getConceptList()</code>。</li>\n<li>自选股预览：先从存储服务 <code>src/services/storage.ts</code> 读取自选列表，再通过 <code>getFullQuotes(watchlistCodes.slice(0, 50))</code> 批量获取前 50 只行情的快照。</li>\n</ul>\n<p>为了保证数据的鲜活度，配合 <code>usePolling</code> Hook（<code>src/hooks/usePolling.ts</code>）实现了每 5 秒自动轮询。贴心的是，当页面处于后台不可见状态时，轮询会自动挂起，绝不浪费你的浏览器资源。</p>\n<p>额外提一句：目前 Dashboard 上的“榜单”主要展示板块数据。如果想做全市场的个股排名，技术路径完全可以参考后面提到的“一日持股法”，也就是直接利用 <code>getAllAShareQuotes</code> 接口。</p>\n<hr />\n<h3 id=\"3-市场热力图-heatmap一图看懂资金流向\">3) 市场热力图 Heatmap：一图看懂资金流向</h3>\n<p><img alt=\"stock-heatmap\" class=\"lazyload\" /></p>\n<p>实现文件位于 <code>src/pages/Heatmap/Heatmap.tsx</code>，底层依赖 ECharts 的矩形树图（Treemap）。</p>\n<p>根据观察视角的不同，数据源也各异：</p>\n<ul>\n<li>行业视角：直接用 <code>getIndustryList()</code>，因为返回的数据中已经包含了涨跌幅、换手率及领涨股信息。</li>\n<li>概念视角：同理，调用 <code>getConceptList()</code>。</li>\n<li>自选视角：获取所有自选代码 <code>getAllWatchlistCodes()</code> 后，通过 <code>getAllQuotesByCodes(codes.slice(0, topK))</code> 批量拉取。</li>\n</ul>\n<p>至于“全市场个股”热力图（代码预留了接口，暂未开启），实现逻辑也不复杂：</p>\n<ol>\n<li>通过 <code>getIndustryConstituents(industryCode)</code> 获取特定板块成分股。</li>\n<li>用 <code>getAllQuotesByCodes(stockCodes)</code> 把行情数据补齐。</li>\n<li>最后组装数据喂给 Treemap 组件。</li>\n</ol>\n<p>热力图最大的魅力在于：<strong>告别枯燥的数字列表，红绿相间的色块让你瞬间洞察市场强弱结构。</strong></p>\n<hr />\n<h3 id=\"4-龙虎榜-rankings观察市场风向标\">4) 龙虎榜 Rankings：观察市场风向标</h3>\n<p><img alt=\"stock-leaderboard\" class=\"lazyload\" /></p>\n<p>页面路径：<code>src/pages/Rankings/Rankings.tsx</code>。</p>\n<p>实现方式属于“简单粗暴且有效”：</p>\n<ul>\n<li>并行获取 <code>getIndustryList()</code> 和 <code>getConceptList()</code>。</li>\n<li>前端直接根据 <code>changePercent</code>（涨跌幅）或 <code>turnoverRate</code>（换手率）进行排序，截取 Top 50。</li>\n</ul>\n<p>目前的榜单本质上是“板块排行榜”。如果未来要扩展到全市场个股排行，技术方案与后文的“选股器”一致。</p>\n<hr />\n<h3 id=\"5-板块透视追踪领涨先锋\">5) 板块透视：追踪领涨先锋</h3>\n<p>板块列表页位于 <code>src/pages/Boards/Boards.tsx</code>：</p>\n<ul>\n<li><code>getIndustryList()</code> 与 <code>getConceptList()</code> 一把梭。</li>\n<li>所谓的 Tab 切换，仅仅是前端对不同数据源数组的渲染切换。</li>\n<li>当然也支持按板块名称或领涨股进行检索。</li>\n</ul>\n<p>详情页见 <code>src/pages/Boards/BoardDetail.tsx</code>，这里展示了 API 的组合拳能力（按行业/概念分流）：</p>\n<ul>\n<li>基础信息：直接复用列表数据，减少一次网络请求。</li>\n<li>成分股列表：调用 <code>getIndustryConstituents(code)</code> 或 <code>getConceptConstituents(code)</code>。</li>\n<li>板块走势：拉取 <code>getIndustryKline</code> 或 <code>getConceptKline</code>。</li>\n<li>盘口快照：通过 <code>getIndustrySpot</code> 或 <code>getConceptSpot</code> 获取。</li>\n</ul>\n<p>为了保证流畅度，板块 K 线图目前只截取了最近 60 根数据，防止缩放图表时浏览器渲染压力过大。</p>\n<hr />\n<h3 id=\"6-自选监控-watchlist只看我在意的\">6) 自选监控 Watchlist：只看我在意的</h3>\n<p>核心页面：<code>src/pages/Watchlist/Watchlist.tsx</code>。所有的增删改查逻辑都封装在 <code>src/services/storage.ts</code> 中。</p>\n<p>行情刷新主要依赖：</p>\n<ul>\n<li><code>getAllQuotesByCodes(normalizedActiveCodes)</code></li>\n</ul>\n<p>特别提一下这里的细节处理：在请求前我会先通过 <code>normalizeStockCode</code>（位于 <code>src/utils/format.ts</code>）对代码进行标准化格式化，有效防止了 <code>SZ000001</code>、<code>sz000001</code> 和 <code>000001</code> 这种“一码多式”造成的去重失败或数据请求异常。</p>\n<hr />\n<h3 id=\"7-个股深度分析-stockdetail全维数据一览无余\">7) 个股深度分析 StockDetail：全维数据一览无余</h3>\n<p><img alt=\"stock-detail\" class=\"lazyload\" /></p>\n<p>页面位置：<code>src/pages/StockDetail/StockDetail.tsx</code>。这是整个项目中承载信息量最大的页面，因为它聚合了极高密度的信息。</p>\n<p>它聚合了多维度的 API 数据：</p>\n<ul>\n<li>实时报价：<code>getFullQuotes([code])</code></li>\n<li>当日分时图（1分钟级）：<code>getTodayTimeline(code)</code></li>\n<li>分钟级 K 线（5/15/30/60）：<code>getMinuteKline(code, { period })</code></li>\n<li>历史 K 线（日/周/月）及复权：<code>getKlineWithIndicators(code, { period, adjust: 'qfq', indicators })</code></li>\n<li>资金流向监测：<code>getFundFlow([code])</code></li>\n<li>盘口大单监控：<code>getPanelLargeOrder([code])</code></li>\n</ul>\n<p>我个人非常推崇 <code>getKlineWithIndicators</code> 这个接口：只需传入你想要的指标参数（如 MA, MACD, KDJ, RSI, BOLL等），SDK 就能把计算好的指标数据连同 K 线一起返回。前端只需负责绘图，彻底告别了在前端手写复杂技术指标计算逻辑的噩梦（少写代码 = 少出 Bug = 长命百岁）。</p>\n<p>在这里，轮询策略也做了精细化分层：</p>\n<ul>\n<li>基础行情：2 秒/次</li>\n<li>分时图：3 秒/次</li>\n<li>资金流向：10 秒/次</li>\n</ul>\n<hr />\n<h3 id=\"8-策略扫描器-scanner量化交易的初体验\">8) 策略扫描器 Scanner：量化交易的初体验</h3>\n<p>页面：<code>src/pages/Scanner/Scanner.tsx</code>。</p>\n<p>扫描逻辑简述如下：</p>\n<ol>\n<li><strong>确定股票池</strong>：\n<ul>\n<li>既可以是你的“自选股列表”。</li>\n<li>也可以是某个板块的成分股，例如调用 <code>getIndustryConstituents('BK0475')</code>。</li>\n</ul>\n</li>\n<li><strong>批量分析</strong>：\n<ul>\n<li>遍历每只股票，调用 <code>getKlineWithIndicators</code> 获取带指标的 K 线数据。</li>\n</ul>\n</li>\n<li><strong>信号匹配</strong>：\n<ul>\n<li>前端逻辑判断最近两根 K 线是否满足预设形态（如均线金叉、MACD 金叉、RSI 超买超卖等）。</li>\n</ul>\n</li>\n</ol>\n<p>虽然这个功能带有一定的“心里安慰”属性，但它确确实实把模糊的“看涨感觉”转化为了可执行的“触发条件”。</p>\n<hr />\n<h3 id=\"9-个性化设置-settings打造顺手的工具\">9) 个性化设置 Settings：打造顺手的工具</h3>\n<p><img alt=\"stock-settings\" class=\"lazyload\" /></p>\n<p>页面：<code>src/pages/Settings/Settings.tsx</code>。</p>\n<p>这个页面并没有调用任何 <code>stock-sdk</code> 接口，它的使命是将你的使用偏好（刷新频率、红涨绿跌配色、各类指标的默认参数等）持久化保存到 localStorage。这样，无论何时打开页面，它都还是那个你最熟悉的样子。</p>\n<hr />\n<h2 id=\"重头戏一日持股策略尾盘选股前端实现的全市场扫描\">重头戏：一日持股策略（尾盘选股）——前端实现的全市场扫描</h2>\n<p><img alt=\"stock-last\" class=\"lazyload\" /></p>\n<p>该功能位于 <code>src/pages/EndOfDayPicker/EndOfDayPicker.tsx</code>。我在这个页面实现了一套经典的“三步走”选股漏斗，其核心动力源自强大的 <strong><code>getAllAShareQuotes</code></strong> 接口。</p>\n<h3 id=\"第一阶段全量-a-股行情抓取\">第一阶段：全量 A 股行情抓取</h3>\n<pre><code class=\"language-ts\">// src/pages/EndOfDayPicker/EndOfDayPicker.tsx\nconst quotes = await getAllAShareQuotes({\n  batchSize: 500,\n  concurrency: 5,\n  onProgress: (completed, total) =&gt; setLoadingProgress({ completed, total, stage: '数据加载中...' }),\n});\n</code></pre>\n<p>这一步调用的是 SDK 的重磅接口：</p>\n<ul>\n<li><code>sdk.getAllAShareQuotes(options?: GetAllAShareQuotesOptions): Promise&lt;FullQuote[]&gt;</code></li>\n<li>参数 <code>batchSize</code> 控制单次批大小（默认 500），<code>concurrency</code> 控制并发数（默认 7）。</li>\n</ul>\n<p>我采取了相对稳健的策略（并发设为 5），兼顾了浏览器的性能负载和网络稳定性。配合 <code>onProgress</code> 回调，用户能看到实时的进度条反馈，体验流畅不卡顿，不会误以为网页卡死。</p>\n<h3 id=\"第二阶段基础指标粗筛\">第二阶段：基础指标粗筛</h3>\n<p>拿到全市场 5000+ 只股票的 <code>FullQuote</code> 数据后，我们先进行一轮粗筛（字段直接取自 <code>FullQuote</code>）：</p>\n<ul>\n<li>流通市值 (<code>circulatingMarketCap</code>)</li>\n<li>量比 (<code>volumeRatio</code>)</li>\n<li>涨跌幅 (<code>changePercent</code>)</li>\n<li>换手率 (<code>turnoverRate</code>)</li>\n<li>ST/风险股过滤</li>\n</ul>\n<p>这一步逻辑封装在 <code>filterStocksBasic()</code> 中，通常能把目标池从 5000+ 缩减到几百甚至几十只，如果不筛这一刀，后续拉取分时数据会直接把浏览器送走。</p>\n<h3 id=\"第三阶段分时图形态精选\">第三阶段：分时图形态精选</h3>\n<p>对于粗筛剩下的候选股，我们再进行更细致的分时图分析：</p>\n<ul>\n<li>调用 <code>getTodayTimeline(fullCode)</code> 拉取分时数据（注意拼接 sh/sz/bj 前缀）。</li>\n<li>计算核心强度指标：<code>timelineAboveAvgRatio</code>（即：现价高于均价的时间占比，由 <code>price</code> 和 <code>avgPrice</code> 对比得出）。</li>\n</ul>\n<p>为了防止浏览器崩溃，<code>filterWithTimeline()</code> 中手动控制了分时数据请求的并发量（batchSize = 5）。<br />\n最终结果按 <code>timelineAboveAvgRatio</code> 降序排列，并在列表中展示迷你的分时走势图。这样一来，尾盘选股的效率直接起飞。</p>\n<hr />\n<h2 id=\"写在最后谁需要这个工具\">写在最后：谁需要这个工具？</h2>\n<p>如果你渴望拥有一个“既能看盘、又能筛股、还能顺便管理自选”的轻量级看板，同时极其排斥维护后端服务或编写复杂的 Python 脚本，那么这个纯前端方案绝对是你的不二之选。<strong>核心思路就是利用 <code>stock-sdk</code> 将强大的数据能力引入前端，剩下的就是单纯的 UI 组装与逻辑编排</strong>。</p>\n<p>本地启动非常简单：</p>\n<pre><code class=\"language-bash\">yarn install\nyarn dev\n</code></pre>\n<p>最后不得不俗套地提醒一句：页面底部的 disclaimer “仅供学习参考，不构成投资建议”并非摆设。代码虽可自信敲，投资仍需谨慎行。</p>\n<hr />\n<h2 id=\"传送门\">传送门</h2>\n<ul>\n<li>在线看板： <a href=\"https://chengzuopeng.github.io/stock-dashboard/\" rel=\"noopener nofollow\" target=\"_blank\">https://chengzuopeng.github.io/stock-dashboard/</a></li>\n<li>SDK 文档： <a href=\"https://stock-sdk.linkdiary.cn/\" rel=\"noopener nofollow\" target=\"_blank\">https://stock-sdk.linkdiary.cn/</a></li>\n<li>SDK 演练场： <a href=\"https://stock-sdk.linkdiary.cn/playground/\" rel=\"noopener nofollow\" target=\"_blank\">https://stock-sdk.linkdiary.cn/playground/</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 19:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/chengzp\">程序猿的程</a>&nbsp;\n阅读(<span id=\"post_view_count\">39</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI → JSON → UI",
      "link": "https://www.cnblogs.com/guangzan/p/19487446",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/guangzan/p/19487446\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 15:23\">\n    <span>AI → JSON → UI</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"背景\">背景</h2>\n<p>过去两年，AI 生成 UI 的实践基本集中在两种路径上。第一种是直接让模型生成 JSX、HTML 或 CSS。这条路线的优势在于自由度极高，模型几乎不受约束，看起来“什么都能写”。但在真实工程环境中，这种方式几乎不可控：输出结构不稳定，无法保证组件边界，难以做权限与审计控制，生成的代码经常无法编译或违背工程约定，更重要的是，它与实际业务中的组件体系和设计系统严重脱节。</p>\n<p>另一条路线是低代码或 schema 驱动 UI，例如基于 JSON Schema 或表单 schema 的方案。这类方案在工程上是可控的，结构稳定、可校验、可复用，但它们本质上是为“人编写配置”设计的，而不是为“模型生成结构”设计的。schema 表达能力有限，扩展成本高，并且与自然语言之间的映射并不自然，Prompt 往往需要大量人工约束。</p>\n<p>Vercel 刚刚开源了 json-render，json-render 的出现，本质上是对这两条路线的重新切分与组合。它并没有试图让 AI 写前端代码，也没有把 AI 限制在传统低代码 schema 中，而是引入了一个中间层：<strong>JSON UI AST</strong>。AI 只能生成这种 AST，而 AST 的能力边界完全由开发者定义。渲染、状态、行为解释全部留在业务侧完成。开发者因此可以安全地让用户通过自然语言生成仪表盘、小部件或数据视图，而不需要把执行权交给模型。</p>\n<p><img alt=\"iShot_2026-01-15_15.25.26\" src=\"https://img2024.cnblogs.com/blog/1501373/202601/1501373-20260115152759556-1171653435.gif\" /></p>\n<h2 id=\"整体架构json-render-是一个-dsl-解释系统\">整体架构：json-render 是一个 DSL 解释系统</h2>\n<p>从架构视角看，json-render 并不是一个 UI 框架，而是一个 DSL 执行系统。系统由三层构成：最底层是 Catalog，用来声明“系统允许 AI 使用哪些 UI 能力”；中间层是 JSON UI Tree，这是 AI 的唯一输出形式；最上层是 Renderer，由业务侧实现，用于解释 JSON 并渲染真实 UI。</p>\n<p>它们之间的关系可以用下面这张结构图来理解：</p>\n<pre><code>┌────────────┐\n│   Prompt   │\n└─────┬──────┘\n      │\n      ▼\n┌──────────────────┐\n│  LLM / AI Model  │\n└─────┬────────────┘\n      │  JSON UI AST（受 Catalog 严格约束）\n      ▼\n┌──────────────────┐\n│     Catalog      │  ← 能力白名单 / Schema / Grammar\n└─────┬────────────┘\n      │ 校验 + 解析\n      ▼\n┌──────────────────┐\n│    Renderer      │  ← React / Vue / Native\n└─────┬────────────┘\n      │\n      ▼\n┌──────────────────┐\n│   Real UI View   │\n└──────────────────┘\n</code></pre>\n<p>在这个模型中，AI 只参与“结构生成”，不参与“执行”。这也是 json-render 在工程上成立的根本原因。</p>\n<h2 id=\"从-catalog-到-ui\">从 Catalog 到 UI</h2>\n<h3 id=\"1-catalog系统的能力边界定义\">1. Catalog：系统的能力边界定义</h3>\n<p>下面这段代码是整个系统中最重要的入口，它定义了 AI 能使用的全部 UI 能力。</p>\n<pre><code class=\"language-ts\">import { createCatalog } from '@json-render/core'\nimport { z } from 'zod'\n\nexport const catalog = createCatalog({\n  components: {\n    Card: {\n      props: z.object({\n        title: z.string()\n      }),\n      hasChildren: true\n    },\n    Metric: {\n      props: z.object({\n        label: z.string(),\n        valuePath: z.string(),\n        format: z.enum(['number', 'currency', 'percent']).optional()\n      })\n    }\n  },\n  actions: {\n    refresh: {\n      params: z.object({})\n    }\n  }\n})\n</code></pre>\n<p>这里没有任何 UI 代码，只有能力声明。props 使用 Zod 定义，这意味着它不仅是类型提示，还包含运行时校验规则。如果你对 Zod 没有了解，可以看看这篇博文，<a href=\"https://www.cnblogs.com/guangzan/p/19350726\" target=\"_blank\">Zod：TypeScript 类型守卫与数据验证</a>。action 并不是函数实现，而是一个“意图声明”，它只描述“可以发生什么”，不描述“怎么发生”。</p>\n<p>Catalog 在系统中的地位，相当于一门语言的语法定义文件。AI 后续生成的所有 JSON，本质上都必须符合这套 grammar。</p>\n<h3 id=\"2-ai-输出的-json-ui-ast\">2. AI 输出的 JSON UI AST</h3>\n<p>当用户输入类似“生成一个收入仪表盘”的提示时，模型生成的结果不是 JSX，而是下面这样的 JSON：</p>\n<pre><code class=\"language-json\">{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Revenue Overview\" },\n  \"children\": [\n    {\n      \"type\": \"Metric\",\n      \"props\": {\n        \"label\": \"Total Revenue\",\n        \"valuePath\": \"/metrics/revenue\",\n        \"format\": \"currency\"\n      }\n    }\n  ]\n}\n</code></pre>\n<p>这个 JSON 有几个非常关键的特征。它不包含任何函数、不包含条件表达式、不包含样式或状态逻辑。它只是结构化地描述“使用哪个组件，用什么参数，组件之间如何嵌套”。所有能力完全来源于 Catalog，因此这个 JSON 是可校验、可存储、可 diff、可审计、可回放的。</p>\n<h3 id=\"3-rendererjson-的解释执行\">3. Renderer：JSON 的解释执行</h3>\n<p>在 React 侧，Renderer 扮演的是解释器的角色。</p>\n<pre><code class=\"language-tsx\">import { Renderer } from '@json-render/react'\nimport { catalog } from './catalog'\n\nfunction App() {\n  return (\n    &lt;Renderer\n      catalog={catalog}\n      components={{\n        Card: ({ title, children }) =&gt; (\n          &lt;div className=\"card\"&gt;\n            &lt;h2&gt;{title}&lt;/h2&gt;\n            {children}\n          &lt;/div&gt;\n        ),\n        Metric: ({ label, value }) =&gt; (\n          &lt;div&gt;\n            {label}: {value}\n          &lt;/div&gt;\n        )\n      }}\n      data={{\n        metrics: { revenue: 120000 }\n      }}\n    /&gt;\n  )\n}\n</code></pre>\n<p>Renderer 并不关心 UI 长什么样，它只做三件事：根据 type 找到对应组件定义，根据 Catalog 校验 props 和 children，根据 valuePath 等规则完成数据注入。</p>\n<h2 id=\"为什么-json-render-是可控的\">为什么 json-render 是“可控的”</h2>\n<p>下面的借助 AI 能力分析基于 <code>vercel-labs/json-render</code> 主仓库。如果你对此不感兴趣，跳过这部分内容。</p>\n<h3 id=\"1-createcatalog能力被冻结的起点\">1. createCatalog：能力被冻结的起点</h3>\n<p>文件路径位于 <code>packages/core/src/create-catalog.ts</code>。这个函数的核心作用不是“注册组件”，而是“冻结能力边界”。</p>\n<p>简化后的核心逻辑可以理解为：</p>\n<pre><code class=\"language-ts\">export function createCatalog(definition) {\n  return {\n    components: definition.components,\n    actions: definition.actions,\n    validateNode(node) {\n      // 校验 type 是否存在\n      // 校验 props 是否符合 Zod schema\n      // 校验 children 是否被允许\n    }\n  }\n}\n</code></pre>\n<p>每一行代码都在服务一个目标：让 Catalog 成为一个不可突破的白名单。Renderer 和 AI 都无法绕过它。这也是为什么 json-render 把 Catalog 放在 core 包中，而不是 React 包中。</p>\n<h3 id=\"2-schema-校验ai-输出必须先编译再执行\">2. Schema 校验：AI 输出必须“先编译再执行”</h3>\n<p>在 JSON Tree 进入 Renderer 之前，系统会逐节点校验。type 是否在 Catalog 中声明，props 是否通过 Zod 校验，children 是否符合 hasChildren 约束，action 是否存在于白名单。这一过程本质上就是一次 AST 校验。</p>\n<p>这意味着 AI 的输出不是“运行时报错”，而是“不通过即拒绝执行”。在 AI UI 系统中，这是一个极其关键但经常被忽视的工程点。</p>\n<h3 id=\"3-renderer真正的解释器模型\">3. Renderer：真正的解释器模型</h3>\n<p>React Renderer 的内部逻辑并不是简单的 switch-case，而是一个递归解释过程。它根据节点的 type 查 Catalog，构造 props，解析 valuePath 注入数据，绑定 action handler，然后递归渲染 children。</p>\n<p>从架构角度看，它更接近一个 JSON AST Interpreter，而不是模板引擎。这也是 json-render 可以跨 React、Vue、Native 复用核心思想的原因。</p>\n<h3 id=\"4-valuepath刻意避免-ai-参与状态逻辑\">4. valuePath：刻意避免 AI 参与状态逻辑</h3>\n<p>valuePath 使用字符串路径描述数据依赖，例如：</p>\n<pre><code class=\"language-json\">\"valuePath\": \"/metrics/revenue\"\n</code></pre>\n<p>这样设计的直接结果是，AI 不需要理解状态结构，也不需要写任何状态逻辑。Renderer 统一负责解析路径、读取数据、触发更新。这在架构上刻意切断了“AI 直接操作状态”的可能性。</p>\n<p>下面是仅包含新增内容的补充章节，重点放在可落到源码层面的机制，避免概念化描述。示例代码与解释均基于 <code>vercel-labs/json-render</code> 当前仓库结构与实现思路。</p>\n<h2 id=\"prompt-与-catalog-的自动对齐\">Prompt 与 Catalog 的自动对齐</h2>\n<p>Prompt 与 Catalog 的自动对齐：不是“调 Prompt”，而是“导出 Grammar”。json-render 中，Prompt 与 Catalog 的对齐并不是通过人肉 Prompt Engineering 完成的，而是通过从 Catalog 派生一份机器可理解的能力描述，并将其注入到模型上下文中。这一点在 <code>packages/core</code> 中的设计非常关键。</p>\n<p>在 core 层，Catalog 本身并不是一个简单的对象，它包含了完整的组件定义、props schema 以及 action 描述。这些信息会被转换为一种“描述性结构”，用于告诉模型当前系统支持的 UI grammar。</p>\n<p>类似这样的逻辑：</p>\n<pre><code class=\"language-ts\">export function catalogToPrompt(catalog) {\n  return `\nYou can generate a JSON UI tree.\nAvailable components:\n${Object.entries(catalog.components).map(([name, def]) =&gt; `\n- ${name}\n  props: ${describeSchema(def.props)}\n  hasChildren: ${def.hasChildren}\n`).join('\\n')}\n\nAvailable actions:\n${Object.keys(catalog.actions).join(', ')}\n\nRules:\n- Output must be valid JSON\n- Only use listed components\n- Follow prop schemas strictly\n`\n}\n</code></pre>\n<p>这里的关键点不在于字符串本身，而在于信息来源完全来自 Catalog。换句话说，Catalog 是 single source of truth，Prompt 只是它的一种序列化视图。当开发者新增或修改组件定义时，Prompt 中允许模型使用的能力会自动发生变化，不存在“代码和 Prompt 不一致”的问题。这也是 json-render 能够避免大量“Prompt 腐化”的根本原因。</p>\n<p>从模型视角看，它面对的不是一段模糊的自然语言说明，而是一套接近 BNF 的 UI grammar 描述。模型生成 JSON UI Tree 的过程，本质上类似于在给定语法约束下生成 AST。这也是为什么 json-render 要使用 Zod 而不是仅靠 TypeScript 类型。Zod schema 可以被同时用于运行时校验和 Prompt 语义描述，形成闭环。</p>\n<h2 id=\"streaming-ui-的实现细节\">Streaming UI 的实现细节</h2>\n<p>流式构建 AST，而不是流式拼字符串。json-render 的 Streaming UI 能力，核心并不在“模型支持流式输出”，而在于 UI 的中间表示是可增量合并的 JSON AST。这一点在 React 包中的实现非常清晰。</p>\n<p>在 <code>packages/react</code> 中，可以看到类似 <code>useUIStream</code> 的 hook，其核心职责是：<br />\n维护一棵当前 UI Tree，并在模型流式输出时不断向这棵树中合并新节点。</p>\n<p>简化后的内部结构大致如下：</p>\n<pre><code class=\"language-ts\">// packages/react/src/use-ui-stream.ts（概念结构）\nexport function useUIStream() {\n  const [tree, setTree] = useState&lt;UITree | null&gt;(null)\n\n  function onChunk(chunk: string) {\n    const partialNode = parseChunkToNode(chunk)\n    if (!partialNode) return\n\n    setTree(prevTree =&gt; {\n      return mergeTree(prevTree, partialNode)\n    })\n  }\n\n  return { tree, onChunk }\n}\n</code></pre>\n<p>这里有两个非常关键但容易被忽略的点。</p>\n<p><code>parseChunkToNode</code> 并不是简单的 <code>JSON.parse</code>。模型在 streaming 模式下输出的通常是不完整 JSON，因此 json-render 采用的是逐段解析、延迟成型的策略。只有当一个节点在结构上是完整且通过 Catalog 校验时，才会被提升为“可合并节点”。<code>mergeTree</code> 是一个纯函数。它不依赖外部状态，只根据已有 UI Tree 和新节点生成下一棵 Tree。这使得每一次更新都是确定性的，也天然适合 React 的状态模型。</p>\n<p>在 Renderer 层，这棵 Tree 会被直接用于递归渲染：</p>\n<pre><code class=\"language-tsx\">function RenderNode({ node }) {\n  const Component = components[node.type]\n\n  const resolvedProps = resolveProps(node.props)\n  const children = node.children?.map(child =&gt;\n    &lt;RenderNode key={child.id} node={child} /&gt;\n  )\n\n  return &lt;Component {...resolvedProps}&gt;{children}&lt;/Component&gt;\n}\n</code></pre>\n<p>由于 Tree 始终是“已校验的合法结构”，Renderer 不需要关心节点是否完整，只需要关心“当前有哪些节点已经存在”。这也是 Streaming UI 能在生成未完成时就安全渲染的根本原因。</p>\n<h2 id=\"streaming-与-catalog-校验如何协同工作\">Streaming 与 Catalog 校验如何协同工作</h2>\n<p>Streaming UI 并不是绕过校验机制的捷径，恰恰相反，它依赖校验机制才能成立。在实际流程中，每一个候选节点在被合并进 UI Tree 之前，都会经过 Catalog 的校验逻辑：</p>\n<pre><code class=\"language-ts\">// packages/core/src/validate-node.ts（概念结构）\nexport function validateNode(node, catalog) {\n  const def = catalog.components[node.type]\n  if (!def) throw new Error('Unknown component')\n\n  def.props.parse(node.props)\n\n  if (node.children &amp;&amp; !def.hasChildren) {\n    throw new Error('Children not allowed')\n  }\n}\n</code></pre>\n<p>Streaming 模式下，这个校验发生得更频繁，但粒度更小。系统宁可“暂时不渲染”，也不会把一个非法节点交给 Renderer。这保证了 UI 在任何时刻都是一个合法子集，而不是半成品垃圾状态。</p>\n<p>Prompt 与 Catalog 的自动对齐，确保模型“不会幻想不存在的能力”；Streaming UI 的 AST 级增量构建，确保 UI“可以在不完整时仍然正确运行”。两者结合，使 json-render 的执行模型更接近编译器与解释器，而不是模板生成器。从工程视角看，这意味着一个重要转变：<strong>UI 生成不再是一次性结果，而是一个可观察、可中断、可回滚的过程。</strong>这也是 json-render 能够真正进入生产系统，而不仅停留在 Demo 层面的根本原因。</p>\n<h2 id=\"json-render-真正解决了什么\">json-render 真正解决了什么</h2>\n<p>json-render 本身并不是一种全新的技术范式。<strong>“用受限结构描述 UI，再由运行时解释执行”这一思想，在前端工程中早已反复出现过。</strong>早期的 JSON Schema Form、react-jsonschema-form、Formily、本质上都是用结构化数据描述界面，再由渲染器生成真实 UI。低代码平台、搭建系统、配置化后台，几乎全部建立在同一逻辑之上。即便在 AI 出现之前，这种模式也已经非常成熟：工程师通过 schema 描述组件、属性和布局，运行时负责校验与渲染，业务侧只操作结构而不直接触碰代码。json-render 并没有发明这种模式，它继承的正是这一整条技术脉络。</p>\n<p>json-render 的不同之处在于，它首次把“模型生成”作为一等公民纳入设计前提。传统 schema UI 假设配置由人编写，因此更强调完整性、可读性和编辑体验；而 json-render 假设结构由模型生成，因此更强调语法边界清晰、失败可恢复、部分结果可执行，以及与 Prompt 的自动对齐能力。从这个角度看，json-render 更像是“为 AI 重新设计的一代 schema UI 执行模型”。它真正解决的问题并不是“怎么用 JSON 渲染 UI”，而是当结构来源变成不可靠的模型时，工程边界应该在哪里。它给出的答案非常明确：AI 只负责生成结构化意图，工程师负责能力定义、执行与渲染，JSON 作为唯一中介和约束层。这使得 AI UI 不再是一次性 Demo，而是可以进入生产系统的工程能力。在当前阶段，这是少数真正站在工程立场思考 AI UI 的方案之一。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://json-render.dev/\" rel=\"noopener nofollow\" target=\"_blank\">json-render.dev</a></li>\n<li><a href=\"https://github.com/vercel-labs/json-render\" rel=\"noopener nofollow\" target=\"_blank\">github.com/vercel-labs/json-render</a></li>\n<li><a href=\"https://vercel.com/blog\" rel=\"noopener nofollow\" target=\"_blank\">vercel.com/blog</a></li>\n<li><a href=\"https://www.cnblogs.com/guangzan/p/19350726\" target=\"_blank\">Zod：TypeScript 类型守卫与数据验证</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 15:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/guangzan\">guangzan</a>&nbsp;\n阅读(<span id=\"post_view_count\">297</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "SeaTunnel(2.3.12)的高级用法（四）：多个source、多个sink",
      "link": "https://www.cnblogs.com/kakarotto-chen/p/19487270",
      "published": "",
      "description": "<h2>\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kakarotto-chen/p/19487270\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 15:08\">\n    <span>SeaTunnel(2.3.12)的高级用法（四）：多个source、多个sink</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"postbody\">\n            <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前置知识seatunnel配置中有数据流data-flow转的概念\">前置知识：seatunnel配置中有数据流（Data Flow）转的概念</h2>\n<p>见：<a href=\"https://www.cnblogs.com/kakarotto-chen/p/19487384\" target=\"_blank\">https://www.cnblogs.com/kakarotto-chen/p/19487384</a></p>\n<h2 id=\"demo1两个source汇聚到一个sink\">demo1：两个source汇聚到一个sink</h2>\n<ul>\n<li>\n<p>关键配置：sink的：plugin_input = [\"source_data1\", \"source_data2\"]</p>\n</li>\n<li>\n<p>对应模型</p>\n</li>\n</ul>\n<pre><code>┌──────────┐\n│ Source A │──┐\n└──────────┘  │\n              ├──▶  Sink\n┌──────────┐  │\n│ Source B │──┘\n└──────────┘\n</code></pre>\n<ul>\n<li>执行语句</li>\n</ul>\n<pre><code># ds-st-demo10-2-mysql2pgsql.conf\nsh /data/tools/seatunnel/seatunnel-2.3.12/bin/seatunnel.sh --config /data/tools/seatunnel/myconf/ds-st-demo10-2-mysql2pgsql.conf -i -DJvmOption=\"-Xms2G -Xmx2G\" -m local\n</code></pre>\n<ul>\n<li>建表</li>\n</ul>\n<pre><code>-- ds-st-demo10-2-mysql2pgsql.conf\nCREATE TABLE \"public\".\"t_8_100w_imp_st_ds_demo10\" (\n  id BIGINT PRIMARY KEY,\n  user_name VARCHAR(2000),\n  sex VARCHAR(20),\n  decimal_f NUMERIC(32, 6),\n  phone_number VARCHAR(20),\n  age INT,\n  create_time TIMESTAMP,\n  description TEXT,\n  address VARCHAR(2000) DEFAULT '未知',\n  my_status INT\n);\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"id\" IS '主键';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"user_name\" IS '名字';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"sex\" IS '性别：男；女';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"decimal_f\" IS '大数字';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"phone_number\" IS '电话';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"age\" IS '字符串年龄转数字';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"create_time\" IS '新增时间';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"description\" IS '大文本';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"address\" IS '空地址转默认值：未知';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"my_status\" IS '状态';\n\n</code></pre>\n<ul>\n<li>conf配置</li>\n</ul>\n<pre><code>env {\n  # 任务名字：业务中可以弄表id\n  job.name = \"ds-st-demo10.conf\"\n  # 最大批线程数：并行度（线程数）\n  parallelism = 5\n  # 任务模式：BATCH:批处理模式；STREAMING:流处理模式\n  job.mode = \"BATCH\"\n}\n\nsource {\n  # 第一个数据集\n  jdbc {\n    # 给这个数据集起个名字\n    plugin_output = \"source_data1\"\n  \n    url = \"jdbc:mysql://ip:port/cs1\"\n    driver = \"com.mysql.cj.jdbc.Driver\"\n    user = \"root\"\n    password = \"***\"\n    # sql\n    query = \"select id,name as user_name,sex,decimal_f,phone_number,CAST(age AS SIGNED) as age,create_time,description,address from t_8_100w where id &lt; 10\"\n    \n    # 并行读取配置\n    # 分片的字段：支持：String、Number(int, bigint, decimal, ...)、Date\n    partition_column = \"id\"\n    # 表的分割大小（行数）：每个分片的数据行（默认8096行）。最后分片数=表的总行数 / split.size\n    split.size = 50000\n    # 分片数，匹配并行度parallelism（2.3.12已不推荐配置了，用split.size来代替）\n    # partition_num = 5\n    # 最大批处理数:查询的行提取大小(指定当前任务每次执行时读取数据条数,该值(默认1000)受运行内存影响,若该值较大或单条数据量较大，需适当调整运行内存大小。)\n    fetch_size = 10000\n    \n    # 连接参数\n    # 连接超时时间300ms\n    connection_check_timeout_sec = 300\n    # 其他jdbc的参数\n    properties = {\n      useUnicode = true\n      characterEncoding = \"utf8\"\n      # 时区，不同数据库参数不一样\n      serverTimezone = \"Asia/Shanghai\"\n      # 使用游标提高大结果集性能\n      useCursorFetch = \"true\"\n      # 每次获取行数\n      defaultFetchSize = \"10000\"\n    }\n  }\n  \n  # 第二个数据集\n  jdbc {\n    # 给这个数据集起个名字\n    plugin_output = \"source_data2\"\n  \n    url = \"jdbc:mysql://ip:port/cs1\"\n    driver = \"com.mysql.cj.jdbc.Driver\"\n    user = \"root\"\n    password = \"***\"\n    # \n    query = \"select id,name as user_name,sex,decimal_f,phone_number,CAST(age AS SIGNED) as age,create_time,description,address from t_8_100w where id &gt; 10 and id &lt; 20\"\n    \n    # 并行读取配置\n    # 分片的字段：支持：String、Number(int, bigint, decimal, ...)、Date\n    partition_column = \"id\"\n    # 表的分割大小（行数）：每个分片的数据行（默认8096行）。最后分片数=表的总行数 / split.size\n    split.size = 50000\n    # 分片数，匹配并行度parallelism（2.3.12已不推荐配置了，用split.size来代替）\n    # partition_num = 5\n    # 最大批处理数:查询的行提取大小(指定当前任务每次执行时读取数据条数,该值(默认1000)受运行内存影响,若该值较大或单条数据量较大，需适当调整运行内存大小。)\n    fetch_size = 10000\n    \n    # 连接参数\n    # 连接超时时间300ms\n    connection_check_timeout_sec = 300\n    # 其他jdbc的参数\n    properties = {\n      useUnicode = true\n      characterEncoding = \"utf8\"\n      # 时区，不同数据库参数不一样\n      serverTimezone = \"Asia/Shanghai\"\n      # 使用游标提高大结果集性能\n      useCursorFetch = \"true\"\n      # 每次获取行数\n      defaultFetchSize = \"10000\"\n    }\n  }\n}\n\n# 清洗转换（简单的清洗转换，直接在source的query的sql中处理了就行）\ntransform {\n  # 1. 字段映射：sql中做了，实际生成中不在这里处理。直接在source的query的sql中处理了就行\n  # 还可以用：FieldMapper 插件，来映射字段\n  \n  # 转换age为数字类型（pgsql必须转）\n  \n  # 2. 手机号脱敏：13812341234 -&gt; 138****1234\n  \n  # 3. 年龄转换：字符串转整数（实际生产中，不用转换，也没有内置的转换插件，可以直接保存成功）\n\n  # 4. 性别转换：1-&gt;男，2-&gt;女\n  \n  # 5. 数据过滤：只保留 age &gt; 25 的记录。\n  \n  # 6. 地址默认值：空地址设为'未知'\n}\n\nsink {\n  jdbc {\n    # 接收的最终数据集（汇聚到一个结果中）\n    plugin_input = [\"source_data1\", \"source_data2\"]\n    \n    url = \"jdbc:postgresql://ip:5432/source_db\"\n    driver = \"org.postgresql.Driver\"\n    user = \"postgres\"\n    password = \"123456\"\n    # \n    # query = \"\"\n    \n    # 自动生成sql的配置，和query参数互斥\n    # 生成自动插入sql。如果目标库没有表，也会自动建表\n    generate_sink_sql = true\n    # database必须要，因为generate_sink_sql=true。\n    database = source_db\n    # 自动生成sql时，table必须要。\n    table = \"public.t_8_100w_imp_st_ds_demo10\"\n    # 生成类似：INSERT INTO …… ON CONFLICT (\"主键\") DO UPDATE SET …… 的sql\n    # enable_upsert = true\n    # 判断值唯一的健：此选项用于支持在自动生成 SQL 时进行 insert，delete 和 update 操作。\n    # primary_keys = [\"id\"]\n\n    # 表结构处理策略：表不存在时报错（任务失败），一般用：CREATE_SCHEMA_WHEN_NOT_EXIST（表不存在时创建表；表存在时跳过操作（保留数据））\n    schema_save_mode = \"ERROR_WHEN_SCHEMA_NOT_EXIST\"\n    # 插入数据的处理策略\n    # APPEND_DATA：保留表结构和数据，追加新数据（不删除现有数据）(一般用这个)\n    # DROP_DATA：保留表结构，删除表中所有数据（清空表）——实现清空重灌\n    # CUSTOM_PROCESSING :用户定义处理。需要配合：custom_sql使用\n    data_save_mode = \"DROP_DATA\"\n    # 当 data_save_mode 选择 CUSTOM_PROCESSING 时，您应该填写 CUSTOM_SQL 参数。此参数通常填入可执行的 SQL。SQL 将在同步任务之前执行。\n    #可以实现：同步删除（执行前置update、truncate的sql等）\n    #这个sql未执行，不知道为啥。\n    #这个sql已经执行。原因：因为generate_sink_sql=true的原因。才会执行custom_sql。（只有自动生成sql的时候，这个才会执行）\n    custom_sql = \"\"\"update \"source_db\".\"public\".\"t_8_100w_imp_st_ds_demo10\" set \"my_status\" = 23\"\"\"\n    \n    # 批量写入条数\n    batch_size = 10000\n    # 批次提交间隔\n    batch_interval_ms = 500\n    # 重试次数\n    max_retries = 3\n    \n    # 连接参数\n    # 连接超时时间300ms\n    connection_check_timeout_sec = 300\n    # 其他jdbc的参数\n    properties = {\n      # PostgreSQL专用参数\n      # PostgreSQL的批量优化（注意大小写）\n      reWriteBatchedInserts = \"true\"  \n      # 如果需要时区设置\n      options = \"-c timezone=Asia/Shanghai\"\n    }\n  }\n}\n</code></pre>\n<ul>\n<li>结果(汇聚了19条数据)</li>\n</ul>\n<pre><code>2026-01-15 14:28:15,952 INFO  [s.c.s.s.c.ClientExecuteCommand] [main] - \n***********************************************\n           Job Statistic Information\n***********************************************\nStart Time                : 2026-01-15 14:28:11\nEnd Time                  : 2026-01-15 14:28:15\nTotal Time(s)             :                   4\nTotal Read Count          :                  19\nTotal Write Count         :                  19\nTotal Failed Count        :                   0\n***********************************************\n</code></pre>\n<h2 id=\"demo2一个source分发到两个sink\">demo2：一个source分发到两个sink</h2>\n<p>……………………未完待续</p>\n\n</div>\n<div class=\"clear\"></div>\n\n        </div>\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-01-15 15:08</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kakarotto-chen\">C_C_菜园</a>&nbsp;\n阅读(<span id=\"post_view_count\">20</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "如何通过 C# 将 PPT 文档转换为 PDF 格式",
      "link": "https://www.cnblogs.com/jazz-z/p/19486170",
      "published": "",
      "description": "<div class=\"postcontent\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在日常开发和办公场景中，将 PowerPoint（PPT/PPTX） 转换为 PDF 格式是高频需求。PDF 格式具有跨平台兼容性强、格式固定不易篡改、便于分发归档等优势。本文将介绍如何使用一款 .NET PowerPoint 组件通过 C# 实现 PPT 转 PDF，并提供完整代码示例。</p>\n<h2 id=\"1-安装-net-库\">1. 安装 .NET 库</h2>\n<p>Spire.Presentation 是一款专门用于处理 PowerPoint 文档的 .NET 组件，无需依赖 Microsoft Office 或 PowerPoint 客户端即可完成 PPT 文档的读取、编辑和格式转换。推荐通过 NuGet 包管理器安装，步骤如下：</p>\n<ol>\n<li>打开 Visual Studio，创建任意 C# 项目（如Console App）；</li>\n<li>右键项目→“管理NuGet程序包”；</li>\n<li>搜索“Spire.Presentation”，选择对应版本安装；</li>\n<li>也可通过NuGet命令行安装：</li>\n</ol>\n<pre><code class=\"language-bash\">Install-Package Spire.Presentation\n</code></pre>\n<h2 id=\"2-基础示例单个-powerpoint-文件转-pdf\">2. 基础示例：单个 PowerPoint 文件转 PDF</h2>\n<p>这是最常用的场景，支持 PPT/PPTX 格式输入，直接通过 <code>SaveToFile</code> 方法输出为 PDF 文件：</p>\n<pre><code class=\"language-csharp\">using System;\nusing Spire.Presentation;\n\nnamespace PptToPdfDemo\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            try\n            {\n                // 1. 定义文件路径\n                string pptFilePath = @\"D:\\Demo\\source.pptx\"; // 输入PPT路径\n                string pdfFilePath = @\"D:\\Demo\\output.pdf\";   // 输出PDF路径\n\n                // 2. 加载PPT文档\n                Presentation presentation = new Presentation();\n                presentation.LoadFromFile(pptFilePath);\n\n                // 3. 转换为PDF并保存\n                // 可选参数：PDF导出选项（如压缩、权限等），此处使用默认配置\n                presentation.SaveToFile(pdfFilePath, FileFormat.PDF);\n\n                // 4. 释放资源（关键，避免内存泄漏）\n                presentation.Dispose();\n\n                Console.WriteLine(\"PPT转PDF成功！\");\n            }\n            catch (Exception ex)\n            {\n                // 异常处理：捕获文件不存在、格式不支持、权限不足等问题\n                Console.WriteLine($\"转换失败：{ex.Message}\");\n            }\n        }\n    }\n}\n</code></pre>\n<h3 id=\"3-批量转换转换多个-powerpoint-文件为-pdf\">3. 批量转换：转换多个 PowerPoint 文件为 PDF</h3>\n<p>通过遍历文件夹实现批量转换，适合处理大量 PPT 文件：</p>\n<pre><code class=\"language-csharp\">using System;\nusing System.IO;\nusing Spire.Presentation;\n\nnamespace BatchPptToPdf\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            // 源PPT文件夹路径\n            string pptFolderPath = @\"D:\\Demo\\PptFiles\";\n            // 输出PDF文件夹路径\n            string pdfFolderPath = @\"D:\\Demo\\PdfFiles\";\n\n            // 确保输出文件夹存在\n            if (!Directory.Exists(pdfFolderPath))\n            {\n                Directory.CreateDirectory(pdfFolderPath);\n            }\n\n            // 遍历文件夹中的PPT/PPTX文件\n            string[] pptFiles = Directory.GetFiles(pptFolderPath, \"*\", SearchOption.TopDirectoryOnly)\n                .Where(file =&gt; file.EndsWith(\".ppt\", StringComparison.OrdinalIgnoreCase) \n                             || file.EndsWith(\".pptx\", StringComparison.OrdinalIgnoreCase))\n                .ToArray();\n\n            foreach (string pptFile in pptFiles)\n            {\n                try\n                {\n                    // 获取文件名（不含扩展名），用于生成PDF文件名\n                    string fileName = Path.GetFileNameWithoutExtension(pptFile);\n                    string pdfFile = Path.Combine(pdfFolderPath, $\"{fileName}.pdf\");\n\n                    // 加载并转换\n                    using (Presentation presentation = new Presentation())\n                    {\n                        presentation.LoadFromFile(pptFile);\n                        presentation.SaveToFile(pdfFile, FileFormat.PDF);\n                    }\n\n                    Console.WriteLine($\"已转换：{pptFile} → {pdfFile}\");\n                }\n                catch (Exception ex)\n                {\n                    Console.WriteLine($\"转换失败 {pptFile}：{ex.Message}\");\n                }\n            }\n\n            Console.WriteLine(\"批量转换完成！\");\n        }\n    }\n}\n</code></pre>\n<h3 id=\"4-进阶示例将-powerpoint-转换为加密的-pdf\">4. 进阶示例：将 PowerPoint 转换为加密的 PDF</h3>\n<p>还可以在转换时直接加密保护 PDF 文件，并为 PDF 设置权限：</p>\n<pre><code class=\"language-csharp\">using Spire.Presentation;\nusing Spire.Presentation.External.Pdf;\n\nnamespace ConvertToEncryptedPdf\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            // 定义明确的文件路径（建议替换为你的实际路径）\n            string inputPptPath = @\"C:\\Users\\Administrator\\Desktop\\Input.pptx\";\n            string outputPdfPath = @\"C:\\Users\\Administrator\\Desktop\\ToEncryptedPdf.pdf\";\n            \n            // 使用using语句自动释放Presentation资源（优于手动Dispose）\n            try\n            {\n                using (Presentation presentation = new Presentation())\n                {\n                    // 加载PPT文件\n                    presentation.LoadFromFile(inputPptPath);\n\n                    // 获取PDF保存选项\n                    SaveToPdfOption option = presentation.SaveToPdfOption;\n                    \n                    // 设置PDF密码和权限\n                    // 参数说明：\n                    // 1. 用户密码（打开PDF需要输入的密码）：abc-123\n                    // 2. 所有者密码（用于修改PDF权限的密码）：owner-456（可自定义）\n                    // 3. PDF权限：允许打印 + 允许填写表单\n                    // 4. 加密级别：默认128位（高安全性）\n                  option.PdfSecurity.Encrypt(\"abc-123\", \"owner-456\", \n                        PdfPermissionsFlags.Print | PdfPermissionsFlags.FillFields, \n                        PdfEncryptionKeySize.Key128Bit);\n\n                    // 保存为加密PDF\n                    presentation.SaveToFile(outputPdfPath, FileFormat.PDF, pdfOptions);\n\n                    Console.WriteLine(\"PPT已成功转换为加密PDF！\");\n                    Console.WriteLine($\"输出路径：{outputPdfPath}\");\n                }\n            }\n            catch (Exception ex)\n            {\n                // 捕获所有可能的异常并提示\n                Console.WriteLine($\"转换失败：{ex.Message}\");\n            }\n\n            // 暂停控制台，便于查看结果\n            Console.ReadLine();\n        }\n    }\n}\n</code></pre>\n<h2 id=\"5-关键注意事项\">5. 关键注意事项</h2>\n<ol>\n<li>\n<p><strong>格式兼容性</strong>：</p>\n<ul>\n<li>支持输入格式：PPT、PPTX、PPS、PPSX 等；</li>\n<li>复杂PPT元素（如3D图表、自定义动画、嵌入式视频）转换后可能丢失或显示异常（。</li>\n</ul>\n</li>\n<li>\n<p><strong>资源释放</strong>：</p>\n<ul>\n<li>必须通过 <code>Dispose()</code> 方法释放 <code>Presentation</code> 对象，或使用 <code>using</code> 语句（推荐），否则易导致内存泄漏，尤其批量转换时需注意。</li>\n</ul>\n</li>\n<li>\n<p><strong>权限问题</strong>：</p>\n<ul>\n<li>确保程序对输入/输出路径有读写权限，否则会抛出 <code>UnauthorizedAccessException</code>。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"6-替代方案参考\">6. 替代方案参考</h2>\n<ol>\n<li><strong>LibreOffice SDK</strong>：免费开源，需部署 LibreOffice 服务，API 较复杂；</li>\n<li><strong>OpenXML SDK + iTextSharp</strong>：仅支持 PPTX（OpenXML 格式），需自行处理布局转换，开发成本高；</li>\n<li><strong>GroupDocs.Conversion</strong>：有免费额度，云原生支持，但依赖网络。</li>\n</ol>\n<hr />\n<p>本文提供了可靠的 C# PowerPoint 转 PDF 解决方案，特别适合在服务器环境或无需安装 Microsoft Office 的场景中使用。其优点包括部署简单、API 设计清晰、支持多种输出选项等。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"itemdesc\">\n                发表于 \n<span id=\"post-date\">2026-01-15 10:37</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jazz-z\">LAYONTHEGROUND</a>&nbsp;\n阅读(<span id=\"post_view_count\">133</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n            </div>"
    },
    {
      "title": "新的旅程",
      "link": "https://www.cnblogs.com/lichengxiao/p/19485897",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lichengxiao/p/19485897\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 09:50\">\n    <span>新的旅程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>4年了，从大三开始接触互联网游戏，每天浑浑噩噩洲瓦派，到现在已经在工作了，真的有点难以置信。</p>\n<p>我没有璀璨的大学生活，没有生日聚会，没有谈过恋爱，没有毕业旅行。在学校的时间大多数也是在打游戏，所以荒废了学业，当时火热的网络安全攻防的行业由于电子游戏的入侵也成功失之交臂，但是我不后悔，可能因为我至始至终都是一个孤独的小孩吧。</p>\n<p>大三那年打apex有幸结识了一个朋友，他打的挺厉害的，但是就是喜欢“骂”我菜，我确实挺菜的，玩什么游戏都没有什么天赋。和他加了微信，由于没给他备注，所以他的微信备注就是他申请好友给我发的：“我是”。</p>\n<p>后来啊，没想到他竟然帮了我一把。认识他的时候，他在成都的IT培训班进行培训，后来听说他入职了一个广东深圳的单位，说是待遇超级好，但是我技术平平，B站的每一个教学视频都看了开头，但是实际上啥也不会写。</p>\n<p>大四在Boss直聘海投，有幸到隔壁城市的一家500强企业实习。但是呆了一周我发现，虽然工资平平，但是我周围都是专科毕业，突然意识到了学历的价值！正赶上毕业季，异想天开辞职考研。结果也是注定的，25届考研难度飙升，花了家里2w块钱，成功没有考上。</p>\n<p>直到25年末，还是在游戏，人生落魄至极点，每天整夜通宵打游戏，早上9点休息，睡醒便是下午5、6点了。然后就是点外卖、打游戏。（实际上打游戏也没有固定的好朋友）甚至有时候觉得生命也就这样吧。</p>\n<p>突然有一天，“我是”和我说他们公司招人，愿意培养新人，稍微有点python底子会使电脑就可以，我之前玩过一段时间python爬虫，于是也就硬着头皮上了。 就此开启了东北人第一次出家门，前往深圳工作的新旅程。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 09:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lichengxiao\">熬夜不早睡</a>&nbsp;\n阅读(<span id=\"post_view_count\">582</span>)&nbsp;\n评论(<span id=\"post_comment_count\">21</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【大数据 & AI】Flink Agents 源码解读 --- (7) ---  AgentsExecutionEnvironment",
      "link": "https://www.cnblogs.com/rossiXYZ/p/19489355",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/rossiXYZ/p/19489355\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 21:56\">\n    <span>【大数据 &amp; AI】Flink Agents 源码解读 --- (7) ---  AgentsExecutionEnvironment</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"大数据--aiflink-agents-源码解读-----7------agentsexecutionenvironment\">【大数据 &amp; AI】Flink Agents 源码解读 --- (7) ---  AgentsExecutionEnvironment</h1>\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">目录</div><ul><li><a href=\"#大数据--aiflink-agents-源码解读-----7------agentsexecutionenvironment\" rel=\"noopener nofollow\">【大数据 &amp; AI】Flink Agents 源码解读 --- (7) ---  AgentsExecutionEnvironment</a><ul><li><a href=\"#0x00-概要\" rel=\"noopener nofollow\">0x00 概要</a></li><li><a href=\"#0x01-基础知识\" rel=\"noopener nofollow\">0x01 基础知识</a><ul><li><a href=\"#11-定义\" rel=\"noopener nofollow\">1.1 定义</a></li><li><a href=\"#12-功能\" rel=\"noopener nofollow\">1.2 功能</a></li><li><a href=\"#13-与原生-flink-environment-的区别\" rel=\"noopener nofollow\">1.3 与原生 Flink Environment 的区别</a></li></ul></li><li><a href=\"#0x02-localexecutionenvironment\" rel=\"noopener nofollow\">0x02 LocalExecutionEnvironment</a><ul><li><a href=\"#21-定义\" rel=\"noopener nofollow\">2.1 定义</a><ul><li><a href=\"#211-主要功能\" rel=\"noopener nofollow\">2.1.1 主要功能</a></li><li><a href=\"#212-代码\" rel=\"noopener nofollow\">2.1.2 代码</a></li><li><a href=\"#213-执行流程\" rel=\"noopener nofollow\">2.1.3 执行流程</a></li><li><a href=\"#214-组件关系\" rel=\"noopener nofollow\">2.1.4 组件关系</a></li></ul></li><li><a href=\"#22-localrunner\" rel=\"noopener nofollow\">2.2 LocalRunner</a><ul><li><a href=\"#221-localrunner-的主要功能\" rel=\"noopener nofollow\">2.2.1 LocalRunner 的主要功能</a></li><li><a href=\"#222-事件驱动执行模型\" rel=\"noopener nofollow\">2.2.2 事件驱动执行模型</a></li><li><a href=\"#223-agentplan-和-localrunner-的关系\" rel=\"noopener nofollow\">2.2.3 AgentPlan 和 LocalRunner 的关系</a></li><li><a href=\"#224-为什么要为每种-key-维护独立的上下文\" rel=\"noopener nofollow\">2.2.4 为什么要为每种 key 维护独立的上下文</a></li><li><a href=\"#225-实际应用场景示例\" rel=\"noopener nofollow\">2.2.5 实际应用场景示例</a></li></ul></li><li><a href=\"#23-localrunnercontext\" rel=\"noopener nofollow\">2.3 LocalRunnerContext</a><ul><li><a href=\"#231-设计目的\" rel=\"noopener nofollow\">2.3.1 设计目的</a></li><li><a href=\"#232-主要功能\" rel=\"noopener nofollow\">2.3.2 主要功能</a></li><li><a href=\"#233-定义\" rel=\"noopener nofollow\">2.3.3 定义</a></li></ul></li></ul></li><li><a href=\"#0x03-remoteexecutionenvironment\" rel=\"noopener nofollow\">0x03 RemoteExecutionEnvironment</a><ul><li><a href=\"#31-核心特色\" rel=\"noopener nofollow\">3.1 核心特色</a></li><li><a href=\"#32-与原生-flink-remoteenvironment-的对比\" rel=\"noopener nofollow\">3.2 与原生 Flink RemoteEnvironment 的对比</a></li><li><a href=\"#33-如何使用-actionexecutionoperator\" rel=\"noopener nofollow\">3.3 如何使用 ActionExecutionOperator</a></li><li><a href=\"#34-典型流程\" rel=\"noopener nofollow\">3.4 典型流程</a></li><li><a href=\"#35-交互逻辑\" rel=\"noopener nofollow\">3.5 交互逻辑</a></li><li><a href=\"#36-实现\" rel=\"noopener nofollow\">3.6 实现</a></li></ul></li><li><a href=\"#0xff-参考\" rel=\"noopener nofollow\">0xFF 参考</a></li></ul></li></ul></div><p></p>\n<h2 id=\"0x00-概要\">0x00 概要</h2>\n<p>AgentsExecutionEnvironment 是在Flink基础上构建的一个更高层次的执行环境，专门为Agent而设计，同时保留了与原生 Flink API 的兼容性。</p>\n<h2 id=\"0x01-基础知识\">0x01 基础知识</h2>\n<p>可以把 Flink 原生的 <code>StreamExecutionEnvironment</code> / <code>TableEnvironment</code> 理解成“Agent 话题里所说的<strong>执行环境</strong>（Execution Environment）”，但是其无法直接被 Agent 使用。因此需要在其上做一些封装和适配，这就是 AgentsExecutionEnvironment。</p>\n<ol>\n<li>Flink Environment = 纯粹的<strong>计算资源与运行时容器</strong>\n<ul>\n<li>负责申请 Slot、管理 Checkpoint、调度算子链、网络 Shuffle</li>\n<li>对“业务语义”一无所知，也不管用户写的是 ETL、CEP 还是 AI 推理</li>\n<li>对应 Agent 词汇表里的“Runtime / Cluster / Engine”这一层</li>\n</ul>\n</li>\n<li>Agent Environment = 在 Flink Runtime 之上包了一层<strong>语义抽象</strong>\n<ul>\n<li>替用户注册 Chat Model、Tools、Memory、Actions、Event Schema</li>\n<li>把“用户消息”或“传感器事件”封装成 Event，按 AgentPlan 去调大模型、执行业务动作</li>\n<li>内部仍然用 <code>StreamExecutionEnvironment</code> 去提交算子，只是看不到显式的 <code>keyBy()</code> 和 <code>process()</code>——框架帮用户生成了 <code>ActionExecutionOperator</code></li>\n</ul>\n</li>\n</ol>\n<p>类比关系如下：</p>\n<pre><code class=\"language-python\">传统 Flink 程序\n├─ StreamExecutionEnvironment   ← 纯运行时\n├─ your ProcessFunction         ← 用户的业务逻辑\n└─ DataStream\n\nFlink Agents 程序\n├─ AgentsExecutionEnvironment   ← Agent 语义环境，内部仍持有 StreamExecutionEnvironment\n├─ AgentPlan（your business）   ← 定义“遇到啥事件该干啥”\n└─ ActionExecutionOperator     ← 框架替用户生成的算子，负责调大模型、更新记忆\n</code></pre>\n<h3 id=\"11-定义\">1.1 定义</h3>\n<p>AgentsExecutionEnvironment 的代码如下。</p>\n<pre><code class=\"language-java\">/**\n * Base class for agent execution environment.\n *\n * &lt;p&gt;This class provides the main entry point for integrating Flink Agents with different types of\n * Flink data sources (DataStream, Table, or simple lists).\n */\npublic abstract class AgentsExecutionEnvironment {\n    protected final Map&lt;ResourceType, Map&lt;String, Object&gt;&gt; resources;\n\n    protected AgentsExecutionEnvironment() {\n        this.resources = new HashMap&lt;&gt;();\n        for (ResourceType type : ResourceType.values()) {\n            this.resources.put(type, new HashMap&lt;&gt;());\n        }\n    }\n    \n    /**\n     * Get agents execution environment.\n     *\n     * &lt;p&gt;Factory method that creates an appropriate execution environment based on the provided\n     * StreamExecutionEnvironment. If no environment is provided, a local execution environment is\n     * returned for testing and development.\n     *\n     * &lt;p&gt;When integrating with Flink DataStream/Table APIs, users should pass the Flink\n     * StreamExecutionEnvironment to enable remote execution capabilities.\n     *\n     * @param env Optional StreamExecutionEnvironment for remote execution. If null, a local\n     *     execution environment will be created.\n     * @param tEnv Optional StreamTableEnvironment for table-to-stream conversion.\n     * @return AgentsExecutionEnvironment appropriate for the execution context.\n     */\n    public static AgentsExecutionEnvironment getExecutionEnvironment(\n            StreamExecutionEnvironment env, @Nullable StreamTableEnvironment tEnv) {\n        if (env == null) {\n            // Return local execution environment for testing/development\n            try {\n                Class&lt;?&gt; localEnvClass =\n                        Class.forName(                                \"org.apache.flink.agents.runtime.env.LocalExecutionEnvironment\");\n                return (AgentsExecutionEnvironment)\n                        localEnvClass.getDeclaredConstructor().newInstance();\n            } catch (Exception e) {\n                throw new RuntimeException(\"Failed to create LocalExecutionEnvironment\", e);\n            }\n        } else {\n            // Return remote execution environment for Flink integration\n            try {\n                Class&lt;?&gt; remoteEnvClass =\n                        Class.forName(                                \"org.apache.flink.agents.runtime.env.RemoteExecutionEnvironment\");\n                return (AgentsExecutionEnvironment)\n                        remoteEnvClass\n                                .getDeclaredConstructor(\n                                        StreamExecutionEnvironment.class,\n                                        StreamTableEnvironment.class)\n                                .newInstance(env, tEnv);\n            } catch (Exception e) {\n                throw new RuntimeException(\"Failed to create RemoteExecutionEnvironment\", e);\n            }\n        }\n    }    \n</code></pre>\n<h3 id=\"12-功能\">1.2 功能</h3>\n<p>AgentsExecutionEnvironment 的功能如下：</p>\n<ul>\n<li>统一入口：\n<ul>\n<li>提供getExecutionEnvironment()系列静态工厂方法，可以依据是否传入Flink的 StreamExecutionEnvironment来创建本地或远程执行环境。</li>\n<li>支持从不同数据源构建构建Agent管道，包括List，DataStream和Table。</li>\n</ul>\n</li>\n<li>资源配置管理：\n<ul>\n<li>内置 resources 映射结构，支持按照资源类型管理各种资源。</li>\n<li>提供 addResource() 方法注册可序列化的资源或者资源描述符。</li>\n</ul>\n</li>\n<li>多输入源支持：\n<ul>\n<li>fromList()：支持从简单列表创建本地执行环境。</li>\n<li>fromDataStream()：集成Flink DataStream API</li>\n<li>fromTable()：集成Flink Table API</li>\n</ul>\n</li>\n<li>配置管理：\n<ul>\n<li>提供getConfig()抽象方法获取可写的配置对象。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"13-与原生-flink-environment-的区别\">1.3 与原生 Flink Environment 的区别</h3>\n<ul>\n<li>抽象层级更高：AgentExecutionEnvrionment是对Flink原生环境的封装，在其之上提供了面向Agent的编程模型。主要用于运行Agent，而非 直接处理数据流。</li>\n<li>执行模式：AgentExecutionEnvrionment 通过 LocalExecutionEnvironment 和 RemoteExecutionEnvironment 分别支持本地测试和远程集群执行。原生 Flink 主要通过配置参数控制执行模式。</li>\n<li>资源管理机制：AgentExecutionEnvrionment 内置了专门的资源注册和管理机制，支持按类型分类管理支援。原生 Flink 没有这种结构化的资源管理方式。</li>\n<li>API 设计目标：面向 Agent 编程范式，强调事件驱动的自主行为体模型。原生Flink 更关注数据流处理和批处理操作。</li>\n</ul>\n<h2 id=\"0x02-localexecutionenvironment\">0x02 LocalExecutionEnvironment</h2>\n<p>LocalExecutionEnvironment 是 AgentsExecutionEnvironment 的一种实现形式。</p>\n<pre><code class=\"language-java\">Class&lt;?&gt; localEnvClass = Class.forName(                                \"org.apache.flink.agents.runtime.env.LocalExecutionEnvironment\");\n                return (AgentsExecutionEnvironment)\n                        localEnvClass.getDeclaredConstructor().newInstance();\n</code></pre>\n<p>LocalExecutionEnvironment  主要用于</p>\n<ul>\n<li>开发阶段的快速测试和调试</li>\n<li>无需 Flink 集群即可验证代理逻辑</li>\n<li>简化Agent应用的本地开发流程</li>\n<li>它与远程执行环境形成对比，后者支持完整的 Flink DataStream 和 Table API 集成。</li>\n</ul>\n<h3 id=\"21-定义\">2.1 定义</h3>\n<h4 id=\"211-主要功能\">2.1.1 主要功能</h4>\n<p>LocalExecutionEnvironment  的主要功能如下：</p>\n<ul>\n<li>本地执行环境实现\n<ul>\n<li>集成自 AgentExecutionEnvrionment，为本地测试和开发提供执行环境</li>\n<li>不依赖 Flink 集群，可以在本地环境中运行和调试代理</li>\n</ul>\n</li>\n<li>数据源支持\n<ul>\n<li>通过from_list方法支持从列表数据源读取输入数据</li>\n<li>不支持 Flink 的DataStream 和 Table API（这些在远程执行环境中使用）</li>\n</ul>\n</li>\n<li>资源配置和管理\n<ul>\n<li>存储和管理通过 add_resource 方法注册的资源</li>\n<li>在构建Agent时，将环境中的资源注入到Agent实例中</li>\n</ul>\n</li>\n<li>代理执行管理\n<ul>\n<li>通过  set_agent 方法设置待执行的Agent、输入和输出</li>\n<li>使用 LocalRunner  在本地执行代理逻辑</li>\n<li>通过 execute 方法触发代理执行</li>\n</ul>\n</li>\n<li>结果收集\n<ul>\n<li>收集Agent执行的输出结果</li>\n<li>通过 to_list  方法返回执行结果</li>\n</ul>\n</li>\n</ul>\n<p>根据代码分析， execute 函数在以下情况下被调用：</p>\n<ul>\n<li>用户手动调用。当用户完成代理配置和输入数据设置后，需要显式调用execute()  方法来启动Agent 执行流程，这通常式配置完所有必要组件后的最后一步。</li>\n</ul>\n<h4 id=\"212-代码\">2.1.2 代码</h4>\n<p>LocalExecutionEnvironment 的定义如下，其中 LocalRunner 是核心。</p>\n<pre><code class=\"language-java\">class LocalExecutionEnvironment(AgentsExecutionEnvironment):\n    \"\"\"Implementation of AgentsExecutionEnvironment for local execution environment.\"\"\"\n\n    __input: List[Dict[str, Any]] = None\n    __output: List[Any] = None\n    __runner: LocalRunner = None\n    __executed: bool = False\n    __config: AgentConfiguration = AgentConfiguration()\n        \n    def set_agent(self, input: list, output: list, runner: LocalRunner) -&gt; None:\n        \"\"\"Set agent input, output and runner.\"\"\"\n        self.__input = input\n        self.__runner = runner\n        self.__output = output\n\n    def execute(self) -&gt; None:\n        \"\"\"Execute agent individually.\"\"\"\n        if self.__executed:\n            err_msg = (\n                \"LocalExecutionEnvironment doesn't support execute multiple times.\"\n            )\n            raise RuntimeError(err_msg)\n        self.__executed = True\n        for input in self.__input:\n            self.__runner.run(**input)\n        outputs = self.__runner.get_outputs()\n        for output in outputs:\n            self.__output.append(output)        \n</code></pre>\n<h4 id=\"213-执行流程\">2.1.3 执行流程</h4>\n<p>在 LocalExecutionEnvironment 中，execute 方法会：</p>\n<ul>\n<li>遍历所有输入数据项</li>\n<li>对每个输入调用 LocalRunner  的run方法进行处理</li>\n<li>收集所有输出结果</li>\n</ul>\n<p>典型的调用序列如下：</p>\n<pre><code class=\"language-python\"># 1. 获取执行环境\nenv = StreamExecutionEnvironment.get_execution_environment()\n# 2. 添加所需资源\nenv.add_resource(...)\n# 3. 设置输入数据\noutput_data = env.from_list(input_data) \n# 4. 应用代理\nbuilder.apply(agent) \n# 5. 执行代理\nenv.execute()\n# 6. 获取结果\nresults = builder.to_list()\n</code></pre>\n<p>关键特点：</p>\n<ul>\n<li>手动触发： execute() 不会自动调用，必须由用户显式调用</li>\n<li>一次性执行：只能调用一次，多次调用会抛出异常</li>\n<li>阻塞操作：在本地环境中，这是个同步阻塞操作，会等待所有输入处理完成</li>\n</ul>\n<h4 id=\"214-组件关系\">2.1.4 组件关系</h4>\n<p>组件关系图如下：</p>\n<pre><code class=\"language-python\">LocalExecutionEnvironmet\n    ↓\n    ↓ creates\nLocalAgentBuilder\n    ↓\n    ↓ creates\nLocalRunner\n    ↓\n    ↓ creates &amp; run(data)\nLocalRunnerContext\n</code></pre>\n<p>关系说明：</p>\n<ul>\n<li>LocalExecutionEnvironmet 是入口点，管理整个执行环境。通过 from_list() 创建LocalAgentBuilder</li>\n<li>LocalAgentBuilder 负责构建Agent 执行管道，通过 apply() 创建 LocalRunner</li>\n<li>LocalRunner 是实际的执行器</li>\n<li>LocalRunner 为每个处理的记录创建 LocalRunnerContext</li>\n</ul>\n<h3 id=\"22-localrunner\">2.2 LocalRunner</h3>\n<p>LocalRunner 是本地执行环境中的核心执行器，负责实际运行Agent逻辑。LocalRunner 提供了一个完整的本地执行环境，模拟了Flink 流处理的行为，使得Agent可以在本地进行开发和测试。</p>\n<h4 id=\"221-localrunner-的主要功能\">2.2.1 LocalRunner 的主要功能</h4>\n<p>LocalRunner 的主要功能：</p>\n<ul>\n<li>代理执行：将Agent转换为可执行的计划并执行</li>\n<li>上下文管理：为每个处理单元创建和管理 LocalRunnerContext</li>\n<li>事件处理：管理事件队列并驱动Agent的执行流程</li>\n<li>结果收集：收集和存储Agent执行的输出结果</li>\n</ul>\n<p>run函数是LocalRunner的核心方法，负责处理单个输入记录：</p>\n<ul>\n<li>从输入数据中提取键值，用于上下文管理</li>\n<li>为每个键创建或复用 LocalRunnerContext</li>\n<li>将输入数据包装成 InputEvent 并发送到事件队列</li>\n<li>事件循环处理，LocalRunner 的 run 函数使用 while 循环是为了处理事件驱动的代理执行模型。这种设计反映了代理执行的核心机制\n<ul>\n<li>持续处理事件队列直到为空</li>\n<li>如果是输出事件、收集结果</li>\n<li>根据事件类型查找对应的动作</li>\n<li>执行动作</li>\n<li>处理异步处理结果</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-python\">    @override\n    def run(self, **data: Dict[str, Any]) -&gt; Any:\n        \"\"\"Execute the agent to process the given data.\n\n        Parameters\n        ----------\n        **data : dict[str, Any]\n            input record from upstream.\n\n        Returns:\n        -------\n        key\n            The key of the input that was processed.\n        \"\"\"\n        if \"key\" in data:\n            key = data[\"key\"]\n        elif \"k\" in data:\n            key = data[\"k\"]\n        else:\n            key = uuid.uuid4()\n\n        if key not in self.__keyed_contexts:\n            self.__keyed_contexts[key] = LocalRunnerContext(self.__agent_plan, key, self.__config)\n        context = self.__keyed_contexts[key]\n\n        if \"value\" in data:\n            input_event = InputEvent(input=data[\"value\"])\n        elif \"v\" in data:\n            input_event = InputEvent(input=data[\"v\"])\n        else:\n            msg = \"Input data must be dict has 'v' or 'value' field\"\n            raise RuntimeError(msg)\n\n        context.send_event(input_event)\n\n        while len(context.events) &gt; 0:\n            event = context.events.popleft()\n            if isinstance(event, OutputEvent):\n                self.__outputs.append({key: event.output})\n                continue\n            event_type = f\"{event.__class__.__module__}.{event.__class__.__name__}\"\n            for action in self.__agent_plan.get_actions(event_type):\n                context.action_name = action.name\n                func_result = action.exec(event, context)\n                if isinstance(func_result, Generator):\n                    try:\n                        for _ in func_result:\n                            pass\n                    except Exception:\n                        logger.exception(\"Error in async execution\")\n                        raise\n        return key\n</code></pre>\n<h4 id=\"222-事件驱动执行模型\">2.2.2 事件驱动执行模型</h4>\n<p>在 Flink Agents 框架中，代理的执行是基于事件的。每个动作 (action)处理一个事件并可能产生新的事件，这些新事件又会触发其他动作的执行。因此需要一个循环来持续处理事件队列中的事件，直到没有更多事件需要处理。</p>\n<p>这种设计使得代理可以处理复杂的、多步骤的交互过程，而不需要预先确定执行步骤的数量。<code>while</code> 循环确保所有相关的事件都被处理完毕，形成了一个完整的事件处理链：</p>\n<ul>\n<li>持续从事件队列 context.events 中取出事件进行处理</li>\n<li>每个事件可能触发一个或多个动作的执行</li>\n<li>动作执行可能产生新的事件，这些事件被添加回队列</li>\n</ul>\n<p>递归事件处理：</p>\n<ul>\n<li>初始时只有一个 InputEvent</li>\n<li>动作处理 InputEvent 可能产生 ChatRequestEvent 等中间事件</li>\n<li>中间事件可能触发其他动作，产生更多事件</li>\n<li>最终产生 OutputEvent 完成处理</li>\n</ul>\n<p>完整处理链：</p>\n<pre><code class=\"language-python\">InputEvent  → →   start_action  → →   ChatRequestEvent  →  →  LLM处理  → →  ChatResponseEvent  → →   stop_action  → →   OutputEvent\n</code></pre>\n<p>具体执行流程</p>\n<ul>\n<li>\n<p>初始化：</p>\n<ul>\n<li>将输入数据包装成 InputEvent 并添加到事件队列</li>\n</ul>\n</li>\n<li>\n<p>循环处理：</p>\n<ul>\n<li>从队列取出事件</li>\n<li>根据事件类型找到对应的 actions</li>\n<li>执行所有监听该事件类型的动作</li>\n<li>动作可能通过 send_event 发送新事件到队列</li>\n</ul>\n</li>\n<li>\n<p>终止条件：</p>\n<ul>\n<li>当事件队列为空时，处理完成</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"223-agentplan-和-localrunner-的关系\">2.2.3 AgentPlan 和 LocalRunner 的关系</h4>\n<ul>\n<li>LocalRunner 在初始化时候使用 AgentPlan</li>\n<li>在执行过程中，LocalRunnerContext 通过 AgentPlan 获取资源和动作</li>\n<li>在事件处理中查找对应的动作</li>\n</ul>\n<p>具体为：LocalRunner 在初始化时候使用 AgentPlan</p>\n<pre><code class=\"language-python\">class LocalRunner(AgentRunner):\n    \"\"\"Agent runner implementation for local execution, which is\n    convenient for debugging.\n\n    Attributes:\n    ----------\n    __agent_plan : AgentPlan\n        Internal agent plan.\n    __keyed_contexts : dict[Any, LocalRunnerContext]\n        Dictionary of active contexts indexed by key.\n    __outputs:\n        Outputs generated by agent execution.\n    __config:\n        Internal configration.\n    \"\"\"\n\n    __agent_plan: AgentPlan\n    __keyed_contexts: Dict[Any, LocalRunnerContext]\n    __outputs: List[Dict[str, Any]]\n    __config: AgentConfiguration\n\n    def __init__(self, agent: Agent, config: AgentConfiguration) -&gt; None:\n        \"\"\"Initialize the runner with the provided agent.\n\n        Parameters\n        ----------\n        agent : Agent\n            The agent class to convert and run.\n        \"\"\"\n        self.__agent_plan = AgentPlan.from_agent(agent, config)\n        self.__keyed_contexts = {}\n        self.__outputs = []\n        self.__config = config\n\n\n</code></pre>\n<p>具体为：在执行过程中，LocalRunnerContext 通过 AgentPlan 获取资源和动作</p>\n<pre><code class=\"language-python\">class LocalRunnerContext(RunnerContext):\n    \"\"\"Implementation of RunnerContext for local agent execution.\n\n    Attributes:\n    ----------\n    __agent_plan : AgentPlan\n        Internal agent plan for this context.\n    __key : Any\n        Unique identifier for the context, correspond to the key in flink KeyedStream.\n    events : deque[Event]\n        Queue of events to be processed in this context.\n    action_name: str\n        Name of the action being executed.\n    \"\"\"\n\n    __agent_plan: AgentPlan\n    __key: Any\n    events: deque[Event]\n    action_name: str\n    _store: dict[str, Any]\n    _short_term_memory: MemoryObject\n    _config: AgentConfiguration\n\n    def __init__(self, agent_plan: AgentPlan, key: Any, config: AgentConfiguration) -&gt; None:\n        \"\"\"Initialize a new context with the given agent and key.\n\n        Parameters\n        ----------\n        agent_plan : AgentPlan\n            Agent plan used for this context.\n        key : Any\n            Unique context identifier, which is corresponding to the key in flink\n            KeyedStream.\n        \"\"\"\n        self.__agent_plan = agent_plan\n        self.__key = key\n        self.events = deque()\n        self._store = {}\n        self._short_term_memory = LocalMemoryObject(\n            self._store, LocalMemoryObject.ROOT_KEY\n        )\n        self._config = config\n        \n    @override\n    def get_resource(self, name: str, type: ResourceType) -&gt; Resource:\n        return self.__agent_plan.get_resource(name, type)        \n\n\n</code></pre>\n<p>具体为：在事件处理中查找对应的动作</p>\n<pre><code class=\"language-python\">            for action in self.__agent_plan.get_actions(event_type):\n                context.action_name = action.name\n                func_result = action.exec(event, context) # 执行\n                if isinstance(func_result, Generator):\n                    try:\n                        for _ in func_result:\n                            pass\n                    except Exception:\n                        logger.exception(\"Error in async execution\")\n                        raise\n\n</code></pre>\n<h4 id=\"224-为什么要为每种-key-维护独立的上下文\">2.2.4 为什么要为每种 key 维护独立的上下文</h4>\n<p>在 LocalRunner 中，每种 key 都有自己独立的上下文是为了模拟 Flink 流处理环境中 keyed state 的行为，并支持状态隔离和并发处理。</p>\n<ul>\n<li><strong>状态隔离</strong>：每个 key 对应的数据流需要维护自己的状态，避免不同 key 的数据相互干扰：</li>\n</ul>\n<pre><code class=\"language-python\"># 不同 key 的状态完全隔离\nkey1_context.short_term_memory.set(\"user_name\", \"Alice\")\nkey2_context.short_term_memory.set(\"user_name\", \"Bob\")\n# 两个 key 有不同的状态值，互不影响\n\n\n</code></pre>\n<ul>\n<li>\n<p><strong>模拟 Flink 的 KeyedStream 行为</strong>：在 Flink 中，当使用 <code>keyBy()</code> 操作时，每个 key 会有独立的状态管理。LocalRunner 通过这种方式模拟了相同的行为：</p>\n<ul>\n<li>相同 key 的事件会在同一个上下文中处理</li>\n<li>不同 key 的事件拥有各自独立的内存和事件队列</li>\n</ul>\n<p>这样保证了本地调试环境与实际 Flink 环境的一致性</p>\n</li>\n<li>\n<p><strong>支持并发处理</strong>：虽然 LocalRunner 是单线程运行的，但它模拟了多 key 并发处理的情况：</p>\n</li>\n<li>\n<p><strong>支持并发处理</strong>：虽然 LocalRunner 是单线程运行的，但它模拟了多 key 并发处理的情况：</p>\n</li>\n</ul>\n<pre><code class=\"language-python\"># 可以同时处理多个 key 的数据\nfor input_record in inputs:\n    runner.run(**input_record)  # 每个 key 有独立上下文\n\n</code></pre>\n<ul>\n<li>\n<p><strong>事件队列隔离</strong>：每个 key 都有自己的事件队列（events），这样可以保证：</p>\n<ul>\n<li>同一 key 的事件按顺序处理</li>\n<li>不同 key 的事件不会互相影响处理顺序</li>\n<li>每个 key 可以独立地维护待处理事件队列</li>\n</ul>\n</li>\n<li>\n<p><strong>内存状态管理</strong>：每个 LocalRunnerContext 都有自己的短期记忆对象（_short_term_memory），允许：</p>\n</li>\n</ul>\n<pre><code class=\"language-python\"># 每个 key 可以存储和检索自己的状态\ncontext.short_term_memory.set(\"step_count\", 1)\ncontext.short_term_memory.get(\"step_count\")  # 获取该 key 特定的状态\n\n</code></pre>\n<h4 id=\"225-实际应用场景示例\">2.2.5 实际应用场景示例</h4>\n<p>考虑一个客户服务聊天机器人应用：</p>\n<pre><code class=\"language-python\"># 用户 Alice 和 Bob 的对话分别用不同的 key 处理\nrunner.run(key=\"user_alice\", value={\"message\": \"Hello\"})\nrunner.run(key=\"user_bob\", value={\"message\": \"Hi there\"})\n# 每个用户的对话历史和状态都独立保存\n# Alice 的上下文不会影响 Bob 的上下文，反之亦然\n\n</code></pre>\n<p>这种设计使 LocalRunner 能够准确模拟真实分布式环境中的行为，方便开发者在本地测试和调试复杂的状态依赖型代理应用。</p>\n<h3 id=\"23-localrunnercontext\">2.3 LocalRunnerContext</h3>\n<p>LocalRunnerContext 是 Flink Agents 框架中用于本地执行环境的运行上下文实现。它的主要功能是为每个 key 提供独立的执行环境，模拟 Flink 分布式环境中 keyed state 的行为，确保了在本地环境中能够准确模拟基于 key 的状态管理和事件处理流程。</p>\n<h4 id=\"231-设计目的\">2.3.1 设计目的</h4>\n<p>LocalRunnerContext 的设计主要是为了：</p>\n<ul>\n<li>本地调试：在本地环境中模拟 Flink 分布式执行的行为</li>\n<li>状态隔离：确保不同 key 的处理状态完全隔离，避免相互干扰</li>\n<li>行为一致性：保证本地测试环境与实际 Flink 执行环境的行为一致</li>\n<li>简化开发：提供与生产环境相同的 API 接口，方便开发者测试和调试</li>\n</ul>\n<h4 id=\"232-主要功能\">2.3.2 主要功能</h4>\n<ul>\n<li>状态管理\n<ul>\n<li>为每个 key 维护独立的短期内存状态（_short_term_memory）</li>\n<li>提供内存对象的读写操作，确保不同 key 的状态隔离</li>\n</ul>\n</li>\n<li>事件处理\n<ul>\n<li>维护每个 key 的事件队列（events）</li>\n<li>提供 send_event 方法将事件添加到处理队列中</li>\n<li>记录事件处理日志，便于调试</li>\n</ul>\n</li>\n<li>资源访问\n<ul>\n<li>提供 get_resource 方法访问 agent 所需的资源（如模型、工具等）</li>\n<li>根据资源名称和类型获取相应的资源实例</li>\n</ul>\n</li>\n<li>配置管理\n<ul>\n<li>提供对 action 配置的访问（action_config, get_action_config_value）</li>\n<li>提供全局配置信息（config）</li>\n</ul>\n</li>\n<li>度量和监控\n<ul>\n<li>提供度量组访问接口（agent_metric_group, action_metric_group）</li>\n<li>目前在本地环境中尚未完全实现</li>\n</ul>\n</li>\n<li>异步执行支持\n<ul>\n<li>提供 execute_async 方法支持异步函数执行</li>\n<li>在本地环境中降级为同步执行并给出警告</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"233-定义\">2.3.3 定义</h4>\n<pre><code class=\"language-java\">class LocalRunnerContext(RunnerContext):\n    \"\"\"Implementation of RunnerContext for local agent execution.\n\n    Attributes:\n    ----------\n    __agent_plan : AgentPlan\n        Internal agent plan for this context.\n    __key : Any\n        Unique identifier for the context, correspond to the key in flink KeyedStream.\n    events : deque[Event]\n        Queue of events to be processed in this context.\n    action_name: str\n        Name of the action being executed.\n    \"\"\"\n\n    __agent_plan: AgentPlan\n    __key: Any\n    events: deque[Event]\n    action_name: str\n    _store: dict[str, Any]\n    _short_term_memory: MemoryObject\n    _config: AgentConfiguration\n\n    def __init__(self, agent_plan: AgentPlan, key: Any, config: AgentConfiguration) -&gt; None:\n        \"\"\"Initialize a new context with the given agent and key.\n\n        Parameters\n        ----------\n        agent_plan : AgentPlan\n            Agent plan used for this context.\n        key : Any\n            Unique context identifier, which is corresponding to the key in flink\n            KeyedStream.\n        \"\"\"\n        self.__agent_plan = agent_plan\n        self.__key = key\n        self.events = deque()\n        self._store = {}\n        self._short_term_memory = LocalMemoryObject(\n            self._store, LocalMemoryObject.ROOT_KEY\n        )\n        self._config = config\n\n    @property\n    def key(self) -&gt; Any:\n        \"\"\"Get the unique identifier for this context.\n\n        Returns:\n        -------\n        Any\n            The unique identifier for this context.\n        \"\"\"\n        return self.__key\n\n    @override\n    def send_event(self, event: Event) -&gt; None:\n        \"\"\"Send an event to the context's event queue and log it.\n\n        Parameters\n        ----------\n        event : Event\n            The event to be added to the queue.\n        \"\"\"\n        logger.info(\"key: %s, send_event: %s\", self.__key, event)\n        self.events.append(event)\n\n    @override\n    def get_resource(self, name: str, type: ResourceType) -&gt; Resource:\n        return self.__agent_plan.get_resource(name, type)\n\n    @property\n    @override\n    def action_config(self) -&gt; Dict[str, Any]:\n        \"\"\"Get config of the action.\"\"\"\n        return self.__agent_plan.get_action_config(action_name=self.action_name)\n\n    @override\n    def get_action_config_value(self, key: str) -&gt; Any:\n        \"\"\"Get config option value of the key.\"\"\"\n        return self.__agent_plan.get_action_config_value(\n            action_name=self.action_name, key=key\n        )\n\n    @property\n    @override\n    def short_term_memory(self) -&gt; MemoryObject:\n        \"\"\"Get the short-term memory object associated with this context.\n\n        Returns:\n        -------\n        MemoryObject\n            The root object of the short-term memory.\n        \"\"\"\n        return self._short_term_memory\n\n    @property\n    @override\n    def agent_metric_group(self) -&gt; MetricGroup:\n        # TODO: Support metric mechanism for local agent execution.\n        err_msg = \"Metric mechanism is not supported for local agent execution yet.\"\n        raise NotImplementedError(err_msg)\n\n    @property\n    @override\n    def action_metric_group(self) -&gt; MetricGroup:\n        # TODO: Support metric mechanism for local agent execution.\n        err_msg = \"Metric mechanism is not supported for local agent execution yet.\"\n        raise NotImplementedError(err_msg)\n\n    def execute_async(\n        self,\n        func: Callable[[Any], Any],\n        *args: Tuple[Any, ...],\n        **kwargs: Dict[str, Any],\n    ) -&gt; Any:\n        \"\"\"Asynchronously execute the provided function. Access to memory\n        is prohibited within the function.\n        \"\"\"\n        logger.warning(\n            \"Local runner does not support asynchronous execution; falling back to synchronous execution.\"\n        )\n        func_result = func(*args, **kwargs)\n        yield\n        return func_result\n\n    @property\n    @override\n    def config(self) -&gt; AgentConfiguration:\n        return self._config\n\n</code></pre>\n<h2 id=\"0x03-remoteexecutionenvironment\">0x03 RemoteExecutionEnvironment</h2>\n<p><code>RemoteExecutionEnvironment</code> 是 Flink Agents 对原生 Flink <code>RemoteEnvironment</code> 的封装（适配 Agent 语义），是 Agent（智能体）与 Flink 集群融合的核心载体，核心目标是让 Agent 能够在 Flink 集群中处理 DataStream 和 Table 类型的流式数据，具体承担以下关键职责：</p>\n<ul>\n<li>\n<p><code>RemoteExecutionEnvironment</code> 是 Flink Agents 实现 Agent 远程执行的核心环境组件，封装了远程集群连接、作业提交、资源管理等能力；</p>\n</li>\n<li>\n<p>核心价值是<strong>屏蔽 Flink 远程执行的底层细节</strong>，让用户聚焦 Agent 逻辑定义，而非集群操作；</p>\n</li>\n<li>\n<p>关键特性是兼容本地调试与远程执行，同时适配 Agent 特有的状态、事件、资源需求，是 Flink Agents 从 “本地单机” 走向 “分布式集群” 的核心支撑。</p>\n</li>\n<li>\n<p>桥接 Agent 框架与 Flink 运行时：将 Agent 的执行逻辑嵌入 Flink 的 StreamExecutionEnvironment/StreamTableEnvironment，使 Agent 能利用 Flink 的分布式计算能力处理流式数据；</p>\n</li>\n<li>\n<p>标准化 Agent 执行流程：提供统一的入口（fromDataStream/fromTable）、处理（apply Agent）、输出（toDataStream/toTable）接口，规范 Agent 在 Flink 中的数据处理链路；</p>\n</li>\n<li>\n<p>配置管理：加载 Flink 集群中 Agent 的专属配置文件（config.yaml），为 Agent 执行提供环境配置支撑；</p>\n</li>\n<li>\n<p>执行调度：最终触发 Flink 作业的执行（env.execute ()），完成 Agent 处理逻辑的分布式运行。</p>\n</li>\n</ul>\n<h3 id=\"31-核心特色\">3.1 核心特色</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">特色维度</th>\n<th style=\"text-align: center;\">具体说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">环境适配性</td>\n<td style=\"text-align: center;\">专门面向 Flink 集群的<strong>远程执行</strong>场景设计，依赖 Flink 的流执行环境（StreamExecutionEnvironment）和表环境（StreamTableEnvironment），而非本地执行；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">数据类型聚焦</td>\n<td style=\"text-align: center;\">仅支持 Flink 原生的 DataStream/Table 作为输入输出，明确禁用本地场景的 List 类型（fromList/toList），贴合流式计算场景；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">分层设计</td>\n<td style=\"text-align: center;\">采用 “环境类（RemoteExecutionEnvironment）+ 构建器类（RemoteAgentBuilder）” 分层模式：环境类管控全局配置和 Flink 环境，构建器类聚焦单个 Agent 的执行链路；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">灵活的 Key 选择</td>\n<td style=\"text-align: center;\">支持自定义 KeySelector 对输入数据分片，无自定义 Key 时默认使用数据自身作为 Key，适配不同的分布式处理需求；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">配置解耦</td>\n<td style=\"text-align: center;\">从 Flink 配置目录加载 Agent 专属配置，配置文件与代码解耦，便于集群环境下的配置管理；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">容错与校验</td>\n<td style=\"text-align: center;\">包含关键流程校验（如调用 toDataStream 前必须先 apply Agent）、空值处理（TableEnvironment 懒加载）、异常封装（配置加载 / Agent 执行异常统一抛出 RuntimeException）；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">表与流互通</td>\n<td style=\"text-align: center;\">支持 Table 与 DataStream 的双向转换（Table 转 DataStream 作为 Agent 输入、DataStream 转 Table 作为输出），适配 Flink SQL / 流处理双场景；</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">资源关联</td>\n<td style=\"text-align: center;\">为 Agent 绑定运行时资源（resources），保障 Agent 执行所需的资源依赖；</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"32-与原生-flink-remoteenvironment-的对比\">3.2 与原生 Flink RemoteEnvironment 的对比</h3>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th>Flink 原生 RemoteEnvironment</th>\n<th>Flink Agents RemoteExecutionEnvironment</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>核心定位</td>\n<td>通用 Flink Job 的远程执行环境</td>\n<td>Agent 语义专属的远程执行环境</td>\n</tr>\n<tr>\n<td>封装层级</td>\n<td>底层 Flink Job 提交</td>\n<td>上层 Agent/AgentPlan 提交</td>\n</tr>\n<tr>\n<td>核心适配</td>\n<td>无 Agent 语义，仅处理通用 JobGraph</td>\n<td>适配 AgentPlan → JobGraph 编译、Agent 状态管理</td>\n</tr>\n<tr>\n<td>资源管理</td>\n<td>通用 Slot / 资源分配</td>\n<td>按 Agent 实例隔离资源，适配工具 / 动作资源需求</td>\n</tr>\n<tr>\n<td>事件 / 状态处理</td>\n<td>无内置事件语义</td>\n<td>封装 Agent 事件（Event）的跨集群传输、状态序列化</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"33-如何使用-actionexecutionoperator\">3.3 如何使用 ActionExecutionOperator</h3>\n<p>RemoteExecutionEnvironment 通过 Python 层的 RemoteAgentBuilder.to_datastream() 方法间接使用ActionExecutionOperator，过程为：</p>\n<ul>\n<li>用户定义了一个Agent并应用到执行环境中</li>\n<li>调用 to_datastream() 方法触发实际的操作符创建</li>\n<li>通过 JNI 调用 Java 层的 CompileUtils.connectToAgent() 方法</li>\n<li>最终在 Flink 作业图中创建并配置  ActionExecutionOperator</li>\n</ul>\n<p>connectToAgent()中会：</p>\n<ul>\n<li>接收输入的 Java DATa Stream 对象</li>\n<li>接收序列化的 AgentPlan（包含所有动作和资源配置）</li>\n<li>创建并连接 ActionExecutionOperator 到数据流处理图中</li>\n</ul>\n<pre><code class=\"language-java\">    // ============================ basic ====================================\n    /**\n     * Connects the given KeyedStream to the Flink Agents agent.\n     *\n     * &lt;p&gt;This method accepts a keyed DataStream and applies the specified agent plan to it. The\n     * source of the input stream determines the data format: Java streams provide Objects, while\n     * Python streams use serialized byte arrays.\n     *\n     * @param keyedInputStream The input keyed DataStream.\n     * @param agentPlan The agent plan to be executed.\n     * @param inputIsJava A flag indicating whether the input stream originates from Java. - If\n     *     true, input and output types are Java Objects. - If false, input and output types are\n     *     byte[].\n     * @param &lt;K&gt; The type of the key used in the keyed DataStream.\n     * @param &lt;IN&gt; The type of the input data (Object or byte[]).\n     * @param &lt;OUT&gt; The type of the output data (Object or byte[]).\n     * @return The processed DataStream as the result of the agent.\n     */\n    private static &lt;K, IN, OUT&gt; DataStream&lt;OUT&gt; connectToAgent(\n            KeyedStream&lt;IN, K&gt; keyedInputStream,\n            AgentPlan agentPlan,\n            TypeInformation&lt;OUT&gt; outTypeInformation,\n            boolean inputIsJava) {\n        return (DataStream&lt;OUT&gt;)\n                keyedInputStream\n                        .transform(\n                                \"action-execute-operator\",\n                                outTypeInformation,\n                                new ActionExecutionOperatorFactory(agentPlan, inputIsJava))\n                        .setParallelism(keyedInputStream.getParallelism());\n    }\n\n</code></pre>\n<h3 id=\"34-典型流程\">3.4 典型流程</h3>\n<p>当用户编写基于 RemoteExecutionEnvironment  的应用程序时，典型流程如下：</p>\n<pre><code class=\"language-python\"># 获取Flink执行环境\nenv = StreamExecutionEnvironment.get_execution_environment()\n# 创建 Agent 执行环境\nagent_env = AgentsExecutionEnvironment.get_execution_environment(env)\n# 添加所需资源\nagent_env.add_resource(...)\n# 设置输入数据流到Agent\ninput_stream = agent_env.from_Collection(input_data) \nbuilder = agent_env.from_datastream(input_stream)\n# 应用代理逻辑\nagent = MyCustomAgent()\nbuilder.apply(agent) \n# 执行代理\noutput_stream = builder.to_datastream()\nenv.execute()\n\n</code></pre>\n<h3 id=\"35-交互逻辑\">3.5 交互逻辑</h3>\n<p>RemoteExecutionEnvironment、ActionExecutionOperator 和 ActionTask 之间的交互逻辑如下。</p>\n<p>这三个组件在 Flink Agents 框架中扮演不同的角色，协同工作来执行 Agent 逻辑：</p>\n<ul>\n<li><strong>RemoteExecutionEnvironment</strong>：提供远程执行环境，负责构建和连接 Agent 到 Flink 数据流</li>\n<li><strong>ActionExecutionOperator</strong>：Flink 流处理操作符，实际执行 Agent 的动作逻辑</li>\n<li><strong>ActionTask</strong>：表示单个动作执行任务的抽象概念</li>\n</ul>\n<p><strong>交互流程图解</strong></p>\n<p><img alt=\"Flink-7-1\" class=\"lazyload\" /></p>\n<p>详细交互流程如下：</p>\n<ol>\n<li>初始化阶段</li>\n</ol>\n<p><img alt=\"Flink-7-2\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>运行时事件处理流程</li>\n</ol>\n<p><img alt=\"Flink-7-3\" class=\"lazyload\" /></p>\n<h3 id=\"36-实现\">3.6 实现</h3>\n<p>RemoteAgentBuilder 的代码如下</p>\n<pre><code class=\"language-python\">class RemoteAgentBuilder(AgentBuilder):\n    \"\"\"RemoteAgentBuilder for integrating datastream/table and agent.\"\"\"\n\n    __input: DataStream\n    __agent_plan: AgentPlan = None\n    __output: DataStream = None\n    __t_env: StreamTableEnvironment\n    __config: AgentConfiguration\n    __resources: Dict[ResourceType, Dict[str, Any]] = None\n\n    def __init__(\n        self,\n        input: DataStream,\n        config: AgentConfiguration,\n        t_env: StreamTableEnvironment | None = None,\n        resources: Dict[ResourceType, Dict[str, Any]] | None = None,\n    ) -&gt; None:\n        \"\"\"Init method of RemoteAgentBuilder.\"\"\"\n        self.__input = input\n        self.__t_env = t_env\n        self.__config = config\n        self.__resources = resources\n\n    @property\n    def t_env(self) -&gt; StreamTableEnvironment:\n        \"\"\"Get or crate table environment.\"\"\"\n        if self.__t_env is None:\n            self.__t_env = StreamTableEnvironment.create(\n                stream_execution_environment=self.__env\n            )\n        return self.__t_env\n\n    def apply(self, agent: Agent) -&gt; \"AgentBuilder\":\n        \"\"\"Set agent of execution environment.\n\n        Parameters\n        ----------\n        agent : Agent\n            The agent user defined to run in execution environment.\n        \"\"\"\n        if self.__agent_plan is not None:\n            err_msg = \"RemoteAgentBuilder doesn't support apply multiple agents yet.\"\n            raise RuntimeError(err_msg)\n\n        # inspect refer actions and resources from env to agent.\n        for type, name_to_resource in self.__resources.items():\n            agent.resources[type] = name_to_resource | agent.resources[type]\n\n        self.__agent_plan = AgentPlan.from_agent(agent, self.__config)\n\n        return self\n\n    def to_datastream(self, output_type: TypeInformation | None = None) -&gt; DataStream:\n        \"\"\"Get output datastream of agent execution.\n\n        Returns:\n        -------\n        DataStream\n            Output datastream of agent execution.\n        \"\"\"\n        if self.__agent_plan is None:\n            err_msg = \"Must apply agent before call to_datastream/to_table.\"\n            raise RuntimeError(err_msg)\n\n        # return the same output datastream when call to_datastream multiple.\n        if self.__output is None:\n            j_data_stream_output = invoke_method(\n                None,\n                \"org.apache.flink.agents.runtime.CompileUtils\",\n                \"connectToAgent\",\n                [\n                    self.__input._j_data_stream,\n                    self.__agent_plan.model_dump_json(serialize_as_any=True),\n                ],\n                [\n                    \"org.apache.flink.streaming.api.datastream.KeyedStream\",\n                    \"java.lang.String\",\n                ],\n            )\n            output_stream = DataStream(j_data_stream_output)\n            self.__output = output_stream.map(\n                lambda x: cloudpickle.loads(x), output_type=output_type\n            )\n        return self.__output\n\n    def to_table(self, schema: Schema, output_type: TypeInformation) -&gt; Table:\n        \"\"\"Get output Table of agent execution.\n\n        Parameters\n        ----------\n        schema : Schema\n            Indicate schema of the output table.\n        output_type : TypeInformation\n            Indicate schema corresponding type information.\n\n        Returns:\n        -------\n        Table\n            Output Table of agent execution.\n        \"\"\"\n        return self.t_env.from_data_stream(self.to_datastream(output_type), schema)\n\n    def to_list(self) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get output list of agent execution.\n\n        This method is not supported for remote execution environments.\n        \"\"\"\n        msg = \"RemoteAgentBuilder does not support to_list.\"\n        raise NotImplementedError(msg)\n\n\n</code></pre>\n<p>RemoteExecutionEnvironment 的代码如下。</p>\n<pre><code class=\"language-python\">class RemoteExecutionEnvironment(AgentsExecutionEnvironment):\n    \"\"\"Implementation of AgentsExecutionEnvironment for execution with DataStream.\"\"\"\n\n    __env: StreamExecutionEnvironment\n    __t_env: StreamTableEnvironment\n    __config: AgentConfiguration\n\n    def __init__(\n        self,\n        env: StreamExecutionEnvironment,\n        t_env: StreamTableEnvironment | None = None,\n    ) -&gt; None:\n        \"\"\"Init method of RemoteExecutionEnvironment.\"\"\"\n        super().__init__()\n        self.__env = env\n        self.__t_env = t_env\n        self.__config = AgentConfiguration()\n        self.__load_config_from_flink_conf_dir()\n\n    @property\n    def t_env(self) -&gt; StreamTableEnvironment:\n        \"\"\"Get or crate table environment.\"\"\"\n        if self.__t_env is None:\n            self.__t_env = StreamTableEnvironment.create(\n                stream_execution_environment=self.__env\n            )\n        return self.__t_env\n\n    def get_config(self, path: str | None = None) -&gt; AgentConfiguration:\n        \"\"\"Get the writable configuration for flink agents.\n\n        Returns:\n        -------\n        LocalConfiguration\n            The configuration for flink agents.\n        \"\"\"\n        return self.__config\n\n    @staticmethod\n    def __process_input_datastream(\n        input: DataStream, key_selector: KeySelector | Callable | None = None\n    ) -&gt; KeyedStream:\n        if isinstance(input, KeyedStream):\n            return input\n        else:\n            if key_selector is None:\n                msg = \"KeySelector must be provided.\"\n                raise RuntimeError(msg)\n            input = input.key_by(key_selector)\n            return input\n\n    def from_datastream(\n        self, input: DataStream, key_selector: KeySelector | Callable | None = None\n    ) -&gt; RemoteAgentBuilder:\n        \"\"\"Set input datastream of agent.\n\n        Parameters\n        ----------\n        input : DataStream\n            Receive a DataStream as input.\n        key_selector : KeySelector\n            Extract key from each input record, must not be None when input is\n            not KeyedStream.\n        \"\"\"\n        input = self.__process_input_datastream(input, key_selector)\n\n        return RemoteAgentBuilder(\n            input=input,\n            config=self.__config,\n            t_env=self.__t_env,\n            resources=self.resources,\n        )\n\n    def from_table(\n        self,\n        input: Table,\n        key_selector: KeySelector | Callable | None = None,\n    ) -&gt; AgentBuilder:\n        \"\"\"Set input Table of agent.\n\n        Parameters\n        ----------\n        input : Table\n            Receive a Table as input.\n        key_selector : KeySelector\n            Extract key from each input record.\n        \"\"\"\n        input = self.t_env.to_data_stream(table=input)\n\n        input = input.map(lambda x: x, output_type=PickledBytesTypeInfo())\n\n        input = self.__process_input_datastream(input, key_selector)\n        return RemoteAgentBuilder(\n            input=input,\n            config=self.__config,\n            t_env=self.t_env,\n            resources=self.resources,\n        )\n\n    def from_list(self, input: List[Dict[str, Any]]) -&gt; \"AgentsExecutionEnvironment\":\n        \"\"\"Set input list of agent execution.\n\n        This method is not supported for remote execution environments.\n        \"\"\"\n        msg = \"RemoteExecutionEnvironment does not support from_list.\"\n        raise NotImplementedError(msg)\n\n    def execute(self) -&gt; None:\n        \"\"\"Execute agent.\"\"\"\n        self.__env.execute()\n\n\n    def __load_config_from_flink_conf_dir(self) -&gt; None:\n        \"\"\"Load agent configuration from FLINK_CONF_DIR if available.\"\"\"\n        flink_conf_dir = os.environ.get(\"FLINK_CONF_DIR\")\n        if flink_conf_dir is None:\n            return\n\n        # Try to find config file, with fallback to legacy name\n        config_path = self.__find_config_file(flink_conf_dir)\n\n        if config_path is None:\n            logging.error(f\"Config file not found in {flink_conf_dir}\")\n        else:\n            self.__config.load_from_file(str(config_path))\n\n    def __find_config_file(self, flink_conf_dir: str) -&gt; Path | None:\n        \"\"\"Find config file in the given directory, checking both new and legacy names.\n\n        Parameters\n        ----------\n        flink_conf_dir : str\n            Directory to search for config files.\n\n        Returns:\n        -------\n        Path | None\n            Path to the config file if found, None otherwise.\n        \"\"\"\n        # Try legacy config file name first\n        legacy_config_path = Path(flink_conf_dir).joinpath(_LEGACY_CONFIG_FILE_NAME)\n        if legacy_config_path.exists():\n            logging.warning(\n                f\"Using legacy config file {_LEGACY_CONFIG_FILE_NAME}\"\n            )\n            return legacy_config_path\n\n        # Try new config file name as fallback\n        primary_config_path = Path(flink_conf_dir).joinpath(_CONFIG_FILE_NAME)\n        if primary_config_path.exists():\n            return primary_config_path\n\n        return None\n\n</code></pre>\n<h2 id=\"0xff-参考\">0xFF 参考</h2>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 21:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/rossiXYZ\">罗西的思考</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "资深程序员白话干货AI工具技术",
      "link": "https://www.cnblogs.com/cykj/p/19489286/AI",
      "published": "",
      "description": "<div class=\"postTitle\">\n\t\t<h1><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/cykj/p/19489286/AI\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 21:43\">\n    <span>资深程序员白话干货AI工具技术</span>\n    \n\n</a>\n</h1>\n\t</div>\n\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        AI大模型\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div class=\"_question-wrapper_1hc3y_44\">\n<div class=\"conversation-flow-question-container _question-container_1hc3y_15\">\n<div class=\"            cs-rank            cs-enable-selection        \">\n<div class=\"cs-question-bubble cs-bubble\">\n<div class=\"                    _question-block_oagij_1                    _swiper-block_1a2le_1                                                                                c-fwb                \"><span class=\"cs-question-pure-text \"><span class=\"_question-line-break_oagij_5\">我是一个从事IT行业数十年工作经验的资深程序员，全站架构师，我对比了市面上所有的AI。如：Trae，Cursor‌，Claude Code，Kimi‌，CodeBuddy（腾讯），通</span></span></div>\n<div class=\"                    _question-block_oagij_1                    _swiper-block_1a2le_1                                                                                c-fwb                \"><span class=\"cs-question-pure-text \"><span class=\"_question-line-break_oagij_5\">义灵码（阿里云），DeepSeek（深度求索），腾讯元宝（混元），豆包（字节跳动），通义千问（阿里）。</span></span></div>\n<div class=\"                    _question-block_oagij_1                    _swiper-block_1a2le_1                                                                                c-fwb                \">\n<p class=\"marklang-paragraph\">作为资深架构师，您对AI代码工具的深入对比和推荐是非常有价值的。以下是对市面上主流AI代码工具的简要分析与使用场景建议，供您在博客中参考：</p>\n<ol>\n<li>‌Trae‌：适用于快速生成代码片段，适合初学者或快速原型开发。</li>\n<li>‌Cursor‌：支持实时协作和代码补全，适合团队开发环境。</li>\n<li>‌Claude Code‌：擅长复杂逻辑和架构设计，适合中大型项目。</li>\n<li>‌Kimi‌：在中文语境下表现优异，适合国内开发者使用。</li>\n<li>‌CodeBuddy（腾讯）‌：集成度高，适合企业级开发流程。</li>\n<li>‌通义灵码（阿里云）‌：支持多语言，适合多语言混合项目。</li>\n<li>‌DeepSeek‌：在代码生成效率方面表现突出，适合快速迭代。</li>\n<li>‌腾讯元宝（混元）‌：在企业级应用中表现稳定，适合大型系统。</li>\n<li>‌豆包（字节跳动）‌：适合轻量级开发和快速验证。</li>\n<li>‌通义千问（阿里）‌：综合能力强，适合通用场景。</li>\n</ol></div>\n<div class=\"cs-hover-menu            _menu-wrapper_14pfw_1                                    _no-margin-bottom_14pfw_48                    \">\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"1\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>Trae‌：中国版SOLO模式‌完全免费‌，无订阅费、无Token限制、无使用次数约束，支持多任务并行开发与可视化项目管控，为当前唯一实现全功能零成本的AI编程助手。</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"3\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>‌Cursor‌：免费版提供‌每日50次AI问答额度‌，支持基础代码补全与单文件上下文理解；Pro版为无限次问答、多文件上下文、专属模型，月费未公开但属订阅制。</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"_note-list-wrapper_yrsjp_1                                    _note-list-square-wrapper_yrsjp_33 cos-space-mt-lg\" id=\"4\">\n<div class=\"cosd-note-list\">\n<div>\n<div class=\"cosd-note-list-grid-wrapper\">\n<div class=\"cosd-note-list-grid\">\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-thumbnail\">&nbsp;</div>\n</div>\n</div>\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-author\">\n<div class=\"cos-avatar cos-avatar-md\"><img alt=\"头像\" class=\"cos-avatar-img\" src=\"http://gips0.baidu.com/it/u=3252066771,2422681703&amp;fm=3033&amp;app=3033&amp;f=PNG?w=200&amp;h=200\" /></div>\n<span class=\"cosd-note-card-author-name\">阿里云开发者</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"5\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>‌Claude Code‌：无官方公开免费额度，但通过非官方渠道（如claudeide.net）可获‌每日2M Token‌用量；国内用户需借助代理访问，官方订阅价格高昂（Max计划$200/月）。</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"_note-list-wrapper_yrsjp_1                                    _note-list-square-wrapper_yrsjp_33 cos-space-mt-lg\" id=\"6\">\n<div class=\"cosd-note-list\">\n<div class=\"cosd-note-list-grid-wrapper\">\n<div class=\"cosd-note-list-grid\">\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">AI编程神器:Claude Code安装与国内免费使用(保姆级教程)</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">Tencent腾讯（腾讯官方网）</span></div>\n</div>\n</div>\n</div>\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">免费使用Claude Code</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">CSDN软件开发网</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"7\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>‌Kimi‌：新用户注册赠送‌15元额度‌；通过硅基流动平台申请API密钥，可获‌2000万Token免费额度‌，支持长期免费调用Kimi K2模型，适用于代码生成与API集成。</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"_note-list-wrapper_yrsjp_1                                    _note-list-square-wrapper_yrsjp_33 cos-space-mt-lg\" id=\"8\">\n<div class=\"cosd-note-list\">\n<div class=\"cosd-note-list-grid-wrapper\">\n<div class=\"cosd-note-list-grid\">\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">免费使用Kimi的API接口,kimi-free-api真香</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">Tencent腾讯（腾讯官方网）</span></div>\n</div>\n</div>\n</div>\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">KIMI AI免费服务完整部署指南:零成本搭建个人智能助手</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">CSDN软件开发网</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"9\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>‌CodeBuddy‌：‌IDE完全免费‌，每日赠送20 Craft积分用于AI辅助；无个人付费订阅，企业版需15万元/年起，含私有代码库训练与安全合规支持。</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"_note-list-wrapper_yrsjp_1                                    _note-list-square-wrapper_yrsjp_33 cos-space-mt-lg\" id=\"10\">\n<div class=\"cosd-note-list\">\n<div class=\"cosd-note-list-grid-wrapper\">\n<div class=\"cosd-note-list-grid\">\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">通义灵码_智能编码助手_AI编程——程序员必备编程利器!</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">阿里云.</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"11\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>\n<p class=\"marklang-paragraph\">‌通义灵码‌：个人基础版‌免费‌，共享‌100万Token免费额度‌（主账号与RAM子账号共用）；专业版49元/人·月，企业版9.9万元/年起，深度优化Java微服务与阿里云生态。</p>\n</li>\n<li>\n<p class=\"marklang-paragraph\">‌DeepSeek‌：基础版API‌完全免费‌，每日提供‌1000万Token配额‌，为当前市场最高免费额度之一；响应延迟&lt;1.2秒，代码补全准确率超Claude 3.5。</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"_note-list-wrapper_yrsjp_1                                    _note-list-square-wrapper_yrsjp_33 cos-space-mt-lg\" id=\"12\">\n<div class=\"cosd-note-list\">\n<div class=\"cosd-note-list-grid-wrapper\">\n<div class=\"cosd-note-list-grid\">\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">DeepSeek V3免费接入指南:获取500万Token并实现高效翻译功能</div>\n</div>\n</div>\n</div>\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">Idea集成DeepSeek指南(免费token)</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">CSDN软件开发网</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"13\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>\n<p class=\"marklang-paragraph\">‌腾讯元宝‌：‌无独立代码助手产品‌，但通过“腾讯混元”为小程序开发者提供‌1亿Token免费额度‌（混元2.0模型），属平台级算力激励，非直接面向编码场景。</p>\n</li>\n<li>\n<p class=\"marklang-paragraph\">‌豆包‌：个人用户每日‌5–60次AI生成额度‌（自动重置）；通过边缘大模型网关可申领‌200万–1000万Token免费额度‌，支持代码生成与API调用。</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"_note-list-wrapper_yrsjp_1                                    _note-list-square-wrapper_yrsjp_33 cos-space-mt-lg\" id=\"14\">\n<div class=\"cosd-note-list\">\n<div class=\"cosd-note-list-grid-wrapper\">\n<div class=\"cosd-note-list-grid\">\n<div class=\"cosd-note-list-grid-item\">\n<div class=\"cosd-note-card\">\n<div class=\"cosd-note-card-content\">\n<div class=\"cosd-note-card-title\">豆包AI插件</div>\n<div class=\"cosd-note-card-author\"><span class=\"cosd-note-card-author-name\">帆软简道云2</span></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"ai-entry-block\">\n<div class=\"cosd-markdown cos-space-mt-lg\" id=\"15\">\n<div class=\"cosd-markdown-content cosd-markdown-content-typingall\">\n<div class=\"marklang\">\n<ul>\n<li>‌通义千问‌：开通百炼服务后享‌100万Token免费额度‌，适用于Qwen-Coder等主流模型；按量计费最低0.000367元/千token（输入），输出单价0.002936元/千token。</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div id=\"MySignature\">\n    用代码行来衡量开发进度，无异于用重量来衡量制造飞机的进度。\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-15 21:43</span>&nbsp;\n<a href=\"https://www.cnblogs.com/cykj\">互联网开发者</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}