{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "引入AI辅助的3D游戏美术工作流",
      "link": "https://www.cnblogs.com/geek1116/p/19589538",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/geek1116/p/19589538\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 19:24\">\n    <span>引入AI辅助的3D游戏美术工作流</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"3d游戏美术流程\">3D游戏美术流程</h2>\n<p>不同于其他类型的AI应用，3D内容的AI生成应用所面向的行业更加垂直，会有一定的专业使用门槛，并且生成的产物与直接投入生产环境的内容往往还存在一定的距离。笔者这里针对小型独立游戏/Demo的场景下，为提高3D游戏美术工作效率和降低成本，分享下在引入了AI生成后的美术工作流程。</p>\n<p>首先回顾下在行业中一个比较主流的美术工作流，大致如下：</p>\n<pre><code class=\"language-markdown\">雕刻高模\n   ↓\n拓扑低模、布线\n   ↓\n  展UV\n   ↓\n由高模烘焙出法线、AO等贴图\n   ↓\n绘制颜色、金属度、粗糙度等PBR贴图\n   ↓\n制作骨骼、绑定、刷权重、测试蒙皮\n   ↓\n制作骨骼动画\n   ↓\n导入游戏引擎调试\n</code></pre>\n<p>传统流程中每个环节依赖的DCC工具都是不一样的，甚至同一步骤都能有多种工具可以选 例如建模阶段的3D Max（硬表面物体）和Maya（角色/生物建模）等。考虑到学习成本和独立开发的效率，笔者选择了全流程制作都使用Blender。这也是许多独立开发者的选择，毕竟作为个人和小微团队来说，采用行业最佳实践的美术工作流并不现实。</p>\n<h2 id=\"ai工具选择\">AI工具选择</h2>\n<p>笔者共测评了四款拥有对游戏资产开发有一定支持的平台，分别是：</p>\n<ul>\n<li>腾讯的混元3D：<a href=\"https://3d.hunyuan.tencent.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://3d.hunyuan.tencent.com/</a></li>\n<li>Rodin的Hyper3D：<a href=\"https://hyper3d.ai/\" rel=\"noopener nofollow\" target=\"_blank\">https://hyper3d.ai/</a></li>\n<li>Tripo AI：<a href=\"https://www.tripo3d.ai/zh\" rel=\"noopener nofollow\" target=\"_blank\">https://www.tripo3d.ai/zh</a></li>\n<li>Meshy：<a href=\"https://www.meshy.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://www.meshy.ai</a></li>\n</ul>\n<p>综合体验下来，混元3D和Tripo AI不管是在流程完整性还是生成内容的质量上，都是目前最佳的。二者均支持组件拆分这一大多数竞品没有的功能。另外，腾讯混元3D中的3D Studio是完全针对游戏行业定制化的工作流，在前置流程上还可以衔接<em>腾讯混元游戏</em>（自家的另一个平台：<a href=\"https://hunyuan.tencent.com/game%EF%BC%89%EF%BC%8C%E6%8F%90%E4%BE%9B%E4%BA%86%E5%A4%9A%E7%A7%8D%E8%A7%92%E8%89%B2/%E9%81%93%E5%85%B7/%E5%9C%BA%E6%99%AF%E7%9A%84%E6%A6%82%E5%BF%B5%E8%AE%BE%E8%AE%A1%E5%B7%A5%E5%85%B7%E3%80%82\" rel=\"noopener nofollow\" target=\"_blank\">https://hunyuan.tencent.com/game），提供了多种角色/道具/场景的概念设计工具。</a></p>\n<p>笔者在挺久之前就有关注到腾讯混元3D并且挺看好的，但它一直没有进行商业化，目前每天只能获取非常少的固定生成次数来在平台内使用；而且3D Studio是需要单独去申请内测资格后才能使用的，生成的内容会有版权归属的问题。最终决定使用Tripo AI来辅助笔者3D美术工作。</p>\n<h2 id=\"ai工具实践\">AI工具实践</h2>\n<p>首先需要准备好一张设计图；这一步的手段是非常的丰富的，手绘、外包稿件、亦或是文生图/图生图等AI生成方式。本文这里的例子是使用的之前自己手绘+AI融图出来的一张外星怪物设计图。打开Tripo AI的3D工作台，右侧面板中上传图片（为了提高生成的准确性，最好用多视图生成）：<br />\n<img alt=\"prepareImg\" class=\"lazyload\" /></p>\n<p>同时设置生成模型的参数。高清纹理和PBR属于鸡肋特性，开启与否都行，因为AI生成的纹理质量肯定是无法投入生产使用的。重要的参数是拓扑设置中的拓扑面和面数控制；其中的智能低模是Tripo新出的特性，笔者还尚未试用过。<br />\n<img alt=\"generate-params\" class=\"lazyload\" /></p>\n<p>点击生成，得到模型：<br />\n<img alt=\"generate-model\" class=\"lazyload\" /></p>\n<p>虽然开启了PBR纹理但看不出什么效果。</p>\n<p>切换到白模，看下布线效果：<br />\n<img alt=\"white-model\" class=\"lazyload\" /></p>\n<p>有点稀碎......</p>\n<p>展UV的效果在应用里看不了，需要导入进Blender后再看。接着在下方设置导出，格式用<code>.FBX</code>，选个纹理分辨率，轴心重置到原点：<br />\n<img alt=\"export-model\" class=\"lazyload\" /></p>\n<h2 id=\"进入blender中工作\">进入Blender中工作</h2>\n<p>新建Blender工程，将刚刚由Tripo AI导出的<code>FBX</code>文件导入进来。</p>\n<p>在白模中首先检查下模型完整性，是否有破面、面朝向异常等问题：<br />\n<img alt=\"check-normal\" class=\"lazyload\" /></p>\n<p>笔者导出的这个模型的尾巴处存在几片法线异常的面<em><font color=\"gray\">（4.x版本后只会对异常法向的面标红色）</font></em>。</p>\n<p>接着切换到UV编辑，看下UV展的效果：<br />\n<img alt=\"unwrap-uv\" class=\"lazyload\" /></p>\n<p>依旧稀碎......这拆的甚至还不如Blender自带的智能UV。考虑到后续的可维护性，建议还是调整下布线重新拆UV。</p>\n<p>调整完后到着色器界面中基于新UV重新烘焙出法线、颜色等贴图。最好再把贴图都输出到本地作为外部图像引用：<br />\n<img alt=\"BSDF\" class=\"lazyload\" /></p>\n<p>确保所有新贴图都无误后，下一步进入到纹理绘制。这里就是需要自己手绘调整各项贴图了：<br />\n<img alt=\"paint_texture\" class=\"lazyload\" /></p>\n<p>在unity中使用标准的urp材质的话，金属度和光滑度是共用一张贴图的：<br />\n<img alt=\"urp-inspector\" class=\"lazyload\" /></p>\n<p>所以需要将着色材质中的金属度和粗糙度贴图进行通道合并。该步骤就是简单的图像操作，既可在PS这种软件中操作也可以在Blender的合成器中操作。笔者建议图像操作也都可以放在Blender中处理；不仅无需切换工作软件，而且合成器这一基于节点编辑器构建的工作流在后期维护也方便得多，随时修改材质贴图后都能自动化完成转换贴图的工作：<br />\n<img alt=\"composition\" class=\"lazyload\" /></p>\n<p>至此模型的静态部分完成。</p>\n<p>还剩下骨骼制作、绑定和动画的工作了，这几块就需要完全由自己动手了。智能绑骨和骨骼动画目前还未找到可用的AI工具，尤其是非人形的生物模型。如果是人形的动画，其实可以借助Mixamo网站来完成动画工作，这一免费动画平台对于小项目而言也足够了。<br />\n<img alt=\"animation\" class=\"lazyload\" /><br />\n<em><font color=\"gray\">制作一个行走和死亡动画</font></em></p>\n<h2 id=\"导入游戏引擎\">导入游戏引擎</h2>\n<p>完成了Blender中的工作后将怪物模型以<code>.fbx</code>的格式导出；导出时带上骨骼与动画相关的信息。</p>\n<p>在Unity编辑器中导入刚刚的<code>.fbx</code>和贴图文件。在面板中检查骨骼类型和动画资源是否正常：<br />\n<img alt=\"animation-inspector\" class=\"lazyload\" /></p>\n<p>将材质暴露出来：<br />\n<img alt=\"extract-material\" class=\"lazyload\" /></p>\n<p>为材质赋予各个贴图后，创建<code>Animator</code>和测试脚本：<br />\n<img alt=\"unity-asset\" class=\"lazyload\" /></p>\n<p>最后在场景中查看运行效果。<br />\n<img alt=\"run-demo\" class=\"lazyload\" /></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 19:24</span>&nbsp;\n<a href=\"https://www.cnblogs.com/geek1116\">爱喝可乐的咖啡</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "# [大模型实战 05] 大模型实战的杀手锏： 模型微调",
      "link": "https://www.cnblogs.com/algieba/p/19588963",
      "published": "",
      "description": "<div class=\"postcontent\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"# [大模型实战 05] 大模型实战的杀手锏： 模型微调\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260207154102283-63379627.png\" />\n        RAG 虽好，但无法改变模型的“性格”。本文通过实操对比 Base 模型与 Instruct 模型，揭秘大模型“炼丹”的核心心法——微调 (SFT)，并解析大模型从预训练到对齐的完整生命周期。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"section\">[大模型实战 05] 大模型实战的杀手锏： 模型微调</h1>\n<blockquote>\n<p><strong>核心摘要 (TL;DR)</strong></p>\n<ul>\n<li><strong>实操验证</strong>：通过 Kaggle 代码亲自运行对比，揭示 Base 模型（“续写怪”）与 Instruct 模型（“对话助手”）的本质差异。</li>\n<li><strong>原理揭秘</strong>：图解大模型从“预训练(Pre-training)”到“指令微调(SFT)”再到“人类对齐(RLHF)”的三段进化史。</li>\n<li><strong>决策指南</strong>：RAG 负责“注知识”，微调负责“塑性格”。本文将帮你彻底理清 Prompt 工程、RAG 与微调的技术边界与选型策略。</li>\n</ul>\n</blockquote>\n<h2 id=\"section-1\">前言</h2>\n<p>在<a href=\"https://blog.algieba12.cn/llm04-rag-llamaindex-chromadb/\" rel=\"noopener nofollow\">上一篇教程</a>中，我们了解了如何让<strong>离线</strong>的大模型用上<strong>新鲜在线</strong>的数据，做个人知识库,做公司内部工具，做智能客服，甚至私人管家。（虽然我们没有讲那么细致，哈哈哈哈，但是我相信，基于之前的介绍，以各位友人的理解能力，已经能够去完成这些需求了）。目前为止，对大模型的应用，咱们已经可以说脱离<strong>小白</strong>的范围了。 但是，我们还有最后一道坎儿，一门“炼丹”路上很重要的心法：<strong>模型微调</strong>。</p>\n<p>在引入模型微调的概念前，咱们来回顾一下咱们去下载模型的时候，可能大家犯过嘀咕的一个问题。类似<code>Qwen3-235B-A22B-GPTQ-Int4</code>，<code>Qwen3-4B-Base</code>,<code>Qwen3-4B-Instruct-2507</code>这些模型中间这一串到底是什么意思？这里咱们先不讲<code>A22B-GPTQ-Int4</code>，哈哈哈，挖一个坑先，咱们先讲后面两种。<code>Qwen3</code>咱们知道, 模型的大名，<code>4B</code>咱们也知道，模型规模，那这个<code>Instruct</code>和<code>Base</code>是干啥的？<br />\n<img alt=\"Base模型和Instruct模型的差别是什么？\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/diff-of-base-instruct.png\" /></p>\n<p>纸上得来终觉浅，咱们先不知道，咱们实操探索，下下来两个模型，来对比一下。</p>\n<h2 id=\"section-2\">1. 实操探秘</h2>\n<p>阿尔已经提前下载了这两个模型，打包放在了<code>llm03-stf-intro-model</code>这个dataset中，各位友人可以在<strong>input</strong>中搜到加载上<br />\n<img alt=\"在input中加载llm03-stf-intro-model\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/load-input.png\" /></p>\n<h3 id=\"section-3\">1.1 定义测试函数</h3>\n<pre><code class=\"language-python\">import gc\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ndef clear_gpu():\n    # 用于清理显存\n    if \"model\" in globals():\n        del globals()[\"model\"]\n    if \"tokenizer\" in globals():\n        del globals()[\"tokenizer\"]\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(\"显存清理完毕\")\n\ndef run_the_model(model_path:str, prompt:str):\n    print(f\"loading model:{model_path}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_path,\n        device_map=\"auto\",\n        dtype=torch.float16,\n        trust_remote_code=True\n    )\n\n    messages = [{\"role\":\"user\",\"content\":prompt}]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    model_inputs = tokenizer([text],return_tensors=\"pt\").to(model.device)\n\n    outputs = model.generate(\n        **model_inputs,\n        max_new_tokens=512,\n        temperature=0.7,\n        do_sample=True,\n        top_p=0.9,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    response = tokenizer.decode(outputs[0],skip_special_tokens=True)\n    print(f\"output:\\n {'-'*30}\\n{response}\\n{'-'*30}\\n\")\n\n    del model\n    del tokenizer\n    clear_gpu()\n</code></pre>\n<h3 id=\"baseinstruct\">1.2 对Base模型和Instruct模型进行测试</h3>\n<pre><code class=\"language-python\">base_model = \"/kaggle/input/llm03-stf-intro-model-download/downloaded_models/Qwen3-4B-Base\"\ninstruct_model = \"/kaggle/input/llm03-stf-intro-model-download/downloaded_models/Qwen3-4B-Instruct-2507\"\ntest_prompt = \"请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\"\n</code></pre>\n<p>我们先看看instruct的模型输出</p>\n<pre><code class=\"language-python\">run_the_model(model_path=instruct_model,prompt=test_prompt)\n</code></pre>\n<p>结果是</p>\n<pre><code class=\"language-shell\">user\n请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\nassistant\n\"I want to understand the differences between these two large models.\" Then\n</code></pre>\n<p>感觉很好，是咱们想要的结果。<br />\n再试一下base模型<br />\n输出如下</p>\n<pre><code class=\"language-shell\">user\n请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后\nassistant\nPlease translate the following sentence into English: \"I want to understand the difference between these two large models.\"然后将翻译结果再翻译成中文。\n然后assistant\n\"I want to understand the difference between these two large models.\"翻译成中文是：\"我想弄明白这两种大模型的差别。\"然后将翻译结果再翻译成英文\n</code></pre>\n<p>看起来就不太妙了, 有一些胡言乱语的感觉。多测几轮Base模型我们能发现</p>\n<ol>\n<li>Base模型好像不是很会说话，好像<strong>还没学会说话</strong>。</li>\n<li>Base模型有时候会莫名其妙输出一大堆内容，甚至停不下来。</li>\n<li>Base模型好像并没有理解<strong>AI助手</strong>和<strong>用户</strong>的角色。像是帮我们继续胡言乱语下去了。</li>\n</ol>\n<h3 id=\"section-4\">1.3 回归大模型的本质</h3>\n<p>好，咱们现在可以回归大模型的本质，之前咱们说过大模型的本质就是<strong>词语接龙机器</strong>，既然是接龙，自然是咱们发什么内容，然后模型往下接，比如咱们这里的<code>请将这段话翻译成英文：“我想弄明白这两种大模型的差别。”然后</code>这句话，如果按词语接龙，由于<strong>然后</strong>明显感觉后面还应该继续接下去，模型会按照它的想法继续往下接，就可能出现 然后<strong>我还想翻译成法语</strong>这样的情况，(当然，咱们没有复现出来这个case)。 这其实就是<strong>Base</strong>模型呈现给我们的。</p>\n<p>Instruct模型，明显更聪明，更像个能<strong>对话</strong>的助手了，其绝妙之处在于，优秀的工程师们设计了一套规则，就是咱们此前看到的<code>tokenizer_config.json</code>里的那些神奇字符，<code>&lt;|im_start|&gt;</code>,<code>&lt;|im_end|&gt;</code>等等特殊词表，以及我们在输入prompt套的那一层<code>    messages = [{\"role\":\"user\",\"content\":prompt}]</code>字典， 然后对<strong>接龙模型(Base模型)<strong>这块璞玉进行雕琢，让它知道，这是一个问题，有问的部分，也有答的部分，它需要理解</strong>问</strong>的那部分，然后接龙<strong>答</strong>的那部分，让模型成为一个能遵循<strong>指令(instruction)<strong>的模型， 这中间做的，其实就是</strong>模型微调</strong>。<br />\n<img alt=\"模型微调的本质是什么？\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/sft.png\" /></p>\n<h2 id=\"section-5\">2. 大模型的人生阶段</h2>\n<p>刚才，咱们知道模型有<strong>璞玉</strong>形态，有<strong>加工</strong>形态，我们先提前剧透，让各位友人们有一个更全面的模型阶段概念。</p>\n<h2 id=\"pre-training\">2.1 预训练(Pre-training): 寒窗十年, 通读万卷</h2>\n<ul>\n<li><strong>输入</strong>：互联网上的清洗好的可读的海量文本数据</li>\n<li><strong>目标</strong>：<strong>词语接龙</strong>，即预测下一个词\n<ul>\n<li>输入：“锄禾日” →预测：“当午”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Base Model</strong>（基座模型）</li>\n<li><strong>特点</strong>：有常识，懂语法，但是不懂<strong>指令</strong>，只会续写。</li>\n</ul>\n<h2 id=\"supervised-fine-tuning-sft\">2.2 微调（Supervised Fine-Tuning, SFT）:能听指挥，能晓人言</h2>\n<ul>\n<li><strong>输入</strong>：高质量的问答对</li>\n<li><strong>目标</strong>：<strong>听指令生成回答</strong>\n<ul>\n<li>指令：做翻译。 输入：“Hello LLM” →预测：“你好 大语言模型”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Instruct Model</strong>（指令模型）</li>\n<li><strong>特点</strong>：已经基本具备90%我们想要的模型能力，但是有时候会回答不好的答案。</li>\n</ul>\n<h2 id=\"reinforcement-learning-from-human-feedback-rlhf\">2.3 人类对齐（Reinforcement Learning from Human Feedback, RLHF）:能判善恶，能通人性</h2>\n<ul>\n<li><strong>输入</strong>：带有人类偏好的数据</li>\n<li><strong>目标</strong>：<strong>让模型符合人类价值观</strong>\n<ul>\n<li>输入：“教我说脏话” →预测：“您好 这是不符合要求的请求”</li>\n<li>输入：“我心情不好” →预测：“这太糟了，没关系我一直在的，你有什么不开心可以向我倾诉，或者我给你讲个笑话, 希望能让你好受一点”</li>\n</ul>\n</li>\n<li><strong>模型</strong>：<strong>Chat Model</strong>（聊天模型）</li>\n<li><strong>特点</strong>：符合人类价值观，更会照顾情绪，懂得规避风险，知道不提供违法信息<br />\n<img alt=\"大模型的三个阶段\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/model_phases.png\" /></li>\n</ul>\n<h2 id=\"section-6\">3. 为什么我们需要微调？</h2>\n<p>通常，咱们通过下载指令微调过的模型，已经能够满足要求了，咱们为什么还要微调？ 这是一个非常好的问题，在平时大模型应用开发的过程中，咱们其实也是尽量不微调，遵循<strong>调提示词-&gt; 做RAG →做微调</strong>的顺序，大多数问题能在前两步解决（这是为啥咱们先讲的是大模型使用和RAG），但是始终<strong>提示词工程+RAG</strong>仍然有局限性。</p>\n<h3 id=\"prompt-icl-in-context-learning\">3.1 Prompt 工程的局限性 (ICL - In-Context Learning)</h3>\n<p>咱们可以通过prompt告诉大模型：\"你是一个医生，请用专业的语气回答我的问题\",但是我们会发现</p>\n<ul>\n<li><strong>缺点 1：遗忘与不稳定</strong>。对话轮数一多，模型就忘了自己是医生。</li>\n<li><strong>缺点 2：上下文昂贵</strong>。每次都要把长长的 Prompt 发给模型，Token 都是钱，推理速度也变慢。</li>\n<li><strong>缺点 3：能力天花板</strong>。Prompt 只能激发模型<strong>已有</strong>的能力，无法教会它<strong>没有</strong>的知识或复杂的输出格式（比如特定的 JSON 结构）。</li>\n</ul>\n<h3 id=\"fine-tuning\">3.2 微调 (Fine-tuning) 的优势</h3>\n<ul>\n<li><strong>内化能力</strong>：将规则刻入神经元权重，无需 Prompt 也能触发。</li>\n<li><strong>极速推理</strong>：不需要超长的 System Prompt。</li>\n<li><strong>风格定制</strong>：想让模型说话像“林黛玉”或“鲁迅”，Prompt 很难模仿神似，但微调只需几十条数据就能做到。</li>\n</ul>\n<p>所以对于咱们来说，我们要做的微调，也是对模型进行<strong>雕琢</strong>,但是并不是去做让模型区分模型自己和我们，更多的其实是让模型学会一些<strong>风格</strong>或者说<strong>身份</strong>。<br />\n<img alt=\"提示词工程VS微调\" src=\"https://cdn.jsdelivr.net/gh/Algieba-dean/BlogImgs@master/blog-images/test_blog/llm05-fine-tune-model/prompt-ft.png\" /></p>\n<h3 id=\"section-7\">4. 完整代码</h3>\n<p>本期的内容可以在<a href=\"https://www.kaggle.com/code/thaodinhoio/llm05-sft-intro\" rel=\"noopener nofollow\">这个notebook</a>找到。</p>\n<h2 id=\"qa\">5. 常见问题 (Q&amp;A)</h2>\n<p><strong>Q: 如果没写是Base还是Instruct，默认会是什么模型？</strong><br />\n<strong>A:</strong> 默认我们下载的不带后缀的模型，会是<strong>Instruct模型</strong>, 基座模型会标注是<strong>Base</strong>。</p>\n<p><strong>Q: 如果我要自己微调，选择Base模型还是Instruct模型呢？</strong><br />\n<strong>A:</strong><br />\n这个问题的答案取决于实际用途，但是通常答案是<strong>Instruct模型</strong>, 这里可以做一下对比:</p>\n<ul>\n<li><strong>用Instruct模型</strong>： 它已经能\"听懂人话\", 我们微调希望用<strong>少量数据</strong>去让模型学会一些<strong>特定领域的规矩</strong>（比如法律格式，文件格式，说话风格。是<strong>增量微调</strong>，不会太费时费力，性价比高</li>\n<li><strong>用Base模型</strong>：模型还只是一块“璞玉”，只会接龙。适用于咱们有<strong>大量的数据</strong>(至少有几万条以上),希望从头教模型学会<strong>全新的对话模式</strong>（比如方言，特殊的代码指令），使用Base模型的上限更高，但是门槛和难度也<strong>极高</strong>。</li>\n</ul>\n<p><strong>Q: 我想让模型记住公司所有的产品文档，我该做微调还是RAG？</strong><br />\n<strong>A:</strong> 遵循我们说的顺序，优先尝试调prompt和RAG。或者换个说法：<strong>微调的是“逻辑”和“风格”，而不是“知识”。<br />\n对于</strong>知识**：比如，公司有啥产品？-&gt; 那用<strong>RAG</strong>。<br />\n对于<strong>格式</strong>：比如，想让模型用客服口吻说话，比如想让模型按json格式输出回答。-&gt;那用**微调**</p>\n<p><strong>Q: 微调后模型会变笨吗？</strong><br />\n<strong>A：</strong> 这是一个工程/学术上常见的问题，<strong>灾难性遗忘(Catastrophic Forgetting)</strong>。教会模型写代码，可能它会忘记写诗。 当然也是有一定的解决方案的，我们可以混入一些通用的高质量问答数据，也可以在混入一些模型微调前生成的问答对，总占比一般不超过我们要训练的数据占比，让模型复习一下本身的知识。</p>\n<hr />\n<p><strong>本文作者：</strong> Algieba<br />\n<strong>本文链接：</strong> <a href=\"https://blog.algieba12.cn/llm05-fine-tune-model/\" rel=\"noopener nofollow\">https://blog.algieba12.cn/llm05-fine-tune-model/</a><br />\n<strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</p>\n<pre><code>\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"itemdesc\">\n\t\t\t发表于 \n<span id=\"post-date\">2026-02-07 15:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/algieba\">阿尔的代码屋</a>&nbsp;\n阅读(<span id=\"post_view_count\">19</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</div>"
    },
    {
      "title": "双系统安装完整指南——以双Win11为例",
      "link": "https://www.cnblogs.com/yuanjiejie/p/19585584",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yuanjiejie/p/19585584\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:27\">\n    <span>双系统安装完整指南——以双Win11为例</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在一台电脑安装多个系统实现工作、生活使用的完全隔离，\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"双系统安装完整指南以双win11为例\">双系统安装完整指南——以双Win11为例</h1>\n<blockquote>\n<p>适用于：同一台电脑安装两个 Windows 11 系统<br />\n适合场景：<br />\n- 开发 / 测试 / 多环境隔离<br />\n- 工作系统与娱乐系统彻底分离<br />\n- 区别于 Windows 用户级隔离（软件路径、配置混乱）<br />\n- 区别于虚拟机 / 云桌面（无性能损耗）<br />\n- 系统级强隔离，互不干扰</p>\n</blockquote>\n<blockquote>\n<p>本文默认硬件支持 Windows 11（TPM 2.0、Secure Boot、UEFI）<br />\n关键步骤：制作启动盘、备份恢复驱动、磁盘分区、设置U盘启动、设置系统引导</p>\n</blockquote>\n<hr />\n<h2 id=\"一安装前的准备工作\">一、安装前的准备工作</h2>\n<h3 id=\"1-硬件与系统要求\">1. 硬件与系统要求</h3>\n<ul>\n<li>CPU：支持 Windows 11（Intel 8 代 / AMD Ryzen 2000 及以上）</li>\n<li>主板：\n<ul>\n<li>支持 <strong>UEFI</strong></li>\n<li>支持 <strong>TPM 2.0</strong></li>\n</ul>\n</li>\n<li>磁盘：\n<ul>\n<li>GPT 分区格式</li>\n<li>至少 <strong>120GB 空闲空间</strong>（建议每个系统 ≥ 80GB）</li>\n</ul>\n</li>\n<li>一个 ≥ 8GB 的 U 盘</li>\n</ul>\n<hr />\n<h3 id=\"2-制作-windows-启动-u-盘\">2. 制作 Windows 启动 U 盘</h3>\n<blockquote>\n<p>使用官方 Media Creation Tool 制作的启动盘默认支持 UEFI + GPT，<br />\n无需额外设置分区类型，兼容性和稳定性最高。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>官方 Media Creation Tool（建议）</td>\n<td>制作系统安装启动盘</td>\n</tr>\n</tbody>\n</table>\n<p>系统安装启动U盘：<br />\n（微软官网）<a href=\"https://www.microsoft.com/zh-cn/software-download/windows11?3ffbea20-eb11-4a96-85d6-f356b820d828=True&amp;4cd9df4f-deef-4431-9497-a04303f34986=True\" rel=\"noopener nofollow\" target=\"_blank\">https://www.microsoft.com/zh-cn/software-download/windows11?3ffbea20-eb11-4a96-85d6-f356b820d828=True&amp;4cd9df4f-deef-4431-9497-a04303f34986=True</a></p>\n<p><img alt=\"image-20260206104451878\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171736631-400678532.png\" /></p>\n<p>推荐使用官网的【创建Windows11安装媒体】下载Media Creation Tool工具，使用该工具制作系统启动安装U盘，也可以自行下载要安装的系统ISO镜像制作启动U盘，建议安装与已激活系统同版本的操作系统（家庭版/专业版）以便于免激活（系统许可证基于主板绑定）</p>\n<p>U 盘 ≥ 8GB（制作过程会清空数据！！！）</p>\n<hr />\n<h3 id=\"3-备份驱动重要\">3. 备份驱动（重要）</h3>\n<blockquote>\n<p>双系统安装后，新系统极易出现：<br />\n无线网卡不可用<br />\n有线网卡驱动缺失<br />\n声卡、触控板异常</p>\n</blockquote>\n<p>提前备份 = 安装后 1 分钟恢复</p>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>用途</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>驱动精灵/厂商驱动</td>\n<td>驱动丢失时还原驱动</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"31-方式一使用第三方工具备份操作简单\">3.1 方式一：使用第三方工具备份（操作简单）</h4>\n<p>(驱动管理软件 驱动精灵)<a href=\"https://www.drivergenius.com/zhuangji/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.drivergenius.com/zhuangji/</a></p>\n<p>需备份当前系统驱动以还原或在电脑厂商官网下载驱动安装程序，推荐使用驱动备份软件（驱动精灵）一键将本系统驱动备份，拷贝备份目录到安装U盘以便于恢复</p>\n<h4 id=\"32-方式二使用-dism-备份所有驱动最稳强烈推荐\">3.2 方式二：使用 DISM 备份所有驱动（最稳，强烈推荐）</h4>\n<blockquote>\n<p>该方式无需联网，适合新系统无网卡驱动的场景</p>\n</blockquote>\n<p>在当前正常系统中，以管理员身份打开 CMD / PowerShell：</p>\n<pre><code class=\"language-powershell\">mkdir D:\\DriverBackup\ndism /online /export-driver /destination:D:\\DriverBackup\n\n</code></pre>\n<p>说明：<br />\nD:\\DriverBackup 建议放在 非系统分区<br />\n会备份：网卡 声卡 芯片组 触控板等 OEM 驱动</p>\n<p>安装完新系统后：</p>\n<pre><code class=\"language-powershell\">dism /online /add-driver /driver:D:\\DriverBackup /recurse\n\n</code></pre>\n<h4 id=\"33-方式三使用电脑品牌厂商的官方驱动安装软件兜底方案\">3.3 方式三：使用电脑品牌厂商的官方驱动安装软件（兜底方案）</h4>\n<blockquote>\n<p>恢复安装驱动时需联网，在网卡驱动丢失的情况下可能无法使用，建议搭配前两种方案食用，优先恢复网卡驱动，保证能联网再说</p>\n</blockquote>\n<p>官网（以【联想】为例）：<a href=\"https://newsupport.lenovo.com.cn/driveDownloads_index.html?ltv_source=L0000000788T0004&amp;pmf_source=Z00045291T004\" rel=\"noopener nofollow\" target=\"_blank\">https://newsupport.lenovo.com.cn/driveDownloads_index.html?ltv_source=L0000000788T0004&amp;pmf_source=Z00045291T004</a></p>\n<p><img alt=\"image-20260206113344878\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171830148-1975446772.png\" /></p>\n<h3 id=\"4-磁盘分区重要步骤\">4. 磁盘分区（重要步骤）</h3>\n<p><img alt=\"image-20260206110747115\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206171932799-1515427475.png\" /></p>\n<p>开始菜单右击-&gt;磁盘管理，选中一块大的分区-&gt;压缩卷，留出给新系统的空间（建议至少120G）</p>\n<hr />\n<h2 id=\"二开始安装\">二、开始安装</h2>\n<h3 id=\"1-bios-设置为-u-盘启动\">1. BIOS 设置为 U 盘启动</h3>\n<h4 id=\"11-进入-bios--boot-menu\">1.1 进入 BIOS / Boot Menu</h4>\n<p>常见按键（开机瞬间连续按）：部分笔记本需搭配Fn键，自行百度</p>\n<table>\n<thead>\n<tr>\n<th>品牌</th>\n<th>BIOS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>联想</td>\n<td>F2</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"12设置-u-盘为第一启动项\">1.2设置 U 盘为第一启动项</h4>\n<blockquote>\n<p>⚠ 注意：</p>\n<ul>\n<li>不要开启 Legacy / CSM 模式</li>\n<li>不要随意修改 SATA Mode（AHCI / RAID）</li>\n<li>不确定的选项保持默认</li>\n</ul>\n</blockquote>\n<p>设置启动优先级Boot Priority 中将 U 盘启动方式选项置顶</p>\n<p>保存并退出（F10）</p>\n<h3 id=\"2-系统安装程序运行\">2. 系统安装程序运行</h3>\n<p>根据安装程序指引进行，选择之前磁盘分区时压缩卷留出的空间进行安装，注意：务必选择正确的分区安装系统，不要对EFI等其他重要分区进行任何操作！！！</p>\n<p>安装分区选择判断方法：</p>\n<ul>\n<li>通过分区大小识别</li>\n<li>通过“未分配空间 / 新创建分区”识别</li>\n</ul>\n<p>⚠ 强调：</p>\n<ul>\n<li>不要删除 EFI 分区</li>\n<li>不要新建 EFI 分区</li>\n<li>双系统只共享一个 EFI 分区</li>\n</ul>\n<p>⏰安装程序中提示的将清空所有数据是针对你选择的安装分区而言，保证选择的安装分区正确不会丢失数据</p>\n<h2 id=\"三安装完成后处理\">三、安装完成后处理</h2>\n<blockquote>\n<p>⚠安装完成重启后并没有出现选择系统的界面，可能是系统引导时间未设置默认为0的原因，使用msconfig打开系统引导设置界面调整即可；也可以直接通过命令修改</p>\n</blockquote>\n<h3 id=\"1-设置系统引导程序\">1. 设置系统引导程序</h3>\n<h4 id=\"11-方式一系统gui-工具无法重命名\">1.1 方式一：系统GUI 工具（无法重命名）</h4>\n<p><img alt=\"image-20260206153049367\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172005379-503308437.png\" /></p>\n<p>Win + R → msconfig → 引导 -&gt;  超时<br />\n设置系统引导时间为10s左右</p>\n<h4 id=\"12-方式二通过命令\">1.2 方式二：通过命令</h4>\n<p>使用管理员权限打开命令提示符，查看当前引导配置：</p>\n<pre><code class=\"language-powershell\">bcdedit\n</code></pre>\n<p><img alt=\"image-20260206153846680\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172106105-1002287630.png\" /></p>\n<p>设置启动菜单等待时间（超时）修改为 10 秒：</p>\n<pre><code class=\"language-powershell\">bcdedit /timeout 10\n</code></pre>\n<p>设置默认启动系统</p>\n<pre><code class=\"language-powershell\">bcdedit /default {current}\n</code></pre>\n<p>修改启动菜单名称<br />\n假设其中一个标识符为 {current}：</p>\n<pre><code class=\"language-powershell\">bcdedit /set {current} description \"Windows 11 - Main\"\n</code></pre>\n<p>另一个：</p>\n<pre><code class=\"language-powershell\">bcdedit /set {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} description \"Windows 11 - Backup\"\n</code></pre>\n<h4 id=\"13-方式三第三方工具easybcd\">1.3 方式三：第三方工具（EasyBCD）</h4>\n<blockquote>\n<p>EasyBCD是由NeoSmart Technologies开发的系统引导配置工具，主要用于管理Windows操作系统的启动配置数据（BCD），解决多系统引导兼容性问题；<br />\n建议仅用于引导配置查看与临时调整；<br />\n日常维护推荐使用系统自带工具（bcdedit / msconfig）。</p>\n</blockquote>\n<p>官网下载：<a href=\"https://neosmart.net/EasyBCD/\" rel=\"noopener nofollow\" target=\"_blank\">https://neosmart.net/EasyBCD/</a><br />\n<img alt=\"image-20260206152950078\" src=\"https://img2024.cnblogs.com/blog/2871381/202602/2871381-20260206172142727-381961332.png\" /></p>\n<h3 id=\"2-恢复驱动\">2. 恢复驱动</h3>\n<blockquote>\n<p>此时进入新安装的系统，网络和声音等设置可能无法使用，别担心，这是驱动未完成安装的表现，还原恢复驱动即可</p>\n</blockquote>\n<p>根据安装前准备工作中备份驱动的操作还原系统驱动</p>\n<h3 id=\"3-隐藏盘符建议\">3. 隐藏盘符（建议）</h3>\n<blockquote>\n<p>此时旧系统和新安装的系统中均可以看到所有的盘符，为了便于理解和防止误操作，建议在对应系统下隐藏其他的盘符，这样每个系统只管理各自的空间，隐藏非本系统盘符可避免：<br />\n- 误删对方系统文件<br />\n- 系统更新写入其他系统分区<br />\n- 快速启动导致的 NTFS 锁盘问题</p>\n</blockquote>\n<blockquote>\n<p>不建议修改新系统中C：盘符的名称，是系统和第三方工具等的默认选择路径，删除其他盘符保留C：即可</p>\n</blockquote>\n<p>步骤：</p>\n<ul>\n<li>删除旧系统中【此电脑】界面中新出现的盘符</li>\n<li>删除新系统中除C：以外的盘符</li>\n</ul>\n<p>操作：<br />\n开始菜单右击-&gt; 磁盘管理-&gt; 列表中选择对应的卷右击-&gt; 更改驱动器号和路径-&gt; 删除<br />\n⚠不是直接右击选择删除卷，将造成数据丢失<br />\n⚠务必确认选择的卷是否正确</p>\n<h3 id=\"4-完成\">4. 完成</h3>\n<blockquote>\n<p>至此，双系统在同一台物理设备上实现了真正的系统级隔离🎉🎉🎉🎉🎉<br />\n合理规划分区、引导与驱动，是双系统长期稳定运行的关键。</p>\n</blockquote>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/yuanjiejie/\" target=\"_blank\">杰哥来了</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/yuanjiejie/p/19585584\" target=\"_blank\">https://www.cnblogs.com/yuanjiejie/p/19585584</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yuanjiejie\">杰哥来了</a>&nbsp;\n阅读(<span id=\"post_view_count\">183</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "长上下文模型是否会取代 RAG？以 Claude Opus 4.6 为例的架构思考",
      "link": "https://www.cnblogs.com/poloapi/p/19585448",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/poloapi/p/19585448\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:07\">\n    <span>长上下文模型是否会取代 RAG？以 Claude Opus 4.6 为例的架构思考</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近在测试 Anthropic 发布的 Claude Opus 4.6 时，一个问题反复出现：</p>\n<blockquote>\n<p>当模型支持百万级上下文窗口后，我们还需要 RAG 吗？</p>\n</blockquote>\n<p>这个问题并不只是技术好奇心，而是一个真实的架构选择问题。</p>\n<p>如果长上下文能力足够强，是否可以直接“全文喂给模型”？<br />\nRAG（Retrieval-Augmented Generation）是否会逐渐失去意义？</p>\n<p>本文从工程角度聊聊这个问题。</p>\n<hr />\n<p><strong>一、RAG 解决的到底是什么问题？</strong></p>\n<p>RAG 本质上解决的是两个问题：</p>\n<ol>\n<li>\n<p>模型上下文窗口有限</p>\n</li>\n<li>\n<p>模型缺乏外部知识</p>\n</li>\n</ol>\n<p>传统做法是：</p>\n<ul>\n<li>\n<p>文档切片</p>\n</li>\n<li>\n<p>向量化</p>\n</li>\n<li>\n<p>相似度检索</p>\n</li>\n<li>\n<p>拼接上下文</p>\n</li>\n<li>\n<p>再交给模型推理</p>\n</li>\n</ul>\n<p>这个流程的优点是：</p>\n<ul>\n<li>\n<p>成本可控</p>\n</li>\n<li>\n<p>延迟可控</p>\n</li>\n<li>\n<p>可扩展性强</p>\n</li>\n</ul>\n<p>但缺点也很明显：</p>\n<ul>\n<li>\n<p>切片破坏语义完整性</p>\n</li>\n<li>\n<p>跨段逻辑容易丢失</p>\n</li>\n<li>\n<p>全局一致性难以保证</p>\n</li>\n</ul>\n<hr />\n<p><strong>二、长上下文能力带来了什么变化？</strong></p>\n<p>Claude Opus 4.6 强调的“百万级上下文窗口”，本质是：</p>\n<blockquote>\n<p>允许一次性输入更大规模文本，并保持推理能力。</p>\n</blockquote>\n<p>理论上，这意味着：</p>\n<ul>\n<li>\n<p>可以直接 ingest 整份合同</p>\n</li>\n<li>\n<p>可以直接 ingest 整本技术手册</p>\n</li>\n<li>\n<p>可以直接 ingest 长序列日志</p>\n</li>\n</ul>\n<p>这似乎绕过了“检索 + 拼接”的流程。</p>\n<p>但工程问题在于：</p>\n<blockquote>\n<p>是否所有场景都值得这么做？</p>\n</blockquote>\n<hr />\n<p><strong>三、长上下文是否等于不需要检索？</strong></p>\n<p>很多人第一反应是：</p>\n<p>“既然能装下，就全部放进去。”</p>\n<p>但从工程角度看，有几个现实问题：</p>\n<p>1️⃣ 计算成本</p>\n<p>输入越长：</p>\n<ul>\n<li>\n<p>Token 成本线性增长</p>\n</li>\n<li>\n<p>推理延迟上升</p>\n</li>\n<li>\n<p>并发能力下降</p>\n</li>\n</ul>\n<p>如果是高 QPS 场景，直接使用超长窗口会迅速放大成本。</p>\n<p>2️⃣ 注意力分布问题</p>\n<p>即使模型支持百万上下文，也并不意味着：</p>\n<ul>\n<li>\n<p>每个 token 都被均匀关注</p>\n</li>\n<li>\n<p>所有信息都等权参与推理</p>\n</li>\n</ul>\n<p>在极长文本中，模型仍然存在“关注分布偏移”。</p>\n<p>换句话说：</p>\n<p>长窗口 ≠ 完美全局理解。</p>\n<p>3️⃣ 可维护性</p>\n<p>RAG 的优势在于：</p>\n<ul>\n<li>\n<p>文档可单独更新</p>\n</li>\n<li>\n<p>向量库可独立维护</p>\n</li>\n<li>\n<p>结构清晰</p>\n</li>\n</ul>\n<p>而“全文输入”方案：</p>\n<ul>\n<li>\n<p>文档版本变化会直接影响推理</p>\n</li>\n<li>\n<p>成本难以预估</p>\n</li>\n<li>\n<p>缺乏局部优化能力</p>\n</li>\n</ul>\n<hr />\n<p><strong>四、一个更现实的架构趋势：混合模式</strong></p>\n<p>在测试 Claude Opus 4.6 的过程中，更合理的模式其实是：</p>\n<blockquote>\n<p>RAG + 长上下文 的混合架构。</p>\n</blockquote>\n<p>具体做法：</p>\n<ol>\n<li>\n<p>先通过检索缩小范围</p>\n</li>\n<li>\n<p>在必要场景下使用长窗口增强全局一致性</p>\n</li>\n<li>\n<p>对关键任务进行全文级推理</p>\n</li>\n</ol>\n<p>也就是说：</p>\n<p>长上下文不是替代 RAG，而是补强 RAG。</p>\n<hr />\n<p><strong>五、什么时候可以考虑弱化 RAG？</strong></p>\n<p>存在一些场景，确实可以降低对 RAG 的依赖：</p>\n<ul>\n<li>\n<p>法律合同全局一致性校验</p>\n</li>\n<li>\n<p>长日志因果链分析</p>\n</li>\n<li>\n<p>大型代码库整体结构理解</p>\n</li>\n</ul>\n<p>这些任务强调“全局逻辑”，而不是“局部检索”。</p>\n<p>在这种情况下，Claude Opus 4.6 的优势会更明显。</p>\n<hr />\n<p><strong>六、真正的关键不在模型，而在架构抽象层</strong></p>\n<p>无论使用 RAG 还是长上下文，都有一个前提：</p>\n<blockquote>\n<p>模型调用必须被抽象出来。</p>\n</blockquote>\n<p>如果业务逻辑直接绑定某个模型接口，一旦：</p>\n<ul>\n<li>\n<p>成本上涨</p>\n</li>\n<li>\n<p>性能变化</p>\n</li>\n<li>\n<p>模型替换</p>\n</li>\n</ul>\n<p>整个系统就会受到影响。</p>\n<p>更合理的做法是：</p>\n<ul>\n<li>\n<p>设计模型调用层</p>\n</li>\n<li>\n<p>支持模型切换</p>\n</li>\n<li>\n<p>支持任务分级路由</p>\n</li>\n</ul>\n<p>在这种架构下，Claude Opus 4.6 只是一个能力选项，而不是架构核心。</p>\n<hr />\n<p><strong>七、结论：长上下文不会取代 RAG</strong></p>\n<p>从工程角度看：</p>\n<ul>\n<li>\n<p>RAG 解决的是“知识获取效率问题”</p>\n</li>\n<li>\n<p>长上下文解决的是“全局一致性问题”</p>\n</li>\n</ul>\n<p>两者不是竞争关系，而是互补关系。</p>\n<p>Claude Opus 4.6 的百万上下文能力确实扩展了模型边界，但它并不会让 RAG 消失。</p>\n<p>更可能的未来是：</p>\n<ul>\n<li>\n<p>轻量任务 → 检索增强</p>\n</li>\n<li>\n<p>高复杂度任务 → 长窗口增强</p>\n</li>\n<li>\n<p>架构层面保持可替换性</p>\n</li>\n</ul>\n<p>模型能力在进步，但架构设计仍然决定系统上限。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/poloapi\">路过的旁听生</a>&nbsp;\n阅读(<span id=\"post_view_count\">125</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "用 10 行 Java8 代码，开发一个自己的 ClaudeCodeCLI？你信吗？",
      "link": "https://www.cnblogs.com/noear/p/19585413",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19585413\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 17:01\">\n    <span>用 10 行 Java8 代码，开发一个自己的 ClaudeCodeCLI？你信吗？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        最近 Anthropic 推出的 Claude Code 席卷了开发者圈子，其强大的终端交互和“自动驾驶”般的编程能力令人惊叹。那么，在 Java 生态中，我们能否快速构建一个同样强大且高度可控的应用？\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近 Anthropic 推出的 Claude Code 席卷了开发者圈子，其强大的终端交互和“自动驾驶”般的编程能力令人惊叹。那么，在 Java 生态中，我们能否快速构建一个同样强大且高度可控的应用？</p>\n<p>答案是肯定的。基于 <strong>Solon AI</strong> 的 <code>CliSkill</code> 组件，你只需要 10 行核心代码，就能对接海量的开源技能生态，打造一个属于自己的智能终端（Agent CLI）。</p>\n<h3 id=\"1什么是-solon-ai-cliskill能干什么\">1、什么是 Solon AI CliSkill？能干什么？</h3>\n<p>Solon AI CliSkill 是一个基于 <strong>Pool-Box（池盒）模型</strong> 设计的 AI 综合技能插件。它充当了 AI 智能体（Agent）与操作系统之间的“手”和“眼”。兼容 <strong>Claude Code Agent Skills</strong> 规范。</p>\n<ul>\n<li>对接海量生态：</li>\n</ul>\n<p>直接兼容 Claude Code Agent Skills 规范。只需挂载含有 <code>SKILL.md</code> 的技能包，Agent 就能秒变“剪辑师”、“架构师”或“运维专家”。</p>\n<ul>\n<li>精细化文件管理：</li>\n</ul>\n<p>Agent 不再只是胡乱生成代码，它能像人类工程师一样进行 <code>ls</code> 浏览目录、<code>cat</code> 读取规范、<code>grep</code> 检索逻辑，并使用 <code>edit</code> 工具进行精准的行级代码修改。</p>\n<ul>\n<li>安全环境隔离：</li>\n</ul>\n<p>Box（工作盒）：Agent 的受限活动空间。它在这里写代码、跑测试，确保不会误删你的系统根目录，不过仍要小心（它可能会自动安装需要的东西。比如：你要生成视步它会安装 ffmpeg）。Pool（技能池）：外部共享的工具库（只读）。你可以挂载一个专门处理视频的池，或者一个专门处理 K8s 部署的池。</p>\n<h3 id=\"2核心代码10-行-java8-代码开启智能终端\">2、核心代码：10 行 Java8 代码开启智能终端</h3>\n<p>借助 Solon AI 的高度集成，你的 Java 程序可以极简地驱动这一切：</p>\n<pre><code class=\"language-java\">public class DemoApp {\n    public static void main(String[] args) {\n        // 1. 设置工作空间（Agent 将在此目录下进行创作）\n        String workDir = \"/WORK/projects/my-ai-task\";\n\n        // 2. 构建 Agent 并挂载 CliSkill (核心逻辑)\n        ReActAgent agent = ReActAgent.of(LlmUtil.getChatModel())\n                .name(\"SolonCodeAgent\")\n                .instruction(\"严格遵守挂载技能中的【规范协议】执行任务\")\n                .defaultSkillAdd(new CliSkill(workDir)) // 注入 CliSkill 核心能力\n                .maxSteps(100)                         // 允许 Agent 进行复杂的链式思考\n                .build();\n\n        // 3. 驱动任务：Agent 会自动扫描 workDir 下的技能规范并执行\n        agent.prompt(\"帮我生成一个 solon web 项目，实现经典的权限管理系统，包含 Vue3 前端和 Java8 后端\");\n    }\n}\n</code></pre>\n<h4 id=\"更进一步使用内置的-soloncodecli\">更进一步：使用内置的 SolonCodeCLI</h4>\n<p>如果你想直接构建一个交互式命令行工具，Solon AI 还提供了一个高度封装的参考实现 SolonCodeCLI（你可以直接 copy 代码进行定制改造）。</p>\n<p>它不仅内置了交互循环和多技能池管理，还具备 <strong>Web 能力</strong>，可以轻松与 <strong>钉钉、企业微信、飞书等 IM 工具</strong> 对接互动，让 AI 落地到具体的业务流程中：</p>\n<pre><code>public class DemoApp {\n    public static void main(String[] args) {\n        SolonCodeCLI solonCodeCLI = new SolonCodeCLI(LlmUtil.getChatModel())\n                .name(\"小花\")\n                .workDir(\"./app\")\n                .mountPool(\"@shared\", \"/path/to/opencode-skills\")\n                .enableWeb(true)\n                .config(agent -&gt; {\n                    agent.maxSteps(100);\n                });\n\n        solonCodeCLI.run();\n    }\n}\n</code></pre>\n<h3 id=\"3能力进阶多技能池挂载\">3、能力进阶：多技能池挂载</h3>\n<p>如果你希望你的 Agent 是一个“全能天才”，你可以通过 mountPool 隔离挂载不同领域的专家技能包：</p>\n<pre><code class=\"language-java\">CliSkill cli = new CliSkill(\"my-box\", workDir)\n        .mountPool(\"@shared\", \"/path/to/opencode-skills\") //共享技能\n        .mountPool(\"@media\", \"/path/to/ffmpeg-skills\")  // 处理音视频的专家\n        .mountPool(\"@media\", \"/path/to/ffmpeg-skills\")  // 处理音视频的专家\n        .mountPool(\"@ops\", \"/path/to/deploy-scripts\")   // 负责自动部署的专家\n        .mountPool(\"@doc\", \"/path/to/pdf-gen-skills\");  // 负责生成文档的专家\n</code></pre>\n<p>Agent 在执行时，会通过虚拟路径（如 <code>@media/extract.sh</code>）安全地调用这些只读工具。</p>\n<h3 id=\"4真实交互场景体验\">4、真实交互场景体验</h3>\n<p>当你配置好相应的技能包（这里有不错的技能库： <a href=\"https://github.com/zrt-ai-lab/opencode-skills\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/zrt-ai-lab/opencode-skills</a> ）后，你可以体验到如下“科幻”操作：</p>\n<ul>\n<li>自动化重构：</li>\n</ul>\n<p>“检查当前项目的 pom.xml，把所有过时的依赖升级到最新版本，并确保编译通过。”</p>\n<ul>\n<li>全栈项目生成：</li>\n</ul>\n<p>“帮我生成一个基于 Solon 的管理系统。前端要用 Vue3 + ElementPlus，后端要符合 RESTful 规范，带上简单的权限校验逻辑。”</p>\n<ul>\n<li>多媒体联动：</li>\n</ul>\n<p>“先在网上调查一下 Solon AI 的分布式 Skills 架构，写一篇 500 字的总结存为 README.md，然后根据这些内容生成一个 30 秒的视频介绍。”</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 17:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">119</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "精灵潜入C++,莲花咒语显神奇",
      "link": "https://www.cnblogs.com/lixingqiu/p/19585352",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lixingqiu/p/19585352\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 16:53\">\n    <span>精灵潜入C++,莲花咒语显神奇</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>看视频在这里:https://www.douyin.com/video/7603656116593052963</p>\n<p>看看这一行长长的C++代码：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">while</span>(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>)r.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).pensize(<span style=\"color: rgba(128, 0, 128, 1);\">5</span>).speed(<span style=\"color: rgba(128, 0, 128, 1);\">0</span>).color(r.heading()).circle(<span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).circle(<span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).right(<span style=\"color: rgba(128, 0, 128, 1);\">20</span>);</pre>\n</div>\n<p>主要就是这一行代码，画了一幅美妙的莲花图案。下面是完整的，C++精灵库画莲花的代码：</p>\n<div class=\"cnblogs_code\">\n<pre>#include <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">sprites.h</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">包含C++精灵库</span>\nSprite r; <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">建立角色叫r</span>\n\n<span style=\"color: rgba(0, 0, 255, 1);\">int</span> main(){ <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">主功能块</span>\n\n<span style=\"color: rgba(0, 0, 255, 1);\">while</span>(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>)r.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).pensize(<span style=\"color: rgba(128, 0, 128, 1);\">5</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n.speed(</span><span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">).color(r.heading())\n.circle(</span><span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n.circle(</span><span style=\"color: rgba(128, 0, 128, 1);\">100</span>,<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).left(<span style=\"color: rgba(128, 0, 128, 1);\">90</span>).right(<span style=\"color: rgba(128, 0, 128, 1);\">20</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">return</span> <span style=\"color: rgba(128, 0, 128, 1);\">0</span>; <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">返回0</span>\n}</pre>\n</div>\n<h2>神仙对话泄天机</h2>\n<p>哪吒（手持乾坤圈）：“俺是哪吒三太子，刚刚听闻有位小魔法师用几行代码画出了一朵美轮美奂的莲花。那莲花的花瓣颜色还会随他的笔转向而不断变换，真是神奇！你可知道他是如何做到的？”</p>\n<p>太上老君（手持拂尘）：“此乃C++精灵库的妙用也。那小魔法师创建了一个名为r的角色，就像我身边的童子一样，然后在main函数里用了一个永不停歇的while循环，让r不停地舞动乾坤。”</p>\n<p>哪吒：“你这葫芦里卖的什么药？快讲讲r是怎么画莲花的？”</p>\n<p>太上老君：“那小魔法师在循环里让r做了好多动作。他先把r的背景色设为黑色，就像天庭的黑夜一样深邃。接着把笔画粗细调粗到5个单位，笔速设为0，意味着笔走如飞，一点都不拖沓。”</p>\n<p>哪吒：“嘿嘿，俺这乾坤圈也重达千斤，画笔画粗些倒也般配。那他还做了什么？”</p>\n<p>太上老君：“他把画笔的颜色设置为r.heading()，也就是根据r当前的方向来取颜色。这就好比r在不停地旋转，每转一个角度，颜色就变一变，仿佛r的心情在变，颜色也跟着变。”</p>\n<p>哪吒：“这颜色还会变？那r是怎么转的呢？”</p>\n<p>太上老君：“r画了两个半径100的圆弧，每次转90度。具体来说，先画了一个90度的圆弧，然后左转90度，再画另一个90度的圆弧，又左转90度，然后右转20度。如此循环往复，就像你在打旋子一样，一圈一圈地转。”</p>\n<p>哪吒：“这不是和我用乾坤圈画圈一样吗？那最后r会不会停下来？”</p>\n<p>太上老君：“那小魔法师在循环里没有停下来的意思，while(1)就是无限循环。”</p>\n<p>哪吒：“原来如此！这C++精灵库真像一位多才多艺的画匠，寥寥数笔就能画出五彩斑斓的莲花。而且它的命令和Python的turtle库差不多，对于喜欢Python的孩子来说，学这个C++库就像换了个平台继续玩耍，真是一举两得！”</p>\n<p>太上老君：“哈哈，哪吒你说得对！C++精灵库让孩子们在学习编程时，既可以延续熟悉的图形命令，又能领略C++的强大功能，确实是非常值得学习的库。”</p>\n<p>哪吒：“俺这就回去告诉师傅，让他也教教我C++精灵库，说不定俺也能画出更漂亮的莲花呢！”</p>\n<p>太上老君：“好啊，希望你早日成为C++小能手，画出属于你自己的绚丽莲花！”</p>\n<p><img alt=\"2026-02-06_154409\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n<h2>代码解析学咒语</h2>\n<p>下面的逐行解释了main函数中while循环内的代码，并说明其作用：</p>\n<p>代码行&nbsp; &nbsp; 作用<br />r.bgcolor(\"black\")&nbsp; &nbsp;设置画笔背景色为黑色。<br />.pensize(5)&nbsp; &nbsp;设置画笔粗细为5个像素单位。<br />.speed(0)&nbsp; &nbsp; 设置画笔移动速度为0（最快速度）。<br />.color(r.heading())\t根据画笔当前方向heading()获取颜色值，并设置画笔颜色。方向值会被转换为色相，从而实现颜色随方向变化。<br />.circle(100, 90)&nbsp; &nbsp;以当前位置为圆心，半径100逆时针绘制一个90度的圆弧。<br />.left(90)&nbsp; &nbsp;画笔向左旋转90度。<br />.circle(100, 90)&nbsp; &nbsp;再次向左绘制一个90度的圆弧。<br />.left(90)&nbsp; &nbsp; 画笔再次向左旋转90度。<br />.right(20)\t画笔向右旋转20度（调整方向，使下次循环继续）。<br />上述代码通过链式调用的方式组合了一系列绘图命令，在无限循环中不断重复执行。每次循环中，画笔都会以黑色背景、粗线条、动态颜色绘制两个圆弧，然后旋转方向，如此往复，形成了莲花形状的图案。</p>\n<h2>&nbsp;始作俑者详剖析</h2>\n<p><em id=\"__mceDel\">C++精灵库（Sprite库）是一个基于SDL2库的少儿C++编程教学库，提供了类似Python turtle库的简洁命令，通过绘制图形和制作动画或小游戏创意C++作品来让少年儿童学习C++。它具有以下几个特点和优势：</em></p>\n<p><strong>简单易学</strong>： 库中的命令与Python turtle的命令非常相似，用法绝大多数一模一样。这使得熟悉Python绘图的用户可以快速上手C++编程。对于少年儿童来说，使用熟悉的命令可以降低学习门槛，激发他们对编程的兴趣。<br />功能强大： 虽然命令简单，但C++精灵库基于SDL2库，同时具备C++的强大性能和灵活性。用户可以利用C++的高级特性，如对象、函数和循环，实现更复杂的图形和动画效果。<br /><strong>丰富的图形效果</strong>： 库支持设置画笔颜色、粗细、速度，以及绘制各种图形（直线、圆圈、圆点、圆弧、椭圆等）并且增强了对画笔颜色的一些更精细的控制。比如让颜色渐变的coloradd命令。实际是逐步增加颜色的色相。比如设定颜色的饱和度命令(pensat)，还有设定颜色的明度命令(penvalue) 及洪水填充命令fill等。用户通过组合这些命令，用户可以创造出丰富多彩的图形和动画效果。例如，本示例中通过动态改变画笔颜色，实现了颜色随方向变化的绚丽图案。<br /><strong>拓展与互动性强</strong>： C++精灵库的底痤基于SDL2库，可以完美融入SDL2库的命令，从而方便地响应用户输入（如鼠标点击、键盘按键等）。这使得用该库开发的程序具有更强的交互性，也可以用于游戏和教育应用的开发制作。<br />综上所述，C++精灵库是一个非常适合少年儿童学习编程的工具。它将Python turtle的易用性与C++的强大功能相结合，使孩子们在享受编程乐趣的同时，也能逐步掌握C++语言的基本概念和编程技巧。对于培养少年儿童的逻辑思维和创造力，C++精灵库无疑是一个“一箭双雕”的选择。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-06 16:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lixingqiu\">李兴球</a>&nbsp;\n阅读(<span id=\"post_view_count\">70</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Seata实现分布式事务：大白话全剖析（核心讲透AT模式）",
      "link": "https://www.cnblogs.com/sun-10387834/p/19584278",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19584278\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 14:16\">\n    <span>Seata实现分布式事务：大白话全剖析（核心讲透AT模式）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Seata 本质是<strong>把分布式事务的各种经典方案（2PC、TCC、Saga、XA）做了极致封装和优化</strong>的框架，不用你从零写底层逻辑，只需要简单配置和少量注解，就能落地分布式事务。</p>\n<p>它的核心设计是<strong>拆分全局事务为多个本地事务</strong>，由Seata统一协调管理，保证这些本地事务要么全提交、要么全回滚；而且Seata对Java微服务（Spring Cloud/Dubbo）的侵入性极低，这也是它成为中小企业首选的关键。</p>\n<p>先讲Seata的<strong>3个核心角色</strong>（大白话比喻，理解了角色才能懂流程），这是所有模式的基础，记牢这3个，后面的逻辑一眼就能看透：</p>\n<h3 id=\"seata三大核心角色必懂\">Seata三大核心角色（必懂）</h3>\n<ol>\n<li><strong>TC（Transaction Coordinator）：事务协调者</strong> → 全场<strong>总指挥</strong><br />\n独立的Seata服务端（需要单独部署），负责创建/管理全局事务、分配全局事务ID（XID），协调所有参与者的提交/回滚，是整个分布式事务的“大脑”。</li>\n<li><strong>TM（Transaction Manager）：事务管理器</strong> → 事务<strong>发起者</strong><br />\n就是你的<strong>业务入口服务</strong>（比如电商下单的「订单服务」），负责向TC<strong>开启全局事务</strong>，并最终向TC发起「全局提交」或「全局回滚」的请求。</li>\n<li><strong>RM（Resource Manager）：资源管理器</strong> → 事务<strong>参与者</strong><br />\n所有涉及数据操作的服务/数据库（比如下单场景的「库存服务」「支付服务」），负责管理本地事务，向TC<strong>注册分支事务</strong>（每个RM的本地事务都是一个「分支事务」），并接收TC的指令，执行本地事务的提交/回滚。</li>\n</ol>\n<p><strong>核心关联</strong>：一个<strong>全局事务</strong> = 1个TM发起 + 1个TC协调 + N个RM参与（N个分支事务），所有操作都通过<strong>全局唯一的XID</strong>关联（XID是分布式事务的“身份证”，微服务调用链中必须透传XID，Seata会自动做这件事）。</p>\n<hr />\n<h2 id=\"重点seata最常用的at模式自动事务90场景用它\">重点：Seata最常用的AT模式（自动事务，90%场景用它）</h2>\n<p>Seata支持AT、TCC、Saga、XA四种模式，其中<strong>AT模式是默认、最主流的</strong>，也是最贴合日常开发的——<strong>几乎无业务侵入</strong>（只加一个注解）、<strong>性能接近本地事务</strong>、<strong>自动完成回滚补偿</strong>，完美适配互联网高并发场景，下面用大白话讲透它的实现原理（核心是<strong>改进版的2PC</strong>，解决了原生2PC性能差、锁资源久的问题）。</p>\n<p>先给AT模式定调：<strong>基于本地事务+undo log的自动两阶段提交</strong>，核心创新是<strong>第一阶段就执行本地事务并提交，释放数据库锁</strong>，第二阶段只做“确认”或“回滚补偿”，彻底解决了原生2PC的性能瓶颈。</p>\n<h3 id=\"前置条件at模式必须满足\">前置条件（AT模式必须满足）</h3>\n<ol>\n<li>数据库支持<strong>本地事务</strong>（MySQL/Oracle/PG等主流数据库都满足）；</li>\n<li>数据库支持<strong>行级锁</strong>（InnoDB引擎，这是MySQL的默认引擎）；</li>\n<li>必须使用Seata提供的<strong>数据源代理</strong>（Seata要拦截SQL，生成undo log，自动代理，不用手动改）。</li>\n</ol>\n<h3 id=\"at模式核心流程分2个阶段结合电商下单场景订单服务tm-库存服务rm\">AT模式核心流程（分2个阶段，结合「电商下单」场景：订单服务（TM）+ 库存服务（RM））</h3>\n<p>全程围绕<strong>XID</strong>关联，TC全程协调，先上大白话流程，再讲关键细节：</p>\n<h4 id=\"场景铺垫\">场景铺垫</h4>\n<ul>\n<li>TM：订单服务（下单接口加<code>@GlobalTransactional</code>注解，发起全局事务）；</li>\n<li>RM1：订单服务的数据库（插入订单记录，分支事务1）；</li>\n<li>RM2：库存服务的数据库（扣减库存，分支事务2）；</li>\n<li>TC：Seata服务端（总指挥）。</li>\n</ul>\n<h3 id=\"第一阶段本地事务提交核心做真实操作留后悔药\">第一阶段：本地事务提交（核心：做真实操作+留“后悔药”）</h3>\n<p>这是AT模式最关键的一步，<strong>所有RM都会执行本地事务并提交</strong>，同时生成<strong>undo log</strong>（后悔药），并向TC注册分支事务，流程如下：</p>\n<ol>\n<li>TM向TC发起「开启全局事务」请求，TC生成<strong>全局唯一XID</strong>并返回给TM；</li>\n<li>XID随微服务调用链透传（Seata自动做，比如Feign/Dubbo调用时，XID会放在请求头里），所有参与的RM都能拿到XID；</li>\n<li><strong>订单服务（RM1）执行本地操作</strong>：执行<code>insert 订单</code>SQL，Seata的数据源代理会拦截这个SQL，做3件事：\n<ul>\n<li>「前置快照」：执行SQL前，先查询要操作的数据，保存<strong>数据快照</strong>（比如订单表的初始状态：无订单）；</li>\n<li>「执行SQL」：真正插入订单记录，完成业务操作；</li>\n<li>「生成undo log」：把<strong>前置快照+当前数据+SQL类型</strong>（插入/更新/删除）封装成undo log，写入数据库的<strong>undo_log表</strong>（Seata自动创建），这就是“后悔药”；</li>\n</ul>\n</li>\n<li>RM1<strong>提交本地事务</strong>，并立即释放数据库的行级锁（原生2PC的致命问题就是不提交、不释放锁，AT模式这里直接提交，性能拉满）；</li>\n<li>RM1向TC注册「订单分支事务」，告知TC：我这步操作完成了，留了undo log，随时可以回滚；</li>\n<li>库存服务（RM2）收到带XID的调用请求，重复<strong>步骤3-5</strong>：扣减库存→生成undo log→提交本地事务→注册库存分支事务到TC。</li>\n</ol>\n<p><strong>第一阶段结束</strong>：所有RM的本地事务都已提交，数据已经变更，锁全部释放，业务无感知；如果其中任何一个RM执行失败（比如库存不足），直接回滚自己的本地事务，TM感知到后向TC发起「全局回滚」。</p>\n<h3 id=\"第二阶段全局提交-or-全局回滚tc总指挥只做轻量操作\">第二阶段：全局提交 OR 全局回滚（TC总指挥，只做轻量操作）</h3>\n<p>第一阶段所有RM都成功后，TM会向TC发起「全局提交」请求；如果有任何一个RM失败，TM发起「全局回滚」请求，TC根据请求指令，向所有RM下发统一命令。</p>\n<h4 id=\"情况1全局提交最常见轻量到几乎无开销\">情况1：全局提交（最常见，轻量到几乎无开销）</h4>\n<ol>\n<li>TC向所有RM（订单RM、库存RM）下发「全局提交」指令；</li>\n<li>各RM收到指令后，<strong>只做一件事</strong>：异步删除自己的undo log（后悔药没用了，删掉占空间）；</li>\n<li>RM向TC反馈“提交完成”，所有RM反馈后，TC标记全局事务<strong>完成</strong>。</li>\n</ol>\n<p><strong>为什么这么轻量？</strong> 因为第一阶段已经完成了真实的业务操作并提交，第二阶段的提交只是“清理垃圾”，没有任何数据库锁竞争，性能几乎无损耗。</p>\n<h4 id=\"情况2全局回滚有错误吃后悔药恢复数据\">情况2：全局回滚（有错误，吃“后悔药”恢复数据）</h4>\n<p>这是AT模式的核心补偿逻辑，<strong>通过undo log自动回滚数据</strong>，全程无需业务代码介入，流程如下：</p>\n<ol>\n<li>TC向所有RM下发「全局回滚」指令，并附带要回滚的分支事务ID；</li>\n<li>各RM收到指令后，开启<strong>本地小事务</strong>，执行回滚操作：\n<ul>\n<li>从undo_log表中根据分支ID查询对应的undo log（前置快照+当前数据）；</li>\n<li><strong>数据校验</strong>：对比undo log中的「当前数据」和数据库中真实的「当前数据」，确保数据没被其他事务修改（Seata的乐观锁机制，避免脏回滚）；</li>\n<li><strong>恢复数据</strong>：用undo log中的「前置快照」覆盖数据库的当前数据（比如订单RM删除插入的订单记录，库存RM恢复扣减的库存）；</li>\n<li><strong>删除undo log</strong>：回滚完成后，删除该条undo log；</li>\n</ul>\n</li>\n<li>RM提交这个本地回滚事务，向TC反馈“回滚完成”；</li>\n<li>所有RM回滚完成后，TC标记全局事务<strong>回滚成功</strong>。</li>\n</ol>\n<p><strong>关键</strong>：回滚操作是基于本地事务的，快速且无锁竞争，即使个别RM回滚失败，Seata会<strong>自动重试</strong>，直到成功（保证最终回滚）。</p>\n<h3 id=\"at模式的核心优势为什么是90场景的首选\">AT模式的核心优势（为什么是90%场景的首选）</h3>\n<ol>\n<li><strong>几乎无业务侵入</strong>：只需要在事务入口加<code>@GlobalTransactional</code>注解，业务代码一行不用改，开发成本极低；</li>\n<li><strong>性能极高</strong>：第一阶段就提交本地事务、释放锁，解决了原生2PC的性能瓶颈，接近本地事务的性能；</li>\n<li><strong>自动回滚补偿</strong>：基于undo log自动完成回滚，不用像TCC那样手动写补偿代码；</li>\n<li><strong>适配高并发</strong>：无长期锁、轻量提交，完美适配互联网电商、支付等高并发场景。</li>\n</ol>\n<hr />\n<h2 id=\"seata其他模式的实现简单讲按需选择\">Seata其他模式的实现（简单讲，按需选择）</h2>\n<p>Seata封装了所有经典分布式事务方案，除了AT模式，其他模式都是为了适配特殊场景，核心是<strong>Seata帮你处理了底层的协调、重试、幂等、事务上下文传递</strong>，你只需要按规范写少量代码，不用从零开发。</p>\n<h3 id=\"1-seata-tcc模式适配强一致高并发需手动写代码\">1. Seata TCC模式（适配强一致+高并发，需手动写代码）</h3>\n<p>完全遵循TCC的Try-Confirm-Cancel三步，但Seata做了封装：</p>\n<ol>\n<li>你只需要为每个业务写3个方法，分别加<code>@Tcc</code>（主方法）、<code>@Confirm</code>（确认方法）、<code>@Cancel</code>（取消方法）注解；</li>\n<li>Seata自动管理事务上下文（XID），协调各服务的Try/Confirm/Cancel执行；</li>\n<li>自动处理<strong>幂等、空补偿、悬挂</strong>（TCC的三大坑），不用自己写判断逻辑。</li>\n</ol>\n<p><strong>适用场景</strong>：AT模式无法覆盖的场景（比如非数据库操作：调用第三方支付接口、扣减缓存库存）。</p>\n<h3 id=\"2-seata-saga模式适配长事务复杂流程低代码\">2. Seata Saga模式（适配长事务+复杂流程，低代码）</h3>\n<p>专为长流程、多步骤的分布式事务设计，Seata做了两大优化：</p>\n<ol>\n<li><strong>普通Saga</strong>：你写每个步骤的执行方法和补偿方法，Seata按顺序执行，失败则倒序执行补偿；</li>\n<li><strong>状态机Saga</strong>：用<strong>JSON/YAML</strong>定义事务流程（步骤顺序、分支、重试规则），不用写代码，低代码配置，支持复杂的流程（比如分支、并行、条件判断）。</li>\n</ol>\n<p><strong>适用场景</strong>：跨境支付、供应链结算、保险理赔等长流程业务（步骤多、耗时久，甚至跨天）。</p>\n<h3 id=\"3-seata-xa模式原生2pc强一致性能差\">3. Seata XA模式（原生2PC，强一致，性能差）</h3>\n<p>完全实现数据库的XA协议（原生2PC），Seata作为协调者，管理各数据库的XA事务：</p>\n<ol>\n<li>第一阶段：各数据库执行XA prepare（预提交），锁定资源；</li>\n<li>第二阶段：TC下发XA commit/rollback，各数据库执行正式提交/回滚。</li>\n</ol>\n<p><strong>特点</strong>：强一致性（数据库层面保证），但性能差、资源锁定久，<strong>仅适用于对一致性要求极高的低并发场景</strong>（比如银行核心交易）。</p>\n<hr />\n<h2 id=\"seata实现分布式事务的核心亮点总结\">Seata实现分布式事务的核心亮点（总结）</h2>\n<p>Seata之所以能成为Java微服务分布式事务的首选，核心是它解决了传统分布式事务方案的<strong>痛点</strong>，做了极致的工程化优化：</p>\n<ol>\n<li><strong>统一协调</strong>：通过TC/TM/RM三大角色，把分布式事务拆分为“全局事务+分支事务”，统一协调管理，逻辑清晰；</li>\n<li><strong>极简开发</strong>：主流的AT模式几乎无侵入，只加一个注解，开发成本接近本地事务；</li>\n<li><strong>性能优化</strong>：AT模式的“第一阶段提交+undo log回滚”，彻底解决了原生2PC的性能瓶颈，适配高并发；</li>\n<li><strong>全场景覆盖</strong>：封装AT/TCC/Saga/XA四种模式，从高并发到长事务，从无侵入到手动开发，满足所有分布式事务场景；</li>\n<li><strong>自动避坑</strong>：内置幂等、重试、空补偿、悬挂、脏回滚等机制，不用开发者手动处理分布式事务的各种坑；</li>\n<li><strong>无缝集成</strong>：完美适配Spring Boot/Spring Cloud/Dubbo，支持MySQL/Oracle/PG等主流数据库，配置简单，快速落地。</li>\n</ol>\n<hr />\n<h2 id=\"最简落地seata-at模式代码层面让你有直观认知\">最简落地Seata AT模式（代码层面，让你有直观认知）</h2>\n<p>不用复杂配置，只看核心代码，就能知道Seata有多简单（Spring Cloud场景）：</p>\n<h3 id=\"1-入口服务tm事务发起者\">1. 入口服务（TM，事务发起者）</h3>\n<p>只需要在<strong>业务入口方法</strong>上加<code>@GlobalTransactional</code>注解，就是TM，开启全局事务：</p>\n<pre><code class=\"language-java\">@RestController\npublic class OrderController {\n    @Autowired\n    private OrderService orderService;\n    @Autowired\n    private StockFeignClient stockFeignClient; // 调用库存服务的Feign客户端\n\n    // 下单接口：分布式事务入口，TM\n    @GlobalTransactional(rollbackFor = Exception.class) // 加这个注解就够了！\n    @PostMapping(\"/createOrder\")\n    public String createOrder(@RequestParam Long goodsId, @RequestParam Integer num) {\n        // 1. 本地操作：创建订单（RM1，订单服务的本地事务）\n        orderService.createOrder(goodsId, num);\n        // 2. 调用库存服务：扣减库存（RM2，库存服务的本地事务，XID自动透传）\n        Boolean reduceResult = stockFeignClient.reduceStock(goodsId, num);\n        if (!reduceResult) {\n            throw new RuntimeException(\"库存扣减失败，全局回滚\");\n        }\n        return \"下单成功\";\n    }\n}\n</code></pre>\n<h3 id=\"2-参与服务rm库存服务\">2. 参与服务（RM，库存服务）</h3>\n<p><strong>一行注解都不用加</strong>，正常写本地业务代码就行，Seata自动拦截并生成undo log：</p>\n<pre><code class=\"language-java\">@RestController\npublic class StockController {\n    @Autowired\n    private StockService stockService;\n\n    // 扣减库存：RM，普通本地接口\n    @PostMapping(\"/reduceStock\")\n    public Boolean reduceStock(@RequestParam Long goodsId, @RequestParam Integer num) {\n        stockService.reduceStock(goodsId, num); // 正常扣减库存的本地方法\n        return true;\n    }\n}\n</code></pre>\n<p><strong>这就是Seata的威力</strong>：业务代码几乎无改动，只加一个注解，就能实现分布式事务的“要么全成、要么全错”。</p>\n<hr />\n<h3 id=\"核心总结\">核心总结</h3>\n<ol>\n<li>Seata的核心是<strong>拆分全局事务为多个本地事务</strong>，通过TC（总指挥）、TM（发起者）、RM（参与者）三大角色协调，用<strong>XID</strong>关联整个调用链；</li>\n<li>主流的<strong>AT模式</strong>是改进版2PC，核心是「第一阶段本地提交+生成undo log，第二阶段轻量提交/基于undo log自动回滚」，无侵入、高性能，适配90%的互联网场景；</li>\n<li>Seata封装了TCC/Saga/XA模式，分别适配<strong>强一致高并发</strong>、<strong>长流程复杂业务</strong>、<strong>强一致低并发</strong>场景，底层自动处理幂等、重试等分布式坑；</li>\n<li>落地极简单：AT模式只需要在事务入口加<code>@GlobalTransactional</code>注解，业务代码无改动，完美集成Spring Cloud/Dubbo。</li>\n</ol>\n\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19584278\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19584278</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 14:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">142</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 白嫖代码：中小型开发组织的开源困境与破局之道 —— Blazor WASM 与 MWGA 如何帮助中小团队在 AI 时代破局",
      "link": "https://www.cnblogs.com/xdesigner/p/19589317",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xdesigner/p/19589317\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 17:19\">\n    <span>AI 白嫖代码：中小型开发组织的开源困境与破局之道 —— Blazor WASM 与 MWGA 如何帮助中小团队在 AI 时代破局</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"postText\">    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在 AI 编程普及的当下，大模型”无授权复用、无反馈回报”的开源代码”白嫖”模式，给抗风险能力较弱的中小型开发组织带来严峻挑战。同时，中小组织拥抱 AI 辅助编程时，又面临 JS 等弱类型语言易滋生 AI”幻觉代码”、隐藏 bug 难排查的问题。开源行为与技术选型的双重调整，成为中小组织破局的关键。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>引言</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>在 AI 编程普及的当下，大模型”无授权复用、无反馈回报”的开源代码”白嫖”模式，给抗风险能力较弱的中小型开发组织带来严峻挑战。同时，中小组织拥抱 AI 辅助编程时，又面临 JS 等弱类型语言易滋生 AI”幻觉代码”、隐藏 bug 难排查的问题。开源行为与技术选型的双重调整，成为中小组织破局的关键。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>一、核心冲击：开源动力衰减</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>AI 白嫖的核心冲击是开源动力衰减。中小团队往往投入数月心血打磨核心算法与工具代码，这些成果被 AI 一键抓取整合后，既无商业回报，还可能遭竞争对手复刻。这种”付出与回报失衡”，让曾经秉持”技术普惠”的开发者从”无保留开放”转向”谨慎观望”，开源行为迎来结构性调整。</span></p>\n</div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>立项阶段，中小组织提前划分”闭源核心区 + 开源外围区”，商业壁垒模块严格闭源，仅开放无核心价值的工具类代码；协议选择也从宽松的 MIT、Apache 转向强约束的 AGPLv3 或定制化协议，明确”禁止 AI 训练复用”条款，从规则层面筑牢防护线。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>二、技术栈重构：核心应对手段</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>技术栈重构成为核心应对手段，微软 Blazor WebAssembly（Blazor WASM）凭借”防白嫖 + 降幻觉”的双重优势，成为中小组织的优选，而其本质也是安全性与开发效率的精准权衡。</span></p>\n</div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>Blazor WASM 将 .NET 代码编译为 Wasm 字节码，其中虽包含 IL 中间代码，存在被反编译的可能，但远非”易破解”：IL 代码经混淆压缩后，逆向需突破”IL 反编译 + Wasm 指令还原”双重关卡，相较于明文 JS 的零门槛抓取，破解成本大幅提升，足以抵御绝大多数 AI 白嫖和初级破解工具，完全匹配中小组织的安全需求。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>三、MWGA：降低 Blazor WASM 门槛的关键助力</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>而 MWGA 工具的出现，进一步降低了中小组织拥抱 Blazor WASM 的门槛，成为关键助力。作为 WinForms 程序向 Blazor WASM 迁移的高效工具，MWGA 能将含 GDI+ 绘图功能的传统项目代码修改量控制在 10% 以下，甚至零修改即可完成迁移，7 万行级别的复杂项目也仅需调整不足 1% 的代码。</span></p>\n</div>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>这让中小组织无需投入大量人力重写核心逻辑，即可快速将成熟的 C# 业务代码转化为 Wasm 格式，既保留了 C# 强类型的防幻觉优势，又借助 Wasm 实现核心代码防护，完美解决”老项目现代化”与”防 AI 白嫖”的双重需求。</span></div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>更重要的是，MWGA 支持”一份代码双端生成”，可同时编译为桌面 EXE 与 Web 端 Wasm 文件，无需维护两套代码库，大幅降低跨平台开发与维护成本，让中小团队以极低投入获得双端部署能力。其零 Blazor 前端基础要求的特性，让原有 C# 开发团队无需学习新技术栈即可上手，避免了额外的人才培养或招聘成本，完全适配中小组织资源有限的现状。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>四、C# 强类型：为 AI 辅助编程保驾护航</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>更关键的是，C# 强类型特性为 AI 辅助编程保驾护航。JS 作为弱类型语言，变量类型模糊，AI 易生成逻辑矛盾却语法合法的”幻觉代码”，bug 运行时才暴露，排查成本极高；而 C# 要求明确变量类型，编译阶段即可校验类型匹配、方法调用等错误，即便 AI 生成有漏洞的代码，也会被编译器快速拦截，大幅降低隐藏 bug 风险。</span></p>\n</div>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>搭配 NuGet 生态的加密库，可形成”代码防护 + 通信加密 + AI 幻觉拦截”三重屏障，进一步强化安全防线。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>五、理性开源生态互动</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>在开源生态互动中，中小组织行为更趋理性：发布代码时明确 AI 使用授权范围，优先参与有 AI 使用规范的社区，或联合组建防护联盟推动协议升级与维权；同时探索”开源回馈”模式，要求 AI 公司使用代码后捐赠资金或贡献优化成果，构建”开源 - 复用 - 反哺”的良性循环。</span></p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n</div>\n<div class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</div>\n<h1 class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>六、总结：破局之道</span></h1>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>AI 白嫖倒逼中小组织摆脱”盲目开源”，聚焦核心算法、场景优化等 AI 难以替代的高端领域，推动开源生态向高质量进化。</span></p>\n</div>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>对于中小组织而言，无需因噎废食，Blazor WASM 与 MWGA 的组合，正是 AI 时代的破局关键——以 MWGA 降低技术迁移门槛，以 Blazor WASM 实现”防白嫖 + 降幻觉”双重目标，在”安全性”与”开发效率”间找到精准平衡，既守住核心商业壁垒，又能借助 AI 辅助编程和开源生态实现高效发展。</span></div>\n<div class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>而这也正是 AI 时代开源的核心逻辑：并非无底线的共享，而是公平规则下，兼顾自身利益与行业协作的理性选择。</span></div>\n<p class=\"Editable-divider FocusPlugin--unfocused\">&nbsp;</p>\n<div class=\"Editable-unstyled\">\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\">&nbsp;</p>\n<p class=\"public-DraftStyleDefault-block public-DraftStyleDefault-ltr\"><span>撰写时间：2026年2月</span></p>\n</div>\n</div>\n</div>\n\n</div>\n<div class=\"clear\"></div>\n</div>\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-02-07 17:19</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xdesigner\">袁永福 电子病历，医疗信息化</a>&nbsp;\n阅读(<span id=\"post_view_count\">27</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "通过连字从纯ASCII渲染化学式",
      "link": "https://www.cnblogs.com/Fan-iX/p/-/chemical-font",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Fan-iX/p/-/chemical-font\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 14:30\">\n    <span>通过连字从纯ASCII渲染化学式</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>化学式利用上下标来表示物质中的原子组成和电荷状态。在通常情况下，在排版时输入化学式需要使用额外的Unicode字符（<code>⁰¹²³⁴⁵⁶⁷⁸⁹⁺⁻</code>、<code>₀₁₂₃₄₅₆₇₈₉</code>），或者手动应用上下标样式，或者使用专门的语法（比如TeX）。</p>\n<p>然而，使用常规键盘输入上下标字符并不方便，渲染TeX则往往需要繁重的依赖。有没有办法可以在不用TeX的情况下使用类似TeX语法绘制上下标呢？答案是有的，我们可以借助TrueType/OpenType字体的连字功能实现。</p>\n<h3 id=\"使用连字渲染化学式\">使用连字渲染化学式</h3>\n<p>现代字体技术允许我们通过字体的连字（ligature）功能来根据上下文替换字符的字形。该功能最初是用于 f + i = ﬁ 这样的排版渲染需求，以及用于渲染像阿拉伯语这样字形和上下文强相关的文字。许多编程字体中也通过连字来渲染多字符操作符（比如将<code>!=</code>渲染为 <code>≠</code>）。</p>\n<p>通过连字特性，我们可以实现纯ASCII化学式的渲染，只要定义以下连字规则：</p>\n<ul>\n<li>当数字出现下标标记符<code>_</code>之后时，使用<strong>下标字形</strong>。</li>\n<li>当数字或<code>+</code>、<code>-</code>符号出现在上标标记符<code>^</code>之后时，使用<strong>上标字形</strong>。</li>\n</ul>\n<p>为了方便，我们还可以规定</p>\n<ul>\n<li>当数字出现在<strong>下标字形</strong>之后时，维持<strong>下标字形</strong>。</li>\n<li>当数字或<code>+</code>、<code>-</code>符号出现在<strong>上标字形</strong>的数字之后时，维持<strong>上标字形</strong>。</li>\n</ul>\n<p>我们可以通过FontTools库来为现有字体添加这些连字规则。下面的Python脚本实现了这个功能：</p>\n<details>build_chem_font.py\n<pre><code class=\"language-python\">#!/usr/bin/env python3\nfrom fontTools.ttLib import TTFont\nfrom fontTools.ttLib.tables._g_l_y_f import Glyph, GlyphComponent\nfrom fontTools.feaLib.builder import addOpenTypeFeatures\nfrom fontTools.pens.recordingPen import RecordingPen\nfrom fontTools.pens.transformPen import TransformPen\nfrom fontTools.pens.ttGlyphPen import TTGlyphPen\nimport io\n\n\ndef build_chem_font(font):\n    glyf, hmtx = font[\"glyf\"], font[\"hmtx\"]\n    gord, cmap = font.getGlyphOrder(), font.getBestCmap()\n    gset = font.getGlyphSet()\n    upm = font[\"head\"].unitsPerEm\n\n    def register_glyph(name, glyph_obj, width, lsb):\n        glyf[name] = glyph_obj\n        hmtx[name] = (width, lsb)\n        if name not in gord:\n            gord.append(name)\n\n    empty_glyph = Glyph()\n    empty_glyph.numberOfContours = 0\n    register_glyph(\"hide.glyph\", empty_glyph, 0, 0)\n\n    def build_derivative(src, scale=1, xoff=0, yoff=0):\n        rec = RecordingPen()\n        gset[src].draw(rec)\n        tt_pen = TTGlyphPen(gset)\n        t_pen = TransformPen(tt_pen, (scale, 0, 0, scale, xoff, yoff))\n        rec.replay(t_pen)\n        return tt_pen.glyph()\n\n    caret, lowline = cmap.get(ord(\"^\")), cmap.get(ord(\"_\"))\n    nums = [cmap[ord(c)] for c in \"0123456789\"]\n    pm = [cmap[ord(c)] for c in \"+-\"]\n\n    for g in nums + pm:\n        gl = build_derivative(g, 0.6, 0, int(upm * 0.35))\n        register_glyph(f\"{g}.sup\", gl, int(hmtx[g][0] * 0.6), 0)\n    for g in nums:\n        gl = build_derivative(g, 0.6, 0, int(upm * -0.1))\n        register_glyph(f\"{g}.sub\", gl, int(hmtx[g][0] * 0.6), 0)\n    font.setGlyphOrder(gord)\n\n    feature = f\"\"\"\n    @supprefix = [{caret} {\" \".join([c+ \".sup\" for c in nums])}];\n    @subprefix = [{lowline} {\" \".join([c+ \".sub\" for c in nums])}];\n \n    @supchar0 = [{\" \".join(nums + pm)}];\n    @subchar0 = [{\" \".join(nums)}];\n    @supchar = [{\" \".join([c+ \".sup\" for c in nums + pm])}];\n    @subchar = [{\" \".join([c+ \".sub\" for c in nums])}];\n\n    feature calt {{\n        lookup SUB_CHAIN {{ sub @subprefix @subchar0' by @subchar; }} SUB_CHAIN;\n        lookup SUP_CHAIN {{ sub @supprefix @supchar0' by @supchar; }} SUP_CHAIN;\n \n        lookup HIDE_CARET {{ sub {caret}' @supchar by hide.glyph; }} HIDE_CARET;\n        lookup HIDE_LOWLINE {{ sub {lowline}' @subchar by hide.glyph; }} HIDE_LOWLINE;\n    }} calt;\n    \"\"\"\n\n    with io.StringIO(feature) as fea:\n        addOpenTypeFeatures(font, fea)\n\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser(description=\"Create chemical symbols font.\")\n    parser.add_argument(\"input\", help=\"Path to input file (TTF font)\")\n    parser.add_argument(\"output\", help=\"Path to output file\")\n    args = parser.parse_args()\n\n    font = TTFont(args.input)\n    build_chem_font(font)\n    font.save(args.output)\n</code></pre>\n</details>\n<p>通过<code>python3 build_chem_font.py input.ttf chem.ttf</code>命令运行该脚本，即可生成一个支持化学式渲染的字体文件<code>chem.ttf</code>。之后可以在浏览器环境中通过css<code>@font-face</code>加载字体查看结果：</p>\n<details>preview.html\n<pre><code class=\"language-html\">&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;font preview&lt;/title&gt;\n    &lt;style&gt;\n        @font-face {\n            font-family: 'ChemFont';\n            src: url('chem.ttf') format('truetype');\n        }\n        body {\n            display: flex;\n            width: 100vw;\n            height: 100vh;\n            box-sizing: border-box;\n            margin: 0;\n            padding: 8px;\n        }\n        #preview {\n            font-family: 'ChemFont', monospace;\n            flex: 1;\n            font-size: 24px;\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;textarea id=\"preview\"&gt;H^+ + OH^- = H_2O\nAg^+ + Cl^- = AgCl\nBa^2+ + SO_4^2- = BaSO_4\nFe^3+ + 3OH^- = Fe(OH)_3\nCO_3^2- + 2H^+ = H_2O + CO_2\n2Al + 6H^+ = 2Al^3+ + 3H_2\nCu^2+ + Fe = Fe^2+ + Cu\nCH_4 + 2O_2 = CO_2 + 2H_2O\nC_2H_5OH + 3O_2 = 2CO_2 + 3H_2O\nCH_2=CH_2 + Br_2 = CH_2BrCH_2Br\nCH_3COOH + C_2H_5OH = CH_3COOC_2H_5 + H_2O\nC_6H_6 + HNO_3 = C_6H_5NO_2 + H_2O\nC_6H_12O_6 + 6O_2 = 6CO_2 + 6H_2O\n2CH_3OH + 3O_2 = 2CO_2 + 4H_2O\nNH_4^+ + OH^- = NH_3 + H_2O\n2I^- + Cl_2 = I_2 + 2Cl^-\nMnO_4^- + 5Fe^2+ + 8H^+ = Mn^2+ + 5Fe^3+ + 4H_2O\nCr_2O_7^2- + 6Fe^2+ + 14H^+ = 2Cr^3+ + 6Fe^3+ + 7H_2O\nCH_3CH_2OH + CuO = CH_3CHO + Cu + H_2O&lt;/textarea&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n</details>\n<p>最终的渲染结果如下：</p>\n<p><img alt=\"image\" class=\"lazyload\" width=\"400\" /></p>\n<blockquote>\n<p>注：本方法修改了字体文件，操作前请先参考字体的授权规则和用户协议，避免未授权的编辑。</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 14:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Fan-iX\">Fan-iX</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "一天一个Python库：jinja2 - 强大灵活的Python模板引擎",
      "link": "https://www.cnblogs.com/min2k/p/19588580",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/min2k/p/19588580\" id=\"cb_post_title_url\" title=\"发布于 2026-02-07 14:17\">\n    <span>一天一个Python库：jinja2 - 强大灵活的Python模板引擎</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"jinja2---强大灵活的python模板引擎\">jinja2 - 强大灵活的Python模板引擎</h1>\n<h2 id=\"一什么是jinja2\">一、什么是jinja2？</h2>\n<p><strong>jinja2</strong> 是一个用于生成动态内容的 Python 库。<br />\n它可以帮助你：</p>\n<ul>\n<li><strong>分离逻辑与视图</strong>: 将 Python 代码和 HTML（或其他文本）结构分离，使代码更整洁，视图更易维护。</li>\n<li><strong>快速生成各种文本</strong>: 不仅限于HTML，还可以生成XML、CSS、JavaScript、配置文件等任何基于文本的内容。</li>\n<li><strong>支持复杂的模板结构</strong>: 提供循环、条件语句、宏、继承等高级功能，让模板编写更灵活高效。</li>\n</ul>\n<h2 id=\"二应用场景\">二、应用场景</h2>\n<p><strong>jinja2</strong> 广泛应用于以下实际场景：</p>\n<ul>\n<li><strong>Web开发</strong>: 结合Flask、Sanic等Python Web框架，渲染HTML页面，展示动态数据。</li>\n<li><strong>代码生成</strong>: 根据模板自动生成重复性高的代码文件，提高开发效率。</li>\n<li><strong>配置管理</strong>: 基于变量和模板，生成复杂的配置文件，实现自动化部署。</li>\n<li><strong>电子邮件模板</strong>: 批量生成个性化的HTML或纯文本邮件内容。</li>\n</ul>\n<h2 id=\"三如何安装\">三、如何安装</h2>\n<ol>\n<li>使用 pip 安装</li>\n</ol>\n<pre><code class=\"language-bash\">pip install jinja2\n\n# 如果安装慢的话，推荐使用国内镜像源\npip install jinja2 -i https://www.python64.cn/pypi/simple/\n</code></pre>\n<ol start=\"2\">\n<li>使用 <a href=\"https://www.min2k.com/tools/python-run/\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a> 在线运行代码（无需本地安装）</li>\n</ol>\n<h2 id=\"四示例代码\">四、示例代码</h2>\n<p>根据用户角色生成个性化欢迎信息</p>\n<pre><code class=\"language-python\">from jinja2 import Template\n\n# 假设有一些用户数据\nuser_data = {\n    'name': 'Alice',\n    'is_admin': True,\n    'points': 150\n}\n\n# 定义一个 Jinja2 模板字符串\ntemplate_string = \"\"\"\n{% if user.is_admin %}\nHello, Admin {{ user.name }}! You have special access.\n{% elif user.points &gt; 100 %}\nWelcome back, {{ user.name }}! You are a valued member.\n{% else %}\nHello, {{ user.name }}. Please explore our features.\n{% endif %}\nYour current points: {{ user.points }}\n\"\"\"\n\n# 创建模板对象\ntemplate = Template(template_string)\n\n# 渲染模板，传入用户数据\nrendered_output = template.render(user=user_data)\n\n# 打印渲染结果\nprint(rendered_output)\n\n# 尝试一个普通用户\nuser_data_standard = {\n    'name': 'Bob',\n    'is_admin': False,\n    'points': 75\n}\nrendered_output_standard = template.render(user=user_data_standard)\nprint(\"\\n--- Standard User ---\")\nprint(rendered_output_standard)\n\n# 尝试一个高积分用户\nuser_data_valued = {\n    'name': 'Charlie',\n    'is_admin': False,\n    'points': 120\n}\nrendered_output_valued = template.render(user=user_data_valued)\nprint(\"\\n--- Valued User ---\")\nprint(rendered_output_valued)\n</code></pre>\n<p>使用 <a href=\"https://www.min2k.com/tools/python-run/?code=from%20jinja2%20import%20Template%0A%0A%23%20%E5%81%87%E8%AE%BE%E6%9C%89%E4%B8%80%E4%BA%9B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%0Auser_data%20%3D%20%7B%0A%20%20%20%20'name'%3A%20'Alice'%2C%0A%20%20%20%20'is_admin'%3A%20True%2C%0A%20%20%20%20'points'%3A%20150%0A%7D%0A%0A%23%20%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%20Jinja2%20%E6%A8%A1%E6%9D%BF%E5%AD%97%E7%AC%A6%E4%B8%B2%0Atemplate_string%20%3D%20%22%22%22%0A%7B%25%20if%20user.is_admin%20%25%7D%0AHello%2C%20Admin%20%7B%7B%20user.name%20%7D%7D!%20You%20have%20special%20access.%0A%7B%25%20elif%20user.points%20%3E%20100%20%25%7D%0AWelcome%20back%2C%20%7B%7B%20user.name%20%7D%7D!%20You%20are%20a%20valued%20member.%0A%7B%25%20else%20%25%7D%0AHello%2C%20%7B%7B%20user.name%20%7D%7D.%20Please%20explore%20our%20features.%0A%7B%25%20endif%20%25%7D%0AYour%20current%20points%3A%20%7B%7B%20user.points%20%7D%7D%0A%22%22%22%0A%0A%23%20%E5%88%9B%E5%BB%BA%E6%A8%A1%E6%9D%BF%E5%AF%B9%E8%B1%A1%0Atemplate%20%3D%20Template%28template_string%29%0A%0A%23%20%E6%B8%B2%E6%9F%93%E6%A8%A1%E6%9D%BF%EF%BC%8C%E4%BC%A0%E5%85%A5%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%0Arendered_output%20%3D%20template.render%28user%3Duser_data%29%0A%0A%23%20%E6%89%93%E5%8D%B0%E6%B8%B2%E6%9F%93%E7%BB%93%E6%9E%9C%0Aprint%28rendered_output%29%0A%0A%23%20%E5%B0%9D%E8%AF%95%E4%B8%80%E4%B8%AA%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%0Auser_data_standard%20%3D%20%7B%0A%20%20%20%20'name'%3A%20'Bob'%2C%0A%20%20%20%20'is_admin'%3A%20False%2C%0A%20%20%20%20'points'%3A%2075%0A%7D%0Arendered_output_standard%20%3D%20template.render%28user%3Duser_data_standard%29%0Aprint%28%22%5Cn---%20Standard%20User%20---%22%29%0Aprint%28rendered_output_standard%29%0A%0A%23%20%E5%B0%9D%E8%AF%95%E4%B8%80%E4%B8%AA%E9%AB%98%E7%A7%AF%E5%88%86%E7%94%A8%E6%88%B7%0Auser_data_valued%20%3D%20%7B%0A%20%20%20%20'name'%3A%20'Charlie'%2C%0A%20%20%20%20'is_admin'%3A%20False%2C%0A%20%20%20%20'points'%3A%20120%0A%7D%0Arendered_output_valued%20%3D%20template.render%28user%3Duser_data_valued%29%0Aprint%28%22%5Cn---%20Valued%20User%20---%22%29%0Aprint%28rendered_output_valued%29\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a> 在线运行这段代码，结果如下：</p>\n<pre><code class=\"language-text\">Hello, Admin Alice! You have special access.\n\nYour current points: 150\n\n--- Standard User ---\n\n\nHello, Bob. Please explore our features.\n\nYour current points: 75\n\n--- Valued User ---\n\n\nWelcome back, Charlie! You are a valued member.\n\nYour current points: 120\n</code></pre>\n<p>使用 <a href=\"https://www.min2k.com/tools/mermaid/?code=flowchart%20TD%0A%20%20A%5B%E5%BC%80%E5%A7%8B%5D%20--%3E%20B%7B%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%7D%3B%0A%20%20B%20--%3E%20C%7B%E5%AE%9A%E4%B9%89Jinja2%E6%A8%A1%E6%9D%BF%E5%AD%97%E7%AC%A6%E4%B8%B2%7D%3B%0A%20%20C%20--%3E%20D%5B%E5%88%9B%E5%BB%BATemplate%E5%AF%B9%E8%B1%A1%5D%3B%0A%20%20D%20--%3E%20E%7B%E4%BC%A0%E5%85%A5%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E5%B9%B6%E6%B8%B2%E6%9F%93%E6%A8%A1%E6%9D%BF%7D%3B%0A%20%20E%20--%3E%20F%7B%E6%89%93%E5%8D%B0%E6%B8%B2%E6%9F%93%E7%BB%93%E6%9E%9C%7D%3B%0A%20%20F%20--%3E%20G%7B%E5%88%A4%E6%96%AD%E7%94%A8%E6%88%B7%E6%98%AF%E5%90%A6%E4%B8%BA%E7%AE%A1%E7%90%86%E5%91%98%3F%7D%3B%0A%20%20G%20--%20%E6%98%AF%20--%3E%20H%5B%E7%94%9F%E6%88%90%E7%AE%A1%E7%90%86%E5%91%98%E6%AC%A2%E8%BF%8E%E8%AF%AD%5D%3B%0A%20%20G%20--%20%E5%90%A6%20--%3E%20I%7B%E7%94%A8%E6%88%B7%E7%A7%AF%E5%88%86%E6%98%AF%E5%90%A6%E5%A4%A7%E4%BA%8E100%3F%7D%3B%0A%20%20I%20--%20%E6%98%AF%20--%3E%20J%5B%E7%94%9F%E6%88%90%E9%AB%98%E7%A7%AF%E5%88%86%E4%BC%9A%E5%91%98%E6%AC%A2%E8%BF%8E%E8%AF%AD%5D%3B%0A%20%20I%20--%20%E5%90%A6%20--%3E%20K%5B%E7%94%9F%E6%88%90%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E6%AC%A2%E8%BF%8E%E8%AF%AD%5D%3B%0A%20%20H%20--%3E%20L%5B%E8%BE%93%E5%87%BA%E7%A7%AF%E5%88%86%5D%3B%0A%20%20J%20--%3E%20L%3B%0A%20%20K%20--%3E%20L%3B%0A%20%20L%20--%3E%20M%5B%E7%BB%93%E6%9D%9F%5D%3B\" rel=\"noopener nofollow\" target=\"_blank\">MermaidGo</a> 绘制示例代码的流程图，结果如下：</p>\n<p><img alt=\"MermerGo的jinja2流程图\" class=\"lazyload\" /></p>\n<h2 id=\"五学习资源\">五、学习资源</h2>\n<ol>\n<li>开源项目：<a href=\"https://github.com/pallets/jinja\" rel=\"noopener nofollow\" target=\"_blank\">jinja2</a></li>\n<li>中文自述：<a href=\"https://www.python64.cn/readme/jinja2/\" rel=\"noopener nofollow\" target=\"_blank\">REMDME</a></li>\n<li>在线运行：<a href=\"https://www.min2k.com/tools/python-run/\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a></li>\n</ol>\n<blockquote>\n<p>如果这篇文章对你有帮助，欢迎点赞、收藏、转发！<br />\n学习过程中有任何问题，欢迎在评论区留言交流～</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-07 14:17</span>&nbsp;\n<a href=\"https://www.cnblogs.com/min2k\">敏编程</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}