{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "终于找到了一款足够简单的任务管理软件",
      "link": "https://www.cnblogs.com/lbnnbs/p/19491338",
      "published": "",
      "description": "<div class=\"postTitle\">\n            <h1><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lbnnbs/p/19491338\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 12:23\">\n    <span>终于找到了一款足够简单的任务管理软件</span>\n    \n\n</a>\n</h1>\n        </div>\n        <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n现在大家不但休息时间很碎片化，工作时间很多时候都是碎片化的。为了管理好自己的工作，我各类软件都使用过。但市面上多数工具要么功能繁杂，要么不支持手机版，要不就是收费太贵，真不是我这样的小白能用的起的。我个人使用过使用过很多的工作任务管理软件，有项目管理类的，有便签类的，有日程类的。但项目管理类的操作过于复杂，日程类和便签类的又没有团队协作功能。总之很难找一款简单好用的小团队小项目任务管理软件。后来百度的时候搜索到了一款叫九运任务宝的小工具，它官网上强调以 “简单、轻快、好用” 为核心定位，感觉有点点靠谱。下载试用后感觉还真不错，最起码要的东西都有。现在经过了几个月的使用，感觉找到了梦中情软（说的过分了点^_^）。<br /><br />传统任务管理软件，创建一个任务需要经历填写名称、设置分类、选择成员、调整时间等多个繁琐步骤，甚至需要跳转多个页面才能完成配置，新手入门需要花不少时间去学习，特别是项目管理类的，特别复杂。不但没有帮到工作排期，反而给增加了额外负担。而且有些工具的任务编辑功能简陋，缺少撤销重做，手机上操作一不小心删除时删过了头，就要重写一大段了。但这个九运任务宝任务创建全流程都和简单，只需专注填写任务内容，会自动根据首段内容智能生成任务名称，不用反复斟酌标题，秒速完成任务记录。任务内容编辑框带了撤销和重做功能，操作失误要不怕。<br /><br />他还有一个上传的图片会自动标注序号的功能，可以和任务内容上的描述匹配起来，让任务要求更清晰。这种 “少操作、多专注” 的设计，让任务创建效率提高不少。<br /><br />传统任务管理软件常常追求 “大而全”，堆砌了大量使用率极低的复杂功能，不仅增加了软件体积和操作难度，还容易让我在众多功能面前一脸懵逼。<br /><br />比如吧，项目管理类软件权限管理模块设计太复杂，设置流程繁琐。在比如大多数工具的任务状态没有 “搁置” 等选项，暂时无需处理的任务只能占用列表空间，导致信息杂乱。<br /><br />但这个九运任务宝在任务设置上，有“已搁置” 这个任务状态，就很方便，任务列表更整洁。在时间选择界面用绿色加粗字体标注节假日，工作排期时不需要额外切换日历APP查询假期。批量操作功能简单直观，长按任务即就可以进入批量编辑模式，右滑操作也很人性化，搞得我不时就像去划一下。此外，任务分类、优先级设置、协作人指派、甘特图等核心功能一应俱全，既满足多场景需求，又没啥多余的操作。<br /><br />另外，大多拥有项目和任务管理的软件移动端都比较难用，外出时宅手机上处理任务很头疼。这个九运任务宝就支持 PC 电脑端、手机 APP 端、微信小程序端、手机 H5 网页端，在外面也能随时随地操作。<br /><br />感觉现在的软件都越做越复杂，不实用的功能一大堆，追求大而全，像这类关注核心需要的软件倒是更少，也不知道是咋回事，是不知道我们需要什么样的工具才顺手吗。\n</div>\n<div class=\"clear\"></div>\n\n        <div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-16 12:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lbnnbs\">lbnnbs</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MySQL深度分页优化实战：从踩坑到落地的全攻略",
      "link": "https://www.cnblogs.com/sun-10387834/p/19491242",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19491242\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 11:57\">\n    <span>MySQL深度分页优化实战：从踩坑到落地的全攻略</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>做后端开发的同学，大概率都遇到过MySQL分页的坑——浅分页时查询秒回，一旦翻到几十页、上百页之后，接口就开始卡顿，甚至直接超时。之前在做电商商品列表接口时，就因为没处理好深度分页，线上出现过多次接口超时告警，排查后才发现是分页SQL的问题。今天就结合实际开发经验，聊聊MySQL深度分页的本质问题，以及那些能直接落地的优化方案，都是经过生产环境验证的干货。</p>\n<p>先说说最开始踩的坑。当时商品列表接口用的是最常规的分页写法，也就是LIMIT offset, size，代码里封装了通用分页逻辑，前端传页码和每页条数，后端计算offset后拼SQL。上线初期数据量少，翻个十几页都没问题，可随着商品数据涨到几十万条，用户翻到第500页之后，接口响应时间直接从几十毫秒飙升到几百甚至上千毫秒，监控面板上全是红色告警。</p>\n<h2 id=\"一深度分页为什么会慢\">一、深度分页为什么会慢？</h2>\n<p>一开始以为是索引没建对，排查后发现索引是正常的，后来翻了MySQL官方文档，再结合执行计划分析，才搞懂了核心原因。我们常用的LIMIT offset, size写法，比如LIMIT 100000, 20，MySQL并不是直接跳过前10万条数据取后面20条，而是会从表的第一条数据开始，逐行扫描，一共读取100020条数据，然后丢弃前10万条，只返回最后20条。</p>\n<p>这就意味着，offset越大，MySQL需要扫描的行数就越多，磁盘IO和内存消耗都会急剧增加，查询效率自然呈指数级下降。如果分页SQL还没命中索引，触发全表扫描，那情况会更糟，直接导致整个数据库实例压力飙升，影响其他接口。</p>\n<h2 id=\"二实战优化方案从易到难落地\">二、实战优化方案：从易到难落地</h2>\n<p>针对深度分页问题，没有万能方案，只能结合业务场景选择最合适的。下面按优先级排序，分享几个实际项目中用过的优化方案，从改造成本低到高逐步说明。</p>\n<h3 id=\"方案一书签分页最优解90场景适用\">方案一：书签分页（最优解，90%场景适用）</h3>\n<p>这是我目前在项目中用得最多的方案，改造成本低，性能提升明显，核心思路是放弃offset偏移，用上一页最后一条数据的主键或唯一索引作为“书签”，让MySQL直接通过索引定位到书签位置，再往后查询指定条数，彻底避免扫描无用数据。</p>\n<p>比如之前的商品列表，用主键id排序，原来的低效写法是：</p>\n<pre><code class=\"language-sql\">-- 第5001页，每页20条，offset=100000\nSELECT id, name, price, category FROM goods WHERE category=1 ORDER BY id LIMIT 100000, 20;\n</code></pre>\n<p>优化后，让前端传递上一页最后一条数据的id，比如上一页最后一条id是100000，新的SQL写法是：</p>\n<pre><code class=\"language-sql\">SELECT id, name, price, category FROM goods WHERE category=1 AND id &gt; 100000 ORDER BY id LIMIT 20;\n</code></pre>\n<p>这样MySQL会直接通过主键索引定位到id=100000的位置，再往后取20条数据，只扫描20条记录，不管数据量多大，查询速度都能稳定在毫秒级。</p>\n<p>这里有个需要注意的点：如果排序字段不是主键，而是普通字段（比如create_time），且存在重复值，直接用该字段作为书签会导致分页重复或漏数据。这时需要用“排序字段+主键”的组合作为锚点，保证唯一性。</p>\n<p>比如按创建时间倒序分页，优化写法如下：</p>\n<pre><code class=\"language-sql\">-- 上一页最后一条数据：create_time='2026-01-15 18:30:00'，id=100000\nSELECT id, name, price, create_time FROM goods \nWHERE category=1 AND (create_time &lt; '2026-01-15 18:30:00' OR (create_time = '2026-01-15 18:30:00' AND id &lt; 100000))\nORDER BY create_time DESC, id DESC LIMIT 20;\n</code></pre>\n<p>这种组合锚点的方式，能完美解决排序字段重复导致的分页异常问题，也是生产环境中处理非主键排序分页的标准写法。</p>\n<h3 id=\"方案二子查询join优化兼容跳页需求\">方案二：子查询/JOIN优化（兼容跳页需求）</h3>\n<p>书签分页的缺点是不支持直接跳转到指定页码，而很多业务场景（比如后台管理系统的分页组件）必须有页码选择功能，这时就需要用子查询或JOIN来优化。</p>\n<p>核心思路是：先通过索引查询出需要的主键ID，再通过主键关联查询全字段数据。因为主键是聚簇索引，查询主键的速度极快，子查询只扫描主键字段的offset+size条数据，而不是全字段，能大幅降低IO开销。</p>\n<p>原来的低效写法优化前：</p>\n<pre><code class=\"language-sql\">SELECT * FROM goods WHERE category=1 ORDER BY id LIMIT 100000, 20;\n</code></pre>\n<p>用JOIN优化后的写法（性能更优，MySQL推荐）：</p>\n<pre><code class=\"language-sql\">SELECT g.* FROM goods g\nJOIN (SELECT id FROM goods WHERE category=1 ORDER BY id LIMIT 100000, 20) t ON g.id = t.id\nORDER BY g.id;\n</code></pre>\n<p>这种方案能完美兼容跳页需求，不需要改造前端分页组件，性能比原生LIMIT提升10~100倍，offset越大，优化效果越明显。需要注意的是，子查询中的排序字段必须建立索引，否则子查询依然会全表扫描，优化失效。</p>\n<h3 id=\"方案三业务层限制最简单的兜底方案\">方案三：业务层限制（最简单的兜底方案）</h3>\n<p>其实很多ToC业务场景中，用户根本不会翻到第100页之后。比如电商商品列表，用户通常只看前10页，翻到后面的概率极低。针对这种场景，最简单的优化方式就是在业务层限制最大页码。</p>\n<p>我们当时在商品列表接口中做了限制：最多只能翻到第50页，超过50页就提示“暂无更多数据”，同时引导用户通过筛选条件（比如价格区间、销量排序）缩小查询范围。这种方式零开发成本，零性能损耗，直接从根源解决问题，适合大多数ToC业务。</p>\n<h3 id=\"方案四特殊场景兜底海量数据批量导出\">方案四：特殊场景兜底（海量数据/批量导出）</h3>\n<p>如果遇到千万级数据的深度分页，或者需要批量导出海量数据的场景，上面的方案可能不够用，这时可以考虑预生成分段ID或使用游标分页。</p>\n<p>预生成分段ID的思路是：在数据表中新增segment_id字段，按主键分段（比如每1000条数据为一个分段），建立segment_id索引。分页时先按segment_id定位分段，再在分段内分页，避免大范围扫描。这种方式适合数据更新频率低的场景，性能极致，但需要预处理数据。</p>\n<p>游标分页则适合批量数据导出、离线任务等不需要跳页的场景，通过MySQL游标逐行读取数据，避免一次性加载大量数据到内存，不会有offset的性能问题，但业务改造成本较高，只适合后端离线任务。</p>\n<h2 id=\"三优化必守原则缺一不可\">三、优化必守原则（缺一不可）</h2>\n<p>不管用哪种优化方案，以下两个原则必须遵守，否则所有优化都会失效：</p>\n<p>1. 分页SQL必须命中索引：WHERE筛选条件+ORDER BY排序条件，必须建立对应的单列索引或联合索引，否则MySQL会触发全表扫描+文件排序，性能依然极差。比如上面的商品列表，需要建立category+id的联合索引，才能让分页SQL高效执行。</p>\n<p>2. 避免使用SELECT *：只查询需要的字段，减少数据传输和内存开销。如果表中有text、blob等大字段，SELECT *会导致性能严重损耗，甚至拖慢整个数据库。</p>\n<h2 id=\"四总结\">四、总结</h2>\n<p>MySQL深度分页的核心矛盾，本质是offset导致的无效扫描。优化的核心思路就是：能不用offset就不用，优先用书签分页；必须用offset就减少扫描数据量，用子查询/JOIN优化；业务上能限制分页深度就限制，从根源规避问题。</p>\n<p>在实际开发中，不需要追求最复杂的方案，而是要结合业务场景选择最合适的。大部分场景下，书签分页+索引优化就能满足需求，改造成本低，性能又稳定。希望这篇实战总结能帮到大家，避开MySQL深度分页的坑。</p>\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19491242\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19491242</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 11:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "网络问题如何排查？mtr命令详解",
      "link": "https://www.cnblogs.com/deep-sky/p/19491194",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deep-sky/p/19491194\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 11:47\">\n    <span>网络问题如何排查？mtr命令详解</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h3 id=\"mtr\">mtr</h3>\n<p><code>mtr</code>命令是一个网络诊断工具，用于检测网络的连通性和延迟。MTR是My Traceroute的缩写，是traceroute和ping命令的结合体。</p>\n<p><code>mtr</code>默认使用<code>ICMP</code>协议，在介绍<code>mtr</code>的详细用法前我们先了解下<code>ICMP</code>协议。</p>\n<h3 id=\"imcp\">IMCP</h3>\n<p><code>ICMP</code>（Internet Control Message Protocol，互联网控制报文协议）<br />\n是一种网络层（OSI 第三层）协议，主要用于在 IP 网络中传递控制信息和错误信息，而不是用来传输业务数据。<br />\n<code>ICMP</code>的作用是：<br />\n1、网络连通性测试<br />\n最常用的就是<code>ping</code>命令，发送的是<code>ICMP Echo Request</code>，对方回复<code>ICMP Echo Reply</code>，用来判断网络是否可达、是否丢包以及延迟</p>\n<p>2、网络故障和错误反馈<br />\n当 IP 包在传输过程中出现问题时，<code>ICMP</code> 会返回错误信息，例如：</p>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>ICMP 类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>目标主机不可达</td>\n<td>Destination Unreachable</td>\n</tr>\n<tr>\n<td>路由中 TTL 用尽</td>\n<td>Time Exceeded</td>\n</tr>\n<tr>\n<td>需要分片但禁止分片</td>\n<td>Fragmentation Needed</td>\n</tr>\n</tbody>\n</table>\n<p>例如：路由器发现下一跳不可达时就会被源主机发送一个ICMP不可达报文</p>\n<p>3、网络路径诊断<br />\n<code>traceroute</code>和<code>tracert</code>就是通过<code>ICMP</code>实现的</p>\n<h3 id=\"mtr的用法\">mtr的用法</h3>\n<pre><code>Usage:\n mtr [options] hostname\n\n -F, --filename FILE              从文件中读取hostname(s)\n -4                               使用IPv4\n -6                               使用IPv6\n -f, --first-ttl NUMBER           起跳ttl参数，跳过前面的N-1跳，只只显示TTL=N后的跳（不改变真实路由，只是不显示）\n -m, --max-ttl NUMBER             maximum number of hops\n -u, --udp                        使用UDP 替代 ICMP echo\n -T, --tcp                        使用 TCP 替代ICMP echo\n -P, --port PORT                  使用TCP、SCTP或UDP探测时的目标端口\n -s, --psize PACKETSIZE           设置探测包的 payload 大小（字节）\n -i, --interval SECONDS           设置探测包的 发送间隔\n -r, --report                     报告模式（一次性输出，不刷新）\n -w, --report-wide                报告模式，宽屏对齐输出（字段不截断）\n -c, --report-cycles COUNT        发送探测包次数，设置20快速判断，设置100较为可信\n -j, --json                       以json格式输出\n -x, --xml                        以xml格式输出\n -C, --csv                        以csv格式输出\n -l, --raw                        以原始格式输出\n -n, --no-dns                     不做反向dns解析(只显示ip)\n -y, --ipinfo NUMBER              输出 IP 归属信息（国家 / 运营商）\n\n</code></pre>\n<p>在linux上执行<code>mtr</code>时，<code>mtr</code>会直接操作网络层构造IP/ICMP报文，所以一般需要使用<code>sudo</code>执行</p>\n<p>示例：<br />\n<code>sudo mtr -r -n -c 100 www.baidu.com</code></p>\n<p>输出结果:</p>\n<pre><code>Start: 2026-01-15T19:00:01+0800\nHOST: LTB-MBP.local               Loss%   Snt   Last   Avg  Best  Wrst StDev\n  1.|-- 183.2.172.177              0.0%   100    2.0   1.8   0.4  26.2   3.4\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>字段</th>\n<th>含义</th>\n<th>解读要点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>HOST</code></td>\n<td>当前跳主机</td>\n<td><code>*</code> 代表无响应</td>\n</tr>\n<tr>\n<td><code>Loss%</code></td>\n<td>丢包率</td>\n<td><strong>核心指标</strong></td>\n</tr>\n<tr>\n<td><code>Snt</code></td>\n<td>发送包数</td>\n<td>统计样本量</td>\n</tr>\n<tr>\n<td><code>Last</code></td>\n<td>最近一次延迟</td>\n<td>波动参考</td>\n</tr>\n<tr>\n<td><code>Avg</code></td>\n<td>平均延迟</td>\n<td>主要看</td>\n</tr>\n<tr>\n<td><code>Best</code></td>\n<td>最小延迟</td>\n<td>理想情况</td>\n</tr>\n<tr>\n<td><code>Wrst</code></td>\n<td>最大延迟</td>\n<td>是否有抖动</td>\n</tr>\n<tr>\n<td><code>StDev</code></td>\n<td>抖动</td>\n<td>越小越稳定</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"icmp限速\">ICMP限速</h4>\n<p>分析MTR输出时，需要关注两个方面：<strong>丢包率</strong>和<strong>延迟</strong>。如果在某个跳点看到一定程度的丢包，这可能说明该路由器有问题。然而，一些服务提供商普遍会限制MTR使用的<code>ICMP</code>响应速率。这可能会让人误以为丢包，实际上并没有丢包。要判断看到的丢包是真实的还是速率限制引起的，可以看看后续跳跃。如果跳跃显示损失为0.0%，那么很可能是因为：<code>ICMP</code>响应速率限制导致的而非真实的丢包，以下面的MTR结果为例:</p>\n<pre><code>root@localhost:~# mtr -r www.google.com\nHOST: example                       Loss%   Snt   Last  Avg  Best  Wrst   StDev\n   1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.3\n   2. 63.247.64.157                50.0%    10    0.4   1.0   0.4   6.1   1.8\n   3. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.7\n   4. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.1\n   5. 72.14.233.56                  0.0%    10    7.2   8.3   7.1  16.4   2.9\n   6. 209.85.254.247                0.0%    10   39.1  39.4  39.1  39.7   0.2\n   7. 64.233.174.46                 0.0%    10   39.6  40.4  39.4  46.9   2.3\n   8. gw-in-f147.1e100.net          0.0%    10   39.6  40.5  39.5  46.7   2.2\n</code></pre>\n<p>第二跳的丢包率虽然是 50%，但是其后续跳没有丢包且最终能到到达第8跳，所以整个链路实际上通的，第二跳的丢包率是因为<code>ICMP</code>限速导致的。</p>\n<p>可能有的同学会有疑问了，难道最后一跳不会出现<code>ICMP</code>限速吗？<br />\n实际上，<code>mtr</code>发送数据包后，会根据收到的 ICMP 响应类型来判断：</p>\n<pre><code>中间跳返回：ICMP Type 11 (Time Exceeded)\n            → \"TTL 耗尽，我不是目标\"\n            → 继续增加 TTL 探测下一跳\n\n最后一跳返回：ICMP Type 0 (Echo Reply)\n或 ICMP Type 3 (Destination Unreachable)\n            → \"我就是目标主机\"\n            → 停止探测\n</code></pre>\n<p>过程可以类比快递配送链路：</p>\n<ul>\n<li>中间转运站（路由器）：可能不会告诉你\"包裹经过了这里\"（限制或完全不响应ICMP Time Exceeded）</li>\n<li>最终收货点（目标主机）：必须签收并确认\"收到了\"（响应ICMP Echo Reply）</li>\n</ul>\n<p>即使中间转运站不告诉你进度，只要最后收到包裹并有签收确认，就说明整条链路是通的。</p>\n<h4 id=\"真实的丢包场景\">真实的丢包场景</h4>\n<p>以下面的MTR结果为例：</p>\n<pre><code>root@localhost:~# mtr -r www.google.com\nHOST: localhost                      Loss%   Snt   Last  Avg  Best  Wrst   StDev\n   1. 63.247.74.43                   0.0%    10    0.3   0.6   0.3   1.2   0.3\n   2. 63.247.64.157                  0.0%    10    0.4   1.0   0.4   6.1   1.8\n   3. 209.51.130.213                60.0%    10    0.8   2.7   0.8  19.0   5.7\n   4. aix.pr1.atl.google.com        60.0%    10    6.7   6.8   6.7   6.9   0.1\n   5. 72.14.233.56                  50.0%    10    7.2   8.3   7.1  16.4   2.9\n   6. 209.85.254.247                40.0%    10   39.1  39.4  39.1  39.7   0.2\n   7. 64.233.174.46                 40.0%    10   39.6  40.4  39.4  46.9   2.3\n   8. gw-in-f147.1e100.net          40.0%    10   39.6  40.5  39.5  46.7   2.2\n</code></pre>\n<p>在这个示例中，第三跳的丢包率高达60%且后续跳均出现了丢包率并且影响了最后的第8跳，所以可以判断第三跳是有问题的。由于中间跳<code>ICMP</code>限速和真实丢包会同时发生，所以会出现中间跳的丢包率高于最后一跳丢包率。</p>\n<p>当判断确实出现了丢包时，最好使用MTR双向测试下，因为数据包可能是发送时遇到了问题，也可能是在返回响应时出现了问题。</p>\n<h4 id=\"延迟\">延迟</h4>\n<p>MTR还能测试主机与目标主机之间连接的延迟。由于物理约束，延迟总是随着路由跳数的增加而增加。然而，增长应保持一致且线性。延迟通常是相对的，并且很大程度上取决于主机连接的质量及其物理距离。 在评估可能有问题的连接的 MTR 报告时，除了给定区域中其他主机之间的已知连接速度之外，还应将早期的功能齐全的报告视为上下文。</p>\n<p>以下面的MTR结果为例：</p>\n<pre><code>root@localhost:~# mtr --report www.google.com\nHOST: localhost                      Loss%   Snt   Last   Avg  Best  Wrst  StDev\n    1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.3\n    2. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.8\n    3. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.7\n    4. aix.pr1.atl.google.com        0.0%    10  388.0 360.4 342.1 396.7   0.2\n    5. 72.14.233.56                  0.0%    10  390.6 360.4 342.1 396.7   0.2\n    6. 209.85.254.247                0.0%    10  391.6 360.4 342.1 396.7   0.4\n    7. 64.233.174.46                 0.0%    10  391.8 360.4 342.1 396.7   2.1\n    8. gw-in-f147.1e100.net          0.0%    10  392.0 360.4 342.1 396.7   1.2\n</code></pre>\n<p>在第3跳和第4跳之间延迟突然增高，并且在后续跳中仍然很高，这可能表明存在网络延迟问题。</p>\n<p>但是，高延迟并不总是意味着当前路由有问题。 像上面这样的报告意味着，尽管第四跳存在某种问题，流量仍然到达目标主机并返回源主机。 延迟也可能是由返回路线问题引起的。 返回路线不会在 MTR 报告中看到，并且数据包可以采用完全不同的路线往返于特定目的地。</p>\n<p>在上面的示例中，虽然在第3跳和第4跳之间的延迟存在较大跳跃，但在任何后续跳中延迟并没有再增高。 由此，可以合理地假设第四个路由器存在问题。</p>\n<p><code>ICMP</code>限速也会导致延迟增加，以下面的MTR报告为例：</p>\n<pre><code>root@localhost:~# mtr --report www.google.com\nHOST:  localhost                     Loss%   Snt   Last  Avg  Best  Wrst   StDev\n    1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.3\n    2. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.8\n    3. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.7\n    4. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.1\n    5. 72.14.233.56                  0.0%    10  254.2 250.3 230.1 263.4   2.9\n    6. 209.85.254.247                0.0%    10   39.1  39.4  39.1  39.7   0.2\n    7. 64.233.174.46                 0.0%    10   39.6  40.4  39.4  46.9   2.3\n    8. gw-in-f147.1e100.net          0.0%    10   39.6  40.5  39.5  46.7   2.2\n</code></pre>\n<p>乍一看，第4跳和第5跳之间的延迟突然增高了。然而，在第五跳之后，延迟急剧下降。这里测得的实际延迟约为40ms，且并没有影响最后一条的延迟，网络实际上是没有问题的。</p>\n<h4 id=\"什么时候需要使用tcp和udp协议进行检测\">什么时候需要使用TCP和UDP协议进行检测？</h4>\n<p>三种协议的对比</p>\n<table>\n<thead>\n<tr>\n<th>协议</th>\n<th>默认使用场景</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ICMP</td>\n<td>默认模式</td>\n<td>最常用,大多数设备支持</td>\n<td>容易被防火墙过滤</td>\n</tr>\n<tr>\n<td>UDP</td>\n<td>测试 UDP 服务</td>\n<td>模拟真实 UDP 流量</td>\n<td>可能被过滤,不可靠</td>\n</tr>\n<tr>\n<td>TCP</td>\n<td>测试 Web/API 服务</td>\n<td>最接近真实应用流量,不易被过滤</td>\n<td>需要指定端口</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"什么时候使用tcp模式\">什么时候使用TCP模式？</h5>\n<ul>\n<li>场景 1：ICMP被防火墙屏蔽或ICMP限速</li>\n</ul>\n<pre><code># ICMP 模式失败\nmtr api.example.com\n→ 大量 \"waiting for reply\" 或 100% 丢包\n\n# 改用 TCP 模式（测试 443 端口）\nmtr -T -P 443 api.example.com\n→ 正常显示路由路径\n</code></pre>\n<ul>\n<li>场景 2：测试特定服务的网络质量</li>\n</ul>\n<pre><code># 测试 HTTPS 服务（443 端口）\nmtr -T -P 443 api.example.com\n\n# 测试 HTTP 服务（80 端口）\nmtr -T -P 80 www.example.com\n\n# 测试 SSH 服务（22 端口）\nmtr -T -P 22 server.example.com\n\n# 测试数据库（3306 端口）\nmtr -T -P 3306 db.example.com\n</code></pre>\n<p><code>mtr</code>使用TCP协议进行网络检测的过程是通过 TCP三次握手的前两步完成的</p>\n<pre><code>Client → SYN (dst port 443, TTL=N)\nServer → SYN-ACK\nClient → RST   （立刻）\n\n</code></pre>\n<p><code>mtr</code>的TCP模式只完成“三次握手的前两步”，并在收到响应后立刻主动 <code>RST</code>，不会建立真正的TCP连接，更不会形成大量的ESTABLISHED 连接，对目标主机性能几乎没有影响。</p>\n<h5 id=\"什么时候使用udp模式\">什么时候使用UDP模式？</h5>\n<ul>\n<li>场景 1：测试 UDP 应用</li>\n</ul>\n<pre><code># 测试 DNS 服务（53 端口）\nmtr -u -P 53 8.8.8.8\n\n# 测试 VoIP/视频会议（如 10000-20000 端口范围）\nmtr -u -P 16384 meeting.example.com\n\n# 测试游戏服务器\nmtr -u -P 27015 game.example.com\n\n# 测试 VPN（如 OpenVPN，1194 端口）\nmtr -u -P 1194 vpn.example.com\n</code></pre>\n<ul>\n<li>场景 2：ICMP 被限流但 UDP 没有</li>\n</ul>\n<pre><code># 某些网络对 ICMP 限流但允许 UDP\nmtr -u api.example.com\n</code></pre>\n<h3 id=\"小结\">小结</h3>\n<p>有了 mtr 之后，当客户反馈诸如：“我们办公室是千兆宽带、Wi-Fi 也是满格，就是你们的产品不行，页面加载慢、接口响应慢”这类问题时，不必慌张。</p>\n<p>拉上客户一起跑一跑 <code>mtr</code>，把链路情况和丢包率、延迟摆出来，沿途每一跳的网络状态都会清清楚楚地呈现在眼前。问题究竟出在本地网络、运营商链路，还是服务器侧，基本就一目了然了。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 11:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deep-sky\">DeepSky丶</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "没有前端后，我把 MCP 做进了 Chats 1.7.0 AI 网关",
      "link": "https://www.cnblogs.com/sdcb/p/19489261/20260115-chats-170",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sdcb/p/19489261/20260115-chats-170\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 08:45\">\n    <span>没有前端后，我把 MCP 做进了 Chats 1.7.0 AI 网关</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这是一篇补档文章。</p>\n<p>如果你还不了解 <strong>Sdcb Chats</strong>：简单说，这是一个支持 20+ 主流模型服务商的 AI 网关。它不只能让你在一个统一界面里聚合管理所有模型，同时也兼容标准 API 协议，支持 Docker 一键部署。</p>\n<p>现在回头看，Sdcb Chats 最新版本已经到了 1.10，后续又融合了交错思考、Code Interpreter、多模态和企业级权限等“看起来更酷”的能力。但如果要问我：<strong>哪个版本是我个人开发节奏的分水岭？</strong>答案大概率还是 1.7.0。</p>\n<p>因为 1.7.0 不只是“加了个功能”，而是有三件事同时发生：</p>\n<ul>\n<li>MCP（Model Context Protocol）在 Chats 里真正落地，终于从“能聊”走向“能调用工具”，理论上能支持任何符合 MCP 的模型服务商和工具服务商，比如知识库、搜索引擎、计算引擎等；</li>\n<li>数据模型与数据库大改（破坏性变更），为后续演进把地基打牢；</li>\n<li>更关键的是：从这个版本开始，Chats 基本变成我一个人维护了——而我第一次深度尝试了 AI 的“氛围编程（Vibe Coding）”。</li>\n</ul>\n<hr />\n<h2 id=\"三个月空窗没有前端的我第一次把ai当同事\">三个月空窗：没有前端的我，第一次把AI当同事</h2>\n<p>距离上次 1.6 正式发布过去了 3 个多月。这期间，和我搭档做 Chats 前端的朋友因为有事没办法继续参与开发。没有前端开发，我一个后端在 Next.js / React 这套体系里，生产力几乎直接归零——项目一度陷入停滞。</p>\n<p>于是我第一次认真尝试把 AI 当作“副驾驶”：从页面布局、状态管理、组件拆分，到各种奇怪的 UI 边角行为（尤其是流式输出和工具调用展示），都让 AI 一起参与。</p>\n<p>可以这样说：</p>\n<ul>\n<li>Chats 1.7 之前：基本还是人类一行代码一行代码撸上去的；</li>\n<li>Chats 1.7.0 起：我开始“系统性”地 Vibe Coding，<strong>尤其是在我并不熟的 React 上，生产力提升非常明显</strong>；</li>\n<li>也从这时起，Chats 的维护者（几乎）变成了我一个人。</li>\n</ul>\n<p>所以这篇文章标题里写“感谢 AI”，不是客套，是事实。</p>\n<hr />\n<h2 id=\"170-的核心mcp-协议全面落地\">1.7.0 的核心：MCP 协议全面落地</h2>\n<p>如果你把 Chats 只当成一个“统一模型网关 + 漂亮 UI”的聊天前端，那它的上限就只是“把模型回答展示出来”。但 MCP 的出现，让“模型能做事”有了更统一、更可组合的方式。</p>\n<p>在 1.7.0 里，MCP 的落地不是停留在“能连上”，而是把整条链路打通了：</p>\n<ul>\n<li>\n<p>后端有完整的 MCP 实体与权限关系（Server、Tool、User 授权、Chat 绑定）；</p>\n</li>\n<li>\n<p>前端设置页新增 MCP 管理：新增/编辑 Server、抓取工具、分配用户；<br />\n<img alt=\"02-mcp-list\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115213720114-1699629549.png\" /><br />\n<img alt=\"03-mcp-edit\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115213726314-440296231.png\" /><br />\n<img alt=\"04-mcp-assign-user\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115213729222-1808157068.png\" /></p>\n</li>\n<li>\n<p>会话侧可绑定多个 MCP Server，并在会话前校验当前用户权限；</p>\n</li>\n<li>\n<p>工具调用全程走流式输出，参数与结果能以结构化方式进入消息内容，前端也能更好地可视化展示。<br />\n<img alt=\"05-mcp-call\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115213734256-659322865.png\" /></p>\n</li>\n</ul>\n<p>对我而言，这意味着 Chats 从“聊天 UI”升级成了“工具编排平台”的雏形：你可以给不同的 Chat Span 配置不同的工具集合，让它们在同一套对话体验里发挥作用。</p>\n<hr />\n<h2 id=\"工具调用体验不只是能用而是要看得懂\">工具调用体验：不只是能用，而是要“看得懂”</h2>\n<p>做过工具调用的人都知道：<strong>能调用是一回事，让用户看懂发生了什么是另一回事。</strong></p>\n<p>1.7.0 在工具调用的事件与消息结构上做了比较大的增强：SSE 事件更丰富、消息内容里新增了工具请求/响应的类型，前端能把“调用了什么工具、传了什么参数、拿到了什么结果”以更清晰的方式展示出来。<br />\n<img alt=\"06-sse-response-line\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115213740193-1073025986.png\" /></p>\n<p>这件事看起来偏“体验”，但它会直接影响你是否愿意在真实业务里用工具调用：当工具一多、调用链一长，如果 UI 只是一坨 Markdown 混在一起，那基本等于不可用。</p>\n<hr />\n<h2 id=\"破坏性变更数据库与数据模型的大规模重构\">破坏性变更：数据库与数据模型的大规模重构</h2>\n<p>1.7.0 还有一个绕不开的关键词：<strong>破坏性变更</strong>。</p>\n<p>为了提升可维护性与可观测性，我在这个版本里对消息存储层做了重构（比如把 <code>Message</code> 拆分为 <code>ChatTurn/Step</code> 的分层结构），同时还伴随了用量关联、默认值约束、排序字段等一系列调整。<br />\n<img alt=\"07-db-schema\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115213746807-893994786.png\" /></p>\n<p>这种重构的特点是：你短期会痛一次，但长期会省很多命。尤其是当你后面要持续叠加“推理/工具/多模态/审计/性能统计”这些能力时，底层结构是否清晰，决定了你是在“继续写功能”，还是在“每加一个功能都要拆一次墙”。</p>\n<hr />\n<h2 id=\"一些我很在意的细节改进\">一些我很在意的细节改进</h2>\n<p>除了 MCP 和数据库重构，1.7.0 还把不少“用起来会爽一点”的点补齐了，比如：</p>\n<ul>\n<li>模型/密钥/预设支持拖拽排序（Provider/Key/Model 的组织方式更清晰）；<br />\n<img alt=\"\" src=\"https://io.starworks.cc:88/cv-public/2026/08-drag-reordering.avif\" /></li>\n<li>聊天再生成能力增强：单条重新生成、从某条用户消息开始重新生成整段；<br />\n<img alt=\"\" src=\"https://io.starworks.cc:88/cv-public/2026/09-regenerate.avif\" /></li>\n<li>Markdown Mermaid 渲染升级：暗/亮主题适配、全屏查看、流式友好；<br />\n<img alt=\"\" src=\"https://io.starworks.cc:88/cv-public/2026/10-mermaid.avif\" /></li>\n<li>图片生成尺寸控制：在会话中指定常用尺寸；</li>\n<li>OpenAI 兼容与第三方联调增强（工具调用适配修复、登录兼容优化等）。<br />\n<img alt=\"11-image-size-control\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260115214018456-481361818.png\" /><br />\n这些看起来零碎，但它们共同指向同一个目标：<strong>把 Chats 从“功能堆叠”推向“可长期使用的产品质感”。</strong></li>\n</ul>\n<hr />\n<h2 id=\"升级与数据迁移不支持自动迁移请手动跑-sql只提供-sql-server\">升级与数据迁移：不支持自动迁移，请手动跑 SQL（只提供 SQL Server）</h2>\n<p>Sdcb Chats的数据库变更 <strong>不支持自动数据迁移</strong>。升级时你需要<strong>手动执行 SQL 迁移脚本</strong>，并且目前只提供了 <strong>SQL Server</strong> 的迁移脚本：</p>\n<ul>\n<li>1.7.0 迁移脚本：<code>src/scripts/db-migration/1.7/20250516-mcp.sql</code></li>\n</ul>\n<p>基本步骤也很朴素：</p>\n<ol>\n<li>先备份数据库；</li>\n<li>在 SQL Server 上执行上面的迁移脚本；</li>\n</ol>\n<p>如果你用的是 SQLite 或 Postgres……我建议你像我一样：把 SQL 甩给 AI，让它帮你改成 SQLite/Postgres 版本，然后你再一边跑一边修，或者如果你能接受，先删库，Chats 会在第一次启动时自动创建新表结构。</p>\n<hr />\n<h2 id=\"致谢\">致谢</h2>\n<p>1.7.0 的发布说明里，我特别感谢过社区贡献（比如<a href=\"https://github.com/sdcb/chats/pull/96\" rel=\"noopener nofollow\" target=\"_blank\">修复登录页面运行时错误的 PR #96</a>）。而在这篇补档里，我还想加一个更个人的致谢：感谢 AI。</p>\n<hr />\n<p>感谢阅读！喜欢的朋友请给我的Github项目一个star：<a href=\"https://github.com/sdcb/chats\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats</a><br />\n有什么想法也欢迎在评论区留言交流，也欢迎加入我的 <strong>Chats QQ群：498452653</strong>，我们一起探索更多AI技术硬核玩法。</p>\n<p>微信群：<img alt=\"\" src=\"https://io.starworks.cc:88/cv-public/2026/chats-wxg-qr.png\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 08:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sdcb\">.NET骚操作</a>&nbsp;\n阅读(<span id=\"post_view_count\">225</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "别再手写 URL 解析器了：PHP 8.5 URI 扩展让 URL 处理更安全、更干净",
      "link": "https://www.cnblogs.com/catchadmin/p/19490082",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/catchadmin/p/19490082\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 07:48\">\n    <span>别再手写 URL 解析器了：PHP 8.5 URI 扩展让 URL 处理更安全、更干净</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"别再手写-url-解析器了php-85-uri-扩展让-url-处理更安全更干净\">别再手写 URL 解析器了：PHP 8.5 URI 扩展让 URL 处理更安全、更干净</h1>\n<h2 id=\"parse_url-能用但不够用\">parse_url() 能用，但不够用</h2>\n<p>多年来，PHP 开发者处理 URL 的方式大同小异：</p>\n<ul>\n<li>用 <code>parse_url()</code> 拆分各部分</li>\n<li>用 <code>rawurlencode()</code> / <code>urlencode()</code> 转义</li>\n<li>用字符串拼接重建最终 URL</li>\n<li>遇到\"奇怪\"输入时，再上几个正则</li>\n</ul>\n<p>大多数情况下这套流程能跑通。问题在于，URL 处理恰恰是那种\"在边角情况下出问题\"的领域：编码、fragment、userinfo、国际化域名、\"等价但不相同\"的 URL，以及各种只在生产日志里才冒出来的边缘场景。</p>\n<p>PHP 8.5 提供了一个内置替代方案：一个始终可用的 URI 扩展，提供 API 来按照 RFC 3986 和 WHATWG URL 标准解析、修改 URL/URI。</p>\n<p>如果\"标准\"二字让你觉得抽象，这里给出实际含义：</p>\n<ul>\n<li>拿到 URI/URL 对象，而不是数组 + 字符串拼接。</li>\n<li>用安全的组件 getter 和不可变的 <code>with*()</code> 方法。</li>\n<li>你可以选择 RFC 3986 行为（严格 URI，\"原始 vs 规范化解码\"）或浏览器风格的 WHATWG 行为（Unicode/IDNA、软错误、自动编码）。</li>\n</ul>\n<p>本文是一篇实战教程，重点讲：</p>\n<ul>\n<li>为什么手动解析容易出错，</li>\n<li>新 URI 对象怎么用，</li>\n<li>如何安全地修改/规范化，</li>\n<li>在重定向、签名链接等安全敏感场景下如何使用。</li>\n</ul>\n<p>不讲升级指南，不讲废弃清单——只讲 URI 扩展。</p>\n<p><a href=\"https://catchadmin.com/post/2026-01/php85-uri-extension-safer-cleaner-urls\" rel=\"noopener nofollow\" target=\"_blank\">原文 别再手写 URL 解析器了：PHP 8.5 URI 扩展让 URL 处理更安全、更干净</a></p>\n<h2 id=\"手动-url-解析的问题\">手动 URL 解析的问题</h2>\n<h3 id=\"parse_url-不解码而且很容易忘\">parse_url() 不解码（而且很容易忘）</h3>\n<p>PHP 的 <code>parse_url()</code> 返回各组件，但<strong>不会</strong> URL 解码它们。</p>\n<p>也就是说：</p>\n<pre><code class=\"language-php\">$u = parse_url(\"https://example.com/t%65st?name=Ali%63e#fr%61g\");\nvar_dump($u['path']);   // \"/t%65st\"\nvar_dump($u['query']);  // \"name=Ali%63e\"\nvar_dump($u['fragment']); // \"fr%61g\"\n</code></pre>\n<p>如果你在比较路径或应用路由规则时没有统一解码/规范化，可能会把等价的 URI 当成不同的来处理。</p>\n<p>更糟的是：团队往往混用：</p>\n<ul>\n<li>有些地方用解码后的值，</li>\n<li>有些地方用原始值，</li>\n<li>再加上散落在各处的临时解码逻辑。</li>\n</ul>\n<p>这种混乱很容易埋下隐蔽 bug 和安全隐患。</p>\n<h3 id=\"字符串拼接容易拼出差一点对的-url\">字符串拼接容易拼出\"差一点对\"的 URL</h3>\n<p>手动重建 URL 容易犯的错：</p>\n<ul>\n<li>漏掉 <code>?</code> 或 <code>#</code></li>\n<li>重复编码</li>\n<li>完全没编码</li>\n<li>编码错了东西（比如把整个 query string 编码而不是只编码 value）</li>\n<li>丢失或打乱参数顺序</li>\n<li>空 query/fragment 处理不当</li>\n</ul>\n<p>一个常见的\"差一点对\"函数：</p>\n<pre><code class=\"language-php\">function addQueryParam(string $url, string $key, string $value): string\n{\n    $parts = parse_url($url);\n    $query = $parts['query'] ?? '';\n    $query .= ($query === '' ? '' : '&amp;') . $key . '=' . urlencode($value);\n    $out = $parts['scheme'] . '://' . $parts['host'] . ($parts['path'] ?? '');\n    if ($query !== '') {\n        $out .= '?' . $query;\n    }\n    if (isset($parts['fragment'])) {\n        $out .= '#' . $parts['fragment'];\n    }\n    return $out;\n}\n</code></pre>\n<p>看起来没问题。直到遇到：</p>\n<ul>\n<li>没有 scheme/host 的 URL（相对 URL），</li>\n<li>带 userinfo/port 的 URL，</li>\n<li>已经编码过的值，</li>\n<li>需要 <code>rawurlencode()</code> 规则（RFC 3986）的参数，</li>\n<li>应该原样保留的 fragment。</li>\n</ul>\n<h3 id=\"等价的-url-不一定是相同的字符串\">等价的 URL 不一定是相同的字符串</h3>\n<p>下面这些可以指向同一个资源，但字符串不同：</p>\n<ul>\n<li>scheme/host 大小写不同（<code>HTTPS://EXAMPLE.com</code>）</li>\n<li>path 中 <code>%65</code> vs <code>e</code>（<code>/t%65st</code> vs <code>/test</code>）</li>\n<li>path 中的点号段（<code>/foo/../bar/</code>）</li>\n<li>默认端口（https 的 <code>:443</code>）</li>\n</ul>\n<p>如果你把 URL 当成纯字符串处理，要么：</p>\n<ul>\n<li>缓存/路由出现诡异问题，</li>\n<li>要么安全检查被绕过，因为你比较的是\"错误的表示形式\"。</li>\n</ul>\n<h3 id=\"idna国际化域名还涉及安全问题\">IDNA（国际化域名）还涉及安全问题</h3>\n<p>如果你允许用户提交 URL，国际化域名可能是合法的——但也可能造成混淆。域名可以用 Unicode 或 punycode（ASCII 形式）表示。RFC 讨论中明确指出人为风险：punycode 域名在 Unicode 渲染时可能看起来像一个熟悉的、但实际不同的域名。</p>\n<p>这不是你想用正则\"手动处理\"然后祈祷没问题的事。</p>\n<h2 id=\"uri-扩展的概念uri-对象--两套标准\">URI 扩展的概念：URI 对象 + 两套标准</h2>\n<p>PHP 8.5 的 URI 扩展提供两个主要类：</p>\n<ul>\n<li><code>Uri\\Rfc3986\\Uri</code>（RFC 3986 合规，严格 URI 规则）</li>\n<li><code>Uri\\WhatWg\\Url</code>（WHATWG URL 合规，浏览器风格的 URL 规则）</li>\n</ul>\n<p>配套的类型包括：</p>\n<ul>\n<li><code>Uri\\InvalidUriException</code></li>\n<li><code>Uri\\WhatWg\\InvalidUrlException</code></li>\n<li><code>Uri\\WhatWg\\UrlValidationError</code> 和 <code>UrlValidationErrorType</code></li>\n<li><code>Uri\\UriComparisonMode</code>（用于比较）</li>\n</ul>\n<p>一个关键设计决策：两个实现都是 readonly 且以不可变方式使用——<code>withPath()</code>、<code>withQuery()</code> 等方法返回新实例。</p>\n<p>另一个要点：这个扩展在 PHP 8.5 中始终可用，底层由以下库驱动：</p>\n<ul>\n<li>uriparser（用于 RFC 3986）</li>\n<li>Lexbor（用于 WHATWG URL）</li>\n</ul>\n<p>所以你不需要第三方库就能获得合理的 URL 处理能力。</p>\n<h2 id=\"创建和解析-uri从字符串到组件\">创建和解析 URI：从字符串到组件</h2>\n<h3 id=\"最简单的情况解析一个-http-url-并访问各部分\">最简单的情况：解析一个 HTTP URL 并访问各部分</h3>\n<p>RFC 3986：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\n$uri = new Uri(\"https://php.net/releases/8.5/en.php\");\n\necho $uri-&gt;getScheme(); // \"https\"\necho $uri-&gt;getHost();   // \"php.net\"\necho $uri-&gt;getPath();   // \"/releases/8.5/en.php\"\n</code></pre>\n<p>WHATWG：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\n$url = new Url(\"https://example.com/path?query=1#frag\");\n\necho $url-&gt;getScheme();      // \"https\"\necho $url-&gt;getAsciiHost();   // \"example.com\"\necho $url-&gt;getPath();        // \"/path\"\necho $url-&gt;getQuery();       // \"query=1\"\necho $url-&gt;getFragment();    // \"frag\"\n</code></pre>\n<p>注意：WHATWG 的 getter 故意不返回分隔符（如 <code>:</code> <code>/</code> <code>?</code> <code>#</code>）。</p>\n<h3 id=\"构造函数抛异常parse-返回-null\">构造函数抛异常；parse() 返回 null</h3>\n<p>两个实现都支持两种解析风格：</p>\n<ul>\n<li>构造函数：无效时抛异常</li>\n<li><code>parse()</code>：无效时返回 null</li>\n</ul>\n<p>RFC 3986 行为：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\nuse Uri\\InvalidUriException;\n\ntry {\n    $uri = new Uri(\"not a uri\");\n} catch (InvalidUriException $e) {\n    // 拒绝输入\n}\n\n$uri = Uri::parse(\"not a uri\");\nvar_dump($uri); // null\n</code></pre>\n<p>WHATWG 行为提供更丰富的错误信息：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\nuse Uri\\WhatWg\\InvalidUrlException;\n\ntry {\n    $url = new Url(\"invalid url\");\n} catch (InvalidUrlException $e) {\n    // $e-&gt;errors 包含 UrlValidationError 实例\n}\n\n$errors = [];\n$url = Url::parse(\"invalid url\", null, $errors);\nvar_dump($url);    // null\nvar_dump($errors); // UrlValidationError 数组\n</code></pre>\n<p>这种区分（硬错误 vs 软错误 vs parse-and-return-null）在 RFC 中有详细说明。</p>\n<h3 id=\"base-url-和引用解析相对--绝对\">Base URL 和引用解析（相对 → 绝对）</h3>\n<p>有了这个功能，你不再需要手动检查是否以 <code>/</code> 开头然后拼接。</p>\n<p>在构造函数或 <code>parse()</code> 中使用 base URL：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\n$base = new Uri(\"https://example.com\");\n$uri  = new Uri(\"/foo\", $base);\n\necho $uri-&gt;toString(); // \"https://example.com/foo\"\n</code></pre>\n<p>WHATWG 类似：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\n$base = new Url(\"https://example.com\");\n$url  = Url::parse(\"/foo\", $base);\n\necho $url-&gt;toAsciiString(); // \"https://example.com/foo\"\n</code></pre>\n<p>扩展还提供了便捷的 <code>resolve()</code> 方法，以当前对象作为 base。</p>\n<h2 id=\"安全修改设置替换-pathqueryfragment不可变\">安全修改：设置/替换 path、query、fragment（不可变）</h2>\n<p>拿到对象后，可以用 <code>with*()</code> 方法修改组件。这些方法返回新实例，原对象保持不变。</p>\n<h3 id=\"rfc-3986withpathwithquerywithfragment\">RFC 3986：withPath()、withQuery()、withFragment()</h3>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\n$uri = new Uri(\"https://example.com/products?sort=asc#top\");\n\n$updated = $uri\n    -&gt;withPath(\"/products/123\")\n    -&gt;withQuery(\"sort=desc&amp;ref=home\")\n    -&gt;withFragment(\"reviews\");\n\necho $uri-&gt;toString();     // 原对象不变\necho $updated-&gt;toString(); // 修改后的\n</code></pre>\n<p>RFC 3986 提供\"原始\"和\"规范化解码\"两种 getter（下一节详述），以及 <code>toString()</code> 和 <code>toRawString()</code> 方法。</p>\n<h3 id=\"whatwg同样的思路外加-asciiunicode-字符串输出\">WHATWG：同样的思路，外加 ASCII/Unicode 字符串输出</h3>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\n$url = new Url(\"https://example.com/\");\n\n$new = $url\n    -&gt;withPath(\"/search\")\n    -&gt;withQuery(\"q=php+8.5\")\n    -&gt;withFragment(\"results\");\n\necho $new-&gt;toAsciiString();\necho $new-&gt;toUnicodeString();\n</code></pre>\n<p>WHATWG 有 <code>toAsciiString()</code> 和 <code>toUnicodeString()</code> 两种输出，分别用于机器处理和人类展示。</p>\n<h3 id=\"一个小但重要的行为输入中的分隔符\">一个小但重要的行为：输入中的分隔符</h3>\n<p>使用 WHATWG 时，如果你在设置 query/fragment 时不小心包含了 <code>?</code> 或 <code>#</code>，它会把它们当作分隔符并去掉：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\n$url = new Url(\"https://example.com/\");\n$url = $url-&gt;withQuery(\"?foo\");\n$url = $url-&gt;withFragment(\"#bar\");\n\necho $url-&gt;getQuery();    // \"foo\"\necho $url-&gt;getFragment(); // \"bar\"\n</code></pre>\n<p>这个行为在文档中有明确说明。</p>\n<h2 id=\"规范化与编码避免重复编码和奇怪字符\">规范化与编码：避免重复编码和\"奇怪字符\"</h2>\n<p>URI 扩展的价值不止于 API 设计——它让你能控制 URL 的表示形式。</p>\n<h3 id=\"rfc-3986-给你两种表示原始-vs-规范化解码\">RFC 3986 给你两种表示：原始 vs 规范化解码</h3>\n<p>对于大多数组件，<code>Uri\\Rfc3986\\Uri</code> 暴露：</p>\n<ul>\n<li>raw：解析器给出的形式（最接近原始输入）</li>\n<li>规范化解码：规范化 + 百分号解码，意在成为规范形式且可往返转换</li>\n</ul>\n<p>RFC 解释了为什么需要两种形式以及何时使用——签名方和 API 客户端通常偏好 raw，而路由/缓存通常偏好规范化解码。</p>\n<p>具体效果：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\n$uri = new Uri(\"https://%61pple:p%61ss@ex%61mple.com:433/foob%61r?%61bc=%61bc#%61bc\");\n\necho $uri-&gt;getRawHost(); // \"ex%61mple.com\"\necho $uri-&gt;getHost();    // \"example.com\"\n\necho $uri-&gt;getRawPath(); // \"/foob%61r\"\necho $uri-&gt;getPath();    // \"/foobar\"\n\necho $uri-&gt;getRawQuery(); // \"%61bc=%61bc\"\necho $uri-&gt;getQuery();    // \"abc=abc\"\n</code></pre>\n<p>规范化示例：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\n$uri = new Uri(\"HTTPS://EXAMPLE.COM/foo/../bar/\");\n\necho $uri-&gt;getRawScheme(); // \"HTTPS\"\necho $uri-&gt;getScheme();    // \"https\"\n\necho $uri-&gt;getRawHost(); // \"EXAMPLE.COM\"\necho $uri-&gt;getHost();    // \"example.com\"\n\necho $uri-&gt;getRawPath(); // \"/foo/../bar/\"\necho $uri-&gt;getPath();    // \"/bar/\"\n</code></pre>\n<h3 id=\"whatwg-在修改时自动编码某些字符\">WHATWG 在修改时自动编码某些字符</h3>\n<p>如果你设置的 path 包含该组件必须百分号编码的字符，WHATWG 会自动编码：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\n$url = new Url(\"https://example.com\");\n$url = $url-&gt;withPath(\"/?#:\");\n\necho $url-&gt;getPath(); // \"/%3F%23:\"\n</code></pre>\n<p>这能防止意外构建出损坏的 URL。</p>\n<h3 id=\"重复编码陷阱以及新-api-如何帮忙\">\"重复编码\"陷阱（以及新 API 如何帮忙）</h3>\n<p>重复编码通常这样发生：</p>\n<ol>\n<li>你用 <code>rawurlencode()</code> 编码一个值，因为\"它要放进 URL\"</li>\n<li>你手动把它加到 query string</li>\n<li>后来某处又编码了一次（框架、代理、客户端）</li>\n</ol>\n<p>使用 URI 对象，一个好做法是：</p>\n<ul>\n<li>数据保持为普通字符串（未编码）</li>\n<li>用 <code>http_build_query()</code> 构建 query（或你偏好的编码器）</li>\n<li>把结果传给 <code>withQuery()</code></li>\n</ul>\n<p>示例：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\n$base = new Uri(\"https://example.com/search\");\n\n$params = [\n    'q' =&gt; 'php 8.5 uri',\n    'tag' =&gt; 'url/encoding',\n];\n\n// RFC 3986 风格编码（空格用 %20 而非 +）\n$query = str_replace('+', '%20', http_build_query($params));\n\n$uri = $base-&gt;withQuery($query);\necho $uri-&gt;toString();\n</code></pre>\n<p><code>http_build_query()</code> 不一定适合所有场景，但好处是编码规则集中在一处，而非散落在各种字符串拼接里。</p>\n<p>如果确实需要对 path 段进行 RFC 3986 原始编码，PHP 的 <code>rawurlencode()</code> 遵循 RFC 3986 规则。</p>\n<h2 id=\"验证用户输入的-url实用的最低规则\">验证用户输入的 URL：实用的最低规则</h2>\n<p>如果输入来自用户（或不可信来源），验证应该有明确的立场。</p>\n<p>对于你打算 fetch 或跳转的 URL，一个务实的安全导向模式：</p>\n<ul>\n<li>必须解析成功（硬错误直接拒绝）</li>\n<li>只允许 http / https</li>\n<li>URL 中不能有用户名/密码</li>\n<li>域名白名单（用 ASCII 形式比较）</li>\n<li>可选：限制端口</li>\n<li>可选：要求绝对 URL（或相对 URL 基于已知 base 解析）</li>\n</ul>\n<h3 id=\"严格验证-helperwhatwg-版本\">严格验证 helper（WHATWG 版本）</h3>\n<p>WHATWG 适合处理\"浏览器风格\"URL 和 IDNA。</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\nuse Uri\\WhatWg\\InvalidUrlException;\n\nfunction validateExternalUrl(string $input, array $allowedHosts): Url\n{\n    try {\n        $softErrors = [];\n        $url = new Url($input, null, $softErrors);\n    } catch (InvalidUrlException $e) {\n        throw new InvalidArgumentException(\"Invalid URL.\");\n    }\n\n    // Scheme 白名单\n    $scheme = $url-&gt;getScheme();\n    if (!in_array($scheme, ['http', 'https'], true)) {\n        throw new InvalidArgumentException(\"Unsupported scheme.\");\n    }\n\n    // 禁止凭证\n    if ($url-&gt;getUsername() !== null || $url-&gt;getPassword() !== null) {\n        throw new InvalidArgumentException(\"Credentials in URL are not allowed.\");\n    }\n\n    // Host 白名单（ASCII 比较）\n    $host = $url-&gt;getAsciiHost();\n    if ($host === null || !in_array(strtolower($host), $allowedHosts, true)) {\n        throw new InvalidArgumentException(\"Host not allowed.\");\n    }\n\n    // 可选：端口限制\n    $port = $url-&gt;getPort();\n    if ($port !== null &amp;&amp; !in_array($port, [80, 443], true)) {\n        throw new InvalidArgumentException(\"Port not allowed.\");\n    }\n\n    return $url;\n}\n</code></pre>\n<p>几点说明：</p>\n<ul>\n<li><code>Url</code> 即使解析成功也可能返回软错误。RFC 解释了\"软 vs 硬\"模型，并给出了解析继续但报告验证错误的例子。</li>\n<li>WHATWG 同时暴露 <code>getAsciiHost()</code> 和 <code>getUnicodeHost()</code>；比较通常用 ASCII，展示用 Unicode。</li>\n</ul>\n<h3 id=\"rfc-3986-验证严格-uri-解析--规范化选项\">RFC 3986 验证：严格 URI 解析 + 规范化选项</h3>\n<p>如果你在验证通用 URI（不只是 HTTP URL），或者你关心 raw vs 规范化解码的表示，<code>Uri\\Rfc3986\\Uri</code> 是个好选择。</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\nuse Uri\\InvalidUriException;\n\nfunction validateHttpUri(string $input, array $allowedHosts): Uri\n{\n    try {\n        $uri = new Uri($input);\n    } catch (InvalidUriException $e) {\n        throw new InvalidArgumentException(\"Invalid URI.\");\n    }\n\n    $scheme = $uri-&gt;getScheme();\n    if (!in_array($scheme, ['http', 'https'], true)) {\n        throw new InvalidArgumentException(\"Unsupported scheme.\");\n    }\n\n    // Userinfo 在大多数 Web 应用中是个坑\n    if ($uri-&gt;getUserInfo() !== null) {\n        throw new InvalidArgumentException(\"Userinfo is not allowed.\");\n    }\n\n    $host = $uri-&gt;getHost();\n    if ($host === null || !in_array(strtolower($host), $allowedHosts, true)) {\n        throw new InvalidArgumentException(\"Host not allowed.\");\n    }\n\n    return $uri;\n}\n</code></pre>\n<h2 id=\"实际用例签名链接安全重定向规范-url\">实际用例：签名链接、安全重定向、规范 URL</h2>\n<h3 id=\"用例签名链接而不破坏编码\">用例：签名链接而不破坏编码</h3>\n<p>签名 URL（HMAC token、临时访问链接、CDN 认证）对表示形式极其敏感。一个小的\"规范化变更\"就能使签名失效。</p>\n<p>这也是 RFC 明确指出\"API 客户端或签名方\"通常偏好原始表示的原因。</p>\n<p>一个简单的签名 URL 方法：</p>\n<ol>\n<li>构建 URL</li>\n<li>对稳定的字符串表示计算签名</li>\n<li>把签名作为 query 参数加进去</li>\n</ol>\n<p>示例，使用 RFC 3986 和 <code>toRawString()</code> 签名：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\nfunction signUri(Uri $uri, string $secret): Uri\n{\n    // 当你想避免意外转换时，用 raw string\n    $baseString = $uri-&gt;toRawString();\n    $sig = hash_hmac('sha256', $baseString, $secret);\n\n    $query = $uri-&gt;getRawQuery();\n    $query = $query ? $query . '&amp;' : '';\n    $query .= 'sig=' . rawurlencode($sig);\n\n    return $uri-&gt;withQuery($query);\n}\n\n$uri = new Uri(\"https://download.example.com/file/%2Fsafe?expires=1736035200\");\n$signed = signUri($uri, \"super-secret-key\");\n\necho $signed-&gt;toRawString();\n</code></pre>\n<p>两个要点：</p>\n<ul>\n<li>你是故意选择 raw 的，因为签名关心的是\"线上实际发送的是什么\"。</li>\n<li>query 构建仍然要小心，避免编码错误。</li>\n</ul>\n<p>如果你的签名算法需要规范形式（有些确实需要），可以故意对 <code>toString()</code> 签名——但要知道自己在做什么，而不是意外这么做。</p>\n<h3 id=\"用例安全重定向避免开放重定向--解析混淆\">用例：安全重定向（避免开放重定向 + 解析混淆）</h3>\n<p>安全重定向问题通常长这样：</p>\n<ol>\n<li>你有 <code>/login?next=&lt;something&gt;</code></li>\n<li>登录后跳转到 next</li>\n<li>攻击者尝试 <code>next=https://evil.com</code> 或各种变体</li>\n</ol>\n<p>一个健壮的模式是：</p>\n<ol>\n<li>把用户输入解析为相对 URL 或绝对 URL</li>\n<li>相对 URL 基于你自己的已知 base 解析</li>\n<li>验证 host/scheme 是你的（或在允许列表中）</li>\n</ol>\n<p>使用 WHATWG：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\nfunction safeRedirectTarget(string $next, string $appBase): string\n{\n    $base = new Url($appBase);\n\n    // 安全解析相对引用\n    $errors = [];\n    $resolved = Url::parse($next, $base, $errors);\n\n    if ($resolved === null) {\n        return $base-&gt;toAsciiString(); // fallback\n    }\n\n    // 只允许同 host\n    if (strtolower($resolved-&gt;getAsciiHost() ?? '') !== strtolower($base-&gt;getAsciiHost() ?? '')) {\n        return $base-&gt;toAsciiString();\n    }\n\n    // 只允许 http/https\n    if (!in_array($resolved-&gt;getScheme(), ['http', 'https'], true)) {\n        return $base-&gt;toAsciiString();\n    }\n\n    return $resolved-&gt;toAsciiString();\n}\n\necho safeRedirectTarget(\"/dashboard\", \"https://app.example.com\");\n</code></pre>\n<p>这里用到了 base URL 解析和引用解析功能。</p>\n<h3 id=\"用例规范-urlseo-和缓存的一致表示\">用例：规范 URL（SEO 和缓存的一致表示）</h3>\n<p>规范化通常意味着：</p>\n<ul>\n<li>scheme/host 小写</li>\n<li>移除 path 中的点号段</li>\n<li>移除默认端口</li>\n<li>query 保持一致（有时排序）</li>\n<li>决定如何处理末尾斜杠</li>\n</ul>\n<p>使用 <code>Uri\\Rfc3986\\Uri</code>，你已经可以通过 <code>get*()</code> vs <code>getRaw*()</code>（以及 <code>toString()</code> vs <code>toRawString()</code>）清晰地获得规范化行为。</p>\n<p>一个简单的规范化示例：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\n\nfunction canonicalizeForCache(Uri $uri): Uri\n{\n    // 从规范化解码的部分开始\n    $uri = $uri\n        -&gt;withScheme($uri-&gt;getScheme())\n        -&gt;withHost($uri-&gt;getHost())\n        -&gt;withPath($uri-&gt;getPath());\n\n    // 为缓存 key 排序 query 参数（这是一种策略选择）\n    $query = $uri-&gt;getQuery();\n    if ($query) {\n        parse_str($query, $params);\n        ksort($params);\n        $sorted = http_build_query($params, '', '&amp;', PHP_QUERY_RFC3986);\n        $uri = $uri-&gt;withQuery($sorted);\n    }\n\n    return $uri;\n}\n\n$u = new Uri(\"HTTPS://EXAMPLE.COM/foo/../bar/?b=2&amp;a=1\");\necho canonicalizeForCache($u)-&gt;toString();\n</code></pre>\n<p>这个函数不试图覆盖所有规范化策略（那是应用层面的事），但结构化 API 的好处是：规则可以显式构建、可以测试。</p>\n<h2 id=\"从-parse_url--字符串拼接迁移不痛苦\">从 parse_url() + 字符串拼接迁移（不痛苦）</h2>\n<p>你不需要一次性重写所有代码。最简单的迁移路径是：</p>\n<p><strong>1. 找出 URL 处理对安全敏感或容易出 bug 的地方：</strong></p>\n<ul>\n<li>重定向</li>\n<li>webhook 验证</li>\n<li>签名 URL</li>\n<li>域名白名单</li>\n<li>路由/缓存 key</li>\n</ul>\n<p><strong>2. 先替换这些。</strong></p>\n<p><strong>3. 纯展示用途的简单解析，等到有必要时再处理。</strong></p>\n<h3 id=\"迁移前数组解析--手动重建\">迁移前：数组解析 + 手动重建</h3>\n<pre><code class=\"language-php\">$parts = parse_url($input);\n$host  = $parts['host'] ?? null;\n\nif ($host !== 'example.com') {\n    throw new Exception(\"Bad host\");\n}\n\n$newUrl = $parts['scheme'] . '://' . $parts['host'] . '/new-path';\n</code></pre>\n<p>问题：</p>\n<ul>\n<li>没处理 port、userinfo、fragment、相对 URL</li>\n<li>没有规范化</li>\n<li>没有规范化选择</li>\n<li>容易构建出无效输出</li>\n</ul>\n<h3 id=\"迁移后使用-urluri改动局部化\">迁移后：使用 Url/Uri，改动局部化</h3>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\n\n$url = new Url($input);\n\nif (strtolower($url-&gt;getAsciiHost() ?? '') !== 'example.com') {\n    throw new InvalidArgumentException(\"Bad host\");\n}\n\n$new = $url-&gt;withPath('/new-path');\necho $new-&gt;toAsciiString();\n</code></pre>\n<p>代码更短，意图更明确，细节上更难出错。</p>\n<h3 id=\"rfc-3986-和-whatwg-怎么选经验法则\">RFC 3986 和 WHATWG 怎么选（经验法则）</h3>\n<p><strong>使用 <code>Uri\\WhatWg\\Url</code> 当：</strong></p>\n<ul>\n<li>你在处理来自浏览器/用户的 HTTP(S) URL</li>\n<li>你需要 IDNA/Unicode 域名处理（<code>getUnicodeHost()</code> 用于展示，<code>getAsciiHost()</code> 用于比较）</li>\n<li>你想要 WHATWG 解析行为和错误报告（软错误）</li>\n</ul>\n<p><strong>使用 <code>Uri\\Rfc3986\\Uri</code> 当：</strong></p>\n<ul>\n<li>你在处理\"Web URL\"之外的通用 URI</li>\n<li>你需要 raw vs 规范化解码的表示</li>\n<li>你在做签名或协议层面的工作，表示形式很重要</li>\n</ul>\n<p>RFC 明确区分了这两种方法，包括 Unicode/IDNA 支持的差异。</p>\n<h2 id=\"附加内容正确比较-urlequals-以及为什么没有-__tostring\">附加内容：正确比较 URL（equals() 以及为什么没有 __toString()）</h2>\n<p>一个值得留意的设计：内置 URI 类故意不实现 <code>__toString()</code>，因为松散比较（<code>==</code>）容易出错。</p>\n<p>取而代之，你用 <code>equals()</code> 比较：</p>\n<pre><code class=\"language-php\">use Uri\\Rfc3986\\Uri;\nuse Uri\\UriComparisonMode;\n\n$u1 = new Uri(\"https://example.COM#foo\");\n$u2 = new Uri(\"https://EXAMPLE.COM\");\n\nvar_dump($u1-&gt;equals($u2)); // true\nvar_dump($u1-&gt;equals($u2, UriComparisonMode::IncludeFragment)); // false\n</code></pre>\n<p>WHATWG 类似：</p>\n<pre><code class=\"language-php\">use Uri\\WhatWg\\Url;\nuse Uri\\UriComparisonMode;\n\n$a = new Url(\"https:////example.COM/\");\n$b = new Url(\"https://EXAMPLE.COM\");\n\nvar_dump($a-&gt;equals($b)); // true\n</code></pre>\n<h2 id=\"结论\">结论</h2>\n<p>PHP 8.5 的 URI 扩展看起来是个小功能，用一段时间后才会发现它挡掉了多少细微的 URL bug。</p>\n<p>核心价值在于<strong>控制</strong>：</p>\n<ul>\n<li>你可以选择 RFC 3986 vs WHATWG 语义。</li>\n<li>你可以决定要 raw 还是规范化解码的表示。</li>\n<li>你可以不可变且安全地修改组件。</li>\n<li>你可以用更难意外削弱的方式验证和比较 URL。</li>\n</ul>\n<p>如果你曾经发布过一个\"快速 URL 修复\"，后来在安全报告或生产事故中看到它，这个扩展值得尽早采用——从重定向和签名 URL 开始。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 07:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/catchadmin\">JaguarJack</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MySQL性能优化：从底层原理到实战落地的全维度方案",
      "link": "https://www.cnblogs.com/liuziyi1/p/19489439",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/liuziyi1/p/19489439\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 22:26\">\n    <span>MySQL性能优化：从底层原理到实战落地的全维度方案</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在数据驱动的业务场景中，MySQL作为主流开源关系型数据库，其性能直接决定系统响应速度、吞吐量与运维成本。尤其对于高并发、大数据量的平台（如DeepSeek这类AI服务场景），慢查询与不合理索引设计可能引发系统卡顿甚至雪崩。MySQL性能优化并非零散的“调参改SQL”，而是基于底层原理的系统性工程——既要掌握可落地的实战技巧，更要理解优化背后的核心逻辑，才能实现从“治标”到“治本”的突破。本文将融合底层理论与实战经验，构建“原理认知-问题定位-优化实施-工程保障”的完整体系，助力开发者实现MySQL性能的精准提升。</p>\n<h1 id=\"-一底层逻辑mysql性能的核心支撑与失衡本质\"># 一、底层逻辑：MySQL性能的核心支撑与失衡本质</h1>\n<p>MySQL性能的底层核心是“资源消耗与结构设计的平衡”，所有慢查询与性能瓶颈，本质都是存储结构、资源分配或执行逻辑出现了失衡。</p>\n<h2 id=\"-11-存储引擎核心b树与磁盘io的底层关联\">## 1.1 存储引擎核心：B+树与磁盘IO的底层关联</h2>\n<p>InnoDB作为MySQL默认存储引擎，其核心存储结构为B+树，性能优劣直接由“磁盘IO次数”决定。B+树的设计特性决定了查询效率的上限：</p>\n<ul>\n<li>\n<p>- 结构特性：B+树为平衡树，叶子节点存储全量数据，非叶子节点仅存储索引键与指针；单页大小默认16KB，高度通常为1-3层，高度3的B+树可存储约2000万行数据。</p>\n</li>\n<li>\n<p>- IO成本：每次查询的IO次数=B+树高度+回表次数（非覆盖索引场景）。全表扫描需遍历所有叶子节点，IO次数飙升至百万级，是慢查询的核心诱因。</p>\n</li>\n<li>\n<p>- 缓存价值：InnoDB缓冲池（innodb_buffer_pool）可缓存数据页与索引页，命中率理想值需超过99%，缓存命中可直接避免磁盘IO，大幅提升查询速度。</p>\n</li>\n</ul>\n<h2 id=\"-12-性能核心维度四大资源的消耗平衡\">## 1.2 性能核心维度：四大资源的消耗平衡</h2>\n<p>MySQL性能瓶颈最终可归结为CPU、磁盘IO、内存、锁四大资源的消耗失衡，其中磁盘IO占比最高，是优化的核心靶点：</p>\n<ul>\n<li>\n<p>- CPU：用于SQL解析、排序、分组、函数计算等操作，低效排序与复杂计算易导致CPU过载。</p>\n</li>\n<li>\n<p>- 磁盘IO：数据页/索引页的读取与写入，全表扫描、索引失效是IO消耗激增的主要原因。</p>\n</li>\n<li>\n<p>- 内存：缓冲池缓存数据页，内存不足会导致缓存命中率下降，被迫频繁读取磁盘。</p>\n</li>\n<li>\n<p>- 锁：行锁/表锁引发的查询等待，如更新操作阻塞查询、高并发下的锁竞争，会间接拉长查询耗时。</p>\n</li>\n</ul>\n<h2 id=\"-13-慢查询的本质执行逻辑与资源消耗的双重失衡\">## 1.3 慢查询的本质：执行逻辑与资源消耗的双重失衡</h2>\n<p>慢查询并非“执行时间长”的表面现象，而是底层执行逻辑与资源消耗的双重问题：一是执行计划不合理（如全表扫描、索引失效），导致IO次数过多；二是资源竞争（如锁等待、缓存失效），导致有效执行时间被拉长。优化慢查询，本质就是优化执行计划、减少资源消耗、化解资源竞争。</p>\n<h1 id=\"-二问题定位从慢查询捕捉到执行计划解析\"># 二、问题定位：从慢查询捕捉到执行计划解析</h1>\n<p>精准定位问题是优化的前提，核心依赖“慢查询日志捕捉+执行计划分析”，实现从“发现问题”到“定位根源”的闭环。</p>\n<h2 id=\"-21-慢查询日志性能瓶颈的第一重捕捉\">## 2.1 慢查询日志：性能瓶颈的第一重捕捉</h2>\n<p>慢查询日志是记录低效SQL的核心工具，需合理配置阈值与存储路径，确保精准捕捉关键问题SQL。</p>\n<h3 id=\"-211-日志配置临时生效永久固化\">### 2.1.1 日志配置（临时生效+永久固化）</h3>\n<p>临时配置（重启MySQL后失效，适用于快速排查）：</p>\n<pre><code class=\"language-sql\">-- 设置慢查询阈值（单位：秒，生产环境建议0.5-1秒，平衡灵敏度与日志量）\nSET GLOBAL long_query_time = 0.5; \n-- 开启慢查询日志\nSET GLOBAL slow_query_log = 'ON';\n-- 指定日志文件路径（需确保MySQL有写入权限）\nSET GLOBAL slow_query_log_file = '/var/log/mysql/slow.log';\n-- 记录未使用索引的查询（辅助定位索引失效场景）\nSET GLOBAL log_queries_not_using_indexes = 'ON';\n</code></pre>\n<p>永久配置（修改my.cnf文件，重启后生效，适用于生产环境常态化监控）：</p>\n<pre><code class=\"language-ini\">[mysqld]\nslow_query_log = 1\nslow_query_log_file = /var/log/mysql/slow.log\nlong_query_time = 0.5\nlog_queries_not_using_indexes = 1\n</code></pre>\n<h3 id=\"-212-日志分析工具提取核心问题sql\">### 2.1.2 日志分析工具：提取核心问题SQL</h3>\n<p>慢查询日志需通过工具解析，才能快速定位高频、高耗的核心SQL，常用工具分为两类：</p>\n<ul>\n<li>\n<p>- pt-query-digest（Percona Toolkit）：分析维度最全面，支持输出执行次数、平均耗时、扫描行数、锁等待时间等指标，适合复杂场景： <code>pt-query-digest /var/log/mysql/slow.log &gt; slow_report.txt</code></p>\n</li>\n<li>\n<p>- mysqldumpslow（MySQL自带工具）：轻量便捷，适合快速提取TopN慢查询： <code>-- 提取耗时最多的10条SELECT语句</code> <code>mysqldumpslow -s t -t 10 -g 'select' /var/log/mysql/slow.log</code></p>\n</li>\n</ul>\n<p>分析报告需重点关注“执行次数多+平均耗时长”“扫描行数多”“锁等待时间长”三类SQL，这类SQL对整体性能影响最大，优先纳入优化清单。</p>\n<h2 id=\"-22-explain执行计划读懂mysql的执行逻辑\">## 2.2 EXPLAIN执行计划：读懂MySQL的执行逻辑</h2>\n<p>捕捉到慢查询后，需通过EXPLAIN关键字分析执行计划，判断索引是否生效、查询是否存在低效操作，核心是读懂MySQL的“执行思路”。</p>\n<h3 id=\"-221-核心字段解读\">### 2.2.1 核心字段解读</h3>\n<p>执行<code>EXPLAIN SELECT * FROM orders WHERE user_id = 100 AND status = 'PAID';</code>后，重点关注以下字段：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>字段</td>\n<td>核心意义</td>\n<td>优化判断标准</td>\n</tr>\n<tr>\n<td>type</td>\n<td>访问类型，反映查询效率</td>\n<td>从优到劣：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL；需避免ALL（全表扫描）</td>\n</tr>\n<tr>\n<td>key</td>\n<td>实际使用的索引</td>\n<td>NULL表示未使用索引，需排查索引失效原因</td>\n</tr>\n<tr>\n<td>rows</td>\n<td>预估扫描行数</td>\n<td>数值越大，IO消耗越高，需通过索引缩小范围</td>\n</tr>\n<tr>\n<td>Extra</td>\n<td>附加执行信息</td>\n<td>Using filesort/Using temporary需优化；Using index为理想状态（覆盖索引）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"-222-关键判断逻辑\">### 2.2.2 关键判断逻辑</h3>\n<p>通过执行计划可快速定位核心问题：若type为ALL（全表扫描），优先排查索引是否缺失或失效；若Extra出现Using filesort，说明排序未使用索引，需优化排序字段；若rows远大于实际返回行数，说明索引选择性差，需调整索引设计。</p>\n<h1 id=\"-三核心优化索引设计与失效规避的实战指南\"># 三、核心优化：索引设计与失效规避的实战指南</h1>\n<p>索引是MySQL性能优化的核心手段，其本质是“基于B+树的有序数据结构”，目的是减少磁盘IO次数。优化索引需同时兼顾“设计合理性”与“避免失效”，遵循底层逻辑与实战原则。</p>\n<h2 id=\"-31-索引设计的三大核心原则\">## 3.1 索引设计的三大核心原则</h2>\n<p>索引设计并非“越多越好”，而是要在“查询效率”与“维护成本”之间找到平衡，核心遵循三大原则：</p>\n<h3 id=\"-311-选择性优先原则\">### 3.1.1 选择性优先原则</h3>\n<p>索引选择性=唯一值数量/总行数，选择性越高，索引定位精度越强，IO次数越少。设计时需将高选择性字段（如用户ID、订单号）放在联合索引前列，低选择性字段（如性别、状态，选择性&lt;0.1）尽量不单独建索引，避免优化器放弃使用。</p>\n<h3 id=\"-312-三星索引原则实战核心\">### 3.1.2 三星索引原则（实战核心）</h3>\n<p>三星索引是理想的索引设计标准，可最大化减少IO与计算消耗：</p>\n<ul>\n<li>\n<p>- 一星：WHERE条件列纳入索引，缩小扫描范围；</p>\n</li>\n<li>\n<p>- 二星：ORDER BY/GROUP BY列纳入索引，利用索引有序性避免排序（Using filesort）；</p>\n</li>\n<li>\n<p>- 三星：SELECT查询列被索引覆盖，避免回表操作（Extra显示Using index）。</p>\n</li>\n</ul>\n<p>示例：查询<code>SELECT user_id, username FROM users WHERE email = 'user@deepseek.com';</code>，设计覆盖索引<code>ALTER TABLE users ADD INDEX idx_email_cover (email, user_id, username);</code>，可实现无回表、无排序的高效查询。</p>\n<h3 id=\"-313-最小维护成本原则\">### 3.1.3 最小维护成本原则</h3>\n<p>索引会增加插入、更新、删除操作的维护成本（需调整B+树结构），设计时需：</p>\n<ul>\n<li>\n<p>- 控制单表索引数在5个以内，避免冗余索引（如已有(a,b)联合索引，单独a索引为冗余）；</p>\n</li>\n<li>\n<p>- 大文本、Blob字段不建索引，避免索引体积过大；</p>\n</li>\n<li>\n<p>- 联合索引需覆盖高频查询场景，减少重复索引。</p>\n</li>\n</ul>\n<h3 id=\"-314-联合索引的字段顺序技巧\">### 3.1.4 联合索引的字段顺序技巧</h3>\n<p>联合索引遵循“最左前缀原则”，本质是基于B+树的有序存储特性，设计时需遵循：</p>\n<ul>\n<li>\n<p>- 等值查询字段在前，范围查询字段在后（如(a,b)联合索引，a=1 AND b&gt;10可走索引，b&gt;10则不可）；</p>\n</li>\n<li>\n<p>- 高频查询字段在前，低频字段在后，确保更多查询能命中索引前缀。</p>\n</li>\n</ul>\n<p>示例：查询<code>SELECT * FROM sales WHERE region='Asia' AND category='Tech' AND sale_date BETWEEN '2023-01-01' AND '2023-12-31' ORDER BY revenue DESC;</code>，最优联合索引为<code>idx_region_category_date (region, category, sale_date)</code>。</p>\n<h2 id=\"-32-索引失效的十大典型场景与解决方案\">## 3.2 索引失效的十大典型场景与解决方案</h2>\n<p>索引失效是慢查询的主要诱因，本质是破坏了B+树的有序性或定位规则，以下是实战中最常见的场景及优化方案：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>失效场景</td>\n<td>错误示例</td>\n<td>优化方案</td>\n</tr>\n<tr>\n<td>索引列参与计算/函数</td>\n<td>SELECT * FROM users WHERE YEAR(create_time) = 2023;</td>\n<td>SELECT * FROM users WHERE create_time BETWEEN '2023-01-01' AND '2023-12-31';</td>\n</tr>\n<tr>\n<td>隐式类型转换</td>\n<td>SELECT * FROM logs WHERE user_id = '123'（user_id为INT）;</td>\n<td>SELECT * FROM logs WHERE user_id = 123（匹配字段类型）;</td>\n</tr>\n<tr>\n<td>LIKE以%开头</td>\n<td>SELECT * FROM user WHERE userId LIKE '%123';</td>\n<td>改用覆盖索引或LIKE '123%';</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-01-15 22:26</span>&nbsp;\n<a href=\"https://www.cnblogs.com/liuziyi1\">刘子毅</a>&nbsp;\n阅读(<span id=\"post_view_count\">56</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "CLAUDE.md 全方位指南：构建高效 AI 开发上下文",
      "link": "https://www.cnblogs.com/didispace/p/19489098",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/didispace/p/19489098\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 20:09\">\n    <span>CLAUDE.md 全方位指南：构建高效 AI 开发上下文</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>如果你是 Claude 的日常用户，你一定熟悉这个场景：每次开启一个新的对话，都必须不厌其烦地重复设置项目背景、编码规范和特定的指令。这不仅耗时，也容易出错。当你忘记提醒某个关键细节时，就不得不花更多时间去修复那些不符合规范的代码。</p>\n<p>CLAUDE.md 文件正是解决这一痛点的关键。它就像 Claude 的项目专属记忆，让 AI 在每次对话开始前自动加载并记住你的所有偏好。这是一个简单而强大的功能，但大多数用户仅仅停留在基础层面。</p>\n<p>事实上，要真正释放 CLAUDE.md 的威力，需要掌握一些更深刻、甚至有些违反直觉的技巧。本文将为你揭示其中最关键的五个，帮助你将这个简单的配置文件，转变为一个能够持续进化的项目知识库。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"1-你的-claudemd-应该是一个活的文档而不是一次性配置\">1. 你的 CLAUDE.md 应该是一个“活的文档”，而不是“一次性配置”</h2>\n<p>许多人认为 CLAUDE.md 文件只需在项目开始时配置一次，然后就可以置之不理。这是一个巨大的误区。最有效的 CLAUDE.md 应该随着项目的演进而持续更新和优化。</p>\n<p>最佳的维护方式是在日常工作中“有机地”构建它。例如，当 Claude 做出了一个需要纠正的假设——比如它建议使用 console.log 进行调试，而你的团队规范是使用特定的日志库——不要只是临时修正。直接告诉 Claude：“将‘总是使用日志库而不是 console.log’这条规则添加到我的 CLAUDE.md 文件中。” 这样，你的修正就会沉淀下来，在未来的所有会话中生效。值得注意的是，早期版本的 Claude 有一个 # 快捷键来添加指令，但在 2.0.70 版本后已被移除。目前，直接请求 Claude 进行修改是官方推荐的最佳实践。</p>\n<p>这种做法的价值在于，它能实时捕捉并固化工作流程中的隐性知识。正如一个精妙的比喻所说：</p>\n<p>这就像在会议中做笔记，不同的是，这些笔记真的会被使用。</p>\n<p>更高级的维护方法是将其与团队协作流程结合。在代码审查（Code Review）中发现的未被文档化的规范，正是更新 CLAUDE.md 的绝佳时机。一个由 Boris Cherny 分享的高效工作流是：通过 GitHub Action，你甚至可以直接在 PR 评论中 @claude，让它将新规范添加到 CLAUDE.md 文件中。这创建了一个强大的反馈循环，将团队的集体智慧源源不断地沉淀到这个核心文件中。</p>\n<h2 id=\"2-少即是多上下文是宝贵资源精简至上\">2. 少即是多：上下文是宝贵资源，精简至上</h2>\n<p>人们普遍认为，提供给 AI 的上下文越多，结果就越好。然而在使用 CLAUDE.md 时，这个直觉可能是错误的。</p>\n<p>核心论点是：“上下文是宝贵的（Context is precious）”。CLAUDE.md 中的每一行内容，都在与你当前的工作指令竞争 AI 的注意力。一个臃肿、充满冗余信息的文件，反而可能稀释掉最关键的指令，导致 AI 抓不住重点。<br />\n因此，精简至上。一个很好的起点是使用 /init 命令，它会根据你的项目结构和技术栈生成一个初始文件。我的建议是，以此为基础，然后删除所有你不需要的内容。从现有内容中删除比从零开始创建要容易得多。</p>\n<p>一般建议将文件长度保持在 300 行以下。当然，这并非硬性规定。对于一些具有复杂约定或非寻常模式的 codebase，一个更长的 CLAUDE.md 反而能通过预先加载足够的上下文，有效防止 Claude 做出错误假设。关键在于，文件中的每一行都应该有其明确的价值。毫不留情地删除那些显而易见的废话（例如“请编写高质量代码”）或没有实际指导意义的“填充”信息。</p>\n<p>精简的 CLAUDE.md 迫使你仔细思考并只保留最重要的指令。这不仅能节省宝贵的上下文空间，更能确保 AI 在处理你的请求时，能够更准确地聚焦于核心要求，而不是在大量无关信息中迷失方向。</p>\n<h2 id=\"3-超越单个文件用模块化结构管理复杂性\">3. 超越单个文件：用模块化结构管理复杂性</h2>\n<p>许多用户只知道在项目根目录下创建一个 CLAUDE.md 文件。这对于小型项目来说足够了，但对于大型或结构复杂的项目，存在着更优雅、更强大的模块化管理方式。</p>\n<ul>\n<li>@imports 语法 你可以使用 @path/to/file 语法，从主 CLAUDE.md 文件中引用其他文件的内容。这能让主文件保持简洁，同时将详细的规范拆分到独立的文档中。例如，你可以将复杂的 API 设计模式放在 docs/api-patterns.md 中，然后在主文件里用 @docs/api-patterns.md 引用它。</li>\n<li>.claude/rules/ 目录 这是一个非常适合大型团队的结构。所有放在 .claude/rules/ 目录下的 .md 文件都会被 Claude 自动加载，无需手动 @import。这使得不同领域的团队可以独立维护各自的规则文件，例如，前端团队维护 code-style.md，安全团队维护 security.md。大家各司其职，有效避免了在单个大文件中频繁产生合并冲突。</li>\n<li>子目录中的 CLAUDE.md 对于 Monorepo（单一代码库）项目，这是一个绝佳的解决方案。你可以在项目的特定子目录（例如 api/ 或 packages/ui/）中放置 CLAUDE.md 文件。这些文件非常特殊：它们并不会在会话启动时加载，而只在 Claude 主动处理该特定子目录中的内容时才会被包含进来。这使得你可以为项目的不同模块定义截然不同的规范，实现真正精细化的上下文管理。<br />\n• 个人配置 CLAUDE.local.md 还有一个关键文件：CLAUDE.local.md。它用于存放那些不应提交到版本控制中的个人偏好，例如你习惯的编辑器 quirks 或偏好的代码冗余度。由于这是个人专属的，请务必将其添加到 .gitignore 文件中，以避免将个人配置泄露给整个团队。</li>\n</ul>\n<h2 id=\"4-魔鬼在细节中文件名是区分大小写的\">4. 魔鬼在细节中：文件名是区分大小写的</h2>\n<p>这是一个极其微小但至关重要的技术细节，也是最容易被忽略的陷阱之一：CLAUDE.md 这个文件名是区分大小写的。</p>\n<p>正确的文件名必须是“CLAUDE.md”——CLAUDE 部分为大写，.md 扩展名为小写。如果你将其命名为 claude.md、Claude.md 或其他任何变体，Claude 的系统将无法识别并加载它。</p>\n<p>这个细节之所以重要，是因为它是一个典型的“陷阱”（gotcha）。有趣的是，这一点在官方文档中并未明确说明。我是通过询问官方文档的 AI 助手才最终确认了这一规则。一旦出错，你可能会花费大量时间排查为什么自己精心编写的指令完全没有生效，最终才发现问题出在一个简单的大小写错误上。这个看似微不足道的细节，恰恰体现了与 AI 高效协作时，精确配置的重要性。</p>\n<h2 id=\"5-让-ai-优化-ai定期请-claude-审查自己的说明书\">5. 让 AI 优化 AI：定期请 Claude 审查自己的“说明书”</h2>\n<p>这是一个非常巧妙的“元认知”技巧：定期让 Claude 自己来审查和优化它的“说明书”——CLAUDE.md 文件。</p>\n<p>随着时间的推移，CLAUDE.md 中不可避免地会积累一些过时、冗余甚至相互冲突的指令。通过一个简单的提示，例如“请审查这个 CLAUDE.md 文件，并提出改进建议以使其更清晰、更高效”，你可以利用 Claude 自身的能力来发现这些问题。它可能会建议你合并重复的规则，或澄清模糊的表述。</p>\n<p>对于那些绝对不能违反的关键规则，你可以使用强调词来引起 Claude 的注意，比如 IMPORTANT: 或 YOU MUST。这能提高 Claude 遵循这些指令的概率，但请务必谨慎使用。正如一句古老的建议所说：如果所有东西都被标记为重要，那就没有什么是重要的了。</p>\n<p>诚然，这需要一些维护成本，但其回报是巨大的。正如源文所说：<br />\n这听起来像是维护开销。确实是。但它比在每个会话中重复自己的话，或修复那些忽略了你的规范的代码要省事得多。</p>\n<p>这不仅仅是一种文件维护策略，更是一种与 AI 协作的新范式。我们不再仅仅是 AI 的使用者，更是其成长过程中的引导者，让工具本身参与到自我完善的流程中，形成一个持续改进的良性循环。</p>\n<h2 id=\"结论\">结论</h2>\n<p>CLAUDE.md 远不止一个简单的配置文件。通过本文分享的五个高级技巧——将其视为活文档、保持精简、模块化管理、注意大小写，以及让 AI 自我优化——你可以将其从一个静态的指令列表，转变为一个强大的、与项目共同成长的动态知识库。</p>\n<p>这些策略代表了一种更深层次的思维方式：将你的 AI 上下文本身视为一个“代码库”。它也需要像代码一样被重构、被审查、被持续改进。你的 CLAUDE.md 值得你如此对待。现在，不妨思考一下：你的 CLAUDE.md 中沉淀了多少团队智慧？或许，现在就是开始构建它的最佳时机。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 20:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/didispace\">程序猿DD</a>&nbsp;\n阅读(<span id=\"post_view_count\">49</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。",
      "link": "https://www.cnblogs.com/xiaohui666/p/19489060",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaohui666/p/19489060\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 19:56\">\n    <span>使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。</p>\n<p>&nbsp;</p>\n<p>打开任务管理器查看到 刚启动就 300M 左右，此时页面还正常流畅使用</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115192758334-1287855783.png\" /></p>\n<p>&nbsp;</p>\n<p>当打开浏览器F12控制台时 ，页面卡顿，内存占用直接到达惊人的1547M ,百思不得其解</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193120944-1363009300.png\" /></p>\n<p>&nbsp;</p>\n<p>打开内存面板，查找原因，此时用了706M</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193422895-368120997.png\" /></p>\n<p>&nbsp;</p>\n<p>筛选一下，发现是样式导入重复</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193617511-1308370927.png\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;查看代码有三处地方引用</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193908039-480362363.png\" /></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193912528-202535441.png\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193917151-2133524706.png\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;先注释&nbsp;vite.config.ts 里的</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115194950450-306480391.png\" /></p>\n<p>&nbsp;</p>\n<p>发现内存明显下降，问题解决</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115195104234-699812157.png\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115195120872-371187655.png\" /></p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 19:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaohui666\">小辉。</a>&nbsp;\n阅读(<span id=\"post_view_count\">61</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘",
      "link": "https://www.cnblogs.com/chengzp/p/19488966/stock-dashboard",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/chengzp/p/19488966/stock-dashboard\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 19:06\">\n    <span>我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1265396/202601/1265396-20260115190434191-202601803.png\" />\n        这篇博客介绍了我用 stock-sdk 搭建的 A 股股票看板 stock-dashboard：基于 React + TypeScript + Vite 的纯前端项目，不依赖后端或定时脚本，直接在页面侧拉取行情并完成展示与筛选。文章从数据层封装（SDK 单例、重试、TTL 缓存、服务层统一出口）讲起，再按功能拆解搜索、Dashboard、热力图、板块/个股详情、自选、信号扫描与设置等模块。最后重点分享“一日持股法（尾盘选股）”的全市场扫描思路：先批量拉取 5000+ 行情做基础过滤，再分批拉分时计算强度指标并排序输出候选。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"这是个啥\">这是个啥</h2>\n<p>背景故事很简单：作为一个日常关注行情的“韭菜”，我有一个不太高效的习惯——同时打开无数个看盘软件和网页，在混乱的窗口切换中迷失自我，最终收获的往往只有焦虑，外加浏览器那令人窒息的标签页堆叠。为了彻底治愈这种低效，我决定动手打造一个专属工具：<strong>在一个页面内集成所有高频功能，涵盖实时行情、板块动态、分时走势、K 线分析、资金流向以及筛选器</strong>。</p>\n<p>这就诞生了 <code>stock-dashboard</code>：一个完全基于 React + TypeScript + Vite 技术栈的前端大屏。所有数据直接由 <a href=\"https://stock-sdk.linkdiary.cn/\" rel=\"noopener nofollow\" target=\"_blank\">stock-sdk</a> 驱动，这意味着项目完全摒弃了后端服务，不需要运行任何 Python 定时任务，也不依赖什么“神秘朋友的高端服务器”。纯前端直连数据源，所见即所得，一切都安排得井井有条。</p>\n<p>直接上在线演示链接：<a href=\"https://chengzuopeng.github.io/stock-dashboard/\" rel=\"noopener nofollow\" target=\"_blank\">stock-dashboard</a> （友情提示：摸鱼期间请谨慎使用，建议配合小窗口模式）。<br />\n<img alt=\"stock-overview\" class=\"lazyload\" /></p>\n<h2 id=\"核心解密数据层架构设计\">核心解密：数据层架构设计</h2>\n<p>为了保持代码整洁，我将所有针对 <code>stock-sdk</code> 的调用逻辑都封装在了 <code>src/services/sdk.ts</code> 中。</p>\n<p>这里主要实施了三个既实用又不矫情的工程化策略：</p>\n<ol>\n<li>\n<p><strong>全局单例与自动重试机制</strong><br />\n通过 <code>new StockSDK({ timeout, retry })</code> 初始化实例。面对网络波动或接口偶尔抽风的情况，SDK 内置的自动重试机制（支持最大 3 次重试及指数退避算法）能完美兜底。</p>\n</li>\n<li>\n<p><strong>智能内存缓存（TTL 策略）</strong><br />\n对于行业或概念列表这类变动频率极低的数据（毕竟它们不会在几秒内发生剧变），直接上缓存减少无效请求；而对于实时行情，则设置了 2~3 秒的生存期（TTL），既保证了数据的时效性，又避免了无意义的高频请求轰炸接口。</p>\n</li>\n<li>\n<p><strong>分层隔离：页面仅对接服务层</strong><br />\n翻阅 <code>src/pages/**</code> 下的代码，你几乎找不到 <code>new StockSDK()</code> 的身影。UI 层只负责调用诸如 <code>getFullQuotes / getTodayTimeline / getKlineWithIndicators</code> 等经过二次封装的业务方法，而类型定义则直接复用 <code>stock-sdk</code> 的导出。</p>\n</li>\n</ol>\n<p>顺便展示两段核心代码骨架，后续的所有功能模块皆构建于此基础之上：</p>\n<pre><code class=\"language-ts\">// src/services/sdk.ts\nexport const sdk = new StockSDK({ timeout: 30000, retry: { maxRetries: 3, baseDelay: 1000, maxDelay: 10000, backoffMultiplier: 2 } });\n\nexport async function getFullQuotes(codes: string[], useCache = true) {\n  const key = getCacheKey('getFullQuotes', codes);\n  if (useCache) {\n    return withCache(key, DEFAULT_TTL.quotes, () =&gt; sdk.getFullQuotes(codes));\n  }\n  return sdk.getFullQuotes(codes);\n}\n</code></pre>\n<pre><code class=\"language-ts\">// src/services/sdk.ts\nexport async function getAllAShareQuotes(options?: { batchSize?: number; concurrency?: number; onProgress?: (completed: number, total: number) =&gt; void }) {\n  return sdk.getAllAShareQuotes(options);\n}\n</code></pre>\n<hr />\n<h2 id=\"功能拆解各模块如何玩转-stock-sdk-数据\">功能拆解：各模块如何玩转 stock-sdk 数据？</h2>\n<p>路由配置位于 <code>src/router/index.tsx</code>，而各个功能页面则模块化地分布在 <code>src/pages/*</code> 目录下。接下也就是大家最关心的——按“用户交互路径”来逐一复盘。</p>\n<h3 id=\"1-全局搜索告别手动翻代码的痛苦\">1) 全局搜索：告别手动翻代码的痛苦</h3>\n<p>搜索栏组件位于 <code>src/components/layout/Header.tsx</code>，其背后的魔法仅需一行代码：</p>\n<ul>\n<li><code>search(keyword)</code> 映射到 <code>stock-sdk</code> 的 <code>sdk.search(keyword)</code></li>\n</ul>\n<p>为了优化体验，我添加了 300ms 的输入防抖处理。搜索结果完美支持个股与板块的混合查询，点击即达：</p>\n<ul>\n<li>行业板块跳转至：<code>/boards/industry/:code</code></li>\n<li>概念板块跳转至：<code>/boards/concept/:code</code></li>\n<li>个股详情跳转至：<code>/s/:code</code></li>\n</ul>\n<p>顺手还利用 localStorage 实现了一个简单的历史记录功能（<code>src/services/storage.ts</code>），毕竟很多时候，我们寻找的不是新标的，而是昨天没看完的那个它。</p>\n<hr />\n<h3 id=\"2-仪表盘-dashboard行情概览与自选速览\">2) 仪表盘 Dashboard：行情概览与自选速览</h3>\n<p>对应页面文件：<code>src/pages/Dashboard/Dashboard.tsx</code>。</p>\n<p>数据获取逻辑非常直白粗暴：</p>\n<ul>\n<li>指数行情：调用 <code>getFullQuotes(MAIN_INDICES)</code> 一次性获取上证、深成指、科创 50 等关键指数。</li>\n<li>板块概况：并行调用 <code>getIndustryList()</code> 和 <code>getConceptList()</code>。</li>\n<li>自选股预览：先从存储服务 <code>src/services/storage.ts</code> 读取自选列表，再通过 <code>getFullQuotes(watchlistCodes.slice(0, 50))</code> 批量获取前 50 只行情的快照。</li>\n</ul>\n<p>为了保证数据的鲜活度，配合 <code>usePolling</code> Hook（<code>src/hooks/usePolling.ts</code>）实现了每 5 秒自动轮询。贴心的是，当页面处于后台不可见状态时，轮询会自动挂起，绝不浪费你的浏览器资源。</p>\n<p>额外提一句：目前 Dashboard 上的“榜单”主要展示板块数据。如果想做全市场的个股排名，技术路径完全可以参考后面提到的“一日持股法”，也就是直接利用 <code>getAllAShareQuotes</code> 接口。</p>\n<hr />\n<h3 id=\"3-市场热力图-heatmap一图看懂资金流向\">3) 市场热力图 Heatmap：一图看懂资金流向</h3>\n<p><img alt=\"stock-heatmap\" class=\"lazyload\" /></p>\n<p>实现文件位于 <code>src/pages/Heatmap/Heatmap.tsx</code>，底层依赖 ECharts 的矩形树图（Treemap）。</p>\n<p>根据观察视角的不同，数据源也各异：</p>\n<ul>\n<li>行业视角：直接用 <code>getIndustryList()</code>，因为返回的数据中已经包含了涨跌幅、换手率及领涨股信息。</li>\n<li>概念视角：同理，调用 <code>getConceptList()</code>。</li>\n<li>自选视角：获取所有自选代码 <code>getAllWatchlistCodes()</code> 后，通过 <code>getAllQuotesByCodes(codes.slice(0, topK))</code> 批量拉取。</li>\n</ul>\n<p>至于“全市场个股”热力图（代码预留了接口，暂未开启），实现逻辑也不复杂：</p>\n<ol>\n<li>通过 <code>getIndustryConstituents(industryCode)</code> 获取特定板块成分股。</li>\n<li>用 <code>getAllQuotesByCodes(stockCodes)</code> 把行情数据补齐。</li>\n<li>最后组装数据喂给 Treemap 组件。</li>\n</ol>\n<p>热力图最大的魅力在于：<strong>告别枯燥的数字列表，红绿相间的色块让你瞬间洞察市场强弱结构。</strong></p>\n<hr />\n<h3 id=\"4-龙虎榜-rankings观察市场风向标\">4) 龙虎榜 Rankings：观察市场风向标</h3>\n<p><img alt=\"stock-leaderboard\" class=\"lazyload\" /></p>\n<p>页面路径：<code>src/pages/Rankings/Rankings.tsx</code>。</p>\n<p>实现方式属于“简单粗暴且有效”：</p>\n<ul>\n<li>并行获取 <code>getIndustryList()</code> 和 <code>getConceptList()</code>。</li>\n<li>前端直接根据 <code>changePercent</code>（涨跌幅）或 <code>turnoverRate</code>（换手率）进行排序，截取 Top 50。</li>\n</ul>\n<p>目前的榜单本质上是“板块排行榜”。如果未来要扩展到全市场个股排行，技术方案与后文的“选股器”一致。</p>\n<hr />\n<h3 id=\"5-板块透视追踪领涨先锋\">5) 板块透视：追踪领涨先锋</h3>\n<p>板块列表页位于 <code>src/pages/Boards/Boards.tsx</code>：</p>\n<ul>\n<li><code>getIndustryList()</code> 与 <code>getConceptList()</code> 一把梭。</li>\n<li>所谓的 Tab 切换，仅仅是前端对不同数据源数组的渲染切换。</li>\n<li>当然也支持按板块名称或领涨股进行检索。</li>\n</ul>\n<p>详情页见 <code>src/pages/Boards/BoardDetail.tsx</code>，这里展示了 API 的组合拳能力（按行业/概念分流）：</p>\n<ul>\n<li>基础信息：直接复用列表数据，减少一次网络请求。</li>\n<li>成分股列表：调用 <code>getIndustryConstituents(code)</code> 或 <code>getConceptConstituents(code)</code>。</li>\n<li>板块走势：拉取 <code>getIndustryKline</code> 或 <code>getConceptKline</code>。</li>\n<li>盘口快照：通过 <code>getIndustrySpot</code> 或 <code>getConceptSpot</code> 获取。</li>\n</ul>\n<p>为了保证流畅度，板块 K 线图目前只截取了最近 60 根数据，防止缩放图表时浏览器渲染压力过大。</p>\n<hr />\n<h3 id=\"6-自选监控-watchlist只看我在意的\">6) 自选监控 Watchlist：只看我在意的</h3>\n<p>核心页面：<code>src/pages/Watchlist/Watchlist.tsx</code>。所有的增删改查逻辑都封装在 <code>src/services/storage.ts</code> 中。</p>\n<p>行情刷新主要依赖：</p>\n<ul>\n<li><code>getAllQuotesByCodes(normalizedActiveCodes)</code></li>\n</ul>\n<p>特别提一下这里的细节处理：在请求前我会先通过 <code>normalizeStockCode</code>（位于 <code>src/utils/format.ts</code>）对代码进行标准化格式化，有效防止了 <code>SZ000001</code>、<code>sz000001</code> 和 <code>000001</code> 这种“一码多式”造成的去重失败或数据请求异常。</p>\n<hr />\n<h3 id=\"7-个股深度分析-stockdetail全维数据一览无余\">7) 个股深度分析 StockDetail：全维数据一览无余</h3>\n<p><img alt=\"stock-detail\" class=\"lazyload\" /></p>\n<p>页面位置：<code>src/pages/StockDetail/StockDetail.tsx</code>。这是整个项目中承载信息量最大的页面，因为它聚合了极高密度的信息。</p>\n<p>它聚合了多维度的 API 数据：</p>\n<ul>\n<li>实时报价：<code>getFullQuotes([code])</code></li>\n<li>当日分时图（1分钟级）：<code>getTodayTimeline(code)</code></li>\n<li>分钟级 K 线（5/15/30/60）：<code>getMinuteKline(code, { period })</code></li>\n<li>历史 K 线（日/周/月）及复权：<code>getKlineWithIndicators(code, { period, adjust: 'qfq', indicators })</code></li>\n<li>资金流向监测：<code>getFundFlow([code])</code></li>\n<li>盘口大单监控：<code>getPanelLargeOrder([code])</code></li>\n</ul>\n<p>我个人非常推崇 <code>getKlineWithIndicators</code> 这个接口：只需传入你想要的指标参数（如 MA, MACD, KDJ, RSI, BOLL等），SDK 就能把计算好的指标数据连同 K 线一起返回。前端只需负责绘图，彻底告别了在前端手写复杂技术指标计算逻辑的噩梦（少写代码 = 少出 Bug = 长命百岁）。</p>\n<p>在这里，轮询策略也做了精细化分层：</p>\n<ul>\n<li>基础行情：2 秒/次</li>\n<li>分时图：3 秒/次</li>\n<li>资金流向：10 秒/次</li>\n</ul>\n<hr />\n<h3 id=\"8-策略扫描器-scanner量化交易的初体验\">8) 策略扫描器 Scanner：量化交易的初体验</h3>\n<p>页面：<code>src/pages/Scanner/Scanner.tsx</code>。</p>\n<p>扫描逻辑简述如下：</p>\n<ol>\n<li><strong>确定股票池</strong>：\n<ul>\n<li>既可以是你的“自选股列表”。</li>\n<li>也可以是某个板块的成分股，例如调用 <code>getIndustryConstituents('BK0475')</code>。</li>\n</ul>\n</li>\n<li><strong>批量分析</strong>：\n<ul>\n<li>遍历每只股票，调用 <code>getKlineWithIndicators</code> 获取带指标的 K 线数据。</li>\n</ul>\n</li>\n<li><strong>信号匹配</strong>：\n<ul>\n<li>前端逻辑判断最近两根 K 线是否满足预设形态（如均线金叉、MACD 金叉、RSI 超买超卖等）。</li>\n</ul>\n</li>\n</ol>\n<p>虽然这个功能带有一定的“心里安慰”属性，但它确确实实把模糊的“看涨感觉”转化为了可执行的“触发条件”。</p>\n<hr />\n<h3 id=\"9-个性化设置-settings打造顺手的工具\">9) 个性化设置 Settings：打造顺手的工具</h3>\n<p><img alt=\"stock-settings\" class=\"lazyload\" /></p>\n<p>页面：<code>src/pages/Settings/Settings.tsx</code>。</p>\n<p>这个页面并没有调用任何 <code>stock-sdk</code> 接口，它的使命是将你的使用偏好（刷新频率、红涨绿跌配色、各类指标的默认参数等）持久化保存到 localStorage。这样，无论何时打开页面，它都还是那个你最熟悉的样子。</p>\n<hr />\n<h2 id=\"重头戏一日持股策略尾盘选股前端实现的全市场扫描\">重头戏：一日持股策略（尾盘选股）——前端实现的全市场扫描</h2>\n<p><img alt=\"stock-last\" class=\"lazyload\" /></p>\n<p>该功能位于 <code>src/pages/EndOfDayPicker/EndOfDayPicker.tsx</code>。我在这个页面实现了一套经典的“三步走”选股漏斗，其核心动力源自强大的 <strong><code>getAllAShareQuotes</code></strong> 接口。</p>\n<h3 id=\"第一阶段全量-a-股行情抓取\">第一阶段：全量 A 股行情抓取</h3>\n<pre><code class=\"language-ts\">// src/pages/EndOfDayPicker/EndOfDayPicker.tsx\nconst quotes = await getAllAShareQuotes({\n  batchSize: 500,\n  concurrency: 5,\n  onProgress: (completed, total) =&gt; setLoadingProgress({ completed, total, stage: '数据加载中...' }),\n});\n</code></pre>\n<p>这一步调用的是 SDK 的重磅接口：</p>\n<ul>\n<li><code>sdk.getAllAShareQuotes(options?: GetAllAShareQuotesOptions): Promise&lt;FullQuote[]&gt;</code></li>\n<li>参数 <code>batchSize</code> 控制单次批大小（默认 500），<code>concurrency</code> 控制并发数（默认 7）。</li>\n</ul>\n<p>我采取了相对稳健的策略（并发设为 5），兼顾了浏览器的性能负载和网络稳定性。配合 <code>onProgress</code> 回调，用户能看到实时的进度条反馈，体验流畅不卡顿，不会误以为网页卡死。</p>\n<h3 id=\"第二阶段基础指标粗筛\">第二阶段：基础指标粗筛</h3>\n<p>拿到全市场 5000+ 只股票的 <code>FullQuote</code> 数据后，我们先进行一轮粗筛（字段直接取自 <code>FullQuote</code>）：</p>\n<ul>\n<li>流通市值 (<code>circulatingMarketCap</code>)</li>\n<li>量比 (<code>volumeRatio</code>)</li>\n<li>涨跌幅 (<code>changePercent</code>)</li>\n<li>换手率 (<code>turnoverRate</code>)</li>\n<li>ST/风险股过滤</li>\n</ul>\n<p>这一步逻辑封装在 <code>filterStocksBasic()</code> 中，通常能把目标池从 5000+ 缩减到几百甚至几十只，如果不筛这一刀，后续拉取分时数据会直接把浏览器送走。</p>\n<h3 id=\"第三阶段分时图形态精选\">第三阶段：分时图形态精选</h3>\n<p>对于粗筛剩下的候选股，我们再进行更细致的分时图分析：</p>\n<ul>\n<li>调用 <code>getTodayTimeline(fullCode)</code> 拉取分时数据（注意拼接 sh/sz/bj 前缀）。</li>\n<li>计算核心强度指标：<code>timelineAboveAvgRatio</code>（即：现价高于均价的时间占比，由 <code>price</code> 和 <code>avgPrice</code> 对比得出）。</li>\n</ul>\n<p>为了防止浏览器崩溃，<code>filterWithTimeline()</code> 中手动控制了分时数据请求的并发量（batchSize = 5）。<br />\n最终结果按 <code>timelineAboveAvgRatio</code> 降序排列，并在列表中展示迷你的分时走势图。这样一来，尾盘选股的效率直接起飞。</p>\n<hr />\n<h2 id=\"写在最后谁需要这个工具\">写在最后：谁需要这个工具？</h2>\n<p>如果你渴望拥有一个“既能看盘、又能筛股、还能顺便管理自选”的轻量级看板，同时极其排斥维护后端服务或编写复杂的 Python 脚本，那么这个纯前端方案绝对是你的不二之选。<strong>核心思路就是利用 <code>stock-sdk</code> 将强大的数据能力引入前端，剩下的就是单纯的 UI 组装与逻辑编排</strong>。</p>\n<p>本地启动非常简单：</p>\n<pre><code class=\"language-bash\">yarn install\nyarn dev\n</code></pre>\n<p>最后不得不俗套地提醒一句：页面底部的 disclaimer “仅供学习参考，不构成投资建议”并非摆设。代码虽可自信敲，投资仍需谨慎行。</p>\n<hr />\n<h2 id=\"传送门\">传送门</h2>\n<ul>\n<li>在线看板： <a href=\"https://chengzuopeng.github.io/stock-dashboard/\" rel=\"noopener nofollow\" target=\"_blank\">https://chengzuopeng.github.io/stock-dashboard/</a></li>\n<li>SDK 文档： <a href=\"https://stock-sdk.linkdiary.cn/\" rel=\"noopener nofollow\" target=\"_blank\">https://stock-sdk.linkdiary.cn/</a></li>\n<li>SDK 演练场： <a href=\"https://stock-sdk.linkdiary.cn/playground/\" rel=\"noopener nofollow\" target=\"_blank\">https://stock-sdk.linkdiary.cn/playground/</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 19:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/chengzp\">程序猿的程</a>&nbsp;\n阅读(<span id=\"post_view_count\">130</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI → JSON → UI",
      "link": "https://www.cnblogs.com/guangzan/p/19487446",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/guangzan/p/19487446\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 15:23\">\n    <span>AI → JSON → UI</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"背景\">背景</h2>\n<p>过去两年，AI 生成 UI 的实践基本集中在两种路径上。第一种是直接让模型生成 JSX、HTML 或 CSS。这条路线的优势在于自由度极高，模型几乎不受约束，看起来“什么都能写”。但在真实工程环境中，这种方式几乎不可控：输出结构不稳定，无法保证组件边界，难以做权限与审计控制，生成的代码经常无法编译或违背工程约定，更重要的是，它与实际业务中的组件体系和设计系统严重脱节。</p>\n<p>另一条路线是低代码或 schema 驱动 UI，例如基于 JSON Schema 或表单 schema 的方案。这类方案在工程上是可控的，结构稳定、可校验、可复用，但它们本质上是为“人编写配置”设计的，而不是为“模型生成结构”设计的。schema 表达能力有限，扩展成本高，并且与自然语言之间的映射并不自然，Prompt 往往需要大量人工约束。</p>\n<p>Vercel 刚刚开源了 json-render，json-render 的出现，本质上是对这两条路线的重新切分与组合。它并没有试图让 AI 写前端代码，也没有把 AI 限制在传统低代码 schema 中，而是引入了一个中间层：<strong>JSON UI AST</strong>。AI 只能生成这种 AST，而 AST 的能力边界完全由开发者定义。渲染、状态、行为解释全部留在业务侧完成。开发者因此可以安全地让用户通过自然语言生成仪表盘、小部件或数据视图，而不需要把执行权交给模型。</p>\n<p><img alt=\"iShot_2026-01-15_15.25.26\" src=\"https://img2024.cnblogs.com/blog/1501373/202601/1501373-20260115152759556-1171653435.gif\" /></p>\n<h2 id=\"整体架构json-render-是一个-dsl-解释系统\">整体架构：json-render 是一个 DSL 解释系统</h2>\n<p>从架构视角看，json-render 并不是一个 UI 框架，而是一个 DSL 执行系统。系统由三层构成：最底层是 Catalog，用来声明“系统允许 AI 使用哪些 UI 能力”；中间层是 JSON UI Tree，这是 AI 的唯一输出形式；最上层是 Renderer，由业务侧实现，用于解释 JSON 并渲染真实 UI。</p>\n<p>它们之间的关系可以用下面这张结构图来理解：</p>\n<pre><code>┌────────────┐\n│   Prompt   │\n└─────┬──────┘\n      │\n      ▼\n┌──────────────────┐\n│  LLM / AI Model  │\n└─────┬────────────┘\n      │  JSON UI AST（受 Catalog 严格约束）\n      ▼\n┌──────────────────┐\n│     Catalog      │  ← 能力白名单 / Schema / Grammar\n└─────┬────────────┘\n      │ 校验 + 解析\n      ▼\n┌──────────────────┐\n│    Renderer      │  ← React / Vue / Native\n└─────┬────────────┘\n      │\n      ▼\n┌──────────────────┐\n│   Real UI View   │\n└──────────────────┘\n</code></pre>\n<p>在这个模型中，AI 只参与“结构生成”，不参与“执行”。这也是 json-render 在工程上成立的根本原因。</p>\n<h2 id=\"从-catalog-到-ui\">从 Catalog 到 UI</h2>\n<h3 id=\"1-catalog系统的能力边界定义\">1. Catalog：系统的能力边界定义</h3>\n<p>下面这段代码是整个系统中最重要的入口，它定义了 AI 能使用的全部 UI 能力。</p>\n<pre><code class=\"language-ts\">import { createCatalog } from '@json-render/core'\nimport { z } from 'zod'\n\nexport const catalog = createCatalog({\n  components: {\n    Card: {\n      props: z.object({\n        title: z.string()\n      }),\n      hasChildren: true\n    },\n    Metric: {\n      props: z.object({\n        label: z.string(),\n        valuePath: z.string(),\n        format: z.enum(['number', 'currency', 'percent']).optional()\n      })\n    }\n  },\n  actions: {\n    refresh: {\n      params: z.object({})\n    }\n  }\n})\n</code></pre>\n<p>这里没有任何 UI 代码，只有能力声明。props 使用 Zod 定义，这意味着它不仅是类型提示，还包含运行时校验规则。如果你对 Zod 没有了解，可以看看这篇博文，<a href=\"https://www.cnblogs.com/guangzan/p/19350726\" target=\"_blank\">Zod：TypeScript 类型守卫与数据验证</a>。action 并不是函数实现，而是一个“意图声明”，它只描述“可以发生什么”，不描述“怎么发生”。</p>\n<p>Catalog 在系统中的地位，相当于一门语言的语法定义文件。AI 后续生成的所有 JSON，本质上都必须符合这套 grammar。</p>\n<h3 id=\"2-ai-输出的-json-ui-ast\">2. AI 输出的 JSON UI AST</h3>\n<p>当用户输入类似“生成一个收入仪表盘”的提示时，模型生成的结果不是 JSX，而是下面这样的 JSON：</p>\n<pre><code class=\"language-json\">{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Revenue Overview\" },\n  \"children\": [\n    {\n      \"type\": \"Metric\",\n      \"props\": {\n        \"label\": \"Total Revenue\",\n        \"valuePath\": \"/metrics/revenue\",\n        \"format\": \"currency\"\n      }\n    }\n  ]\n}\n</code></pre>\n<p>这个 JSON 有几个非常关键的特征。它不包含任何函数、不包含条件表达式、不包含样式或状态逻辑。它只是结构化地描述“使用哪个组件，用什么参数，组件之间如何嵌套”。所有能力完全来源于 Catalog，因此这个 JSON 是可校验、可存储、可 diff、可审计、可回放的。</p>\n<h3 id=\"3-rendererjson-的解释执行\">3. Renderer：JSON 的解释执行</h3>\n<p>在 React 侧，Renderer 扮演的是解释器的角色。</p>\n<pre><code class=\"language-tsx\">import { Renderer } from '@json-render/react'\nimport { catalog } from './catalog'\n\nfunction App() {\n  return (\n    &lt;Renderer\n      catalog={catalog}\n      components={{\n        Card: ({ title, children }) =&gt; (\n          &lt;div className=\"card\"&gt;\n            &lt;h2&gt;{title}&lt;/h2&gt;\n            {children}\n          &lt;/div&gt;\n        ),\n        Metric: ({ label, value }) =&gt; (\n          &lt;div&gt;\n            {label}: {value}\n          &lt;/div&gt;\n        )\n      }}\n      data={{\n        metrics: { revenue: 120000 }\n      }}\n    /&gt;\n  )\n}\n</code></pre>\n<p>Renderer 并不关心 UI 长什么样，它只做三件事：根据 type 找到对应组件定义，根据 Catalog 校验 props 和 children，根据 valuePath 等规则完成数据注入。</p>\n<h2 id=\"为什么-json-render-是可控的\">为什么 json-render 是“可控的”</h2>\n<p>下面的借助 AI 能力分析基于 <code>vercel-labs/json-render</code> 主仓库。如果你对此不感兴趣，跳过这部分内容。</p>\n<h3 id=\"1-createcatalog能力被冻结的起点\">1. createCatalog：能力被冻结的起点</h3>\n<p>文件路径位于 <code>packages/core/src/create-catalog.ts</code>。这个函数的核心作用不是“注册组件”，而是“冻结能力边界”。</p>\n<p>简化后的核心逻辑可以理解为：</p>\n<pre><code class=\"language-ts\">export function createCatalog(definition) {\n  return {\n    components: definition.components,\n    actions: definition.actions,\n    validateNode(node) {\n      // 校验 type 是否存在\n      // 校验 props 是否符合 Zod schema\n      // 校验 children 是否被允许\n    }\n  }\n}\n</code></pre>\n<p>每一行代码都在服务一个目标：让 Catalog 成为一个不可突破的白名单。Renderer 和 AI 都无法绕过它。这也是为什么 json-render 把 Catalog 放在 core 包中，而不是 React 包中。</p>\n<h3 id=\"2-schema-校验ai-输出必须先编译再执行\">2. Schema 校验：AI 输出必须“先编译再执行”</h3>\n<p>在 JSON Tree 进入 Renderer 之前，系统会逐节点校验。type 是否在 Catalog 中声明，props 是否通过 Zod 校验，children 是否符合 hasChildren 约束，action 是否存在于白名单。这一过程本质上就是一次 AST 校验。</p>\n<p>这意味着 AI 的输出不是“运行时报错”，而是“不通过即拒绝执行”。在 AI UI 系统中，这是一个极其关键但经常被忽视的工程点。</p>\n<h3 id=\"3-renderer真正的解释器模型\">3. Renderer：真正的解释器模型</h3>\n<p>React Renderer 的内部逻辑并不是简单的 switch-case，而是一个递归解释过程。它根据节点的 type 查 Catalog，构造 props，解析 valuePath 注入数据，绑定 action handler，然后递归渲染 children。</p>\n<p>从架构角度看，它更接近一个 JSON AST Interpreter，而不是模板引擎。这也是 json-render 可以跨 React、Vue、Native 复用核心思想的原因。</p>\n<h3 id=\"4-valuepath刻意避免-ai-参与状态逻辑\">4. valuePath：刻意避免 AI 参与状态逻辑</h3>\n<p>valuePath 使用字符串路径描述数据依赖，例如：</p>\n<pre><code class=\"language-json\">\"valuePath\": \"/metrics/revenue\"\n</code></pre>\n<p>这样设计的直接结果是，AI 不需要理解状态结构，也不需要写任何状态逻辑。Renderer 统一负责解析路径、读取数据、触发更新。这在架构上刻意切断了“AI 直接操作状态”的可能性。</p>\n<p>下面是仅包含新增内容的补充章节，重点放在可落到源码层面的机制，避免概念化描述。示例代码与解释均基于 <code>vercel-labs/json-render</code> 当前仓库结构与实现思路。</p>\n<h2 id=\"prompt-与-catalog-的自动对齐\">Prompt 与 Catalog 的自动对齐</h2>\n<p>Prompt 与 Catalog 的自动对齐：不是“调 Prompt”，而是“导出 Grammar”。json-render 中，Prompt 与 Catalog 的对齐并不是通过人肉 Prompt Engineering 完成的，而是通过从 Catalog 派生一份机器可理解的能力描述，并将其注入到模型上下文中。这一点在 <code>packages/core</code> 中的设计非常关键。</p>\n<p>在 core 层，Catalog 本身并不是一个简单的对象，它包含了完整的组件定义、props schema 以及 action 描述。这些信息会被转换为一种“描述性结构”，用于告诉模型当前系统支持的 UI grammar。</p>\n<p>类似这样的逻辑：</p>\n<pre><code class=\"language-ts\">export function catalogToPrompt(catalog) {\n  return `\nYou can generate a JSON UI tree.\nAvailable components:\n${Object.entries(catalog.components).map(([name, def]) =&gt; `\n- ${name}\n  props: ${describeSchema(def.props)}\n  hasChildren: ${def.hasChildren}\n`).join('\\n')}\n\nAvailable actions:\n${Object.keys(catalog.actions).join(', ')}\n\nRules:\n- Output must be valid JSON\n- Only use listed components\n- Follow prop schemas strictly\n`\n}\n</code></pre>\n<p>这里的关键点不在于字符串本身，而在于信息来源完全来自 Catalog。换句话说，Catalog 是 single source of truth，Prompt 只是它的一种序列化视图。当开发者新增或修改组件定义时，Prompt 中允许模型使用的能力会自动发生变化，不存在“代码和 Prompt 不一致”的问题。这也是 json-render 能够避免大量“Prompt 腐化”的根本原因。</p>\n<p>从模型视角看，它面对的不是一段模糊的自然语言说明，而是一套接近 BNF 的 UI grammar 描述。模型生成 JSON UI Tree 的过程，本质上类似于在给定语法约束下生成 AST。这也是为什么 json-render 要使用 Zod 而不是仅靠 TypeScript 类型。Zod schema 可以被同时用于运行时校验和 Prompt 语义描述，形成闭环。</p>\n<h2 id=\"streaming-ui-的实现细节\">Streaming UI 的实现细节</h2>\n<p>流式构建 AST，而不是流式拼字符串。json-render 的 Streaming UI 能力，核心并不在“模型支持流式输出”，而在于 UI 的中间表示是可增量合并的 JSON AST。这一点在 React 包中的实现非常清晰。</p>\n<p>在 <code>packages/react</code> 中，可以看到类似 <code>useUIStream</code> 的 hook，其核心职责是：<br />\n维护一棵当前 UI Tree，并在模型流式输出时不断向这棵树中合并新节点。</p>\n<p>简化后的内部结构大致如下：</p>\n<pre><code class=\"language-ts\">// packages/react/src/use-ui-stream.ts（概念结构）\nexport function useUIStream() {\n  const [tree, setTree] = useState&lt;UITree | null&gt;(null)\n\n  function onChunk(chunk: string) {\n    const partialNode = parseChunkToNode(chunk)\n    if (!partialNode) return\n\n    setTree(prevTree =&gt; {\n      return mergeTree(prevTree, partialNode)\n    })\n  }\n\n  return { tree, onChunk }\n}\n</code></pre>\n<p>这里有两个非常关键但容易被忽略的点。</p>\n<p><code>parseChunkToNode</code> 并不是简单的 <code>JSON.parse</code>。模型在 streaming 模式下输出的通常是不完整 JSON，因此 json-render 采用的是逐段解析、延迟成型的策略。只有当一个节点在结构上是完整且通过 Catalog 校验时，才会被提升为“可合并节点”。<code>mergeTree</code> 是一个纯函数。它不依赖外部状态，只根据已有 UI Tree 和新节点生成下一棵 Tree。这使得每一次更新都是确定性的，也天然适合 React 的状态模型。</p>\n<p>在 Renderer 层，这棵 Tree 会被直接用于递归渲染：</p>\n<pre><code class=\"language-tsx\">function RenderNode({ node }) {\n  const Component = components[node.type]\n\n  const resolvedProps = resolveProps(node.props)\n  const children = node.children?.map(child =&gt;\n    &lt;RenderNode key={child.id} node={child} /&gt;\n  )\n\n  return &lt;Component {...resolvedProps}&gt;{children}&lt;/Component&gt;\n}\n</code></pre>\n<p>由于 Tree 始终是“已校验的合法结构”，Renderer 不需要关心节点是否完整，只需要关心“当前有哪些节点已经存在”。这也是 Streaming UI 能在生成未完成时就安全渲染的根本原因。</p>\n<h2 id=\"streaming-与-catalog-校验如何协同工作\">Streaming 与 Catalog 校验如何协同工作</h2>\n<p>Streaming UI 并不是绕过校验机制的捷径，恰恰相反，它依赖校验机制才能成立。在实际流程中，每一个候选节点在被合并进 UI Tree 之前，都会经过 Catalog 的校验逻辑：</p>\n<pre><code class=\"language-ts\">// packages/core/src/validate-node.ts（概念结构）\nexport function validateNode(node, catalog) {\n  const def = catalog.components[node.type]\n  if (!def) throw new Error('Unknown component')\n\n  def.props.parse(node.props)\n\n  if (node.children &amp;&amp; !def.hasChildren) {\n    throw new Error('Children not allowed')\n  }\n}\n</code></pre>\n<p>Streaming 模式下，这个校验发生得更频繁，但粒度更小。系统宁可“暂时不渲染”，也不会把一个非法节点交给 Renderer。这保证了 UI 在任何时刻都是一个合法子集，而不是半成品垃圾状态。</p>\n<p>Prompt 与 Catalog 的自动对齐，确保模型“不会幻想不存在的能力”；Streaming UI 的 AST 级增量构建，确保 UI“可以在不完整时仍然正确运行”。两者结合，使 json-render 的执行模型更接近编译器与解释器，而不是模板生成器。从工程视角看，这意味着一个重要转变：<strong>UI 生成不再是一次性结果，而是一个可观察、可中断、可回滚的过程。</strong>这也是 json-render 能够真正进入生产系统，而不仅停留在 Demo 层面的根本原因。</p>\n<h2 id=\"json-render-真正解决了什么\">json-render 真正解决了什么</h2>\n<p>json-render 本身并不是一种全新的技术范式。<strong>“用受限结构描述 UI，再由运行时解释执行”这一思想，在前端工程中早已反复出现过。</strong>早期的 JSON Schema Form、react-jsonschema-form、Formily、本质上都是用结构化数据描述界面，再由渲染器生成真实 UI。低代码平台、搭建系统、配置化后台，几乎全部建立在同一逻辑之上。即便在 AI 出现之前，这种模式也已经非常成熟：工程师通过 schema 描述组件、属性和布局，运行时负责校验与渲染，业务侧只操作结构而不直接触碰代码。json-render 并没有发明这种模式，它继承的正是这一整条技术脉络。</p>\n<p>json-render 的不同之处在于，它首次把“模型生成”作为一等公民纳入设计前提。传统 schema UI 假设配置由人编写，因此更强调完整性、可读性和编辑体验；而 json-render 假设结构由模型生成，因此更强调语法边界清晰、失败可恢复、部分结果可执行，以及与 Prompt 的自动对齐能力。从这个角度看，json-render 更像是“为 AI 重新设计的一代 schema UI 执行模型”。它真正解决的问题并不是“怎么用 JSON 渲染 UI”，而是当结构来源变成不可靠的模型时，工程边界应该在哪里。它给出的答案非常明确：AI 只负责生成结构化意图，工程师负责能力定义、执行与渲染，JSON 作为唯一中介和约束层。这使得 AI UI 不再是一次性 Demo，而是可以进入生产系统的工程能力。在当前阶段，这是少数真正站在工程立场思考 AI UI 的方案之一。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://json-render.dev/\" rel=\"noopener nofollow\" target=\"_blank\">json-render.dev</a></li>\n<li><a href=\"https://github.com/vercel-labs/json-render\" rel=\"noopener nofollow\" target=\"_blank\">github.com/vercel-labs/json-render</a></li>\n<li><a href=\"https://vercel.com/blog\" rel=\"noopener nofollow\" target=\"_blank\">vercel.com/blog</a></li>\n<li><a href=\"https://www.cnblogs.com/guangzan/p/19350726\" target=\"_blank\">Zod：TypeScript 类型守卫与数据验证</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 15:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/guangzan\">guangzan</a>&nbsp;\n阅读(<span id=\"post_view_count\">316</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}