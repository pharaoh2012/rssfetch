{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "ArcGIS授权管理器断网后自动停止",
      "link": "https://www.cnblogs.com/leaguecn/p/19585000",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/leaguecn/p/19585000\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 16:07\">\n    <span>ArcGIS授权管理器断网后自动停止</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"问题的由来\">问题的由来</h2>\n<p>系统重装win10 22h2，重新安装ArcGIS10.2.2版本，断网启动<strong>许可服务器管理员（LicenseManager）</strong> 的时候无法启动，联网时该软件自动启动了，断网时又自动停止了。</p>\n<h3 id=\"排查\">排查</h3>\n<p>查看lmgrd9.log没啥问题，-&gt;<strong>授权</strong>-&gt;<strong>机器ID</strong>，得到以下的异常标识。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1410060/202602/1410060-20260206160653610-505996147.png\" /></p>\n<ul>\n<li>异常的机器ID</li>\n</ul>\n<pre><code>下面列出了此计算机的主机标识符:\n\nMAC 地址: xxxxxxxxx\n主机名: DESKTOP-7E9QMGD\nIP 地址: ::1\n域: DESKTOP-7E9QMGD\nUMN 2: xxxxxxxxxxxxxxxxxxxxxxx\n</code></pre>\n<p>重新连接WIFI后，查看到正常的表示：</p>\n<ul>\n<li>正常的机器ID</li>\n</ul>\n<pre><code>下面列出了此计算机的主机标识符:\n\nMAC 地址: xxxxxxxxx\n主机名: DESKTOP-7E9QMGD\nIP 地址: 192.168.9.56\n域: DESKTOP-7E9QMGD\nUMN 2: xxxxxxxxxxxxxxxxxxxxxxx\n</code></pre>\n<h2 id=\"甄别与修复\">甄别与修复</h2>\n<h3 id=\"可能出现的异常及尝试\">可能出现的异常及尝试</h3>\n<ul>\n<li>首先排查了Hosts文件，不存在localhost被解析到::1这个ipv6中内容</li>\n<li>调整ipv4和ipv6顺序，使断网情况下有限回环到127.0.0.1，使得ip有可用值。调整后，许可服务器管理员断网状态获取的IP依旧是::1回环地址</li>\n<li>自行组建局域网，使得有IP地址。</li>\n</ul>\n<p>使用大模型进行检索：</p>\n<pre><code>断网后ArcGIS License Manager获取IP时出现以下的log：下面列出了此计算机的主机标识符:\n\nMAC 地址: xxxxxxxxx\n主机名: DESKTOP-7E9QMGD\nIP 地址: ::1\n域: DESKTOP-7E9QMGD\nUMN 2: xxxxxxxxxxxxxxxxxxxxxxx\n\n</code></pre>\n<ul>\n<li>简单说：断网后，你的电脑没有真实的物理网络 IP，License Manager 只能检测到系统默认的本地回环地址 ::1，这会导致许可验证失败（因为许可文件绑定的是物理网卡的真实 IP/MAC）。</li>\n</ul>\n<p><strong>断网时出现该问题的核心原因</strong></p>\n<ul>\n<li>ArcGIS License Manager 验证许可时，会优先读取物理网卡的真实 IP 地址（如 192.168.1.100），但断网后：</li>\n</ul>\n<ol>\n<li>物理网卡（以太网、WiFi）处于「未连接」状态，系统不会分配真实 IP；</li>\n<li>系统会默认使用「回环适配器」的 IP（::1 或 127.0.0.1）作为本机唯一可用 IP；</li>\n<li>许可文件中绑定的是你联网时的物理网卡 IP/MAC，与断网时的回环地址不匹配，导致验证失败。</li>\n</ol>\n<p><strong>解决方案：断网时让 License Manager 读取到「虚拟 IP」</strong>*<br />\n要解决这个问题，核心是给电脑添加一个始终存在的「虚拟网卡」，让 License Manager 无论是否断网，都能读取到固定的真实 IP（而非回环地址）。</p>\n<h3 id=\"有效的解决办法\">有效的解决办法</h3>\n<ul>\n<li>方法一：安装「Microsoft 环回适配器」</li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1410060/202602/1410060-20260206160628370-802218261.png\" /></p>\n<ol>\n<li>这是 Windows 自带的虚拟网卡工具，安装后会生成一个虚拟物理网卡，断网时也能分配固定 IP，完美适配 ArcGIS License Manager。</li>\n<li>操作步骤（Windows 10/11 通用）：</li>\n<li>打开「设备管理器」：按下 Win+X，选择「设备管理器」；</li>\n<li>添加过时硬件：点击设备管理器顶部的「操作」→「添加过时硬件」；</li>\n<li>启动硬件安装向导：</li>\n<li>选择「下一步」→ 选择「安装我手动从列表选择的硬件（高级）」→「下一步」；</li>\n<li>下拉列表找到「网络适配器」→「下一步」；</li>\n<li>选择环回适配器：</li>\n<li>左侧厂商选择「Microsoft」，右侧型号选择「Microsoft KM-TEST 环回适配器」→「下一步」；</li>\n<li>继续点击「下一步」，完成安装（等待几秒，系统会自动配置）；</li>\n<li>给虚拟网卡分配固定 IP：</li>\n<li>打开「控制面板→网络和共享中心→更改适配器设置」；</li>\n<li>找到刚安装的「以太网 2」（名称可能不同，带「环回」标识），右键「属性」；</li>\n<li>双击「Internet 协议版本 4 (TCP/IPv4)」；</li>\n<li>选择「使用下面的 IP 地址」，输入固定 IP（如 192.168.100.100），子网掩码填 255.255.255.0，网关留空；</li>\n<li>点击「确定」保存；</li>\n<li>重启 ArcGIS License Manager 服务：</li>\n<li>按下 Win+R，输入 services.msc 打开服务列表；</li>\n<li>找到「ArcGIS License Manager」，右键「重启」；</li>\n<li>验证效果：重新打开 License Server Administrator，查看主机标识符，IP 地址会显示为你设置的 192.168.100.100（而非 ::1），许可验证即可恢复正常。</li>\n</ol>\n<ul>\n<li>方法二：临时启用「虚拟 WiFi / 热点」<br />\n断网状态下，无法通过[热点]图标、按钮开启热点，需要使用powershell命令，以管理员身份开启powershell命令行，键入：</li>\n</ul>\n<pre><code class=\"language-PS\"># 注册热点配置\n$connectionProfile = [Windows.Networking.Connectivity.NetworkInformation,Windows.Networking.Connectivity,ContentType=WindowsRuntime]::GetInternetConnectionProfile()\n$tetheringManager = [Windows.Networking.NetworkOperators.NetworkOperatorTetheringManager,Windows.Networking.NetworkOperators,ContentType=WindowsRuntime]::CreateFromConnectionProfile($connectionProfile)\n\n# 启动热点\n$tetheringManager.StartTetheringAsync()\n\n# 停止热点\n$tetheringManager.StopTetheringAsync()\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 16:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/leaguecn\">leaguecn</a>&nbsp;\n阅读(<span id=\"post_view_count\">21</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Windows + AMD 显卡，终于能用 PyTorch 炼丹了",
      "link": "https://www.cnblogs.com/deali/p/19584890",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19584890\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 15:53\">\n    <span>Windows + AMD 显卡，终于能用 PyTorch 炼丹了</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>上一篇文章里，我开始折腾在 Windows11 上编译 ROCm 版的 PyTorch，虽然折腾失败了，但积累了一些经验。</p>\n<p>这不第二天就编译成功了。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/c4c248b3bf4132cd/77f0fcbc86478c7e.jpg\" /></p>\n<h2 id=\"编译产物\">编译产物</h2>\n<p>爽啊！</p>\n<pre><code class=\"language-bash\">-a---            2026/1/5    15:58      151148776 torch-2.9.1+rocm7.11.0a20260104-cp312-cp312-win_amd64.whl\n-a---            2026/1/5    15:59         514989 torchaudio-2.9.0+rocm7.11.0a20260104-cp312-cp312-win_amd64.whl\n-a---            2026/1/5    16:01        1247290 torchvision-0.24.0+rocm7.11.0a20260104-cp312-cp312-win_amd64.whl\n</code></pre>\n<p>Windows + AMD + ROCm + PyTorch，</p>\n<p>懂不懂这些词凑在一起的含金量啊！！😄</p>\n<h2 id=\"要点\">要点</h2>\n<p>总结下来这次编译功能的要点就俩。</p>\n<h3 id=\"使用官方版的-rocm\">使用官方版的 ROCm</h3>\n<p>之前因为网上查到的资料都说官方还没推出 gfx103x 的 ROCm，所以我安装了一个第三方预构建好的版本，可能是太老了还是咋的，编译 PyTorch 时老是失败。</p>\n<p>这次我使用了这个命令安装：</p>\n<pre><code class=\"language-bash\">pip install --index-url https://rocm.nightlies.amd.com/v2-staging/gfx103X-dgpu/ --pre rocm[libraries,devel]\n</code></pre>\n<p>你可以在这些位置尝试找到对应的 ROCm 软件包：</p>\n<ul>\n<li><a href=\"https://rocm.nightlies.amd.com/v2-staging/\" rel=\"noopener nofollow\" target=\"_blank\">https://rocm.nightlies.amd.com/v2-staging/</a></li>\n<li><a href=\"https://rocm.nightlies.amd.com/v2/\" rel=\"noopener nofollow\" target=\"_blank\">https://rocm.nightlies.amd.com/v2/</a></li>\n<li><a href=\"https://rocm.devreleases.amd.com/v2\" rel=\"noopener nofollow\" target=\"_blank\">https://rocm.devreleases.amd.com/v2</a></li>\n<li><a href=\"https://rocm.devreleases.amd.com/v2-staging\" rel=\"noopener nofollow\" target=\"_blank\">https://rocm.devreleases.amd.com/v2-staging</a></li>\n</ul>\n<p>别迷信第三方包，能用官方的就用官方的，没有就自己编译 ROCm，很幸运我这个卡有官方的 ROCm 包。</p>\n<h3 id=\"使用旧版本-pytorch\">使用旧版本 PyTorch</h3>\n<p>这一点上篇文章也说了，最新版可能不行，我在网上看有人编译 2.10 版本成功了。</p>\n<p>其实之前折腾的时候已经隐约感觉到了，PyTorch 版本太新，在 Windows + ROCm 这条路径上，更容易踩坑。</p>\n<p>网上已经有人确认：</p>\n<ul>\n<li>2.10：有人成功</li>\n<li>2.11：存在各种不确定性</li>\n</ul>\n<p>这次我直接选了更保守的方案：<strong>PyTorch 2.9.1</strong></p>\n<p>事实证明，这个选择是对的。</p>\n<p>至于 2.11 行不行？</p>\n<p>以后有精力再继续折腾，现在先享受成果。</p>\n<h2 id=\"安装-wheel\">安装 wheel</h2>\n<p>既然编译好了，那就可以安装试用一下。</p>\n<p>按顺序安装这三个文件（注意：torch 必须最先安装）</p>\n<pre><code class=\"language-bash\">pip install .\\torch-2.9.1+rocm7.11.0a20260104-cp312-cp312-win_amd64.whl\npip install .\\torchvision-0.24.0+rocm7.11.0a20260104-cp312-cp312-win_amd64.whl\npip install .\\torchaudio-2.9.0+rocm7.11.0a20260104-cp312-cp312-win_amd64.whl\n</code></pre>\n<p><strong>Windows + AMD 显卡，炼丹通道已打通。</strong></p>\n<h2 id=\"下一步做啥\">下一步做啥？</h2>\n<p>显卡加速能用了，那能做的事情就很多了。</p>\n<p>深度学习跑起来，AI画图玩起来~</p>\n<p>下一步我想先试试：</p>\n<ul>\n<li>一些简单的深度学习模型训练任务</li>\n<li>把 AI 画图重新玩起来</li>\n<li>重点试试 Z-Image : <a href=\"https://huggingface.co/Comfy-Org/z_image_turbo\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/Comfy-Org/z_image_turbo</a></li>\n</ul>\n<p>这个系列后续还有很多值得记录分享的，欢迎继续关注。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 15:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">75</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[大模型实战 04] 从玩具到生产：基于 ChromaDB 打造工程级 RAG 系统",
      "link": "https://www.cnblogs.com/algieba/p/19584786",
      "published": "",
      "description": "<div class=\"postcontent\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"[大模型实战 04] 从玩具到生产：基于 ChromaDB 打造工程级 RAG 系统\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153641800-755924643.png\" />\n        大模型应用开发必修课！本文通过通俗易懂的案例详解 RAG (检索增强生成) 的核心原理，对比 LlamaIndex 与 LangChain 的优劣，并手把手带咱们在 Kaggle 环境下，利用 ChromaDB 和 Qwen 模型搭建一个支持私有数据问答的企业级 RAG 系统。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"大模型实战-04-从玩具到生产基于-chromadb-打造工程级-rag-系统\">[大模型实战 04] 从玩具到生产：基于 ChromaDB 打造工程级 RAG 系统</h1>\n<blockquote>\n<p><strong>核心摘要 (TL;DR)</strong></p>\n<ul>\n<li><strong>痛点</strong>：大模型不知道最新的新闻，也不知道企业的私有文档（如员工手册）。</li>\n<li><strong>方案</strong>：<strong>RAG (检索增强生成)</strong>。就像“开卷考试”，先去翻书找答案，再回答问题。</li>\n<li><strong>工具链</strong>：<strong>LlamaIndex</strong> (框架) + <strong>BGE</strong> (嵌入模型) + <strong>ChromaDB</strong> (向量数据库) + <strong>Qwen2.5</strong> (推理模型)。</li>\n<li><strong>实战</strong>：在 Kaggle 上从零搭建一个能回答“企业内部机密”的 AI 助手。</li>\n</ul>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>各位友人们，大家好，这里是<strong>阿尔</strong>。在上一节中，我们大概知道了大模型的构成，safetensor格式的大模型的文件组成，transformers库的基本使用。我们已经能够使用大模型去做一些简单对话应用了，它可以是上知天文，下知地理，中间还能知道人情冷暖。但是，我们需要加一个限定词，在<strong>训练数据截止日期前</strong>的。因为训练一次需要耗费很多的计算资源，时间和人力，当我们想让它知道一些新知识的时候，比如让它知道现在美国的总统是拜登还是特朗普，我们可以在对话中告诉他，这没问题，但是如果我们想让它知道更多，比如我的<strong>私人日记</strong>?比如我<strong>刚写的那篇博客</strong>？比如公司的<strong>员工手册</strong>, 比如自己产品的<strong>使用说明书</strong>？</p>\n<p>这类<strong>私有数据</strong>，是大模型企业应用的痛点，毕竟大模型是基于在互联网上公开数据训练的。重新把这部分资料加进去，再训练一下模型？也不是不行，但是有点没有性价比，这时候就引出了大模型落地应用的核心技术-&gt; <strong>RAG (Retrieval-Augmented Generation，检索增强生成)</strong>。<br />\n<img alt=\"本地大模型的痛点，以及RAG如何解决的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153556816-660023016.png\" /></p>\n<h2 id=\"1-rag检索增强生成\">1. RAG（检索增强生成）</h2>\n<h3 id=\"11-什么是rag\">1.1 什么是RAG?</h3>\n<p>考试的时候，如果考到不会的知识，不知道各位友人们会不会头疼，如果这时候，允许我们翻书，现去书里找，我们也很有可能找得到对应的答案，哪怕我们可能完全没学过。这就是<strong>RAG</strong>的大致思路：<strong>不让模型凭空回忆，而是先给它找资料。</strong></p>\n<p>RAG，检索增强生成,字面上讲，就是 拿到考题-&gt;然后去翻书，通过目录之类的索引，快速翻到（<strong>检索</strong>）相关的内容-&gt;再根据这些内容（<strong>增强</strong>了的内容），回答出问题（<strong>生成</strong>回答）。</p>\n<p>对比简单地把东西一股脑全部跟大模型说一遍，我们能清楚得发现，我们只用了检索到的那一部分内容，并没有让整本书大模型的脑子将占用, 这就是RAG的效率体现。<br />\n<img alt=\"用开卷考试比喻RAG和离线模型的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153648126-1948951348.png\" /></p>\n<h3 id=\"12-rag的步骤\">1.2 RAG的步骤</h3>\n<p>RAG技术的思路很简单，但是实现并非只是一个单一的技术能实现的，它有一套<strong>流水线（流水线）</strong>。 把这头\"大象\"放进冰箱，总共需要两步：<strong>准备好数据</strong>和<strong>让模型拿到数据</strong>。<br />\n<img alt=\"用把“大象”装进冰箱的比喻来描述RAG的两个过程的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153557028-1079400548.png\" /></p>\n<h4 id=\"第一个阶段数据准备indexing---把书装进书包\">第一个阶段：数据准备(Indexing) -&gt; 把书装进书包</h4>\n<p>在大模型能够<strong>翻书</strong>之前，咱们得先把我们想给它看的<strong>书</strong>整理好，放进<strong>书包</strong>里。</p>\n<ol>\n<li><strong>加载 (Load)</strong>：咱们的资料可能是各种各样的格式，一般大模型是不认识这么些格式的，所以我们就需要把 PDF、Word、网页等各种格式的文件读进来，统一提取出纯文本。</li>\n<li><strong>切分 (Chunking)</strong>：大模型一次吃不下整本书,就和我们一眼看不完整本《三国演义》一样，它有<strong>上下文长度限制</strong>。我们需要把长文本切成一个个小的<strong>片段 (Chunks)</strong>，比如每 500 个字切一段。</li>\n<li><strong>向量化 (Embedding)</strong>：<strong>这是最关键的一步！</strong>\n<ul>\n<li>计算机无法直接比较“苹果”和“iphone”是不是相关的。</li>\n<li>我们需要用一个专门的模型（Embedding Model），把每一段文字变成一串<strong>数字向量</strong>（比如 <code>[0.1, -0.5, 0.8, ...]</code>）,是不是有点耳熟，对这和大模型训练的Embedding是一个思路，但是我们一般会使用<strong>特制</strong>的嵌入模型来做这个<strong>专业</strong>的事情。</li>\n<li>在这个数学空间里，语义相近的词，距离就越近, 这样我们就能知道，这本书中的所有向量，哪些是和我们的问题相关的了。</li>\n</ul>\n</li>\n<li><strong>存储 (Storage)</strong>：把这些向量和对应的文字，存入<strong>向量数据库 (Vector DB)</strong> 中。<br />\n<img alt=\"RAG的数据准备流程，包括“加载”，“切分”，“向量化”，“存储”等步骤的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153558790-898603395.png\" /></li>\n</ol>\n<h4 id=\"第二个阶段应用数据给大模型生成retrieval--generation--开卷答题\">第二个阶段：应用数据给大模型生成（Retrieval &amp; Generation）-&gt; 开卷答题</h4>\n<p>拿到书了之后，我们想要<strong>翻书</strong>，就得找到和问题<strong>有关系</strong>的内容，然后再将这些内容和我们自己的常识<strong>结合</strong>起来，对提出的问题进行答题。</p>\n<ol>\n<li><strong>问题向量化(Embedding)</strong>：要想知道用户的提问（例如“火星基地吃什么？”）和内容的相关性，我们就需要像对准备的数据一样，用同一个 Embedding 模型将问题变成向量。</li>\n<li><strong>检索 (Retrieval)</strong>：拿着这个“问题向量”，去向量数据库里搜, 去找到关系性高的内容。\n<ul>\n<li>系统会计算：“哪个文档片段的向量，和问题向量的距离最近？”</li>\n<li>找出最相似的前 3-5 个片段 (Top-k)。</li>\n</ul>\n</li>\n<li><strong>增强 (Augmentation)</strong>：把这 3-5 个片段拼在一起，和用户的问题组合成一个超级长的 Prompt。\n<ul>\n<li><em>Prompt 模板示例：</em>\n<blockquote>\n<p>你是一个助手。请根据以下参考资料回答问题。<br />\n参考资料：[片段1]... [片段2]...<br />\n用户问题：火星基地吃什么？</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><strong>生成 (Generation)</strong>：把这个 Prompt 喂给大模型（LLM）。大模型阅读资料，总结并生成最终答案。<br />\n<img alt=\"RAG的检索生成阶段，包括向量化，检索，增强和生成\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153614608-948909083.png\" /></li>\n</ol>\n<h2 id=\"2-rag技术选型\">2. RAG技术选型</h2>\n<p>好了，理论我们已经懂了，现在我们撸起袖子，准备来实操一下子吧。我们打算<strong>从零开始</strong>快速搭建一个<strong>工程级</strong>的RAG系统: <strong>私有API助手</strong>, 在我直接告诉各位友人们我们要用到的工具前，我觉得也有必要大概让各位友人们知道还有哪些别的选择，我们为什么选择了这几个。</p>\n<h2 id=\"21-框架-llamaindex-vs-langchain\">2.1 框架: LlamaIndex vs. LangChain</h2>\n<ul>\n<li><strong>LangChain</strong>：万能胶水，适合做复杂的 Agent（智能体），但写 RAG 代码比较啰嗦，抽象层级太碎，我们后面写智能体的时候（如果有精力做智能体的教程的话）再来使用它。</li>\n<li><strong>LlamaIndex</strong>：<strong>数据专家</strong>。专门为 RAG 也就是“索引和检索”而生。接口极度简洁，且对数据清洗（Ingestion）的处理更专业。</li>\n<li><strong>结论</strong>：我们做RAG，直接先上<strong>LlamaIndex</strong>, 快速地实现效果。<br />\n<img alt=\"LlamaIndex vs. LangChain的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153543478-1007132028.png\" /></li>\n</ul>\n<h3 id=\"22-嵌入模型-embeddingbge-vs-openai\">2.2 嵌入模型 (Embedding)：BGE vs. OpenAI</h3>\n<ul>\n<li><strong>OpenAI (text-embedding-3)</strong>：效果好，但要钱，且数据要传给 OpenAI（隐私风险）。</li>\n<li><strong>BAAI/bge-small-zh-v1.5</strong>：<strong>国货之光</strong>。中文效果霸榜，体积极小（几百 MB），完全可以在 Kaggle 本地跑。</li>\n<li><strong>结论</strong>：为了免费和隐私，首选 <strong>BGE-Small</strong>。</li>\n<li><strong>PS</strong>: 如果是英文资料的话，建议换成 <code>BAAI/bge-small-en-v1.5</code> 或者 OpenAI 的 <code>text-embedding-3-small</code><br />\n<img alt=\"BGE vs. OpenAI示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153638605-1843213838.png\" /></li>\n</ul>\n<h3 id=\"23-向量数据库chroma-vs-milvus-vs-pinecone\">2.3 向量数据库：Chroma vs. Milvus vs. Pinecone</h3>\n<ul>\n<li><strong>Pinecone</strong>：纯云端 SaaS，不可本地部署，对 Kaggle 不友好。</li>\n<li><strong>Milvus</strong>：性能强悍，适合十亿级数据，需要 Docker 部署，适合数据量大的时候使用，但是对于咱们的这个项目来说，太重了。</li>\n<li><strong>ChromaDB</strong>：<strong>轻量级王者</strong>。可以像 SQLite 一样以“本地文件”形式存在，也可以部署成服务器。</li>\n<li><strong>结论</strong>：中小型项目，首选 <strong>ChromaDB</strong>。<br />\n<img alt=\"向量数据库：Chroma vs. Milvus vs. Pinecone对比示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153650391-14712818.png\" /></li>\n</ul>\n<h2 id=\"3-上手实操\">3. 上手实操</h2>\n<p><strong>项目背景</strong>：假设我们是一家名叫 \"DeepStar\" 的初创公司，我们有一套内部绝密的 API 文档，新来的实习生总是问重复的问题。我们要用 RAG 让他自己查。<br />\n<img alt=\"项目背景的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153605492-890080127.png\" /></p>\n<h3 id=\"31-环境配置-kaggle\">3.1 环境配置 (Kaggle)</h3>\n<p>启动 Kaggle Notebook，确保 <strong>Internet: On</strong>，<strong>Accelerator: GPU T4 x2</strong>。</p>\n<pre><code class=\"language-bash\"># 1. 更新transformers及其相关库\n!pip install -U transformers peft accelerate bitsandbytes sentence-transformers\n\n# 2. 安装 LlamaIndex 核心及相关插件\n!pip install llama-index-core llama-index-llms-huggingface llama-index-embeddings-huggingface\n\n# 3. 安装 ChromaDB 向量库支持\n!pip install llama-index-vector-stores-chroma chromadb\n</code></pre>\n<p><img alt=\"环境部署步骤的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153548348-1600979809.png\" /><br />\n<strong>下载依赖库可能会需要一点时间</strong>，之后我看看能不能在kaggle上用uv去做包管理。</p>\n<h3 id=\"32-造数据模拟企业内部文档\">3.2 造数据：模拟企业内部文档</h3>\n<p>我们创建两份文档：一份是核心接口定义，一份是错误码说明。</p>\n<pre><code class=\"language-python\">import os\n\ndata_path = \"/kaggle/working/data\"\n# 创建数据目录\nos.makedirs(data_path, exist_ok=True)\n\n# 文档 1: 核心 API 定义\napi_doc = \"\"\"\n[机密] DeepStar 核心交易接口 v2.0\n1. 创建订单 API: POST /api/v2/order/create\n   - 必填参数: 'user_id' (String), 'amount' (Decimal), 'token' (X-Auth-Token)\n   - 特殊逻辑: 如果 amount &gt; 10000, 必须额外传递 'audit_code' (审计码)。\n   - 频率限制: 单用户每秒最多 5 次调用。\n2. 查询余额 API: GET /api/v2/balance\n   - 缓存策略: 默认缓存 5 秒。传递 'no-cache=true' 可强制刷新。\n\"\"\"\n\n# 文档 2: 错误码字典\nerror_doc = \"\"\"\n[机密] DeepStar 全局错误码字典\n- E1001: 签名验证失败。请检查 X-Auth-Token 是否过期。\n- E2009: 余额不足。注意：冻结金额不计入可用余额。\n- E5003: 审计风控拦截。大额交易未通过自动审计，请联系人工客服。\n\"\"\"\n\nwith open(f\"{/data_path}/api_specs.txt\", \"w\") as f:\n    f.write(api_doc)\nwith open(f\"/{data_path}/error_codes.txt\", \"w\") as f:\n    f.write(error_doc)\n\nprint(\"[Success] 企业文档库已就绪！\")\n</code></pre>\n<p><img alt=\"3.2模拟企业内部文档示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153620323-1280867794.png\" /></p>\n<h3 id=\"33-初始化大脑与眼睛-settings\">3.3 初始化大脑与眼睛 (Settings)</h3>\n<p>提前根据自己的情况来配置待会儿用的<strong>词嵌入模型</strong>和<strong>推理模型</strong>。</p>\n<pre><code class=\"language-python\">embedding_model =\"BAAI/bge-small-zh-v1.5\"\nllm = \"Qwen/Qwen2.5-7B-Instruct\"\n# 在本地服务器，可以用modelscope下载下来, 把路径配置在这儿\n</code></pre>\n<p>利用 <code>Settings</code> 全局配置，将默认的 OpenAI 替换为本地模型。</p>\n<pre><code class=\"language-python\">import torch\nfrom llama_index.core import Settings\nfrom llama_index.llms.huggingface import HuggingFaceLLM\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\n\n# 1. 设置 Embedding (眼睛)\n# 使用 BGE-Small，显存占用极低，检索中文效果极佳\nprint(\"正在加载 Embedding 模型...\")\n\nSettings.embed_model = HuggingFaceEmbedding(\n    model_name=embedding_model\n)\n\n# 2. 设置 LLM (大脑)\n# 使用 Qwen2.5-7B-Instruct\nprint(\"正在加载 LLM 模型...\")\nSettings.llm = HuggingFaceLLM(\n    model_name=llm,\n    tokenizer_name=llm,\n    context_window=30000,\n    max_new_tokens=512,\n    generate_kwargs={\"temperature\": 0.1, \"do_sample\": True}, # 技术文档要求严谨，温度调低\n    device_map=\"auto\",\n    model_kwargs={\"dtype\": torch.float16, \"trust_remote_code\": True}\n)\nprint(\"[Success] 模型加载完毕！\")\n</code></pre>\n<p><img alt=\"初始化词嵌入模型和推理模型的示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153615744-1133194901.png\" /></p>\n<h3 id=\"34-核心组件chromadb-持久化流水线\">3.4 核心组件：ChromaDB 持久化流水线</h3>\n<p>这是本篇最关键的代码。我们要实现：<strong>如果本地已经有数据库，就直接读；如果没有，才去解析文档。</strong></p>\n<pre><code class=\"language-python\">import chromadb\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\n\n# 定义持久化路径\nCHROMA_DB_PATH = \"/kaggle/working/chroma_db\"\nCOLLECTION_NAME = \"deepstar_docs\"\n\n# 1. 初始化 Chroma 客户端 (PersistentClient 实现了写硬盘功能)\ndb_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n\n# 2. 创建或获取集合 (Collection)\nchroma_collection = db_client.get_or_create_collection(COLLECTION_NAME)\n\n# 3. 将 Chroma 对接给 LlamaIndex\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n# 4. 智能加载逻辑 (幂等性设计)\nif chroma_collection.count() == 0:\n    print(\"[Info] 数据库为空，开始初始化...\")\n    # 读取 data 目录下的所有文件\n    documents = SimpleDirectoryReader(\"./data\").load_data()\n    # 建立索引并自动存入 Chroma (Ingestion)\n    index = VectorStoreIndex.from_documents(\n        documents, storage_context=storage_context\n    )\n    print(\"[Success] 数据写入完成！\")\nelse:\n    print(f\"[Info] 发现 {chroma_collection.count()} 条存量数据，直接加载...\")\n    # 直接从 Vector Store 加载，无需重新计算 Embedding\n    index = VectorStoreIndex.from_vector_store(\n        vector_store, storage_context=storage_context\n    )\n    print(\"[Success] 索引加载完成！\")\n</code></pre>\n<p><img alt=\"ChromaDB流水线示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153628021-457268917.png\" /></p>\n<h3 id=\"35-验收测试复杂逻辑问答\">3.5 验收测试：复杂逻辑问答</h3>\n<p>现在，我们模拟实习生提问。注意，这个问题需要结合两个文档（接口定义 + 错误码）以及逻辑推理才能回答。</p>\n<pre><code class=\"language-python\"># 创建查询引擎\nquery_engine = index.as_query_engine(similarity_top_k=3)\n\n# 实习生的提问\nquestions = [\n    \"创建订单时，如果你只有 100 块钱，能传 amount=20000 吗？为什么？\",\n    \"我收到了 E5003 错误，这是什么意思？该怎么办？\"\n]\n\nprint(\"======== 开始 RAG 问答测试 ========\")\n\nfor q in questions:\n    print(f\"\\n[Question] {q}\")\n    response = query_engine.query(q)\n    print(f\"[Answer]\\n{str(response)}\")\n\n    # 打印引用源 (Debug 必备，看看它参考了哪个文件)\n    source_file = response.source_nodes[0].metadata.get('file_name')\n    print(f\"[Source]: {source_file}\")\n</code></pre>\n<p><img alt=\"验收测试部分示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153610360-1434394446.png\" /></p>\n<p><strong>答复如下</strong><br />\n<img alt=\"RAG的回答示意图\" src=\"https://img2024.cnblogs.com/blog/3169973/202602/3169973-20260206153607605-376937231.png\" /></p>\n<hr />\n<h2 id=\"4-进阶技巧如何管理你的数据库\">4. 进阶技巧：如何管理你的数据库？</h2>\n<p>既然用了 ChromaDB，我们就可以像查 SQL 一样查它。这在 Debug 时非常有用。</p>\n<pre><code class=\"language-python\"># 偷看数据库里的前 2 条记录\ndata = chroma_collection.peek(limit=2)\n\nprint(\"\\n[Debug] 数据库抽查:\")\nfor i, doc in enumerate(data['documents']):\n    print(f\"--- 片段 {i} ---\")\n    print(f\"内容: {doc[:50]}...\") # 只打印前50个字\n    print(f\"来源: {data['metadatas'][i]}\")\n</code></pre>\n<h2 id=\"5-完整代码\">5. 完整代码</h2>\n<p>完整代码可以点击<a href=\"https://www.kaggle.com/code/thaodinhoio/llm04-rag-llamaindex-chromadb\" rel=\"noopener nofollow\" target=\"_blank\">kaggle笔记</a>获取</p>\n<h2 id=\"5-常见问题-qa\">5. 常见问题 (Q&amp;A)</h2>\n<p><strong>Q: 为什么不直接把所有文档都塞进 Prompt 里 (Long Context)？</strong><br />\n<strong>A:</strong> 虽然现在很多模型支持长文本（比如 128k），但直接塞文档有三个问题：</p>\n<ol>\n<li><strong>太贵</strong>：Token 是要钱的（如果用商业 API）。</li>\n<li><strong>太慢</strong>：上下文越长，推理越慢。</li>\n<li><strong>记不住</strong>：大模型有“长上下文迷失 (Lost in the Middle)”现象，塞太多反而会忽略中间的关键细节。RAG 相当于先做了一次筛选，只给模型看最有用的，效果反而更好。</li>\n</ol>\n<p><strong>Q: LlamaIndex 和 LangChain 我该学哪个？</strong><br />\n<strong>A:</strong></p>\n<ul>\n<li>做 <strong>RAG/知识库</strong>：首选 <strong>LlamaIndex</strong>，它对数据索引、切分、向量化做了极其深度的优化，接口更简洁。</li>\n<li>做 <strong>Agent/工具调用</strong>：首选 <strong>LangChain</strong>，它的生态和工具链更丰富。</li>\n<li><strong>结论</strong>：咱们这个项目专注于“找资料”，所以 LlamaIndex 是最佳选择。</li>\n</ul>\n<p><strong>Q: ChromaDB 的数据存在哪里了？</strong><br />\n<strong>A:</strong> 在上面代码中，我们通过 <code>PersistentClient</code> 指定了路径 <code>/kaggle/working/chroma_db</code>。<br />\n它就像 SQLite 一样，数据就存在这个文件夹里的 <code>.sqlite3</code> 和 <code>.bin</code> 文件中。咱们可以把这个文件夹拷贝到任何电脑上，无需重新向量化就能直接使用。</p>\n<hr />\n<p><strong>本文作者：</strong> Algieba<br />\n<strong>本文链接：</strong> <a href=\"https://blog.algieba12.cn/llm04-rag-llamaindex-chromadb/\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.algieba12.cn/llm04-rag-llamaindex-chromadb/</a><br />\n<strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！</p>\n<pre><code>\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"itemdesc\">\n\t\t\t发表于 \n<span id=\"post-date\">2026-02-06 15:37</span>&nbsp;\n<a href=\"https://www.cnblogs.com/algieba\">阿尔的代码屋</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</div>"
    },
    {
      "title": "从零开始学Flink：Flink SQL 极简入门",
      "link": "https://www.cnblogs.com/daimajiangxin/p/19584653",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/daimajiangxin/p/19584653\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 15:16\">\n    <span>从零开始学Flink：Flink SQL 极简入门</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"从零开始学Flink：Flink SQL 极简入门\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3365149/202602/3365149-20260206151553657-54750339.png\" />\n        无需Java/Scala代码！本文基于Flink 1.20.1版本，手把手教你在WSL2 Ubuntu环境下搭建开发环境，使用SQL Client体验实时流计算的魅力，轻松跑通第一个数据流任务。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Flink SQL 是 Apache Flink 的核心模块之一，它让开发者可以使用标准的 SQL 语法来编写流处理和批处理作业。对于不想深究 Java/Scala 复杂 API 的“小白”来说，Flink SQL 是进入实时计算领域的最佳敲门砖。</p>\n<p>本文将基于 <strong>Flink 1.20.1</strong> 版本，手把手教你在 WSL2 (Ubuntu) 环境下搭建环境，并运行你的第一个 Flink SQL 任务。</p>\n<h2 id=\"一为什么选择-flink-sql\">一、为什么选择 Flink SQL？</h2>\n<ol>\n<li><strong>低门槛</strong>：会写 SQL 就能开发实时任务。</li>\n<li><strong>统一性</strong>：批流一体，同一套 SQL 既可以跑历史数据（批），也可以跑实时数据（流）。</li>\n<li><strong>生态丰富</strong>：内置了大量的 Connector（连接器），轻松连接 Kafka、MySQL、Hive 等主流组件。</li>\n</ol>\n<p><img alt=\"Flink SQL 架构图\" class=\"lazyload\" /><br />\n<em>(图：Flink SQL 架构示意图，展示 SQL 解析、优化到执行的过程)</em></p>\n<h2 id=\"二环境准备-wsl2-ubuntu\">二、环境准备 (WSL2 Ubuntu)</h2>\n<p>本教程演示环境为 Windows 下的 WSL2 (Ubuntu 20.04/22.04)，这是目前 Windows 用户体验 Linux 开发环境的最佳姿势。<br />\n参考以前些的文章<a href=\"https://mp.weixin.qq.com/s/2_d434kpSeKrSh-krRgvsQ\" rel=\"noopener nofollow\" target=\"_blank\">从零开始学Flink：揭开实时计算的神秘面纱</a>，搭建好 Flink 环境。</p>\n<h2 id=\"三体验-flink-sql-client\">三、体验 Flink SQL Client</h2>\n<p>Flink 提供了一个交互式的命令行工具：<strong>SQL Client</strong>。它允许你直接在终端编写和提交 SQL 任务。</p>\n<h3 id=\"1-启动-sql-client\">1. 启动 SQL Client</h3>\n<p>如果没有启动Flink集群,则先启动flink集群:</p>\n<pre><code class=\"language-bash\">./bin/start-cluster.sh\n</code></pre>\n<p>,然后在 Flink 目录下执行：</p>\n<pre><code class=\"language-bash\">./bin/sql-client.sh\n</code></pre>\n<p>你将看到那只著名的松鼠 LOGO：</p>\n<p><img alt=\"SQLClient启动界面\" class=\"lazyload\" /><br />\n<em>(图：SQL Client 启动欢迎界面)</em></p>\n<h3 id=\"2-hello-world数据生成与打印\">2. Hello World：数据生成与打印</h3>\n<p>我们不依赖任何外部组件（如 Kafka），直接使用 Flink 内置的 <code>datagen</code> 连接器生成模拟数据，并用 <code>print</code> 连接器打印结果。</p>\n<p><strong>第一步：创建源表 (Source Table)</strong></p>\n<p>复制以下 SQL 到 SQL Client 中执行：</p>\n<pre><code class=\"language-sql\">CREATE TABLE source_table (\n    id INT,\n    name STRING,\n    ts TIMESTAMP(3),\n    WATERMARK FOR ts AS ts - INTERVAL '5' SECOND\n) WITH (\n    'connector' = 'datagen',       -- 使用数据生成器\n    'rows-per-second' = '1',       -- 每秒生成1条数据\n    'fields.id.kind' = 'sequence', -- id 字段为序列\n    'fields.id.start' = '1',       -- id 从1开始\n    'fields.id.end' = '100'        -- id 到100结束\n);\n</code></pre>\n<p>执行后显示 <code>[INFO] Execute statement succeed.</code>。</p>\n<p><strong>第二步：创建结果表 (Sink Table)</strong></p>\n<pre><code class=\"language-sql\">CREATE TABLE print_table (\n    id INT,\n    name STRING,\n    ts TIMESTAMP(3)\n) WITH (\n    'connector' = 'print'          -- 使用控制台打印连接器\n);\n</code></pre>\n<p><strong>第三步：提交任务</strong></p>\n<p>将源表的数据插入到结果表：</p>\n<pre><code class=\"language-sql\">INSERT INTO print_table SELECT * FROM source_table;\n</code></pre>\n<p>此时，SQL Client 会提交一个异步任务到集群。你会看到类似 Job ID 的输出。</p>\n<h3 id=\"3-查看运行结果\">3. 查看运行结果</h3>\n<p>由于我们使用的是 <code>print</code> 连接器，在 Standalone 模式下，输出会打印到 TaskManager 的日志文件中。</p>\n<p>打开一个新的 WSL2 终端窗口，进入 Flink 目录查看日志：</p>\n<pre><code class=\"language-bash\"># 进入 log 目录\ncd log\n\n# 查看最新的 .out 文件 (文件名包含 taskexecutor)\ntail -f flink-*-taskexecutor-*.out\n</code></pre>\n<p>你应该能看到屏幕上不断跳动的数据流：</p>\n<p><img alt=\"运行结果日志截图位置\" class=\"lazyload\" /><br />\n<em>(图：终端 tail -f 命令看到的实时数据输出)</em></p>\n<h2 id=\"四常用命令速查\">四、常用命令速查</h2>\n<p>在 SQL Client 中，你可以使用以下命令：</p>\n<ul>\n<li><code>HELP</code>: 查看帮助。</li>\n<li><code>SHOW TABLES</code>: 查看当前创建的表。</li>\n<li><code>SHOW JOBS</code>: 查看运行中的作业。</li>\n<li><code>DESCRIBE table_name</code>: 查看表结构。</li>\n<li><code>QUIT</code>: 退出 SQL Client。</li>\n</ul>\n<h2 id=\"五总结\">五、总结</h2>\n<p>恭喜你！你已经成功运行了人生中第一个 Flink SQL 任务。</p>\n<p>通过本文，我们完成了：</p>\n<ol>\n<li>WSL2 下 Java 和 Flink 1.20.1 的安装。</li>\n<li>启动了 Flink 本地集群。</li>\n<li>使用 SQL Client 创建了 Source 和 Sink 表，并跑通了数据流。</li>\n</ol>\n<p>下一篇，我们将深入讲解 Flink SQL 中的<strong>窗口（Window）</strong>操作，看看如何处理“过去5分钟的订单总额”这类经典需求。</p>\n<hr />\n<p><strong>参考资料</strong>：</p>\n<ul>\n<li><a href=\"https://nightlies.apache.org/flink/flink-docs-release-1.20/\" rel=\"noopener nofollow\" target=\"_blank\">Flink 官方文档</a></li>\n<li><a href=\"http://blog.daimajiangxin.com.cn/article/bigdata/flink-10.html\" rel=\"noopener nofollow\" target=\"_blank\">原文来自</a></li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 15:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/daimajiangxin\">代码匠心</a>&nbsp;\n阅读(<span id=\"post_view_count\">29</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从回调函数到Promise",
      "link": "https://www.cnblogs.com/LFeather/p/19583059",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/LFeather/p/19583059\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 10:47\">\n    <span>从回调函数到Promise</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近在面试中遇到了很多关于 <code>Promise</code> 的问题，因为以前的业务在请求方面并不复杂，多数时候都是在用 <code>async/await</code>，对 <code>Promise</code> 的理解还是有所欠缺，最近重新学习了一下 <code>Promise</code>，尽量避免写成API式的文章，主要还是结合自己的一些理解和思考来整理一下。</p>\n<h2 id=\"为什么要使用-promise\">为什么要使用 Promise</h2>\n<p>众所周知，JavaScript 的主线程是单线程执行的，所有的同步代码都是在一个线程中执行的，当遇到一些耗时操作时（比如网络请求、文件读取等），如果采用同步的方式去处理这些操作，就会阻塞主线程，导致页面卡顿，用户体验变差。为了解决这个问题，我们发明了异步编程，最早的异步编程方式是回调函数（Callback），我们先看一个简单的例子：</p>\n<pre><code class=\"language-javascript\">function add(getX, getY, finalCallback) {\n  var x, y;\n  getX(function (xVal) {\n    x = xVal;\n    if (y !== undefined) {\n      finalCallback(x + y);\n    }\n  });\n\n  getY(function (yVal) {\n    y = yVal;\n    if (x !== undefined) {\n      finalCallback(x + y);\n    }\n  });\n}\n\nfunction fetchX(xCallback) {\n  setTimeout(function () {\n    xCallback(2);\n  }, 1000);\n}\n\nfunction fetchY(yCallback) {\n  setTimeout(function () {\n    yCallback(3);\n  }, 1000);\n}\n\nadd(fetchX, fetchY, function (sum) {\n  console.log(\"Sum is: \" + sum);\n});\n</code></pre>\n<p><code>fetchX</code> 和 <code>fetchY</code> 是两个异步函数，分别模拟从服务器获取数据的过程，我们要进行 <code>x+y</code> 的计算，如果它们中的任何一个还没有准备好，就等待两者都准备好。我们逐步拆解这个过程：</p>\n<ol>\n<li>\n<p>调用 <code>add</code> 函数，传入 <code>fetchX</code>、<code>fetchY</code> 和回调函数。</p>\n</li>\n<li>\n<p>在 <code>add</code> 函数内部，调用 <code>getX</code>（即 <code>fetchX</code>），传入一个回调函数。</p>\n</li>\n</ol>\n<pre><code class=\"language-JavaScript\">function (xVal) {\n  x = xVal;\n  if (y !== undefined) {\n    finalCallback(x + y);\n  }\n}\n</code></pre>\n<ol start=\"3\">\n<li>\n<p><code>fetchX</code> 开始执行，经过1秒钟后，调用传入的回调函数（<code>xCallback</code>），将 <code>2</code> 作为参数传递进去。</p>\n</li>\n<li>\n<p>回调函数执行，<code>x</code> 被赋值为 <code>2</code>，然后检查 <code>y</code> 是否已经准备好（即 <code>y</code> 是否不为 <code>undefined</code>）。此时 <code>y</code> 还没有准备好，所以不会调用最终的 <code>finalCallback</code>。</p>\n</li>\n<li>\n<p>同样的过程发生在 <code>getY</code>（即 <code>fetchY</code>）上，经过1秒钟后，<code>y</code> 被赋值为 <code>3</code>，然后检查 <code>x</code> 是否已经准备好。此时 <code>x</code> 已经准备好了（<code>x=2</code>），所以调用 <code>finalCallback</code>，计算出最终的结果 <code>5</code>，并打印出来。</p>\n</li>\n</ol>\n<p>从这个例子中，我们是否能看出使用回调函数来处理异步操作存在一些问题？首先，也许这个思路很巧妙，但是代码很复杂，我在逐步拆解前很难直接理解这个过程。其次，如果有更多的异步操作需要处理，代码会变得更加复杂，难以维护，这就是著名的“回调地狱”问题。</p>\n<p>回想我刚上班时，使用的还是 jQuery，jQuery 的 Ajax 请求就是基于回调函数的，代码如下：</p>\n<pre><code class=\"language-javascript\">$.ajax({\n  url: \"https://api.example.com/data\",\n  method: \"GET\",\n  success: function (data) {\n    console.log(\"Data received:\", data);\n    $.ajax({\n      url: \"https://api.example.com/more-data\",\n      method: \"GET\",\n      success: function (moreData) {\n        console.log(\"More data received:\", moreData);\n        // 继续嵌套更多的回调...\n      },\n      error: function (err) {\n        console.error(\"Error fetching more data:\", err);\n      },\n    });\n  },\n  error: function (err) {\n    console.error(\"Error fetching data:\", err);\n  },\n});\n</code></pre>\n<p>显然，随着嵌套层级的增加，代码变得越来越难以阅读和维护，而且错误处理也变得复杂。所以回收这一节的标题，因为用回调函数来处理异步操作确实存在一些问题：</p>\n<ol>\n<li>可读性差：嵌套的回调函数使代码难以理解。</li>\n<li>错误处理复杂：每个回调函数都需要单独处理错误，导致代码冗长。</li>\n<li>控制流困难：管理多个异步操作的顺序和依赖关系变得复杂。</li>\n</ol>\n<p>等讲完 <code>Promise</code> 之后我们看下 <code>Promise</code> 是否能解决这些问题。</p>\n<h2 id=\"promise\">Promise</h2>\n<h3 id=\"是什么\">是什么</h3>\n<p>通俗的说，我们可以把 <code>Promise</code> 理解成一个异步操作的代理，它是异步操作的返回值，原本只有同步操作才能有返回值，异步操作只能使用我们上面所说的回调函数嵌套来获得结果。</p>\n<blockquote>\n<p>异步方法不会立即返回最终值，而是返回一个 <code>Promise</code>，以便在将来的某个时间点提供该值。</p>\n</blockquote>\n<p><code>Promise</code> 的基本用法应该都很熟悉了，我们创建一个 <code>Promise</code> 的例子：</p>\n<pre><code class=\"language-javascript\">// ES6 原生 Promise\nconst asyncTask = new Promise((resolve, reject) =&gt; {\n  // 模拟异步操作（比如接口请求、文件读取）\n  setTimeout(() =&gt; {\n    const success = true;\n    if (success) {\n      resolve(\"操作成功\"); // 成功回调\n    } else {\n      reject(\"操作失败\"); // 失败回调\n    }\n  }, 1000);\n});\n\n// 调用 Promise\nasyncTask\n  .then((result) =&gt; console.log(result)) // 输出：操作成功\n  .catch((error) =&gt; console.log(error))\n  .finally(() =&gt; console.log(\"操作完成\"));\n</code></pre>\n<p>可以看到，我们把异步操作 <code>setTimeout</code> 包装在 <code>Promise</code> 中，然后通过 <code>then</code>、<code>catch</code> 和 <code>finally</code> 来处理结果和错误，<code>setTimeout</code> 可以是任意异步操作，比如网络请求、文件读取等。</p>\n<p>隐藏在这些 API 之下的还有一个参数，一个 <code>Promise</code> 必然处于以下三种状态之一：</p>\n<ul>\n<li><strong><code>Pending</code>（进行中）</strong>：初始状态，既不是成功，也不是失败。</li>\n<li><strong><code>Fulfilled</code>（已成功）</strong>：操作成功完成。</li>\n<li><strong><code>Rejected</code>（已失败）</strong>：操作失败。</li>\n</ul>\n<p>这一部分内容可以参考 MDN 的 <a href=\"https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise\" rel=\"noopener nofollow\" target=\"_blank\">Promise - JavaScript | MDN</a>，讲得很清楚。</p>\n<p><img alt=\"\" src=\"https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Promise/promises.png\" /></p>\n<p>参考这张图，<code>Pending</code> 状态通向两个结果：<code>Fulfilled</code> 和 <code>Rejected</code>，这个过程是单向不可逆的，一旦状态改变，就会永久保持该状态。当任意一种情况发生时，<code>then</code> 方法注册的回调函数就会被调用，即不再处于\"待定\"（<code>Pending</code>）状态，称之为\"已敲定\"（<code>Settled</code>）。</p>\n<h4 id=\"rejected\">Rejected</h4>\n<p>我们先看 <code>Rejected</code> 的情况：</p>\n<pre><code class=\"language-JavaScript\">// catch\nconst failedTask = new Promise((resolve, reject) =&gt; {\n  setTimeout(() =&gt; {\n    reject(\"操作失败\"); // 失败回调\n  }, 1000);\n});\n\nfailedTask\n  .then((result) =&gt; console.log(result))\n  .catch((error) =&gt; console.log(error)) // 输出：操作失败\n  .finally(() =&gt; console.log(\"操作完成\"));\n\n// then 第二个参数\nconst anotherFailedTask = new Promise((resolve, reject) =&gt; {\n  setTimeout(() =&gt; {\n    reject(\"操作失败\"); // 失败回调\n  }, 1000);\n});\n\nanotherFailedTask\n  .then(\n    (result) =&gt; console.log(\"成功：\" + result),\n    (error) =&gt; console.log(\"失败：\" + error),\n  ) // 输出：操作失败\n  .finally(() =&gt; console.log(\"操作完成\"));\n</code></pre>\n<p>有两种方式可以捕获 <code>Promise</code> 的拒绝状态：一种是使用 <code>catch</code> 方法，另一种是将错误处理函数作为 <code>then</code> 方法的第二个参数传入。两种方式都能有效地处理 <code>Promise</code> 的拒绝状态，如果不进行错误处理，未捕获的拒绝会导致未处理的 <code>Promise</code> 拒绝警告。更详细的说明我们后面再聊，这里只看用法。</p>\n<h4 id=\"fulfilled\">Fulfilled</h4>\n<p>在构造器 <code>Promise(..)</code> 中，我们通常用两个回调函数来表示成功和失败的情况，这两个函数的命名并不固定，通常我们使用 <code>resolve</code> 和 <code>reject</code>，<code>reject</code> 很清楚地表示失败，并且代表 <code>Promise</code> 进入 <code>Rejected</code> 状态，而成功的回调函数 <code>resolve</code>（决议），它表示 <code>Promise</code> 进入 <code>Fulfilled</code> 状态，这里用 ES6 规范中的回调命名来说明：</p>\n<pre><code class=\"language-JavaScript\">myPromise.then((result) =&gt; onFulfilled, onRejected)\n</code></pre>\n<h4 id=\"链式调用\">链式调用</h4>\n<p>在提到 <code>Promise</code> 时，链式调用是一个非常重要的概念，上面的例子中，我们看到 <code>Promise</code> 对象可以调用 <code>then</code> 方法，而 <code>then</code> 方法又可以调用 <code>catch</code> 和 <code>finally</code> 方法，因为 <code>then</code> 方法返回的仍然是一个 <code>Promise</code> 对象，而 <code>catch</code> 和 <code>finally</code> 方法内在内部调用的也是 <code>then</code> 方法，这样它们就可以链式调用。</p>\n<pre><code class=\"language-JavaScript\">// Promise.resolve这种写法我们之后讨论\nPromise.resolve('第一步结果')\n  .then(res =&gt; {\n    console.log(res); // 打印：第一步结果\n    // return 普通值 → 新 Promise 状态为 fulfilled\n    return '第二步结果';\n  })\n  .then(res =&gt; {\n    console.log(res); // 打印：第二步结果\n    // return 新 Promise → 新 Promise 跟随该 Promise 的状态\n    return Promise.resolve('第三步结果');\n  })\n  .then(res =&gt; {\n    console.log(res); // 打印：第三步结果\n  });\n</code></pre>\n<p>通过例子可以看到，链式调用可以将多个异步操作串联起来，每个 <code>then</code> 方法处理上一个 <code>Promise</code> 的结果，这就解决了我们最开始提到的回调地狱问题，使代码更加清晰和易于维护。</p>\n<p>这个例子中还有一个细节，在 <code>then</code> 方法中通过 <code>return</code> 来传递值，当使用 <code>return</code> 返回一个普通值时，新的 <code>Promise</code> 会进入 <code>Fulfilled</code> 状态，也可以返回一个新的 <code>Promise</code> 对象，这样新的 <code>Promise</code> 会跟随该 <code>Promise</code> 的状态。值得注意的是，如果返回的是一个 <code>thenable</code> 对象（具有 <code>then</code> 方法的对象），<code>Promise</code> 也会等待该对象解决，这使得 <code>Promise</code> 可以与其他实现了类 <code>Promise</code> 接口的库进行互操作。</p>\n<p>大体上我们了解了 <code>Promise</code> 的用法，我们用 <code>Promise</code> 来实现嵌套异步操作：</p>\n<pre><code class=\"language-JavaScript\">function getFirstData() {\n  // 返回一个 Promise，用 setTimeout 模拟异步\n  return new Promise((resolve) =&gt; {\n    setTimeout(() =&gt; {\n      const data = \"第一个异步操作的结果\";\n      console.log(\"Data received:\", data);\n      // 异步成功，传递结果给下一个 .then()\n      resolve(data);\n    }, 1000);\n  });\n}\n\nfunction getSecondData(prevData) {\n  return new Promise((resolve) =&gt; {\n    setTimeout(() =&gt; {\n      const moreData = `第二个异步操作的结果（基于上一步：${prevData}）`;\n      console.log(\"More data received:\", moreData);\n      resolve(moreData); // 可选：继续传递结果给后续链式调用\n    }, 1000);\n  });\n}\n\n// 链式调用\ngetFirstData()\n  .then((data) =&gt; {\n    // 第一个异步成功后，执行第二个异步\n    return getSecondData(data);\n  })\n  .catch((err) =&gt; {\n    // 统一捕获所有异步操作的错误\n    console.error(\"异步操作出错：\", err);\n  });\n</code></pre>\n<h3 id=\"promise-解决了什么问题\">Promise 解决了什么问题</h3>\n<p>通过这个例子可以看到，我们一开始提出的回调函数的三个问题得到了不同程度的解决：</p>\n<ol>\n<li><strong>可读性提升</strong>：通过链式调用，代码结构更加清晰，每个异步操作都在自己的 <code>then</code> 块中处理，避免了嵌套回调的复杂性。</li>\n<li><strong>统一错误处理</strong>：使用 <code>catch</code> 方法可以统一捕获所有异步操作的错误，简化了错误处理逻辑。</li>\n<li><strong>控制流简化</strong>：通过链式调用，可以更容易地管理多个异步操作的顺序和依赖关系，使代码更易于理解。</li>\n</ol>\n<p>这里有点像一种 <code>if</code> 语句的替代写法：</p>\n<pre><code class=\"language-JavaScript\">if (condition1) {\n  // do something\n  if (condition2) {\n    // do something\n    if (condition3) {\n      // do something\n    }\n  }\n}\n\n// 可以改写为：\n\nif(!condition1) return;\n// do something\nif(!condition2) return;\n// do something\nif(!condition3) return;\n// do something\n\n</code></pre>\n<p>换个思路，作用相同，但代码的可读性会变高，不过 <code>Promise</code> 要复杂得多，我没有直接使用一开始的回调函数版本来对比，并非做不到，而是涉及了新的知识点，需要用到 <code>Promise</code> 的一些 API，我打算换一种角度来理解，然后我们再回头看这个对比。</p>\n<h3 id=\"promise-的-api-与原型\">Promise 的 API 与原型</h3>\n<p><code>Promise</code> 是 ES6（ES2015）引入的一种用于处理异步操作的<strong>对象</strong>，最近刚写了一篇关于原型的文章：<a href=\"https://www.cnblogs.com/LFeather/p/19312203\" target=\"_blank\">对于原型、原型链和继承的理解</a>，这里就是想从原型和面向对象的角度来加深一下理解，我们还是用前面的例子，分步拆解：</p>\n<pre><code class=\"language-javascript\">// ES6 原生 Promise\nconst asyncTask = new Promise((resolve, reject) =&gt; {\n  // 模拟异步操作（比如接口请求、文件读取）\n  setTimeout(() =&gt; {\n    const success = true;\n    if (success) {\n      resolve(\"操作成功\"); // 成功回调\n    } else {\n      reject(\"操作失败\"); // 失败回调\n    }\n  }, 1000);\n});\n\n// 调用 Promise\nasyncTask\n  .then((result) =&gt; console.log(result)) // 输出：操作成功\n  .catch((error) =&gt; console.log(error))\n  .finally(() =&gt; console.log(\"操作完成\"));\n</code></pre>\n<h4 id=\"构造函数-promise\">构造函数 Promise()</h4>\n<p>先从核心语句说起， <code>new Promise((resolve, reject) =&gt; { ... })</code> 这里事关两个概念：构造函数和 <code>new</code>。</p>\n<p><code>Promise()</code> 是一个构造器（Constructor）或者说构造函数，用于创建 <code>Promise</code> 对象。</p>\n<p>使用构造函数的形式来创建对象有几个好处：</p>\n<ol>\n<li>\n<p><strong>封装初始化逻辑</strong>：<code>Promise</code> 构造函数内部封装了初始化 <code>Promise</code> 对象所需的逻辑，比如设置初始状态（<code>pending</code>）、设置回调函数（<code>resolve</code> 和 <code>reject</code>）。</p>\n</li>\n<li>\n<p><strong>共享方法</strong>：通过构造函数创建的对象实例可以共享原型上的方法（如 <code>then</code>、<code>catch</code>、<code>finally</code>），避免每个实例都创建一份相同的方法，节省内存。</p>\n</li>\n<li>\n<p><strong>立即执行</strong>：当我们创建一个新的 <code>Promise</code> 实例时，传入的执行器函数（executor function）会立即执行，这使得我们可以在创建 <code>Promise</code> 的同时开始异步操作。</p>\n</li>\n</ol>\n<p>而 <code>new</code> 关键字用于创建一个新的对象实例，并将其原型链接到构造函数的原型对象上，也就是让新创建的对象继承构造函数原型上的方法和属性，结合上面的例子就是说我们创建的 <code>asyncTask</code> 对象会继承 <code>Promise.prototype</code> 上的方法，比如 <code>then</code>、<code>catch</code> 和 <code>finally</code>，这也就是为什么我们可以在 <code>asyncTask</code> 上调用这些方法，以及进行前面所说的链式调用。</p>\n<p>要注意的一点是，执行器函数的返回值对 <code>Promise</code> 的影响有限，在 <code>then</code> 方法中我们通过 <code>return</code> 来传递值，但在执行器函数中 <code>return</code> 语句仅影响控制流程，并不会直接改变 <code>Promise</code> 的状态，<code>Promise</code> 的状态只能通过调用 <code>resolve</code> 或 <code>reject</code> 来改变。</p>\n<pre><code class=\"language-JavaScript\">const myPromise = new Promise((resolve, reject) =&gt; {\n  // 一些异步操作\n  if (/* 操作成功 */) {\n    resolve(\"成功结果\");\n  } else {\n    reject(\"失败原因\");\n  }\n  return \"这个返回值不会影响 Promise 的状态\";\n});\n</code></pre>\n<h4 id=\"入参-resolve-reject-\">入参 (resolve, reject) =&gt;</h4>\n<p>接下来我们看构造函数的入参 <code>(resolve, reject) =&gt; { ... }</code> ，也就是执行器函数（executor function），它会在 <code>Promise</code> 实例创建时立即执行，这个上面说过了。使用 <code>Promise</code> 时，我们不会关注执行器函数，主要是使用这个函数的入参 <code>resolve</code> 和 <code>reject</code> 用来改变 <code>Promise</code> 的状态。</p>\n<pre><code class=\"language-JavaScript\">function executor(resolveFunc, rejectFunc) {\n  // 通常，`executor` 函数用于封装某些接受回调函数作为参数的异步操作，比如上面的 `setTimeout` 函数\n}\n</code></pre>\n<p>当调用 <code>resolve</code> 或 <code>reject</code> 时，<code>Promise</code> 的状态会立即改变，从 <code>pending</code> 变为 <code>fulfilled</code> 或 <code>rejected</code>，然后执行回调函数，这个回调函数就是我们通过 <code>then</code> 方法注册的函数。</p>\n<pre><code class=\"language-JavaScript\">const p = new Promise((resolve) =&gt; {\n  console.log('1. 执行器函数立即执行');\n  resolve('成功');\n  console.log('2. resolve 调用完成（同步）');\n});\n\nconsole.log('3. Promise 创建完成');\n\np.then((value) =&gt; {\n  console.log('5. then 回调执行:', value);\n});\n\nconsole.log('4. then 方法调用完成');\n\n// 输出顺序：\n// 1. 执行器函数立即执行\n// 2. resolve 调用完成（同步）\n// 3. Promise 创建完成\n// 4. then 方法调用完成\n// 5. then 回调执行: 成功\n</code></pre>\n<p>但我们用到 <code>Promise</code> 时主要还是用于异步任务，<code>then</code> 方法是典型的微任务（microtask），如果 <code>then</code> 方法先执行，里面的回调函数会被放入微任务队列，等待当前宏任务执行完毕后再执行。</p>\n<p>对于更细致的执行顺序，之前有写过一篇关于事件循环的文章，刚好是用 <code>Promise</code> 举例，可以参考：<a href=\"https://www.cnblogs.com/LFeather/p/16139014.html\" target=\"_blank\">有关 JavaScript 事件循环的若干疑问探究</a>。</p>\n<p><code>Promise</code> 内部的大致逻辑是这样的：</p>\n<pre><code class=\"language-JavaScript\">// Promise 内部简化实现\nclass MyPromise {\n  constructor(executor) {\n    this.state = 'pending';           // 状态\n    this.value = undefined;           // 结果值\n    this.onFulfilledCallbacks = [];   // ← 存储 then 的成功回调\n    this.onRejectedCallbacks = [];    // ← 存储 then 的失败回调\n\n    const resolve = (value) =&gt; {\n      if (this.state === 'pending') {\n        this.state = 'fulfilled';\n        this.value = value;\n        // ← 关键：遍历回调队列，将所有回调加入微任务\n        this.onFulfilledCallbacks.forEach(callback =&gt; {\n          queueMicrotask(() =&gt; callback(value));\n        });\n      }\n    };\n\n    const reject = (reason) =&gt; {\n      if (this.state === 'pending') {\n        this.state = 'rejected';\n        this.value = reason;\n        this.onRejectedCallbacks.forEach(callback =&gt; {\n          queueMicrotask(() =&gt; callback(reason));\n        });\n      }\n    };\n\n    executor(resolve, reject);\n  }\n\n  then(onFulfilled, onRejected) {\n    // 如果 Promise 还是 pending，就把回调存起来\n    if (this.state === 'pending') {\n      this.onFulfilledCallbacks.push(onFulfilled);  // ← 存储回调\n      this.onRejectedCallbacks.push(onRejected);\n    }\n    // 如果 Promise 已经 fulfilled，立即将回调加入微任务\n    else if (this.state === 'fulfilled') {\n      queueMicrotask(() =&gt; onFulfilled(this.value));\n    }\n    // 如果 Promise 已经 rejected\n    else if (this.state === 'rejected') {\n      queueMicrotask(() =&gt; onRejected(this.value));\n    }\n\n    return new MyPromise(() =&gt; {}); // 简化，实际更复杂\n  }\n}\n</code></pre>\n<p>所以 <code>then</code> 中的回调函数被执行的前提是 <code>resolve</code> 或 <code>reject</code> 被调用并且 <code>then</code> 方法也被调用，这也是 <code>Promise</code> 能处理异步操作的关键。</p>\n<h4 id=\"静态方法\">静态方法</h4>\n<p>简单提一下，静态方法是直接挂载在构造函数上的方法，而不是实例对象上，以前面的例子来说，<code>asyncTask</code> 是 <code>Promise</code> 的一个实例对象，而 <code>Promise.all(..)</code> 和 <code>Promise.resolve(..)</code> 这种则是 <code>Promise</code> 构造函数的一个静态方法。</p>\n<p>基于上面的简单例子，<code>Promise</code> 大体上的用法我们已经了解了，但还有很多 API 没有涉及到，我们可以通过打印 <code>Promise</code> 的原型来查看：</p>\n<pre><code class=\"language-JavaScript\">console.log(Promise.prototype);\n</code></pre>\n<p><img alt=\"\" src=\"https://blog-1252364274.cos.ap-guangzhou.myqcloud.com/20260205173555584.png\" /></p>\n<p>我们可以看到 <code>then</code>、<code>catch</code> 和 <code>finally</code> 方法都在 <code>Promise.prototype</code> 上，这些方法是实例方法，意味着它们可以被任何 <code>Promise</code> 实例调用。</p>\n<p>由于安全机制，直接打印 <code>Promise</code> 本身是看不到原生代码的，我们换一种方式，只需要得到静态方法名就行：</p>\n<pre><code class=\"language-JavaScript\">console.log(Object.getOwnPropertyNames(Promise));\n\n// 输出：['length', 'name', 'prototype', 'all', 'allSettled', 'any', 'race', 'resolve', 'reject', 'withResolvers', 'try']\n</code></pre>\n<p>输出结果中有的熟悉有的不熟悉，因为我之前对 <code>Promise</code> 仅停留在会用的层面，所以有些我甚至是第一次知道，但没关系，通过原型再对照 MDN 文档，逐个学习一下。 <code>length</code>、<code>name</code> 和 <code>prototype</code> 是函数对象的默认属性，我们主要关注其他的静态方法：</p>\n<ol>\n<li><code>Promise.resolve(..)</code> 和 <code>Promise.reject(..)</code></li>\n</ol>\n<p>这两个方法应该是最常见的了，上面的例子中也用到过，<code>reject</code> 比较简单，返回一个拒绝状态的 <code>Promise</code> 对象，入参就是拒绝的原因：</p>\n<pre><code class=\"language-JavaScript\">const promiseReject = Promise.reject(new Error(\"失败原因\"));\npromiseReject.catch((reason) =&gt; {\n  console.log(reason.message);\n  // Expected output: 失败原因\n});\n\n// 或者\nfunction resolved(result) {\n  console.log(\"Resolved\");\n}\n\nfunction rejected(result) {\n  console.log(\"Rejected:\", result);\n}\n\nconst promiseReject2 = Promise.reject(\"失败原因\");\npromiseReject2.then(resolved, rejected);\n</code></pre>\n<p><code>resolve</code> 方法则比较复杂一些，它有两种返回形式：1. 如果入参是一个普通值（非 <code>Promise</code> 对象），则返回一个以该值为结果的已解决（<code>fulfilled</code>）状态的 <code>Promise</code> 对象，这一点与 <code>reject</code> 对应；2. 如果入参是一个 <code>Promise</code> 对象，则返回该 <code>Promise</code> 对象本身。</p>\n<pre><code class=\"language-JavaScript\">// 入参是普通值\nconst promise1 = Promise.resolve(123);\n\npromise1.then((value) =&gt; {\n  console.log(value);\n  // Expected output: 123\n});\n\n// 入参是 Promise 对象\nconst originalPromise = new Promise((resolve) =&gt; {\n  setTimeout(() =&gt; {\n    resolve(\"原始 Promise 结果\");\n  }, 1000);\n});\n\nconst promise2 = Promise.resolve(originalPromise);\npromise2.then((value) =&gt; {\n  console.log(value);\n  // Expected output: 原始 Promise 结果\n});\n</code></pre>\n<ol start=\"2\">\n<li><code>Promise.all(..)</code>、<code>Promise.race(..)</code>、<code>Promise.allSettled(..)</code> 和 <code>Promise.any(..)</code></li>\n</ol>\n<p>这四个我觉得可以放一起介绍，它们都是用于处理多个 <code>Promise</code> 对象的静态方法，入参都是一个可迭代对象（通常是数组），包含多个 <code>Promise</code> 对象，返回一个新的 <code>Promise</code> 对象，其他的区别用一张表格来说明：</p>\n<table>\n<thead>\n<tr>\n<th>方法</th>\n<th>描述</th>\n<th>返回值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>Promise.all(..)</code></td>\n<td>全成功才成功，一失败就失败。</td>\n<td>成功时返回一个包含所有结果的数组，失败时返回第一个失败的原因。</td>\n</tr>\n<tr>\n<td><code>Promise.allSettled(..)</code></td>\n<td>等所有完成，无论成败。</td>\n<td>结果是一个包含每个 <code>Promise</code> 结果状态的数组。</td>\n</tr>\n<tr>\n<td><code>Promise.any(..)</code></td>\n<td>一成功就成功，全失败才失败。</td>\n<td>成功时返回第一个成功的结果，失败时返回一个 <code>AggregateError</code>，包含所有失败的原因。</td>\n</tr>\n<tr>\n<td><code>Promise.race(..)</code></td>\n<td>谁先完成（成败均可），就用谁的结果。</td>\n<td>结果是第一个解决或拒绝的 <code>Promise</code> 的结果或原因。</td>\n</tr>\n</tbody>\n</table>\n<p>关于 <code>Promise.all(..)</code> 的应用，我们最开始的回调函数就是一个很好的例子，我们可以用它来重写：</p>\n<pre><code class=\"language-JavaScript\">function fetchX() {\n  return new Promise((resolve) =&gt; {\n    setTimeout(() =&gt; {\n      resolve(2);\n    }, 1000);\n  });\n}\nfunction fetchY() {\n  return new Promise((resolve) =&gt; {\n    setTimeout(() =&gt; {\n      resolve(3);\n    }, 1000);\n  });\n}\n\nfunction add() {\n  return Promise.all([fetchX(), fetchY()]).then(([x, y]) =&gt; x + y);\n}\n\nadd().then((sum) =&gt; {\n  console.log(\"Sum is: \" + sum); // 输出：Sum is: 5\n});\n</code></pre>\n<p>如果有三个异步操作：</p>\n<pre><code class=\"language-JavaScript\">function fetchZ() {\n  return new Promise((resolve) =&gt; {\n    setTimeout(() =&gt; {\n      resolve(4);\n    }, 1000);\n  });\n}\n\nfunction addThree() {\n  return Promise.all([fetchX(), fetchY(), fetchZ()]).then(([x, y, z]) =&gt; x + y + z);\n}\n</code></pre>\n<p>MDN上的 <code>Promise.allSettled(..)</code> 例子：</p>\n<pre><code class=\"language-JavaScript\">Promise.allSettled([\n  Promise.resolve(33),\n  new Promise((resolve) =&gt; setTimeout(() =&gt; resolve(66), 0)),\n  99,\n  Promise.reject(new Error(\"一个错误\")),\n]).then((values) =&gt; console.log(values));\n\n// [\n//   { status: 'fulfilled', value: 33 },\n//   { status: 'fulfilled', value: 66 },\n//   { status: 'fulfilled', value: 99 },\n//   { status: 'rejected', reason: Error: 一个错误 }\n// ]\n</code></pre>\n<p>这里的返回值有些不同，是一个对象数组，每个对象表示对应 <code>Promise</code> 的状态和结果。</p>\n<p><code>Promise.any(..)</code> 的返回值是第一个成功的结果，如果所有 <code>Promise</code> 都失败了，则返回一个 <code>AggregateError</code>，它包含所有失败的原因：</p>\n<pre><code class=\"language-JavaScript\">const promiseA = Promise.reject(\"失败原因 A\");\nconst promiseB = Promise.reject(\"失败原因 B\");\n\nPromise.any([promiseA, promiseB])\n  .then((value) =&gt; {\n    console.log(value);\n  })\n  .catch((error) =&gt; {\n    console.log(error);\n  });\n\n// 输出：AggregateError: All promises were rejected\n</code></pre>\n<p>与其他三个方法不同，<code>Promise.race(..)</code> 返回的 <code>Promise</code> 状态的敲定总是异步的，前面的三种方法入参的 <code>Promise</code> 数组中有一个甚至多个是已经解决（<code>fulfilled</code>）或拒绝（<code>rejected</code>）的 <code>Promise</code> 对象（简单来说，和上面的大部分例子一样，我们传入一个确定的值而不是异步方法），那么 <code>Promise.all(..)</code>、<code>Promise.allSettled(..)</code> 和 <code>Promise.any(..)</code> 会立即返回结果，而 <code>Promise.race(..)</code> 的返回值则是异步的。</p>\n<p>MDN 针对每个方法的返回值都有详细的说明，比如说 <code>Promise.all(..)</code> ，如果传入的参数为空，则它的状态会立即变为 <strong>已解决（<code>fulfilled</code>）</strong> 另外两种返回状态则为 <strong>异步兑现（asynchronously fulfilled）</strong> 和 <strong>异步拒绝（asynchronously rejected）</strong> ，而 <code>Promise.any(..)</code> 则是相反的，如果传入的参数为空，则它的状态会立即变为 <strong>已拒绝（<code>rejected</code>）</strong>，其他情况都是异步的。</p>\n<p>向 <code>Promise.race(..)</code> 传入一个空的可迭代对象会导致返回的 <code>Promise</code> 永远处于挂起状态（<code>pending</code>），因为没有任何 <code>Promise</code> 可以兑现或拒绝。</p>\n<pre><code class=\"language-JavaScript\">const foreverPendingPromise = Promise.race([]);\nconsole.log(foreverPendingPromise);\nsetTimeout(() =&gt; {\n  console.log(\"堆栈现在为空\");\n  console.log(foreverPendingPromise);\n});\n\n// 按顺序打印：\n// Promise { &lt;state&gt;: \"pending\" }\n// 堆栈现在为空\n// Promise { &lt;state&gt;: \"pending\" }\n</code></pre>\n<p><code>Promise.race(..)</code> 的异步性有什么意义呢？假设我们有一个网络请求操作，我们希望在一定时间内获得响应，否则就放弃请求，这时我们可以使用 <code>Promise.race(..)</code> 来实现超时控制：</p>\n<pre><code class=\"language-JavaScript\">const data = Promise.race([\n  fetch(\"/api\"),\n  new Promise((resolve, reject) =&gt; {\n    // 5 秒后拒绝\n    setTimeout(() =&gt; reject(new Error(\"请求超时\")), 5000);\n  }),\n])\n  .then((res) =&gt; res.json())\n  .catch((err) =&gt; displayError(err));\n</code></pre>\n<ol start=\"3\">\n<li><code>Promise.try()</code></li>\n</ol>\n<blockquote>\n<p><code>Promise.try()</code> 静态方法接受一个任意类型的回调函数（无论其是同步或异步，返回结果或抛出异常），并将其结果封装成一个 <code>Promise</code>。</p>\n</blockquote>\n<p>这是一个截止到目前（2026年2月）仍在提案阶段的 API，在一些现代浏览器和 Node.js 最新版本中已经可以使用，作用类似于 <code>async</code> 函数，可以将同步代码和异步代码统一处理为 <code>Promise</code> 对象：</p>\n<pre><code class=\"language-JavaScript\">Promise.try(() =&gt; {\n  // 这里可以是同步代码\n  const result = synchronousFunction();\n  return result;\n})\n  .then((value) =&gt; {\n    console.log(\"同步结果:\", value);\n  })\n  .catch((error) =&gt; {\n    console.error(\"错误:\", error);\n  });\n// 也可以是异步代码\nPromise.try(async () =&gt; {\n  const result = await asynchronousFunction();\n  return result;\n})\n  .then((value) =&gt; {\n    console.log(\"异步结果:\", value);\n  })\n  .catch((error) =&gt; {\n    console.error(\"错误:\", error);\n  });\n</code></pre>\n<ol start=\"4\">\n<li><code>Promise.withResolvers()</code></li>\n</ol>\n<blockquote>\n<p><code>Promise.withResolvers()</code> 静态方法返回一个对象，其包含一个新的 <code>Promise</code> 对象和两个函数，用于解决或拒绝它，对应于传入给 <code>Promise()</code> 构造函数执行器的两个参数。</p>\n</blockquote>\n<p>它完全等价于下面的代码：</p>\n<pre><code class=\"language-JavaScript\">let resolve, reject;\nconst promise = new Promise((res, rej) =&gt; {\n  resolve = res;\n  reject = rej;\n});\n</code></pre>\n<p>它的作用是简化创建一个可控的 <code>Promise</code> 对象，我们可以在外部调用 <code>resolve</code> 和 <code>reject</code> 来改变 <code>Promise</code> 的状态：</p>\n<pre><code class=\"language-JavaScript\">const { promise, resolve, reject } = Promise.withResolvers();\n// 模拟异步操作\nsetTimeout(() =&gt; {\n  const success = true;\n  if (success) {\n    resolve(\"操作成功\");\n  } else {\n    reject(\"操作失败\");\n  }\n}, 1000);\npromise\n  .then((result) =&gt; console.log(result))\n  .catch((error) =&gt; console.log(error))\n  .finally(() =&gt; console.log(\"操作完成\"));\n</code></pre>\n<p>这个 API 的使用场景比较少见，目前我还不能完全理解它的作用，感兴趣可以到 MDN 上查看。</p>\n<h2 id=\"asyncawait-与-promise\">async/await 与 Promise</h2>\n<p>最开始就说到 <code>async/await</code> 了，我是先接触到 <code>async/await</code> 这种写法的，然后才了解到它是基于 <code>Promise</code> 的语法糖，个人理解来说，<code>async/await</code> 让异步代码看起来更像同步代码，主要是提高代码的可读性和可维护性，就像 <code>Promise</code> 之于回调函数一样。</p>\n<p>在使用上，<code>async/await</code> 的争议集中在是否要使用 <code>try/catch</code> 来处理错误，我之前的处理方式是在请求的封装里使用 <code>try/catch</code> 来捕获错误，调用时正常使用 <code>async/await</code> ，其他地方处理异步操作还是直接使用 <code>Promise</code>。以前其实没有太深入考虑过合理性的问题，在新公司看代码规范时发现他们有针对这个问题讨论过，才意识到这个问题的重要性。关于这个问题争议比较大，而且关于 <code>async/await</code> 完全可以单独写一篇，这篇主要还是针对 <code>Promise</code> 的学习记录，再写下去也有些超篇幅了，之后学习时应该还会再聊到。</p>\n<h2 id=\"缺陷\">缺陷</h2>\n<p>这个部分对于我来说还是有些超纲了，但也有参考资料，列一下《你不知道的JavaScript》中卷提到的几个缺陷，不过这些纸质书有一定的时代性，内容仅供参考：</p>\n<ol>\n<li><strong>顺序错误处理</strong>： 如果构建了一个没有错误处理函数的Promise链，链中后续的 <code>then</code> 仍然会被执行，可能导致错误被忽略或处理不当。</li>\n<li><strong>单一值</strong>： <code>Promise</code> 只能处理单一值的传递，无法直接处理多个值或复杂的数据结构（可以传递封装的对象，但如果在链中的每一步都进行封装和解封，就有些笨重了）。</li>\n<li><strong>单决议</strong>： <code>Promise</code> 一旦被解决（<code>fulfilled</code>）或拒绝（<code>rejected</code>），其状态就不能再改变，无法重新解决或拒绝。</li>\n<li><strong>惯性</strong>： 时代性的体现，考虑当时的环境 <code>Promise</code> 还未普及，现在应该可以忽略这一点了。</li>\n<li><strong>不可取消</strong>： 一旦创建，<code>Promise</code> 就会一直执行，无法取消正在进行的异步操作。这个也有些时代性了，现在有 <code>AbortController</code> 可以配合 <code>fetch</code> 来实现取消请求的功能。</li>\n<li><strong>性能</strong>： 相较于回调函数，<code>Promise</code> 在创建和管理状态方面有一定的性能开销，但个人认为这在通常的应用场景中影响不大。</li>\n</ol>\n<h2 id=\"总结\">总结</h2>\n<p>说实话动笔之前就是觉得应该写一篇关于 <code>Promise</code> 的，但开始写之后发现没什么方向，相关资料也是浩如烟海，写这篇耗费了非常多的时间，开始不断地深挖细节后感觉有无穷无尽的问题，好在现在通过 AI 至少可以把这些问题大致理清楚，\"大致\"理解说明还有很多内容没有涉及，之后在项目中应该会更加注意 <code>Promise</code> 的应用，然后把《你不知道的JavaScript》的相关内容看完结合一下应该还可以再水一篇。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 10:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/LFeather\">夜尽丶</a>&nbsp;\n阅读(<span id=\"post_view_count\">143</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "刚刚，Claude Opus 4.6 和 GPT-5.3-Codex 同时炸场！AI 编程要变天了",
      "link": "https://www.cnblogs.com/yupi/p/19583031",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yupi/p/19583031\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 10:40\">\n    <span>刚刚，Claude Opus 4.6 和 GPT-5.3-Codex 同时炸场！AI 编程要变天了</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"刚刚，Claude Opus 4.6 和 GPT-5.3-Codex 同时炸场！AI 编程要变天了\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2225420/202602/2225420-20260206102350805-967131892.png\" />\n        这次两家巨头同时发布新模型，互相贴脸开大，对我们用户来说是好事。可以看到，这两个模型都在往 实用方向 猛卷，是真的想让你日常工作中用得上。\n这两个大模型你会如何选择呢？\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"md-end-block md-heading\"><span class=\"md-plain\">大家好，我是程序员鱼皮。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">今天凌晨，AI 圈又双叒炸了。Anthropic 和 OpenAI 几乎同时发布了自家的最新大模型 —— Claude Opus 4.6 和 GPT-5.3-Codex，中门对狙，火药味十足。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这次两家是真往编程和实际工作能力上卷了，不是那种 “跑分升了 2 个点” 就发篇博客的敷衍更新。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">下面我带大家快速了解一下，这两个模型到底更新了什么？对我们程序员和 AI 玩家来说有什么用？</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">Claude Opus 4.6：更聪明、更能干、更持久</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">先说 Anthropic 这边。Claude Opus 4.6 是目前 Claude 家族最强的模型，之前用 Claude Opus 4.5 编程就已经让我感觉 “AI 写代码无所不能” 了，而这次的 Opus 4.6 在多项评估中均处于最先进水平，包括智能编码、多学科推理、知识工作和智能搜索等。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">光看这个跑分我就贼激动了！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">实际上手后，我最直观的感受就是：<span class=\"md-pair-s \"><strong>干活更靠谱了</strong><span class=\"md-plain\">。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">具体更新了这些：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">1）编程能力大幅提升：Opus 4.6 能更好地在大型代码库中工作，调试和代码审查能力增强，写完代码还能自己检查错误。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我实测了一波，让之前的 Opus 4.5 和新出的 Opus 4.6 同时开发一个「聚合搜索引擎」项目：</span></p>\n<pre class=\"md-fences md-end-block ty-contain-cm modeLoaded\"><span>请你帮我开发一个聚合搜索网站，包含完整的前端和后端，能够同时从多个不同的搜索引擎搜索和聚合结果。<br /><span>应该先做 MVP 最小可行产品，整个过程不需要向我确认、不需要我提供 API Key，你必须确保功能正常可用。</span></span></pre>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">几分钟后，二者都完成了任务：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但是对比一下实际搜索效果，Opus 4.5 完败，看到这我就放心了，以后我用 AI 编程估计 Bug 更少了~</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">2）100 万 token 上下文窗口。Opus 系列第一次支持这么长的上下文，简单来说就是你可以一次性给它丢一大堆文件和代码，它都能记住并理解，不会像以前那样聊着聊着就失忆了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这也是我最最最期待的特性，复杂的前后端项目也可以在同一对话框中一把梭了！不用来来回回总结上下文和新开对话框。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">赣，准备嘎嘎烧 Tokens 了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">3）128k 输出 token。输出长度翻倍，意味着 Claude 可以一次性生成更长的代码和文档，不用再拆成好几次请求了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">4）自适应思考。以前开发者只能手选开启或关闭深度推理，现在 Claude 会自动判断这个问题需不需要深度思考。简单问题秒回，复杂问题慢慢想，智能调节，省时省钱。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">5）上下文压缩。以前跑长任务的时候，AI 经常会撞到上下文长度的天花板。现在 Claude 能自动压缩和总结之前的对话内容，让长时间运行的任务不会中途翻车。搭配 100 万 token 上下文，不敢想象有多持久！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">6）Claude Code 支持多智能体协作。你可以同时启动多个 AI Agent 并行工作，比如让几个 Agent 同时审查代码库的不同部分，效率直接翻倍。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">7）Claude in Excel 大升级。现在能处理更复杂的长时间任务，支持数据透视表、图表修改、条件格式、数据验证等，还能一次性处理多步骤操作。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">8）Claude in PowerPoint 上线。能读取你已有的模板、字体和母版，保持品牌风格一致，然后直接帮你生成完整的 PPT。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">大家对 Opus 4.6 也是一致好评，不少早期测试的公司都表示 “用了回不去”，Cursor 官方说 Opus 4.6 是他们内部长任务测试中的最强模型，Replit 说它的任务拆解和并行规划能力有了巨大飞跃。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">GPT-5.3-Codex：OpenAI 的编程杀手锏</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">再看 OpenAI 这边。这次发布的 GPT-5.3-Codex，剑指 <span class=\"md-pair-s \"><strong>最强编程 Agent</strong><span class=\"md-plain\">，而且不只是写代码，还能像你的同事一样边干活边和你沟通。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">相比 Claude 官方连发好几个帖子介绍自家新模型，OpenAI 官方这边则低调不少。Sam Altman 亲自在 X 上喊话：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">来看看具体有什么：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">1）编程跑分全面领先。SWE-Bench Pro 57% 和 TerminalBench 2.0 77%，编程相关基准都创了新高。尤其是 OSWorld（测试 AI 在真实桌面环境中完成任务的能力）直接从上一代的 38.2% 飙到 64.7%，这个提升幅度相当炸裂。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">2）速度更快、更省钱。完成同样的任务，token 消耗量不到上一代（5.2-Codex）的一半，而且每个 token 处理速度还快了 25%。又快又省，这才是实实在在的体验提升。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">3）边干活边汇报。以前你丢一个任务给 AI，只能干等结果。现在 GPT-5.3-Codex 会在工作过程中实时告诉你它在做什么、做到哪了，你随时可以插嘴调整方向，就像真的在和一个同事协作一样。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">4）超强的前端开发能力。官方直接展示了让它做赛车游戏和潜水游戏的效果，完整度高得离谱，有多个地图、道具系统和完整的游戏逻辑。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">生成普通网页时 AI 也更懂你的意图了，默认就能给你做出功能更丰富、设计更合理的页面。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">5）电脑操作能力增强。不只是写代码，它还能像人一样操作电脑完成各种任务，比如做 PPT、分析数据、处理表格，把编程 Agent 的边界扩展到了全能打工 Agent。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">6）自己训练自己。OpenAI 团队说 GPT-5.3-Codex 是第一个 <span class=\"md-pair-s \"><strong>参与了自身创造</strong><span class=\"md-plain\"> 的模型。团队用它的早期版本来调试训练过程、管理部署、分析测试结果。也就是说，AI 在加速 AI 自身的进化，以后的进化速度肯定会越来越快。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">7）网络安全能力大幅增强。这是第一个被 OpenAI 归类为高能力网络安全模型的版本，能主动发现代码漏洞。OpenAI 同时承诺投入 1000 万美元 API 额度支持网络防御研究。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">我的看法</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这次两家巨头同时发布新模型，互相贴脸开大，对我们用户来说是好事。可以看到，这两个模型都在往 <span class=\"md-pair-s \"><strong>实用方向</strong><span class=\"md-plain\"> 猛卷，是真的想让你日常工作中用得上。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这两个大模型应该如何选择呢？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">简单对比一下：</span></p>\n<ul class=\"ul-list\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Claude Opus 4.6 是六边形战士，编程、办公、研究样样行，特别是在 Excel、PowerPoint 这些办公场景里做了很深的整合。</span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">GPT-5.3-Codex 把编程能力拉满，在代码生成、任务执行和人机协作上打出了差异化优势。</span></p>\n</li>\n</ul>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">不过我估计网络和价格就已经劝退一大波国内用户了，如果你只是日常学习、或者做做工具类小项目，也不必盲目追求国外的大模型。很快 DeepSeek V4 等一系列国产大模型应该就要出来了，期待一波~</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">更多编程学习资源</span></h2>\n<ul class=\"ul-list\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course\" rel=\"noopener nofollow\"><span class=\"md-plain\">Java前端程序员必做项目实战教程+毕设网站</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费编程学习交流社区（自学必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course/cv\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员保姆级求职写简历指南（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.mianshiya.com/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费面试刷题网站工具（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640584449888772098\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Java零基础入门学习路线 + Java教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586673306091521\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Python零基础入门学习路线 + Python教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586014108303362\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新前端零基础入门学习路线 + 前端教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586867363954689\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据结构和算法零基础入门学习路线 + 算法教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1644279832026075138\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新C++零基础入门学习路线、C++教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641797333479903234\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据库零基础入门学习路线 + 数据库教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640589994284695553\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Redis零基础入门学习路线 + Redis教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641035880439271426\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机基础入门学习路线 + 计算机基础教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641366118197153793\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新小程序入门学习路线 + 小程序开发教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"http://sqlmother.yupi.icu/\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新SQL零基础入门学习路线 + SQL教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586295529324545\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Linux零基础入门学习路线 + Linux教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588753362108417\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Git/GitHub零基础入门学习路线 + Git教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640587909942099969\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新操作系统零基础入门学习路线 + 操作系统教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588119619551233\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机网络零基础入门学习路线 + 计算机网络教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588392073150465\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新设计模式零基础入门学习路线 + 设计模式教程</span></a></span></p>\n</li>\n<li class=\"md-list-item md-focus-container\">\n<p class=\"md-end-block md-p md-focus\"><span class=\"md-meta-i-c md-link md-expand\"><a href=\"https://www.code-nav.cn/post/1640648711119892481\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新软件工程零基础入门学习路线 + 软件工程教程</span></a></span></p>\n</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 10:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yupi\">程序员鱼皮</a>&nbsp;\n阅读(<span id=\"post_view_count\">371</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Linux内核中模块定义宏机制解析",
      "link": "https://www.cnblogs.com/ttkwzyttk/p/19582878",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ttkwzyttk/p/19582878\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 10:10\">\n    <span>Linux内核中模块定义宏机制解析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文解析了 Linux 内核中的 module driver helper macro，讲解了 module_platform_driver 的实现原理与设计思想，展示了宏如何通过 宏拼接、可变参数、__init/__exit 和 module_init/module_exit 自动生成驱动注册与注销模板，是内核驱动开发者掌握标准写法的实用指南。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在编写 Linux 设备驱动时，尤其是 platform、I2C、SPI 等总线驱动，我们经常会看到类似下面的写法：</p>\n<pre><code class=\"language-c\">module_platform_driver(my_driver);\n</code></pre>\n<p>这类宏看起来很“魔法”，但实际上它们只是 Linux 内核为了减少样板代码而提供的一种 <strong>driver helper macro</strong>，本文主要讲解这类宏的用法与机制</p>\n<h1 id=\"一传统模块初始化方式\">一、传统模块初始化方式</h1>\n<p>这里以platform驱动为例，传统的驱动写法通常是这样的：</p>\n<pre><code class=\"language-c\">static struct platform_driver my_platform_driver = {\n    .probe  = my_probe,\n    .remove = my_remove,\n    .driver = {\n        .name = \"my_driver\",\n    },\n};\n\nstatic int __init my_init(void)\n{\n    return platform_driver_register(&amp;my_platform_driver);\n}\n\nstatic void __exit my_exit(void)\n{\n    platform_driver_unregister(&amp;my_platform_driver);\n}\n\nmodule_init(my_init);\nmodule_exit(my_exit);\nMODULE_LICENSE(\"GPL\");\n</code></pre>\n<p>这是一个标准的驱动模板，有驱动的入口init函数与出口exit函数，并通过<code>module_init</code>和<code>module_exit</code>接口函数进行注册，这种写法的样板代码高度重复，几乎每一个platform驱动都是一模一样的，内核中存在大量这种固定模式的代码，非常适合使用宏来简化</p>\n<h1 id=\"二模块定义宏的引入\">二、模块定义宏的引入</h1>\n<p>为了解决上述问题，Linux 内核引入了一组 <strong>module driver helper macro</strong>，用于简化驱动的注册与注销过程。</p>\n<p>以platform驱动为例，内核提供了</p>\n<pre><code class=\"language-c\">module_platform_driver(...)\n</code></pre>\n<p>虽然接口看着像是函数，但是他是由宏来实现的，使用该宏之后，上面的代码就可以简化为：</p>\n<pre><code class=\"language-c\">static struct platform_driver my_platform_driver = {\n    .probe  = my_probe,\n    .remove = my_remove,\n    .driver = {\n        .name = \"my_driver\",\n    },\n};\n\nmodule_platform_driver(my_platform_driver);\nMODULE_LICENSE(\"GPL\");\n</code></pre>\n<p>可以看见，使用该宏之后，就不需要再手写<code>__init</code>和<code>__exit</code>注册与注销接口函数了，也不需要再显式调用<code>platform_driver_register</code>和<code>platform_driver_unregister</code>接口函数了，与传统写法完全相同</p>\n<p>当然这种写法不仅仅只有platform驱动有，内核为不同的总线都提供了对应的宏定义</p>\n<pre><code class=\"language-c\">module_i2c_driver(my_i2c_driver);\nmodule_spi_driver(my_spi_driver);\nmodule_usb_driver(my_usb_driver);\nmodule_pci_driver(my_pci_driver);\n.......\n</code></pre>\n<p>他们遵循完全相同的设计思想：一个模块，只注册一个驱动，用一行宏搞定</p>\n<h1 id=\"三本质解析\">三、本质解析</h1>\n<p>这里还是以platform驱动为例，<code>module_platform_driver</code> 是一个宏封装。我们可以打开内核源码<code>kernel/include/linux/platform_device.h</code>找到对应的宏，如果为其他总线驱动，需要到对应的头文件中查找，如下所示</p>\n<pre><code class=\"language-c\">/* module_platform_driver() - Helper macro for drivers that don't do\n* anything special in module init/exit. This eliminates a lot of\n* boilerplate. Each module may only use this macro once, and\n* calling it replaces module_init() and module_exit()\n*/\n\n#define module_platform_driver(__platform_driver) \\\nmodule_driver(__platform_driver, platform_driver_register, \\\nplatform_driver_unregister)\n</code></pre>\n<p>可以看见<code>module_platform_driver</code>宏中又使用了<code>module_driver</code>这个宏定义，这个宏定在<code>kernel/include/linux/device/driver.h</code>头文件中，定义代码如下</p>\n<pre><code class=\"language-c\">/**\n\n* module_driver() - Helper macro for drivers that don't do anything\n* special in module init/exit. This eliminates a lot of boilerplate.\n* Each module may only use this macro once, and calling it replaces\n* module_init() and module_exit().\n*\n* @__driver: driver name\n* @__register: register function for this driver type\n* @__unregister: unregister function for this driver type\n* @...: Additional arguments to be passed to __register and __unregister.\n*\n* Use this macro to construct bus specific macros for registering\n* drivers, and do not use it on its own.\n*/\n#define module_driver(__driver, __register, __unregister, ...) \\\nstatic int __init __driver##_init(void) \\\n{ \\\nreturn __register(&amp;(__driver) , ##__VA_ARGS__); \\\n} \\\nmodule_init(__driver##_init); \\\nstatic void __exit __driver##_exit(void) \\\n{ \\\n__unregister(&amp;(__driver) , ##__VA_ARGS__); \\\n} \\\n\nmodule_exit(__driver##_exit);\n</code></pre>\n<p>在<code>module_driver</code>宏中就可以看见对应的驱动注册与注销的模板了，这里主要就是通过宏拼接以及可变参数宏来实现，读者可以自行宏展开进行分析，所有的模块宏<code>platform</code>驱动、<code>pci</code>驱动、<code>usb</code>驱动等等，底层都是调用了<code>module_driver</code>进行宏替换与拼接组成最后的模块注册模板，这里就不再赘述了</p>\n<h1 id=\"四使用场景\">四、使用场景</h1>\n<p>在主线内核中，这种写法已经成为<strong>事实标准</strong>，原因主要有：</p>\n<ul>\n<li>*<strong>减少样板代码</strong></li>\n<li><strong>统一驱动风格</strong></li>\n<li><strong>降低出错概率</strong></li>\n<li><strong>代码审查更友好</strong></li>\n</ul>\n<p>对于维护者来说，一眼看到<code>module_platform_driver(xxx_driver);</code> 就能立刻知道这是一个“标准的 platform 模块驱动。</p>\n<p>虽然 helper macro 很方便，但并非所有场景都适合。不建议使用的情况包括：</p>\n<ul>\n<li>一个模块中注册 <strong>多个 driver</strong></li>\n<li>模块 init 阶段还需要做额外初始化工作，使用模块宏的话，它的底层只能调用对应的<code>register</code>和<code>unregister</code>函数无法做其他操作</li>\n<li>对初始化/退出顺序有精细控制需求</li>\n</ul>\n<p>在这些场景下，手写 <code>module_init</code> / <code>module_exit</code> 反而更清晰。所以需要具体情况具体分析</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 10:10</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ttkwzyttk\">ttkwzyttk</a>&nbsp;\n阅读(<span id=\"post_view_count\">6</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "ClawdBot 出圈记：AI Agent 正在走向大众",
      "link": "https://www.cnblogs.com/bugshare/p/19582865",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/bugshare/p/19582865\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 10:08\">\n    <span>ClawdBot 出圈记：AI Agent 正在走向大众</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>国内外的社交平台上，无论你是否关注 AI，最近大概率都刷到过 <strong>ClawdBot / OpenClaw</strong>。短短几天时间，这个项目在 GitHub 上已经斩获了 <strong>13 万+ Star</strong>，堪称现象级开源项目。</p>\n<p>它不仅再次点燃了大众对 <strong>AI Agent</strong> 的热情，也让「让 AI 真正帮你干活」这件事，从极客玩具逐步走向普通用户。</p>\n<hr />\n<h1 id=\"简介\">简介</h1>\n<h2 id=\"创始人\">创始人</h2>\n<p>先来看看 ClawdBot（现名 <strong>OpenClaw</strong>）的创始人 <strong>Peter Steinberger</strong>。</p>\n<p>他是奥地利人，毕业于 <strong>维也纳科技大学</strong>，是一位典型的技术天才。</p>\n<p>在因为 OpenClaw 被更多人熟知之前，Peter 就已经是靠代码成功创业、实现 <strong>身家上亿欧元</strong>、提前退休的程序员了。这次出山，更像是一次「技术理想主义者」的回归。</p>\n<p><img alt=\"steipete.png\" class=\"lazyload\" /></p>\n<hr />\n<h2 id=\"命名之旅一只龙虾的蜕变史\">命名之旅：一只龙虾的蜕变史</h2>\n<p>OpenClaw 的名字，并不是一开始就确定的，反而经历了一段颇有戏剧性的演化过程。</p>\n<h3 id=\"clawd\">Clawd</h3>\n<p><strong>Clawd</strong> 诞生于 <strong>2025 年 11 月</strong>。一切看似都很完美，直到 <strong>Anthropic 的法务团队</strong> 非常礼貌地联系了作者，请他「重新考虑一下这个名字」。</p>\n<p>原因嘛，大家懂的 😄</p>\n<h3 id=\"moltbot\">Moltbot</h3>\n<p>接下来诞生的是 <strong>Moltbot</strong>。</p>\n<p>这个名字是在 <strong>凌晨 5 点</strong>，作者和社区成员在 Discord 上进行了一场略显混乱的头脑风暴后敲定的。</p>\n<p>“Molt（蜕皮）”象征着成长——就像龙虾不断脱壳，最终变成更强大的个体。寓意非常美好，但问题也很明显：</p>\n<blockquote>\n<p>听起来有点拗口，不太好念。</p>\n</blockquote>\n<h3 id=\"openclaw最终形态\">OpenClaw（最终形态）</h3>\n<p>最终，项目正式更名为 <strong>OpenClaw</strong>。</p>\n<ul>\n<li>商标检索结果：✅ 安全</li>\n<li>域名：✅ 已购买</li>\n<li>代码迁移：✅ 已完成</li>\n</ul>\n<p>这个名字也恰如其分地概括了项目的现状：</p>\n<ul>\n<li><strong>Open</strong>：完全开源，对所有人开放，社区驱动</li>\n<li><strong>Claw</strong>：龙虾之爪，传承最初的精神象征</li>\n</ul>\n<hr />\n<h2 id=\"什么是-openclaw\">什么是 OpenClaw？</h2>\n<p>一句话概括：</p>\n<blockquote>\n<p><strong>OpenClaw 是一个运行在你自己电脑上的开源 AI Agent 平台。</strong></p>\n</blockquote>\n<p>它可以与你日常使用的各种聊天工具无缝集成：</p>\n<ul>\n<li>WhatsApp</li>\n<li>Telegram</li>\n<li>Discord</li>\n<li>Slack</li>\n<li>Microsoft Teams</li>\n</ul>\n<p>无论你身在何处，只要能发消息，就能随时指挥你的 AI 助手。</p>\n<p>官网：</p>\n<p>👉 <a href=\"https://openclaw.ai/\" rel=\"noopener nofollow\" target=\"_blank\">https://openclaw.ai/</a></p>\n<hr />\n<h1 id=\"安装quickstart\">安装（QuickStart）</h1>\n<p>下面是官方提供的快速上手流程，基本一路回车 + 选择即可完成。</p>\n<ol>\n<li>快速安装 <code>curl -fsSL https://openclaw.ai/install.sh | bash</code></li>\n<li>提示 <em>I understand this is powerful and inherently risky</em> → 选择 <strong>Yes</strong></li>\n<li>Onboarding mode → <strong>QuickStart</strong></li>\n<li>Model / auth provider → <strong>Z.AI (GLM 4.7)</strong></li>\n<li>输入 <strong>Z.AI API Key</strong></li>\n<li>Default model → 默认</li>\n<li>Select channel → <strong>WhatsApp (QR link)</strong></li>\n<li>WhatsApp phone setup → <strong>This is my personal phone number</strong></li>\n<li>输入你的 <strong>WhatsApp 注册手机号</strong></li>\n<li>Configure skills now? → <strong>Yes</strong></li>\n<li>Node manager → <strong>npm</strong></li>\n<li>Install missing skill dependencies → <strong>Skip for now</strong></li>\n<li>GOOGLE_PLACES_API_KEY → <strong>No</strong></li>\n<li>Enable hooks → <strong>Skip for now</strong></li>\n<li>Hatch your bot → <strong>Hatch in TUI (recommended)</strong></li>\n</ol>\n<p><img alt=\"PixPin_2026-02-01_22-35-27.png\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"openclaw-能做什么\">OpenClaw 能做什么？</h1>\n<p>你可以把 OpenClaw 理解为：</p>\n<blockquote>\n<p><strong>一个 24 小时在线、可长期运行、能记住你习惯的「数字员工」。</strong></p>\n</blockquote>\n<p>它不仅能一次性完成任务，还可以：</p>\n<ul>\n<li>持续执行</li>\n<li>定时触发</li>\n<li>记住你的偏好</li>\n<li>通过手机聊天远程操控你的电脑</li>\n</ul>\n<h3 id=\"一些真实使用场景\">一些真实使用场景</h3>\n<ol>\n<li>\n<p><strong>信息收集与简报</strong></p>\n<blockquote>\n<p>“查一下 GitHub 今日热榜，整理成简报，每天早上 8 点发给我。”</p>\n</blockquote>\n</li>\n<li>\n<p><strong>自动化下载</strong></p>\n<blockquote>\n<p>“去某学习网站，帮我下载一套 Python 教学视频。”</p>\n</blockquote>\n</li>\n<li>\n<p><strong>抢票 / 抢资源</strong><br />\n有网友分享：通过 OpenClaw 成功抢到了高铁票（是否成功取决于运气 + 网络环境）。</p>\n</li>\n<li>\n<p><strong>浏览器与系统操作</strong><br />\n自动操作网页、表单填写、数据整理，真正做到「替你点鼠标」。</p>\n</li>\n</ol>\n<p><img alt=\"PixPin_2026-02-01_22-50-44.png\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"不可忽视的弊端\">不可忽视的弊端</h1>\n<p>在惊艳之外，OpenClaw 也并非没有成本。</p>\n<ol>\n<li>\n<p><strong>Token 消耗极大</strong><br />\n如果你用的是按量付费模型，真的会“烧钱”，建议先小规模尝试。</p>\n</li>\n<li>\n<p><strong>权限要求非常高</strong><br />\n它几乎等同于“把电脑交给 AI”，</p>\n<blockquote>\n<p>理论上，它<strong>确实有能力清空你的文件</strong>。</p>\n</blockquote>\n<p>所以：</p>\n<ul>\n<li>不要在主力生产环境直接使用</li>\n<li>不要授予不必要的权限</li>\n</ul>\n</li>\n<li>\n<p><strong>国内网络环境有门槛</strong><br />\n需要你具备一定的「KeXue上网」能力，否则体验会大打折扣。</p>\n</li>\n</ol>\n<hr />\n<h1 id=\"如何卸载-openclaw\">如何卸载 OpenClaw</h1>\n<p>如果你只是尝鲜，或者不打算继续使用，可以按下面步骤完整卸载。</p>\n<pre><code class=\"language-bash\">openclaw uninstall\n# 空格+箭头选择全部\n</code></pre>\n<p><img alt=\"PixPin_2026-02-02_09-23-18.png\" class=\"lazyload\" /></p>\n<pre><code class=\"language-bash\"># 定位安装路径\nwhich openclaw\n\n# 全局卸载\nnpm uninstall -g openclaw\n# 或\npnpm remove -g openclaw\n\n# 清理配置和缓存\nrm -rf ~/.openclaw\nrm -rf ~/.config/openclaw\nrm -rf ~/.cache/openclaw\n\n# /Users/用户名/.zshrc 里的openclaw删除下\n</code></pre>\n<hr />\n<h2 id=\"写在最后\">写在最后</h2>\n<p>OpenClaw 的爆火，并不只是又一个“好玩的 AI 项目”，而是一个非常清晰的信号：</p>\n<blockquote>\n<p><strong>AI Agent 正在从实验室，走向普通人的真实生活。</strong></p>\n</blockquote>\n<p>它或许还不完美，甚至有点危险，但毫无疑问——</p>\n<p><strong>未来，越来越多的工作，真的会交给 AI 来完成。</strong></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 10:08</span>&nbsp;\n<a href=\"https://www.cnblogs.com/bugshare\">BugShare</a>&nbsp;\n阅读(<span id=\"post_view_count\">71</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Seata实现分布式事务：大白话全剖析（核心讲透AT模式）",
      "link": "https://www.cnblogs.com/sun-10387834/p/19584278",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19584278\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 14:16\">\n    <span>Seata实现分布式事务：大白话全剖析（核心讲透AT模式）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Seata 本质是<strong>把分布式事务的各种经典方案（2PC、TCC、Saga、XA）做了极致封装和优化</strong>的框架，不用你从零写底层逻辑，只需要简单配置和少量注解，就能落地分布式事务。</p>\n<p>它的核心设计是<strong>拆分全局事务为多个本地事务</strong>，由Seata统一协调管理，保证这些本地事务要么全提交、要么全回滚；而且Seata对Java微服务（Spring Cloud/Dubbo）的侵入性极低，这也是它成为中小企业首选的关键。</p>\n<p>先讲Seata的<strong>3个核心角色</strong>（大白话比喻，理解了角色才能懂流程），这是所有模式的基础，记牢这3个，后面的逻辑一眼就能看透：</p>\n<h3 id=\"seata三大核心角色必懂\">Seata三大核心角色（必懂）</h3>\n<ol>\n<li><strong>TC（Transaction Coordinator）：事务协调者</strong> → 全场<strong>总指挥</strong><br />\n独立的Seata服务端（需要单独部署），负责创建/管理全局事务、分配全局事务ID（XID），协调所有参与者的提交/回滚，是整个分布式事务的“大脑”。</li>\n<li><strong>TM（Transaction Manager）：事务管理器</strong> → 事务<strong>发起者</strong><br />\n就是你的<strong>业务入口服务</strong>（比如电商下单的「订单服务」），负责向TC<strong>开启全局事务</strong>，并最终向TC发起「全局提交」或「全局回滚」的请求。</li>\n<li><strong>RM（Resource Manager）：资源管理器</strong> → 事务<strong>参与者</strong><br />\n所有涉及数据操作的服务/数据库（比如下单场景的「库存服务」「支付服务」），负责管理本地事务，向TC<strong>注册分支事务</strong>（每个RM的本地事务都是一个「分支事务」），并接收TC的指令，执行本地事务的提交/回滚。</li>\n</ol>\n<p><strong>核心关联</strong>：一个<strong>全局事务</strong> = 1个TM发起 + 1个TC协调 + N个RM参与（N个分支事务），所有操作都通过<strong>全局唯一的XID</strong>关联（XID是分布式事务的“身份证”，微服务调用链中必须透传XID，Seata会自动做这件事）。</p>\n<hr />\n<h2 id=\"重点seata最常用的at模式自动事务90场景用它\">重点：Seata最常用的AT模式（自动事务，90%场景用它）</h2>\n<p>Seata支持AT、TCC、Saga、XA四种模式，其中<strong>AT模式是默认、最主流的</strong>，也是最贴合日常开发的——<strong>几乎无业务侵入</strong>（只加一个注解）、<strong>性能接近本地事务</strong>、<strong>自动完成回滚补偿</strong>，完美适配互联网高并发场景，下面用大白话讲透它的实现原理（核心是<strong>改进版的2PC</strong>，解决了原生2PC性能差、锁资源久的问题）。</p>\n<p>先给AT模式定调：<strong>基于本地事务+undo log的自动两阶段提交</strong>，核心创新是<strong>第一阶段就执行本地事务并提交，释放数据库锁</strong>，第二阶段只做“确认”或“回滚补偿”，彻底解决了原生2PC的性能瓶颈。</p>\n<h3 id=\"前置条件at模式必须满足\">前置条件（AT模式必须满足）</h3>\n<ol>\n<li>数据库支持<strong>本地事务</strong>（MySQL/Oracle/PG等主流数据库都满足）；</li>\n<li>数据库支持<strong>行级锁</strong>（InnoDB引擎，这是MySQL的默认引擎）；</li>\n<li>必须使用Seata提供的<strong>数据源代理</strong>（Seata要拦截SQL，生成undo log，自动代理，不用手动改）。</li>\n</ol>\n<h3 id=\"at模式核心流程分2个阶段结合电商下单场景订单服务tm-库存服务rm\">AT模式核心流程（分2个阶段，结合「电商下单」场景：订单服务（TM）+ 库存服务（RM））</h3>\n<p>全程围绕<strong>XID</strong>关联，TC全程协调，先上大白话流程，再讲关键细节：</p>\n<h4 id=\"场景铺垫\">场景铺垫</h4>\n<ul>\n<li>TM：订单服务（下单接口加<code>@GlobalTransactional</code>注解，发起全局事务）；</li>\n<li>RM1：订单服务的数据库（插入订单记录，分支事务1）；</li>\n<li>RM2：库存服务的数据库（扣减库存，分支事务2）；</li>\n<li>TC：Seata服务端（总指挥）。</li>\n</ul>\n<h3 id=\"第一阶段本地事务提交核心做真实操作留后悔药\">第一阶段：本地事务提交（核心：做真实操作+留“后悔药”）</h3>\n<p>这是AT模式最关键的一步，<strong>所有RM都会执行本地事务并提交</strong>，同时生成<strong>undo log</strong>（后悔药），并向TC注册分支事务，流程如下：</p>\n<ol>\n<li>TM向TC发起「开启全局事务」请求，TC生成<strong>全局唯一XID</strong>并返回给TM；</li>\n<li>XID随微服务调用链透传（Seata自动做，比如Feign/Dubbo调用时，XID会放在请求头里），所有参与的RM都能拿到XID；</li>\n<li><strong>订单服务（RM1）执行本地操作</strong>：执行<code>insert 订单</code>SQL，Seata的数据源代理会拦截这个SQL，做3件事：\n<ul>\n<li>「前置快照」：执行SQL前，先查询要操作的数据，保存<strong>数据快照</strong>（比如订单表的初始状态：无订单）；</li>\n<li>「执行SQL」：真正插入订单记录，完成业务操作；</li>\n<li>「生成undo log」：把<strong>前置快照+当前数据+SQL类型</strong>（插入/更新/删除）封装成undo log，写入数据库的<strong>undo_log表</strong>（Seata自动创建），这就是“后悔药”；</li>\n</ul>\n</li>\n<li>RM1<strong>提交本地事务</strong>，并立即释放数据库的行级锁（原生2PC的致命问题就是不提交、不释放锁，AT模式这里直接提交，性能拉满）；</li>\n<li>RM1向TC注册「订单分支事务」，告知TC：我这步操作完成了，留了undo log，随时可以回滚；</li>\n<li>库存服务（RM2）收到带XID的调用请求，重复<strong>步骤3-5</strong>：扣减库存→生成undo log→提交本地事务→注册库存分支事务到TC。</li>\n</ol>\n<p><strong>第一阶段结束</strong>：所有RM的本地事务都已提交，数据已经变更，锁全部释放，业务无感知；如果其中任何一个RM执行失败（比如库存不足），直接回滚自己的本地事务，TM感知到后向TC发起「全局回滚」。</p>\n<h3 id=\"第二阶段全局提交-or-全局回滚tc总指挥只做轻量操作\">第二阶段：全局提交 OR 全局回滚（TC总指挥，只做轻量操作）</h3>\n<p>第一阶段所有RM都成功后，TM会向TC发起「全局提交」请求；如果有任何一个RM失败，TM发起「全局回滚」请求，TC根据请求指令，向所有RM下发统一命令。</p>\n<h4 id=\"情况1全局提交最常见轻量到几乎无开销\">情况1：全局提交（最常见，轻量到几乎无开销）</h4>\n<ol>\n<li>TC向所有RM（订单RM、库存RM）下发「全局提交」指令；</li>\n<li>各RM收到指令后，<strong>只做一件事</strong>：异步删除自己的undo log（后悔药没用了，删掉占空间）；</li>\n<li>RM向TC反馈“提交完成”，所有RM反馈后，TC标记全局事务<strong>完成</strong>。</li>\n</ol>\n<p><strong>为什么这么轻量？</strong> 因为第一阶段已经完成了真实的业务操作并提交，第二阶段的提交只是“清理垃圾”，没有任何数据库锁竞争，性能几乎无损耗。</p>\n<h4 id=\"情况2全局回滚有错误吃后悔药恢复数据\">情况2：全局回滚（有错误，吃“后悔药”恢复数据）</h4>\n<p>这是AT模式的核心补偿逻辑，<strong>通过undo log自动回滚数据</strong>，全程无需业务代码介入，流程如下：</p>\n<ol>\n<li>TC向所有RM下发「全局回滚」指令，并附带要回滚的分支事务ID；</li>\n<li>各RM收到指令后，开启<strong>本地小事务</strong>，执行回滚操作：\n<ul>\n<li>从undo_log表中根据分支ID查询对应的undo log（前置快照+当前数据）；</li>\n<li><strong>数据校验</strong>：对比undo log中的「当前数据」和数据库中真实的「当前数据」，确保数据没被其他事务修改（Seata的乐观锁机制，避免脏回滚）；</li>\n<li><strong>恢复数据</strong>：用undo log中的「前置快照」覆盖数据库的当前数据（比如订单RM删除插入的订单记录，库存RM恢复扣减的库存）；</li>\n<li><strong>删除undo log</strong>：回滚完成后，删除该条undo log；</li>\n</ul>\n</li>\n<li>RM提交这个本地回滚事务，向TC反馈“回滚完成”；</li>\n<li>所有RM回滚完成后，TC标记全局事务<strong>回滚成功</strong>。</li>\n</ol>\n<p><strong>关键</strong>：回滚操作是基于本地事务的，快速且无锁竞争，即使个别RM回滚失败，Seata会<strong>自动重试</strong>，直到成功（保证最终回滚）。</p>\n<h3 id=\"at模式的核心优势为什么是90场景的首选\">AT模式的核心优势（为什么是90%场景的首选）</h3>\n<ol>\n<li><strong>几乎无业务侵入</strong>：只需要在事务入口加<code>@GlobalTransactional</code>注解，业务代码一行不用改，开发成本极低；</li>\n<li><strong>性能极高</strong>：第一阶段就提交本地事务、释放锁，解决了原生2PC的性能瓶颈，接近本地事务的性能；</li>\n<li><strong>自动回滚补偿</strong>：基于undo log自动完成回滚，不用像TCC那样手动写补偿代码；</li>\n<li><strong>适配高并发</strong>：无长期锁、轻量提交，完美适配互联网电商、支付等高并发场景。</li>\n</ol>\n<hr />\n<h2 id=\"seata其他模式的实现简单讲按需选择\">Seata其他模式的实现（简单讲，按需选择）</h2>\n<p>Seata封装了所有经典分布式事务方案，除了AT模式，其他模式都是为了适配特殊场景，核心是<strong>Seata帮你处理了底层的协调、重试、幂等、事务上下文传递</strong>，你只需要按规范写少量代码，不用从零开发。</p>\n<h3 id=\"1-seata-tcc模式适配强一致高并发需手动写代码\">1. Seata TCC模式（适配强一致+高并发，需手动写代码）</h3>\n<p>完全遵循TCC的Try-Confirm-Cancel三步，但Seata做了封装：</p>\n<ol>\n<li>你只需要为每个业务写3个方法，分别加<code>@Tcc</code>（主方法）、<code>@Confirm</code>（确认方法）、<code>@Cancel</code>（取消方法）注解；</li>\n<li>Seata自动管理事务上下文（XID），协调各服务的Try/Confirm/Cancel执行；</li>\n<li>自动处理<strong>幂等、空补偿、悬挂</strong>（TCC的三大坑），不用自己写判断逻辑。</li>\n</ol>\n<p><strong>适用场景</strong>：AT模式无法覆盖的场景（比如非数据库操作：调用第三方支付接口、扣减缓存库存）。</p>\n<h3 id=\"2-seata-saga模式适配长事务复杂流程低代码\">2. Seata Saga模式（适配长事务+复杂流程，低代码）</h3>\n<p>专为长流程、多步骤的分布式事务设计，Seata做了两大优化：</p>\n<ol>\n<li><strong>普通Saga</strong>：你写每个步骤的执行方法和补偿方法，Seata按顺序执行，失败则倒序执行补偿；</li>\n<li><strong>状态机Saga</strong>：用<strong>JSON/YAML</strong>定义事务流程（步骤顺序、分支、重试规则），不用写代码，低代码配置，支持复杂的流程（比如分支、并行、条件判断）。</li>\n</ol>\n<p><strong>适用场景</strong>：跨境支付、供应链结算、保险理赔等长流程业务（步骤多、耗时久，甚至跨天）。</p>\n<h3 id=\"3-seata-xa模式原生2pc强一致性能差\">3. Seata XA模式（原生2PC，强一致，性能差）</h3>\n<p>完全实现数据库的XA协议（原生2PC），Seata作为协调者，管理各数据库的XA事务：</p>\n<ol>\n<li>第一阶段：各数据库执行XA prepare（预提交），锁定资源；</li>\n<li>第二阶段：TC下发XA commit/rollback，各数据库执行正式提交/回滚。</li>\n</ol>\n<p><strong>特点</strong>：强一致性（数据库层面保证），但性能差、资源锁定久，<strong>仅适用于对一致性要求极高的低并发场景</strong>（比如银行核心交易）。</p>\n<hr />\n<h2 id=\"seata实现分布式事务的核心亮点总结\">Seata实现分布式事务的核心亮点（总结）</h2>\n<p>Seata之所以能成为Java微服务分布式事务的首选，核心是它解决了传统分布式事务方案的<strong>痛点</strong>，做了极致的工程化优化：</p>\n<ol>\n<li><strong>统一协调</strong>：通过TC/TM/RM三大角色，把分布式事务拆分为“全局事务+分支事务”，统一协调管理，逻辑清晰；</li>\n<li><strong>极简开发</strong>：主流的AT模式几乎无侵入，只加一个注解，开发成本接近本地事务；</li>\n<li><strong>性能优化</strong>：AT模式的“第一阶段提交+undo log回滚”，彻底解决了原生2PC的性能瓶颈，适配高并发；</li>\n<li><strong>全场景覆盖</strong>：封装AT/TCC/Saga/XA四种模式，从高并发到长事务，从无侵入到手动开发，满足所有分布式事务场景；</li>\n<li><strong>自动避坑</strong>：内置幂等、重试、空补偿、悬挂、脏回滚等机制，不用开发者手动处理分布式事务的各种坑；</li>\n<li><strong>无缝集成</strong>：完美适配Spring Boot/Spring Cloud/Dubbo，支持MySQL/Oracle/PG等主流数据库，配置简单，快速落地。</li>\n</ol>\n<hr />\n<h2 id=\"最简落地seata-at模式代码层面让你有直观认知\">最简落地Seata AT模式（代码层面，让你有直观认知）</h2>\n<p>不用复杂配置，只看核心代码，就能知道Seata有多简单（Spring Cloud场景）：</p>\n<h3 id=\"1-入口服务tm事务发起者\">1. 入口服务（TM，事务发起者）</h3>\n<p>只需要在<strong>业务入口方法</strong>上加<code>@GlobalTransactional</code>注解，就是TM，开启全局事务：</p>\n<pre><code class=\"language-java\">@RestController\npublic class OrderController {\n    @Autowired\n    private OrderService orderService;\n    @Autowired\n    private StockFeignClient stockFeignClient; // 调用库存服务的Feign客户端\n\n    // 下单接口：分布式事务入口，TM\n    @GlobalTransactional(rollbackFor = Exception.class) // 加这个注解就够了！\n    @PostMapping(\"/createOrder\")\n    public String createOrder(@RequestParam Long goodsId, @RequestParam Integer num) {\n        // 1. 本地操作：创建订单（RM1，订单服务的本地事务）\n        orderService.createOrder(goodsId, num);\n        // 2. 调用库存服务：扣减库存（RM2，库存服务的本地事务，XID自动透传）\n        Boolean reduceResult = stockFeignClient.reduceStock(goodsId, num);\n        if (!reduceResult) {\n            throw new RuntimeException(\"库存扣减失败，全局回滚\");\n        }\n        return \"下单成功\";\n    }\n}\n</code></pre>\n<h3 id=\"2-参与服务rm库存服务\">2. 参与服务（RM，库存服务）</h3>\n<p><strong>一行注解都不用加</strong>，正常写本地业务代码就行，Seata自动拦截并生成undo log：</p>\n<pre><code class=\"language-java\">@RestController\npublic class StockController {\n    @Autowired\n    private StockService stockService;\n\n    // 扣减库存：RM，普通本地接口\n    @PostMapping(\"/reduceStock\")\n    public Boolean reduceStock(@RequestParam Long goodsId, @RequestParam Integer num) {\n        stockService.reduceStock(goodsId, num); // 正常扣减库存的本地方法\n        return true;\n    }\n}\n</code></pre>\n<p><strong>这就是Seata的威力</strong>：业务代码几乎无改动，只加一个注解，就能实现分布式事务的“要么全成、要么全错”。</p>\n<hr />\n<h3 id=\"核心总结\">核心总结</h3>\n<ol>\n<li>Seata的核心是<strong>拆分全局事务为多个本地事务</strong>，通过TC（总指挥）、TM（发起者）、RM（参与者）三大角色协调，用<strong>XID</strong>关联整个调用链；</li>\n<li>主流的<strong>AT模式</strong>是改进版2PC，核心是「第一阶段本地提交+生成undo log，第二阶段轻量提交/基于undo log自动回滚」，无侵入、高性能，适配90%的互联网场景；</li>\n<li>Seata封装了TCC/Saga/XA模式，分别适配<strong>强一致高并发</strong>、<strong>长流程复杂业务</strong>、<strong>强一致低并发</strong>场景，底层自动处理幂等、重试等分布式坑；</li>\n<li>落地极简单：AT模式只需要在事务入口加<code>@GlobalTransactional</code>注解，业务代码无改动，完美集成Spring Cloud/Dubbo。</li>\n</ol>\n\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19584278\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19584278</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 14:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">26</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Redmi AX6 TTL 救砖记录",
      "link": "https://www.cnblogs.com/sollong/p/19584026",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sollong/p/19584026\" id=\"cb_post_title_url\" title=\"发布于 2026-02-06 13:37\">\n    <span>Redmi AX6 TTL 救砖记录</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        记一次红米 AX6 普砖TTL救砖过程。本文通过 TTL 串口利用 TFTP 在UBoot命令行 修复MIBIB分区表，重新刷入 OpenWrt 固件。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><em>仅做一次记录,可能会有不理解和错误的地方</em></p>\n<h1 id=\"背景\">背景</h1>\n<p>刷过不死Uboot + ImmortalWrt, 想刷回原厂固件,试图刷原厂分区因操作分区表不当成普砖.</p>\n<blockquote>\n<p>砖度判断:<a href=\"https://www.right.com.cn/forum/thread-5181728-1-1.html\" rel=\"noopener nofollow\" target=\"_blank\">引用恩山</a><br />\n一台刷砖的AX6，先判定是普通砖还是深度砖，普通砖TTL可救，深度砖编程器才能救：<br />\n1、普通砖：上电SYS黄灯常亮，过会儿双黄灯闪一下又开始SYS黄灯常亮，然后重复。<br />\n——这种UBOOT未损坏（一般是sysupgrade、ubiformat指令或web里写入固件失败导致）。<br />\n2、深度砖：接上电源，双黄灯闪一下，过几秒双黄灯又闪一下，然后重复。<br />\n——这种UBOOT已损坏（一般刷入新分区表文件后漏拔电重启步骤），请走售后或拆ROM芯片上编程器。</p>\n</blockquote>\n<p>试图小米路由器修复工具救砖,但是不识别,无反应<br />\n在后续的串口信息发现分区表变成这样:</p>\n<pre><code>IPQ807x#   mtdparts\ndevice nand0 &lt;nand0&gt;, # parts = 1\n #: name                size            offset          mask_flags\n 0: fs                  0x023c0000      0x02dc0000      0\n\nactive partition: nand0,0 - (fs) 0x023c0000 @ 0x02dc0000\n\ndefaults:\nmtdids  : none\nmtdparts: none\n</code></pre>\n<p>经判断这次是普通砖,使用TTL救砖.</p>\n<h1 id=\"大致思路\">大致思路</h1>\n<p>重刷分区表和openwrt固件再用小米路由器修复工具刷回原厂固件</p>\n<h1 id=\"准备工作\">准备工作</h1>\n<ol>\n<li>USB转TTL工具 + 杜邦线 这里使用CH340G (记得装驱动)</li>\n</ol>\n<p><img alt=\"test2\" height=\"200\" src=\"https://img2024.cnblogs.com/blog/3309763/202601/3309763-20260131231407423-1048980357.jpg\" width=\"300\" /></p>\n<p><img alt=\"test\" height=\"200\" src=\"https://img2024.cnblogs.com/blog/3309763/202601/3309763-20260131231413635-1323732633.jpg\" width=\"300\" /></p>\n<ol start=\"2\">\n<li><a href=\"https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html\" rel=\"noopener nofollow\" target=\"_blank\">Putty</a> 进行串口通信</li>\n<li><a href=\"https://github.com/PJO2/tftpd64/releases\" rel=\"noopener nofollow\" target=\"_blank\">tftpd64</a> 用于搭建本地 TFTP 服务器，传输文件</li>\n<li><a href=\"https://github.com/ZqinKing/wrt_release/releases\" rel=\"noopener nofollow\" target=\"_blank\">ImmortalWrt</a>原厂分区固件 这里使用immortalwrt-qualcommax-ipq807x-redmi_ax6-stock-squashfs-factory.ubi</li>\n<li>原厂分区表文件mibib.bin</li>\n<li><a href=\"https://bigota.miwifi.com/xiaoqiang/tools/MIWIFIRepairTool.x86.zip\" rel=\"noopener nofollow\" target=\"_blank\">小米路由器修复工具</a></li>\n</ol>\n<p>将分区表文件mibib.bin和固件immortalwrt-qualcommax-ipq807x-redmi_ax6-stock-squashfs-factory.ubi放入tftpd64目录<br />\nimmortalwrt-qualcommax-ipq807x-redmi_ax6-stock-squashfs-factory.ubi在本文中被改名成test.bin</p>\n<h1 id=\"章节1-拆机找ttl触点-连线进行putty串口通信\">章节1 拆机找TTL触点 连线进行Putty串口通信</h1>\n<p>大概在这个位置:<br />\n<img alt=\"202921e8t5jtztgt4ztguc\" height=\"200\" src=\"https://img2024.cnblogs.com/blog/3309763/202601/3309763-20260131231947950-1180083227.png\" width=\"300\" /></p>\n<p>可以焊个4pin针方便连接</p>\n<p><img alt=\"image\" height=\"200\" src=\"https://img2024.cnblogs.com/blog/3309763/202601/3309763-20260131233641930-1376623072.png\" width=\"300\" /></p>\n<p>*CH340G跳线帽需短接在 3.3V 模式 *</p>\n<p>PC插上CH340G 在设备管理器查看它的端口号<br />\n<img alt=\"设备管理器\" height=\"200\" src=\"https://img2024.cnblogs.com/blog/3309763/202602/3309763-20260206134347304-1019943611.png\" width=\"300\" /></p>\n<p>在putty设置:<br />\nConnection type: Serial<br />\nSerial line: COM5 &lt;--用实际CH340G的端口号<br />\nSpeed (Baud rate): 115200</p>\n<p><img alt=\"image\" height=\"200\" src=\"https://img2024.cnblogs.com/blog/3309763/202601/3309763-20260131233134423-1601931815.png\" width=\"300\" /></p>\n<p>然后按照以下逻辑相联</p>\n<pre><code>CH340G GND       &lt;--&gt; 路由器 GND\nCH340G TX (发送) &lt;--&gt; 路由器 RX (接收)\nCH340G RX (接收) &lt;--&gt; 路由器 TX (发送)\nVCC不连\n</code></pre>\n<p><em>路由器通电之后再接TTL,不然路由器无法启动</em></p>\n<p>正常情况应该是路由器开始闪黄灯,putty开始输出:</p>\n<pre><code>...\nU-Boot 2016.01 (Jul 08 2021 - 07:16:48 +0000), Build: jenkins-common_router_openwrt_ota_publish-1455\n\nDRAM:  smem ram ptable found: ver: 1 len: 4\n512 MiB\nNAND:  ONFI device found\nID = 158061c8\nVendor = c8\nDevice = 61\nSF: Unsupported flash IDs: manuf ff, jedec ffff, ext_jedec ffff\nipq_spi: SPI Flash not found (bus/cs/speed/mode) = (0/0/48000000/0)\n128 MiB\nMMC:   sdhci: Node Not found, skipping initialization\n\nPCI1 is not defined in the device tree\nIn:    serial@78B3000\nOut:   serial@78B3000\nErr:   serial@78B3000\nmachid: 8010010\nMMC Device 0 not found\neth5 MAC Address from ART is not valid\nwrite phy_id=1, reg(0x8074):0x0670\nwrite phy_id=2, reg(0x8074):0x0670\nwrite phy_id=3, reg(0x8074):0x0670\nwrite phy_id=4, reg(0x8074):0x0670\nbootwait is on, bootdelay=2\nHit any key to stop autoboot:  0\n trigger button release!\nboot from rootfs 0\n  miwifi: check crash in rmem !\nubi0: attaching mtd1\nubi0: scanning is finished\nUBI init error 22\nErasing NAND...\nErasing at 0x6e0000 -- 100% complete.\nWriting to NAND... OK\nresetting ...\n\n</code></pre>\n<p>我们需要在</p>\n<pre><code class=\"language-bash\">Hit any key to stop autoboot:  0\n</code></pre>\n<p>倒计时结束前按任意键如 Ctrl+C 或者 Enter<br />\n呼出UBOOT命令行 <em>IPQ807x#</em><br />\n如果倒计时过短或者压根没有bootwait,可以试着按住reset再通电再接TTL再试图中断呼出UBOOT命令行</p>\n<pre><code>Hit any key to stop autoboot:  0\n detect button press, continue check 5 secs\n detect button pressed 5 secs !\n confirm to launch xq_upgrade ! &lt;--检测到reset,进入原厂救援模式\n</code></pre>\n<h1 id=\"章节2-修复分区表\">章节2 修复分区表</h1>\n<p>查询当前分区表,发现已经变成以下这种情况了</p>\n<pre><code>IPQ807x#   mtdparts\ndevice nand0 &lt;nand0&gt;, # parts = 1\n #: name                size            offset          mask_flags\n 0: fs                  0x023c0000      0x02dc0000      0\nactive partition: nand0,0 - (fs) 0x023c0000 @ 0x02dc0000\ndefaults:\nmtdids  : none\nmtdparts: none\n</code></pre>\n<blockquote>\n<p>Gemini:<br />\nparts = 1：你的闪存里现在只认出了1个分区。<br />\nName: fs：这就是为什么启动会失败，它找不到 rootfs，只找到了个叫 fs 的残余分区。<br />\nOffset: 0x02dc0000：好消息是，这个地址正好是 AX6 原厂固件 rootfs (系统分区) 的起始物理地址。</p>\n</blockquote>\n<h2 id=\"重刷分区表-mibibbin-到物理地址-0x40000\">重刷分区表 mibib.bin 到物理地址 0x40000</h2>\n<h3 id=\"电脑网卡设置\">电脑网卡设置</h3>\n<p>先设置连接路由器的网卡:<br />\nIP: 192.168.31.100<br />\n掩码: 255.255.255.0<br />\n网关: 192.168.31.1</p>\n<h3 id=\"配置tftpd\">配置Tftpd</h3>\n<p>打开Tftpd64-设置-DHCP<br />\nIP pool start address: 192.168.31.2<br />\nSize of pool: 5<br />\nRouter (Opt 3): 填入 192.168.31.1<br />\nMask: 255.255.255.0<br />\nWINS/DNS: 填 0.0.0.0 或者留空即可。</p>\n<p>Tftpd64主界面<br />\nServer interfaces 选择相应网卡</p>\n<p><img alt=\"image\" height=\"400\" src=\"https://img2024.cnblogs.com/blog/3309763/202602/3309763-20260205204518215-1615573348.png\" width=\"300\" /></p>\n<h3 id=\"重刷分区表\">重刷分区表</h3>\n<h4 id=\"将分区表文件mibibbin-下载到内存\">将分区表文件mibib.bin 下载到内存</h4>\n<p>在UBOOT命令行输入:<br />\n设置TFTP服务器</p>\n<pre><code>IPQ807x# setenv serverip 192.168.31.100\nIPQ807x# setenv ipaddr 192.168.31.2\n</code></pre>\n<pre><code>\nIPQ807x# tftpboot 0x44000000 mibib.bin \n</code></pre>\n<h4 id=\"擦除-mibib-所在的区块\">擦除 MIBIB 所在的区块</h4>\n<pre><code>IPQ807x# nand erase 0x40000 0x40000\n</code></pre>\n<h4 id=\"写入-mibib\">写入 MIBIB</h4>\n<pre><code>IPQ807x# nand write 0x44000000 0x40000 0x40000\n</code></pre>\n<h2 id=\"设置启动标志并重置环境变量\">设置启动标志并重置环境变量</h2>\n<pre><code>IPQ807x# env default -a\nIPQ807x# saveenv\nIPQ807x# reset\n</code></pre>\n<blockquote>\n<p>env default -a<br />\ngemini:<br />\n这步操作相当于给 U-Boot 进行了一次“格式化大脑”。它忘掉了所有错误的旧设置，重启后重新从闪存里读取了你之前刷进去的那个正确的 mibib.bin。</p>\n</blockquote>\n<h1 id=\"章节3-刷入openwrt底包\">章节3 刷入Openwrt底包</h1>\n<h2 id=\"通过tftp下载固件到路由器内存\">通过tftp下载固件到路由器内存</h2>\n<p>重新设置TFTP服务器</p>\n<pre><code>IPQ807x# setenv serverip 192.168.31.100\nIPQ807x# setenv ipaddr 192.168.31.2\n</code></pre>\n<p>下载固件到内存</p>\n<pre><code>IPQ807x# tftpboot 0x44000000 test.bin\n</code></pre>\n<h2 id=\"擦除rootfs分区\">擦除rootfs分区</h2>\n<pre><code>IPQ807x# nand erase 0x2dc0000 0x23c0000\n</code></pre>\n<h2 id=\"将固件写入分区\">将固件写入分区</h2>\n<pre><code>IPQ807x# nand write 0x44000000 0x2dc0000 0x1c50000\n</code></pre>\n<blockquote>\n<p>使用nand write 0x44000000 0x2dc0000 $filesize<br />\n会报错<br />\nIPQ807x# nand write 0x44000000 0x2dc0000 $filesize<br />\nNAND write: device 0 offset 0x2dc0000, size 0x1c403bc<br />\nNAND write to offset 2dc0000 failed -22<br />\nGemini:<br />\nNAND write ... failed -22 是完全预料之中的，也是个“好”错误。<br />\n原因：-22 代表 \"Invalid Argument\" (参数无效)。<br />\n详解：NAND Flash 的写入必须严格按照页大小 (Page Size) 对齐（通常是 2048 字节或 4096 字节）。你的固件大小是 0x1c403bc，末尾的 3bc 说明它没有对齐，所以 U-Boot 拒绝写入。</p>\n</blockquote>\n<h2 id=\"保存环境变量\">保存环境变量</h2>\n<pre><code>IPQ807x# saveenv\nIPQ807x# reset\n</code></pre>\n<p>出现resetting...后重新接TTL线,不出意外的话加载一会后串口应该会显示:</p>\n<pre><code>## Loading kernel from FIT Image at 44000000 ...\n   Using 'config@ac04' configuration\n   Trying 'kernel-1' kernel subimage\n     Description:  ARM64 OpenWrt Linux-6.12.60\n     Type:         Kernel Image\n     Compression:  gzip compressed\n     Data Start:   0x440000e8\n     Data Size:    5599108 Bytes = 5.3 MiB\n     Architecture: AArch64\n     OS:           Linux\n     Load Address: 0x41000000\n     Entry Point:  0x41000000\n     Hash algo:    crc32\n     Hash value:   498fead8\n     Hash algo:    sha1\n     Hash value:   77fc2d898d54e6241736c2f5ad567dcf550ed6dd\n   Verifying Hash Integrity ... crc32+ sha1+ OK\n## Loading fdt from FIT Image at 44000000 ...\n   Using 'config@ac04' configuration\n   Trying 'fdt-1' fdt subimage\n     Description:  ARM64 OpenWrt redmi_ax6-stock device tree blob\n     Type:         Flat Device Tree\n     Compression:  uncompressed\n     Data Start:   0x445571ac\n     Data Size:    49003 Bytes = 47.9 KiB\n     Architecture: AArch64\n     Hash algo:    crc32\n     Hash value:   7aca8bd9\n     Hash algo:    sha1\n     Hash value:   f9759b7825963dbbd670ab22d1b7be2e8c778124\n   Verifying Hash Integrity ... crc32+ sha1+ OK\n   Booting using the fdt blob at 0x445571ac\n   Uncompressing Kernel Image ... OK\n   Loading Device Tree to 4a3f1000, end 4a3fff6a ... OK\nUsing machid 0x8010010 from environment\n\nStarting kernel ...\n\nJumping to AARCH64 kernel via monitor\n\n</code></pre>\n<h1 id=\"章节3-小米路由器修复工具刷回原厂官方固件\">章节3 小米路由器修复工具刷回原厂官方固件</h1>\n<p>进入immortalwrt bash 查看当前分区信息,可以看见已经还原分区表了<br />\n<img alt=\"恢复成功mtd\" height=\"300\" src=\"https://img2024.cnblogs.com/blog/3309763/202602/3309763-20260205221018952-1473979721.png\" width=\"400\" /></p>\n<p>接下来就可以捅reset然后用小米路由器修复工具刷原厂官方固件了<br />\n这部分就省略了</p>\n<h1 id=\"结尾\">结尾</h1>\n<p>感谢网上各路大神的教程和Gemini的帮助,但是貌似bdata丢了,没SN码和MAC地址了<br />\n累了,先不折腾了,下次一定</p>\n<h1 id=\"uboot-日志记录\">Uboot 日志记录:</h1>\n<pre><code>U-Boot 2016.01 (Jul 08 2021 - 07:16:48 +0000), Build: jenkins-common_router_open\n\nDRAM:  smem ram ptable found: ver: 1 len: 4\n512 MiB\nNAND:  ONFI device found\nID = 158061c8\nVendor = c8\nDevice = 61\nSF: Unsupported flash IDs: manuf ff, jedec ffff, ext_jedec ffff\nipq_spi: SPI Flash not found (bus/cs/speed/mode) = (0/0/48000000/0)\n128 MiB\nMMC:   sdhci: Node Not found, skipping initialization\n\nPCI1 is not defined in the device tree\nIn:    serial@78B3000\nOut:   serial@78B3000\nErr:   serial@78B3000\nmachid: 8010010\nMMC Device 0 not found\neth5 MAC Address from ART is not valid\nwrite phy_id=1, reg(0x8074):0x0670\nwrite phy_id=2, reg(0x8074):0x0670\nwrite phy_id=3, reg(0x8074):0x0670\nwrite phy_id=4, reg(0x8074):0x0670\nbootwait is on, bootdelay=2\nHit any key to stop autoboot:  0\n\nNet:   MAC0 addr:9c:9d:7e:5c:d2:31\nPHY ID1: 0x4d\nPHY ID2: 0xd0b1\nEDMA ver 1 hw init\nNum rings - TxDesc:1 (0-0) TxCmpl:1 (7-7)\nRxDesc:1 (15-15) RxFill:1 (7-7)\nipq807x_edma_alloc_rings: successfull\nipq807x_edma_setup_ring_resources: successfull\nipq807x_edma_configure_rings: successfull\nipq807x_edma_hw_init: successfull\nboard_eth_init: ipq807x_edma_init successed\neth0\nIPQ807x#   mtdparts\n\ndevice nand0 &lt;nand0&gt;, # parts = 1\n #: name                size            offset          mask_flags\n 0: fs                  0x023c0000      0x02dc0000      0\n\nactive partition: nand0,0 - (fs) 0x023c0000 @ 0x02dc0000\n\ndefaults:\nmtdids  : none\nmtdparts: none\nIPQ807x# &lt;INTERRUPT&gt;\nIPQ807x# setenv serverip 192.168.31.100\nIPQ807x# setenv ipaddr 192.168.31.2\nIPQ807x# tftpboot 0x44000000 mibib.bin\nipq807x_eth_halt: done\neth0 PHY0 Down Speed :10 Half duplex\neth0 PHY1 up Speed :10 Full duplex\neth0 PHY2 Down Speed :10 Half duplex\neth0 PHY3 up Speed :1000 Full duplex\neth0 PHY4 Down Speed :10 Half duplex\neth0 PHY5 Down Speed :10 Half duplex\nipq807x_eth_init: done\nUsing eth0 device\nTFTP from server 192.168.31.100; our IP address is 192.168.31.2\nFilename 'mibib.bin'.\nLoad address: 0x44000000\nLoading: *\nGot TFTP_OACK: TFTP remote port: changes from 69 to 51212\n#################################################################\n         #######\n         2.1 MiB/s\ndone\nBytes transferred = 1048576 (100000 hex)\nipq807x_eth_halt: done\nIPQ807x# nand erase 0x40000 0x40000\n\nNAND erase: device 0 offset 0x40000, size 0x40000\nErasing at 0x60000 -- 100% complete.\nOK\nIPQ807x# nand write 0x44000000 0x40000 0x40000\n\nNAND write: device 0 offset 0x40000, size 0x40000\n 262144 bytes written: OK\nIPQ807x# tftpboot 0x44000000 test.bin\nipq807x_eth_halt: done\neth0 PHY0 Down Speed :10 Half duplex\neth0 PHY1 up Speed :10 Full duplex\neth0 PHY2 Down Speed :10 Half duplex\neth0 PHY3 up Speed :1000 Full duplex\neth0 PHY4 Down Speed :10 Half duplex\neth0 PHY5 Down Speed :10 Half duplex\nipq807x_eth_init: done\nUsing eth0 device\nTFTP from server 192.168.31.100; our IP address is 192.168.31.2\nFilename 'test.bin'.\nLoad address: 0x44000000\nLoading: *\nGot TFTP_OACK: TFTP remote port: changes from 69 to 51542\n#################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         ###\n         2.1 MiB/s\ndone\nBytes transferred = 29623228 (1c403bc hex)\nipq807x_eth_halt: done\nIPQ807x# nand erase 0x2dc0000 0x23c0000\n\nNAND erase: device 0 offset 0x2dc0000, size 0x23c0000\nErasing at 0x5160000 -- 100% complete.\nOK\nIPQ807x# nand write 0x44000000 0x2dc0000 $filesize\n\nNAND write: device 0 offset 0x2dc0000, size 0x1c403bc\nNAND write to offset 2dc0000 failed -22\n 0 bytes written: ERROR\nIPQ807x# &lt;INTERRUPT&gt;\nIPQ807x# reset\nresetting ...\nPCI1 is not defined in the device tree\nIn:    serial@78B3000\nOut:   serial@78B3000\nErr:   serial@78B3000\nmachid: 8010010\nMMC Device 0 not found\neth5 MAC Address from ART is not valid\nwrite phy_id=1, reg(0x8074):0x0670\nwrite phy_id=2, reg(0x8074):0x0670\nwrite phy_id=3, reg(0x8074):0x0670\nwrite phy_id=4, reg(0x8074):0x0670\nbootwait is on, bootdelay=2\nHit any key to stop autoboot:  0\n\nNet:   MAC0 addr:9c:9d:7e:5c:d2:31\nPHY ID1: 0x4d\nPHY ID2: 0xd0b1\nEDMA ver 1 hw init\nNum rings - TxDesc:1 (0-0) TxCmpl:1 (7-7)\nRxDesc:1 (15-15) RxFill:1 (7-7)\nipq807x_edma_alloc_rings: successfull\nipq807x_edma_setup_ring_resources: successfull\nipq807x_edma_configure_rings: successfull\nipq807x_edma_hw_init: successfull\nboard_eth_init: ipq807x_edma_init successed\neth0\nIPQ807x# &lt;INTERRUPT&gt;\nIPQ807x# mtdparts\n\ndevice nand0 &lt;nand0&gt;, # parts = 1\n #: name                size            offset          mask_flags\n 0: fs                  0x023c0000      0x02dc0000      0\n\nactive partition: nand0,0 - (fs) 0x023c0000 @ 0x02dc0000\n\ndefaults:\nmtdids  : none\nmtdparts: none\nIPQ807x# &lt;INTERRUPT&gt;\nIPQ807x# setenv serverip 192.168.31.100\nIPQ807x# setenv ipaddr 192.168.31.2\nIPQ807x# tftpboot 0x44000000 test.bin\nipq807x_eth_halt: done\neth0 PHY0 Down Speed :10 Half duplex\neth0 PHY1 up Speed :10 Full duplex\neth0 PHY2 Down Speed :10 Half duplex\neth0 PHY3 up Speed :1000 Full duplex\neth0 PHY4 Down Speed :10 Half duplex\neth0 PHY5 Down Speed :10 Half duplex\nipq807x_eth_init: done\nUsing eth0 device\nTFTP from server 192.168.31.100; our IP address is 192.168.31.2\nFilename 'test.bin'.\nLoad address: 0x44000000\nLoading: *\nGot TFTP_OACK: TFTP remote port: changes from 69 to 57976\n#################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         #################################################################\n         ############################\n         2.1 MiB/s\ndone\nBytes transferred = 20447232 (1380000 hex)\nipq807x_eth_halt: done\nIPQ807x# &lt;INTERRUPT&gt;\nIPQ807x# nand write 0x44000000 0x2dc0000 0x1380000\n\nNAND write: device 0 offset 0x2dc0000, size 0x1380000\n 20447232 bytes written: OK\nIPQ807x# setenv flag_boot_rootfs 0\nIPQ807x# setenv flag_last_success 0\nIPQ807x# setenv flag_try_sys1_failed 8\nIPQ807x# setenv flag_try_sys2_failed 8\nIPQ807x# saveenv\nSaving Environment to NAND...\nErasing NAND...\nErasing at 0x6e0000 -- 100% complete.\nWriting to NAND... OK\nIPQ807x# reset\nresetting ...\n\n\nU-Boot 2016.01 (Jul 08 2021 - 07:16:48 +0000), Build: jenkins-common_router_openwrt_ota_publish-1455\n\nDRAM:  smem ram ptable found: ver: 1 len: 4\n512 MiB\nNAND:  ONFI device found\nID = 158061c8\nVendor = c8\nDevice = 61\nSF: Unsupported flash IDs: manuf ff, jedec ffff, ext_jedec ffff\nipq_spi: SPI Flash not found (bus/cs/speed/mode) = (0/0/48000000/0)\n128 MiB\nMMC:   sdhci: Node Not found, skipping initialization\n\nPCI1 is not defined in the device tree\nIn:    serial@78B3000\nOut:   serial@78B3000\nErr:   serial@78B3000\nmachid: 8010010\nMMC Device 0 not found\neth5 MAC Address from ART is not valid\nwrite phy_id=1, reg(0x8074):0x0670\nwrite phy_id=2, reg(0x8074):0x0670\nwrite phy_id=3, reg(0x8074):0x0670\nwrite phy_id=4, reg(0x8074):0x0670\nbootwait is on, bootdelay=2\nHit any key to stop autoboot:  0\n trigger button release!\nboot from rootfs 0\n  miwifi: check crash in rmem !\nubi0: attaching mtd1\nubi0: scanning is finished\nUBI init error 22\nErasing NAND...\nErasing at 0x6e0000 -- 100% complete.\nWriting to NAND... OK\nresetting ...\n\n\nU-Boot 2016.01 (Jul 08 2021 - 07:16:48 +0000), Build: jenkins-common_router_openwrt_ota_publish-1455\n\nDRAM:  smem ram ptable found: ver: 1 len: 4\n512 MiB\nNAND:  ONFI device found\nID = 158061c8\nVendor = c8\nDevice = 61\nSF: Unsupported flash IDs: manuf ff, jedec ffff, ext_jedec ffff\nipq_spi: SPI Flash not found (bus/cs/speed/mode) = (0/0/48000000/0)\n128 MiB\nMMC:   sdhci: Node Not found, skipping initialization\n\nPCI1 is not defined in the device tree\nIn:    serial@78B3000\nOut:   serial@78B3000\nErr:   serial@78B3000\nmachid: 8010010\nMMC Device 0 not found\neth5 MAC Address from ART is not valid\nwrite phy_id=1, reg(0x8074):0x0670\nwrite phy_id=2, reg(0x8074):0x0670\nwrite phy_id=3, reg(0x8074):0x0670\nwrite phy_id=4, reg(0x8074):0x0670\nbootwait is on, bootdelay=2\nHit any key to stop autoboot:  0\n\nNet:   MAC0 addr:9c:9d:7e:5c:d2:31\nPHY ID1: 0x4d\nPHY ID2: 0xd0b1\nEDMA ver 1 hw init\nNum rings - TxDesc:1 (0-0) TxCmpl:1 (7-7)\nRxDesc:1 (15-15) RxFill:1 (7-7)\nipq807x_edma_alloc_rings: successfull\nipq807x_edma_setup_ring_resources: successfull\nipq807x_edma_configure_rings: successfull\nipq807x_edma_hw_init: successfull\nboard_eth_init: ipq807x_edma_init successed\neth0\nIPQ807x# env default -a\n## Resetting to default environment\nIPQ807x# saveenv\nSaving Environment to NAND...\nErasing NAND...\nErasing at 0x6e0000 -- 100% complete.\nWriting to NAND... OK\nIPQ807x# reset\nresetting ...\n\n\nU-Boot 2016.01 (Jul 08 2021 - 07:16:48 +0000), Build: jenkins-common_router_openwrt_ota_publish-1455\n\nDRAM:  smem ram ptable found: ver: 1 len: 4\n512 MiB\nNAND:  ONFI device found\nID = 158061c8\nVendor = c8\nDevice = 61\nSF: Unsupported flash IDs: manuf ff, jedec ffff, ext_jedec ffff\nipq_spi: SPI Flash not found (bus/cs/speed/mode) = (0/0/48000000/0)\n128 MiB\nMMC:   sdhci: Node Not found, skipping initialization\n\nPCI1 is not defined in the device tree\nIn:    serial@78B3000\nOut:   serial@78B3000\nErr:   serial@78B3000\nmachid: 8010010\nMMC Device 0 not found\neth5 MAC Address from ART is not valid\nwrite phy_id=1, reg(0x8074):0x0670\nwrite phy_id=2, reg(0x8074):0x0670\nwrite phy_id=3, reg(0x8074):0x0670\nwrite phy_id=4, reg(0x8074):0x0670\nHit any key to stop autoboot:  0\n trigger button release!\nboot from rootfs 1\n  miwifi: check crash in rmem !\nubi0: attaching mtd1\nubi0: scanning is finished\nubi0: volume 2 (\"rootfs_data\") re-sized from 9 to 108 LEBs\nubi0: attached mtd1 (name \"mtd=0\", size 35 MiB)\nubi0: PEB size: 131072 bytes (128 KiB), LEB size: 126976 bytes\nubi0: min./max. I/O unit sizes: 2048/2048, sub-page size 2048\nubi0: VID header offset: 2048 (aligned 2048), data offset: 4096\nubi0: good PEBs: 286, bad PEBs: 0, corrupted PEBs: 0\nubi0: user volume: 3, internal volumes: 1, max. volumes count: 128\nubi0: max/mean erase counter: 1/0, WL threshold: 4096, image sequence number: 1764934210\nubi0: available PEBs: 0, total reserved PEBs: 286, PEBs reserved for bad PEB handling: 20\nRead 0 bytes from volume kernel to 44000000\nNo size specified -&gt; Using max size (5713920)\nCould not find PCI in device tree\nErasing NAND...\nErasing at 0x6e0000 -- 100% complete.\nWriting to NAND... OK\n## Loading kernel from FIT Image at 44000000 ...\n   Using 'config@ac04' configuration\n   Trying 'kernel-1' kernel subimage\n     Description:  ARM64 OpenWrt Linux-6.12.60\n     Type:         Kernel Image\n     Compression:  gzip compressed\n     Data Start:   0x440000e8\n     Data Size:    5599108 Bytes = 5.3 MiB\n     Architecture: AArch64\n     OS:           Linux\n     Load Address: 0x41000000\n     Entry Point:  0x41000000\n     Hash algo:    crc32\n     Hash value:   498fead8\n     Hash algo:    sha1\n     Hash value:   77fc2d898d54e6241736c2f5ad567dcf550ed6dd\n   Verifying Hash Integrity ... crc32+ sha1+ OK\n## Loading fdt from FIT Image at 44000000 ...\n   Using 'config@ac04' configuration\n   Trying 'fdt-1' fdt subimage\n     Description:  ARM64 OpenWrt redmi_ax6-stock device tree blob\n     Type:         Flat Device Tree\n     Compression:  uncompressed\n     Data Start:   0x445571ac\n     Data Size:    49003 Bytes = 47.9 KiB\n     Architecture: AArch64\n     Hash algo:    crc32\n     Hash value:   7aca8bd9\n     Hash algo:    sha1\n     Hash value:   f9759b7825963dbbd670ab22d1b7be2e8c778124\n   Verifying Hash Integrity ... crc32+ sha1+ OK\n   Booting using the fdt blob at 0x445571ac\n   Uncompressing Kernel Image ... OK\n   Loading Device Tree to 4a3f1000, end 4a3fff6a ... OK\nUsing machid 0x8010010 from environment\n\nStarting kernel ...\n\nJumping to AARCH64 kernel via monitor\n\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-06 13:37</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sollong\">九日不见</a>&nbsp;\n阅读(<span id=\"post_view_count\">37</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}