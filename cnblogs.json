{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "OddAgent：一个通用的意图、指令识别框架",
      "link": "https://www.cnblogs.com/oddmeta/p/19450366",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/oddmeta/p/19450366\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 09:02\">\n    <span>OddAgent：一个通用的意图、指令识别框架</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"OddAgent：一个通用的意图、指令识别框架\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3718265/202601/3718265-20260107090149523-2082541314.png\" />\n        以[小落同学](https://x.oddmeta.net \"小落同学\")而言，她支持天气预报，会议调度，智能家居控制等多种智能体功能，她的做法是部署多个不同的智能体，也即：启动多个oddagent，每个oddagent配置一个智能体配置，并绑定一个端口，然后前置一个工作流接受用户输入，并根据用户的输出再导到不同的oddagent过去处理。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"20260106-oddagent一个通用的意图指令识别框架\">20260106 OddAgent：一个通用的意图、指令识别框架</h1>\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">目录</div><ul><li><a href=\"#20260106-oddagent一个通用的意图指令识别框架\" rel=\"noopener nofollow\">20260106 OddAgent：一个通用的意图、指令识别框架</a><ul><li><a href=\"#一功能特性\" rel=\"noopener nofollow\">一、功能特性</a><ul><li><a href=\"#1-框架特性\" rel=\"noopener nofollow\">1. 框架特性</a></li><li><a href=\"#2-示例功能\" rel=\"noopener nofollow\">2. 示例功能</a></li></ul></li><li><a href=\"#二快速开始\" rel=\"noopener nofollow\">二、快速开始</a></li><li><a href=\"#三创建你自己的智能体项目\" rel=\"noopener nofollow\">三、创建你自己的智能体项目</a><ul><li><a href=\"#1-步骤一在任意你想要的目录下创建一个目录\" rel=\"noopener nofollow\">1. 步骤一：在任意你想要的目录下创建一个目录</a></li><li><a href=\"#2-步骤二下载项目配置样例\" rel=\"noopener nofollow\">2. 步骤二：下载项目配置样例</a></li></ul></li><li><a href=\"#四配置你自己的系统配置\" rel=\"noopener nofollow\">四、配置你自己的系统配置</a><ul><li><a href=\"#1-大模型配置\" rel=\"noopener nofollow\">1. 大模型配置</a></li><li><a href=\"#2-智能体配置\" rel=\"noopener nofollow\">2. 智能体配置</a></li></ul></li><li><a href=\"#五-智能体技能配置\" rel=\"noopener nofollow\">五. 智能体技能配置</a></li><li><a href=\"#六运行测试你自己的智能体\" rel=\"noopener nofollow\">六、运行测试你自己的智能体</a><ul><li><a href=\"#1-启动oddagent智能体后台\" rel=\"noopener nofollow\">1. 启动oddagent智能体后台</a></li><li><a href=\"#2-启动测试界面\" rel=\"noopener nofollow\">2. 启动测试界面</a><ul><li><a href=\"#1界面测试\" rel=\"noopener nofollow\">1）界面测试</a></li><li><a href=\"#2实际api测试\" rel=\"noopener nofollow\">2）实际API测试</a></li></ul></li></ul></li><li><a href=\"#七进阶用法同时运行多个智能体\" rel=\"noopener nofollow\">七、进阶用法：同时运行多个智能体</a><ul><li><a href=\"#1-用一个oddagent搞定\" rel=\"noopener nofollow\">1. 用一个oddagent搞定</a></li><li><a href=\"#2-用多个oddagent分开部署\" rel=\"noopener nofollow\">2. 用多个oddagent分开部署</a></li></ul></li><li><a href=\"#八广而告之\" rel=\"noopener nofollow\">八、广而告之</a></li></ul></li></ul></div><p></p>\n<p>想自己动手来手搓一个完全属于你自己的“小爱同学”、“小艺”吗？如果有你这么一个想法，而又不知道该如何开始的话，那么<a href=\"https://pypi.org/project/oddagent/\" rel=\"noopener nofollow\" target=\"_blank\" title=\"OddAgent\">OddAgent</a>项目可以成为你非常容易上手的开源项目。</p>\n<p>本来这个功能是<a href=\"https://x.oddmeta.net\" rel=\"noopener nofollow\" target=\"_blank\" title=\"小落同学\">小落同学</a>在2024年初就已经支持，由于前阵子公司老板说需要做一个基于LLM的智能助手系统，因此就先从小落同学项目里把相关的代码摘了一下出来，单独搞了一个OddAgent项目出来，作为一个基于LLM的智能助手系统，提供多轮问答、流式AI聊天等功能独立项目来演进。</p>\n<p>OddAgent作为一个通用的意图、指令识别框架，跟业务无关，效果识别的准确率，可识别的能力，完全由你的智能体技术配置文件决定。</p>\n<p>同时，<font color=\"red\"><strong>OddAgent只负责识别意图、指令</strong></font>，不负责实现具体的功能。通过OddAgent识别出来意图、指令后，你需要<font color=\"red\"><strong>自行实现工具</strong></font>逻辑，并调用对应的工具，完成相应的功能。</p>\n<div align=\"center\">\n  <img alt=\"OddAgent Logo\" class=\"lazyload\" width=\"400\" />\n<p><a href=\"https://docs.oddmeta.net/\" rel=\"noopener nofollow\" target=\"_blank\"><img alt=\"Documentation\" class=\"lazyload\" /></a><br />\n<a href=\"LICENSE\" rel=\"noopener nofollow\" target=\"_blank\"><img alt=\"License\" class=\"lazyload\" /></a></p>\n</div>\n<h2 id=\"一功能特性\">一、功能特性</h2>\n<h3 id=\"1-框架特性\">1. 框架特性</h3>\n<ul>\n<li>支持多轮对话</li>\n<li>支持流式AI聊天接口</li>\n<li>工具模板化处理</li>\n<li>支持语音对话（需要自行部署 <a href=\"https://github.com/oddmeta/oddasr\" rel=\"noopener nofollow\" target=\"_blank\" title=\"OddAsr项目\">OddAsr项目</a>，并在config.json中将OddAsr部署的IP地址指向OddAsr所在的服务器）</li>\n</ul>\n<blockquote>\n<p>OddAsr项目位于：<a href=\"https://github.com/oddmeta/oddasr\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/oddmeta/oddasr</a> ，若需要语音的支持，请自行部署。</p>\n</blockquote>\n<h3 id=\"2-示例功能\">2. 示例功能</h3>\n<p>根据视频会议的功能特性，在示例中实现了如下的助手功能：</p>\n<ul>\n<li>预约会议服务，可创建指定时间、地点的会议。</li>\n<li>创建会议服务。</li>\n<li>结束会议服务。</li>\n<li>加入会议服务，可加入指定会议。</li>\n<li>退出会议服务。</li>\n<li>邀请参会人服务，可邀请指定会议的参会人。</li>\n<li>挂断参会人服务，可挂断指定会议的参会人。</li>\n<li>打开摄像头服务。</li>\n<li>关闭摄像头服务。</li>\n<li>打开麦克风服务。</li>\n<li>关闭麦克风服务。</li>\n<li>发送双流服务。</li>\n<li>停止双流服务。</li>\n<li>打开同声字幕服务。</li>\n<li>打开会议纪要服务。</li>\n<li>关闭会议纪要服务。</li>\n</ul>\n<h2 id=\"二快速开始\">二、快速开始</h2>\n<p>建议在一个虚拟环境里安装，以避免与其它的产品和项目冲突。我个人习惯用conda，你用venv, uv，poetry什么也都OK。下面以conda为例介绍整个安装。</p>\n<p>环境要求: Python 3.10+</p>\n<ul>\n<li>\n<ol>\n<li>创建测试用的虚拟环境</li>\n</ol>\n</li>\n</ul>\n<pre><code class=\"language-bash\">conda create -n oddagent_test python==3.12\nconda activate oddagent_test\n</code></pre>\n<ul>\n<li>\n<ol start=\"2\">\n<li>在虚拟环境里安装OddAgent</li>\n</ol>\n</li>\n</ul>\n<pre><code class=\"language-bash\">pip install -i https://pypi.org/simple/ oddagent\n</code></pre>\n<blockquote>\n<p>非官方的镜像站可能不一定能找到最新版本，因此建议使用pypi官方源。</p>\n</blockquote>\n<h2 id=\"三创建你自己的智能体项目\">三、创建你自己的智能体项目</h2>\n<h3 id=\"1-步骤一在任意你想要的目录下创建一个目录\">1. 步骤一：在任意你想要的目录下创建一个目录</h3>\n<p>如：<code>d:\\\\myagent</code> 或者 <code>/home/user/myagent</code></p>\n<h3 id=\"2-步骤二下载项目配置样例\">2. 步骤二：下载项目配置样例</h3>\n<p>项目配置样例：<a href=\"https://oddmeta.net/tools/oddagent/config.json.sample\" rel=\"noopener nofollow\" target=\"_blank\">https://oddmeta.net/tools/oddagent/config.json.sample</a><br />\n智能体配置样例：<a href=\"https://oddmeta.net/tools/oddagent/conference_config.json\" rel=\"noopener nofollow\" target=\"_blank\">https://oddmeta.net/tools/oddagent/conference_config.json</a></p>\n<p>下载好后放在你前面创建的目录下。然后复制<code>config.json.sample</code>，并将其改名为<code>config.json</code></p>\n<p>然后开始调整设置config.json里配置你自己的系统配置</p>\n<h2 id=\"四配置你自己的系统配置\">四、配置你自己的系统配置</h2>\n<p>在<code>config.json</code>系统配置里，必改的内容主要是两个：</p>\n<ul>\n<li>大模型配置：需要将你自己用的大模型的地址<code>GPT_URL</code>，模型名<code>MODEL</code>，以及<code>API_KEY</code>在配置里填一下</li>\n<li>智能体的配置：指定OddAgent启用哪个智能体。如果你有多个不同的智能体希望同时运行的话，可以参考后面的介绍《<code>进阶用法：同时运行多个智能体</code>》</li>\n</ul>\n<p>下面是一个系统配置的示例。</p>\n<h3 id=\"1-大模型配置\">1. 大模型配置</h3>\n<pre><code class=\"language-bash\">  \"GPT_URL\": \"https://qianfan.baidubce.com/v2/chat/completions\",\n  \"MODEL\": \"ernie-4.5-turbo-128k\",\n  \"API_KEY\": \"your api key\",\n</code></pre>\n<h3 id=\"2-智能体配置\">2. 智能体配置</h3>\n<pre><code class=\"language-bash\">  \"TOOL_CONFIG_FILE_EXT\": \"_config.py\",\n  \"TOOL_CONFIG_FILE\": \"agents/xiaoluo/xiaoluo_config.py\",\n</code></pre>\n<h2 id=\"五-智能体技能配置\">五. 智能体技能配置</h2>\n<p>OddAgent支持通过JSON文件配置不同的智能体技能，配置文件位于你的项目根目录下<code>agents</code>目录下。</p>\n<p>在agent_tool_list字段下面，将你要实现的功能一个个加进去：</p>\n<ul>\n<li><code>tool_name</code>： 工具名。建议可以是实际这个工具在实现时需要调用的API的名字。</li>\n<li><code>name</code>: 详细工具名。一个实际的、用户要以看在懂的名字。</li>\n<li><code>description</code>: 工具具体介绍。</li>\n<li><code>example</code>: 可选。如果这个工具是需要带调用参数的，建议在这里具体介绍一下，这里的介绍是会带在prompt提示词里送给大模型，让大模型来更清楚明白的了解这个工具所对应的意图（intent），以及更准确的去解析出此工具对应的slot(槽位)。</li>\n<li><code>parameters</code>: 可选。如果这个工具是需要带调用参数的，所有的参数需要在这里列示一下。同example一样，这里的内容也是会在prompt里带给大模型的，以便大模型更精准的解析意图及槽位。</li>\n<li><code>enabled</code>: 启用与否</li>\n<li><code>tool_api_url</code>: 【不建议使用】识别出工具意图后，实际实现该工具所需要调用的API的地址。</li>\n<li><code>tool_api_headers</code>: 【不建议使用】调用工具API时，需要在API的头信息里带的参数列表，如认证的token。</li>\n<li><code>tool_api_method</code>: 【不建议使用】调用工具API时，使用的方法（method），比如：GET/POST/PUT/DELETE等。</li>\n</ul>\n<p>注意事项：<br />\n<font color=\"red\"><strong>当前开源版本每个tool只提供一个parameter槽位的支持，请匆填充多个parameter，否则测试时会一直在要求你补充。</strong></font></p>\n<p>以下是一个示例配置。</p>\n<pre><code class=\"language-json\">{\n  \"global_variants\": [],\n  \"agent_tool_list\": [],\n    {\n      \"tool_name\": \"meeting_schedule\",\n      \"name\": \"预约会议\",\n      \"description\": \"预约会议服务，可创建指定时间、地点的会议。\",\n      \"example\": \"JSON：[{'name': 'time', 'desc': '会议时间，格式为yyyy-MM-dd HH:mm:ss', 'value': ''} ]\\n输入：帮我预约一个2046年4月18日10:00:00的会议\\n答：{ 'time': '2046-04-18 10:00:00'}\",\n      \"parameters\": [\n        {\"name\": \"time\", \"desc\": \"会议时间，格式为yyyy-MM-dd HH:mm:ss\", \"type\": \"string\", \"required\": false},\n      ],\n      \"enabled\": true,\n      \"tool_api_url\": \"https://api.oddmeta.net/api/meeting_schedule\",\n      \"tool_api_headers\": \"{'Content-Type': 'application/json', 'Authorization': '{{ api_key }}'}\",\n      \"tool_api_method\": \"POST\"\n    }\n  ]\n}\n</code></pre>\n<h2 id=\"六运行测试你自己的智能体\">六、运行测试你自己的智能体</h2>\n<h3 id=\"1-启动oddagent智能体后台\">1. 启动oddagent智能体后台</h3>\n<p>在你创建的自己的智能体项目的目录下，打开一个terminal命令行，然后启动oddagent。当然你也可以自己写个简单的脚本来实现启动或者自动启动。</p>\n<p>启动命令：<code>oddagent -c config.json</code></p>\n<h3 id=\"2-启动测试界面\">2. 启动测试界面</h3>\n<h4 id=\"1界面测试\">1）界面测试</h4>\n<p>oddagent后台加了一个简单的Web界面，专门用于测试和调试你的智能体技能配置，默认的地址是：<a href=\"http://localhost:5050\" rel=\"noopener nofollow\" target=\"_blank\">http://localhost:5050</a><br />\n绑定的IP和端口可以在系统配置（config.json）里修改。<br />\n打开后的界面如下图所示<br />\n<img alt=\"\" class=\"lazyload\" /><br />\n在这个界面里，你可以选择右边的命令词然后发送请求到oddagent，然后看看它是否正确的解析并返回了你要的意图和槽位，如果有一些命令词说法未能正确识别出意图和槽位的话，可以再继续对你的智能体技术配置里做调整。</p>\n<h4 id=\"2实际api测试\">2）实际API测试</h4>\n<p>OddAgent只做意图、指令的识别，所以实际场景里基本上都是在你自己的产品里用API来调用OddAgent识别意图指令，然后自行去实现相应的功能。<br />\n以下是一个API调用OddAgent的完整示例代码：</p>\n<pre><code class=\"language-python\">import json\nimport requests\n\nAPI_BASE_URL = 'http://127.0.0.1:5050/oddagent/chat'                # API地址\n\ndef recognize_intent(message):\n    \"\"\"调用api_oddagent_chat API\"\"\"\n    try:\n        response = requests.post(\n            API_BASE_URL,\n            json={\n                'question': message, \n                'api_mode': 1 # 模拟API结果，0-不模拟，1-模拟，2-自定义API\n                }, \n            headers={'Content-Type': 'application/json'},\n            timeout=30\n        )\n        response.raise_for_status()\n        data = response.json()\n        return { 'err_code': 200, 'message': 'success', 'data': data}\n    except Exception as e:\n        print(f\"API调用失败: {str(e)}\")\n        return { 'err_code': 500, 'message': f'API调用失败: {str(e)}', 'data': None }\n\nif __name__ == '__main__':\n    json_response = recognize_intent(\"开个周例会\")\n    print(json.dumps(json_response, ensure_ascii=False, indent=2))\n</code></pre>\n<p>运行测试代码：<code>python test_oddagent.py</code></p>\n<p>调用后返回的结果：</p>\n<pre><code class=\"language-json\">{\n  \"err_code\": 200,\n  \"message\": \"success\",\n  \"data\": {\n    \"answer\": {\n      \"data\": \"[模拟API模式] 假装成功！\",\n      \"err_code\": 0,\n      \"message\": \"[meeting_create] API调用成功\",\n      \"slots\": {\n        \"meeting_name\": \"周例会\"\n      },\n      \"tool_name\": \"meeting_create\"\n    }\n  }\n}\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><code>tool_name</code>: 识别出来的意图（由智能体技能配置文件所配置）</li>\n<li><code>slots</code>: 该意图工具对应的槽位值。</li>\n</ul>\n<p>再次强制：OddAgent作为一个通用的意图、指令识别框架，跟业务无关，效果完全由你的智能体技术配置文件决定。</p>\n<h2 id=\"七进阶用法同时运行多个智能体\">七、进阶用法：同时运行多个智能体</h2>\n<p>在一些情况下，存在同时运行多个智能体的需求，建议的方案有两种。</p>\n<h3 id=\"1-用一个oddagent搞定\">1. 用一个oddagent搞定</h3>\n<p>在系统配置（config.json）里，你可以将 <code>TOOL_CONFIG_FILE</code> 设置为<code>agents/xiaoluo/*</code>，然后把你智能体配置都放到 <code>agents/xiaoluo</code> 目录下，这样 oddagent 在启动的时候就会去读取 这个目录下所有的 <code>*_config.json</code> 结尾的文件，并将他们加载起来。</p>\n<h3 id=\"2-用多个oddagent分开部署\">2. 用多个oddagent分开部署</h3>\n<p>为每个智能体启用一个系统配置（config1.json, config2.json, config3.json...），并在每个系统配置里设置</p>\n<ul>\n<li><code>TOOL_CONFIG_FILE</code>: 指向对应智能体的配置文件。如：<code>conference_config.py</code>，<code>smarthome_iot_config.py</code>...</li>\n<li><code>BACKEND_PORT</code>: 使用不同的端口，如：5050，5051，5052，5053...</li>\n</ul>\n<p>以<a href=\"https://x.oddmeta.net\" rel=\"noopener nofollow\" target=\"_blank\" title=\"小落同学\">小落同学</a>而言，她支持天气预报，会议调度，智能家居控制等多种智能体功能，她的做法是部署多个不同的智能体，也即：启动多个oddagent，每个oddagent配置一个智能体配置，并绑定一个端口，然后前置一个工作流接受用户输入，并根据用户的输出再导到不同的oddagent过去处理。</p>\n<p>下面是小落同学的一个智能体示例。</p>\n<pre><code class=\"language-bash\">\\---oddagent\n    |   config.json\n    |   config.json.sample\n    |\n    +---agents\n    |   \\---xiaoluo\n    |       |   conference_config.py\n    |       |   GAB_config.py\n    |       |   odd_bookmark_config.py\n    |       |   smarthome_iot_config.py\n    |       |   tpad_work_hour.py\n    |       |   weather_config.py\n    |       |   xiaoluo_config.py\n    |       |   __init__.py\n</code></pre>\n<p>如果想用一个oddagent搞定，那你就在系统配置config.json里将 <code>TOOL_CONFIG_FILE</code> 设置为<code>agents/xiaoluo/*</code>，然后在<code>config.json</code>所在的目录下： <code>oddagent -c config.json</code> 启动 oddagent 即可。<br />\n如果想用多个 oddagent分开部署的话，就把系统配置config.json复制多份，并修改每个系统配置中对应的<code>TOOL_CONFIG_FILE</code>和<code>BACKEND_PORT</code>，然后再每个oddagent分别启动即可： <code>oddagent -c config1.json</code> , <code>oddagent -c config2.json</code> ...</p>\n<h2 id=\"八广而告之\">八、广而告之</h2>\n<p>新建了一个技术交流群，欢迎大家一起加入讨论。<br />\n扫码加入AI技术交流群（微信）<br />\n关注我的公众号：奥德元<br />\n<strong><font color=\"red\">让我们一起学习人工智能，一起追赶这个时代。</font></strong><br />\n(若二维码过期了，可私信我)<br />\n有事+wx: oddmeta 交流群: 8655372</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 09:02</span>&nbsp;\n<a href=\"https://www.cnblogs.com/oddmeta\">程序员老奥</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "FastAPI + TinyDB并发陷阱与实战：告别数据错乱的解决方案",
      "link": "https://www.cnblogs.com/ymtianyu/p/19450340",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19450340\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 08:54\">\n    <span>FastAPI + TinyDB并发陷阱与实战：告别数据错乱的解决方案</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文针对在FastAPI框架下使用TinyDB（JSON文件数据库）时，因多人同时读写导致的并发数据冲突问题，进行了深度剖析。文章通过生动的比喻解释了问题根源，并详细提供了文件锁、内存操作队列和应用层乐观锁三种由浅入深的实战解决方案，附有可直接整合的代码示例。同时，明确了各方案的适用场景与局限性，为开发者在轻量级与生产级应用之间提供平滑过渡的思路。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">你的FastAPI应用在多人同时修改数据时，会不会出现数据错乱或丢失？</strong></p>\n<p>试像一下，团队里一个用于管理内部资源的工具突然“抽风”了。几个同事同时提交申请，结果后台数据显示，有的申请记录神秘消失，有的资源数量对不上。一查日志，发现大家都在同一秒对同一个<code style=\"color: rgba(186, 55, 42, 1);\">db.json</code>文件进行了读写。这就是为了轻量而选用TinyDB（一个纯Python的、以JSON文件为存储的数据库）后，最有可能真切地感受到“并发”带来的痛。🎯</p>\n<p>这篇文章，我将和你一起拆解这个问题，并分享如何用几个轻量级方案，让这个基于FastAPI和TinyDB的应用稳定地支撑起了日均数千次的并发请求。它不是一套放之四海而皆准的架构，但绝对是你在原型开发、小型工具或特定轻量场景下，性价比最高的解决方案。</p>\n<h2>📖 核心摘要</h2>\n<p>本文针对在FastAPI框架下使用TinyDB（JSON文件数据库）时遇到的并发写入数据冲突、错乱问题，深入浅出地解释了问题根源，并提供了从“文件锁”到“内存队列”再到“乐观锁”的三种由浅入深的实战解决方案，帮助你根据实际场景选择，确保数据一致性。</p>\n<h2>🚶‍♀️ 主要内容脉络</h2>\n<div>\n<p>🔍 一、问题根源：为什么简单的JSON文件会“打架”？</p>\n<p>🛠️ 二、解决方案：从“锁”到“队列”的三层防御</p>\n<p>- 方案一：文件锁（fcntl / portalocker）—— 给文件上个“请勿打扰”牌</p>\n<p>- 方案二：内存操作队列（asyncio.Queue）—— 让请求排好队，一个一个来</p>\n<p>- 方案三：应用层乐观锁（版本号校验）—— “我改的时候，东西还是原来的样子吗？”</p>\n<p>💻 三、实战代码：将方案融入FastAPI依赖项与路由</p>\n<p>⚠️ 四、重要提醒与边界探讨：这不是银弹</p>\n</div>\n<h2>🔍 第一部分：问题与背景</h2>\n<p>想象一下，TinyDB的<code style=\"color: rgba(186, 55, 42, 1);\">db.json</code>文件就是一个共享的笔记本。FastAPI的每个工作进程（Worker）就像一个快速记录员。</p>\n<p>当用户A的请求到来时，记录员1打开笔记本，读到某个值（比如库存为5），准备将其改为4。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">就在这“读到”和“改写”的毫秒之间</strong>，用户B的请求也来了。记录员2也打开了同一个笔记本，他读到的库存<strong>仍然是5</strong>（因为记录员1还没写回去），然后他也计算，将库存改为3。</p>\n<p>结果就是，无论谁最后保存，另一个人的修改都会被完全覆盖。这就是典型的“并发写冲突”。在高并发的Web API场景下，这个问题会被急剧放大。</p>\n<h2>🛠️ 第二部分：核心原理与步骤</h2>\n<h3>🎯 方案一：文件锁（最直接的物理隔离）</h3>\n<p>原理：在读写文件前，先给这个文件加一把系统级的锁。其他进程尝试加锁时，会被阻塞或失败，直到锁被释放。这就像给笔记本的房间门上了锁，一次只进一个人。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">适用场景：</strong> 低并发（如内部工具）、读写不那么频繁的场景。</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 安装：pip install portalocker\nimport portalocker\n\ndef safe_update_db():\n    with open('db.json', 'r+') as f:\n        portalocker.lock(f, portalocker.LOCK_EX)  # 获取独占锁\n        # 在这里安全地读取和修改数据\n        data = json.load(f)\n        data['counter'] += 1\n        f.seek(0)\n        json.dump(data, f)\n        f.truncate()\n        # 退出with块时，锁会自动释放</code></pre>\n<h3>🎯 方案二：内存操作队列（单进程内的秩序维护者）</h3>\n<p>原理：利用Python的<code style=\"color: rgba(186, 55, 42, 1);\">asyncio.Queue</code>，将所有对TinyDB的写操作封装成任务，放入一个队列。由一个单独的“消费者”协程从队列中依次取出任务执行。这样，无论外部请求多么并发，对数据库的写操作都是<strong>串行化</strong>的。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">优点：</strong> 完全在内存中操作，速度极快，避免了文件锁可能带来的死锁或跨平台问题。非常适合FastAPI的异步模式。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">关键警告：</strong> 此方案仅在<u>单个服务进程</u>内有效。如果你使用多个工作进程（如<span style=\"color: rgba(186, 55, 42, 1);\"><code>Uvicorn with --workers 4</code></span>），每个进程有自己的内存和队列，冲突依然会发生。此时需搭配方案一或方案三。</p>\n<h3>🎯 方案三：应用层乐观锁（基于版本的冲突检测）</h3>\n<p>原理：不阻止“读”，只在“写”的时候检查冲突。为每条数据增加一个<code style=\"color: rgba(186, 55, 42, 1);\">version</code>字段。每次读取数据时，连带版本号一起读出。修改后写回时，检查当前文件中的版本号是否和自己读到的版本号一致。如果一致，则写入，并将版本号+1；如果不一致，则说明在此期间数据已被他人修改，本次操作失败，需要提示用户重试。</p>\n<p>这就像两个人编辑在线文档，系统会提示你“在你编辑期间，文档已被他人更新”。</p>\n<h2>💻 第三部分：实战演示（整合方案二与三）</h2>\n<p>下面是一个在FastAPI中整合<strong>内存队列</strong>与<strong>乐观锁</strong>的核心示例：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>from fastapi import FastAPI, Depends, HTTPException\nfrom contextlib import asynccontextmanager\nimport asyncio\nfrom tinydb import TinyDB, Query\nimport json\nfrom pydantic import BaseModel\n\napp = FastAPI()\nwrite_queue = asyncio.Queue()\ndb_path = 'db.json'\n\n# 数据模型\nclass ItemUpdate(BaseModel):\n    item_id: int\n    new_value: str\n    read_version: int  # 客户端传来的读取时的版本号\n\n# 启动时启动写任务消费者\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # 启动时\n    asyncio.create_task(db_write_consumer())\n    yield\n    # 关闭时...\n\napp = FastAPI(lifespan=lifespan)\n\nasync def db_write_consumer():\n    \"\"\"写操作消费者，常驻后台，串行处理写队列\"\"\"\n    while True:\n        task_data = await write_queue.get()\n        await _perform_safe_write(task_data)\n        write_queue.task_done()\n\nasync def _perform_safe_write(task_data: dict):\n    \"\"\"执行带乐观锁检查的写入\"\"\"\n    with TinyDB(db_path) as db:\n        Item = Query()\n        record = db.get(Item.id == task_data['item_id'])\n        if not record:\n            # 处理记录不存在的情况...\n            return\n        # 乐观锁检查！！！\n        if record['version'] != task_data['read_version']:\n            raise ValueError(f\"数据版本冲突。当前版本{record['version']}，提交版本{task_data['read_version']}\")\n        # 通过检查，执行更新\n        db.update({\n            'value': task_data['new_value'],\n            'version': record['version'] + 1  # 版本号递增\n        }, Item.id == task_data['item_id'])\n\n@app.put(\"/update_item/\")\nasync def update_item(update: ItemUpdate):\n    \"\"\"更新接口\"\"\"\n    try:\n        # 将写操作封装成任务，放入队列，等待消费者处理\n        await write_queue.put(update.dict())\n        # 这里可以返回一个任务ID，让客户端轮询结果，或者使用WebSocket推送\n        return {\"message\": \"更新请求已加入队列\"}\n    except asyncio.QueueFull:\n        raise HTTPException(status_code=429, detail=\"系统繁忙，请稍后重试\")\n\n@app.get(\"/get_item/{item_id}\")\nasync def get_item(item_id: int):\n    \"\"\"读取接口，返回数据和当前版本号\"\"\"\n    with TinyDB(db_path) as db:\n        Item = Query()\n        record = db.get(Item.id == item_id)\n        if record:\n            return {\"value\": record['value'], \"version\": record['version']}\n        raise HTTPException(status_code=404, detail=\"Item not found\")</code></pre>\n<h2>⚠️ 第四部分：注意事项与进阶思考</h2>\n<div>\n<p>🚨 <strong style=\"color: rgba(186, 55, 42, 1);\">重要提醒：</strong></p>\n<p>1. <strong>性能瓶颈：</strong> 所有方案的核心都是“串行化写”。这意味着你的数据库写吞吐量存在上限。对于超高并发写入场景，JSON文件本身就会成为瓶颈。</p>\n<p>2. <strong>多进程限制：</strong> 内存队列方案在单进程内完美，多进程需配合分布式锁（如Redis锁）或回归到数据库方案。</p>\n<p>3. <strong>故障恢复：</strong> 队列中的任务在服务重启时会丢失。对数据一致性要求极高的场景，需要引入持久化消息队列（如RabbitMQ）或直接使用真正的数据库。</p>\n</div>\n<p><strong>升华思考：</strong> 技术选型永远是权衡的艺术。TinyDB的优点是极致简单、无需外部服务。但当你的并发和一致性要求增长到一定阶段时，就是考虑升级到SQLite（支持更完善的事务和并发控制）、PostgreSQL等更强大数据库的时候了。本次实战的方案，是你从“玩具项目”平稳过渡到“生产系统”的一座关键桥梁。</p>\n<p style=\"text-align: center;\">---<strong>写在最后</strong>---<br />希望这份总结能帮你避开一些坑。如果觉得有用，不妨点个 赞👍 或 收藏⭐ 标记一下，方便随时回顾。也欢迎关注我，后续为你带来更多类似的实战解析。有任何疑问或想法，我们评论区见，一起交流开发中的各种心得与问题。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 08:54</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "PHP 异步与多线程 从 TrueAsync 展望未来",
      "link": "https://www.cnblogs.com/catchadmin/p/19450129",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/catchadmin/p/19450129\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 07:12\">\n    <span>PHP 异步与多线程 从 TrueAsync 展望未来</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"php-异步与多线程-从-trueasync-展望未来\">PHP 异步与多线程 从 TrueAsync 展望未来</h1>\n<p>RFC TrueAsync 1.7 讨论中有个问题：这个提议会如何与 PHP 核心未来的变化互动？要设计好语言的长期演进，至少得对 PHP 的发展方向有基本判断。本文试图回答这个问题。</p>\n<p>TrueAsync 项目不仅是 PHP 核心的 async 改动，还包括回答以下问题所需的其他研究：</p>\n<ul>\n<li>PHP 能在多大程度上向多线程方向发展？</li>\n<li>是否存在根本性限制？</li>\n<li>实现真正的多线程可能需要哪些核心改动？</li>\n<li>可以实现哪些语言抽象？</li>\n</ul>\n<p>本文不是 PHP 多线程的详尽综述，也不追求每个细节的技术精确性或大众可读性。但希望它对 PHP 开发者有参考价值，能为后续讨论提供方向。</p>\n<p><a href=\"https://catchadmin.com/post/2026-01/multithreading-in-php-looking-to-the-future\" rel=\"noopener nofollow\" target=\"_blank\">原文 PHP 异步与多线程 从 TrueAsync 展望未来</a></p>\n<h2 id=\"历史\">历史</h2>\n<p>几年前要给 PHP 应用加高容量遥测，我说做不到。看到 Swoole 架构后想测试一下。能不能做一个 API，生成和处理大量数据的同时不拖慢客户端？</p>\n<p>我们给 PHP 做了个优化的 OpenTelemetry，分批写数据，收集成大块再发到中间遥测服务器。数据压缩，JSON 结构用 MessagePack 序列化。</p>\n<p>假设是：用单线程协程逐步构建遥测数据，定时或达到阈值时发送。没有跨线程交互，代码应该快。真的吗？</p>\n<p>实验结果：遥测让 API 吞吐量减半。假设错了。为什么？概念上看起来没问题。Swoole 已经让 PHP 函数非阻塞，协程应该高效才对。哪里出错了？</p>\n<p>第二版改成：遥测只在一个请求期间收集，立即扔给作业进程去聚合、压缩、发送。这版性能好多了。但不应该啊？进程间数据走管道，一端序列化另一端反序列化。管道在内存里，但系统调用开销不小。</p>\n<p>后来找到原因：遥测数据量大，压缩相对 API 请求处理吃掉太多 CPU。Swoole 协程对 I/O 高效，但帮不了 CPU 密集型任务。</p>\n<p>这个案例说明单线程协程解决不了所有问题。也说明多线程能补充协程，给更多问题提供工具。</p>\n<h2 id=\"单线程--offload\">单线程 + offload</h2>\n<p>把 CPU 密集型工作卸载到单独进程不是什么新发明。这个模式在不同语言和框架中独立出现，叫 <code>Single-threaded + offload</code>。</p>\n<p>打个比方：一个人快速分拣信件（每小时几千封），重包裹由其他员工用卡车装走。分拣员要是自己去搬包裹，信件队列就堆到天花板了。</p>\n<p><code>Single-threaded + offload</code> 模型把任务分两类：</p>\n<ul>\n<li><strong>I/O-bound 任务</strong> — 读文件、网络调用、数据库访问。大部分时间在等外部世界。通过并发 async（协程、<code>await</code>），一个线程能容纳几千个这类操作。</li>\n<li><strong>CPU-bound 任务</strong> — 压缩、加密、解析、计算。CPU 满负荷跑，光靠并发不够，得上更多核心。</li>\n</ul>\n<p>模型在物理上分离这两类任务：主线程（<code>Event Loop</code>）只管 I/O，CPU 任务扔给单独的线程或进程（<code>Workers</code>）。</p>\n<p>Node.js 靠单线程 <code>Event Loop</code> 出名，很适合网络应用。但开发者要是在请求处理器里直接处理图像或压缩视频，服务器就变南瓜了。后来加了 <code>Worker Threads</code>，专门跑 CPU 密集型操作。</p>\n<p>Python 走了类似路线。<code>asyncio</code> 出来后，I/O-bound 代码有了好工具，但 GIL（全局解释器锁）挡着，单进程内没法真正 CPU 并行（写这篇文章时问题已解决）。阻塞操作有 <code>loop.run_in_executor()</code> 和 <code>asyncio.to_thread()</code>（Python 3.9+），把重活卸载到线程池或进程池。<code>Event Loop</code> 保持响应，计算并行跑。</p>\n<p>PHP/Swoole 也是这个架构：<code>Request Workers</code> 用协程处理 HTTP 请求，<code>Task Workers</code> 跑重计算。通过 UnixSocket 或管道通信，单进程能处理每秒约 10 万次操作。</p>\n<h3 id=\"模型的优势\">模型的优势</h3>\n<p><strong>1. 资源效率</strong></p>\n<p>单线程 <code>Event Loop</code> 能以极小开销服务几千个并发 I/O 操作。协程任务间切换比操作系统线程上下文切换便宜得多。CPU-bound 任务在多核上真正并行——每个 worker 占一个核心，互不干扰。</p>\n<p><strong>2. 开发简单</strong></p>\n<p><code>Event Loop</code> 里的代码不用互斥锁、信号量这些多线程编程的玩意儿。单线程模型一次只跑一个任务，竞态条件不可能出现。<code>Workers</code> 并行跑，但只要遵循 <code>Shared Nothing</code>，同步问题就不存在。</p>\n<p>多线程代码和单线程 async 代码的复杂度差距很大。现代语言和框架都奔着单线程 async 去，不走经典多线程。</p>\n<p><strong>3. 编译器/运行时更简单</strong></p>\n<p>单线程模型的 async 函数对编译器和运行时简单得多。好的多线程语言需要自己的代码生成管道。PHP 有个硬约束：部分代码用 C 写的，没法对线程、内存管理、参数传递做高效的字节码级优化。Go 的设计复杂出名：专有栈、复杂 GC，都是高效 goroutines 和 channels 必需的。PHP 的 GC 后面会讲，先别放松。</p>\n<p><strong>4. 手动负载分配</strong></p>\n<p>开发者可以主动在请求处理代码和 worker 池之间分配负载。手动控制能从硬件榨出理论最大值。但这也是缺点。</p>\n<h3 id=\"模型的劣势\">模型的劣势</h3>\n<p><strong>1. 手动负载分配</strong></p>\n<p>手动分配是双刃剑。开发者可以针对特定任务优化，也可能误判什么该放 I/O 代码、什么该放 workers。I/O 代码塞了重活会过载，响应变慢、延迟上升。</p>\n<p>这个模型要求 PHP 开发者有足够技能，或者依赖框架作者提供的现成方案。</p>\n<p><strong>2. 不适合所有任务</strong></p>\n<p><code>Single-threaded + offload</code> 很适合 Web 服务器、API、微服务——主要负载是数据库、文件系统、网络调用这些 I/O。但每一步都要密集计算的场景——科学计算、渲染、机器学习——这个模型效果就差了。那些场景更适合完全多线程。</p>\n<p>你可能说：能接受！准备好了！但 PHP 本身准备好多线程了吗？</p>\n<h2 id=\"php-准备好多线程了吗\">PHP 准备好多线程了吗？</h2>\n<p>开发 TrueAsync 时，最难的讨论之一是\"为什么 PHP 没有 async\"。解释 PHP 为什么还没准备好多线程可能同样难。不过先聊聊多线程本身。我们为什么需要它？或者换个问法：我们为什么不需要它？</p>\n<p><strong>多线程不是并行执行代码的必要条件。</strong></p>\n<p>\"并行必须多线程\"这个想法早就刻在程序员脑子里了，就像\"黑洞会吸东西\"刻在流行文化里一样。</p>\n<p>并行执行完全可以用进程，进程彼此隔离（80386 架构就有了）。进程通过 IPC 通信，完成状态通过信号（操作系统事件）跟踪。那为什么还要线程？</p>\n<p>要老实回答这个问题，得穿越回去请当年做决定的人解释：Edsger Dijkstra、Fernando Corbató、Barbara Liskov、Richard Rashid。办个脱口秀挺好。但就算他们都来了，可能也说不出直接答案。</p>\n<p>下面这个说法是错的：</p>\n<blockquote>\n<p>线程是为了让并行代码不用额外工具就能共享内存。</p>\n</blockquote>\n<p>进程也能共享内存，但得把段映射到地址空间（额外工具）。线程默认共享所有内存。线程 A 能访问的变量 <code>x</code>，线程 B 在同一地址也能访问，不用任何技巧……但等等！多个线程没法在不加额外工具的情况下安全使用共享变量。</p>\n<p>更准确的说法是：</p>\n<blockquote>\n<p>线程是为了在任务间传递内存时没有额外开销。</p>\n</blockquote>\n<p>如果线程用内存传消息，保证同一时间只有一个线程能访问某块内存区域，那在内存和 CPU 两方面都是最高效的。线程刻意避免共享内存。这个模型叫 <code>Shared Nothing</code>。</p>\n<p><strong>线程是为了在任务间高效传数据。</strong> 跟\"黑洞不吸东西\"一样是事实。</p>\n<h2 id=\"php-内存模型\">PHP 内存模型</h2>\n<p>PHP 怎么处理内存？简化的抽象模型：</p>\n<ul>\n<li>代码</li>\n<li>数据</li>\n<li>PHP VM 状态</li>\n</ul>\n<p>线程间共享 PHP 代码已经能做到（PHP JIT 解决了）。其他组件紧密耦合，拆不开。比如 PHP 用一个全局 <code>object_store</code> 存所有创建对象的引用。PHP 内存管理器是给单个 PHP VM 的对象设计的，不面向多线程。PHP 垃圾收集器处理不了不同线程的数据，甚至要完全停掉 VM，因为它直接改对象的 <code>refcount</code>。</p>\n<p>所以 <strong>PHP 是严格的单线程模型，带 stop-the-world GC</strong>。</p>\n<h2 id=\"在线程间移动-php-vm\">在线程间移动 PHP VM</h2>\n<p>PHP 用线程局部存储（<code>Thread-Local Storage</code>，TLS）保存每个线程的 VM 状态。这对 ZTS（Zend Thread Safety）模式下线程间隔离很关键。</p>\n<p>现代 PHP 构建用 C11 标准的 <code>__thread</code>（MSVC 里是 <code>__declspec(thread)</code>）获取 VM 状态指针。速度很快，x86_64 上就是从 FS 或 GS 寄存器的基址读一个偏移量。</p>\n<pre><code class=\"language-asm\">; offset - 编译时计算的常量偏移量\n; fs - 内存段的基地址\nmov rax, QWORD PTR fs:offset\n</code></pre>\n<p>FS/GS 对每个线程唯一（操作系统保证），读出来的总是正确的 VM 状态指针。</p>\n<p>能在线程间移动 VM 状态，就能实现类似 Go 协程或 actors 的功能。现代 VM 通过自定义代码生成传上下文，用 CPU 寄存器传 VM 状态。PHP 做不到这个，因为底层用 C 函数，C 没法给每个函数传隐式上下文参数。在线程间移动 PHP VM 状态会损失一定性能。</p>\n<p>但如果只移动执行代码需要的那一小部分 VM 状态呢？比如 PHP Fiber 切换时会复制指向全局结构（<code>zend_executor_globals</code>）的部分指针。</p>\n<p>如果把 PHP VM 概念上分成两部分：</p>\n<ul>\n<li><strong>PHP VM shared</strong>。类、函数、常量、ini 指令、可执行代码。</li>\n<li><strong>PHP VM movable</strong>。需要移动的 VM 部分。</li>\n</ul>\n<p><img alt=\"PHP Memory Model\" class=\"lazyload\" /></p>\n<p>有些结构可以标记为共享，有些标记为可移动；<code>Executor Globals</code> 甚至可以拆成共享和可移动两部分，实现线程间高效的 VM 状态移动。扩展全局结构不会因为多一层间接而损失性能，因为它们本来就在用间接访问。</p>\n<p>问题出在代码编译相关的结构上。PHP 通过 <code>include</code>/<code>require</code>、<code>eval</code> 和自动加载是动态的，这让 VM 状态很难有效拆成共享和可移动两部分。如果能解决这个问题，PHP 就能以很小的开销在线程间移动部分 VM 状态。</p>\n<h2 id=\"在线程间传递对象\">在线程间传递对象</h2>\n<p>PHP 要改什么才能安全地在线程间传递对象？怎么做？</p>\n<p>从语言层面看。假设 <code>$obj</code> 里有个 <code>SomeObject</code> 实例，要发到另一个线程。能做到吗？</p>\n<pre><code class=\"language-php\">$obj = new SomeObject();\n\n$thread = new Thread(function () use ($obj) {\n    echo $obj-&gt;someMethod();\n});\n\n$thread-&gt;join();\n</code></pre>\n<p><code>SomeObject</code> 只属于 <code>$obj</code>，可以安全地把地址从一个线程移到另一个。主线程的 <code>$obj</code> 会被销毁：</p>\n<pre><code class=\"language-php\">$obj = new SomeObject();\n$thread = new Thread(function () use ($obj) {\n    echo $obj-&gt;someMethod();\n});\n\n// $obj 在这里未定义\n$thread-&gt;join();\n</code></pre>\n<p>上面的代码跟 C++ 和 Rust 的移动语义完全一样。这种线程间传内存的方式：</p>\n<ul>\n<li><strong>安全</strong>。只有一个线程拥有对象。</li>\n<li><strong>没有复制或序列化开销</strong>。</li>\n</ul>\n<p>为了让行为可预测、静态分析器能读懂，应该加特殊的移动语法：</p>\n<pre><code class=\"language-php\">$obj = new SomeObject();\n\n// consume $obj 表示移动对象\n$thread = new Thread(function () use (consume $obj) {\n    echo $obj-&gt;someMethod();\n});\n\n// $obj 在这里未定义。在 PHP9 中应该在这里报告错误。\necho $obj;\n</code></pre>\n<p>看着不错？</p>\n<p>但移动 <code>refcount = 1</code> 的对象有问题。</p>\n<p>看个分类树的例子：</p>\n<pre><code class=\"language-php\">$electronics = new CategoryNode('Electronics');\n$categoriesTree = new Tree();\n$categoriesTree-&gt;addToPath('/products/electronics', $electronics);\n$categoriesTree-&gt;addToPath('/popular/electronics', $electronics);  \n// 同一个分类！\n</code></pre>\n<p><code>$electronics</code> 在树里出现两次（<code>refcount = 2</code>）。把 <code>$categoriesTree</code> 移到另一个线程会怎样？</p>\n<p>要安全移动，必须保证图里所有对象都没有外部引用：</p>\n<pre><code class=\"language-php\">$node = new CategoryNode('Electronics');\n$categoriesTree = new Tree();\n$categoriesTree-&gt;addToPath('/products/electronics', $node);\n\n$favourites = [$node];  // 外部引用！\n$thread = new Thread(function () use ($categoriesTree) {\n    // $categoriesTree 被移动\n});\n\n// $favourites[0] 现在指向另一个线程中的内存\n// 悬空指针！\n</code></pre>\n<p>安全移动需要：</p>\n<ul>\n<li><strong>完整图遍历</strong>：检查所有嵌套对象。</li>\n<li><strong>Refcount 检查</strong>：图里每个对象都要查。</li>\n<li><strong>身份保留</strong>：图内的重复项得保持重复。</li>\n</ul>\n<p>可以为此设计算法，叫深拷贝。简单实现大概这样：</p>\n<pre><code class=\"language-php\">// 深拷贝伪代码\n// 线程 A 中的源图\n$node = new Node('A');        // addr: 0x1000\n$tree-&gt;left = $node;          // addr: 0x1000\n$tree-&gt;right = $node;         // addr: 0x1000 (相同引用)\n\n// 深拷贝到线程 B（带 MM 的伪代码）\n$copied_map = [];  // 哈希表: addr_source -&gt; addr_target\nfunction deepCopyToThread(object $obj, Thread $target_thread_mm) \n{\n    $source_addr = get_object_address($obj);\n    if (isset($copied_map[$source_addr])) {\n        return $copied_map[$source_addr];  // 已经复制！\n    }\n    // 在另一个线程的 MM 中分配内存\n    $new_addr = $target_thread_mm-&gt;allocate(sizeof($obj));\n    $copied_map[$source_addr] = $new_addr;\n    // 复制对象数据\n    memcpy($new_addr, $source_addr, sizeof($obj));\n    // 遍历属性\n    foreach ($obj-&gt;properties as $prop) {\n        if (is_object($prop)) {\n            $new_prop_addr = deepCopyToThread($prop, $target_thread_mm);\n            // 更新新对象中的指针\n            update_property($new_addr, $prop, $new_prop_addr);\n        }\n    }\n    return $new_addr;\n}\n// 线程 B 中的结果：\n// $newTree-&gt;left (addr: 0x2500) === $newTree-&gt;right (addr: 0x2500)\n// 身份保留！\n</code></pre>\n<p>深拷贝时间复杂度 O(N + E)，N 是对象数，E 是引用数。空间复杂度 O(N)——哈希表 + 新对象 + 递归栈。</p>\n<p>比序列化快，因为不用转换传输格式，但收益取决于数据形状和图大小。也可以混合：<code>refcount = 1</code> 的移动，其他的深拷贝。</p>\n<p>结果：</p>\n<ul>\n<li>PHP 开发者不用管对象怎么传到另一个线程。</li>\n<li>最好情况：内存直接移动（<code>refcount = 1</code>）。</li>\n<li>最坏情况：深拷贝，保留身份（<code>refcount &gt; 1</code>）。</li>\n</ul>\n<p>看着还行：</p>\n<ul>\n<li>PHP 语法改动最小</li>\n<li>可以逐步改</li>\n<li>多线程能用了</li>\n</ul>\n<p>但核心层面没那么美好。要让对象移动成真，PHP 需要跨线程的内存管理机制。现在做不到。</p>\n<h2 id=\"多线程-php-内存管理器\">多线程 PHP 内存管理器</h2>\n<p>PHP 内存管理器类似 jemalloc 或 tcmalloc 这些现代分配器。区别是：它没有从另一个线程释放内存的正确算法。</p>\n<p>场景：</p>\n<ul>\n<li>线程 A 创建对象。</li>\n<li>移动（原样）给线程 B。</li>\n<li>B 不再需要，要释放。</li>\n</ul>\n<p>每个 PHP 线程有自己的内存管理器（<code>Memory Manager</code>，MM）。B 想释放 A 分配的内存就出问题了。B 的 MM 不认识 A 的内存，释放会出错。B 直接访问 A 的 MM 结构也不行，需要同步。现代高性能多线程分配器用延迟释放（<code>deferred free</code>）解决这个问题。</p>\n<p>延迟释放的思路：</p>\n<ul>\n<li>B 的 MM 看到一个不认识的指针。</li>\n<li>找到哪个 MM 拥有它，给那个 MM 的队列发消息说可以释放了。</li>\n<li>A 的 MM 处理队列，在自己的上下文里释放。</li>\n</ul>\n<p><img alt=\"Cross thread deferred free\" class=\"lazyload\" /></p>\n<p>用现代无锁结构，这个算法吞吐量高，不同线程能并行释放内存，几乎不用锁。</p>\n<p>多线程 PHP 内存管理器为以前不可能的改动打开了门。</p>\n<h2 id=\"共享对象\">共享对象</h2>\n<p>能用最少操作把内存从一个线程传到另一个很好，但如果能创建一开始就设计成跨线程共享的对象呢？</p>\n<p>很多服务可以构建成不可变对象，应该能在进程间共享，省内存、加快 worker 启动。</p>\n<p>但 <code>refcount</code> 挡着，它让所有 PHP 对象实际上都是可变的。能绕过吗？</p>\n<h3 id=\"代理对象\">代理对象</h3>\n<p>第一种方法是代理对象，引用存在所有线程可访问的共享内存池里的真实对象。代理只存标识符或指针，加上访问数据的方法。缺点：</p>\n<ul>\n<li>访问数据/属性变慢</li>\n<li>Reflection API 和类型检查更复杂</li>\n</ul>\n<p>PHP 已经有强大的代理机制。代理共享对象在某些场景不错，比如计数器表或 Swoole/Table 这样的数据表。</p>\n<h3 id=\"带有-gc_share-标志的共享对象\">带有 GC_SHARE 标志的共享对象</h3>\n<p>PHP 有个内置机制通过 <code>GC_IMMUTABLE</code> 标志实现不可变元素，用于：</p>\n<ul>\n<li>内部字符串（<code>IS_STR_INTERNED</code>）——整个 PHP 进程存在的字符串常量</li>\n<li>不可变数组（<code>IS_ARRAY_IMMUTABLE</code>）——比如 <code>zend_empty_array</code></li>\n<li>opcache 里的常量——带常量数据的编译代码</li>\n</ul>\n<p><code>GC_IMMUTABLE</code> 让引擎跳过这些结构的 <code>refcount</code> 修改：</p>\n<pre><code class=\"language-c\">// Zend/zend_types.h\n// 为 zend_refcounted_h 增加 refcount 的函数\nstatic zend_always_inline void zend_gc_try_addref(zend_refcounted_h *p) {\n    if (!(p-&gt;u.type_info &amp; GC_IMMUTABLE)) {\n        ZEND_RC_MOD_CHECK(p);\n        ++p-&gt;refcount;\n    }\n}\n</code></pre>\n<p>类似机制可以支持 <code>SharedObjects</code>，比如加个 <code>GC_SHARE</code> 标志。</p>\n<p>性能分析显示，检查 <code>GC_SHARE</code> 给单独的 <code>refcount++</code> 加了 +34% 开销（微基准测试）。实际应用里 <code>refcount</code> 操作只占总工作一小部分，影响几乎看不出来：</p>\n<ul>\n<li>真实操作（数组/对象）：+3–9%</li>\n<li>实际应用：+0.05–0.5%</li>\n</ul>\n<p>这解决了一半问题；另一半是给这些对象设计 GC。用原子 <code>refcount</code> 不理想，多线程访问同一对象时会变慢。延迟释放算法可能更合适。</p>\n<h2 id=\"基于区域的内存\">基于区域的内存</h2>\n<p>基于区域的内存（<code>Region-based memory</code>）在面向 Web 的语言里越来越流行。</p>\n<p>思路：给特定任务或线程在单独区域分配内存，不需要时整体释放。避免了逐个对象管理的复杂性，GC 也简单了。</p>\n<p>比如 PHP MM 可以保证对象在绑定到特定 PHP 对象的区域里创建。区域生命周期等于对象生命周期。</p>\n<p>对象销毁时整个区域直接释放，不用遍历子对象。这种对象要\"移动\"到另一个线程，可以避免深拷贝。</p>\n<p>PHP VM 实现基于区域的内存有问题：比如全局对象列表、操作码缓存。但高效实现的机会不是零，值得继续研究。</p>\n<p>有效的基于区域的内存算法能为 actors 打开门——有隔离内存的特殊对象。</p>\n<p><strong>Actors 是多线程编程里最方便、最强大、最安全的工具。</strong></p>\n<h2 id=\"协程和线程协作\">协程和线程协作</h2>\n<p>从协程角度看，<code>Thread</code> 是个 <code>Awaitable</code> 对象。协程可以等 <code>Thread</code> 结果而不阻塞其他协程。一个线程能托管很多等重任务的协程。服务它们的线程对新请求保持快速响应，因为等 <code>Thread</code> 不阻塞 <code>Event Loop</code>。</p>\n<pre><code class=\"language-php\">use Async\\await;\nuse Async\\Thread;\n\n$thread = new Thread(function() {\n    // 硬件密集型任务在这里\n    return 42;\n});\n\n$result = await($thread); \n// 协程在这里暂停，直到 Thread 完成\n</code></pre>\n<p>这种方式能实现有 CPU 密集型任务和简单业务逻辑的聊天场景。<br />\n<img alt=\"协程和线程协作\" class=\"lazyload\" /></p>\n<p>图里是个示例架构。应用有两个线程池：带并发多任务的请求处理线程，和跑 CPU 密集型任务的 worker 线程。协程处理请求，worker 跑重任务时可以完全暂停，跑完继续。</p>\n<pre><code class=\"language-php\">use Async\\await;\nuse Async\\ThreadPool;\n\nfinal readonly class ImageDto\n{\n    public function __construct(\n    public int $width,\n    public int $height,\n    public string $text,\n) {}\n}\n\n$pool = new ThreadPool(2);\n$dto = new ImageDto(\n    width: 200,\n    height: 200,\n    text: 'Hello TrueAsync!'\n);\n\n$image = $pool-&gt;enqueue(function (ImageDto $dto) {\n    $img = imagecreatetruecolor($dto-&gt;width, $dto-&gt;height);\n\n    $white = imagecolorallocate($img, 255, 255, 255);\n    $black = imagecolorallocate($img, 0, 0, 0);\n\n    imagefill($img, 0, 0, $white);\n    imagestring($img, 5, 20, 90, $dto-&gt;text, $black);\n\n    ob_start();\n    imagepng($img);\n    imagedestroy($img);\n    return ob_get_clean();\n}, $dto);\n\n$response-&gt;setHeader('Content-Type', 'image/png');\n$response-&gt;write($image);\n$response-&gt;end();\n</code></pre>\n<p>协程代码是顺序的，读起来像普通代码，<code>ThreadPool::enqueue</code> 像在同一线程调用回调一样。DTO 跨线程传，结果字符串不会在内存里复制两次。</p>\n<h2 id=\"垃圾收集器和有状态模式\">垃圾收集器和有状态模式</h2>\n<p>现代化 PHP 内存管理器不是改进多线程环境唯一要做的事。没有高效 GC，多线程 PHP 会有性能问题和循环引用导致的内存泄漏。</p>\n<p>PHP GC 用两种算法：引用计数做主要内存管理，并发循环收集（Concurrent Cycle Collection，Bacon-Rajan，2001）处理循环。引用计数每次赋值都递增/递减，没同步的话多线程不安全。每次赋值用原子操作开销太大；不同步就有竞态和泄漏。循环收集器虽然叫\"并发\"，但只在单线程内工作，用颜色标记（PURPLE → GREY → WHITE/BLACK）找循环，也不是线程安全的。</p>\n<p>好消息是：当前 GC 实现在多线程环境能工作，因为它跟内存管理器分开，不依赖内存在哪分配。</p>\n<p>但 PHP 要进入有状态应用的多线程时代，GC 得适应：</p>\n<ul>\n<li>在单独线程并行跑，不影响业务代码。</li>\n<li>尽快释放资源。</li>\n<li>提供泄漏检测、日志、遥测的额外工具（长时间运行的应用特别需要）。</li>\n</ul>\n<p>循环收集器可以改成在多线程环境工作，在单独线程处理引用，提高整体响应性。这可能够用了！</p>\n<h2 id=\"actors\">Actors</h2>\n<p><code>ThreadPool</code> 和线程间传对象有用，但需要开发者的注意力、技能和精力。有个更好的多线程编程抽象，藏住线程/内存复杂性，完美契合业务逻辑：actors。</p>\n<p><strong>Actors 是并发并行编程模型，计算的基本单元是 actor。</strong></p>\n<p>每个 actor：</p>\n<ul>\n<li>有自己的隔离状态</li>\n<li>顺序处理消息</li>\n<li>只通过消息跟其他 actors 交互</li>\n<li>可能在单独线程跑</li>\n</ul>\n<p>可以把 actor 想成对象，这让多线程 PHP 能用熟悉的 OOP 模式。</p>\n<p>想象一个有很多房间的聊天服务器。每个房间是单独的对象。</p>\n<pre><code class=\"language-php\">use Async\\Actor;\n\nclass ChatRoom extends Actor\n{\n    private array $messages = [];\n    private string $name;\n\n    public function __construct(string $name)\n    {\n        $this-&gt;name = $name;\n    }\n\n    public function postMessage(string $user, string $text): void\n    {\n        $this-&gt;messages[] = [\n            'user' =&gt; $user,\n            'text' =&gt; $text,\n            'time' =&gt; time()\n        ];\n    }\n\n    public function getMessages(): array\n    {\n        return $this-&gt;messages;\n    }\n}\n\nspawn(function() {\n   $room = new ChatRoom('general');\n   $room-&gt;postMessage('Alice', 'Hello!');  // 在另一个线程中运行，暂停协程！\n   $messages = $room-&gt;getMessages();       // 在另一个线程中运行，暂停协程！\n   echo json_encode($messages);\n});\n</code></pre>\n<p><code>ChatRoom</code> 对象特殊。它们的数据和 PHP VM 状态本地化了，方便在线程间移动。每个方法在自己的线程跑，但任何时刻只有一个线程能执行给定 actor 的方法。</p>\n<p>语义上，基类 <code>Actor</code> 定义了 PHP VM 和内存管理器的工作方式，让 <code>ChatRoom</code> 对象能安全地在单独线程跑。类类型不只\"存\"方法和属性信息，还存 MM 和 GC 该怎么操作这类对象。Rust、C++ 也有类似做法。好处：不改语法，符合 OOP 哲学。</p>\n<p>示例看起来像协程里跑的普通顺序代码。但 <code>postMessage</code> 和 <code>getMessages</code> 在另一个线程跑，不会直接执行。协程给 actor 队列发消息，进入等待，actor 在另一个线程跑完方法返回结果后才恢复。</p>\n<p>这跟熟悉的 PHP OOP 不冲突：<code>Actor</code> 重写 <code>__call</code>：</p>\n<pre><code class=\"language-php\">class Actor \n{\n    private $threadPool;\n\n    public function __call(string $name, array $arguments): mixed\n    {\n        if(current_thread_id() === $this-&gt;threadPool-&gt;getThreadIdForActor($this)) {\n            // 如果我们在同一个线程中，直接运行方法\n            return $this-&gt;$name(...$arguments);\n        }\n    \n        // 否则将调用排队给 actor\n        return $this-&gt;threadPool-&gt;enqueueActorMethod($this, $name, $arguments);\n    }\n}\n</code></pre>\n<p><code>enqueueActorMethod</code> 把 <code>postMessage</code> 加到 actor 队列，订阅结果事件，调用 <code>Async\\suspend()</code> 暂停协程。</p>\n<p>Actor 代码顺序执行，解决竞态条件，多线程开发对开发者透明。</p>\n<p>并行性靠每个 <code>ChatRoom</code> actor 能在单独线程跑来实现：</p>\n<pre><code class=\"language-php\">spawn(function() {\n   $room = new ChatRoom('room1');\n   $room-&gt;postMessage('Alice', 'Hello!');\n   $messages = $room-&gt;getMessages();\n   echo json_encode($messages);\n});\n\nspawn(function() {\n   $room = new ChatRoom('room2');\n   $room-&gt;postMessage('Bob', 'Hi there!');\n   $messages = $room-&gt;getMessages();\n   echo json_encode($messages);\n});\n</code></pre>\n<p><code>ChatRoom</code> 实例能在不同线程并行跑，因为每个 actor 有自己的执行线程、唯一的 PHP VM 状态和内存。</p>\n<p>创建 100 个聊天室：</p>\n<pre><code class=\"language-php\">use Async\\Actor;\n\n$rooms = [\n    'general' =&gt; new ChatRoom('general'),\n    'random'  =&gt; new ChatRoom('random'),\n    'tech'    =&gt; new ChatRoom('tech'),\n    // ... 97 个更多房间\n];\n\n// 处理请求的协程\nHttpServer::onRequest(function(Request $request, Response $response) use ($rooms) {\n   // HTTP 请求处理\n   $roomName = $request-&gt;getQueryParam('room');\n   $room = $rooms[$roomName] ?? null;\n   \n   if (!$room) {\n      $response-&gt;setStatus(404);\n      $response-&gt;write('Room not found');\n      $response-&gt;end();\n      return;\n   }\n   \n   // 调用看起来是同步的，但在另一个线程中运行！\n   $room-&gt;postMessage($request-&gt;getQueryParam('user'), $request-&gt;getQueryParam('text'));\n   $messages = $room-&gt;getMessages();\n   \n   $response-&gt;setHeader('Content-Type',  'application/json');  \n   $response-&gt;write(json_encode($messages));\n   $response-&gt;end();\n});\n</code></pre>\n<p>每个聊天室顺序处理消息，跟其他房间并行。</p>\n<p>Actors 不需要互斥锁、锁、复杂同步或手动线程池交互。它们是现成的高级并行化方案。</p>\n<p>一个聊天室要给另一个发消息也行，因为 actors 是 <code>SharedObject</code>，能跨线程交互：</p>\n<pre><code class=\"language-php\">class Rooms extends Actor\n{\n    private array $rooms = [];\n    \n    public function __construct(string ...$roomNames)\n    {\n       foreach ($roomNames as $name) {\n           $this-&gt;rooms[$name] = new ChatRoom($name);\n       }\n    }\n    \n    public function broadcastMessage(string $fromRoom, string $user, string $text): void\n    {\n        foreach ($this-&gt;rooms as $name =&gt; $room) {\n            if ($name !== $fromRoom) {\n                // 非阻塞调用\n                $room-&gt;postMessageAsync($user, $text);\n            }\n        }\n    }\n}\n\nspawn(function() {\n   $rooms = new Rooms('general', 'room1', 'room2', 'room3');\n   $rooms-&gt;broadcastMessage('general', 'Alice', 'Hello!');\n});\n</code></pre>\n<h3 id=\"actor-内部\">Actor 内部</h3>\n<p>PHP VM 保证 actor 内所有对象：</p>\n<ul>\n<li>要么只属于该 actor，在其唯一区域分配</li>\n<li>要么从其他区域或线程移动过来</li>\n<li>要么是另一个 <code>SharedObject</code> 或另一个 actor</li>\n</ul>\n<p>Actor 要么拥有自己的区域，要么只用显式共享的不可变对象；否则竞态还是会有。</p>\n<p>内存管理器保证 actor 方法内所有内存操作自动绑定到与 actor 关联的区域。</p>\n<p>方法通过 <code>Scheduler</code> 服务的 MPMC 消息队列执行。<code>Scheduler</code> 在 actors 间分配 CPU 时间，提供并发和并行执行。</p>\n<p><img alt=\"Actor 内部\" class=\"lazyload\" /></p>\n<h2 id=\"结论\">结论</h2>\n<p>这些听着都不错，但什么时候能真正用上？</p>\n<p><code>Single-threaded + offload</code> 模型可能很快出现，很多组件已经就绪。TrueAsync 单线程协程已到 beta 版。实验性的多线程内存管理器和创建线程的 API 已经实现。</p>\n<p>Actors 需要更多开发时间，因为涉及 PHP 核心很多部分，但仍是 PHP 9 的现实目标，给市场提供一种安全的多线程编程语言。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 07:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/catchadmin\">JaguarJack</a>&nbsp;\n阅读(<span id=\"post_view_count\">15</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第一周：循环神经网络 （二）循环神经网络",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19449622",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19449622\" id=\"cb_post_title_url\" title=\"发布于 2026-01-06 22:53\">\n    <span>吴恩达深度学习课程五：自然语言处理  第一周：循环神经网络 （二）循环神经网络</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课的第一周内容，<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=152\" rel=\"noopener nofollow\" target=\"_blank\">1.2</a>到<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.player.switch&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=154\" rel=\"noopener nofollow\" target=\"_blank\">1.4</a>的内容。</p>\n<hr />\n<p>本周为第五课的第一周内容，与 CV 相对应的，这一课所有内容的中心只有一个：<strong>自然语言处理（Natural Language Processing，NLP）</strong>。<br />\n应用在深度学习里，它是专门用来进行<strong>文本与序列信息建模</strong>的模型和技术，本质上是在全连接网络与统计语言模型基础上的一次“结构化特化”，也是人工智能中<strong>最贴近人类思维表达方式</strong>的重要研究方向之一。<br />\n<strong>这一整节课同样涉及大量需要反复消化的内容，横跨机器学习、概率统计、线性代数以及语言学直觉。</strong><br />\n语言不像图像那样“直观可见”，更多是抽象符号与上下文关系的组合，因此<strong>理解门槛反而更高</strong>。<br />\n因此，我同样会尽量补足必要的背景知识，尽可能用比喻和实例降低理解难度。<br />\n本篇的内容关于<strong>循环神经网络</strong>，在 NLP 中，循环神经网络就像卷积网络在 CV 中一样，是处理序列数据的核心特化模型，专门用于捕捉上下文依赖。</p>\n<h1 id=\"1-nlp-中的符号规范\">1. NLP 中的符号规范</h1>\n<p>在正式开始引入循环神经网络前，我们同样需要先了解一些相关的符号规范，主要是在数据的表示方面。</p>\n<h2 id=\"11-模型的输入与输出\">1.1 模型的输入与输出</h2>\n<p><img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106225017927-302231808.png\" /><br />\n再复述一下：</p>\n<ol>\n<li><span class=\"math inline\">\\(x^{&lt;t&gt;}\\)</span> ：<strong>输入序列在第 <span class=\"math inline\">\\(t\\)</span> 个时间步的输入</strong>。</li>\n<li><span class=\"math inline\">\\(y^{&lt;t&gt;}\\)</span> ：<strong>输出序列在第 <span class=\"math inline\">\\(t\\)</span> 个时间步的输出</strong>。</li>\n<li><span class=\"math inline\">\\(T_x\\)</span>：<strong>输入序列的长度</strong>。</li>\n<li><span class=\"math inline\">\\(T_y\\)</span>：<strong>输出序列的长度</strong>。</li>\n</ol>\n<p>现在，结合我们之前的符号规范，就可以知道：<br />\n<strong><span class=\"math inline\">\\(X^{(n)&lt;t&gt;}\\)</span> 代表一批次输入中第 <span class=\"math inline\">\\(n\\)</span> 个样本的第 <span class=\"math inline\">\\(t\\)</span> 个元素。</strong></p>\n<h2 id=\"12-词典vocabulary\">1.2 词典（Vocabulary）</h2>\n<p>经过上一部分，我们知道，<span class=\"math inline\">\\(x^{&lt;t&gt;}\\)</span> 代表了一个序列中的某一个元素。<br />\n但是又有一个新的问题：在 NLP 任务中，<span class=\"math inline\">\\(x^{&lt;t&gt;}\\)</span> 往往是一个<strong>离散的符号</strong>，例如某个具体的词（如 <em>hello</em>、<em>Hi</em>），而神经网络本质上只能处理<strong>数值向量</strong>，并不能直接理解“词”这一抽象概念。</p>\n<p>因此，在将文本序列送入模型之前，我们必须先完成一件事情：给“词”一个能输入网络的表示方法，<strong>即建立一种从“词”到“数值表示”的映射规则。</strong><br />\n显然，这种映射关系必须是<strong>确定且唯一的</strong>，即每一个词都对应一个唯一的数值表示。<br />\n而<strong>其中一种</strong>表示方法，就是我们在多分类标签表示中使用的<strong>独热编码</strong>。<br />\n我们看一个简单的示例：<br />\n假设我们当前的<strong>词典</strong>只包含 4 个词：</p>\n<p></p><div class=\"math display\">\\[{\\text{hello},\\ \\text{Hi},\\ \\text{thanks},\\ \\text{bye}}\n\\]</div><p></p><p>我们可以为词典中的每一个词分配一个唯一的索引：</p>\n<p></p><div class=\"math display\">\\[\\text{hello}\\rightarrow 1,\\quad \\text{Hi}\\rightarrow 2,\\quad \\text{thanks}\\rightarrow 3,\\quad \\text{bye}\\rightarrow 4\n\\]</div><p></p><p>在这种设定下，每一个词都可以用一个<strong>长度为 4 的独热向量</strong>来表示。<br />\n例如：</p>\n<ul>\n<li><span class=\"math inline\">\\(\\text{hello}\\)</span> 对应的表示为：<span class=\"math inline\">\\(x = [1,0,0,0]\\)</span></li>\n<li><span class=\"math inline\">\\(\\text{Hi}\\)</span> 对应的表示为：<span class=\"math inline\">\\(x = [0,1,0,0]\\)</span><br />\n<strong>词典中的每个词都有且仅有一个位置为 1，其余位置全部为 0。</strong><br />\n从模型的角度来看，这样的表示方式意味着：模型在任意时刻接收到的输入，本质上是一个高维稀疏向量，这正好满足“词 → 数值向量”的一对一映射要求，因此能够直接作为神经网络的输入。</li>\n</ul>\n<p>然而，在真实的 NLP 任务中，一个不可忽视的现实问题是：<strong>词典的规模通常非常巨大。</strong><br />\n在常见的语言建模或翻译任务中，词典大小往往达到<strong>数万甚至百万级别</strong>。<br />\n这意味着：</p>\n<ul>\n<li>独热向量的维度极高</li>\n<li>向量极度稀疏</li>\n<li>计算和存储成本都非常不经济</li>\n</ul>\n<p>因此，在实际模型中，我们往往会采用一种更紧凑、也更具语义表达能力的词表示方法，叫做<strong>词向量（Embedding）</strong> ，我们会在之后的内容详细展开它。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106224853098-1209020991.png\" /><br />\n此外，还会出现另一个问题：  <strong>测试或实际使用时，可能会遇到词典中从未出现过的词。</strong><br />\n对于这种<strong>不在词典中的词（Out-Of-Vocabulary，OOV）</strong>，常见的一种处理方式是在词典中额外引入一个特殊标记<code>&lt;UNK&gt;</code>，用于统一表示所有未知词，这种方式虽然简单，但也会丢失不同未知词之间的差异性，这也是后续子词建模方法要解决的问题之一。</p>\n<p>这些我们都会在之后的实际演示中详细展开，现在，先了解简单的符号规范后，我们正式开始引入循环神经网络。</p>\n<h1 id=\"2-循环神经网络recurrent-neural-networkrnn\">2. 循环神经网络（Recurrent Neural Network，RNN）</h1>\n<p>在<a href=\"https://www.cnblogs.com/Goblinscholar/p/19437798\" target=\"_blank\">上一篇</a>对序列模型的介绍中，我们已经知道：全连接网络和卷积网络并不适合用来处理序列数据。<br />\n我们需要一种模型，<strong>在处理当前输入的同时，能够保留并更新对“过去信息”的表示，让模型在理解当前内容时，不是孤立地“看这一刻”，而是基于整个上下文来判断。</strong><br />\n而这，就是 RNN 的基本思想。<br />\nRNN最早可追溯到 Jordan（1986）对序列连接主义模型的研究，而现代深度学习中常用的 RNN 基本形式，则来源于 Elman 在1990年发表的一篇论文： <a href=\"https://langev.com/pdf/elman90findingStructure.pdf?\" rel=\"noopener nofollow\" target=\"_blank\">Finding Structure in Time</a>中提出的递归状态网络结构。<br />\n可以看到，尽管论文距今已有几十年，但像最初的 CNN 一样，RNN 的思想并没有被时间淹没，而是不断被推广和创新，最终成为现代 NLP 中不可或缺的基础模型。</p>\n<p>现在，我们用一个最简单的<strong>单层循环神经网络</strong>来介绍 RNN 的传播过程及其特点。</p>\n<h2 id=\"21-单层循环神经网络的结构\">2.1 单层循环神经网络的结构</h2>\n<p>来看课程里这样一个循环网络的<strong>传播示意图</strong>：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106224834808-1322487049.png\" /><br />\n你可能会觉得，这个结构看起来好像不像传统意义上的“单层网络”，反而更像每一层都直接接收原始输入的全连接网络。<br />\n其实这正体现了 RNN 与 FN 或 CNN 的本质区别：<strong>在 RNN 中，每个时间步的隐藏状态不会直接传给下一层，而是传递给下一个时间步的自身。</strong><br />\n也就是说，这个网络的实际结构是这样的：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106224835295-122620775.png\" /><br />\n也就是说，RNN 本质上就是<strong>在全连接层基础上加了时间维度的循环连接</strong>。<br />\n你会发现，<strong>如果抛开传播逻辑不看，单层循环网络实际上就是一层全连接层。</strong><br />\n但这也恰恰说明了它的传播逻辑的重要性，到底是怎么样的设计能让单层的全连接层一跃而成为 NLP 的基石？<br />\n我们继续。</p>\n<h2 id=\"22-单层循环神经网络的正向传播\">2.2 单层循环神经网络的正向传播</h2>\n<p>了解了 RNN 的基本逻辑后， 现在，我们就来演示一下单层 RNN 的具体传播过程中的一些细节：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106224834545-1669402886.png\" /><br />\n了解了这些后，我们规范一下单层 RNN 的正向传播过程：</p>\n<ol>\n<li><strong>初始状态</strong><br />\nRNN 在第一个时间步输入第一个元素 <span class=\"math inline\">\\(x^{&lt;1&gt;}\\)</span>（例如“韩”）时，同时会引入初始的伪激活值 (<span class=\"math inline\">\\(a^{&lt;0&gt;}\\)</span>) 作为网络的初始状态，<span class=\"math inline\">\\(a^{&lt;0&gt;}\\)</span> 通常设为零向量或随机初始化。</li>\n<li><strong>逐步处理序列</strong><br />\n每个时间步，RNN 会将当前输入 <span class=\"math inline\">\\(x^{&lt;t&gt;}\\)</span> 与上一时间步的隐藏状态 <span class=\"math inline\">\\(a^{&lt;t-1&gt;}\\)</span> 一起输入网络，计算当前的隐藏状态 <span class=\"math inline\">\\(a^{&lt;t&gt;}\\)</span>,例如在第二步，输入为 <span class=\"math inline\">\\(x^{&lt;2&gt;}\\)</span>（“信”）和 <span class=\"math inline\">\\(a^{&lt;1&gt;}\\)</span>，得到 <span class=\"math inline\">\\(a^{&lt;2&gt;}\\)</span>。</li>\n<li><strong>输出生成</strong><br />\n每一步的隐藏状态 <span class=\"math inline\">\\(a^{&lt;t&gt;}\\)</span> 都会产生一个预测输出 <span class=\"math inline\">\\(\\hat{y}^{&lt;t&gt;}\\)</span>。输出不仅依赖当前输入，也包含了前面时间步的历史信息，这就是 RNN 能够“记忆”序列上下文的原因。</li>\n<li><strong>信息传递</strong><br />\n隐藏状态会沿时间步向后传递，使后续时间步的输出能够利用之前所有的序列信息，最终一步输出 <span class=\"math inline\">\\(\\hat{y}^{&lt;T_x&gt;}\\)</span> 包含整个序列的信息，可用于完整序列的预测或判断。</li>\n</ol>\n<p>明白了传播逻辑后，我们便可以更好地理解 RNN 正向传播的公式表达，我们先<strong>说明一下网络中的参数表示：</strong><br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106225018168-1671840978.png\" /><br />\n现在便摆出正向传播的通式如下：</p>\n<p></p><div class=\"math display\">\\[a^{&lt;t&gt;} = g(W_{aa} a^{&lt;t-1&gt;} + W_{ax} x^{&lt;t&gt;} + b_a)\n\\]</div><p></p><p></p><div class=\"math display\">\\[y^{&lt;t&gt;} = g(W_{ya} a^{&lt;t&gt;} + b_y)\n\\]</div><p></p><p>总结一下：RNN 的正向传播就是<strong>每个时间步将当前输入和上一隐藏状态结合，更新当前隐藏状态并生成输出，隐藏状态沿时间步传递，从而使网络能够逐步累积和利用序列历史信息</strong>。</p>\n<p>了解了正向传播的大致流程后，我们再看看 RNN 的反向传播是如何进行的。</p>\n<h2 id=\"23-单层循环神经网络的反向传播\">2.3 单层循环神经网络的反向传播</h2>\n<p>经过上一部分，我们已经知道：RNN 的正向传播，本质上是在<strong>时间维度上反复使用同一组参数</strong>，并通过隐藏状态把历史信息向后传递。</p>\n<p>那么问题自然就来了：  <strong>这些跨时间步传递的信息，反向传播时该怎么“算梯度”？</strong></p>\n<p>答案是： 怎么过去就怎么回来——RNN 的反向传播，并不是在“层”之间传播，而是<strong>在时间维度上反向传播</strong>，这种传播被称为 <strong>BPTT（Backpropagation Through Time）</strong> 。<br />\n我们来简要演示一下这个过程：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260106225121561-283647183.png\" /></p>\n<p>在监督学习中，反向传播的起点永远是<strong>损失函数</strong>，对于 RNN 来说，损失通常是<strong>所有时间步损失的累加</strong>（默认 <span class=\"math inline\">\\(T_x = T_y\\)</span>）：</p>\n<p></p><div class=\"math display\">\\[\\mathcal{L}\n=\n\\sum_{t=1}^{T_x}\n\\mathcal{L}^{&lt;t&gt;}(\\hat{y}^{&lt;t&gt;}, y^{&lt;t&gt;})\n\\]</div><p></p><p>也就是说，<strong>每一个时间步的输出都会对总损失产生贡献</strong>。<br />\n而对于单步的损失，最常用的仍然是我们比较熟悉的<a href=\"https://www.cnblogs.com/Goblinscholar/p/19133349\" target=\"_blank\">交叉熵损失</a>,你可以通过链接查看我们之前的介绍，应用在 RNN 中，它的公式是这样的：</p>\n<p></p><div class=\"math display\">\\[\\mathcal{L}\n=\n\\sum_{t=1}^{T_x}\n\\left(\n- \\sum_{k=1}^{C} y_k^{&lt;t&gt;} \\log \\hat{y}_k^{&lt;t&gt;}\n\\right)\n\\]</div><p></p><p>因此，反向传播时，我们会从最后一个时间步开始，逐步向前，把每个时间步的误差信号往回传， 由于参数在所有时间步共享，每个时间步的损失都会通过时间链路对这些参数产生梯度贡献，最终用于更新的梯度，是<strong>沿时间维度反向传播后，各时间步贡献的综合结果</strong>。</p>\n<p>这就是单层循环神经网络的反向传播，这样我们就对 RNN 的基本运行逻辑有了大体的了解。</p>\n<h1 id=\"3总结\">3.总结</h1>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>原理</th>\n<th>比喻</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>序列数据</td>\n<td>数据元素具有<strong>明确顺序</strong>，当前理解依赖历史上下文</td>\n<td>一句话的意思要从前往后读，不能只看中间一个词。</td>\n</tr>\n<tr>\n<td>时间步 <span class=\"math inline\">\\(t\\)</span></td>\n<td>序列中第 <span class=\"math inline\">\\(t\\)</span> 个位置，用于展开时间维度</td>\n<td>时间轴上的第 <span class=\"math inline\">\\(t\\)</span> 帧画面。</td>\n</tr>\n<tr>\n<td>输入 <span class=\"math inline\">\\(x^{}\\)</span></td>\n<td>第 <span class=\"math inline\">\\(t\\)</span> 个时间步送入模型的输入向量</td>\n<td>当前这一秒你听到的一个词。</td>\n</tr>\n<tr>\n<td>预测输出 <span class=\"math inline\">\\(\\hat{y}^{}\\)</span></td>\n<td>模型在第 <span class=\"math inline\">\\(t\\)</span> 个时间步给出的预测结果</td>\n<td>听到一句话后，此刻你做出的判断。</td>\n</tr>\n<tr>\n<td>序列长度 <span class=\"math inline\">\\(T_x, T_y\\)</span></td>\n<td>输入序列与输出序列的长度（可相同或不同）</td>\n<td>一段话的字数 vs 你回答时说了几句话。</td>\n</tr>\n<tr>\n<td>词典（Vocabulary）</td>\n<td>从词到索引的<strong>一一映射表</strong></td>\n<td>电话簿：名字 ↔ 电话号码</td>\n</tr>\n<tr>\n<td>RNN 核心思想</td>\n<td>当前状态由<strong>当前输入 + 过去状态</strong>共同决定</td>\n<td>你理解一句话时，会不断修正之前的理解。</td>\n</tr>\n<tr>\n<td>BPTT</td>\n<td>梯度沿时间维度反向传播</td>\n<td>从句尾倒回去反思：是哪一步理解错了。</td>\n</tr>\n<tr>\n<td>梯度累积</td>\n<td>参数梯度来自所有时间步的综合贡献</td>\n<td>每一句话的错误都会影响你下次的理解方式。</td>\n</tr>\n</tbody>\n</table>\n<p>。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-06 22:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">30</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "大道至简：如何用最轻量的代码实现跨团队的微服务契约？",
      "link": "https://www.cnblogs.com/jieky/p/19449427",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jieky/p/19449427\" id=\"cb_post_title_url\" title=\"发布于 2026-01-06 21:27\">\n    <span>大道至简：如何用最轻量的代码实现跨团队的微服务契约？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"大道至简如何用最轻量的代码实现跨团队的微服务契约\">大道至简：如何用最轻量的代码实现跨团队的微服务契约？</h1>\n<h3 id=\"1-二十年的架构长征从加法到减法\">1. 二十年的架构长征：从加法到减法</h3>\n<p>回首我的职业生涯，有三个时间坐标让我印象深刻：</p>\n<ul>\n<li><strong>2006 年：</strong> 身边同事开始谈论 DDD（领域驱动设计）和马丁·福勒的《企业应用架构模式》。那是<strong>求知</strong>的年代，我们试图通过增加模式的复杂度来驯服代码的混乱。</li>\n<li><strong>2016 年：</strong> 微服务浪潮袭来，我引入了 <strong>ABP 框架</strong>。那是<strong>工具</strong>的年代，重型框架提供了开箱即用的功能，但也带来了不可忽视的依赖负担和“全家桶”式的束缚。</li>\n<li><strong>2026 年：</strong> 站在即将 45 岁的时间点，我写下了 <strong>NexusContract</strong>。这是<strong>回归+AI</strong>的年代。在见过了无数过度设计的疲惫后，我明白了一个道理：<strong>架构的尊严在于边界的清晰，而非功能的堆砌。</strong></li>\n</ul>\n<h3 id=\"2-现状之痛被重型工具绑架的契约\">2. 现状之痛：被“重型工具”绑架的契约</h3>\n<p>在支付对账、第三方集成（如银联、支付宝）这种典型的异构场景中，我们经常陷入以下泥潭：</p>\n<ul>\n<li><strong>强耦合的 SDK：</strong> 为了用一个接口，不得不拉下一整套业务逻辑 SDK，里面甚至包含数据库依赖。</li>\n<li><strong>隐式魔法：</strong> 靠运行时推断、全局反射和硬编码来猜测字段名，一旦上游协议变更，整个系统瞬间崩溃。</li>\n<li><strong>沟通成本：</strong> 不同团队之间唯一的“契约”文档竟是半年前的 Markdown 截图，缺乏强类型约束。</li>\n</ul>\n<h3 id=\"3-nexuscontract-的内核repr-p-模式\">3. NexusContract 的内核：REPR-P 模式</h3>\n<p>我们扩展了 <a href=\"https://fast-endpoints.com/\" rel=\"noopener nofollow\" target=\"_blank\">FastEndpoints</a> 倡导的 <strong>REPR (Request-Endpoint-Response)</strong> 模式，通过 <strong>Proxying (代理化)</strong> 机制实现了逻辑与协议的彻底解耦。</p>\n<p><strong>核心宪法：显式边界优于隐式魔法。</strong><br />\n在 NexusContract 中，契约（Contract）是不可变的语义内核，是团队间唯一的法律。</p>\n<h3 id=\"4-核心实现在启动阶段冷冻元数据\">4. 核心实现：在启动阶段“冷冻”元数据</h3>\n<p>为了追求极致的性能，我为框架制定了两个严苛的技术决策：</p>\n<h4 id=\"a-元数据冷冻-frozen-metadata\">A. 元数据冷冻 (Frozen Metadata)</h4>\n<p>我们拒绝运行时反射。所有的元数据提取、约束审计都在启动阶段完成并缓存。启动完成后，结果存入不可变的 <code>ReflectionCache</code>。</p>\n<ul>\n<li><strong>运行期：</strong> O(1) 查询，零反射开销。</li>\n<li><strong>确定性：</strong> 确保 P50 与 P99 曲线高度重合，消除了 GC 导致的波动。</li>\n</ul>\n<h4 id=\"b-预编译投影-expression-tree\">B. 预编译投影 (Expression Tree)</h4>\n<p>我们利用 <strong>Expression Tree（表达式树）</strong> 将对象的映射逻辑预编译为 IL 代码。相比运行时反射遍历，我们将指令消耗减少了数倍，性能等同于硬编码映射。</p>\n<h3 id=\"5-架构红线用-nxc-诊断码捍卫确定性\">5. 架构红线：用 NXC 诊断码捍卫确定性</h3>\n<p>我们不抛出含义模糊的异常，每一处失效都有其唯一索引。</p>\n<ul>\n<li><strong>NXC1xx (静态红线)</strong>：架构违规。例如 <strong>【决策 A-401】</strong> 强制要求最大嵌套深度 ≤ 3。设计太复杂，系统将拒绝启动。</li>\n<li><strong>NXC2xx/3xx (运行诊断)</strong>：精确锁定出向报文不合规或入向协议对齐失败。</li>\n</ul>\n<h3 id=\"6-代码展示回归纯粹的-poco\">6. 代码展示：回归纯粹的 POCO</h3>\n<pre><code class=\"language-csharp\">/// &lt;summary&gt;\n/// 统一下单契约：纯净、强类型、显式边界\n/// &lt;/summary&gt;\n[ApiOperation(\"payment.order.create\", HttpVerb.POST)]\npublic class OrderRequest : IApiRequest&lt;OrderResponse&gt;\n{\n    [ApiField(\"mer_order_no\", IsRequired = true)]\n    public string OrderNo { get; set; }\n\n    [ApiField(\"card_no\", IsEncrypted = true)] // 触发【规则 R-201】验证，必须显式锁定名称\n    public string CardNo { get; set; }\n\n    [ApiField(\"txn_amt\")]\n    public long Amount { get; set; }\n}\n\n</code></pre>\n<h3 id=\"7-结语\">7. 结语</h3>\n<p>在软件架构的世界里，我们总是习惯于做加法，认为功能越多越强大。但真正的工业级作品，往往敢于在关键时刻停下来做减法。</p>\n<p><strong>在网络延迟的 3 秒黑暗中，我们要让内部处理的 50 微秒闪耀得像恒星。</strong></p>\n<h3 id=\"️-项目地址与源码\">🏛️ 项目地址与源码</h3>\n<p>本项目已正式开源，欢迎各位同行指正、交流：</p>\n<ul>\n<li><strong>GitHub:</strong> <a href=\"https://github.com/NexusContract/PubSoft.NexusContract\" rel=\"noopener nofollow\" target=\"_blank\">NexusContract</a></li>\n<li><strong>核心理念：</strong> Kernelized Contract Integration (KCI) Framework</li>\n<li><strong>适用场景：</strong> 高性能支付集成、跨团队微服务契约管理、异构协议透明转换。</li>\n</ul>\n<hr />\n<p><strong>关于作者：</strong><br />\n一名在 .NET 阵营潜行 20 年的架构师，从 .NET Framework 1.1 到今天的 .NET 10，依然对干净的代码保持热爱。</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>______________________________________<br />生活，要用圣人的胸怀面对，用科学的方法支配， <br />&nbsp; &nbsp; &nbsp; &nbsp; 用皇帝的御膳养胃，用清洁的空气洗肺， <br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 用小猪的感觉去睡，用太阳的热情灌水。<br />______________________________________</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-06 21:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jieky\">消失者</a>&nbsp;\n阅读(<span id=\"post_view_count\">71</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AUC 的两种等价定义：从排序概率到 ROC 曲线的统一理解",
      "link": "https://www.cnblogs.com/GlenTt/p/19449279",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GlenTt/p/19449279\" id=\"cb_post_title_url\" title=\"发布于 2026-01-06 20:27\">\n    <span>AUC 的两种等价定义：从排序概率到 ROC 曲线的统一理解</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"auc-的两种等价定义从排序概率到-roc-曲线的统一理解\">AUC 的两种等价定义：从排序概率到 ROC 曲线的统一理解</h1>\n<p>在推荐系统与广告排序中，AUC 是最常用、也最容易被误解的离线评估指标之一。很多人同时接触过两种说法：<br />\n一种是“ROC 曲线下面积”，另一种是“正样本排在负样本前面的概率”。<strong>这并不是两种不同的指标，而是同一个指标的两种完全等价的定义</strong>。</p>\n<h2 id=\"一auc-的本质一个排序概率\">一、AUC 的本质：一个排序概率</h2>\n<h3 id=\"1-问题设定\">1. 问题设定</h3>\n<p>假设我们面对的是一个二分类 / 排序问题：</p>\n<ul>\n<li>每个样本 <span class=\"math inline\">\\(x_i\\)</span> 有真实标签 <span class=\"math inline\">\\(y_i \\in {0,1}\\)</span></li>\n<li>模型给出一个连续预测分数 <span class=\"math inline\">\\(s_i \\in \\mathbb{R}\\)</span></li>\n<li>分数越大，模型认为样本“越可能是正样本”</li>\n</ul>\n<p>定义：</p>\n<ul>\n<li>正样本集合<p></p><div class=\"math display\">\\[P = { i \\mid y_i = 1 }\n\\]</div><p></p></li>\n<li>负样本集合<p></p><div class=\"math display\">\\[N = { j \\mid y_j = 0 }\n\\]</div><p></p></li>\n</ul>\n<h3 id=\"2-auc-的概率定义最本质定义\">2. AUC 的概率定义（最本质定义）</h3>\n<p><strong>AUC 的概率定义是：</strong></p>\n<p>从正样本集合中随机抽取一个样本，从负样本集合中随机抽取一个样本，<br />\n正样本的预测分数大于负样本预测分数的概率。</p>\n<p>其数学形式为：</p>\n<p></p><div class=\"math display\">\\[\\mathrm{AUC}\n=\n\n\\frac{1}{|P|\\cdot|N|}\n\\sum_{p \\in P}\\sum_{n \\in N}\n\\left[\n\\mathbb{I}(s_p &gt; s_n)\n+\n\\frac{1}{2}\\mathbb{I}(s_p = s_n)\n\\right]\n\\]</div><p></p><p>其中：</p>\n<ul>\n<li><span class=\"math inline\">\\(\\mathbb{I}(\\cdot)\\)</span> 为指示函数</li>\n<li>当 <span class=\"math inline\">\\(s_p = s_n\\)</span> 时记为 <span class=\"math inline\">\\(0.5\\)</span>，表示随机打平</li>\n</ul>\n<h3 id=\"3-这一点意味着什么\">3. 这一点意味着什么？</h3>\n<ul>\n<li>AUC <strong>不依赖任何阈值</strong></li>\n<li>AUC <strong>不是一个分类指标，而是一个排序指标</strong></li>\n<li>AUC 衡量的是：<br />\n<strong>模型是否倾向于把正样本整体排在负样本前面</strong></li>\n</ul>\n<p>这也是为什么在推荐系统中，即便最终没有明确的“正负分类决策”，AUC 依然是最核心的离线评估指标之一。</p>\n<h2 id=\"二roc-曲线定义几何视角下的同一个量\">二、ROC 曲线定义：几何视角下的同一个量</h2>\n<h3 id=\"1-roc-曲线如何构造\">1. ROC 曲线如何构造</h3>\n<p>给定一组预测分数 <span class=\"math inline\">\\(s_i\\)</span>，我们引入一个阈值 <span class=\"math inline\">\\(\\tau\\)</span>：</p>\n<ul>\n<li>若 <span class=\"math inline\">\\(s_i \\ge \\tau\\)</span>，预测为正类</li>\n<li>若 <span class=\"math inline\">\\(s_i &lt; \\tau\\)</span>，预测为负类</li>\n</ul>\n<p>在每一个阈值 <span class=\"math inline\">\\(\\tau\\)</span> 下，可以计算：</p>\n<ul>\n<li>真阳性率（TPR）<p></p><div class=\"math display\">\\[\\mathrm{TPR}(\\tau)\n=\n\n\\frac{\\mathrm{TP}}{\\mathrm{P}}\n\\]</div><p></p></li>\n<li>假阳性率（FPR）<p></p><div class=\"math display\">\\[\\mathrm{FPR}(\\tau)\n=\n\n\\frac{\\mathrm{FP}}{\\mathrm{N}}\n\\]</div><p></p></li>\n</ul>\n<p>当阈值 <span class=\"math inline\">\\(\\tau\\)</span> 从 <span class=\"math inline\">\\(+\\infty\\)</span> 连续下降到 <span class=\"math inline\">\\(-\\infty\\)</span> 时，<br />\n点对 <span class=\"math inline\">\\((\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))\\)</span> 在平面上形成一条曲线，即 <strong>ROC 曲线</strong>。</p>\n<h3 id=\"2-auc-的-roc-定义\">2. AUC 的 ROC 定义</h3>\n<p><strong>AUC 定义为 ROC 曲线下方的面积：</strong></p>\n<p></p><div class=\"math display\">\\[\\mathrm{AUC}\n=\n\n\\int_0^1 \\mathrm{TPR}(\\mathrm{FPR}) , d(\\mathrm{FPR})\n\\]</div><p></p><p>这是一个<strong>几何意义上的定义</strong>。</p>\n<h2 id=\"三两种定义为什么是完全等价的\">三、两种定义为什么是完全等价的？</h2>\n<p>一个统计学习中的经典结论是：</p>\n<p></p><div class=\"math display\">\\[\\boxed{\n\\mathrm{AUC}\n=\n\nP(s^+ &gt; s^-)\n}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(s^+\\)</span> 表示正样本分数，<span class=\"math inline\">\\(s^-\\)</span> 表示负样本分数。</p>\n<p>直观解释如下：</p>\n<ul>\n<li>ROC 曲线本质是在 <strong>按照 score 从高到低扫描排序结果</strong></li>\n<li>每遇到一个正样本，TPR 增加</li>\n<li>每遇到一个负样本，FPR 增加</li>\n<li>某个正样本是否“早于”负样本被扫描到，正对应于<p></p><div class=\"math display\">\\[s^+ &gt; s^-\n\\]</div><p></p></li>\n</ul>\n<p>因此：</p>\n<blockquote>\n<p><strong>ROC 曲线下面积，等价于所有正负样本对中，排序正确的比例。</strong></p>\n</blockquote>\n<p>ROC 只是将“排序关系”用几何方式进行了表达。</p>\n<h2 id=\"四一个完整可手算的例子\">四、一个完整、可手算的例子</h2>\n<h3 id=\"1-样本与预测分数\">1. 样本与预测分数</h3>\n<table>\n<thead>\n<tr>\n<th>样本</th>\n<th>label</th>\n<th>score</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>1</td>\n<td>0.90</td>\n</tr>\n<tr>\n<td>B</td>\n<td>1</td>\n<td>0.60</td>\n</tr>\n<tr>\n<td>C</td>\n<td>0</td>\n<td>0.70</td>\n</tr>\n<tr>\n<td>D</td>\n<td>0</td>\n<td>0.40</td>\n</tr>\n<tr>\n<td>E</td>\n<td>0</td>\n<td>0.20</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>正样本：A, B</li>\n<li>负样本：C, D, E</li>\n<li>正负样本对总数：<span class=\"math inline\">\\(2 \\times 3 = 6\\)</span></li>\n</ul>\n<hr />\n<h3 id=\"2-按概率定义逐对比较\">2. 按概率定义逐对比较</h3>\n<table>\n<thead>\n<tr>\n<th>正样本</th>\n<th>负样本</th>\n<th>是否排序正确</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A(0.90)</td>\n<td>C(0.70)</td>\n<td>✓</td>\n</tr>\n<tr>\n<td>A(0.90)</td>\n<td>D(0.40)</td>\n<td>✓</td>\n</tr>\n<tr>\n<td>A(0.90)</td>\n<td>E(0.20)</td>\n<td>✓</td>\n</tr>\n<tr>\n<td>B(0.60)</td>\n<td>C(0.70)</td>\n<td>✗</td>\n</tr>\n<tr>\n<td>B(0.60)</td>\n<td>D(0.40)</td>\n<td>✓</td>\n</tr>\n<tr>\n<td>B(0.60)</td>\n<td>E(0.20)</td>\n<td>✓</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>排序正确对数：5</li>\n<li>总对数：6</li>\n</ul>\n<p></p><div class=\"math display\">\\[\\mathrm{AUC} = \\frac{5}{6} \\approx 0.833\n\\]</div><p></p><h2 id=\"五对应的计算代码\">五、对应的计算代码</h2>\n<p>下面给出两种 AUC 计算实现。</p>\n<h3 id=\"1-概率定义两两比较定义直译\">1. 概率定义（两两比较，定义直译）</h3>\n<pre><code class=\"language-python\">def auc_pairwise(labels, scores):\n    \"\"\"\n    基于 AUC 的概率定义（Pairwise Comparison）进行计算。\n\n    输入：\n    - labels: List[int] 或 1D array\n        样本真实标签，取值为 {0, 1}\n        1 表示正样本，0 表示负样本\n    - scores: List[float] 或 1D array\n        模型对每个样本给出的预测分数，分数越大表示越倾向正类\n\n    输出：\n    - auc: float\n        AUC 值，取值范围 [0, 1]\n\n    核心思想：\n    随机取一个正样本 p 和一个负样本 n，\n    统计 P(score_p &gt; score_n) 的比例\n    \"\"\"\n\n    # 提取正样本 (label=1) 的预测分数\n    pos_scores = [s for l, s in zip(labels, scores) if l == 1]\n\n    # 提取负样本 (label=0) 的预测分数\n    neg_scores = [s for l, s in zip(labels, scores) if l == 0]\n\n    # 排序正确的正负样本对数量（允许 0.5 的打平贡献）\n    correct = 0.0\n\n    # 正负样本对的总数量 |P| * |N|\n    total = len(pos_scores) * len(neg_scores)\n\n    # 对所有正负样本对进行两两比较\n    for sp in pos_scores:        # sp: positive sample score\n        for sn in neg_scores:    # sn: negative sample score\n            if sp &gt; sn:\n                # 正样本分数严格大于负样本分数，排序正确\n                correct += 1.0\n            elif sp == sn:\n                # 分数相等，按约定计为 0.5（随机打平）\n                correct += 0.5\n            # sp &lt; sn 时不加分，表示排序错误\n\n    # AUC = 排序正确的比例\n    return correct / total\n</code></pre>\n<p><strong>复杂度分析：</strong></p>\n<ul>\n<li>时间复杂度：<p></p><div class=\"math display\">\\[O(|P| \\cdot |N|)\n\\]</div><p></p>其中 <span class=\"math inline\">\\(|P|\\)</span> 为正样本数，<span class=\"math inline\">\\(|N|\\)</span> 为负样本数</li>\n<li>空间复杂度：<p></p><div class=\"math display\">\\[O(|P| + |N|)\n\\]</div><p></p></li>\n</ul>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>严格对应 AUC 的概率定义</li>\n<li>适合教学、理论验证、小规模数据</li>\n<li>不适用于工程和大规模离线计算</li>\n</ul>\n<hr />\n<h3 id=\"2-排序--rank-based-实现工程思想\">2. 排序 / Rank-based 实现（工程思想）</h3>\n<pre><code class=\"language-python\">import numpy as np\n\ndef auc_rank(labels, scores):\n    \"\"\"\n    基于排序（Rank / Mann–Whitney U）的 AUC 计算方法。\n\n    输入：\n    - labels: List[int] 或 1D numpy array\n        样本真实标签，取值为 {0, 1}\n    - scores: List[float] 或 1D numpy array\n        模型预测分数，分数越大表示越可能为正样本\n\n    输出：\n    - auc: float\n        AUC 值，取值范围 [0, 1]\n\n    核心思想：\n    1. 按预测分数从小到大排序\n    2. 扫描排序后的样本序列\n    3. 每遇到一个正样本，统计其前面已有多少负样本\n       这些负样本都被该正样本“正确地排在后面”\n    \"\"\"\n\n    # 转为 numpy array，便于排序和向量化操作\n    labels = np.asarray(labels)\n    scores = np.asarray(scores)\n\n    # 获取按照 score 从小到大排序后的索引\n    order = np.argsort(scores)\n\n    # 按排序后的顺序重排标签\n    labels_sorted = labels[order]\n\n    # 正样本数量 |P|\n    n_pos = np.sum(labels_sorted == 1)\n\n    # 负样本数量 |N|\n    n_neg = np.sum(labels_sorted == 0)\n\n    # 已扫描到的负样本数量（前缀负样本计数）\n    neg_count = 0\n\n    # 排序正确的正负样本对数量\n    correct = 0.0\n\n    # 从低分到高分扫描\n    for l in labels_sorted:\n        if l == 1:\n            # 当前是正样本：\n            # 它前面的所有负样本都满足 score_neg &lt; score_pos\n            correct += neg_count\n        else:\n            # 当前是负样本，增加负样本计数\n            neg_count += 1\n\n    # AUC = 排序正确的正负样本对 / 总正负样本对\n    return correct / (n_pos * n_neg)\n</code></pre>\n<p><strong>复杂度分析：</strong></p>\n<ul>\n<li>时间复杂度：<p></p><div class=\"math display\">\\[O(n \\log n)\n\\]</div><p></p>主要来自排序操作，其中 <span class=\"math inline\">\\(n = |P| + |N|\\)</span></li>\n<li>空间复杂度：<p></p><div class=\"math display\">\\[O(n)\n\\]</div><p></p></li>\n</ul>\n<p><strong>工程说明：</strong></p>\n<ul>\n<li>与 Mann–Whitney U 统计量完全等价</li>\n<li>是工业界离线 AUC 计算（Spark / MapReduce / Flink）的理论基础</li>\n<li>可自然扩展为分桶、分 user、分实验组的 AUC 统计</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-01-06 20:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GlenTt\">GlenTt</a>&nbsp;\n阅读(<span id=\"post_view_count\">21</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "性能提升4倍！使用Granian作为Django项目的ASGI服务器",
      "link": "https://www.cnblogs.com/deali/p/19449242",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19449242\" id=\"cb_post_title_url\" title=\"发布于 2026-01-06 20:11\">\n    <span>性能提升4倍！使用Granian作为Django项目的ASGI服务器</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>最近我又继续在开发 DjangoStarter 的新版本了。</p>\n<p>之前为了实现 docker 部署，我把 Nginx 打包进了 DjangoStarter 的 compose 配置里了，不过这带来了配置的复杂度，特别是还要搭配框架实现 URL prefix 之类的功能。</p>\n<p>从 v3.2.x 版本开始，我就启动了减法计划，简化代码和功能，减少心智负担，这个 Nginx 容器也是我一直想去掉的。</p>\n<p>最近发现 Granian 这个 Rust 开发的 ASGI 服务器，性能高，而且还可以支持静态文件，正好完美符合我的需求，于是这次正好拿来替换原本使用的 Daphne</p>\n<h2 id=\"granian\">Granian</h2>\n<p>项目主页: <a href=\"https://github.com/emmett-framework/granian\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/emmett-framework/granian</a></p>\n<p>Granian 是一款高性能 Python Web Server，支持 ASGI、WSGI、RSGI，基于 Rust 编写，启动速度快、并发能力强，非常适合 Django / FastAPI / Starlette。</p>\n<p>官方描述为 “A Rust HTTP server for Python applications built on top of Hyper/Tokio”。</p>\n<p>特点：</p>\n<ul>\n<li>支持 <strong>ASGI 3</strong>、<strong>RSGI</strong>（Rust-Server-Gateway Interface）和 <strong>WSGI</strong> 接口。</li>\n<li>支持 HTTP/1 和 HTTP/2（未来计划 HTTP/3）协议。</li>\n<li>支持静态文件直出 (“Direct static files serving”)。</li>\n</ul>\n<h2 id=\"使用方式\">使用方式</h2>\n<p>很简单，不需要修改代码，只需要修改启动命令。</p>\n<p>目前搭配 DjangoStarter 使用的启动命令是这样的：</p>\n<pre><code class=\"language-bash\">granian --interface asgi --host 0.0.0.0 --port 8000 --static-path-route /static --static-path-mount ./static-dist config.asgi:application\n</code></pre>\n<p>类似 uvicorn，这个 granian 也支持热重载，加个 <code>--reload</code> 参数就行了</p>\n<h2 id=\"性能测试\">性能测试</h2>\n<p>本次用 wrk 进行性能测试</p>\n<h3 id=\"测试数据\">测试数据</h3>\n<p>以下数据在腾讯云 2 cores CPU + 2G 内存的服务器上测得。</p>\n<p>django 5.x + ninja + daphne</p>\n<pre><code>$ wrk -t4 -c200 -d30s http://127.0.0.1:9876/api/django-starter/monitoring/health\nRunning 30s test @ http://127.0.0.1:9876/api/django-starter/monitoring/health\n  4 threads and 200 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.97s     0.00us   1.97s   100.00%\n    Req/Sec    38.55     55.33   343.00     90.23%\n  1343 requests in 30.04s, 760.03KB read\n  Socket errors: connect 0, read 0, write 0, timeout 1342\nRequests/sec:     44.70\nTransfer/sec:     25.30KB\n</code></pre>\n<p>django 5.x + ninja + granian</p>\n<pre><code>$ wrk -t4 -c200 -d30s http://127.0.0.1:9875/api/django-starter/monitoring/hea\nlth\nRunning 30s test @ http://127.0.0.1:9875/api/django-starter/monitoring/health\n  4 threads and 200 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.20s    93.05ms   1.72s    82.69%\n    Req/Sec    83.13    105.81   460.00     83.72%\n  4980 requests in 30.04s, 2.85MB read\nRequests/sec:    165.76\nTransfer/sec:     97.31KB\n</code></pre>\n<p>因为好奇，我还找到之前一个很老的项目，使用WSGI部署的进行对比。</p>\n<p>以下数据在私有云的 4 cores CPU + 2G 内存服务器上测得。</p>\n<p>因为是完全不同的服务器硬件，数据仅供参考。</p>\n<p>Django 3.x + drf + uwsgi + nginx</p>\n<pre><code>$ wrk -t4 -c200 -d30s http://127.0.0.1:9001/api/health/\nRunning 30s test @ http://127.0.0.1:9001/api/health/\n  4 threads and 200 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   295.30ms  373.95ms   1.96s    85.14%\n    Req/Sec   205.54     68.42   380.00     73.73%\n  19583 requests in 30.09s, 5.83MB read\n  Socket errors: connect 0, read 0, write 0, timeout 474\n  Non-2xx or 3xx responses: 12\nRequests/sec:    650.89\nTransfer/sec:    198.32KB\n</code></pre>\n<p>Django 3.x + ninja + uwsgi + nginx</p>\n<pre><code>$ wrk -t4 -c200 -d30s http://127.0.0.1:9001/api2/health\nRunning 30s test @ http://127.0.0.1:9001/api2/health\n  4 threads and 200 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   203.75ms  280.30ms   1.95s    88.44%\n    Req/Sec   250.81    108.59   500.00     61.21%\n  22542 requests in 30.06s, 5.68MB read\n  Socket errors: connect 0, read 0, write 0, timeout 420\n  Non-2xx or 3xx responses: 12\nRequests/sec:    749.88\nTransfer/sec:    193.35KB\n</code></pre>\n<h3 id=\"结论\">结论</h3>\n<p>以下是使用 AI 对上面的测试数据进行分析的结论，不过 ASGI 和 uWSGI 不在同一台服务器进行测试，其实很难直接对比。目前看来切换到 Granian 确实可以提高4倍的性能。</p>\n<p>① Daphne 在 Django + ASGI 下的性能表现非常差</p>\n<ul>\n<li>延迟直接飙到 <strong>1.9 秒级别</strong>，</li>\n<li>wrk 200 并发几乎把它压扁，</li>\n<li><strong>1343 请求里 1342 超时</strong>，等于完全顶不住。</li>\n</ul>\n<p>说白了：<strong>Daphne 更像是开发环境服务器，不推荐上生产高并发。</strong></p>\n<p>② Granian 性能比 Daphne 好 3–4 倍，但仍然有限</p>\n<ul>\n<li>每秒处理 <strong>165 req/s</strong>（同机房、同代码）。</li>\n<li>延迟仍然在 <strong>1.2s</strong> 左右，远不算理想（在高并发下仍吃力）。</li>\n<li>优点是 ASGI 原生 + Rust 实现，比 Daphne 强太多。</li>\n</ul>\n<p>直观感受：<strong>Granian 能用，但你别指望它像 uWSGI 那样扛流量。</strong></p>\n<p>③ uWSGI（WSGI）表现碾压：单机可达 650–750 req/s 级别</p>\n<ul>\n<li>性能直接是 granian 的 <strong>4～5 倍</strong>。</li>\n<li>虽然是老架构（WSGI），但调优成熟、稳定、分配机制强，抗压能力远强于同类 ASGI 服务。</li>\n</ul>\n<p>简而言之：<strong>如果不用异步，WSGI 依旧是 Django 的最强部署方式（性能层面）。</strong></p>\n<h2 id=\"docker-compose\">docker-compose</h2>\n<p>这是精简后的 compose 配置</p>\n<pre><code class=\"language-yaml\">services:\n  app:\n    image: ${APP_IMAGE_NAME}:${APP_IMAGE_TAG}\n    container_name: $APP_NAME-app\n    command:\n      - granian\n      - --interface\n      - asgi\n      - --host\n      - 0.0.0.0\n      - --port\n      - \"${APP_INTERNAL_PORT:-8000}\"\n      - --static-path-route\n      - /static\n      - --static-path-mount\n      - /project/static-dist\n      - config.asgi:application\n</code></pre>\n<h2 id=\"命令行参数\">命令行参数</h2>\n<p>它的命令行结构很简单：</p>\n<pre><code class=\"language-bash\">granian [OPTIONS] APP\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><strong>APP</strong> 是入口，例如：<code>config.asgi:application</code></li>\n<li><strong>OPTIONS</strong> 是各种配置参数</li>\n</ul>\n<p>下面按分类整理所有参数（附带说明与建议）。</p>\n<h3 id=\"-基础参数启动必要项\">🧩 基础参数（启动必要项）</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>APP</code></td>\n<td><strong>要启动的应用入口</strong>（如 <code>mysite.asgi:application</code>）</td>\n<td>必填</td>\n</tr>\n<tr>\n<td><code>--interface</code></td>\n<td>接口类型：<code>asgi</code> / <code>asginl</code> / <code>rsgi</code> / <code>wsgi</code></td>\n<td>rsgi</td>\n</tr>\n<tr>\n<td><code>--host</code></td>\n<td>监听地址</td>\n<td>127.0.0.1</td>\n</tr>\n<tr>\n<td><code>--port</code></td>\n<td>端口</td>\n<td>8000</td>\n</tr>\n<tr>\n<td><code>--uds</code></td>\n<td>使用 Unix Domain Socket</td>\n<td>无</td>\n</tr>\n<tr>\n<td><code>--http</code></td>\n<td>HTTP 版本：<code>1</code>、<code>2</code>、<code>auto</code></td>\n<td>auto</td>\n</tr>\n<tr>\n<td><code>--workers</code></td>\n<td>Worker 进程数</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n<p>👉 Django、FastAPI 用户一般写：</p>\n<pre><code>--interface asgi\n</code></pre>\n<h3 id=\"️-静态文件服务django-专用配置\">🗂️ 静态文件服务（Django 专用配置）</h3>\n<p>Granian 内置静态文件服务：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--static-path-route</code></td>\n<td>URL 路由前缀，例如 <code>/static</code></td>\n<td>/static</td>\n</tr>\n<tr>\n<td><code>--static-path-mount</code></td>\n<td>文件目录，例如 <code>/project/static-dist</code></td>\n<td>无</td>\n</tr>\n<tr>\n<td><code>--static-path-expires</code></td>\n<td>缓存时间（秒）</td>\n<td>86400</td>\n</tr>\n</tbody>\n</table>\n<p>示例：</p>\n<pre><code>--static-path-route /static --static-path-mount /project/static-dist\n</code></pre>\n<h3 id=\"️-多进程线程事件循环选项\">⚙️ 多进程、线程、事件循环选项</h3>\n<p>Worker / Thread</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--workers</code></td>\n<td>Worker 数量</td>\n</tr>\n<tr>\n<td><code>--blocking-threads</code></td>\n<td>阻塞线程数</td>\n</tr>\n<tr>\n<td><code>--runtime-threads</code></td>\n<td>Runtime 线程数</td>\n</tr>\n<tr>\n<td><code>--runtime-blocking-threads</code></td>\n<td>Runtime I/O 阻塞线程</td>\n</tr>\n</tbody>\n</table>\n<p>建议：</p>\n<ul>\n<li><strong>CPU × 2</strong> 左右的 worker 容量通常够用</li>\n<li>大部分 ASGI 项目不需要调 thread 参数</li>\n</ul>\n<h3 id=\"-事件循环--runtime\">🔁 事件循环 &amp; Runtime</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--loop</code></td>\n<td>事件循环：<code>auto</code>、<code>asyncio</code>、<code>rloop</code>、<code>uvloop</code></td>\n</tr>\n<tr>\n<td><code>--task-impl</code></td>\n<td>task 执行器：<code>asyncio</code> / <code>rust</code></td>\n</tr>\n<tr>\n<td><code>--runtime-mode</code></td>\n<td>单线程 <code>st</code> / 多线程 <code>mt</code></td>\n</tr>\n</tbody>\n</table>\n<p>适用建议：</p>\n<ul>\n<li>普通项目：用默认即可</li>\n<li>高并发：<code>--task-impl rust</code> 性能更强</li>\n</ul>\n<h3 id=\"-http1-与-http2-相关参数\">🔒 HTTP/1 与 HTTP/2 相关参数</h3>\n<table>\n<thead>\n<tr>\n<th>类别</th>\n<th>常用配置</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>HTTP/1</td>\n<td><code>--http1-buffer-size</code>、<code>--http1-keep-alive</code></td>\n</tr>\n<tr>\n<td>HTTP/2</td>\n<td><code>--http2-*</code> 一系列参数控制 flow control、窗口、keepalive、stream 数量等</td>\n</tr>\n</tbody>\n</table>\n<p>大部分项目无需调整，默认即可。</p>\n<h3 id=\"-日志logging\">📜 日志（Logging）</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n<th>默认</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--log / --no-log</code></td>\n<td>启用日志</td>\n<td>enabled</td>\n</tr>\n<tr>\n<td><code>--log-level</code></td>\n<td>日志等级</td>\n<td>info</td>\n</tr>\n<tr>\n<td><code>--log-config</code></td>\n<td>使用 JSON 配置文件</td>\n<td>无</td>\n</tr>\n<tr>\n<td><code>--access-log</code></td>\n<td>开启 access log</td>\n<td>disabled</td>\n</tr>\n<tr>\n<td><code>--access-log-fmt</code></td>\n<td>Access log 格式</td>\n<td>无</td>\n</tr>\n</tbody>\n</table>\n<p>如果你希望生产环境有 Nginx 样式的 access log：</p>\n<pre><code>--access-log --access-log-fmt \"%a %r %s %b\"\n</code></pre>\n<h3 id=\"-热重载开发环境用\">🔁 热重载（开发环境用）</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--reload</code></td>\n<td>开启自动重载</td>\n</tr>\n<tr>\n<td><code>--reload-paths</code></td>\n<td>指定监控目录</td>\n</tr>\n<tr>\n<td><code>--reload-ignore-*</code></td>\n<td>忽略目录、路径、pattern</td>\n</tr>\n</tbody>\n</table>\n<p>例如：</p>\n<pre><code>--reload --reload-paths src/\n</code></pre>\n<h3 id=\"-https\">🔐 HTTPS</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--ssl-certificate</code></td>\n<td>证书文件</td>\n</tr>\n<tr>\n<td><code>--ssl-keyfile</code></td>\n<td>密钥文件</td>\n</tr>\n<tr>\n<td><code>--ssl-ca</code></td>\n<td>CA</td>\n</tr>\n<tr>\n<td><code>--ssl-client-verify</code></td>\n<td>客户端证书验证</td>\n</tr>\n</tbody>\n</table>\n<p>（一般反向代理交给 Nginx 做 HTTPS）</p>\n<h3 id=\"-其他有用但不常改的参数\">🧰 其他有用但不常改的参数</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>--working-dir</code></td>\n<td>切换 WorkDir</td>\n</tr>\n<tr>\n<td><code>--env-files</code></td>\n<td>加载环境变量文件</td>\n</tr>\n<tr>\n<td><code>--factory</code></td>\n<td>APP 是 factory function 时使用</td>\n</tr>\n<tr>\n<td><code>--url-path-prefix</code></td>\n<td>应用挂载前缀</td>\n</tr>\n<tr>\n<td><code>--process-name</code></td>\n<td>自定义进程名</td>\n</tr>\n<tr>\n<td><code>--pid-file</code></td>\n<td>写入 PID 文件</td>\n</tr>\n<tr>\n<td><code>--version</code></td>\n<td>显示版本</td>\n</tr>\n<tr>\n<td><code>--help</code></td>\n<td>显示帮助</td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-06 20:11</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">24</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Zsh 配置笔记",
      "link": "https://www.cnblogs.com/owlman/p/19449225",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19449225\" id=\"cb_post_title_url\" title=\"发布于 2026-01-06 20:01\">\n    <span>Zsh 配置笔记</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记主要记录了我在使用 Zsh 这款 Shell 的过程中所记录的一些心得与体会。它将会被存储在我个人的 <a href=\"https://github.com/owlman/CS_Studynotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机专业笔记库</a> 中，以便日后查阅。</p>\n</blockquote>\n<h2 id=\"zsh-简介\">Zsh 简介</h2>\n<p>Z shell（以下简称 Zsh）是保罗·弗斯塔德（Paul Falstad）于 1990 年在普林斯顿大学求学时编写的、一款可用作交互式登录的 Shell。Zsh 对 <a href=\"https://zh.wikipedia.org/wiki/Bourne_shell\" rel=\"noopener nofollow\" target=\"_blank\">Bourne shell</a>做出了大量改进，同时加入了 <a href=\"https://zh.wikipedia.org/wiki/Bash\" rel=\"noopener nofollow\" target=\"_blank\">Bash</a>、<a href=\"https://zh.wikipedia.org/wiki/Korn_shell\" rel=\"noopener nofollow\" target=\"_blank\">ksh</a> 及 <a href=\"https://zh.wikipedia.org/wiki/Tcsh\" rel=\"noopener nofollow\" target=\"_blank\">tcsh</a> 的某些功能。</p>\n<p>2019 年，由于新版本的 Bash v5 将开源授权改成了 GPLv3 协议，而 Apple 公司一贯避免在系统组件中引入 GPLv3 软件。于是自从那时起，macOS 系统上的预置 Shell 就已从 Bash 改为了 Zsh。另外，<a href=\"https://zh.wikipedia.org/wiki/Kali_Linux\" rel=\"noopener nofollow\" target=\"_blank\">Kali Linux</a> 也使用 Zsh 作为预置 Shell。其主要特性包括：</p>\n<ul>\n<li>提供可编程的命令行补全功能，该功能可帮助用户键入常用命令选项及参数；</li>\n<li>提供可编程的命令行界面，包括将提示行信息显示在屏幕右侧，以及自动隐藏过长指令等功能；</li>\n<li>提供可与任意 Shell 共享的命令行历史记录；</li>\n<li>可在不借助外部程序的情况下实现文件的查找；</li>\n<li>改进了针对变量/数组的处理方式；</li>\n<li>允许在单缓冲区内编辑多行命令；</li>\n<li>支持针对命令的拼写检查；</li>\n<li>支持多种兼容模式（例如，Zsh 可在运行为<code>/bin/sh</code>的情况下伪装成 Bourne shell）</li>\n<li>支持以加载模块的方式引入额外的功能，包括支持 Unix 域套接字控制、FTP 客户端等；</li>\n<li>提供有<code>where</code>命令，该命令的使用方法与<code>which</code>命令类似，但返回的是指定指令在<code>$PATH</code>中的全部位置，而不是它当前最优先匹配的位置；</li>\n<li>允许用户为指定目录设置别名，例如，用户可以为<code>/usr/bin</code>设置别名<code>/u</code>，这样在输入<code>/u</code>时，Zsh 会自动将其替换为<code>/usr/bin</code>；</li>\n</ul>\n<h2 id=\"安装步骤\">安装步骤</h2>\n<p>在安装之前，我希望读者确定自己是在类 UNIX 系统下，因为 Zsh 是在类 UNIX 系统下运行的 Shell 程序，如果您使用的是 Windows 系统，推荐使用 Windows Subsystem for Linux（WSL）。下面书归正传，Zsh 在每个操作系统中的安装方式并不完全相同，下面是其在几种常见 Linux/UNIX 系统下的安装命令：</p>\n<pre><code class=\"language-bash\"># macOS 系统下的安装命令：\nbrew install zsh\n\n# ubuntu/debian 系统下的安装命令：\nsudo apt install zsh\n\n# CentOS 系统下的安装命令：\nsudo yum install zsh\n\n# ArchLinux/Manjaro 系统下的安装命令：\nsudo pacman -S zsh\n</code></pre>\n<p>如果您使用的是上述操作系统之一，在执行完相应的安装命令之后，就可以使用<code>cat /etc/shells</code>命令查看当前系统可以用的 Shell 了。然后，只要在该命令返回的结果中看到<code>/bin/zsh</code>，就说明 Zsh 已经安装好了，如图 1 所示。</p>\n\n<p><img alt=\"图 1：当前可用的 Shell\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：当前可用的 Shell</p>\n<p>接下来，我们可以使用<code>chsh -s /bin/zsh</code>命令将 Zsh 设置为系统默认 Shell 了。如果到目前为止的操作一切顺利，现在只需要重新启动一个 Shell 会话（通常是一个命令行终端窗口），就会看到 Zsh 的初始配置了，如图 2 所示。</p>\n\n<p><img alt=\"图 2：Zsh 的配置引导界面\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：Zsh 的配置引导界面</p>\n<p>在上述界面中，如果我们输入<code>q</code>会直接退出配置引导，下一次运行 zsh 时会再次进入配置引导。如果输入<code>0</code>，也会退出配置引导，但是会在当前用户目录生成一个空白的文件<code>.zshrc</code>（路径为<code>~/.zshrc</code>），并且不会再进入配置引导界面。换言之，Zsh 会不会在启动时进入配置引导界面取决于当前用户目录下是否存在<code>.zshrc</code>文件，该文件是 Zsh 的默认配置文件，人们可以使用 vim 编辑器打开它并进行源码级别的手动配置。而如果我们在这里输入<code>1</code>，就会开始进行一系列自定义的配置。但通常情况下，考虑到<code>.zshrc</code>文件中各项配置的复杂性，我们在这里并不推荐读者直接进行手动配置，使用 Oh-My-Zsh 来进行配置会是更好的选择。</p>\n<h2 id=\"oh-my-zsh\">Oh-My-Zsh</h2>\n<p>Oh-My-Zsh 是一款 Zsh 的配置管理工具，它提供了丰富的主题和插件，可以极大地美化命令行界面，并提高工作效率。我们需要这项工具的原因在于：原生的 Zsh 虽然很强大，但存在着以下几个配置成本方面的问题：</p>\n<ul>\n<li>稍复杂的配置就需要使用编码的方式修改<code>.zshrc</code>文件；</li>\n<li>命令的自动补全和提示需要手动调教；</li>\n<li>引入第三方主题与插件的相关配置就更为复杂了。</li>\n</ul>\n<p>而 Oh-My-Zsh 的作用就是把这些复杂的配置一次性打包好，确保开箱即用，它相对于 Bash、原生 Zsh 的优势如表 1 所示：</p>\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th>Bash</th>\n<th>原生 Zsh</th>\n<th>Oh My Zsh</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>自动补全</td>\n<td>基础</td>\n<td>强</td>\n<td><strong>非常强</strong></td>\n</tr>\n<tr>\n<td>配置难度</td>\n<td>低</td>\n<td>高</td>\n<td><strong>低</strong></td>\n</tr>\n<tr>\n<td>插件系统</td>\n<td>无</td>\n<td>无</td>\n<td><strong>有</strong></td>\n</tr>\n<tr>\n<td>主题</td>\n<td>基本无</td>\n<td>有</td>\n<td><strong>大量现成</strong></td>\n</tr>\n<tr>\n<td>上手速度</td>\n<td>快</td>\n<td>慢</td>\n<td><strong>最快</strong></td>\n</tr>\n</tbody>\n</table>\n<p><strong>表 1</strong>：Bash、原生 Zsh 与 Oh My Zsh 的对比</p>\n<p>在了解 Oh-My-Zsh 的基本信息以及所能发挥的功能之后，我们现在就来演示一下它的安装步骤：</p>\n<ul>\n<li>\n<p>在安装 Oh-My-Zsh 之前，需要确保本地已经安装了 Git，关于 Git 的安装与配置步骤，读者可参考我在《[[Git 使用笔记]]》中的记录；</p>\n</li>\n<li>\n<p>打开 Zsh 终端窗口，并在用户目录下使用 curl 或 wget 命令下载 Oh-My-Zsh 的安装脚本，并执行它：</p>\n<pre><code class=\"language-bash\"># 使用 curl 下载脚本并安装：\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\n# 使用 wget 下载脚本并安装：\nsh -c \"$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)\"\n</code></pre>\n</li>\n<li>\n<p>在执行上述命令过程中，我们需要同意 Oh-My-Zsh 使用自身的配置模板覆盖已有的<code>.zshrc</code>文件，如图 3 所示（由于我已完成配置，不便截图，此处引用来自<a href=\"https://www.haoyep.com/posts/zsh-config-oh-my-zsh/\" rel=\"noopener nofollow\" target=\"_blank\">网络的截图</a>）：</p>\n  \n<p><img alt=\"图 3：Oh-My-Zsh 的安装界面\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：Oh-My-Zsh 的安装过程</p>\n</li>\n</ul>\n<p>待安装顺利完成之后，用户的<code>home</code>目录下会出现一个名为<code>.oh-my-zsh</code>的目录，该目录中存储的就是 Oh-My-Zsh 框架本身，及其主题和插件的实现代码。下面，我们从功能插件、外观配置与快捷命令三个方面来介绍基于 Oh-My-Zsh 配置 Zsh 的主要方法。</p>\n<h3 id=\"功能插件\">功能插件</h3>\n<p>Oh-My-Zsh 的核心竞争力主要来自于它所提供的那套极具开放性的，高度可定制的插件系统，这让我们可以根据自己的喜好进行选择和配置，打造一个富有个性的命令行终端界面。下面是我个人常用的一些插件及其相关介绍：</p>\n<table>\n<thead>\n<tr>\n<th>插件</th>\n<th>功能</th>\n<th>使用说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>z</code></td>\n<td>可实现智能目录跳转。</td>\n<td><code>z &lt;目录名&gt;</code> （该目录需历史记录中出现过）</td>\n</tr>\n<tr>\n<td><code>git</code></td>\n<td>可用<code>ga</code>、<code>gc</code>等快捷命令。</td>\n<td><code>gc -m \"commit message\"</code></td>\n</tr>\n<tr>\n<td><code>extract</code></td>\n<td>提供<code>x</code>压缩包解压命令。</td>\n<td><code>x file_name.tar.gz</code></td>\n</tr>\n<tr>\n<td><code>web-search</code></td>\n<td>可实现网页搜索。</td>\n<td><code>google &lt;搜索内容&gt;</code>或<code>baidu &lt;搜索内容&gt;</code></td>\n</tr>\n<tr>\n<td><code>you-should-use</code></td>\n<td>命令行错误提示功能。</td>\n<td>在命令输入错误时，会给出正确的命令提示。</td>\n</tr>\n<tr>\n<td><code>zsh-completions</code></td>\n<td>命令行自动补齐功能。</td>\n<td>在输入命令时按<code>Tab</code>键会自动补齐。</td>\n</tr>\n<tr>\n<td><code>zsh-autosuggestions</code></td>\n<td>命令行自动提示功能。</td>\n<td>在输入命令时会自动给出提示。</td>\n</tr>\n<tr>\n<td><code>zsh-syntax-highlighting</code></td>\n<td>命令行语法高亮功能。</td>\n<td>在输入命令时会根据语法高亮。</td>\n</tr>\n</tbody>\n</table>\n<p>在 Oh-My-Zsh 中安装和启用插件通常可按照以下三个步骤来进行（如果是自带插件，则可跳过第一步）：</p>\n<ol>\n<li>\n<p>如果我们要启用的不是 Oh-My-Zsh 的内置插件，那该插件通常会在 Github 上有独立的仓库，人们需要先使用<code>git clone</code>命令将其下载到 Oh-My-Zsh 安装目录下的<code>custom/plugins</code>目录中（而内置插件则已存在于 Oh-My-Zsh 安装目录下的<code>plugins</code>目录中，无需下载），例如，我们现在要启用的是<code>zsh-autosuggestions</code>插件，这是一个第三方插件，这就需要先执行以下命令，将其下载到 Oh-My-Zsh 安装目录下的<code>custom/plugins</code>目录中：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions\n</code></pre>\n</li>\n<li>\n<p>使用 vim 这样的文本编辑器打开<code>.zshrc</code>文件，并在其中找到<code>plugins</code>字段，并将要启用的插件名称添加到该字段中（该字段的值是一个用空白符分隔的字符串），例如，如果我们现在要启用的插件包括<code>z</code>、<code>git</code>、<code>extract</code>、<code>web-search</code>、<code>you-should-use</code>、<code>zsh-completions</code>、<code>zsh-autosuggestions</code>、<code>zsh-syntax-highlighting</code>，那么<code>.zshrc</code>文件中<code>plugins</code>字段的值就该被设置如下：</p>\n<pre><code class=\"language-bash\">plugins=(\n    z \n    git\n    extract\n    web-search\n    you-should-use \n    zsh-completions \n    zsh-autosuggestions \n    zsh-syntax-highlighting \n    zsh-history-substring-search\n)\n</code></pre>\n</li>\n<li>\n<p>保存并关闭<code>.zshrc</code>文件，然后执行<code>source ~/.zshrc</code>或<code>omz reload</code>命令使配置生效。例如，图 4 所示的是启用<code>extract</code>插件之后，使用<code>x</code>命令解压文件的效果：</p>\n \n<p><img alt=\"图 4：extract 插件的效果\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：extract 插件的效果</p>\n</li>\n</ol>\n<h3 id=\"外观配置\">外观配置</h3>\n<p>在 Oh-My-Zsh 中，我们可以通过一种被称之为“主题”的特殊插件来配置 Zsh 界面所呈现的外观，目的是通过各种特定的颜色和提示信息让命令行界面的易用性和美观性达到一个平衡。Oh-My-Zsh 内置了大量的主题，它们都被存放在 Oh-My-Zsh 安装目录下的<code>themes</code>目录中（也可以前往 <a href=\"https://github.com/ohmyzsh/ohmyzsh/wiki/Themes\" rel=\"noopener nofollow\" target=\"_blank\">Oh-My-Zsh 官方文档</a>查看），如图 5 所示：</p>\n\n<p><img alt=\"图 5：Oh-My-Zsh 内置的主题\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：Oh-My-Zsh 内置的主题</p>\n<p>如果我们想启用上述任意一个 Oh-My-Zsh 的内置主题，就只需将<code>.zshrc</code>文件中的<code>ZSH_THEME</code>变量值修改为该主题的名称即可，例如，假设现在要启用的是<code>agnoster</code>主题，我们就只需要执行以下步骤：</p>\n<ul>\n<li>\n<p>先使用 vim 这样的文本编辑器打开<code>.zshrc</code>文件；</p>\n</li>\n<li>\n<p>找到<code>ZSH_THEME</code>变量，并将它的值设置如下即可：</p>\n<pre><code class=\"language-bash\">ZSH_THEME=\"agnoster\" # 默认主题为 robbyrussell\n</code></pre>\n</li>\n<li>\n<p>保存并关闭<code>.zshrc</code>文件，然后执行<code>source ~/.zshrc</code>命令使配置生效，其效果如图 6 所示：</p>\n  \n<p><img alt=\"图 6：agnoster 主题的效果\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：agnoster 主题的效果</p>\n</li>\n</ul>\n<p>当然，除了上述内置主题之外，我们还可以选择安装其他开源的主题，例如，<a href=\"https://github.com/romkatv/powerlevel10k\" rel=\"noopener nofollow\" target=\"_blank\">powerlevel10k</a>就是一个非常受欢迎的，功能强大的主题，它提供了丰富的配置选项，可以让我们打造出各种个性化的命令行界面，其安装与配置步骤如下：</p>\n<ol>\n<li>\n<p>使用<code>git clone</code>命令将主题下载到 Oh-My-Zsh 安装目录下的<code>custom/themes</code>目录中：</p>\n<pre><code class=\"language-bash\">git clone --depth=1 https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k\n</code></pre>\n</li>\n<li>\n<p>使用 vim 这样的文本编辑器打开<code>.zshrc</code>文件，并在其中找到<code>ZSH_THEME</code>变量，并将它的值设置为我们刚刚下载的主题名称即可：</p>\n<pre><code class=\"language-bash\">ZSH_THEME=\"powerlevel10k/powerlevel10k\"\n</code></pre>\n</li>\n<li>\n<p>保存并关闭<code>.zshrc</code>文件，然后执行<code>source ~/.zshrc</code>或<code>omz reload</code>命令使配置生效。在该主题配置首次生效时会启动一个配置向导（之后也可以通过执行<code>p10k configure</code>命令来启动该向导），引导我们完成主题的配置，如图 7 所示：</p>\n \n<p><img alt=\"图 7：powerlevel10k 主题的配置向导\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：powerlevel10k 主题的配置向导</p>\n</li>\n<li>\n<p>接下来，我们只需要根据上述配置向导的提示，按照自己的喜欢一步一步地做出选择，就可以完成主题的配置，我个人的配置效果如图 8 所示：</p>\n \n<p><img alt=\"图 8：powerlevel10k 主题的配置效果\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：powerlevel10k 主题的配置效果</p>\n</li>\n</ol>\n<h3 id=\"快捷命令\">快捷命令</h3>\n<p>对于类似于进入某个特定工作目录的常用命令，Zsh 提供了一种被称为 alias 的机制，让我们可以为其设置一个快捷命令。例如，<code>~/working/notes</code>目录是我们每次写笔记时要打开的目录，如果我们想使用 Zsh 的 alias 机制为<code>cd ~/working/notes</code>命令设置一个快捷命令，就可以使用 vim 编辑器打开在<code>.zshrc</code>文件，并在其中恰当的位置上添加如下配置：</p>\n<pre><code class=\"language-bash\">alias cd-notes=\"cd ~/working/notes\"\n</code></pre>\n<p>配置完成后，我们就可以使用<code>cd-notes</code>这个快捷命令命令来执行进入<code>~/working/notes</code>目录了。当然，除了手动配置的 Zsh alias 之外，在安装了Oh-My-Zsh 之后，我们还可以使用该框架所内置的一系列常用的 alias。例如在启用了<code>git</code>插件之后，我们就可以使用它提供的 alias 来执行 git 相关操作了，具体命令列表可查阅 Oh-My-Zsh 官方提供的 <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git\" rel=\"noopener nofollow\" target=\"_blank\">git 插件文档</a>。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-01-06 20:01</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">26</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "C# 不依赖 OpenCV 的图像处理算法：滤波、锐化与边缘检测",
      "link": "https://www.cnblogs.com/1312mn/p/19444713",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/1312mn/p/19444713\" id=\"cb_post_title_url\" title=\"发布于 2026-01-06 14:28\">\n    <span>C# 不依赖 OpenCV 的图像处理算法：滤波、锐化与边缘检测</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>数字图像处理作为计算机视觉和多媒体技术的基础内容，其核心不仅在于理解算法原理，更在于动手实现与验证。为了深入掌握本项目选择从底层像素级别出发，使用C#语言手动实现各类经典图像处理算法，避免依赖现成的高级图像库。</p>\n<p>这种\"从零开始\"的方式虽然开发成本较高，却能真正厘清每个操作背后的数学逻辑与工程细节，也为后续学习更复杂的视觉任务打下坚实基础。</p>\n<h2 id=\"项目介绍\">项目介绍</h2>\n<p>项目是一个基于.NET 平台开发的桌面级数字图像处理工具，在通过图形化界面直观展示多种图像处理算法的效果。</p>\n<p>整个系统围绕System.Drawing.Bitmap类开发，直接操作像素数据完成各类变换，涵盖几何操作、灰度调整、噪声模拟、滤波去噪、边缘检测、图像分割等多个模块。</p>\n<p>项目代码结构清晰，功能完整，既可用于学习参考，也适合作为开发项目。</p>\n<h2 id=\"项目功能\">项目功能</h2>\n<p>1、支持图像的打开、保存及基本信息显示（如尺寸、颜色深度等）</p>\n<p>2、提供灰度化转换与灰度直方图可视化功能</p>\n<p>3、实现基本几何变换：旋转、放大、缩小、错切</p>\n<p>4、支持线性灰度变换与直方图均衡化以增强图像对比度</p>\n<p>5、可添加高斯噪声与椒盐噪声，并配套多种去噪滤波器</p>\n<p>6、集成多种边缘检测算子：Roberts、Sobel、Laplacian、LoG、Wallis、双向梯度等</p>\n<p>7、提供二值化处理及迭代阈值分割方法</p>\n<p>8、包含二值图像后处理功能，如孤立点去除、轮廓提取、区域测量等</p>\n<p>9、实现选择式掩膜滤波（LSMF）与KNN平滑滤波等进阶去噪策略<br />\n10、内置完整的撤销（Undo）与重做（Redo）机制，便于操作回溯与效果对比</p>\n<h2 id=\"项目特点\">项目特点</h2>\n<p>1、坚持从像素级别手动实现算法，不依赖OpenCV等封装库，强化原理理解</p>\n<p>2、界面采用WPF构建，交互友好，参数输入动态生成，操作流程清晰</p>\n<p>3、所有处理操作均可逆，支持多步历史记录，提升实验灵活性</p>\n<p>4、代码模块化程度高，每个功能对应独立方法，便于阅读与扩展<br />\n5、兼顾实用性，既能验证理论，也能处理真实图像任务</p>\n<h2 id=\"项目技术\">项目技术</h2>\n<table>\n<thead>\n<tr>\n<th>技术类别</th>\n<th>具体说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>开发语言</td>\n<td>C#</td>\n</tr>\n<tr>\n<td>运行平台</td>\n<td>.NET Framework（使用 <code>System.Drawing.Bitmap</code> 处理位图）</td>\n</tr>\n<tr>\n<td>UI 框架</td>\n<td>WPF（Windows Presentation Foundation）</td>\n</tr>\n<tr>\n<td>图像数据访问</td>\n<td>通过 <code>Bitmap.GetPixel</code> / <code>SetPixel</code> 及 <code>HBITMAP</code> 指针与 WPF <code>Image</code> 控件对接</td>\n</tr>\n<tr>\n<td>关键算法实现</td>\n<td>双线性插值（用于缩放/旋转）、卷积核运算（用于滤波与边缘检测）、直方图统计、噪声模型模拟等</td>\n</tr>\n<tr>\n<td>辅助技术</td>\n<td>使用 <code>Operation</code> 类封装操作历史，支持 Undo/Redo；通过 Interop 调用 Win32 API 实现位图转换</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"项目代码\">项目代码</h2>\n<h3 id=\"为图片添加高斯噪声\">为图片添加高斯噪声</h3>\n<pre><code class=\"language-csharp\">/// &lt;summary&gt;\n/// 为图片添加高斯噪声\n/// &lt;/summary&gt;\nprivate void GaussNoise(int k)\n{\n    Random ran = new Random(GetRandomSeed());\n    Bitmap bmp_ = new Bitmap(bmp.Width, bmp.Height);\n    for (int i = 0; i &lt; bmp.Width; i++)\n    {\n        for (int j = 0; j &lt; bmp.Height; j++)\n        {\n            double r1 = ran.NextDouble();\n            double r2 = ran.NextDouble();\n            double result = Math.Sqrt((-2) * Math.Log(r2)) * Math.Sin(2 * Math.PI * r1);\n            result *= k;\n            Color c = bmp.GetPixel(i, j);\n\n            int rr = (int)(c.R + result),\n                gg = (int)(c.G + result),\n                bb = (int)(c.B + result);\n            if (rr &gt; 255) rr = 255;\n            else if (rr &lt; 0) rr = 0;\n            if (gg &gt; 255) gg = 255;\n            else if (gg &lt; 0) gg = 0;\n            if (bb &gt; 255) bb = 255;\n            else if (bb &lt; 0) bb = 0;\n            bmp_.SetPixel(i, j, Color.FromArgb(c.A, rr, gg, bb));\n        }\n    }\n    UpdateImg(ref bmp_);\n}\n</code></pre>\n<h3 id=\"为图片添加椒盐噪声\">为图片添加椒盐噪声</h3>\n<pre><code class=\"language-csharp\">/// &lt;summary&gt;\n/// 为图片添加椒盐噪声\n/// &lt;/summary&gt;\n/// &lt;param name=\"SNR\"&gt;信噪比&lt;/param&gt;\n/// &lt;param name=\"pa\"&gt;图片为暗点的概率&lt;/param&gt;\nprivate void SaltNoise(double SNR, double pa)\n{\n    // 噪声点的数量\n    int NP = (int)(bmp.Width * bmp.Height * (1 - SNR));\n    Bitmap bmp_ = new Bitmap(bmp);\n    Random rand = new Random();\n    for (int i = 0; i &lt; NP; i++)\n    {\n        int r = rand.Next(0, bmp.Height), c = rand.Next(0, bmp.Width);\n        double prob = rand.NextDouble();\n        if (prob &gt; pa)\n        {\n            bmp_.SetPixel(c, r, Color.FromArgb(255, 255, 255));\n        }\n        else\n        {\n            bmp_.SetPixel(c, r, Color.FromArgb(0, 0, 0));\n        }\n    }\n    UpdateImg(ref bmp_);\n}\n</code></pre>\n<h2 id=\"项目效果\">项目效果</h2>\n<p>项目运行稳定，能够准确还原各类经典图像处理算法的预期效果。例如，在对自然图像进行灰度化后，直方图均衡化显著提升了整体对比度；添加椒盐噪声后，中值滤波有效抑制了噪点而保留边缘；使用Sobel或LoG算子可清晰提取物体轮廓。</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/576536/202601/576536-20260105210103962-1763205682.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"50%\" /></p>\n<p><img src=\"https://img2024.cnblogs.com/blog/576536/202601/576536-20260105210118061-1765878502.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"50%\" /></p>\n<p><img src=\"https://img2024.cnblogs.com/blog/576536/202601/576536-20260105210140975-938016934.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"50%\" /></p>\n<p><img src=\"https://img2024.cnblogs.com/blog/576536/202601/576536-20260105210152223-942589643.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"50%\" /></p>\n<h2 id=\"总结\">总结</h2>\n<p>项目不仅是一次视觉的学习，更是一场对数字图像处理知识体系的深度实践。通过亲手编写每一个像素操作，可以穿透API的黑箱，真正理解\"图像\"在计算机中的表示方式以及各类变换的本质。这种自底向上的学习路径，虽略显笨拙，却最为扎实。对于希望夯实图像处理基础的大家而言，这个项目无疑是不错的参考。</p>\n<h2 id=\"关键词\">关键词</h2>\n<p>数字图像处理、C#、像素操作、几何变换、灰度变换、噪声抑制、边缘检测、图像分割、WPF、直方图均衡化</p>\n<h2 id=\"最后\">最后</h2>\n<p>如果你觉得这篇文章对你有帮助，不妨点个赞支持一下！你的支持是我继续分享知识的动力。如果有任何疑问或需要进一步的帮助，欢迎随时留言。</p>\n<p>也可以加入微信公众号[DotNet技术匠] 社区，与其他热爱技术的同行一起交流心得，共同成长！</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/576536/202505/576536-20250527195524293-1794896295.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"50%\" /></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-06 14:28</span>&nbsp;\n<a href=\"https://www.cnblogs.com/1312mn\">小码编匠</a>&nbsp;\n阅读(<span id=\"post_view_count\">326</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "为什么说 IO 操作异步才有意义",
      "link": "https://www.cnblogs.com/kklldog/p/19449864",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kklldog/p/19449864\" id=\"cb_post_title_url\" title=\"发布于 2026-01-07 01:32\">\n    <span>为什么说 IO 操作异步才有意义</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>为什么说 IO 操作异步才有意义，CPU 密集操作异步没有意义</p>\n<h2 id=\"背景与问题\">背景与问题</h2>\n<p>在后端开发中，我们经常讨论异步编程模型，尤其是在 Node.js、Netty 等技术栈中。一个普遍的共识是：异步对于 IO 操作 效果显著，而对于 CPU 密集型操作 却意义不大，甚至可能起反作用。这背后的原因是什么？</p>\n<p>本文的目标就是深入计算机的底层运行机制，从根本上解释清楚这两类操作的本质区别，从而阐明异步的真正价值所在。</p>\n<hr />\n<h2 id=\"核心原理与类比\">核心原理与类比</h2>\n<p>要理解这个问题的核心，关键在于回答一个问题：在执行任务时，CPU 到底是在“等别人干活”，还是在“自己亲自干活”？</p>\n<h3 id=\"核心逻辑谁在干活一个餐厅的比喻\">核心逻辑：谁在干活？一个餐厅的比喻</h3>\n<p>我们可以用一个简单的餐厅模型来直观地理解。</p>\n<h3 id=\"io-操作异步最有用的场景\">IO 操作（异步最有用的场景）</h3>\n<ol>\n<li>场景定义: 典型的 IO 操作包括读取文件、请求数据库、访问网络接口等。</li>\n<li>核心特征: IO 操作的核心特征是 CPU 在大部分时间里都在“等”。对于 CPU 而言，这些操作极慢。CPU 执行指令的速度是纳秒级 (ns)，而一次网络或磁盘 IO 的耗时是毫秒级 (ms)，两者相差数个数量级。</li>\n</ol>\n<h3 id=\"微波炉比喻\">微波炉比喻:</h3>\n<ul>\n<li>这个过程好比你（CPU）在餐厅后厨用微波炉热饭（执行 IO 操作）。真正干活的是微波炉（硬盘/网卡）。巨大的速度差异意味着，你按一下微波炉的开关（发送 IO 请求），然后微波炉可能需要转很长时间才能把饭热好。</li>\n<li>同步模式：你按下微波炉的开关，然后像个雕像一样站在它面前干等，直到饭热好。在这期间，你什么别的事也做不了，这极大地浪费了 CPU 资源。</li>\n<li>异步模式：你按下开关，定个闹钟（设置回调），然后就立刻转身去切菜、打扫卫生。等微波炉“叮”的一声（中断通知），你再回来处理热好的饭。这种模式极大地提升了 CPU 利用率。</li>\n</ul>\n<h3 id=\"结论\">结论</h3>\n<p>IO 操作适合异步，因为工作主要由外部设备完成，CPU 本身处于闲置状态。异步编程模型可以有效利用这段宝贵的闲置时间去处理其他任务。</p>\n<h3 id=\"cpu-密集操作异步意义不大\">CPU 密集操作（异步意义不大）</h3>\n<p>场景定义: 典型的 CPU 密集型操作包括视频转码、数据加密解密、复杂的数学计算、训练神经网络等。</p>\n<h3 id=\"做酸辣土豆丝比喻\">做酸辣土豆丝比喻:</h3>\n<ul>\n<li>这个过程好比小红想要(CPU main thread)做一盘酸辣土豆丝（CPU 密集操作）。</li>\n<li>在这种场景下强行“异步”，行为就变成了：小红呼叫小明（CPU another thread）来替她切土豆，她跑去擦桌子,等小明切好土豆丝了，小红再回来继续起油锅烧土豆丝。</li>\n<li>这种行为的后果是，切土豆丝的总工作量一点没少，反而因为小红在土豆丝切好后再次接管烧菜这件事而引入了额外的“上下文切换开销”，导致整体效率变得更低。</li>\n<li>可能有同学不理解，觉得这个没问题啊，小红明明空出来了啊，去做别的事情了啊，这不是效率提高了吗？真的是这样吗？小红不呼叫小明切土豆，那小明这时候也是空闲的啊。小明直接去擦桌子，小红直接切土豆丝然后烧土豆丝，这个过程才是效率最高的。</li>\n</ul>\n<h3 id=\"结论-1\">结论</h3>\n<p>CPU 密集型任务不适合异步，因为调度其他线程来完成 CPU 密集操作的效率不如当前线程直接计算高。强行切换任务只会带来不必要的开销。</p>\n<h2 id=\"深入技术视角计算机如何处理任务\">深入技术视角：计算机如何处理任务</h2>\n<p>从更技术的层面来看，这两种场景的底层机制差异巨大。</p>\n<h3 id=\"io-密集型dma-的功劳\">IO 密集型：DMA 的功劳</h3>\n<p>CPU 在执行 IO 操作时之所以可以“脱身”，关键在于 DMA（直接存储器访问） 机制。</p>\n<p>当我们的代码执行一个 IO 请求（例如 Node.js 中的 fs.readFile()）时，CPU 实际上只是向磁盘控制器下达一个指令：“把这个文件的数据读到内存的这个位置，完成后通知我。”</p>\n<p>指令下达后，CPU 就立刻被释放，可以去处理其他任务了。真正的数据拷贝工作由 DMA 控制器全权负责，它会在磁盘和内存之间直接搬运数据，整个过程不需要占用 CPU。工作完成后，DMA 会通过一个中断信号通知 CPU。</p>\n<p>因此，这个过程可以精炼地总结为：异步 IO = CPU 外包工作 + 中断通知。</p>\n<h3 id=\"cpu-密集型线程的竞争\">CPU 密集型：线程的竞争</h3>\n<p>对于 CPU 密集型任务，情况完全不同。这类任务需要持续占用 CPU 的核心计算资源，例如 ALU（算术逻辑单元） 和寄存器。</p>\n<ul>\n<li>单线程阻塞: 在一个单线程环境（如 Node.js 主线程）中执行一个耗时很长的计算任务，会导致整个程序假死。因为 CPU 全力在计算，根本无暇响应任何其他事件（如网络请求、用户点击）。</li>\n<li>多线程开销: 在多线程环境中，如果大量并发的 CPU 密集型任务在少数几个 CPU 核心上运行，会导致 CPU 频繁进行上下文切换 (Context Switch)。操作系统需要不断地保存当前线程的运行状态（例如寄存器里的值、程序计数器等），再加载下一个线程的状态。这个“保存现场”和“恢复现场”的过程本身就会消耗大量 CPU 资源，导致实际用于计算的时间减少。</li>\n</ul>\n<h2 id=\"特殊情况何时-cpu-操作需要异步\">特殊情况：何时 CPU 操作需要“异步”？</h2>\n<p>虽然 CPU 密集型操作通过异步无法提高整体吞吐量，但在一种特殊场景下，这种“异步”是有意义的。</p>\n<ol>\n<li>核心目的: 此时，异步的目的不再是提升效率，而是为了保持响应性 (Responsiveness)。</li>\n<li>场景举例: 最典型的就是 GUI 界面，例如浏览器。假设你在网页中用 JavaScript 执行一个大规模的同步计算，UI 渲染线程会被完全阻塞，导致页面卡死，用户无法进行任何操作。</li>\n<li>解决方案: 我们可以通过 Web Worker 将计算任务放到一个独立的线程中，或者使用 setTimeout 将大任务拆分成许多小块分片执行。</li>\n<li>本质分析: 这种“异步化”处理并没有减少总的计算时间（甚至可能因为切换开销而变慢），但它的核心价值在于避免主线程被堵塞，从而保证了界面的流畅和用户的交互体验。</li>\n</ol>\n<hr />\n<h2 id=\"总结与延伸\">总结与延伸</h2>\n<p>通过以上的分析，我们可以清晰地看到 IO 密集型和 CPU 密集型任务在本质上的区别，以及异步模型适用性的根源。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">IO 密集型 (IO-Bound)</th>\n<th style=\"text-align: left;\">CPU 密集型 (CPU-Bound)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>主要瓶颈</strong></td>\n<td style=\"text-align: left;\">网络、硬盘、数据库</td>\n<td style=\"text-align: left;\">CPU 计算能力</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>CPU 状态</strong></td>\n<td style=\"text-align: left;\">大部分时间在等待</td>\n<td style=\"text-align: left;\">大部分时间在全速运转</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>异步的价值</strong></td>\n<td style=\"text-align: left;\">极高。利用等待时间处理其他并发请求（高并发的核心）。</td>\n<td style=\"text-align: left;\">低。切换其他线程来代替当前线程计算不会有性能提升，只要开销</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>典型例子</strong></td>\n<td style=\"text-align: left;\">Web 服务器接口、文件上传下载</td>\n<td style=\"text-align: left;\">视频压缩、区块链挖矿、图像渲染</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>最佳策略</strong></td>\n<td style=\"text-align: left;\">异步非阻塞 (Async/Await, Reactive)</td>\n<td style=\"text-align: left;\">多进程、多线程并行 (Parallelism)</td>\n</tr>\n</tbody>\n</table>\n<p>一句话总结：</p>\n<p>异步是为了填补 CPU 的空窗期。IO 操作有巨大的空窗期，所以异步有意义；CPU 密集操作切换其他线程来代替当前线程计算不会有性能提升，只要开销。</p>\n<h2 id=\"关注我的公众号一起玩转技术\">关注我的公众号一起玩转技术</h2>\n<p><img alt=\"\" src=\"https://static.xbaby.xyz/qrcode.jpg\" /></p>\n\n</div>\n<div id=\"MySignature\">\n    <div id=\"AllanboltSignature\">        \n<p id=\"PSignature\">       \nQQ群：1022985150 VX：kklldog 一起探讨学习.NET技术\n<br />\n作者：<a href=\"http://www.cnblogs.com/kklldog\" target=\"_blank\">Agile.Zhou(kklldog)</a>            \n<br /> \n出处：<a href=\"http://www.cnblogs.com/kklldog/\" target=\"_blank\">http://www.cnblogs.com/kklldog/</a>\n<br />本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。\n </p>  \n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-07 01:32</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kklldog\">Agile.Zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}