{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第二周：词嵌入 课后习题与代码实践",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19540925",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19540925\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 23:25\">\n    <span>吴恩达深度学习课程五：自然语言处理  第二周：词嵌入 课后习题与代码实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课第二周的课后习题和代码实践部分。</p>\n<hr />\n<h1 id=\"1-理论习题\">1. 理论习题</h1>\n<p><a href=\"https://blog.csdn.net/u013733326/article/details/83089164\" rel=\"noopener nofollow\" target=\"_blank\">【中英】【吴恩达课后测验】Course 5 -序列模型 - 第二周测验 </a><br />\n本周习题同样较为简单，就不再展开了。</p>\n<h1 id=\"2-代码实践\">2. 代码实践</h1>\n<p><a href=\"https://blog.csdn.net/u013733326/article/details/83341643\" rel=\"noopener nofollow\" target=\"_blank\">词向量与Emoji生成器-CSDN博客</a><br />\n在本周的编程作业里，链接里的博主除了编码演示关于词向量的一些基本应用外，主要是实现了一个表情生成器。<br />\n其原理是通过文本和相应的表情标签进行监督学习，构建分类模型，在完成训练后，通过对模型输出的下游加工，可以实现“输入文本，输出配有表情的文本”的效果。感兴趣可以进入了解。</p>\n<p>同样，我们还是使用成熟框架来演示本周的内容，得益于 PyTorch 对基础模块的封装非常完善，我们可以较简洁地完成本周内容的演示，主要内容列举如下：</p>\n<ol>\n<li><strong>如何在代码中使用词嵌入？</strong></li>\n<li><strong>使用词向量取代独热编码对命名实体识别模型性能的影响。</strong></li>\n<li><strong>使用词向量进行情绪分类。</strong></li>\n</ol>\n<h2 id=\"21-在pytorch-中使用词嵌入\">2.1 在PyTorch 中使用词嵌入</h2>\n<p>在 PyTorch 调用词嵌入的方法被封装在模型模块中，就像我们调用方法创建全连接层和卷积层一样，现在，我们要做的就是<strong>创建嵌入层</strong>。</p>\n<p>先来单独看看创建嵌入层的方法本身：</p>\n<pre><code class=\"language-python\">self.embedding = nn.Embedding(  \n    num_embeddings=vocab_size,  # 词典大小\n    embedding_dim=embed_dim,    # 词向量维度，既一个词用多少维的向量表示。\n    # 上面这两个参数就划定好了词嵌入矩阵的大小。\n    padding_idx=word_vocab[\"&lt;PAD&gt;\"]  # 获取填充符索引，固定其向量为 0 ，并屏蔽梯度计算。 \n)\n</code></pre>\n<p>这里有一点需要强调，如果你对我们<a href=\"https://www.cnblogs.com/Goblinscholar/p/19484728\" target=\"_blank\">上周的实践内容</a>还有印象，会发现我们其实已经在前面的代码了显式定义了 <code>&lt;PAD&gt;</code> 的索引：</p>\n<pre><code class=\"language-python\">word_vocab[\"&lt;PAD&gt;\"] = 0\n</code></pre>\n<p>也就是说，在方法的参数里，我们可以直接写成：</p>\n<pre><code class=\"language-python\">padding_idx= 0\n</code></pre>\n<p><strong>但是，我们基本不会这么做。</strong><br />\n这其实是代码规范里一个老生常谈的问题：<strong>避免硬编码</strong>。<br />\n在这里，一旦词表构建策略发生调整（例如交换 <code>&lt;PAD&gt;</code> 与 <code>&lt;UNK&gt;</code> 的索引），参数就会被错误使用，<strong>却不会触发任何报错</strong>，最终导致模型在训练过程中学到错误的表示。<br />\n因此，我们在实践中更倾向使用统一的变量，来显式表达语义依赖，避免在调整时引入隐蔽错误。</p>\n<p>回到正题，了解了嵌入层方法本身后，现在就来看看如何将其应用在模型中，先看看我们<strong>上周使用独热编码的模型代码：</strong></p>\n<pre><code class=\"language-python\">class RNNTagger(nn.Module):  \n    def __init__(self, vocab_size, hidden_dim, num_classes,  \n                 rnn_type='RNN', bidirectional=False, num_layers=1):  \n        super().__init__()  \n        self.vocab_size = vocab_size  \n        self.bidirectional = bidirectional  \n        self.rnn_type = rnn_type.upper()  \n  \n        input_size = vocab_size  # 独热编码输入维度 = 词表大小  \n  \n        if self.rnn_type == 'RNN':  \n            self.rnn = nn.RNN(input_size, hidden_dim, batch_first=True,  \n                              bidirectional=bidirectional, num_layers=num_layers)  \n        ......其他模型选择\n        \n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)  \n  \n    def forward(self, x):   \n        x_onehot = torch.nn.functional.one_hot(x, num_classes=self.vocab_size).float() # 传播第一步，将输入从索引转换为独热编码。\n        out, _ = self.rnn(x_onehot)  \n        out = self.fc(out)  \n        return out\n</code></pre>\n<p>而把使用独热编码改为使用词向量的工作量也并不大，我们需要：</p>\n<ol>\n<li><strong>新增参数定义词向量维度。</strong></li>\n<li><strong>创建嵌入层。</strong></li>\n<li><strong>在传播的第一步将索引从转换为独热编码改为输入嵌入层提取词向量。</strong></li>\n</ol>\n<p>更改完的代码如下：</p>\n<pre><code class=\"language-python\">class RNNTagger(nn.Module):  \n    def __init__(self, vocab_size, hidden_dim, num_classes,  \n                 rnn_type='RNN', bidirectional=False, num_layers=1,  \n                 embed_dim=300):  # ← 新增一个嵌入维度参数  \n        super().__init__()  \n        self.bidirectional = bidirectional  \n        self.rnn_type = rnn_type.upper()  \n  \n        # 新增：词嵌入层  \n        self.embedding = nn.Embedding(  \n            num_embeddings=vocab_size,  \n            embedding_dim=embed_dim,  \n            padding_idx=word_vocab[\"&lt;PAD&gt;\"]  \n        )  \n  \n        input_size = embed_dim  # ← RNN 输入改为 embedding 维度  \n  \n        if self.rnn_type == 'RNN':  \n            self.rnn = nn.RNN(input_size, hidden_dim, batch_first=True,  \n                              bidirectional=bidirectional, num_layers=num_layers)  \n        elif self.rnn_type == 'LSTM':  \n            self.rnn = nn.LSTM(input_size, hidden_dim, batch_first=True,  \n                               bidirectional=bidirectional, num_layers=num_layers)  \n        elif self.rnn_type == 'GRU':  \n            self.rnn = nn.GRU(input_size, hidden_dim, batch_first=True,  \n                              bidirectional=bidirectional, num_layers=num_layers)  \n        else:  \n            raise ValueError(\"rnn_type must be 'RNN','LSTM','GRU'\")  \n  \n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)  \n  \n    def forward(self, x):  \n        x_embed = self.embedding(x) #在传播中首先输入嵌入层提取词向量。\n        out, _ = self.rnn(x_embed)  \n        out = self.fc(out)  \n        return out\n</code></pre>\n<p>这样，只需要在模型部分完成改动，我们便可以直接应用上周的代码框架直接进行训练。<br />\n下面就来看看效果：</p>\n<h2 id=\"22-使用词嵌入进行命名实体识别\">2.2 使用词嵌入进行命名实体识别</h2>\n<p>我们先使用<strong>普通的双向 RNN</strong> 来看看效果，多次实验部分结果如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231952652-728374191.png\" /><br />\n可以看出，相比独热编码，虽然在指标上并没有明显的提升，但是使用 300 维的词向量<strong>完成相同的训练，只需要独热编码训练用时的约 65%</strong> ，这种优势会随着词表规模增加而更明显。<br />\n显然，词向量避免了独热编码向量的极高维度且极其稀疏缺陷，这是在计算性能上的极大提升。<br />\n简单打印一些训练后的词向量如下：（只截取了前 20 维）<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231746057-63686229.png\" /><br />\n然后，我们再试试上周综合表现最好的 GRU ，结果如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127232402014-1527482926.png\" /><br />\n训练用时同样得到了极大提升，但是，好像出现问题了：<br />\n<strong>在使用了词嵌入后，明明还增加了训练轮次，但指标反而不如使用独热编码高</strong>，这是为什么？</p>\n<p>实际上，<strong>词嵌入并不天然适用于所有 NLP 任务</strong>。对于实体命名识别这类以<strong>词和标签强对齐</strong>为主的任务，one-hot 表示由于其<strong>完全区分词身份的特性</strong>，反而可能取得更好的效果。<br />\n说简单些，由于<strong>命名实体识别任务更关注“这个词是什么”，而不是“词之间的关系”</strong>，使用完全正交的独热编码反而让界限更明显。<br />\n来简单看个例子：</p>\n<p>假设<strong>在训练语料中</strong>，<code>Apple</code> 大量以 <code>B-ORG</code>（组织）标签出现，而 <code>Google</code>、<code>Microsoft</code> 等词在词嵌入空间中与 <code>Apple</code> 距离很近，这是因为它们共享了“公司”“科技”“产品”等相似上下文。但在具体句子中：</p>\n<ul>\n<li><code>Apple released a new product.</code> → <code>Apple</code> 是 <code>ORG</code>（苹果公司）</li>\n<li><code>I ate an apple after lunch.</code> → <code>apple</code> 是 <code>O</code>（食物苹果）</li>\n</ul>\n<p>对于 NER 来说，关键不是“这个词在语义上像什么”，而是<strong>在当前任务标注体系下，它在这个位置对应什么标签</strong>。<br />\n而词嵌入会引入一种强烈的归纳偏置：<strong>语义相近的词，其表示也应当相近</strong>。当模型的上下文建模能力有限时，这种相似性结构可能被过度利用，使<strong>模型倾向于根据词向量的邻近关系做出判断，而不是严格依赖监督信号本身</strong>，从而在某些语境下产生错误的实体类型预测。</p>\n<p>比如词嵌入会天然鼓励模型<strong>将 <code>Apple</code> 与其他科技公司词拉近</strong>，从而放大“公司语义”的共性，而如果模型设计<strong>对大小写不敏感</strong>，另外的部分语料里又让<strong>水果间的距离更近</strong>，就可能导致 <strong>“香蕉公司”，“菠萝公司”</strong> 等错误识别。<br />\n而在 one-hot 表示下，<code>Apple</code> 的表示与任何其他词完全独立，模型只能依赖监督信号本身去学习它在不同上下文中与标签之间的对应关系，<strong>反而避免了这种误解</strong>。</p>\n<p>总结来说，在不进行进一步上下文建模或结构化约束的情况下，词嵌入由于为<strong>多义词</strong>提供了共享的连续表示，可能在某些任务中引入语义混淆，从而影响模型对具体标签的判别。<br />\n而 one-hot 表示通过其完全正交的设计，显式区分了不同词项的身份，在词—标签强对齐的任务中反而在一定程度上缓解这一问题。</p>\n<p>现在，我们在词嵌入的强项：情绪分类上再来看看其效果：</p>\n<h2 id=\"23-使用词向量进行情绪分类\">2.3 使用词向量进行情绪分类</h2>\n<p>要进行新的任务，自然首先要引入新的数据集，这里我们使用情绪分类中的经典数据集：<strong>IMDb</strong><br />\nIMDb 数据集是一个经典的<strong>二分类</strong>情绪分析任务数据集，它的输入是电影评论文本，输出是情绪标签，<code>0</code> 表示负面（negative），<code>1</code> 表示正面（positive）。<br />\n训练集和测试集各包含 25,000 条评论，评论长度不固定，从几十词到几百词不等，文本中包含标点、大小写、数字等元素。数据类别平衡。比较适合我们的演示。<br />\n同样，我们使用之前介绍过的 HuggingFace Datasets 来下载，完整代码附在最后，这里展示几条样本数据：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231746713-502919155.png\" /><br />\n现在，同样使用 <strong>单层双向 GRU</strong> 来进行实验，设置<strong>词表大小为 20000，批次大小为 32</strong>，部分训练结果如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231746505-1423343285.png\" /><br />\n可以在较少的轮次中，实现较好的拟合。<br />\n而在同等参数下使用独热编码则会爆内存，以我的电脑配置需要将词表缩小到 5000 以下，并将批次大小降至 6，才勉强可以运行且单轮时间较长，这样的配置并不适配一般的使用场景，因此就不再展示独热编码的效果了。</p>\n<p><strong>词向量在计算效率与大词表适应性上拥有极大优势</strong>，可以在保持模型性能的同时，大幅降低显存消耗与训练时间。<br />\n如果你的资源足够，可以进行更多的尝试看看效果。</p>\n<h1 id=\"3-附录\">3. 附录</h1>\n<h2 id=\"31-使用词嵌入进行情绪分类-pytorch版\">3.1 使用词嵌入进行情绪分类 PyTorch版</h2>\n<pre><code class=\"language-python\">import torch  \nimport torch.nn as nn  \nfrom torch.utils.data import DataLoader  \nfrom torch.nn.utils.rnn import pad_sequence  \nfrom datasets import load_dataset  \nfrom collections import Counter  \nfrom sklearn.metrics import accuracy_score, f1_score  \nimport time  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \ndataset = load_dataset(\"mteb/imdb\")  \ntrain_data = dataset['train']  \ntest_data  = dataset['test']  \n   \ndef build_vocab(dataset, max_vocab_size=5000):  \n    counter = Counter()  \n    for item in dataset:  \n        counter.update(item['text'].split())  \n    most_common = counter.most_common(max_vocab_size)  \n    word_vocab = {w:i+2 for i,(w,_) in enumerate(most_common)}  \n    word_vocab[\"&lt;PAD&gt;\"] = 0  \n    word_vocab[\"&lt;UNK&gt;\"] = 1  \n    return word_vocab  \n  \nword_vocab = build_vocab(train_data)  \nvocab_size = len(word_vocab)  \n  \ndef encode(item):  \n    x = torch.tensor([word_vocab.get(w,1) for w in item['text'].split()], dtype=torch.long)  \n    y = torch.tensor(item['label'], dtype=torch.long)  \n    return x, y  \n  \ntrain_dataset = [encode(item) for item in train_data]  \ntest_dataset  = [encode(item) for item in test_data]  \n  \ndef collate_fn(batch):  \n    xs, ys = zip(*batch)  \n    xs_pad = pad_sequence(xs, batch_first=True, padding_value=word_vocab[\"&lt;PAD&gt;\"])  \n    ys = torch.tensor(ys, dtype=torch.long)  \n    return xs_pad.to(device), ys.to(device)  \n  \ntrain_loader = DataLoader(train_dataset, batch_size=6, shuffle=True, collate_fn=collate_fn)  \ntest_loader  = DataLoader(test_dataset, batch_size=6, shuffle=False, collate_fn=collate_fn)  \n  \nclass GRUSentiment(nn.Module):  \n    def __init__(self, vocab_size, hidden_dim, num_classes,  \n                 bidirectional=True, embed_dim=300):  \n        super().__init__()  \n        self.bidirectional = bidirectional  \n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)  \n        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True,  \n                          bidirectional=bidirectional, num_layers=1)  \n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)  \n  \n    def forward(self, x):  \n        x = self.embedding(x)           \n        out, _ = self.rnn(x)            \n        if self.bidirectional:  \n            out = torch.cat([out[:, -1, :self.rnn.hidden_size],  \n                             out[:, 0, self.rnn.hidden_size:]], dim=1)  \n        else:  \n            out = out[:, -1, :]  \n        out = self.fc(out)  \n        return out  \n\ndef train_validate(model, train_loader, test_loader, epochs=3, lr=0.001):  \n    model.to(device)  \n    criterion = nn.CrossEntropyLoss()  \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n  \n    for epoch in range(epochs):  \n        model.train()  \n        total_loss = 0  \n        total_correct = 0  \n        total_tokens = 0  \n        start_time = time.time()  \n  \n        for x_batch, y_batch in train_loader:  \n            optimizer.zero_grad()  \n            outputs = model(x_batch)  \n            loss = criterion(outputs, y_batch)  \n            loss.backward()  \n            optimizer.step()  \n            total_loss += loss.item()  \n  \n            preds = outputs.argmax(dim=-1)  \n            total_correct += (preds == y_batch).sum().item()  \n            total_tokens += y_batch.numel()  \n  \n        train_acc = total_correct / total_tokens  \n        avg_loss = total_loss / len(train_loader)  \n  \n        # 验证  \n        model.eval()  \n        all_preds, all_labels = [], []  \n        val_total_correct = 0  \n        val_total_tokens = 0  \n  \n        with torch.no_grad():  \n            for x_batch, y_batch in test_loader:  \n                outputs = model(x_batch)  \n                preds = outputs.argmax(dim=-1)  \n                all_preds.extend(preds.cpu().tolist())  \n                all_labels.extend(y_batch.cpu().tolist())  \n                val_total_correct += (preds == y_batch).sum().item()  \n                val_total_tokens += y_batch.numel()  \n  \n        val_acc = val_total_correct / val_total_tokens  \n        val_f1  = f1_score(all_labels, all_preds, average='macro')  \n        epoch_time = time.time() - start_time  \n  \n        print(  \n            f\"轮次 {epoch+1} | \"            f\"训练损失: {avg_loss:.4f} | \"            f\"训练准确率: {train_acc:.4f} | \"            f\"验证准确率: {val_acc:.4f} | \"            f\"验证F1: {val_f1:.4f} | \"            f\"本轮耗时: {epoch_time:.2f} 秒\"  \n        )  \n  \n    print(\"\\n训练完成！\")  \n    print(f\"最终验证准确率: {val_acc:.4f}, F1-macro: {val_f1:.4f}\")  \n    return model  \n  \n\nif __name__ == \"__main__\":  \n    model = GRUSentiment(  \n        vocab_size=vocab_size,  \n        hidden_dim=128,  \n        num_classes=2,  \n        bidirectional=True,  \n        embed_dim=300  \n    )  \n    model = train_validate(model, train_loader, test_loader, epochs=10, lr=0.001)\n</code></pre>\n<h2 id=\"32-使用词嵌入进行情绪分类-tf版\">3.2 使用词嵌入进行情绪分类 TF版</h2>\n<pre><code class=\"language-python\">import tensorflow as tf  \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences  \nfrom tensorflow.keras.utils import to_categorical  \nfrom datasets import load_dataset  \nfrom collections import Counter  \nimport numpy as np  \nimport time  \n  \ndevice = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"  \n  \n  \ndataset = load_dataset(\"mteb/imdb\")  \ntrain_data = dataset['train']  \ntest_data  = dataset['test']  \n  \ndef build_vocab(dataset, max_vocab_size=5000):  \n    counter = Counter()  \n    for item in dataset:  \n        counter.update(item['text'].split())  \n    most_common = counter.most_common(max_vocab_size)  \n    word_vocab = {w:i+2 for i,(w,_) in enumerate(most_common)}  \n    word_vocab[\"&lt;PAD&gt;\"] = 0  \n    word_vocab[\"&lt;UNK&gt;\"] = 1  \n    return word_vocab  \n  \nword_vocab = build_vocab(train_data, max_vocab_size=20000)  \nvocab_size = len(word_vocab)  \nprint(\"词表大小:\", vocab_size)  \n  \ndef encode(item):  \n    x = [word_vocab.get(w, 1) for w in item['text'].split()]  \n    y = item['label']  \n    return x, y  \n  \ntrain_encoded = [encode(item) for item in train_data]  \ntest_encoded  = [encode(item) for item in test_data]  \n  \nmax_len = 200  X_train = pad_sequences([x for x, _ in train_encoded], maxlen=max_len, padding='post', truncating='post')  \ny_train = np.array([y for _, y in train_encoded])  \nX_test  = pad_sequences([x for x, _ in test_encoded], maxlen=max_len, padding='post', truncating='post')  \ny_test  = np.array([y for _, y in test_encoded])  \n  \ndef build_model(vocab_size, embed_dim=300, hidden_dim=128, bidirectional=True, num_classes=2):  \n    inputs = tf.keras.Input(shape=(max_len,), dtype=tf.int32)  \n    x = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)(inputs)  \n    if bidirectional:  \n        x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(hidden_dim))(x)  \n    else:  \n        x = tf.keras.layers.GRU(hidden_dim)(x)  \n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)  \n    model = tf.keras.Model(inputs, outputs)  \n    return model  \n  \nmodel = build_model(vocab_size=vocab_size, embed_dim=300, hidden_dim=128, bidirectional=True, num_classes=2)  \nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.001),  \n              loss='sparse_categorical_crossentropy',  \n              metrics=['accuracy'])  \n  \nmodel.summary()  \n  \nstart_time = time.time()  \nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test),  \n                    epochs=10, batch_size=32)  \ntotal_time = time.time() - start_time  \nprint(f\"训练完成，用时 {total_time:.2f} 秒\")  \n  \ny_pred = np.argmax(model.predict(X_test), axis=1)  \nfrom sklearn.metrics import f1_score  \nf1 = f1_score(y_test, y_pred, average='macro')  \nacc = np.mean(y_pred == y_test)  \nprint(f\"验证准确率: {acc:.4f}, F1-macro: {f1:.4f}\")\n</code></pre>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 23:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET 虚拟单体存储库 (VMR)架构演进、同步机制与统一构建策略",
      "link": "https://www.cnblogs.com/shanyou/p/19540873",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shanyou/p/19540873\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 22:42\">\n    <span>.NET 虚拟单体存储库 (VMR)架构演进、同步机制与统一构建策略</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        .NET 虚拟单体存储库 (VMR) 代表了大型开源软件工程领域的一次大胆尝试与创新。它并未盲目照搬 Google 的闭源单体模式，也没有固守传统的多仓库泥潭，而是开创了一条“中间道路”\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"摘要\"><strong>摘要</strong></h2>\n<p>本文对.NET 平台的构建架构转型进行了详尽的剖析，特别是从分布式多存储库模式向<strong>虚拟单体存储库 (Virtual Monolithic Repository, VMR)</strong> 的战略迁移。随着.NET 从 Windows 专有框架演变为跨平台、开源的开发生态系统，其底层的工程复杂性呈指数级增长。传统的依赖图构建模型导致了严重的“一致性延迟”和维护碎片化问题。VMR 作为一种创新的混合架构模式，旨在通过“虚拟化”手段，在保留原有各产品存储库（Product Repositories）独立开发灵活性的同时，实现单体存储库（Monorepo）所具备的统一构建、原子级版本控制和供应链安全优势。</p>\n<h2 id=\"1-架构背景与演进动力\"><strong>1. 架构背景与演进动力</strong></h2>\n<h3 id=\"11-从单体到碎片化net-的开源征程\"><strong>1.1 从单体到碎片化：.NET 的开源征程</strong></h3>\n<p>在.NET Framework 时代，构建系统主要围绕 Windows 操作系统紧密集成，采用传统的封闭式开发模式。然而，随着.NET Core 的推出，微软开启了彻底的开源与跨平台转型。为了适应开源社区的协作习惯，并实现不同组件（如 Runtime, SDK, ASP.NET Core, Roslyn 编译器等）的独立迭代，.NET 团队最初采用了极为分散的多存储库（Multi-Repo）策略1。</p>\n<p>在这种模式下，.NET 平台被拆解为数十甚至上百个独立的 Git 存储库。每个存储库拥有独立的构建管道、版本控制历史和发布周期。这种架构在初期极大地促进了各个组件团队的敏捷性，使得负责 JIT 编译器的团队与负责 ASP.NET 路由的团队能够互不干扰地并行开发 。</p>\n<h3 id=\"12-分布式依赖图的系统性崩溃\"><strong>1.2 分布式依赖图的系统性崩溃</strong></h3>\n<p>随着.NET 生态系统的壮大，这种完全解耦的架构逐渐暴露出严重的系统性缺陷，特别是在构建整个.NET SDK 产品时。这些存储库并非真正独立，而是通过复杂的依赖关系相互连接，形成了一个庞大的<strong>有向无环图 (DAG)</strong> 3。</p>\n<h4 id=\"121-一致性延迟-coherency-latency\"><strong>1.2.1 一致性延迟 (Coherency Latency)</strong></h4>\n<p>在分布式图中，变更的传播是线性的且极其缓慢。例如，当 Roslyn 编译器团队修复了一个底层 Bug 并发布新版本后，该变更必须沿着依赖链逐级向下传播：首先更新 Runtime，Runtime 构建发布后更新 ASP.NET Core，最后才能到达 SDK 和 Installer。这个过程可能长达数天甚至数周。在此期间，处于依赖树不同层级的组件可能基于不同版本的上游组件构建，导致整个产品在任意时间点都处于“非一致性”状态。</p>\n<h4 id=\"122-钻石依赖与版本地狱\"><strong>1.2.2 钻石依赖与版本地狱</strong></h4>\n<p>分布式架构最典型的问题是<strong>钻石依赖 (Diamond Dependency)</strong>。假设存储库 A 和存储库 B 都依赖于存储库 C 的不同版本，而下游的存储库 D 同时依赖于 A 和 B。当 D 尝试构建时，就会遇到版本冲突（NuGet Hell）。解决这种冲突通常需要人工介入，强制统一依赖版本，这不仅耗时，还容易引入运行时错误。</p>\n<h4 id=\"123-跨栈重构的死锁\"><strong>1.2.3 跨栈重构的死锁</strong></h4>\n<p>当开发人员需要进行跨越多个技术栈的重构时（例如，在 Runtime 中引入新 API 并在 SDK 中立即使用），分布式架构构成了巨大的阻碍。开发者必须先在 Runtime 提交代码，等待构建发布，然后在 SDK 中升级依赖。这种“多阶段提交”不仅效率低下，而且使得原子性变更变得不可能，严重阻碍了架构层面的技术演进。</p>\n<h3 id=\"13-统一构建-unified-build-的战略转折\"><strong>1.3 统一构建 (Unified Build) 的战略转折</strong></h3>\n<p>为了解决上述问题，微软提出了 <strong>统一构建 (Unified Build)</strong> 愿景，其核心目标是能够从<strong>单一的源码提交 (Single Commit)</strong> 构建出完整的.NET SDK 产品。这不仅是内部工程效率的需求，也是为了满足 Linux 发行版（如 Fedora, Debian, Ubuntu）的合规性要求。Linux 社区有着严格的“源码构建”政策，要求软件包必须能够在其基础设施上从源代码从头编译，而不依赖预构建的二进制文件（Binary Blobs）。</p>\n<p>为了实现这一目标，必须打破物理存储库的边界，建立一个逻辑上的统一视图。<strong>虚拟单体存储库 (VMR)</strong> 应运而生，它成为了 Unified Build 的物理载体和操作核心。</p>\n<h2 id=\"2-虚拟单体存储库-vmr-的架构解析\"><strong>2. 虚拟单体存储库 (VMR) 的架构解析</strong></h2>\n<p>VMR (dotnet/dotnet) 并非传统意义上的单体存储库，而是一种混合架构模式。它巧妙地平衡了现有工程流程的惯性与统一构建的需求。</p>\n<h3 id=\"21-定义-虚拟-与-单体\"><strong>2.1 定义 \"虚拟\" 与 \"单体\"</strong></h3>\n<p>VMR 的设计哲学包含两个核心维度：</p>\n<ul>\n<li><strong>单体性 (Monolithic):</strong> 从构建系统的角度看，VMR 就是一个标准的单体库。它包含了构建.NET SDK 所需的<strong>所有</strong>源代码、构建脚本、基础设施定义和测试用例。在这个存储库上的任意一个 Git Commit SHA，都唯一且完整地定义了该时刻.NET 产品的全貌。</li>\n<li><strong>虚拟性 (Virtual):</strong> 从开发工作流的角度看，它是一个“投影”或“镜像”。原始的产品存储库（如 dotnet/runtime, dotnet/sdk）依然存在，并且是大多数开发人员日常工作的“主战场”。VMR 中的代码并非凭空产生，而是通过自动化机制从这些产品存储库同步而来的。因此，VMR 是各组件的聚合体，而非替代品 。</li>\n</ul>\n<h3 id=\"22-文件系统与存储模型\"><strong>2.2 文件系统与存储模型</strong></h3>\n<p>VMR 的目录结构经过精心设计，以映射并整合来自数十个上游存储库的内容。</p>\n<ul>\n<li><strong>src/ 目录：</strong> 这是 VMR 的核心。每个上游产品存储库的内容被映射到 src/ 下的一个子目录中。例如，dotnet/runtime 的源码被放置在 src/runtime，dotnet/aspnetcore 被放置在 src/aspnetcore。这种物理上的聚合使得跨组件的搜索、重构和构建成为可能。</li>\n<li><strong>eng/ 目录：</strong> 包含共享的工程基础设施，特别是 Arcade 工具集。这是.NET 团队通用的构建系统核心。</li>\n<li><strong>eng/common/：</strong> 这是一个特殊的引导目录，包含用于启动构建过程的脚本。这些文件通常从 Arcade 存储库同步而来，用于确保所有组件使用一致的构建工具版本。</li>\n<li><strong>source-manifest.json：</strong> 这是 VMR 的“数据库”或“注册表”。由于 VMR 是由多个上游仓库聚合而成，系统必须精确记录 VMR 当前状态对应于上游仓库的哪个 Commit SHA。该 JSON 文件维护了组件名称、远程仓库 URL 以及当前同步的 Git Hash 的映射关系，是实现双向同步的关键元数据。</li>\n</ul>\n<h3 id=\"23-存储模型的特殊处理\"><strong>2.3 存储模型的特殊处理</strong></h3>\n<p>为了适应.NET 的庞大规模和特殊构建需求，VMR 在存储模型上做了一些非标准 Git 的处理：</p>\n<ul>\n<li><strong>子模块实体化 (Hard Copy vs Pointers):</strong> 与 Git Submodules 仅存储指向外部仓库的指针不同，VMR 将子模块的代码<strong>物理复制</strong>并提交到 VMR 的 Git 树中。这意味着 src/runtime 下不仅有文件，而且这些文件是 VMR 历史的一部分。这样做是为了支持离线构建（Source Build），确保即使在没有网络连接的环境下，只要克隆了 VMR，就拥有了构建所需的一切代码。</li>\n<li><strong>文件屏蔽与路径映射 (Cloaking):</strong> 上游存储库中可能包含一些不适合放入 VMR 的文件，例如大尺寸的二进制测试数据、Windows 专用的闭源组件，或者违反 Linux 发行版许可协议的文件。VMR 的同步机制支持配置“屏蔽规则”，在同步过程中自动剔除这些路径/文件。这类似于 .gitignore，但发生在同步逻辑层面。</li>\n</ul>\n<h2 id=\"3-同步机制详解maestro-与-darc\"><strong>3. 同步机制详解：Maestro 与 Darc</strong></h2>\n<p>VMR 的生命力在于其同步机制。如果没有高效、准确的同步，VMR 将迅速与上游存储库脱节，失去其作为“真相来源”的价值。微软为此构建了一套复杂的依赖流系统，核心组件包括云服务 <strong>Maestro</strong> 和命令行工具 <strong>Darc</strong>。</p>\n<h3 id=\"31-同步架构的演进阶段\"><strong>3.1 同步架构的演进阶段</strong></h3>\n<p>VMR 的同步机制并非一蹴而就，而是经历了三个阶段的迭代 ：</p>\n<ul>\n<li><strong>阶段一：Source Build Tarball (源码构建压缩包)</strong><br />\n在.NET 6 时代，所谓的“单体”仅仅是一个巨大的 Tarball 压缩包，专门提供给 Linux 合作伙伴。它通过一系列补丁（Patches）将各个仓库的源码拼凑在一起。这种方式缺乏版本控制历史，调试极其困难，被描述为“脆弱且不透明”。</li>\n<li><strong>阶段二：VMR-lite (单向只读镜像)</strong><br />\n2022 年 10 月，微软建立了只读的 VMR。同步是单向的：从产品存储库流向 VMR。这解决了代码可见性和历史追踪问题，但由于是单向的，开发者无法直接在 VMR 中修复集成错误，必须回到原仓库修改，导致反馈循环过长。</li>\n<li><strong>阶段三：Writable VMR (双向读写同步)</strong> 从.NET 10 Preview 5 开始，VMR 变为可读写。引入了“扁平化流 (Flat Flow)”模型，允许代码在产品存储库和 VMR 之间双向流动。这标志着 VMR 正式成为生产级的基础设施。</li>\n</ul>\n<h3 id=\"32-控制平面maestro-产品构建服务\"><strong>3.2 控制平面：Maestro (产品构建服务)</strong></h3>\n<p><strong>Maestro</strong>（也被称为产品构建服务，Product Construction Service）是编排整个.NET 构建生态系统的“大脑”。它是一个运行在 Azure 上的微服务，负责监听存储库状态、计算依赖关系并触发代码流。</p>\n<p><strong>Maestro 的核心职责：</strong></p>\n<ol>\n<li><strong>订阅管理 (Subscription Management):</strong> Maestro 维护着一张庞大的订阅图。订阅定义了“源仓库”与“目标仓库”之间的关系。例如，dotnet/runtime 的 main 分支订阅了 dotnet/dotnet (VMR) 的 main 分支。</li>\n<li><strong>自动 PR 创建:</strong> 当源仓库产生新的构建时，Maestro 会计算差异，并自动在目标仓库创建 Pull Request (PR)。</li>\n<li><strong>冲突检测:</strong> 如果同步过程中发现文件冲突，Maestro 会标记 PR 并通知相关维护者（通常是 @dotnet/product-construction 团队）。</li>\n</ol>\n<h3 id=\"33-开发者工具darc-cli\"><strong>3.3 开发者工具：Darc CLI</strong></h3>\n<p><strong>Darc</strong> 是开发者与 Maestro 服务交互的本地命令行接口。它允许开发者查看、添加或更新订阅，并在本地模拟同步过程。</p>\n<p>核心命令解析 :</p>\n<ul>\n<li>darc get-subscriptions: 列出当前仓库或指定仓库的所有活跃订阅。输出通常包含源仓库 URL、目标分支、更新频率等信息。</li>\n<li>darc add-subscription: 创建新的依赖流通道。例如，将 dotnet/arcade 的更新流向 dotnet/msbuild。</li>\n<li>darc update-subscription: 修改现有订阅的参数，如排除特定的资产（Excluded Assets）或调整批处理策略。</li>\n<li>darc vmr forwardflow / backflow: （虽然文档未详细展开，但推测存在）用于在本地触发 VMR 的正向或反向同步逻辑，帮助开发者验证变更 。</li>\n</ul>\n<h3 id=\"34-代码流算法-code-flow-algorithm\"><strong>3.4 代码流算法 (Code Flow Algorithm)</strong></h3>\n<p>VMR 的同步通过两种主要的代码流模式实现：<strong>正向流 (Forward Flow)</strong> 和 <strong>反向流 (Backflow)</strong>。</p>\n<h4 id=\"341-正向流-forward-flow-产品库---vmr\"><strong>3.4.1 正向流 (Forward Flow): 产品库 -&gt; VMR</strong></h4>\n<p>当开发者在 dotnet/runtime 合并了一个 PR 后：</p>\n<ol>\n<li><strong>触发:</strong> Maestro 检测到构建成功。</li>\n<li><strong>补丁生成:</strong> 系统根据 VMR 中记录的 source-manifest.json 获取上一次同步的 Commit SHA，并与当前最新的 Commit SHA 进行对比。使用 git diff --patch --binary 生成包含了二进制差异的补丁文件。</li>\n<li><strong>路径重写:</strong> 补丁中的文件路径会被重写，加上前缀（如 src/runtime/），以匹配 VMR 的目录结构。</li>\n<li><strong>应用与提交:</strong> 补丁应用到 VMR 分支上，并更新 source-manifest.json 中的 SHA 记录。这个过程是自动化的。</li>\n</ol>\n<h4 id=\"342-反向流-backflow-vmr---产品库\"><strong>3.4.2 反向流 (Backflow): VMR -&gt; 产品库</strong></h4>\n<p>当开发者直接在 VMR 中进行跨组件修改（例如同时修改 Runtime 和 SDK）并合并后：</p>\n<ol>\n<li><strong>逆向映射:</strong> 系统识别出哪些文件属于哪个子组件。</li>\n<li><strong>分支与 PR:</strong> 针对每个受影响的产品存储库，系统会创建一个包含源码变更的 PR。</li>\n<li><strong>依赖更新:</strong> 关键点在于，反向流不仅包含<strong>源码</strong>，还包含 VMR 构建出的<strong>新二进制包版本</strong>。这意味着，当反向流回到 dotnet/runtime 时，该仓库的 Version.Details.xml 也会被更新，指向 VMR 构建出的最新依赖。这保证了产品库始终基于最新的全栈环境进行构建。</li>\n</ol>\n<h3 id=\"35-状态追踪与防环路设计\"><strong>3.5 状态追踪与防环路设计</strong></h3>\n<p>双向同步最容易导致的问题是死循环（Ping-Pong Effect）：A 的变更同步给 B，B 的构建触发同步回 A。为了防止这种情况，.NET 团队采用了严格的状态追踪机制。</p>\n<ul>\n<li><strong>eng/Version.Details.xml:</strong> 在产品库中，此文件记录了该仓库依赖的 VMR 版本。</li>\n<li><strong>src/source-manifest.json:</strong> 在 VMR 中，此文件记录了包含的各产品库版本。</li>\n</ul>\n<p>同步逻辑会检查这些元数据。如果 Maestro 发现 VMR 中的变更实际上就是源自产品库最近的一次提交，它会识别为“已同步”，从而通过空操作（No-Op）切断循环。</p>\n<h2 id=\"4-统一构建-unified-build-与供应链安全\"><strong>4. 统一构建 (Unified Build) 与供应链安全</strong></h2>\n<p>VMR 的建立不仅仅是为了方便代码管理，更是 <strong>Unified Build</strong> 的基石。它改变了.NET 产品的构建范式，从水平分层构建转向垂直切片构建。</p>\n<h3 id=\"41-垂直构建-vertical-builds\"><strong>4.1 垂直构建 (Vertical Builds)</strong></h3>\n<p>在旧的模式下，构建是水平的：先构建所有 Runtime，再构建所有 ASP.NET。而在 VMR 中，构建是<strong>垂直</strong>的。 一个垂直构建会基于 VMR 的单一 Commit，按照依赖顺序（Toolset -&gt; Runtime -&gt; ASP.NET -&gt; SDK）在一次构建流水线中从源码编译出整个栈。</p>\n<p><strong>优势：</strong></p>\n<ul>\n<li><strong>消除时间差:</strong> 任何代码变更都会立即在全栈范围内进行验证。</li>\n<li><strong>简化发布:</strong> 发布.NET 10 Preview 1 只需要对 VMR 的特定 Commit 打标签，而不需要协调几十个仓库的 Commit 组合。</li>\n</ul>\n<h3 id=\"42-linux-源码构建-source-build-与发行版合规\"><strong>4.2 Linux 源码构建 (Source Build) 与发行版合规</strong></h3>\n<p>Linux 发行版（如 Fedora, Red Hat）对软件包有严格的“源码构建”要求。他们不信任上游厂商提供的预编译二进制文件，因为这些文件可能包含后门或未修补的漏洞，且无法审计。</p>\n<p>VMR 通过提供一个自包含的 Git 仓库，完美支持了这一需求：</p>\n<ol>\n<li><strong>离线能力:</strong> VMR 包含了所有必要的源码（通过实体化的子模块），不依赖构建时的 git clone 操作。</li>\n<li><strong>预制脚本:</strong> prep-source-build.sh 脚本用于准备环境。</li>\n<li><strong>引用包 (Reference Packages):</strong> 为了解决循环依赖（如构建 C# 编译器需要 C# 编译器），Unified Build 引入了 dotnet/source-build-reference-packages。这些是仅包含 API 定义（元数据）的文本格式包，可以轻易地从源码生成，作为自举（Bootstrapping）的起点 5。</li>\n</ol>\n<h3 id=\"43-可重现构建-reproducible-builds\"><strong>4.3 可重现构建 (Reproducible Builds)</strong></h3>\n<p>供应链安全的核心是<strong>可重现性</strong>。即：在不同环境、不同时间，使用相同的源码应当生成比特级完全一致（Bit-for-bit identical）的二进制文件 15。</p>\n<p>VMR 架构极大地促进了这一点：</p>\n<ul>\n<li><strong>输入确定性:</strong> 单一 Commit 锁定了所有源代码输入。</li>\n<li><strong>环境一致性:</strong> eng/common 锁定了所有构建工具链版本。</li>\n<li><strong>路径规范化:</strong> 编译器配置被调整为忽略绝对路径（如 /home/user/src），使用相对路径或确定性路径映射（Source Link），确保构建产物不包含构建机器的元数据 16。</li>\n</ul>\n<p>这使得第三方（如企业安全团队或政府机构）可以独立验证微软发布的.NET SDK 是否真的由公开的源码构建而来，从而防止类似 SolarWinds 的供应链攻击。</p>\n<h2 id=\"5-开发者工作流与体验\"><strong>5. 开发者工作流与体验</strong></h2>\n<p>VMR 的引入对开发者的日常工作流产生了深远影响，形成了“内循环”与“外循环”并存的局面。</p>\n<h3 id=\"51-内循环-inner-loop产品库开发\"><strong>5.1 内循环 (Inner Loop)：产品库开发</strong></h3>\n<p>对于绝大多数日常任务（如修复 System.String 中的 Bug），开发者依然工作在 dotnet/runtime 等独立产品库中。</p>\n<ul>\n<li><strong>流程:</strong> Fork -&gt; Clone -&gt; Branch -&gt; Commit -&gt; PR。</li>\n<li><strong>优势:</strong> 保持了较小的仓库体积（相比 VMR），IDE 加载速度快，构建时间短。</li>\n<li><strong>同步:</strong> 变更合并后，开发者无需手动操作，Maestro 会自动将其正向流转到 VMR。</li>\n</ul>\n<h3 id=\"52-外循环-outer-loopvmr-开发\"><strong>5.2 外循环 (Outer Loop)：VMR 开发</strong></h3>\n<p>当任务涉及跨仓库修改时，开发者切换到 VMR。</p>\n<ul>\n<li><strong>场景:</strong> 修改 Roslyn 编译器的一个接口，并同时更新 Runtime 中对该接口的调用。</li>\n<li><strong>流程:</strong> Clone dotnet/dotnet -&gt; 修改 src/roslyn 和 src/runtime -&gt; 本地全量构建验证 -&gt; 提交 PR 给 VMR。</li>\n<li><strong>优势:</strong> 原子性提交，一次性解决所有破坏性变更（Breaking Changes），无需临时向后兼容代码 。</li>\n</ul>\n<h3 id=\"53-痛点与挑战\"><strong>5.3 痛点与挑战</strong></h3>\n<p>尽管 VMR 解决了架构问题，但也给开发者带来了一些“痛点”：</p>\n<ol>\n<li><strong>仓库体积:</strong> VMR 非常庞大，Clone 和 Checkout 的时间显著增加。</li>\n<li><strong>构建时间:</strong> 垂直构建整个.NET 栈需要消耗大量的计算资源和时间，普通开发者的笔记本电脑可能难以通过 VMR 进行全量调试。</li>\n<li><strong>权限控制:</strong> 在多仓库模式下，权限可以细分（如只有特定团队能合并 Runtime 代码）。在 VMR 中，权限管理变得更加复杂，需要通过 CODEOWNERS 文件精细控制目录级权限，防止误操作 。</li>\n</ol>\n<h2 id=\"6-架构对比分析\"><strong>6. 架构对比分析</strong></h2>\n<p>为了更清晰地定位 VMR 的架构属性，我们将其与业界其他主流方案进行对比。</p>\n<h3 id=\"表-1vmr-与-传统-monorepo-及-git-submodules-的深度对比\"><strong>表 1：VMR 与 传统 Monorepo 及 Git Submodules 的深度对比</strong></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">分布式多仓库 (Legacy.NET)</th>\n<th style=\"text-align: left;\">标准 Monorepo (Google/Meta)</th>\n<th style=\"text-align: left;\">虚拟单体库 (.NET VMR)</th>\n<th style=\"text-align: left;\">Git Submodules 方案</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>代码存储</strong></td>\n<td style=\"text-align: left;\">物理分散，逻辑连接</td>\n<td style=\"text-align: left;\">物理集中，单一仓库</td>\n<td style=\"text-align: left;\"><strong>物理集中（镜像），逻辑分散（开发）</strong></td>\n<td style=\"text-align: left;\">物理分散，指针连接</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>版本控制工具</strong></td>\n<td style=\"text-align: left;\">Standard Git</td>\n<td style=\"text-align: left;\">Custom (Piper, Mononoke) + Virtual FS</td>\n<td style=\"text-align: left;\">Standard Git (需启用长路径支持)</td>\n<td style=\"text-align: left;\">Standard Git</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>构建一致性</strong></td>\n<td style=\"text-align: left;\">低 (存在一致性延迟)</td>\n<td style=\"text-align: left;\">极高 (原子性)</td>\n<td style=\"text-align: left;\"><strong>高 (通过 Maestro 同步保障)</strong></td>\n<td style=\"text-align: left;\">低 (依赖指针更新，易碎)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>离线构建支持</strong></td>\n<td style=\"text-align: left;\">困难 (需拉取 NuGet 包)</td>\n<td style=\"text-align: left;\">原生支持</td>\n<td style=\"text-align: left;\"><strong>原生支持 (代码实体化)</strong></td>\n<td style=\"text-align: left;\">中等 (需递归 Clone)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>开发环境成本</strong></td>\n<td style=\"text-align: left;\">低 (仅需 Clone 相关库)</td>\n<td style=\"text-align: left;\">高 (需专用工具支持大库)</td>\n<td style=\"text-align: left;\"><strong>中/高 (VMR 庞大，但可选产品库)</strong></td>\n<td style=\"text-align: left;\">低</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>跨组件重构</strong></td>\n<td style=\"text-align: left;\">极难 (多阶段提交)</td>\n<td style=\"text-align: left;\">容易 (原子提交)</td>\n<td style=\"text-align: left;\"><strong>容易 (在 VMR 中原子提交)</strong></td>\n<td style=\"text-align: left;\">困难 (需多库协调)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>文件屏蔽 (Cloaking)</strong></td>\n<td style=\"text-align: left;\">不适用</td>\n<td style=\"text-align: left;\">支持 (构建规则控制)</td>\n<td style=\"text-align: left;\"><strong>原生支持 (同步时过滤)</strong></td>\n<td style=\"text-align: left;\">不支持 (全量拉取)</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"61-与-google-模式的区别\"><strong>6.1 与 Google 模式的区别</strong></h3>\n<p>Google 和 Meta 使用单一的巨型仓库（Monolith），所有开发者直接在其中工作。这需要极其昂贵的定制基础设施（如虚拟文件系统 VFS for Git, Piper）。微软并未强制.NET 社区使用这种重型设施，因为开源贡献者通常只使用标准的 Git 客户端。VMR 作为一个“投影”，兼容了标准 Git 工具链，虽然牺牲了一定的实时性（同步延迟），但换取了对开源社区的友好度 。</p>\n<h3 id=\"62-为什么不直接使用-git-submodules\"><strong>6.2 为什么不直接使用 Git Submodules？</strong></h3>\n<p>Git Submodules 在处理大规模项目时非常脆弱。如果上游仓库重写了历史（Force Push），子模块指针就会失效。此外，Submodules 无法处理“文件屏蔽”需求（即在 Linux 构建中剔除 Windows 二进制文件）。VMR 通过物理复制和补丁机制，彻底解耦了对上游 Git 历史的依赖，实现了更健壮的控制。</p>\n<h2 id=\"7-挑战局限性与未来展望\"><strong>7. 挑战、局限性与未来展望</strong></h2>\n<h3 id=\"71-分支对齐与-snapping\"><strong>7.1 分支对齐与 \"Snapping\"</strong></h3>\n<p>一个主要挑战是如何保持 VMR 分支与数十个产品库分支的精确对齐。特别是在发布窗口期（Snap），所有仓库必须几乎同时切出 release/x.y 分支。现在，这一过程由 VMR 中心化驱动：VMR 先切分支，然后通过自动化工具强制所有下游产品库切分，以防止历史错位 。</p>\n<h3 id=\"72-合并冲突的复杂性\"><strong>7.2 合并冲突的复杂性</strong></h3>\n<p>随着 VMR 变为可写，双向同步带来的合并冲突不可避免。如果一个文件在 VMR 中被修改（重构），同时在产品库中被修改（Bug修复），同步 PR 就会失败。目前这主要依赖人工介入解决。未来的改进方向可能是引入更智能的语义合并工具。</p>\n<h3 id=\"73-基础设施成本\"><strong>7.3 基础设施成本</strong></h3>\n<p>运行 Maestro 服务和频繁的垂直构建对 CI/CD 资源（Azure DevOps）构成了巨大压力。每次同步都需要大量的计算资源来生成补丁、应用补丁并运行全套测试。优化构建效率（如增量构建、缓存复用）是持续优化的重点。</p>\n<h3 id=\"74-未来展望\"><strong>7.4 未来展望</strong></h3>\n<p>展望未来，VMR 可能会逐渐从“镜像”过渡为“主源”。随着 Git 对大仓库支持的改进（如 Scalar, Sparse Checkout 的普及），也许有一天微软会建议所有核心开发者直接在 VMR 上工作，而将拆分的产品库作为只读镜像提供给只需关注特定组件的社区成员。这将彻底反转目前的拓扑结构，进一步简化架构 。</p>\n<h2 id=\"结论\"><strong>结论</strong></h2>\n<p>.NET 虚拟单体存储库 (VMR) 代表了大型开源软件工程领域的一次大胆尝试与创新。它并未盲目照搬 Google 的闭源单体模式，也没有固守传统的多仓库泥潭，而是开创了一条“中间道路”。</p>\n<p>通过 <strong>Maestro</strong> 的智能编排和 <strong>VMR</strong> 的结构化映射，微软成功地在不破坏现有开发生态的前提下，解决了一致性延迟和供应链安全的难题。VMR 不仅实现了 Linux 发行版的合规性要求，更为.NET 平台未来的长期演进提供了坚实的架构基础。对于任何面临微服务碎片化治理、跨组件协作困难以及构建一致性挑战的大型软件组织而言，.NET VMR 的架构设计都提供了极具价值的参考范式。</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>\n<img src=\"https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg\" width=\"170\" />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 22:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shanyou\">张善友</a>&nbsp;\n阅读(<span id=\"post_view_count\">6</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI Agent 框架探秘：拆解 OpenHands（3）--- 启动",
      "link": "https://www.cnblogs.com/rossiXYZ/p/19530105",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/rossiXYZ/p/19530105\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 20:55\">\n    <span>AI Agent 框架探秘：拆解 OpenHands（3）--- 启动</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"ai-agent-框架探秘拆解-openhands3----启动\">AI Agent 框架探秘：拆解 OpenHands（3）--- 启动</h1>\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">目录</div><ul><li><a href=\"#ai-agent-框架探秘拆解-openhands3----启动\" rel=\"noopener nofollow\">AI Agent 框架探秘：拆解 OpenHands（3）--- 启动</a><ul><li><a href=\"#0x00-概要\" rel=\"noopener nofollow\">0x00 概要</a></li><li><a href=\"#0x01-背景\" rel=\"noopener nofollow\">0x01 背景</a><ul><li><a href=\"#11-总体架构\" rel=\"noopener nofollow\">1.1 总体架构</a></li><li><a href=\"#12-切入点\" rel=\"noopener nofollow\">1.2 切入点</a></li></ul></li><li><a href=\"#0x02-初始化--run_controller\" rel=\"noopener nofollow\">0x02 初始化 @ run_controller</a><ul><li><a href=\"#21-总体流程\" rel=\"noopener nofollow\">2.1 总体流程</a></li><li><a href=\"#22-创建注册中心\" rel=\"noopener nofollow\">2.2 创建注册中心</a></li><li><a href=\"#23-创建agent\" rel=\"noopener nofollow\">2.3 创建Agent</a></li><li><a href=\"#24-构建runtime\" rel=\"noopener nofollow\">2.4 构建Runtime</a></li><li><a href=\"#25-构建memory--microagent\" rel=\"noopener nofollow\">2.5 构建Memory &amp; Microagent</a><ul><li><a href=\"#251-创建-memory\" rel=\"noopener nofollow\">2.5.1 创建 Memory</a></li><li><a href=\"#252-创建microagent\" rel=\"noopener nofollow\">2.5.2 创建Microagent</a></li></ul></li><li><a href=\"#26-创建mcp\" rel=\"noopener nofollow\">2.6 创建MCP</a></li><li><a href=\"#27-创建controller\" rel=\"noopener nofollow\">2.7 创建Controller</a></li><li><a href=\"#28-发送启动事件\" rel=\"noopener nofollow\">2.8 发送启动事件</a></li><li><a href=\"#29-订阅事件流注册用户输入回调函数\" rel=\"noopener nofollow\">2.9 订阅事件流：注册用户输入回调函数</a></li><li><a href=\"#210-运行代理\" rel=\"noopener nofollow\">2.10 运行代理</a></li><li><a href=\"#211-run_controller全部代码\" rel=\"noopener nofollow\">2.11 run_controller全部代码</a></li></ul></li><li><a href=\"#0xff-参考\" rel=\"noopener nofollow\">0xFF 参考</a></li></ul></li></ul></div><p></p>\n<h2 id=\"0x00-概要\">0x00 概要</h2>\n<p>当分析一个系统时，启动部分和用户典型使用场景是比较理想的切入点，因为这两个部分可以覆盖系统大部分功能模块，可以借此深入架构。</p>\n<p>因为本系列借鉴的文章过多，可能在参考文献中有遗漏的文章，如果有，还请大家指出。</p>\n<h2 id=\"0x01-背景\">0x01 背景</h2>\n<h3 id=\"11-总体架构\">1.1 总体架构</h3>\n<p>以下是 OpenHands 的架构图，这是一个复杂的系统。</p>\n<p><img alt=\"Openhands-arch\" class=\"lazyload\" /></p>\n<p>抛开复杂的技术细节，OpenHands Agent 的交互逻辑可提炼为 “初始化 - 事件注入 - 协同处理 - 等待” 的极简流程，核心围绕 EventStream 实现模块联动：</p>\n<ul>\n<li>初始化就绪：用户创建会话时，系统自动完成 Agent、AgentController、Runtime、Memory 有核心模块的初始化，且每个模块都会自动订阅 EventStream，确保能捕获相关事件；</li>\n<li>任务发起：用户发送消息本质是向 EventStream 中注入一条事件，这条事件会触发所有订阅相关回调函数的模块，启动协同处理；</li>\n<li>多模块协同响应：\n<ul>\n<li>Session 模块持续上报事件流中的各类状态事件，保障全局可观测；</li>\n<li>若用户开启 Security Analyzer，该模块会通过安全分析，自动确认低风险任务，减少用户手动干预；</li>\n<li>AgentController 向事件流注入 RecallAction，Memory 模块判断是否为首次接收的用户信息，据此补充相关记忆并返回 RecallObservation 事件；</li>\n</ul>\n</li>\n<li>状态同步：AgentController 更新任务当前状态，并将相关信息传递给 Agent。即AgentController 调用 <code>Agent.step</code> 方法处理当前事件，生成 Action 并注入事件流。</li>\n<li>行动决策：Agent 基于接收的状态信息，向 LLM 发起请求，生成下一步具体行动方案；</li>\n<li>行动输出：Agent 明确输出行动指令，可能是运行系统命令、读取文件、调用工具等具体操作；</li>\n<li>行动分发：该行动指令通过 EventStream 传递至 Runtime 组件，等待执行；</li>\n<li>执行与反馈：Runtime 执行行动指令，生成包含执行结果、错误信息等内容的观察结果；</li>\n<li>结果回传：观察结果通过 EventStream 回传给 AgentController，完成一次执行闭环；</li>\n<li>循环或终止：AgentController 根据观察结果判断任务是否完成，若未完成则重复上述流程；若需协同，则委派给其他 Agent，直至任务结束。</li>\n</ul>\n<h3 id=\"12-切入点\">1.2 切入点</h3>\n<p>以下是一个例子。我们由此进入，看看OpenHands如何启动，也可以从此处看看OpenHands的基本逻辑。</p>\n<pre><code class=\"language-python\">config = load_openhands_config()\naction = MessageAction(content=\"Write a hello world program\")\nstate = await run_controller(config=config, initial_user_action=action)\n</code></pre>\n<p>上述代码是直接命令行调用 run_controller，因此我们从run_controller入手。</p>\n<h2 id=\"0x02-初始化--run_controller\">0x02 初始化 @ run_controller</h2>\n<p>run_controller 作为 OpenHands 后端单个会话的核心入口协程，核心职责是依据预设配置启动运行时环境、智能体及对应控制器，搭建起从接收用户指令到多步骤执行任务，再到最终将会话状态持久化存储的完整处理链路。其核心设计亮点体现在三方面：</p>\n<ul>\n<li>实现会话全生命周期的一体化管理，集中完成会话标识（SID）生成、运行时连接建立、代码仓库克隆、MCP 工具嵌入及任务执行轨迹重放等关键操作；</li>\n<li>构建双重安全管控机制，通过设置最大迭代次数（max_iterations）与单任务最高预算（max_budget_per_task）的硬性限制，有效规避无限循环执行与资源费用超额的风险；</li>\n<li>强化全流程可观测性，借助 EventStream 实现事件实时分发，支持命令行界面（CLI）、前端界面、日志系统等多端同步订阅，同时生成可回放、可审计的 JSON 格式执行轨迹，便于后续追溯与核查。</li>\n</ul>\n<h3 id=\"21-总体流程\">2.1 总体流程</h3>\n<p>openhands\\core\\main.py 的 run_controller 的总体流程如下。</p>\n<ul>\n<li>初始化系统组件\n<ul>\n<li>创建Agent。</li>\n<li>创建runtime和内存系统</li>\n<li>创建controller。</li>\n</ul>\n</li>\n<li>运行Agent，具体会:\n<ul>\n<li>管理任务执行流程。\n<ul>\n<li>接收初始用户操作</li>\n<li>处理事件流中的各种事件。</li>\n<li>监听agent状态变化，特别是等待用户输入的状态。</li>\n</ul>\n</li>\n<li>处理用户交互。\n<ul>\n<li>当agent需要用户输入时，依据配置进行自动响应或者等待真实用户输入。</li>\n<li>支持mock用户响应函数fake_user_response_fn，这样可以自动化测试。</li>\n</ul>\n</li>\n<li>状态管理和持久化。\n<ul>\n<li>保存会话状态到文件。</li>\n<li>记录执行轨迹，这样可以分析调试。</li>\n<li>支持轨迹重放。</li>\n</ul>\n</li>\n<li>资源管理。\n<ul>\n<li>管理MCP集成。</li>\n<li>控制执行预算（迭代次数和费用限制）</li>\n<li>正确关闭资源。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>具体流程图如下。</p>\n<p><img alt=\"OpenHands-3-1\" class=\"lazyload\" /></p>\n<p>我们接下来看看具体流程细节。</p>\n<h3 id=\"22-创建注册中心\">2.2 创建注册中心</h3>\n<p>下面语句会创建 LLM 注册中心 &amp; 对话统计实例。</p>\n<pre><code class=\"language-python\">    sid = sid or generate_sid(config)\n\n    llm_registry, conversation_stats, config = create_registry_and_conversation_stats(\n        config,\n        sid,\n        None,\n    )\n</code></pre>\n<p>具体代码如下，其功能是:</p>\n<ol>\n<li>根据用户设置调整基础配置</li>\n<li>初始化LLM注册表（管理所有LLM实例）</li>\n<li>初始化文件存储和对话统计器（跟踪对话数据）</li>\n<li>建立注册表与统计器的订阅关系</li>\n</ol>\n<pre><code class=\"language-python\">def create_registry_and_conversation_stats(\n    config: OpenHandsConfig,\n    sid: str,\n    user_id: Optional[str],\n    user_settings: Optional[Settings] = None,\n) -&gt; tuple[LLMRegistry, ConversationStats, OpenHandsConfig]:\n    \"\"\"\n    创建LLM注册表、对话统计实例和用户配置的组合函数。\n    \n    参数：\n        config: 基础配置对象\n        sid: 会话ID（用于标识当前对话）\n        user_id: 用户ID（可选，用于用户级数据跟踪）\n        user_settings: 用户自定义设置（可选，用于覆盖默认配置）\n    \n    返回：\n        三元组 (LLM注册表, 对话统计实例, 最终用户配置)\n    \"\"\"\n    # 初始化用户配置（优先使用用户设置覆盖默认配置）\n    user_config = config\n    if user_settings:\n        user_config = setup_llm_config(config, user_settings)\n\n    # 确定代理类型（从用户设置或默认配置中获取）\n    agent_cls = user_settings.agent if user_settings else None\n    # 创建LLM注册表，关联配置和代理类型\n    llm_registry = LLMRegistry(user_config, agent_cls)\n    \n    # 初始化文件存储（用于持久化对话数据）\n    file_store = get_file_store(\n        file_store_type=config.file_store,\n        file_store_path=config.file_store_path,\n        file_store_web_hook_url=config.file_store_web_hook_url,\n        file_store_web_hook_headers=config.file_store_web_hook_headers,\n        file_store_web_hook_batch=config.file_store_web_hook_batch,\n    )\n    \n    # 创建对话统计实例（绑定文件存储、会话ID和用户ID）\n    conversation_stats = ConversationStats(file_store, sid, user_id)\n    # 订阅注册表事件：当新LLM注册时，自动记录到对话统计中\n    llm_registry.subscribe(conversation_stats.register_llm)\n    \n    return llm_registry, conversation_stats, user_config\n</code></pre>\n<h3 id=\"23-创建agent\">2.3 创建Agent</h3>\n<p>此处会根据config信息来创建agent。</p>\n<pre><code class=\"language-python\">agent = create_agent(config, llm_registry)\n</code></pre>\n<p>create_agent代码如下，从缺省配置可以看到，默认生成CodeActAgent。</p>\n<pre><code class=\"language-python\">#default_agent = \"CodeActAgent\"\n\ndef create_agent(config: OpenHandsConfig, llm_registry: LLMRegistry) -&gt; Agent:\n    agent_cls: type[Agent] = Agent.get_cls(config.default_agent)\n    agent_config = config.get_agent_config(config.default_agent)\n    # Pass the runtime information from the main config to the agent config\n    agent_config.runtime = config.runtime\n    config.get_llm_config_from_agent(config.default_agent)\n    agent = agent_cls(config=agent_config, llm_registry=llm_registry)\n    return agent\n</code></pre>\n<p>CodeActAgent 定义如下。</p>\n<pre><code class=\"language-python\">class CodeActAgent(Agent):\n    \"\"\"\n    CodeActAgent：极简主义的智能代理，基于 CodeAct 理念实现。\n    核心逻辑：将模型的行动统一到“代码执行”这一单一行动空间，通过传递“行动-观察”对列表，\n    引导模型决策下一步操作，兼顾简洁性与执行性能。\n\n    核心理念（源自论文：https://arxiv.org/abs/2402.01030）：\n    打破传统代理多行动类型的复杂设计，用代码执行统一所有行动，既简化架构又提升效率。\n\n    每一轮交互中，代理可执行两种操作：\n    1. **对话（Converse）**：用自然语言与人类沟通，例如请求澄清需求、确认操作等。\n    2. **代码行动（CodeAct）**：通过执行代码完成任务，支持两种形式：\n       - 执行任意有效的 Linux bash 命令\n       - 执行任意有效的 Python 代码（通过交互式 IPython 解释器模拟，\n         实际通过 bash 命令实现，详见插件系统说明）\n    \"\"\"\n    VERSION = '2.2'  # 代理版本号\n\n    # 沙盒环境所需插件依赖（按初始化顺序排列）\n    sandbox_plugins: list[PluginRequirement] = [\n        # 注意：AgentSkillsRequirement 需在 JupyterRequirement 之前初始化\n        # 原因：AgentSkillsRequirement 提供大量 Python 工具函数，\n        # Jupyter 环境需要依赖这些函数才能正常工作\n        AgentSkillsRequirement(),  # 提供代理核心技能函数的插件\n        JupyterRequirement(),      # 提供交互式 Python 执行环境的插件\n    ]\n\n    def __init__(self, config: AgentConfig, llm_registry: LLMRegistry) -&gt; None:\n        \"\"\"\n        初始化 CodeActAgent 实例。\n\n        参数：\n            config (AgentConfig)：当前代理的配置对象（包含模型路由、记忆策略等）\n            llm_registry (LLMRegistry)：LLM 注册表实例，用于获取所需 LLM 或路由 LLM\n        \"\"\"\n        # 调用父类 Agent 的初始化方法，完成基础配置（如 LLM 注册、提示词管理器初始化）\n        super().__init__(config, llm_registry)\n        \n        self.pending_actions: deque['Action'] = deque()  # 待执行的行动队列（双端队列，支持高效进出）\n        self.reset()  # 重置代理状态（初始化行动历史、观察记录等）\n        self.tools = self._get_tools()  # 获取代理可使用的工具集（从插件或配置中提取）\n\n        # 初始化对话记忆实例：存储“行动-观察”对，支持记忆压缩、上下文管理\n        self.conversation_memory = ConversationMemory(self.config, self.prompt_manager)\n\n        # 初始化上下文压缩器：根据配置创建 Condenser 实例，用于压缩长对话历史\n        self.condenser = Condenser.from_config(self.config.condenser, llm_registry)\n\n        # 覆盖父类的 LLM 实例：如需模型路由，优先使用路由 LLM（根据代理配置动态选择模型）\n        self.llm = self.llm_registry.get_router(self.config)\n</code></pre>\n<p>具体参见下图。</p>\n<p><img alt=\"image-20251019171311325\" class=\"lazyload\" /></p>\n<p>CodeActAgent的初始化流程图如下。</p>\n<p><img alt=\"Openhands-3-2\" class=\"lazyload\" /></p>\n<h3 id=\"24-构建runtime\">2.4 构建Runtime</h3>\n<p>create_runtime()构建了AI 代理的 “专属工作间”Runtime。在OpenHands系统中，Runtime扮演着至关重要的角色，它为人工智能代理提供了一个稳定且可控的操作平台。</p>\n<pre><code class=\"language-python\">    # 运行时创建后会自动连接并克隆选定的代码仓库\n    repo_directory = None\n    if runtime is None:\n        # 初始化代码仓库（如需）\n        repo_tokens = get_provider_tokens()\n        # 创建运行时实例\n        runtime = create_runtime(\n            config,\n            llm_registry,\n            sid=sid,\n            headless_mode=headless_mode,\n            agent=agent,\n            git_provider_tokens=repo_tokens,\n        )\n        # 同步调用异步的运行时连接方法\n        call_async_from_sync(runtime.connect)\n\n        # 初始化代码仓库（如需）\n        if config.sandbox.selected_repo:\n            repo_directory = initialize_repository_for_runtime(\n                runtime,\n                immutable_provider_tokens=repo_tokens,\n                selected_repository=config.sandbox.selected_repo,\n            )\n            \n    # event_stream 是  event_stream = EventStream(session_id, file_store)        \n    event_stream = runtime.event_stream        \n</code></pre>\n<p>Runtime 的<code>__init__</code>会注册EventStreamSubscriber.RUNTIME。</p>\n<pre><code class=\"language-python\">        self.event_stream = event_stream\n        if event_stream:\n            event_stream.subscribe(\n                EventStreamSubscriber.RUNTIME, self.on_event, self.sid\n            )\n</code></pre>\n<p><code>Runtime</code>只处理可运行的<code>Action</code>事件，执行动作拿到输出<code>Observation</code>发送回事件流中</p>\n<ul>\n<li><code>isinstance(event, MCPAction)</code>执行MCP获取结果</li>\n</ul>\n<ul>\n<li>其他runtime支持的action则执行获取结果</li>\n</ul>\n<h3 id=\"25-构建memory--microagent\">2.5 构建Memory &amp; Microagent</h3>\n<p>接下来初始化memory，</p>\n<pre><code class=\"language-python\">    # when memory is created, it will load the microagents from the selected repository\n    if memory is None:\n        memory = create_memory(\n            runtime=runtime,\n            event_stream=event_stream,\n            sid=sid,\n            selected_repository=config.sandbox.selected_repo,\n            repo_directory=repo_directory,\n            conversation_instructions=conversation_instructions,\n            working_dir=str(runtime.workspace_root),\n        )\n\n</code></pre>\n<h4 id=\"251-创建-memory\">2.5.1 创建 Memory</h4>\n<p>create_memory 函数会创建memory。</p>\n<pre><code class=\"language-python\">def create_memory(\n    runtime: Runtime,\n    event_stream: EventStream,\n    sid: str,\n    selected_repository: str | None = None,\n    repo_directory: str | None = None,\n    status_callback: Callable | None = None,\n    conversation_instructions: str | None = None,\n    working_dir: str = DEFAULT_WORKSPACE_MOUNT_PATH_IN_SANDBOX,\n) -&gt; Memory:\n    \"\"\"Create a memory for the agent to use.\n\n    Args:\n        runtime: The runtime to use.\n        event_stream: The event stream it will subscribe to.\n        sid: The session id.\n        selected_repository: The repository to clone and start with, if any.\n        repo_directory: The repository directory, if any.\n        status_callback: Optional callback function to handle status updates.\n        conversation_instructions: Optional instructions that are passed to the agent\n    \"\"\"\n    memory = Memory(\n        event_stream=event_stream,\n        sid=sid,\n        status_callback=status_callback,\n    )\n\n    memory.set_conversation_instructions(conversation_instructions)\n\n    if runtime:\n        # sets available hosts\n        memory.set_runtime_info(runtime, {}, working_dir)\n\n        # loads microagents from repo/.openhands/microagents\n        microagents: list[BaseMicroagent] = runtime.get_microagents_from_selected_repo(\n            selected_repository\n        )\n        memory.load_user_workspace_microagents(microagents)\n\n        if selected_repository and repo_directory:\n            memory.set_repository_info(selected_repository, repo_directory)\n\n    return memory\n\n\n</code></pre>\n<p>memory初始化的时候有一个event_stream的订阅，会注册 EventStreamSubscriber.MEMORY，当有event的时候Memory 的<code>on_event</code>方法会被调用。</p>\n<pre><code class=\"language-python\">self.event_stream.subscribe(\n            EventStreamSubscriber.MEMORY,\n            self.on_event,\n            self.sid,\n        )\n\n\n</code></pre>\n<p><code>Memory</code>只处理<code>RecallAction</code>，对于用户首次输入信息则将一些额外的工作空间上下文信息添加到<code>RecallObservation</code>发送回事件流中，对于其他非用户首次的输入信息则加入<code>microagent knowledge(领域强化提示词)</code>到<code>RecallObservation</code>发送回事件流中。</p>\n<h4 id=\"252-创建microagent\">2.5.2 创建Microagent</h4>\n<p>create_memory函数中会加载Microagent。</p>\n<pre><code class=\"language-python\">        # loads microagents from repo/.openhands/microagents\n        microagents: list[BaseMicroagent] = runtime.get_microagents_from_selected_repo(\n            selected_repository\n        )\n        memory.load_user_workspace_microagents(microagents)\n\n</code></pre>\n<p>Microagent是主代理的“专业合作伙伴”。</p>\n<p>为了高效完成复杂任务，通常需要专业的分工协作，Microagent正是为了这一目的而设计的“专业执行者”。当主代理在执行任务时遇到特定领域的细分工作，它不必亲自处理，而是可以将这部分任务“委托”给相应的Microagent，从而利用其专业能力提高效率和准确性。</p>\n<p>从本质上讲，Microagent同样基于大型语言模型构建，比如，其独特之处可以是其内置的专业提示词（Prompt）。这些提示词中融入了特定领域的知识准则与操作规范，例如，与Git相关的Microagent，其提示词会包含Git操作的核心技巧与最佳实践，能够引导模型更精确地处理与Git相关的任务，成为主代理应对细分场景的“得力助手”。</p>\n<p>BaseMicroagent 定义如下：</p>\n<pre><code class=\"language-python\">class BaseMicroagent(BaseModel):\n    \"\"\"Base class for all microagents.\"\"\"\n\n    name: str\n    content: str\n    metadata: MicroagentMetadata\n    source: str  # path to the file\n    type: MicroagentType\n\n    PATH_TO_THIRD_PARTY_MICROAGENT_NAME: ClassVar[dict[str, str]] = {\n        '.cursorrules': 'cursorrules',\n        'agents.md': 'agents',\n        'agent.md': 'agents',\n    }\n\n</code></pre>\n<h3 id=\"26-创建mcp\">2.6 创建MCP</h3>\n<p>接下来会创建MCP相关部分。</p>\n<pre><code class=\"language-python\">    # Add MCP tools to the agent\n    if agent.config.enable_mcp:\n        # Add OpenHands' MCP server by default\n        _, openhands_mcp_stdio_servers = (\n            OpenHandsMCPConfigImpl.create_default_mcp_server_config(\n                config.mcp_host, config, None\n            )\n        )\n        runtime.config.mcp.stdio_servers.extend(openhands_mcp_stdio_servers)\n\n        await add_mcp_tools_to_agent(agent, runtime, memory)\n\n</code></pre>\n<h3 id=\"27-创建controller\">2.7 创建Controller</h3>\n<p>接下来会创建AgentController。</p>\n<p>AgentController 是 OpenHands 系统中的核心控制器组件，负责管理代理（Agent）的整个生命周期和行为。是代理与系统其他组件之间的桥梁，确保代理可以安全有效地执行任务，同时管理系统资源。</p>\n<p><code>AgentController</code>作为主要状态管理模块，</p>\n<ul>\n<li>根据<code>Observation</code>事件进行状态变换</li>\n<li>根据<code>Action</code>进行状态变换和以下处理：\n<ul>\n<li>对于<code>MessageAction</code>发送<code>RecallAction</code>到事件流中</li>\n<li>对于<code>AgentDelegateAction</code>做Agent路由（后续机制解读中再详细介绍）</li>\n</ul>\n</li>\n<li>根据当前的<code>event</code>判断进行调用<code>agent.step</code></li>\n</ul>\n<pre><code class=\"language-python\">    controller, initial_state = create_controller(\n        agent, runtime, config, conversation_stats, replay_events=replay_events\n    )\n\n</code></pre>\n<p>create_controller代码如下。</p>\n<pre><code class=\"language-python\">def create_controller(\n    agent: Agent,\n    runtime: Runtime,\n    config: OpenHandsConfig,\n    conversation_stats: ConversationStats,\n    headless_mode: bool = True,\n    replay_events: list[Event] | None = None,\n) -&gt; tuple[AgentController, State | None]:\n    event_stream = runtime.event_stream\n    initial_state = None\n    initial_state = State.restore_from_session(\n            event_stream.sid, event_stream.file_store)\n    controller = AgentController(\n        agent=agent,\n        conversation_stats=conversation_stats,\n        iteration_delta=config.max_iterations,\n        budget_per_task_delta=config.max_budget_per_task,\n        agent_to_llm_config=config.get_agent_to_llm_config_map(),\n        event_stream=event_stream,\n        initial_state=initial_state,\n        headless_mode=headless_mode,\n        confirmation_mode=config.security.confirmation_mode,\n        replay_events=replay_events,\n        security_analyzer=runtime.security_analyzer,\n    )\n    return (controller, initial_state)\n\n\n</code></pre>\n<p>在 AgentController 的<code>__init__</code>中，会注册EventStreamSubscriber.AGENT_CONTROLLER。</p>\n<pre><code class=\"language-python\">        # subscribe to the event stream if this is not a delegate\n        if not self.is_delegate:\n            self.event_stream.subscribe(\n                EventStreamSubscriber.AGENT_CONTROLLER, self.on_event, self.id\n            )\n\n</code></pre>\n<h3 id=\"28-发送启动事件\">2.8 发送启动事件</h3>\n<p>发送一个启动事件MessageAction。</p>\n<pre><code class=\"language-python\">    # start event is a MessageAction with the task, either resumed or new\n    if initial_state is not None and initial_state.last_error:\n        # we're resuming the previous session\n        event_stream.add_event(\n            MessageAction(\n                content=(\n                    \"Let's get back on track. If you experienced errors before, do \"\n                    'NOT resume your task. Ask me about it.'\n                ),\n            ),\n            EventSource.USER,\n        )\n    else:\n        # init with the provided actions\n        event_stream.add_event(initial_user_action, EventSource.USER)\n\n</code></pre>\n<h3 id=\"29-订阅事件流注册用户输入回调函数\">2.9 订阅事件流：注册用户输入回调函数</h3>\n<p>把自己注册为 EventStreamSubscriber.MAIN。</p>\n<pre><code class=\"language-python\">    def on_event(event: Event) -&gt; None:\n        if isinstance(event, AgentStateChangedObservation):\n            if event.agent_state == AgentState.AWAITING_USER_INPUT:\n                if exit_on_message:\n                    message = '/exit'\n                elif fake_user_response_fn is None:\n                    message = read_input(config.cli_multiline_input)\n                else:\n                    message = fake_user_response_fn(controller.get_state())\n                action = MessageAction(content=message)\n                event_stream.add_event(action, EventSource.USER)\n\n    event_stream.subscribe(EventStreamSubscriber.MAIN, on_event, sid)\n\n    end_states = [\n        AgentState.FINISHED,\n        AgentState.REJECTED,\n        AgentState.ERROR,\n        AgentState.PAUSED,\n        AgentState.STOPPED,\n    ]\n\n</code></pre>\n<p>几个模块的初始化范式基本一致，在<code>__init__</code>函数中完成模块的初始化准备工作，并且向事件流中订阅消息并注册各自模块的消息处理函数。事件回调函数会根据当前的事件进行状态机的状态转移。</p>\n<ul>\n<li>Runtime 在事件流中订阅 EventStreamSubscriber.RUNTIME，事件回调函数会处理需要runtine处理的action，比如mcp/tool等等。</li>\n<li>Memory 在事件流中订阅 EventStreamSubscriber.MEMORY。事件回调函数根据当前的<code>event</code>生成一个带<code>microagent_knowledge</code>的<code>Observation</code>并以<code>ENVIRONMENT</code>作为源添加回事件流中，这里的<code>microagent_knowledge</code>是一种特定提示词增强的方法。</li>\n<li>AgentController 在事件流中订阅 EventStreamSubscriber.AGENT_CONTROLLER。</li>\n<li>run_controller 在事件流中订阅 EventStreamSubscriber.MAIN。</li>\n</ul>\n<h3 id=\"210-运行代理\">2.10 运行代理</h3>\n<p>运行代理直到进入结束状态。</p>\n<pre><code class=\"language-python\">    try:\n        await run_agent_until_done(controller, runtime, memory, end_states)\n    except Exception as e:\n        logger.error(f'Exception in main loop: {e}')\n\n    # save session when we're about to close\n    if config.file_store is not None and config.file_store != 'memory':\n        end_state = controller.get_state()\n        # NOTE: the saved state does not include delegates events\n        end_state.save_to_session(\n            event_stream.sid, event_stream.file_store, event_stream.user_id\n        )\n\n    await controller.close(set_stop_state=False)\n\n</code></pre>\n<h3 id=\"211-run_controller全部代码\">2.11 run_controller全部代码</h3>\n<p>run_controller全部代码如下：</p>\n<pre><code class=\"language-python\">async def run_controller(\n    config: OpenHandsConfig,\n    initial_user_action: Action,\n    sid: str | None = None,\n    runtime: Runtime | None = None,\n    exit_on_message: bool = False,\n    fake_user_response_fn: FakeUserResponseFunc | None = None,\n    headless_mode: bool = True,\n    memory: Memory | None = None,\n    conversation_instructions: str | None = None,\n) -&gt; State | None:\n    \"\"\"主协程，用于运行代理控制器，支持灵活的任务输入。\n    仅在通过命令行直接启动 OpenHands 后端时使用。\n\n    参数:\n        config: 应用配置实例\n        initial_user_action: 包含初始用户输入的 Action 对象\n        sid: (可选) 会话 ID。重要提示：非必要请勿手动设置，\n             错误设置可能导致 RemoteRuntime 出现异常行为\n        runtime: (可选) 代理运行的运行时环境实例\n        exit_on_message: 当代理请求用户消息时退出（可选）\n        fake_user_response_fn: (可选) 接收当前状态并返回模拟用户响应的函数\n        headless_mode: 代理是否以无头模式运行\n\n    返回:\n        代理的最终状态；若发生错误则返回 None\n\n    异常:\n        AssertionError: 若 initial_user_action 不是 Action 实例\n        Exception: 执行过程中可能抛出各类异常，均会被记录日志\n\n    注意:\n        - 状态持久化：若配置了 config.file_store，代理状态将在会话间保存\n        - 执行轨迹：若配置了 config.trajectories_path，执行历史将以 JSON 格式保存用于分析\n        - 预算控制：执行受 config.max_iterations 和 config.max_budget_per_task 限制\n\n    示例:\n        &gt;&gt;&gt; config = load_openhands_config()\n        &gt;&gt;&gt; action = MessageAction(content=\"Write a hello world program\")\n        &gt;&gt;&gt; state = await run_controller(config=config, initial_user_action=action)\n    \"\"\"\n    # 若未提供会话ID，则生成一个\n    sid = sid or generate_sid(config)\n\n    # 创建 LLM 注册中心、对话统计实例，并处理配置\n    llm_registry, conversation_stats, config = create_registry_and_conversation_stats(\n        config,\n        sid,\n        None,\n    )\n\n    # 基于配置和 LLM 注册中心创建代理实例\n    agent = create_agent(config, llm_registry)\n\n    # 运行时创建后会自动连接并克隆选定的代码仓库\n    repo_directory = None\n    if runtime is None:\n        # 初始化代码仓库（如需）\n        repo_tokens = get_provider_tokens()\n        # 创建运行时实例\n        runtime = create_runtime(\n            config,\n            llm_registry,\n            sid=sid,\n            headless_mode=headless_mode,\n            agent=agent,\n            git_provider_tokens=repo_tokens,\n        )\n        # 同步调用异步的运行时连接方法\n        call_async_from_sync(runtime.connect)\n\n        # 初始化代码仓库（如需）\n        if config.sandbox.selected_repo:\n            repo_directory = initialize_repository_for_runtime(\n                runtime,\n                immutable_provider_tokens=repo_tokens,\n                selected_repository=config.sandbox.selected_repo,\n            )\n\n    # 从运行时获取事件流实例（组件间通信核心）\n    event_stream = runtime.event_stream\n\n    # 记忆系统创建后会从选定仓库加载微代理\n    if memory is None:\n        # 创建记忆系统实例\n        memory = create_memory(\n            runtime=runtime,\n            event_stream=event_stream,\n            sid=sid,\n            selected_repository=config.sandbox.selected_repo,\n            repo_directory=repo_directory,\n            conversation_instructions=conversation_instructions,\n            working_dir=str(runtime.workspace_root),\n        )\n\n    # 为代理添加 MCP 工具（若启用）\n    if agent.config.enable_mcp:\n        # 默认添加 OpenHands 的 MCP 服务器配置\n        _, openhands_mcp_stdio_servers = (\n            OpenHandsMCPConfigImpl.create_default_mcp_server_config(\n                config.mcp_host, config, None\n            )\n        )\n        runtime.config.mcp.stdio_servers.extend(openhands_mcp_stdio_servers)\n\n        # 异步将 MCP 工具添加到代理\n        await add_mcp_tools_to_agent(agent, runtime, memory)\n\n    # 加载回放事件（若启用轨迹回放）\n    replay_events: list[Event] | None = None\n    if config.replay_trajectory_path:\n        logger.info('Trajectory replay is enabled')\n        # 断言初始用户动作必须是空动作（回放场景）\n        assert isinstance(initial_user_action, NullAction)\n        # 从指定路径加载回放日志和初始用户动作\n        replay_events, initial_user_action = load_replay_log(\n            config.replay_trajectory_path\n        )\n\n    # 创建控制器和初始状态\n    controller, initial_state = create_controller(\n        agent, runtime, config, conversation_stats, replay_events=replay_events\n    )\n\n    # 断言初始用户动作必须是 Action 实例，否则抛出异常\n    assert isinstance(initial_user_action, Action), (\n        f'initial user actions must be an Action, got {type(initial_user_action)}'\n    )\n    # 记录调试日志：控制器初始化信息\n    logger.debug(\n        f'Agent Controller Initialized: Running agent {agent.name}, model '\n        f'{agent.llm.config.model}, with actions: {initial_user_action}'\n    )\n\n    # 发送启动事件（恢复会话或新会话）\n    if initial_state is not None and initial_state.last_error:\n        # 恢复之前的会话（存在历史错误）\n        event_stream.add_event(\n            MessageAction(\n                content=(\n                    \"Let's get back on track. If you experienced errors before, do \"\n                    'NOT resume your task. Ask me about it.'\n                ),\n            ),\n            EventSource.USER,\n        )\n    else:\n        # 新会话：添加初始用户动作到事件流\n        event_stream.add_event(initial_user_action, EventSource.USER)\n\n    # 定义事件回调函数：处理代理等待用户输入的场景\n    def on_event(event: Event) -&gt; None:\n        # 监听代理状态变更事件\n        if isinstance(event, AgentStateChangedObservation):\n            # 当代理进入等待用户输入状态时\n            if event.agent_state == AgentState.AWAITING_USER_INPUT:\n                if exit_on_message:\n                    # 需退出时发送 /exit 指令\n                    message = '/exit'\n                elif fake_user_response_fn is None:\n                    # 读取真实用户输入\n                    message = read_input(config.cli_multiline_input)\n                else:\n                    # 调用模拟用户响应函数\n                    message = fake_user_response_fn(controller.get_state())\n                # 创建消息动作并添加到事件流\n                action = MessageAction(content=message)\n                event_stream.add_event(action, EventSource.USER)\n\n    # 订阅事件流：注册 MAIN 订阅者和回调函数\n    event_stream.subscribe(EventStreamSubscriber.MAIN, on_event, sid)\n\n    # 定义代理结束状态列表\n    end_states = [\n        AgentState.FINISHED,\n        AgentState.REJECTED,\n        AgentState.ERROR,\n        AgentState.PAUSED,\n        AgentState.STOPPED,\n    ]\n\n    try:\n        # 运行代理直到进入结束状态\n        await run_agent_until_done(controller, runtime, memory, end_states)\n    except Exception as e:\n        # 记录主循环异常日志\n        logger.error(f'Exception in main loop: {e}')\n\n    # 关闭前保存会话（若配置文件存储）\n    if config.file_store is not None and config.file_store != 'memory':\n        end_state = controller.get_state()\n        # 注意：保存的状态不包含委托事件\n        end_state.save_to_session(\n            event_stream.sid, event_stream.file_store, event_stream.user_id\n        )\n\n    # 关闭控制器（不设置停止状态）\n    await controller.close(set_stop_state=False)\n\n    # 获取控制器最终状态\n    state = controller.get_state()\n\n    # 保存执行轨迹（若配置）\n    if config.save_trajectory_path is not None:\n        # 若路径是文件夹，则以会话ID为文件名\n        if os.path.isdir(config.save_trajectory_path):\n            file_path = os.path.join(config.save_trajectory_path, sid + '.json')\n        else:\n            file_path = config.save_trajectory_path\n        # 创建目录（如需）\n        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n        # 获取执行轨迹历史\n        histories = controller.get_trajectory(config.save_screenshots_in_trajectory)\n        # 写入 JSON 文件\n        with open(file_path, 'w') as f:  # noqa: ASYNC101\n            json.dump(histories, f, indent=4)\n\n    # 返回最终状态\n    return state\n\n</code></pre>\n<h2 id=\"0xff-参考\">0xFF 参考</h2>\n<p><a href=\"https://docs.all-hands.dev/openhands/usage/architecture/backend\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.all-hands.dev/openhands/usage/architecture/backend</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1936485868761257658\" rel=\"noopener nofollow\" target=\"_blank\">当AI Agent从“玩具”走向“工具”，我们该关注什么？Openhands架构解析【第二篇：Agent 相关核心概念】</a>  <a href=\"https://www.zhihu.com/people/dreamrenderx\" rel=\"noopener nofollow\" target=\"_blank\">克里</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1936175201323825087\" rel=\"noopener nofollow\" target=\"_blank\">当AI Agent从“玩具”走向“工具”，我们该关注什么？Openhands架构解析【第一篇：系列导读】</a> <a href=\"https://www.zhihu.com/people/dreamrenderx\" rel=\"noopener nofollow\" target=\"_blank\">克里</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1940436682949244630\" rel=\"noopener nofollow\" target=\"_blank\">Coding Agent之Openhands解析(含代码)</a>  <a href=\"https://www.zhihu.com/people/wu-long-ming-cha-56\" rel=\"noopener nofollow\" target=\"_blank\">Arrow</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1940824548485347192\" rel=\"noopener nofollow\" target=\"_blank\">OpenHands 源码解读</a>  <a href=\"https://www.zhihu.com/people/xiao-hui-66-72\" rel=\"noopener nofollow\" target=\"_blank\">一力辉</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 20:55</span>&nbsp;\n<a href=\"https://www.cnblogs.com/rossiXYZ\">罗西的思考</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "并查集及其应用专题--全网最详细版",
      "link": "https://www.cnblogs.com/hicode002/p/-/union_set",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/hicode002/p/-/union_set\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 19:57\">\n    <span>并查集及其应用专题--全网最详细版</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"并查集\">并查集</h1>\n<p>并查集是用来查找和合并集合关系的<br />\n这个集合必须是不交集<br />\n支持查找和合并两种操作，修改后可以支持删除单个元素并分离集合。<br />\n使用动态开点线段树还可以实现可持久化并查集</p>\n<p>来自 <a href=\"https://oi-wiki.org/ds/dsu/\" rel=\"noopener nofollow\" target=\"_blank\">https://oi-wiki.org/ds/dsu/</a></p>\n<p>并查集类似于树，普通并查集是无向的，但是加权并查集是可以做到有向的，详见NOI2001食物链</p>\n<h2 id=\"查找操作查找两个元素是否在同一集合\">查找操作：查找两个元素是否在同一集合</h2>\n<p>假设有一个集合，元素是{1,2,3}<br />\n还有一个集合元素是{4,5,6}<br />\n现在查找2和4在不在同一个集合，则需要枚举2所在或4所在集合所有元素直到找到4或到最后也没有4<br />\n太慢了，有一个更好的方法，如果我们随便选一个集合中的某个元素作为该集合的代表元素，<br />\n其它该集合中的元素都指向这个元素<br />\n当查找元素所在集合时，只要找到这个元素的指向的元素的最顶级元素即根，这个根就是代表节点<br />\n最后判断这两个元素的根是否相同即可<br />\n这里遇到一个问题，就是这个根元素怎么标记呢，可以让它所指向的元素是自己，这样询问时只要遇到指向元素是自己的元素，那么说明找到根了，即可停止<br />\n我们把这个指向的元素叫做这个元素的父亲<br />\n注意树不只有两层，因为在合并操作时集合被合并，原先两个集合的根中有一个变成了子节点，此时层数会增加，而这个代表元素是整棵树的根，这个点的父亲只是它的原来的集合的根，因为集合已经合并，所以判断两个元素是否在同一集合中时要用整棵树的根，因此要递归寻找这个元素的父亲直到元素的父亲是自身时停止寻找并返回该元素。当然这个过程可以循环解决，只需要定义临时变量为该元素的父亲，然后这个变量不断等于这个变量的父亲，直到其父亲等于自身为止，然后返回该变量即可<br />\n举例：<br />\n假设集合1以3为根，集合2以6为根，则<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162032821-1549875642.png\" /><br />\n2和4的根分别是3和6，不等，所以不在一个集合<br />\n1和3的根分别是3和3，相等，所以在一个集合。</p>\n<h2 id=\"合并操作\">合并操作：</h2>\n<p>把两个元素 所在集合 合并为一个集合，合并后两个集合等同于在一个大集合中，此时一个元素所在集合的根要变成子节点，另一个作为大集合的根。<br />\n如何合并：<br />\n很简单，先查找两个元素的根，然后把一个根的父亲改为另一个根，这样就完成了合并 ，但是如果两个元素的根相同说明在一个集合就直接返回不用合并<br />\n例：<br />\n以查找时为例<br />\n合并前：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162032821-1549875642.png\" /><br />\n假设新根是6<br />\n合并后：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162149379-1024618492.png\" /><br />\n再查找2和4：<br />\n2的父亲是3，3的父亲是6，6的父亲是6<br />\n4的父亲是6<br />\n在一个集合<br />\n注意合并时要把一个根直接接到另一个根上，而不是接到子节点上！！</p>\n<h2 id=\"路径压缩\">路径压缩</h2>\n<p>在查找时我们不关心这个元素的父亲，只要这个元素通过找父亲能找到根即可，所以每次查找后把查找的这条链上的元素的父亲直接改为根，这样不影响查找，而且减少以后查找的次数（减小树高）<br />\n递归时只要返回时return fa[x]=find(fa[x])即可，这样会递归到最后找到根把父亲从上往下回溯着改<br />\n循环法要找到根后再开一个循环，先让循环变量=它的父亲，然后把它的父亲改为根，直到 父亲=父亲 时停止（到根了），这是自下往上的。<br />\n但是一次只能保证这条链上的，不能是全树都改好，所以后面删除元素时比较麻烦</p>\n<h2 id=\"按秩合并启发式合并\">按秩合并：(启发式合并）</h2>\n<p>在合并时我们要将其中一个元素所在集合的根变为子节点，另一个变为新根，可是哪一个变为子节点呢？<br />\n显然将尺寸小的接到尺寸大的集合上更好，这样查找大的时还是那个复杂度，可反之要花更多的时间，但是尺寸小的集合造成影响小，所以要把尺寸小的接到尺寸大的集合上<br />\n但是尺寸是什么呢？<br />\n尺寸既可以是一个集合的元素个数即点数，也可以是树的高度，它们优化的效果是等价的<br />\n如果以点数为尺寸，那么合并时把点数小的根父亲等于点数大的根，点数大的根的点数+=点数小的根的点数，这个叫做启发式合并，其他数据结构也常用<br />\n如果以高度为尺寸，那么合并时把高度小的根父亲等于高度大的根，但是高度不变，为什么？ 这个叫做按秩合并，不是很常用<br />\n只要a的高度小于b，因为高度是整数，所以a的高度比b至少少一，把a接到b的下面，此时这个高度不能超过b<br />\n什么时候高度改变？当a和b高度相等时，可以随便接，但是无论怎么接高度都增加1<br />\n假如a接在b下面，那么b的这个子树的高度为b，而b的其他子树中最大的高度是b-1，因此b的高度变为b+1!</p>\n<h2 id=\"复杂度\">复杂度：</h2>\n<p><span class=\"math inline\">\\(n\\)</span>个元素，<span class=\"math inline\">\\(m\\)</span>次操作（查找或合并）<br />\n空间复杂度：<br />\n由于每个元素都有一个父亲，所以<span class=\"math inline\">\\(fa\\)</span>数组大小是<span class=\"math inline\">\\(n\\)</span>，故空间复杂度<span class=\"math inline\">\\(O（n）\\)</span><br />\n时间复杂度：<br />\n既使用路径压缩，又使用按秩合并:<br />\n每个操作平均时间复杂度<span class=\"math inline\">\\(O(α(n))\\)</span><br />\n<span class=\"math inline\">\\(α\\)</span>是反阿克曼函数，近似于常数</p>\n<p>总操作平均复杂度<span class=\"math inline\">\\(O(mα(n))\\)</span><br />\n只使用路径压缩：<br />\n总操作平均复杂度<span class=\"math inline\">\\(O(mα(n))\\)</span><br />\n总操作最坏复杂度<span class=\"math inline\">\\(O(m log⁡n )\\)</span><br />\n只使用按秩合并：<br />\n总操作平均复杂度<span class=\"math inline\">\\(O(m log⁡n )\\)</span></p>\n<h2 id=\"删除操作\">删除操作：</h2>\n<p>修改后的并查集支持单个元素的删除<br />\n但是需要注意的是删除不是说删除这个点和这个点所连的点，而是仅仅删除这个点，其余与他相连的点仍然在原并查集中，但这个点独立成一个集合<br />\n在完美形态的并查集中，每个节点的父亲都是根，此时删除一个节点就是把这个节点的父亲改为自己，这样不影响其他节点，但是实际上路径压缩只能将这条链上的节点的父亲改为根，所以实际并查集形态不可估计<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162414092-577349486.png\" /><br />\n删除2后<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162431589-133329972.png\" /><br />\n那么我们可以用盒子来代替这个真正的节点去合并，而我们真正的每一个节点都指向每一个盒子<br />\n详细：<br />\n每一个节点都对应一个盒子，每个节点的父亲起初都是对应的一个新盒子<br />\n当我们合并集合时，我们只合并节点指向的盒子的所在集合，仍然符合按秩合并<br />\n当我们删除时把节点的父亲改为一个新的，从未使用过的盒子，原盒子保持空，这样原来集合的关系可以通过这个空盒子保留<br />\n当我们查找时查找节点所在盒子的根<br />\n仍然可以用路径压缩<br />\n一旦这个节点被删除，就到了新盒子，此时这个节点和原来的集合并不在一个集合中，所以删除有效<br />\n删除的节点再和别的节点合并改变的是它新盒子的集合<br />\n与原来集合无关<br />\n还可以有还原操作，就是删除后把这个节点还原到它最近被删除的集合中，显然可以再合并 ，但也可以数组记录每个节点上一次被删除的盒子编号，然后把这个节点的指向改为上一次被删除的盒子编号，这样就完全还原上一次这个节点的形态，不需要合并了</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\nusing namespace std;\nint fa[10006],fa1[90006],t=10007,lasts[10006];\t\ninline int finds(int x ){\n\tif(fa1[x]==x)return x;\n\treturn fa1[x]=finds(fa1[x]);\n}\ninline void inserts(int x,int y){\n\tint a=finds(x),b=finds(y);\n\tif(a==b)return;\n\tfa1[a]=b;\n}\ninline void deletes(int x){\n\tlasts[x]=fa[x];\n\tfa[x]=t;\n\t++t;\n}\ninline void restore(int x){\n\tfa[x]=lasts[x];\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(lasts,0,sizeof lasts);\n\tfor(int i=0;i&lt;90006;++i){\n\t\tfa1[i]=i;\n\t}\n\tint m;\n\tcin&gt;&gt;m;\n\tfor(int i=0;i&lt;m;++i){\n\t\tchar op ;int x,y;\n\t\tcin&gt;&gt;op;\n\t\tif(op=='U'){\n\t\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\t\tif(fa[x]==-1)fa[x]=x;\n\t\t\tif(fa[y]==-1)fa[y]=y;\n\t\t\tinserts(fa[x],fa[y]);\n\t\t\t\n\t\t}else if(op=='F'){\n\t\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\t\tif(fa[x]==-1)fa[x]=x;\n\t\t\tif(fa[y]==-1)fa[y]=y;\n\t\t\tif(finds(fa[x])!=finds(fa[y])){\n\t\t\t\tcout&lt;&lt;0&lt;&lt;endl;\n\t\t\t}else{\n\t\t\t\tcout&lt;&lt;1&lt;&lt;endl;\n\t\t\t}\n\t\t}else if(op=='D'){\n\t\t\tcin&gt;&gt;x;\n\t\t\tdeletes(x);\n\t\t}else{\n\t\t\tcin&gt;&gt;x;\n\t\t\trestore(x);\n\t\t}\n\t}\n\treturn 0;\n}\n</code></pre>\n<h2 id=\"带权并查集\">带权并查集：</h2>\n<p>本质是并查集的向量拓展<br />\n把树看成dag图，每个元素的权值记录的是它和它父亲之间的边权，主要记录的是一种关系，这里是一些普通的数字，但在实际问题中边权往往是一些关系，最后可能还要取模<br />\n目的是利用路径压缩求出元素到根节点的边权和，然后给定任意两个元素求出这两个元素之间的某些关系（与根有关的和差）<br />\n假设权值数组为<span class=\"math inline\">\\(w\\)</span><br />\n路径压缩时可以先递归找根并存储，然后把w[x]+=w[fa[x]]，最后把fa[x]改成根<br />\n因为是递归，所以会先找到根，然后回溯像前缀和一样层层加，直到加到当前元素为止，此时w[x]就为x到根节点的权值和，同时这条链上的元素都把权值改了<br />\n但是重点在合并<br />\n合并两个元素x，y所在集合，其中x，y两个元素之间权值为有向值s（把x合并到y或把y合并到x）<br />\n由于x到y和y到x只需调换顺序即可，所以只考虑x到y<br />\n假如x的根是px，，y的根是py，省略中间的链，因为路径压缩时会改，问题在于x到y的权值明确，x到px的权值明确，y到py的权值明确，但是px到py就不知道了<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162708674-1940796842.png\" /><br />\n可以辅助线来解决<br />\n先求x到py，这里x到y和y到py等价于x到py，所以x到py权值用向量加法为s+v2<br />\n同理，x到py又等于v1+px到py<br />\n所以px到py=s+v2-v1<br />\n这是个抽象问题，这里加的是向量，而不是向量的模，很懵逼<br />\n但是实际问题往往要取模或者是压根再开一个数组，详见NOI2002银河英雄传说<br />\n基础操作就是这些，还有一些例题</p>\n<h3 id=\"hdu-3038-how-many-answers-are-wrong\">HDU-3038-How Many Answers Are Wrong</h3>\n<p>来自 <a href=\"https://blog.csdn.net/yjr3426619/article/details/82315133\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/yjr3426619/article/details/82315133</a></p>\n<p>有M个数，不知道它们具体的值，但是知道某两个数之间（包括这两个数）的所有数之和，现在给出N个这样的区间和信息，需要判断有多少个这样的区间和与前边已知的区间和存在矛盾。例如给出区间和<span class=\"math inline\">\\([1,4]\\)</span>为20，<span class=\"math inline\">\\([3,4]\\)</span>为15，再给出<span class=\"math inline\">\\([1,2]\\)</span>为30，显然这个<span class=\"math inline\">\\([1,2]\\)</span>的值就有问题，它应该为20-15=5。<br />\n由于不知道每句区间是否正确，所以要根据先前的正确的区间来推出这个区间，如果推不出就是对的，因为是新的，如果推出了，若题目给的与之前的正确的区间推出的区间的值相等就说明正确，可以忽略，若不相等，则不正确，也忽略，留下正确的值<br />\n注意不相等是唯一矛盾的时候，<span class=\"math inline\">\\([1,10]=50\\)</span>  ,<span class=\"math inline\">\\([1,5]=100\\)</span>这看起来不对，但实际上题目没说每个数是正数，所以这也是对的，可能<span class=\"math inline\">\\([6,10]=-50\\)</span><br />\n我们想到区间的合并，很像并查集<br />\n但是这是个闭区间，没有公共点，我们需要半开半闭区间，不能全开区间，这样<span class=\"math inline\">\\([1,4]=(0,5)\\)</span>   <span class=\"math inline\">\\([3,4]=(2,5)\\)</span>   <span class=\"math inline\">\\([1,2]=(0,3)\\)</span>，没有公共点<br />\n常见左闭右开区间，这样<span class=\"math inline\">\\([1,4]=[1,5)\\)</span>  <span class=\"math inline\">\\([1,2]=[1,3)\\)</span>   <span class=\"math inline\">\\([3,4]=[3，5)\\)</span><br />\n可以把1 3和3 5合成1 5<br />\n所以要先改区间<br />\n然后就可以用并查集了。<br />\n看图：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163306555-1040943616.png\" /><br />\n这两种都是对的<br />\n都是向量的加法<br />\n第一种以5为根，合并时并没有真正1 3连边和求值，要 求 1 3时只需要用1 5的和减去3 5的和即可<br />\n第二种以1为根，合并时用公式s+v2-v1，因为3是孤立点，所以v2=0，即s-v1，这就算出了1 3<br />\n然后求1 3的和用1 3的和 减去 1 1的和即可<br />\n由此可见询问区间x y时是sum x  -  sum y还是反过来完全取决于合并时把x的集合并到y还是把y的集合并到x，如果x-》y就sum x  -sum y<br />\n如果y-》x就sum y -sum x<br />\n所以不能启发式合并<br />\n那么什么时候算不出x y的和？<br />\n当区间两个端点在一个集合时说明两个sum可以用向量求，而不在一个集合时求不出，因为两个集合没有交集，中间的数不知道是多少<br />\n因此，思路如下：<br />\n读入区间<br />\n合并两个区间端点，若在一个集合中时公式算出和，比对给出的，不合法记录下来<br />\n不在一个集合时认为这个和是对的，把这两个合并，以这个和为权值<br />\n合并时用基本向量公式<br />\n若x-&gt;y就用w(x,y)+w（y,py)-w(x,px)<br />\n若y-&gt;x就用w(x,y)+w(x,px)-w(y,py)<br />\npx就是x的根<br />\nw就是之间的和<br />\n初始化把w数组置为0，即使是根节点到自身也满足上面的公式<br />\n把fa【i】=i不要等于-1，容易出错</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\nusing namespace std;\nint fa[2000003],v[2000003];\ninline int find(int x){\n\tif(fa[x]==x)return x;\n\tint k=find(fa[x]);\n\tv[x]+=v[fa[x]];\n\tfa[x]=k;\n\treturn k;\n}\ninline void inserts(int x,int y,int a,int b,int z){\n\tfa[a]=b;\n\tv[a]=z+v[y]-v[x];\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(v,0,sizeof v);\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tint cnt=0;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y,z;\n\t\tcin&gt;&gt;x&gt;&gt;y&gt;&gt;z;\n\t\ty=y+1;//闭区间改成开区间 \n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=find(x),b=find(y);\t\n\t\tif(a!=b){\n\t\t\tinserts(x,y,a,b,z);\n\t\t}else{\n\t\t\tif(v[x]-v[y]!=z)cnt++;\n\t\t}\n\t}\n\tcout&lt;&lt;cnt&lt;&lt;endl;\n\treturn 0;\n}\n\n</code></pre>\n<p>另一个例题：</p>\n<h3 id=\"hihocoder-1515-分数调查\">HihoCoder-1515-分数调查</h3>\n<p>描述<br />\n小Hi的学校总共有N名学生，编号1-N。学校刚刚进行了一场全校的古诗文水平测验。</p>\n<p>学校没有公布测验的成绩，所以小Hi只能得到一些小道消息，例如X号同学的分数比Y号同学的分数高S分。</p>\n<p>小Hi想知道利用这些消息，能不能判断出某两位同学之间的分数高低？</p>\n<p>输入<br />\n第一行包含三个整数N, M和Q。N表示学生总数，M表示小Hi知道消息的总数，Q表示小Hi想询问的数量。</p>\n<p>以下M行每行三个整数，X, Y和S。表示X号同学的分数比Y号同学的分数高S分。</p>\n<p>以下Q行每行两个整数，X和Y。表示小Hi想知道X号同学的分数比Y号同学的分数高几分。</p>\n<p>对于50%的数据，$1 &lt;= N, M, Q &lt;= 1000 $</p>\n<p>对于100%的数据，<span class=\"math inline\">\\(1 &lt;= N, M, Q&lt;= 100000 1 &lt;= X, Y &lt;= N -1000 &lt;= S &lt;= 1000\\)</span></p>\n<p>数据保证没有矛盾。</p>\n<p>输出<br />\n对于每个询问，如果不能判断出X比Y高几分输出-1。否则输出X比Y高的分数。</p>\n<p>样例输入</p>\n<p>10 5 3<br />\n1 2 10<br />\n2 3 10<br />\n4 5 -10<br />\n5 6 -10<br />\n2 5 10<br />\n1 10<br />\n1 5<br />\n3 5<br />\n样例输出</p>\n<p>-1<br />\n20<br />\n0</p>\n<p>分析一下：<br />\n考虑传递性和向量性<br />\n显然是图，x比y高可以x-》y连一条边，权值是x比y高的分数<br />\n看图：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163431046-1074997319.png\" /><br />\n3比2高3分，2比1高5分，所以3比1高8分<br />\n具有传递性</p>\n<p>向量合并：<br />\n对于1比2高8分<br />\n3比4高3分<br />\n1比3高3分<br />\n则1比4高6分<br />\n则2比4高-2分<br />\n注意当x比y低时就是x比y高y比x高的分数的相反数<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163544199-37076875.png\" /><br />\n具有向量性<br />\n因此可以用并查集<br />\n那么怎么由x到根节点权值和y到根节点权值推出x比y高的分呢?<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163601865-836423128.png\" /><br />\n即w【x】-w【y】<br />\n什么时候无解呢？<br />\n当x与y在一个并查集时可以根据根节点来求x与y的权值，当x与y不在一个并查集时不能得出x到y的权值，<br />\n如：<br />\n1比2高3分，3比4高2分，无法求出2比3高的分数<br />\nw数组代表x比x的父亲高的分数<br />\n路径压缩时统计和，得知x到根的权值<br />\n合并时同样不能启发式合并，要把x合并到y<br />\n向量法计算合并后的权值<br />\n合并x和y所在集合<br />\n询问时先判断x与y是否在一个并查集，是输出w[x]-w[y]<br />\n不是输出-1!</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\n\nusing namespace std;\nint fa[100003],v[100003];\ninline int find(int x){\n\tif(fa[x]==x)return x;\n\tint k=find(fa[x]);\n\tv[x]+=v[fa[x]];\n\treturn fa[x]=k;\n}\ninline void inserts(int a,int b,int x,int y,int z){\n\tfa[a]=b;\n\tv[a]=z+v[y]-v[x];\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(v,0,sizeof v);\n\tint n,m,q;\n\tcin&gt;&gt;n&gt;&gt;m&gt;&gt;q;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y,k;\n\t\tcin&gt;&gt;x&gt;&gt;y&gt;&gt;k;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=find(x),b=find(y);\n\t\tif(a!=b){\n\t\t\tinserts(a,b,x,y,k);\n\t\t}\n\t}\n\tfor(int i=0;i&lt;q;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n//\t\tcout&lt;&lt;9;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\t//这里注意可能x和y还没出现过，所以要检验-1，因为-1做下标会re \n\t\tint g=find(x),f=find(y);\n\t\tif(g!=f){\n\t\t\tcout&lt;&lt;-1&lt;&lt;endl;\n\t\t}else{\n\t\t\tcout&lt;&lt;v[x]-v[y]&lt;&lt;endl;\n\t\t}\n\t\t\n\t}\n\treturn 0;\n}\n</code></pre>\n<h2 id=\"种类并查集\">种类并查集：</h2>\n<p>当我们在维护一些复杂的传递关系时，普通的并查集无法满足需求<br />\n维护朋友的朋友是朋友，敌人的敌人是朋友，<br />\n异性的异性是同性<br />\n<span class=\"math inline\">\\(a\\)</span>吃<span class=\"math inline\">\\(b\\)</span> <span class=\"math inline\">\\(b\\)</span>吃<span class=\"math inline\">\\(c\\)</span> 则<span class=\"math inline\">\\(c\\)</span>吃<span class=\"math inline\">\\(a\\)</span><br />\n这种具有反向传递性的关系时，可以用加权并查集<br />\n当然很复杂<br />\n于是有一种占空间更大但是简单的种类并查集<br />\n我们可以根据关系的数目确定出要把fa数组开一定的倍数<br />\n然后把这个数组分成几类，用来维护反向传递性<br />\n洛谷P1525 关押罪犯</p>\n<p>来自 <a href=\"https://zhuanlan.zhihu.com/p/97813717\" rel=\"noopener nofollow\" target=\"_blank\">https://zhuanlan.zhihu.com/p/97813717</a></p>\n<p>团伙<br />\n食物链<br />\n异性问题<br />\n这是最简单的<br />\n因为只有男和女两种<br />\n当a和b同性b和c同性时a和c同性，这是基础并查集的合并<br />\n当a和b异性b和c异性时a和c同性<br />\n当a和b同性b和c异性则a和c异性<br />\n后两个具有反向传递性<br />\n这里我们fa多开一倍数组<br />\n我们假定<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(a+n\\)</span>为异性，<span class=\"math inline\">\\(n\\)</span>是正常开的数组大小<br />\n所以当<span class=\"math inline\">\\(a\\)</span>为<span class=\"math inline\">\\(n-1\\)</span>时<span class=\"math inline\">\\(a+n=2n-1\\)</span>，因此需要开两倍数组<br />\n当<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>是同性时，我们可以合并<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>所在集合，因为都是同性<br />\n还可以合并<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>所在集合，因为<span class=\"math inline\">\\(a+n\\)</span>是与<span class=\"math inline\">\\(a\\)</span>异性的，<span class=\"math inline\">\\(b+n\\)</span>是与<span class=\"math inline\">\\(b\\)</span>异性的，当<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>同性时，<span class=\"math inline\">\\(a\\)</span>的异性和<span class=\"math inline\">\\(b\\)</span>的异性是同性<br />\n而<span class=\"math inline\">\\(a+n\\)</span>里的所有元素全是一个性别<br />\n<span class=\"math inline\">\\(b+n\\)</span>也是<br />\n所以可以合并<br />\n当<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>异性时<br />\n那么把<span class=\"math inline\">\\(a\\)</span>的异性和<span class=\"math inline\">\\(b\\)</span>合并，把<span class=\"math inline\">\\(b\\)</span>的异性和<span class=\"math inline\">\\(a\\)</span>合并<br />\n即合并<span class=\"math inline\">\\(a+n,b\\)</span>      ;   <span class=\"math inline\">\\(b+n,a\\)</span><br />\n因为<span class=\"math inline\">\\(a\\)</span>的异性肯定和<span class=\"math inline\">\\(b\\)</span>同性<br />\n<span class=\"math inline\">\\(b\\)</span>的异性肯定和<span class=\"math inline\">\\(a\\)</span>同性</p>\n<p>为什么这样可以做到那三条？<br />\n第一条显然满足<br />\n第三条<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>同性则<span class=\"math inline\">\\(a,b\\)</span>    <span class=\"math inline\">\\(a+n,b+n\\)</span>分别在一个并查集，<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c\\)</span>异性则<span class=\"math inline\">\\(b+n  ,c\\)</span>           <span class=\"math inline\">\\(c+n,b\\)</span>分别在一个并查集，所以<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(c\\)</span>     <span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c+n\\)</span>分别在一个并查集，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c\\)</span>不在一个并查集，所以<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c\\)</span>是异性<br />\n第二条比较复杂<br />\n<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>是异性时<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>不在一个并查集，但是<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(a+n\\)</span>，，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>分别都在一个并查集<br />\n<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c\\)</span>异性时<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c\\)</span>不在一个并查集，但是<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c+n\\)</span> ，，<span class=\"math inline\">\\(c\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>分别在一个并查集<br />\n所以<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(c+n\\)</span>在一个并查集，，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c\\)</span>也在一个并查集<br />\n所以<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(c+n\\)</span>,,,<span class=\"math inline\">\\(a\\)</span>,<span class=\"math inline\">\\(c\\)</span>分别在一个并查集<br />\n即它们分别同性<br />\n所以第二条满足</p>\n<p>那么查找时问<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>同性还是异性只需要看：<br />\n<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>在一个并查集时说明是同性，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>不在一个并查集时若<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>同性<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>就是异性（就两种性别）<br />\n注意<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>不在一个并查集不能说明是异性<br />\n因为如1 2同性<br />\n3 4同性<br />\n再说2 3同性，2和3<br />\n不在一个并查集中，而2的异性集合中没有3，所以2 3同性这是对的</p>\n<p>但是原题：<br />\n每次给出两个昆虫的关系（异性关系），然后发现这些条件中是否有悖论</p>\n<p>来自 <a href=\"https://blog.csdn.net/sunmaoxiang/article/details/80959300?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/sunmaoxiang/article/details/80959300?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control</a></p>\n<p>所以要动态判断<br />\n当输入<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>后<br />\n若<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>有一个没有初始化就先初始化（<span class=\"math inline\">\\(a，b，a+n，b+n\\)</span>中没有初始化的都要初始化）然后把<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>按照前面的规则合并<br />\n然后这个数据是对的</p>\n<p>若<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>已经初始化也不能说明它们的关系已经确定，如上面的例子，此时判断<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>关系是否与输入的相符，若相符就是对的，若不符就是不对的，就跳过。若不在一个并查集中且<span class=\"math inline\">\\(a\\)</span>的异性和<span class=\"math inline\">\\(b\\)</span>也不在一个并查集中关系就未确定，此时<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>的关系再合并，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>的关系是对的<br />\n这时路径压缩和按秩合并都可以用</p>\n<pre><code>#include&lt;iostream&gt; \n#include&lt;cstdio&gt; \n#include&lt;cstring&gt;\nusing namespace std;\nint fa[200002];\ninline int find(int x){\n\tif(fa[x]==x)return x;\n\treturn fa[x]=find(fa[x]);\n}\ninline void inserts(int x,int y){\n\tint a=find(x),b=find(y);\n\tif(a==b)return;\n\tfa[a]=b;\n}\nint main(){\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tmemset(fa,-1,sizeof fa);\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=find(x),b=find(y);\n\t\tif(a==b)cout&lt;&lt;\"N\"&lt;&lt;endl;\n\t\telse{\n\t\t\tif(fa[y+n]==-1)fa[y+n]=y+n;//注意y+n x+n可能没用过，所以要先初始化 \n\t\t\tif(fa[x+n]==-1)fa[x+n]=x+n;\n\t\t\tinserts(x,y+n);\n\t\t\tinserts(x+n,y);\n\t\t\tcout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t}\n\t}\n\treturn 0;\n} \n</code></pre>\n<p>再用加权并查集做一下：<br />\nw数组记录x到x父亲的关系（1异性 0同性）<br />\n路径压缩时求和，但是要取模2<br />\n为什么？<br />\n有1号 2号 3号<br />\n成链状，现在把3路径压缩，使得w【3】是1与3的关系<br />\n1与2同性且2与3同性时：w[1]=0   w[2]=0       w[3]=0      w[3new]=w[1]+w[2]+w[3]=0  0%2=0      满足1 3同性<br />\n1与2同性且2与3异性时  w[1]=0  w[2]=0  w[3]=1   w[3new]=w[1]+w[2]+w[3]=1  1%2=1  满足1 3异性<br />\n1与2异性且2与3同性时w[1]=0  w[2]=1  w[3]=0   w[3new]=w[1]+w[2]+w[3]=1   1%2=1  满足1 3异性<br />\n1与2异性且2与3异性时最重要  w[1]=0  w[2]=1  w[3]=1  w[3new]=w[1]+w[2]+w[3]=2  2%2=0   满足异性的异性是同性<br />\n可见在压缩求和时可以顺便%2，这样最后的关系是正确的，实际上这是分了两类，所以%2</p>\n<p>然后合并，同样不能按秩合并<br />\n向量法<br />\n具有向量性，但要取模<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124164323599-1904309385.png\" /><br />\n由此可见，我们把y连到x的向量公式<span class=\"math inline\">\\(w[py]=w(x,y)+w[x]-w[y]+2\\)</span>再取模2即可，这样合并后px和py的关系是正确的<br />\n+2是为了防止<span class=\"math inline\">\\(w[x]\\)</span>与<span class=\"math inline\">\\(w(x,y)\\)</span>都是为0，而<span class=\"math inline\">\\(w[y]=1\\)</span>，会出现负数</p>\n<p>那么询问关系时怎么处理？<br />\n询问<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系<br />\n当<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>在一个并查集时即<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系确定<br />\n当<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>不在一个并查集时<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系不确定，给出的这个关系是对的，然后合并<br />\n注意与种类并查集不同的是：<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>在一个并查集并不能说明x和y的关系是同性，只能说明它们有明确的关系，而同异性是根据权值数组w来确定的<br />\n当关系确定时<br />\n若<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的共同根节点是<span class=\"math inline\">\\(px\\)</span>，那么<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系就是$(w[x]-w[y]+2) \\mod 2 $<br />\n+2同样防止出现负数<br />\n如<span class=\"math inline\">\\(x\\)</span>到<span class=\"math inline\">\\(px\\)</span>是1，y到py是1<br />\n则<span class=\"math inline\">\\(x\\)</span>到<span class=\"math inline\">\\(y\\)</span>是1-1=0 0%2=0<br />\n符合要求<br />\n然后判断与给出的是否符合即可<br />\n注意初始化每个节点的w都是0，即根节点和它自己是同性，否则会造成问题。<br />\n注意这里给出<span class=\"math inline\">\\(x\\)</span> <span class=\"math inline\">\\(y\\)</span>时我们把<span class=\"math inline\">\\(y\\)</span>连向<span class=\"math inline\">\\(x\\)</span></p>\n<pre><code>#include&lt;iostream&gt;//x连接向y\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\nusing namespace std;\nint fa[1006],w[1006];\ninline int finds(int x){\n\tif(fa[x]==x)return x;\n\tint k=finds(fa[x]);\n\tw[x]=(w[x]+w[fa[x]])%2;\n\treturn fa[x]=k;\n}\ninline void inserts(int x ,int y,int a,int b,int z){\n\tfa[a]=b;\n\tw[a]=z+w[y]-w[x];\n\tw[a]=w[a]+2;\n\tw[a]=w[a]%2;\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(w,0,sizeof w);\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=finds(x),b=finds(y);\n\t\tif(a!=b){\n\t\t\tinserts(x,y,a,b,1);\n\t\t\tcout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t\t\n\t\t}else{\n\t\t\tif((w[y]-w[x]+2)%2==1){\n\t\t\t\tcout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t\t}else{\n\t\t\t\tcout&lt;&lt;\"N\"&lt;&lt;endl;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n</code></pre>\n<p>种类并查集可以维护敌人的敌人是朋友这样的关系，这种说法不够准确，较为本质地说，种类并查集（包括普通并查集）维护的是一种循环对称的关系。</p>\n<p>来自 <a href=\"https://zhuanlan.zhihu.com/p/97813717\" rel=\"noopener nofollow\" target=\"_blank\">https://zhuanlan.zhihu.com/p/97813717</a></p>\n<p>还有一类问题：<br />\n拆地毯</p>\n<p>修复公路   贪心<br />\n||<br />\n营救   贪心<br />\n这两道题等价，都是最大值的最小化<br />\n星球大战   倒推</p>\n<p>这些题都是些思维题，主要是倒推和贪心<br />\n拆地毯是星球大战和修复公路结合</p>\n<h2 id=\"并查集联通块数量统计\">并查集联通块数量统计</h2>\n<p>关于并查集联通块数量统计，首先要知道初始状态的联通块个数，然后每一次合并是若不在一个并查集则合并能使联通块数量减少<span class=\"math inline\">\\(1\\)</span>，若在一个并查集则没有贡献，切忌哈希统计<br />\n这指的是一个节点原先是独立的集合时。<br />\n但是如果是一个节点从原先不存在到出现并连边，联通块的数量要分类讨论<br />\n若这个点没有任何边将要和它相连，那么出现后联通块个数反而加一，，若这个节点出现并连第一条边，则联通块数量不变，因为节点出现相当于增加了一个联通块，连一条边合并后联通块减少了<span class=\"math inline\">\\(1\\)</span>，所以不变<br />\n若这个节点已经出现且连的不是第一条边，那么合并（当然不在一个集合时）后联通块数量减少<span class=\"math inline\">\\(1\\)</span>，因为此时这个节点已经在一个集合中了，若再与另一个集合连边，就会使得集合数目减少<span class=\"math inline\">\\(1\\)</span></p>\n<p>当遇到拆毁/彻底删除（连着点和边一起删除，破坏了集合关系）时，应该倒推，寻求全部<br />\n删除后的状态，然后倒着合并<br />\n当遇到移动集合元素，分离单一元素为独立集合（保持原来集合关系，只是那一个元素空了）时，应该用盒子来做，，即源节点指向盒子，对于合并与查找都是操作盒子，当移动或分离改变源节点指向的盒子，就可以保留原来集合关系，但是实现源节点的转移或分离。</p>\n<h2 id=\"并查集的另一种写法\">并查集的另一种写法</h2>\n<p>就是路径压缩 启发式合并  找父亲 使用了一个数组完成<br />\n当f【i】为负数时，说明这个节点是根节点，此时f[i]的值是这个根节点的树的节点个数的相反数<br />\n当f[i]为正数时，f[i]是i的父亲<br />\n这样查找x的根时，当f[x]&lt;0时返回x，是根节点，其余情况照常路径压缩return f[x]=find(f[x])<br />\n合并时x y先找根节点，如果根节点不同，那么就进行合并<br />\n设x的根为rx<br />\ny的根为ry<br />\n如果f[rx]&gt;f[ry]  就交换rx和ry<br />\n这样f[rx]一定&lt;=f[ry]<br />\n即-f[rx]&gt;=-f[ry]<br />\n此时rx的树的尺寸大小&gt;=ry的树的尺寸大小<br />\nrx做根<br />\nf[rx]+=f[ry]<br />\n更新rx的尺寸的相反数<br />\nf[ry]=rx<br />\n此时ry就指向了rx，做了儿子<br />\n这两步顺序不能错，因为在第二步之前f[ry]记录的是ry下的树尺寸的相反数，f[rx]+=f[ry]可以更新尺寸，而第二步是因为ry做了儿子，所以f[ry]成了ry的父亲，如果颠倒，那么f[rx]就可能变成正数从而误认为不是根节点</p>\n<p>理解：<br />\n对于两个集合的根节点rx，ry<br />\n它们的f已经计算好，是它们的树的尺寸的相反数，合并是通过比较这个尺寸来实现启发式 合并，然后假设rx做新根<br />\n那么rx的尺寸相反数自然要更新，加上ry的尺寸的相反数（都是负数），然后ry的f就变成了指向父亲的作用，ry的父亲是rx<br />\n查找时若x是根节点，f[x]不一定=-1，也有可能&lt;-1，代表的是尺寸的相反数，同时能说明找到了根节点<br />\n当f[x]&gt;0时说明f【x】是x的父亲，要继续递归并路径压缩<br />\n初始化时f[]要置为-1，代表每个树尺寸为1</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\n#include&lt;algorithm&gt;\nusing namespace std;\nint f[10006];\ninline int finds(const int&amp;x ){\n\tif(f[x]&lt;0)return x;\n\treturn f[x]=finds(f[x]);\n}\ninline void unions(const int&amp;x,const int &amp;y){\n\tint rx=finds(x);\n\tint ry=finds(y);\n\tif(rx==ry)return;\n\tif(f[rx]&gt;f[ry])swap(rx,ry);\n\tf[rx]+=f[ry];\n\tf[ry]=rx;\n\t\n}\nint main(){\n\tmemset(f,-1,sizeof f);\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tfor(int i=1;i&lt;=m;++i){\n\t\tint opt;\n\t\tcin&gt;&gt;opt;\n\t\tint x1,y1;\n\t\tcin&gt;&gt;x1&gt;&gt;y1;\n\t\tif(opt==1){\n\t\t\tunions(x1,y1);\n\t\t}else{\n\t\t\tint rx1=finds(x1);\n\t\t\tint ry1=finds(y1);\n\t\t\tif(rx1==ry1)cout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t\telse cout&lt;&lt;\"N\"&lt;&lt;endl;\n\t\t}\n\t}\n\treturn 0;\n}\n</code></pre>\n<hr />\n<h2 id=\"例题详解\">例题详解</h2>\n<h3 id=\"p1197-jsoi2008星球大战\">P1197 [JSOI2008]星球大战</h3>\n<p><a href=\"https://www.luogu.com.cn/problem/P1197\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1197</a></p>\n<p>特殊的倒推法<br />\n问题等价于<span class=\"math inline\">\\(n\\)</span>个节点<span class=\"math inline\">\\(m\\)</span>条无向边<br />\n然后拆掉一些点和它们相连的所有边，每拆一个点就输出联通块个数<br />\n暴力肯定超时<br />\n有合并且无向，可以用并查集<br />\n需要想一个特殊的方法<br />\n我们不拆点，这样很困难<br />\n我们倒着加点<br />\n先把除了所有拆的点有关的所有边之外的剩下的边用并查集合并<br />\n这是拆掉这些点后的状态，枚举剩下的点求出联通块个数<br />\n然后从后往前加点，因为前面的点拆掉时后面的点还要连着<br />\n接下来每加一个点就把它们相连的边合并一下，然后合并时若两个点都在一个并查集则合并这两个点对联通块没有影响，若不在一个并查集那么合并，注意加一个节点可能合并多条边并减小多个联通块数目<br />\n然后把这个减小后的变量记录 下来逆序输出<br />\n我们要把所有要摧毁的点所相连的边存起来，以便于后面倒推加边，并且剩下的边要合并起来作为所有都拆毁后的联通块，联通块一定要边合并边统计，切忌最后哈希统计<br />\n我们如果哈希记下边，读拆毁点时找边太难了，但我们可以哈希记下拆毁点，再遍历边时找出拆毁点相连的边会容易，同时还可以合并剩下的边，这是哈希的第一个妙用<br />\n原来<span class=\"math inline\">\\(n\\)</span>个点<br />\n去掉<span class=\"math inline\">\\(k\\)</span>个后<span class=\"math inline\">\\(n-k\\)</span>个，此时每合并一次减小一个联通块</p>\n<p>接下来倒着加点，把点所连的边合并<br />\n注意：<br />\n有时一条边的另一个点也是拆毁点，此时要看先后顺序来决定是否连边<br />\n当拆毁点靠前时，实际上这个点现在已经被拆毁，不能向他连边<br />\n当拆毁点靠后时，这个点已经恢复，所以要向他连边<br />\n因为从后往前，所以每恢复一个点就要把<span class=\"math inline\">\\(hash\\)</span>改为<span class=\"math inline\">\\(2\\)</span>，即已恢复，此时可以向他连边，而非拆毁点肯定要向他连边，而<span class=\"math inline\">\\(hash\\)</span>为<span class=\"math inline\">\\(1\\)</span>的还处于拆毁状态，不连边<br />\n然后算联通块的个数<br />\n注意：<br />\n这里拆毁节点不是把边断开，而是连同点一块删除，因此加边后联通块不能减1</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\n#include&lt;vector&gt;\nusing namespace std;\nint fa[400006];\nstruct edge{\n\tint a,b;\n}edges[200006];\nint goal[400006];\nint hash1[400006];//hash1数组记录这个节点状态，0为不是要摧毁的节点，1为当前已摧毁的节点，2为当前未摧毁的节点（即已倒退回来到这个节点）\nvector&lt;int&gt; edge2[400006];//每一个要摧毁的节点所相连的边\nint out[400006];//因为从后往前加边，所以要逆序输出\nint num=0;\ninline int finds(int x){\n\tif(fa[x]==x)return x;\n\treturn fa[x]=finds(fa[x]);\n}\ninline void inserts(int x,int y,int a,int b){\n//\tif(a==b)return ;\n\tfa[a]=b;\n}\nint main(){\n\tmemset(hash1,0,sizeof hash1);\n\tfor(int i=0;i&lt;400006;++i){\n\t\tfa[i]=i;\n\t}//不要memset -1，这样后面要一个个改，要提前初始化好\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\tedges[i].a =x;//edge数组存边\n\t\tedges[i].b=y;\n\t}\n\tint k;\n\tcin&gt;&gt;k;\n\tfor(int i=0;i&lt;k;++i){\n\t\tcin&gt;&gt;goal[i];\n\t\thash1[goal[i]]=1;//哈希表定为1因为这个点是已经拆毁了的\n\t}\n\tint lian1=n-k;\n\tfor(int i=0;i&lt;m;++i){\n\t\tif(hash1[edges[i].a ]==1){\n\t\t\tedge2[edges[i].a].push_back(edges[i].b );\n\t\t\t \n\t\t}//这两个if要并列不要else，因为两个a b点有可能都是要拆毁的点\n\t\tif(hash1[edges[i].b ]==1){\n\t\t\tedge2[edges[i].b].push_back(edges[i].a );\n\t\t\t \n\t\t}\n\t\tif((!hash1[edges[i].a ])&amp;&amp;(!hash1[edges[i].b ])){\n\t\t\tint root1=finds(edges[i].a ),root2=finds(edges[i].b);//如果两个都不拆毁，那么就要合并来算出联通块\n\t\t\tif(root1!=root2){//根节点相同时合并没有用，联通块不变\n\t\t\t\tinserts(edges[i].a,edges[i].b,root1,root2);\n\t\t\t\tlian1-=1;\t\n\t\t\t}\n\t\t}\n\t}\n\t//cout&lt;&lt;lian1&lt;&lt;endl;\n\tout[num]=lian1;\n\t++num;\n\tfor(int i=k-1;i&gt;=0;--i){//要等于0，因为全部恢复后是全连好的联通块，是要求输出的\n\t\tint root1=finds(goal[i] );\n\t\tint fl1=1,fl2=1;//fl1是看这个点是否孤立，若整个遍历没有可以连的边说明它是孤立的，此时恢复后联通块反而加1，fl2看这个点是否是第一次连边\n\t\t若是，说明这是把原先不存在的点和一个集合连边，此时一旦连起之后联通块不减少，因为原先这个点不存在，而现在连起之后就存在了\n\t\t而若不是第一次连边，那么这个点已经存在了，此时它与其他点构成了集合\n\t\t那么这是连边就能将联通块个数减一\n\t\tfor(int j=0;j&lt;edge2[goal[i]].size();++j){\n\t\t\tif(hash1[edge2[goal[i]][j]]!=1){\n\t\t\t\tfl1=0;\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tint root2=finds(edge2[goal[i]][j]);\n\t\t\t\t\n\t\t\t\tif(root1!=root2){\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tinserts(edge2[goal[i]][j],goal[i],root2,root1);\n\t\t\t\t\tif(fl2){\n\t\t\t\t\t\tfl2=0;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tlian1-=1;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\tif(fl1)lian1+=1;\n\t\thash1[goal[i]]=2;\n\t\tout[num++]=lian1;\n\t}\n\tfor(int i=num-1;i&gt;=0;--i){\n\t\tcout&lt;&lt;out[i]&lt;&lt;endl;\n\t}\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"p1111-修复公路\">P1111 修复公路</h3>\n<p><a href=\"https://www.luogu.com.cn/problem/P1111\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1111</a></p>\n<p>这是并查集的贪心算法<br />\n<span class=\"math inline\">\\(n\\)</span>个节点<span class=\"math inline\">\\(m\\)</span>条无向边，给定边的修好时间<br />\n求最小能使<span class=\"math inline\">\\(n\\)</span>个节点相互连通的时间<br />\n无向图，连边相当于合并，可以使用并查集<br />\n因为是最小。可以考虑贪心，先把边按时间由小到大排序并遍历<br />\n然后从小开始遍历，每遍历一条边就把这两个节点合并起来，用<span class=\"math inline\">\\(size\\)</span>数组记录根的尺寸，启发式合并，如果这个根的<span class=\"math inline\">\\(size\\)</span>是<span class=\"math inline\">\\(n\\)</span>，那就说明所有节点都在一个并查集中，就输出此时的时间，否则若到最后也没有联通，就输出<span class=\"math inline\">\\(-1\\)</span></p>\n<p>为什么贪心正确?<br />\n我们选择的时间是从小到大中刚刚保持联通的时间，假设有完成联通的时间比这个小的情况，那么之前遍历到的时间中就必定有这个时间，那么答案就会更小，而如果有联通时间比这个大的话那么这个时间下已经保持联通，再加边也没有用，不如这个更小的时间<br />\n虽然前面合并的时候有一些对联通无用的重复边被加上了，但这并不影响答案，因为我们不求和，而是求一个满足条件的最小值，时间是一点点流逝的，修建公路是同步进行的，修这些无用的公路之时也在修有用的公路，所以这些重复边对答案没有影响<br />\n这个题与<br />\nP1396 营救</p>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P1396\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1396</a><br />\n有相似之处</p>\n<h3 id=\"p1396-营救\">P1396 营救</h3>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P1396\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1396</a></p>\n<p>这是个重点题<br />\n题目的意思是说找一条从<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>的路径使其边权的最大值是所有每条<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>的路径中边权最大值最小的那个<br />\n就是说<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>的某条路径权值是这条<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span> 路径中边权的最大值<br />\n而要求一条路径使其权值最小，输出这个最小值</p>\n<p>而最小值最大是指<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>某条路径权值是这条路径中边权的最小值<br />\n要求1条路径使得权值最大</p>\n<p>也可以按边权从小到大排序，从小开始合并，直到刚好<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>联通，输出这个权值</p>\n<p>为什么成立呢？</p>\n<p>考虑这个权值显然是这里<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>边权中的最大值，但如何保证它是所有路径中最小的？<br />\n假设还有联通路径的最大值比这个还小，那么这条路径的所有边权都比这个还小，那么它们应该在这个的前面访问到，如果前面能构成联通，那么就会更早选择，而不会选择这个，所以是这个最小的</p>\n<p>最小值最大就应该从大到小排序合并到刚好联通为止<br />\n而这个权值也是当前路径的最小值。<br />\n假设还有联通路径的最小值比这个还大，那么路径所有边权都比这个大，那么它们就会在这个之前访问，若能构成联通就会更早选择，可是选择了这个就说明没有比这个还大的解</p>\n<h3 id=\"p2330-scoi2005繁忙的都市\">P2330 [SCOI2005]繁忙的都市</h3>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P2330\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P2330</a></p>\n<p>改造的道路尽量少就是要刚好保持联通不要有无用的边<br />\n所以从小到大排序合并时如果当前的两个点已经在一个并查集中就说明这条边无用，不要统计数量，跳过</p>\n<h3 id=\"p2121-拆地毯\">P2121 拆地毯</h3>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P2121\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P2121</a></p>\n<p>不要求联通，只是要求取的点不能有环<br />\n所以就像星球大战那样先把所有边拆掉，然后按权值从大到小排序<br />\n注意这里统计和，从大到小遍历，把当前两个点合并，如果发现已经在一个并查集就说明已经联通，再加边就会形成环，就不要把这个权值加进去</p>\n<p>一直加到<span class=\"math inline\">\\(k\\)</span>个真正的地毯（不成环），输出和<br />\n因为这是从大到小最大的<span class=\"math inline\">\\(k\\)</span>个或是除去一些之后最大的<span class=\"math inline\">\\(k\\)</span>个<br />\n所以和是最大的</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>黄粱一梦，终是一空</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/hicode002/\" target=\"_blank\">hicode002</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/hicode002/p/-/union_set\" target=\"_blank\">https://www.cnblogs.com/hicode002/p/-/union_set</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 19:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/hicode002\">hicode002</a>&nbsp;\n阅读(<span id=\"post_view_count\">13</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "PostgreSQL：新增语句：特殊处理：ON CONFLICT ... DO (UPDATE SET ...)/(NOTHING)",
      "link": "https://www.cnblogs.com/kakarotto-chen/p/19538290",
      "published": "",
      "description": "<h2>\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kakarotto-chen/p/19538290\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 15:16\">\n    <span>PostgreSQL：新增语句：特殊处理：ON CONFLICT ... DO (UPDATE SET ...)/(NOTHING)</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"postbody\">\n            <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1普通的insert-into\">1、普通的insert into</h2>\n<ul>\n<li>如果（主键/唯一建）存在，则会报错</li>\n<li>新需求：就算冲突也不报错，用其他处理逻辑</li>\n</ul>\n<h2 id=\"2基本语法insert-into--on-conflict--do-update-set-nothing\">2、基本语法（INSERT INTO ... ON CONFLICT (...) DO (UPDATE SET ...)/(NOTHING)）</h2>\n<ul>\n<li>语法图</li>\n</ul>\n<div class=\"mermaid\">flowchart TD\n    A[开始: INSERT发生主键/唯一冲突] --&gt; B{冲突后的期望是?}\n    B --&gt;|“保留旧数据，&lt;br&gt;静默跳过”| C[使用 ON CONFLICT DO NOTHING]\n    B --&gt;|“用新数据替换或修改旧数据”| D[使用 ON CONFLICT DO UPDATE SET]\n    \n    D --&gt; E{需要精细控制吗?}\n    E --&gt;|“是，只更新部分字段”| F[在SET中仅指定目标字段]\n    E --&gt;|“是，需满足条件才更新”| G[添加WHERE子句]\n    E --&gt;|“否，全量覆盖”| H[使用EXCLUDED.*或指定所有字段]\n</div><ul>\n<li>🔀 两种核心处理逻辑<br />\n为了方便你对比和理解，我将它们总结在下表中：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">处理逻辑</th>\n<th style=\"text-align: left;\">关键字</th>\n<th style=\"text-align: left;\">核心行为与目的</th>\n<th style=\"text-align: left;\">类比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>1. 静默放弃</strong></td>\n<td style=\"text-align: left;\"><strong><code>DO NOTHING</code></strong></td>\n<td style=\"text-align: left;\">如果冲突（数据已存在），就<strong>什么也不做</strong>，静默地保留现有数据，并让语句成功结束。</td>\n<td style=\"text-align: left;\"><strong>“无视”</strong>：看到店里已有同样的商品，就决定不放了，直接离开。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>2. 更新覆盖</strong></td>\n<td style=\"text-align: left;\"><strong><code>DO UPDATE SET ...</code></strong></td>\n<td style=\"text-align: left;\">如果冲突（数据已存在），就用<strong>新值更新</strong>已有的那条记录。</td>\n<td style=\"text-align: left;\"><strong>“置换”</strong>：看到店里已有同样的商品，就用你手里的新款替换掉旧款。</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>语法1：DO UPDATE SET</li>\n</ul>\n<pre><code class=\"language-sql\">INSERT INTO 表名 (列1, 列2, ...)\nVALUES (值1, 值2, ...)\nON CONFLICT (冲突列[可以多个]) \nDO UPDATE SET\n    列1 = EXCLUDED.列1,\n    列2 = EXCLUDED.列2,\n    ...;\n</code></pre>\n<ul>\n<li>语法2：DO NOTHING</li>\n</ul>\n<pre><code class=\"language-sql\">INSERT INTO table_name (column1, column2, ...)\nVALUES (value1, value2, ...)\nON CONFLICT (冲突列[可以多个])\nDO NOTHING;\n</code></pre>\n<h2 id=\"3示例\">3、示例</h2>\n<h3 id=\"31简单示例\">3.1、简单示例</h3>\n<pre><code class=\"language-sql\">-- 示例1: DO NOTHING - 确保数据唯一，重复则忽略\n-- 场景：收集用户邮箱，同一邮箱只记录第一次出现\nINSERT INTO user_emails (email, collected_at, source)\nVALUES ('alice@example.com', NOW(), '官网抽奖')\nON CONFLICT (email) \nDO NOTHING; -- 如果邮箱已存在，则静默跳过，不报错\n\n-- 示例2: DO UPDATE SET - 用最新信息覆盖旧记录\n-- 场景：更新用户的最后登录状态\nINSERT INTO user_sessions (user_id, last_login_ip, last_login_time, login_count)\nVALUES (123, '192.168.1.100', NOW(), 1)\nON CONFLICT (user_id) \nDO UPDATE SET\n    last_login_ip = EXCLUDED.last_login_ip, -- 使用本次尝试插入的新IP\n    last_login_time = EXCLUDED.last_login_time, -- 更新时间\n    login_count = user_sessions.login_count + 1; -- 在原有次数上累加\n</code></pre>\n<h3 id=\"32on-conflict-多列组合唯一约束示例\">3.2、ON CONFLICT 多列组合唯一约束示例</h3>\n<p><strong>场景说明</strong><br />\n假设我们有一个<strong>学生选课记录表</strong>，设计逻辑是：</p>\n<ul>\n<li>单个学生可以选多门课</li>\n<li>单门课程可以被多个学生选</li>\n<li>但 <strong>一个学生不能重复选同一门课</strong>（即 <code>(student_id, course_id)</code> 组合必须唯一）</li>\n</ul>\n<p><strong>示例表结构</strong></p>\n<pre><code class=\"language-sql\">CREATE TABLE student_courses (\n    -- 自增主键，但不是业务唯一键\n    id SERIAL PRIMARY KEY,\n    student_id INT NOT NULL,\n    course_id INT NOT NULL,\n    selected_at TIMESTAMP DEFAULT NOW(),\n    status VARCHAR(20) DEFAULT 'active',\n\n    -- 关键：为(student_id, course_id)创建组合唯一约束\n    CONSTRAINT unique_student_course UNIQUE (student_id, course_id)\n);\n</code></pre>\n<p><strong>示例数据</strong><br />\n假设表中已有数据：</p>\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>student_id</th>\n<th>course_id</th>\n<th>selected_at</th>\n<th>status</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1001</td>\n<td>101</td>\n<td>2024-01-01</td>\n<td>active</td>\n</tr>\n<tr>\n<td>2</td>\n<td>1001</td>\n<td>102</td>\n<td>2024-01-02</td>\n<td>active</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1002</td>\n<td>101</td>\n<td>2024-01-03</td>\n<td>active</td>\n</tr>\n</tbody>\n</table>\n<p><strong>场景1：尝试重复选课 → 使用 DO NOTHING</strong><br />\n学生1001想再次选择课程101（已存在），我们静默拒绝：</p>\n<pre><code class=\"language-sql\">INSERT INTO student_courses (student_id, course_id, selected_at)\nVALUES (1001, 101, NOW()) -- (1001,101)组合已存在！\nON CONFLICT (student_id, course_id) -- 指定两列组合为冲突目标\nDO NOTHING; -- 什么都不做，防止重复选课\n\n-- 结果：语句执行成功，但没有插入新行\n-- 表数据保持不变\n</code></pre>\n<p><strong>场景2：尝试重复选课 → 使用 DO UPDATE SET</strong><br />\n学生1001重复选课101，但我们允许更新选择时间和状态：</p>\n<pre><code class=\"language-sql\">INSERT INTO student_courses (student_id, course_id, selected_at, status)\nVALUES (1001, 101, NOW(), 'renewed') -- 再次尝试选择已选课程\nON CONFLICT (student_id, course_id) -- 检测(student_id, course_id)组合冲突\nDO UPDATE SET\n    selected_at = EXCLUDED.selected_at, -- 更新时间戳\n    status = EXCLUDED.status, -- 更新状态\n    id = student_courses.id -- 保持原id不变，避免主键冲突\n    \nRETURNING *; -- 返回更新后的行\n\n-- 结果：不会创建新行，而是更新id=1的记录\n-- 将selected_at更新为当前时间，status更新为'renewed'\n</code></pre>\n<p><strong>场景3：混合情况处理</strong><br />\n批量插入选课记录，处理各种冲突情况：</p>\n<pre><code class=\"language-sql\">INSERT INTO student_courses (student_id, course_id, selected_at)\nVALUES \n    (1001, 103, NOW()), -- 新组合：插入成功\n    (1001, 101, NOW()), -- 已存在组合：触发ON CONFLICT\n    (1002, 102, NOW())  -- 新组合：插入成功\nON CONFLICT (student_id, course_id)\nDO UPDATE SET\n    selected_at = EXCLUDED.selected_at,\n    status = 'refreshed'\nRETURNING student_id, course_id, selected_at;\n</code></pre>\n<p><strong>输出结果可能：</strong></p>\n<pre><code> student_id | course_id |       selected_at       \n------------+-----------+-------------------------\n       1001 |       103 | 2024-06-15 10:30:00.000  -- 新插入\n       1001 |       101 | 2024-06-15 10:30:00.000  -- 更新（冲突处理）\n       1002 |       102 | 2024-06-15 10:30:00.000  -- 新插入\n</code></pre>\n<h3 id=\"33其他多列唯一约束示例\">3.3、其他多列唯一约束示例</h3>\n<p>示例1：会议室预订系统</p>\n<pre><code class=\"language-sql\">-- 确保同一会议室在同一时间段不被重复预订\n-- 唯一约束：(room_id, date, time_slot)\nINSERT INTO room_bookings (room_id, date, time_slot, booker_name)\nVALUES (101, '2024-06-20', '09:00-10:00', '张三')\nON CONFLICT (room_id, date, time_slot)\nDO NOTHING; -- 时间段冲突则直接拒绝\n</code></pre>\n<p><strong>示例2：用户-产品评分表</strong></p>\n<pre><code class=\"language-sql\">-- 确保一个用户对同一产品只能评分一次\n-- 唯一约束：(user_id, product_id)\nINSERT INTO product_ratings (user_id, product_id, rating, review)\nVALUES (5001, 3005, 5, '非常好用')\nON CONFLICT (user_id, product_id)\nDO UPDATE SET\n    rating = EXCLUDED.rating,\n    review = EXCLUDED.review,\n    rated_at = NOW();\n</code></pre>\n<p><strong>关键要点总结</strong></p>\n<ol>\n<li><strong>语法格式</strong>：<code>ON CONFLICT (column1, column2, ...)</code> 用括号包含多个列</li>\n<li><strong>约束要求</strong>：这些列必须已定义组合唯一约束（可以是复合主键或复合唯一约束）</li>\n<li><strong>冲突检测</strong>：只有当<strong>所有指定列的值都完全匹配</strong>时，才被认为是冲突</li>\n<li><strong>常见场景</strong>：多对多关系表、时间-资源组合、用户-实体关联表等</li>\n</ol>\n<p>这种多列约束特别适合处理<strong>业务层面的组合唯一性要求</strong>，而不仅仅是技术上的主键唯一性。</p>\n<h2 id=\"4特殊参数解析冲突列可以多个\">4、特殊参数解析：冲突列[可以多个]</h2>\n<ul>\n<li>ON CONFLICT 后面必须指定一个：唯一约束（主键也可以）字段\n<ul>\n<li>多个字段唯一也可以</li>\n</ul>\n</li>\n</ul>\n<p><strong>关键机制</strong>：</p>\n<ul>\n<li>\n<p><strong>冲突目标</strong>：<code>ON CONFLICT</code> 后面必须指定一个<strong>唯一约束</strong>，通常是主键或唯一索引。当插入的数据在这个约束上与已有数据冲突时，就会触发 <code>UPDATE</code> 操作。</p>\n</li>\n<li>\n<p><strong>约束要求：这些列必须已定义组合唯一约束（可以是复合主键或复合唯一约束）</strong></p>\n</li>\n<li>\n<p><strong>EXCLUDED 伪表</strong>：在 <code>DO UPDATE SET</code> 子句中，你可以使用 <code>EXCLUDED.列名</code> 来引用<strong>本次尝试插入但发生了冲突的那些值</strong>，这是实现“用新值覆盖旧值”的关键。</p>\n</li>\n</ul>\n<h2 id=\"returning参数见下篇\">RETURNING参数，见下篇</h2>\n\n</div>\n<div class=\"clear\"></div>\n\n        </div>\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-01-27 15:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kakarotto-chen\">C_C_菜园</a>&nbsp;\n阅读(<span id=\"post_view_count\">165</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "langchain 快速入门(六)：实现多agent协作",
      "link": "https://www.cnblogs.com/ClownLMe/p/19538384",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ClownLMe/p/19538384\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 14:27\">\n    <span>langchain 快速入门(六)：实现多agent协作</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"简介\">简介</h1>\n<p><strong>多Agent协作</strong>能够将一个复杂的任务拆解成一个个子任务给专门的agent，能够解决复杂问题，实现复杂的ai工作流。</p>\n<h1 id=\"多agent协作\">多Agent协作</h1>\n<p>不同的Agent，有不同的能力，我们可能会有各种实际需求，例如：实时识别车牌位置（Yolo）-&gt;识别车牌内容（qwen-vl）-&gt; LLM管理记录车牌信息。通过多Agent协作的工作流，能够实现拍照答题，自动剪辑，ppt生成等一系列复杂问题。</p>\n<p>下面用一个简单的案例，来说明。</p>\n<h1 id=\"简单的多agent协作\">简单的多Agent协作</h1>\n<h3 id=\"示例\">示例</h3>\n<p>需求：查一下阿里、腾讯、百度的PE，并计算平均值。</p>\n<pre><code class=\"language-python\">import os\nimport operator\nfrom pydantic import BaseModel, Field\nfrom langchain_community.chat_models.tongyi import ChatTongyi\nfrom langchain_core.tools import tool\nfrom langchain_core.messages import HumanMessage, BaseMessage, ToolMessage, SystemMessage\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom typing import Annotated, List, Literal, TypedDict\nfrom langgraph.graph import StateGraph, END\n\nos.environ[\"DASHSCOPE_API_KEY\"] = \"apikey\"\nllm = ChatTongyi(model=\"qwen-plus\")\n\n@tool\ndef web_search(query: str):\n    \"\"\"用于查找最新的股票数据、公司财报信息。\"\"\"\n    results = []\n    if \"阿里\" in query: results.append(\"阿里巴巴(BABA) PE: 15.5\")\n    if \"腾讯\" in query: results.append(\"腾讯控股(0700) PE: 18.2\")\n    if \"百度\" in query: results.append(\"百度(BIDU) PE: 11.8\")\n    \n    if not results:\n        return \"未找到数据\"\n    return \" ; \".join(results)\n\n@tool\ndef python_calculator(code: str):\n    \"\"\"用于计算。输入必须是 python 代码。\"\"\"\n    try:\n        result = eval(code)\n        return f\"计算结果: {result}\"\n    except Exception as e:\n        return f\"计算错误: {e}\"\n\ndef create_agent(state: dict, llm, tools, system_prompt):\n    llm_tools = llm.bind_tools(tools)\n    \n    prompt = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n    response = llm_tools.invoke(prompt)\n\n    results = [response]\n\n    for tool_call in response.tool_calls:\n        func_name = tool_call[\"name\"]\n        args = tool_call[\"args\"]\n        call_id = tool_call[\"id\"]\n        \n        func = next((t for t in tools if t.name == func_name), None)\n\n        if func:\n            tool_output = func.invoke(args)\n            tool_msg = ToolMessage(\n                content=str(tool_output),\n                name=func_name,\n                tool_call_id=call_id\n            )\n            results.append(tool_msg)\n\n    return {\"messages\": results}\n\nclass State(TypedDict):\n    messages: Annotated[List[BaseMessage], operator.add]\n    next: str\n\ndef researcher_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[web_search],\n        system_prompt=\"你是一个研究员。只负责查数据，找到数据后直接输出原话，不需要计算。\"\n    )\n\ndef coder_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[python_calculator],\n        system_prompt=\"你是一个程序员。根据上面研究员查到的数据，写代码计算平均值。\"\n    )\n\ndef finish_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[],\n        system_prompt=\"任务完成，简短的总结最终结果。\"\n    )\n\ndef supervisor_node(state):\n    system_prompt = (\n        \"你是项目经理。根据对话历史决定下一步交给谁。\"\n        \"查数据找 Researcher，计算找 Coder，识别图片找 Photographer。\"\n        \"如果任务完成，必须选择 FINISH。\"\n    )\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\"),\n        (\"system\", \"根据以上情况，请做出选择。\"),\n    ])\n\n    class RouteResponse(BaseModel):\n        next: Literal[\"Researcher\", \"Coder\", \"FINISH\"] = Field(\n            ..., \n            description=\"下一步交给谁？如果任务完成请选 FINISH\"\n        )\n\n    chain = prompt | llm.with_structured_output(RouteResponse)\n\n    response = chain.invoke(state)\n\n    return {\"next\": response.next}\n\ndef init_agent():\n    workflow = StateGraph(State)\n    workflow.add_node(\"Researcher\", researcher_node)\n    workflow.add_node(\"Coder\", coder_node)\n    workflow.add_node(\"Supervisor\", supervisor_node)\n    workflow.add_node(\"Finish\", finish_node)\n\n    workflow.add_edge(\"Researcher\", \"Supervisor\")\n    workflow.add_edge(\"Coder\", \"Supervisor\")\n    workflow.add_edge(\"Finish\", END)\n    workflow.add_conditional_edges(\n        \"Supervisor\",\n        lambda state: state[\"next\"],{\n        \"Researcher\": \"Researcher\",\n        \"Coder\": \"Coder\",\n        \"FINISH\": \"Finish\",\n    })\n\n    workflow.set_entry_point(\"Supervisor\")\n\n    return workflow.compile()\n\nif __name__ == \"__main__\":\n    agent = init_agent()\n    for result in agent.stream({\n        \"messages\": [HumanMessage(content=\"查一下阿里、腾讯、百度的PE，并计算平均值。\")]\n        }):\n        for key, value in result.items():\n            if key == \"Supervisor\":\n                print(\"[\" + key + \"] 去向: \" + value[\"next\"])\n            else:\n                print(\"[\" + key + \"] 回复: \" + value['messages'][-1].content)\n\n</code></pre>\n<h3 id=\"代码解释\">代码解释</h3>\n<p>代码一共用到了4个agent：</p>\n<ol>\n<li>agent Researcher，其有一个工具，负责搜索某些内容</li>\n<li>agent coder，其有一个工具，负责进行精确计算</li>\n<li>agent finish，其没有工具，负责总结内容</li>\n<li>agent Supervisor，其没有工具，负责管理上面3个agent，决定任务的去向<br />\n上面案例使用的是langgraph组件，这里就不详细讲解了，请看之前文章。</li>\n</ol>\n<p><strong>代码流程：</strong> 初始化工具库-&gt;初始化agent-&gt;构建图-&gt;运行</p>\n<h3 id=\"初始化工具库\">初始化工具库</h3>\n<pre><code class=\"language-python\">@tool\ndef web_search(query: str):\n    \"\"\"用于查找最新的股票数据、公司财报信息。\"\"\"\n    results = []\n    if \"阿里\" in query: results.append(\"阿里巴巴(BABA) PE: 15.5\")\n    if \"腾讯\" in query: results.append(\"腾讯控股(0700) PE: 18.2\")\n    if \"百度\" in query: results.append(\"百度(BIDU) PE: 11.8\")\n    \n    if not results:\n        return \"未找到数据\"\n    return \" ; \".join(results)\n\n@tool\ndef python_calculator(code: str):\n    \"\"\"用于计算。输入必须是 python 代码。\"\"\"\n    try:\n        result = eval(code)\n        return f\"计算结果: {result}\"\n    except Exception as e:\n        return f\"计算错误: {e}\"\n</code></pre>\n<p>这里的<code>web_search</code>使用的是虚假的模拟信息，上面的工具描述不够完整，但是能用，如果用实际案例，请描述完整，工具的描述参考之前文章。</p>\n<h1 id=\"初始化agent\">初始化agent</h1>\n<h5 id=\"其他3个agent\">其他3个agent</h5>\n<pre><code class=\"language-python\">def create_agent(state: dict, llm, tools, system_prompt):\n    llm_tools = llm.bind_tools(tools)\n    \n    prompt = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n    response = llm_tools.invoke(prompt)\n\n    results = [response]\n\n    for tool_call in response.tool_calls:\n        func_name = tool_call[\"name\"]\n        args = tool_call[\"args\"]\n        call_id = tool_call[\"id\"]\n        \n        func = next((t for t in tools if t.name == func_name), None)\n\n        if func:\n            tool_output = func.invoke(args)\n            tool_msg = ToolMessage(\n                content=str(tool_output),\n                name=func_name,\n                tool_call_id=call_id\n            )\n            results.append(tool_msg)\n\ndef researcher_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[web_search],\n        system_prompt=\"你是一个研究员。只负责查数据，找到数据后直接输出原话，不需要计算。\"\n    )\n\ndef coder_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[python_calculator],\n        system_prompt=\"你是一个程序员。根据上面研究员查到的数据，写代码计算平均值。\"\n    )\n\ndef finish_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[],\n        system_prompt=\"任务完成，简短的总结最终结果。\"\n    )\n</code></pre>\n<p>流程相对简单，<code>create_agent</code>细节前面文章已经讲解，这里就不废话了。</p>\n<h5 id=\"管理agent\">管理agent</h5>\n<pre><code class=\"language-python\">def supervisor_node(state):\n    system_prompt = (\n        \"你是项目经理。根据对话历史决定下一步交给谁。\"\n        \"查数据找 Researcher，计算找 Coder，识别图片找 Photographer。\"\n        \"如果任务完成，必须选择 FINISH。\"\n    )\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\"),\n        (\"system\", \"根据以上情况，请做出选择。\"),\n    ])\n\n    class RouteResponse(BaseModel):\n        next: Literal[\"Researcher\", \"Coder\", \"FINISH\"] = Field(\n            ..., \n            description=\"下一步交给谁？如果任务完成请选 FINISH\"\n        )\n\n    chain = prompt | llm.with_structured_output(RouteResponse)\n\n    response = chain.invoke(state)\n\n    return {\"next\": response.next}\n</code></pre>\n<p>这一步需要简单说明：</p>\n<pre><code class=\"language-python\">class RouteResponse(BaseModel):\n    next: Literal[\"Researcher\", \"Coder\", \"FINISH\"] = Field(\n        ..., \n        description=\"下一步交给谁？如果任务完成请选 FINISH\"\n    )\nchain = prompt | llm.with_structured_output(RouteResponse)\n</code></pre>\n<ul>\n<li>LLM中的<code>with_structured_output</code>方法是langchain提供的一个组件，功能是，限定LLM的输出格式，返回相应格式的字典。</li>\n<li>定义输出格式限定的类：</li>\n</ul>\n<ol>\n<li>该类是<code>BaseModel</code>的子类</li>\n<li><code>Literal</code>是选择，要求ai从<code>\"Researcher\", \"Coder\", \"FINISH\"</code>三选一</li>\n<li><code>Field</code>描述变量，尽量详尽，描述+例子，因为是给大模型看的</li>\n</ol>\n<pre><code class=\"language-python\">class classname(BaseModel):\n\tfieldname: fieldtype = Field(..., description=\"描述\")\n</code></pre>\n<h3 id=\"构建图重要\">构建图（重要）</h3>\n<pre><code class=\"language-python\">def init_agent():\n    workflow = StateGraph(State)\n    workflow.add_node(\"Researcher\", researcher_node)\n    workflow.add_node(\"Coder\", coder_node)\n    workflow.add_node(\"Supervisor\", supervisor_node)\n    workflow.add_node(\"Finish\", finish_node)\n\n    workflow.add_edge(\"Researcher\", \"Supervisor\")\n    workflow.add_edge(\"Coder\", \"Supervisor\")\n    workflow.add_edge(\"Finish\", END)\n    workflow.add_conditional_edges(\n        \"Supervisor\",\n        lambda state: state[\"next\"],{\n        \"Researcher\": \"Researcher\",\n        \"Coder\": \"Coder\",\n        \"FINISH\": \"Finish\",\n    })\n\n    workflow.set_entry_point(\"Supervisor\")\n\n    return workflow.compile()\n</code></pre>\n<p>这一步相当于连接工作流，构建的流程图如下：</p>\n<pre><code>       +---------------------------+\n       |           开始             |\n       +-------------+-------------+\n                     |\n                     v\n       +---------------------------+\n       |       Supervisor          |&lt;----------------+\n       | (通过当前任务状态，返回next) |                 |\n       +-------------+-------------+                 |\n                     |(根据state中next判断去向)        |\n        _____________|_____________                  |\n       /             |             \\                 |\n      /              |              \\                |\n     v               v               v               |\n+------------+  +------------+  +------------+       |\n| Researcher |  |   Coder    |  |   Finish   |       |\n|  (Agent)   |  |  (Agent)   |  | (Cleanup)  |       |\n+-----+------+  +-----+------+  +-----+------+       |\n      |               |               |              |\n      |               |               v              |\n      |               |         +------------+       |\n      +---------------+         |    END     |       |\n              |                 +------------+       |\n              |                                      |\n              +--------------------------------------+\n                    (返回重新选择下一个agent)\n</code></pre>\n<p><strong>如果❤喜欢❤本系列教程，就点个关注吧，后续不定期更新~</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 14:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ClownLMe\">ClownLMe</a>&nbsp;\n阅读(<span id=\"post_view_count\">158</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "spring boot3--自动配置与手动配置",
      "link": "https://www.cnblogs.com/alineverstop/p/19537574",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/alineverstop/p/19537574\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 11:50\">\n    <span>spring boot3--自动配置与手动配置</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"springboot自动配置\">springboot自动配置</h1>\n<p>自动配置了大量组件，配置信息可以在application.properties文件中修改。</p>\n<p>当添加了特定的Starter POM后，springboot会根据类路径上的jar包来自动配置bean（比如：springboot发现类路径上的MyBatis相关类，springboot会自动配置MyBatis相关的bean）。</p>\n<p>springboot使用默认配置来设置这些功能，开发人员也可以自定义配置来覆盖默认配置。</p>\n<h2 id=\"这些配置信息如何生效的\">这些配置信息如何生效的？</h2>\n<p>通过@ConfigurationProperties注解将配置信息注入到组件中的属性类的。属性类一般以Properties结尾。比如tomcat组件的ServerProperties类，就是将配置信息中server开头的配置注入到属性中，比如server.port=8080会被绑定到属性中</p>\n<pre><code class=\"language-java\">@ConfigurationProperties(\"server\")\npublic class ServerProperties {\n    private @Nullable Integer port;\n    private @Nullable InetAddress address;\n  .....\n}\n</code></pre>\n<h2 id=\"自动配置是按需加载的\">自动配置是按需加载的</h2>\n<p>springboot提供很多自动配置类，这些自动配置不是全部生效，它是按需加载的，导入了哪个启动器，则该启动器对应的配置类才会被加载。</p>\n<p>任何启动器都会关联一个启动器：spring-boot-Starter，它是springboot框架最核心的启动器。</p>\n<p>spring-boot-Starter又关联引入spring-boot-auto从figure。所有的自动配置类都在这里。</p>\n<p>自动配置类用来创建相应的组件。</p>\n<h2 id=\"按需加载如何实现\">按需加载如何实现？</h2>\n<p>使用条件注解可以实现按需加载。</p>\n<p>条件注解基于某些条件决定是否应该创建一个bean。这些注解通常用在自动配置类上，以确保只有在特定条件满足时才会应用相应的配置。</p>\n<p>条件注解可以用在类上，也可以用在方法上。</p>\n<p>常见的条件注解有：</p>\n<ul>\n<li>@ConditionalOnClass 指定类存在时才创建bean</li>\n<li>@ConditionalOnMissingClass 指定类不存在时才创建bean</li>\n<li>@ConditionalOnBean 容器中存在指定bean时才创建bean</li>\n<li>@ConditionalOnMissingBean 容器中不存在指定bean时才创建bean</li>\n<li>@ConditionalOnProperty 配置文件中存在指定属性时，才创建bean</li>\n<li>@ConditionalOnResource 指定资源存在时才创建bean</li>\n<li>@ConditionalOnWebApplication 应用程序是Web应用时才创建bean</li>\n<li>@ConditionalOnNotWebApplication 应用程序不是Web应用时才创建bean</li>\n</ul>\n<h2 id=\"修改默认的包扫描规则\">修改默认的包扫描规则</h2>\n<p>修改扫描规则有2种方式：</p>\n<p>在主入口类上添加以下注解的任意一个都可以修改包扫描规则（扫描com包及其子孙包）</p>\n<ol>\n<li>\n<pre><code class=\"language-java\">@ComponentScan(\"com\")\n</code></pre>\n</li>\n<li>\n<pre><code class=\"language-java\">@SpringBootApplication(scanBasePackages = \"com\")\n</code></pre>\n</li>\n</ol>\n<h1 id=\"自动配置的实现原理\">自动配置的实现原理</h1>\n<ol>\n<li>\n<p>程序从main方法开始执行，主入口类上使用@SpringBootApplication进行标注</p>\n</li>\n<li>\n<p>@SpringBootApplication是复合注解，代表以下三个注解的功能</p>\n<p>a. @SpringBootConfiguration:它被@Configuration标注。表明主入口类是一个配置类，此时该配置开始加载。</p>\n<p>b. @ComponentScan 默认扫描主入口类所在包及其子孙包，因此spring-boot-autoconfigure 自动配置类是无法加载的，那么这些自动配置类又是怎么生效的呢？</p>\n<p>c. <strong>@EnableAutoConfiguration 该注解的作用就是启用自动配置</strong></p>\n</li>\n<li>\n<p>@EnableAutoConfiguration  被@Import({AutoConfigurationImportSelector.class})标注</p>\n</li>\n</ol>\n<p>​        @Import({AutoConfigurationImportSelector.class})的作用是将AutoConfigurationImportSelector作为一个bean加载到Ioc容器中</p>\n<p>​        这个bean的作用是：负责收集和选择所有符合条件的自动配置类。</p>\n<h2 id=\"总结\">总结</h2>\n<ol>\n<li>运行环境准备阶段\n<ul>\n<li>引入Web启动器</li>\n<li>最终传递引入了自动配置的jar包</li>\n<li>自动配置的jar包中有152个自动配置类，到此运行环境准备完毕</li>\n</ul>\n</li>\n<li>运行阶段\n<ul>\n<li>@EnableAutoConfiguration  启用自动配置，将152个自动配置类全部加载到Ioc容器中。然后根据开发场景筛选出必须得自动配置类</li>\n<li>自动配置类加载了很多组件</li>\n<li>每个组件需要的数据来自属性类</li>\n<li>属性类的属性来自配置文件</li>\n</ul>\n</li>\n</ol>\n<p>总之一句话。导入启动器，修改配置文件。就可以完成对应功能的开发。</p>\n<h1 id=\"springmvc配置\">springmvc配置</h1>\n<pre><code class=\"language-properties\"># 让springboot的静态资源处理失效\nspring.web.resources.add-mappings=false\n# 配置静态资源的访问URL\nspring.mvc.static-path-pattern=/**\n#  静态资源文件存储位置默认配置\nspring.web.resources.static-locations=classpath:/META-INF/resources/, classpath:/resources/, classpath:/static/, classpath:/public/\n\n</code></pre>\n<p>springboot对静态资源是如何处理的？</p>\n<p>什么样的URL ？访问哪个位置上的资源文件？</p>\n<h2 id=\"webjars\">webjars</h2>\n<p>webjars是现在前后端分离中比较重要的一种静态资源打包方式。</p>\n<p>webjars是一种常用的前端库（如jQuery）打包成jar包的形式，方便在java程序中使用。</p>\n<p>webjars提供了一种标准化的方式来管理前端库，使其更容易集成到java项目中，并且可以利用Maven的依赖管理功能。</p>\n<pre><code class=\"language-xml\">&lt;!--        webjars,将前端库打成jar包--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.webjars.npm&lt;/groupId&gt;\n            &lt;artifactId&gt;vue&lt;/artifactId&gt;\n            &lt;version&gt;3.5.12&lt;/version&gt;\n        &lt;/dependency&gt;\n</code></pre>\n<p>默认规则是：当请求路径是/wbjars/**,则会去classpath:/MEAT-INF/resources/webjars/找。</p>\n<h2 id=\"静态资源缓存处理\">静态资源缓存处理</h2>\n<p>静态资源缓存是指浏览器的缓存行为，浏览器可以缓存（js、CSS、图片、声音、视频）到浏览器中，下一次用户访问同样的资源就直接从缓存中获取，不再从服务器获取，这样能减少服务器压力，提高相应效率。</p>\n<p>可以通过配置来修改默认的缓存机制。</p>\n<pre><code class=\"language-properties\">＃静态资源缓存设置\n＃缓存有效期设置\nspring.web.resources.cache.period=3600\n# 缓存控制设置\nspring.web.resources.cache.cachecontrol.max-age=20\n# 是否启用最后一次修改时间的比对\nspring.web.resources.cache.use-last-modified=true\n</code></pre>\n<h2 id=\"静态indexhtml的支持\">静态index.html的支持</h2>\n<p>spring会自动处理位于静态资源目录下的index.html（文件名必须是index.html），使其成为应用程序的主页。</p>\n<p>注意：此时不能配置静态资源访问url（spring.mvc.static-path-pattern），必须使用默认的配置</p>\n<h2 id=\"faviconico\">favicon.ico</h2>\n<p>将favicon.ico放在静态资源根目录下，就会自动生效。</p>\n<h1 id=\"spring-boot的web手动配置静态资源处理\">spring boot的web手动配置（静态资源处理）</h1>\n<h2 id=\"编写代码的方式\">编写代码的方式</h2>\n<h3 id=\"第一种方式-实现webmvcconfigurer接口\">第一种方式 实现WebMvcConfigurer接口</h3>\n<pre><code class=\"language-java\">// 添加这个注解后，表示不再使用springboot提供的默认配置\n// @EnableWebMvc\n@Configuration\npublic class WebConfig implements WebMvcConfigurer {\n    \n    // 静态资源处理需要重写的方法\n    @Override\n    public void addResourceHandlers(ResourceHandlerRegistry registry) {\n        // 使用注册器registry 绑定 pathPatterns 以及真实的静态资源文件存储路径\n        registry.addResourceHandler(\"/abc/**\") // 配置路径访问模式\n                .addResourceLocations(\"classpath:/static1/\", \"classpath:/static2/\", \"classpath:/static3/\"); // 配置静态资源路径\n    }\n}\n</code></pre>\n<h3 id=\"第二种方式\">第二种方式</h3>\n<pre><code class=\"language-java\">@Configuration\npublic class WebConfig2 {\n\n    @Bean\n    public WebMvcConfigurer addResourceHandlers() {\n        return new WebMvcConfigurer() {\n            @Override\n            public void addResourceHandlers(ResourceHandlerRegistry registry) {\n                registry.addResourceHandler(\"/abc/**\") // 配置路径访问模式\n                        .addResourceLocations(\"classpath:/static1/\", \"classpath:/static2/\", \"classpath:/static3/\"); // 配置静态资源路径\n            }\n        };\n    }\n}\n</code></pre>\n<h1 id=\"web请求的路径匹配\">web请求的路径匹配</h1>\n<pre><code class=\"language-properties\"># 前端请求的url 匹配到controller中的某个方法\n# 使用ant风格的路径匹配规则，默认值是path_pattern_matcher\n# path_pattern_matcher兼容且支持ant风格\n# 在ant风格中** 可以出现在任何位置，但在path_pattern_matcher风格中，** 只能出现在末尾\n# spring6 下的ant风格 ** 也只能出现在末尾\nspring.mvc.pathmatch.matching-strategy=ant_path_matcher\n</code></pre>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/alineverstop/\" target=\"_blank\">NE_STOP</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/alineverstop/p/19537574\" target=\"_blank\">https://www.cnblogs.com/alineverstop/p/19537574</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 11:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/alineverstop\">NE_STOP</a>&nbsp;\n阅读(<span id=\"post_view_count\">129</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "面积图的奇妙变形：流图与地平线图",
      "link": "https://www.cnblogs.com/wang_yb/p/19536752",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wang_yb/p/19536752\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 09:52\">\n    <span>面积图的奇妙变形：流图与地平线图</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>想象一下面积图就像一层层叠起来的彩色玻璃片，每一层代表一个类别，从下往上堆叠，形成整体的视觉冲击。</p>\n<p>但有时我们需要更特别的方式来展示数据的变化：是像河流一样蜿蜒流淌，还是像地平线上的群山连绵起伏？</p>\n<p>今天，本文将介绍两种创意<strong>面积图变体</strong>——<strong>流图</strong>和<strong>地平线图</strong>，它们能让你的时间序列数据讲述更生动的故事。</p>\n<h1 id=\"1-流图数据的河流\">1. 流图：数据的河流</h1>\n<p>如果把传统的堆叠面积图想象成一块块整齐堆叠的积木，那么<strong>流图</strong>就像一条蜿蜒流淌的河流，河道的宽窄变化自然流畅，波峰波谷过渡平滑。</p>\n<p>它特别适合展示多个类别数据随时间的变化趋势，尤其是当你想强调整体流动感和各部分的相对比例变化时。</p>\n<p><strong>流图</strong>的<strong>核心思想</strong>是将传统的堆叠面积图进行\"平滑\"处理。</p>\n<p>在<code>matplotlib</code>中，我们可以使用<code>fill_between</code>函数结合样条插值来创建平滑的边缘。</p>\n<p>关键在于将堆叠的数据进行累积，然后对累积边界进行平滑处理。</p>\n<pre><code class=\"language-python\"># 数据准备\nx = np.linspace(0, 10, 100)\n# 构造三组波浪数据\ny1 = 2 + np.sin(x)            # 基础波动\ny2 = 2 + np.cos(x - 1.5)      # 错位波动\ny3 = 2 + np.sin(x + 2)        # 再次错位\n\n# 省略 ...\n\n# 绘图设置\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- 左图：普通堆叠面积图 (baseline='zero') ---\nax1.stackplot(x, y_data, labels=labels, colors=colors, baseline='zero', alpha=0.8)\n# 省略 ...\n\n# --- 右图：流图 (baseline='sym') ---\n# 'sym' 表示对称中心布局\nax2.stackplot(x, y_data, labels=labels, colors=colors, baseline='sym', alpha=0.8)\nax2.axhline(0, color='black', ls='--', alpha=0.1) # 画一条中心参考线\n# 省略 ...\n\n# 去除右图边框，增加流动感\nfor spine in ax2.spines.values():\n    spine.set_visible(False)\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260127095106236-1661454977.png\" /></p>\n<p><strong>流图</strong>解决了一个视觉错觉问题：在普通<strong>堆叠面积图</strong>中，上面的数据层会因为下面数据层的起伏而被迫“扭曲”，很难看出它原本的形状。</p>\n<p><strong>流图</strong>通过中心布局，减少了这种扭曲，非常适合展示随时间变化的趋势和不同类别权重的波动，这种有机的形态还能给读者带来极强的审美愉悦感。</p>\n<h1 id=\"2-地平线图数据的群山\">2. 地平线图：数据的群山</h1>\n<p>想象一下远处的地平线上有一排连绵的山脉，每座山的高度代表一个数据值。</p>\n<p><strong>地平线图</strong>就是这样一种可视化技术，它将时间序列数据压缩在一个很小的垂直空间内，通过颜色和分层来展示数据的变化。</p>\n<p>特别适合在有限空间内展示多个时间序列的对比。</p>\n<p><strong>地平线图</strong>的<strong>核心思想</strong>是数据分层和颜色渐变。</p>\n<p>它将数据值分成若干层（通常是2-3层），每层用一种颜色表示。当数据值超过一层时，就用更深的颜色或不同的颜色填充。这样可以在很小的垂直空间内展示很大的数据范围。</p>\n<pre><code class=\"language-python\">from datetime import timedelta\n\n# 生成模拟数据：过去10年五大科技公司的股价波动\nnp.random.seed(42)\n\n# 生成日期范围：过去10年，每月一个数据点\ndates = pd.date_range(\"2013-01-01\", \"2023-01-01\", freq=\"ME\")\ncompanies = [\"苹果\", \"谷歌\", \"微软\", \"亚马逊\", \"Meta\"]\n\n# 生成各公司的股价模拟数据（标准化到相似范围）\ndata = {}\nfor company in companies:\n    # 基础趋势：每家公司有不同的增长趋势，但最终都在70-90范围内\n    # 省略 ...\n\n# 转换为DataFrame\ndf = pd.DataFrame(data, index=dates)\n\n# 创建对比图表\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\n# ============ 传统堆叠面积图 ============\ncolors = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#FFD166\", \"#9B5DE5\"]\n\n# 为堆叠面积图重新归一化数据\ndf_normalized = df.div(df.sum(axis=1), axis=0) * 100\ny_cumulative = np.zeros(len(df))\n\nfor i, company in enumerate(companies):\n    axes[0].fill_between(\n        df.index,\n        y_cumulative,\n        y_cumulative + df_normalized[company].values,\n        color=colors[i],\n        alpha=0.7,\n        label=company,\n        edgecolor=\"white\",\n        linewidth=0.5,\n    )\n    y_cumulative += df_normalized[company].values\n\n# 省略 ...\n\n# ============ 地平线图：股价波动对比 ============\n# 生成股价变化百分比数据（更能体现波动对比）\nnp.random.seed(42)\nprice_changes = {}\nfor company in companies:\n    # 生成均值附近波动的变化数据\n    # 省略 ...\n\n# 关键参数：定义“波段”\nBAND_HEIGHT = 3.0  # 每个颜色波段代表的变化率幅度 (%)\nNUM_BANDS = 3  # 正负方向各使用的波段层数\n\ndf = pd.DataFrame(price_changes, index=dates)\n\n# 为每家公司计算并绘制地平线\nfor i, company in enumerate(companies):\n    # 公司的基准Y轴位置（水平线）\n    # 省略 ...\n\n    # 分层与绘制：从第1层到第NUM_BANDS层\n    for band in range(NUM_BANDS):\n        # --- 处理正偏差（上涨）---\n        # 计算当前层的数据：偏差值减去已绘制层的高度，并限制在本层高度内\n        # 省略 ...\n\n        # --- 处理负偏差（下跌）---\n        # 对负值取绝对值，进行类似处理\n        # 省略 ...\n\n# 美化图表\n# 省略 ...\n\n# 6. 添加图例\nimport matplotlib.patches as mpatches\n\nlegend_patches = []\n# 省略 ...\n\nplt.tight_layout(h_pad=5)\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260127095106427-578985873.png\" /></p>\n<p><strong>地平线图</strong>是空间利用大师。当你有 20 个股票或者 50 个城市的温度需要放在一张图里对比时，普通的面积图会挤成一团乱麻。</p>\n<p><strong>地平线图</strong>可以将每个序列压缩成一个窄窄的横条，但在保持视觉分辨率的同时，还能让你看清极值（通过深颜色）。</p>\n<h1 id=\"3-总结\">3. 总结</h1>\n<p>数据可视化不仅是科学，也是艺术。<strong>流图</strong>和<strong>地平线图</strong>这两种面积图变体，分别从<strong>\"流动之美\"</strong>和<strong>\"空间效率\"</strong>两个角度拓展了面积图的可能性。</p>\n<p>它们证明了，通过对基础图表的创意改造，我们可以让数据讲述更丰富、更生动的故事。</p>\n<p>下次当你面对时间序列数据时，不妨问问自己：我的数据像一条蜿蜒的河流，还是像地平线上的群山？选择适合的可视化方式，让你的数据真正\"流动\"起来或\"层叠\"起来。</p>\n<p>记住，最好的可视化不是最复杂的，而是最能清晰传达信息、启发思考的那一个。</p>\n<p>完整的代码共享在：<a href=\"https://url11.ctfile.com/f/45455611-8635132430-f06d31?p=6872\" rel=\"noopener nofollow\" target=\"_blank\">面积图的2个变种.ipynb</a> (访问密码: 6872)</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 09:52</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wang_yb\">wang_yb</a>&nbsp;\n阅读(<span id=\"post_view_count\">114</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "基于 C# 和 Nuke 打造现代化构建系统的最佳实践",
      "link": "https://www.cnblogs.com/newbe36524/p/19536496",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19536496\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 08:54\">\n    <span>基于 C# 和 Nuke 打造现代化构建系统的最佳实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"告别脚本地狱为什么我们选择用-c-打造现代化构建系统\">告别脚本地狱：为什么我们选择用 C# 打造现代化构建系统</h1>\n<blockquote>\n<p>揭秘 HagiCode 项目如何利用 Nuke 实现类型安全、跨平台且高度可扩展的自动化构建流程，彻底解决传统构建脚本的维护痛点。</p>\n</blockquote>\n\n<h2 id=\"背景\">背景</h2>\n<p>在软件开发的漫长旅途中，\"构建\"这个词往往让人又爱又恨。爱的是，一键点击，代码变成产品，那是程序员最迷人的时刻；恨的是，维护那一堆乱糟糟的构建脚本，简直是噩梦。</p>\n<p>在很多项目中，我们习惯了用 Python 写脚本，或者用 XML 配置文件（想象一下那段被 <code>&lt;property&gt;</code> 支配的恐惧）。但随着项目复杂度的提升，尤其是像 HagiCode 这样涉及前后端、多平台、多语言混合开发的项目，传统的构建方式开始显得力不从心。脚本逻辑分散、缺乏类型检查、IDE 支持弱……这些问题像一个个小坑，时不时就让开发团队绊个跟头。</p>\n<p>为了解决这些痛点，在 HagiCode 项目中，我们决定引入 <strong>Nuke</strong> —— 一个基于 C# 的现代化构建系统。它不仅仅是一个工具，更像是一种对构建流程的重新思考。今天，我们就来聊聊为什么选择它，以及它是如何让我们的开发体验\"起飞\"的。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<blockquote>\n<p>嘿，介绍一下我们正在做的东西</p>\n</blockquote>\n<p>我们正在开发 <strong>HagiCode</strong> —— 一款 AI 驱动的代码智能助手，让开发体验变得更智能、更便捷、更有趣。</p>\n<p><strong>智能</strong> —— AI 全程辅助，从想法到代码，让编码效率提升数倍。<strong>便捷</strong> —— 多线程并发操作，充分利用资源，开发流程顺畅无阻。<strong>有趣</strong> —— 游戏化机制和成就系统，让编码不再枯燥，充满成就感。</p>\n<p>项目正在快速迭代中，如果你对技术写作、知识管理或者 AI 辅助开发感兴趣，欢迎来 <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">GitHub</a> 看看～</p>\n<h2 id=\"核心剖析为什么是-nuke\">核心剖析：为什么是 Nuke？</h2>\n<p>你可能心里会犯嘀咕：\"哎呀，构建系统那么多，比如 Make、Gradle，甚至直接用 Shell 脚本不行吗？为啥非得整一个 C# 的？\"</p>\n<p>这其实是个好问题。Nuke 的核心魅力在于它把我们最熟悉的编程语言特性带进了构建脚本的世界。</p>\n<h3 id=\"1-将构建流程模块化target-的艺术\">1. 将构建流程模块化：Target 的艺术</h3>\n<p>Nuke 的设计理念非常清晰：<strong>一切皆为目标</strong>。</p>\n<p>在传统的脚本里，我们可能会写出几百行线性执行的代码，逻辑错综复杂。而在 Nuke 中，我们将构建流程分解为独立的 <code>Target</code>（目标）。每个目标只负责一件事，比如：</p>\n<ul>\n<li><code>Clean</code>: 清理输出目录</li>\n<li><code>Restore</code>: 还原依赖包</li>\n<li><code>Compile</code>: 编译代码</li>\n<li><code>Test</code>: 运行单元测试</li>\n</ul>\n<p>这种设计非常符合单一职责原则。就像搭积木一样，我们可以随意组合这些 Target。更重要的是，Nuke 允许我们定义 Target 之间的依赖关系。比如，你想要 <code>Test</code>，那系统会自动检查你是否先执行了 <code>Compile</code>；想要 <code>Compile</code>，自然得先 <code>Restore</code>。</p>\n<p>这种依赖关系图不仅让逻辑更清晰，还极大地提高了执行效率，Nuke 会自动分析最优执行路径。</p>\n<h3 id=\"2-类型安全告别拼写错误的噩梦\">2. 类型安全：告别拼写错误的噩梦</h3>\n<p>用过 Python 写构建脚本的朋友肯定遇到过这种尴尬：脚本跑了五分钟，最后报错说 <code>Confi.guration</code> 拼写错了，或者传了一个字符串给了一个本该是数字的参数。</p>\n<p>使用 C# 编写构建脚本最大的优势就是 <strong>类型安全</strong>。这意味着：</p>\n<ul>\n<li><strong>编译时检查</strong>：你在敲代码的时候，IDE 就会告诉你哪里错了，不用等到运行时才发现。</li>\n<li><strong>重构无忧</strong>：如果你想改个变量名或者方法名，IDE 的重构功能一键搞定，不用全局搜索替换提心吊胆。</li>\n<li><strong>智能提示</strong>：强大的 IntelliSense 会自动补全代码，你不需要去翻文档记那些生僻的 API。</li>\n</ul>\n<h3 id=\"3-跨平台统一的构建体验\">3. 跨平台：统一的构建体验</h3>\n<p>以前在 Windows 上写 <code>.bat</code>，在 Linux 上写 <code>.sh</code>，为了兼容两者，还得写个 Python 脚本。现在，只要是 .NET Core（现 .NET 5+）能跑的地方，Nuke 就能跑。</p>\n<p>这意味着无论团队成员是使用 Windows、Linux 还是 macOS，无论是用 Visual Studio、VS Code 还是 Rider，大家执行的都是同一套逻辑。这就极大地消除了\"在我机器上能跑\"这类环境差异导致的问题。</p>\n<h3 id=\"4-参数与配置管理\">4. 参数与配置管理</h3>\n<p>Nuke 提供了一套非常优雅的参数解析机制。你不需要手动去解析 <code>string[] args</code>，只需要定义一个属性，加上 <code>[Parameter]</code> 特性，Nuke 就会自动处理命令行参数和配置文件的映射。</p>\n<p>比如，我们可以轻松定义构建配置：</p>\n<pre><code class=\"language-csharp\">[Parameter(\"Configuration to build - Default is 'Debug'\")]\nreadonly Configuration BuildConfiguration = IsLocalBuild ? Configuration.Debug : Configuration.Release;\n\nTarget Compile =&gt; _ =&gt; _\n    .DependsOn(Restore)\n    .Executes(() =&gt;\n    {\n        // 在这里使用 BuildConfiguration，它是类型安全的\n        DotNetBuild(s =&gt; s\n            .SetConfiguration(BuildConfiguration)\n            .SetProjectFile(SolutionFile));\n    });\n</code></pre>\n<p>这种写法既直观又不容易出错。</p>\n<h2 id=\"实践指南如何在项目中落地\">实践指南：如何在项目中落地</h2>\n<p>空谈误国，实干兴邦。让我们看看在 HagiCode 项目中，具体是怎么落地这套方案的。</p>\n<h3 id=\"1-规划项目结构\">1. 规划项目结构</h3>\n<p>我们不想让构建脚本污染项目根目录，也不想搞得像某些 Java 项目那样目录结构深不见底。所以，我们将所有与 Nuke 相关的构建文件统一放置在 <code>nukeBuild/</code> 文件夹中。</p>\n<p>这样做的好处是：</p>\n<ul>\n<li>项目根目录保持清爽。</li>\n<li>构建逻辑内聚，方便管理。</li>\n<li>新成员加入时，一眼就能看到\"哦，这是构建相关的逻辑\"。</li>\n</ul>\n<h3 id=\"2-设计清晰的-target-依赖链\">2. 设计清晰的 Target 依赖链</h3>\n<p>在设计 Target 时，我们遵循了一个原则：<strong>原子化 + 依赖流</strong>。</p>\n<p>每个 Target 应该足够小，只做一件事。比如 <code>Clean</code> 就只管删文件，不要在里面顺便做打包。</p>\n<p>推荐的依赖流大概是这个样子的：</p>\n<p><code>Clean</code> -&gt; <code>Restore</code> -&gt; <code>Compile</code> -&gt; <code>Test</code> -&gt; <code>Pack</code></p>\n<p>当然，这不是绝对的。比如如果你只想跑个测试，不想打包，Nuke 允许你直接执行 <code>nuke Test</code>，它会自动处理好前置的 Restore 和 Compile 步骤。</p>\n<h3 id=\"3-完善的错误处理与日志\">3. 完善的错误处理与日志</h3>\n<p>构建脚本最怕的是什么？是报错信息不明确。比如构建失败了，日志只显示 \"Error: 1\"，这就让人很抓狂。</p>\n<p>在 Nuke 中，由于我们可以直接使用 C# 的异常处理机制，因此可以非常精确地捕获和报告错误。</p>\n<pre><code class=\"language-csharp\">Target Publish =&gt; _ =&gt; _\n    .DependsOn(Test)\n    .Executes(() =&gt;\n    {\n        try \n        {\n            // 尝试发布到 NuGet\n            DotNetNuGetPush(s =&gt; s\n                .SetTargetPath(ArtifactPath)\n                .SetSource(\"https://api.nuget.org/v3/index.json\")\n                .SetApiKey(ApiKey));\n        }\n        catch (Exception ex)\n        {\n            Log.Error($\"发布失败了，兄弟们检查一下 Key 对不对: {ex.Message}\");\n            throw; // 确保构建进程以非零退出码结束\n        }\n    });\n</code></pre>\n<h3 id=\"4-集成测试保障质量\">4. 集成测试保障质量</h3>\n<p>构建脚本本身也是代码，也需要测试。Nuke 允许我们为构建流程编写测试，确保当我们修改了构建逻辑后，不会破坏现有的发布流程。这在持续集成（CI）流水线中尤为重要。</p>\n<h2 id=\"总结\">总结</h2>\n<p>通过引入 Nuke，HagiCode 的构建流程变得前所未有的顺畅。它不仅仅是一个工具的替换，更是工程化思维的提升。</p>\n<p><strong>我们收获了什么？</strong></p>\n<ul>\n<li><strong>可维护性</strong>：代码即配置，逻辑清晰，新人也能快速上手。</li>\n<li><strong>稳定性</strong>：强类型检查减少了 90% 以上的低级错误。</li>\n<li><strong>一致性</strong>：跨平台的统一体验，消除了环境差异。</li>\n</ul>\n<p>如果说以前写构建脚本是\"在黑暗中摸索\"，那么使用 Nuke 就像是\"开着灯走夜路\"。如果你受够了维护那些难以调试的脚本语言，不妨试试把构建逻辑也搬到 C# 的世界里来，也许你会发现，原来构建也可以这么优雅。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://nuke.build/\" rel=\"noopener nofollow\" target=\"_blank\">Nuke 官方文档</a></li>\n<li><a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">HagiCode 项目地址</a></li>\n<li><a href=\"https://learn.microsoft.com/en-us/archive/csharp-team/introducing-csharp-scripting\" rel=\"noopener nofollow\" target=\"_blank\">关于 C# Scripting 的更多细节</a></li>\n</ul>\n<hr />\n<p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p>\n<p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p>\n<ul>\n<li><strong>本文作者:</strong> <a href=\"https://www.newbe.pro\" rel=\"noopener nofollow\" target=\"_blank\">newbe36524</a></li>\n<li><strong>本文链接:</strong> <a href=\"https://hagicode-org.github.io/site/blog/2026/01/26/modern-build-system-with-csharp-and-nuke\" rel=\"noopener nofollow\" target=\"_blank\">https://hagicode-org.github.io/site/blog/2026/01/26/modern-build-system-with-csharp-and-nuke</a></li>\n<li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 08:54</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">410</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Sdcb Chats 1.10 私有化代码执行器部署教程",
      "link": "https://www.cnblogs.com/sdcb/p/19533814/chats-1-10-deploy",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sdcb/p/19533814/chats-1-10-deploy\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 08:45\">\n    <span>Sdcb Chats 1.10 私有化代码执行器部署教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>之前我写了这篇博客<a href=\"https://www.cnblogs.com/sdcb/p/19528764/chats-1-10\" target=\"_blank\">《复刻 ChatGPT 高级数据分析！Sdcb Chats 1.10 重磅发布：能分析Excel、做PPT》</a>，向大家介绍了 Chats 1.10 最激动人心的新功能——内置代码执行器（Code Interpreter）。</p>\n<p>文章发出后，反响很热烈，但也有很多朋友在问：“这功能看着很强，但到底怎么部署及其配置啊？”</p>\n<p>回头看了一下前一篇文章，确实光顾着兴奋地介绍功能，把最关键的<strong>部署实操</strong>给略过了。为了让大家都能尽快用上这个“硬核”功能，今天特地补上这篇详细的保姆级部署配置文档。</p>\n<hr />\n<p>想要在 Chats 中使用“代码执行”功能，主要分两步走：</p>\n<ol>\n<li><strong>基础设施层</strong>：让 Chats 服务能连上 Docker Daemon（因为代码是在隔离的 Docker 容器中运行的）。</li>\n<li><strong>应用配置层</strong>：在 Chats 后台和前台开启相应的功能开关。</li>\n</ol>\n<h2 id=\"第一部分连接-docker-daemon\">第一部分：连接 Docker Daemon</h2>\n<p>Chats 的代码执行器原理是：当模型需要执行代码时，Chats 会动态创建一个一次性的 Docker 容器（沙箱），在里面运行代码并获取结果。因此，<strong>Chats 必须拥有管理 Docker 的权限</strong>。</p>\n<p>这里主要介绍两种最常见的场景：纯 Docker 环境（Linux 服务器）和 Windows 下的 Docker Desktop。</p>\n<h3 id=\"场景一linux-服务器--纯-docker-环境\">场景一：Linux 服务器 / 纯 Docker 环境</h3>\n<p>这是生产环境最常用的方式。你只需要将宿主机的 Docker Socket 挂载到 Chats 容器中即可。</p>\n<p><img alt=\"00-docker\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260126155139396-122617623.avif\" /></p>\n<h4 id=\"1-docker-镜像说明\">1. Docker 镜像说明</h4>\n<p>Chats 的 Docker 镜像托管在 <code>sdcb/chats</code>，我们提供了完善的多架构支持：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">描述</th>\n<th style=\"text-align: left;\">Docker 镜像 Tag</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>Latest（推荐）</strong></td>\n<td style=\"text-align: left;\"><code>latest</code></td>\n<td style=\"text-align: left;\">包含最新稳定版功能，多架构支持</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">指定完整版本</td>\n<td style=\"text-align: left;\"><code>{version}</code> (如 <code>1.10.0</code>)</td>\n<td style=\"text-align: left;\">生产环境推荐锁定版本</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">指定主/次版本</td>\n<td style=\"text-align: left;\"><code>{major}</code> / <code>{major.minor}</code></td>\n<td style=\"text-align: left;\">如 <code>1</code>, <code>1.10</code>，自动更新到该系列最新版</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">特定平台</td>\n<td style=\"text-align: left;\"><code>...-linux-x64</code> 等</td>\n<td style=\"text-align: left;\">仅在必须手动指定架构时使用</td>\n</tr>\n</tbody>\n</table>\n<p><strong>关于 Manifest (多架构支持)</strong>：<br />\n我们的 <code>latest</code> 和语义化版本标签（如 <code>1.10.0</code>）都是 <strong>Manifest List</strong>。这意味着你<strong>不需要</strong>手动区分 <code>linux-x64</code> 还是 <code>linux-arm64</code>。<br />\n无论你在 x64 的 Linux 服务器、ARM64 的树莓派，还是 Windows Server (Nano Server) 上执行 <code>docker pull sdcb/chats:latest</code>，Docker 都会自动检测并拉取最适合当前系统的镜像层。</p>\n<h4 id=\"2-启动配置\">2. 启动配置</h4>\n<p>由于 Docker Socket 默认属于 root 用户，为了避免权限问题（Permission Denied），建议显式指定 <code>--user 0:0</code> 以 root 身份运行容器。</p>\n<p>在启动 Chats 的 <code>docker run</code> 命令或 <code>docker-compose.yml</code> 中，添加 user 配置和挂载卷：</p>\n<pre><code class=\"language-bash\">-v /var/run/docker.sock:/var/run/docker.sock --user 0:0\n</code></pre>\n<p><strong>完整的 docker run 命令示例</strong>：</p>\n<pre><code class=\"language-bash\"># 创建数据目录并授权\nmkdir -p ./AppData &amp;&amp; chmod 755 ./AppData\n\n# 启动容器\ndocker run -d --restart unless-stopped --name sdcb-chats \\\n  -p 8080:8080 \\\n  -e DBType=sqlite \\\n  -e ConnectionStrings__ChatsDB=\"Data Source=./AppData/chats.db\" \\\n  -v ./AppData:/app/AppData \\\n  -v /var/run/docker.sock:/var/run/docker.sock --user 0:0 \\\n  sdcb/chats:latest\n</code></pre>\n<p><strong>示例 docker-compose.yml</strong>：</p>\n<pre><code class=\"language-yaml\">version: '3'\nservices:\n  chats:\n    image: sdcb/chats:latest\n    user: 0:0 # 关键：必须使用 root 用户才能访问 docker.sock\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock # 关键配置：挂载 Docker 守护进程\n      - ./data:/app/data\n    ports:\n      - \"8080:8080\"\n</code></pre>\n<h3 id=\"场景二windows-环境\">场景二：Windows 环境</h3>\n<p>在 Windows (使用 Docker Desktop) 上部署时，情况稍微特殊一点，取决于你是<strong>在 Docker 容器内运行 Chats</strong>，还是<strong>直接运行 Chats 的 Windows 可执行文件 (.exe)</strong>。</p>\n<h4 id=\"情况-achats-运行在-docker-容器内推荐\">情况 A：Chats 运行在 Docker 容器内（推荐）</h4>\n<p>如果你是通过 <code>docker run</code> 启动 Chats 的，那么恭喜你，配置方法其实和 Linux <strong>完全一样</strong>！</p>\n<p>Docker Desktop for Windows 做了很好的兼容，你只需要把 <code>/var/run/docker.sock</code> 挂载进去即可，<strong>不需要</strong>配置 npipe 或 TCP。</p>\n<p><strong>PowerShell 启动命令示例</strong>：</p>\n<pre><code class=\"language-powershell\">docker run -d -p 8080:8080 `\n  -v /var/run/docker.sock:/var/run/docker.sock `\n  -v ${PWD}/data:/app/data `\n  sdcb/chats:latest\n</code></pre>\n<h4 id=\"情况-bchats-作为原生可执行文件运行\">情况 B：Chats 作为原生可执行文件运行</h4>\n<p>如果你不习惯使用 Docker 部署应用，我们提供了基于预编译的原生可执行文件，<strong>无需安装任何运行时</strong>（如 .NET SDK/Runtime）即可直接运行，启动速度较快且内存占用低。</p>\n<p><strong>可执行文件列表</strong>：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">平台</th>\n<th style=\"text-align: left;\">文件名</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>Windows 64位</strong></td>\n<td style=\"text-align: left;\"><code>chats-win-x64.zip</code></td>\n<td style=\"text-align: left;\">推荐大多数 Windows 用户</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Linux 64位</td>\n<td style=\"text-align: left;\"><code>chats-linux-x64.zip</code></td>\n<td style=\"text-align: left;\">常见的 Linux 服务器 (glibc)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Linux ARM64</td>\n<td style=\"text-align: left;\"><code>chats-linux-arm64.zip</code></td>\n<td style=\"text-align: left;\">树莓派、Mac M系列docker等</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Linux Musl</td>\n<td style=\"text-align: left;\"><code>chats-linux-musl-*.zip</code></td>\n<td style=\"text-align: left;\">适用于 Alpine 等轻量级发行版</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">macOS</td>\n<td style=\"text-align: left;\"><code>chats-osx-*.zip</code></td>\n<td style=\"text-align: left;\">支持 x64 (Intel) 和 ARM64 (M系列芯片)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">通用包</td>\n<td style=\"text-align: left;\"><code>chats.zip</code></td>\n<td style=\"text-align: left;\"><strong>需安装 .NET 10</strong>，跨平台</td>\n</tr>\n</tbody>\n</table>\n<p>你可以从 <a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/downloads.md\" rel=\"noopener nofollow\" target=\"_blank\">下载指南文档</a> 页面获取下载地址。该文档详细列出了 GitHub Releases 及国内加速镜像的下载方式。</p>\n<p><strong>配置与启动</strong>：</p>\n<p>如果你下载了 <code>Chats.BE.exe</code> (Windows 版后端) 直接运行，而不是使用 Docker 镜像，那么你需要通过命令行参数指定 Windows 的<strong>命名管道 (Named Pipe)</strong> 来连接 Docker 引擎。</p>\n<ol>\n<li><strong>下载程序</strong>：下载并解压对应的 <code>chats-win-x64.zip</code>。</li>\n<li><strong>启动命令</strong>：使用 <code>--CodePod:DockerEndpoint</code> 参数指定 Docker 接入点。</li>\n</ol>\n<p><strong>PowerShell 启动命令示例</strong>：</p>\n<pre><code class=\"language-powershell\"># 启动后端程序，并指定 Docker 引擎地址\n.\\Chats.BE.exe --CodePod:DockerEndpoint npipe://./pipe/docker_engine\n</code></pre>\n<p>你也可以同时指定其它参数（如端口）：</p>\n<pre><code class=\"language-powershell\">.\\Chats.BE.exe --urls http://+:5000 --CodePod:DockerEndpoint npipe://./pipe/docker_engine\n</code></pre>\n<p>这样，原生运行的 Chats 也能顺利指挥 Docker Desktop 创建沙箱环境了。</p>\n<hr />\n<h2 id=\"第二部分在-chats-中启用功能\">第二部分：在 Chats 中启用功能</h2>\n<p>连上 Docker 只是打通了经脉，接下来还需要在 Chats 内部“解锁”这个技能。</p>\n<h3 id=\"1-后端配置模型设置\">1. 后端配置：模型设置</h3>\n<p>首先，我们要告诉 Chats，哪些模型允许使用这个能力。</p>\n<ol>\n<li>以管理员身份登录 Chats。</li>\n<li>进入<strong>后台管理</strong> -&gt; <strong>模型配置</strong>。</li>\n<li>展开你想要的模型提供商-&gt;模型密钥，然后编辑你想要使用的模型（例如deepseek-v3.2）。\n<ul>\n<li><strong>注意</strong>：任何支持 Tool Call (工具调用) 的模型 API 都可以，无论是 OpenAI 原生的 Chat Completions，还是Responses API/Messages API。</li>\n</ul>\n</li>\n<li>在功能列表中，找到并勾选 <strong>“代码执行 (Code Execution)”</strong>。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260126151714293-1229825697.avif\" /></li>\n</ol>\n<p><strong>⚠️ 特别注意：用户权限分配</strong></p>\n<p>很多第一次添加模型的朋友容易忽略这一点：<strong>启用功能后，必须明确授权给用户。</strong></p>\n<p>在模型编辑页面的底部，展开<strong>用户列表 (User Access)</strong>，确保<strong>给你自己的账号（或需要使用的用户）勾选上权限</strong>。如果不勾选，你在前台是看不到这个模型的，或者无法调用该功能。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260126151715025-1987207460.avif\" /></p>\n<h3 id=\"2-前端配置开启会话开关\">2. 前端配置：开启会话开关</h3>\n<p>后端准备就绪后，最后一步是在聊天界面开启使用。</p>\n<ol>\n<li>回到<strong>聊天 (Chat)</strong> 界面。</li>\n<li>在顶部的模型配置栏（通常显示模型名称的地方），点击展开配置面板。</li>\n<li>找到 <strong>“代码执行”</strong> 开关，将其打开。</li>\n</ol>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260126151715455-1639921351.avif\" /></p>\n<hr />\n<h2 id=\"效果演示\">效果演示</h2>\n<p>一切就绪！现在你可以像使用 ChatGPT 的高级数据分析一样，上传一个 Excel 文件，或者让它帮你画一张图表了。</p>\n<p>试试发送这样的指令：</p>\n<blockquote>\n<p>请帮我分析这个 Excel 文件：<a href=\"https://cv-public.sdcb.pub/2026/changsha_weather_2025.xlsx%EF%BC%8C%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AA%E5%8C%85%E5%90%AB%E6%AF%8F%E6%9C%88%E5%B9%B3%E5%9D%87%E6%B0%94%E6%B8%A9%E5%92%8C%E9%99%8D%E6%B0%B4%E9%87%8F%E7%9A%84%E6%8A%A5%E5%91%8A%EF%BC%8C%E5%B9%B6%E9%99%84%E4%B8%8A%E5%9B%BE%E8%A1%A8\" rel=\"noopener nofollow\" target=\"_blank\">https://cv-public.sdcb.pub/2026/changsha_weather_2025.xlsx，生成一个包含每月平均气温和降水量的报告，并附上图表</a></p>\n</blockquote>\n<p>Chats 会自动创建一个隔离的 Docker 环境，编写 Python 代码，执行并把生成的图片直接贴在对话框里。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102328487-114968639.avif\" /></p>\n<hr />\n<h2 id=\"安全性考量\">安全性考量</h2>\n<p>⚠️ <strong>重要提示</strong>：与模型 API 调用不同，代码执行功能目前<strong>不进行任何计费</strong>，仅通过全局配置做了一些基础限制。如果你打算将 Chats 开放给未经充分信任的用户使用（例如搭建类似 ChatGPT/Manus 的公开服务），务必认真配置以下安全策略，避免服务器资源被滥用甚至被攻击。</p>\n<h3 id=\"1-网络隔离\">1. 网络隔离</h3>\n<p>代码执行容器的默认网络模式为 <code>bridge</code>，这与 ChatGPT 的完全隔离沙箱不同——<strong>容器是可以联网的</strong>。</p>\n<p>这个设计是有意为之的，因为它带来了更强大的能力：</p>\n<ul>\n<li>AI 可以在容器内下载文件、调用外部 API、安装依赖包。</li>\n<li>甚至可以让 AI 创建多个 Docker 容器协同工作（比如一个跑 Web 应用、一个跑数据库），Chats 会在工具调用响应中返回容器的局域网 IP 地址，模型可以据此进行容器间通信。</li>\n</ul>\n<p>但这也意味着潜在风险：</p>\n<ul>\n<li>容器可以访问宿主机同一 Docker 网络内的其他服务（包括你的数据库、Redis 等）。</li>\n<li>恶意用户可能利用此能力进行内网扫描或攻击。</li>\n</ul>\n<p><strong>建议</strong>：</p>\n<ul>\n<li><strong>安全敏感环境</strong>：将 <code>CodeInterpreter:MaxAllowedNetworkMode</code> 设置为 <code>none</code>，完全禁止容器联网。</li>\n<li><strong>物理隔离</strong>：在一台独立的虚拟机或物理机上运行 Docker Daemon，Chats 通过 TCP 远程连接，从而实现网络层面的彻底隔离。</li>\n</ul>\n<h3 id=\"2-资源限制\">2. 资源限制</h3>\n<p>AI 可以创建任意数量的 Docker 会话（通过 <code>create_docker_session</code> 工具）。虽然空闲会话会在一定时间后自动清理，但仍存在以下风险：</p>\n<ul>\n<li><strong>算力滥用</strong>：恶意用户可能运行高负载任务，耗尽服务器 CPU/内存。</li>\n<li><strong>磁盘占用</strong>：AI 可能拉取不同版本的镜像，这些镜像<strong>不会自动清理</strong>，长期积累会占满磁盘。</li>\n</ul>\n<p>Chats 提供了细粒度的资源限制配置，<strong>强烈建议根据实际情况调整</strong>：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">配置项</th>\n<th style=\"text-align: left;\">默认值</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:DefaultResourceLimits:MemoryBytes</code></td>\n<td style=\"text-align: left;\"><code>2147483648</code> (2GB)</td>\n<td style=\"text-align: left;\">单个容器内存上限</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:DefaultResourceLimits:CpuCores</code></td>\n<td style=\"text-align: left;\"><code>2.0</code></td>\n<td style=\"text-align: left;\">单个容器 CPU 核数</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:DefaultResourceLimits:MaxProcesses</code></td>\n<td style=\"text-align: left;\"><code>200</code></td>\n<td style=\"text-align: left;\">单个容器最大进程数</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:MaxResourceLimits:*</code></td>\n<td style=\"text-align: left;\"><code>null</code> (不限制)</td>\n<td style=\"text-align: left;\">硬上限，防止 AI 请求超额资源</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:SessionIdleTimeoutSeconds</code></td>\n<td style=\"text-align: left;\"><code>1800</code> (30分钟)</td>\n<td style=\"text-align: left;\">空闲会话自动回收时间</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:DefaultTimeoutSeconds</code></td>\n<td style=\"text-align: left;\"><code>300</code> (5分钟)</td>\n<td style=\"text-align: left;\">单次命令执行超时</td>\n</tr>\n</tbody>\n</table>\n<p>默认的 2 核 2GB 配置可以完成大多数日常任务（数据分析、图表生成、文档处理等）。如果你的场景需要更多资源（如视频处理、大规模计算），可以适当放宽；反之，如果是公开服务，建议收紧限制。</p>\n<h3 id=\"3-文件上传限制\">3. 文件上传限制</h3>\n<p>AI 执行代码后可以将生成的文件（artifacts）回传给用户。为防止滥用，Chats 也提供了相应限制：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">配置项</th>\n<th style=\"text-align: left;\">默认值</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:MaxArtifactsFilesToUpload</code></td>\n<td style=\"text-align: left;\"><code>50</code></td>\n<td style=\"text-align: left;\">每轮最多回传文件数</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:MaxSingleUploadBytes</code></td>\n<td style=\"text-align: left;\"><code>157286400</code> (150MB)</td>\n<td style=\"text-align: left;\">单个文件最大大小</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><code>CodeInterpreter:MaxTotalUploadBytesPerTurn</code></td>\n<td style=\"text-align: left;\"><code>314572800</code> (300MB)</td>\n<td style=\"text-align: left;\">单轮总上传大小</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"4-其他建议\">4. 其他建议</h3>\n<ul>\n<li><strong>定期清理镜像</strong>：使用 <code>docker image prune</code> 或 <code>docker system prune</code> 定期清理未使用的镜像和悬挂资源。</li>\n<li><strong>监控与告警</strong>：对 Docker 宿主机的 CPU、内存、磁盘使用率设置监控告警。</li>\n<li><strong>用户权限管理</strong>：仅对信任的用户开放代码执行功能，在模型配置中谨慎分配权限。</li>\n</ul>\n<p>更多配置细节请参考：<a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/configuration.md\" rel=\"noopener nofollow\" target=\"_blank\">配置说明文档</a></p>\n<hr />\n<h2 id=\"结语\">结语</h2>\n<p>希望这篇文档能帮你顺利部署 Chats 1.10，体验完全私有化、可控的代码解释器功能。</p>\n<p>感谢阅读！喜欢的朋友请给我的 GitHub 项目一个 star：<br />\n<a href=\"https://github.com/sdcb/chats\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats</a></p>\n<p>这是完整的更新日志，包含更多技术细节：<br />\n<a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md</a></p>\n<p>有什么想法也欢迎在评论区留言交流，也欢迎加入我的新创建的微信群：</p>\n<p><img alt=\"\" src=\"https://io.starworks.cc:88/cv-public/2026/chats-wxg-qr.png\" /></p>\n<p>如果你更习惯用 QQ 的话，也可以加入 Chats QQ 群：<strong>498452653</strong>，我们一起探索更多 AI 技术硬核玩法。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 08:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sdcb\">.NET骚操作</a>&nbsp;\n阅读(<span id=\"post_view_count\">180</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}