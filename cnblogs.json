{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "Grafana Loki自动监控日志",
      "link": "https://www.cnblogs.com/ZouYua/p/19462083",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ZouYua/p/19462083\" id=\"cb_post_title_url\" title=\"发布于 2026-01-09 16:06\">\n    <span>Grafana Loki自动监控日志</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"grafana-loki-日志监控配置指南\">Grafana Loki 日志监控配置指南</h1>\n<p><img alt=\"d3135d676e_1_k-hdOAQjRXKoyguzKuoeKg\" src=\"https://img2024.cnblogs.com/blog/3196947/202601/3196947-20260109160333955-1410605029.jpg\" /></p>\n<h2 id=\"前言\">前言</h2>\n<p>在微服务架构中，日志收集和分析是运维的重要环节。本文介绍如何使用 Grafana Loki 搭建轻量级日志监控系统，并与传统的 ELK 技术栈进行对比。</p>\n<h2 id=\"loki-vs-elk-技术栈对比\">Loki vs ELK 技术栈对比</h2>\n<h3 id=\"架构对比\">架构对比</h3>\n<table>\n<thead>\n<tr>\n<th>组件</th>\n<th>ELK</th>\n<th>Loki</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>日志采集</td>\n<td>Logstash / Filebeat</td>\n<td>Promtail</td>\n</tr>\n<tr>\n<td>日志存储</td>\n<td>Elasticsearch</td>\n<td>Loki</td>\n</tr>\n<tr>\n<td>可视化</td>\n<td>Kibana</td>\n<td>Grafana</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"核心差异\">核心差异</h3>\n<table>\n<thead>\n<tr>\n<th>对比项</th>\n<th>ELK</th>\n<th>Loki</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>索引方式</td>\n<td>全文索引</td>\n<td>仅索引标签（Label）</td>\n</tr>\n<tr>\n<td>存储占用</td>\n<td>高（原始日志 + 索引）</td>\n<td>低（压缩存储，索引小）</td>\n</tr>\n<tr>\n<td>资源消耗</td>\n<td>高（ES 需要大量内存）</td>\n<td>低（单机 256MB 可运行）</td>\n</tr>\n<tr>\n<td>查询方式</td>\n<td>Lucene 语法</td>\n<td>LogQL（类 PromQL）</td>\n</tr>\n<tr>\n<td>查询速度</td>\n<td>全文搜索快</td>\n<td>标签过滤快，全文搜索慢</td>\n</tr>\n<tr>\n<td>部署复杂度</td>\n<td>复杂（多组件协调）</td>\n<td>简单（3 个容器即可）</td>\n</tr>\n<tr>\n<td>学习成本</td>\n<td>较高</td>\n<td>较低（熟悉 Prometheus 更容易）</td>\n</tr>\n<tr>\n<td>与 Prometheus 集成</td>\n<td>需额外配置</td>\n<td>原生集成</td>\n</tr>\n</tbody>\n</table>\n<p><img alt=\"567ffc184541f44c0384d02f8b991447\" src=\"https://img2024.cnblogs.com/blog/3196947/202601/3196947-20260109160412006-423286371.jpg\" /></p>\n<p><img alt=\"056f09368ad6dde870727e48171c89ee\" src=\"https://img2024.cnblogs.com/blog/3196947/202601/3196947-20260109160528026-1366870051.gif\" /></p>\n<h3 id=\"选型建议\">选型建议</h3>\n<p><strong>选择 ELK 的场景：</strong></p>\n<ul>\n<li>需要复杂的全文搜索</li>\n<li>日志分析是核心业务需求</li>\n<li>有专门的运维团队</li>\n<li>服务器资源充足</li>\n</ul>\n<p><strong>选择 Loki 的场景：</strong></p>\n<ul>\n<li>中小型项目，资源有限</li>\n<li>已使用 Prometheus + Grafana 监控体系</li>\n<li>主要需求是日志查看和简单过滤</li>\n<li>追求快速部署和低维护成本</li>\n</ul>\n<h2 id=\"系统架构\">系统架构</h2>\n<pre><code>┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n│  微服务应用   │ ──▶ │   日志文件   │ ──▶ │  Promtail   │ ──▶ │    Loki     │\n│ (Java/Go等) │     │ (.log files)│     │  (采集器)    │     │  (存储)      │\n└─────────────┘     └─────────────┘     └─────────────┘     └──────┬──────┘\n                                                                    │\n                                                                    ▼\n                                                            ┌─────────────┐\n                                                            │   Grafana   │\n                                                            │  (可视化)    │\n                                                            └─────────────┘\n</code></pre>\n<h2 id=\"环境准备\">环境准备</h2>\n<ul>\n<li>Docker 20.10+</li>\n<li>Docker Compose 2.0+</li>\n<li>服务器内存 &gt;= 2GB</li>\n</ul>\n<h2 id=\"目录结构\">目录结构</h2>\n<pre><code>/docker/\n├── docker-compose.yaml\n├── loki/\n│   └── loki-config.yaml\n└── promtail/\n    └── promtail-config.yaml\n</code></pre>\n<h2 id=\"配置文件\">配置文件</h2>\n<h3 id=\"1-loki-配置-loki-configyaml\">1. Loki 配置 (loki-config.yaml)</h3>\n<pre><code class=\"language-yaml\">auth_enabled: false\n\nserver:\n  http_listen_port: 3100\n  grpc_listen_port: 9096\n\ncommon:\n  instance_addr: 127.0.0.1\n  path_prefix: /loki\n  storage:\n    filesystem:\n      chunks_directory: /loki/chunks\n      rules_directory: /loki/rules\n  replication_factor: 1\n  ring:\n    kvstore:\n      store: inmemory\n\nquery_range:\n  results_cache:\n    cache:\n      embedded_cache:\n        enabled: true\n        max_size_mb: 100\n\nlimits_config:\n  metric_aggregation_enabled: true\n  retention_period: 720h  # 日志保留 30 天\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: tsdb\n      object_store: filesystem\n      schema: v13\n      index:\n        prefix: index_\n        period: 24h\n\npattern_ingester:\n  enabled: true\n  metric_aggregation:\n    loki_address: localhost:3100\n\ncompactor:\n  working_directory: /loki/compactor\n  retention_enabled: true\n  delete_request_store: filesystem\n\nfrontend:\n  encoding: protobuf\n</code></pre>\n<p><strong>配置说明：</strong></p>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>auth_enabled: false</code></td>\n<td>关闭认证，单机部署使用</td>\n</tr>\n<tr>\n<td><code>http_listen_port: 3100</code></td>\n<td>Loki HTTP API 端口</td>\n</tr>\n<tr>\n<td><code>path_prefix: /loki</code></td>\n<td>数据存储路径前缀</td>\n</tr>\n<tr>\n<td><code>retention_period: 720h</code></td>\n<td>日志保留 30 天</td>\n</tr>\n<tr>\n<td><code>store: tsdb</code></td>\n<td>使用 TSDB 存储引擎（Loki 3.x 推荐）</td>\n</tr>\n<tr>\n<td><code>schema: v13</code></td>\n<td>最新的 schema 版本</td>\n</tr>\n<tr>\n<td><code>embedded_cache</code></td>\n<td>内置查询缓存，提升查询性能</td>\n</tr>\n<tr>\n<td><code>compactor</code></td>\n<td>自动压缩和清理过期日志</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"2-promtail-配置-promtail-configyaml\">2. Promtail 配置 (promtail-config.yaml)</h3>\n<pre><code class=\"language-yaml\">server:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /tmp/positions.yaml\n\nclients:\n  - url: http://loki:3100/loki/api/v1/push\n\nscrape_configs:\n  - job_name: xiaohashu\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: xiaohashu\n          __path__: /var/log/xiaohashu/*.log\n\n    pipeline_stages:\n      # 从文件名提取服务名: note.2025-07-01-0.log → service=note\n      - regex:\n          source: filename\n          expression: '(?P&lt;service&gt;[a-z-]+)\\.\\d{4}-\\d{2}-\\d{2}-\\d+\\.log$'\n      - labels:\n          service:\n      \n      # 从日志内容提取级别: INFO/WARN/ERROR/DEBUG\n      - regex:\n          expression: '^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3} \\[[^\\]]+\\] (?P&lt;level&gt;\\w+)'\n      - labels:\n          level:\n</code></pre>\n<p><strong>配置说明：</strong></p>\n<table>\n<thead>\n<tr>\n<th>配置项</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>positions.filename</code></td>\n<td>记录读取位置，重启后继续读取</td>\n</tr>\n<tr>\n<td><code>clients.url</code></td>\n<td>Loki 推送地址</td>\n</tr>\n<tr>\n<td><code>__path__</code></td>\n<td>日志文件匹配路径</td>\n</tr>\n<tr>\n<td><code>pipeline_stages</code></td>\n<td>日志处理管道</td>\n</tr>\n<tr>\n<td><code>regex</code> + <code>labels</code></td>\n<td>从文件名/内容提取标签</td>\n</tr>\n</tbody>\n</table>\n<p><strong>日志格式示例：</strong></p>\n<pre><code>2025-07-01 10:30:00.123 [main] INFO  com.example.Service - 启动成功\n</code></pre>\n<p>经过 pipeline 处理后，会自动添加标签：</p>\n<ul>\n<li><code>service=note</code>（从文件名提取）</li>\n<li><code>level=INFO</code>（从日志内容提取）</li>\n</ul>\n<h3 id=\"3-docker-compose-配置\">3. Docker Compose 配置</h3>\n<pre><code class=\"language-yaml\">services:\n  loki:\n    image: grafana/loki:3.5.0\n    container_name: loki\n    ports:\n      - \"3100:3100\"\n    volumes:\n      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml\n      - loki-data:/loki\n    command: -config.file=/etc/loki/local-config.yaml\n    restart: unless-stopped\n\n  promtail:\n    image: grafana/promtail:3.5.0\n    container_name: promtail\n    volumes:\n      - ./promtail/promtail-config.yaml:/etc/promtail/config.yaml\n      - /www/wwwroot/life_diary/logs:/var/log/xiaohashu:ro\n    command: -config.file=/etc/promtail/config.yaml\n    restart: unless-stopped\n    depends_on:\n      - loki\n\n  grafana:\n    image: grafana/grafana:11.4.0\n    container_name: grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=admin123\n    volumes:\n      - grafana-data:/var/lib/grafana\n    restart: unless-stopped\n    depends_on:\n      - loki\n\nvolumes:\n  loki-data:\n  grafana-data:\n</code></pre>\n<p><strong>关键配置说明：</strong></p>\n<table>\n<thead>\n<tr>\n<th>配置</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>loki-data:/loki</code></td>\n<td>Loki 数据持久化，容器重启不丢失</td>\n</tr>\n<tr>\n<td><code>/www/wwwroot/life_diary/logs:/var/log/xiaohashu:ro</code></td>\n<td>挂载宿主机日志目录，<code>:ro</code> 表示只读</td>\n</tr>\n<tr>\n<td><code>grafana-data:/var/lib/grafana</code></td>\n<td>Grafana 配置持久化</td>\n</tr>\n<tr>\n<td><code>depends_on</code></td>\n<td>服务启动依赖顺序</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"部署步骤\">部署步骤</h2>\n<h3 id=\"1-创建目录和配置文件\">1. 创建目录和配置文件</h3>\n<pre><code class=\"language-bash\">mkdir -p /docker/loki /docker/promtail\ncd /docker\n\n# 创建配置文件（内容见上文）\nvim loki/loki-config.yaml\nvim promtail/promtail-config.yaml\nvim docker-compose.yaml\n</code></pre>\n<h3 id=\"2-启动服务\">2. 启动服务</h3>\n<pre><code class=\"language-bash\">cd /docker\ndocker-compose up -d\n</code></pre>\n<h3 id=\"3-查看服务状态\">3. 查看服务状态</h3>\n<pre><code class=\"language-bash\">docker-compose ps\ndocker-compose logs -f loki      # 查看 Loki 日志\ndocker-compose logs -f promtail  # 查看 Promtail 日志\n</code></pre>\n<h3 id=\"4-配置-grafana-数据源\">4. 配置 Grafana 数据源</h3>\n<ol>\n<li>浏览器访问 <code>http://服务器IP:3000</code></li>\n<li>登录（默认 admin / admin123）</li>\n<li>左侧菜单 → <strong>Connections</strong> → <strong>Data sources</strong></li>\n<li>点击 <strong>Add data source</strong> → 选择 <strong>Loki</strong></li>\n<li>URL 填写：<code>http://loki:3100</code></li>\n<li>点击 <strong>Save &amp; Test</strong>，显示绿色 ✓ 表示成功</li>\n</ol>\n<h2 id=\"logql-查询语法\">LogQL 查询语法</h2>\n<h3 id=\"基础查询\">基础查询</h3>\n<pre><code class=\"language-logql\"># 查看所有日志\n{job=\"xiaohashu\"}\n\n# 按服务筛选\n{service=\"note\"}\n{service=\"gateway\"}\n\n# 按日志级别筛选\n{level=\"ERROR\"}\n{level=\"WARN\"}\n\n# 组合条件\n{service=\"note\", level=\"ERROR\"}\n</code></pre>\n<h3 id=\"关键字搜索\">关键字搜索</h3>\n<pre><code class=\"language-logql\"># 包含关键字\n{job=\"xiaohashu\"} |= \"Exception\"\n{service=\"note\"} |= \"NullPointer\"\n\n# 不包含关键字\n{service=\"gateway\"} != \"health\"\n\n# 正则匹配\n{job=\"xiaohashu\"} |~ \"user.*login\"\n</code></pre>\n<h3 id=\"统计分析\">统计分析</h3>\n<pre><code class=\"language-logql\"># 最近 5 分钟各服务错误数\ncount_over_time({level=\"ERROR\"}[5m]) by (service)\n\n# 每分钟日志量\nrate({job=\"xiaohashu\"}[1m])\n\n# 错误率\nsum(rate({level=\"ERROR\"}[5m])) / sum(rate({job=\"xiaohashu\"}[5m]))\n</code></pre>\n<h2 id=\"常用运维命令\">常用运维命令</h2>\n<pre><code class=\"language-bash\"># 启动所有服务\ndocker-compose up -d\n\n# 停止所有服务\ndocker-compose down\n\n# 重启单个服务\ndocker-compose restart loki\n\n# 查看资源占用\ndocker stats loki promtail grafana\n\n# 查看日志\ndocker-compose logs -f --tail=100 loki\n\n# 清理旧数据（谨慎使用）\ndocker volume rm docker_loki-data\n</code></pre>\n<h2 id=\"常见问题\">常见问题</h2>\n<h3 id=\"1-promtail-cpu-占用高\">1. Promtail CPU 占用高</h3>\n<p>刚启动时需要扫描历史日志，属于正常现象。等处理完历史数据后会降下来。</p>\n<h3 id=\"2-grafana-连接-loki-失败\">2. Grafana 连接 Loki 失败</h3>\n<p>检查 URL 是否正确，容器内部通信使用服务名 <code>http://loki:3100</code>，不是 <code>localhost</code>。</p>\n<h3 id=\"3-看不到日志\">3. 看不到日志</h3>\n<ul>\n<li>检查日志路径挂载是否正确</li>\n<li>检查 Promtail 日志：<code>docker logs promtail</code></li>\n<li>确认日志文件名格式与 <code>__path__</code> 匹配</li>\n</ul>\n<h3 id=\"4-磁盘空间不足\">4. 磁盘空间不足</h3>\n<p>调整 <code>retention_period</code> 缩短保留时间，或手动清理：</p>\n<pre><code class=\"language-bash\">docker-compose down\ndocker volume rm docker_loki-data\ndocker-compose up -d\n</code></pre>\n<h2 id=\"总结\">总结</h2>\n<p>Grafana Loki 相比 ELK 更加轻量，适合中小型项目和资源有限的场景。通过合理配置 Promtail 的 pipeline，可以自动提取服务名和日志级别，实现高效的日志查询和分析。</p>\n<p>对于已经使用 Prometheus + Grafana 的团队，Loki 是日志监控的最佳选择，可以在同一个 Grafana 界面中同时查看指标和日志，大大提升排查问题的效率。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-09 16:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ZouYua\">zouyua</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "EF Core自定义映射PostgreSQL原生函数",
      "link": "https://www.cnblogs.com/netry/p/19452236/efcore_jsonb_extract_path_text_in_postgredb",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/netry/p/19452236/efcore_jsonb_extract_path_text_in_postgredb\" id=\"cb_post_title_url\" title=\"发布于 2026-01-09 15:09\">\n    <span>EF Core自定义映射PostgreSQL原生函数</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"背景\">背景</h1>\n<p>在 ASP.NET Core 应用开发中，使用 PostgreSQL的<code>jsonb</code>类型存储多语言数据是一种常见的方案。这种方式相比传统的多列存储或独立翻译表，在模式定义上更加灵活。</p>\n<p>例如，对于一个包含多语言简介的“艺术家”实体，我们通常如下定义：</p>\n<pre class=\"language-cs\"><code class=\"language-cs\">public class ArtistEntity \n{\n    public int Id { get; set; }\n\n    // 使用 jsonb 存储多语言字典：Key=语言代码(en, zh-CN), Value=内容\n    [Column(TypeName = \"jsonb\")] \n    public Dictionary&lt;string, string&gt; Biography { get; set; } = [];\n}</code></pre><h1 id=\"性能考量\">性能考量</h1>\n<p>虽然存储方便，但在读取时会面临流量和性能问题。在大多数业务场景中，前端仅需要展示当前用户语言（如英语）的内容。如果直接查询实体，EF Core会将包含所有语言的JSONB对象完整加载到内存中。对于包含几十种语言的长文本字段，这不仅浪费数据库 I/O，也增加了网络传输开销。</p>\n<p>尝试使用EF Core的字典索引器语法：</p>\n<pre class=\"language-cs\"><code class=\"language-cs\">// 期望生成的 SQL 是直接取值\nvar bio = context.Artists.Select(x =&gt; x.Biography[\"en\"]).FirstOrDefault();</code></pre><p>根据 <a href=\"https://www.npgsql.org/efcore/mapping/json.html?tabs=data-annotations%2Ccomplex-types%2Cjsondocument\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Npgsql EF Core Provider\">Npgsql EF Core Provider</a> 文档，虽然 Provider 提供了如<code>EF.Functions.JsonContains</code>、<code>EF.Functions.JsonExists</code>等丰富的 JSONB 操作函数，但在处理 Dictionary 索引器的投影翻译时仍存在局限性。在某些复杂的 Select 投影中，它可能无法生成最优的<code> -&gt;&gt;</code> 操作符，或者导致查询在客户端求值。</p>\n<p>目前Npgsql的<code>EF.Functions</code>中并没有直接对应<code>jsonb_extract_path_text</code>的方法，而这个原生函数恰恰是解决此类需求最直接的方式。它能在数据库服务端完成解析，仅返回指定路径的文本值。</p>\n<h1 id=\"什么是-jsonb_extract_path_text\">什么是 jsonb_extract_path_text？</h1>\n<p><code>jsonb_extract_path_text</code>是PostgreSQL的原生函数（等同于操作符 <code>#&gt;&gt;</code>），专门用于从 JSON 数据中根据路径提取文本。</p>\n<p>相比于直接返回 JSON 对象，它能直接返回纯文本（text 类型），非常适合提取多语言字典中的单一语言值。<br />\n假设数据库里的 <code>Biography</code> 字段存储如下 JSON：</p>\n<pre><code>{\n  \"en\": \"Hello World\",\n  \"zh-CN\": \"你好世界\",\n  \"fr\": \"Bonjour le monde\"\n}\n</code></pre>\n<p>如果我们只想获取中文简介：</p>\n<pre><code>-- 使用函数提取 'zh-CN' 键的值\nSELECT jsonb_extract_path_text(\"Biography\", 'zh-CN') \nFROM \"Artists\";\n\n-- 结果仅返回字符串： \"你好世界\"\n</code></pre>\n<p>这种处理方式完全在数据库端完成，传输到应用层的只有这4个字符，而不是包含英文和法文的完整JSON 对象。</p>\n<h1 id=\"解决方案映射自定义函数\">解决方案：映射自定义函数</h1>\n<p>为了在EF Core中使用<code>jsonb_extract_path_text</code>，我们可以通过自定义函数映射来实现。</p>\n<h3 id=\"什么是-ef-core自定义函数\">什么是 EF Core自定义函数？</h3>\n<p>EF Core 的自定义函数映射（User-defined function mapping）允许开发者 C#方法直接映射到数据库中的 SQL 函数。在 LINQ 查询中使用这些被映射的 C# 方法时，EF Core不会在客户端执行它们，而是将它们“翻译”成对应的 SQL 片段发送给数据库执行。这就像是给了你一把钥匙，让你能够从 C# 代码中直接调用数据库特有的、强大的原生能力（如 PostgreSQL 的 JSON 处理、GIS 地理信息计算等），而无需编写原生的 SQL 字符串。</p>\n<h3 id=\"1-定义函数存根\">1. 定义函数存根</h3>\n<p>在 C# 中定义一个静态方法作为存根（Stub），用于告诉 EF Core 即使翻译 SQL。</p>\n<pre class=\"language-cs\"><code class=\"language-cs\">public static class DbFunctionsExtensions\n{\n    // 此方法仅用于 EF Core 查询映射，客户端调用时抛出异常\n    public static string JsonExtractPathText(this Dictionary&lt;string, string&gt; json, string key)\n    {\n        throw new NotSupportedException(\"此方法仅用于 EF Core 查询映射，不可在客户端执行。\");\n    }\n}</code></pre><h3 id=\"2-配置模型映射\">2. 配置模型映射</h3>\n<p>在 <code>OnModelCreating</code> 中通过 Fluent API 进行映射关系配置,  <code>HasDbFunction</code> 将其映射到数据库函数 <code>jsonb_extract_path_text</code>。</p>\n<pre class=\"language-cs\"><code class=\"language-cs\">protected override void OnModelCreating(ModelBuilder modelBuilder)\n{\n    modelBuilder.HasDbFunction(typeof(DbFunctionsExtensions)\n            .GetMethod(nameof(DbFunctionsExtensions.JsonExtractPathText),\n                [typeof(Dictionary&lt;string, string&gt;), typeof(string)])!)\n        .HasName(\"jsonb_extract_path_text\")\n        .IsBuiltIn();\n}</code></pre><p>或者，也可以使用 <code>[DbFunction] </code>特性直接配置映射关系，这样代码更加紧凑。</p>\n<pre class=\"language-cs\"><code class=\"language-cs\">using Microsoft.EntityFrameworkCore;\n\npublic static class DbFunctionsExtensions\n{\n    // 映射到 PostgreSQL 的内置函数 jsonb_extract_path_text\n    [DbFunction(\"jsonb_extract_path_text\", IsBuiltIn = true)]\n    public static string JsonExtractPathText(this Dictionary&lt;string, string&gt; json, string key)\n    {\n       throw new NotSupportedException(\"此方法仅用于 EF Core 查询映射，不可在客户端执行。\");\n    }\n}</code></pre><h3 id=\"3-使用示例\">3. 使用示例</h3>\n<p>配置完成后，可以在 LINQ 查询中直接调用该扩展方法：</p>\n<pre class=\"language-cs\"><code class=\"language-cs\">var query = db.Artists\n    .Select(entity =&gt; new \n    {\n        Id = entity.Id,\n        // 数据库仅返回当前语言的文本\n        Bio = entity.Biography.JsonExtractPathText(CultureInfo.CurrentUICulture.Name)\n    });</code></pre><p>生成的 SQL 将调用原生<code>jsonb_extract_path_text</code>函数，避免了全量传输 JSON 数据。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1181943/202601/1181943-20260107143638710-1533499015.png\" /></p>\n<h2 id=\"索引优化策略\">索引优化策略</h2>\n<p>针对 JSONB 字段的查询优化，需要根据具体需求选择合适的索引类型。</p>\n<ol>\n<li>GIN 索引：适用于“包含”类查询（如 Biography 是否包含 en 键）。</li>\n</ol>\n<pre><code>builder.Entity&lt;ArtistEntity&gt;()\n    .HasIndex(x =&gt; x.Biography)\n    .HasMethod(\"gin\");\n</code></pre>\n<ol start=\"2\">\n<li>函数索引 (B-Tree)：如果业务中存在大量基于特定语言（如英文名称）的精确查找或排序需求，GIN 索引效率较低。此时应针对热点语言创建函数索引：</li>\n</ol>\n<pre><code>-- 针对英语内容建立 B-Tree 索引\nCREATE INDEX idx_artist_bio_en ON \"Artists\" (( \"Biography\" -&gt;&gt; 'en' ));\n</code></pre>\n<h2 id=\"适用场景与局限性\">适用场景与局限性</h2>\n<p>虽然通过 <code>jsonb_extract_path_text</code> 可以减少网络传输，但这并不是所有场景下的万能解。</p>\n<ul>\n<li>\n<p>高并发读取：即便减少了传输量，解析 JSONB 在数据库层面依然有 CPU 开销。如果面临极高并发的读取请求（如首页热门列表），频繁让数据库解析 JSON 并不是最优解。在这种情况下，应当引入应用层缓存（如 Redis）或使用专门的搜索引擎（如 Elasticsearch）。</p>\n</li>\n<li>\n<p>数据结构复杂度：此方法最适合扁平的 Key-Value 结构。如果 JSON 结构非常复杂且嵌套深，维护路径映射会变得困难。</p>\n</li>\n<li>\n<p>数据库负载：将数据处理逻辑下推到数据库虽然方便，但会增加数据库 CPU 负载。在数据库资源已是瓶颈的系统中，需谨慎使用。</p>\n</li>\n</ul>\n<p>通过这种方式，我们在保持开发便利性的同时，通过利用数据库原生能力，解决了一个具体的性能问题。开发者应根据实际的数据量级和访问模式，决定是采用此直连方案还是引入更复杂的缓存架构。</p>\n<h1 id=\"参考链接\">参考链接</h1>\n<ul>\n<li><a href=\"https://learn.microsoft.com/en-us/ef/core/querying/user-defined-function-mapping\" rel=\"noopener nofollow\" target=\"_blank\">https://learn.microsoft.com/en-us/ef/core/querying/user-defined-function-mapping</a></li>\n<li><a href=\"https://github.com/npgsql/efcore.pg/issues/2703\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/npgsql/efcore.pg/issues/2703</a></li>\n</ul>\n\n</div>\n<div id=\"MySignature\">\n    \n\n  \n  <div id=\"MySignature1\" style=\"color: 0; font-size: small;\">\n            <p>\n          作者： \n          <a href=\"https://www.cnblogs.com/netry/\"></a><a href=\"https://www.cnblogs.com/netry/\" target=\"_blank\">马行空的博客</a>\n      </p>\n      <p>\n          出处：\n          <a href=\"https://www.cnblogs.com/netry/p/19452236/efcore_jsonb_extract_path_text_in_postgredb\" target=\"_blank\">https://www.cnblogs.com/netry/p/19452236/efcore_jsonb_extract_path_text_in_postgredb</a>\n      </p>\n       \n \n      <p>\n          本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接。\n      </p>\n  </div>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-09 15:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/netry\">马行空的博客</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "51单片机_按键检测",
      "link": "https://www.cnblogs.com/WIRO/p/19461450",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/WIRO/p/19461450\" id=\"cb_post_title_url\" title=\"发布于 2026-01-09 14:49\">\n    <span>51单片机_按键检测</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"51单片机_按键检测\">51单片机_按键检测</h1>\n<h2 id=\"一独立按键介绍\">一、独立按键介绍</h2>\n<p>轻触按键相当于是一种电子开关</p>\n<p>按下时开关接通，松开时开关断开，实现原理是通过轻触按键内部的金属弹片受力弹动来实现接通和断开</p>\n<p><img alt=\"image-20260109110408710\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754276-1163410502.png\" /></p>\n<p><img alt=\"image-20260109110503289\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754526-1860924412.png\" /></p>\n<p>由于机械点的弹性作用，按键开关在闭合时不会马上稳定的接通，在断开时也不会一下子断开。因而在闭合和断开的瞬间均伴随着一连串的抖动。抖动时间的长短由按键的机械特性决定，一般为5ms到10ms。</p>\n<p>按键稳定闭合时间的长短由操作人员的按键动作决定，一般为零点几秒至数秒。按键抖动会引起按键被误读多次。为了确保CPU对按键的依次闭合仅作一次处理，必须及时进行消抖。</p>\n<p>按键消抖有两种方式，一种是硬件消抖，另一种是软件消抖。为了使电路更加简单，通常采用软件消抖。</p>\n<p>软件消抖一般来说一个简单的按键消抖就是先读取按键的状态，如果得到按键按下之后，延时10ms，再次读取按键状态，如果按键还是按下状态，那么说明按键已经按下。其中的延时10ms就是软件消抖处理。</p>\n<p>常用的软件去抖动方法：</p>\n<ol>\n<li>先设置IO口为高电平，由于开发板IO有上拉电阻，默认IO为高电平；</li>\n<li>读取IO口电平确认是否有按键按下；</li>\n<li>如果有IO电平为低电平后，延时几个毫秒；</li>\n<li>再读取该IO电平，如果仍为低电平，说明按键按下；</li>\n<li>执行相应按键的程序；</li>\n</ol>\n<h2 id=\"二独立按键检测原理\">二、独立按键检测原理</h2>\n<p>独立按键电路构成是由各个按键的一个管脚连接在一起接地，按键其它引脚分别接到单片机IO口。</p>\n<p>单片机的IO口既可作为输出也可作为输入使用，当检测按键时用的是它的输入功能，独立按键的一端接地，另一端与单片机的某个IO口相连，开始时先给IO口赋一高电平，然后让单片机不断检测该IO口是否变为低电平，当按键闭合时，相当于该IO口通过按键与地相连，变成低电平，程序一旦检测到IO口变为低电平则说明按键被按下，然后执行相应的指令。</p>\n<p><img alt=\"image-20260109110908433\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754146-1606670533.png\" /></p>\n<h2 id=\"三独立按键应用实践\">三、独立按键应用实践</h2>\n<h3 id=\"1实现按键控制led功能\">1）实现按键控制LED功能</h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\n\n/**\n * 主函数\n */\nvoid main()\n{\n\twhile(1)\n\t{\n\t\tif(P3_1 == 0)  \t\t\t  // 如果K1按键按下，则为低电平\n\t\t{\n\t\t\tDelay(20);\t\t\t  // 延时消抖\n\t\t\twhile(P3_1 == 0);\t  // 松手检测\n\t\t\tDelay(20);\t\t\t  // 延时消抖\n\t\t\n\t\t\tP2_0 = ~P2_0;\t\t  // LED1 取反\n\t\t}\n\t}\n}\n</code></pre>\n<p>这段代码依旧存在不灵敏的情况，下面是改进：</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\n\nvoid main()\n{\n    while(1)\n    {\n        if(P3_1 == 0)              // 检测按键是否按下\n        {\n            Delay(10);             // 延时消抖\n            if(P3_1 == 0)          // 再次确认按键确实按下\n            {\n                P2_0 = ~P2_0;      // 执行LED取反\n                \n                // 等待按键释放，避免连按\n                while(P3_1 == 0);  // 等待按键松开\n            }\n        }\n    }\n}\n</code></pre>\n<h3 id=\"2按键控制led灯二进制显示\">2）按键控制LED灯二进制显示</h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\n\nvoid main()\n{\n\tunsigned char LEDNum=0;\n\twhile(1)\n\t{\n\t\tif(P3_1==0)\t\t\t\t\t//如果K1按键按下\n\t\t{\n\t\t\tDelay(10);\t\t\t\t//延时消抖\n\t\t\tif(P3_1==0)\n\t\t\t{\n\t\t\t  LEDNum++;\t\t\t\t//变量自增\n\t\t\t  P2=~LEDNum;\t\t\t//变量取反输出给LED\n\t\t\t\twhile(P3_1==0);\t    //松手检测\n\t\t\t}\n\t\t}\n\t}\n}\n\n//  实现原理：\n//  +000  LEDNum 0000 0000  \t取反 —&gt;  1111 1111\n//  +001  LEDNum 0000 0001  \t取反 —&gt;  1111 1110\n//  +002  LEDNum 0000 0010  \t取反 —&gt;  1111 1101\n//  +003  LEDNum 0000 0011  \t取反 —&gt;  1111 1100\n//  ···\n//  +255  LEDNum 1111 1111  \t取反 —&gt;  0000 0000\n//  +256  溢出 -&gt; LEDNum 0000 0000  重新开始计数\n</code></pre>\n<h3 id=\"3按键实现led左右移动\">3）按键实现LED左右移动</h3>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\n\nunsigned char LEDNum;\n\nvoid main()\n{\n\tP2=~0x01;\t\t\t\t\t//上电默认LED1点亮 0000 0001 取反 -&gt; 1111 1110\n\twhile(1)\n\t{\n\t\tif(P3_0==0)\t\t\t    //如果K1按键按下，右移\n\t\t{ \n\t\t\tDelay(20);\n\t\t\twhile(P3_0==0);\n\t\t\tDelay(20);\n\t\t\t\n\t\t\tLEDNum++;\t\t\t //LEDNum自增\n\t\t\tif(LEDNum&gt;=8)\t\t //限制LEDNum自增范围\n\t\t\t\tLEDNum=0;\n\t\t\tP2=~(0x01&lt;&lt;LEDNum);\t //LED的第LEDNum位点亮\n\t\t}\n\t\tif(P3_1==0)\t\t\t\t //如果K2按键按下，左移\n\t\t{\n\t\t\tDelay(20);\n\t\t\twhile(P3_1==0);\n\t\t\tDelay(20);\n\t\t\t\n\t\t\tif(LEDNum==0)\t\t //LEDNum减到0后变为7\n\t\t\t\tLEDNum=7;\n\t\t\telse\t\t\t\t //LEDNum未减到0，自减\n\t\t\t\tLEDNum--;\n\t\t\tP2=~(0x01&lt;&lt;LEDNum);  //LED的第LEDNum位点亮\n\t\t}\n\t}\n}\n</code></pre>\n<p><code>P2=~(0x01&lt;&lt;LEDNum);</code>  实现原理如下：</p>\n<table>\n<thead>\n<tr>\n<th>LEDNum</th>\n<th>0x01 &lt;&lt; LEDNum (二进制)</th>\n<th>取反后 (二进制)</th>\n<th>效果说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td><code>0000 0001</code></td>\n<td><code>1111 1110</code></td>\n<td>LED0亮，其他灭</td>\n</tr>\n<tr>\n<td>1</td>\n<td><code>0000 0010</code></td>\n<td><code>1111 1101</code></td>\n<td>LED1亮，其他灭</td>\n</tr>\n<tr>\n<td>2</td>\n<td><code>0000 0100</code></td>\n<td><code>1111 1011</code></td>\n<td>LED2亮，其他灭</td>\n</tr>\n<tr>\n<td>3</td>\n<td><code>0000 1000</code></td>\n<td><code>1111 0111</code></td>\n<td>LED3亮，其他灭</td>\n</tr>\n<tr>\n<td>4</td>\n<td><code>0001 0000</code></td>\n<td><code>1110 1111</code></td>\n<td>LED4亮，其他灭</td>\n</tr>\n<tr>\n<td>5</td>\n<td><code>0010 0000</code></td>\n<td><code>1101 1111</code></td>\n<td>LED5亮，其他灭</td>\n</tr>\n<tr>\n<td>6</td>\n<td><code>0100 0000</code></td>\n<td><code>1011 1111</code></td>\n<td>LED6亮，其他灭</td>\n</tr>\n<tr>\n<td>7</td>\n<td><code>1000 0000</code></td>\n<td><code>0111 1111</code></td>\n<td>LED7亮，其他灭</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"四矩阵按键\">四、矩阵按键</h2>\n<p>独立键盘与单片机连接时，每一个按键都需要单片机的一个I/O口。若某单片机系统需要较多按键，如果用独立按键便会占用过多的I/O口资源。</p>\n<p>当用到多个按键时，为了减少I/O口引脚，引入了矩阵按键。比如4*4矩阵键盘。</p>\n<p>对于4*4矩阵键盘，开发板上通常将16个按键排成4行4列。第一行将每个按键的一端连接在一起构成行线，第一列将每个按键的另一端连接在一起构成列线，这样便一共有4行4列共8根线。将这8根线连接到单片机的8个I/O口上，通过程序扫描键盘可以检测16个键。</p>\n<p>无论是独立键盘还是矩阵键盘，单片机检测其是否被按下的依据都是一样的，即检测与该键对应的I/O口是否为低电平。独立键盘有一端固定为低电平而矩阵键盘两端都与单片机I/O口相连，在检测时需编程通过单片机I/O口送出低电平。检测方法最常用的是行列扫描和线翻转法。</p>\n<ul>\n<li>行列扫描法检测时，先送一列为低电平，其余几列全为高电平，此时确定列数；然后立即轮流检测一次各行是否有低电平，若检测到某一行为低电平，此时确定了行数，便可以确认当前被按下的键是哪一行哪一列的。用同样方法轮流送各列一次低电平，再轮流检测一次各行是否变为低电平，这样即可检测完所有的按键，当有按键被按下时便可判断出按下的键是哪一个键。</li>\n<li>线翻转法检测时，就是使所有行线为低电平时，检测所有列线是否有低电平，如果有，就记录列线值；然后再翻转，使所有列线都为低电平，检测所有行线的值。由于有按键按下，行线的值也会有变化，记录行线的值，从而就可以检测到全部按键。</li>\n</ul>\n<p><strong>矩阵按键也需要按键消抖。</strong></p>\n<p><img alt=\"image-20260109120836392\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754496-78745305.png\" /></p>\n<p><img alt=\"image-20260109121508035\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754398-1331883375.png\" /></p>\n<p><img alt=\"image-20260109123822715\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754445-1533630463.png\" /></p>\n<p>以第一列代码作为示例，简单介绍下 <strong>逐列扫描</strong> 的检测原理：</p>\n<p><img alt=\"image-20260109124004422\" src=\"https://img2024.cnblogs.com/blog/3732387/202601/3732387-20260109144754216-452685151.png\" /></p>\n<ul>\n<li><code>P1=0xFF;</code> 把所有按键端口置为高电平，也就是关闭所有按键</li>\n<li><code>P1_3=0;</code>  将第一列按键置为低电平，其他按键依旧为高电平（关闭状态）</li>\n<li>使用  <code>If判断</code>  检测行按键，如果某一行为低电平，就返回 <code>KeyNumber</code> 编号</li>\n</ul>\n<p>其他3列按键的检测原理同上</p>\n<h2 id=\"五矩阵按键应用实践\">五、矩阵按键应用实践</h2>\n<h3 id=\"1实现lcd1602显示按键编号\">1）实现LCD1602显示按键编号</h3>\n<p>main.c</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\t\t  //包含Delay头文件\n#include \"LCD1602.h\"\t  //包含LCD1602头文件\n#include \"MatrixKey.h\"\t  //包含矩阵键盘头文件\n\nunsigned char KeyNum;\n\nvoid main()\n{\n\tLCD_Init();\t\t\t\t\t\t\t          //LCD初始化\n\tLCD_ShowString(1,1,\"MatrixKey:\");\t          //LCD显示字符串\n\twhile(1)\n\t{\n\t\tKeyNum=MatrixKey();\t\t\t\t          //获取矩阵键盘键码\n\t\tif(KeyNum)\t\t\t\t\t\t          //如果有按键按下\n\t\t{\n\t\t\tLCD_ShowNum(2,1,KeyNum,2);\t          //LCD显示键码\n\t\t}\n\t}\n}\n</code></pre>\n<p>Delay.c</p>\n<pre><code class=\"language-c\">\nvoid Delay(unsigned int xms)\n{\n\tunsigned char i, j;\n\twhile(xms--)\n\t{\n\t\ti = 2;\n\t\tj = 239;\n\t\tdo\n\t\t{\n\t\t\twhile (--j);\n\t\t} while (--i);\n\t}\n}\n</code></pre>\n<p>Delay.h</p>\n<pre><code class=\"language-c\">#ifndef __DELAY_H__\n#define __DELAY_H__\n\nvoid Delay(unsigned int xms);\n\n#endif\n\n</code></pre>\n<p>LCD1602.c</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n\n//引脚配置：\nsbit LCD_RS=P2^6;\nsbit LCD_RW=P2^5;\nsbit LCD_EN=P2^7;\n#define LCD_DataPort P0\n\n//函数定义：\n/**\n  * @brief  LCD1602延时函数，12MHz调用可延时1ms\n  * @param  无\n  * @retval 无\n  */\nvoid LCD_Delay()\n{\n\tunsigned char i, j;\n\n\ti = 2;\n\tj = 239;\n\tdo\n\t{\n\t\twhile (--j);\n\t} while (--i);\n}\n\n/**\n  * @brief  LCD1602写命令\n  * @param  Command 要写入的命令\n  * @retval 无\n  */\nvoid LCD_WriteCommand(unsigned char Command)\n{\n\tLCD_RS=0;\n\tLCD_RW=0;\n\tLCD_DataPort=Command;\n\tLCD_EN=1;\n\tLCD_Delay();\n\tLCD_EN=0;\n\tLCD_Delay();\n}\n\n/**\n  * @brief  LCD1602写数据\n  * @param  Data 要写入的数据\n  * @retval 无\n  */\nvoid LCD_WriteData(unsigned char Data)\n{\n\tLCD_RS=1;\n\tLCD_RW=0;\n\tLCD_DataPort=Data;\n\tLCD_EN=1;\n\tLCD_Delay();\n\tLCD_EN=0;\n\tLCD_Delay();\n}\n\n/**\n  * @brief  LCD1602设置光标位置\n  * @param  Line 行位置，范围：1~2\n  * @param  Column 列位置，范围：1~16\n  * @retval 无\n  */\nvoid LCD_SetCursor(unsigned char Line,unsigned char Column)\n{\n\tif(Line==1)\n\t{\n\t\tLCD_WriteCommand(0x80|(Column-1));\n\t}\n\telse if(Line==2)\n\t{\n\t\tLCD_WriteCommand(0x80|(Column-1+0x40));\n\t}\n}\n\n/**\n  * @brief  LCD1602初始化函数\n  * @param  无\n  * @retval 无\n  */\nvoid LCD_Init()\n{\n\tLCD_WriteCommand(0x38);//八位数据接口，两行显示，5*7点阵\n\tLCD_WriteCommand(0x0c);//显示开，光标关，闪烁关\n\tLCD_WriteCommand(0x06);//数据读写操作后，光标自动加一，画面不动\n\tLCD_WriteCommand(0x01);//光标复位，清屏\n}\n\n/**\n  * @brief  在LCD1602指定位置上显示一个字符\n  * @param  Line 行位置，范围：1~2\n  * @param  Column 列位置，范围：1~16\n  * @param  Char 要显示的字符\n  * @retval 无\n  */\nvoid LCD_ShowChar(unsigned char Line,unsigned char Column,char Char)\n{\n\tLCD_SetCursor(Line,Column);\n\tLCD_WriteData(Char);\n}\n\n/**\n  * @brief  在LCD1602指定位置开始显示所给字符串\n  * @param  Line 起始行位置，范围：1~2\n  * @param  Column 起始列位置，范围：1~16\n  * @param  String 要显示的字符串\n  * @retval 无\n  */\nvoid LCD_ShowString(unsigned char Line,unsigned char Column,char *String)\n{\n\tunsigned char i;\n\tLCD_SetCursor(Line,Column);\n\tfor(i=0;String[i]!='\\0';i++)\n\t{\n\t\tLCD_WriteData(String[i]);\n\t}\n}\n\n/**\n  * @brief  返回值=X的Y次方\n  */\nint LCD_Pow(int X,int Y)\n{\n\tunsigned char i;\n\tint Result=1;\n\tfor(i=0;i&lt;Y;i++)\n\t{\n\t\tResult*=X;\n\t}\n\treturn Result;\n}\n\n/**\n  * @brief  在LCD1602指定位置开始显示所给数字\n  * @param  Line 起始行位置，范围：1~2\n  * @param  Column 起始列位置，范围：1~16\n  * @param  Number 要显示的数字，范围：0~65535\n  * @param  Length 要显示数字的长度，范围：1~5\n  * @retval 无\n  */\nvoid LCD_ShowNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length)\n{\n\tunsigned char i;\n\tLCD_SetCursor(Line,Column);\n\tfor(i=Length;i&gt;0;i--)\n\t{\n\t\tLCD_WriteData(Number/LCD_Pow(10,i-1)%10+'0');\n\t}\n}\n\n/**\n  * @brief  在LCD1602指定位置开始以有符号十进制显示所给数字\n  * @param  Line 起始行位置，范围：1~2\n  * @param  Column 起始列位置，范围：1~16\n  * @param  Number 要显示的数字，范围：-32768~32767\n  * @param  Length 要显示数字的长度，范围：1~5\n  * @retval 无\n  */\nvoid LCD_ShowSignedNum(unsigned char Line,unsigned char Column,int Number,unsigned char Length)\n{\n\tunsigned char i;\n\tunsigned int Number1;\n\tLCD_SetCursor(Line,Column);\n\tif(Number&gt;=0)\n\t{\n\t\tLCD_WriteData('+');\n\t\tNumber1=Number;\n\t}\n\telse\n\t{\n\t\tLCD_WriteData('-');\n\t\tNumber1=-Number;\n\t}\n\tfor(i=Length;i&gt;0;i--)\n\t{\n\t\tLCD_WriteData(Number1/LCD_Pow(10,i-1)%10+'0');\n\t}\n}\n\n/**\n  * @brief  在LCD1602指定位置开始以十六进制显示所给数字\n  * @param  Line 起始行位置，范围：1~2\n  * @param  Column 起始列位置，范围：1~16\n  * @param  Number 要显示的数字，范围：0~0xFFFF\n  * @param  Length 要显示数字的长度，范围：1~4\n  * @retval 无\n  */\nvoid LCD_ShowHexNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length)\n{\n\tunsigned char i,SingleNumber;\n\tLCD_SetCursor(Line,Column);\n\tfor(i=Length;i&gt;0;i--)\n\t{\n\t\tSingleNumber=Number/LCD_Pow(16,i-1)%16;\n\t\tif(SingleNumber&lt;10)\n\t\t{\n\t\t\tLCD_WriteData(SingleNumber+'0');\n\t\t}\n\t\telse\n\t\t{\n\t\t\tLCD_WriteData(SingleNumber-10+'A');\n\t\t}\n\t}\n}\n\n/**\n  * @brief  在LCD1602指定位置开始以二进制显示所给数字\n  * @param  Line 起始行位置，范围：1~2\n  * @param  Column 起始列位置，范围：1~16\n  * @param  Number 要显示的数字，范围：0~1111 1111 1111 1111\n  * @param  Length 要显示数字的长度，范围：1~16\n  * @retval 无\n  */\nvoid LCD_ShowBinNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length)\n{\n\tunsigned char i;\n\tLCD_SetCursor(Line,Column);\n\tfor(i=Length;i&gt;0;i--)\n\t{\n\t\tLCD_WriteData(Number/LCD_Pow(2,i-1)%2+'0');\n\t}\n}\n</code></pre>\n<p>LCD1602.h</p>\n<pre><code class=\"language-c\">#ifndef __LCD1602_H__\n#define __LCD1602_H__\n\n//用户调用函数：\nvoid LCD_Init();\nvoid LCD_ShowChar(unsigned char Line,unsigned char Column,char Char);\nvoid LCD_ShowString(unsigned char Line,unsigned char Column,char *String);\nvoid LCD_ShowNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length);\nvoid LCD_ShowSignedNum(unsigned char Line,unsigned char Column,int Number,unsigned char Length);\nvoid LCD_ShowHexNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length);\nvoid LCD_ShowBinNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length);\n\n#endif\n\n</code></pre>\n<p>MatrixKey.c</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\n\n/**\n  * @brief  矩阵键盘读取按键键码\n  * @param  无\n  * @retval KeyNumber 按下按键的键码值\n\t\t\t如果按键按下不放，程序会停留在此函数，松手的一瞬间，返回按键键码，没有按键按下时，返回0\n  */\nunsigned char MatrixKey()\n{\n\tunsigned char KeyNumber=0;\n\t\n\tP1=0xFF;  // 1111 1111 全部置高电平，没有按键按下\n\tP1_3=0;   // 检测第一列\n\tif(P1_7==0){Delay(20);while(P1_7==0);Delay(20);KeyNumber=1;}\n\tif(P1_6==0){Delay(20);while(P1_6==0);Delay(20);KeyNumber=5;}\n\tif(P1_5==0){Delay(20);while(P1_5==0);Delay(20);KeyNumber=9;}\n\tif(P1_4==0){Delay(20);while(P1_4==0);Delay(20);KeyNumber=13;}\n\t\n\tP1=0xFF;  // 1111 1111 全部置高电平，没有按键按下\n\tP1_2=0;   // 检测第二列\n\tif(P1_7==0){Delay(20);while(P1_7==0);Delay(20);KeyNumber=2;}\n\tif(P1_6==0){Delay(20);while(P1_6==0);Delay(20);KeyNumber=6;}\n\tif(P1_5==0){Delay(20);while(P1_5==0);Delay(20);KeyNumber=10;}\n\tif(P1_4==0){Delay(20);while(P1_4==0);Delay(20);KeyNumber=14;}\n\t\n\tP1=0xFF;  // 1111 1111 全部置高电平，没有按键按下\n\tP1_1=0;   // 检测第三列\n\tif(P1_7==0){Delay(20);while(P1_7==0);Delay(20);KeyNumber=3;}\n\tif(P1_6==0){Delay(20);while(P1_6==0);Delay(20);KeyNumber=7;}\n\tif(P1_5==0){Delay(20);while(P1_5==0);Delay(20);KeyNumber=11;}\n\tif(P1_4==0){Delay(20);while(P1_4==0);Delay(20);KeyNumber=15;}\n\t\n\tP1=0xFF;  // 1111 1111 全部置高电平，没有按键按下\n\tP1_0=0;   // 检测第四列\n\tif(P1_7==0){Delay(20);while(P1_7==0);Delay(20);KeyNumber=4;}\n\tif(P1_6==0){Delay(20);while(P1_6==0);Delay(20);KeyNumber=8;}\n\tif(P1_5==0){Delay(20);while(P1_5==0);Delay(20);KeyNumber=12;}\n\tif(P1_4==0){Delay(20);while(P1_4==0);Delay(20);KeyNumber=16;}\n\t\n\treturn KeyNumber;\n}\n</code></pre>\n<p>MatrixKey.h</p>\n<pre><code class=\"language-c\">#ifndef __MATRIXKEY_H__\n#define __MATRIXKEY_H__\n\nunsigned char MatrixKey();\n\n#endif\n\n</code></pre>\n<h3 id=\"2使用矩阵键盘实现密码锁功能\">2）使用矩阵键盘实现密码锁功能</h3>\n<p>只需要修改main.c ,其余代码同上</p>\n<pre><code class=\"language-c\">#include &lt;REGX52.H&gt;\n#include \"Delay.h\"\n#include \"LCD1602.h\"\n#include \"MatrixKey.h\"\n\nunsigned char KeyNum;\nunsigned int Password,Count;\n\nvoid main()\n{\n\tLCD_Init();\n\tLCD_ShowString(1,1,\"Password:\");\n\twhile(1)\n\t{\n\t\tKeyNum=MatrixKey();\n\t\tif(KeyNum)\n\t\t{\n\t\t\tif(KeyNum&lt;=10)\t                      //如果S1~S10按键按下，输入密码\n\t\t\t{                                    \n\t\t\t\tif(Count&lt;4)\t                       //如果输入次数小于4\n\t\t\t\t{                                  \n\t\t\t\t\tPassword*=10;\t\t\t\t   //密码左移一位\n\t\t\t\t\tPassword+=KeyNum%10;\t\t   //获取一位密码\n\t\t\t\t\tCount++;\t                   //计次加一\n\t\t\t\t}\n\t\t\t\tLCD_ShowNum(2,1,Password,4);\t   //更新显示\n\t\t\t}                                    \n\t\t\tif(KeyNum==11)\t                       //如果S11按键按下，确认\n\t\t\t{                                    \n\t\t\t\tif(Password==2345)\t               //如果密码等于正确密码\n\t\t\t\t{                                  \n\t\t\t\t\tLCD_ShowString(1,14,\"OK \");\t   //显示OK\n\t\t\t\t\tPassword=0;\t\t               //密码清零\n\t\t\t\t\tCount=0;\t\t               //计次清零\n\t\t\t\t\tLCD_ShowNum(2,1,Password,4);   //更新显示\n\t\t\t\t}\n\t\t\t\telse\t\t\t\t               //否则\n\t\t\t\t{\n\t\t\t\t\tLCD_ShowString(1,14,\"ERR\");\t   //显示ERR\n\t\t\t\t\tPassword=0;\t\t               //密码清零\n\t\t\t\t\tCount=0;\t\t               //计次清零\n\t\t\t\t\tLCD_ShowNum(2,1,Password,4);   //更新显示\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(KeyNum==12)\t                       //如果S12按键按下，取消\n\t\t\t{\n\t\t\t\tPassword=0;\t\t                   //密码清零\n\t\t\t\tCount=0;\t\t                   //计次清零\n\t\t\t\tLCD_ShowNum(2,1,Password,4);\t   //更新显示\n\t\t\t}\n\t\t}\n\t}\n}\n</code></pre>\n<p><code>Password*=10;\t\t\t\t   //密码左移一位</code></p>\n<p><code>Password+=KeyNum%10;\t\t   //获取一位密码 </code></p>\n<p><strong>图表：按键序列 5 → 6 → 3 → 8 的处理过程</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">按键</th>\n<th style=\"text-align: left;\">运算前 Password</th>\n<th style=\"text-align: left;\">Password × 10</th>\n<th style=\"text-align: left;\">KeyNum % 10</th>\n<th style=\"text-align: left;\">运算后 Password</th>\n<th style=\"text-align: left;\">解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">5</td>\n<td style=\"text-align: left;\">0</td>\n<td style=\"text-align: left;\">0 × 10 = 0</td>\n<td style=\"text-align: left;\">5 % 10 = 5</td>\n<td style=\"text-align: left;\"><strong>5</strong></td>\n<td style=\"text-align: left;\">第一个数字直接存入</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">6</td>\n<td style=\"text-align: left;\">5</td>\n<td style=\"text-align: left;\">5 × 10 = 50</td>\n<td style=\"text-align: left;\">6 % 10 = 6</td>\n<td style=\"text-align: left;\"><strong>56</strong></td>\n<td style=\"text-align: left;\">5移到十位，6放在个位</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">3</td>\n<td style=\"text-align: left;\">56</td>\n<td style=\"text-align: left;\">56 × 10 = 560</td>\n<td style=\"text-align: left;\">3 % 10 = 3</td>\n<td style=\"text-align: left;\"><strong>563</strong></td>\n<td style=\"text-align: left;\">56变为560，3放在个位</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">8</td>\n<td style=\"text-align: left;\">563</td>\n<td style=\"text-align: left;\">563 × 10 = 5630</td>\n<td style=\"text-align: left;\">8 % 10 = 8</td>\n<td style=\"text-align: left;\"><strong>5638</strong></td>\n<td style=\"text-align: left;\">563变为5630，8放在个位</td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-09 14:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/WIRO\">Q&amp;25</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "小白也能看懂的LLM-RL算法：PPO/DPO/GRPO/GSPO",
      "link": "https://www.cnblogs.com/aifrontiers/p/19461279",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/aifrontiers/p/19461279\" id=\"cb_post_title_url\" title=\"发布于 2026-01-09 14:29\">\n    <span>小白也能看懂的LLM-RL算法：PPO/DPO/GRPO/GSPO</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>原文: <a href=\"https://mp.weixin.qq.com/s/9KT9LrMTXDGHSvGFrQhRkg\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/9KT9LrMTXDGHSvGFrQhRkg</a></p>\n<p><strong>LLM-RL往期文章推荐</strong></p>\n<p><a href=\"https://mp.weixin.qq.com/s/cx3qY42Lp0L3RaSOgsH77A\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RL-PPO</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/nfN0dWT3ZfDuW7ZGfaG6dA\" rel=\"noopener nofollow\" target=\"_blank\">收藏！强化学习从入门到封神：5 本经典教材 + 8 大实战项目 + 7个免费视频，一站式搞定</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/4_6CBXMJhqmiYKSzsAXncg\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RLHF：基础篇</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/8O7W8--x14-b1d3M9IS_3w\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RLHF-PPO：原理篇</a></p>\n<p>强化学习 (RL, Reinforcement Learning) 已成为大模型后训练的关键环节，在前几篇中，我们对LLM-RL中最基础、最核心的PPO算法做了详细的拆解，有需要的可以点击上面链接阅读，本篇将介绍其他主流的LLM-RL算法。读完这篇后，你会发现，不管是哪种LLM-RL算法，本质都是将人类偏好融入到大模型中，差异点在于以何种方式/更高效地挖掘偏好数据的价值、如何在降低算力资源需求下保证模型性能、如何提高算法稳定性。</p>\n<p>在介绍LLM-RL各类策略算法前，我们将先解释一些基本概念，涵盖强化学习理解、价值函数、NLP中的强化学习。 随后，介绍RLHF的起源、设计思路、如何与大模型RLHF算法关联的。再对LLM-RL主流的（DPO、GRPO、GSPO）策略优化算法进行细致讲解，如各个算法原理、训练过程、优缺点等。为了能够更好地对比各个算法，也会捎带介绍下PPO算法。</p>\n<h1 id=\"1-基本概念\">1 基本概念</h1>\n<h2 id=\"11-强化学习理解\">1.1 强化学习理解</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>强化学习关键在于「<strong>强化</strong>」这个词，简单理解就是「<strong>用反馈强化行为</strong>」，即用奖惩规则让智能体自己在试错中筛选出有效行为，再通过重复反馈把这些行为巩固成最优策略，本质就是「<strong>奖惩驱动的行为筛选与巩固</strong>」，咱们结合之<strong>训练小狗坐下</strong>的例子逐词解释下这句话。</p>\n<ul>\n<li>\n<p><strong>奖惩驱动</strong>：RL整个学习过程的核心动力来自<strong>奖励</strong> 和 <strong>惩罚/无奖励</strong>的即时反馈，比如小狗做对<strong>坐下</strong>就给零食（奖励），没做对就不给零食（无奖励），小狗的行为选择完全由这种反馈驱动。</p>\n</li>\n<li>\n<p><strong>行为筛选</strong>：智能体（小狗）会在动作空间里不断尝试不同行为，而奖惩就像一个筛选器，<strong>被奖励的行为会被保留，被惩罚/无奖励的行为会被淘汰</strong>。比如小狗一开始可能尝试蹦跳、趴着、摇尾巴等动作，这些动作都没得到零食，就会慢慢被筛选掉；只有<strong>坐下</strong>这个动作能拿到零食，就会被筛选出来。</p>\n</li>\n<li>\n<p><strong>行为巩固</strong>：被筛选出来的有效行为，会在一次次重复的「<strong>行为—奖励</strong>」循环中被强化，最终变成稳定的条件反射。比如小狗每次做坐下都能拿到零食，重复次数多了，它就会把<strong>听到指令→坐下</strong>这个行为固定下来，形成稳定的技能。</p>\n</li>\n</ul>\n<p>简单来说，「<strong>强化</strong>」不是增强能力，而是强化「<strong>动作 - 奖励之间</strong>」的关联，让智能体慢慢记住<strong>做什么能拿到好处，做什么会吃亏</strong>。就像训练小狗时，你不用强行掰它的腿让它坐下，只需要用零食的奖惩，让它自己悟出<strong>坐下=有吃的</strong>这个规律，最后形成稳定的行为习惯。</p>\n<p>接下来，我们继续以<strong>训练小狗坐下为例，</strong>理解下强化学习的关键要素、学习过程。</p>\n<p>强化学习的2个核心角色：</p>\n<ul>\n<li>\n<p><strong>智能体（Agent）</strong>：要学习<strong>坐下</strong>技能的<strong>小狗</strong></p>\n</li>\n<li>\n<p><strong>环境（Environment）</strong>：小狗所处的训练场景（比如家里的客厅、户外的院子等）</p>\n</li>\n</ul>\n<p>强化学习的3个关键要素：</p>\n<ul>\n<li>\n<p><strong>状态空间</strong> <span class=\"math inline\">\\(S\\)</span>：训练环境中所有可能出现的场景集合。比如小狗可能站着/趴着/对着玩具叫，也可能身边有陌生人经过，这些不同的状态都属于状态空间</p>\n</li>\n<li>\n<p><strong>动作空间</strong> <span class=\"math inline\">\\(A\\)</span>：小狗能做出的所有动作集合。比如小狗可以站着不动、趴着休息、摇尾巴、跳跃、坐下，这些都是它动作空间里的内容</p>\n</li>\n<li>\n<p><strong>奖励</strong> <span class=\"math inline\">\\(R\\)</span>：小狗处于某个状态、做出某个动作时，给出的即时反馈。比如小狗做出<strong>坐下</strong>动作时，给它一块零食；如果小狗乱蹦乱跳不配合，就不给零食甚至轻声制止。</p>\n</li>\n</ul>\n<p>那小狗（智能体）和训练环境是怎么互动的，最终学会坐下的呢？我们以训练中 <span class=\"math inline\">\\(t\\)</span>时刻的互动过程为例：</p>\n<ul>\n<li>\n<p>当前状态<span class=\"math inline\">\\(S\\_t\\)</span>：小狗正站在客厅里看着你，此时它还没做出目标动作，所以没拿到奖励，即时奖励<span class=\"math inline\">\\(R\\_t\\)</span>= 0</p>\n</li>\n<li>\n<p>小狗的动作<span class=\"math inline\">\\(A\\_t\\)</span>：你发出<strong>坐下</strong>的指令后，小狗可能做出各种反应，比如蹦跳、可能趴着，也可能偶然做出<strong>坐下</strong>的动作；</p>\n</li>\n<li>\n<p>新状态 <span class=\"math inline\">\\(S\\_{t+1}\\)</span>与新反馈与<span class=\"math inline\">\\(R\\_{t+1}\\)</span>：如果小狗刚才做的动作<span class=\"math inline\">\\(A\\_t\\)</span>=坐下，训练状态就变成<strong>小狗处于坐下状态</strong><span class=\"math inline\">\\(S\\_{t+1}\\)</span>，主人立刻给它一块零食作为奖励<span class=\"math inline\">\\(R\\_{t+1}\\)</span>=2 的正向奖励；如果小狗做的是其他动作，<span class=\"math inline\">\\(S\\_{t+1}\\)</span>可能变成小狗趴着或小狗蹦跳，主人不给零食<span class=\"math inline\">\\(R_{t+1}\\)</span>=0。</p>\n</li>\n</ul>\n<p>这样的互动会一次次重复：主人反复发出指令，小狗在不同状态下尝试不同动作，并根据是否拿到零食（奖励）总结经验。最终，小狗（智能体）就会学到一套最优玩法：当接收到<strong>坐下</strong>指令时，立刻做出<strong>坐下</strong>动作，以此稳定拿到零食奖励，这就是强化学习的核心逻辑。</p>\n<h2 id=\"12-价值函数\">1.2 价值函数</h2>\n<p>前面提到的<strong>即时奖励</strong><span class=\"math inline\">\\(R\\_t\\)</span>，只反映了当前状态<span class=\"math inline\">\\(S\\_t\\)</span>的收益，忽略了当前状态和动作对未来收益的影响。更合理的计算方式，需要兼顾<strong>即时收益</strong>和<strong>未来收益</strong>，公式如下：</p>\n<p></p><div class=\"math display\">\\[V\\_t = R_t + \\gamma V_{t+1}\n\\]</div><p></p><p>其中：</p>\n<ul>\n<li>\n<p><span class=\"math inline\">\\(V_t\\)</span>：<span class=\"math inline\">\\(t\\)</span>时刻的总收益（包含即时和未来收益）</p>\n</li>\n<li>\n<p><span class=\"math inline\">\\(R_t\\)</span>：<span class=\"math inline\">\\(t\\)</span>时刻的即时收益</p>\n</li>\n<li>\n<p><span class=\"math inline\">\\(V_{t+1}\\)</span>： <span class=\"math inline\">\\(t+1\\)</span>时刻的总收益，对 <span class=\"math inline\">\\(t\\)</span>时刻而言属于未来收益</p>\n</li>\n<li>\n<p><span class=\"math inline\">\\(\\gamma\\)</span>：折扣因子，用来调节未来收益在当前总收益中的权重</p>\n</li>\n</ul>\n<p>此处不展开强化学习价值函数的假设与推导，仅提供简化结论，方便读者聚焦于更好的理解各类算法策略的具体做法和直觉理解。</p>\n<h2 id=\"13-nlp中的强化学习\">1.3 NLP中的强化学习</h2>\n<p>对应到<span class=\"math inline\">\\(NLP\\)</span> 下，大语言模型就是智能体，输入的提示词 <span class=\"math inline\">\\(prompt\\)</span> 就对应状态 <span class=\"math inline\">\\(S\\)</span>，输出下一个<span class=\"math inline\">\\(token\\)</span> 就是动作 <span class=\"math inline\">\\(A\\)</span>，对 <span class=\"math inline\">\\(prompt+response\\)</span> 进行打分就是奖励 <span class=\"math inline\">\\(R\\)</span>，整体目标就是给定<span class=\"math inline\">\\(prompt\\)</span>，调整策略模型，生成符合人类喜好的<span class=\"math inline\">\\(response\\)</span>。</p>\n<h1 id=\"2-rlhf的起源\">2 RLHF的起源</h1>\n<p>论文标题：Deep Reinforcement Learning from Human Preferences</p>\n<p>论文地址：<a href=\"https://arxiv.org/pdf/1706.03741\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/1706.03741</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>这篇发表于2017年NIPS的论文是强化学习领域的开创性成果，其核心设计直接奠定了大模型RLHF的技术基础，我们来看看这篇论文到底做出了哪些开创新工作、以及如何对RLHF带来启发的。</p>\n<h2 id=\"21-文章的核心问题创新与方法\">2.1 文章的核心：问题、创新与方法</h2>\n<ul>\n<li>\n<p><strong>解决的问题</strong>：传统强化学习的核心思路是为任务手工设计明确奖励函数，用以引导智能体学习。这种模式对于简单的应用场景还行，一旦涉及复杂场景，如机器人控制、游戏，会面临奖励函数难以精准定义、奖励设计违背人类真实需求的问题，直接影响是智能体行为与人类偏好严重错位，比如机器人为适配简单奖励规则会出现跛行式行走，智能驾驶智能体为追求得分奖励而忽视人类更看重的平稳驾驶体验。</p>\n</li>\n<li>\n<p><strong>核心创新</strong>：舍弃手工设计奖励，提出「<strong>用人类偏好反馈驱动强化学习</strong>」，无需真实奖励函数就可以让智能体对齐人类需求，大幅降低人类监督成本。</p>\n</li>\n<li>\n<p><strong>关键方法</strong>：构建「<strong>偏好收集→奖励建模→策略优化</strong>」三阶段闭环。① 偏好收集：让非专家对比1-2秒短轨迹片段（如机器人后空翻成败片段），快速给出偏好判断；② 奖励建模：用Bradley-Terry模型训练奖励模型，拟合人类偏好背后的隐性规则；③ 策略优化：通过A2C（游戏场景）、TRPO（机器人场景）算法，结合拟合的奖励模型持续更新策略。</p>\n</li>\n</ul>\n<h2 id=\"22-方法效果\">2.2 方法效果</h2>\n<p>论文在多个场景验证了所提方法的有效性：① MuJoCo机器人任务（8项）：仅700条人类查询，性能就接近手工奖励方案，1400条查询实现反超；② Atari游戏（7项）：5500条查询让多数任务性能显著提升；③ 可训练novel行为：1小时内教会机器人连续后空翻等人类难以演示的动作。核心亮点是仅需不到1%的环境交互反馈，就能达到甚至超越传统方法。</p>\n<h2 id=\"23-对大模型rlhf的启发\">2.3 对大模型RLHF的启发</h2>\n<p>论文的核心思想与设计，被RLHF完整继承并适配文本场景（后文会给出详细解读），成为其核心技术框架：</p>\n<ul>\n<li>\n<p><strong>核心逻辑复用</strong>：RLHF直接借鉴「<strong>用人类偏好替代手工奖励</strong>」的思路，解决大模型对话连贯性、礼貌性等难以量化的问题，避免大模型无法对齐人类偏好。</p>\n</li>\n<li>\n<p><strong>三步流程照抄</strong>：让标注员快速对比两条文本，选出人类偏好，训练模型学会怎么给文本打分，将人类偏好打分融合到PPO算法中优化大模型参数</p>\n</li>\n<li>\n<p><strong>关键突破的支撑</strong>：大模型文本任务维度极高，全量标注不现实，得益于论文验证的「<strong>少量反馈即可驱动模型优化</strong>」，RLHF仅用数万条偏好数据就实现了问答质量跃升。</p>\n</li>\n</ul>\n<p>从上面的描述可以看出，论文提出的「<strong>奖励难定义</strong>」、「<strong>三阶段闭环</strong>」、「<strong>低成本反馈</strong>」构成了RLHF的技术基石，启发了OpenAI的研发人员将「<strong>智能体对齐人类偏好</strong>」这一想法，从机器人、游戏领域成功迁移至大模型，成为ChatGPT一夜爆火的重要原因。</p>\n<h1 id=\"3-rlhf-ppo\">3 RLHF-PPO</h1>\n<p>论文标题：Training language models to follow instructions with human feedback 论文地址： <a href=\"https://arxiv.org/pdf/2203.02155\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2203.02155</a></p>\n<p>PPO（Proximal Policy Optimization）算法是 InstructGPT 模型实现人类反馈强化学习（RLHF）的核心，核心思想是通过约束策略更新幅度，在保证训练稳定性的前提下，最大化人类偏好导向的奖励，同时避免策略过度偏离初始监督模型。</p>\n<h2 id=\"31-rlhf-ppo的四大模型\">3.1 RLHF-PPO的四大模型</h2>\n<p>相比传统PPO算法，RLHF-PPO模型架构更为复杂，一共包含4个模型，比传统PPO多出了<strong>参考模型（Reference Model）</strong> 和<strong>奖励模型（Reward Model）</strong>。</p>\n<p>**四大模型作用和参数初始化：</p>\n<ul>\n<li>\n<p><strong>Actor Model</strong> <span class=\"math inline\">\\(\\pi_{\\theta}\\)</span> ：用SFT后的模型作为初始模型，通过PPO训练调整参数，得到最终的模型，使其生成的回答更符合人类偏好，<strong>参数可变</strong>。</p>\n</li>\n<li>\n<p><strong>Reference Model</strong> <span class=\"math inline\">\\(\\pi_{base}\\)</span>：SFT后的模型，用于限制Actor Model不要偏离Reference Model太远，<strong>参数冻结</strong>。</p>\n</li>\n<li>\n<p><strong>Reward Model</strong> <span class=\"math inline\">\\(r\\_{\\theta}\\)</span>：对模型回答打分，表示贴合人类偏好的程度，训练完后，在PPO中是<strong>参数冻结</strong>的。</p>\n</li>\n<li>\n<p><strong>Critic Model</strong> <span class=\"math inline\">\\(V_{t}\\)</span>：用于预测期望总收益，为优势函数 <span class=\"math inline\">\\(A_{t}\\)</span>提供基线，使策略更新更稳定，<strong>参数可变</strong>。</p>\n</li>\n</ul>\n<h2 id=\"32-rlhf-ppo的训练过程\">3.2 RLHF-PPO的训练过程</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>我们回顾一下RLHF里的整体流程，如上图所示：</p>\n<p>Step 1：收集演示数据，训练监督策略（SFT）</p>\n<p>Step 2：收集对比数据，训练奖励模型（RM）</p>\n<p>Step 3：用强化学习（PPO）优化策略模型</p>\n<p>整个流程的核心是<strong>用人类偏好数据（演示、排序）指导模型训练</strong>，最终让大模型输出既有用、又符合人类意图的内容。</p>\n<p>下面，重点讨论PPO算法的训练过程</p>\n<h3 id=\"经验数据收集\">经验数据收集</h3>\n<ul>\n<li>\n<p>将一个batch的prompt喂给当前的Actor模型<span class=\"math inline\">\\(\\pi_{\\theta}\\)</span>，生成对应的响应序列response</p>\n</li>\n<li>\n<p>对于响应序列的每个token，计算以下中间变量：</p>\n<ul>\n<li>\n<p>Actor模型的对数概率<span class=\"math inline\">\\(log(\\pi_\\theta(a_t | s_t))\\)</span></p>\n</li>\n<li>\n<p>Reference模型的对数概率<span class=\"math inline\">\\(log(\\pi_{base}(a_t | s_t))\\)</span></p>\n</li>\n<li>\n<p>Critic模型根据当前状态 <span class=\"math inline\">\\(s\\_t\\)</span>的价值估计 $V_t $</p>\n</li>\n<li>\n<p>计算每个token的KL散度<span class=\"math inline\">\\(kl = log(\\pi_\\theta(a_t | s_t)) - log(\\pi_{base}(a_t | s_t)) = log \\frac {\\pi_\\theta(a_t | s_t)}{\\pi_{base}(a_t | s_t)}\\)</span></p>\n</li>\n<li>\n<p>若该token位于序列的最后一个，通过Reward Model 计算人类偏好分数<span class=\"math inline\">\\(r_{\\theta}\\)</span></p>\n</li>\n<li>\n<p>结合 Reward Model 计算人类偏好分数<span class=\"math inline\">\\(r_{\\theta}\\)</span>（只在最后一步）和 每个token 的 KL 惩罚 ，计算出每个token的最终即时奖励信号 $R_t $，以deepspeed-chat的RLHF为例， $R_t $的计算如下</p>\n</li>\n</ul>\n<p>$$\\begin{align} R_t = \\begin{cases} -kl\\_ctl *(log\\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{base}(a_t | s_t)}), &amp;\\text t\\not =T \\\\ -kl\\_ctl *(log\\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{base}(a_t | s_t)}) + r_\\theta, &amp;\\text t=T \\end{cases} \\end{align}$$</p>\n<ul>\n<li>使用最终即时奖励信号 $R_t $和Critic模型的价值估计 $V_t $，通过 GAE (Generalized Advantage Estimation) 方法计算每个 token 的优势 <span class=\"math inline\">\\(Adv_t\\)</span>，计算如下</li>\n</ul>\n</li>\n</ul>\n<p></p><div class=\"math display\">\\[\\begin{align} \\delta_t = R_t + \\gamma*V_{t+1} - V_t \\\\ Adv_t = \\delta_t + \\gamma* \\lambda*Adv_{t+1} \\end{align}\n\\]</div><p></p><p>将前面收集到的经验数据（prompt、<span class=\"math inline\">\\(log(\\pi_\\theta(a_t | s_t))\\)</span>、<span class=\"math inline\">\\(log(\\pi_{base}(a_t | s_t))\\)</span> 、<span class=\"math inline\">\\(Adv_t\\)</span>、...）构成批次，放到经验池中</p>\n<p>如果对上述计算过程有疑惑，可以回看<a href=\"https://mp.weixin.qq.com/s/8O7W8--x14-b1d3M9IS_3w\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RLHF-PPO：原理篇</a>，文章有详细解读。</p>\n<h3 id=\"模型参数更新\">模型参数更新</h3>\n<ul>\n<li>\n<p>循环epochs次</p>\n<ul>\n<li>\n<p>对经验池的每个batch数据</p>\n<ul>\n<li>\n<p>Actor Model参数更新： PPO更新模型 <span class=\"math inline\">\\(\\pi_{\\theta}\\)</span> 参数，这里为了防止策略模型 <span class=\"math inline\">\\(\\pi_{\\theta}\\)</span> 过度偏离参考模型 <span class=\"math inline\">\\(\\pi_{base}\\)</span> ，有两种形式保证模型在有限的空间里微调参数，一种是引入PPO-KL散度，</p>\n<p>$$\\begin{align} L^{PPO-KL}(\\theta) = E_{\\tau \\sim {\\pi_{base}}}^t [\\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{base}(a_t | s_t)} A_{t} - \\beta D_{KL}(\\pi_{base}(.|x_t) || \\pi_{\\theta}(.|x_t))] \\end {align}$$</p>\n<p>另一种PPO-CLIP比较直接，在目标函数中，限制新旧模型的差距在约定的区间内：</p>\n<p>$$\\begin{align} L^{PPO-CLIP}(\\theta) = E_{\\tau \\sim {\\pi_{base}}}^t [min( \\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{base}(a_t | s_t)} A_{t},  \\ clip(\\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{base}(a_t | s_t)}, 1-\\varepsilon,1+\\varepsilon)A_{t})] \\end {align}$$</p>\n</li>\n<li>\n<p>Critic Model参数更新：$$\\begin{align} L^{Critic}({\\phi}) &amp;= E_t [(R_t + \\gamma V_{t+1} - V_t)^2] \\end {align}$$</p>\n<p><span class=\"math inline\">\\(V\\_{t}\\)</span>: Critic模型对 <span class=\"math inline\">\\(t\\)</span>时刻收益的预估，即未来和即时收益的整体预估</p>\n<p>$ R_t + \\gamma*V_{t+1}<span class=\"math inline\">\\(: 计算得到的即时收益\\)</span>R_{t}$ ,<span class=\"math inline\">\\(\\gamma*V_{t+1}\\)</span> 为Critic模型预测出 <span class=\"math inline\">\\(t+1\\)</span>时刻之后的折损收益</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"模型参数同步\">模型参数同步</h3>\n<ul>\n<li>\n<p><strong>策略参数更新</strong>：完成经验池的数据训练迭代后，用新训练得到的Actor模型参数、Critic模型参数替换旧的模型参数。</p>\n</li>\n<li>\n<p><strong>丢弃旧数据</strong>：因这批数据是用旧策略模型收集的，与现有的新策略模型偏差较大，重要性采样的假设不再准确，所以必须丢弃当前这批数据。</p>\n</li>\n<li>\n<p><strong>循环训练流程</strong>：回到数据收集阶段，用更新后的策略模型与环境重新交互，采集全新的数据；之后重复整个训练流程，直到策略性能稳定收敛，或达到预设的训练步数。</p>\n</li>\n</ul>\n<p>以上就是PPO算法训练全流程的说明，核心环节包括：经验数据收集、模型参数更新和模型参数同步</p>\n<h2 id=\"33-rlhf-ppo的优缺点\">3.3 RLHF-PPO的优缺点</h2>\n<p><strong>优点</strong>：① 稳定性强：靠裁剪/KL惩罚限制策略更新幅，降低崩坏风险，易收敛；② 易落地：无需TRPO的二阶计算，用Adam优化器即可；核心超参数（如clip系数、GAE参数）易调试</p>\n<p><strong>缺点</strong>：① 训练成本高：涉及4个模型的运算/更新，是后续改进重点；② 梯度信息浪费：clip机制会截断大量梯度，拖慢训练、限制策略精细度；③ 样本利用率低：本质是on-policy架构，策略同步阶段需丢弃旧数据，新模型每次收集数据都会带来算力、时间成本。</p>\n<h1 id=\"4-dpo\">4 DPO</h1>\n<p>论文标题：Direct Preference Optimization: Your Language Model is Secretly a Reward Model 论文地址：<a href=\"https://arxiv.org/pdf/2305.18290\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2305.18290</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>如前文所述，PPO算法虽被证实有效，但也暴露诸多痛点。如需同时维护和运行四个模型，对计算资源和显存的要求极高；训练过程还伴随强化学习（RL）常见的不稳定性问题；一次完整的PPO训练，覆盖多个环节，调优的难度较大。</p>\n<p>能否找到一种方法，绕过显式训练奖励模型和复杂的强化学习环节，基于人类偏好数据直接优化策略模型呢？</p>\n<p>DPO正是在这一背景下诞生的创新方法，由斯坦福大学研究团队提出。其核心思想是摒弃「<strong>先训练奖励模型，再用RL优化策略</strong>」的两步流程，直接将人类偏好数据转化为对策略参数的二分类损失优化，大幅简化了训练链路。</p>\n<h2 id=\"41-dpo算法的原理\">4.1 DPO算法的原理</h2>\n<p>DPO 的关键理论支撑在于人类偏好数据里隐藏的奖励规则，而针对这个规则，存在一个<strong>最优策略</strong> <span class=\"math inline\">\\(\\pi^*\\)</span>，</p>\n<p>既能让模型获得的期望奖励尽可能高，又能控制策略模型<span class=\"math inline\">\\(\\pi_\\theta\\)</span>和参考模型 <span class=\"math inline\">\\(\\pi_{ref}\\)</span>之间的差异在合理的范围内。</p>\n<p>论文进一步证明了，这个最优策略 <span class=\"math inline\">\\(\\pi^*\\)</span>、参考策略模型 <span class=\"math inline\">\\(\\pi_{ref}\\)</span>以及偏好数据里藏着的奖励函数<span class=\"math inline\">\\(r_{\\theta}\\)</span> ，三者之间有明确的数学关系，详细的推导过程见论文。这意味着，不用单独训练一个奖励模型，直接拿偏好数据就能优化策略模型。</p>\n<p>具体来说，DPO 让正在训练的模型<span class=\"math inline\">\\(\\pi_\\theta\\)</span>，在面对同一个输入提示 <span class=\"math inline\">\\(x\\)</span>时，生成人类偏好的回答<span class=\"math inline\">\\(y_w\\)</span>，而不是被否定的回答<span class=\"math inline\">\\(y_l\\)</span>。对应的损失函数定义如下：</p>\n<p></p><div class=\"math display\">\\[\\begin{align} L_{DPO}(\\pi_\\theta, \\pi_{ref}) = -E_{(x, y_w, y_l) \\sim {D}}[log(\\sigma(\\beta * (log\\frac{\\pi_\\theta(y_w | x)}{\\pi_{ref}(y_w | x)} - log\\frac{\\pi_\\theta(y_l | x)}{\\pi_{ref}(y_l | x)})))] \\end {align}\n\\]</div><p></p><p>我们来拆解这个公式的几个关键部分：</p>\n<ul>\n<li>\n<p><strong>数据来源</strong> <span class=\"math inline\">\\(D\\)</span> : 是人类标注的偏好数据集，每个样本是 \"提示 <span class=\"math inline\">\\(x\\)</span> + 更优回答<span class=\"math inline\">\\(y_w\\)</span> + 较差回答<span class=\"math inline\">\\(y\\_l\\)</span>\" 的组合</p>\n</li>\n<li>\n<p><strong>概率比的比较</strong>:</p>\n<ul>\n<li>\n<p><span class=\"math inline\">\\(log\\frac{\\pi_\\theta(y_w | x)}{\\pi_{ref}(y_w | x)}\\)</span>：反映当前模型<span class=\"math inline\">\\(\\pi_\\theta\\)</span>相比参考模型<span class=\"math inline\">\\(\\pi_{ref}\\)</span>倾向于生成优质回答<span class=\"math inline\">\\(y_w\\)</span>的程度，这个值越大越好</p>\n</li>\n<li>\n<p><span class=\"math inline\">\\(log\\frac{\\pi_\\theta(y_l | x)}{\\pi_{ref}(y_l | x)}\\)</span>：反映当前模型<span class=\"math inline\">\\(\\pi_\\theta\\)</span>相比参考模型<span class=\"math inline\">\\(\\pi_{ref}\\)</span>倾向于生成差回答<span class=\"math inline\">\\(y_l\\)</span>的程度，这个值越小越好</p>\n</li>\n<li>\n<p>这两个概率比的差值，就是模型学到的<strong>优质回答比差回答好多少</strong>的信号，两者相差越大，说明模型越能区分好坏，并且越偏爱好的回答，相当于把偏好转化成了隐式奖励。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>调控因子</strong> <span class=\"math inline\">\\(\\beta\\)</span>：用来控制<span class=\"math inline\">\\(\\pi_\\theta\\)</span>和<span class=\"math inline\">\\(\\pi_{ref}\\)</span>的偏离程度，<span class=\"math inline\">\\(\\beta\\)</span>越大，表明模型需要更明显的偏好差异，才会认定一个回答比另一个好。</p>\n</li>\n<li>\n<p><strong>损失的作用</strong>：<span class=\"math inline\">\\(Sigmoid\\)</span>把奖励信号转成更优回答的概率，再用负对数似然损失来训练，本质是让模型尽可能准确地区分好回答和差回答。</p>\n</li>\n</ul>\n<h2 id=\"42-dpo的训练过程\">4.2 DPO的训练过程</h2>\n<p><strong>数据准备</strong>：收集人类偏好数据集 (<span class=\"math inline\">\\(x, y_w, y_l\\)</span>)</p>\n<p><strong>模型初始化</strong>：</p>\n<ul>\n<li>\n<p><strong>Actor Model</strong> <span class=\"math inline\">\\(\\pi_{\\theta}\\)</span> ：用SFT后的模型作为初始模型，<strong>参数可变</strong>。</p>\n</li>\n<li>\n<p><strong>Reference Model</strong> <span class=\"math inline\">\\(\\pi_{ref}\\)</span>：SFT后的模型，<strong>参数冻结</strong>。</p>\n</li>\n</ul>\n<p><strong>训练过程</strong>：</p>\n<ul>\n<li>\n<p>循环epochs次</p>\n<ul>\n<li>\n<p>从 数据集<span class=\"math inline\">\\(D\\)</span>中抽取 (<span class=\"math inline\">\\(x, y_w, y_l\\)</span>) batch数据</p>\n<ul>\n<li>\n<p>对于每个样本，计算公式（7）中的中间变量值 <span class=\"math inline\">\\(\\pi_\\theta(y_w | x)\\)</span>、<span class=\"math inline\">\\(\\pi_{ref}(y_w | x)\\)</span>、<span class=\"math inline\">\\(\\pi_\\theta(y_l | x)\\)</span>、<span class=\"math inline\">\\(\\pi_{ref}(y_w | x)\\)</span>及其对数概率。通常是计算序列的总对数概率， <span class=\"math inline\">\\(log \\pi_theta(y | x) = \\sum_t log \\pi_\\theta(token_t | x, y_{&lt;t})\\)</span></p>\n</li>\n<li>\n<p>代入 DPO 损失函数公式，计算损失，使用梯度下降更新 <span class=\"math inline\">\\(\\pi_{\\theta}\\)</span> 的参数。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>重复此过程，直到模型收敛或达到预定训练步数。</p>\n</li>\n</ul>\n<h2 id=\"43-dpo的优缺点\">4.3 DPO的优缺点</h2>\n<p><strong>优点</strong>：① 训练链路极简化：直接从偏好数据里提取隐式的奖励信息，没有复杂的数据采样过程，省掉了训练奖励模型、价值函数的步骤。② 资源占用少：仅有参考模型和策略模型，显存和计算资源的消耗大幅降低，训练也更稳定、更容易落地。</p>\n<p><strong>缺点</strong>：① 依赖大量高质量二元偏好数据：虽然可以借助开源 LLM 生成优质数据，但数据收集仍有难度；② 适配场景较局限：因高度依赖偏好数据，难以覆盖复杂推理任务，能力上限不及 PPO，仅胜在流程简单、训练成本低。</p>\n<h1 id=\"5-grpo\">5 GRPO</h1>\n<p>论文标题：DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</p>\n<p>论文地址：<a href=\"https://arxiv.org/pdf/2402.03300\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2402.03300</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek团队发现，PPO算法中Critic模型，参数规模与Actor模型相当，显著增加了LLM训练的内存占用与计算成本；更关键的是，很多LLM任务（如数学推理、代码生成等））奖励信号稀疏（仅序列末尾由RM给出奖励），导致训练能精准估计每个token价值的Critic模型异常困难。</p>\n<p>Critic模型的核心作用是为优势函数计算提供基线以降低方差，能否用更高效方式替代Critic实现该目标呢？为此，DeepSeek团队提出GRPO（Group Relative Policy Optimization）算法，突破了对Critic模型的依赖，为策略模型的高效优化开辟了新路径。</p>\n<h2 id=\"51-grpo的原理\">5.1 GRPO的原理</h2>\n<p>GRPO取消了PPO中用于估计价值的Critic模型，通过同一Prompt下的群体信息来构造基线。即，针对单个 Prompt，让策略模型生成 <span class=\"math inline\">\\(G\\)</span> 个不同输出 <span class=\"math inline\">\\({\\{o_1, o_2, ..., o_G\\}}\\)</span>，用奖励模型给每个输出打分 <span class=\"math inline\">\\(r={\\{r_1, r_2, ..., r_G\\}}\\)</span>，计算这组奖励的均值与标准差，再将每个输出的原始奖励归一化，得到优势</p>\n<p></p><div class=\"math display\">\\[\\begin{align} \\hat{A}_{i,t} = \\widetilde{r}_i = \\frac{r_i - mean(r)}{std(r)} \\end{align}\n\\]</div><p></p><p>由上式得到反映群组相对好坏的分数，以此替代 Critic 提供的优势基线。</p>\n<p>由此看出，GRPO的训练仅需三个模型：</p>\n<ul>\n<li>\n<p><strong>策略模型</strong> <span class=\"math inline\">\\(\\\\pi_{\\theta}\\)</span> ：由SFT模型初始化，根据组内相对奖励动态更新参数，参数变化</p>\n</li>\n<li>\n<p><strong>参考模型</strong> <span class=\"math inline\">\\(\\pi_{ref}\\)</span>：冻结参数的SFT，参数不变</p>\n</li>\n<li>\n<p><strong>奖励模型</strong> <span class=\"math inline\">\\(r\\_{\\theta}\\)</span>：用于评估生成的完整响应序列的质量，为策略模型提供优化方向，冻结参数</p>\n</li>\n</ul>\n<p>GRPO算法沿用 PPO 的 clip 阶段结构，优势估计被替换为组内归一化奖励：</p>\n<p></p><div class=\"math display\">\\[\\begin{align}\nJ_{GPRO}(\\theta) = E[q\\sim P(Q), {o_i} \\sim \\pi_{\\theta_{old}(O|q)}] \n\\frac{1}{G} \\sum_{i=1}^G \\frac{1}{|o_i|} \\sum_{t=1}^{|o_i|} {\\{min [ratio_t *\\hat{A}_{i,t}, clip(ratio_t, 1-\\varepsilon, 1+\\varepsilon)\\}}*\\hat{A}_{i,t}] - \\beta D_{KL}[\\pi_\\theta || \\pi_{ref}]\\}\n\n\\end {align}\\]</div><p></p><p>式（9）的中间变量拆解如下：</p>\n<ul>\n<li>\n<p>$\\hat{A}_{i,t} $ 由公式（8）给出，作用于序列中每一个 token，就是说，所有 token 共享同一个优势</p>\n</li>\n<li>\n<p><span class=\"math inline\">\\(ratio_t=\\frac{\\pi_\\theta(o_{i,t} |q, o_{i,&lt;t})}{\\pi_{old}(o_{i,t} |q, o_{i,&lt;t})}\\)</span>, ，即新旧策略对同一动作的概率比</p>\n</li>\n<li>\n<p><span class=\"math inline\">\\(\\beta D_{KL}[\\pi_\\theta || \\pi_{ref}]\\)</span>，约束 策略模型不要偏离参考模型太远</p>\n</li>\n</ul>\n<h2 id=\"52-grpo的训练过程\">5.2 GRPO的训练过程</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p><strong>输入项</strong>：初始策略模型 <span class=\"math inline\">\\(\\pi_{\\theta_{init}}\\)</span> 、奖励模型 <span class=\"math inline\">\\(r_{\\theta}\\)</span>、任务提示集 <span class=\"math inline\">\\(D\\)</span>，以及超参数 <span class=\"math inline\">\\(\\varepsilon\\)</span>,<span class=\"math inline\">\\(\\beta\\)</span>（控制训练稳定性、更新步长等）。</p>\n</li>\n<li>\n<p><strong>外层循环，总迭代轮次</strong> <span class=\"math inline\">\\(I\\)</span></p>\n<p>每一轮外层循环包含以下操作：</p>\n<ul>\n<li>\n<p>复制当前策略模型<span class=\"math inline\">\\(\\pi_{\\theta}\\)</span>的参数并冻结，将其作为参考模型<span class=\"math inline\">\\(\\pi_{ref}\\)</span></p>\n</li>\n<li>\n<p>进入内层循环（步长<span class=\"math inline\">\\(M\\)</span>），执行策略的更新</p>\n<ul>\n<li>\n<p>采样任务与旧策略：从任务提示集 <span class=\"math inline\">\\(D\\)</span>中采样一个批次 <span class=\"math inline\">\\(D_b\\)</span>, 将当前策略模型<span class=\"math inline\">\\(\\pi_{\\theta}\\)</span>暂存为旧策略 <span class=\"math inline\">\\(\\pi_{\\theta_{old}}\\)</span>（用于后续生成候选输出）</p>\n</li>\n<li>\n<p>生成候选输出并计算奖励：对批次中每个任务q，用旧策略旧策略 <span class=\"math inline\">\\(\\pi_{\\theta_{old}}\\)</span>生成G个候选输出 <span class=\"math inline\">\\({\\{o_1, o_2, ..., o_G\\}}\\)</span>，用奖励模型 $$r_{\\theta}$$为每个候选输出计算奖励 <span class=\"math inline\">\\({\\{r_1, r_2, ..., r_G\\}}\\)</span></p>\n</li>\n<li>\n<p>计算组相对优势： 由公式（8）计算群组相对优势 $\\hat{A}_{i,t} $</p>\n</li>\n<li>\n<p>优化策略模型：公式（9)（10）的梯度更新策略模型<span class=\"math inline\">\\(\\pi_{\\theta}\\)</span>的参数</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"53-grpo算法的优缺点\">5.3 GRPO算法的优缺点</h2>\n<p><strong>优点</strong>：① 稳定性更强：无需依赖价值函数，只要奖励模型能相对判断群体内策略优劣，降低对价值估计精度的依赖降低对价值估计精度的依赖，提升算法稳定性；② 训练成本更低：没有了Critic 模型，显存占用减少大幅降低，相同硬件可训练更大模型或更大batch；③ 易实现且适配并行：组内各策略可独立与环境交互、收集数据，便于利用分布式框架实现并行训练加速。</p>\n<p><strong>缺点</strong>：①存在固有偏差：归一化易偏好短答案或冗长错误输出，且标准差归一化使模型优先优化简单问题（奖励稳定），忽视难题（奖励波动大） ；② 目标不一致问题：奖励函数针对完整序列打分（需等待完整回答），而GRPO优化目标的重要性采样基于token级别计算损失，两者目标存在偏差；③ 高方差和不稳定问题：GRPO 在 token 级别计算重要性采样权重，单个token只被采样一次，难以校正偏离原始策略的 token 分布，易引入高方差噪声，导致梯度估计不稳定。</p>\n<h1 id=\"6-gspo\">6 GSPO</h1>\n<p>论文标题：Group Sequence Policy Optimization</p>\n<p>论文地址：<a href=\"https://arxiv.org/pdf/2507.18071\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2507.18071</a></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>GSPO(Group Sequence Policy Optimization，组序列策略优化)旨在解决GRPO中训练过程中存在的固有偏差、目标不一致、高方差和不稳定的问题。GSPO将RL中重要性采样的单位从令牌级别提升至整个序列级别，又引入了序列长度归一化， 确保不同长度的问题享有公平的优化尺度，从根源解决训练稳定性问题，完美适配 MoE 了架构。</p>\n<h2 id=\"61-gspo的原理和训练过程\">6.1 GSPO的原理和训练过程</h2>\n<p>首先，我们来看下GRPO和GSPO的目标函数</p>\n<ul>\n<li>GRPO目标函数</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>其中，<span class=\"math inline\">\\(ratio_t=\\frac{\\pi_\\theta(o_{i,t} |q, o_{i,&lt;t})}{\\pi_{old}(o_{i,t} |q, o_{i,&lt;t})}\\)</span></p>\n<ul>\n<li>GSPO目标函数</li>\n</ul>\n<p></p><div class=\"math display\">\\[ \\begin{align}\nJ_{GSPO}(\\theta) = E[x\\sim D, {\\{y_i}\\}_{i=1}^G \\sim \\pi_{\\theta_{old}(.|x)}] [\n\\frac{1}{G} \\sum_{i=1}^G min (s_i(\\theta) *\\hat{A}_i, clip(s_i(\\theta), 1-\\varepsilon, 1+\\varepsilon)*\\hat{A}_i)]\n\n\\end {align} \\]</div><p></p><p>其中，<span class=\"math inline\">\\(s_i(\\theta)=(\\frac{\\pi_\\theta(y_i |x)}{\\pi_{old}(y_i |x)}) ^{(\\frac{1}{|y_i|})} = exp(\\frac{1}{|y_i|} \\sum_{t=1}^{|y_i|}log\\frac{\\pi_\\theta(y_{i,t} |x, y_{i,&lt;t})}{\\pi_{old}(y_{i,t} |x, y_{i,&lt;t})})\\)</span> ，<span class=\"math inline\">\\(|y_i|\\)</span>是响应<span class=\"math inline\">\\(y_i\\)</span> 的长度，长度归一 化是关键，确保不同长度序列的重要性比率具有可比性，防止比率因序列过长而剧烈波动。注意，论文里为了简化，在公式（11）中没有加KL，实际应用中是有用KL的。</p>\n<p>通过对比GRPO与GSPO的核心公式，能清晰看出两者在重要性采样单位与计算逻辑上的关键差异。</p>\n<p>先看GRPO的目标函数，其加权优势的计算核心聚焦于<strong>token级别</strong>的，如<span class=\"math inline\">\\(ratio_t=\\frac{\\pi_\\theta(o_{i,t} |q, o_{i,&lt;t})}{\\pi_{old}(o_{i,t} |q, o_{i,&lt;t})}\\)</span>, 所示，针对第 <span class=\"math inline\">\\(i\\)</span>个序列中的第<span class=\"math inline\">\\(t\\)</span>个token进行运算。</p>\n<p>举个直观例子，若一个组包含5条样本序列，每条序列有20个token，GRPO需要为这5条序列的每一个token分别计算加权优势。</p>\n<p>两次平均操作：内层先对单条序列的20个token取平均，外层再对5条不同序列取平均，<strong>本质就是算术平均</strong>，最终得到梯度更新的有效信号。</p>\n<p>再看GSPO的目标函数，从公式<span class=\"math inline\">\\(s_i(\\theta)=(\\frac{\\pi_\\theta(y_i |x)}{\\pi_{old}(y_i |x)}) ^{(\\frac{1}{|y_i|})} = exp(\\frac{1}{|y_i|} \\sum_{t=1}^{|y_i|}log\\frac{\\pi_\\theta(y_{i,t} |x, y_{i,&lt;t})}{\\pi_{old}(y_{i,t} |x, y_{i,&lt;t})})\\)</span>, 可以看出，其加权优势的计算单位直接升级为<strong>序列级别，</strong>内层平均由算术平均本变为了几何平均，外层的计算逻辑依然不变。</p>\n<p>GSPO的训练过程和GRPO基本一致，差别在于目标函数中重要性采样计算逻辑，这里不做过多解释。</p>\n<h2 id=\"62-gspo的优缺点\">6.2 GSPO的优缺点</h2>\n<p><strong>优点</strong>：① 提升训练稳定性：GRPO 在 token 级进行重要性采样时，若某时间步生成错误 token，此时优势为 <span class=\"math inline\">\\(A\\_t &lt;0\\)</span>，旧策略生成该 token 的概率极低（如<span class=\"math inline\">\\(1e^{-8}\\)</span>），新策略生成概率即使仅为 0.001，重要性比值也会飙升至 <span class=\"math inline\">\\(10^5\\)</span>，通过公式(9) (10)发现，在<span class=\"math inline\">\\(A_t &lt;0\\)</span>情况下，这么大的重要性比值不会被裁剪，进而造成损失函数的大波动，噪声会不断累积，甚至模型会训崩。而 GSPO 以序列为单位计算重要性采样比值，即便个别 token的重要性比值飙升，经过几何平均后(经过Log运算、算术平均、指数运算)，也会被平滑，不会造成比值的大幅波动，从而避免了损失函数的震荡，保障了训练稳定性；② 适配 MoE 架构模型：GRPO 采用 token 级重要性采样，需依赖路由重放等技巧才能稳定训练；而 GSPO 基于序列级计算重要性采样，无需这类复杂操作即可实现 MoE 模型的稳定训练，大幅简化了训练流程，同时释放了 MoE 模型的潜力。</p>\n<p><strong>缺点</strong>：① 计算复杂度升高：相比 GRPO 的 token 级重要性采样，GSPO 切换为序列级计算后，算法的实现难度与计算成本有所增加。</p>\n<h1 id=\"7-参考资料\">7 参考资料</h1>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1932791271363154917\" rel=\"noopener nofollow\" target=\"_blank\">https://zhuanlan.zhihu.com/p/1932791271363154917</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/gSUw8bXraKy0RzVU_Crwcw\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/gSUw8bXraKy0RzVU_Crwcw</a></p>\n<p><a href=\"https://arxiv.org/pdf/1706.03741\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/1706.03741</a></p>\n<p><a href=\"https://arxiv.org/pdf/2305.18290\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2305.18290</a></p>\n<p><a href=\"https://arxiv.org/pdf/2402.03300\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2402.03300</a></p>\n<p><a href=\"https://arxiv.org/pdf/2507.18071\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2507.18071</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-09 14:29</span>&nbsp;\n<a href=\"https://www.cnblogs.com/aifrontiers\">AI-Frontiers</a>&nbsp;\n阅读(<span id=\"post_view_count\">33</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "干掉 Claude Code，这个开源 AI 编程工具杀疯了？",
      "link": "https://www.cnblogs.com/yupi/p/19460549",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yupi/p/19460549\" id=\"cb_post_title_url\" title=\"发布于 2026-01-09 11:30\">\n    <span>干掉 Claude Code，这个开源 AI 编程工具杀疯了？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"干掉 Claude Code，这个开源 AI 编程工具杀疯了？\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2225420/202601/2225420-20260109111409828-677596839.png\" />\n        最近我身边很多程序员朋友开始从 Claude Code 转向了另一个工具，正是突然大火的开源项目 OpenCode。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"md-end-block md-heading\"><span class=\"md-plain\">大家好，我是程序员鱼皮。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Claude Code 一直是大家公认的 AI 编程命令行工具 Top 1，在 AI 和程序员圈子里几乎是神一般的存在。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但是，这狗玩意儿对中国用户可不太友好……</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">首先，如果你想要使用 Claude Code，就必须要有特殊的网络 + 官方账号，否则就会看到一片红。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">此外，2025 年 9 月，Anthropic 公司不知道抽什么风，突然宣布 <span class=\"md-pair-s \"><strong>全面禁止中国控股企业使用 Claude 服务</strong><span class=\"md-plain\">，不仅包括中国大陆企业，连海外中资控股超过 50% 的公司都在封禁范围内！</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">甚至 Anthropic 还特别点名了中国，把咱们称为 <span class=\"md-pair-s \"><strong>敌对国家</strong><span class=\"md-plain\">！</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">天下苦 Claude Code 久矣！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但是最近我身边很多程序员朋友开始从 Claude Code 转向了另一个工具，正是突然大火的开源项目 OpenCode。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这玩意只用了半年的时间，就在 GitHub 上涨到了 5.2w Star！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这是个什么概念？比我在 GitHub 上开源的几十个项目的总和加起来都多！慕了慕了……</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">OpenCode 到底是什么？凭什么这么火？</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">啥是 OpenCode？</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://opencode.ai/\" rel=\"noopener nofollow\"><span class=\"md-plain\">OpenCode</span></a><span class=\"md-plain\"> 是一款 100% 开源的 AI 编程命令行工具，可以在 <span class=\"md-pair-s \"><strong>终端、IDE、甚至桌面应用</strong><span class=\"md-plain\"> 中使用。</span></span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">你可能会问：这玩意儿跟 Claude Code 有啥区别？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">试试不就知道了？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">接下来我带大家实操一下，从零开始安装、配置、到实际写代码，一条龙服务~</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">从 0 开始上手 OpenCode</span></h2>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">1、安装运行 OpenCode</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">直接进入 OpenCode 官网，复制一行命令：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">命令如下：</span></p>\n<pre class=\"md-fences md-end-block ty-contain-cm modeLoaded\"><span><span class=\"cm-builtin\">curl&nbsp;<span class=\"cm-attribute\">-fsSL&nbsp;https://opencode.ai/install |&nbsp;<span class=\"cm-builtin\">bash</span></span></span></span></pre>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">然后在终端中执行，就可以完成安装了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">安装完成之后，输入 <span class=\"md-pair-s\"><code>opencode</code><span class=\"md-plain\"> 进入程序，接下来你就可以愉快地使用了~</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">先来个经典的 Hello World，AI 成功给出了回复。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">恭喜，到这里你已经掌握了 OpenCode 的 70% 了。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">2、选择模式和模型</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">OpenCode 支持 2 种模式，默认是 Build 模式，用来构建应用、生成代码。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">按一下 Tab 键，就可以切换到 Plan 模式，用于生成执行计划。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">按一下 <span class=\"md-pair-s\"><code>Ctrl + p</code><span class=\"md-plain\"> 键，可以打开命令面板，里面有几十个内置命令。我们先来试着切换一下大模型：</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">默认提供了 4 个免费模型：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">好家伙，连智谱最新的 GLM-4.7 竟然也免费？那我的 Coding Plan 套餐不是白开了？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">除了免费的模型外，OpenCode 支持超多的 AI 模型，你可以自由选择：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">选中模型后，配置自己的 API Key 就好了：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">如果你之前有 <span class=\"md-pair-s \"><strong>Claude Pro/Max 订阅账号</strong><span class=\"md-plain\">，可以直接登录使用，无缝从 Claude Code 迁移过来。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">3、快捷指令</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">OpenCode 支持斜杠命令，输入 <span class=\"md-pair-s\"><code>/</code><span class=\"md-plain\">，能看到很多操作，比如查看模型列表、查看 Agents、管理 MCP、切换主题等等：</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">支持几十个不同的主题，颜值都挺高的，从这点也能看出来 OpenCode 很注重用户的体验：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">输入 <span class=\"md-pair-s\"><code>@</code><span class=\"md-plain\"> 可以快速关联目录文件，给 AI 添加上下文： </span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">4、交互体验</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">相比于 Claude Code，OpenCode 真是把命令行的交互体验拉满了，甚至我觉得它是一个伪装成命令行的桌面应用。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">你可以点击某条消息，然后会弹出一个消息动作框，你可以撤回消息和 AI 的回复，也可以复制、或者基于当前对话新开一个对话框。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">你可以通过鼠标上下滚动来切换选单，并且可以直接通过鼠标点击进入下一步。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">你可以按 <span class=\"md-pair-s\"><code>Ctrl + p</code><span class=\"md-plain\"> 键打开命令面板，然后开启侧边栏：</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">然后界面就变成了这样，你管这叫命令行？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">5、LSP 支持</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">细心的你一定看到了，右边的侧边栏有个 <span class=\"md-pair-s\"><code>LSP</code><span class=\"md-plain\">，这是什么鬼东西？老色批？</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">LSP（Language Server Protocol 语言服务器协议）是微软开发的一种通信协议，用于让代码编辑器和语言服务器之间进行通信。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">简单来说，<span class=\"md-pair-s \"><strong>LSP 就是让编辑器看懂代码的技术。</strong></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">比如你在 VS Code 里写代码，输入 <span class=\"md-pair-s\"><code>console.</code><span class=\"md-plain\"> 它会自动提示 <span class=\"md-pair-s\"><code>log</code><span class=\"md-plain\">、点击函数名能跳转到代码定义、写错代码会画红线提醒。这些代码编辑器的功能，背后都是 LSP 在干活。</span></span></span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">OpenCode 支持 LSP，意味着 AI 能真正理解你的代码结构，而不是把代码当普通文字瞎猜，改起来更精准。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">比如我让 AI 介绍我的 AI 答题平台项目中最有价值的代码，LSP 就派上用场了。它能帮 AI 快速定位某段代码在哪里被调用、引用了哪些变量，而不是让 AI 傻傻地全局搜索文本。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">6、回到之前的会话</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">如果你不小心关闭了 OpenCode，不用担心，可以打开命令面板，选中 “Switch session” 切换会话：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">就能回到之前的聊天了：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">桌面版 OpenCode</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">即使 OpenCode 支持了这么多改进用户体验的交互，但我估计大多数同学还是不喜欢小黑框的。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">没关系，OpenCode 还提供了桌面应用版本！macOS、Windows、Linux 全端支持，这是真的要卷死 Claude Code 的节奏啊……</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://opencode.ai/download\" rel=\"noopener nofollow\">https://opencode.ai/download</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">不过当我怀着满腔热血安装并打开它时，竟然报错了！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">经过一番排查，发现原来是我开了代理，关闭之后就正常运行了。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">但是用惯了 Cursor，这个交互体验真的有点敷衍了，不推荐大家使用。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">OpenCode 扩展能力</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">到目前为止，我觉得 OpenCode 在前端用户体验上全方面碾压 Claude Code，而且 OpenCode 完全兼容 Claude Code 的 Skills 系统！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Skills 是一种给 AI 准备的能力扩展包。你可以把它理解成给新同事准备的工作交接文档，里面包含任务执行方法、工具使用说明、模板素材等。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">比如你可以创建一个 <span class=\"md-pair-s\"><code>公司代码规范 Skill</code><span class=\"md-plain\">，把代码风格、命名规则、注释要求等写进去。之后 Claude Code 生成的代码就会自动遵循这些规范，不用每次都重复说明。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">根据官方文档，OpenCode 会自动搜索这些位置的 Skills：</span></p>\n<ul class=\"ul-list\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\"><code>.opencode/skill/&lt;name&gt;/SKILL.md</code><span class=\"md-plain\">（项目目录）</span></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\"><code>~/.config/opencode/skill/&lt;name&gt;/SKILL.md</code><span class=\"md-plain\">（用户目录）</span></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\"><code>.claude/skills/&lt;name&gt;/SKILL.md</code><span class=\"md-plain\">（Claude Code 兼容）</span></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\"><code>~/.claude/skills/&lt;name&gt;/SKILL.md</code><span class=\"md-plain\">（Claude Code 兼容）</span></span></p>\n</li>\n</ul>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">也就是说，如果你之前给 Claude Code 创建过自定义 Skills，直接拿过来就能用！又是无缝迁移。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">Oh My OpenCode 开挂插件</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">如果你觉得 OpenCode 还不够强，可以试试 <span class=\"md-pair-s\"><code>Oh My OpenCode</code><span class=\"md-plain\"> 这个开源的 OpenCode 增强插件，已经 1w Star 了。</span></span></span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">项目地址：<span class=\"md-link md-pair-s\"><a href=\"https://github.com/code-yeongyu/oh-my-opencode\" rel=\"noopener nofollow\">https://github.com/code-yeongyu/oh-my-opencode</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这个插件有多牛？看看用户评价：</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">\"It made me cancel my Cursor subscription.\"（它让我取消了 Cursor 订阅）</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">\"Knocked out 8000 eslint warnings with Oh My Opencode, just in a day\"（一天内用它解决了 8000 个 eslint 警告）</span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Oh My OpenCode 的核心功能是引入了一个叫 <span class=\"md-pair-s \"><strong>Sisyphus</strong><span class=\"md-plain\"> 的智能体编排系统。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我特地去搜了一下：</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">西西弗斯（Sisyphus）是古希腊神话中一位因欺骗众神、挑战权威而被诸神惩罚的国王，他的惩罚是永无止境地将一块巨石推上山顶，而石头一到山顶便会滚落，如此周而复始，象征着徒劳无功、永无休止的任务，也代表着一种对荒诞命运的抗争精神。</span></p>\n</blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这个系统可以：</span></p>\n<ol class=\"ol-list\" start=\"\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">并行调度多个 AI 模型：比如让 GPT debug 的同时让 Gemini 写前端</span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">自动任务管理：不完成任务不让停，像西西弗斯推石头一样锲而不舍</span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">智能代码审查：自动检测并清理 AI 生成的冗余注释</span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">LSP 深度集成：提供重命名、跳转定义等 IDE 级功能</span></p>\n</li>\n</ol>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">简单来说，Sisyphus 就是一个 AI 监工，它能同时指挥多个 AI 模型干活，还会盯着它们把任务做完。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">虽然官方说用一行命令就能完成安装，但我建议你先安装 bun，再执行 npx 来安装，否则可能会报错。</span></p>\n<pre class=\"md-fences md-end-block ty-contain-cm modeLoaded\"><span><span class=\"cm-builtin\">npm&nbsp;install bun&nbsp;<span class=\"cm-attribute\">-g<br /><span>npx oh-my-opencode install</span></span></span></span></pre>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">安装过程中，可能会问你有没有某些模型的订阅，我反正啥都没有，一直选 \"No\" 就行了：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">安装完成后，再次进入 OpenCode，之后只需要在你的提示词里加上 <span class=\"md-pair-s\"><code>ultrawork</code><span class=\"md-plain\">（或 <span class=\"md-pair-s\"><code>ulw</code><span class=\"md-plain\">）这个开挂咒语，就能激活全部增强功能。自动调度多个 AI 模型同时工作、深度探索代码库、锲而不舍地执行。</span></span></span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">下面我们试试看，正好来验证一下 OpenCode 做项目的能力如何？能不能把 Claude Code 一脚踹飞？</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">实战项目 - 用 OpenCode 做个 AI 健康助手</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">最近蚂蚁集团的 <span class=\"md-pair-s\"><code>蚂蚁阿福</code><span class=\"md-plain\"> AI 健康助手火了，地铁口、公司楼下的电视广告中随处可见何炅老师的身影。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">虽然我还没有用过它，但是听说它可以通过拍皮肤、拍报告提供 AI 初诊，还能智能回答医学科普和治疗建议。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">那我们也来做个类似的健康小助手网站吧！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">前有蚂蚁阿福，今有鱼皮阿坤。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">先分析一下，我们要做的是包含前端 + 后端的全栈项目，而且后端还需要调用 AI 大模型来生成内容。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这里我选择用 <span class=\"md-pair-s \"><strong>Vercel AI Gateway</strong><span class=\"md-plain\"> 来实现 AI 能力，这是一款简单易用的 AI 网关。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">什么是 AI 网关？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">简单来说，它就像是火车站的检票口，你的应用发来的请求先经过网关，网关帮你处理认证、限流、监控等一系列复杂的操作，然后把请求转发给 AI 大模型。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">而且 Vercel AI Gateway 支持对接 500 多个大模型，还有免费额度，非常适合学习和小项目。</span></p>\n<blockquote>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">指路：<span class=\"md-link md-pair-s\"><a href=\"https://vercel.com/ai-gateway\" rel=\"noopener nofollow\">https://vercel.com/ai-gateway</a></span></span></p>\n</blockquote>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">1）首先你需要注册登录 Vercel，然后在控制台创建 API Key，注意不要泄露哦：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">2）启动 OpenCode，切换模型到编程能力很强、并且免费的 GLM-4.7，然后输入这段提示词：</span></p>\n<pre class=\"md-fences md-end-block ty-contain-cm modeLoaded\"><span>你是一位专业的程序员，请帮我开发《每日健康小助手》网站，用户可以通过和 AI 聊天来记录和管理每日健康状态。<br /><span><span>​<br /><span><span class=\" cm-header cm-header2\">## 开发要求<br /><span><span>​<br /><span><span class=\"cm-block-start cm-variable-2\">1.&nbsp;<span class=\"cm-variable-2\">需要包含完整的前端和后端，后端使用 Node.js<br /><span><span class=\"cm-block-start cm-variable-2\">2.&nbsp;<span class=\"cm-variable-2\">使用 Vercel 的 AI Gateway 实现 AI 能力，需要先通过官方文档来获取用法：https://vercel.com/docs/ai-gateway/getting-started<br /><span><span class=\"cm-block-start cm-variable-2\">3.&nbsp;<span class=\"cm-variable-2\">以完成核心功能为目标，确保项目可以正常运行<br /><span><span class=\"cm-block-start cm-variable-2\">4.&nbsp;<span class=\"cm-variable-2\">整体网站界面采用清新的绿色健康风格，响应式适配各种尺寸的设备<br /><span><span class=\"cm-block-start cm-variable-2\">5.&nbsp;<span class=\"cm-variable-2\">AI 需要主动询问用户的健康状况，比如睡眠、运动、饮食等</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">点击发送后，OpenCode 会自动使用网页抓取工具读取 Vercel AI Gateway 的官方文档，学习最新的用法：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">大概 5 分钟左右，AI 就完成了全部代码的生成，并且自动安装了依赖。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">3）我直接把之前拿到的 Vercel 的 API Key 提供给 AI，让它帮我启动项目：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">4）启动项目成功后，打开浏览器访问 <span class=\"md-pair-s\"><code>localhost:3000</code><span class=\"md-plain\">，测试一下效果。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">结果报错了！无法调用 AI。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">可能是 AI 对 Vercel AI Gateway 文档的理解不到位，导致写错了调用 AI 的代码。于是我再次把文档输入给 AI，让它再战一次：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">结果又报错了，明明我已经给 AI 提供了 API Key，系统还是报错 “缺少 API Key”。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">于是我又调了一次 AI，告诉它 “这个 key 我之前已经提供给你了”。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">经过大概 5 次左右的报错和修复，仍然不能正常使用！我麻了啊……</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">于是，我有一个鬼点子：既然要跟 Claude Code 比较，那我不妨尝试用 Claude Code 修复这个 OpenCode 解决不了的问题？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">试试看！输入提示词：</span></p>\n<pre class=\"md-fences md-end-block ty-contain-cm modeLoaded\"><span>现在项目后端 AI 功能不可用<br /><span>请参考 https://vercel.com/docs/ai-gateway/getting-started 文档<br /><span>帮我修复后端，确保项目能正常运行</span></span></span></pre>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Claude Code 成功修复了问题，终于能够正常使用了：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">💡 注意，如果你遇到了调用 AI 网络超时的问题，可以让 AI 把调用的 baseURL 改为 <span class=\"md-link md-pair-s\"><a href=\"https://ai-gateway.vercel.sh/v1\" rel=\"noopener nofollow\">https://ai-gateway.vercel.sh/v1</a></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">之前类似的任务我用 Claude Code / Cursor + GLM，不到 10 分钟就搞定了。这次竟然花了 20 分钟左右，还要经过来回拉扯，才能正常使用。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">这让我不得不怀疑 OpenCode 的能力了。而且感觉 GLM 大模型在 OpenCode 中好像变笨了，不知道是不是我的错觉…… </span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">不行，大家把 OpenCode 吹得这么牛批，我得再试试，一定是我用法的问题！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<h3 class=\"md-end-block md-heading\"><span class=\"md-plain\">Ultrawork 模式</span></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">还记得前面提到的 <span class=\"md-pair-s\"><code>ultrawork</code><span class=\"md-plain\">（或 <span class=\"md-pair-s\"><code>ulw</code><span class=\"md-plain\">）开挂咒语么？搞起！</span></span></span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">进入战斗状态了：</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">可以查看子代理运行详情，先按 <span class=\"md-pair-s\"><code>Ctrl + x</code><span class=\"md-plain\"> 键，再按方向键来查看不同的代理。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">而且当后台任务完成时，会有一个提示。可以看到 “研究 Vercel AI SDK 对话模式” 的任务已经完成。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">不过你猜怎么着？我等了将近 10 分钟，任务还没结束……</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">看看这个任务列表，需要这么复杂吗？连数据库都给我干出来了？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img alt=\"=\" class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">我已经没耐心等下去了，毁灭吧！</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">看来这种不算太复杂的工作并不能发挥出多代理的优势。就像你只是要打印一张纸，没必要发动全公司的人，有的研究打印的纸张类型、有的研究打印机的状态、有的研究怎么打印姿势更优雅。</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">最后</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">经过上述简单的测试，我暂时对 OpenCode 保持观望状态。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">前端做的确实很不错，但后端的能力感觉跟 Claude Code 还有差距。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">如果只是追求前端使用方便，那我为什么不用 Cursor？</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-image md-img-loaded\"><img class=\"lazyload\" /></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">不过 OpenCode 的成功说明了一个道理：<span class=\"md-pair-s \"><strong>谁离用户近、谁能发现痛点，谁就有超越巨头的机会。</strong></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">Claude Code 确实很强，但它对中国用户的封禁，给了开源社区一个绝佳的机会。OpenCode 抓住了这个痛点，用更开放的方式赢得了用户的心。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">虽然效果有待提高，但毕竟 OpenCode 完全开源免费，对于喜欢折腾的程序员来说，可定制性更强。你甚至可以 fork 一份自己魔改，想怎么玩就怎么玩。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\">OK，就聊到这里。你用过 OpenCode 吗？欢迎评论区聊聊你的体验~</span></p>\n<p class=\"md-end-block md-p\">&nbsp;</p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\">更多编程学习资源</span></h2>\n<ul class=\"ul-list\">\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course\" rel=\"noopener nofollow\"><span class=\"md-plain\">Java前端程序员必做项目实战教程+毕设网站</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费编程学习交流社区（自学必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/course/cv\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员保姆级求职写简历指南（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.mianshiya.com/\" rel=\"noopener nofollow\"><span class=\"md-plain\">程序员免费面试刷题网站工具（找工作必备）</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640584449888772098\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Java零基础入门学习路线 + Java教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586673306091521\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Python零基础入门学习路线 + Python教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586014108303362\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新前端零基础入门学习路线 + 前端教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586867363954689\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据结构和算法零基础入门学习路线 + 算法教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1644279832026075138\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新C++零基础入门学习路线、C++教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641797333479903234\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新数据库零基础入门学习路线 + 数据库教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640589994284695553\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Redis零基础入门学习路线 + Redis教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641035880439271426\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机基础入门学习路线 + 计算机基础教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1641366118197153793\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新小程序入门学习路线 + 小程序开发教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"http://sqlmother.yupi.icu/\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新SQL零基础入门学习路线 + SQL教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640586295529324545\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Linux零基础入门学习路线 + Linux教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588753362108417\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新Git/GitHub零基础入门学习路线 + Git教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640587909942099969\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新操作系统零基础入门学习路线 + 操作系统教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588119619551233\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新计算机网络零基础入门学习路线 + 计算机网络教程</span></a></span></p>\n</li>\n<li class=\"md-list-item\">\n<p class=\"md-end-block md-p\"><span class=\"md-meta-i-c  md-link\"><a href=\"https://www.code-nav.cn/post/1640588392073150465\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新设计模式零基础入门学习路线 + 设计模式教程</span></a></span></p>\n</li>\n<li class=\"md-list-item md-focus-container\">\n<p class=\"md-end-block md-p md-focus\"><span class=\"md-meta-i-c md-link md-expand\"><a href=\"https://www.code-nav.cn/post/1640648711119892481\" rel=\"noopener nofollow\"><span class=\"md-plain\">最新软件工程零基础入门学习路线 + 软件工程教程</span></a></span></p>\n</li>\n</ul>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-09 11:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yupi\">程序员鱼皮</a>&nbsp;\n阅读(<span id=\"post_view_count\">510</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "线程池和高并发",
      "link": "https://www.cnblogs.com/philry/p/19359433",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/philry/p/19359433\" id=\"cb_post_title_url\" title=\"发布于 2026-01-09 09:14\">\n    <span>线程池和高并发</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div>\n<div><strong><span style=\"font-size: 18px;\">多线程</span></strong></div>\n<div><strong><span style=\"font-size: 16px;\">Java创建线程的几种方式有哪些？</span></strong></div>\n<div>常见有以下五种方式创建使用多线程：</div>\n<div><strong>1）实现&nbsp;Runnable&nbsp;接口：</strong></div>\n<ul>\n<li>\n<div>实现&nbsp;Runnable&nbsp;接口的&nbsp;run()&nbsp;方法，使用&nbsp;Thread&nbsp;类的构造函数传入&nbsp;Runnable&nbsp;对象，调用&nbsp;start()&nbsp;方法启动线程。</div>\n</li>\n<li>\n<div>例子：Thread thread = new Thread(new MyRunnable()); thread.start();</div>\n</li>\n</ul>\n<div><strong>2）继承&nbsp;Thread&nbsp;类：</strong></div>\n<ul>\n<li>\n<div>继承&nbsp;Thread&nbsp;类并重写&nbsp;run()&nbsp;方法，直接创建&nbsp;Thread&nbsp;子类对象并调用&nbsp;start()&nbsp;方法启动线程。</div>\n</li>\n<li>\n<div>例子：MyThread thread = new MyThread(); thread.start();</div>\n</li>\n</ul>\n<div><strong>3）使用&nbsp;Callable&nbsp;和&nbsp;FutureTask：</strong></div>\n<ul>\n<li>\n<div>实现&nbsp;Callable&nbsp;接口的&nbsp;call()&nbsp;方法，使用&nbsp;FutureTask&nbsp;包装&nbsp;Callable&nbsp;对象，再通过&nbsp;Thread&nbsp;启动。</div>\n</li>\n<li>\n<div>例子：FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new MyCallable()); Thread thread = new Thread(task); thread.start();</div>\n</li>\n</ul>\n<div><strong>4）使用线程池（ExecutorService）：</strong></div>\n<ul>\n<li>\n<div>通过&nbsp;ExecutorService&nbsp;提交&nbsp;Runnable&nbsp;或&nbsp;Callable&nbsp;任务，不直接创建和管理线程，适合管理大量并发任务。</div>\n</li>\n<li>\n<div>例子：ExecutorService executor = Executors.newFixedThreadPool(10); executor.submit(new MyRunnable());</div>\n</li>\n</ul>\n<div><strong>5）CompletableFuture（本质也是线程池，默认 forkjoinpool）：</strong></div>\n<ul>\n<li>\n<div>Java 8 引入的功能，非常方便地进行异步任务调用，且通过&nbsp;thenApply、thenAccept&nbsp;等方法可以轻松处理异步任务之间的依赖关系。</div>\n</li>\n<li>\n<div>CompletableFuture&lt;Void&gt; future1 = CompletableFuture.runAsync(() -&gt; {});</div>\n</li>\n</ul>\n<div>\n<div>&nbsp;</div>\n<div><strong><span style=\"font-size: 18px;\">线程生命周期及五种状态</span></strong></div>\n<div><img class=\"lazyload\" width=\"476\" /></div>\n<h3>&nbsp;</h3>\n<h3>1、New(初始化状态)</h3>\n<div>&nbsp;&nbsp; &nbsp;用new语句创建的线程处于新建状态，此时它和其他Java对象一样，仅仅在堆区中被分配了内存。如：Thread t = new MyThread();</div>\n<div>2、Runnable(就绪状态)</div>\n<div>&nbsp;&nbsp; &nbsp;当调用线程对象的start()方法，线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，Java虚拟机会为它创建方法调用栈和程序计数器。处于这个状态的线程位于可运行池中，等待获得CPU的使用权，并不是说执行了start()此线程立即就会执行。</div>\n<h3>3、Running(运行状态)</h3>\n<div>&nbsp;&nbsp; &nbsp;当就绪状态中的线程获得了CUP执行资源，执行run()中的代码，这样的线程我们称为运行状态的线程。</div>\n<div>4、Blocked(阻塞状态)</div>\n<div>&nbsp; &nbsp; 处于运行中的线程，由于某种原因放弃对cpu的使用权，处于阻塞状态，直到其进入就绪状态，才有机会再次被cpu调用进入运行状态。</div>\n<div>根据阻塞原因不同，阻塞分为三种：</div>\n<div>等待阻塞：运行状态中的线程执行wait方法，进入等待队列，等待阻塞；Java虚拟机就会把线程放到这个对象的等待池中；</div>\n<div>同步阻塞：线程获取同步锁失败（因为锁被其他线程占用），Java虚拟机就会把这个线程放到这个对象的锁池中；</div>\n<div>其他阻塞：通过调用sleep方法或者join方法或者发出I/O请求时，线程会进入阻塞状态，当sleep()状态超时，或者join()等待线程终止或者超时，或者I/O处理完毕，线程重新转入就绪状态；</div>\n<h3>5、Terminated（终止状态)</h3>\n<div>\n<div>\n<div>&nbsp;&nbsp; &nbsp;正常结束，线程执行完</div>\n<div>&nbsp;&nbsp; &nbsp;异常退出</div>\n</div>\n</div>\n<div>\n<div>\n<div>&nbsp;&nbsp; &nbsp;异常退出，除了程序有问题导致的异常的退出，还可以使用共享变量的方式（定义个boolean标识等）退出，或者Interrupt中断线程,抛出异常，捕获异常break，跳出循环状态；</div>\n<div>&nbsp;&nbsp; &nbsp;调用stop()，会造成死锁，线程不安全，不建议使用</div>\n<div>&nbsp;</div>\n<div><strong><span style=\"font-size: 18px;\">线程基本方法</span></strong></div>\n<div>1、线程等待（wait）</div>\n<div>&nbsp; &nbsp;&nbsp;调用该方法，线程进入waiting状态，只有等待另外的线程通知或被中断才会返回，调用wait()后，会释放对象锁，因为wait方法一般用在同步方法或者同步代码块中。</div>\n<div>2、线程睡眠（sleep）</div>\n<div>强迫一线程睡 N毫秒，sleep不会释放当前锁，导致线程进入Timed-wating状态。</div>\n<div>3、线程让步（yield）</div>\n<div>&nbsp; &nbsp; yeild会使当前线程让出cpu执行时间片，与其他线程一起重新竞争cpu时间片，一般情况下，优先级高的先得到，但也不一定，有的系统对优先级不敏感。</div>\n<div>4、线程中断（interrupt）</div>\n<div>&nbsp; &nbsp; 在run内部根据thread.isIterrupted() 安全终止线程。调用一个线程的interrupt() 方法中断一个线程，并不是强行关闭这个线程，仅仅是改变了内部维护的中断标识位，是线程固有的一个标识位。可以调用static方法isIterrupted() 判定当前线程是否处于中断状态：</div>\n<div>&nbsp; &nbsp; 1）如果一个正常线程，调用interrupt() ，是不能被打断的，打印中断标志位置为true</div>\n<div>&nbsp; &nbsp; 2）如果一个sleep或者wait的线程，调用interrupt() ，方法则抛出InterruptedException( InterruptedException表示一个阻塞被中断了)，线程的中断标志位会被复位成false；相当于用异常响应了这个中断，所以释放中断标志位。</div>\n<div>5、join（等待其他线程终止）</div>\n<div>&nbsp; &nbsp; 当前线程调用join（），则线程转为阻塞状态，eg：A线程中插入了B.join()，则B先执行，执行完，A线程继续执行；常见的是主线程生成并启动了子线程，需要用到子线程返回结果的场景；</div>\n<div>6、线程唤醒（notify）</div>\n<div>&nbsp; &nbsp; Object类中的notify唤醒在此对象监视器上等待的单个线程；</div>\n<div>&nbsp; &nbsp; notifyAll唤醒在此对象监视器上等待的所有线程；</div>\n<div>7、其他常用方法</div>\n</div>\n<table><colgroup><col /><col /></colgroup>\n<tbody>\n<tr>\n<td>\n<div>方法功能</div>\n</td>\n<td>\n<div>方法名</div>\n</td>\n</tr>\n<tr>\n<td>\n<div>&nbsp;判断一个线程是否存活；</div>\n</td>\n<td>\n<div>isAlive()&nbsp;&nbsp;</div>\n</td>\n</tr>\n<tr>\n<td>\n<div>程序中活跃的线程数；</div>\n</td>\n<td>\n<div>activeCount()&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;</div>\n</td>\n</tr>\n<tr>\n<td>\n<div>得到当前线程；</div>\n</td>\n<td>\n<div>currentThread()&nbsp;&nbsp; &nbsp;</div>\n</td>\n</tr>\n<tr>\n<td>\n<div>设置一个线程的优先级；</div>\n</td>\n<td>\n<div>setPriority()&nbsp; &nbsp;</div>\n</td>\n</tr>\n<tr>\n<td>\n<div>获取一个线程的优先级；</div>\n</td>\n<td>\n<div>getPriority()&nbsp;&nbsp; &nbsp;&nbsp;</div>\n</td>\n</tr>\n<tr>\n<td>\n<div>线程是否为守护线程；</div>\n</td>\n<td>\n<div>isDaemon()&nbsp;&nbsp; &nbsp;&nbsp;</div>\n</td>\n</tr>\n</tbody>\n</table>\n<div>&nbsp;</div>\n</div>\n</div>\n<div>&nbsp;</div>\n<div>&nbsp;</div>\n<div><strong><span style=\"font-size: 18px;\">线程池</span></strong></div>\n<div>线程池的基本概念是，在应用程序启动时创建一定数量的线程，并将它们保存在线程池中。当需要执行任务时，从线程池中获取一个空闲的线程，将任务分配给该线程执行。当任务执行完毕后，线程将返回到线程池，可以被其他任务复用。</div>\n<div>线程池创建有两种方式，一种是Executors使用默认方法创建，另一种是通过ThreadPoolExecutor自定义，不推荐前者是因为前者的配置很多都是取得integer得最大值，很容易造成OOM。</div>\n<div>工作中就是需要以new ThreadPoolExecutor的方式创建线程池的，其余的不安全。&nbsp; &nbsp;&nbsp;</div>\n<div>\n<div><img class=\"lazyload\" width=\"692\" /></div>\n</div>\n<div>使用线程池的一般步骤如下：&nbsp;</div>\n<div>\n<div>1、创建线程池：使用ThreadPoolExecutor类来创建线程池。</div>\n<div>&nbsp;&nbsp; &nbsp;ExecutorService executor = Executors.newFixedThreadPool(5); // 创建固定大小的线程池&nbsp;</div>\n</div>\n<div>\n<div>2、提交任务：将任务提交给线程池。</div>\n<div>&nbsp;&nbsp; &nbsp;executor.execute(new MyRunnable()); // 提交Runnable任务</div>\n<div>&nbsp;&nbsp; &nbsp;Future&lt;String&gt; future = executor.submit(new MyCallable()); // 提交Callable任务，并返回Future对象</div>\n</div>\n<div>\n<div>3、关闭线程池：在不再需要线程池时，需要调用shutdown()方法来关闭线程池。这将停止接受新任务，并逐渐关闭线程池中的线程。</div>\n<div>&nbsp;&nbsp; &nbsp;executor.shutdown();</div>\n</div>\n<div>\n<div>&nbsp;&nbsp; &nbsp;<strong><span style=\"font-size: 16px;\">线程池核心概念：</span></strong></div>\n</div>\n<div>　&nbsp;&nbsp;int &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;corePoolSize　　　&nbsp;&nbsp; 核心线程数</div>\n<div>　　int &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;maximumPoolSize　最大线程数</div>\n<div>　　long&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;keepAliveTime　　&nbsp; &nbsp;空闲线程最大存活时间</div>\n<div>　　TimeUnit &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; unit　　　　　　&nbsp; &nbsp; &nbsp; &nbsp;时间单位，m，h，d</div>\n<div>　　BlockingQueue&lt;Runnable&gt; workQueue　　&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;阻塞任务队列</div>\n<div>　　ThreadFactory &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; threadFactory　　&nbsp; &nbsp; 创建线程工厂</div>\n<div>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; RejectedExecutionHandler &nbsp;&nbsp; handler　　&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;拒绝策略</div>\n<h3>ThreadPoolExecutor参数详解</h3>\n<div>我们可以通过下面的场景理解ThreadPoolExecutor中的各个参数;</div>\n<div>a客户(任务)去银行(线程池)办理业务,但银行刚开始营业,窗口服务员还未就位(相当于线程池中初始线程数量为0),</div>\n<div>于是经理(线程池管理者)就安排1号工作人员(创建1号线程执行任务)接待a客户(创建线程);</div>\n<div>在a客户业务还没办完时,b客户(任务)又来了,于是经理(线程池管理者)就安排2号工作人员(创建2号线程执行任务)接待b客户(又创建了一个新的线程);假设该银行总共就2个窗口(核心线程数量是2);</div>\n<div>紧接着在a,b客户都没有结束的情况下c客户来了,于是经理(线程池管理者)就安排c客户先坐到银行大厅的座位上(空位相当于是任务队列)等候,</div>\n<div>并告知他: 如果1、2号工作人员空出,c就可以前去办理业务;</div>\n<div>此时d客户又到了银行,(工作人员都在忙,大厅座位也满了)于是经理赶紧安排临时工(新创建的线程)在大堂站着,手持pad设备给d客户办理业务;</div>\n<div>假如前面的业务都没有结束的时候e客户又来了,此时正式工作人员都上了,临时工也上了,座位也满了(临时工加正式员工的总数量就是最大线程数),于是经理只能按《超出银行最大接待能力处理办法》(饱和处理机制)拒接接待e客户;</div>\n<div>最后,进来办业务的人少了,大厅的临时工空闲时间也超过了1个小时(最大空闲时间),经理就会让这部分空闲的员工人下班.(销毁线程)</div>\n<div>但是为了保证银行银行正常工作(有一个allowCoreThreadTimeout变量控制是否允许销毁核心线程,默认false),即使正式工闲着,也不得提前下班,所以1、2号工作人员继续待着(池内保持核心线程数量);</div>\n<div>2、详细解释</div>\n<div>　　1)、&nbsp;核心线程数</div>\n<div>　　　　当线程是IO密集型时，主要消耗磁盘的读写性能，可以设置为2*n，n为当前服务器核数（比如8核16G的服务器设置为16，Runtime.getRuntime().availableProcessors()获取）</div>\n<div>　　　　当线程是CPU密集型时，主要消耗cpu性能，设置为n+1</div>\n<div>　　2)、最大线程数</div>\n<div>　　　　当核心线程核消息队列都满了之后才会去创建最大线程，直到达到最大线程数，之后的线程就会执行拒绝策略</div>\n<div>　　3)、&nbsp;阻塞消息队列</div>\n<div>　　　　ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小，读写用一把锁，性能较差；</div>\n<div>　　　　LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；一般是用这个，指定了大小则限制具体大小，写核读分两把锁进行操作，所以性能较好</div>\n<div>　　　　synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。</div>\n<div>　　　　注意：当核心线程数满了之后，新线程会先存储在消息队列中，当消息队列也满了之后才会去创建最大线程，直到达到最大线程数，之后的线程就会执行拒绝策略</div>\n<div>　　4)、&nbsp;线程工厂</div>\n<div>　　　　创建线程的类，可以用默认工厂，也可以自定义线程工厂实现&nbsp;implements ThreadFactory类，实现newThread方法，自定义工厂的话可以设置线程名或者定义辅助线程</div>\n<div>　　5)、拒绝策略</div>\n<div>　　　　ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。</div>\n<div>　　　　ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。</div>\n<div>　　　　ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务</div>\n<div>　　　　ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）处理该任务</div>\n<div>&nbsp;</div>\n<div><strong>线程池的主要优点包括：</strong></div>\n<div>1、重用线程：线程池会在内部维护一组可重用的线程，避免了频繁地创建和销毁线程的开销，提高了线程的利用率。</div>\n<div>2、控制并发度：线程池可以限制并发执行的线程数量，防止系统过载。通过调整线程池的大小，可以控制并发度，避免资源消耗过大。</div>\n<div>3、提供线程管理和监控：线程池提供了一些管理和监控机制，例如线程池的创建、销毁、线程状态的监控等，方便开发人员进行线程的管理和调试。</div>\n<div>4、提供任务队列：线程池通常会使用任务队列来存储待执行的任务，这样可以实现任务的缓冲和调度。</div>\n<div>&nbsp;</div>\n<div><strong>线程池的一些缺点包括：</strong></div>\n<div>1、需要合理配置：线程池的性能和效果受到配置参数的影响，需要根据具体的应用场景和硬件环境来合理配置线程池的大小、任务队列的大小等参数。</div>\n<div>2、可能引发资源泄露：如果线程池中的线程长时间闲置而不被使用，可能会导致资源的浪费和泄露。</div>\n<div>3、可能引发死锁：在使用线程池时，如果任务之间存在依赖关系，可能会引发死锁问题，需要额外的注意和处理。</div>\n<div>&nbsp;</div>\n<div>\n<div>\n<div>\n<div><strong><span style=\"font-size: 16px;\">重点面试问题</span></strong></div>\n<div>1、sleep和wait的区别：</div>\n<div>&nbsp; &nbsp; 1)、sleep属于Thread类，让出cpu，但是监控状态依然保持者，指定时间到了，就会恢复运行；</div>\n<div>&nbsp; &nbsp; 2)、wait属于Object类方法，释放对象锁，进入等待锁定池，需要notify()才能重新进入运行状态；</div>\n<div>2、wait()、notify() 释放锁问题：</div>\n<div>&nbsp; &nbsp; 1)、wait()会立刻释放synchronized(obj)中的obj锁,以便其他线程可以执行obj.notify()</div>\n<div>&nbsp; &nbsp; <span>2)、</span>但是notify()不会立刻立刻释放sycronized(obj)中的obj锁,必须要等notify()所在线程执行完synchronized(obj)块中的所有代码才会释放这把锁.yield(),sleep()不会释放锁。</div>\n<div>&nbsp;</div>\n<div><span style=\"font-size: 15px;\"><strong>异步线程间数据同步传递的四种方式</strong></span></div>\n<div>手动设置、线程池设置TaskDecorator、使用InheritableThreadLocal、使用TransmittableThreadLocal</div>\n<div>主线程</div>\n</div>\n</div>\n<div>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> @description 用户上下文信息</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> OauthContext {\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">private</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span>  <span style=\"color: rgba(0, 0, 255, 1);\">final</span>  ThreadLocal&lt;LoginVal&gt; loginValThreadLocal=<span style=\"color: rgba(0, 0, 255, 1);\">new</span> ThreadLocal&lt;&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span><span style=\"color: rgba(0, 0, 0, 1);\">  LoginVal get(){\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> loginValThreadLocal.get();\n    }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> set(LoginVal loginVal){\n        loginValThreadLocal.set(loginVal);\n    }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> clear(){\n        loginValThreadLocal.remove();\n    }\n}</span></pre>\n</div>\n<p>&nbsp;</p>\n</div>\n<div>1、手动设置</div>\n<div>每执行一次异步线程都要分为两步：</div>\n<div>&nbsp; &nbsp; 1)、获取父线程的值</div>\n<div>&nbsp; &nbsp; 2)、将值设置到子线程，达到复用， 代码如下：</div>\n<div>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> handlerAsync() {\n        LoginVal loginVal </span>= OauthContext.get();  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">1. 获取父线程的loginVal</span>\n        log.info(\"父线程的值：{}\"<span style=\"color: rgba(0, 0, 0, 1);\">,OauthContext.get());\n        CompletableFuture.runAsync(()</span>-&gt;<span style=\"color: rgba(0, 0, 0, 1);\">{\n           OauthContext.set(loginVal);   </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">2. 设置子线程的值，复用</span>\n           log.info(\"子线程的值：{}\"<span style=\"color: rgba(0, 0, 0, 1);\">,OauthContext.get());\n        });\n    }</span></pre>\n</div>\n<p>&nbsp;</p>\n</div>\n<div><strong>2、线程池设置TaskDecorator</strong></div>\n<div>TaskDecorator是一个执行回调方法的接口，主要应用于传递上下文，或者提供任务的监控/统计信息。</div>\n<div>首先需要去实现它，代码如下：</div>\n</div>\n<div>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> @description 上下文装饰器</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span> ContextTaskDecorator <span style=\"color: rgba(0, 0, 255, 1);\">implements</span><span style=\"color: rgba(0, 0, 0, 1);\"> TaskDecorator {\n    @Override\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span><span style=\"color: rgba(0, 0, 0, 1);\"> Runnable decorate(Runnable runnable) {\n        LoginVal loginVal </span>= OauthContext.get();  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">获取父线程的loginVal</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">return</span> () -&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> {\n            </span><span style=\"color: rgba(0, 0, 255, 1);\">try</span><span style=\"color: rgba(0, 0, 0, 1);\"> {\n                OauthContext.set(loginVal);  </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 将主线程的请求信息，设置到子线程中</span>\n                runnable.run();  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 执行子线程</span>\n            } <span style=\"color: rgba(0, 0, 255, 1);\">finally</span><span style=\"color: rgba(0, 0, 0, 1);\"> {\n                OauthContext.clear();  </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 线程结束，清空这些信息，否则可能造成内存泄漏</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">            }\n        };\n    }\n}</span></pre>\n</div>\n<p>这里我只是设置了LoginVal，实际开发中其他的共享数据，比如SecurityContext，RequestAttributes....</p>\n</div>\n<div>\n<div>TaskDecorator需要结合线程池使用，实际开发中异步线程建议使用线程池，只需要在对应的线程池配置一下，代码如下：</div>\n</div>\n<div>\n<div class=\"cnblogs_code\">\n<pre>@Bean(\"taskExecutor\"<span style=\"color: rgba(0, 0, 0, 1);\">)\n</span><span style=\"color: rgba(0, 0, 255, 1);\">public</span><span style=\"color: rgba(0, 0, 0, 1);\"> ThreadPoolTaskExecutor taskExecutor() {\n        ThreadPoolTaskExecutor poolTaskExecutor </span>= <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> ThreadPoolTaskExecutor();\n        poolTaskExecutor.setCorePoolSize(xx);\n        poolTaskExecutor.setMaxPoolSize(xx);\n        poolTaskExecutor.setKeepAliveSeconds(xx);   </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 设置线程活跃时间（秒）</span>\n        poolTaskExecutor.setQueueCapacity(xx);  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 设置队列容量</span>\n        poolTaskExecutor.setTaskDecorator(<span style=\"color: rgba(0, 0, 255, 1);\">new</span> ContextTaskDecorator()); <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">设置TaskDecorator，用于解决父子线程间的数据复用</span>\n        poolTaskExecutor.setRejectedExecutionHandler(<span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> ThreadPoolExecutor.CallerRunsPolicy());\n        poolTaskExecutor.setWaitForTasksToCompleteOnShutdown(</span><span style=\"color: rgba(0, 0, 255, 1);\">true</span>);  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 等待所有任务结束后再关闭线程池</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> poolTaskExecutor;\n    }</span></pre>\n</div>\n<p>此时业务代码就不需要去设置子线程的值，直接使用即可，代码如下：</p>\n</div>\n<div>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> handlerAsync() {\n        log.info(</span>\"父线程的用户信息：{}\"<span style=\"color: rgba(0, 0, 0, 1);\">, OauthContext.get());\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">执行异步任务，需要指定的线程池</span>\n        CompletableFuture.runAsync(()-&amp;gt; log.info(\"子线程的用户信息：{}\"<span style=\"color: rgba(0, 0, 0, 1);\">, OauthContext.get()),taskExecutor);\n    }</span></pre>\n</div>\n<p>这里使用的是CompletableFuture执行异步任务，使用@Async这个注解同样是可行的。</p>\n</div>\n<div>\n<div>注意：无论使用何种方式，都需要指定线程池</div>\n<div>&nbsp;</div>\n</div>\n<div><strong><span style=\"font-size: 14px;\">3、使用InheritableThreadLocal</span></strong></div>\n<div>这种方案不建议使用，InheritableThreadLocal虽然能够实现父子线程间的复用，但是在线程池中使用会存在复用的问题，这种方案使用也是非常简单，直接用InheritableThreadLocal替换ThreadLocal即可，代码如下：</div>\n<div>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> @description 用户上下文信息</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> OauthContext {\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">private</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span>  <span style=\"color: rgba(0, 0, 255, 1);\">final</span>  InheritableThreadLocal&lt;LoginVal&gt; loginValThreadLocal=<span style=\"color: rgba(0, 0, 255, 1);\">new</span> InheritableThreadLocal&lt;&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span><span style=\"color: rgba(0, 0, 0, 1);\">  LoginVal get(){\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> loginValThreadLocal.get();\n    }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> set(LoginVal loginVal){\n        loginValThreadLocal.set(loginVal);\n    }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> clear(){\n        loginValThreadLocal.remove();\n    }\n}</span></pre>\n</div>\n<p>&nbsp;</p>\n</div>\n<div><strong><span style=\"font-size: 15px;\">4、使用TransmittableThreadLocal</span></strong></div>\n<div><span>TransmittableThreadLocal是阿里开源的工具，弥补了InheritableThreadLocal的缺陷，在使用线程池等会池化复用线程的执行组件情况下，提供ThreadLocal值的传递功能，解决异步执行时上下文传递的问题。</span></div>\n<div>&nbsp;</div>\n<div><strong>TransmittableThreadLocal原理</strong></div>\n<div><span>TransimittableThreadLocal继承于InheritableThreadLocal，并实现TtlCopier接口，它里面只有一个copy方法。所以主要是对InheritableThreadLocal的扩展。</span></div>\n<div>\n<div><span>在TransimittableThreadLocal中添加holder属性。这个属性的作用就是被标记为具备线程传递资格的对象都会被添加到这个对象中。</span></div>\n<div>要标记一个类，可以给这个类新增一个Type字段，还有一个方法就是将具备这种类型的的对象都添加到一个静态全局集合中，之后使用时，这个集合里的所有值都具备这个标记。</div>\n<div>应用代码是通过TtlExecutors工具类对线程池对象进行包装。工具类只是简单的判断，输入的线程池是否已经被包装过、非空校验等，然后返回包装类ExecutorServiceTtlWrapper。根据不同的线程池类型，有不同和的包装类。</div>\n<div>进入包装类ExecutorServiceTtlWrapper。可以注意到不论是通过ExecutorServiceTtlWrapper#submit方法或者是ExecutorTtlWrapper#execute方法，都会将线程对象包装成TtlCallable或者TtlRunnable，用于在真正执行run方法前做一些业务逻辑。</div>\n</div>\n<div><span>所以，重点的核心逻辑应该是在TtlCallable#call()或者TtlRunnable#run()中。以下以TtlCallable为例，TtlRunnable同理类似。</span></div>\n<div><span>总的来说在创建TtlCallable对象是，调用capture()方法捕获调用方的本地线程变量，在call()执行时，将捕获到的线程变量，替换到线程池所对应获取到的线程的本地变量中，并且在执行完成之后，将其本地变量恢复到调用之前。</span></div>\n<div><span>&nbsp;</span></div>\n<div>&nbsp;</div>\n<div><strong><span style=\"font-size: 18px;\">高并发</span></strong></div>\n<div><img class=\"lazyload\" width=\"361\" /></div>\n<div><strong><span style=\"font-size: 16px;\">高并发系统系统指标</span></strong></div>\n<div><span>1、QPS（Queries Per Second</span>）</div>\n<div>QPS 是每秒请求数，是衡量信息系统在一秒钟内接收到的搜索流量的一种常见度量指标，被广泛应用在任何请求-响应的系统中。对于高并发的系统，必须要关注 QPS，这样你才能指导你的系统何时需要进行扩容。</div>\n<div>2、TPS（Transactions Per Second）</div>\n<div>TPS 是每秒的事务数量，是软件测试结果的测量单位，一个事务是指一个客户端向服务器发送请求然后服务器做出响应的过程。客户端在发送请求时开始计时，收到服务器响应后结束计时，用来计算使用的时间和完成的事务个数。</div>\n<div>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;QPS VS TPS</div>\n<div>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;QPS 基本可以理解为类似于 TPS，但不同的是，对于一个页面的一次访问，形成一个 TPS，但一次页面请求，可能会产生多次对服务器的请求，就是说会有多个 QPS。</div>\n<div>3、RT（Response-time）</div>\n<div>RT 即响应时间，是指一个请求从开始到最后收到响应数据结果所花费的总时间，它的数值大小直接反应了系统的快慢。</div>\n<div>4、并发数</div>\n<div><span>并发数是指系统同时能处理的请求数量，这个指标反应了系统的负载能力。并发意味着可以同时进行多个处理，并发在现代编程中无处不在。</span></div>\n<div>5、吞吐量</div>\n<div>系统的吞吐量和处理对 CPU 的消耗、外部接口、IO 等多个因素紧密相关，单个处理请求对 CPU 消耗越高，外部系统接口、IO 速度越慢，系统的吞吐能力越低，反之越高。系统吞吐量有几个重要指标参数：QPS/TPS、并发数、响应时间。</div>\n<div><span style=\"font-family: Arial;\">&nbsp;</span></div>\n<div>\n<div>&nbsp;&nbsp; &nbsp;QPS/TPS：每秒请求/事务数量。</div>\n<div>&nbsp;&nbsp; &nbsp;并发数： 系统同时处理的请求/事务数。</div>\n<div>&nbsp;&nbsp; &nbsp;响应时间： 一般取请求平均响应时间。</div>\n<div>理解了上面三个指标的意义之后，就能推算出它们之间的关系：</div>\n<div>QPS(TPS) = 并发数/平均响应时间</div>\n<div>并发数 = QPS*平均响应时间</div>\n<div>&nbsp;</div>\n<div><strong><span style=\"font-size: 18px;\">实际举例</span></strong></div>\n<div>某宝直播业务要求预估计算对应的各个指标。正常在进行流量估算的时候，会采用二八定律，如果每天 80% 的访问集中在 20% 的时间段里，那这个 20% 的时间就被称为峰值时间。</div>\n<div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<span>峰值时间的 QPS = （总 PV 数 * 80%）/（每天秒数 * 20%）</span></div>\n<div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<span>需要的机器数量 = 峰值时间的 QPS / 单台机器的 QPS</span></div>\n<div>每天300w PV 的在单台机器上，这台机器需要多少QPS？</div>\n<div>&nbsp; &nbsp;&nbsp;( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)</div>\n<div>如果一台机器的QPS是58，需要几台机器来支持？</div>\n<div>&nbsp; &nbsp;&nbsp;139 / 58 = 3</div>\n<div>高并发系统的目标从系统层面看，有高性能、高可用和高扩展三个目标</div>\n</div>\n<div>&nbsp;</div>\n<div><strong><span style=\"font-size: 18px;\">高并发解决方案</span></strong></div>\n<div><span>使用分布式微服务架构模式、集群部署与负载均衡、用分布式缓存、使用消息队列、分库分表、读写分离、限流和熔断、动静分离、使用分布式数据库、数据库优化。</span></div>\n<div><strong>1、使用分布式微服务架构模式</strong></div>\n<div>将一个系统拆分为多个子系统。&nbsp;微服务架构拆分，最常见的就是Spring Cloud 和Spring Cloud Alibaba。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，这样就可以抗高并发。</div>\n<div><strong>2、集群部署与负载均衡</strong></div>\n<div>将系统部署在多台服务器上，通用负载均衡将用户请求均匀地分发到各个服务器进行处理， 分担单台服务器的压力，这种方式可以通过添加新的服务器或者服务节点来提高系统的整体处理能力， 提高系统的并发处理能力和整体性能。</div>\n<div>负载均衡（Load Balancing）是一种分布式系统架构中的技术，用于将网络请求或任务分散到多个服务器或资源上。</div>\n<div>比如：当系统面临大量用户访问，负载过高的时候，通常会使用增加服务器数量来进行横向扩展来提高整个系统的处理能力。</div>\n<div>负载均衡可以在不同的层次上实现，包括：</div>\n<div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;硬件负载均衡器：&nbsp;使用专门的硬件设备来实现负载均衡，如硬件负载均衡器。</div>\n<div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;软件负载均衡器：&nbsp;在应用层或网络层使用软件来实现负载均衡，如反向代理服务器、负载均衡算法。</div>\n<div>在负载均衡的设计中，有几种常见的负载均衡策略：</div>\n<div>&nbsp; &nbsp;&nbsp;1、轮询（Round Robin）：&nbsp;将请求依次分配给服务器列表中的每个服务器，每次请求后移动到下一个服务器。适用于服务器性能相近的情况。</div>\n<div>&nbsp; &nbsp; &nbsp; 2、加权轮询（Weighted Round Robin）：&nbsp;类似于轮询，但每个服务器有不同的权重，可以根据服务器性能调整权重。</div>\n<div>&nbsp; &nbsp; &nbsp; 3、最少连接（Least Connections）：&nbsp;将请求分配给当前连接数最少的服务器，以确保负载均衡。适用于长连接的情况。</div>\n<div>&nbsp; &nbsp; &nbsp; 4、加权最少连接（Weighted Least Connections）：&nbsp;类似于最少连接，但每个服务器有不同的权重，可以根据服务器性能调整权重。</div>\n<div>&nbsp; &nbsp; &nbsp; 5、随机（Random）：&nbsp;随机选择一个服务器来处理请求，适用于简单的负载均衡需求。</div>\n<div>&nbsp; &nbsp; &nbsp; 6、IP 哈希（IP Hash）：&nbsp;根据客户端 IP 地址的哈希值来选择服务器，可以确保同一客户端的请求始终发送到同一服务器。</div>\n<div><strong>3、分布式缓存</strong></div>\n<div>大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家redis轻轻松松单机几万的并发啊。没问题的。所以你可以考的虑考虑你的项目里，那些承载主要请求读场景，怎么用缓存来抗高并发。（缓存你也可以考虑集群，不过前提就是你的服务器得支持怎么多高负荷的中间件。俗话说没有任何事物加一层解决不了的，如果一层不行，就在加一层解决）</div>\n<div>\n<div>一些常见的分布式缓存系统包括：；</div>\n<div>&nbsp;&nbsp; &nbsp;1)、Redis：&nbsp;Redis 是一种基于内存的键值存储系统，支持多种数据结构，如字符串、哈希、列表等，适用于快速读取和写入场景。&nbsp;&nbsp;</div>\n<div>&nbsp;&nbsp; &nbsp;2)、Memcached：&nbsp;Memcached 也是一种基于内存的键值存储系统，适用于分布式缓存和缓存共享。</div>\n<div>&nbsp; &nbsp; 3)、Hazelcast：&nbsp;Hazelcast 是一个开源的分布式数据存储和计算平台，支持分布式缓存、分布式计算等。</div>\n<div>&nbsp; &nbsp; 4)、Couchbase：&nbsp;Couchbase 是一个分布式缓存和数据库系统，结合了缓存和文档存储的功能。</div>\n<div>&nbsp; &nbsp; 5)、Ehcache：&nbsp;Ehcache 是一个 Java 缓存库，可以作为本地缓存或分布式缓存使用。</div>\n<div>当然，这里使用最多的还是Redis。</div>\n</div>\n<div><strong>4、MQ(消息队列)</strong></div>\n<div>可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，人家是缓存你要是用redis来承载写那肯定不行，数据随时就被LRU(淘汰掉最不经常使用的)了，数据格式还无比简单，没有事务支持。所以该用mysql还得用mysql啊。那你咋办？用MQ吧，大量的写请求灌入MQ里，排队慢慢玩儿，后边系统消费后慢慢写，控制在mysql承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用MQ来异步写，提升并发性。MQ单机抗几万并发也是ok的。（这个是根据自己的业务来用的，一般中小型项目用rabbitmq就够了，建议日志用kafka，这样日志的数量多就可以很好的解决）</div>\n<div>&nbsp;</div>\n<div><strong>5、分库分表</strong></div>\n<div>可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来抗更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高sql跑的性能。（这个前提你的服务器得支持，不然弄得华丽花哨）</div>\n<div>1.什么是分库分表？</div>\n<div>1.1 分库</div>\n<div>\n<div>分库是指在表数量不变的情况下对库进行切分。</div>\n<div>举例：如下图，数据库A 中存放了 user 和 order 两张表，将两张表切分到两个数据库中，user表放到 database A，order表放到 database B</div>\n<div>1.2 分表</div>\n<div>分表是指在库数量不变的情况下对表进行切分。</div>\n<div>举例：如下图，数据库 A 中存放了 user表，将 user表切分成 user1 和 user2 两张表并放到 database A中。</div>\n<div>1.3 分库分表</div>\n<div>分库分表是指库和表都切分，数量都发生变化。</div>\n<div>举例：如下图，数据库 A 中存放了 user表，将 user表切分成 user1、user2、user3、user4 四张表，user1 和 user2 放到 database A中，user3 和 user4 放到 database B 中。</div>\n<div>2. 如何切分库和表？</div>\n<div><span>主流的切分方式有 3种：水平切分、垂直切分和混合切分。</span></div>\n<div>2.1 水平切分</div>\n<div>水平切分包含水平分库和水平分表。</div>\n<div>2.1.1 水平分表</div>\n<div><span>水平分表指的表结构不变，将单表数据切分成多表。切分后的结果：每个表的结构一样，数据不一样，所有表的数据并集为全量数据。</span></div>\n<div>举例：如下图，order表，按照 oder_id 的数据范围水平切分后变成了 order1 和 order2 表，两个表的结构一样，数据不同。</div>\n<div>2.1.2 水平分库</div>\n<div><span>水平分库是指，将表水平切分后分到不同的数据库，使得每个库具有相同的表，表中的数据不相同，水平分库一般是伴随水平分表。</span></div>\n<div>举例：如下图，order 表，水平切分后，分到 database A 和 database B 中，这样原来一个库就被拆分成 2个库。</div>\n<div>2.2 垂直切分</div>\n<div>垂直切分包含垂直分库和垂直分表。</div>\n<div>2.2.1 垂直分表</div>\n<div><span>垂直分表指将存在一张表中的字段切分到多张表。切分后的结果：每个表的结构不一样，数据也不一样，所有表的字段并集是原表的字段。</span></div>\n<div>举例：如下图，order 表，根据字段垂直切分，切分后 order_base表包含一部分字段的数据 和 order_info表包含另一部分字段的数据。</div>\n<div>2.2.2 垂直分库</div>\n<div>垂直分库指的是，将单个库中的表分到多个库，每个库包含的表不一样。</div>\n<div>举例：如下图，database A 中的 order 表 和 user表，垂直分库为 database A 包含 order表，database B 包含 user 表。</div>\n<div>2.3 混合切分</div>\n<div>混合切分其实就是水平切分和垂直切分的组合</div>\n</div>\n<div><strong>6、读写分离</strong></div>\n<div>这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。</div>\n<div><strong>&nbsp;</strong></div>\n<div><strong>7、限流和熔断</strong></div>\n<div>限流（Rate Limiting）和熔断（Circuit Breaking）是分布式系统中常用的两种流量控制和容错机制。</div>\n<div>并发量高的情况下，利用SpringCloud的Hystrix组件(监控和熔断器)进行限流熔断处理， 首先保护核心系统的安全性，</div>\n<div><img class=\"lazyload\" width=\"382\" /></div>\n<div>&nbsp;</div>\n<div><strong>8、动静分离</strong></div>\n<div>将css、html、jpg、&nbsp;js&nbsp;等&nbsp;静态文件和动态页面区分开</div>\n<div>&nbsp;</div>\n<div><strong>9、使用分布式数据库</strong></div>\n<div>分布式数据库是一种数据库系统，将数据分散存储在多个物理节点或服务器上，以提高系统的性能、可扩展性和可用性。</div>\n<div>\n<div>分布式数据库分类：</div>\n<div>1.分布式关系型数据库</div>\n<div>这类数据库将关系型数据库的特性与分布式系统的优势相结合，提供了支持SQL查询和事务的能力。</div>\n<div>一些例子包括：Google Cloud Spanner、TiDB一种全球分布式的关系型数据库，提供了强一致性和水平扩展能力。</div>\n<div>2.分布式列式数据库</div>\n<div>这类数据库以列式存储方式存储数据，适用于大规模分析和查询需求。</div>\n<div>Apache Cassandra：一个分布式的NoSQL数据库，适用于高可用性和可扩展性的场景。</div>\n<div>HBase：一个基于Hadoop的分布式列式数据库，适用于大数据存储和实时查询。</div>\n<div><span>3.</span>分布式文档数据库</div>\n<div>这类数据库以文档为单位存储数据，适用于半结构化数据。</div>\n<div>MongoDB：一个面向文档的NoSQL数据库，支持分布式部署和水平扩展。</div>\n<div>Couchbase：一个分布式NoSQL数据库，支持文档和键值数据模型。</div>\n<div>使用分布式数据库系统，如分布式 NoSQL 数据库，来提高数据存储和查询的并发处理能力。</div>\n<div><strong>10、数据库优化</strong></div>\n<div>优化数据库的设计、索引、查询语句等，提高数据库的读写性能。</div>\n<div>综合运用上述高并发架构解决方案，都可以构建出具有高性能、高可用和可扩展性的系统，满足大量并发请求的需求。</div>\n</div>\n</div>\n<div>&nbsp;</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-09 09:14</span>&nbsp;\n<a href=\"https://www.cnblogs.com/philry\">大芒果2点0</a>&nbsp;\n阅读(<span id=\"post_view_count\">139</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "GIS中的“高度”到底指什么？一文厘清正高、正常高与大地高的区别",
      "link": "https://www.cnblogs.com/charlee44/p/19458808",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/charlee44/p/19458808\" id=\"cb_post_title_url\" title=\"发布于 2026-01-08 21:56\">\n    <span>GIS中的“高度”到底指什么？一文厘清正高、正常高与大地高的区别</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        深入解析 GIS 中高程参考系统的核心概念——大地水准面、似大地水准面与参考椭球面的关系，厘清正高、正常高与大地高的区别及转换方法，并介绍我国高程基准与全球重力模型。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>节选自《GIS基础原理与技术实践》第2章 地理空间参考系统</strong><br />\n作者原创内容，转载请注明出处。</p>\n</blockquote>\n<p><img alt=\"GIS基础原理与技术实践\" class=\"lazyload\" /></p>\n<h2 id=\"23-高程参考系统\">2.3 高程参考系统</h2>\n<p>使用经度和纬度表示的地理坐标系是一种水平坐标系统（这里的水平坐标系统并不表示其就是平面坐标系的意思，更准确的含义是其表达了三维空间坐标系的两个维度），缺少对于第三维度也就是高程的参考，也就是本节我们要介绍的：高程参考系统。高程参考系统是一种垂直坐标系。</p>\n<h3 id=\"231-大地水准面\">2.3.1 大地水准面</h3>\n<p>我们知道，参考椭球体是对地球表面的一种逼近。那么问题来了，参考椭球体是用喜马拉雅山所在的高度进行逼近，还是以马里亚纳海沟的高度进行逼近？答案肯定都不是。其实，这其中还隐藏了另一个逼地球自然表面的参考面，那就是本节我们要讲的——大地水准面（Geoid）。</p>\n<p>地理坐标系的第三维度通常使用海拔高度（Elevation），而不是到球心的距离。然而问题在于，高度的值是一个相对量，需要一个起算点。并且，这个高度必须沿着重力方向（铅锤方向）才有物理意义（想一想为什么建筑物总是要修的与地面垂直）。我们说到“海拔”这个名词，就会联想到高度的值应该是一个目标地物距离海平面的高差。事实也确实如此，我们可以定一个平均海平面作为高程的起算点，并且假设这个海平面完全静止，并且延伸到所有大陆下部，生成了一个密闭的曲面——这个曲面就是大地水准面。</p>\n<p>与参考椭球面不同的是，参考椭球面是数学模型得到的，处处平滑且平整；而大地水准面虽然平滑但不平整，是一个不规则但连续的闭合曲面。这其中的原因在于，地球质量分布不均匀，造成地球的引力场也是分布不均的。假设地球球体完全被水覆盖，水的高度也不会是完全一样：在地球局部密度更大的地方，地球施加的引力就会越大，造成水位越高。换句话说，大地水准面是一个重力等势面，重力方向（铅垂方向）在其任何地方都与其表面垂直；由于质量（引力）不均，每个位置的铅垂方向不一样，结果就是大地水准面并不平整。如下图2.8所示。</p>\n<p><img alt=\"图2.8 大地水准面与旋转椭球体\" class=\"lazyload\" /></p>\n<h3 id=\"232-三级逼近\">2.3.2 三级逼近</h3>\n<p>现在我们已经有了大地水准面、参考椭球面和大地基准面。那么它们的关系是如何呢？简单来说，它们共同组成了对地球自然表面的三级逼近。</p>\n<ul>\n<li>大地水准面是对地球自然表面的第一级逼近。大地水准面通过重力等势，确定了一个高程起算面，它远比地球自然表面平整得多，但是不是完全平整。地球自然表面具有从珠穆朗玛峰（+8800米）到马里亚纳海沟（-11,000米）的高差，但大地水准面与参考椭球面的偏差范围不超过200m（从+85米的冰岛到-106米的印度南部）。</li>\n<li>参考椭球面是对地球自然表面的第二级逼近。地球自然表面和大地水准面都是不规则的曲面，无法通过数学模型对其进行表达，这也意味着难以对其进行测算和分析。通过将大地水准面拟合成一个旋转椭球体，使我们可以对地球自然表面进行空间几何计算。参考椭球面是测量计算的基准面。</li>\n<li>大地基准面是对地球自然表面的第三极逼近。参考椭球体是对地球球体的抽象，但大地基准面解决的是这个参考椭球体如何摆放的问题：大地基准面要么与地球自然表面的局部区域具有较好的重合度，以便解决局部区域精度的问题；要么让椭球体中心位于地球质心，以便具有全球范围可使用的便捷性。</li>\n</ul>\n<h3 id=\"233-高程系统\">2.3.3 高程系统</h3>\n<h4 id=\"1-似大地水准面\">1 似大地水准面</h4>\n<p>如前所述，大地水准面确定了高程的起算面。那么，地球表面上一点到大地水准面必然有一个高度，这个高度就是正高（Orthometric Height）。正高就是我们通常意义上所说的海拔或者海拔高度，也叫做高程（Elevation）。这个高程系统就是正高系统。</p>\n<p>然而，大地水准面的问题是其仅仅只是一个理想化的模型，是不能准确测量的。客观地说，大地水准面所假想的大陆下部的海平面无法被量测，没有现实意义。为了解决这个问题，就引入了一个数学辅助面：似大地水准面（Quasi-geoid）。似大地水准面采用平均正常重力值来拟合水准面曲线（大地某一点的重力值无法精确求取），导致两者在海洋上完全重合，在大陆上有2 ~ 4米的微小差异。如果不能理解不要紧，我们可以定性的理解：似大地水准面是对大地水准面的数学近似，似大地水准面可以精确求得，大地水准面不可以精确求得。</p>\n<p>同样的，地球表面上一点到似大地水准面也有一个高度，我们把这个高度叫做正常高（Normal height），其高程就是正常高系统。正因为似大地水准面是大地水准面得近似且可求取，所以一般使用正常高来替代正高，正常高系统结果也可以称为海拔高度。我国目前采用的法定高程系统就是正常高系统。</p>\n<p>正高和正常高，大地水准面和似大地水准面的示意图如下图2.9所示：</p>\n<p><img alt=\"图2.9 正高、正常高与大地高\" class=\"lazyload\" /></p>\n<h4 id=\"2-高程系统\">2 高程系统</h4>\n<p>如图2.9中所示，除了正高系统和正常高系统，还有一类常用的高程系统就是大地高系统。所谓大地高，指的是以参考椭球面为基准面的高程系统，其值是地面上一点沿该点的椭球面法线到参考椭球面的距离。大地高也称为椭球高。</p>\n<p>虽然我们一般采用的高程系统是正常高系统，但在实际的使用过程中，有的时候知道正常高需要计算大地高，有的时候又需要通过大地高来计算正常高。一个很典型的例子就是，GPS（Global Positioning System，全球定位系统）获取的高程一般是大地高，那么如何得到我们想要的正常高呢？</p>\n<p>如下表2.4所述，对于高程系统中变量，我们有如下定义：</p>\n\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">符号</th>\n<th style=\"text-align: center;\">名称</th>\n<th style=\"text-align: center;\">含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><span class=\"math inline\">\\(H_n\\)</span></td>\n<td style=\"text-align: center;\">正常高（Normal Height）</td>\n<td style=\"text-align: center;\">地面上一点沿重力方向到似大地水准面的距离</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><span class=\"math inline\">\\(H_o\\)</span></td>\n<td style=\"text-align: center;\">正高 （Orthometric Height）</td>\n<td style=\"text-align: center;\">地面上一点沿重力方向到大地水准面的距离</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><span class=\"math inline\">\\(H_g\\)</span></td>\n<td style=\"text-align: center;\">大地高（Geodetic Height）</td>\n<td style=\"text-align: center;\">地面上一点沿椭球面法线方向到参考椭球面的距离</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><span class=\"math inline\">\\(\\zeta\\)</span></td>\n<td style=\"text-align: center;\">高程异常（Height Anomaly）</td>\n<td style=\"text-align: center;\">似大地水准面到参考椭球面的距离</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><span class=\"math inline\">\\(N\\)</span></td>\n<td style=\"text-align: center;\">大地水准面差距（Geoid Undulation）</td>\n<td style=\"text-align: center;\">大地水准面到参考椭球面的距离</td>\n</tr>\n</tbody>\n</table>\n<p>将它们在示意图中标识，如下图2.10所示：<br />\n<img alt=\"图2.10 正高、正常高与大地高\" class=\"lazyload\" /></p>\n<p>根据图示很显然可以得到如下公式：</p>\n<p></p><div class=\"math display\">\\[H_g = H_n + \\zeta \\tag{2.6}\n\\]</div><p></p><p></p><div class=\"math display\">\\[H_g = H_o + N \\tag{2.7}\n\\]</div><p></p><p>回到之前提到的问题，GPS获取的高程为大地高<span class=\"math inline\">\\(H_g\\)</span>，那么再通过大地测量的方法，可以精确确定高程异常<span class=\"math inline\">\\(\\zeta\\)</span>，根据公式2.6，大地高减去高程异常就可以得到正常高<span class=\"math inline\">\\(H_n\\)</span>，正常高可以用来代替正高，正高即最常用的海拔高度。在实际的应用中，有时需要大地高，有时需要正常高，可根据上述公式灵活转换。</p>\n<h4 id=\"3-高程基准\">3 高程基准</h4>\n<p>如2.3.1节所述，大地水准面使用一个假想的平均海平面作为高程起点（基准），这个平均海面可以通过在各地的验潮站观测、计算、综合得到。我国根据实际的观测结果之上，建立多个高程基准面，其中最常用的两个国家高程基准是：</p>\n<ul>\n<li>1956黄海高程基准，水准原点高程72.289米。</li>\n<li>1985国家高程基准，水准原点高程72.260米。</li>\n</ul>\n<p>目前，1985国家高程基准已经全部替代1956黄海高程基准，之前所有使用1956黄海高程基准的高程结果都需要通过下式2.8进行转换：</p>\n<p></p><div class=\"math display\">\\[H_{85} = H_{56} - 0.029\n\\]</div><p></p><p>此外，国际上通用的还有美国国家地理空间情报局（National Geospatial-Intelligence Agency，NGA）发布的EGM（Earth Gravitational Models，地球重力模型）大地水准面。这个大地水准面模型是综合利用现有全球大量重力数据计算出来的，适用于全球范围。目前已经发布了EGM84、EGM96、EGM2008和EGM2020四个版本。</p>\n<hr />\n<p>本文节选自作者新书《GIS基础原理与技术实践》第2章。书中系统讲解 GIS 核心理论与多语言实战，适合开发者与高校师生。</p>\n<p>📚 <strong>配套资源开源</strong>：<a href=\"https://github.com/fafa1899/GISBasic\" rel=\"noopener nofollow\" target=\"_blank\">GitHub</a> | <a href=\"https://gitcode.com/charlee44/GISBasic\" rel=\"noopener nofollow\" target=\"_blank\">GitCode</a></p>\n<p>🛒 <strong>支持正版</strong>：<a href=\"https://item.jd.com/14603137.html\" rel=\"noopener nofollow\" target=\"_blank\">京东</a>｜<a href=\"https://product.dangdang.com/29988568.html\" rel=\"noopener nofollow\" target=\"_blank\">当当</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-08 21:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/charlee44\">charlee44</a>&nbsp;\n阅读(<span id=\"post_view_count\">34</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第一周：循环神经网络 （四）RNN 中的梯度现象",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19458774",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19458774\" id=\"cb_post_title_url\" title=\"发布于 2026-01-08 21:37\">\n    <span>吴恩达深度学习课程五：自然语言处理  第一周：循环神经网络 （四）RNN 中的梯度现象</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课的第一周内容，<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=158\" rel=\"noopener nofollow\" target=\"_blank\">1.8</a>的内容以及一些相关基础的补充。</p>\n<hr />\n<p>本周为第五课的第一周内容，与 CV 相对应的，这一课所有内容的中心只有一个：<strong>自然语言处理（Natural Language Processing，NLP）</strong>。<br />\n应用在深度学习里，它是专门用来进行<strong>文本与序列信息建模</strong>的模型和技术，本质上是在全连接网络与统计语言模型基础上的一次“结构化特化”，也是人工智能中<strong>最贴近人类思维表达方式</strong>的重要研究方向之一。<br />\n<strong>这一整节课同样涉及大量需要反复消化的内容，横跨机器学习、概率统计、线性代数以及语言学直觉。</strong><br />\n语言不像图像那样“直观可见”，更多是抽象符号与上下文关系的组合，因此<strong>理解门槛反而更高</strong>。<br />\n因此，我同样会尽量补足必要的背景知识，尽可能用比喻和实例降低理解难度。<br />\n本篇的内容关于<strong>RNN 中的梯度现象</strong>，是对 RNN 中存在的问题的阐述，也是对之后的门控机制的引入内容。</p>\n<h1 id=\"1-rnn-中的梯度现象\">1. RNN 中的梯度现象</h1>\n<p>在很久之前，我们就介绍过深度学习训练中的<a href=\"https://www.cnblogs.com/Goblinscholar/p/19190303\" target=\"_blank\">梯度现象</a>，这种情况主要出现在深层神经网络中，在反向传播中随着层层的梯度计算导致梯度过大或过小，从而出现梯度爆炸或者梯度消失，导致网络无法训练。<br />\n而在 RNN 中，即使是我们演示过的单层 RNN ，也可能产生梯度现象，而且这一问题会显得<strong>更加隐蔽，却也更加严重</strong>，其原因就在于 RNN 的<strong>时间反向传播</strong>特性。</p>\n<h2 id=\"11-rnn-的深度\">1.1 RNN 的深度</h2>\n<p>首先，我们知道：<strong>RNN 的“深度”并不体现在空间结构上，而是体现在时间维度上。</strong><br />\n因此，虽然我们画出来的 RNN 看起来只有一层，但在训练时，RNN 会在时间维度上被“展开”为一个<strong>共享参数的深层网络</strong>，就像这样：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260108213552905-491823195.png\" /></p>\n<p>也就是说，如果序列长度为 <span class=\"math inline\">\\(T\\)</span>，那么在反向传播时，梯度就需要沿着时间轴，从第 <span class=\"math inline\">\\(T\\)</span> 个时刻一路反传回第 <span class=\"math inline\">\\(1\\)</span> 个时刻。<br />\n需要说明的是，这里时间展开的长度 <span class=\"math inline\">\\(T\\)</span> 指的是 <strong>RNN 在时间维度上的递推步数</strong>，在我们介绍的基础 RNN 场景下，通常等同于输入序列的长度 <span class=\"math inline\">\\(T_x\\)</span>，而非生成序列的长度 <span class=\"math inline\">\\(T_y\\)</span>。<br />\n最终，从效果上看，这相当于：  <strong>同一组权重矩阵被反复相乘了 <span class=\"math inline\">\\(T\\)</span> 次。</strong></p>\n<p>因此，在 RNN 中，我们同样有必要了解训练中出现梯度现象的处理方法。</p>\n<h2 id=\"12-梯度爆炸的处理梯度裁剪gradient-clipping\">1.2 梯度爆炸的处理：梯度裁剪（Gradient Clipping）</h2>\n<p>在 RNN 的梯度问题中，<strong>梯度爆炸通常是最先、也是最容易被观察到的现象</strong>。<br />\n其表现非常直观：损失函数在训练过程中剧烈震荡，甚至直接变为 NaN，参数更新完全失控，模型无法继续训练。<br />\n与梯度消失不同，梯度爆炸并不是“学不到”，而是 <strong>“学得太猛”</strong>。<br />\n因此，相比梯度消失，梯度爆炸问题更容易被控制和缓解。这很好理解：东西多了我们可以扔，但少了我们不能凭空创造出来。<br />\n而其中一种最常见、也最直接的方法，就是<strong>梯度裁剪（Gradient Clipping）</strong>。</p>\n<p>梯度裁剪的思想非常简单，可以概括为一句话：</p>\n<blockquote>\n<p><strong>当梯度过大时，不让它继续放大更新幅度。</strong></p>\n</blockquote>\n<p>也就是说，我们并不试图改变梯度的“方向”，而只是<strong>限制梯度的“大小”</strong>，从而避免一次参数更新步长过大，破坏训练稳定性。</p>\n<p>再打个比方：在下坡骑车时，我们的方向是对的，但速度太快容易摔，所以我们通过“刹车”来控制风险。<br />\n梯度裁剪，本质上就是反向传播阶段的“数值刹车”。</p>\n<p>在实际使用中，最常见的是<strong>基于梯度范数（norm）的裁剪方式</strong>。<br />\n设所有参数的梯度拼接成一个向量 <span class=\"math inline\">\\(g\\)</span>，其 <strong><span class=\"math inline\">\\(L_2\\)</span> 范数</strong>为：</p>\n<p></p><div class=\"math display\">\\[\\lVert g \\rVert_=\\sqrt{g_1^2 + g_2^2 + \\cdots + g_n^2}  \n\\]</div><p></p><p>我们用 <strong><span class=\"math inline\">\\(L_2\\)</span> 范数</strong>衡量梯度的<strong>整体大小</strong>，它反映的是<strong>这一次反向传播中，参数更新“总体有多激进”</strong>。</p>\n<p>下一步，给定一个<strong>阈值 <span class=\"math inline\">\\(c\\)</span></strong>，梯度裁剪的规则是：</p>\n<p></p><div class=\"math display\">\\[g =\n\\begin{cases}\ng, &amp; \\lVert g \\rVert \\le c \\\\\n\\dfrac{c}{\\lVert g \\rVert} \\, g, &amp; \\lVert g \\rVert &gt; c\n\\end{cases}\n\\]</div><p></p><p>也就是说：</p>\n<ul>\n<li>如果梯度范数在可接受范围内：<strong>不做任何处理。</strong></li>\n<li>如果梯度范数超过阈值：<strong>整体缩放，使其范数恰好等于 <span class=\"math inline\">\\(c\\)</span>。</strong></li>\n</ul>\n<p>这样操作下来，你会发现：<strong>梯度裁剪并不会改变梯度各分量之间的相对比例，只是统一缩放其大小到合适程度。</strong></p>\n<p>这样，在反向传播中，梯度裁剪就会<strong>阻断“指数级放大”的最坏情况</strong>， 保证参数更新始终处在一个稳定区间，从而让训练过程“至少可以继续进行下去”。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260108213603856-931372748.png\" /><br />\n要强调的是：在实际训练中时，<strong>梯度裁剪几乎是默认配置</strong>，而不是可选技巧。</p>\n<p>但是，梯度裁剪也有其局限性：<strong>梯度裁剪只能缓解梯度爆炸，无法解决梯度消失。</strong><br />\n原因很简单：</p>\n<ul>\n<li>梯度爆炸是“数值过大”的问题 → 可以强行压缩</li>\n<li>梯度消失是“信号本身接近于 0” → 裁剪无能为力</li>\n</ul>\n<p>因此，对于梯度消失这一更常见也更难缓解的梯度现象，我们需要别的解决方案，这也是我们下面要讨论的主要内容。</p>\n<h1 id=\"2-rnn-中的梯度消失长距离依赖问题\">2. RNN 中的梯度消失：长距离依赖问题</h1>\n<p>我们知道，<a href=\"https://www.cnblogs.com/Goblinscholar/p/19449622\" target=\"_blank\">RNN</a> 擅长处理序列数据，并能够逐步积累历史信息。然而，在长序列训练中，梯度消失会让早期时间步的影响被逐渐“抹掉”，这就导致了著名的 <strong>长距离依赖问题</strong>：模型难以捕捉序列中相隔较远的信息。<br />\n我们用之前的反向传播例子来演示一下这个问题：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260108213553401-1851089098.png\" /><br />\n注意我们标红的字体：<strong>当序列过长时，与结尾距离很远的最初几步信息很难实现有效更新。因此梯度已经在层层连乘中所剩无几了。</strong><br />\n这样带来的后果是什么？来看看：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260108213555854-2054969424.png\" /></p>\n<p>这就是 RNN 中的梯度消失现象，<strong>它直接导致 RNN 难以捕捉序列中相隔较远的依赖关系</strong>，显然，这对模型性能的影响是巨大的。</p>\n<p>那么如何缓解 RNN 中的梯度消失现象？<br />\n你可能想到了我们之前介绍过的<a href=\"https://www.cnblogs.com/Goblinscholar/p/19359236\" target=\"_blank\">残差网络</a>，即通过在 RNN 中引入<strong>残差连接</strong>，为梯度提供了一条直接传递的通路，可以在一定程度上缓解梯度消失问题，使深层或长序列的训练更加稳定。这的确是一种可行的改进方案。但残差路径虽然提供了梯度直通通道，但<strong>无法进行信息选择性控制</strong>，对于非常长序列仍然存在梯度衰减。<br />\n因此，在 RNN 中，我们有一种更好的技术：<strong>门控机制</strong>，这是在实际实验和部署中我们更常使用的方法，它不仅能保持梯度稳定传递，还能智能控制信息流。<br />\n其原理较为复杂，我们经过本篇的引用，在下一篇来详细展开它。</p>\n<h1 id=\"3-总结\">3. 总结</h1>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>原理</th>\n<th>比喻</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>梯度现象（Gradient Phenomena）</strong></td>\n<td>在深层网络或 RNN 的反向传播中，梯度可能过大或过小，导致训练不稳定，即梯度爆炸或梯度消失</td>\n<td>就像水流管道，如果水压过大管道爆裂，水压过小又无法输送水</td>\n</tr>\n<tr>\n<td><strong>RNN 的“深度”</strong></td>\n<td>RNN 在时间维度上展开为共享参数的深层网络，梯度需要沿时间轴反向传播，连续乘以权重矩阵 <span class=\"math inline\">\\(T\\)</span> 次</td>\n<td>好比一个接力赛，每一棒都必须传递能量，接力棒越多，总能量损耗越大</td>\n</tr>\n<tr>\n<td><strong>梯度裁剪（Gradient Clipping）</strong></td>\n<td>当梯度范数超过阈值 <span class=\"math inline\">\\(c\\)</span> 时，对梯度整体缩放，使其范数等于 <span class=\"math inline\">\\(c\\)</span>；不改变梯度方向，只调整大小</td>\n<td>就像给过快下坡的车装刹车，保持安全速度</td>\n</tr>\n<tr>\n<td><strong>RNN 的长距离依赖问题</strong></td>\n<td>梯度在层层连乘或长序列反向传播中逐渐趋近 0，早期时间步的影响被“抹掉”，导致长距离依赖难以学习</td>\n<td>像传话游戏，信息经过太多人，最开始的话慢慢被模糊甚至忘掉</td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-08 21:37</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">79</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "20250702 - FPC Token 攻击事件：严格的限制，灵活的黑客",
      "link": "https://www.cnblogs.com/ACaiGarden/p/19458550",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ACaiGarden/p/19458550\" id=\"cb_post_title_url\" title=\"发布于 2026-01-08 19:56\">\n    <span>20250702 - FPC Token 攻击事件：严格的限制，灵活的黑客</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"背景\">背景</h1>\n<p>FPC 是 BPE-20 项目，实现了复杂的交易机制，包括<strong>买卖手续费、流动性池燃烧机制、限制交易频率、限制交易数量</strong>等功能。漏洞产生的原因是当用户卖出代币时，<strong>合约会从流动性池中燃烧代币（而非从卖出者余额中燃烧）</strong>，导致池子中 FPC 代币数量减少，价格抬高。</p>\n<blockquote>\n<p>项目方应该是为了加上流动性池燃烧机制，发现直接加上这不行呀，这个会被利用去套利的。然后打了限制交易频率和限制交易数量两个补丁。希望以此来限制代币持有者通过机制进行获利。</p>\n</blockquote>\n<p>攻击交易</p>\n<ul>\n<li><strong>攻击交易哈希</strong>: <code>0x3a9dd216fb6314c013fa8c4f85bfbbe0ed0a73209f54c57c1aab02ba989f5937</code></li>\n<li><strong>攻击者地址</strong>: <code>0xbf6e706d505e81ad1f73bbc0babfe2b414ba3eb3</code></li>\n</ul>\n<p>漏洞合约</p>\n<ul>\n<li><strong>FPC代币合约</strong>: <code>0xb192d4a737430aa61cea4ce9bfb6432f7d42592f</code></li>\n<li><strong>主要流动性池</strong>: <code>0xa1e08e10eb09857a8c6f2ef6cca297c1a081ed6b</code></li>\n</ul>\n<h1 id=\"trace-分析\">Trace 分析</h1>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195418546-1108887978.png\" /></p>\n<ol>\n<li>\n<p>攻击者通过闪电贷获得大量的 USDT</p>\n</li>\n<li>\n<p>在 [FPC, USDT] 池子中购买大量的 FPC</p>\n</li>\n<li>\n<p>把 FPC 转移到新的地址中</p>\n</li>\n<li>\n<p>出售所有的 FPC：先触发<strong>流动性池燃烧机制</strong>，推高了 FPC 的价格，然后再计算出售获得的 USDT，从而获得超额的利润。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195438039-1592352059.png\" /></p>\n</li>\n</ol>\n<h1 id=\"代码分析\">代码分析</h1>\n<p>在背景介绍了 FPC 代币实现了<strong>流动性池燃烧机制、限制交易频率、限制交易数量</strong>等功能，接下来将会通过代码实现以及攻击者的手法向读者展示。</p>\n<h2 id=\"在-fpc-usdt-池子中购买大量的-fpc\">在 [FPC, USDT] 池子中购买大量的 FPC</h2>\n<p>在黑客购买 FPC 的操作中，黑客没有通过 router 进行兑换，而是直接调用 pool 进行兑换。</p>\n<pre><code class=\"language-markdown\">CALLCake-LP.swap(**amount0Out=1,000,000,000,000,000,000**, amount1Out=790,178,970,489,172,772,916,652)\n</code></pre>\n<p>并且在购买大量 FPC 代币的同时，还换出了 1 USDT。很反常的操作，如果只是为了购买 FPC，这个amount0Out 的值应为为 0。</p>\n<blockquote>\n<p>黑客这样做的目的是为了绕开最大购买数量的限制</p>\n</blockquote>\n<p>在直接通过 pool 大量购买 FPC 时同时换出 1 个 USDT，目的就为了欺骗 _isLiquidity 函数的检查，伪装成移除流动性的操作，使得 isDel 的值为 true。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195457477-1676036854.png\" /></p>\n<p>如果  isDel 的值为 true，就会绕过 <code>value &lt;= _maxBuyAmount()</code> 的限额检查了。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195511387-780783212.png\" /></p>\n<h2 id=\"把-fpc-转移到新的地址中\">把 FPC 转移到新的地址中</h2>\n<p>在 FPC 代币中，如果用户进行 swap 操作，会被记录下操作的区块号，并且限制 3 个区块内不允许再次交易。但是它没有对转账操作进行限制，所以攻击者可以通过把 FPC 转移到没有进行过 swap 的地址进行出售，从而绕过这个限制。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195529422-1735776335.png\" /></p>\n<h2 id=\"出售所有的-fpc触发流动性池燃烧机制\">出售所有的 FPC：触发<strong>流动性池燃烧机制</strong></h2>\n<p>这一步是关键的步骤，卖出 FPC 代币，触发合约的燃烧机制</p>\n<pre><code class=\"language-markdown\">CALLPancakeSwap: Router v2.swapExactTokensForTokensSupportingFeeOnTransferTokens(\n  amountIn=247,441,170,766,403,071,054,109)\n</code></pre>\n<p>在 sell 的逻辑分支中，会调用 burnLpToken 函数按照出售的数量 value 来销毁 FPC 代币。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195542694-2016383265.png\" /></p>\n<p>而在 burnLpToken 函数函数中，燃烧的是 pool 中的代币（不是燃烧 seller 提供的代币，而是直接燃烧 pool 中的代币）。这样会使得 pool 中 FPC 的价格被推高。使得黑客在卖出 FPC 代币时能够获取到更多的利润。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1483609/202601/1483609-20260108195628531-1501728881.png\" /></p>\n<h1 id=\"后记\">后记</h1>\n<p>这个代币在添加流动性池燃烧机制的初衷应该是希望在用户出售代币的时候，啊把池子里面的代币取出来一点，一个是收归项目方所有，第二个是抬高一点币价不要跌的这么快。</p>\n<p>但是，但是在 Pancake 和 Uniswap 的 V2/V3 版本中，都是遵循着“先转账，后结算”的模式去进行 swap 的。而代币设置的各种机制只能在转账的过程中触发，这就使得了这个燃烧机制始终都是发生在结算前的，这就给了黑客套利的空间。如果想要实现这种特殊机制，可以考虑一下通过 Uniswap V4 的 Hook 去实现，但是会对开发的技术与质量要求更高（不得不说后续更新的版本都不如 V2 的 x * y = k 来得简单直接，叽里咕噜又集中流动性又 Hook 说啥呢，我 V2 一把加完流动性就能用。也是为什么直至现在很多代币的发行方都钟爱在 V2 上部署池子）。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-08 19:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ACaiGarden\">ACai_sec</a>&nbsp;\n阅读(<span id=\"post_view_count\">36</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "云原生AI算力平台的架构解读",
      "link": "https://www.cnblogs.com/JulianHuang/p/19458390",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/JulianHuang/p/19458390\" id=\"cb_post_title_url\" title=\"发布于 2026-01-08 18:41\">\n    <span>云原生AI算力平台的架构解读</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>给近半年做的云原生AI算力平台做一个回顾， 思考和实践参考了云溪大会上的分享：<a href=\"https://developer.aliyun.com/article/1414573\" rel=\"noopener nofollow\" target=\"_blank\" title=\"为大模型工程提效，基于阿里云 ACK 的云原生 AI 工程化实践\">为大模型工程提效，基于阿里云 ACK 的云原生 AI 工程化实践</a>，全文很长，我这边做一个牵引和解读。</p>\n</blockquote>\n<h2 id=\"1-云计算迎来智算时代\">1. 云计算迎来“智算”时代</h2>\n<p>云计算是一种<strong>通过互联网的方式按需提供计算资源（如服务器、存储、数据库、网络、软件等）</strong>的服务模式， 用户可以像使用水电气一样,按需购买、灵活付费，无需购买和维护物理设备。</p>\n<p>特征是① 按需自助服务 ② 广泛的网络访问 ③ 资源池化  ④ 快速弹性伸缩  ⑤ 使用量计费</p>\n<blockquote>\n<p>为什么叫“云计算”？<br />\n在冯诺依曼体系中，计算资源是CPU，但我们还是以“计算机”来指代包含计算、存储、网络、软件形成的完整服务器；<br />\n在云计算领域，“计算”一次被沿用，将传统计算机核心组件拆开虚拟化、池化，并提供了“用于信息处理所有软硬件要素的总和抽象”。</p>\n</blockquote>\n<p>今天的云计算已经承载了web应用、数据库、大数据、机器学习和高性能计算等计算负载。</p>\n<p>面对LLM和GAI这类对算力和数据都有极高需求的新负载，云计算也迎来了“智算”时代，<br />\n一方面以服务化资源池的概念提供万卡算力、PB级存储、和单机TB级高速网络互联，另一方面以云原生标准化交付算力给大模型的生产者和使用者。</p>\n<h2 id=\"2-大模型带来的挑战\">2. 大模型带来的挑战</h2>\n<p>AI有工程化的要求，同时也对基础设施提出挑战。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108183944896-1604958658.png\" /><br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108183950488-1199602426.png\" /></p>\n<h2 id=\"3-云原生ai的能力\">3. 云原生AI的能力</h2>\n<p>最近在做的“AI大模型基础设施”， 宏观目标也是帮助AI工程从小作坊向端到端云原生解决方案演进。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108183959371-1234056611.png\" /></p>\n<h3 id=\"统一管理异构资源提供资源利用率\">统一管理异构资源，提供资源利用率</h3>\n<p>对idc内各种异构计算（GPU、CPU、NPU等）、存储（OSS、NAS、CPFS、HDFS）、网络（TCP、RDMA）资源进行抽象，统一管理和运维和分配，通过软硬协同优化，提供资源利用率。</p>\n<h3 id=\"通过统一工作流--统一调度-实现ai大数据等复杂任务的高效管理\">通过①统一工作流 ② 统一调度， 实现AI/大数据等复杂任务的高效管理</h3>\n<ul>\n<li>\n<p>从异构资源管理的角度，可一键部署、操作各种异构资源，在运维过程中，需要多维度的异构资源可观测性： 监控、健康检查、告警、自愈等自动化运维能力</p>\n</li>\n<li>\n<p>对于宝贵的GPU/NPU算力资源，使用各种调度、隔离、共享的方式提供资源利用率</p>\n</li>\n<li>\n<p>分钟级准备好开发和测试环境，帮助算法工程师把 ①执行深度学习任务②产出/评测模型③模型部署 以端到端的工作流串起来， 天然支持主流框架 tensorflow/pytorchjob/mpi<br />\n--  对于分布式任务，提供丰富的任务调度策略，如Gang scheduling、Capacity scheduling、Topology aware scheduling、优先级队列等。</p>\n</li>\n<li>\n<p>提供弹性训练和弹性推理服务， 建立统一的数据集管理，模型生命周期管理， 优化模型访问性能，通过标准API使推理能力易于被业务应用集成。</p>\n</li>\n</ul>\n<h2 id=\"4-云原生ai的架构实践\">4. 云原生AI的架构实践</h2>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184015761-1427603173.png\" /></p>\n<p>我们的云原生AI算力平台， 有参考上面的实践，针对企业业务的现状和侧重， 技术调研上做了调整和裁剪。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184025350-220307939.png\" /></p>\n<p>没有从0到1的使用kubeflow全家桶，使用了arena、 kubeflow  trainer。</p>\n<blockquote>\n<p><a href=\"https://www.kubeflow.org/docs/started/architecture/\" rel=\"noopener nofollow\" target=\"_blank\" title=\"kubeflow\">kubeflow</a>是一个包含多个开源项目的AI生态组合， kubeflow以Kubernetes为底座，目标是成为部署、扩展和管理AI平台的系统。</p>\n</blockquote>\n<p>在平台侧，我们统一纳管了集群资源，实现了统一调度能力和模型生命周期管理，关联了公司自有的数据存储（涉及数据集预热、模型存储），<br />\n这里有一个技术点：Go动态感知资源变更的技术实践，你指定用过！</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184044867-660442933.png\" /></p>\n<p>用户行为的触发点是arena， 我们使用arena提交了训练任务。 ref:  Golang 文本模板，你指定没用过!</p>\n<p>在调度侧，使用tranning operator和kerve组件，tranning operator 提供统一的训练工作流， kserve提供了将模型以云原生方式部署、扩缩容的能力。</p>\n<p>arena产生训练任务/部署动作---&gt; 内部helm形成对应的CRD（pytorchjob、InferenceService)---&gt;控制器监听CRD的变更---&gt; 生成底层资源（deploy/service/network)</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184107591-1084626310.png\" /></p>\n<p>各算法团队天然对应租户概念，也就是k8s命名空间， 我们给租户下面每一个用户颁发了一个<a href=\"https://blog.miniasp.com/post/2022/08/24/Understanding-Service-Account-in-Kubernetes-through-MicroK8s\" rel=\"noopener nofollow\" target=\"_blank\" title=\"serviceAccount\">serviceAccount</a>作为登录和操作凭据。</p>\n<p>为实现自动任务调度，我们引入了kueue这样的任务队列组件，在任务被k8s调度器调度之前做准入，kueue成为了异构资源池化多租户配额、任务排队的技术支撑。</p>\n<p>有关kueue的使用，请参考：🎉在k8s调度的花园里面挖呀挖 。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184122928-1792259600.png\" /></p>\n<p>为适配AI工程化的调度要求，我们使用Koordinator调度器支持了binpack装箱调度。</p>\n<p>什么叫binpack， 为什么AI训练需要binpack， 请参考:🎉卷不过AI算法， AI工程化或许是一个出路？<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184133179-1065900826.png\" /></p>\n<p>最后平台需要管控多渠道的任务，我们使用 informer机制监听了多渠道任务并回显到页面， 这里有个技术点，值得参考。</p>\n<p>🚀糟糕，我实现的k8s informer好像是依托答辩<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/587720/202601/587720-20260108184141433-1556621842.png\" /></p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/4236/528d857f-9d29-4937-8275-20accf704f4e.png\" /></p>\n\n</div>\n<div id=\"MySignature\">\n    <hr color=\"#987cb9\" size=\"3\" width=\"80%\" />\n<div style=\"text-align: center;\">\n<p>本文来自博客园，作者：{有态度的马甲}，转载请注明原文链接：<a href=\"https://www.cnblogs.com/JulianHuang/p/19458390\" target=\"_blank\">https://www.cnblogs.com/JulianHuang/p/19458390</a></p>\n<strong style=\"color: red;\">欢迎关注我的原创技术、职场公众号， 加好友谈天说地，一起进化</strong>\n<div><img src=\"https://blog-static.cnblogs.com/files/JulianHuang/QR.gif\" style=\"width: 250px; height: 250px;\" /> </div>\n\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-08 18:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/JulianHuang\">码甲哥不卷</a>&nbsp;\n阅读(<span id=\"post_view_count\">78</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}