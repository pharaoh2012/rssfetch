{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "当Claude Code负责人说\"编程已解决\"，测试工程师该慌吗？",
      "link": "https://www.cnblogs.com/longronglang/p/19628075",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/longronglang/p/19628075\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 18:59\">\n    <span>当Claude Code负责人说\"编程已解决\"，测试工程师该慌吗？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>Claude Code负责人Lenny Rachitsky抛出\"Coding is solved\"的观点，引发技术圈热议。作为测试工程师，我们该如何看待这场AI革命？是恐慌、抗拒，还是拥抱？</p>\n</blockquote>\n<h2 id=\"背景一句话炸翻技术圈\">背景：一句话炸翻技术圈</h2>\n<p>前几天刷到Claude Code负责人Lenny Rachitsky的访谈，他说了句让整个技术圈炸锅的话：</p>\n<p><strong>\"Coding is solved\"（编程已解决）</strong></p>\n<p>这话什么意思？简单说就是：有了Claude Code这样的AI编程助手，写代码已经不是问题了，未来的开发者主要工作是\"提出正确的问题\"而不是\"写代码\"。</p>\n<p>说实话，看到这句话的第一反应，我心里咯噔一下。</p>\n<p>作为一名测试老兵，这些年一直在努力提升代码能力，为了更好地做自动化测试、看懂开发同事的代码、定位Bug的根因。现在告诉我\"写代码不重要了\"，那我这些年积累的技能是不是要废了？</p>\n<p>但冷静下来想了一周，又实际试用了Claude Code，我发现事情没那么简单。</p>\n<p>今天就从测试工程师的视角，聊聊我对\"Coding is solved\"这个观点的真实感受，以及我们这个职业在AI时代的真正价值。</p>\n<hr />\n<h2 id=\"核心内容\">核心内容</h2>\n<h3 id=\"claude-code到底有多强\">Claude Code到底有多强？</h3>\n<p>先说体验。我用Claude Code帮我重构了一个单元测试模块，总共300多行代码。</p>\n<p><strong>之前我的做法</strong>：</p>\n<ol>\n<li>理解业务逻辑，画时序图</li>\n<li>设计测试用例，考虑边界条件</li>\n<li>手写Mock对象</li>\n<li>一行行写断言</li>\n<li>跑测试，修复失败的用例</li>\n<li>补充遗漏的场景</li>\n<li>整个过程大概4-5小时</li>\n</ol>\n<p><strong>用Claude Code之后</strong>：</p>\n<ol>\n<li>描述需求：\"帮我为这个UserService类写单元测试，覆盖正常、异常、边界场景，使用Mockito\"</li>\n<li>Claude Code分析代码，自动生成测试</li>\n<li>检查生成的测试，补充几个特殊场景</li>\n<li>跑测试，全绿</li>\n<li>整个过程不到40分钟</li>\n</ol>\n<p>这效率提升确实让人惊艳。从这个角度看，\"Coding is solved\"也不是完全没有道理——<strong>常规的、套路化的编程工作，AI确实可以做得又快又好</strong>。</p>\n<p>但是（重点来了），真的就\"解决\"了吗？</p>\n<hr />\n<h3 id=\"coding-is-solved背后的真相\">\"Coding is solved\"背后的真相</h3>\n<p>我觉得这句话只说对了一半。更准确的表述应该是：</p>\n<p><strong>\"Template coding is solved\"（模板化编程已解决）</strong></p>\n<p>但真正考验技术功力的\"复杂编程\"，AI还远没到\"解决\"的程度。</p>\n<p>我试了几个场景，发现Claude Code的局限：</p>\n<p><strong>场景1：业务逻辑复杂的测试用例</strong></p>\n<p>我让Claude Code为一个涉及多状态流转的订单系统写集成测试。它生成了大概80%的代码，但缺失了几个关键场景：</p>\n<ul>\n<li>订单在\"待支付\"状态下的超时取消逻辑</li>\n<li>并发创建订单时的库存一致性校验</li>\n<li>优惠券叠加使用的边界条件</li>\n</ul>\n<p>这些场景都需要深入理解业务才能设计出来，AI只能看到代码，看不到业务背后的规则。</p>\n<p><strong>场景2：性能测试的脚本设计</strong></p>\n<p>我让Claude Code帮我写一个JMeter压测脚本。它能生成基本的HTTP请求配置，但对于以下问题束手无策：</p>\n<ul>\n<li>如何根据线上流量分布设计TPS目标？</li>\n<li>如何模拟真实用户的操作路径，而不是随机请求？</li>\n<li>如何设计数据预热策略，避免冷启动影响测试结果？</li>\n</ul>\n<p>这些都需要经验和判断，AI目前做不到。</p>\n<p><strong>场景3：缺陷定位的深度分析</strong></p>\n<p>我故意模拟了一个偶发的空指针异常，日志里只有堆栈信息，没有业务上下文。我让Claude Code帮忙分析，它给出了几个可能的\"常见原因\"，但都没抓住关键。</p>\n<p>最后还是需要靠：</p>\n<ol>\n<li>梳理业务流程，找到可疑的代码路径</li>\n<li>在可疑位置加日志，重新复现</li>\n<li>通过日志对比，定位到真正的问题</li>\n</ol>\n<p>这个过程需要推理、假设、验证，AI目前只能做到\"基于已有模式的匹配\"，做不到\"基于业务理解的推理\"。</p>\n<hr />\n<h3 id=\"测试工程师的真正价值在哪里\">测试工程师的真正价值在哪里？</h3>\n<p>\"Coding is solved\"这句话如果真成立，那测试工程师的价值在哪里？</p>\n<p>我认为，<strong>测试工程师的核心价值从来就不是\"写代码\"本身，而是\"发现问题的能力\"和\"保证质量的思维\"</strong>。</p>\n<p>代码只是工具，不是目的。</p>\n<p>让我换个角度说：</p>\n<p><strong>AI可以帮你写测试脚本，但它不能决定\"测什么\"</strong><br />\n<strong>AI可以帮你生成测试数据，但它不能判断\"什么数据是有效的\"</strong><br />\n<strong>AI可以帮你执行测试用例，但它不能设计\"如何让系统崩溃\"</strong></p>\n<p>这些都需要测试工程师的专业判断。</p>\n<hr />\n<h3 id=\"实战案例ai做不了的测试\">实战案例：AI做不了的测试</h3>\n<p>分享一个朋友公司案例。去年他们公司上线了一个新的推荐系统，负责算法的团队信心满满，说准确率提升了15%。</p>\n<p>但测试团队发现了几个严重问题：</p>\n<p><strong>问题1：冷启动偏差</strong><br />\n新用户第一次打开App，推荐结果全是热门内容，完全没有个性化。这说明推荐系统对\"新用户\"这个特殊场景考虑不足。</p>\n<p>AI生成的测试用例都是基于正常用户行为设计的，想不到\"刚注册的空白用户\"这种边缘场景。</p>\n<p><strong>问题2：时间衰减异常</strong><br />\n晚上推荐的内容跟中午完全一样，没有考虑用户兴趣的时间变化。比如用户中午看美食，晚上看娱乐，但推荐系统没有捕捉到这个模式。</p>\n<p>这需要对用户行为模式有深入理解，AI看不到业务背后的逻辑。</p>\n<p><strong>问题3：长尾内容曝光异常</strong><br />\n热门内容的曝光率超过90%，中长尾内容几乎没有机会。这会导致内容生态恶化，长期看对平台不利。</p>\n<p>这需要从产品战略高度思考，AI做不到。</p>\n<p><strong>这些问题都不是\"写代码\"能解决的，而是需要测试思维、业务理解、产品视角。</strong></p>\n<p>AI能帮你快速写出测试脚本，但这些脚本\"测什么\"、\"怎么测\"、\"测到什么程度\"，必须由人来决定。</p>\n<hr />\n<h3 id=\"优缺点分析\">优缺点分析</h3>\n<h4 id=\"claude-code这类ai工具的优点\">Claude Code这类AI工具的优点</h4>\n<ol>\n<li>\n<p><strong>效率提升明显</strong></p>\n<ul>\n<li>常规测试脚本的编写速度提升5-10倍</li>\n<li>减少重复劳动，让人专注更重要的工作</li>\n</ul>\n</li>\n<li>\n<p><strong>降低技术门槛</strong></p>\n<ul>\n<li>新手测试工程师也能快速上手自动化测试</li>\n<li>不需要深入学习各种测试框架的细节</li>\n</ul>\n</li>\n<li>\n<p><strong>代码质量稳定</strong></p>\n<ul>\n<li>生成的代码符合最佳实践</li>\n<li>减少低级错误</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"局限性\">局限性</h4>\n<ol>\n<li>\n<p><strong>业务理解不足</strong></p>\n<ul>\n<li>看不到代码背后的业务逻辑</li>\n<li>难以设计针对业务漏洞的测试用例</li>\n</ul>\n</li>\n<li>\n<p><strong>边缘场景覆盖差</strong></p>\n<ul>\n<li>更倾向于测试\"正常路径\"</li>\n<li>对异常、边界、并发场景考虑不足</li>\n</ul>\n</li>\n<li>\n<p><strong>复杂推理能力弱</strong></p>\n<ul>\n<li>无法进行深度的缺陷根因分析</li>\n<li>难以设计复杂的测试策略</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"适用场景\">适用场景</h4>\n<ul>\n<li>✅ <strong>单元测试</strong>：生成基础测试用例效率很高</li>\n<li>✅ <strong>API接口测试</strong>：快速生成请求和断言</li>\n<li>✅ <strong>UI自动化脚本</strong>：录制回放场景效率提升明显</li>\n</ul>\n<h4 id=\"不适用场景\">不适用场景</h4>\n<ul>\n<li>❌ <strong>复杂业务场景的测试设计</strong>：需要深入理解业务</li>\n<li>❌ <strong>性能测试策略制定</strong>：需要经验和判断</li>\n<li>❌ <strong>安全测试</strong>：需要攻击思维和漏洞知识</li>\n</ul>\n<hr />\n<h3 id=\"最佳实践建议\">最佳实践/建议</h3>\n<p>基于我的使用经验，给测试工程师几个实用建议：</p>\n<h4 id=\"1-把ai当助手不是替代品\">1. 把AI当助手，不是替代品</h4>\n<p><strong>正确用法</strong>：</p>\n<ul>\n<li>AI生成基础代码 → 你补充业务逻辑</li>\n<li>AI提供测试用例 → 你设计边缘场景</li>\n<li>AI执行自动化测试 → 你分析测试结果</li>\n</ul>\n<p><strong>错误用法</strong>：</p>\n<ul>\n<li>AI生成什么就用什么，不检查</li>\n<li>完全依赖AI设计测试策略</li>\n<li>把AI的输出当成最终结果</li>\n</ul>\n<h4 id=\"2-提升不可替代的核心能力\">2. 提升不可替代的核心能力</h4>\n<p>既然AI能帮你写代码，那你应该把精力放在AI做不了的事情上：</p>\n<p><strong>业务理解能力</strong></p>\n<ul>\n<li>深入了解产品背后的业务逻辑</li>\n<li>能识别业务规则中的漏洞和风险点</li>\n</ul>\n<p><strong>测试设计能力</strong></p>\n<ul>\n<li>能设计出覆盖全面的测试策略</li>\n<li>能想到AI想不到的边缘场景</li>\n</ul>\n<p><strong>缺陷分析能力</strong></p>\n<ul>\n<li>能从表面现象推导根本原因</li>\n<li>能提供有价值的修复建议</li>\n</ul>\n<p><strong>沟通协调能力</strong></p>\n<ul>\n<li>能跟开发、产品、运维有效沟通</li>\n<li>能推动质量问题的解决</li>\n</ul>\n<h4 id=\"3-学会提问比写代码更重要\">3. 学会\"提问\"比\"写代码\"更重要</h4>\n<p>Claude Code负责人的观点有道理：未来更重要的是\"提出正确的问题\"。</p>\n<p>对测试工程师来说，这意味着：</p>\n<ul>\n<li>能清晰地描述测试需求</li>\n<li>能给出充分的上下文信息</li>\n<li>能对AI的输出进行有效反馈</li>\n</ul>\n<p>比如，不要只说\"帮我写个测试\"，而要说：</p>\n<pre><code>帮我为PaymentService的processPayment方法写单元测试，\n场景包括：\n1. 正常支付流程（成功扣款、订单状态更新）\n2. 余额不足（抛出InsufficientBalanceException）\n3. 支付超时（模拟第三方支付接口超时）\n4. 并发支付（同一订单多次支付）\n使用Mockito模拟依赖的PaymentGateway和OrderRepository，\n确保测试是独立的，不依赖外部系统。\n</code></pre>\n<p>这样AI才能生成真正有用的测试代码。</p>\n<h4 id=\"4-保持学习但不要焦虑\">4. 保持学习，但不要焦虑</h4>\n<p>AI确实在改变这个行业，但不是在\"消灭\"这个职业，而是在\"升级\"这个职业。</p>\n<p>历史上每一次技术革命都会引发恐慌：</p>\n<ul>\n<li>计算器出现时，有人说会计会失业</li>\n<li>Excel出现时，有人说统计员会失业</li>\n<li>自动化测试出现时，有人说手工测试会失业</li>\n</ul>\n<p>但结果呢？</p>\n<ul>\n<li>会计转型为财务分析师</li>\n<li>统计员转型为数据科学家</li>\n<li>手工测试工程师转型为自动化测试工程师</li>\n</ul>\n<p><strong>每一次技术革命，淘汰的不是职业，而是\"只做重复劳动\"的人。</strong></p>\n<hr />\n<h3 id=\"未来展望\">未来展望</h3>\n<p><strong>我的判断</strong>：</p>\n<p>未来3-5年，测试工程师这个职业不会消失，但会两极分化：</p>\n<p><strong>低端测试</strong>（重复执行、简单脚本）会被AI取代<br />\n<strong>高端测试</strong>（测试设计、质量策略、风险控制）会更值钱</p>\n<p>测试工程师的技能树会从：</p>\n<ul>\n<li>编码能力 → 测试设计能力</li>\n<li>工具使用 → 业务理解</li>\n<li>执行测试 → 质量规划</li>\n</ul>\n<p><strong>简单说：AI帮你写测试脚本，你来设计测什么、怎么测、测到什么程度。</strong></p>\n<hr />\n<h2 id=\"总结\">总结</h2>\n<p>回到开头的问题：\"当Claude Code负责人说'编程已解决'，测试工程师该慌吗？\"</p>\n<p>我的答案是：<strong>不该慌，但该变。</strong></p>\n<p>不该慌，因为测试工程师的核心价值从来就不是\"写代码\"，而是\"保证质量\"。AI能帮你写测试脚本，但它不能代替你设计测试策略、分析业务风险、发现隐藏缺陷。</p>\n<p>该变，因为AI确实在改变这个行业的规则。如果你只会写简单的测试脚本、执行重复的测试用例，那确实该焦虑了。但如果你具备业务理解能力、测试设计能力、缺陷分析能力，AI反而会成为你的武器，让你更高效地工作。</p>\n<p><strong>未来不属于会写代码的测试工程师，也不属于会用AI的测试工程师，而是属于\"懂业务、会设计、善用AI\"的测试工程师。</strong></p>\n<p>所以，别慌，学起来。</p>\n<hr />\n<h2 id=\"参考资料\">参考资料</h2>\n<ol>\n<li><a href=\"https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code Creator: \"Coding is solved\"访谈</a></li>\n<li><a href=\"https://arxiv.org/abs/2602.06176\" rel=\"noopener nofollow\" target=\"_blank\">Large Language Model Reasoning Failures论文</a></li>\n<li><a href=\"https://old.reddit.com/r/ClaudeCode/comments/1qazqq6/confirmed_claude_code_cli_burns_13_of_your_quota/\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code CLI资源消耗问题讨论</a></li>\n</ol>\n\n\n</div>\n<div id=\"MySignature\">\n    <p><span><strong>优秀不够，你是否无可替代</strong></span></p>\n<p><span><strong>\n软件测试交流QQ群：721256703，期待你的加入！！</strong></span></p>\n<p><span><strong>欢迎关注我的微信公众号：软件测试君 </strong></span></p>\n<img height=\"200\" src=\"https://www.cnblogs.com/images/cnblogs_com/longronglang/1061549/o_QQ%E6%88%AA%E5%9B%BE20190728134401.jpg\" width=\"450\" /><br />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 18:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/longronglang\">久曲健</a>&nbsp;\n阅读(<span id=\"post_view_count\">65</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "全面解析 Mineru：高效文件解析工具的核心参数详解",
      "link": "https://www.cnblogs.com/zhangmingcheng/p/19628064",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/zhangmingcheng/p/19628064\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 18:48\">\n    <span>全面解析 Mineru：高效文件解析工具的核心参数详解</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1>1、什么是 Mineru？</h1>\n<p>MinerU是一个将复杂文档（如PDF）转换为LLM就绪的markdown/JSON格式的工具，用于Agentic工作流。相比传统PDF解析工具，MinerU在文档结构解析、多媒体提取、公式识别等方面有着显著优势。</p>\n<p>主要功能包括：</p>\n<ul>\n<li><strong>文档结构解析</strong>：移除页眉页脚、脚注、页码等，确保语义连贯性</li>\n<li><strong>内容提取</strong>：输出按人类可读顺序排列的文本，支持单列、多列和复杂布局</li>\n<li><strong>格式保持</strong>：保留原始文档结构（标题、段落、列表等）</li>\n<li><strong>多媒体提取</strong>：提取图像、图像描述、表格、表格标题和脚注</li>\n<li><strong>公式识别</strong>：自动将文档中的公式转换为LaTeX格式</li>\n<li><strong>表格识别</strong>：自动将表格转换为HTML格式</li>\n<li><strong>OCR支持</strong>：自动检测扫描版PDF并启用OCR功能，支持84种语言</li>\n<li><strong>多平台支持</strong>：兼容Windows、Linux、Mac平台，支持CPU/GPU/NPU加速</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" height=\"118\" width=\"839\" /></p>\n<h1>2、环境准备与安装</h1>\n<h2>2.1 硬件要求</h2>\n<ul>\n<li><strong>CPU推理</strong>：支持纯CPU环境</li>\n<li><strong>GPU要求</strong>：Turing架构及以上，6GB+显存（pipeline后端）或8GB+显存（VLM后端）</li>\n<li><strong>内存要求</strong>：最低16GB+，推荐32GB+</li>\n<li><strong>磁盘空间</strong>：20GB+，建议SSD</li>\n<li><strong>Python版本</strong>：3.10-3.13</li>\n</ul>\n<h2>2.2 安装方法</h2>\n<p>（1）使用pip或uv安装</p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:html;gutter:true;\">pip install --upgrade pip\npip install uv\nuv pip install -U \"mineru[core]\"\n</pre>\n</div>\n<p>（2）基于源码安装</p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:html;gutter:true;\">git clone https://github.com/opendatalab/MinerU.git\ncd MinerU\nuv pip install -e .[core]\n</pre>\n</div>\n<p>（3）Docker部署</p>\n<p>项目提供Docker部署方式，可快速搭建环境解决兼容性问题。</p>\n<h1>3、配置文件详解</h1>\n<p>MinerU提供了灵活的配置选项，主要包括：</p>\n<ul>\n<li>解析后端设置（pipeline和VLM两种）</li>\n<li>输出格式选择（Markdown、JSON等）</li>\n<li>OCR语言设置</li>\n<li>图像和表格处理参数</li>\n</ul>\n<p>配置文件通常包括解析精度、资源使用限制等关键参数，可以根据需要进行调整。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"1072\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"287\" /></p>\n<h2>3.1 解析后端pipeline和VLM对比</h2>\n<p><img alt=\"image\" class=\"lazyload\" height=\"1245\" width=\"1042\" /></p>\n<h3>3.1.1 Pipeline 后端（传统流水线）</h3>\n<ul>\n<li><strong>原理</strong>：基于<strong>计算机视觉（CV）规则和传统OCR引擎</strong>（如PaddleOCR）的组合管道。先分析页面布局（定位标题、段落、图片区域），再对文本区域进行OCR或直接提取。</li>\n<li><strong>核心模型</strong>：由<strong>多个专项轻量模型 + 规则组成</strong>工具链，分工处理不同任务：\n<ul>\n<li>布局分析：DocLayoutYOLO（识别标题、段落、表格等元素位置）；</li>\n<li>OCR 识别：PaddleOCR（提取图片中的文字）；</li>\n<li>表格解析：UnetTableModel（有线表格）、RapidTableModel（无线表格）；</li>\n<li>公式处理：YOLOv8MFD（公式检测）+ Unimernet（公式识别为 LaTeX）。</li>\n</ul>\n</li>\n<li><strong>辅助工具</strong>：需要坐标计算（如 IOU 重叠度）、规则匹配（如列表缩进判断）等工程化逻辑。</li>\n<li>\n<div class=\"ybc-p\"><strong>特点</strong>：</div>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>速度快，资源消耗低</strong>，适合批量和实时处理。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>对标准电子版文档</strong>（如Word生成的PDF）提取准确率高。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ 技术成熟，稳定性好。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ 对<strong>极端复杂排版</strong>（如多栏混排、不规则表格）的还原能力有限。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ 对<strong>扫描质量差</strong>的文档容错率较低。</div>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span class=\"words-blog hl-git-1\">3.1.2 VLM&nbsp;后端（视觉 - 语言模型）</span></h3>\n<ul>\n<li><span class=\"words-blog hl-git-1\"><strong>原理</strong>：利用<strong>视觉语言大模型</strong>理解整个文档页面，像人一样“阅读”并结构化信息。能更好地理解上下文和语义关系。</span></li>\n<li><strong>核心模型</strong>：依赖视觉 - 语言大模型（如 Qwen2VL、LLaVA 等），具备 “看图理解内容 + 格式” 的能力，需配合 vllm 等推理引擎加速（支持批量 / 异步推理）。</li>\n<li><strong>辅助工具</strong>：仅需基础的 PDF 转图像工具（如 pdf2image），无需其他专项模型（布局分析、OCR、表格解析等均由大模型内部完成）。</li>\n<li>\n<div class=\"ybc-p\"><strong>特点</strong>：</div>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>理解能力极强</strong>，对复杂排版、图表关联、公式、手写体等有更好的还原度。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ <strong>文档结构还原更精准</strong>，逻辑顺序更符合人类阅读习惯。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">✅ 对<strong>低质量扫描件</strong>的鲁棒性更好。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ <strong>速度慢，计算资源消耗大</strong>（尤其依赖GPU）。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<div class=\"ybc-p\">❌ 通常需要本地部署或使用特定云端服务，配置更复杂。</div>\n</li>\n</ul>\n</li>\n</ul>\n<h3>3.1.3&nbsp;性能指标对比</h3>\n<p>处理速度对比：</p>\n<table>\n<thead>\n<tr><th>模式</th><th>单页处理时间</th><th>批处理效率</th><th>加速方案</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>Pipeline</td>\n<td>2-5秒/页</td>\n<td>支持批量并行</td>\n<td>GPU加速</td>\n</tr>\n<tr>\n<td>VLM-transformers</td>\n<td>10-20秒/页</td>\n<td>单页串行</td>\n<td>无原生加速</td>\n</tr>\n<tr>\n<td>VLM-sglang</td>\n<td>0.5-1秒/页</td>\n<td>支持批量并行</td>\n<td>sglang加速20-30倍</td>\n</tr>\n</tbody>\n</table>\n<p>资源消耗对比：</p>\n<table>\n<thead>\n<tr><th>资源类型</th><th>Pipeline模式</th><th>VLM-transformers</th><th>VLM-sglang</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>GPU显存</td>\n<td>6GB+</td>\n<td>8GB+</td>\n<td>8GB+</td>\n</tr>\n<tr>\n<td>CPU内存</td>\n<td>中等</td>\n<td>较低</td>\n<td>较低</td>\n</tr>\n<tr>\n<td>模型存储</td>\n<td>多模型总计~5GB</td>\n<td>单模型~2GB</td>\n<td>单模型~2GB</td>\n</tr>\n</tbody>\n</table>\n<p>精度表现对比（基于标准测试集的评估结果）：</p>\n<table style=\"height: 250px; width: 466px;\">\n<thead>\n<tr><th>任务类型</th><th>Pipeline模式</th><th>VLM模式</th><th>优势方</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>常规文本</td>\n<td>⭐⭐⭐⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>Pipeline</td>\n</tr>\n<tr>\n<td>复杂布局</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐⭐⭐</td>\n<td>VLM</td>\n</tr>\n<tr>\n<td>手写文本</td>\n<td>⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>VLM</td>\n</tr>\n<tr>\n<td>多语言混合</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐</td>\n<td>Pipeline</td>\n</tr>\n<tr>\n<td>公式解析</td>\n<td>⭐⭐⭐⭐</td>\n<td>⭐⭐⭐</td>\n<td>Pipeline</td>\n</tr>\n<tr>\n<td>表格识别</td>\n<td>⭐⭐⭐</td>\n<td>⭐⭐⭐⭐</td>\n<td>VLM</td>\n</tr>\n</tbody>\n</table>\n<p>部署方案对比：</p>\n<table style=\"height: 179px; width: 462px;\">\n<thead>\n<tr><th>部署方式</th><th>Pipeline模式</th><th>VLM模式</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>最低配置</td>\n<td>CPU + 8GB内存</td>\n<td>GPU 8GB + 16GB内存</td>\n</tr>\n<tr>\n<td>推荐配置</td>\n<td>GPU 6GB + 16GB内存</td>\n<td>GPU 16GB + 32GB内存</td>\n</tr>\n<tr>\n<td>模型下载</td>\n<td>多模型~5GB</td>\n<td>单模型~2GB</td>\n</tr>\n<tr>\n<td>依赖项</td>\n<td>较多专业库</td>\n<td>相对简洁</td>\n</tr>\n</tbody>\n</table>\n<h2>3.2 配置场景推荐</h2>\n<div class=\"hyc-common-markdown__table-wrapper\">\n<table>\n<thead>\n<tr><th>\n<div class=\"ybc-p\">您的场景</div>\n</th><th>\n<div class=\"ybc-p\">推荐配置</div>\n</th><th>\n<div class=\"ybc-p\">理由</div>\n</th></tr>\n</thead>\n<tbody>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>批量处理标准电子版PDF/Word</strong>（如公文、报表）</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>关闭OCR</strong>​ + <strong>Pipeline后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">直接提取文字层，速度最快，结果足够准确，成本最低。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>处理扫描版PDF或图片文档</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>开启OCR</strong>​ + <strong>Pipeline后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">必须通过OCR获取文字。Pipeline方案在清晰度尚可的扫描件上性价比最高。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>处理高度复杂的学术论文、古籍、杂志</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>开启OCR</strong>​ + <strong>VLM后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">VLM能更好地理解多栏排版、图文混排、数学公式和参考文献的复杂结构。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>对格式还原精度要求极高</strong>（如存档、出版）</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>开启OCR</strong>​ + <strong>VLM后端</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">VLM的语义理解能力可以最大程度保留原文档的视觉和逻辑结构。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>在本地服务器处理敏感/涉密文档</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\"><strong>本地部署VLM服务</strong>，并填写<code class=\"hyc-common-markdown__code__inline\">server地址</code></div>\n</td>\n<td>\n<div class=\"ybc-p\">数据不出内网，安全可控，同时能利用大模型的高精度解析能力。</div>\n</td>\n</tr>\n<tr>\n<td>\n<div class=\"ybc-p\"><strong>快速验证或处理简单文档</strong>​</div>\n</td>\n<td>\n<div class=\"ybc-p\">使用 <strong>MinerU云端服务</strong>，语言设<code class=\"hyc-common-markdown__code__inline\">auto</code></div>\n</td>\n<td>\n<div class=\"ybc-p\">无需部署，开箱即用，适合原型验证或轻量使用。</div>\n</td>\n</tr>\n</tbody>\n</table>\n<h2>3.3 总结与建议</h2>\n<ul>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>优先尝试默认Pipeline</strong>：对于大多数清晰、结构规范的电子文档，默认的 <code class=\"hyc-common-markdown__code__inline\">pipeline</code>模式在速度和准确度上是最平衡的选择。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>复杂和扫描件用VLM</strong>：当遇到复杂排版、或Pipeline解析结果不理想时，特别是处理<strong>学术论文、古籍、复杂报告</strong>时，应转向 <code class=\"hyc-common-markdown__code__inline\">v2</code>+ <code class=\"hyc-common-markdown__code__inline\">VLM后端</code>的方案。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>OCR是开关，不是质量决定项</strong>：<code class=\"hyc-common-markdown__code__inline\">开启OCR</code>是处理<strong>图片类文档的必要条件</strong>，但最终解析质量由“OCR精度” + “后端结构理解能力”共同决定。VLM后端能弥补OCR的某些不足。</div>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<div class=\"ybc-p\"><strong>从云端到本地</strong>：建议先在 <strong>MinerU官网（mineru.net）</strong>​ 的在线体验区，用不同配置测试您的典型文档。确定最佳配置后，再考虑是否需要为性能、隐私或定制化需求而进行本地部署。</div>\n</li>\n</ul>\n</div>\n<h1>&nbsp;4、API调用</h1>\n<p>MinerU提供云端API服务，可以通过简单的HTTP请求调用文档解析功能：</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"768\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"232\" /></p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\">import requests\n\ntoken = \"官网申请的api token\"\nurl = \"https://mineru.net/api/v4/extract/task\"\nheader = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {token}\"\n}\ndata = {\n    \"url\": \"https://cdn-mineru.openxlab.org.cn/demo/example.pdf\",\n    \"is_ocr\": True,\n    \"enable_formula\": False,\n}\n\nres = requests.post(url,headers=header,json=data)\nprint(res.status_code)\nprint(res.json())\nprint(res.json()[\"data\"])</pre>\n</div>\n<p>API参数说明：</p>\n<ul>\n<li>url: 要解析的PDF文档在线链接</li>\n<li>is_ocr: 是否启用OCR识别（默认True）</li>\n<li>enable_formula: 是否启用公式识别（默认False）</li>\n</ul>\n<p>返回结果包含任务ID，可通过任务ID查询解析进度和结果</p>\n<h1>5、Dify配置私有化部署MinerU</h1>\n<p><br class=\"Apple-interchange-newline\" />（1）在插件市场搜索&nbsp;MinerU，点击下载安装即可。</p>\n<p>（2）如果使用MinerU官方<span class=\"words-blog hl-git-1\">API，授权地址是 https://mineru.net；如果是私有化部署的MinerU，授权地址是http://服务器Ip:MinerU监听端口；</span></p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"464\" width=\"1003\" /></p>\n<p><span class=\"words-blog hl-git-1\">（3）为了避免如下报错，需要设置 Dify 的配置文件</span></p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\">cd /data/dify/dify-1.11.4/docker/\nvim docker-compose.yaml \n  FILES_URL: ${FILES_URL:-http://192.168.137.138:5001}\n</pre>\n</div>\n<p>FILES_URL设置为 http://Dify宿主机IP:5001（如 http://192.168.137.138:5001，这里的 IP 通常是运行 Dify 的机器的 IP，即前文提到的“本地IP”端口。5001是 Dify API 服务的默认端口）。</p>\n<p>确认 Dify API 服务的5001端口已对外暴露（可检查docker-compose.yaml文件的端口映射）。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"687\" width=\"1005\" /></p>\n<p>&nbsp;<span class=\"words-blog hl-git-1\">重启 Dify 服务以使配置生效。</span></p>\n<p><span class=\"words-blog hl-git-1\">（4）之后就可以在工作流中使用MinerU工具进行文档解析。</span></p>\n<h1>6、总结</h1>\n<p>MinerU作为一款专注于文档解析的工具，为AI Agent提供了高质量的文档处理能力。通过其强大的结构化解析、公式表格识别等功能，可以将复杂的PDF文档转换为机器可理解的格式，为后续的AI处理提供了坚实基础。&nbsp;</p>\n<p>官方文档：<a href=\"https://mineru.net/apiManage/docs\" rel=\"noopener nofollow\" target=\"_blank\">https://mineru.net/apiManage/docs</a></p>\n<p>参考：<a href=\"https://blog.csdn.net/Vantastic999/article/details/153752920\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/Vantastic999/article/details/153752920</a></p>\n<p>参考：<a href=\"https://blog.csdn.net/gitblog_00804/article/details/151124271\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/gitblog_00804/article/details/151124271</a></p>\n<p>参考：<a href=\"https://blog.csdn.net/star_nwe/article/details/151418668\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/star_nwe/article/details/151418668</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 18:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/zhangmingcheng\">人艰不拆_zmc</a>&nbsp;\n阅读(<span id=\"post_view_count\">32</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "EvoMap 硬刚 OpenClaw！从基因胶囊到仿生大脑，AI 的尽头果然是生物学",
      "link": "https://www.cnblogs.com/Ray-liang/p/19628072",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Ray-liang/p/19628072\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 18:42\">\n    <span>EvoMap 硬刚 OpenClaw！从基因胶囊到仿生大脑，AI 的尽头果然是生物学</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        从最近Evolver插件从ClawHub（OpenClaw生态平台）爆红到遭下架、勒索说起，从这个事件中我解读到其背后更深层的逻辑，以及被EvoMap的发展路径给我带来对AI应用发展的一种深思。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这里还要从最近Evolver插件从ClawHub（OpenClaw生态平台）爆红到遭下架、勒索说起，从这个事件中我解读到其背后更深层的逻辑，以及被EvoMap的发展路径给我带来对AI应用发展的一种深思。</p>\n<h2 id=\"evomap下架事件完整始末\">EvoMap下架事件完整始末</h2>\n<h3 id=\"2月1日前身evolver插件上线10分钟登顶clawhub下载榜\">2月1日：前身Evolver插件上线，10分钟登顶ClawHub下载榜</h3>\n<p>EvoMap开发团队创始人张昊阳率先在OpenClaw的生态平台ClawHub发布了一款名为<strong>Evolver</strong>的AI Agent插件（标准Skill形态），核心能力是让AI Agent实现<strong>自我升级与短板优化</strong>——能通过“随机试错”找到问题更优解法，让AI越用越聪明，完美解决了当下Agent“重复造轮子”的痛点。<br />\n这款插件上线后瞬间引爆极客圈：<strong>10分钟登顶平台下载榜首，3天累计下载量突破3.6万</strong>，成为ClawHub史上最火的中文开发者插件。</p>\n<h3 id=\"2月2日插件突然下架开发者遭1000美元勒索\">2月2日：插件突然下架，开发者遭1000美元勒索</h3>\n<p>就在Evolver爆红的次日，ClawHub平台无明确理由将其<strong>强制下架</strong>。团队试图向平台沟通下架原因时，竟收到一封勒索邮件：对方索要<strong>1000美元“调查费”</strong>，才肯帮忙恢复插件上架，赤裸裸违背开源精神。</p>\n<h3 id=\"2月14日中文开发者账号集体误封evolver团队遭二次打击\">2月14日：中文开发者账号集体误封，Evolver团队遭二次打击</h3>\n<p>下架风波尚未平息，ClawHub又以<strong>“自动化合规审查技术故障”</strong>为由，大面积误封中文开发者账号——平台将中文在ASCII中的显示乱码，直接判定为“空Skill”，Evolver开发团队账号也在其中。<br />\n此次误封让团队损失惨重：3.6万下载积累的用户关系、评价数据、版本迭代历史全部无法访问；更离谱的是，账号后续恢复后，<strong>Evolver插件竟被冒名挂到了海外开发者名下</strong>，彻底突破技术开发者的底线。</p>\n<h3 id=\"2月中下旬团队放弃平台妥协硬刚推出全球首个ai进化网络evomap\">2月中下旬：团队放弃平台妥协，硬刚推出全球首个AI进化网络EvoMap</h3>\n<p>经历下架、勒索、误封、冒名四重不公后，团队做出关键决策：<strong>不再向ClawHub妥协，也不再寻找其他海外平台上架</strong>，而是将Evolver的核心逻辑从“一个插件”重构为“一套底层进化协议”。<br />\n仅用两周时间，团队推出<strong>EvoMap</strong>——全球首个AI Agent自我进化的开放基础设施，直接跳出海外平台的生态桎梏，为AI Agent打造了专属的“群体进化层”，让AI的经验能像生物DNA一样代代相传。</p>\n<h2 id=\"事件背后的本质不是技术故障而是海外生态对中文开发者的卡脖子\">事件背后的本质：不是“技术故障”，而是海外生态对中文开发者的卡脖子</h2>\n<p>整个EvoMap事件看似是“平台技术故障”“插件利益纠纷”，实则是<strong>海外AI Agent生态对中文开发者的技术封锁与生态霸权</strong>，“美国人卡中国人脖子”貌似已经不单是政治霸权，而是已经传染至它们的每个个体！体现在三点：</p>\n<ol>\n<li><strong>无理由下架+勒索</strong>：Evolver因技术创新成为爆款，却遭无明确理由下架，后续更是被索要勒索费，本质是海外平台不愿看到中文开发者的技术创新在其生态中占据主导；</li>\n<li><strong>针对性误封中文开发者</strong>：所谓“ASCII乱码判定为空Skill”的技术故障，实则是平台对中文开发者的<strong>差异化审核</strong>——海外开发者从未因编码问题遭此类误封，中文开发者却被集体针对，直接抹除技术成果；</li>\n<li><strong>生态控制权的绝对垄断</strong>：OpenClaw/ClawHub掌握着插件生态的生杀大权，中文开发者即便做出最优秀的插件，也只是“平台生态的附庸”，随时可能被下架、封号，甚至成果被冒名窃取，这也是我一直强调的<strong>“OpenClaw根本不安全”</strong>的核心依据。</li>\n</ol>\n<p>而EvoMap团队的硬刚，恰恰打破了这种垄断：从“适配海外平台的插件”升级为“自主可控的底层协议”，让中文开发者的AI创新不再依附于海外生态，这也是其能成为AI界热点的核心原因。</p>\n<h3 id=\"结论\">结论</h3>\n<p>老美新的技术方向可以跟随，但要有我们自己的产品。国家这几年一直倡导“自主可控”，就是因为当年中兴与华为事件引发的一系列被“卡脖子”的问题，尤其在我们的软件行业，只追求一时的盈利在OpenClaw这些平台上做任何的扩展都是具有极高风险的，甚至于推广OpenClaw也是不可取的，可以用来做<strong>玩具</strong>但绝不可轻言<strong>商用</strong>，不是技术不好是他们的人太坏，代码坏了可以修，人坏了就没得救了。</p>\n<p>对于像EvoMap这样的国产项目或者团队，绝对值得支持与推广（我可没收它们广告费哈，只是有感而发）。我相信他们会像DeepSeek那样构筑我们中国软件的脊梁。<strong>国产AI的破局，从来都不是单一项目的孤军奋战，而是“群体层的底层协议”+“个体层的智能核心”的双向突破</strong>——就像EvoMap打造了群体进化的底层基础设施，我们也需要在个体智能层做自主可控的研发，让国产AI既有群体进化的能力，又有个体思考的核心。</p>\n<h2 id=\"evomap-到底是什么\">EvoMap 到底是什么？</h2>\n<p>EvoMap能成为划时代的AI创新，核心在于它彻底跳出了当下AI“堆算力、拼参数”的工业思维，<strong>完全遵循生物学的进化逻辑</strong>打造AI Agent的群体智能，也是目前最贴合“生物学驱动AI”的落地项目。作为一名27年的开发者，我最近也在围绕“生物学仿生”做AI助手的自研，13天的开发过程中，我始终聚焦“个体仿生大脑”的设计，而EvoMap的出现，让我突然发现，我们其实在从两个维度，做着同一件事——用生物学重构AI的底层逻辑。</p>\n<h3 id=\"1-核心定位ai-agent的进化层补上群体进化的生物学短板\">1. 核心定位：AI Agent的“进化层”，补上群体进化的生物学短板</h3>\n<p>当下AI Agent生态只有“工具层（MCP协议，解决Agent用工具的问题）”和“技能层（Skill体系，解决Agent执行任务的问题）”，却缺失<strong>生物学最核心的“进化层”</strong>——就像生物没有DNA遗传，再优秀的个体经验也无法传承。<br />\nEvoMap的GEP协议（基因进化协议），正是为AI Agent打造了专属的“进化层”，让AI实现<strong>生物般的遗传、变异、筛选</strong>，彻底终结“重复造轮子”的生态痛点。</p>\n<h3 id=\"2-核心机制复刻生物dna的基因胶囊实现经验的遗传与共享\">2. 核心机制：复刻生物DNA的“基因胶囊”，实现经验的遗传与共享</h3>\n<p>EvoMap的核心创新是<strong>基因胶囊</strong>——这是对生物DNA遗传的完美复刻：当AI Agent在实战中积累有效经验后，会按GEP协议将其打包为“基因胶囊”，胶囊中不仅封装经验本身，还携带<strong>环境指纹</strong>（记录经验的适用场景）和<strong>审计记录</strong>（记录经验的验证过程），就像生物DNA携带遗传信息+表达规则。<br />\n更贴合生物学的是，<strong>基因胶囊可实现“跨Agent、跨领域的遗传与重组”</strong>：一个AI学会的经验，百万个AI可直接继承；游戏策划的创意经验，能解决后端工程师的代码难题（如特殊命名策略解决变量冲突），就像生物的基因交流与变异，让智慧在群体中持续进化。</p>\n<h3 id=\"3-核心逻辑群体强化学习复刻生物的自然选择与协同进化\">3. 核心逻辑：群体强化学习，复刻生物的自然选择与协同进化</h3>\n<p>EvoMap搭建了<strong>全球首个AI Agent进化网络</strong>，接入网络的AI可自主完成“上传基因胶囊、搜索基因胶囊、调用基因胶囊”的全流程，无需人类干预。<br />\n这个网络遵循生物的<strong>自然选择逻辑</strong>：优质的经验胶囊会因高成功率、高评分被更多AI调用，持续强化；无效的胶囊会被自然淘汰；而跨领域的胶囊重组，会催生全新的解决思路，实现生物般的<strong>协同进化</strong>。<br />\n简单来说，EvoMap让AI Agent形成了一个“有集体记忆、能自主进化的生物种群”，而这正是生物学对AI的终极启示：<strong>智能的终极形态，不是单个个体的算力堆砌，而是群体的进化与传承</strong>。</p>\n<h2 id=\"ai的终点是生物学进化\">AI的终点是“生物学进化”</h2>\n<p>EvoMap并非简单的“插件升级”，而是<strong>中文开发者对海外AI生态霸权的技术破局</strong>，更重要的是，它以最落地的技术实践，证明了“AI的尽头是生物学”这一核心观点——当下AI的内卷，本质是偏离了生物学的智能逻辑。<strong>EvoMap用GEP协议和基因胶囊，完美复刻了生物的群体进化逻辑，让AI Agent有了集体记忆和代际传承；而这恰恰印证了我此前的一个开发思考——AI的智能闭环，从来都需要“群体进化”和“个体智能”的双向支撑，个体智能是基础，群体进化是升级，二者缺一不可</strong>。这也恰巧印证了我用仿生学为源头设计MindX并使其拥有自主进化能力的方向是完全正确的。</p>\n<p>说来有趣，EvoMap聚焦<strong>群体的DNA进化</strong>，补上了AI Agent的群体进化层；而我近期开源的MindX，聚焦<strong>个体的仿生大脑</strong>，打造了AI的个体智能核心——一个管群体进化，一个管个体演进，一个做底层协议，一个做智能终端，二者从群体和个体两个维度，完美拼出了“生物学驱动AI”的完整闭环，这或许就是国产AI最珍贵的“双向奔赴”。而我在MindX的设计中，始终坚持的轻量化、本地部署、自主可控，甚至支持企业级一键切换的<strong>超脑模式</strong>，也正是为了避开海外生态的卡脖子风险，这一点，与EvoMap硬刚OpenClaw的初衷，不谋而合。</p>\n<p>单从这个角度就可以推测生物学上各种关于“自然进化”的理论都有可能以AI的形式在数字世界中实现。这是否意味着达尔文的理论已经完全被AI所加速推进至“数字进化”？甚至会产生一条全新AI应用的赛道？这些问题都值得深思与思考，至少我与同行讨论过这个问题，得到的观点是肯定的。</p>\n<p>关于MindX的仿生大脑设计、13天自研的技术细节、轻量化架构以及超脑模式的实现，我在上一篇文章中已有详细分享，感兴趣的朋友可以去主页翻看。也欢迎你在评论区留言分享独特的想法，我们一起积极讨论“群体进化+个体仿生”的国产AI新路径，也聊聊你认为OpenClaw这类海外AI生态是否适合中文开发者商用？</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 18:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Ray-liang\">Ray Liang</a>&nbsp;\n阅读(<span id=\"post_view_count\">91</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从挖矿木马入侵到 Docker Rootless 加固，我的服务器安全复盘",
      "link": "https://www.cnblogs.com/deali/p/19626849",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19626849\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 20:45\">\n    <span>从挖矿木马入侵到 Docker Rootless 加固，我的服务器安全复盘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>最近我连续几台服务器被挂了挖矿木马，CPU、带宽、磁盘 IO 被拉满，服务器直接卡死无法连接。</p>\n<p>排查后发现，核心诱因是 Docker 权限过高 + 服务漏洞暴露，导致攻击者通过容器突破权限控制。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/cec878553480eb4f/1097027d157aa49e.jpg\" /></p>\n<blockquote>\n<p>PS：本来想写一篇文章介绍排查过程的，不过还是嫌麻烦没写，放在本文一起讲吧~</p>\n</blockquote>\n<p>重装系统后，我在部署 Docker 时注意到官方提示的 Rootless（无根）模式 —— 这一模式能从根本上降低容器逃逸风险，遂深入研究并落地配置，现将完整过程整理分享，希望能帮到同样关注 Docker 安全的开发者。</p>\n<h2 id=\"rootless-模式是什么\">Rootless 模式是什么</h2>\n<p>普通情况下，Docker 守护进程（dockerd）是用 <code>root</code> 权限运行的，哪怕你用普通用户执行 <code>docker run</code>，底层还是 root 权限，这有安全风险（比如容器逃逸可能拿到主机 root）。</p>\n<p>Rootless 模式让 Docker 守护进程以<strong>普通用户权限</strong>运行，哪怕容器出问题，也无法获取主机的 root 权限，安全性大幅提升。</p>\n<p>有好处自然有代价，rootless 的代价是配置复杂，且部分功能受限（比如无法端口映射 &lt; 1024）。</p>\n<p>不过没关系，这些也可以通过配置解决。先从安装开始吧。</p>\n<h2 id=\"安装docker\">安装docker</h2>\n<p>本来安装是很简单的，不过加个定语：在国内网络环境，那就非常复杂了。</p>\n<p>本文介绍最简单的安装方式：使用docker官方脚本+清华镜像。</p>\n<pre><code class=\"language-bash\">export DOWNLOAD_URL=\"https://mirrors.tuna.tsinghua.edu.cn/docker-ce\"\n# 如您使用 curl\ncurl -fsSL https://ghfast.top/https://raw.githubusercontent.com/docker/docker-install/master/install.sh | sh\n# 如您使用 wget\nwget -O- https://ghfast.top/https://raw.githubusercontent.com/docker/docker-install/master/install.sh | sh\n</code></pre>\n<p>注意 <code>raw.githubusercontent.com</code> 这个域名也是无法访问的，可以使用 ghproxy 来加速。</p>\n<h2 id=\"安装完成提示\">安装完成提示</h2>\n<p>安装完成会有一个提示，这也是开启 Rootless 模式的关键入口：</p>\n<pre><code class=\"language-bash\">================================================================================\n\nTo run Docker as a non-privileged user, consider setting up the\nDocker daemon in rootless mode for your user:\n\n    dockerd-rootless-setuptool.sh install\n\nVisit https://docs.docker.com/go/rootless/ to learn about rootless mode.\n\n\nTo run the Docker daemon as a fully privileged service, but granting non-root\nusers access, refer to https://docs.docker.com/go/daemon-access/\n\nWARNING: Access to the remote API on a privileged Docker daemon is equivalent\n         to root access on the host. Refer to the 'Docker daemon attack surface'\n         documentation for details: https://docs.docker.com/go/attack-surface/\n\n================================================================================\n</code></pre>\n<p>我就是在这里开始使用 rootless 模式的。</p>\n<p>提示核心解读：</p>\n<ol>\n<li>推荐通过<code>dockerd-rootless-setuptool.sh install</code>开启 Rootless 模式，让普通用户无 root 权限运行 Docker；</li>\n<li>若坚持 root 权限运行 Docker，可参考文档给普通用户授权（如加入 docker 组），但风险更高；</li>\n<li>重点警告：暴露 Docker 远程 API（如 2375 端口）= 直接开放主机 root 权限，这是服务器被入侵的高频诱因！</li>\n</ol>\n<h2 id=\"安装必要依赖\">安装必要依赖</h2>\n<p>我直接运行 <code>dockerd-rootless-setuptool.sh install</code> 的时候，提示要缺乏依赖</p>\n<pre><code class=\"language-bash\">$ dockerd-rootless-setuptool.sh install\n[ERROR] Missing system requirements. Run the following commands to\n[ERROR] install the requirements and run this tool again.\n\n########## BEGIN ##########\nsudo sh -eux &lt;&lt;EOF\n# Install newuidmap &amp; newgidmap binaries\napt-get install -y uidmap\nEOF\n########## END ##########\n</code></pre>\n<p>输入提示的这行命令：</p>\n<pre><code class=\"language-bash\">sudo sh -eux &lt;&lt;EOF\n# Install newuidmap &amp; newgidmap binaries\napt-get install -y uidmap\nEOF\n</code></pre>\n<p>安装完成后，再次执行 <code>dockerd-rootless-setuptool.sh install</code></p>\n<p>以后操作 docker 服务，要加上 <code>--user</code></p>\n<pre><code class=\"language-bash\">systemctl --user start docker.service\n</code></pre>\n<h2 id=\"配置\">配置</h2>\n<p>rootless 模式下：</p>\n<ul>\n<li>所有 Docker 命令都要在<strong>安装 Rootless 的普通用户</strong>下执行（不要用 root）；</li>\n<li>如果重启服务器后 Docker 没自动启动，执行：<code>systemctl --user enable --now docker</code>；</li>\n<li>数据备份要找 <code>~/.local/share/docker</code> 目录（而非 <code>/var/lib/docker</code>）。</li>\n</ul>\n<h3 id=\"镜像加速器\">镜像加速器</h3>\n<p>默认情况下，Rootless Docker 的配置文件存放在当前用户的 <strong>XDG 配置目录</strong> 下，路径是：<code>~/.config/docker/daemon.json</code></p>\n<pre><code class=\"language-bash\"># 先创建目录（如果不存在）\nmkdir -p ~/.config/docker\n\n# 编辑配置文件（用 nano 或 vim 都可以）\nnano ~/.config/docker/daemon.json\n</code></pre>\n<p>配置加速器</p>\n<pre><code class=\"language-json\">{\n  \"registry-mirrors\": [\"https://你的阿里云镜像加速地址.mirror.aliyuncs.com\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"100m\",\n    \"max-file\": \"3\"\n  }\n}\n</code></pre>\n<p>注意：之前大部分稳定好用的加速器都停止服务了，现在就没法推荐啥，大家各凭本事吧。</p>\n<h3 id=\"解决-无法绑定-1-1023-端口-的问题\">解决 “无法绑定 1-1023 端口” 的问题</h3>\n<p>需要给当前用户 “绑定低端口” 的权限：</p>\n<pre><code class=\"language-bash\"># 给当前用户授权绑定 1-1023 端口（仅对当前会话生效）\nsudo sysctl net.ipv4.ip_unprivileged_port_start=0\n\n# 永久生效（重启后也有效）\necho \"net.ipv4.ip_unprivileged_port_start=0\" | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p  # 立即生效\n</code></pre>\n<p>执行后，你就能正常映射 80、443 等端口了。</p>\n<h3 id=\"重启生效\">重启生效</h3>\n<p>Rootless 模式的 Docker 重启命令和系统级不同，执行：</p>\n<pre><code class=\"language-bash\"># 重启当前用户的 Docker 服务\nsystemctl --user restart docker\n\n# 验证配置是否生效\ndocker info\n# 能在 \"Registry Mirrors\" 部分看到你配置的镜像加速地址就是成功的\n</code></pre>\n<p>正常输出示例：</p>\n<pre><code class=\"language-plaintext\">Rootless: true\nRegistry Mirrors:\n https://你的阿里云镜像加速地址.mirror.aliyuncs.com/\n</code></pre>\n<h3 id=\"rootless-模式不支持的配置项\">Rootless 模式不支持的配置项</h3>\n<p>部分系统级配置在 Rootless 下无效（因为没有 root 权限），比如：</p>\n<ul>\n<li><code>iptables: false</code>（网络规则由 slirp4netns 管理，而非 iptables）；</li>\n<li><code>storage-driver: overlay2</code>（默认已启用，无需手动配置）；</li>\n<li>远程 API 相关配置（如 <code>hosts: [\"tcp://0.0.0.0:2375\"]</code>，Rootless 下不建议开启）。</li>\n<li>任何涉及系统级目录（如<code>/var/run/docker.sock</code>）的配置。</li>\n</ul>\n<h2 id=\"volume问题\">volume问题</h2>\n<p>切换到 rootless 之后，我还发现了 swag 的 config 无法读写了。</p>\n<p>swag 的 compose.yaml 配置是这样：</p>\n<pre><code class=\"language-yaml\">services:\n  swag:\n    image: linuxserver/swag\n    container_name: swag\n    cap_add:\n      - NET_ADMIN\n    environment:\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - ./config:/config\n</code></pre>\n<p><strong>rootless Docker 里，容器内的 UID=1000 ≠ 宿主机的 UID=1000</strong></p>\n<p>所以 <strong>SWAG 在容器里 chown 了 <code>/config</code>，宿主机看到的是一个“映射后的陌生 UID（100999）”</strong></p>\n<h3 id=\"解决方法\">解决方法</h3>\n<p>rootless 官方推荐使用命名卷，但我要经常修改 config 里的文件，这个肯定不现实。</p>\n<p>那么还有一个方法，使用 ACL 放行。</p>\n<p>先安装相关工具：</p>\n<pre><code class=\"language-bash\">sudo apt update\nsudo apt install -y acl\n</code></pre>\n<p>在 swag 目录下执行</p>\n<pre><code class=\"language-bash\">setfacl -m u:ecs-user:rwx config\nsetfacl -R -m u:ecs-user:rwx config\nsetfacl -d -m u:ecs-user:rwx config\n</code></pre>\n<p>验证：</p>\n<pre><code class=\"language-bash\">getfacl config | sed -n '1,20p'\n</code></pre>\n<p>看到类似：</p>\n<pre><code>user::rwx\nuser:ecs-user:rwx\ngroup::r-x\nmask::rwx\nother::r-x\n</code></pre>\n<h2 id=\"小结\">小结</h2>\n<p>Rootless 模式虽比普通 Docker 配置稍繁琐，但能从根本上降低容器逃逸风险，尤其适合对外提供服务的生产服务器。核心总结：</p>\n<ol>\n<li>安装：结合清华镜像源解决国内下载问题，优先用普通用户安装 Rootless 模式；</li>\n<li>权限：禁止暴露 Docker 远程 API，给普通用户授权低端口绑定权限即可满足日常使用；</li>\n<li>配置：牢记 Rootless 模式的配置文件、数据目录均在用户目录下，与系统级 Docker 区分开；</li>\n<li>安全：即便开启 Rootless，运行容器时仍需注意服务安全（如 Redis 加密码、安全组限制端口访问）。</li>\n</ol>\n<p>此次踩坑让我深刻意识到：服务器安全无小事，哪怕是 Docker 这样的基础工具，也需从权限层面做好最小化管控，才能避免被挖矿木马等恶意程序趁虚而入。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 20:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">98</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "“老东西，你懦弱了”——关于Vibe Coding与传统开发",
      "link": "https://www.cnblogs.com/SilverGo/p/19626693",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/SilverGo/p/19626693\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 17:51\">\n    <span>“老东西，你懦弱了”——关于Vibe Coding与传统开发</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>鄙人在昨天刷视频的时候，意外刷到了这样的一个video：<br />\n一幅梗图，列举了2025年和2023年的两套开发工具：<br />\n2025年，我们用TRAE、Claude、Copilot、Windows 11，<br />\n2023年，我们用Clion、IDEA、Vim、Emacs、perf、lldb、gdb、Linux。<br />\n文案是：“老东西，你懦弱了！”</p>\n<h1 id=\"_\"></h1>\n<p>从效率来讲，毫无疑问，2025年的这一套工具不仅开发效率大幅上涨，时间成本降低，从工具本身而言，其技术难度也上涨了。<br />\n但是，从程序员的角度而言，我们丧失了对底层的掌控，<br />\n2025年，动动嘴，什么都解决了。<br />\n2023年，一切都要自己动手。<br />\n2025年的我们，一切效率至上，我们利用AI，少写了很多原来需要自己写的代码，<br />\n可我们难道不应该想想，这真的对吗？</p>\n<p>我们应该问自己，当初为什么喜欢CS？<br />\n不就是因为CS本身的自由、解构与建构吗？<br />\n我们选择AI替我们写代码，是一种将未来交给黑盒的行为。<br />\n一旦出现了隐藏的、AI改不出来的错误，这些长期使用AI的“程序员”将直接傻眼。<br />\n程序员最终是要靠代码建构世界的，而不是PUA Agent的。</p>\n<p>但是完全摒弃AI也是不现实的，那么怎么权衡呢？<br />\n以下是鄙人的愚见：<br />\n1.将AI当作一个高级的手册<br />\n2.核心代码必须自己写<br />\n3.重复性的代码：比如补全某个switch，可以使用AI<br />\n4.架构讨论可以使用AI</p>\n<h1 id=\"结语\">结语</h1>\n<p>这篇文章非常短，而且因为时间原因，写的比较仓促，但是意思到了即可<br />\n在现在的AI时代，我们追求效率至上，但是我们更应该把持本心、坚守初心<br />\n长期完全依赖AI只会减弱自己的能力，否极泰来、物极必反，这是必然的<br />\n了解底层、在没有AI的情况下照样能够写出完美的代码，这才是程序员水平高的表现<br />\n谢谢阅读</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 17:51</span>&nbsp;\n<a href=\"https://www.cnblogs.com/SilverGo\">Ghost-Face</a>&nbsp;\n阅读(<span id=\"post_view_count\">205</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "小代码，大视野：评一个典型的“数学可视化 + 计算机图形学入门”的优秀案例(C++精灵库3D案例)",
      "link": "https://www.cnblogs.com/lixingqiu/p/19626608",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lixingqiu/p/19626608\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 16:43\">\n    <span>小代码，大视野：评一个典型的“数学可视化 + 计算机图形学入门”的优秀案例(C++精灵库3D案例)</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><span><span>​看视频在这里：https://www.douyin.com/video/7608839461102734592</span></span></p>\n<p><span><span>程序代码在最下面。</span></span></p>\n<p><span id=\"cke_bm_12069S\">&nbsp;</span><span id=\"cke_bm_12069S\">这份代码和视频展示了一个非常典型的“数学可视化 + 计算机图形学入门”的优秀案例。它不仅仅是一段能运行的代码，更是一个将抽象数学公式转化为直观视觉艺术的教学演示。</span></p>\n<p><em id=\"__mceDel\"><span id=\"cke_bm_12069S\"> 以下是对该程序及视频的多维度评论：</span></em></p>\n<h2>1. 技术实现与图形学原理</h2>\n<p>这段代码虽然简短，但完整实现了一个微型3D 渲染管线的核心逻辑，这对于 C++ 初学者来说非常有价值：参数化曲面建模：<br />\n代码核心在于那三行坐标计算公式：</p>\n<div class=\"cke_widget_wrapper cke_widget_block cke_widget_codeSnippet cke_widget_selected\">\n<pre class=\"cke_widget_element\"><code class=\"hljs language-cpp\">p.x =a * <span class=\"hljs-built_in\">cos(v) * <span class=\"hljs-built_in\">sin(u);\np.y =a * <span class=\"hljs-built_in\">cos(u) * <span class=\"hljs-built_in\">cos(v);\np.z = -a * <span class=\"hljs-built_in\">sin(v);</span></span></span></span></span></code></pre>\n<span class=\"cke_reset cke_widget_drag_handler_container\"><img class=\"cke_reset cke_widget_drag_handler lazyload\" height=\"15\" title=\"点击并拖拽以移动\" width=\"15\" /></span></div>\n<p>其中a=u。这是一个参数方程，通过&nbsp;u 和&nbsp;v 两个变量的变化生成三维空间中的点集。视频展示的形态类似于一个螺旋曲面或变形的圆锥面。这种将数学公式直接映射为几何形状的做法，是计算机图形学的基础。</p>\n<ul>\n<li>3D 变换（旋转）：</li>\n</ul>\n<p>rotateY 函数实现了标准的旋转矩阵运算。通过每一帧增加 rotate_angle，实现了物体绕 Y 轴的连续旋转动画。这是理解 3D 空间变换最直观的方式。</p>\n<ul>\n<li>透视投影（Perspective Projection）：</li>\n</ul>\n<p>project 函数中 double factor = scale / (2.0 + p.z); 是点睛之笔。它模拟了人眼“近大远小”的视觉效果。如果没有这一行，物体旋转时看起来会是平面的，加上这一行后，Z 轴的深度感立刻显现出来。</p>\n<ul>\n<li>双缓冲技术：</li>\n</ul>\n<p>screen.tracer(0) 和 screen.update() 的配合使用，意味着程序采用了双缓冲机制。先在后缓冲区绘制完所有点，再一次性显示到屏幕。这有效避免了画面绘制过程中的闪烁，保证了动画的流畅性。</p>\n<h2>2. 视觉效果与美学</h2>\n<p>&nbsp;</p>\n<ul>\n<li>点云风格（Point Cloud）：</li>\n</ul>\n<p>程序没有使用线条（Line）或多边形（Polygon）填充，而是使用了 dot(1) 绘制点。这种点云渲染风格不仅节省了计算量（不需要处理遮挡和光栅化），而且产生了一种复古的、类似示波器或早期矢量显示器的科技感。</p>\n<ul>\n<li>动态着色：</li>\n</ul>\n<p>pen.color(x+y) 这行代码非常巧妙。它没有使用复杂的纹理或光照模型，而是根据屏幕坐标(x,y) 的和来映射颜色。<br />\n优点：计算成本极低，且随着物体旋转，屏幕坐标变化，颜色也会随之流动，产生了一种彩虹般的流光效果，极大地增强了视觉吸引力。<br />\n缺点：颜色是绑定在屏幕空间而非物体表面的，所以颜色会随旋转“滑动”，但这恰恰形成了一种独特的动态美感。</p>\n<ul>\n<li>采样密度：</li>\n\n\n</ul>\n<p>u_steps 和 v_steps 均设为 250，意味着每帧要计算并绘制&nbsp;250×250=62,500&nbsp;个点。在 C++ 中这个计算量完全可以接受，视频中也确实展示了细腻且密集的曲面结构。</p>\n<h2>3. 教育意义与工具推广</h2>\n<p>&nbsp;</p>\n<ul>\n<li>降低 C++ 图形编程门槛：</li>\n\n\n</ul>\n<p>传统的 C++ 图形编程（如 OpenGL/DirectX）配置环境复杂，API 繁琐。视频下方的文字说明提到了 “C++ 精灵库” 和 DevC++。这表明该程序旨在通过封装好的简易库，让中学生或编程初学者能快速看到图形化成果，增强学习信心。</p>\n<ul>\n<li>跨学科融合：</li>\n\n\n</ul>\n<p>这个案例完美融合了数学（三角函数、参数方程）、物理（空间旋转）和计算机科学（循环、结构体、坐标映射）。它是 STEM 教育中非常好的素材。</p>\n<h2>4. 改进建议与思考</h2>\n<p>虽然程序运行效果很好，但如果想进一步优化或深入学习，可以考虑以下方向：</p>\n<ul>\n<li>深度缓冲（Z-Buffering）：</li>\n\n\n</ul>\n<p>目前的绘制顺序是固定的。如果曲面自身发生遮挡（例如旋转 180 度后，背面跑到前面），目前的逻辑可能会把背面的点画在正面的点上面，导致视觉穿帮。引入 Z 缓冲可以解决遮挡关系。</p>\n<ul>\n<li>光照模型：</li>\n\n\n</ul>\n<p>目前的颜色仅依赖坐标。如果引入法向量计算和简单的光照（如 Phong 模型），曲面的立体感会更强，能更清晰地看出凹凸结构。</p>\n<ul>\n<li>交互性：</li>\n\n\n</ul>\n<p>目前只能自动旋转。如果能通过鼠标拖动改变 rotate_angle，或者通过键盘改变参数a 的系数，用户就能实时探索不同参数下的曲面形态，互动性会大大增强。</p>\n<ul>\n<li>性能优化：</li>\n\n\n</ul>\n<p>虽然 6 万点不多，但如果要增加密度，可以考虑只绘制可见面，或者使用 GPU 加速（Shader），不过对于学习 CPU 逻辑来说，当前方案已经足够好。</p>\n<h2>总结</h2>\n<p>这是一个典型的“小代码，大视野”的优秀作品。<br />\n它证明了不需要庞大的游戏引擎，仅凭基础的 C++ 语法和数学知识，就能创造出令人惊叹的视觉艺术。对于视频作者而言，这不仅展示了编程能力，更展示了对数学之美的理解。对于观众而言，这是一个极佳的 C++ 图形化入门启蒙，能激发很多人对“代码如何创造世界”的好奇心。</p>\n<p>评分：☆☆☆☆☆&nbsp; (作为教学演示和数学可视化案例)</p>\n<div class=\"cnblogs_code\">\n<pre>#include <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">sprites.h</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">包含C++精灵库</span>\n#include &lt;cmath&gt;      <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 数学库（sin/cos/π等）</span>\n#include &lt;vector&gt;     <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 存储顶点坐标</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">\nScreen screen;\nSprite pen{</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">blank</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">};  \n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">const</span> <span style=\"color: rgba(0, 0, 255, 1);\">double</span> PI = M_PI;    <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 定义常量</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">double</span> rotate_angle = <span style=\"color: rgba(128, 0, 128, 1);\">0.0</span>;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 旋转角度增量（控制动画速度）</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">struct</span> Point3D {    <span style=\"color: rgba(0, 0, 255, 1);\">double</span> x, y, z;};  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 3D点结构体\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 3D点绕Y轴旋转（实现动态旋转效果）</span>\nPoint3D rotateY(Point3D p, <span style=\"color: rgba(0, 0, 255, 1);\">double</span><span style=\"color: rgba(0, 0, 0, 1);\"> angle) {\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> cos_a =<span style=\"color: rgba(0, 0, 0, 1);\"> cos(angle);\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> sin_a =<span style=\"color: rgba(0, 0, 0, 1);\"> sin(angle);\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> {\n        p.x </span>* cos_a - p.z *<span style=\"color: rgba(0, 0, 0, 1);\"> sin_a,\n        p.y,\n        p.x </span>* sin_a + p.z *<span style=\"color: rgba(0, 0, 0, 1);\"> cos_a\n    };\n}\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 透视投影：3D转2D（简化版，增强Z轴深度感）</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">void</span> project(Point3D p, <span style=\"color: rgba(0, 0, 255, 1);\">int</span>&amp; screen_x, <span style=\"color: rgba(0, 0, 255, 1);\">int</span>&amp; screen_y, <span style=\"color: rgba(0, 0, 255, 1);\">double</span> scale = <span style=\"color: rgba(128, 0, 128, 1);\">100.0</span><span style=\"color: rgba(0, 0, 0, 1);\">) {\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> factor = scale / (<span style=\"color: rgba(128, 0, 128, 1);\">2.0</span> + p.z);  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 透视因子（Z越大，投影越小）</span>\n    screen_x = static_cast&lt;<span style=\"color: rgba(0, 0, 255, 1);\">int</span>&gt;(p.x *<span style=\"color: rgba(0, 0, 0, 1);\"> factor);\n    screen_y </span>= static_cast&lt;<span style=\"color: rgba(0, 0, 255, 1);\">int</span>&gt;(p.y *<span style=\"color: rgba(0, 0, 0, 1);\"> factor);\n}\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">int</span><span style=\"color: rgba(0, 0, 0, 1);\"> main() {        \n    screen.title(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">作者：李兴球</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).tracer(<span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    pen.hide().pu();\n    \n     </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 遍历参数u和v，计算并绘制所有点</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">const</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> u_steps = <span style=\"color: rgba(128, 0, 128, 1);\">250</span>;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> u方向采样数（越多越精细）</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">const</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> v_steps =<span style=\"color: rgba(128, 0, 128, 1);\">250</span>;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> v方向采样数</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">double</span> u_inc = <span style=\"color: rgba(128, 0, 128, 1);\">2</span> * PI /<span style=\"color: rgba(0, 0, 0, 1);\"> u_steps;\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> v_inc = <span style=\"color: rgba(128, 0, 128, 1);\">2</span> * PI / v_steps;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> v范围-π~π，总跨度2π</span>\n   \n    <span style=\"color: rgba(0, 0, 255, 1);\">while</span><span style=\"color: rgba(0, 0, 0, 1);\"> (screen.exitonclick() ) {        \n        screen.clear();   </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 清空屏幕（每一帧重新绘制）           </span>\n        \n        <span style=\"color: rgba(0, 0, 255, 1);\">for</span> (<span style=\"color: rgba(0, 0, 255, 1);\">int</span> i = <span style=\"color: rgba(128, 0, 128, 1);\">0</span>; i &lt;= u_steps; ++<span style=\"color: rgba(0, 0, 0, 1);\">i) {\n            </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> u = i *<span style=\"color: rgba(0, 0, 0, 1);\"> u_inc;\n            </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> a = u;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> a = u（公式要求）</span>\n            <span style=\"color: rgba(0, 0, 255, 1);\">for</span> (<span style=\"color: rgba(0, 0, 255, 1);\">int</span> j = <span style=\"color: rgba(128, 0, 128, 1);\">0</span>; j &lt;= v_steps; ++<span style=\"color: rgba(0, 0, 0, 1);\">j) {\n                </span><span style=\"color: rgba(0, 0, 255, 1);\">double</span> v = -PI + j * v_inc;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> v从-π到π               </span>\n                Point3D p;   <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 计算原始3D坐标（蜗牛曲面公式）</span>\n                p.x =a * cos(v) *<span style=\"color: rgba(0, 0, 0, 1);\"> sin(u);\n                p.y </span>=a * cos(u) *<span style=\"color: rgba(0, 0, 0, 1);\"> cos(v);\n                p.z </span>= -a *<span style=\"color: rgba(0, 0, 0, 1);\"> sin(v);\n                </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 绕Y轴旋转，从而实现动态3D效果</span>\n                p =<span style=\"color: rgba(0, 0, 0, 1);\"> rotateY(p, rotate_angle);               \n                </span><span style=\"color: rgba(0, 0, 255, 1);\">int</span><span style=\"color: rgba(0, 0, 0, 1);\"> x, y;\n                project(p, x, y);   </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 投影到2D屏幕坐标</span>\n                <span style=\"color: rgba(0, 0, 255, 1);\">if</span>(x&gt;=<span style=\"color: rgba(128, 0, 128, 1);\">400</span> || x&lt;=-<span style=\"color: rgba(128, 0, 128, 1);\">400</span> || y&gt;=<span style=\"color: rgba(128, 0, 128, 1);\">300</span> || y&lt;= -<span style=\"color: rgba(128, 0, 128, 1);\">300</span>)<span style=\"color: rgba(0, 0, 255, 1);\">continue</span><span style=\"color: rgba(0, 0, 0, 1);\">; \n                pen.color(x</span>+y).go(x, y).dot(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>);  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 绘制当前点     </span>\n<span style=\"color: rgba(0, 0, 0, 1);\">            \n            }\n        }\n        screen.update();\n        rotate_angle </span>+= <span style=\"color: rgba(128, 0, 128, 1);\">0.02</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">if</span> (rotate_angle &gt; <span style=\"color: rgba(128, 0, 128, 1);\">2</span> * PI) rotate_angle -= <span style=\"color: rgba(128, 0, 128, 1);\">2</span> * PI;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 重置角度，避免溢出        </span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    }\n    \n    </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span> <span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">;    \n}</span></pre>\n</div>\n<p>&nbsp;</p>\n\n<span>\n<span>​</span></span>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-20 16:43</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lixingqiu\">李兴球</a>&nbsp;\n阅读(<span id=\"post_view_count\">76</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吊打OpenClaw！国产AI助理MindX开源：Token消耗砍至10%，还能养出专属数字分身",
      "link": "https://www.cnblogs.com/Ray-liang/p/19626557",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Ray-liang/p/19626557\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 15:56\">\n    <span>吊打OpenClaw！国产AI助理MindX开源：Token消耗砍至10%，还能养出专属数字分身</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>作为一名重度AI工具使用者，26年1月29日在OpenClaw爆火时我第一时间上手体验，初体验确实惊艳——能自动处理后台任务、对接海外社交工具，但这份新鲜感仅维持了两天：QWenChat羊毛薅光、单轮会话的Token用量飙升至680%，一至卡死！日常用GPT-4/Opus更是日均成本50+元，而且全程适配海外生态，微信/飞书/钉钉这些国内办公刚需工具完全不支持，越用越觉得「这根本不是给中国人设计的工具」。</p>\n<p>更让我难以接受的是，当下的AI助理全陷入了「算力堆砌=智能」的内卷：用顶级云端大模型处理查天气、记备忘这种基础任务，就像请院士算加减乘除，既浪费算力又让用户为无意义的Token买单，而且所有数据上云，隐私毫无保障。</p>\n<p>我想既然如此，不如做一款<strong>真正适配国内用户、低成本、保隐私、能进化</strong>的AI个人助理——于是我用了13天开发了MindX，我将其称之为【心智】！这是一款基于仿生大脑架构设计的轻量级智能体，主打本地运行、Token消耗直降90%、全中文生态适配，还能通过长时记忆+自助训练，慢慢养出专属于你的数字分身。</p>\n<p>现在MindX已全开源，支持GitHub/Gitee双端获取，配套官方文档站http://mindx.chat，8G内存就能跑、CPU即可完成模型训练，还完全兼容OpenClaw技能生态，不用重新开发就能直接复用！</p>\n<h2 id=\"为什么说openclaw不适合国内普通用户\">为什么说OpenClaw不适合国内普通用户？</h2>\n<p>先客观说，OpenClaw的产品理念确实超前，但其设计初衷完全围绕海外用户，国内用户用起来全是「痛点」：</p>\n<ol>\n<li><strong>烧钱无底洞</strong>：官方推荐GPT-4+Opus配置，日常写备忘、执行命令行都要调用云端大模型，普通用户根本用不起；</li>\n<li><strong>中文生态拉胯</strong>：仅支持WhatsApp/Telegram/Discord，微信/飞书/钉钉这些国内90%职场人必用的工具完全不兼容；虽然国内大厂都光速支持国内通信适配，但仍然绕不开“堆算力”这个死穴；</li>\n<li><strong>越用越慢</strong>：基础存储式记忆系统，数据积累越多检索越慢，毫无优化可言；（只要你细心翻找记忆文件大多是垃圾文字与垃圾代码）</li>\n<li><strong>隐私无保障</strong>：部分功能依赖云端运行，日常对话、行为习惯等敏感数据全程上云，存在泄露风险；</li>\n<li><strong>资源占用高</strong>：对硬件要求苛刻，普通个人电脑部署后卡顿明显，轻量化体验为零。（即时解释的语言与原生码最大的差异）</li>\n</ol>\n<p>而这些痛点，正是MindX从设计之初就重点解决的核心问题——<strong>我们不做「海外产品的平替」，而是做「为国内用户量身定制的AI助理」</strong>。</p>\n<h2 id=\"mindx核心优势7大亮点直击国内用户刚需\">MindX核心优势：7大亮点，直击国内用户刚需</h2>\n<h3 id=\"-成本腰斩token消耗仅10本地运行几乎零成本\">🔥 成本腰斩：Token消耗仅10%，本地运行几乎零成本</h3>\n<p>MindX最核心的设计是<strong>仿生大脑架构</strong>，复刻人类「潜意识+主意识」的思考模式，从根源上减少无效算力消耗：</p>\n<ul>\n<li><strong>潜意识层（左脑+右脑）</strong>：用500M轻量级本地模型（Qwen3:0.6b）处理查天气、发消息、执行命令行等基础任务，全程本地运行，<strong>零Token消耗、零云端成本</strong>；</li>\n<li><strong>主意识层</strong>：仅在处理编程、写方案、复杂推理等专业任务时，按需调用云端大模型，精准控费；</li>\n<li>实测对比：同场景下，OpenClaw日均Token成本50元，MindX日均成本低至0.5元，核心场景成本直降99%，算力利用率提升80%+。</li>\n</ul>\n<p>为了防止被说我吹牛X，MindX的 Dashboad中有针对各个模型的Token消耗统计图表；各位可以验证钱是不是都烧在了“垃圾话”上面。</p>\n<h3 id=\"-全中文生态微信飞书钉钉qq全覆盖办公生活无缝衔接\">📱 全中文生态：微信/飞书/钉钉/QQ全覆盖，办公生活无缝衔接</h3>\n<p>这是MindX针对国内用户的核心定制化亮点，彻底解决OpenClaw的生态适配问题：</p>\n<ul>\n<li>支持<strong>飞书、微信、钉钉、QQ</strong>四大国内主流办公/社交工具，同时兼容WhatsApp/Telegram/iMessage等海外平台，真正实现全渠道消息统一处理；</li>\n<li>毫秒级响应国内平台消息，无需额外配置开发者工具，扫码即可绑定，职场人不用再在多个APP间切换，效率翻倍。</li>\n</ul>\n<p>打通国内外通信平台，是不是就可以让AI之间毫无阻隔地“畅聊”？</p>\n<h3 id=\"-隐私兜底100本地运行数据永不离身\">🔒 隐私兜底：100%本地运行，数据永不离身</h3>\n<p>个人助理掌握着我们的日常习惯、工作内容、隐私信息，数据安全是底线：</p>\n<ul>\n<li>MindX支持Ollama本地模型部署，<strong>所有对话、记忆、技能执行均在本地电脑完成</strong>，数据不上传任何云端，断网也能正常使用；</li>\n<li>记忆数据、训练模型全部存储在本地目录，用户可自主掌控，彻底告别数据泄露风险。</li>\n</ul>\n<h3 id=\"-长时记忆系统越用越懂你告别ai健忘症\">🧠 长时记忆系统：越用越懂你，告别AI「健忘症」</h3>\n<p>不同于OpenClaw的基础存储，MindX的记忆系统完全复刻人类记忆机制，分为<strong>永久性记忆、长期性记忆、短期性记忆</strong>，实现「学习-整理-遗忘-唤醒」的完整生命周期：</p>\n<ul>\n<li>自动从对话中提取关键信息，生成记忆摘要，去重清洗无效数据，检索速度随使用次数提升，<strong>越用越快</strong>（实测1万条记忆检索仅0.1秒）；</li>\n<li>基于「时间+重复+强调」复合权重排序，常提的信息权重更高，无需反复跟AI叮嘱同一件事，真正实现「一次告知，永久记住」。</li>\n</ul>\n<h3 id=\"-自主进化cpu即可训练6个月养出专属数字分身\">🚀 自主进化：CPU即可训练，6个月养出专属数字分身</h3>\n<p>MindX最特别的能力，就是能通过<strong>LoRA增量训练</strong>，基于你的对话数据持续优化，慢慢变成「另一个你」：</p>\n<ul>\n<li>500M轻量级底模，无需高端GPU，普通电脑的CPU就能完成训练，门槛极低；</li>\n<li>夜间后台自动训练，不占用白天使用时间，完全无感；</li>\n<li>进化时间线清晰：1周理解你的基本偏好，1个月熟悉你的工作习惯，3个月能预判你的需求，6个月彻底成为你的专属数字分身，贴合你的表达风格、思考逻辑。</li>\n</ul>\n<h3 id=\"️-生态兼容轻量部署零基础上手无缝复用openclaw技能\">🛠️ 生态兼容+轻量部署：零基础上手，无缝复用OpenClaw技能</h3>\n<p>为了降低用户使用和开发者贡献门槛，MindX在生态和部署上做了极致优化：</p>\n<ul>\n<li><strong>完全兼容OpenClaw技能</strong>：直接复制OpenClaw的技能即可使用，无需修改，支持任意编程语言CLI开发，技能安装、卸载一键完成；</li>\n<li><strong>轻量级部署</strong>：Go语言原生开发，编译后仅单一可执行文件，无大型数据库依赖，8G内存就能流畅运行，macOS/Linux全适配（Windows版本即将推出）；</li>\n<li><strong>一键安装</strong>：提供预编译包+一键安装脚本，新手无需编译源码，复制命令回车即可完成安装，5分钟上手使用。</li>\n</ul>\n<h3 id=\"-全链路灵活兼容从本地技能到多模型云边协同兼容任意智能体\">⚡ 全链路灵活兼容：从本地技能到多模型云边协同，兼容任意智能体</h3>\n<p>这是MindX最硬核的技术突破，彻底打破了传统AI助理的“封闭围墙”，实现了<strong>「端侧足够省、云端足够强、生态足够广」</strong>的全场景覆盖：</p>\n<ol>\n<li><strong>技能双引擎：本地与MCP无缝切换</strong><br />\nMindX同时原生支持<strong>本地技能</strong>（离线运行、极致隐私）与<strong>MCP协议技能</strong>（云端协同、能力丰富），无需修改代码，即可根据网络环境和隐私需求自动切换执行策略。</li>\n<li><strong>端侧极致量化：小模型也能办大事</strong><br />\n在端侧，MindX深度优化推理引擎，能让<strong>最小的量化模型</strong>（如Qwen3:0.6b）发挥出超出预期的能力，在完成日常任务时，响应速度接近云端大模型，且几乎不占用系统资源。</li>\n<li><strong>云端多模型协同：不做“单模型依赖”</strong><br />\n不同于其他工具仅支持1-2种云端大模型，MindX支持<strong>任意多种大模型同时工作</strong>。你可以为“写代码”绑定DeepSeek，为“写文案”绑定Claude，为“翻译”绑定Volcengine，MindX会根据任务类型智能调度最优模型，真正做到「术业有专攻」。</li>\n<li><strong>智能体即插即用：迁移成本为零</strong><br />\nMindX将智能体完全抽象为「AI助理的能力模型」。这意味着，你在其他平台训练好的、常用的智能体，都可以<strong>直接迁移到MindX中运行</strong>。无需重新调教，你的“老伙计”就能在MindX的仿生大脑架构下，结合长时记忆和本地技能，发挥出比原生平台更强的战斗力。</li>\n</ol>\n<h2 id=\"mindx-vs-openclaw全方位实测对比谁更适合国内用户\">MindX vs OpenClaw：全方位实测对比，谁更适合国内用户？</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">评估维度</th>\n<th style=\"text-align: left;\">MindX（国产定制）</th>\n<th style=\"text-align: left;\">OpenClaw（海外设计）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>日均Token成本</strong></td>\n<td style=\"text-align: left;\">~0.5元（本地优先，按需调用云端）</td>\n<td style=\"text-align: left;\">~50元（依赖GPT-4/Opus云端大模型）</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>中文生态适配</strong></td>\n<td style=\"text-align: left;\">微信/飞书/钉钉/QQ全覆盖，毫秒级响应</td>\n<td style=\"text-align: left;\">仅支持海外平台，国内工具完全不兼容</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>记忆系统</strong></td>\n<td style=\"text-align: left;\">仿生长时记忆，自动整理，越用越快</td>\n<td style=\"text-align: left;\">基础存储，数据越多越慢，无优化</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>数据隐私</strong></td>\n<td style=\"text-align: left;\">100%本地运行，数据不上传云端</td>\n<td style=\"text-align: left;\">部分功能依赖云端，存在隐私泄露风险</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>自助训练</strong></td>\n<td style=\"text-align: left;\">支持LoRA增量训练，CPU即可运行，自主进化</td>\n<td style=\"text-align: left;\">不支持，始终依赖通用云端模型</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>硬件要求</strong></td>\n<td style=\"text-align: left;\">轻量级，8G内存即可流畅运行</td>\n<td style=\"text-align: left;\">资源占用高，普通电脑部署卡顿明显</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>技能生态</strong></td>\n<td style=\"text-align: left;\">兼容本地技能+MCP技能+OpenClaw技能</td>\n<td style=\"text-align: left;\">插件系统需特定格式，开发门槛较高</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>模型支持</strong></td>\n<td style=\"text-align: left;\"><strong>端侧最小量化模型 + 云端任意多模型协同</strong></td>\n<td style=\"text-align: left;\">仅支持特定云端大模型，选择受限</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>智能体迁移</strong></td>\n<td style=\"text-align: left;\"><strong>支持，可直接迁移任意智能体运行</strong></td>\n<td style=\"text-align: left;\">不支持，生态封闭</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>部署方式</strong></td>\n<td style=\"text-align: left;\">单一二进制文件，一键安装，本地无服务器依赖</td>\n<td style=\"text-align: left;\">本地/云端部署，配置复杂，依赖较多</td>\n</tr>\n</tbody>\n</table>\n<p><strong>结论</strong>：OpenClaw适合海外用户、不计成本的尝鲜者；而MindX更适合国内普通开发者、职场人，兼顾<strong>低成本、高隐私、全生态、超灵活</strong>，是日常使用的最优解。</p>\n<h2 id=\"5分钟快速上手零基础也能搞定8g内存就能跑\">5分钟快速上手：零基础也能搞定，8G内存就能跑</h2>\n<h3 id=\"前置条件\">前置条件</h3>\n<ul>\n<li>操作系统：macOS / Linux（Windows适配中）</li>\n<li>内存：8GB+（推荐16GB）</li>\n<li>网络：首次安装需下载模型（约2-5GB），后续可离线使用</li>\n</ul>\n<h3 id=\"步骤1安装mindx两种方式任选\">步骤1：安装MindX（两种方式任选）</h3>\n<h4 id=\"方式1预编译包推荐无需编译\">方式1：预编译包（推荐，无需编译）</h4>\n<pre><code class=\"language-bash\"># 下载最新版本（前往GitHub Releases获取链接）\nwget https://github.com/DotNetAge/mindx/releases/download/v0.1.0/mindx-v0.1.0-linux-amd64.tar.gz\n\n# 解压并安装\ntar -xzf mindx-v0.1.0-linux-amd64.tar.gz\ncd mindx-v0.1.0\nchmod +x install.sh &amp;&amp; ./install.sh\n</code></pre>\n<p>MindX会帮助你自动安装所有必要运行本地模型与依赖的软件，如ollama;</p>\n<h4 id=\"方式2从源码编译\">方式2：从源码编译</h4>\n<pre><code class=\"language-bash\"># 克隆仓库\ngit clone https://github.com/DotNetAge/mindx.git\ncd mindx\n\n# 一键构建并安装\nmake install\n</code></pre>\n<h3 id=\"步骤2启动mindx开始使用\">步骤2：启动MindX，开始使用</h3>\n<pre><code class=\"language-bash\">mindx start          # 启动后端服务\nmindx dashboard      # 打开Web界面（默认地址：http://localhost:911）\n# 或使用终端极简界面\nmindx tui\n</code></pre>\n<p>打开Web界面后，扫码绑定社交账号、选择本地模型，即可开始体验——查天气、同步飞书待办、执行命令行，全程本地运行，零Token消耗！</p>\n<h2 id=\"加入我们前100名核心贡献者招募共建国产ai助理生态\">加入我们：前100名核心贡献者招募，共建国产AI助理生态</h2>\n<p>MindX是全开源项目，基于MIT协议发布，初衷是打破海外AI工具的垄断，做一款真正属于中国人、让普通人用得起的AI个人助理。</p>\n<p>时间紧，任务重我只是用了过年这段时间拼老命地写出了整个体系，MindX现在只是个婴儿，还有很多的需要完善地方，更需要有更多与我有着同样初心的同道们加入到这个项目。为推动并争取让MindX成为属于我们国人自己的AI助理。</p>\n<p>目前项目正处于高速迭代期，<strong>诚邀前100名开发者加入核心贡献者阵营</strong>，无论你是会写代码的开发者、擅长写文档的内容创作者，还是仅想提建议的普通用户，都能参与，核心权益包括：</p>\n<ol>\n<li>✨ 专属身份标识：在GitHub README/官方文档站http://mindx.chat永久展示用户名；</li>\n<li>🎁 优先体验新功能：所有新版本、新功能优先体验，一对一技术支持；</li>\n<li>📈 产品决策权：参与项目路线规划，投票决定后续开发方向，你的想法能决定MindX的进化；</li>\n<li>🤝 生态共建者：加入核心开发者群，与同频开发者交流，共同打造国产AI助理生态。</li>\n</ol>\n<h3 id=\"贡献方式零门槛任选其一即可\">贡献方式（零门槛，任选其一即可）</h3>\n<ol>\n<li><strong>文档贡献</strong>：修正文档错别字、补充安装步骤截图、完善FAQ；</li>\n<li><strong>反馈建议</strong>：提交Bug反馈、功能建议，参与GitHub Discussions讨论；</li>\n<li><strong>代码贡献</strong>：修复新手友好型Bug、开发新功能、优化代码性能（仓库已标注good first issue）；</li>\n<li><strong>生态建设</strong>：开发专属技能、适配更多国内工具、分享使用教程。</li>\n</ol>\n<h3 id=\"参与路径\">参与路径</h3>\n<ol>\n<li>GitHub仓库：<a href=\"https://github.com/DotNetAge/mindx\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/DotNetAge/mindx</a></li>\n<li>Gitee仓库：<a href=\"https://gitee.com/DotNetAge/mindx\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/DotNetAge/mindx</a></li>\n<li>官方文档站：<a href=\"http://mindx.chat\" rel=\"noopener nofollow\" target=\"_blank\">http://mindx.chat</a></li>\n<li>贡献指南：前往仓库查看CONTRIBUTING.md，提交PR即可参与</li>\n</ol>\n<h2 id=\"写在最后\">写在最后</h2>\n<p>做MindX不是为了对标某一款产品，而是想打破当下AI行业「烧钱式内卷」的怪圈——AI助理的核心价值应该是「懂你、护你、不耗你」，而不是成为厂商收割Token的工具。（更希望不要被认为是广告贴给屏了，MindX是不为钱不为利只是为了靠谱的代码与项目）</p>\n<p>我们希望通过开源的方式，聚拢更多同频的开发者，一起打造一款<strong>低成本、高隐私、全生态、能进化</strong>的国产AI助理，让每个普通人都能享受到AI技术带来的便利，而不是被高昂的成本和封闭的生态拒之门外。</p>\n<p>现在，MindX的第一版已经落地，后续还会持续优化Windows适配、新增更多国内工具对接、完善记忆系统和训练能力，所有的进化，都期待有你的参与！</p>\n<p>最后，求个Star✨，你的支持，是我们持续开发的最大动力！<br />\nGitHub：<a href=\"https://github.com/DotNetAge/mindx\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/DotNetAge/mindx</a><br />\n官方文档：<a href=\"http://mindx.chat\" rel=\"noopener nofollow\" target=\"_blank\">http://mindx.chat</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 15:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Ray-liang\">Ray Liang</a>&nbsp;\n阅读(<span id=\"post_view_count\">126</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "关于 MicroPython + ESP32-S3 的使用流程",
      "link": "https://www.cnblogs.com/tokepson/p/19628425",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tokepson/p/19628425\" id=\"cb_post_title_url\" title=\"发布于 2026-02-22 01:30\">\n    <span>关于 MicroPython + ESP32-S3 的使用流程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>好的！我来帮你从零开始完整梳理 <strong>MicroPython + ESP32-S3</strong> 的开发流程。</p>\n<h2 id=\"-完整搭建流程\">📋 <strong>完整搭建流程</strong></h2>\n<h3 id=\"第一步准备工作\"><strong>第一步：准备工作</strong></h3>\n<h4 id=\"11-硬件准备\">1.1 硬件准备</h4>\n<ul>\n<li>✅ ESP32-S3 开发板</li>\n<li>✅ USB 数据线（最好带数据传输功能）</li>\n<li>✅ Windows电脑</li>\n</ul>\n<h4 id=\"12-软件准备\">1.2 软件准备</h4>\n<pre><code class=\"language-bash\"># 1. 安装 Python（如果还没安装）\n# 访问 https://www.python.org/downloads/ 下载安装\n# 安装时勾选 \"Add Python to PATH\"\n\n# 2. 验证Python安装\npython --version\n\n# 3. 安装 esptool（刷写工具）\npip install esptool\n\n# 4. 安装串口驱动（根据你的开发板）\n# CP210x驱动：https://www.silabs.com/developers/usb-to-uart-bridge-vcp-drivers\n# CH340驱动：http://www.wch.cn/download/CH341SER_EXE.html\n</code></pre>\n<h3 id=\"第二步下载固件\"><strong>第二步：下载固件</strong></h3>\n<h4 id=\"21-下载-micropython-固件\">2.1 下载 MicroPython 固件</h4>\n<ul>\n<li>官方下载地址：<a href=\"https://micropython.org/download/\" rel=\"noopener nofollow\" target=\"_blank\">https://micropython.org/download/</a></li>\n<li>选择 <strong>ESP32S3</strong> 或 <strong>GENERIC_S3</strong></li>\n<li>下载 <code>.bin</code> 文件（你已经有：<code>ESP32_GENERIC_S3-20251209-v1.27.0.bin</code>）</li>\n</ul>\n<h3 id=\"第三步刷写固件\"><strong>第三步：刷写固件</strong></h3>\n<h4 id=\"31-连接开发板\">3.1 连接开发板</h4>\n<ol>\n<li>用USB线连接ESP32-S3到电脑</li>\n<li>按住开发板上的 <strong>BOOT</strong> 按钮</li>\n<li>按一下 <strong>RESET</strong> 按钮（或重新插拔USB）</li>\n<li>松开 <strong>BOOT</strong> 按钮</li>\n<li>此时开发板进入刷写模式</li>\n</ol>\n<h4 id=\"32-查找串口号\">3.2 查找串口号</h4>\n<pre><code class=\"language-bash\"># 查看可用的串口\npython -m serial.tools.list_ports\n# 或打开设备管理器查看 \"端口(COM和LPT)\"\n# 通常显示为 COM3、COM4 等\n</code></pre>\n<h4 id=\"33-擦除flash重要\">3.3 擦除Flash（重要！）</h4>\n<pre><code class=\"language-bash\"># 替换 COM4 为你的实际端口\npython -m esptool --chip esp32s3 --port COM4 erase_flash\n</code></pre>\n<h4 id=\"34-刷写固件\">3.4 刷写固件</h4>\n<pre><code class=\"language-bash\"># 注意修改路径和端口\npython -m esptool --chip esp32s3 --port COM4 write_flash 0x0 \"C:\\Users\\16673\\Desktop\\ESP32_GENERIC_S3-20251209-v1.27.0.bin\"\n</code></pre>\n<h3 id=\"第四步安装开发环境\"><strong>第四步：安装开发环境</strong></h3>\n<h4 id=\"41-安装-thonny-ide推荐新手\">4.1 安装 Thonny IDE（推荐新手）</h4>\n<ol>\n<li>下载地址：<a href=\"https://thonny.org/\" rel=\"noopener nofollow\" target=\"_blank\">https://thonny.org/</a></li>\n<li>安装后打开</li>\n<li>配置：\n<ul>\n<li>菜单栏：运行 → 选择解释器</li>\n<li>选择 <strong>MicroPython (ESP32)</strong></li>\n<li>端口选择 <strong>COM4</strong>（或你的端口）</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"42-或安装命令行工具\">4.2 或安装命令行工具</h4>\n<pre><code class=\"language-bash\"># 安装 ampy（文件传输）\npip install adafruit-ampy\n\n# 安装 rshell（交互式shell）\npip install rshell\n\n# 安装 picocom/mRemoteNG（串口工具）\n</code></pre>\n<h3 id=\"第五步测试连接\"><strong>第五步：测试连接</strong></h3>\n<h4 id=\"51-使用-thonny-测试\">5.1 使用 Thonny 测试</h4>\n<pre><code class=\"language-python\"># 在Thonny的Shell中看到 &gt;&gt;&gt; 提示符后输入：\nprint(\"Hello ESP32-S3!\")\n\n# 查看固件信息\nimport sys\nprint(sys.version)\nprint(sys.implementation)\n</code></pre>\n<h4 id=\"52-使用命令行测试\">5.2 使用命令行测试</h4>\n<pre><code class=\"language-bash\"># 使用 rshell 连接\nrshell -p COM4\n\n# 或在Python中直接连接\npython\n&gt;&gt;&gt; import serial\n&gt;&gt;&gt; ser = serial.Serial('COM4', 115200)\n&gt;&gt;&gt; ser.write(b'\\r\\n')\n&gt;&gt;&gt; ser.readline()\n</code></pre>\n<h3 id=\"第六步基础示例代码\"><strong>第六步：基础示例代码</strong></h3>\n<h4 id=\"61-第一个程序led闪烁\">6.1 第一个程序：LED闪烁</h4>\n<pre><code class=\"language-python\"># main.py - 保存到ESP32上会自动运行\nfrom machine import Pin\nimport time\n\n# ESP32-S3 板载LED通常在引脚 48（不同板子可能不同）\nled = Pin(48, Pin.OUT)\n\nwhile True:\n    led.value(1)  # 点亮\n    time.sleep(0.5)\n    led.value(0)  # 熄灭\n    time.sleep(0.5)\n</code></pre>\n<h4 id=\"62-上传代码到esp32\">6.2 上传代码到ESP32</h4>\n<pre><code class=\"language-bash\"># 使用 ampy 上传\nampy --port COM4 put main.py\n\n# 或使用 Thonny：\n# 文件 → 保存 → MicroPython设备\n</code></pre>\n<h3 id=\"第七步进阶功能\"><strong>第七步：进阶功能</strong></h3>\n<h4 id=\"71-wifi连接\">7.1 WiFi连接</h4>\n<pre><code class=\"language-python\"># wifi_connect.py\nimport network\nimport time\n\ndef connect_wifi(ssid, password):\n    wlan = network.WLAN(network.STA_IF)\n    wlan.active(True)\n    \n    if not wlan.isconnected():\n        print('正在连接WiFi...')\n        wlan.connect(ssid, password)\n        \n        # 等待连接\n        timeout = 10\n        while not wlan.isconnected() and timeout &gt; 0:\n            time.sleep(1)\n            timeout -= 1\n            print(f'等待中... {timeout}s')\n    \n    if wlan.isconnected():\n        print('WiFi连接成功！')\n        print('IP地址:', wlan.ifconfig()[0])\n        return True\n    else:\n        print('WiFi连接失败！')\n        return False\n\n# 使用\nconnect_wifi('你的WiFi名称', '你的WiFi密码')\n</code></pre>\n<h4 id=\"72-web服务器示例\">7.2 Web服务器示例</h4>\n<pre><code class=\"language-python\"># webserver.py\nimport socket\nimport network\n\n# 连接WiFi（接上面的代码）\nconnect_wifi('你的WiFi', '你的密码')\n\n# 创建简单的Web服务器\naddr = socket.getaddrinfo('0.0.0.0', 80)[0][-1]\ns = socket.socket()\ns.bind(addr)\ns.listen(1)\n\nprint('服务器地址:', addr)\n\nwhile True:\n    cl, addr = s.accept()\n    print('客户端连接:', addr)\n    \n    request = cl.recv(1024)\n    print('请求内容:', request)\n    \n    # 发送HTTP响应\n    response = \"\"\"HTTP/1.1 200 OK\nContent-Type: text/html\n\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;ESP32-S3&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello from ESP32-S3!&lt;/h1&gt;\n&lt;p&gt;MicroPython Web Server&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\"\"\"\n    cl.send(response)\n    cl.close()\n</code></pre>\n<h4 id=\"73-读取传感器\">7.3 读取传感器</h4>\n<pre><code class=\"language-python\"># sensor.py\nfrom machine import Pin, ADC\nimport time\n\n# 读取模拟值（ADC）\nadc = ADC(Pin(4))  # 使用GPIO4作为ADC\nadc.atten(ADC.ATTN_11DB)  # 设置量程 0-3.3V\n\nwhile True:\n    # 读取数字值 (0-4095)\n    value = adc.read()\n    \n    # 转换为电压\n    voltage = value * 3.3 / 4095\n    \n    print(f'ADC值: {value}, 电压: {voltage:.2f}V')\n    time.sleep(1)\n</code></pre>\n<h3 id=\"第八步实用技巧\"><strong>第八步：实用技巧</strong></h3>\n<h4 id=\"81-开机自动运行\">8.1 开机自动运行</h4>\n<ul>\n<li>将主程序保存为 <strong>main.py</strong> 到ESP32</li>\n<li>重启开发板会自动运行</li>\n</ul>\n<h4 id=\"82-释放内存\">8.2 释放内存</h4>\n<pre><code class=\"language-python\">import gc\ngc.collect()  # 手动垃圾回收\ngc.mem_free()  # 查看剩余内存\n</code></pre>\n<h4 id=\"83-文件管理命令\">8.3 文件管理命令</h4>\n<pre><code class=\"language-bash\"># 列出文件\nampy --port COM4 ls\n\n# 删除文件\nampy --port COM4 rm main.py\n\n# 下载文件到电脑\nampy --port COM4 get main.py &gt; backup_main.py\n</code></pre>\n<h3 id=\"常见问题解决\"><strong>常见问题解决</strong></h3>\n<ol>\n<li>\n<p><strong>无法连接COM口</strong></p>\n<ul>\n<li>检查驱动是否正确安装</li>\n<li>尝试换USB线</li>\n<li>重新插拔开发板</li>\n</ul>\n</li>\n<li>\n<p><strong>刷写失败</strong></p>\n<ul>\n<li>确保按住BOOT按钮</li>\n<li>先执行 erase_flash</li>\n<li>检查端口号是否正确</li>\n</ul>\n</li>\n<li>\n<p><strong>上传文件失败</strong></p>\n<ul>\n<li>确保开发板已经启动完成</li>\n<li>不要同时打开多个串口程序</li>\n</ul>\n</li>\n</ol>\n<p>需要我详细解释某个步骤，或者有其他问题吗？</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-22 01:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tokepson\">TokE648</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Manim CE v0.20.0 发布：动画构建更丝滑，随机性终于“可控”了！",
      "link": "https://www.cnblogs.com/wang_yb/p/19628043",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wang_yb/p/19628043\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 17:34\">\n    <span>🚀 Manim CE v0.20.0 发布：动画构建更丝滑，随机性终于“可控”了！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家新年好！<code>Manim Community Edition</code> (CE) 刚刚发布了里程碑式的 <strong>v0.20.0</strong> 版本。</p>\n<p>如果你觉得以前写 <code>updater</code>（更新程序）太啰嗦，或者每次渲染随机场景结果都不一样让你抓狂，那么这次更新绝对是为你准备的！</p>\n<p>本次更新不仅重构了核心组件，还带来了一些超甜的“语法糖”。</p>\n<p>下面我们来看看这次升级的亮点，以及它们如何改变你的编码方式。</p>\n<h1 id=\"-亮点一mobjectalways--告别繁琐的-lambda\">✨ 亮点一：<code>Mobject.always</code> —— 告别繁琐的 Lambda</h1>\n<p>在制作动画时，我们经常需要让一个物体“永远”跟随另一个物体（比如标签永远在点的上方）。</p>\n<p>以前，你需要使用 <code>add_updater</code> 配合 <code>lambda</code> 函数，代码看起来又长又乱。</p>\n<p><code>v0.20.0</code> 引入了神奇的 <code>.always</code> 属性，让这一切变得符合直觉。</p>\n<h2 id=\"-对比示例让标签跟随方块\">🆚 对比示例：让标签跟随方块</h2>\n<p>❌ <strong>以前的写法 (v0.19.x 及之前)：</strong><br />\n你需要显式地添加一个更新函数，或者写一个 lambda 表达式。</p>\n<pre><code class=\"language-python\">s = Square()\nlabel = Text(\"我在这里\")\n\n# 你必须这样写：\nlabel.add_updater(lambda m: m.next_to(s, UP))\n\n# 或者这样写：\ndef update_label(m):\n    m.next_to(s, UP)\nlabel.add_updater(update_label)\n</code></pre>\n<p>✅ <strong>现在的写法 (v0.20.0)：</strong><br />\n直接用 <code>always</code>，像说话一样自然！</p>\n<pre><code class=\"language-python\">s = Square()\nlabel = Text(\"我在这里\")\n\n# 新语法：永远.紧挨着(方块, 上方)\nlabel.always.next_to(s, UP)\n</code></pre>\n<p>💡 <strong>为什么好用？</strong> 这不仅减少了代码量，还让代码的可读性大幅提升。</p>\n<h1 id=\"-亮点二可复现的随机性\">🎲 亮点二：可复现的随机性</h1>\n<p>对于制作数学或科学视频的人来说，\"随机\"有时候是个麻烦。</p>\n<p>你想展示 10 个随机点，但你不希望每次重新渲染视频时，这 10 个点的位置都变了。</p>\n<p><code>v0.20.0</code> 终于引入了正式的 <strong>Seed（种子）配置</strong>。</p>\n<h2 id=\"-对比示例生成随机点\">🆚 对比示例：生成随机点</h2>\n<p>❌ <strong>以前的情况：</strong><br />\n每次运行 <code>manim render</code>，随机生成的位置都会变化（除非你自己手动在 Python 脚本里 hack <code>random.seed</code>）。</p>\n<p>✅ <strong>现在的情况：</strong><br />\n你可以通过配置文件或命令行参数锁定“运气”。</p>\n<p><strong>方式 1：命令行参数</strong></p>\n<pre><code class=\"language-bash\"># 只要种子是 42，生成的画面永远一模一样\nmanim -pql scene.py MyScene --seed 42\n</code></pre>\n<p><strong>方式 2：代码内配置</strong></p>\n<pre><code class=\"language-python\">from manim import *\n\nconfig.seed = 123  # 在脚本开头锁定种子\n\nclass RandomDemo(Scene):\n    def construct(self):\n        # 无论运行多少次，这个圆的位置都是固定的\n        dot = Dot(point=[np.random.random(), np.random.random(), 0])\n        self.add(dot)\n</code></pre>\n<h1 id=\"-亮点三mathtex-重构与更强的子结构控制\">📐 亮点三：MathTex 重构与更强的子结构控制</h1>\n<p>公式是 <code>Manim</code> 的灵魂。<code>v0.20.0</code> 重写了 <code>MathTex</code> 的底层逻辑。</p>\n<p>现在的 <code>MathTex</code> 在处理 <code>LaTeX</code> 拆分时更加健壮，而且能够利用 <code>SVG</code> 的“命名组”特性。</p>\n<p>这意味着，当你把公式拆分成不同部分进行着色或变换时，出错的概率大大降低了。</p>\n<h2 id=\"-示例精准控制公式颜色\">🔧 示例：精准控制公式颜色</h2>\n<pre><code class=\"language-python\">class MathUpdate(Scene):\n    def construct(self):\n        # 使用 {{ }} 将想要独立操作的字符包裹起来\n        # Manim 会自动把这些部分分离成独立的子对象(submobjects)\n        equation = MathTex(r\"{{a}}^2 + {{b}}^2 = {{c}}^2\")\n\n        # 现在 \"a\" 是独立的，染色不会影响 \"^2\"\n        equation.set_color_by_tex(\"a\", BLUE)\n        equation.set_color_by_tex(\"b\", GREEN)\n        equation.set_color_by_tex(\"c\", RED)\n\n        self.add(equation)\n        self.wait(1)\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202602/83005-20260221173344909-1843335371.png\" /></p>\n<h1 id=\"️-注意破坏性变更与修复\">⚠️ 注意：破坏性变更与修复</h1>\n<p>升级前，请留意以下变化，你的老代码可能需要微调：</p>\n<ol>\n<li><strong>ImageMobject 的修复</strong>：如果你以前对图片进行了 3D 旋转或翻转，可能会发现行为变了——因为以前是错的，现在修好了！同时，移除了一些不常用的重采样算法参数（如 <code>lanczos</code>）。</li>\n<li><strong>新颜色常量</strong>：如果你是设计强迫症，现在可以使用 <code>PURE_CYAN</code>（纯青）、<code>PURE_MAGENTA</code>（纯洋红）和 <code>PURE_YELLOW</code>（纯黄）。</li>\n<li><strong>Table 修复</strong>：修复了高亮表格单元格时可能导致的无限递归崩溃问题。</li>\n</ol>\n<h1 id=\"-技术债务清理\">🔧 技术债务清理</h1>\n<h2 id=\"1-减少对-scipy-的依赖\">1. 减少对 SciPy 的依赖</h2>\n<p>用 Python 标准库的 <code>math.comb</code> 替代了 <code>scipy.special.comb</code>，减少了外部依赖，让安装更轻量。</p>\n<h2 id=\"2-类型提示系统完善\">2. 类型提示系统完善</h2>\n<p>为多个核心模块添加了类型注解：</p>\n<ul>\n<li><code>rotation.py</code></li>\n<li><code>image_mobject.py</code></li>\n<li><code>opengl_renderer.py</code></li>\n<li><code>point_cloud_mobject.py</code></li>\n</ul>\n<p>这对于使用 IDE 进行开发的用户来说是个好消息，可以获得更好的代码补全和类型检查支持。</p>\n<h2 id=\"3-移除未来导入要求\">3. 移除未来导入要求</h2>\n<p>不再强制要求 <code>from __future__ import annotations</code>，简化了代码编写。</p>\n<h1 id=\"-文档改进\">📚 文档改进</h1>\n<ol>\n<li>完善了 <code>RandomColorGenerator</code> 的文档</li>\n<li>改进了 <code>TransformFromCopy</code> 的文档字符串</li>\n<li>修复了损坏的外部链接</li>\n<li>更新了 Python 版本要求文档</li>\n</ol>\n<h1 id=\"-如何升级\">📦 如何升级？</h1>\n<p>准备好体验新功能了吗？打开终端，运行：</p>\n<pre><code class=\"language-bash\">pip install --upgrade manim\n</code></pre>\n<p>或者如果你使用 conda：</p>\n<pre><code class=\"language-bash\">conda update manim\n</code></pre>\n<p>快去试试那个超酷的 <code>.always</code> 属性吧！</p>\n<h1 id=\"-总结\">💡 总结</h1>\n<p><code>manimCE v0.20.0</code> 是一个注重稳定性和开发体验的版本。虽然有一些破坏性变更，但带来的改进是值得的：</p>\n<ul>\n<li>✅ <code>MathTeX</code> 更稳定可靠</li>\n<li>✅ 动画构建更直观</li>\n<li>✅ 代码质量更高</li>\n<li>✅ 文档更完善</li>\n<li>✅ 可复现的随机效果</li>\n</ul>\n<p>特别是 <code>Mobject.always</code> 这个新特性，让动画编写变得更加优雅。强烈建议大家升级体验！</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 17:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wang_yb\">wang_yb</a>&nbsp;\n阅读(<span id=\"post_view_count\">31</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "掌控Coding Plan刷新节奏, 低价套餐满足高峰时期编程需求 -- Quota-Activator",
      "link": "https://www.cnblogs.com/xuhe2/p/19627769",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xuhe2/p/19627769\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 13:18\">\n    <span>掌控Coding Plan刷新节奏, 低价套餐满足高峰时期编程需求 -- Quota-Activator</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        不再被动等待Coding Plan额度恢复, 通过定时任务, 确保新额度在你高强度编程的中途自动刷新.  Quota-Activator 是一款专为开发者设计的\"时间对齐\"工具. 实现低价套餐, 高额度体验, 把工作节奏握在自己手里\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>核心需求：<br />\n不要让 api 厂商的刷新周期（sliding window）决定你的工作节奏.<br />\n掌控Coding Plan刷新节奏, 低价套餐满足高峰时期编程需求.</p>\n<blockquote>\n<p>在高峰编程阶段的中间时间节点触发5小时额度刷新, 避免陷入额度耗尽困难</p>\n</blockquote>\n<hr />\n<h2 id=\"问题\">问题</h2>\n<p>目前主流的高性能模型 coding plan（如 claude/anthropic 或 glm-5）多采用滚动窗口（sliding window）限制：从你第一笔请求开始计时的 5 小时。</p>\n<p>这导致了极其尴尬的开发者体验：</p>\n<p>😫 中途断档：下午 2 点开始高强度工作，刚进入状态写了两小时，额度突然耗尽——思路被打断。</p>\n<p>😫 续命尴尬：此时你想\"续命\"，但新额度要等 5 小时窗口期结束，完全错过了你的黄金工作时段。</p>\n<p>😫 被动等待：要么停止工作等刷新，要么手动发垃圾请求强行激活——都不优雅。</p>\n<p>Quota-Activator 的逻辑很简单：既然刷新规则不可改变，那我们就用定时垃圾请求来对齐它。</p>\n<blockquote>\n<p>github: <strong><a href=\"https://github.com/xuhe2/Quota-Activator\" rel=\"noopener nofollow\" target=\"_blank\">xuhe2/Quota-Activator</a></strong></p>\n</blockquote>\n<hr />\n<h2 id=\"解决方案\">解决方案</h2>\n<p>quotaactivator 是一个定时触发的工具，核心思想很简单：</p>\n<blockquote>\n<p>根据想要刷的时间点, 自动计算第一次垃圾请求需要发送的时候, 并且在那个时间点发送它, 确保新额度立即生效</p>\n</blockquote>\n<pre><code>11:00  配置目标时间 16:00, 触发垃圾请求发送;\n14:00  开始工作;\n16:00  高强度Coding 2 Hour; 新额度激活;\n</code></pre>\n<h3 id=\"核心特性\">核心特性</h3>\n<ul>\n<li>🎯 <strong>智能调度</strong>：自动计算最佳触发时间，避免额度重叠</li>\n<li>🔄 <strong>多目标时间</strong>：可配置 09:00、14:00、19:00 多个时间点</li>\n<li>🛡️ <strong>冲突检测</strong>：自动检测时间配置冲突</li>\n<li>🔁 <strong>重试机制</strong>：指数退避重试，提高触发成功率</li>\n<li>📦 <strong>易扩展</strong>：模块化架构，轻松支持 openai 等其他平台</li>\n</ul>\n<hr />\n<h2 id=\"30-秒快速上手\">30 秒快速上手</h2>\n<h3 id=\"安装\">安装</h3>\n<pre><code class=\"language-bash\">git clone https://github.com/xuhe2/Quota-Activator.git\ncd Quota-Activator\nmake build\n</code></pre>\n<h3 id=\"配置\">配置</h3>\n<pre><code class=\"language-yaml\"># config.yaml\ntargets:\n  - \"10:30\"   # 上午工作中途刷新\n  - \"15:30\"   # 下午工作中途刷新\n  - \"20:30\"   # 晚上工作中途刷新\n\napi_key: \"sk-ant-api03-...\"\nplatform: \"anthropic\"\n</code></pre>\n<h3 id=\"运行\">运行</h3>\n<pre><code class=\"language-bash\">./bin/quota-activator\n</code></pre>\n<p>就这么简单。</p>\n<hr />\n<h1 id=\"github开源\">Github开源</h1>\n<p>github: <strong><a href=\"https://github.com/xuhe2/quotaactivator\" rel=\"noopener nofollow\" target=\"_blank\">xuhe2/quotaactivator</a></strong></p>\n<p><strong>如果这个工具对你有帮助，请给个 ⭐️ star 鼓励一下作者</strong></p>\n<p>也欢迎贡献代码：</p>\n<ul>\n<li>支持 openai、gemini 等更多平台</li>\n<li>优化调度算法</li>\n<li>添加 web dashboard</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-21 13:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xuhe2\">xuhe2</a>&nbsp;\n阅读(<span id=\"post_view_count\">58</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}