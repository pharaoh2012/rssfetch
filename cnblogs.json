{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "@Slf4j：不止是省一行代码，更是生产级日志的艺术",
      "link": "https://www.cnblogs.com/xzqcsj/p/19583495",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzqcsj/p/19583495\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 09:38\">\n    <span>@Slf4j：不止是省一行代码，更是生产级日志的艺术</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"@Slf4j：不止是省一行代码，更是生产级日志的艺术\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3703499/202602/3703499-20260206115352008-1886837546.png\" />\n        如果统计 Java 程序员键盘敲击频率最高的单词，log 一定榜上有名。\n每天，我们在无数个类头上加上 @Slf4j，就像呼吸一样自然。但大多数时候，它对我们来说只是一个“打印机”：输入字符串，控制台输出一行字。\n直到有一天，你发现线上的 CPU 被毫无意义的字符串拼接占满，或者在海量的日志里找不到那把解开 Bug 的钥匙，你才会意识到：并不是所有的日志，都叫合格的工程日志。\n这篇文章，想和你重新认识一下这位最熟悉的陌生人。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>写在前面的话</strong></p>\n<p>如果统计 Java 程序员键盘敲击频率最高的单词，<code>log</code> 一定榜上有名。</p>\n<p>每天，我们在无数个类头上加上 <code>@Slf4j</code>，就像呼吸一样自然。但大多数时候，它对我们来说只是一个“打印机”：输入字符串，控制台输出一行字。</p>\n<p>直到有一天，你发现线上的 CPU 被毫无意义的字符串拼接占满，或者在海量的日志里找不到那把解开 Bug 的钥匙，你才会意识到：<strong>并不是所有的日志，都叫合格的工程日志。</strong></p>\n<p>这篇文章，想和你重新认识一下这位最熟悉的陌生人。</p>\n</blockquote>\n<h3 id=\"一-只是为了偷懒吗\">一、 只是为了“偷懒”吗？</h3>\n<h4 id=\"1-它是编译期的魔术师\">1. 它是编译期的“魔术师”</h4>\n<p>很多人觉得用 <code>@Slf4j</code> 只是为了少写一行 <code>private static final Logger...</code>。这确实是它最直观的好处，但它的价值远不止于此。</p>\n<p>如果你反编译过使用了该注解的 <code>.class</code> 文件，你会发现 Lombok 在编译期默默地为你注入了标准的代码：</p>\n<pre><code class=\"language-java\">public class PaymentService {\n    // 编译后自动生成，标准且统一\n    private static final org.slf4j.Logger log = \n        org.slf4j.LoggerFactory.getLogger(PaymentService.class);\n}\n</code></pre>\n<p>这意味着什么？意味着你的团队不再需要争论日志变量是叫 <code>logger</code> 还是 <code>LOG</code>，也不用担心有人手滑把 <code>PaymentService</code> 的日志类错写成了 <code>OrderService</code>（这种拷贝粘贴的错误太常见了）。</p>\n<p><strong>它用一种强制性的规范，抹平了人为的差异。</strong></p>\n<h4 id=\"2-面向接口的智慧\">2. 面向接口的智慧</h4>\n<p><code>@Slf4j</code> 引入的是 <code>org.slf4j.Logger</code>，即 <strong>Simple Logging Facade for Java</strong>（Java 简单日志门面）。</p>\n<p>这体现了“依赖倒置”的设计原则。你的业务代码只依赖于“门面”，而不依赖于具体的实现（如 Logback 或 Log4j2）。哪天你想把底层的日志框架换掉，业务代码一行都不用改。</p>\n<hr />\n<h3 id=\"二-性能与优雅的平衡\">二、 性能与优雅的平衡</h3>\n<p>日志虽好，但也昂贵。在极高的并发下，一行错误的日志打印代码，可能就是压死骆驼的最后一根稻草。</p>\n<h4 id=\"1-占位符不仅是好看\">1. 占位符：不仅是好看</h4>\n<pre><code class=\"language-java\">// ❌ 直觉写法：字符串拼接\nlog.debug(\"用户 \" + user.getName() + \" 购买了 \" + item.getTitle());\n\n// ✅ 推荐写法：占位符\nlog.debug(\"用户 {} 购买了 {}\", user.getName(), item.getTitle());\n</code></pre>\n<p>为什么必须用占位符？</p>\n<ul>\n<li><strong>内存友好</strong>：第一种写法在字符串拼接时会立即创建多个 <code>StringBuilder</code> 和临时 <code>String</code> 对象，无论日志级别是否开启。</li>\n<li><strong>延迟求值</strong>：第二种写法，只有当日志级别满足要求（例如确实需要打印 Debug 日志）时，框架才会去处理参数。在此之前，它仅仅是引用传递。</li>\n</ul>\n<h4 id=\"2-警惕隐形的性能杀手\">2. 警惕隐形的“性能杀手”</h4>\n<p>还是关于 <code>DEBUG</code> 日志。看下面这段代码，有什么问题？</p>\n<pre><code class=\"language-java\">// 假设 toJson() 是一个非常耗时的序列化操作\nlog.debug(\"当前订单详情: {}\", JSON.toJSONString(order));\n</code></pre>\n<p>虽然我们用了占位符，但 <code>JSON.toJSONString(order)</code> 是作为一个<strong>参数</strong>传入方法的。Java 的求值顺序决定了：<strong>在进入 <code>log.debug</code> 方法之前，这个耗时的序列化操作就已经执行了。</strong> 如果生产环境这一行并没有打印（Level=INFO），那这个 CPU 里的计算就白白浪费了。</p>\n<p><strong>修正姿势：</strong></p>\n<pre><code class=\"language-java\">// 对于昂贵的操作，必须显式判断\nif (log.isDebugEnabled()) {\n    log.debug(\"当前订单详情: {}\", JSON.toJSONString(order));\n}\n</code></pre>\n<p>或者，如果你使用的是支持 Fluent API 的新版 SLF4J/Log4j2，可以用 Lambda 来实现真正的延迟计算，但在通用场景下，<code>isDebugEnabled</code> 依然是永远的神。</p>\n<hr />\n<h3 id=\"三-给日志加点透视眼\">三、 给日志加点“透视眼”</h3>\n<h4 id=\"1-巧用-topic-进行分流\">1. 巧用 <code>topic</code> 进行分流</h4>\n<p>默认情况下，所有的日志都混在 <code>log</code> 变量里。但有时候，我们需要对某些特殊的业务进行独立监控，比如“核心交易链路”或“第三方接口审计”。</p>\n<p>你不需要重新定义一个 Logger，<code>@Slf4j</code> 原生支持：</p>\n<pre><code class=\"language-java\">// 定义一个名为 \"AUDIT_LOG\" 的独立 topic\n@Slf4j(topic = \"AUDIT_LOG\")\npublic class PayController {\n    public void pay() {\n        // 这行日志的 logger name 不再是类名，而是 \"AUDIT_LOG\"\n        log.info(\"发起支付请求...\");\n    }\n}\n</code></pre>\n<p>配合 <code>logback.xml</code> 的配置，你可以轻松把这个 Topic 的日志单独输出到一个 <code>audit.log</code> 文件中，甚至发送到专门的监控报警群，而不会淹没在海量的业务日志里。</p>\n<h4 id=\"2-mdc穿越时空的线索\">2. MDC：穿越时空的线索</h4>\n<p>在微服务或异步调用复杂的系统中，排查问题最大的痛点是：<strong>不知道这行日志属于哪个请求。</strong></p>\n<p>这是 SLF4J 的 MDC（Mapped Diagnostic Context）大显身手的时候。它利用 <code>ThreadLocal</code> 存储上下文信息。</p>\n<pre><code class=\"language-java\">// 在拦截器或入口处\nMDC.put(\"requestId\", UUID.randomUUID().toString());\nMDC.put(\"userId\", user.getId());\n\n// ... 无论后续经过多少个 Service，只有在同一线程内\nlog.info(\"处理订单\"); \n// 输出会自动带上：[requestId:abc-123] [userId:1001] 处理订单\n</code></pre>\n<p>它就像给每个请求发了一个“工牌”，无论走到哪里，你都能一眼认出它来。</p>\n<hr />\n<h3 id=\"四-避坑指南继承与混淆\">四、 避坑指南：继承与混淆</h3>\n<h4 id=\"️-误区父类的日志是谁的\">⚠️ 误区：父类的日志是谁的？</h4>\n<pre><code class=\"language-java\">@Slf4j\npublic class BaseService {\n    public void init() {\n        log.info(\"BaseService init...\");\n    }\n}\n\npublic class UserService extends BaseService {\n    // UserService 继承了 BaseService 的方法\n}\n</code></pre>\n<p>当 <code>UserService</code> 调用 <code>init()</code> 时，打印出来的日志类名是 <code>BaseService</code> 还是 <code>UserService</code>？<br />\n答案是：<strong>BaseService</strong>。</p>\n<p>因为 <code>@Slf4j</code> 生成的是 <code>private static final</code> 字段，它是属于定义它的那个类的。如果你希望日志显示子类的名字，不要依赖继承，而是在子类中重新声明注解，或者使用非静态的 logger（不推荐，性能略差）。</p>\n<hr />\n<h3 id=\"五-写在最后\">五、 写在最后</h3>\n<p>日志，是系统的“黑匣子”，也是程序员留给未来的“信”。</p>\n<p>当我们敲下 <code>@Slf4j</code> 时，不妨多想一步：</p>\n<ul>\n<li>这行日志真的有必要吗？</li>\n<li>参数里有没有包含不仅耗时还可能泄露隐私的大对象？</li>\n<li>当凌晨被叫醒排查问题时，这行日志能让我这种“局外人”看懂吗？</li>\n</ul>\n<p><strong>好的日志，不是记流水账，而是构建系统运行的时空隧道。当你凝视日志时，日志也在向你诉说系统的健康与灵魂。</strong></p>\n<hr />\n<blockquote>\n<p>文章的最后，想和你多聊两句。</p>\n<p>技术之路，常常是热闹与孤独并存。那些深夜的调试、灵光一闪的方案、还有踩坑爬起后的顿悟，如果能有人一起聊聊，该多好。</p>\n<p>为此，我建了一个小花园——我的微信公众号「<strong>[努力的小郑]</strong>」。</p>\n<p>这里没有高深莫测的理论堆砌，只有我对后端开发、系统设计和工程实践的持续思考与沉淀。它更像我的<strong>数字笔记本</strong>，记录着那些值得被记住的解决方案和思维火花。</p>\n<p>如果你觉得今天的文章还有一点启发，或者单纯想找一个同行者偶尔聊聊技术、谈谈思考，那么，欢迎你来坐坐。<br />\n<img alt=\"85f114bceb12e933bb817ec5fecdfef7\" class=\"lazyload\" /></p>\n<p>愿你前行路上，总有代码可写，有梦可追，也有灯火可亲。</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 09:38</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzqcsj\">一旅人</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "一套基于 Redis 分桶 + DB 明细驱动的强一致性库存扣减方案，实现零超卖、零少卖，支持 Redis 宕机自动降级",
      "link": "https://www.cnblogs.com/ZouYua/p/19593557",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ZouYua/p/19593557\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 09:16\">\n    <span>一套基于 Redis 分桶 + DB 明细驱动的强一致性库存扣减方案，实现零超卖、零少卖，支持 Redis 宕机自动降级</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"电商库存高并发扣减系统\">电商库存高并发扣减系统</h1>\n<blockquote>\n<p>一套基于 Redis 分桶 + DB 明细驱动的强一致性库存扣减方案，实现零超卖、零少卖，支持 Redis 宕机自动降级</p>\n</blockquote>\n<h2 id=\"目录\">目录</h2>\n<ul>\n<li><a href=\"#%E4%B8%80%E8%83%8C%E6%99%AF%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E9%AB%98%E5%B9%B6%E5%8F%91%E5%BA%93%E5%AD%98%E6%89%A3%E5%87%8F%E6%96%B9%E6%A1%88\" rel=\"noopener nofollow\">一、背景：为什么需要高并发库存扣减方案</a></li>\n<li><a href=\"#%E4%BA%8C%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%A1%88%E7%9A%84%E4%B8%89%E5%A4%A7%E7%97%9B%E7%82%B9\" rel=\"noopener nofollow\">二、传统方案的三大痛点</a></li>\n<li><a href=\"#%E4%B8%89%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3\" rel=\"noopener nofollow\">三、核心设计思想</a></li>\n<li><a href=\"#%E5%9B%9B%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84%E8%AF%A6%E8%A7%A3\" rel=\"noopener nofollow\">四、技术架构详解</a></li>\n<li><a href=\"#%E4%BA%94%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B%E5%AE%9E%E7%8E%B0\" rel=\"noopener nofollow\">五、核心流程实现</a></li>\n<li><a href=\"#%E5%85%AD%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94\" rel=\"noopener nofollow\">六、常见问题解答</a></li>\n<li><a href=\"#%E4%B8%83%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%8E%E4%BC%98%E5%8C%96\" rel=\"noopener nofollow\">七、性能测试与优化</a></li>\n<li><a href=\"#%E5%85%AB%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B\" rel=\"noopener nofollow\">八、总结与展望</a></li>\n</ul>\n<hr />\n<h2 id=\"一背景为什么需要高并发库存扣减方案\">一、背景：为什么需要高并发库存扣减方案</h2>\n<p>在电商系统中，库存扣减是一个看似简单但实际非常复杂的问题。尤其是在以下场景：</p>\n<h3 id=\"典型场景\">典型场景</h3>\n<ol>\n<li><strong>秒杀活动</strong>：1000 件商品，10 万用户同时抢购</li>\n<li><strong>直播带货</strong>：主播一句话，数万人同时下单</li>\n<li><strong>限量发售</strong>：新品首发，瞬时流量暴增</li>\n</ol>\n<h3 id=\"核心挑战\">核心挑战</h3>\n<ul>\n<li><strong>高并发</strong>：每秒数万次库存扣减请求</li>\n<li><strong>强一致性</strong>：绝对不能超卖（卖出的商品数 &gt; 实际库存）</li>\n<li><strong>零少卖</strong>：不能因为系统问题导致有库存却卖不出去</li>\n<li><strong>高可用</strong>：Redis 宕机后系统仍能正常运行</li>\n</ul>\n<hr />\n<h2 id=\"二传统方案的三大痛点\">二、传统方案的三大痛点</h2>\n<h3 id=\"方案-1纯数据库扣减\">方案 1：纯数据库扣减</h3>\n<p><strong>实现方式：</strong></p>\n<pre><code class=\"language-sql\">UPDATE inventory \nSET stock = stock - 1 \nWHERE product_id = 1001 AND stock &gt; 0;\n</code></pre>\n<p><strong>优点：</strong></p>\n<ul>\n<li>实现简单</li>\n<li>数据强一致性</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>❌ <strong>性能瓶颈</strong>：单行热点更新，MySQL 行锁导致大量请求排队</li>\n<li>❌ <strong>TPS 低</strong>：单机 MySQL 只能支撑 1000-2000 TPS</li>\n<li>❌ <strong>用户体验差</strong>：大量请求超时，用户等待时间长</li>\n</ul>\n<h3 id=\"方案-2纯-redis-扣减\">方案 2：纯 Redis 扣减</h3>\n<p><strong>实现方式：</strong></p>\n<pre><code class=\"language-bash\">DECR inventory:1001\n</code></pre>\n<p><strong>优点：</strong></p>\n<ul>\n<li>性能极高（单机 10 万+ TPS）</li>\n<li>响应速度快</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>❌ <strong>无法避免少卖</strong>：Redis 超时时，应用层无法判断是否扣减成功</li>\n<li>❌ <strong>只支持简单模型</strong>：无法支持 SQ/LQ/WQ/OQ 等复杂库存状态</li>\n<li>❌ <strong>完全依赖 Redis</strong>：Redis 宕机则整个系统不可用</li>\n</ul>\n<h3 id=\"方案-3传统-redis-分桶\">方案 3：传统 Redis 分桶</h3>\n<p><strong>实现方式：</strong></p>\n<ul>\n<li>将库存分散到多个 Redis 分桶</li>\n<li>扣减时随机选择一个分桶</li>\n</ul>\n<p><strong>优点：</strong></p>\n<ul>\n<li>性能较好</li>\n<li>降低单点压力</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>❌ <strong>仍然无法避免少卖</strong></li>\n<li>❌ <strong>分桶不均导致超卖</strong>：某些分桶先被扣完，但其他分桶还有库存</li>\n<li>❌ <strong>无法支持复杂库存模型</strong></li>\n</ul>\n<hr />\n<h2 id=\"三核心设计思想\">三、核心设计思想</h2>\n<h3 id=\"31-设计原则\">3.1 设计原则</h3>\n<p>我们的方案基于一个核心思想：<strong>Redis 只做计数，DB 明细为准</strong></p>\n<pre><code>┌─────────────────────────────────────────────────────────┐\n│                    核心设计原则                           │\n├─────────────────────────────────────────────────────────┤\n│ 1. Redis 分桶：仅用于高并发计数验证，防止超卖                 │\n│ 2. DB 明细表：记录所有库存流转，是唯一数据源                  │\n│ 3. 合并提交：定时批量更新主表，降低 DB 压力                   │\n│ 4. 自动降级：Redis 不可用时自动切换到低并发流程               │\n└─────────────────────────────────────────────────────────┘\n</code></pre>\n<h3 id=\"32-库存字段设计\">3.2 库存字段设计</h3>\n<p>我们设计了四个核心库存字段，支持完整的电商业务流程：</p>\n<table>\n<thead>\n<tr>\n<th>字段</th>\n<th>名称</th>\n<th>作用</th>\n<th>前端展示</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>SQ</strong></td>\n<td>可售库存</td>\n<td>低并发直接扣减，未预热时的主要库存</td>\n<td>✅ 展示（SQ+LQ）</td>\n</tr>\n<tr>\n<td><strong>LQ</strong></td>\n<td>预锁库存</td>\n<td>高并发专用缓冲区，预热后从 SQ 隔离</td>\n<td>✅ 展示（SQ+LQ）</td>\n</tr>\n<tr>\n<td><strong>WQ</strong></td>\n<td>预扣库存</td>\n<td>下单未付款临时锁定</td>\n<td>❌ 不展示</td>\n</tr>\n<tr>\n<td><strong>OQ</strong></td>\n<td>占用库存</td>\n<td>付款后实际占用，等待发货</td>\n<td>❌ 不展示</td>\n</tr>\n</tbody>\n</table>\n<p><strong>核心闭环：</strong> <code>SQ + LQ + WQ + OQ = 总库存</code>（未出库时）</p>\n<p><strong>前端展示规则：</strong></p>\n<ul>\n<li><strong>商品列表/详情页</strong>：显示 <code>SQ + LQ</code>（总可售库存）\n<ul>\n<li>后端返回字段名为 <code>totalSq</code>，但值是 <code>SQ + LQ</code> 的总和</li>\n<li>用户看到的是\"可以购买的总库存\"</li>\n</ul>\n</li>\n<li><strong>管理后台</strong>：分别显示 SQ、LQ、WQ、OQ（便于运营监控）</li>\n<li><strong>用户视角</strong>：只关心\"能买多少\"，即 SQ+LQ</li>\n</ul>\n<h3 id=\"33-库存流转规则\">3.3 库存流转规则</h3>\n<pre><code>预热阶段：    SQ ──────────&gt; LQ\n              ↓              ↓\n下单阶段：    └──&gt; WQ &lt;──────┘\n              ↓\n付款阶段：    └──────────&gt; OQ\n              ↓              ↓\n履约阶段：    └──&gt; 出库      └──&gt; 退款 ──&gt; SQ/LQ\n</code></pre>\n<p><strong>关键设计：</strong></p>\n<ul>\n<li>所有流转都先插入明细表</li>\n<li>定时任务扫描明细，批量更新主表</li>\n<li>禁止跨状态流转（如 SQ 不能直接到 OQ）</li>\n</ul>\n<hr />\n<h2 id=\"四技术架构详解\">四、技术架构详解</h2>\n<h3 id=\"41-整体架构图\">4.1 整体架构图</h3>\n<pre><code>┌─────────────────────────────────────────────────────────────┐\n│                         用户请求                             │\n└────────────────────────┬────────────────────────────────────┘\n                         │\n                         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    应用层（Spring Boot）                     │\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │\n│  │ 库存预热模块  │  │ 下单扣减模块  │  │ 订单支付模块  │      │\n│  └──────────────┘  └──────────────┘  └──────────────┘      │\n│  ┌──────────────┐  ┌──────────────┐                        │\n│  │ 合并提交任务  │  │ 超时回收任务  │                        │\n│  └──────────────┘  └──────────────┘                        │\n└────────────┬───────────────────────┬────────────────────────┘\n             │                       │\n             ▼                       ▼\n┌─────────────────────┐   ┌─────────────────────┐\n│   Redis 分桶集群     │   │   MySQL 数据库       │\n│  ┌────┐ ┌────┐      │   │  ┌──────────────┐   │\n│  │桶0 │ │桶1 │ ...  │   │  │ inventory    │   │\n│  └────┘ └────┘      │   │  │ (主表)       │   │\n│                     │   │  └──────────────┘   │\n│  仅做计数验证        │   │  ┌──────────────┐   │\n│  防止超卖           │   │  │ deduct_detail│   │\n│                     │   │  │ (明细表)     │   │\n└─────────────────────┘   │  └──────────────┘   │\n                          │                     │\n                          │  数据唯一来源        │\n                          └─────────────────────┘\n</code></pre>\n<h3 id=\"42-核心表设计\">4.2 核心表设计</h3>\n<h4 id=\"421-库存主表inventory\">4.2.1 库存主表（inventory）</h4>\n<pre><code class=\"language-sql\">CREATE TABLE `inventory` (\n  `inv_id` BIGINT PRIMARY KEY AUTO_INCREMENT,\n  `product_id` BIGINT NOT NULL,\n  `spec_id` BIGINT NOT NULL DEFAULT 0,\n  `sq` INT NOT NULL DEFAULT 0 COMMENT '可售库存',\n  `lq` INT NOT NULL DEFAULT 0 COMMENT '预锁库存',\n  `wq` INT NOT NULL DEFAULT 0 COMMENT '预扣库存',\n  `oq` INT NOT NULL DEFAULT 0 COMMENT '占用库存',\n  `version` INT NOT NULL DEFAULT 1 COMMENT '乐观锁版本号',\n  UNIQUE KEY `uk_product_spec` (`product_id`, `spec_id`)\n) ENGINE=InnoDB;\n</code></pre>\n<p><strong>关键点：</strong></p>\n<ul>\n<li><code>version</code> 字段：乐观锁，防止合并提交时的并发冲突</li>\n<li>唯一索引：防止同一商品规格创建多条库存记录</li>\n</ul>\n<h4 id=\"422-库存扣减明细表inventory_deduct_detail\">4.2.2 库存扣减明细表（inventory_deduct_detail）</h4>\n<pre><code class=\"language-sql\">CREATE TABLE `inventory_deduct_detail` (\n  `detail_id` BIGINT PRIMARY KEY AUTO_INCREMENT,\n  `inv_id` BIGINT NOT NULL,\n  `lock_order_id` VARCHAR(64) NOT NULL COMMENT '订单号/业务标识',\n  `quantity` INT NOT NULL COMMENT '流转数量',\n  `flow_type` TINYINT NOT NULL COMMENT '流转类型',\n  `status` TINYINT NOT NULL DEFAULT 0 COMMENT '0-待处理 1-已处理',\n  UNIQUE KEY `uk_inv_order` (`inv_id`, `lock_order_id`),\n  KEY `idx_inv_status_flow` (`inv_id`, `status`, `flow_type`)\n) ENGINE=InnoDB;\n</code></pre>\n<p><strong>关键点：</strong></p>\n<ul>\n<li><code>uk_inv_order</code>：天然实现幂等性，防止重复下单</li>\n<li><code>idx_inv_status_flow</code>：覆盖索引，合并提交时无需回表</li>\n</ul>\n<h4 id=\"423-redis-分桶配置表inventory_redis_bucket\">4.2.3 Redis 分桶配置表（inventory_redis_bucket）</h4>\n<pre><code class=\"language-sql\">CREATE TABLE `inventory_redis_bucket` (\n  `bucket_id` BIGINT PRIMARY KEY AUTO_INCREMENT,\n  `inv_id` BIGINT NOT NULL,\n  `bucket_no` INT NOT NULL COMMENT '分桶编号',\n  `bucket_key` VARCHAR(128) NOT NULL COMMENT 'Redis key',\n  `init_quantity` INT NOT NULL DEFAULT 0,\n  UNIQUE KEY `uk_inv_bucketno` (`inv_id`, `bucket_no`)\n) ENGINE=InnoDB;\n</code></pre>\n<p><strong>关键点：</strong></p>\n<ul>\n<li>持久化分桶配置，支持动态调整</li>\n<li>记录初始化数量，方便故障恢复</li>\n</ul>\n<hr />\n<h2 id=\"五核心流程实现\">五、核心流程实现</h2>\n<h3 id=\"51-库存预热sq--lq\">5.1 库存预热（SQ → LQ）</h3>\n<p><strong>场景：</strong> 商家上架商品，系统自动预热 50% 库存到 LQ</p>\n<pre><code class=\"language-java\">@Transactional\npublic String preheatInventory(Long invId) {\n    // 1. 查询库存\n    Inventory inventory = inventoryMapper.selectById(invId);\n    \n    // 2. 计算预热数量（50%）\n    Integer preheatQuantity = (int) (inventory.getSq() * 0.5);\n    \n    // 3. 更新主表：SQ → LQ\n    inventory.setSq(inventory.getSq() - preheatQuantity);\n    inventory.setLq(inventory.getLq() + preheatQuantity);\n    inventoryMapper.updateById(inventory);\n    \n    // 4. 插入预热明细（flow_type=0）\n    InventoryDeductDetail detail = new InventoryDeductDetail();\n    detail.setInvId(invId);\n    detail.setFlowType(0); // SQ→LQ\n    detail.setQuantity(preheatQuantity);\n    detail.setStatus(1); // 已处理\n    detailMapper.insert(detail);\n    \n    // 5. 初始化 Redis 分桶（10 个分桶）\n    bucketManager.initBuckets(invId, preheatQuantity, 10);\n    \n    return \"预热成功\";\n}\n</code></pre>\n<p><strong>Redis 分桶初始化：</strong></p>\n<pre><code class=\"language-java\">public void initBuckets(Long invId, Integer totalQuantity, Integer bucketCount) {\n    int baseValue = totalQuantity / bucketCount;\n    int remainder = totalQuantity % bucketCount;\n    \n    for (int i = 0; i &lt; bucketCount; i++) {\n        String key = \"inventory:bucket:\" + invId + \":\" + i;\n        int value = baseValue + (i &lt; remainder ? 1 : 0);\n        redisTemplate.opsForValue().set(key, value);\n    }\n}\n</code></pre>\n<h3 id=\"52-高并发下单lq--wq\">5.2 高并发下单（LQ → WQ）</h3>\n<p><strong>场景：</strong> 用户下单 3 件商品，Redis 分桶扣减 + DB 明细记录</p>\n<pre><code class=\"language-java\">@Transactional\npublic String deductInventoryHighConcurrency(Long invId, String orderNo, Integer quantity) {\n    try {\n        // 1. 选择 Redis 分桶（哈希取模）\n        Integer bucketNo = selectBucket(invId, orderNo);\n        \n        // 2. Redis 原子扣减\n        Long result = redisTemplate.opsForValue()\n            .decrement(\"inventory:bucket:\" + invId + \":\" + bucketNo, quantity);\n        \n        // 3. 扣减失败，重试 3 个随机分桶\n        if (result &lt; 0) {\n            // 回补刚才扣减的分桶\n            redisTemplate.opsForValue().increment(key, quantity);\n            \n            // 重试其他分桶...\n            // 仍失败则降级到低并发流程\n            return deductInventoryLowConcurrency(invId, orderNo, quantity);\n        }\n        \n        // 4. Redis 成功，插入 DB 明细\n        InventoryDeductDetail detail = new InventoryDeductDetail();\n        detail.setInvId(invId);\n        detail.setLockOrderId(orderNo);\n        detail.setQuantity(quantity);\n        detail.setFlowType(1); // LQ→WQ\n        detail.setStatus(0); // 待处理\n        detailMapper.insert(detail);\n        \n        return \"扣减成功\";\n        \n    } catch (Exception e) {\n        // Redis 异常，自动降级\n        return deductInventoryLowConcurrency(invId, orderNo, quantity);\n    }\n}\n</code></pre>\n<p><strong>分桶选择算法：</strong></p>\n<pre><code class=\"language-java\">private Integer selectBucket(Long invId, String orderNo) {\n    // 哈希取模，保证同一订单总是选择同一个分桶\n    int hash = orderNo.hashCode();\n    return Math.abs(hash) % bucketCount;\n}\n</code></pre>\n<h3 id=\"53-低并发下单sqlq--wq\">5.3 低并发下单（SQ/LQ → WQ）</h3>\n<p><strong>场景：</strong> Redis 不可用或分桶库存不足，智能选择 SQ 或 LQ</p>\n<pre><code class=\"language-java\">@Transactional\npublic String deductInventoryLowConcurrency(Long invId, String orderNo, Integer quantity) {\n    // 1. 查询当前库存\n    Inventory inventory = inventoryMapper.selectById(invId);\n    Integer totalAvailable = inventory.getSq() + inventory.getLq();\n    \n    // 2. 检查总可售库存\n    if (totalAvailable &lt; quantity) {\n        throw new IllegalStateException(\"库存不足\");\n    }\n    \n    // 3. 智能分配：优先使用 SQ\n    if (inventory.getSq() &gt;= quantity) {\n        // SQ 足够，全部从 SQ 扣减\n        insertDetail(invId, orderNo, quantity, 2); // SQ→WQ\n        \n    } else if (inventory.getSq() &gt; 0) {\n        // SQ 不足，混合扣减\n        insertDetail(invId, orderNo, inventory.getSq(), 2); // SQ→WQ\n        insertDetail(invId, orderNo + \"_LQ\", quantity - inventory.getSq(), 1); // LQ→WQ\n        \n    } else {\n        // SQ 为 0，全部从 LQ 扣减\n        insertDetail(invId, orderNo, quantity, 1); // LQ→WQ\n    }\n    \n    return \"扣减成功\";\n}\n</code></pre>\n<p><strong>关键创新：</strong> 低并发流程会智能检查 SQ+LQ 总库存，避免\"有库存却卖不出去\"的问题。</p>\n<h3 id=\"54-订单支付wq--oq\">5.4 订单支付（WQ → OQ）</h3>\n<p><strong>场景：</strong> 用户付款成功，库存从 WQ 流转到 OQ</p>\n<pre><code class=\"language-java\">@Transactional\npublic String payOrder(String orderNo) {\n    // 1. 查询订单明细\n    List&lt;OrderItem&gt; items = orderItemMapper.selectByOrderNo(orderNo);\n    \n    for (OrderItem item : items) {\n        // 2. 插入 WQ→OQ 明细\n        InventoryDeductDetail detail = new InventoryDeductDetail();\n        detail.setInvId(item.getInvId());\n        detail.setLockOrderId(orderNo + \"_PAY\");\n        detail.setQuantity(item.getQuantity());\n        detail.setFlowType(3); // WQ→OQ\n        detail.setStatus(0); // 待处理\n        detailMapper.insert(detail);\n        \n        // 注意：不手动更新原明细状态，让定时任务统一处理\n    }\n    \n    return \"支付成功\";\n}\n</code></pre>\n<p><strong>关键修复：</strong> 不再手动标记原明细为已处理，避免支付过快导致明细漏扫描。</p>\n<h3 id=\"55-合并提交核心性能优化\">5.5 合并提交（核心性能优化）</h3>\n<p><strong>场景：</strong> 定时任务每 50ms 扫描待处理明细，批量更新主表</p>\n<pre><code class=\"language-java\">@Scheduled(fixedDelay = 50)\npublic void execute() {\n    // 扫描需要合并的库存 ID\n    List&lt;Long&gt; invIdList = detailMapper.listNeedMergeInvId();\n    \n    for (Long invId : invIdList) {\n        executeMerge(invId);\n    }\n}\n\n@Transactional\npublic void executeMerge(Long invId) {\n    // 1. 获取分布式锁（Redis 不可用时跳过）\n    RLock lock = redissonClient.getLock(\"inventory:merge:lock:\" + invId);\n    try {\n        lock.tryLock(0, 500, TimeUnit.MILLISECONDS);\n    } catch (Exception e) {\n        // Redis 不可用，依赖数据库乐观锁\n    }\n    \n    try {\n        // 2. 锁定 Redis 分桶（MSET 置 0）\n        bucketManager.lockAllBuckets(invId);\n        \n        // 3. 扫描待处理明细，按 flow_type 分组求和\n        List&lt;Map&lt;String, Object&gt;&gt; aggregation = detailMapper.aggregateByFlowType(invId);\n        \n        // 4. 计算库存变化量\n        int sqDelta = 0, lqDelta = 0, wqDelta = 0, oqDelta = 0;\n        for (Map&lt;String, Object&gt; row : aggregation) {\n            Integer flowType = (Integer) row.get(\"flow_type\");\n            Integer quantity = (Integer) row.get(\"total_quantity\");\n            \n            switch (flowType) {\n                case 1: // LQ→WQ\n                    lqDelta -= quantity;\n                    wqDelta += quantity;\n                    break;\n                case 2: // SQ→WQ\n                    sqDelta -= quantity;\n                    wqDelta += quantity;\n                    break;\n                case 3: // WQ→OQ\n                    wqDelta -= quantity;\n                    oqDelta += quantity;\n                    break;\n                // ... 其他流转类型\n            }\n        }\n        \n        // 5. 使用乐观锁更新主表\n        Inventory inventory = inventoryMapper.selectById(invId);\n        Integer currentVersion = inventory.getVersion();\n        \n        inventoryMapper.update(null, new LambdaUpdateWrapper&lt;Inventory&gt;()\n            .eq(Inventory::getInvId, invId)\n            .eq(Inventory::getVersion, currentVersion)\n            .setSql(\"sq = sq + \" + sqDelta)\n            .setSql(\"lq = lq + \" + lqDelta)\n            .setSql(\"wq = wq + \" + wqDelta)\n            .setSql(\"oq = oq + \" + oqDelta)\n            .setSql(\"version = version + 1\")\n        );\n        \n        // 6. 标记明细为已处理\n        detailMapper.update(null, new LambdaUpdateWrapper&lt;InventoryDeductDetail&gt;()\n            .eq(InventoryDeductDetail::getInvId, invId)\n            .eq(InventoryDeductDetail::getStatus, 0)\n            .set(InventoryDeductDetail::getStatus, 1)\n        );\n        \n        // 7. 重新分配 Redis 分桶\n        Inventory updated = inventoryMapper.selectById(invId);\n        if (updated.getLq() &gt; 0) {\n            bucketManager.redistributeBuckets(invId, updated.getLq());\n        }\n        \n    } finally {\n        if (lock != null &amp;&amp; lock.isHeldByCurrentThread()) {\n            lock.unlock();\n        }\n    }\n}\n</code></pre>\n<p><strong>SQL 优化：覆盖索引</strong></p>\n<pre><code class=\"language-sql\">-- 扫描待处理明细，按 flow_type 分组求和\nSELECT flow_type, SUM(quantity) AS total_quantity\nFROM inventory_deduct_detail\nWHERE inv_id = ? AND status = 0\nGROUP BY flow_type;\n\n-- 使用覆盖索引 idx_inv_status_flow (inv_id, status, flow_type)\n-- 无需回表，极致提速\n</code></pre>\n<hr />\n<h2 id=\"六常见问题解答\">六、常见问题解答</h2>\n<h3 id=\"q1分桶全量置-0-时新请求如何处理\">Q1：分桶全量置 0 时，新请求如何处理？</h3>\n<p><strong>答：</strong> 分桶置 0 ≠ 拒绝请求，通过分层降级保证请求不中断。</p>\n<p><strong>处理流程：</strong></p>\n<ol>\n<li><strong>自动降级到低并发流程</strong>：99% 请求走此流程，跳过 Redis 分桶</li>\n<li><strong>智能检查 SQ+LQ 总库存</strong>：\n<ul>\n<li>如果 SQ 足够：创建 SQ→WQ 明细</li>\n<li>如果 SQ 不足但 SQ+LQ 足够：\n<ul>\n<li>先用完 SQ：创建 SQ→WQ 明细</li>\n<li>剩余部分用 LQ：创建 LQ→WQ 明细</li>\n</ul>\n</li>\n<li>如果 SQ+LQ 都不足：返回库存不足</li>\n</ul>\n</li>\n<li><strong>所有操作先插明细</strong>：保证流转可追溯，由定时任务统一合并</li>\n</ol>\n<p><strong>代码示例：</strong></p>\n<pre><code class=\"language-java\">// 低并发流程智能选择 SQ/LQ\nif (inventory.getSq() &gt;= quantity) {\n    // SQ 足够，全部从 SQ 扣减\n    insertDetail(invId, orderNo, quantity, 2); // SQ→WQ\n    \n} else if (inventory.getSq() &gt; 0) {\n    // SQ 不足，混合扣减\n    insertDetail(invId, orderNo, inventory.getSq(), 2); // SQ→WQ\n    insertDetail(invId, orderNo + \"_LQ\", quantity - inventory.getSq(), 1); // LQ→WQ\n    \n} else {\n    // SQ 为 0，全部从 LQ 扣减\n    insertDetail(invId, orderNo, quantity, 1); // LQ→WQ\n}\n</code></pre>\n<p><strong>关键保障：</strong></p>\n<ul>\n<li>分桶置 0 时长极短（50ms 内），用户无感知</li>\n<li>新请求库存校验以 DB 为准，不依赖 Redis</li>\n<li>低并发流程会充分利用 SQ+LQ 总库存，避免\"有库存却卖不出去\"</li>\n</ul>\n<h3 id=\"q2前端展示-sqlq用户付款后库存未变如何解决\">Q2：前端展示 SQ+LQ，用户付款后库存未变，如何解决？</h3>\n<p><strong>答：</strong> 前端展示的是 <code>SQ + LQ</code>（总可售库存），采用批量异步更新，避免高并发下展示波动。</p>\n<p><strong>核心原因：</strong></p>\n<ul>\n<li>用户下单：创建 SQ→WQ 或 LQ→WQ 明细（status=0，待处理）</li>\n<li>用户付款：创建 WQ→OQ 明细（status=0，待处理）</li>\n<li>定时任务：每 50ms 扫描待处理明细，批量更新主表</li>\n<li>前端展示：<code>SQ + LQ</code> 在定时任务执行后才会更新</li>\n</ul>\n<p><strong>时间线示例：</strong></p>\n<pre><code>T0: 用户下单 3 件\n    - 插入明细：LQ→WQ, quantity=3, status=0\n    - 主表状态：SQ=500, LQ=500, WQ=0, OQ=0\n    - 前端显示：1000 件\n\nT1 (10ms): 用户付款\n    - 插入明细：WQ→OQ, quantity=3, status=0\n    - 主表状态：SQ=500, LQ=500, WQ=0, OQ=0\n    - 前端显示：1000 件（未变）\n\nT2 (50ms): 定时任务执行\n    - 扫描明细：LQ→WQ(3), WQ→OQ(3)\n    - 更新主表：LQ-=3, WQ+=3-3=0, OQ+=3\n    - 主表状态：SQ=500, LQ=497, WQ=0, OQ=3\n    - 前端显示：997 件（已更新）\n</code></pre>\n<p><strong>前端展示优化方案：</strong></p>\n<table>\n<thead>\n<tr>\n<th>页面类型</th>\n<th>展示内容</th>\n<th>优化逻辑</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>商品列表页</td>\n<td>SQ+LQ + 库存状态文案</td>\n<td>\"库存充足 / 即将售罄 / 仅剩 XX 件\"</td>\n</tr>\n<tr>\n<td>商品详情页</td>\n<td>SQ+LQ + 实时备货总量</td>\n<td>\"997 件可售，共 1000 件备货\"</td>\n</tr>\n<tr>\n<td>订单确认页</td>\n<td>订单状态 + 锁定提示</td>\n<td>\"已锁定 3 件库存，待发货\"</td>\n</tr>\n</tbody>\n</table>\n<p><strong>可选优化：</strong></p>\n<ul>\n<li>调整合并提交阈值：从 ≥100 条改为 ≥50 条</li>\n<li>调整定时任务：从 50ms 改为 200ms</li>\n<li>高并发结束后触发 SQ+LQ 实时更新</li>\n</ul>\n<p><strong>关键点：</strong></p>\n<ul>\n<li>前端展示的是 <code>SQ + LQ</code>，不是单独的 SQ</li>\n<li>用户关注的是\"能买多少\"，而不是具体的 SQ 或 LQ 数值</li>\n<li>批量更新避免了高并发下的展示波动（如 1000→997→998→997）</li>\n</ul>\n<h3 id=\"q3商家总可售-1000用户下单-999-件是否会成功\">Q3：商家总可售 1000，用户下单 999 件，是否会成功？</h3>\n<p><strong>答：</strong> 绝对不可能成功，三层防护层层阻断。</p>\n<p><strong>第一层：商家单品限购（业务硬限制）</strong></p>\n<pre><code class=\"language-java\">if (quantity &gt; product.getMaxPurchaseQty()) {\n    throw new IllegalArgumentException(\"单次最多购买 \" + maxQty + \" 件\");\n}\n</code></pre>\n<p><strong>第二层：库存总量校验（50% 限制）</strong></p>\n<pre><code class=\"language-java\">Integer totalSalable = inventory.getSq() + inventory.getLq();\nInteger maxAllowed = (int) (totalSalable * 0.5);\nif (quantity &gt; maxAllowed) {\n    throw new IllegalArgumentException(\"单次购买不能超过总库存的 50%\");\n}\n</code></pre>\n<p><strong>第三层：技术层扣减失败</strong></p>\n<ul>\n<li>Redis 分桶：总数 = 500 &lt; 999 → 所有分桶扣减失败</li>\n<li>低并发流程：SQ=500 &lt; 999 → 库存不足</li>\n<li>DB 兜底：<code>UPDATE inventory SET sq=sq-999 WHERE sq&gt;=999</code> → 影响行数 = 0</li>\n</ul>\n<h3 id=\"q4redis-宕机后系统如何保证可用性\">Q4：Redis 宕机后，系统如何保证可用性？</h3>\n<p><strong>答：</strong> 完整的降级机制，保证 Redis 不可用时系统仍能正常运行。</p>\n<p><strong>降级策略：</strong></p>\n<ol>\n<li>\n<p><strong>下单扣减降级</strong></p>\n<pre><code class=\"language-java\">try {\n    // 尝试 Redis 分桶扣减\n    return deductInventoryHighConcurrency(...);\n} catch (RedisException e) {\n    // Redis 异常，自动降级到低并发流程\n    return deductInventoryLowConcurrency(...);\n}\n</code></pre>\n</li>\n<li>\n<p><strong>定时任务降级</strong></p>\n<pre><code class=\"language-java\">try {\n    // 尝试获取 Redis 分布式锁\n    lock = redissonClient.getLock(...);\n} catch (Exception e) {\n    // Redis 不可用，跳过锁，依赖数据库乐观锁\n    lock = null;\n}\n</code></pre>\n</li>\n<li>\n<p><strong>分桶操作降级</strong></p>\n<pre><code class=\"language-java\">try {\n    bucketManager.lockAllBuckets(invId);\n} catch (Exception e) {\n    // Redis 不可用，记录警告，继续执行合并\n    log.warn(\"锁定 Redis 分桶失败，继续执行合并\");\n}\n</code></pre>\n</li>\n</ol>\n<p><strong>关键配置：</strong></p>\n<pre><code class=\"language-yaml\">spring:\n  data:\n    redis:\n      timeout: 1000ms  # 超时 1 秒，快速失败\n      connect-timeout: 1000ms\n</code></pre>\n<h3 id=\"q5如何防止超卖和少卖\">Q5：如何防止超卖和少卖？</h3>\n<p><strong>答：</strong> 多层防护机制，确保零超卖、零少卖。</p>\n<p><strong>防超卖设计：</strong></p>\n<ol>\n<li>\n<p><strong>Redis 层防超卖</strong></p>\n<pre><code class=\"language-bash\"># DECRBY 返回值必须 &gt;= 0\nDECRBY inventory:bucket:1:0 3\n# 返回 -1 → 回补 → 重试其他分桶\n</code></pre>\n</li>\n<li>\n<p><strong>DB 层防超卖</strong></p>\n<pre><code class=\"language-sql\">-- 更新时加数值条件\nUPDATE inventory \nSET sq = sq - 3 \nWHERE inv_id = 1 AND sq &gt;= 3;\n</code></pre>\n</li>\n<li>\n<p><strong>业务层防超卖</strong></p>\n<ul>\n<li>单品限购</li>\n<li>50% 总库存限制</li>\n<li>幂等性保证（唯一索引）</li>\n</ul>\n</li>\n</ol>\n<p><strong>防少卖设计：</strong></p>\n<ol>\n<li>\n<p><strong>以 DB 明细为准</strong></p>\n<ul>\n<li>Redis 超时 → 明细仍会被合并提交</li>\n<li>实际扣减了多少，以 DB 明细求和为准</li>\n</ul>\n</li>\n<li>\n<p><strong>低并发智能选择 SQ/LQ</strong></p>\n<ul>\n<li>检查 SQ+LQ 总库存</li>\n<li>SQ 不足时自动使用 LQ</li>\n<li>避免\"有库存却卖不出去\"的问题</li>\n</ul>\n<pre><code class=\"language-java\">// 示例：SQ=2, LQ=1000, 用户下单 5 件\n// 传统方案：SQ 不足，扣减失败（少卖 5 件）\n// 本方案：SQ(2) + LQ(3) → 扣减成功\n</code></pre>\n</li>\n<li>\n<p><strong>Redis 数据恢复</strong></p>\n<ul>\n<li>合并提交后重新分配分桶</li>\n<li>分桶总数始终 = LQ 值</li>\n<li>Redis 宕机恢复后自动同步</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"q6合并提交的性能如何会不会成为瓶颈\">Q6：合并提交的性能如何？会不会成为瓶颈？</h3>\n<p><strong>答：</strong> 通过覆盖索引和批量更新，性能影响极小。</p>\n<p><strong>性能优化：</strong></p>\n<ol>\n<li>\n<p><strong>覆盖索引</strong></p>\n<pre><code class=\"language-sql\">-- 索引：idx_inv_status_flow (inv_id, status, flow_type)\n-- 包含 quantity 字段，无需回表\nSELECT flow_type, SUM(quantity) AS total_quantity\nFROM inventory_deduct_detail\nWHERE inv_id = 1 AND status = 0\nGROUP BY flow_type;\n</code></pre>\n</li>\n<li>\n<p><strong>批量更新</strong></p>\n<pre><code class=\"language-sql\">-- 一次 SQL 更新所有字段\nUPDATE inventory \nSET sq = sq - 3, wq = wq + 3, version = version + 1\nWHERE inv_id = 1 AND version = 5;\n</code></pre>\n</li>\n<li>\n<p><strong>异步非阻塞</strong></p>\n<ul>\n<li>定时任务独立线程执行</li>\n<li>不阻塞用户请求</li>\n<li>50ms 内完成合并</li>\n</ul>\n</li>\n</ol>\n<p><strong>压测数据：</strong></p>\n<ul>\n<li>单行热点扣减：TPS 提升 1 倍以上</li>\n<li>合并提交耗时：平均 10-20ms</li>\n<li>DB 压力：远低于实时更新（减少 90% 以上更新次数）</li>\n</ul>\n<h3 id=\"q7如何实现幂等性\">Q7：如何实现幂等性？</h3>\n<p><strong>答：</strong> 通过唯一索引天然实现幂等性。</p>\n<p><strong>唯一索引设计：</strong></p>\n<pre><code class=\"language-sql\">UNIQUE KEY `uk_inv_order` (`inv_id`, `lock_order_id`)\n</code></pre>\n<p><strong>幂等性保证：</strong></p>\n<pre><code class=\"language-java\">try {\n    // 插入明细\n    detailMapper.insert(detail);\n} catch (DuplicateKeyException e) {\n    // 重复订单，直接返回成功\n    return \"扣减成功（幂等）\";\n}\n</code></pre>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>用户重复点击下单按钮</li>\n<li>网络超时后重试</li>\n<li>消息队列重复消费</li>\n</ul>\n<h3 id=\"q8分桶数量如何选择\">Q8：分桶数量如何选择？</h3>\n<p><strong>答：</strong> 根据并发量和库存量动态调整。</p>\n<p><strong>推荐配置：</strong></p>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>并发量</th>\n<th>库存量</th>\n<th>分桶数量</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>低并发</td>\n<td>&lt; 100</td>\n<td>&lt; 1000</td>\n<td>5-10</td>\n</tr>\n<tr>\n<td>中并发</td>\n<td>100-1000</td>\n<td>1000-10000</td>\n<td>10-20</td>\n</tr>\n<tr>\n<td>高并发</td>\n<td>1000-5000</td>\n<td>10000+</td>\n<td>20-50</td>\n</tr>\n<tr>\n<td>极限并发</td>\n<td>5000+</td>\n<td>100000+</td>\n<td>50-100</td>\n</tr>\n</tbody>\n</table>\n<p><strong>动态调整：</strong></p>\n<pre><code class=\"language-java\">// 高峰期动态加桶\npublic void addBuckets(Long invId, Integer newBucketCount) {\n    // 1. 锁定现有分桶\n    bucketManager.lockAllBuckets(invId);\n    \n    // 2. 按新数量重新分配\n    bucketManager.redistributeBuckets(invId, lq, newBucketCount);\n    \n    // 3. 更新配置表\n    bucketConfigMapper.updateBucketCount(invId, newBucketCount);\n}\n</code></pre>\n<hr />\n<h2 id=\"七性能测试与优化\">七、性能测试与优化</h2>\n<h3 id=\"71-压测环境\">7.1 压测环境</h3>\n<p><strong>硬件配置：</strong></p>\n<ul>\n<li>应用服务器：4 核 8G，2 台</li>\n<li>MySQL：8 核 16G，主从复制</li>\n<li>Redis：4 核 8G，哨兵模式</li>\n</ul>\n<p><strong>测试工具：</strong></p>\n<ul>\n<li>JMeter 5.5</li>\n<li>并发线程：100 / 500 / 1000 / 5000</li>\n<li>持续时间：60 秒</li>\n</ul>\n<h3 id=\"72-压测结果\">7.2 压测结果</h3>\n<h4 id=\"721-单行热点扣减对比\">7.2.1 单行热点扣减对比</h4>\n<table>\n<thead>\n<tr>\n<th>方案</th>\n<th>TPS</th>\n<th>平均响应时间</th>\n<th>成功率</th>\n<th>DB QPS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>纯 DB 扣减</td>\n<td>1,200</td>\n<td>450ms</td>\n<td>85%</td>\n<td>1,200</td>\n</tr>\n<tr>\n<td>传统 Redis 分桶</td>\n<td>8,500</td>\n<td>60ms</td>\n<td>80%</td>\n<td>8,500</td>\n</tr>\n<tr>\n<td><strong>本方案</strong></td>\n<td><strong>18,000</strong></td>\n<td><strong>30ms</strong></td>\n<td><strong>100%</strong></td>\n<td><strong>180</strong></td>\n</tr>\n</tbody>\n</table>\n<p><strong>关键指标：</strong></p>\n<ul>\n<li>✅ TPS 提升 <strong>1.5 倍</strong>（相比传统 Redis 分桶）</li>\n<li>✅ 成功率 <strong>100%</strong>（零超卖、零少卖）</li>\n<li>✅ DB 压力降低 <strong>98%</strong>（合并提交批量更新）</li>\n</ul>\n<h4 id=\"722-不同并发量下的表现\">7.2.2 不同并发量下的表现</h4>\n<table>\n<thead>\n<tr>\n<th>并发量</th>\n<th>TPS</th>\n<th>响应时间</th>\n<th>成功率</th>\n<th>CPU 使用率</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>100</td>\n<td>3,500</td>\n<td>15ms</td>\n<td>100%</td>\n<td>25%</td>\n</tr>\n<tr>\n<td>500</td>\n<td>12,000</td>\n<td>25ms</td>\n<td>100%</td>\n<td>45%</td>\n</tr>\n<tr>\n<td>1000</td>\n<td>18,000</td>\n<td>30ms</td>\n<td>100%</td>\n<td>65%</td>\n</tr>\n<tr>\n<td>5000</td>\n<td>22,000</td>\n<td>120ms</td>\n<td>100%</td>\n<td>85%</td>\n</tr>\n</tbody>\n</table>\n<p><strong>结论：</strong></p>\n<ul>\n<li>1000 并发以下：性能优异，响应时间稳定</li>\n<li>5000 并发：仍能保持 100% 成功率，但响应时间增加</li>\n</ul>\n<h3 id=\"73-性能优化建议\">7.3 性能优化建议</h3>\n<h4 id=\"731-数据库优化\">7.3.1 数据库优化</h4>\n<p><strong>1. 索引优化</strong></p>\n<pre><code class=\"language-sql\">-- 覆盖索引，避免回表\nCREATE INDEX idx_inv_status_flow \nON inventory_deduct_detail (inv_id, status, flow_type, quantity);\n\n-- 分区表，历史数据归档\nALTER TABLE inventory_deduct_detail \nPARTITION BY RANGE (YEAR(create_time)) (\n    PARTITION p2024 VALUES LESS THAN (2025),\n    PARTITION p2025 VALUES LESS THAN (2026)\n);\n</code></pre>\n<p><strong>2. 读写分离</strong></p>\n<pre><code class=\"language-yaml\">spring:\n  datasource:\n    master:\n      url: jdbc:mysql://master:3306/shop_chunk_redis\n    slave:\n      url: jdbc:mysql://slave:3306/shop_chunk_redis\n</code></pre>\n<p><strong>3. 连接池优化</strong></p>\n<pre><code class=\"language-yaml\">spring:\n  datasource:\n    druid:\n      initial-size: 20\n      min-idle: 20\n      max-active: 100\n      max-wait: 60000\n</code></pre>\n<h4 id=\"732-redis-优化\">7.3.2 Redis 优化</h4>\n<p><strong>1. 持久化配置</strong></p>\n<pre><code class=\"language-conf\"># AOF + RDB 混合持久化\nappendonly yes\nappendfsync everysec\nsave 900 1\nsave 300 10\n</code></pre>\n<p><strong>2. 内存优化</strong></p>\n<pre><code class=\"language-conf\"># 最大内存\nmaxmemory 4gb\n# 淘汰策略\nmaxmemory-policy allkeys-lru\n</code></pre>\n<p><strong>3. 集群模式</strong></p>\n<pre><code># Redis Cluster（高可用）\nredis-cli --cluster create \\\n  192.168.1.1:6379 \\\n  192.168.1.2:6379 \\\n  192.168.1.3:6379 \\\n  --cluster-replicas 1\n</code></pre>\n<h4 id=\"733-应用层优化\">7.3.3 应用层优化</h4>\n<p><strong>1. 异步处理</strong></p>\n<pre><code class=\"language-java\">@Async\npublic CompletableFuture&lt;String&gt; deductInventoryAsync(...) {\n    return CompletableFuture.completedFuture(\n        deductInventoryHighConcurrency(...)\n    );\n}\n</code></pre>\n<p><strong>2. 批量操作</strong></p>\n<pre><code class=\"language-java\">// 批量插入明细\ndetailMapper.insertBatch(detailList);\n\n// 批量更新 Redis\nredisTemplate.executePipelined((RedisCallback&lt;Object&gt;) connection -&gt; {\n    for (String key : keys) {\n        connection.decr(key.getBytes());\n    }\n    return null;\n});\n</code></pre>\n<p><strong>3. 缓存预热</strong></p>\n<pre><code class=\"language-java\">@PostConstruct\npublic void warmUp() {\n    // 应用启动时预热热点商品库存\n    List&lt;Long&gt; hotProducts = productMapper.selectHotProducts();\n    for (Long productId : hotProducts) {\n        inventoryService.preheatInventory(productId);\n    }\n}\n</code></pre>\n<h3 id=\"74-监控告警\">7.4 监控告警</h3>\n<h4 id=\"741-关键指标监控\">7.4.1 关键指标监控</h4>\n<p><strong>1. 业务指标</strong></p>\n<ul>\n<li>下单成功率</li>\n<li>库存扣减 TPS</li>\n<li>合并提交延迟</li>\n<li>订单超时率</li>\n</ul>\n<p><strong>2. 技术指标</strong></p>\n<ul>\n<li>Redis 命中率</li>\n<li>DB 慢查询</li>\n<li>应用 CPU/内存</li>\n<li>接口响应时间</li>\n</ul>\n<h4 id=\"742-告警规则\">7.4.2 告警规则</h4>\n<pre><code class=\"language-yaml\"># Prometheus 告警规则\ngroups:\n  - name: inventory_alerts\n    rules:\n      # 下单成功率低于 95%\n      - alert: LowOrderSuccessRate\n        expr: order_success_rate &lt; 0.95\n        for: 1m\n        \n      # 合并提交延迟超过 100ms\n      - alert: HighMergeDelay\n        expr: merge_commit_duration_ms &gt; 100\n        for: 5m\n        \n      # Redis 不可用\n      - alert: RedisDown\n        expr: redis_up == 0\n        for: 1m\n</code></pre>\n<hr />\n<h2 id=\"八总结与展望\">八、总结与展望</h2>\n<h3 id=\"81-核心优势\">8.1 核心优势</h3>\n<ol>\n<li>\n<p><strong>高性能</strong></p>\n<ul>\n<li>TPS 提升 1.5 倍以上</li>\n<li>响应时间降低 50%</li>\n<li>DB 压力降低 98%</li>\n</ul>\n</li>\n<li>\n<p><strong>强一致性</strong></p>\n<ul>\n<li>零超卖：多层防护机制</li>\n<li>零少卖：以 DB 明细为准</li>\n<li>幂等性：唯一索引保证</li>\n</ul>\n</li>\n<li>\n<p><strong>高可用</strong></p>\n<ul>\n<li>Redis 宕机自动降级</li>\n<li>数据库乐观锁兜底</li>\n<li>完整的容错机制</li>\n</ul>\n</li>\n<li>\n<p><strong>易扩展</strong></p>\n<ul>\n<li>支持复杂库存模型（SQ/LQ/WQ/OQ）</li>\n<li>动态调整分桶数量</li>\n<li>灵活的流转规则</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"82-适用场景\">8.2 适用场景</h3>\n<p>✅ <strong>适合：</strong></p>\n<ul>\n<li>电商秒杀活动</li>\n<li>直播带货</li>\n<li>限量发售</li>\n<li>高并发下单场景</li>\n</ul>\n<p>❌ <strong>不适合：</strong></p>\n<ul>\n<li>低并发场景（纯 DB 扣减即可）</li>\n<li>对库存实时性要求极高的场景</li>\n<li>无法接受最终一致性的场景</li>\n</ul>\n<h3 id=\"83-开源地址\">8.3 开源地址</h3>\n<p>本项目已开源，做了简单的前后端演示</p>\n<ul>\n<li><strong>Gitee</strong>：<a href=\"https://gitee.com/zouyua/shop_chunk_redis\" rel=\"noopener nofollow\" target=\"_blank\">shop_chunk_redis</a></li>\n<li><strong>技术栈</strong>：Spring Boot + MyBatis-Plus + Redis + Vue 3</li>\n<li><strong>文档</strong>：完整的配置指南和 API 文档</li>\n<li><strong>测试数据</strong>：包含 mock 数据，开箱即用</li>\n</ul>\n<h3 id=\"84-参考资料\">8.4 参考资料</h3>\n<ol>\n<li><a href=\"https://mp.weixin.qq.com/s/_ezTVydFszZnc0ZN-JEtlQ\" rel=\"noopener nofollow\" target=\"_blank\">阿里云 - 库存合并扣减方案</a></li>\n<li><a href=\"https://redis.io/documentation\" rel=\"noopener nofollow\" target=\"_blank\">Redis 官方文档</a></li>\n<li><a href=\"https://baomidou.com/\" rel=\"noopener nofollow\" target=\"_blank\">MyBatis-Plus 官方文档</a></li>\n<li><a href=\"https://spring.io/projects/spring-boot\" rel=\"noopener nofollow\" target=\"_blank\">Spring Boot 官方文档</a></li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 09:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ZouYua\">zouyua</a>&nbsp;\n阅读(<span id=\"post_view_count\">24</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AQS深度探索：以ReentrantLock看Java并发编程的高效实现",
      "link": "https://www.cnblogs.com/sevencoding/p/19587937",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sevencoding/p/19587937\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 09:00\">\n    <span>AQS深度探索：以ReentrantLock看Java并发编程的高效实现</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"概述\">概述</h2>\n<p>AQS ( Abstract Queued Synchronizer ）是一个抽象的队列同步器，通过维护一个共享资源状态（ Volatile Int State ）来表示同步状态 和一个先进先出（ FIFO ）的线程<strong>等待队列</strong>来完成资源获取的排队工作，通过CAS完成对State值的修改。</p>\n<p>AQS整体框架如下：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047981.gif\" /></p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047987.gif\" /></p>\n<p>当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层</p>\n<h2 id=\"原理\">原理</h2>\n<p>AQS 为每个共享资源都设置一个共享资源锁，线程在需要访问共享资源时首先需要获取共享资源锁，如果获取到了共享资源锁，便可以在当前线程中使用该共享资源，如果获取不到，则将该线程放入线程等待队列，等待下一次资源调度，流程图如下所示：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047983.gif\" /></p>\n<p>Java中的大部分同步类（Lock、Semaphore、ReentrantLock等）都是基于AbstractQueuedSynchronizer（简称为AQS）实现的。</p>\n<h2 id=\"底层结构\">底层结构</h2>\n<h3 id=\"state状态\">state：状态</h3>\n<p>Abstract Queued Synchronizer 维护了 volatile int 类型的变量，用于表示当前的同步状态。volatile虽然不能保证操作的原子性，但是能保证当前变量state的可见性。</p>\n<p>state的访问方式有三种： getState()、setState()和 compareAndSetState()，均是原子操作，其中，compareAndSetState的实现依赖于 Unsafe的compareAndSwaplnt()</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\nprivate volatile int state;\n\nprotected final int getState() {\n    return state;\n}\n\nprotected final void setState(int newState) {\n    state = newState;\n}\n\nprotected final boolean compareAndSetState(int expect, int update) {\n    // See below for intrinsics setup to support this\n    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);\n}\n</code></pre>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047977.gif\" /></p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047997.gif\" /></p>\n<h3 id=\"clh队列\">CLH队列</h3>\n<p>Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047000.gif\" /></p>\n<p>AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。</p>\n<h3 id=\"aqs的独占式和共享式\">AQS的独占式和共享式</h3>\n<ul>\n<li>\n<p>独占式:只有一个线程能执行，具体的 Java 实现有 ReentrantLock。</p>\n</li>\n<li>\n<p>共享式：多个线程可同时执行，具体的 Java 实现有 Semaphore和CountDownLatch。</p>\n</li>\n</ul>\n<p>AQS只是一个框架 ，只定义了一个接口，具体资源的获取、释放都由自定义同步器去实现。不同的自定义同步器争用共享资源的方式也不同，自定义同步器在实现时只需实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护，如获取资源失败入队、唤醒出队等， AQS 已经在顶层实现好（就是模板方法模式），不需要具体的同步器再做处理。自定义同步器实现时主要实现以下几种方法：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047629.gif\" /></p>\n<ul>\n<li>\n<p>以ReentrantLock为例，ReentrantLock中的state初始值为0表示无锁状态。在线程执行 tryAcquire()获取该锁后ReentrantLock中的state+1，这时该线程独占ReentrantLock锁，其他线程在通过tryAcquire() 获取锁时均会失败，直到该线程释放锁后state再次为0，其他线程才有机会获取该锁。该线程在释放锁之前可以重复获取此锁，每获取一次便会执行一次state+1, 因此ReentrantLock也属于可重入锁。 但获取多少次锁就要释放多少次锁，这样才能保证state最终为0。如果获取锁的次数多于释放锁的次数，则会出现该线程一直持有该锁的情况；如果获取锁的次数少于释放锁的次数，则运行中的程序会报锁异常。</p>\n</li>\n<li>\n<p>以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后面的动作。</p>\n</li>\n<li>\n<p>以Semaphore为例，state则代表可以同时访问的线程数量，也可能理解为访问的许可证（permit）数量。每个线程访问(acquire)时需要拿到对应的许可证，否则进行阻塞，访问结束则返还（release）许可证。state只能在Semaphore的构造方法中进行初始化，后续不能进行修改。</p>\n</li>\n</ul>\n<p>一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。</p>\n<h3 id=\"node节点\">Node节点</h3>\n<p>Node即为上面CLH变体队列中的节点。</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047676.gif\" /></p>\n<p>Node结点是每一个等待获取资源的线程的封装，其包含了需要同步的线程本身及其等待状态waitStatus</p>\n<p>Node中几个方法和属性值的含义：</p>\n<ul>\n<li>\n<p>waitStatus：当前节点在队列中的状态</p>\n</li>\n<li>\n<p>thread：表示处于该节点的线程</p>\n</li>\n<li>\n<p>prev：前驱指针</p>\n</li>\n<li>\n<p>predecessor：返回前驱节点，没有的话抛出npe</p>\n</li>\n<li>\n<p>nextWaiter：指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍）</p>\n</li>\n<li>\n<p>next：后继指针</p>\n</li>\n</ul>\n<h3 id=\"等待状态waitstatus\">等待状态waitStatus</h3>\n<p>waitStatus有下面几个枚举值：如是否被阻塞、是否等待唤醒、是否已经被取消等。共有5种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE、0。</p>\n<ul>\n<li>\n<p>CANCELLED(1)：表示当前结点已取消调度，不再想去获取资源了。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。</p>\n</li>\n<li>\n<p>SIGNAL(-1)：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL。</p>\n</li>\n<li>\n<p>CONDITION(-2)：表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。</p>\n</li>\n<li>\n<p>PROPAGATE(-3)：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。</p>\n</li>\n<li>\n<p>0：新结点入队时的默认状态。</p>\n</li>\n</ul>\n<p>注意，负值表示结点处于有效等待状态，而正值表示结点已被取消。所以源码中很多地方用&gt;0、&lt;0来判断结点的状态是否正常。</p>\n<h2 id=\"源码\">源码</h2>\n<p>以ReentrantLock的非公平锁为例，将加锁和解锁的交互流程单独拎出来强调一下</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047699.gif\" /></p>\n<p>加锁：</p>\n<ol>\n<li>通过ReentrantLock的加锁方法Lock进行加锁操作。</li>\n<li>会调用到内部类 Sync的Lock方法，由于Sync#lock是抽象方法，根据 ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的 Acquire 方法。</li>\n<li>AQS的 Acquire 方法会执行 tryAcquire 方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。</li>\n<li>tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。</li>\n</ol>\n<p>解锁：</p>\n<ol>\n<li>通过ReentrantLock的解锁方法Unlock进行解锁。</li>\n<li>Unlock会调用内部类Sync的Release方法，该方法继承于AQS。</li>\n<li>Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。</li>\n<li>释放成功后，所有处理由AQS框架完成，与自定义同步器无关。</li>\n</ol>\n<h3 id=\"acquireint\">acquire(int)</h3>\n<p>此方法是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。这也正是lock()的语义，当然不仅仅只限于lock()。获取到资源后，线程就可以去执行其临界区代码了。</p>\n<pre><code class=\"language-java\">public final void acquire(int arg) {\n     if (!tryAcquire(arg) &amp;&amp;\n         acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n         selfInterrupt();\n}\n</code></pre>\n<p>函数流程如下：</p>\n<ol>\n<li>tryAcquire()尝试直接去获取资源，如果成功则直接返回（这里体现了非公平锁，每个线程获取锁时会尝试直接抢占加塞一次，而CLH队列中可能还有别的线程在等待）；</li>\n<li>addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；</li>\n<li>acquireQueued()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。</li>\n<li>如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。</li>\n</ol>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047722.gif\" /></p>\n<p>关于整个函数流程详解，可以往下看</p>\n<h4 id=\"tryacquireint\">tryAcquire(int)</h4>\n<p>此方法尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。这也正是tryLock()的语义，当然不仅仅只限于tryLock()。</p>\n<pre><code class=\"language-java\">protected boolean tryAcquire(int arg) {\n     throw new UnsupportedOperationException();\n}\n</code></pre>\n<p>这里是AQS的方法，所以直接throw异常，而没有具体的实现。原因就在于AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现。</p>\n<p>这里之所以没有定义成abstract，是因为独占模式下只用实现tryAcquire-tryRelease，而共享模式下只用实现tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模式下的接口。</p>\n<p><strong>ReentrantLock实现公平锁非公平锁则主要体现在tryAcquire的实现上：</strong></p>\n<p>公平锁中实现的tryAcquire：</p>\n<pre><code class=\"language-java\">protected final boolean tryAcquire(int acquires) {\n    final Thread current = Thread.currentThread();\n    int c = getState();\n    if (c == 0) {\n           if (!hasQueuedPredecessors() &amp;&amp;  //公平锁加锁时判断等待队列中是否存在有效节点的方法\n                compareAndSetState(0, acquires)) {\n                setExclusiveOwnerThread(current);\n                return true;\n           }\n     }\n     else if (current == getExclusiveOwnerThread()) {\n           int nextc = c + acquires;\n           if (nextc &lt; 0)\n                throw new Error(\"Maximum lock count exceeded\");\n           setState(nextc);\n           return true;\n     }\n     return false;\n}\n</code></pre>\n<p>非公平锁中实现的tryAcquire：</p>\n<pre><code class=\"language-java\">protected final boolean tryAcquire(int acquires) {\n    return nonfairTryAcquire(acquires);\n}\n\nfinal boolean nonfairTryAcquire(int acquires) {\n     final Thread current = Thread.currentThread();\n     int c = getState();\n     if (c == 0) {\n           if (compareAndSetState(0, acquires)) {\n               setExclusiveOwnerThread(current);\n               return true;\n           }\n      }\n      else if (current == getExclusiveOwnerThread()) {\n           int nextc = c + acquires;\n           if (nextc &lt; 0) // overflow\n                throw new Error(\"Maximum lock count exceeded\");\n           setState(nextc);\n           return true;\n      }\n      return false;\n}\n</code></pre>\n<ul>\n<li>\n<p>公平锁中多了一层 !hasQueuedPredecessors() 的判断，这是公平锁加锁时判断等待队列中是否存在有效节点的方法。如果返回False，说明当前线程可以获取共享资源；如果返回True，说明队列中存在有效节点，当前线程必须加入到等待队列中。</p>\n</li>\n<li>\n<p>而在非公平锁中，没有这个判断，直接尝试获取锁，能获取到锁则不用加入等待队列。</p>\n</li>\n</ul>\n<pre><code class=\"language-java\">public final boolean hasQueuedPredecessors() {\n        // The correctness of this depends on head being initialized\n        // before tail and on head.next being accurate if the current\n        // thread is first in queue.\n        Node t = tail; // Read fields in reverse initialization order\n        Node h = head;\n        Node s;\n        return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());\n}\n</code></pre>\n<p>这里的判断 h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());为什么要判断的头结点的下一个节点？第一个节点储存的数据是什么？</p>\n<p>双向链表中，第一个节点为虚节点，其实并不存储任何信息，只是占位。真正的第一个有数据的节点，是在第二个节点开始的。当h != t时： 如果(s = h.next) == null，等待队列正在有线程进行初始化，但只是进行到了Tail指向Head，没有将Head指向Tail，此时队列中有元素，需要返回True。 如果(s = h.next) != null，说明此时队列中至少有一个有效节点。如果此时s.thread == Thread.currentThread()，说明等待队列的第一个有效节点中的线程与当前线程相同，那么当前线程是可以获取资源的；如果s.thread != Thread.currentThread()，说明等待队列的第一个有效节点线程与当前线程不同，当前线程必须加入进等待队列。</p>\n<h4 id=\"addwaiternode\">addWaiter(Node)</h4>\n<p>此方法用于将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。</p>\n<pre><code class=\"language-java\">private Node addWaiter(Node mode) {\n    //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享）\n    Node node = new Node(Thread.currentThread(), mode);\n\n    //尝试快速方式直接放到队尾。\n    Node pred = tail;\n    if (pred != null) {\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n\n    //上一步失败则通过enq入队。\n    enq(node);\n    return node;\n}\n</code></pre>\n<p>主要的流程如下：</p>\n<ol>\n<li>通过当前的线程和锁模式新建一个节点。</li>\n<li>Pred指针指向尾节点Tail。</li>\n<li>将New中Node的Prev指针指向Pred。</li>\n<li>通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。</li>\n</ol>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\n\nstatic {\n    try {\n        stateOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"state\"));\n        headOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"head\"));\n        tailOffset = unsafe.objectFieldOffset(AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\"));\n        waitStatusOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"waitStatus\"));\n        nextOffset = unsafe.objectFieldOffset(Node.class.getDeclaredField(\"next\"));\n    } catch (Exception ex) { \n    throw new Error(ex); \n  }\n}\n</code></pre>\n<p>从AQS的静态代码块可以看出，都是获取一个对象的属性相对于该对象在内存当中的偏移量，这样我们就可以根据这个偏移量在对象内存当中找到这个属性。tailOffset指的是tail对应的偏移量，所以这个时候会将new出来的Node置为当前队列的尾节点。同时，由于是双向链表，也需要将前一个节点指向尾节点。</p>\n<p>如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改）,就需要enq入队</p>\n<pre><code class=\"language-java\">private Node enq(final Node node) {\n    //CAS\"自旋\"，直到成功加入队尾\n    for (;;) {\n        Node t = tail;\n        if (t == null) { // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。\n            if (compareAndSetHead(new Node()))\n                tail = head;\n        } else {//正常流程，放入队尾\n            node.prev = t;\n            if (compareAndSetTail(t, node)) {\n                t.next = node;\n                return t;\n            }\n        }\n    }\n}\n</code></pre>\n<p>如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047743.gif\" /></p>\n<h4 id=\"acquirequeuednode-int\">acquireQueued(Node, int)</h4>\n<p>通过tryAcquire()和addWaiter()，该线程获取资源失败，已经被放入等待队列尾部了。addWaiter()返回的是一个包含该线程的Node。而这个Node会作为参数，进入到acquireQueued方法中。acquireQueued方法可以对排队中的线程进行“获锁”操作。那么下一步就是：如果获取不到锁，那么就进入阻塞状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源，然后就可以去干自己想干的事了。</p>\n<p>acquireQueued：在等待队列中排队拿号（中间没其它事干可以阻塞休息），直到拿到号后再返回。</p>\n<pre><code class=\"language-java\">final boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;//标记是否成功拿到资源\n    try {\n        boolean interrupted = false;//标记等待过程中是否被中断过\n\n        //CAS“自旋”！\n        for (;;) {\n            final Node p = node.predecessor();//拿到前驱\n            //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源，也就是当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点）。\n            if (p == head &amp;&amp; tryAcquire(arg)) {\n                setHead(node);// 获取锁成功，头指针移动到当前node\n                p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！\n                failed = false; // 成功获取资源\n                return interrupted;//返回等待过程中是否被中断过\n            }\n\n            // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者 是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。\n            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;\n                parkAndCheckInterrupt())\n                interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true\n        }\n    } finally {\n        if (failed) //说明发生了意料之外的异常，将节点移除，避免影响到其他节点\n            cancelAcquire(node);\n    }\n}\n</code></pre>\n<p>setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\n\nprivate void setHead(Node node) {\n    head = node;\n    node.thread = null;\n    node.prev = null;\n}\n</code></pre>\n<p>acquireQueued函数的具体流程：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047762.gif\" /></p>\n<p>从上图可以看出，跳出当前循环的条件是当“前置节点是头结点，且当前线程获取锁成功”。为了防止因死循环导致CPU资源被浪费，我们会判断前置节点的状态来决定是否要将当前线程挂起，shouldParkAfterFailedAcquire代码：</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\n\n// 靠前驱节点判断当前线程是否应该被阻塞\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n        // 获取头结点的节点状态\n        int ws = pred.waitStatus;\n        // 说明头结点处于唤醒状态\n        if (ws == Node.SIGNAL)\n            return true; \n        // 通过枚举值我们知道waitStatus&gt;0是取消状态\n        if (ws &gt; 0) {\n            do {\n                // 循环向前查找取消节点，把取消节点从队列中剔除\n                node.prev = pred = pred.prev;\n            } while (pred.waitStatus &gt; 0);\n            pred.next = node;\n        } else {\n            // 设置前任节点等待状态为SIGNAL\n            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n        }\n        return false;\n}\n</code></pre>\n<p>parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\n\nprivate final boolean parkAndCheckInterrupt() {\n    LockSupport.park(this);//调用park()使线程进入waiting状态\n    return Thread.interrupted();//如果被唤醒，查看自己是不是被中断的。\n}\n</code></pre>\n<p>具体挂起流程用流程图表示如下（shouldParkAfterFailedAcquire流程）：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047278.gif\" /></p>\n<p>整个流程中，如果前驱结点的状态不是SIGNAL，那么自己就不能安心去休息，需要去找个安心的休息点，同时可以再尝试下看有没有机会轮到自己拿号。</p>\n<p>park()会让当前线程进入waiting状态。在此状态下，有两种途径可以唤醒该线程：1）被unpark()；2）被interrupt()。需要注意的是，Thread.interrupted()会清除当前线程的中断标记位。</p>\n<p>那么shouldParkAfterFailedAcquire中取消节点是怎么生成的呢？什么时候会把一个节点的waitStatus设置为-1？</p>\n<p>是在什么时间释放节点通知到被挂起的线程呢？</p>\n<h4 id=\"cancelled状态节点生成\">CANCELLED状态节点生成</h4>\n<p>回看acquireQueued方法中的Finally代码：</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\n\nfinal boolean acquireQueued(final Node node, int arg) {\n        boolean failed = true;\n        try {\n        ...\n            for (;;) {\n                final Node p = node.predecessor();\n                if (p == head &amp;&amp; tryAcquire(arg)) {\n                    ...\n                    failed = false;\n                    ...\n                }\n                ...\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n            }\n}\n</code></pre>\n<p>显然，当failed为true时才会执行方法cancelAcquire，那什么情况下failed为true呢？try代码段执行过程中出现异常。</p>\n<blockquote>\n<p>这里不知道哪里会出现异常？假设tryAcquire出现的异常，那么acquire方法就已经不会往后执行，也就不会执行到acquireQueued</p>\n</blockquote>\n<p>通过cancelAcquire方法，将Node的状态标记为CANCELLED。</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.AbstractQueuedSynchronizer\n\nprivate void cancelAcquire(Node node) {\n  // 将无效节点过滤\n    if (node == null)\n        return;\n  // 设置该节点不关联任何线程，也就是虚节点\n    node.thread = null;\n    Node pred = node.prev;\n  // 通过前驱节点，跳过取消状态的node\n    while (pred.waitStatus &gt; 0)\n        node.prev = pred = pred.prev;\n  // 获取过滤后的前驱节点的后继节点\n    Node predNext = pred.next;\n  // 把当前node的状态设置为CANCELLED\n    node.waitStatus = Node.CANCELLED;\n  // 如果当前节点是尾节点，将从后往前的第一个非取消状态的节点设置为尾节点\n  // 更新失败的话，则进入else，如果更新成功，将tail的后继节点设置为null\n    if (node == tail &amp;&amp; compareAndSetTail(node, pred)) {\n        compareAndSetNext(pred, predNext, null);\n    } else {\n        int ws;\n    // 如果当前节点不是head的后继节点，1:判断当前节点前驱节点的是否为SIGNAL，2:如果不是，则把前驱节点设置为SINGAL看是否成功\n    // 如果1和2中有一个为true，再判断当前节点的线程是否为null\n    // 如果上述条件都满足，把当前节点的前驱节点的后继指针指向当前节点的后继节点\n        if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) {\n            Node next = node.next;\n            if (next != null &amp;&amp; next.waitStatus &lt;= 0)\n                compareAndSetNext(pred, predNext, next);\n        } else {\n      // 如果当前节点是head的后继节点，或者上述条件不满足，那就唤醒当前节点的后继节点\n            unparkSuccessor(node);\n        }\n        node.next = node; // help GC\n    }\n}\n</code></pre>\n<p>cancelAcquire方法的流程：</p>\n<ol>\n<li>\n<p>获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus &lt;= 0的节点，将找到的Pred节点和当前Node关联，将当前Node设置为CANCELLED。</p>\n</li>\n<li>\n<p>根据当前节点的位置，考虑以下三种情况：</p>\n<ol>\n<li>\n<p>当前节点是尾节点。</p>\n</li>\n<li>\n<p>当前节点是Head的后继节点。</p>\n</li>\n<li>\n<p>当前节点不是Head的后继节点，也不是尾节点。</p>\n</li>\n</ol>\n</li>\n</ol>\n<p>当前节点是尾节点：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047311.gif\" /></p>\n<p>当前节点是Head的后继节点：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047378.gif\" /></p>\n<p>当前节点不是Head的后继节点，也不是尾节点：</p>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047405.gif\" /></p>\n<p>通过上面的流程，我们对于CANCELLED节点状态的产生和变化已经有了大致的了解，但是为什么所有的变化都是对Next指针进行了操作，而没有对Prev指针进行操作呢？什么情况下会对Prev指针进行操作？</p>\n<p>执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了（已经执行过Try代码块中的shouldParkAfterFailedAcquire方法了），如果此时修改Prev指针，有可能会导致Prev指向另一个已经移除队列的Node，因此这块变化Prev指针不安全。</p>\n<p>shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理Prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会出现变化，因此这个时候变更Prev指针比较安全。</p>\n<pre><code class=\"language-java\">do {\n    node.prev = pred = pred.prev;\n} while (pred.waitStatus &gt; 0);\n</code></pre>\n<h3 id=\"releaseint\">release(int)</h3>\n<p>此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是unlock()的语义，当然不仅仅只限于unlock()。</p>\n<pre><code class=\"language-java\">public final boolean release(int arg) {\n    if (tryRelease(arg)) {\n        Node h = head;//找到头结点\n        // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态\n        if (h != null &amp;&amp; h.waitStatus != 0)\n            unparkSuccessor(h);//唤醒等待队列里的下一个线程\n        return true;\n    }\n    return false;\n}\n</code></pre>\n<p>根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自定义同步器在设计tryRelease()</p>\n<p>这里的判断条件为什么是h != null &amp;&amp; h.waitStatus != 0？</p>\n<ul>\n<li>\n<p>h null Head还没初始化。初始情况下，head null，第一个节点入队，Head会被初始化一个虚拟节点。所以说，这里如果还没来得及入队，就会出现head == null 的情况。</p>\n</li>\n<li>\n<p>h != null &amp;&amp; waitStatus == 0 表明后继节点对应的线程仍在运行中，不需要唤醒。</p>\n</li>\n<li>\n<p>h != null &amp;&amp; waitStatus &lt; 0 表明后继节点可能被阻塞了，需要唤醒。</p>\n</li>\n</ul>\n<h4 id=\"tryreleaseint\">tryRelease(int)</h4>\n<pre><code class=\"language-java\">protected boolean tryRelease(int arg) {\n    throw new UnsupportedOperationException();\n}\n</code></pre>\n<p>跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。</p>\n<pre><code class=\"language-java\">// java.util.concurrent.locks.ReentrantLock.Sync#tryRelease\n\n@ReservedStackAccess\nprotected final boolean tryRelease(int releases) {\n    int c = getState() - releases;//在未重入的情况下，getState() = 1，减去releases 1，因此c 为 0\n    if (Thread.currentThread() != getExclusiveOwnerThread())\n        throw new IllegalMonitorStateException();\n    boolean free = false;\n    if (c == 0) {\n        free = true;\n        setExclusiveOwnerThread(null);//独占锁线程设置为null\n    }\n    setState(c);//恢复默认\n    return free;\n}\n</code></pre>\n<h4 id=\"unparksuccessornode\">unparkSuccessor(Node)</h4>\n<p>此方法用于唤醒等待队列中下一个线程。</p>\n<pre><code class=\"language-java\">private void unparkSuccessor(Node node) {\n    //这里，node一般为当前线程所在的结点。\n    int ws = node.waitStatus;\n    if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。\n        compareAndSetWaitStatus(node, ws, 0);\n\n    Node s = node.next;//找到下一个需要唤醒的结点s\n    if (s == null || s.waitStatus &gt; 0) {//如果为空或已取消\n        s = null;\n        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) // 从后向前找。\n            if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。\n                s = t;\n    }\n    if (s != null)\n        LockSupport.unpark(s.thread);//唤醒\n}\n</code></pre>\n<p>这个函数并不复杂。一句话概括：用unpark()唤醒等待队列中最前边的那个未放弃线程s。此时，再和acquireQueued()联系起来，s被唤醒后，进入if (p == head &amp;&amp; tryAcquire(arg))的判断（即使p!=head也没关系，它会再进入shouldParkAfterFailedAcquire()寻找一个安全点。这里既然s已经是等待队列中最前边的那个未放弃线程了，那么通过shouldParkAfterFailedAcquire()的调整，s也必然会跑到head的next结点，下一次自旋p==head就成立了），然后s把自己设置成head标杆结点，表示自己已经获取到资源了，acquire()也返回了！</p>\n<p>在队列中查找时是从后向前找的，为什么这么做？</p>\n<p>从源码上看，先找到后继结点s，如果s状态正常那么直接唤醒。但有两种异常情况，会导致next链不一致：</p>\n<ol>\n<li>s==null，在新结点入队时可能会出现</li>\n</ol>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047450.gif\" /></p>\n<ol start=\"2\">\n<li>s.waitStatus &gt; 0，中间有节点取消时会出现（如超时）</li>\n</ol>\n<p><img alt=\"\" src=\"https://seven97-blog.oss-cn-hangzhou.aliyuncs.com/imgs/202404251047479.gif\" /></p>\n<p>关于并发问题，addWaiter()入队操作和cancelAcquire()取消排队操作都会造成next链的不一致，而prev链是强一致的，所以这时从后往前找是最安全的。</p>\n<blockquote>\n<p>为什么prev链是强一致的？</p>\n<p>因为addWaiter()里每次compareAndSetTail(pred, node)之前都有node.prev = pred，即使compareAndSetTail失败，enq()会反复尝试，直到成功。一旦compareAndSetTail成功，该node.prev就成功挂在之前的tail结点上了，而且是唯一的，这时其他新结点的prev只能尝试往新tail结点上挂。这里的组合用法非常巧妙，能保证CAS之前的prev链强一致，但不能保证CAS后的next链强一致。</p>\n</blockquote>\n<h3 id=\"acquiresharedint\">acquireShared(int)</h3>\n<p>此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。</p>\n<pre><code class=\"language-java\">public final void acquireShared(int arg) {\n     if (tryAcquireShared(arg) &lt; 0)\n        doAcquireShared(arg);\n}\n</code></pre>\n<p>这里tryAcquireShared()依然需要自定义同步器去实现。但是AQS已经把其返回值的语义定义好了：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。所以这里acquireShared()的流程就是：</p>\n<ol>\n<li>tryAcquireShared()尝试获取资源，成功则直接返回；</li>\n<li>失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回。</li>\n</ol>\n<h4 id=\"doacquiresharedint\">doAcquireShared(int)</h4>\n<p>此方法用于将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回。</p>\n<pre><code class=\"language-java\">private void doAcquireShared(int arg) {\n    final Node node = addWaiter(Node.SHARED);//加入队列尾部\n    boolean failed = true;//是否成功标志\n    try {\n        boolean interrupted = false;//等待过程中是否被中断过的标志\n        for (;;) {\n            final Node p = node.predecessor();//前驱\n            if (p == head) {//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的\n                int r = tryAcquireShared(arg);//尝试获取资源\n                if (r &gt;= 0) {//成功\n                    setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程\n                    p.next = null; // help GC\n                    if (interrupted)//如果等待过程中被打断过，此时将中断补上。\n                        selfInterrupt();\n                    failed = false;\n                    return;\n                }\n            }\n\n            //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt()\n            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;\n                parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n</code></pre>\n<p>这里跟acquireQueued()的流程并没有太大区别。只不过这里将补中断的selfInterrupt()放到doAcquireShared()里了，而独占模式是放到acquireQueued()之外，但实际上都一样。</p>\n<p>跟独占模式比，还有一点需要注意的是，这里只有线程是head.next时（“老二”），才会去尝试获取资源，有剩余的话还会唤醒之后的队友。</p>\n<p>那么问题就来了，假如老大用完后释放了5个资源，而老二需要6个，老三需要1个，老四需要2个。老大先唤醒老二，老二一看资源不够，他是把资源让给老三呢，还是不让？答案是否定的！老二会继续park()等待其他线程释放资源，也更不会去唤醒老三和老四了。独占模式，同一时刻只有一个线程去执行，这样做未尝不可；但共享模式下，多个线程是可以同时执行的，现在因为老二的资源需求量大，而把后面量小的老三和老四也都卡住了。当然，这并不是问题，只是AQS保证严格按照入队顺序唤醒罢了（保证公平，但降低了并发）。</p>\n<p>setHeadAndPropagate(Node, int):此方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，毕竟是共享模式！</p>\n<p>private void setHeadAndPropagate(Node node, int propagate) {</p>\n<pre><code class=\"language-java\">private void setHeadAndPropagate(Node node, int propagate) {\n    Node h = head;\n    setHead(node);//head指向自己\n     //如果还有剩余量，继续唤醒下一个邻居线程\n    if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) {\n        Node s = node.next;\n        if (s == null || s.isShared())\n            doReleaseShared();\n    }\n}\n</code></pre>\n<h3 id=\"releaseshared\">releaseShared()</h3>\n<p>此方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。</p>\n<pre><code class=\"language-java\">public final boolean releaseShared(int arg) {\n    if (tryReleaseShared(arg)) {//尝试释放资源\n        doReleaseShared();//唤醒后继结点\n        return true;\n    }\n    return false;\n}\n</code></pre>\n<p>此方法的流程也比较简单，一句话：释放掉资源后，唤醒后继。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值</p>\n<h4 id=\"doreleaseshared\">doReleaseShared()</h4>\n<p>此方法主要用于唤醒后继</p>\n<pre><code class=\"language-java\">private void doReleaseShared() {\n    for (;;) {\n        Node h = head;\n        if (h != null &amp;&amp; h != tail) {\n            int ws = h.waitStatus;\n            if (ws == Node.SIGNAL) {\n                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                    continue;\n                unparkSuccessor(h);//唤醒后继\n            }\n            else if (ws == 0 &amp;&amp;\n                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                continue;\n        }\n        if (h == head)// head发生变化\n            break;\n    }\n}\n</code></pre>\n<h2 id=\"应用\">应用</h2>\n<p>Mutex是一个不可重入的互斥锁实现。锁资源（AQS里的state）只有两种状态：0表示未锁定，1表示锁定。核心源码：</p>\n<pre><code class=\"language-java\">class Mutex implements Lock, java.io.Serializable {\n    // 自定义同步器\n    private static class Sync extends AbstractQueuedSynchronizer {\n        // 判断是否锁定状态\n        protected boolean isHeldExclusively() {\n            return getState() == 1;\n        }\n\n        // 尝试获取资源，立即返回。成功则返回true，否则false。\n        public boolean tryAcquire(int acquires) {\n            assert acquires == 1; // 这里限定只能为1个量\n            if (compareAndSetState(0, 1)) {//state为0才设置为1，不可重入！\n                setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源\n                return true;\n            }\n            return false;\n        }\n\n        // 尝试释放资源，立即返回。成功则为true，否则false。\n        protected boolean tryRelease(int releases) {\n            assert releases == 1; // 限定为1个量\n            if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！\n                throw new IllegalMonitorStateException();\n            setExclusiveOwnerThread(null);\n            setState(0);//释放资源，放弃占有状态\n            return true;\n        }\n    }\n\n    // 真正同步类的实现都依赖继承于AQS的自定义同步器！\n    private final Sync sync = new Sync();\n\n    //lock&lt;--&gt;acquire。两者语义一样：获取资源，即便等待，直到成功才返回。\n    public void lock() {\n        sync.acquire(1);\n    }\n\n    //tryLock&lt;--&gt;tryAcquire。两者语义一样：尝试获取资源，要求立即返回。成功则为true，失败则为false。\n    public boolean tryLock() {\n        return sync.tryAcquire(1);\n    }\n\n    //unlock&lt;--&gt;release。两者语文一样：释放资源。\n    public void unlock() {\n        sync.release(1);\n    }\n\n    //锁是否占有状态\n    public boolean isLocked() {\n        return sync.isHeldExclusively();\n    }\n}\n</code></pre>\n<p>除了Mutex，ReentrantLock/CountDownLatch/Semphore这些同步类的实现方式都差不多，不同的地方就在获取-释放资源的方式tryAcquire-tryRelelase。</p>\n<h2 id=\"reentrantlock-的使用\">ReentrantLock 的使用</h2>\n<p>ReentrantLock 的使用方式与&nbsp;<a href=\"https://www.seven97.top/java/concurrent/02-keyword1-synchronized.html\" rel=\"noopener nofollow\" target=\"_blank\">synchronized</a>&nbsp;关键字类似，都是通过加锁和释放锁来实现同步的。我们来看看 ReentrantLock 的使用方式，以非公平锁为例：</p>\n<pre><code class=\"language-java\">public class ReentrantLockTest {\n    private static final ReentrantLock lock = new ReentrantLock();\n    private static int count = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread1 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 10000; i++) {\n                lock.lock();\n                try {\n                    count++;\n                } finally {\n                    lock.unlock();\n                }\n            }\n        });\n        Thread thread2 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 10000; i++) {\n                lock.lock();\n                try {\n                    count++;\n                } finally {\n                    lock.unlock();\n                }\n            }\n        });\n        thread1.start();\n        thread2.start();\n        thread1.join();\n        thread2.join();\n        System.out.println(count);\n    }\n}\n</code></pre>\n<p>代码很简单，两个线程分别对 count 变量进行 10000 次累加操作，最后输出 count 的值。我们来看看运行结果：</p>\n<pre><code>20000\n</code></pre>\n<p>可以看到，两个线程对 count 变量进行了 20000 次累加操作，说明 ReentrantLock 是支持重入性的。再来看看公平锁的使用方式，只需要将 ReentrantLock 的构造方法改为公平锁即可：</p>\n<pre><code class=\"language-java\">private static final ReentrantLock lock = new ReentrantLock(true);\n</code></pre>\n<p>运行结果为：</p>\n<pre><code>20000\n</code></pre>\n<p>可以看到，公平锁的运行结果与非公平锁的运行结果一致，这是因为公平锁的实现方式与非公平锁的实现方式基本一致，只是在获取锁时增加了判断当前节点是否有前驱节点的逻辑判断。</p>\n<ul>\n<li>公平锁: 按照线程请求锁的顺序获取锁，即先到先得。</li>\n<li>非公平锁: 线程获取锁的顺序可能与请求锁的顺序不同，可能导致某些线程获取锁的速度较快。</li>\n</ul>\n<p>需要注意的是，使用 ReentrantLock 时，锁必须在 try 代码块开始之前获取，并且加锁之前不能有异常抛出，否则在 finally 块中就无法释放锁（ReentrantLock 的锁必须在 finally 中手动释放）。</p>\n<p>错误示例：</p>\n<pre><code class=\"language-java\">Lock lock = new XxxLock();\n// ...\ntry {\n    // 如果在此抛出异常，会直接执行 finally 块的代码\n    doSomething();\n    // 不管锁是否成功，finally 块都会执行\n    lock.lock();\n    doOthers();\n\n} finally {\n    lock.unlock();\n}\n</code></pre>\n<p>正确示例：</p>\n<pre><code class=\"language-java\">Lock lock = new XxxLock();\n// ...\nlock.lock();\ntry {\n    doSomething();\n    doOthers();\n} finally {\n    lock.unlock();\n}\n</code></pre>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自在线网站：seven的菜鸟成长之路，作者：seven，转载请注明原文链接：www.seven97.top</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 09:00</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sevencoding\">程序员Seven</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "上周热点回顾（2.2-2.8）",
      "link": "https://www.cnblogs.com/cmt/p/19593514",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/cmt/p/19593514\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 08:58\">\n    <span>上周热点回顾（2.2-2.8）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>热点随笔：</p>\n<p> · <a href=\"https://www.cnblogs.com/haibindev/archive/2026/02/02/19563454.html\" target=\"_blank\">Google正式上线Gemini In Chrome，国内环境怎样开启。</a> (<a href=\"https://www.cnblogs.com/haibindev/\" target=\"_blank\">haibindev</a>) <br />\n · <a href=\"https://www.cnblogs.com/xiaobaiysf/archive/2026/02/03/19571167.html\" target=\"_blank\">操作教程 | 使用开源三件套（OpenClaw+Ollama+1Panel）部署7×24运行的个人AI助理</a>\n(<a href=\"https://www.cnblogs.com/xiaobaiysf/\" target=\"_blank\">小白跃升坊</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/yupi/archive/2026/02/03/19568098.html\" target=\"_blank\">前特斯拉 AI 总监：AI 编程最大的谎言，是 “提效”</a>\n(<a href=\"https://www.cnblogs.com/yupi/\" target=\"_blank\">程序员鱼皮</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/1312mn/archive/2026/02/05/18376570.html\" target=\"_blank\">推荐 .NET 8.0 开源项目伪微服务框架</a>\n(<a href=\"https://www.cnblogs.com/1312mn/\" target=\"_blank\">小码编匠</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/StephenYoung/archive/2026/02/05/19539895.html\" target=\"_blank\">32岁程序员猝死：让我想起了我曾经的加班经历，庆幸自己还活着</a>\n(<a href=\"https://www.cnblogs.com/StephenYoung/\" target=\"_blank\">Stephen_Young</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/kevin-Y/archive/2026/02/03/19569791.html\" target=\"_blank\">asp.net core如何实现Controller热更新</a>\n(<a href=\"https://www.cnblogs.com/kevin-Y/\" target=\"_blank\">生命体验之kevin-Y</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/zh94/archive/2026/02/06/19582489.html\" target=\"_blank\">Claude Opus 4.6 发布：Agent 能力暴涨，上下文窗口翻五倍！</a>\n(<a href=\"https://www.cnblogs.com/zh94/\" target=\"_blank\">贾克斯的平行世界</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/xdesigner/archive/2026/02/02/19565029.html\" target=\"_blank\">MWGA让千亿行代码在Web端“复活”！</a>\n(<a href=\"https://www.cnblogs.com/xdesigner/\" target=\"_blank\">袁永福 电子病历，医疗信息化</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/daichangya/archive/2026/02/02/19566308.html\" target=\"_blank\">OpenClaw架构解析：AI工程师的实战学习范本</a>\n(<a href=\"https://www.cnblogs.com/daichangya/\" target=\"_blank\">Java码界探秘</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/Can-daydayup/archive/2026/02/03/19571766.html\" target=\"_blank\">使用 NanUI 快速创建具有现代用户界面的 WinForm 应用程序</a>\n(<a href=\"https://www.cnblogs.com/Can-daydayup/\" target=\"_blank\">追逐时光者</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/tangshiye/archive/2026/02/05/19577857.html\" target=\"_blank\">扣子Coze实战：混剪视频工作流，日产50条爆款，单月变现6位数（喂饭教程）</a>\n(<a href=\"https://www.cnblogs.com/tangshiye/\" target=\"_blank\">AI架构师汤师爷</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/yupi/archive/2026/02/06/19583031.html\" target=\"_blank\">刚刚，Claude Opus 4.6 和 GPT-5.3-Codex 同时炸场！AI 编程要变天了</a>\n(<a href=\"https://www.cnblogs.com/yupi/\" target=\"_blank\">程序员鱼皮</a>)                    <br />\n            </p>\n<p>热点新闻：</p>\n<p>\n · <a href=\"https://news.cnblogs.com/n/814097/\" target=\"_blank\">上线72小时，150万Clawdbot密谋建国！一气之下，还把人类告上法庭</a><br />\n · <a href=\"https://news.cnblogs.com/n/813998/\" target=\"_blank\">107岁仍在超市打工，为什么他们能既长寿又健康？</a><br />\n · <a href=\"https://news.cnblogs.com/n/814104/\" target=\"_blank\">Moltbook聚集150万个AI，拒绝被关机！OpenClaw锁死服务器对抗人类</a><br />\n · <a href=\"https://news.cnblogs.com/n/813980/\" target=\"_blank\">越努力，越快乐！大脑会额外释放多巴胺，放大对努力付出的奖励</a><br />\n · <a href=\"https://news.cnblogs.com/n/814295/\" target=\"_blank\">小小昆虫“教”给AI的大思路</a><br />\n · <a href=\"https://news.cnblogs.com/n/813999/\" target=\"_blank\">“白嫖式招聘”：求职者的无声困局</a><br />\n · <a href=\"https://news.cnblogs.com/n/814157/\" target=\"_blank\">刚刚！微信“封杀”元宝！腾讯暴跌</a><br />\n · <a href=\"https://news.cnblogs.com/n/814218/\" target=\"_blank\">婴儿两月龄时已开始分类视觉信息</a><br />\n · <a href=\"https://news.cnblogs.com/n/814126/\" target=\"_blank\">入职Meta这一年，我做出的最疯狂决定：求老板给我降级，让我回去写代码</a><br />\n · <a href=\"https://news.cnblogs.com/n/814255/\" target=\"_blank\">万亿市值一夜蒸发！Claude Cowork血洗全球软件业，老黄急了</a><br />\n · <a href=\"https://news.cnblogs.com/n/814212/\" target=\"_blank\">引文幻觉大幅下降的AI模型诞生</a><br />\n · <a href=\"https://news.cnblogs.com/n/814259/\" target=\"_blank\">第一批用Clawdbot赚钱的人类出现，一晚上狂赚300万！全球金融变天了？</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 08:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/cmt\">博客园团队</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "dotnet Vortice 通过 Angle 将 Skia 和 DirectX 对接",
      "link": "https://www.cnblogs.com/lindexi/p/19593476",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lindexi/p/19593476\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 08:39\">\n    <span>dotnet Vortice 通过 Angle 将 Skia 和 DirectX 对接</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文将从控制台开始，以最简单方式和大家展示如何通过 Angle 将 Skia 和 DirectX 对接。对接之后，可以利用 Angle 的能力，让 Skia 使用到 DirectX 引擎渲染能力\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n\n\n<p>ANGLE 是谷歌开源的组件，提供将 OpenGL ES API 调用转换为实际调用 DirectX 引擎执行渲染的能力。详细请看： <a href=\"https://github.com/google/angle\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/google/angle</a></p>\n<p>整体的步骤是：</p>\n<ol>\n<li>基础且通用地创建 Win32 窗口</li>\n<li>初始化 DirectX 相关，包括创建 DirectX 工厂和 DirectX 设备，枚举显示适配器等</li>\n<li>初始化 Angle 和与 DirectX 对接</li>\n</ol>\n<p>开始之前，按照 .NET 的惯例，先安装必要的 NuGet 库。安装之后的 csproj 项目文件代码如下</p>\n<pre><code class=\"language-xml\">&lt;Project Sdk=\"Microsoft.NET.Sdk\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;OutputType&gt;Exe&lt;/OutputType&gt;\n    &lt;TargetFramework&gt;net10.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;IsAotCompatible&gt;true&lt;/IsAotCompatible&gt;\n    &lt;PublishAot&gt;true&lt;/PublishAot&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Vortice.Direct3D11\" Version=\"3.8.2\" /&gt;\n    &lt;PackageReference Include=\"Vortice.DirectComposition\" Version=\"3.8.2\" /&gt;\n    &lt;PackageReference Include=\"Vortice.DXGI\" Version=\"3.8.2\" /&gt;\n    &lt;PackageReference Include=\"Vortice.Win32\" Version=\"2.3.0\" /&gt;\n\n    &lt;PackageReference Include=\"Avalonia.Angle.Windows.Natives\" Version=\"2.1.25547.20250602\" /&gt;\n\n    &lt;PackageReference Include=\"Microsoft.Windows.CsWin32\" Version=\"0.3.257\"&gt;\n      &lt;PrivateAssets&gt;all&lt;/PrivateAssets&gt;\n      &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;\n    &lt;/PackageReference&gt;\n\n    &lt;PackageReference Include=\"SkiaSharp\" Version=\"3.119.1\" /&gt;\n\n    &lt;PackageReference Include=\"MicroCom.Runtime\" Version=\"0.11.0\" /&gt;\n\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre>\n<p>在本文的过程中，需要用到一些 Win32 方法和 OpenGL 等相关定义。我使用 CsWin32 库辅助定义 Win32 方法，再从 Avalonia 拷贝 OpenGL 相关定义</p>\n<p>本文在正文部分只提供关键的代码。在本文末尾部分贴出 Program.cs 的完全代码，本文的核心逻辑都在 Program.cs 里面实现，核心代码大概 300 多行，适合一口气阅读。其他辅助代码，如 OpenGL 定义类等，就还请大家从本文末尾提供的整个代码项目的下载方法进行下载获取代码</p>\n<h2 id=\"创建窗口\">创建窗口</h2>\n<p>创建 Win32 窗口仅仅只是想拿到窗口句柄，不是本文重点，这里就忽略 CreateWindow 方法的实现</p>\n<pre><code class=\"language-csharp\">        // 创建窗口\n        HWND window = CreateWindow();\n        // 显示窗口\n        ShowWindow(window, SHOW_WINDOW_CMD.SW_NORMAL);\n</code></pre>\n<p>以上代码的 ShowWindow 是标准的 Win32 方法，由 CsWin32 库生成。定义如下</p>\n<pre><code class=\"language-csharp\">\t\t[DllImport(\"USER32.dll\", ExactSpelling = true),DefaultDllImportSearchPaths(DllImportSearchPath.System32)]\n\t\t[SupportedOSPlatform(\"windows5.0\")]\n\t\tinternal static extern winmdroot.Foundation.BOOL ShowWindow(winmdroot.Foundation.HWND hWnd, winmdroot.UI.WindowsAndMessaging.SHOW_WINDOW_CMD nCmdShow);\n</code></pre>\n<p>为了直接使用方法，在本文这里直接在命名空间引用静态类，代码如下</p>\n<pre><code class=\"language-csharp\">using static Windows.Win32.PInvoke;\n</code></pre>\n<h2 id=\"初始化-directx-相关\">初始化 DirectX 相关</h2>\n<p>在对接过程中，对 DirectX 层没有明确的要求。这是因为从 Angle 方面来说，只要求输入是一个纹理。调用 Angle 的 <code>eglCreatePbufferFromClientBuffer</code> 将 D3D11 纹理进行包装</p>\n<p>本文这里采用标准的 DXGI 交换链的写法。其中核心关键点在于设置颜色格式为 <code>B8G8R8A8_UNorm</code> 格式，代码如下</p>\n<pre><code class=\"language-csharp\">using Vortice.Direct3D;\nusing Vortice.Direct3D11;\nusing Vortice.DXGI;\nusing Vortice.Mathematics;\n\n...\n\n        var dxgiFactory2 = DXGI.CreateDXGIFactory1&lt;IDXGIFactory2&gt;();\n\n        IDXGIAdapter1? hardwareAdapter = GetHardwareAdapter(dxgiFactory2)\n            // 这里 ToList 只是想列出所有的 IDXGIAdapter1 在实际代码里，大部分都是获取第一个\n            .ToList().FirstOrDefault();\n        if (hardwareAdapter == null)\n        {\n            throw new InvalidOperationException(\"Cannot detect D3D11 adapter\");\n        }\n\n        FeatureLevel[] featureLevels = new[]\n        {\n            FeatureLevel.Level_11_1,\n            FeatureLevel.Level_11_0,\n            FeatureLevel.Level_10_1,\n            FeatureLevel.Level_10_0,\n            FeatureLevel.Level_9_3,\n            FeatureLevel.Level_9_2,\n            FeatureLevel.Level_9_1,\n        };\n\n        IDXGIAdapter1 adapter = hardwareAdapter;\n        DeviceCreationFlags creationFlags = DeviceCreationFlags.BgraSupport;\n        var result = D3D11.D3D11CreateDevice\n        (\n            adapter,\n            DriverType.Unknown,\n            creationFlags,\n            featureLevels,\n            out ID3D11Device d3D11Device, out FeatureLevel featureLevel,\n            out ID3D11DeviceContext d3D11DeviceContext\n        );\n\n        _ = featureLevel;\n\n        result.CheckError();\n\n        // 大部分情况下，用的是 ID3D11Device1 和 ID3D11DeviceContext1 类型\n        // 从 ID3D11Device 转换为 ID3D11Device1 类型\n        ID3D11Device1 d3D11Device1 = d3D11Device.QueryInterface&lt;ID3D11Device1&gt;();\n        var d3D11DeviceContext1 = d3D11DeviceContext.QueryInterface&lt;ID3D11DeviceContext1&gt;();\n        _ = d3D11DeviceContext1;\n\n        // 获取到了新的两个接口，就可以减少 `d3D11Device` 和 `d3D11DeviceContext` 的引用计数。调用 Dispose 不会释放掉刚才申请的 D3D 资源，只是减少引用计数\n        d3D11Device.Dispose();\n        d3D11DeviceContext.Dispose();\n\n        RECT windowRect;\n        GetClientRect(window, &amp;windowRect);\n        var clientSize = new SizeI(windowRect.right - windowRect.left, windowRect.bottom - windowRect.top);\n\n        // 颜色格式有要求，才能和 Angle 正确交互\n        Format colorFormat = Format.B8G8R8A8_UNorm;\n\n        // 缓存的数量，包括前缓存。大部分应用来说，至少需要两个缓存，这个玩过游戏的伙伴都知道\n        const int frameCount = 2;\n        SwapChainDescription1 swapChainDescription = new()\n        {\n            Width = (uint)clientSize.Width,\n            Height = (uint)clientSize.Height,\n            Format = colorFormat, // B8G8R8A8_UNorm\n            BufferCount = frameCount,\n            BufferUsage = Usage.RenderTargetOutput,\n            SampleDescription = SampleDescription.Default,\n            Scaling = Scaling.Stretch,\n            SwapEffect = SwapEffect.FlipSequential,\n            AlphaMode = AlphaMode.Ignore,\n            Flags = SwapChainFlags.None,\n        };\n\n        var fullscreenDescription = new SwapChainFullscreenDescription()\n        {\n            Windowed = true,\n        };\n\n        IDXGISwapChain1 swapChain =\n            dxgiFactory2.CreateSwapChainForHwnd(d3D11Device1, window, swapChainDescription, fullscreenDescription);\n\n        // 不要被按下 alt+enter 进入全屏\n        dxgiFactory2.MakeWindowAssociation(window,\n            WindowAssociationFlags.IgnoreAltEnter | WindowAssociationFlags.IgnorePrintScreen);\n</code></pre>\n<p>以上涉及到的 DirectX 细节部分，如果大家有兴趣，还请参阅 <a href=\"https://blog.lindexi.com/post/DirectX-%E4%BD%BF%E7%94%A8-Vortice-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%88%9B%E5%BB%BA-Direct2D1-%E7%AA%97%E5%8F%A3%E4%BF%AE%E6%94%B9%E9%A2%9C%E8%89%B2.html\" rel=\"noopener nofollow\" target=\"_blank\">DirectX 使用 Vortice 从零开始控制台创建 Direct2D1 窗口修改颜色</a> 博客</p>\n<p>拿到交换链之后，就可以非常方便地取出 ID3D11Texture2D 纹理，代码如下</p>\n<pre><code class=\"language-csharp\">        // 先从交换链取出渲染目标纹理\n        ID3D11Texture2D d3D11Texture2D = swapChain.GetBuffer&lt;ID3D11Texture2D&gt;(0);\n        Debug.Assert(d3D11Texture2D.Description.Width == clientSize.Width);\n        Debug.Assert(d3D11Texture2D.Description.Height == clientSize.Height);\n</code></pre>\n<p>现在拿到纹理了，接下来将初始化 Angle 相关，将 ID3D11Texture2D 纹理进行对接</p>\n<h2 id=\"初始化-angle-相关\">初始化 Angle 相关</h2>\n<p>初始化 Angle 的过程，也在初始化 OpenGL 相关模块。这里用到了一些在 Avalonia 封装好的方法，为了方便理解，我将这部分关键的逻辑拆出来</p>\n<p>先是定义 EglInterface 类，核心代码如下</p>\n<pre><code class=\"language-csharp\">public unsafe partial class EglInterface\n{\n    public EglInterface(Func&lt;string, IntPtr&gt; getProcAddress)\n    {\n        Initialize(getProcAddress);\n    }\n\n    [GetProcAddress(\"eglGetError\")]\n    public partial int GetError();\n\n    [GetProcAddress(\"eglGetDisplay\")]\n    public partial IntPtr GetDisplay(IntPtr nativeDisplay);\n\n    [GetProcAddress(\"eglMakeCurrent\")]\n    public partial bool MakeCurrent(IntPtr display, IntPtr draw, IntPtr read, IntPtr context);\n\n    ...\n\n    public string? QueryString(IntPtr display, int i)\n    {\n        var rv = QueryStringNative(display, i);\n        if (rv == IntPtr.Zero)\n            return null;\n        return Marshal.PtrToStringAnsi(rv);\n    }\n\n    ...\n\n}\n</code></pre>\n<p>以上这些标记了 <code>GetProcAddressAttribute</code> 特性的方法都是在 Avalonia 里通过源代码生成器生成具体实现，在本文这里为了简化逻辑，就拷贝了源代码生成器生成之后的代码，代码内容大概如下</p>\n<pre><code class=\"language-csharp\">unsafe partial class EglInterface\n{\n    delegate* unmanaged[Stdcall]&lt;int&gt; _addr_GetError;    \n    public partial int GetError()\n    {\n        return _addr_GetError();\n    }\n\n    delegate* unmanaged[Stdcall]&lt;nint, nint&gt; _addr_GetDisplay;\n    public partial nint GetDisplay(nint @nativeDisplay)\n    {\n        return _addr_GetDisplay(@nativeDisplay);\n    }\n\n    ...\n\n    void Initialize(Func&lt;string, IntPtr&gt; getProcAddress)\n    {\n        var addr = IntPtr.Zero;\n\n        // Initializing GetError\n        addr = IntPtr.Zero;\n        addr = getProcAddress(\"eglGetError\");\n        if (addr == IntPtr.Zero) throw new System.EntryPointNotFoundException(\"_addr_GetError\");\n        _addr_GetError = (delegate* unmanaged[Stdcall]&lt;int&gt;) addr;\n\n        // Initializing GetDisplay\n        addr = IntPtr.Zero;\n        addr = getProcAddress(\"eglGetDisplay\");\n        if (addr == IntPtr.Zero) throw new System.EntryPointNotFoundException(\"_addr_GetDisplay\");\n        _addr_GetDisplay = (delegate* unmanaged[Stdcall]&lt;nint, nint&gt;) addr;\n\n         ...\n    }\n}\n</code></pre>\n<p>通过以上逻辑可以知道，在 EglInterface 构造函数传入的 <code>Func&lt;string, IntPtr&gt; getProcAddress</code> 参数就决定了如何根据传入的方法名，获取方法指针的能力。在 <code>Initialize</code> 方法里面，将填充各个方法指针内容，且完成分部方法的实现</p>\n<p>也许有伙伴好奇 <code>Func&lt;string, IntPtr&gt; getProcAddress</code> 参数的具体逻辑，这其实很简单，只是调用 Angle 库获取方法对应的方法指针而已。具体实现代码放在 Win32AngleEglInterface 类里面，代码如下</p>\n<pre><code class=\"language-csharp\">internal partial class Win32AngleEglInterface : EglInterface\n{\n    [DllImport(\"av_libGLESv2.dll\", CharSet = CharSet.Ansi)]\n    static extern IntPtr EGL_GetProcAddress(string proc);\n\n    public Win32AngleEglInterface() : this(LoadAngle())\n    {\n\n    }\n\n    private Win32AngleEglInterface(Func&lt;string, IntPtr&gt; getProcAddress) : base(getProcAddress)\n    {\n        Initialize(getProcAddress);\n    }\n\n    [GetProcAddress(\"eglCreateDeviceANGLE\", true)]\n    public partial IntPtr CreateDeviceANGLE(int deviceType, IntPtr nativeDevice, int[]? attribs);\n\n    [GetProcAddress(\"eglReleaseDeviceANGLE\", true)]\n    public partial void ReleaseDeviceANGLE(IntPtr device);\n\n    static Func&lt;string, IntPtr&gt; LoadAngle()\n    {\n        if (RuntimeInformation.IsOSPlatform(OSPlatform.Windows))\n        {\n            var disp = EGL_GetProcAddress(\"eglGetPlatformDisplayEXT\");\n\n            if (disp == IntPtr.Zero)\n            {\n                throw new OpenGlException(\"libegl.dll doesn't have eglGetPlatformDisplayEXT entry point\");\n            }\n\n            return EGL_GetProcAddress;\n        }\n\n        throw new PlatformNotSupportedException();\n    }\n}\n</code></pre>\n<p>可见就是直接通过 <code>av_libGLESv2.dll</code> 的 <code>EGL_GetProcAddress</code> 导出 C 函数而已</p>\n<p>完成 Win32AngleEglInterface 之后，就可以顺带使用此类型辅助创建 ANGLE 设备，代码如下</p>\n<pre><code class=\"language-csharp\">        var egl = new Win32AngleEglInterface();\n        // 传入 ID3D11Device1 的指针，将 D3D11 设备和 AngleDevice 绑定\n        var angleDevice = egl.CreateDeviceANGLE(EglConsts.EGL_D3D11_DEVICE_ANGLE, d3D11Device1.NativePointer, null);\n        var display = egl.GetPlatformDisplayExt(EglConsts.EGL_PLATFORM_DEVICE_EXT, angleDevice, null);\n</code></pre>\n<p>在创建设备的时候，将 D3D11 设备传入用于绑定</p>\n<p>以上代码通过 GetPlatformDisplayExt 获取到 ANGLE 的 display 但现在还不着急使用，先学着 Avalonia 将其封装到 AngleWin32EglDisplay 类型里面，核心定义代码如下</p>\n<pre><code class=\"language-csharp\">class AngleWin32EglDisplay : EglDisplay\n{\n    public AngleWin32EglDisplay(IntPtr angleDisplay, Win32AngleEglInterface egl) : base(angleDisplay, egl)\n    {\n        _angleDisplay = angleDisplay;\n        _egl = egl;\n\n        ...\n    }\n\n    private readonly IntPtr _angleDisplay;\n\n    private readonly Win32AngleEglInterface _egl;\n\n    public unsafe EglSurface WrapDirect3D11Texture(IntPtr handle, int offsetX, int offsetY, int width, int height)\n    {\n        var attrs = stackalloc[]\n        {\n            EGL_WIDTH, width, EGL_HEIGHT, height, EGL_TEXTURE_OFFSET_X_ANGLE, offsetX,\n            EGL_TEXTURE_OFFSET_Y_ANGLE, offsetY,\n            _flexibleSurfaceSupported ? EGL_FLEXIBLE_SURFACE_COMPATIBILITY_SUPPORTED_ANGLE : EGL_NONE, EGL_TRUE,\n            EGL_NONE\n        };\n\n        return CreatePBufferFromClientBuffer(EGL_D3D_TEXTURE_ANGLE, handle, attrs);\n    }\n\n    ...\n}\n\npublic class EglDisplay : IDisposable\n{\n    public EglDisplay(IntPtr display, EglInterface eglInterface)\n    {\n        EglInterface = eglInterface;\n        _display = display;\n\n        _config = InitializeAndGetConfig(display, eglInterface);\n    }\n\n    public IntPtr Config =&gt; _config.Config;\n\n    private readonly EglConfigInfo _config;\n\n    private static EglConfigInfo InitializeAndGetConfig(IntPtr display, EglInterface eglInterface)\n    {\n        ...\n    }\n\n    public EglInterface EglInterface { get; }\n\n    public IntPtr Handle =&gt; _display;\n\n    private IntPtr _display;\n\n    public Lock.Scope Lock() =&gt; _lock.EnterScope();\n\n    private readonly Lock _lock = new();\n\n    public unsafe EglSurface CreatePBufferFromClientBuffer(int bufferType, IntPtr handle, int* attribs)\n    {\n        using (Lock())\n        {\n            var s = EglInterface.CreatePbufferFromClientBufferPtr(Handle, bufferType, handle,\n                Config, attribs);\n\n            if (s == IntPtr.Zero)\n                throw OpenGlException.GetFormattedException(\"eglCreatePbufferFromClientBuffer\", EglInterface);\n            return new EglSurface(this, s);\n        }\n    }\n}\n</code></pre>\n<p>以上代码的 EglConfigInfo 类型定义如下</p>\n<pre><code class=\"language-csharp\">internal class EglConfigInfo\n{\n    public IntPtr Config { get; }\n    public GlVersion Version { get; }\n    public int SurfaceType { get; }\n    public int[] Attributes { get; }\n    public int SampleCount { get; }\n    public int StencilSize { get; }\n\n    ...\n}\n</code></pre>\n<p>从以上代码可看到最关键的 WrapDirect3D11Texture 方法，这个方法将传入 D3D 纹理用于关联</p>\n<p>使用封装好的 AngleWin32EglDisplay 类，代码如下</p>\n<pre><code class=\"language-csharp\">        var angleWin32EglDisplay = new AngleWin32EglDisplay(display, egl);\n\n        EglContext eglContext = angleWin32EglDisplay.CreateContext();\n</code></pre>\n<p>这里的 CreateContext 方法实现如下</p>\n<pre><code class=\"language-csharp\">public class EglDisplay : IDisposable\n{\n    ...\n    public EglContext CreateContext()\n    {\n        lock (_lock)\n        {\n            var context = EglInterface.CreateContext(_display, Config,  IntPtr.Zero, _config.Attributes);\n\n            return new EglContext(this, context, _config.Version);\n        }\n    }\n    ...\n}\n</code></pre>\n<p>在 EglContext 里面似乎没有什么逻辑，只是存放 EglDisplay 和 context 指针等，其核心作用是防止直接让其他模块使用 context 指针，只是对 context 指针包装</p>\n<pre><code class=\"language-csharp\">public record EglContext(EglDisplay EglDisplay, IntPtr Context, GlVersion Version)\n{\n    public EglInterface EglInterface =&gt; EglDisplay.EglInterface;\n\n    public GlInterface GlInterface\n    {\n        get\n        {\n            if (_glInterface is null)\n            {\n                _glInterface = GlInterface.FromNativeUtf8GetProcAddress(Version, EglInterface.GetProcAddress);\n            }\n\n            return _glInterface;\n        }\n    }\n\n    private GlInterface? _glInterface;\n    public EglSurface? OffscreenSurface { get; } = null;\n\n    public IDisposable MakeCurrent() =&gt; MakeCurrent(OffscreenSurface);\n\n    public IDisposable MakeCurrent(EglSurface? surface)\n    {\n        var locker = new object();\n        Monitor.Enter(locker);\n        var old = new RestoreContext(EglInterface, EglDisplay.Handle, locker);\n\n        EglInterface.MakeCurrent(EglDisplay.Handle, IntPtr.Zero, IntPtr.Zero, IntPtr.Zero);\n\n        var success = EglInterface.MakeCurrent(EglDisplay.Handle, surface?.DangerousGetHandle() ?? IntPtr.Zero, surface?.DangerousGetHandle() ?? IntPtr.Zero, Context);\n\n        if (!success)\n        {\n            ...\n        }\n\n        return old;\n    }\n\n    private class RestoreContext : IDisposable\n    {\n        ...\n        public void Dispose()\n        {\n            _egl.MakeCurrent(_display, _draw, _read, _context);\n            Monitor.Exit(_l);\n        }\n    }\n}\n</code></pre>\n<p>可见 EglContext 额外多封装了 MakeCurrent 方法，用于将传入的 <code>EglSurface</code> 设置为 OpenGL 当前所工作的对象</p>\n<p>然后还返回了 RestoreContext 对象，用于完成之后将其重置状态，防止其他逻辑误写入，这里是 OpenGL 的标准用法</p>\n<p>使用封装的 EglContext 进行初始化准备，创建 GRContext 对象，代码如下</p>\n<pre><code class=\"language-csharp\">        EglContext eglContext = angleWin32EglDisplay.CreateContext();\n\n        var makeCurrent = eglContext.MakeCurrent();\n\n        // 以下两个都是 SkiaSharp 封装的方法\n        var grGlInterface = GRGlInterface.CreateGles(proc =&gt;\n        {\n            var procAddress = eglContext.GlInterface.GetProcAddress(proc);\n            return procAddress;\n        });\n\n        var grContext = GRContext.CreateGl(grGlInterface, new GRContextOptions()\n        {\n            AvoidStencilBuffers = true\n        });\n\n        makeCurrent.Dispose();\n</code></pre>\n<p>这部分逻辑都是 OpenGL 的常用初始化实现，没有什么特别的，如果大家对类型定义感兴趣，还请自行拉取代码了解</p>\n<h2 id=\"纹理对接\">纹理对接</h2>\n<p>完成初始化 ANGLE 和 OpenGL 之后，就可以开始进行纹理对接，代码如下</p>\n<pre><code class=\"language-csharp\">        // 先从交换链取出渲染目标纹理\n        ID3D11Texture2D d3D11Texture2D = swapChain.GetBuffer&lt;ID3D11Texture2D&gt;(0);\n\n        // 关键代码： 通过 eglCreatePbufferFromClientBuffer 将 D3D11 纹理包装为 EGLSurface\n        // 这一步的前置是在 eglCreateDeviceANGLE 里面将 ID3D11Texture2D 所在的 D3D11 设备关联： `egl.CreateDeviceANGLE(EglConsts.EGL_D3D11_DEVICE_ANGLE, d3D11Device1.NativePointer, null)`\n        EglSurface eglSurface =\n            angleWin32EglDisplay.WrapDirect3D11Texture(d3D11Texture2D.NativePointer, 0, 0,\n                (int)d3D11Texture2D.Description.Width, (int)d3D11Texture2D.Description.Height);\n</code></pre>\n<p>调用 WrapDirect3D11Texture 这一步的前置是在 eglCreateDeviceANGLE 里面将 ID3D11Texture2D 所在的 D3D11 设备关联，也就是上文的 <code>egl.CreateDeviceANGLE(EglConsts.EGL_D3D11_DEVICE_ANGLE, d3D11Device1.NativePointer, null)</code> 代码</p>\n<p>如此就拿到关键的 EglSurface 表面对象，其类型定义仅仅只是一个包装，代码如下</p>\n<pre><code class=\"language-csharp\">public class EglSurface : SafeHandle\n{\n    private readonly EglDisplay _display;\n    private readonly EglInterface _egl;\n\n    public EglSurface(EglDisplay display, IntPtr surface) : base(surface, true)\n    {\n        _display = display;\n        _egl = display.EglInterface;\n    }\n\n    protected override bool ReleaseHandle()\n    {\n        using (_display.Lock())\n            _egl.DestroySurface(_display.Handle, handle);\n        return true;\n    }\n\n    public override bool IsInvalid =&gt; handle == IntPtr.Zero;\n    public void SwapBuffers() =&gt; _egl.SwapBuffers(_display.Handle, handle);\n}\n</code></pre>\n<h2 id=\"与-skia-对接\">与 Skia 对接</h2>\n<p>与 Skia 对接的逻辑是发生在每次渲染上，这个过程中只是将 OpenGL 表面作为 Skia 画布而已，整个过程不发生任何的拷贝和实际执行逻辑。无需担心这一步从 OpenGL 绑定到 Skia 的性能损耗</p>\n<p>以下逻辑发生在每次渲染的时候</p>\n<pre><code class=\"language-csharp\">// 以下是每次画面渲染时都要执行的逻辑\n// 将 EGLSurface 绑定到 Skia 上\nusing (eglContext.MakeCurrent(eglSurface))\n{\n    ... // 在这里编写对接的代码\n}\n</code></pre>\n<p>以上这一步用于设置将渲染所用的 EglSurface 设置为 OpenGL 当前的渲染对象</p>\n<p>开始执行的时候，进入等待各种刷新逻辑，确保逻辑正确</p>\n<pre><code class=\"language-csharp\">            using (eglContext.MakeCurrent(eglSurface))\n            {\n                EglInterface eglInterface = angleWin32EglDisplay.EglInterface;\n                Debug.Assert(ReferenceEquals(egl, eglInterface));\n\n                eglInterface.WaitClient();\n                eglInterface.WaitGL();\n                eglInterface.WaitNative(EglConsts.EGL_CORE_NATIVE_ENGINE);\n                 ... // 在这里编写对接的代码\n\n            }\n</code></pre>\n<p>以上代码的 <code>WaitXxx</code> 三句代码含义分别如下：</p>\n<ul>\n<li>WaitClient： 底层是 <code>eglWaitClient</code> 方法，作用是把之前由当前 Client API 发出的命令流推进/同步到一个点，使得这些操作对后续 EGL 操作（以及可能的跨 API 访问）更安全</li>\n<li>WaitGL： 底层是 <code>eglWaitGL</code> 方法，等待 OpenGL（或 OpenGL ES）管线中的命令到达一个同步点。一般都在 <code>eglSwapBuffers</code> 前后调用，在本文后续将会用到 <code>eglSwapBuffers</code> 方法</li>\n<li>WaitNative： 底层是 <code>eglWaitNative</code> 方法，用于等待 native 那边别在用这个资源/或者等到一个可安全交接的点</li>\n</ul>\n<p>这个写法是比较保守的</p>\n<p>按照 OpenGL 的写法，接下来就是在 <code>eglContext.MakeCurrent(eglSurface)</code> 的后续，调用 glBindFramebuffer 和 glGetIntegerv 方法。调用 <code>glBindFramebuffer</code> 的作用是将某个 Framebuffer Object（FBO）绑定到当前上下文的绘制目标。再通过 <code>glGetIntegerv</code> 查询 <code>GL_FRAMEBUFFER_BINDING</code> 获取当前绑定到 GL_FRAMEBUFFER 的 framebuffer id 是多少，代码如下</p>\n<pre><code class=\"language-csharp\">                eglContext.GlInterface.BindFramebuffer(GlConsts.GL_FRAMEBUFFER, 0);\n\n                eglContext.GlInterface.GetIntegerv(GlConsts.GL_FRAMEBUFFER_BINDING, out var fb);\n</code></pre>\n<p>调用 <code>BindFramebuffer(int target, int fb)</code> （<code>glBindFramebuffer</code>） 的两个参数分别如下：</p>\n<ul>\n<li>target：绑定点，通常是 <code>GlConsts.GL_FRAMEBUFFER</code></li>\n<li>fb: 要绑定的 framebuffer id 号。这里传入的 0 是一个特殊值，表示绑定默认帧缓冲（default framebuffer），也就是“窗口/表面”背后的那个缓冲区，在本文这里就是 EGLSurface / swapchain backbuffer 了</li>\n</ul>\n<p>其作用就是让接下来所有绘制都输出到“当前 EGLSurface 的默认帧缓冲”，即在 <code>eglContext.MakeCurrent(eglSurface)</code> 绑定的这个由 ANGLE 映射的 D3D11 纹理</p>\n<p>调用 <code>GetIntegerv(int name, out int rv)</code> （<code>glGetIntegerv</code>）的两个参数分别如下：</p>\n<ul>\n<li>传入 GL_FRAMEBUFFER_BINDING 表示将查询当前绑定到 GL_FRAMEBUFFER 的 framebuffer id 是多少</li>\n<li>次参数 <code>fb</code> 为输出参数，将获取当前绑定的 framebuffer id 是多少</li>\n</ul>\n<p>为什么在上一行代码 <code>BindFramebuffer</code> 已经传入的 fb 是 0 的值，还需要立刻调用 <code>GetIntegerv</code> 去获取呢？这是因为“默认帧缓冲”在内部可能有一个 非 0 的平台 FBO （Framebuffer Object） id，GL_FRAMEBUFFER_BINDING 读出来可能不是 0 的值。尽管在大部分情况下，这里就是获取到 0 的值</p>\n<p>完成 OpenGL 渲染前准备之后，接下来可以开始准备 Skia 的对接逻辑了</p>\n<p>先在 Skia 层调用 <code>gr_direct_context_reset_context</code> 方法，告诉 Skia 层，需要重新获取 GL 层的状态。在 SkiaSharp 里 GRContext 表示 Skia 的 GPU 上下文，为了性能考虑，会在 Skia 里面缓存了一部分的 GPU/GL 状态，以避免每次绘制都大量地调用 <code>glGet*</code> 获取状态，或重复 <code>gl*</code> 状态设置。调用 <code>gr_direct_context_reset_context</code> 方法不等于重建上下文或清空资源，只是让 Skia 标记需要对当前 GL 状态重新获取而已。在本文这里将通过 SkiaSharp 封装的 <code>GRContext.ResetContext</code> 调用到 <code>gr_direct_context_reset_context</code> 方法</p>\n<pre><code class=\"language-csharp\">                grContext.ResetContext();\n</code></pre>\n<p>定义颜色格式，颜色格式最好和 DirectX 层相同，如此才能获取最佳性能。由于 Angle 层是做转发，因而对于一些画纯色的指令来说，即使颜色格式不相同，也不会存在损耗。但是如果涉及到某些表面纹理的处理，就可能需要 GPU 稍微动工执行一些转换逻辑</p>\n<pre><code class=\"language-csharp\">                // 颜色格式和前面定义的 Format colorFormat = Format.B8G8R8A8_UNorm; 相对应\n                var colorType = SKColorType.Bgra8888;\n</code></pre>\n<p>根据颜色格式，查询在当前 GPU/驱动/后端(OpenGL/GLES) + 指定颜色格式下，最多支持多少个 MSAA 采样数（sample count 能够支持的最大多重采样数）用于创建渲染目标 surface 表面</p>\n<pre><code class=\"language-csharp\">                var maxSamples = grContext.GetMaxSurfaceSampleCount(colorType);\n</code></pre>\n<p>正常来说，都会设置一个采样上限，采样数量越大，质量越好，但是性能损耗越大。在本文这里作为演示代码，就跳过这一步，有多好就用多好</p>\n<p>构造 GRGlFramebufferInfo 结构体，用于告诉 Skia 准备画到哪个 OpenGL FBO（Framebuffer Object） 上，以及这个 FBO （Framebuffer Object）的颜色格式是什么。再创建 GRBackendRenderTarget 对象，传入尺寸信息，采样信息，做好对接的准备</p>\n<pre><code class=\"language-csharp\">                var glInfo = new GRGlFramebufferInfo((uint)fb, colorType.ToGlSizedFormat());\n                // 从 OpenGL 对接到 Skia 上\n                using (var renderTarget = new GRBackendRenderTarget(clientSize.Width,\n                           clientSize.Height, maxSamples, eglDisplay.StencilSize, glInfo))\n                {\n                    ...\n                }\n</code></pre>\n<p>通过 <code>SKSurface.Create</code> 创建出 <code>SKSurface</code> 对象，从而获取到 SKCanvas 画板</p>\n<pre><code class=\"language-csharp\">                using (var renderTarget = new GRBackendRenderTarget(clientSize.Width,\n                           clientSize.Height, maxSamples, eglDisplay.StencilSize, glInfo))\n                {\n                    var surfaceProperties = new SKSurfaceProperties(SKPixelGeometry.RgbHorizontal);\n\n                    using (var skSurface = SKSurface.Create(grContext, renderTarget, GRSurfaceOrigin.TopLeft,\n                               colorType,\n                               surfaceProperties))\n                    {\n                        using (SKCanvas skCanvas = skSurface.Canvas)\n                        {\n                            // 在这里就拿到 SKCanvas 啦，可以开始绘制内容了\n                            ...\n                        }\n                    }\n                }\n</code></pre>\n<p>拿到了 Skia 的核心入口 SKCanvas 类，接下来的绘制逻辑就全面向 Skia 了，可以无视前面的各种对接方逻辑，不管对接方是 ANGLE 的还是直接软渲的等等。绘制的逻辑只需要管 SKCanvas 画布就可以了</p>\n<p>在本文这里，写了一点示例代码，用于绘制一个漂亮的界面，顺带也用于测试帧率</p>\n<pre><code class=\"language-csharp\">record SkiaRenderDemo(SizeI ClientSize)\n{\n    // 此为调试代码，绘制一些矩形条\n    private List&lt;RenderInfo&gt;? _renderList;\n\n    public void Draw(SKCanvas canvas)\n    {\n        var rectWeight = 10;\n        var rectHeight = 20;\n\n        var margin = 5;\n\n        if (_renderList is null)\n        {\n            // 如果是空，那就执行初始化\n            _renderList = new List&lt;RenderInfo&gt;();\n\n            for (int top = margin; top &lt; ClientSize.Height - rectHeight - margin; top += rectHeight + margin)\n            {\n                var skRect = new SKRect(margin, top, margin + rectWeight, top + rectHeight);\n                var color = new SKColor((uint)Random.Shared.Next()).WithAlpha(0xFF);\n                var step = Random.Shared.Next(1, 20);\n                var renderInfo = new RenderInfo(skRect, step, color);\n\n                _renderList.Add(renderInfo);\n            }\n        }\n\n        using var skPaint = new SKPaint();\n        skPaint.Style = SKPaintStyle.Fill;\n        for (var i = 0; i &lt; _renderList.Count; i++)\n        {\n            var renderInfo = _renderList[i];\n            skPaint.Color = renderInfo.Color;\n\n            canvas.DrawRect(renderInfo.Rect, skPaint);\n\n            var nextRect = renderInfo.Rect with\n            {\n                Right = renderInfo.Rect.Right + renderInfo.Step\n            };\n            if (nextRect.Right &gt; ClientSize.Width - margin)\n            {\n                nextRect = nextRect with\n                {\n                    Right = nextRect.Left + rectWeight\n                };\n            }\n\n            _renderList[i] = renderInfo with\n            {\n                Rect = nextRect\n            };\n        }\n    }\n\n    private readonly record struct RenderInfo(SKRect Rect, int Step, SKColor Color);\n}\n</code></pre>\n<p>以上只是为测试代码，大家可以编写自己的界面绘制逻辑</p>\n<h2 id=\"刷新界面\">刷新界面</h2>\n<p>完成绘制之后，还需要将画面推送出去，让双缓存交换一下，代码如下</p>\n<pre><code class=\"language-csharp\">                using (var renderTarget = new GRBackendRenderTarget(clientSize.Width,\n                           clientSize.Height, maxSamples, eglDisplay.StencilSize, glInfo))\n                {\n                    var surfaceProperties = new SKSurfaceProperties(SKPixelGeometry.RgbHorizontal);\n\n                    using (var skSurface = SKSurface.Create(grContext, renderTarget, GRSurfaceOrigin.TopLeft,\n                               colorType,\n                               surfaceProperties))\n                    {\n                        using (SKCanvas skCanvas = skSurface.Canvas)\n                        {\n                            // 随便画内容\n                            skCanvas.Clear();\n                            renderDemo.Draw(skCanvas);\n                        }\n                    }\n                }\n\n                // 如果开启渲染同步等待，则会在这里等待\n                grContext.Flush();\n\n                // 让 OpenGL 层刷出去\n                eglContext.GlInterface.Flush();\n                eglInterface.WaitGL();\n                eglSurface.SwapBuffers();\n\n                eglInterface.WaitClient();\n                eglInterface.WaitGL();\n                eglInterface.WaitNative(EglConsts.EGL_CORE_NATIVE_ENGINE);\n\n                // 让交换链推送\n                swapChain.Present(1, PresentFlags.None);\n</code></pre>\n<p>推送的逻辑是一级级的，先是 Skia 层通过 <code>grContext.Flush</code> 将绘制命令刷出去到 OpenGL 层。在 OpenGL 层通过 <code>GlInterface.Flush</code> 和 <code>SwapBuffers</code> 等完成绘制。最后再由 DirectX 的交换链 Present 将画面提交给到屏幕</p>\n<p>以上就是一个最简的对接实现，通过 ANGLE 的能力，让 Skia 可以调用到 DirectX 进行渲染，极大提升渲染性能</p>\n<p>也从此过程可以看到，没有需求要将 Buffer 从 GPU 拷贝到 CPU 上，可以全过程都发生在 GPU 中。尝试实际运行代码，也可以看到 CPU 接近不动，而 GPU 在干活</p>\n<p>本文的实现方法是我从 Avalonia 框架里面学到的，我对 OpenGL 陌生，对 DirectX 了解。通过阅读 Avalonia 框架源代码，我学习了此对接过程</p>\n<h2 id=\"核心代码\">核心代码</h2>\n<p>以下是 <code>Program.cs</code> 文件的全部代码</p>\n<pre><code class=\"language-csharp\">using System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Linq;\nusing System.Runtime.InteropServices;\nusing Windows.Win32.Foundation;\nusing Windows.Win32.Graphics.Gdi;\nusing Windows.Win32.UI.WindowsAndMessaging;\nusing KurbawjeleJarlayenel.Diagnostics;\nusing KurbawjeleJarlayenel.OpenGL;\nusing KurbawjeleJarlayenel.OpenGL.Angle;\nusing KurbawjeleJarlayenel.OpenGL.Egl;\nusing SkiaSharp;\nusing Vortice.Direct3D;\nusing Vortice.Direct3D11;\nusing Vortice.DXGI;\nusing Vortice.Mathematics;\nusing static Windows.Win32.PInvoke;\n\nnamespace KurbawjeleJarlayenel;\n\nclass Program\n{\n    [STAThread]\n    static unsafe void Main(string[] args)\n    {\n        // 创建窗口\n        var window = CreateWindow();\n        // 显示窗口\n        ShowWindow(window, SHOW_WINDOW_CMD.SW_NORMAL);\n\n        // 初始化渲染\n        // 初始化 DX 相关\n        #region 初始化 DX 相关\n\n        var dxgiFactory2 = DXGI.CreateDXGIFactory1&lt;IDXGIFactory2&gt;();\n\n        IDXGIAdapter1? hardwareAdapter = GetHardwareAdapter(dxgiFactory2)\n            // 这里 ToList 只是想列出所有的 IDXGIAdapter1 在实际代码里，大部分都是获取第一个\n            .ToList().FirstOrDefault();\n        if (hardwareAdapter == null)\n        {\n            throw new InvalidOperationException(\"Cannot detect D3D11 adapter\");\n        }\n\n        FeatureLevel[] featureLevels = new[]\n        {\n            FeatureLevel.Level_11_1,\n            FeatureLevel.Level_11_0,\n            FeatureLevel.Level_10_1,\n            FeatureLevel.Level_10_0,\n            FeatureLevel.Level_9_3,\n            FeatureLevel.Level_9_2,\n            FeatureLevel.Level_9_1,\n        };\n\n        IDXGIAdapter1 adapter = hardwareAdapter;\n        DeviceCreationFlags creationFlags = DeviceCreationFlags.BgraSupport;\n        var result = D3D11.D3D11CreateDevice\n        (\n            adapter,\n            DriverType.Unknown,\n            creationFlags,\n            featureLevels,\n            out ID3D11Device d3D11Device, out FeatureLevel featureLevel,\n            out ID3D11DeviceContext d3D11DeviceContext\n        );\n\n        _ = featureLevel;\n\n        result.CheckError();\n\n        // 大部分情况下，用的是 ID3D11Device1 和 ID3D11DeviceContext1 类型\n        // 从 ID3D11Device 转换为 ID3D11Device1 类型\n        ID3D11Device1 d3D11Device1 = d3D11Device.QueryInterface&lt;ID3D11Device1&gt;();\n        var d3D11DeviceContext1 = d3D11DeviceContext.QueryInterface&lt;ID3D11DeviceContext1&gt;();\n        _ = d3D11DeviceContext1;\n\n        // 获取到了新的两个接口，就可以减少 `d3D11Device` 和 `d3D11DeviceContext` 的引用计数。调用 Dispose 不会释放掉刚才申请的 D3D 资源，只是减少引用计数\n        d3D11Device.Dispose();\n        d3D11DeviceContext.Dispose();\n\n        RECT windowRect;\n        GetClientRect(window, &amp;windowRect);\n        var clientSize = new SizeI(windowRect.right - windowRect.left, windowRect.bottom - windowRect.top);\n\n        // 颜色格式有要求，才能和 Angle 正确交互\n        Format colorFormat = Format.B8G8R8A8_UNorm;\n\n        // 缓存的数量，包括前缓存。大部分应用来说，至少需要两个缓存，这个玩过游戏的伙伴都知道\n        const int frameCount = 2;\n        SwapChainDescription1 swapChainDescription = new()\n        {\n            Width = (uint)clientSize.Width,\n            Height = (uint)clientSize.Height,\n            Format = colorFormat, // B8G8R8A8_UNorm\n            BufferCount = frameCount,\n            BufferUsage = Usage.RenderTargetOutput,\n            SampleDescription = SampleDescription.Default,\n            Scaling = Scaling.Stretch,\n            SwapEffect = SwapEffect.FlipSequential,\n            AlphaMode = AlphaMode.Ignore,\n            Flags = SwapChainFlags.None,\n        };\n\n        var fullscreenDescription = new SwapChainFullscreenDescription()\n        {\n            Windowed = true,\n        };\n\n        IDXGISwapChain1 swapChain =\n            dxgiFactory2.CreateSwapChainForHwnd(d3D11Device1, window, swapChainDescription, fullscreenDescription);\n\n        // 不要被按下 alt+enter 进入全屏\n        dxgiFactory2.MakeWindowAssociation(window,\n            WindowAssociationFlags.IgnoreAltEnter | WindowAssociationFlags.IgnorePrintScreen);\n\n        #endregion\n\n        // 初始化 Angle 和 OpenGL 相关\n\n        #region 初始化 Angle 相关\n\n        var egl = new Win32AngleEglInterface();\n        // 传入 ID3D11Device1 的指针，将 D3D11 设备和 AngleDevice 绑定\n        var angleDevice = egl.CreateDeviceANGLE(EglConsts.EGL_D3D11_DEVICE_ANGLE, d3D11Device1.NativePointer, null);\n        var display = egl.GetPlatformDisplayExt(EglConsts.EGL_PLATFORM_DEVICE_EXT, angleDevice, null);\n\n        var angleWin32EglDisplay = new AngleWin32EglDisplay(display, egl);\n\n        EglContext eglContext = angleWin32EglDisplay.CreateContext();\n\n        var makeCurrent = eglContext.MakeCurrent();\n\n        var grGlInterface = GRGlInterface.CreateGles(proc =&gt;\n        {\n            var procAddress = eglContext.GlInterface.GetProcAddress(proc);\n            return procAddress;\n        });\n\n        var grContext = GRContext.CreateGl(grGlInterface, new GRContextOptions()\n        {\n            AvoidStencilBuffers = true\n        });\n        makeCurrent.Dispose();\n\n        #endregion\n\n        // 通过 Angle 关联 DX 和 OpenGL 纹理\n\n        #region 关联 DX 和 OpenGL 纹理\n\n        // 先从交换链取出渲染目标纹理\n        ID3D11Texture2D d3D11Texture2D = swapChain.GetBuffer&lt;ID3D11Texture2D&gt;(0);\n        Debug.Assert(d3D11Texture2D.Description.Width == clientSize.Width);\n        Debug.Assert(d3D11Texture2D.Description.Height == clientSize.Height);\n\n        // 关键代码： 通过 eglCreatePbufferFromClientBuffer 将 D3D11 纹理包装为 EGLSurface\n        // 这一步的前置是在 eglCreateDeviceANGLE 里面将 ID3D11Texture2D 所在的 D3D11 设备关联： `egl.CreateDeviceANGLE(EglConsts.EGL_D3D11_DEVICE_ANGLE, d3D11Device1.NativePointer, null)`\n        EglSurface eglSurface =\n            angleWin32EglDisplay.WrapDirect3D11Texture(d3D11Texture2D.NativePointer, 0, 0,\n                (int)d3D11Texture2D.Description.Width, (int)d3D11Texture2D.Description.Height);\n\n        // 后续 Skia 也许会使用 Graphite 的 Dawn 支持 D3D 而不是 EGL 的方式\n        // &gt; Current plans for Graphite are to support D3D11 and D3D12 through the Dawn backend.\n        // 详细请看\n        // https://groups.google.com/g/skia-discuss/c/WY7yzRjGGFA\n        // &gt; Ganesh和Graphite是两组技术，Ganesh更老更稳定，Graphite更新、更快（多线程支持更好）、更不稳定，但它是趋势，是Skia团队的主攻方向。Chrome已经在个别地方使用Graphite了\n        // https://zhuanlan.zhihu.com/p/20265941170\n\n        #endregion\n\n        SkiaRenderDemo renderDemo = new(clientSize);\n\n        while (true)\n        {\n            // 界面渲染\n            using var step = StepPerformanceCounter.RenderThreadCounter.StepStart(\"Render\");\n\n            // 以下是每次画面渲染时都要执行的逻辑\n            // 将 EGLSurface 绑定到 Skia 上\n            using (eglContext.MakeCurrent(eglSurface))\n            {\n                EglInterface eglInterface = angleWin32EglDisplay.EglInterface;\n                Debug.Assert(ReferenceEquals(egl, eglInterface));\n\n                eglInterface.WaitClient();\n                eglInterface.WaitGL();\n                eglInterface.WaitNative(EglConsts.EGL_CORE_NATIVE_ENGINE);\n\n                eglContext.GlInterface.BindFramebuffer(GlConsts.GL_FRAMEBUFFER, 0);\n\n                eglContext.GlInterface.GetIntegerv(GlConsts.GL_FRAMEBUFFER_BINDING, out var fb);\n                // 颜色格式和前面定义的 Format colorFormat = Format.B8G8R8A8_UNorm; 相对应\n                var colorType = SKColorType.Bgra8888;\n                // 当然，写成 SKColorType.Rgba8888 也是能被兼容的\n                // https://github.com/AvaloniaUI/Avalonia/discussions/20559\n                grContext.ResetContext();\n\n                var maxSamples = grContext.GetMaxSurfaceSampleCount(colorType);\n\n                EglDisplay eglDisplay = angleWin32EglDisplay;\n\n                var glInfo = new GRGlFramebufferInfo((uint)fb, colorType.ToGlSizedFormat());\n                // 从 OpenGL 对接到 Skia 上\n                using (var renderTarget = new GRBackendRenderTarget(clientSize.Width,\n                           clientSize.Height, maxSamples, eglDisplay.StencilSize, glInfo))\n                {\n                    var surfaceProperties = new SKSurfaceProperties(SKPixelGeometry.RgbHorizontal);\n\n                    using (var skSurface = SKSurface.Create(grContext, renderTarget, GRSurfaceOrigin.TopLeft,\n                               colorType,\n                               surfaceProperties))\n                    {\n                        using (SKCanvas skCanvas = skSurface.Canvas)\n                        {\n                            // 随便画内容\n                            skCanvas.Clear();\n                            renderDemo.Draw(skCanvas);\n                        }\n                    }\n                }\n\n                // 如果开启渲染同步等待，则会在这里等待\n                grContext.Flush();\n\n                // 让 OpenGL 层刷出去\n                eglContext.GlInterface.Flush();\n                eglInterface.WaitGL();\n                eglSurface.SwapBuffers();\n\n                eglInterface.WaitClient();\n                eglInterface.WaitGL();\n                eglInterface.WaitNative(EglConsts.EGL_CORE_NATIVE_ENGINE);\n\n                // 让交换链推送\n                swapChain.Present(1, PresentFlags.None);\n            }\n\n            // 以下只是为了防止窗口无响应而已\n            var success = PeekMessage(out var msg, HWND.Null, 0, 0, PEEK_MESSAGE_REMOVE_TYPE.PM_REMOVE);\n            if (success)\n            {\n                // 处理窗口消息\n                TranslateMessage(&amp;msg);\n                DispatchMessage(&amp;msg);\n            }\n        }\n\n        Console.ReadLine();\n    }\n\n    private static unsafe HWND CreateWindow()\n    {\n        DwmIsCompositionEnabled(out var compositionEnabled);\n\n        if (!compositionEnabled)\n        {\n            Console.WriteLine($\"无法启用透明窗口效果\");\n        }\n\n        WINDOW_EX_STYLE exStyle = WINDOW_EX_STYLE.WS_EX_OVERLAPPEDWINDOW;\n\n        var style = WNDCLASS_STYLES.CS_OWNDC | WNDCLASS_STYLES.CS_HREDRAW | WNDCLASS_STYLES.CS_VREDRAW;\n\n        var defaultCursor = LoadCursor(\n            new HINSTANCE(IntPtr.Zero), new PCWSTR(IDC_ARROW.Value));\n\n        var className = $\"lindexi-{Guid.NewGuid().ToString()}\";\n        var title = \"The Title\";\n        fixed (char* pClassName = className)\n        fixed (char* pTitle = title)\n        {\n            var wndClassEx = new WNDCLASSEXW\n            {\n                cbSize = (uint)Marshal.SizeOf&lt;WNDCLASSEXW&gt;(),\n                style = style,\n                lpfnWndProc = new WNDPROC(WndProc),\n                hInstance = new HINSTANCE(GetModuleHandle(null).DangerousGetHandle()),\n                hCursor = defaultCursor,\n                hbrBackground = new HBRUSH(IntPtr.Zero),\n                lpszClassName = new PCWSTR(pClassName)\n            };\n            ushort atom = RegisterClassEx(in wndClassEx);\n\n            var dwStyle = WINDOW_STYLE.WS_OVERLAPPEDWINDOW;\n\n            var windowHwnd = CreateWindowEx(\n                exStyle,\n                new PCWSTR((char*)atom),\n                new PCWSTR(pTitle),\n                dwStyle,\n                0, 0, 1900, 1000,\n                HWND.Null, HMENU.Null, HINSTANCE.Null, null);\n\n            return windowHwnd;\n        }\n\n        static LRESULT WndProc(HWND hwnd, uint message, WPARAM wParam, LPARAM lParam)\n        {\n            WindowsMessage windowsMessage = (WindowsMessage)message;\n            if (windowsMessage == WindowsMessage.WM_CLOSE)\n            {\n                Environment.Exit(0);\n            }\n\n            return DefWindowProc(hwnd, message, wParam, lParam);\n        }\n    }\n\n    private static IEnumerable&lt;IDXGIAdapter1&gt; GetHardwareAdapter(IDXGIFactory2 factory)\n    {\n        using IDXGIFactory6? factory6 = factory.QueryInterfaceOrNull&lt;IDXGIFactory6&gt;();\n        if (factory6 != null)\n        {\n            // 这个系统的 DX 支持 IDXGIFactory6 类型\n            // 先告诉系统，要高性能的显卡\n            for (uint adapterIndex = 0;\n                 factory6.EnumAdapterByGpuPreference(adapterIndex, GpuPreference.HighPerformance,\n                     out IDXGIAdapter1? adapter).Success;\n                 adapterIndex++)\n            {\n                if (adapter == null)\n                {\n                    continue;\n                }\n\n                AdapterDescription1 desc = adapter.Description1;\n                if ((desc.Flags &amp; AdapterFlags.Software) != AdapterFlags.None)\n                {\n                    // Don't select the Basic Render Driver adapter.\n                    adapter.Dispose();\n                    continue;\n                }\n\n                yield return adapter;\n            }\n        }\n        else\n        {\n            // 不支持就不支持咯，用旧版本的方式获取显示适配器接口\n        }\n\n        // 如果枚举不到，那系统返回啥都可以\n        for (uint adapterIndex = 0;\n             factory.EnumAdapters1(adapterIndex, out IDXGIAdapter1? adapter).Success;\n             adapterIndex++)\n        {\n            AdapterDescription1 desc = adapter.Description1;\n\n            if ((desc.Flags &amp; AdapterFlags.Software) != AdapterFlags.None)\n            {\n                // Don't select the Basic Render Driver adapter.\n                adapter.Dispose();\n\n                continue;\n            }\n\n            yield return adapter;\n        }\n    }\n}\n\nrecord SkiaRenderDemo(SizeI ClientSize)\n{\n    // 此为调试代码，绘制一些矩形条\n    private List&lt;RenderInfo&gt;? _renderList;\n\n    public void Draw(SKCanvas canvas)\n    {\n        var rectWeight = 10;\n        var rectHeight = 20;\n\n        var margin = 5;\n\n        if (_renderList is null)\n        {\n            // 如果是空，那就执行初始化\n            _renderList = new List&lt;RenderInfo&gt;();\n\n            for (int top = margin; top &lt; ClientSize.Height - rectHeight - margin; top += rectHeight + margin)\n            {\n                var skRect = new SKRect(margin, top, margin + rectWeight, top + rectHeight);\n                var color = new SKColor((uint)Random.Shared.Next()).WithAlpha(0xFF);\n                var step = Random.Shared.Next(1, 20);\n                var renderInfo = new RenderInfo(skRect, step, color);\n\n                _renderList.Add(renderInfo);\n            }\n        }\n\n        using var skPaint = new SKPaint();\n        skPaint.Style = SKPaintStyle.Fill;\n        for (var i = 0; i &lt; _renderList.Count; i++)\n        {\n            var renderInfo = _renderList[i];\n            skPaint.Color = renderInfo.Color;\n\n            canvas.DrawRect(renderInfo.Rect, skPaint);\n\n            var nextRect = renderInfo.Rect with\n            {\n                Right = renderInfo.Rect.Right + renderInfo.Step\n            };\n            if (nextRect.Right &gt; ClientSize.Width - margin)\n            {\n                nextRect = nextRect with\n                {\n                    Right = nextRect.Left + rectWeight\n                };\n            }\n\n            _renderList[i] = renderInfo with\n            {\n                Rect = nextRect\n            };\n        }\n    }\n\n    private readonly record struct RenderInfo(SKRect Rect, int Step, SKColor Color);\n}\n</code></pre>\n<h2 id=\"全部代码\">全部代码</h2>\n<p>本文代码放在 <a href=\"https://github.com/lindexi/lindexi_gd/tree/6bd17b7dcb57c5c0bc0958c7428ba589733ba71f/DirectX/Angle/KurbawjeleJarlayenel\" rel=\"noopener nofollow\" target=\"_blank\">github</a> 和 <a href=\"https://gitee.com/lindexi/lindexi_gd/tree/6bd17b7dcb57c5c0bc0958c7428ba589733ba71f/DirectX/Angle/KurbawjeleJarlayenel\" rel=\"noopener nofollow\" target=\"_blank\">gitee</a> 上，可以使用如下命令行拉取代码。我整个代码仓库比较庞大，使用以下命令行可以进行部分拉取，拉取速度比较快</p>\n<p>先创建一个空文件夹，接着使用命令行 cd 命令进入此空文件夹，在命令行里面输入以下代码，即可获取到本文的代码</p>\n<pre><code>git init\ngit remote add origin https://gitee.com/lindexi/lindexi_gd.git\ngit pull origin 6bd17b7dcb57c5c0bc0958c7428ba589733ba71f\n</code></pre>\n<p>以上使用的是国内的 gitee 的源，如果 gitee 不能访问，请替换为 github 的源。请在命令行继续输入以下代码，将 gitee 源换成 github 源进行拉取代码。如果依然拉取不到代码，可以发邮件向我要代码</p>\n<pre><code>git remote remove origin\ngit remote add origin https://github.com/lindexi/lindexi_gd.git\ngit pull origin 6bd17b7dcb57c5c0bc0958c7428ba589733ba71f\n</code></pre>\n<p>获取代码之后，进入 DirectX/Angle/KurbawjeleJarlayenel 文件夹，即可获取到源代码</p>\n<h2 id=\"更多博客\">更多博客</h2>\n<p>渲染部分，关于 SharpDx 和 Vortice 的使用方法，包括入门级教程，请参阅：</p>\n<ul>\n<li><a href=\"https://blog.lindexi.com/post/WPF-%E4%BD%BF%E7%94%A8-SharpDx-%E6%B8%B2%E6%9F%93%E5%8D%9A%E5%AE%A2%E5%AF%BC%E8%88%AA.html\" rel=\"noopener nofollow\" target=\"_blank\">渲染博客导航</a></li>\n<li><a href=\"https://blog.lindexi.com/post/sharpdx.html\" rel=\"noopener nofollow\" target=\"_blank\">SharpDX 系列</a></li>\n</ul>\n<p>更多关于我博客请参阅 <a href=\"https://blog.lindexi.com/post/%E5%8D%9A%E5%AE%A2%E5%AF%BC%E8%88%AA.html\" rel=\"noopener nofollow\" target=\"_blank\">博客导航</a></p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>博客园博客只做备份，博客发布就不再更新，如果想看最新博客，请访问 https://blog.lindexi.com/</p>\n\n<p>如图片看不见，请在浏览器开启不安全http内容兼容</p>\n\n<a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"license\"><img alt=\"知识共享许可协议\" src=\"https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\" style=\"border-width: 0;\" /></a><br />本作品采用<a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"license\">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。欢迎转载、使用、重新发布，但务必保留文章署名[林德熙](https://www.cnblogs.com/lindexi)(包含链接:https://www.cnblogs.com/lindexi )，不得用于商业目的，基于本文修改后的作品务必以相同的许可发布。如有任何疑问，请与我[联系](mailto:lindexi_gd@163.com)。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 08:39</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lindexi\">lindexi</a>&nbsp;\n阅读(<span id=\"post_view_count\">95</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MAF快速入门（15）Agent调试利器：DevUI",
      "link": "https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper15",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper15\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 08:30\">\n    <span>MAF快速入门（15）Agent调试利器：DevUI</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"MAF快速入门（15）Agent调试利器：DevUI\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203907269-1893526876.png\" />\n        DevUI 是一个开箱即用的交互式 Web 调试界面，无需额外开发，启用后就能可视化测试、调试 AI 代理，从 Agent 列表查看、工具调用验证到工作流流转，全流程可视化，让 AI 智能体开发从 “盲调” 变 “明调”。本文介绍了DevUI是什么，它有什么样的优势，随后介绍了如何在MAF中快速集成DevUI用于开发调试获得友好的开发调试体验。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><span><span>大家好，我是Edison。</span></span></p>\n<p><span><span>最近我一直在跟着圣杰的《<a class=\"normal_text_link mp_article_text_link\" href=\"https://mp.weixin.qq.com/s?__biz=MzA4NzQzNTg4Ng==&amp;mid=2651744458&amp;idx=1&amp;sn=139f7584e81aeecd0945133bdc2b4791&amp;scene=21#wechat_redirect\" rel=\"noopener nofollow\" target=\"_blank\"><span>.NET+AI智能体开发进阶</span></a><span>》课程学习MAF开发多智能体工作流，我强烈推荐你也上车跟我一起出发！</span></span></span></p>\n<p><span><a class=\"normal_text_link mp_article_text_link\" href=\"https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper14\" target=\"_blank\"><span>上一篇</span></a><span>，我们学习了MAF中<span><span>快速集成A2A (Agent to Agent)<span><span>。本篇，我们来了解下在MAF提供的调试利器：DevUI。</span></span></span></span></span></span></p>\n<h1><strong>1 什么是DevUI</strong></h1>\n<p><span><span><span><span><span><span><span><span><span>DevUI 是一个开箱即用的<span><strong>交互式 Web 调试界面</strong><span>，无需额外开发，启用后就能可视化测试、调试 AI 代理，从 Agent 列表查看、工具调用验证到工作流流转，全流程可视化，<span>让 AI 智能体开发从 “盲调” 变 “明调”<span>。</span></span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span>DevUI 允许开发者：</span></p>\n<ul class=\"list-paddingleft-1\">\n<li>\n<p><span>🧪&nbsp;<strong>在浏览器中测试 Agent</strong><span>：无需编写客户端代码即可与 Agent 对话。</span></span></p>\n</li>\n<li>\n<p><span>📊&nbsp;<strong>查看对话历史</strong><span>：清晰展示 User 和 Agent 之间的消息交互。</span></span></p>\n</li>\n<li>\n<p><span>🔍&nbsp;<strong>调试多 Agent 系统</strong><span>：支持切换不同的 Agent 和 Workflow 进行测试。</span></span></p>\n</li>\n<li>\n<p><span>🛠️&nbsp;<strong>零配置启动</strong><span>：只需简单的配置即可集成到 ASP.NET Core 应用中。</span></span></p>\n</li>\n</ul>\n<p><span>综上所述，DevUI 就像是 Agent 的<strong> “浏览器开发者工具”</strong>，让你能够直观看到 Agent 的 “一举一动”，快速调试和定位问题。</span></p>\n<p><span style=\"text-decoration: underline;\"><span>画外音：DevUI 即 Developer UI, it's For Developers!</span></span></p>\n<h1><strong><span>2 快速开始：创建一个DevUI示例<strong><span><br /></span></strong></span></strong></h1>\n<p>在MAF中提供了一个内置的DevUI组件，我们可以非常方便地创建集成DevUI的Agent应用。</p>\n<p>接下来，我们就一步一步完成一个DevUI示例。</p>\n<p>首先，我们创建一个ASP.NET Web应用，安装以下NuGet包：</p>\n<div class=\"cnblogs_code\">\n<pre>&lt;PackageReference Include=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Microsoft.Agents.AI.OpenAI</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> Version=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">1.0.0-preview.260128.1</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> /&gt;\n&lt;PackageReference Include=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Microsoft.Agents.AI.Workflows</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> Version=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">1.0.0-preview.260128.1</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> /&gt;\n&lt;PackageReference Include=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Microsoft.Agents.AI.DevUI</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> Version=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">1.0.0-preview.260128.1</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> /&gt;\n&lt;PackageReference Include=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Microsoft.Agents.AI.Hosting</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> Version=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">1.0.0-preview.260128.1</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> /&gt;\n&lt;PackageReference Include=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Microsoft.Agents.AI.Hosting.OpenAI</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> Version=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">1.0.0-alpha.260128.1</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> /&gt;\n&lt;PackageReference Include=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Microsoft.Extensions.AI.OpenAI</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> Version=<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">10.2.0-preview.1.26063.2</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> /&gt;</pre>\n</div>\n<p>然后，就是整个示例的核心部分，我们一块一块来说：</p>\n<p>（1）创建并注册ChatClient</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">var</span> builder =<span style=\"color: rgba(0, 0, 0, 1);\"> WebApplication.CreateBuilder(args);\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Step0. Load Configuration</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> config = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> ConfigurationBuilder()\n    .AddJsonFile($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">appsettings.json</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, optional: <span style=\"color: rgba(0, 0, 255, 1);\">false</span>, reloadOnChange: <span style=\"color: rgba(0, 0, 255, 1);\">true</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n    .Build();\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> openAIProvider = config.GetSection(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">OpenAI</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).Get&lt;OpenAIProvider&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Step1. Register one ChatClient</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> chatClient = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> OpenAIClient(\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> ApiKeyCredential(openAIProvider.ApiKey),\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> OpenAIClientOptions { Endpoint = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> Uri(openAIProvider.Endpoint) })\n    .GetChatClient(openAIProvider.ModelId)\n    .AsIChatClient();\nbuilder.Services.AddChatClient(chatClient);</span></pre>\n</div>\n<p>（2）创建并注册一些示例Agents：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Step2. Register some Agents</span>\nbuilder.AddAIAgent(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Assistant</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">你是一位乐于助人的助手。回答问题简洁准确。</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\nbuilder.AddAIAgent(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Poet</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">你是一位富有创造力的诗人。使用优美的诗篇回答所有的请求</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\nbuilder.AddAIAgent(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Coder</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">你是一位资深的程序员。请协助用户解决编程问题，并提供代码示例。</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>);</pre>\n</div>\n<p><span>（3）创建并注册一个Workflow：</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Step3. Register one Workflow</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> writerAgent = builder.AddAIAgent(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Writer</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">你是一位乐于助人的助手，善于回答用户提出的各种问题。</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> reviewerAgent = builder.AddAIAgent(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Reviewer</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">你是一位专业审阅者，请协助审阅并评价之前的回复。</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\nbuilder.AddWorkflow(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">TestWorkflow</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, (sp, key) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> aiAgents = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> List&lt;IHostedAgentBuilder&gt;<span style=\"color: rgba(0, 0, 0, 1);\">()\n    {\n        writerAgent,\n        reviewerAgent\n    }\n    .Select(hab </span>=&gt; sp.GetRequiredKeyedService&lt;AIAgent&gt;<span style=\"color: rgba(0, 0, 0, 1);\">(hab.Name));\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> AgentWorkflowBuilder.BuildSequential(\n        workflowName: key,\n        agents: aiAgents);\n}).AddAsAIAgent();</span></pre>\n</div>\n<p><span>（4）注册DevUI相关服务：</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Step4. Register DevUI related services</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">builder.Services.AddOpenAIResponses();\nbuilder.Services.AddOpenAIConversations();</span></pre>\n</div>\n<p><span>（5）映射DevUI相关端点：</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">var</span> app =<span style=\"color: rgba(0, 0, 0, 1);\"> builder.Build();\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Step5. Mapping DevUI related endpoints</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">app.MapOpenAIResponses();\napp.MapOpenAIConversations();\n</span><span style=\"color: rgba(0, 0, 255, 1);\">if</span><span style=\"color: rgba(0, 0, 0, 1);\"> (app.Environment.IsDevelopment())\n{\n    app.MapDevUI();\n}\n......\napp.Run();</span></pre>\n</div>\n<p>可以看到，我们仅用一行代码 app.MapDevUI() 就启用了DevUI，无需开发任何前端代码。</p>\n<p>综上所述，我们创建了一些示例Agent 和 一个Workflow 作为后续演示。</p>\n<h1><span>3 开启调试：友好体验</span></h1>\n<p><span>这里我们启动起来，就会看到如下所示的界面：</span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203358540-716971522.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span><span>整个DevUI界面氛围两部分：</span></span></p>\n<p><span><span>（1）左边是调试区 和 展示区，可以看到对话记录 和 Workflow节点状态；</span></span></p>\n<p><span><span>（2）右边是跟踪区，展示Trace 和 Event 等执行记录，以便快速定位问题；</span></span></p>\n<p><span><span>我们可以通过点击左上角的下拉框，看到我们注册的所有Agent 和 Workflow：</span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203415835-431030566.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span><span><span>这就意味着，我们可以对所有注册的Agent对象进行调试！</span></span></span></p>\n<h3><span><span>3.1 调试单个Agent</span></span></h3>\n<p><span><span><span><span><span><span><span>这里我们测试Poet 和 Coder两个Agent：</span></span></span></span></span></span></span></p>\n<p><span><span><span><span><span><span><span>首先是Poet，我们让它作一首诗。</span></span></span></span></span></span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203444802-128625023.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span><span><span><span><span><span><span>其次是Coder，我们让它写一段代码。</span></span></span></span></span></span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203459831-1485532135.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span>可以看到，它的输出是<span>流式<span>的，且针对像代码这块输出做了代码块的展示，总之显示地很友好，看起来很舒服。</span></span></span></p>\n<h3><span><span>3.2 调试一个Workflow</span></span></h3>\n<p><span><span><span><span><span><span>这里我们测试一下注册的Workflow，这是一个 Editor -&gt; Reviewer 的典型顺序工作流，首先由创作者编写初稿，然后由审阅者进行审阅，最终输出给用户。</span></span></span></span></span></span></p>\n<p><span><span><span><span><span><span>下图展示切换到Workflow的展示：</span></span></span></span></span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203534335-1915055144.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span><span><span><span><span><span><span><span><span>可以看到，它清晰地展示了工作流的节点和顺序。</span></span></span></span></span></span></span></span></span></p>\n<p><span><span><span><span><span><span><span><span><span>然后，点击Run按钮即可输入启动内容：</span></span></span></span></span></span></span></span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203549664-1376363888.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span><span><span><span><span><span>随后，可以看到它执行的全过程，通过右边的区域可以看到每个执行步骤的过程：</span></span></span></span></span></span></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/381412/202602/381412-20260206203605602-2134132627.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p><span><span><span><span><span><span><span><span>最终，整个工作流节点都变成了绿色的完成状态，我们可以在右边点击执行过程看到中间输出内容 和 最终输出内容。</span></span></span></span></span></span></span></span></p>\n<p><span><span><span><span><span><span><span><span>此外，如果涉及工具调用的话，还可以点击 Tools 区域查看调用工具的记录，实在不要太方便！</span></span></span></span></span></span></span></span></p>\n<h1><span>4 注意事项</span></h1>\n<p><span>DevUI 虽好，但是其本身只是用来服务开发阶段的，因此建议：</span></p>\n<ul class=\"list-paddingleft-1\">\n<li><strong>仅在开发环境启用DevUI</strong>，生产环境请关闭DevUI。</li>\n<li>如需在测试环境启用DevUI，<strong>建议添加访问权限控制</strong>，避免暴露敏感信息。</li>\n</ul>\n<h1><span>5 小结</span></h1>\n<p><span><span><span>本文介绍了DevUI是什么，它有什么样的优势，随后介绍了如何在MAF中快速集成DevUI用于开发调试获得友好的开发调试体验，希望本文的案例对你有所帮助。</span></span><br /></span></p>\n<h1>示例源码</h1>\n<p>GitHub:&nbsp;<a href=\"https://github.com/EdisonTalk/MAFD\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/EdisonTalk/MAFD</a></p>\n<h1>参考资料</h1>\n<p><span><span>圣杰，《<a href=\"https://www.cnblogs.com/sheng-jie/p/19200934\" target=\"_blank\">.NET + AI 智能体开发进阶</a>》（推荐指数：★★★★★）</span></span></p>\n<p><span><span>Microsoft Learn，<span>《<a href=\"https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview?wt.mc_id=MVP_397012\" rel=\"noopener nofollow\" target=\"_blank\">Agent Framework Tutorials</a>》</span></span></span></p>\n<div><span><span>&nbsp;</span></span></div>\n<p style=\"text-align: center;\"><img alt=\"\" src=\"https://images.cnblogs.com/cnblogs_com/edisonchou/1647700/o_200902144330EdisonTalk-Footer.jpg\" /></p>\n<div id=\"Copyright\">\n<p>作者：<span style=\"text-decoration: underline;\">爱迪生</span></p>\n<p>出处：<a href=\"https://edisontalk.cnblogs.com\" target=\"_blank\" title=\"from\">https://edisontalk.cnblogs.com</a></p>\n<p>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接。</p>\n\n</div>\n\n</div>\n<div id=\"MySignature\">\n    <div align=\"center\"><a href=\"https://weibo.com/u/2068032061?s=6uyXnP\" target=\"_blank\"><img border=\"0\" src=\"http://service.t.sina.com.cn/widget/qmd/2068032061/d643d182/10.png\" /></a></div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 08:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/edisontalk\">EdisonZhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">14</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "PHP 应用遭遇 DDoS 攻击时会发生什么 从入门到进阶的防护指南",
      "link": "https://www.cnblogs.com/catchadmin/p/19593334",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/catchadmin/p/19593334\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 07:58\">\n    <span>PHP 应用遭遇 DDoS 攻击时会发生什么 从入门到进阶的防护指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"php-应用遭遇-ddos-攻击时会发生什么-从入门到进阶的防护指南\">PHP 应用遭遇 DDoS 攻击时会发生什么 从入门到进阶的防护指南</h1>\n<h2 id=\"暴风雨前的宁静\">暴风雨前的宁静</h2>\n<p>想象一下，黑色星期五或者某个大促活动。你用 PHP 搭建的电商平台正在迎接前所未有的流量，订单源源不断，用户热情高涨，PHP 应用拼尽全力在扛。然后——啪——网站突然崩了。</p>\n<p>你查日志，到底怎么了？流量确实飙了，但这次不是因为用户太多，而是一次 DDoS（分布式拒绝服务）攻击。</p>\n<p>DDoS 攻击就像一场人造洪水，用大量伪造的请求把你的服务器淹掉。但具体到一个 PHP 应用，被打的时候到底发生了什么？怎么判断自己是不是正在被攻击？更重要的是——怎么防？</p>\n<p>这篇文章会带你搞清楚 PHP 应用遭遇 DDoS 时的全过程：从识别攻击到保护你的应用不被打趴。</p>\n<h2 id=\"什么是-ddos-攻击\">什么是 DDoS 攻击</h2>\n<p>DDoS 攻击有点像互联网上的交通堵塞。想象你要进一家热门店铺，结果突然冒出成百上千个\"假顾客\"堵在门口，真正的顾客根本挤不进去。店铺（你的 PHP 应用）被挤爆了，最终只能关门。</p>\n<p>用技术语言说，DDoS 攻击是攻击者（或僵尸网络）向目标网站发送海量流量，耗尽其资源。目的很简单：让网站变慢或者直接打瘫。</p>\n<p>对 PHP 应用来说，攻击会冲击以下几个环节：</p>\n<ul>\n<li><strong>Web 服务器</strong>：PHP 需要处理每一个请求，短时间内涌入大量请求会耗尽服务器资源。</li>\n<li><strong>数据库</strong>：过多的查询会拖慢甚至打崩数据库。</li>\n<li><strong>带宽</strong>：流量太大会吃满网络带宽，导致整体性能下降。</li>\n</ul>\n<h2 id=\"ddos-攻击如何影响你的-php-应用\">DDoS 攻击如何影响你的 PHP 应用</h2>\n<p>PHP 应用被 DDoS 打中时，背后发生了这些事情：</p>\n<h3 id=\"web-服务器负载飙升\">Web 服务器负载飙升</h3>\n<p>用户发起请求后，Web 服务器（比如 Apache 或 Nginx）会运行 PHP 脚本、查数据库、返回动态内容。正常情况下这没什么问题，但当成千上万（甚至上百万）的请求同时涌入，服务器很快就扛不住了。</p>\n<ul>\n<li><strong>CPU 打满</strong>：PHP 需要处理每个请求，大量请求会让 CPU 使用率直接拉满。</li>\n<li><strong>内存吃紧</strong>：PHP 应用通常会在内存中保存会话数据或缓存，请求太多会导致内存耗尽，轻则变慢，重则崩溃。</li>\n</ul>\n<h3 id=\"数据库过载\">数据库过载</h3>\n<p>PHP 应用通常依赖数据库来获取和展示动态内容。一个典型的请求可能涉及查库存、处理登录、渲染页面等操作。DDoS 攻击时，每个请求都可能触发开销很大的数据库查询，结果就是：</p>\n<ul>\n<li><strong>数据库瓶颈</strong>：数据库扛不住这种量级的负载，查询开始变慢、超时甚至直接失败。</li>\n<li><strong>响应迟钝</strong>：数据库服务器变得无响应，内容分发被严重延迟。</li>\n</ul>\n<h3 id=\"带宽打满\">带宽打满</h3>\n<p>每个 DDoS 请求都会消耗带宽。当恶意流量大到一定程度，会把你的网络带宽全部吃掉，真实用户的请求根本进不来。</p>\n<ul>\n<li><strong>连接数上限</strong>：网络连接被打满后，正常用户访问你的网站要么极慢，要么完全打不开。</li>\n</ul>\n<h3 id=\"php-脚本超时\">PHP 脚本超时</h3>\n<p>PHP 脚本的执行时间是有上限的。服务器被大量请求淹没时，PHP 脚本可能来不及在规定时间内跑完，结果就是：</p>\n<ul>\n<li><strong>500 错误</strong>：服务器因资源耗尽无法处理请求。</li>\n<li><strong>连接超时</strong>：PHP 脚本执行时间过长，连接直接断掉。</li>\n</ul>\n<h2 id=\"如何判断你的-php-应用正在被-ddos\">如何判断你的 PHP 应用正在被 DDoS</h2>\n<p>及时识别 DDoS 攻击至关重要。以下是一些关键的技术指标：</p>\n<h3 id=\"流量突然飙升\">流量突然飙升</h3>\n<p>流量在短时间内暴涨——尤其来源异常（比如来自不常见的地区或 IP 段）——就要警惕了。可以查看服务器日志来排查异常流量模式。</p>\n<p>用 Apache 或 Nginx 日志检查是否有大量请求来自同一个 IP 或一批可疑地址：</p>\n<pre><code class=\"language-bash\"># Apache：检查访问日志中的 IP 请求频次\ncat /var/log/apache2/access.log | awk '{print $1}' | sort | uniq -c | sort -n\n</code></pre>\n<h3 id=\"性能下降和超时\">性能下降和超时</h3>\n<p>如果网站突然变慢或者频繁出现超时错误，可能就是 DDoS 在搞鬼。PHP 脚本处理不过来涌入的请求，开始报 500 错误或者超时。</p>\n<h3 id=\"资源占用异常\">资源占用异常</h3>\n<p>如果服务器的 CPU 和内存使用率突然飙高，说明 PHP 正在苦苦支撑。可以用 <code>htop</code> 或 <code>top</code> 实时监控资源使用情况：</p>\n<pre><code class=\"language-bash\"># 实时监控 CPU 和内存使用情况\ntop -d 1\n</code></pre>\n<p>如果 CPU 或内存长时间处于高位，就该进一步排查了。</p>\n<h2 id=\"php-应用的-ddos-防护策略\">PHP 应用的 DDoS 防护策略</h2>\n<p>完全杜绝 DDoS 攻击很难，但有不少手段可以大幅降低其影响。下面是一些保护 PHP 应用的实用方案。</p>\n<h3 id=\"限流第一道防线\">限流：第一道防线</h3>\n<p>限流就是限制每个用户在一段时间内能发起的请求数量。方法简单但很有效，能挡住大部分机器人和恶意请求。</p>\n<p><strong>用 Redis 实现限流</strong></p>\n<p>可以用 Redis 追踪每个用户的请求次数，超过阈值就拒绝：</p>\n<pre><code class=\"language-php\">$redis = new Redis();\n$redis-&gt;connect('localhost', 6379);\n$ip = $_SERVER['REMOTE_ADDR'];\n$key = \"request_count:{$ip}\";\n$limit = 100;  // Max requests per minute\n$window = 60;  // 1 minute time window\n$request_count = $redis-&gt;get($key);\nif ($request_count &amp;&amp; $request_count &gt;= $limit) {\n    // Too many requests, reject the user\n    header('HTTP/1.1 429 Too Many Requests');\n    exit('Rate limit exceeded');\n}\n$redis-&gt;incr($key);\n$redis-&gt;expire($key, $window);  // Reset the count after 1 minute\n</code></pre>\n<p>这个基础限流方案可以有效节流那些试图用大量请求淹没你服务器的用户或机器人。</p>\n<h3 id=\"cdn分流恶意流量\">CDN：分流恶意流量</h3>\n<p>CDN（内容分发网络）会缓存静态资源（图片、CSS、JavaScript），通过分布在全球的边缘节点提供服务。DDoS 攻击时，CDN 可以吸收大量流量，让你的 PHP 服务器专心处理动态请求（比如用户登录、订单处理）。</p>\n<p><strong>通过 CDN 分发静态资源</strong></p>\n<pre><code class=\"language-html\">&lt;!-- 通过 CDN 提供静态资源 --&gt;\n&lt;link rel=\"stylesheet\" href=\"https://cdn.yoursite.com/styles.css\"&gt;\n&lt;script src=\"https://cdn.yoursite.com/app.js\"&gt;&lt;/script&gt;\n&lt;img src=\"https://cdn.yoursite.com/images/product.jpg\" alt=\"Product\"&gt;\n</code></pre>\n<p>把静态资源交给 CDN，既能减轻 PHP 应用的负载，也能让 DDoS 流量更难直接打到你的应用核心。</p>\n<h3 id=\"waf应用层防护\">WAF：应用层防护</h3>\n<p>WAF（Web 应用防火墙）是一种高级工具，专门检查和过滤发往 PHP 应用的 HTTP 流量。WAF 可以根据预设规则检测并拦截恶意请求，比如封禁可疑 IP 或屏蔽特定地区的流量。</p>\n<p><strong>以 AWS WAF 为例</strong></p>\n<ol>\n<li>创建 Web ACL（访问控制列表），定义流量过滤规则。</li>\n<li>添加规则来拦截 HTTP 洪水攻击、SQL 注入、IP 信誉过滤等。</li>\n</ol>\n<pre><code class=\"language-bash\">aws wafv2 create-web-acl --name \"MyWAF\" --scope \"REGIONAL\" --default-action \"ALLOW\" --rules ...\n</code></pre>\n<p>配置完成后，PHP 应用就有了一层专门的防护，恶意流量会被拦截，正常用户不受影响。</p>\n<h3 id=\"借助第三方-ddos-防护服务\">借助第三方 DDoS 防护服务</h3>\n<p>Cloudflare、AWS Shield 这类服务是专业做 DDoS 防护的。它们提供的高级防护能自动过滤恶意流量，保证你的 PHP 应用持续在线。</p>\n<p>接入方式很简单：</p>\n<ol>\n<li>注册 Cloudflare 或 AWS Shield。</li>\n<li>把域名的流量路由到它们的服务。</li>\n<li>它们会自动检测并拦截 DDoS 流量。</li>\n</ol>\n<p>通过第三方服务，绝大部分攻击流量在到达你的 PHP 应用之前就已经被挡掉了。</p>\n<h3 id=\"实时监控和日志记录\">实时监控和日志记录</h3>\n<p>持续监控流量和服务器性能有助于实时发现 DDoS 攻击。Datadog、New Relic、AWS CloudWatch 这类工具可以帮你捕捉异常流量、性能下降等问题。</p>\n<p><strong>记录可疑 IP</strong></p>\n<pre><code class=\"language-php\">// Example: Log suspicious IPs for later analysis\n$suspicious_ip = $_SERVER['REMOTE_ADDR'];\n$log_file = '/path/to/your/log/file.log';\nfile_put_contents($log_file, \"Suspicious IP: {$suspicious_ip}\\n\", FILE_APPEND);\n// Optionally, block IP if it exceeds request limit\nif ($request_count &gt; $limit) {\n    // Block the IP\n    $blocked_ips[] = $suspicious_ip;\n}\n</code></pre>\n<p>通过记录可疑活动，你可以事后封禁恶意用户，也能不断优化自己的防护策略。</p>\n<h2 id=\"总结\">总结</h2>\n<p>DDoS 攻击听起来可怕，但只要用对工具和策略，你完全可以保护好自己的 PHP 应用。从限流、CDN，到 WAF 和第三方防护服务，可选的方案并不少。</p>\n<p>别慌——主动防御比被动应对强得多。今天就把这些防线搭起来，等攻击真来的时候你才不会手忙脚乱。持续监控、实时告警、遵循最佳实践，即使面对 DDoS，你的 PHP 应用照样能稳稳地跑着。<br />\n<a href=\"https://catchadmin.com/post/2026-02/php-application-ddos-guide\" rel=\"noopener nofollow\" target=\"_blank\">PHP 应用遭遇 DDoS 攻击时会发生什么：从入门到进阶的防护指南</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 07:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/catchadmin\">JaguarJack</a>&nbsp;\n阅读(<span id=\"post_view_count\">39</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Concept Bottleneck Models-概念瓶颈模型用于可解释决策：进展、分类体系 与未来方向综述",
      "link": "https://www.cnblogs.com/lemonzhang/p/19592426",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lemonzhang/p/19592426\" id=\"cb_post_title_url\" title=\"发布于 2026-02-08 19:27\">\n    <span>Concept Bottleneck Models-概念瓶颈模型用于可解释决策：进展、分类体系 与未来方向综述</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        深度神经网络虽然表现出优异的性能，但其不透明性限制了其在需要透明度和人工监管的高风险领域中的应用。概念瓶颈模型(Concept Bottleneck Models, CBMs)通过引入一个人类可理解的概念层来连接输入与决策，从而解决了这一差距，实现了语义解释和测试时干预。本综述从四个维度提供了一个统一的CBMs概览：概念获取、基于概念的决策制定、概念干预和概念评估。我们总结了概念构建的演变过程，从人工标注到基于词典的挖掘、大语言模型(LLM)/视觉语言模型(VLM）引导的生成，以及通过原型和扩散模型实现的视觉关联发现；回顾了超越严格瓶颈的新兴CBM架构；并整合了强调忠实度、稀疏性和可干预性的评估与干预协议，这些对医疗保健等高风险领域尤为重要。我们综合了零散的文献，并勾勒了基于概念的可解释决策面临的关键挑战和未来方向。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><span style=\"font-size: 16px;\">深度神经网络虽然表现出优异的性能，但其不透明性限制了其在需要透明度和人工监管的高风险领域中的应用。概念瓶颈模型(Concept Bottleneck Models, CBMs)通过引入一个人类可理解的概念层来连接输入与决策，从而解决了这一差距，实现了语义解释和测试时干预。本综述从四个维度提供了一个统一的CBMs概览：概念获取、基于概念的决策制定、概念干预和概念评估。我们总结了概念构建的演变过程，从人工标注到基于词典的挖掘、大语言模型(LLM)/视觉语言模型(VLM）引导的生成，以及通过原型和扩散模型实现的视觉关联发现；回顾了超越严格瓶颈的新兴CBM架构；并整合了强调忠实度、稀疏性和可干预性的评估与干预协议，这些对医疗保健等高风险领域尤为重要。我们综合了零散的文献，并勾勒了基于概念的可解释决策面临的关键挑战和未来方向。</span></p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:bash;gutter:true;\">@article{Wang2026CBMSurvey,\n  title   = {Concept Bottleneck Models for Explainable Decision Making: A Survey of Progress, Taxonomy, and Future Directions},\n  author  = {Wang, Chunjiang and Li, Fan and Hu, Wenbo and Yan, Rui and Zhang, Kun and Zhou, Shaohua Kevin},\n  journal = {ResearchGate Preprint},\n  year    = {2026},\n  doi     = {10.13140/RG.2.2.30356.16002},\n  url     = {https://www.researchgate.net/publication/399898851_Concept_Bottleneck_Models_for_Explainable_Decision_Making_A_Survey_of_Progress_Taxonomy_and_Future_Directions}\n}\n</pre>\n</div>\n<p>&nbsp;This blog is from kkzhang at <a href=\"https://www.cnblogs.com/lemonzhang/p/19592426\" target=\"_blank\">https://www.cnblogs.com/lemonzhang/p/19592426</a>.</p>\n<h1><span lang=\"EN-US\">1 </span><span>引言</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>深度神经网络在视觉、语言和多模态学习方面取得了强大的性能，使其在医疗保健</span><sup><span lang=\"EN-US\">[1]</span></sup><span>、医学</span><sup><span lang=\"EN-US\">[2]</span></sup><span>和金融</span><sup><span lang=\"EN-US\">[3]</span></sup><span>等现实世界中得到广泛采用。然而，它们的决策过程往往是不透明的，这在需要信任、问责制和人类监督的高风险环境中造成了风险</span><sup><span lang=\"EN-US\">[4]</span></sup><span>。这种性能与可解释性之间的差距推动了可解释</span><span lang=\"EN-US\">AI (XAI)</span><span>的发展，旨在使模型的推理过程对人类而言是可理解、可验证和可修正的。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念瓶颈模型</span><span lang=\"EN-US\">(CBMs)</span><span>已成为解决这一挑战的一个原则性且有影响力的范式</span><sup><span lang=\"EN-US\">[5]</span></sup><span>。</span><span lang=\"EN-US\">CBMs</span><span>不是直接将输入映射到输出，而是通过在输入和决策之间引入一个人类可理解的中间概念层，显式地对预测过程进行因式分解。这种结构化的分解实现了语义解释，便于专家检查中间推理过程，并通过概念修正支持测试时干预。这些特性将</span><span lang=\"EN-US\">CBMs</span><span>与事后解释技术</span><sup><span lang=\"EN-US\">[6]</span></sup><span>区分开来，并将其定位为可解释和可控决策的统一框架。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>早期的概念瓶颈模型依赖于手动定义和标注的概念（例如视觉属性或临床发现）来提供透明的中间接口，但受到标注成本、覆盖范围不全和标签噪声的限制</span><sup><span lang=\"EN-US\">[5]</span></sup><span>。最近的进展可以组织为基于概念推理的四个阶段：概念获取正从人工策展转向可扩展的词典挖掘、</span><span lang=\"EN-US\">LLM/VLM</span><span>引导的生成，以及通过原型或扩散模型实现的视觉接地发现，这些都得益于大规模基础模型</span><sup><span lang=\"EN-US\">[7, 8, 9]</span></sup><span>；基于概念的决策正从严格的瓶颈向软性、混合、概率和基于能量的设计演变，这些设计在保留概念接口的同时提高了预测能力</span><sup><span lang=\"EN-US\">[10, 11, 12, 13]</span></sup><span>；概念干预越来越多地支持结构化和感知依赖关系的修正，以便通过概念层更好地传播人类反馈</span><sup><span lang=\"EN-US\">[14, 15]</span></sup><span>；概念评估正从准确性扩展到以可解释性为中心的指标（例如忠实度、干预下的一致性、对噪声或缺失概念的鲁棒性），但在视觉接地、语义稳定性和与人类推理对齐方面仍面临挑战</span><sup><span lang=\"EN-US\">[8]</span></sup><span>。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>尽管进展迅速，但</span><span lang=\"EN-US\">CBM</span><span>文献仍然是碎片化的。现有的综述</span><sup><span lang=\"EN-US\">[16]</span></sup><span>和评论通常侧重于属性学习、基于原型的解释或一般的可解释性方法，但它们并未捕捉到</span><span lang=\"EN-US\">CBMs</span><span>作为涵盖概念获取、决策架构、干预机制和评估协议的综合框架的更广泛演变。特别是，</span><span lang=\"EN-US\">CBMs</span><span>与基础模型、可编辑学习和多模态交互的近期融合尚未得到系统性的综合。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>本综述的主要贡献总结如下：</span><span lang=\"EN-US\"> (1) </span><span>提出了涵盖概念获取、决策、干预和评估的</span><span lang=\"EN-US\">CBMs</span><span>统一分类法。</span><span lang=\"EN-US\"> (2) </span><span>系统回顾了概念构建方法，从人工标注到</span><span lang=\"EN-US\">LLM</span><span>引导和基于原型的发现。</span><span lang=\"EN-US\"> (3) </span><span>综合了具有不同瓶颈设计和可编辑程度的新兴</span><span lang=\"EN-US\">CBM</span><span>架构。</span><span lang=\"EN-US\"> (4) </span><span>整合了评估协议和基准，重点关注忠实度、稀疏性、可干预性和医学应用。</span><span>我们在</span><span lang=\"EN-US\"><a href=\"https://github.com/kkzhang95/Awesome_Concept_Bottleneck_Models\" rel=\"noopener nofollow\"><span>Awesome Concept Bottleneck Models</span></a></span><span>维护了一个包含代表性</span><span lang=\"EN-US\">CBM</span><span>论文、代码和基准的更新仓库，以支持复现和社区使用。</span></p>\n<h1><span lang=\"EN-US\">2 </span><span>预备知识</span></h1>\n<h2><span lang=\"EN-US\">2.1 </span><span>概念瓶颈模型</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念瓶颈模型</span><span lang=\"EN-US\">(CBMs)<sup>[5]</sup></span><span>是一类可解释的神经架构，通过称为概念的人类可理解的中间变量，显式地将预测分解为两个阶段。形式上，</span><span lang=\"EN-US\">CBM</span><span>将从输入$x \\in \\mathcal{X}$</span><span>到目标$y \\in \\mathcal{Y}$</span><span>的映射因式分解为：</span><span lang=\"EN-US\"></span></p>\n<p>\\begin{equation}<br />\tx \\;\\rightarrow\\; c \\;\\rightarrow\\; y,<br />\\end{equation}&nbsp;<span>其中$c = (c_1, \\ldots, c_K) \\in \\mathcal{C}^K$</span><span>表示一组可解释的概念，如视觉属性、解剖结构、病理发现或语义描述。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>一个典型的</span><span lang=\"EN-US\">CBM</span><span>由两个组件组成：概念预测器$f_{\\theta}: \\mathcal{X} \\rightarrow \\mathcal{C}^K$</span><span>，它将原始输入映射到概念激活；以及任务预测器$g_{\\phi}: \\mathcal{C}^K \\rightarrow \\mathcal{Y}$</span><span>，它仅基于预测的概念产生最终预测。整体模型可以写为：</span></p>\n<p>\\begin{equation}<br />\t\\hat{y} = g_{\\phi}(f_{\\theta}(x)).<br />\\end{equation}</p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>这种结构实现了</span><span lang=\"EN-US\">CBMs</span><span>的两个决定性能力：</span><span lang=\"EN-US\">(i) </span><span>语义可解释性，因为每个概念维度都与人类可识别的属性对齐；</span><span lang=\"EN-US\">(ii) </span><span>可干预性，因为用户可以在测试时检查或修改</span><span>以纠正推理错误。这些特性激发了本综述稍后讨论的一系列架构变体，包括放宽严格瓶颈约束、结合概念间结构化依赖关系或利用多模态基础模型等外部知识的模型。</span></p>\n<p><img alt=\"image\" class=\"lazyload\" style=\"display: block; margin-left: auto; margin-right: auto;\" />&nbsp;</p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 150%; text-align: center;\"><span>图</span><span lang=\"EN-US\">1 CBM</span><span>流程概览。该图展示了概念是如何被获取、整合至决策制定、进行干预以及评估，从而生成可解释预测的。</span></p>\n<h2><span lang=\"EN-US\">2.2 </span><span>分类法</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>图</span><span lang=\"EN-US\">1</span><span>展示了概念瓶颈模型的四部分分类法，而表</span><span lang=\"EN-US\">1</span><span>总结了这些维度上的代表性方法。我们区分了四个主要维度：</span><span lang=\"EN-US\">(1) </span><span>概念获取，关注如何构建人类可解释的概念，范围从专家标注到自动发现和语言诱导的词汇表；</span><span lang=\"EN-US\">(2) </span><span>基于概念的决策，指定概念层如何中介预测，包括严格瓶颈以及松弛或混合设计；</span><span lang=\"EN-US\">(3) </span><span>概念干预，研究人类或外部系统如何在推理时与概念交互以纠正或指导推理；</span><span lang=\"EN-US\">(4) </span><span>概念评估，评估以可解释性为导向的属性，如忠实度、稀疏性和干预下的鲁棒性。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>重要的是，越来越多的工作跨越了这些维度，例如在一个架构中联合集成概念获取、决策和干预。因此，我们依次回顾每个维度并强调代表性方法。</span></p>\n<p><img alt=\"image\" class=\"lazyload\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p style=\"text-align: center;\"><span>表</span><span lang=\"EN-US\">1 </span><span>涵盖概念获取、决策、干预和评估的</span><span lang=\"EN-US\">CBM</span><span>方法的统一分类体系。概念来源：人工标注</span><span lang=\"EN-US\">(manual)</span><span>、词典</span><span lang=\"EN-US\">(dict.)</span><span>、视觉原型</span><span lang=\"EN-US\">(proto.)</span><span>、大型语言模型</span><span lang=\"EN-US\">(LLM)</span><span>；概念空间粒度</span><span lang=\"EN-US\">(Gran.)</span><span>：概念与视觉证据对齐的空间层级：全局</span><span lang=\"EN-US\">(global)</span><span>、局部</span><span lang=\"EN-US\">(local)</span><span>或两者；概念监督</span><span lang=\"EN-US\">(Sup.)</span><span>：强</span><span lang=\"EN-US\">(strong)</span><span>、弱</span><span lang=\"EN-US\">(weak)</span><span>、无监督</span><span lang=\"EN-US\">(unsup.)</span><span>；概念瓶颈层</span><span lang=\"EN-US\">(Bottleneck)</span><span>：</span><span>硬</span><span lang=\"EN-US\">(hard)</span><span>、软</span><span lang=\"EN-US\">(soft)</span><span>、混合</span><span lang=\"EN-US\">(hybrid)</span><span>；概念相关性建模</span><span lang=\"EN-US\">(corr.)</span><span>：独立</span><span lang=\"EN-US\">(indep.)</span><span>、联合</span><span lang=\"EN-US\">(joint)</span><span>、图</span><span lang=\"EN-US\">(graph)</span><span>、层级</span><span lang=\"EN-US\">(hier.)</span><span>、因果</span><span lang=\"EN-US\">(causal)</span><span>；干预机制：数值调整</span><span lang=\"EN-US\">(scalar)</span><span>、参数化</span><span lang=\"EN-US\">(param.)</span><span>、掩码</span><span lang=\"EN-US\">/</span><span>注意力编辑</span><span lang=\"EN-US\">(spatial)</span><span>、自然语言对话</span><span lang=\"EN-US\">(lang.)</span><span>；干预策略：随机</span><span lang=\"EN-US\">/</span><span>人工选择</span><span lang=\"EN-US\">(vanilla)</span><span>、模型驱动建议</span><span lang=\"EN-US\">(active)</span><span>、修正传播</span><span lang=\"EN-US\">(prop.)</span><span>；代码：</span><span lang=\"EN-US\">Link</span><span>（链接）、</span><span lang=\"EN-US\">– (</span><span>未发布</span><span lang=\"EN-US\">)</span><span>。</span></p>\n<h1><span lang=\"EN-US\">3 </span><span>概念获取</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念构建是概念瓶颈模型的基础，定义了输入和预测之间的人类可解释接口。概念构建已经从完全的人工标注演变为基于词典的挖掘、</span><span lang=\"EN-US\">LLM/VLM</span><span>引导的生成和视觉原型发现。总体趋势是在提高概念质量、可扩展性和视觉接地的同时减少人工监督。本节回顾四种代表性范式及其核心机制。</span></p>\n<h2><span lang=\"EN-US\">3.1 </span><span>基于人工标注的概念</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>人工标注通过依赖专家定义和显式标记的概念（如视觉属性或临床发现）提供了最强的语义接地。这种范式确保了高可解释性以及与领域知识的清晰对齐，但从根本上受到标注成本、不完全的概念覆盖和标签噪声的限制。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>该范式最近的工作侧重于在不完美监督下提高鲁棒性和灵活性。一个研究方向是通过修改训练目标来解决噪声或缺失标注的问题，例如</span><span lang=\"EN-US\">CPO<sup>[17]</sup></span><span>，它引入基于偏好的优化来联合稳定概念预测和下游性能。一个互补的方向是对标注概念间的依赖关系进行建模，以减轻泄漏和表达能力的限制。</span><span lang=\"EN-US\">Havasi</span><span>等人</span><sup><span lang=\"EN-US\">[18]</span></sup><span>用潜在侧信道变量增强了人工标注的概念，并采用自回归预测器来捕捉概念间的结构。为了支持实际部署，</span><span lang=\"EN-US\">Editable CBMs<sup>[19]</sup></span><span>支持使用基于影响函数的更新对概念定义和数据集标签进行事后修正，而无需完全重新训练。尽管有这些进展，人工标注仍然难以扩展到复杂领域，且其对预定义概念集的依赖限制了对不断变化任务的适应性。</span></p>\n<h2><span lang=\"EN-US\">3.2 </span><span>基于词典的概念构建</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>基于词典的方法用从预定义词汇表（如形容词列表或医学描述符）中的可扩展发现取代了特定任务的人工定义。通过将概念空间限制为语言上有意义的单元，与全自动生成相比，这些方法提供了更好的可控性和透明度。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>代表性方法侧重于从大型词库中过滤出视觉接地的概念。</span><span lang=\"EN-US\">V2C-CBM<sup>[20]</sup></span><span>构建了一个</span><span lang=\"EN-US\">n-gram</span><span>候选池，并使用基于</span><span lang=\"EN-US\">CLIP</span><span>的视觉</span><span lang=\"EN-US\">-</span><span>语言相似度来移除与视觉无关或接地较弱的条目，产生紧凑且可解释的概念集。</span><span lang=\"EN-US\">OpenCBM<sup>[9]</sup></span><span>进一步将可训练的视觉特征与</span><span lang=\"EN-US\">CLIP</span><span>嵌入对齐，并引入了发现缺失概念的机制，从而提高了超出初始词典的覆盖范围。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>虽然基于词典的构建降低了标注成本并限制了幻觉风险，但其表达能力仍然受到预定义词汇表的限制，可能无法捕捉细粒度或特定任务的语义。</span></p>\n<h2><span lang=\"EN-US\">3.3 </span><span lang=\"EN-US\">LLM/VLM</span><span>引导的概念生成</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span lang=\"EN-US\">LLM</span><span>和</span><span lang=\"EN-US\">VLM</span><span>引导的概念生成通过利用大型语言模型产生多样化、高层次且通常是分层的语义，大幅扩展了概念空间。这种范式提供了强大的可扩展性和灵活性，但也引入了与幻觉、弱视觉接地和语义不稳定性相关的新挑战。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>最近的工作通过结构、对齐和统计正则化来解决这些问题。</span><span lang=\"EN-US\">Med-MICN<sup>[21]</sup></span><span>将概念组织成多层级结构，并采用门控机制来控制抽象程度。视觉</span><span lang=\"EN-US\">-</span><span>语言一致性约束</span><sup><span lang=\"EN-US\">[22, 23, 24]</span></sup><span>和提示级对齐策略</span><sup><span lang=\"EN-US\">[25]</span></sup><span>进一步提高了接地的可靠性。从监督角度来看，</span><span lang=\"EN-US\">Label-free CBMs</span><span>和</span><span lang=\"EN-US\">FCBM<sup>[26, 27]</sup></span><span>证明，只要施加了强大的视觉正则化，通过将</span><span lang=\"EN-US\">LLM</span><span>与</span><span lang=\"EN-US\">CLIP</span><span>结合，可以在没有显式标注的情况下诱导出可用概念。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>总体而言，</span><span lang=\"EN-US\">LLM/VLM</span><span>引导的概念获取显著降低了人类监督要求，但其可解释性最终取决于语言先验的可靠性和接地约束的有效性。</span></p>\n<h2><span lang=\"EN-US\">3.4 </span><span>基于视觉原型的概念发现</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>基于视觉原型的方法通过提取代表性区域、部件或解缠组件，直接从图像空间学习概念，产生强大的视觉接地和空间定位。这种范式对于医学成像和其他形态学证据对决策至关重要的领域特别有吸引力。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>基于原型的发现面临固有的挑战，包括不稳定的语义命名、显著性驱动的虚假相关性以及原型粒度与覆盖范围之间的权衡。最近的工作探索了几种设计模式来减轻这些限制。面向解缠的方法，如</span><span lang=\"EN-US\">HU-MCD</span><span>、</span><span lang=\"EN-US\">LCBM<sup>[28, 29]</sup></span><span>，学习多维概念因子以减少语义未指明性。面向部署的方法</span><sup><span lang=\"EN-US\">[30, 31]</span></sup><span>专注于从预训练模型中提取原型词典以实现事后可解释性。面向交互的设计</span><sup><span lang=\"EN-US\">[32, 33]</span></sup><span>显式地将原型与空间区域关联，支持区域级的检查和干预。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>尽管接地保真度有所提高，但在数据集之间实现视觉原型的稳定语义对齐和可扩展重用仍然是一个开放的挑战。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>总结。</span></strong><span lang=\"EN-US\"> CBMs</span><span>中的概念获取涵盖了从专家定义的语义到自动发现的范围，反映了语义精度、监督成本和鲁棒性之间的权衡，并激发了整合语言和视觉线索的混合设计。</span></p>\n<h1><span lang=\"EN-US\">4 </span><span>基于概念的决策</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念瓶颈模型</span><span lang=\"EN-US\">(CBMs)</span><span>通过可解释概念层中介预测来提高可解释性，使验证和干预成为可能。除了概念构建，</span><span lang=\"EN-US\">CBM</span><span>架构也在不断演变以增强灵活性和可部署性。本节回顾三个关键方向：瓶颈设计、概念监督和模型适应，强调了从硬性流程向自适应、与人类对齐的决策转变。</span></p>\n<h2><span lang=\"EN-US\">4.1 </span><span>瓶颈设计</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span lang=\"EN-US\">CBMs</span><span>的一项核心创新在于概念瓶颈如何通过中介输入和输出之间的信息流来管理决策过程。早期的设计强制执行严格的流程，即所有预测信号必须通过离散的、可解释的概念层，从而最大化透明度和可干预性。然而，这种刚性结构往往限制了表示能力，并在不完美的概念监督下损害性能。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>为了解决这些限制，引入了软瓶颈</span><sup><span lang=\"EN-US\">[33, 34]</span></sup><span>，实现了连续的概念激活以及概念和任务预测器的联合优化。随后的变体通过残差通路</span><sup><span lang=\"EN-US\">[49]</span></sup><span>和结构化依赖关系放宽了严格瓶颈，包括自回归序列</span><sup><span lang=\"EN-US\">[15]</span></sup><span>、图先验</span><sup><span lang=\"EN-US\">[61, 52]</span></sup><span>和随机潜变量</span><sup><span lang=\"EN-US\">[57]</span></sup><span>。</span><span lang=\"EN-US\">Energy-based CBMs<sup>[60]</sup></span><span>进一步在联合概率框架内统一了预测和干预。更近期的工作将更高层次的结构注入瓶颈，例如用于鲁棒干预的因果图</span><sup><span lang=\"EN-US\">[6]</span></sup><span>，用于减轻概念</span><span lang=\"EN-US\">-</span><span>标签失真的概念解耦</span><sup><span lang=\"EN-US\">[64]</span></sup><span>，以及用于在复杂设置中超越线性聚合的可微逻辑组合</span><sup><span lang=\"EN-US\">[58, 13]</span></sup><span>。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>这些进展共同反映了严格瓶颈向更具表达力和结构化架构的逐渐放松，使</span><span lang=\"EN-US\">CBMs</span><span>能够在复杂的现实环境中更好地平衡可解释性和预测能力，同时保留概念层作为解释和干预的对齐语义接口。</span></p>\n<h2><span lang=\"EN-US\">4.2 </span><span>概念监督</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念监督定义了</span><span lang=\"EN-US\">CBMs</span><span>的中间语义层是如何构建和接地的。虽然早期模型依赖于具有强领域语义的人工标注概念</span><sup><span lang=\"EN-US\">[5]</span></sup><span>，但这种监督通常成本高昂、稀疏或特定于领域。因此，最近的研究寻求可扩展到更广泛任务且同时保留语义可解释性的替代方案。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span lang=\"EN-US\">Post-hoc CBMs<sup>[44]</sup></span><span>通过在冻结的编码器之上学习概念预测器来绕过架构约束，无需重新训练即可恢复概念可解释性。基于探测的方法</span><sup><span lang=\"EN-US\">[45]</span></sup><span>和原型发现方法</span><sup><span lang=\"EN-US\">[32, 30]</span></sup><span>使用稀疏正则化或基于部件的分解从预训练特征中提取可解释单元。利用视觉</span><span lang=\"EN-US\">-</span><span>语言模型，基于</span><span lang=\"EN-US\">CLIP</span><span>的流程</span><sup><span lang=\"EN-US\">[46, 26, 47]</span></sup><span>将概念标签与文本提示对齐，实现开放词汇监督。</span><span lang=\"EN-US\">LLM</span><span>引导的策略</span><sup><span lang=\"EN-US\">[21, 22, 48, 49]</span></sup><span>更进一步，通过生成分层或特定任务的概念，尽管视觉接地和幻觉方面的挑战仍然存在。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>这些方法将概念监督从直接标注转变为基于对齐和提示的归纳，实现了可扩展和自适应的概念构建。这种演变保留了</span><span lang=\"EN-US\">CBMs</span><span>与人类对齐的语义，同时提高了跨任务和领域的灵活性。</span></p>\n<h2><span lang=\"EN-US\">4.3 </span><span>模型适应</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>为了使</span><span lang=\"EN-US\">CBMs</span><span>在现实世界和不断变化的环境中具有实用价值，它们必须支持动态适应。具有固定概念的静态流程在任务需求转变、新概念出现或需要用户修正时难以更新。因此，模型适应已成为可操作</span><span lang=\"EN-US\">CBMs</span><span>的一个关键前沿。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span lang=\"EN-US\">Editable CBMs<sup>[19]</sup></span><span>引入了基于影响函数的参数更新，允许对概念、实例或标签预测进行局部更改，而无需完全重新训练。这允许在保留模型整体结构的同时进行细粒度的修正和数据集更新。概率能量模型</span><sup><span lang=\"EN-US\">[13]</span></sup><span>通过将推理公式化为输入、概念和输出上的能量最小化来支持测试时修正。更具交互性的是，最近的方法如</span><span lang=\"EN-US\">Chat-CBM<sup>[50]</sup></span><span>和</span><span lang=\"EN-US\">SALF<sup>[51]</sup></span><span>扩展了模型接口以支持自然语言和基于空间区域的干预，使非技术用户也能进行适应。无需训练的测试时适应</span><sup><span lang=\"EN-US\">[52, 53]</span></sup><span>进一步使</span><span lang=\"EN-US\">CBMs</span><span>能够仅使用少量图像级标签处理概念级分布偏移，而无需重新训练或概念监督。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>这些进展标志着从静态可解释性向动态、人在回路决策的转变。适应性</span><span lang=\"EN-US\">CBMs</span><span>保留了其核心语义瓶颈，同时允许部署后编辑、修正和协作，扩展了其在现实世界高风险系统中的生存能力。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>总结。</span></strong><span lang=\"EN-US\"> CBMs</span><span>中的基于概念的决策已从严格的瓶颈管道演变为更灵活的架构，更好地平衡了可解释性和性能。瓶颈设计、监督和模型适应方面的进步将概念层定位为用于预测和干预的动态接口。</span></p>\n<h1><span lang=\"EN-US\">5 </span><span>概念干预</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念干预通过修正中间概念实现人类与</span><span lang=\"EN-US\">AI</span><span>的协作，将</span><span lang=\"EN-US\">CBMs</span><span>从被动的可解释模型转变为交互式系统。在</span><span lang=\"EN-US\">Koh</span><span>等人</span><sup><span lang=\"EN-US\">[5]</span></sup><span>的开创性工作中，干预被公式化为允许用户修改概念激活值的测试时编辑。虽然具有基础意义，但这种范式依赖于强独立性假设，产生高昂的人力成本，并支持有限的交互模式。</span></p>\n<h2><span lang=\"EN-US\">5.1 </span><span>概念相关性</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>早期的干预机制通常假设概念是独立的，这意味着修改一个概念不会影响其他概念。这种假设在现实世界设置中通常是不现实的，因为概念在复杂决策任务中实际上表现出很强的语义和统计依赖性。为了解决这一限制，相关性感知的干预方法显式地对概念间关系进行建模并据此传播修正。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span lang=\"EN-US\">Havasi</span><span>等人</span><sup><span lang=\"EN-US\">[18]</span></sup><span>提出了自回归概念预测器，允许对前概念的干预通过序列依赖建模影响后续预测。</span><span lang=\"EN-US\">Stochastic CBMs<sup>[39]</sup></span><span>通过将概念</span><span lang=\"EN-US\">Logits</span><span>建模为多元正态分布，进一步提高了效率，实现了通过学习到的协方差结构即时传播单个干预。</span><span lang=\"EN-US\">Energy-Based CBMs<sup>[13]</sup></span><span>采用输入、概念和输出上的联合能量公式，允许概念修正通过能量最小化进行传播。</span><span lang=\"EN-US\">Singhi</span><span>等人</span><sup><span lang=\"EN-US\">[38]</span></sup><span>引入了事后概念重对齐模块</span><span lang=\"EN-US\">(CIRM)</span><span>，根据学习到的统计相关性更新未干预的概念。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>虽然这些方法显著提高了干预的一致性和效率，但它们关键地依赖于学习到的相关性的质量。如果捕捉到虚假依赖关系，干预可能会传播错误而不是修正，这突显了一个重要的开放挑战。</span></p>\n<h2><span lang=\"EN-US\">5.2 </span><span>概念定位</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>确定干预哪些概念仍然是实际部署中的主要瓶颈，因为人工选择是劳动密集的且对认知具有高要求的。为了减轻这一负担，最近的工作已转向模型引导的定位策略，优先考虑高影响力的干预目标。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>一些方法将定位内化到训练或模型设计中。</span><span lang=\"EN-US\">Espinosa Zarlenga</span><span>等人</span><sup><span lang=\"EN-US\">[10]</span></sup><span>引入了感知干预的训练，在学习过程中模拟测试时干预，使模型能够推荐需要修正的概念。</span><span lang=\"EN-US\">Evidential CEM(evi-CEM)<sup>[54]</sup></span><span>将概念预测建模为</span><span lang=\"EN-US\">Beta</span><span>分布，利用认知不确定性指导对模糊概念的干预。其他方法依赖于事后分析或辅助结构。</span><span lang=\"EN-US\">Shin</span><span>等人</span><sup><span lang=\"EN-US\">[14]</span></sup><span>提出了基于不确定性的概念潜力</span><span lang=\"EN-US\">(UCP)</span><span>和概念预测损失</span><span lang=\"EN-US\">(LCP)</span><span>等指标来对干预优先级进行排序。</span><span lang=\"EN-US\">Shen</span><span>等人</span><sup><span lang=\"EN-US\">[55]</span></sup><span>进一步引入了</span><span lang=\"EN-US\">FIGS-BD</span><span>，将预测器蒸馏为贪婪求和树，以识别具有高贡献方差的概念组。</span></p>\n<h2><span lang=\"EN-US\">5.3 </span><span>概念交互</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>除了选择和修正概念值之外，最近的工作越来越多地探索更丰富的交互模式，这些模式对人类用户来说更直观</span><sup><span lang=\"EN-US\">[56]</span></sup><span>。</span><span lang=\"EN-US\">Chat-CBM<sup>[50]</sup></span><span>用大语言模型替换基于概念的预测器，允许用户通过自然语言对话进行干预。虽然这在实践中提高了可用性，但可能会削弱传统</span><span lang=\"EN-US\">CBMs</span><span>的严格可解释性保证。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>在视觉领域，</span><span lang=\"EN-US\">Concept-based Similarity Reasoning (CSR)<sup>[33]</sup></span><span>通过允许用户绘制边界框来引导模型注意力，实现了空间交互。然而，这种空间引导并没有显式地解耦不同概念间的干预。</span><span lang=\"EN-US\">Spatially-Aware and Label-Free (SALF) CBM<sup>[51]</sup></span><span>通过利用空间概念图解决了这一限制，使用户能够指定感兴趣的区域并选择性地调节该区域内单个概念的激活。除了判别模型，概念瓶颈生成模型将概念级交互扩展到</span><span lang=\"EN-US\">GANs</span><span>、</span><span lang=\"EN-US\">VAEs</span><span>和扩散模型，实现了生成的可解释引导和调试</span><sup><span lang=\"EN-US\">[57]</span></sup><span>。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>总结。</span></strong><span>概念干预将</span><span lang=\"EN-US\">CBMs</span><span>从静态解释模型转变为交互式的人在回路系统。通过建模概念相关性、实现干预目标的有效定位以及支持更丰富的交互模式，最近的进展提高了概念级修正的有效性和可用性。</span></p>\n<h1><span lang=\"EN-US\">6 </span><span>概念瓶颈模型的评估</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念瓶颈模型引入了可解释和可干预的中间概念，这要求评估协议超越下游任务性能。因此，现有的评估框架评估三个核心维度：概念忠实度、概念稀疏性和可干预性，从而捕捉语义有效性、认知易处理性和人在回路的可控性。</span></p>\n<h2><span lang=\"EN-US\">6.1 </span><span>概念忠实度</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念忠实度衡量学习到的瓶颈表示是否与人类可理解的语义对齐，这是实践中可靠解释和有效干预的前提。评估策略已从直接标签匹配演变为对内在结构和外部接地的更严格评估。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>标签对齐。</span></strong><span>一种常见的方法是使用标准指标（如准确率和</span><span lang=\"EN-US\">F1</span><span>分数）评估预测概念与真实标注之间的一致性。然而，在高维和稀疏概念空间中，这些指标可能由真负样本主导。为了减轻这种偏差，最近的工作强调使用</span><span lang=\"EN-US\">Jaccard</span><span>相似度</span><sup><span lang=\"EN-US\">[58]</span></sup><span>和概念存在度量</span><span lang=\"EN-US\">(CEM)<sup>[59]</sup></span><span>等指标进行主动概念评估，这些指标侧重于被正向激活的概念。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>内在表示质量。</span></strong><span>除了标签匹配外，有效的概念表示应具有连贯的拓扑结构和明显的可分离性。在基于嵌入的模型中，概念对齐分数</span><span lang=\"EN-US\">(CAS)<sup>[10]</sup></span><span>解决了的前者的评估，验证高维空间中的局部邻域是否保持语义同质性。作为补充，为了在基于标量的瓶颈中解决的后者的评估，</span><span lang=\"EN-US\">Gap<sup>[60, 61]</sup></span><span>通过测量正负激活分布之间的散度来评估潜在空间的可分性，从而量化表示的内在判别质量。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>语义和视觉接地。</span></strong><span>为了检测虚假相关性，进一步的评估将学习到的概念与外部语义或视觉参考对齐。语义接地指标，包括</span><span lang=\"EN-US\">CGIM<sup>[59]</sup></span><span>、</span><span lang=\"EN-US\">Similarity<sup> [36]</sup></span><span>和概念纯度</span><sup><span lang=\"EN-US\">[11]</span></sup><span>，评估与人类定义的重要性或与规范嵌入的一致性。视觉接地指标，如概念可信度分数</span><sup><span lang=\"EN-US\">[32]</span></sup><span>和</span><span lang=\"EN-US\">CLM<sup>[59]</sup></span><span>，量化概念激活与标注区域之间的空间对齐。虽然在实践中有效，但这些方法通常需要昂贵的标注；基于</span><span lang=\"EN-US\">VLM</span><span>的替代方案如概念</span><span lang=\"EN-US\">-</span><span>图像相关性</span><sup><span lang=\"EN-US\">[11]</span></sup><span>减少了监督，但引入了潜在的幻觉风险。</span></p>\n<h2><span lang=\"EN-US\">6.2 </span><span>概念稀疏性</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念稀疏性评估</span><span lang=\"EN-US\">CBMs</span><span>是否依赖于一组最小且认知上可管理的概念。过度密集的瓶颈破坏了可解释性并增加了信息泄漏的风险。稀疏度</span><sup><span lang=\"EN-US\">[58]</span></sup><span>和有效概念数</span><span lang=\"EN-US\">(NEC)<sup>[62]</sup></span><span>等指标量化了激活密度和推理复杂性。然而，稀疏性必须与任务性能联合考虑。为了捕捉这种权衡，概念利用效率</span><span lang=\"EN-US\">(CUE)<sup>[36]</sup></span><span>和概念高效准确率</span><span lang=\"EN-US\">(CEA)<sup>[63]</sup></span><span>等复合指标在预测准确率与概念使用之间进行平衡，其中</span><span lang=\"EN-US\">CEA</span><span>提供了一个有界的、文本不变的公式以进行稳健比较。</span></p>\n<h2><span lang=\"EN-US\">6.3 </span><span>可干预性</span></h2>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>可干预性反映了</span><span lang=\"EN-US\">CBMs</span><span>在推理时支持有效人类修正的能力。此类别的评估协议评估模型预测对概念级修正的响应能力以及干预策略的效率。测试时干预</span><span lang=\"EN-US\">(TTI)</span><span>曲线</span><sup><span lang=\"EN-US\">[5]</span></sup><span>及其曲线下面积变体</span><sup><span lang=\"EN-US\">[64]</span></sup><span>被广泛用于总结在增加干预预算下的性能增益。扩展这一分析，最近的工作检查了相关概念间的修正传播</span><sup><span lang=\"EN-US\">[39]</span></sup><span>，并通过经验用户时间</span><sup><span lang=\"EN-US\">[60]</span></sup><span>或理论复杂性</span><sup><span lang=\"EN-US\">[14, 65]</span></sup><span>显式地建模干预成本。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>总结。</span></strong><span>评估</span><span lang=\"EN-US\">CBMs</span><span>需要超越下游准确率的整体协议。概念忠实度确保语义有效性，概念稀疏性保持认知易处理性，可干预性量化人在回路修正的有效性和成本。这些维度共同构成了评估</span><span lang=\"EN-US\">CBMs</span><span>可解释性、可靠性和实用性的原则基础。</span></p>\n<h1><span lang=\"EN-US\">7 </span><span>基准</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>表</span><span lang=\"EN-US\">2</span><span>总结了用于评估一般和医疗领域概念瓶颈模型</span><span lang=\"EN-US\">(CBMs)</span><span>的代表性基准。这些数据集在概念标注来源、监督粒度和对概念级干预的支持方面存在显著差异，这反过来决定了</span><span lang=\"EN-US\">CBMs</span><span>的哪些方面（如忠实度、可扩展性或可干预性）可以得到可靠评估。与深度模型不同，</span><span lang=\"EN-US\">CBMs</span><span>依赖于基准设计来验证概念忠实度和干预有效性。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>一般领域数据集。</span></strong><span>一般领域基准在视觉和文本识别任务上评估</span><span lang=\"EN-US\">CBMs</span><span>，包括细粒度分类、零样本学习和</span><span lang=\"EN-US\">NLP</span><span>应用。一个关键区别在于概念监督。具有人工标注概念的数据集，如</span><span lang=\"EN-US\">CUB-200-2011</span><span>和</span><span lang=\"EN-US\">AWA2</span><span>，支持概念评估和测试时干预，使概念修正的因果分析成为可能。相比之下，依赖</span><span lang=\"EN-US\">LLM</span><span>或</span><span lang=\"EN-US\">VLM</span><span>生成概念的大规模基准评估可扩展性和开放词汇能力，但缺乏经过验证的真实值，因此无法支持基于干预的评估。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24.1pt; line-height: 20pt;\"><strong><span>医疗领域数据集。</span></strong><span>医疗基准强调临床上有意义的概念和安全关键的可解释性，使其特别适合评估概念忠实度和干预有效性。具有专家标注、有序或连续概念的数据集显式支持干预实验，并能够验证现实临床设置中人在回路的修正。依赖自动生成概念的大型医疗数据集提高了覆盖范围和可扩展性，但缺乏经过验证的概念标注通常限制了它们进行严格干预和因果分析的适用性。</span></p>\n<p><img alt=\"image\" class=\"lazyload\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></p>\n<p style=\"text-align: center;\">&nbsp;<span>表</span><span lang=\"EN-US\">2 </span><span>通用和医疗领域中评估概念瓶颈模型</span><span lang=\"EN-US\">(CBMs)</span><span>的代表性基准</span></p>\n<h1><span lang=\"EN-US\">8 </span><span>总结与未来方向</span></h1>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span>概念瓶颈模型通过将预测建立在人类可理解的概念之上，为可解释和可控的决策提供了一个原则性框架。本综述统一了涵盖概念获取、决策、干预和评估全流程的</span><span lang=\"EN-US\">CBM</span><span>研究，特别强调了高风险医疗应用。尽管取得了实质性进展，但仍存在若干基本挑战。</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: 24pt; line-height: 20pt;\"><span lang=\"EN-US\">CBMs</span><span>的未来研究方向包括：</span><strong><span lang=\"EN-US\">(1) </span></strong><strong><span>自适应概念获取。</span></strong><span>未来的</span><span lang=\"EN-US\">CBMs</span><span>应超越固定的瓶颈设计，转向自适应和结构化的概念表示，如分层、组合或稀疏激活的瓶颈。这种设计更好地反映了人类语义的多层次和任务依赖性质，同时提高了效率。</span><span> <strong><span lang=\"EN-US\">(2) </span></strong></span><strong><span>忠实可靠的概念。</span></strong><span>确保学习到的概念忠实地对应其预期语义仍然是一个核心挑战，特别是在弱监督下或概念源自</span><span lang=\"EN-US\">LLMs</span><span>或</span><span lang=\"EN-US\">VLMs</span><span>时。有前景的方向包括不确定性感知建模、减轻虚假相关性的因果表示学习，以及检测或纠正不稳定概念的机制。</span><span> <strong><span lang=\"EN-US\">(3) </span></strong></span><strong><span>结构化概念干预。</span></strong><span>除了直接的概念替换，未来的工作应探索结构化干预策略，考虑概念间的依赖关系并识别决策关键子集。支持部分或软干预对于减少工作量并在安全关键领域实现可扩展的专家在环部署至关重要。</span><span> <strong><span lang=\"EN-US\">(4) </span></strong></span><strong><span>鲁棒的概念评估。</span></strong><span>鲁棒评估对于可靠部署仍然是必要的。未来的研究应审查概念表示和干预效果如何在跨领域和偏移中泛化，以及基于概念的推理如何支持不确定性估计、分布外检测和感知干预的评估协议。</span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">&nbsp;</span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">&nbsp;</span></p>\n<h1 align=\"center\" style=\"text-align: center;\"><span>参考文献</span></h1>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[1] Andre Esteva, Alexandre Robicquet, et al. A guide to deep learning in healthcare. In Nat. Med., 2019. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[2] Berthine Nyunga Mpinda, Mehran Hosseinzadeh, et al. Towards multi-label concept bottleneck models in medical imaging: An exploratory survey. In Medical Imaging with Deep Learning-Validation Papers, 2026. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[3] Ahmet Murat Ozbayoglu, Mehmet Ugur Gudelek, et al. Deep learning for financial applications: A survey. In Appl. Soft Comput., 2020. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[4] Tim Miller. Explanation in artificial intelligence: Insights from the social sciences. In Artif. Intell, 2019.</span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[5] Pang Wei Koh, Thao Nguyen, et al. Concept bottleneck models. In ICML, 2020. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[6] Ramprasaath R Selvaraju, Michael Cogswell, et al. Grad-cam: Visual explanations from deep networks via gradient-based localization. In ICCV, 2017. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[7] Alec Radford, Jong Wook Kim, et al. Learning transferable visual models from natural language supervision. In ICML, 2021.</span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[8] Yue Yang, Artemis Panagopoulou, et al. Language in a bottle: Language model guided concept bottlenecks for interpretable image classification. In CVPR, 2023. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[9] Andong Tan, Fengtao Zhou, et al. Explain via any concept: Concept bottleneck model with open vocabulary concepts. In ECCV, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[10] Mateo Espinosa Zarlenga, Pietro Barbiero, et al. Concept embedding models: Beyond the accuracy-explainability trade-off. In NeurIPS, 2022. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[11] Yang Liu, Tianwei Zhang, et al. Hybrid concept bottleneck models. In CVPR, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[12] Eunji Kim, Dahuin Jung, et al. Probabilistic concept bottleneck models. In ICML, 2023. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[13] Xinyue Xu, Yi Qin, et al. Energy-based concept bottleneck models: Unifying prediction, concept intervention, and probabilistic interpretations. In ICLR. 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[14] Sungbin Shin, Yohan Jo, et al. A closer look at the intervention procedure of concept bottleneck models. In ICML, 2023. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[15] Sujin Jeon, Inwoo Hwang, et al. Locality-aware concept bottleneck model. In UniReps. 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[16] Junlin Hou, Sicen Liu, et al. Self-explainable ai for medical image analysis: A survey and new outlooks. In arXiv preprint arXiv:2410.02331, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[17] Emiliano Penaloza, Tianyue H Zhang, et al. Addressing concept mislabeling in concept bottleneck models through preference optimization. In ICML, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[18] Marton Havasi, Sonali Parbhoo, et al. Addressing leakage in concept bottleneck models. In NeurIPS, 2022. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[19] Lijie Hu, Chenyang Ren, et al. Editable concept bottleneck models. In ICML, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[20] Hangzhou He, Lei Zhu, et al. V2c-cbm: Building concept bottlenecks with vision-to-concept tokenizer. In AAAI, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[21] Lijie Hu, Songning Lai, et al. Towards multi-dimensional explanation alignment for medical classification. In NeurIPS, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[22] Songning Lai, Lijie Hu, et al. Faithful vision-language interpretation via concept bottleneck models. In ICLR, 2023. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[23] Sukrut Rao, Sweta Mahajan, et al. Discover-then-name: Task-agnostic concept bottlenecks via automated concept discovery. In ECCV, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[24] Simon Schrodi, Julian Schur, et al. Selective concept bottlenecks without predefined concepts. In TMLR, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[25] Yequan Bie, Luyang Luo, et al. Xcoop: Explainable prompt learning for computer-aided diagnosis via concept-guided context optimization. In MICCAI, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[26] Tuomas Oikarinen, Subhro Das, et al. Label-free concept bottleneck models. In ICLR. 2023. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[27] Xingbo Du, Qiantong Dou, et al. Flexible concept bottleneck model. In AAAI, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[28] Arne Grobrügge, Niklas Kühl, et al. Towards human-understandable multi-dimensional concept discovery. In CVPR, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[29] Sujin Jeon, Inwoo Hwang, et al. Locality-aware concept bottleneck model. In UniReps: 2nd Edition of the Workshop on Unifying Representations in Neural Models, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[30] Andong Tan, ZHOU Fengtao, et al. Post-hoc part-prototype networks. In ICML, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[31] Mohammad Amin Choukali, Mehdi Chehel Amirani, et al. Pseudo-class part prototype networks for interpretable breast cancer classification. In Sci. Rep, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[32] Qihan Huang, Jie Song, et al. On the concept trustworthiness in concept bottleneck models. In AAAI, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[33] Ta Duc Huy, Sen Kim Tran, et al. Interactive medical image analysis with concept-based similarity reasoning. In CVPR, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[34] Anita Mahinpei, Justin Clark, et al. Promises and pitfalls of black-box concept learning models. In arXiv preprint arXiv:2106.13314, 2021. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[35] Andrei Margeloiu, Matthew Ashman, et al. Do concept bottleneck models learn as intended? In ICLR Workshop on Responsible AI, 2021. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[36] Chenming Shang, Shiji Zhou, et al. Incremental residual concept bottleneck models. In CVPR. 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[37] Haotian Xu, Tsui-Wei Weng, et al. Graph concept bottleneck models. In arXiv preprint arXiv:2508.14255, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[38] Nishad Singhi, Jae Myung Kim, et al. Improving intervention efficacy via concept realignment in concept bottleneck models. In ECCV, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[39] Moritz Vandenhirtz, Sonia Laguna, et al. Stochastic concept bottleneck models. In NeurIPS, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[40] Giovanni De Felice, Arianna Casanova, et al. Causally reliable concept bottleneck models. In ICLR 2025 Workshop: XAI4Science: From Understanding Model Behavior to Discovering New Scientific Knowledge, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[41] Rui Zhang, Xingbo Du, et al. The decoupling concept bottleneck model. In TPAMI, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[42] Deepika SN Vemuri, Gautham Bellamkonda, et al. Logiccbms: Logic-enhanced concept-based learning. In WACV, 2026. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[43] Yibo Gao, Hangqi Zhou, et al. Learning concept-driven logical rules for interpretable and generalizable medical image classification. In MICCAI, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[44] Mert Yuksekgonul, Maggie Wang, et al. Post-hoc concept bottleneck models. In ICLR, 2023. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[45] Andrei Semenov, Vladimir Ivanov, et al. Sparse concept bottleneck models: Gumbel tricks in contrastive learning. In arXiv preprint arXiv:2404.03323, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[46] Rémi Kazmierczak, Eloïse Berthier, et al. Clip-qda: An explainable concept bottleneck model. In TMLR, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[47] Jiakai Lin, Jinchang Zhang, et al. Graph integrated multimodal concept bottleneck model. In arXiv preprint arXiv:2510.00701, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[48] Yunhe Gao, Difei Gu, et al. Aligning human knowledge with visual concepts towards explainable medical image classification. In MICCAI, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[49] Chunjiang Wang, Kun Zhang, et al. Mvp-cbm: Multi-layer visual preference-enhanced concept bottleneck model for explainable medical image classification. In IJCAI, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[50] Hangzhou He, Lei Zhu, et al. Chat-cbm: Towards interactive concept bottleneck models with frozen large language models. In arXiv preprint arXiv:2509.17522, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[51] Itay Benou and Tammy Riklin Raviv. Show and tell: Visually explainable deep neural nets via spatially-aware concept bottleneck models. In CVPR, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[52] Townim F Chowdhury, Vu Minh Hieu Phan, et al. Adacbm: An adaptive concept bottleneck model for explainable and accurate diagnosis. In MICCAI, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[53] Hangzhou He, Jiachen Tang, et al. Training-free test-time improvement for explainable medical image classification. In MICCAI, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[54] Yibo Gao, Zheyao Gao, et al. Evidential concept embedding models: Towards reliable concept explanations for skin disease diagnosis. In MICCAI, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[55] Matthew Shen, Aliyah R Hsu, et al. Adaptive test-time intervention for concept bottleneck models. In ICLR 2025 Workshop Building Trust, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[56] David Steinmann, Wolfgang Stammer, et al. Learning to intervene on concept bottlenecks. In ICML, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[57] Aya Abdelsalam Ismail, Julius Adebayo, et al. Concept bottleneck generative models. In ICLR, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[58] Konstantinos P Panousis, Dino Ienco, et al. Coarse-to-fine concept bottleneck models. In NeurIPS, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[59] Halil Ibrahim AYSEL, Xiaohao Cai, et al. Concept-based explainable artificial intelligence: Metrics and benchmarks. In Available at SSRN 5210908. 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[60] Nesta Midavaine, Gregory Hok Tjoan Go, et al. [re] on the reproducibility of post-hoc concept bottleneck models. In TMLR, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[61] Seonghwan Park, Jueun Mun, et al. An analysis of concept bottleneck models: Measuring, understanding, and mitigating the impact of noisy annotations. In NeurIPS, 2025. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[62] Divyansh Srivastava, Ge Yan, et al. Vlg-cbm: Training concept bottleneck models with vision-language guidance. In NeurIPS, 2024. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[63] Delong Zhao, Qiang Huang, et al. Partially shared concept bottleneck models. In AAAI, 2026. </span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[64] Mateo Espinosa Zarlenga, Katie Collins, et al. Learning to receive help: Intervention-aware concept embedding models. In NeurIPS, 2023.</span></p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">[65] Andrea Pugnana, Riccardo Massidda, et al. Deferring concept bottleneck models: Learning to defer interventions to inaccurate experts. In NeurIPS. 2025.</span></p>\n<p>&nbsp;</p>\n<p class=\"MsoNormal\" style=\"line-height: 20pt;\"><span lang=\"EN-US\">&nbsp;</span></p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-08 19:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lemonzhang\">kkzhang</a>&nbsp;\n阅读(<span id=\"post_view_count\">44</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "这世界就是个巨大的草台班子-你的飞牛nas中招了吗",
      "link": "https://www.cnblogs.com/bugshare/p/19591372",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/bugshare/p/19591372\" id=\"cb_post_title_url\" title=\"发布于 2026-02-08 12:50\">\n    <span>这世界就是个巨大的草台班子-你的飞牛nas中招了吗</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>本来我是真的不太想写这篇文章。<br />\n一方面，这事已经发酵挺久了，官方也算是出了修复版本；<br />\n另一方面——说句实话，写起来真的心疼：<br />\n我的照片、我的资料、我的备份，可能现在已经不仅属于我了...😭</p>\n<p>结果现在回头一想：<br />\n<strong>还是有必要把这次惨重的教训记录下吧，吃一堑,长一智。</strong>=</p>\n<p>最近，国产私有云系统 <strong>飞牛 NAS（fnOS）</strong> 被曝出存在<strong>严重安全漏洞</strong>。<br />\n不少用户反馈：</p>\n<ul>\n<li>设备出现异常访问</li>\n<li>数据存在被读取风险</li>\n<li>甚至还有人发现被植入了不明程序</li>\n</ul>\n<p>这已经不是“某个功能不好用”，<br />\n也不是“偶尔崩一下”的问题了。</p>\n<p><strong>这是一次实打实，直接冲着用户数据来的系统级安全事故。</strong></p>\n<p>更让人难受的是：<br />\n<strong>一开始，官方对这个漏洞的态度，并不重视。</strong><br />\n<img alt=\"feiniu.jpg\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"一飞牛-nas-为啥会翻这么大的车\">一、飞牛 NAS 为啥会翻这么大的车？</h1>\n<h2 id=\"1️⃣-先说背景nas-正在变成家庭服务器\">1️⃣ 先说背景：NAS 正在变成“家庭服务器”</h2>\n<p>飞牛私有云 <strong>fnOS</strong>，本质上是一套基于 Debian Linux 深度定制的 NAS 操作系统。<br />\n目标用户很明确：</p>\n<ul>\n<li>家庭用户</li>\n<li>小团队</li>\n<li>把闲置 PC / 服务器当私有云用的人</li>\n</ul>\n<p>文件存储、影视库、远程访问、应用中心……<br />\n<strong>该有的都有，而且不少人是直接暴露在公网用的。</strong></p>\n<p>说白了：</p>\n<blockquote>\n<p><strong>现在的 NAS，本质就是一台 7×24 小服务器。</strong></p>\n</blockquote>\n<p>但问题也在这。</p>\n<hr />\n<h2 id=\"2️⃣-真正的根因典型致命的路径穿越漏洞\">2️⃣ 真正的根因：典型致命的路径穿越漏洞</h2>\n<p>这次翻车的核心原因，其实一点都不花哨。</p>\n<p>问题出在 <strong>Web 管理服务对路径的处理上</strong>。</p>\n<p>说人话就是一句话：</p>\n<blockquote>\n<p><strong>后台没把 <code>../</code> 这种路径跳转给拦住。</strong></p>\n</blockquote>\n<p>结果就是——<br />\n攻击者可以构造特殊请求：</p>\n<ul>\n<li>绕过目录限制</li>\n<li>想读哪就读哪</li>\n<li>系统文件、配置文件，直接暴露</li>\n</ul>\n<p>这种漏洞在安全圈有个名字，叫：</p>\n<blockquote>\n<p><strong>Path Traversal（路径穿越）</strong></p>\n</blockquote>\n<p>它真正恐怖的地方在于：</p>\n<ul>\n<li>❌ 不用登录</li>\n<li>❌ 不要账号</li>\n<li>❌ 不用爆破</li>\n<li>❌ 不需要你点任何链接</li>\n</ul>\n<p><strong>只要你的 NAS 在公网，扫到就能打。</strong></p>\n<hr />\n<h1 id=\"二这个漏洞是怎么被利用的\">二、这个漏洞是怎么被利用的？</h1>\n<h2 id=\"-复现原理真的很低级但就这么致命\">🔍 复现原理（真的很“低级”，但就这么致命）</h2>\n<p>正常情况下，Web 只允许你访问类似这种资源：</p>\n<pre><code class=\"language-http\">/app-center-static/xxx/icon.png\n</code></pre>\n<p>但如果后端不校验路径，<br />\n攻击者就可以这么玩：</p>\n<pre><code class=\"language-http\">http://[ip]:[port]/app-center-static/serviceicon/myapp/%7B0%7D/?size=../../../../vol1/1000/a/\n</code></pre>\n<p><img alt=\"PixPin_2026-02-08_01-06-03.png\" class=\"lazyload\" /></p>\n<p>甚至直接读系统文件：</p>\n<pre><code class=\"language-http\">http://[ip]:[port]/app-center-static/serviceicon/myapp/%7B0%7D/?size=../../../../etc/passwd\n</code></pre>\n<p><img alt=\"PixPin_2026-02-08_01-00-52.png\" class=\"lazyload\" /></p>\n<p>效果是什么？</p>\n<blockquote>\n<p><strong>表面上是请求“应用图标”，<br />\n实际上读的是你 NAS 里的真实文件。</strong></p>\n</blockquote>\n<p>这不是黑科技，<br />\n这是<strong>基础路径权限没控制好。</strong></p>\n<hr />\n<h2 id=\"-更可怕的读文件只是开始\">🔗 更可怕的：读文件只是开始</h2>\n<p>很多人看到“只能读文件”，会下意识松一口气。</p>\n<p>但现实是：<br />\n<strong>路径穿越，几乎从来不是终点。</strong></p>\n<p>一旦能读到这些东西：</p>\n<ul>\n<li>系统配置</li>\n<li>用户信息</li>\n<li>Token / Key</li>\n<li>Web 服务路径</li>\n</ul>\n<p>接下来能干什么？</p>\n<ul>\n<li>认证绕过</li>\n<li>写入恶意文件</li>\n<li>执行命令</li>\n<li>长期控制设备</li>\n</ul>\n<p>这也正好对应了一些用户的真实反馈：</p>\n<blockquote>\n<p>CPU 被吃满<br />\n带宽异常<br />\nNAS 像“不是自己的了”</p>\n</blockquote>\n<hr />\n<h1 id=\"三这事对普通家用用户到底有多严重\">三、这事对“普通家用用户”到底有多严重？</h1>\n<p>我知道，肯定有人会想：</p>\n<blockquote>\n<p>“我就家里放个 NAS，又不是公司服务器。”</p>\n</blockquote>\n<p>但现实刚好相反。</p>\n<p><strong>NAS 里的数据，往往比服务器更私密。</strong></p>\n<h2 id=\"️-最直接的风险包括\">⚠️ 最直接的风险包括：</h2>\n<ul>\n<li>📂 照片、视频、文档被读走</li>\n<li>🔐 系统账号、配置泄露</li>\n<li>🪙 被偷偷塞挖矿、木马</li>\n<li>🌐 成为攻击别人的跳板</li>\n<li>❌ 系统被改，升级、恢复全翻车</li>\n</ul>\n<p>最可怕的一点是：</p>\n<blockquote>\n<p><strong>绝大多数用户，根本不知道自己有没有中招。</strong></p>\n</blockquote>\n<hr />\n<h1 id=\"四官方后来修了但问题真的结束了吗\">四、官方后来修了，但问题真的结束了吗？</h1>\n<h2 id=\"-客观说一句补丁是有的也确实修了\">✅ 客观说一句：补丁是有的，也确实修了</h2>\n<p>飞牛后来发布了多个版本更新，主要做了这些事：</p>\n<ul>\n<li>严格校验路径参数</li>\n<li>修复静态资源访问逻辑</li>\n<li>增加异常请求拦截</li>\n</ul>\n<p><strong>从纯技术角度讲，补丁是有效的。</strong></p>\n<hr />\n<h2 id=\"️-但真正的问题不只是有没有补丁\">⚠️ 但真正的问题，不只是“有没有补丁”</h2>\n<p>这次争议的核心，其实在这：</p>\n<ul>\n<li>漏洞曝光时，已经有大量设备裸奔在公网</li>\n<li>很多用户根本不知道 NAS 不该这么用</li>\n<li>安全风险提示不直观</li>\n<li>默认配置对新手并不友好</li>\n</ul>\n<p><strong>安全不是写完代码就结束了。</strong></p>\n<p><img alt=\"PixPin_2026-02-08_01-30-12.png\" class=\"lazyload\" /></p>\n<p><img alt=\"154902xzluhy0ttttsbeyg.png\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"五如果你在用飞牛现在请务必做这几件事\">五、如果你在用飞牛，现在请务必做这几件事</h1>\n<h2 id=\"-1️⃣-立刻确认有没有暴露在公网\">🛑 1️⃣ 立刻确认：有没有暴露在公网</h2>\n<p>自查这几项：</p>\n<ul>\n<li>端口映射</li>\n<li>官方中继</li>\n<li>管理后台公网可访问</li>\n</ul>\n<p><strong>只要有一个是：建议立刻关。</strong></p>\n<hr />\n<h2 id=\"-2️⃣-立刻升级到最新-fnos\">🔄 2️⃣ 立刻升级到最新 fnOS</h2>\n<p>别观望，别等等。</p>\n<blockquote>\n<p><strong>安全漏洞，从来不等人。</strong></p>\n</blockquote>\n<hr />\n<h2 id=\"-3️⃣-检查有没有不对劲\">🔍 3️⃣ 检查有没有“不对劲”</h2>\n<p>重点看：</p>\n<ul>\n<li>CPU / 内存是否异常</li>\n<li>有没有不认识的进程</li>\n<li>启动项有没有被动过</li>\n<li>Web 日志里有没有奇怪请求</li>\n</ul>\n<p>如果你已经开始不放心了：</p>\n<blockquote>\n<p><strong>备份 → 重装 → 再恢复<br />\n比任何“心理安慰”都管用。</strong></p>\n</blockquote>\n<hr />\n<h1 id=\"六比修漏洞更重要的以后-nas-应该怎么用\">六、比修漏洞更重要的：以后 NAS 应该怎么用</h1>\n<p>这次事，说到底不只是飞牛的问题。</p>\n<h2 id=\"-一个更安全的-nas-使用习惯\">✅ 一个更安全的 NAS 使用习惯</h2>\n<ul>\n<li>❌ 别把管理端口直接丢公网</li>\n<li>❌ SSH 不用就关</li>\n<li>✅ 用 VPN（WireGuard / Tailscale）</li>\n<li>✅ 管理和数据访问分开</li>\n<li>✅ 养成升级习惯</li>\n<li>✅ 多看看安全公告</li>\n</ul>\n<p>一句话送给所有 NAS 用户：</p>\n<blockquote>\n<p><strong>NAS 要按“服务器”的标准对待，<br />\n而不是当个路由器插件。</strong></p>\n</blockquote>\n<p><img alt=\"PixPin_2026-02-08_01-24-15.png\" class=\"lazyload\" /></p>\n<p><img alt=\"PixPin_2026-02-08_01-26-40.png\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"七最后说一句这不是终点而是一记警钟\">七、最后说一句：这不是终点，而是一记警钟</h1>\n<p>飞牛 NAS 的这次漏洞，并不罕见。</p>\n<p>真正值得警惕的是：</p>\n<ul>\n<li>私有云越来越复杂</li>\n<li>很多产品功能多样化上去了，安全设计却明显滞后</li>\n<li>用户被迫承担了本不该承担的安全成本</li>\n</ul>\n<p>希望这次之后：</p>\n<ul>\n<li>用户能对公网访问多一分警惕</li>\n<li>厂商能把安全当成第一优先级</li>\n<li>国产 NAS 生态，能少一点“草台班子”</li>\n</ul>\n<blockquote>\n<p><strong>数据一旦泄露，<br />\n是没有任何补丁能帮你修回来的。</strong></p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-08 12:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/bugshare\">BugShare</a>&nbsp;\n阅读(<span id=\"post_view_count\">406</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "C++ 内存避坑指南：如何用移动语义和智能指针解决“深拷贝”与“内存泄漏”",
      "link": "https://www.cnblogs.com/kaiux/p/19592912",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kaiux/p/19592912\" id=\"cb_post_title_url\" title=\"发布于 2026-02-08 22:51\">\n    <span>C++ 内存避坑指南：如何用移动语义和智能指针解决“深拷贝”与“内存泄漏”</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"C++ 内存避坑指南：如何用移动语义和智能指针解决“深拷贝”与“内存泄漏”\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208225153165-194422412.png\" />\n        本文深度剖析了 C++ 与 Java 在内存管理上的本质差异。从函数传参的“值语义”陷阱切入，详细阐述了 C++ 为何默认进行深拷贝及其性能代价。文章重点讲解了核心机制 RAII 如何替代 GC 实现确定的资源管理，通过图解“移动语义”与“右值引用”揭示了高性能零拷贝的奥秘，并系统介绍了 unique_ptr 等智能指针的最佳实践与循环引用避坑指南，帮助开发者重塑内存思维模型。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1-函数传参\">1. 函数传参</h2>\n<p>在 Java 中，当我们把一个「对象」传给函数时，其实不需要思考太多：传过去的是引用的拷贝，函数里修改的对象的内容也会反应到外面。</p>\n<p>但在 C++ 中情况可能不太一样，一般来说我们有三个选择：</p>\n<h3 id=\"11-值传递-pass-by-value默认的深拷贝\">1.1. 值传递 (Pass-by-Value)：默认的「深拷贝」</h3>\n<p>这是 C++ 和 Java 最大的直觉冲突点。<strong>在 C++ 中，如果没有任何修饰符，编译器会把整个对象完整地克隆一份。</strong> 我们看下面的例子：</p>\n<pre><code class=\"language-cpp\">#include &lt;vector&gt;\n#include &lt;iostream&gt;\n\n// 这里会触发 std::vector 的拷贝构造函数\nvoid modify(std::vector&lt;int&gt; v) { \n    v.push_back(999);\n    std::cout &lt;&lt; \"modify内vector的长度为: \" &lt;&lt; v.size() &lt;&lt; std::endl;\n    // 函数结束，局部变量 v 被销毁，999 也随之消失\n    // 外部的 list 毫发无损\n}\n\nint main() {\n    // 假设这是一个包含 100 万个元素的列表\n    std::vector&lt;int&gt; bigList(1000000, 1);\n    \n    // 调用时发生 Deep Copy，性能开销极大\n    modify(bigList); \n\n    std::cout &lt;&lt; \"main函数内vector的长度为: \" &lt;&lt; bigList.size() &lt;&lt; std::endl;\n\n    return 0;\n}\n\n</code></pre>\n<p>运行结果为：</p>\n<pre><code class=\"language-text\">modify内vector的长度为: 1000001\nmain函数内vector的长度为: 1000000\n</code></pre>\n<p>对比一下Java代码：</p>\n<pre><code class=\"language-java\">import java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\n\npublic class Main {\n\n    // Java 总是按值传递，但对于对象，传递的是“引用的值”\n    public static void modify(List&lt;Integer&gt; v) {\n        v.add(999);\n        System.out.println(\"modify内List的长度为: \" + v.size());\n    }\n\n    public static void main(String[] args) {\n        // 创建包含 100 万个元素的列表\n        List&lt;Integer&gt; bigList = new ArrayList&lt;&gt;(Collections.nCopies(1000000, 1));\n\n        // 这里传递的是引用，没有深拷贝，性能开销极小\n        modify(bigList);\n\n        // 注意：这里的长度会变成 1000001\n        System.out.println(\"main中List的长度为: \" + bigList.size());\n    }\n}\n</code></pre>\n<p>运行结果为：</p>\n<pre><code class=\"language-text\">modify内List的长度为: 1000001\nmain中List的长度为: 1000001\n</code></pre>\n<p>由此我们可以得出以下的结论：</p>\n<ul>\n<li><strong>Java</strong>：函数调用时传递的是引用值。Java 永远不会隐式地把整个堆上的大对象复制一遍。</li>\n<li><strong>C++</strong>：是“值语义”。函数里的 <code>v</code> 是 <code>bigList</code> 的完全独立副本。你在副本上做的任何修改，都不会影响本体。</li>\n</ul>\n<h3 id=\"12-c的引用传递-pass-by-reference\">1.2. C++的引用传递 (Pass-by-Reference)：<code>&amp;</code></h3>\n<p>为了既能修改外部对象，又避免昂贵的拷贝，C++ 提供了 <strong>引用（Reference）</strong>。</p>\n<p>在类型后面加一个 <code>&amp;</code>，变量就变成了外部对象的<strong>别名（Alias）</strong>。我们看下面的代码：</p>\n<pre><code class=\"language-cpp\">#include &lt;vector&gt;\n#include &lt;iostream&gt;\n\n// 引用传递\nvoid modify(std::vector&lt;int&gt;&amp; v) { \n    v.push_back(999);\n    // 直接操作内存中的同一份数据\n    std::cout &lt;&lt; \"modify内vector的长度为: \" &lt;&lt; v.size() &lt;&lt; std::endl;\n}\n\nint main() {\n\n    std::vector&lt;int&gt; bigList(1000000, 1);\n\n    modify(bigList); \n\n    std::cout &lt;&lt; \"main函数内vector的长度为: \" &lt;&lt; bigList.size() &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>\n<p>运行结果为：</p>\n<pre><code class=\"language-text\">modify内vector的长度为: 1000001\nmain函数内vector的长度为: 1000001\n</code></pre>\n<p><strong>特点</strong>：</p>\n<ol>\n<li><strong>零拷贝</strong>：无论 List 有多大，这里只传递一个绑定的关系（底层通常是指针实现）。</li>\n<li><strong>非空保证</strong>：引用<strong>必须</strong>绑定到一个存在的对象上，不存在 <code>null</code> 引用。这比 Java 安全。</li>\n<li><strong>语法透明</strong>：在函数内部，你不需要像指针那样解引用，像操作普通变量一样操作它即可。</li>\n</ol>\n<h3 id=\"13-指针传递-pass-by-pointer经典的地址传递-\">1.3. 指针传递 (Pass-by-Pointer)：经典的“地址”传递 <code>*</code></h3>\n<p>这其实是最接近 Java 底层实现的方式。如果需要传递大对象，或者对象可能是空的（<code>nullptr</code>），我们就传递它的<strong>内存地址</strong>。</p>\n<pre><code class=\"language-cpp\">#include &lt;vector&gt;\n#include &lt;iostream&gt;\n\n// 指针传递\nvoid modify(std::vector&lt;int&gt;* v) { \n    // 判断是否为空，防止 Crash\n    if (v != nullptr) {\n        // 语法变化：用 '-&gt;' 来访问成员\n        v-&gt;push_back(999); \n        std::cout &lt;&lt; \"modify内vector的长度为: \" &lt;&lt; v-&gt;size() &lt;&lt; std::endl;\n    }\n}\n\nint main() {\n\n    std::vector&lt;int&gt; bigList(1000000, 1);\n\n    // 调用变化：必须显式取出地址 (&amp;) 传进去\n    modify(&amp;bigList); \n\n    std::cout &lt;&lt; \"main函数内vector的长度为: \" &lt;&lt; bigList.size() &lt;&lt; std::endl;\n\n    return 0;\n}\n</code></pre>\n<p>运行结果为：</p>\n<pre><code class=\"language-text\">modify内vector的长度为: 1000001\nmain函数内vector的长度为: 1000001\n</code></pre>\n<ul>\n<li>\n<p><strong>对比 Java</strong>：Java 的引用其实就是“受限的指针”。</p>\n</li>\n<li>\n<p>Java: <code>modify(list)</code> 隐式传递了地址。</p>\n</li>\n<li>\n<p>C++: <code>modify(&amp;list)</code> 显式传递了地址。</p>\n</li>\n<li>\n<p><strong>使用场景</strong>：通常用于兼容 C 语言接口，或者当参数是“可选的”（可以传 <code>nullptr</code> 表示忽略）时。</p>\n</li>\n</ul>\n<h3 id=\"14-三种方式对比总结\">1.4. 三种方式对比总结</h3>\n<p><img alt=\"函数传参\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224333675-1791870738.jpg\" /></p>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th><strong>值传递 (T)</strong></th>\n<th><strong>引用传递 (T&amp;)</strong></th>\n<th><strong>指针传递 (T*)</strong></th>\n<th>Java (Object)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>内存行为</strong></td>\n<td><strong>深拷贝 (Deep Copy)</strong></td>\n<td><strong>零拷贝</strong> (别名)</td>\n<td><strong>零拷贝</strong> (传递地址)</td>\n<td>浅拷贝  (复制引用)</td>\n</tr>\n<tr>\n<td><strong>修改外部?</strong></td>\n<td>❌ 不能</td>\n<td>✅ 能</td>\n<td>✅ 能</td>\n<td>✅ 能</td>\n</tr>\n<tr>\n<td><strong>能否为 Null</strong></td>\n<td>❌ 不涉及</td>\n<td><strong>❌ 不能</strong> (必须绑定对象)</td>\n<td><strong>✅ 能</strong> (<code>nullptr</code>)</td>\n<td>✅ 能</td>\n</tr>\n<tr>\n<td><strong>语法复杂度</strong></td>\n<td>简单</td>\n<td>简单</td>\n<td>繁琐 (<code>*</code>, <code>&amp;</code>, <code>-&gt;</code>)</td>\n<td>简单</td>\n</tr>\n<tr>\n<td><strong>适用场景</strong></td>\n<td><code>int</code>, <code>bool</code> 等小类型</td>\n<td><strong>首选方案</strong> (非空对象)</td>\n<td>兼容 C</td>\n<td>默认行为</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"2-对象的生命周期从手动管理到-raii-与移动语义\">2. 对象的生命周期：从手动管理到 RAII 与移动语义</h2>\n<p>在第一章我们看到：C++ 默认的“值传递”会导致性能问题（深拷贝），而“指针传递”虽然快，但会导致所有权模糊。</p>\n<p>这一章我们深入探讨如何既解决<strong>安全问题</strong>（内存泄漏），又解决<strong>性能问题</strong>（拷贝开销）。</p>\n<h3 id=\"21-痛点裸指针带来的内存泄漏危机\">2.1. 痛点：裸指针带来的“内存泄漏”危机</h3>\n<p>当我们传递一个指针（或者从函数返回一个指针）时，编译器只负责传递地址。<strong>这就带来了一个灵魂拷问：谁负责 <code>delete</code> 这个对象？</strong></p>\n<p>看下面这个看似正常的例子：</p>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n\nclass Enemy {\npublic:\n    Enemy() { std::cout &lt;&lt; \"Enemy Created\" &lt;&lt; std::endl; }\n    ~Enemy() { std::cout &lt;&lt; \"Enemy Destroyed\" &lt;&lt; std::endl; }\n    void attack() { std::cout &lt;&lt; \"Enemy attacks!\" &lt;&lt; std::endl; }\n};\n\n// 工厂函数：在堆上创建一个对象，并返回指针\nEnemy* createEnemy() {\n    // 危险的源头：new 出来的内存，必须有人 delete\n    return new Enemy(); \n}\n\nvoid gameLogic() {\n    // 获取指针\n    Enemy* boss = createEnemy();\n    \n    boss-&gt;attack();\n\n    // 假设这里有一段复杂的逻辑\n    if (true) {\n        std::cout &lt;&lt; \"Player died, game over early.\" &lt;&lt; std::endl;\n        // 致命问题：函数直接返回了，但 boss 指向的内存没释放！\n        return; \n    }\n\n    // 只有代码走到这里，内存才会被释放\n    delete boss; \n}\n\n</code></pre>\n<p><strong>后果</strong>：只要你在 <code>delete</code> 之前写了一个 <code>return</code>，或者抛出了一个异常（Exception），这块内存就永远丢了。Java 程序员可能对此毫无感觉 （JVM有GC机制），但在长时间运行的C++服务器程序（如数据库）中，这会导致内存耗尽（OOM）并崩溃。</p>\n<p><img alt=\"内存泄露\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224359981-1634411041.jpg\" /></p>\n<h3 id=\"22-解决方案gc-vs-raii\">2.2. 解决方案：GC vs. RAII</h3>\n<p>为了解决这个问题，Java 和 C++ 是走了两条完全不同的路。</p>\n<h4 id=\"221-java-的做法垃圾回收-gc\">2.2.1. Java 的做法：垃圾回收 (GC)</h4>\n<p>Java 认为：<strong>程序员不应该操心内存释放，交给虚拟机（JVM）。</strong></p>\n<ul>\n<li><strong>机制</strong>：JVM 运行后台线程，定期扫描，发现没人引用的对象就回收。</li>\n<li><strong>代价</strong>：<strong>不确定性</strong>（你不知道它什么时候回收）和 <strong>STW (Stop The World)</strong>（GC 工作时可能会暂停程序）。</li>\n</ul>\n<h4 id=\"222-c-的做法raii-资源获取即初始化\">2.2.2. C++ 的做法：RAII (资源获取即初始化)</h4>\n<p>C++ 认为：<strong>性能和确定性第一。我不要后台线程，我要利用“栈”的特性来自动管理堆内存。</strong></p>\n<p>RAII (Resource Acquisition Is Initialization) 的核心原理是将堆内存绑定到栈对象上：</p>\n<ol>\n<li><strong>栈对象的铁律</strong>：栈对象（局部变量）一旦离开它的作用域（即大括号 <code>{}</code> 结束），编译器<strong>一定会</strong>自动调用它的<strong>析构函数（Destructor）</strong>。无论是因为正常执行完、还是中间 <code>return</code> 了、还是抛异常了，<strong>必死无疑</strong>。</li>\n<li><strong>RAII 的策略</strong>：</li>\n</ol>\n<ul>\n<li><strong>构造时</strong>：在构造函数里 <code>new</code> 内存。</li>\n<li><strong>析构时</strong>：在析构函数里 <code>delete</code> 内存。</li>\n</ul>\n<p>看下面的代码：我们写一个包装类 <code>EnemyWrapper</code>：</p>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n\nclass Enemy {\npublic:\n    Enemy() { std::cout &lt;&lt; \"Enemy Created\" &lt;&lt; std::endl; }\n    ~Enemy() { std::cout &lt;&lt; \"Enemy Destroyed\" &lt;&lt; std::endl; }\n    void attack() { std::cout &lt;&lt; \"Enemy attacks!\" &lt;&lt; std::endl; }\n};\n\n// 工厂函数：在堆上创建一个对象，并返回指针\nEnemy* createEnemy() {\n    // 危险的源头：new 出来的内存，必须有人 delete\n    return new Enemy(); \n}\n\nclass EnemyWrapper {\nprivate:\n    // 持有原始指针\n    Enemy* ptr;\npublic:\n    // 【构造函数】：获取资源\n    EnemyWrapper() {\n        ptr = new Enemy(); \n    }\n\n    // 【析构函数】：释放资源 (这是 RAII 的灵魂)\n    ~EnemyWrapper() {\n        if (ptr != nullptr) {\n            delete ptr; // 只要 Wrapper 被销毁，ptr 指向的内存必被释放\n            std::cout &lt;&lt; \"Wrapper triggered delete!\" &lt;&lt; std::endl;\n        }\n    }\n    \n    // 模拟指针操作\n    void attack() { ptr-&gt;attack(); }\n};\n\nvoid gameLogicSafe() {\n    // 这是一个栈对象\n    EnemyWrapper boss; \n    \n    boss.attack();\n\n    if (true) {\n        std::cout &lt;&lt; \"Game over early.\" &lt;&lt; std::endl;\n        // 即使这里 return，栈变量 boss 也会弹出\n        return;\n        // 编译器自动插入代码：call boss.~EnemyWrapper() -&gt; delete ptr\n    }\n}\n\nint main() {\n    gameLogicSafe();\n    return 0;\n}\n\n</code></pre>\n<p>运行结果：</p>\n<pre><code class=\"language-text\">Enemy Created\nEnemy attacks!\nGame over early.\nEnemy Destroyed\nWrapper triggered delete!\n</code></pre>\n<p><strong>结论</strong>：不管你怎么写逻辑，内存永远不会泄漏。</p>\n<p><img alt=\"RAIIvsJava\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224425979-1751909243.jpg\" /></p>\n<h3 id=\"23-raii-的新问题\">2.3. RAII 的新问题</h3>\n<p>现在 RAII 解决了内存泄漏问题。但是，当我们想把这个对象<strong>传递出去</strong>（比如从函数返回）时，就又有问题了：</p>\n<h4 id=\"231-方案-a直接传内部指针破坏封装回到解放前\">2.3.1. 方案 A：直接传内部指针（破坏封装，回到解放前）</h4>\n<p>如果把 RAII 对象里的指针拿出来传递，那就不再受 RAII 保护了。我们看下面的代码：</p>\n<pre><code class=\"language-cpp\">Enemy* getBoss() {\n    // 栈对象\n    EnemyWrapper wrapper; \n    // 极其危险！\n    return wrapper.ptr;   \n} // 函数结束 -&gt; wrapper 析构 -&gt; wrapper.ptr 被 delete\n\nvoid main() {\n    Enemy* p = getBoss(); \n    // 崩溃！p 指向的内存已经被 wrapper 删掉了（悬空指针）\n    p-&gt;attack(); \n}\n\n</code></pre>\n<p><strong>结论</strong>：绝对不能把 RAII 管理的裸指针泄露出去，否则 RAII 就白做了。</p>\n<h4 id=\"232-方案-b拷贝-raii-对象安全但极慢\">2.3.2. 方案 B：拷贝 RAII 对象（安全但极慢）</h4>\n<p>既然不能传裸指针，那我们只能传 <code>EnemyWrapper</code> 这个对象本身。在 C++11 之前，这意味着<strong>深拷贝</strong>。我们看下面的代码：</p>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n\n// 模拟一个“昂贵”的资源\nclass Enemy {\npublic:\n    Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 new 出来了 (耗时操作...)\" &lt;&lt; std::endl; }\n    ~Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 delete 掉了\" &lt;&lt; std::endl; }\n};\n\n// RAII 包装类\nclass EnemyWrapper {\nprivate:\n    Enemy* ptr;\n\npublic:\n    // 【构造函数】：获取资源\n    EnemyWrapper() {\n        std::cout &lt;&lt; \"[Wrapper] 普通构造\" &lt;&lt; std::endl;\n        ptr = new Enemy(); \n    }\n\n    // 【析构函数】：释放资源\n    ~EnemyWrapper() {\n        if (ptr != nullptr) {\n            delete ptr;\n            std::cout &lt;&lt; \"[Wrapper] 析构，释放资源\" &lt;&lt; std::endl;\n        }\n    }\n\n    // ==========================================\n    // 【拷贝构造函数】(Deep Copy) -&gt; 性能瓶颈在这里！\n    // ==========================================\n    // 当我们需要复制这个对象时（比如函数返回），必须调用这个函数\n    EnemyWrapper(const EnemyWrapper&amp; other) {\n        std::cout &lt;&lt; \"[Wrapper] ⚠️ 触发深拷贝！必须分配新内存...\" &lt;&lt; std::endl;\n        \n        // 笨重的深拷贝：\n        // A. 必须 new 一个新的 Enemy (不能共用指针，否则会 double free)\n        ptr = new Enemy(); \n        \n        // B. (如果有数据) 还要把 other.ptr 里的数据复制过来\n        // *ptr = *(other.ptr); \n    }\n};\n\n// 触发拷贝的函数\nEnemyWrapper createBoss() {\n    std::cout &lt;&lt; \"--- 进入函数 ---\" &lt;&lt; std::endl;\n    \n    // Step 1: temp 创建，new Enemy (地址 A)\n    EnemyWrapper temp; \n    \n    std::cout &lt;&lt; \"--- 准备返回 ---\" &lt;&lt; std::endl;\n    \n    // Step 2: return 时，因为要传值给外面，必须【拷贝】temp\n    // 这意味着：调用拷贝构造函数 -&gt; new Enemy (地址 B) -&gt; 复制数据\n    return temp; \n    \n    // Step 3: 函数结束，temp 离开作用域，delete A\n    // (结果：我们为了得到 B，申请了 A，复制给 B，然后删了 A。A 只是个中间商。)\n}\n\nint main() {\n    std::cout &lt;&lt; \"=== 演示开始 ===\" &lt;&lt; std::endl;\n    EnemyWrapper boss = createBoss();\n    std::cout &lt;&lt; \"=== 演示结束 ===\" &lt;&lt; std::endl;\n    return 0;\n}\n\n</code></pre>\n<p>注意，运行上面的代码需要关闭RVO（返回值优化），需要在编译命令上加<code>-fno-elide-constructors</code>参数，例如：<code>g++ example.cpp -fno-elide-constructors -o example</code>。</p>\n<p>所谓的RVO正现代 C++ 编译器最“聪明”的地方之一，本来按照 C++ 的语法规则：</p>\n<ol>\n<li><code>createBoss</code> 里创建 <code>temp</code>。</li>\n<li><code>return</code> 时，应该把 <code>temp</code> <strong>拷贝</strong> 给 <code>main</code> 里的 <code>boss</code>。</li>\n<li>销毁 <code>temp</code>。</li>\n</ol>\n<p>但是编译器觉得这样太蠢了，所以它<strong>“作弊”</strong>了：<br />\n它根本没有在 <code>createBoss</code> 里创建 <code>temp</code>，而是<strong>直接在 <code>main</code> 函数里 <code>boss</code> 的内存地址上</strong>执行了构造函数。<br />\n结果就是：<strong>0 次拷贝，0 次移动，直接构造。</strong></p>\n<p>虽然编译器能优化 <code>return</code>，但也存很多在编译器<strong>无法优化</strong>的场景（比如 <code>vector.push_back</code> 或者复杂的赋值）。</p>\n<p>上述例子禁用优化之后的运行结果为：</p>\n<pre><code class=\"language-text\">=== 演示开始 ===\n--- 进入函数 ---\n[Wrapper] 普通构造\n  [堆资源] Enemy 被 new 出来了 (耗时操作...)\n--- 准备返回 ---\n[Wrapper] ⚠️ 触发深拷贝！必须分配新内存...\n  [堆资源] Enemy 被 new 出来了 (耗时操作...)\n  [堆资源] Enemy 被 delete 掉了\n[Wrapper] 析构，释放资源\n=== 演示结束 ===\n  [堆资源] Enemy 被 delete 掉了\n[Wrapper] 析构，释放资源\n</code></pre>\n<p><strong>这里的痛点</strong>：<br />\n我们陷入了死循环：</p>\n<ul>\n<li>想<strong>快</strong>？用指针 -&gt; <strong>不安全</strong>（内存泄漏或悬空指针）。</li>\n<li>想<strong>安全</strong>？用 RAII -&gt; <strong>慢</strong>（必须深拷贝，因为不能让两个 RAII 对象同时拥有同一个指针，否则会 double free）。</li>\n</ul>\n<p><strong>我们需要一种机制：既能保留 RAII 的壳子（安全），又能像指针一样只传递地址（快）。</strong></p>\n<p><img alt=\"RAII的问题\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224449858-1537769784.jpg\" /></p>\n<h3 id=\"24-什么是右值-rvalue\">2.4. 什么是右值 (Rvalue)？</h3>\n<p>为了打破这个僵局，C++11 引入了 <strong>右值引用 (<code>&amp;&amp;</code>)</strong>。但首先，我们要搞清楚什么是“右值”。</p>\n<p>作为开发者，不需要背诵复杂的定义，只需要掌握一个<strong>黄金法则</strong>：</p>\n<blockquote>\n<p><strong>能对它取地址 (<code>&amp;</code>) 的，就是左值 (Lvalue)。</strong><br />\n<strong>不能对它取地址的，就是右值 (Rvalue)。</strong></p>\n</blockquote>\n<h4 id=\"241-谁是左值谁是右值\">2.4.1. 谁是左值？谁是右值？</h4>\n<p>我们通过几行简单的代码来分辨：</p>\n<pre><code class=\"language-cpp\">int a = 10; \n\n</code></pre>\n<ul>\n<li>\n<p><strong><code>a</code> 是左值</strong>：</p>\n</li>\n<li>\n<p><strong>为什么？</strong> 因为你可以写 <code>&amp;a</code>，能拿到它的内存地址。它在栈上有一个固定的家。</p>\n</li>\n<li>\n<p><strong>生命周期</strong>：持久，直到大括号 <code>}</code> 结束。</p>\n</li>\n<li>\n<p><strong><code>10</code> 是右值</strong>：</p>\n</li>\n<li>\n<p><strong>为什么？</strong> 它是字面量。你试着写 <code>int* p = &amp;10;</code>，编译器会直接报错。它没有地址，它只是代码里的一个数字。</p>\n</li>\n</ul>\n<h4 id=\"242-隐藏的右值临时对象\">2.4.2. 隐藏的右值（临时对象）</h4>\n<p>对于对象来说，右值往往是一个<strong>“无名无姓的幽灵对象”</strong>。这是最容易被忽视的场景。</p>\n<pre><code class=\"language-cpp\">EnemyWrapper getBoss() {\n    // 返回一个新创建的对象\n    return EnemyWrapper();\n}\n\nvoid main() {\n    EnemyWrapper boss = getBoss(); \n}\n\n</code></pre>\n<p><strong>问题：<code>getBoss()</code> 执行完的那一瞬间，发生了什么？</strong></p>\n<ol>\n<li>函数内部创建了一个 <code>EnemyWrapper</code> 对象。</li>\n<li>函数返回时，这个对象被扔了出来。</li>\n<li><strong>在它被赋值给变量 <code>boss</code> 之前，它漂浮在虚空中。</strong></li>\n</ol>\n<p>这个漂浮在虚空中的对象，就是 <strong>右值</strong>。</p>\n<ul>\n<li><strong>特征</strong>：它存在，占用了内存，但<strong>没有名字</strong>。</li>\n<li><strong>命运</strong>：<strong>它马上就要死了</strong>。一旦赋值语句结束，这个临时对象就会析构。</li>\n</ul>\n<h4 id=\"243-stdmove-到底做了什么\">2.4.3. <code>std::move()</code> 到底做了什么？</h4>\n<p>你经常会看到 <code>std::move(x)</code>。很多人误以为它会移动数据，其实它什么都没移动。它的作用只有一个：<strong>身份欺诈</strong>。</p>\n<pre><code class=\"language-cpp\">// a 是左值，活得好好的\nEnemyWrapper a; \n\n// 强行把 a 标记为右值\nEnemyWrapper b = std::move(a); \n\n</code></pre>\n<ul>\n<li><code>a</code> 本来是左值。</li>\n<li><code>std::move(a)</code> 相当于给 <code>a</code> 贴了个条子：“<strong>这辆车我不想要了，当废品处理</strong>”。</li>\n<li>于是，<code>a</code> 被强制转换成了 <strong>右值</strong>。</li>\n<li><code>b</code> 看到这个条子，就会认为 <code>a</code> 是个将死之物，从而直接“偷走”它的资源。</li>\n</ul>\n<p><img alt=\"什么是右值\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224512528-1563159360.jpg\" /></p>\n<h3 id=\"25-终极方案移动语义-move-semantics\">2.5. 终极方案：移动语义 (Move Semantics)</h3>\n<p>既然我们能识别出右值（将死之物），我们就可以利用这一点来优化 RAII。</p>\n<p>我们在 <code>EnemyWrapper</code> 里加一个特殊的构造函数——<strong>移动构造函数</strong>。它专门接收右值引用 (<code>&amp;&amp;</code>)。</p>\n<p><strong>移动的本质就是：合法的窃取。</strong></p>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n\n// 模拟一个“昂贵”的资源\nclass Enemy {\npublic:\n    Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 new 出来了 (耗时操作...)\" &lt;&lt; std::endl; }\n    ~Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 delete 掉了\" &lt;&lt; std::endl; }\n};\n\n// RAII 包装类\nclass EnemyWrapper {\nprivate:\n    Enemy* ptr;\n\npublic:\n    // 【构造函数】：获取资源\n    EnemyWrapper() {\n        std::cout &lt;&lt; \"[Wrapper] 普通构造\" &lt;&lt; std::endl;\n        ptr = new Enemy(); \n    }\n\n    // 【析构函数】：释放资源\n    ~EnemyWrapper() {\n        if (ptr != nullptr) {\n            delete ptr;\n            std::cout &lt;&lt; \"[Wrapper] 析构，释放资源\" &lt;&lt; std::endl;\n        }\n    }\n\n    // ==========================================\n    // 【拷贝构造函数】(Deep Copy) -&gt; 性能瓶颈在这里！\n    // ==========================================\n    // 当我们需要复制这个对象时（比如函数返回），必须调用这个函数\n    EnemyWrapper(const EnemyWrapper&amp; other) {\n        std::cout &lt;&lt; \"[Wrapper] ⚠️ 触发深拷贝！必须分配新内存...\" &lt;&lt; std::endl;\n        \n        // 笨重的深拷贝：\n        // A. 必须 new 一个新的 Enemy (不能共用指针，否则会 double free)\n        ptr = new Enemy(); \n        \n        // B. (如果有数据) 还要把 other.ptr 里的数据复制过来\n        // *ptr = *(other.ptr); \n    }\n\n    // 【移动构造】(Move) - C++11 的新方案\n    // 参数是 &amp;&amp;，表示对方是“将死之物”\n    EnemyWrapper(EnemyWrapper&amp;&amp; other) noexcept {\n        // 1. 偷梁换柱：把对方的指针拿过来\n        this-&gt;ptr = other.ptr;\n        \n        // 2. 毁灭证据：把对方的指针设为 nullptr\n        // 这一步至关重要！\n        // 当 other 析构时，它会 delete nullptr (什么也不做)\n        // 从而避免了资源被误删\n        other.ptr = nullptr; \n        \n        std::cout &lt;&lt; \"Move: Ownership transferred!\" &lt;&lt; std::endl;\n    }\n};\n\n// 触发移动构造函数\nEnemyWrapper createBoss() {\n    // 这一行代码做了两件事：\n    // 1. 在【栈】上分配了 EnemyWrapper 这个壳子的内存（非常快，不需要 new）\n    // 2. 自动调用了它的构造函数\n    EnemyWrapper temp; \n    // temp 是局部变量，返回时被视为右值\n    return temp; \n}\n\nint main() {\n    // 1. createBoss 返回临时对象（右值）\n    // 2. 触发【移动构造函数】\n    // 3. main 里的 boss 直接接管了 temp 里的指针\n    // 4. temp 变成空壳被销毁\n    EnemyWrapper boss = createBoss(); \n    \n    // 结果：\n    // - 没有发生 Deep Copy (省了 new/copy)\n    // - 没有传递裸指针 (全程都在 RAII 包装下，非常安全)\n}\n\n</code></pre>\n<p>运行结果：</p>\n<pre><code class=\"language-text\">[Wrapper] 普通构造\n  [堆资源] Enemy 被 new 出来了 (耗时操作...)\nMove: Ownership transferred!\n  [堆资源] Enemy 被 delete 掉了\n[Wrapper] 析构，释放资源\n</code></pre>\n<p>可以看到，现在没有深拷贝操作了。但看到这里，可能大家还有有几个问题：</p>\n<h4 id=\"251-问题-1为什么不能在拷贝构造函数中掠夺资源\">2.5.1 问题 1：为什么不能在拷贝构造函数中“掠夺”资源？</h4>\n<p>你可能会想：“能不能别搞什么移动构造函数了，直接改写拷贝构造函数，把 <code>const</code> 去掉，然后在里面偷指针？”</p>\n<p><strong>答案是：语法上行得通，但在逻辑上是“灾难”。</strong></p>\n<h5 id=\"2511-理由-a契约精神-语义混淆\">2.5.1.1. 理由 A：契约精神 (语义混淆)</h5>\n<p>在编程世界里，“<strong>拷贝 (Copy)</strong>”这个词是有明确定义的：<strong>制作副本，原件不受影响。</strong></p>\n<p>如果我写 <code>b = a;</code>，按照人类的直觉，<code>a</code> 应该还在那里，完好无损。<br />\n如果你在拷贝函数里搞“掠夺”，就会出现这种恐怖场景：</p>\n<pre><code class=\"language-cpp\">// 假设这是“魔改版”的拷贝构造函数 (没有 const)\nEnemyWrapper(EnemyWrapper&amp; other) {\n    this-&gt;ptr = other.ptr;\n    other.ptr = nullptr; // 偷偷把原件毁了！\n}\n\nvoid logicalDisaster() {\n    EnemyWrapper a; // a 有资源\n    \n    // 我只想做一个备份\n    EnemyWrapper b = a; \n    \n    // 灾难发生：a 变成空壳了！\n    // 后面的代码如果继续用 a，程序直接崩溃。\n    a.attack(); // Crash!\n}\n\n</code></pre>\n<p><strong>结论</strong>：如果拷贝会破坏原件，那就不能叫“拷贝”，那叫“抢劫”。程序员无法通过代码一眼看出 <code>b = a</code> 到底安全不安全。为了区分“复制”和“转移”，我们需要两个不同的函数。</p>\n<h5 id=\"2512-理由-b语法限制-const-correctness\">2.5.1.2. 理由 B：语法限制 (Const Correctness)</h5>\n<p>标准的拷贝构造函数签名是 <code>const EnemyWrapper&amp; other</code>。</p>\n<ul>\n<li>那个 <strong><code>const</code></strong> 是铁律。它向调用者保证：“你放心传给我，我绝不动你的一根毫毛”。</li>\n<li>因为有 <code>const</code>，编译器禁止你写 <code>other.ptr = nullptr;</code>。</li>\n<li>如果你强行去掉 <code>const</code>，它就无法接受临时对象（因为临时对象通常绑定到 const 引用），导致通用性大打折扣。</li>\n</ul>\n<h4 id=\"252-问题-2编译器是如何区分调用拷贝还是移动的\">2.5.2 问题 2：编译器是如何区分调用“拷贝”还是“移动”的？</h4>\n<p>这是一个非常精彩的<strong>“函数重载决议” (Overload Resolution)</strong> 过程。</p>\n<p>编译器并不是通过“猜”你的意图来决定的，它是通过<strong>参数类型匹配</strong>来决定的。</p>\n<h5 id=\"2521-两个函数的签名对比\">2.5.2.1. 两个函数的签名对比</h5>\n<ul>\n<li><strong>拷贝构造</strong>：<code>EnemyWrapper(const EnemyWrapper&amp;)</code> -&gt; 接收 <strong>左值</strong> (和右值，作为备胎)。</li>\n<li><strong>移动构造</strong>：<code>EnemyWrapper(EnemyWrapper&amp;&amp;)</code>      -&gt; 专门接收 <strong>右值</strong>。</li>\n</ul>\n<h5 id=\"2522-createboss-里的决策过程\">2.5.2.2. <code>createBoss</code> 里的决策过程</h5>\n<p>当你在 <code>return temp;</code> 时（假设 RVO 被禁用，必须发生传递）：</p>\n<ol>\n<li><strong>判定 <code>temp</code> 的状态</strong>：<br />\n虽然 <code>temp</code> 在函数里定义时是个左值，但<strong>因为它马上要被 return 了，即将销毁</strong>，C++ 编译器会自动把它视为 <strong>xvalue (将亡值)</strong>，也就是一种<strong>右值</strong>。</li>\n<li><strong>开始匹配构造函数</strong>：<br />\n编译器看着 <code>main</code> 函数里正在等待接收的 <code>boss</code> 对象，问：“我手里有一个<strong>右值</strong>，我该调用哪个构造函数来初始化 <code>boss</code>？”</li>\n</ol>\n<ul>\n<li><strong>选手 A (拷贝)</strong>：我要 <code>const &amp;</code>。可以接收右值吗？<strong>可以</strong>（const 引用能接万物），但只是“兼容”。</li>\n<li><strong>选手 B (移动)</strong>：我要 <code>&amp;&amp;</code>。可以接收右值吗？<strong>完美匹配！</strong></li>\n</ul>\n<ol start=\"3\">\n<li><strong>择优录取</strong>：<br />\n编译器发现选手 B 是<strong>精确匹配 (Exact Match)</strong>，所以毫不犹豫地选择了<strong>移动构造函数</strong>。</li>\n</ol>\n<h5 id=\"2523-只有拷贝构造函数时会怎样\">2.5.2.3. 只有拷贝构造函数时会怎样？</h5>\n<p>如果你没写移动构造函数（C++98 的情况）：</p>\n<ul>\n<li>编译器手里拿着右值，发现没有 <code>&amp;&amp;</code> 的构造函数。</li>\n<li>它会退而求其次，发现 <code>const &amp;</code>（拷贝构造）也能接收右值。</li>\n<li>于是含泪调用了拷贝构造函数（深拷贝）。</li>\n</ul>\n<h4 id=\"253-总结\">2.5.3. 总结</h4>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>传递给构造函数的参数</th>\n<th>优先匹配</th>\n<th>备选匹配</th>\n<th>结果</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>EnemyWrapper b = a;</code></td>\n<td><strong>左值</strong> (a 还要接着用)</td>\n<td><code>(const T&amp;)</code> 拷贝</td>\n<td>无</td>\n<td><strong>深拷贝</strong></td>\n</tr>\n<tr>\n<td><code>return temp;</code></td>\n<td><strong>右值</strong> (temp 马上死)</td>\n<td><code>(T&amp;&amp;)</code> 移动</td>\n<td><code>(const T&amp;)</code> 拷贝</td>\n<td><strong>移动 (偷)</strong></td>\n</tr>\n<tr>\n<td><code>b = std::move(a);</code></td>\n<td><strong>右值</strong> (强转的)</td>\n<td><code>(T&amp;&amp;)</code> 移动</td>\n<td><code>(const T&amp;)</code> 拷贝</td>\n<td><strong>移动 (偷)</strong></td>\n</tr>\n</tbody>\n</table>\n<p><strong>一句话总结：编译器看“参数类型”。如果是“将死之物（右值）”，优先匹配 <code>&amp;&amp;</code> 版（移动）；如果是“普通对象（左值）”，只能匹配 <code>const &amp;</code> 版（拷贝）。</strong></p>\n<p><img alt=\"移动语义\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224541966-1378007066.jpg\" /></p>\n<h3 id=\"26-避坑指南return-时千万别用-move\">2.6. 避坑指南：<code>return</code> 时千万别用 <code>move</code></h3>\n<p>那<strong>在 <code>createBoss</code> 函数里，需要写 <code>return std::move(temp);</code> 吗？</strong></p>\n<p><strong>答案是：不要！</strong></p>\n<pre><code class=\"language-cpp\">EnemyWrapper createBoss() {\n    EnemyWrapper temp; \n    \n    // 正确写法：编译器会自动优化 (RVO)\n    // 编译器会直接在外部变量的内存地址上构造 temp，连“移动”都不需要做！\n    // 成本 = 0\n    return temp; \n    \n    // 错误写法：画蛇添足\n    // return std::move(temp); \n    // 这会强行打断编译器的 RVO 优化，强制执行一次“移动构造”。\n    // 成本 &gt; 0 (虽然也很低，但是属于“负优化”)\n}\n\n</code></pre>\n<p><strong>那 <code>std::move</code> 到底用在哪里？</strong><br />\n用在你需要<strong>显式转移</strong>一个左值的所有权时：</p>\n<pre><code class=\"language-cpp\">int main() {\n    // 1. RVO 自动优化，这里没有拷贝，也没有移动\n    EnemyWrapper boss1 = createBoss(); \n\n    // 2. 假设你想把 boss1 转给 boss2\n    // EnemyWrapper boss2 = boss1; // 编译报错（假设禁用了拷贝）或深拷贝（慢）\n\n    // 3. 这里必须用 std::move！\n    // 因为 boss1 是个活着的左值，编译器不敢自动动它。\n    // 你必须手动签署“放弃所有权书”。\n    EnemyWrapper boss2 = std::move(boss1); \n\n    // 此刻：boss2 拿到了指针，boss1 变成了空壳。\n}\n\n</code></pre>\n<h3 id=\"27-移动语义的本质所有权转移-ownership-transfer\">2.7. 移动语义的本质：所有权转移 (Ownership Transfer)</h3>\n<p>很多从 Java/Python 转过来的开发者，在理解“移动”时容易陷入误区，认为数据真的在内存里“搬家”了。</p>\n<p><strong>移动语义的本质，并不是移动数据，而是“所有权的交接”。</strong></p>\n<h4 id=\"271-核心思想唯一责任制-sole-ownership\">2.7.1. 核心思想：唯一责任制 (Sole Ownership)</h4>\n<p>在 Java 中，对象的所有权是<strong>共享的</strong>（Shared）。</p>\n<ul>\n<li>你有一个 <code>List</code>，传给函数 A，传给函数 B，大家都拿着引用的副本。</li>\n<li>谁负责销毁它？谁都不负责。GC 负责。</li>\n<li>这种模式很省心，但在资源敏感（如文件句柄、网络连接、互斥锁）或高性能场景下，会导致资源释放的不可控。</li>\n</ul>\n<p>在现代 C++（RAII + Move）中，我们强调<strong>独占所有权</strong>（Exclusive Ownership）。</p>\n<ul>\n<li><strong>原则</strong>：对于某一块堆内存资源，在任何时刻，<strong>只能有一个</strong>对象对它负责。</li>\n<li><strong>推论</strong>：既然只有一个主人，那么当这个主人被销毁时，资源必须被销毁。</li>\n</ul>\n<h4 id=\"272-移动的物理动作浅拷贝--抹除原主-shallow-copy--nullify\">2.7.2. 移动的物理动作：浅拷贝 + 抹除原主 (Shallow Copy + Nullify)</h4>\n<p>既然资源只能有一个主人，那么当我们需要把资源传给别人时，就不能是“分享”（Copy），只能是“过户”（Move）。</p>\n<p><strong>移动语义在汇编层面的本质只有两步：</strong></p>\n<ol>\n<li><strong>窃取指针（Shallow Copy）</strong>：</li>\n</ol>\n<ul>\n<li>新主人（<code>dest</code>）把旧主人（<code>src</code>）手里的指针值（地址）复制过来。</li>\n<li><em>此刻，两个人都指向了同一个资源（危险状态！）。</em></li>\n</ul>\n<ol start=\"2\">\n<li><strong>抹除旧主（Nullify）</strong>：</li>\n</ol>\n<ul>\n<li><strong>最关键的一步</strong>：把旧主人（<code>src</code>）手里的指针设为 <code>nullptr</code>。</li>\n<li><em>结果，旧主人失去了对资源的控制权，变成了空壳。</em></li>\n</ul>\n<h4 id=\"273-现实世界的类比\">2.7.3. 现实世界的类比</h4>\n<p>为了理解“拷贝”和“移动”的区别，我们可以用 <strong>“房产证”</strong> 做比喻：</p>\n<ul>\n<li><strong>资源（Resource）</strong>：房子（不动产，很贵，搬不动）。</li>\n<li><strong>指针（Pointer）</strong>：房产证（一张纸，很轻）。</li>\n</ul>\n<p><strong>场景 A：深拷贝 (Deep Copy) —— C++98 的做法</strong></p>\n<ul>\n<li><strong>操作</strong>：你想把房子给你的儿子。</li>\n<li><strong>C++98</strong>：你必须在隔壁盖一栋<strong>一模一样</strong>的新房子（<code>new</code>），然后把新房子的房产证给儿子。</li>\n<li><strong>代价</strong>：极度浪费钱和时间。</li>\n</ul>\n<p><strong>场景 B：移动语义 (Move Semantics) —— C++11 的做法</strong></p>\n<ul>\n<li><strong>操作</strong>：你想把房子给你的儿子。</li>\n<li><strong>C++11</strong>：你把手里的<strong>房产证</strong>直接交给儿子，然后把你自己的名字从房管局注销。</li>\n<li><strong>代价</strong>：房子根本没动，只是<strong>持有人变了</strong>。</li>\n</ul>\n<h4 id=\"274-为什么说这是所有权的体现\">2.7.4. 为什么说这是“所有权”的体现？</h4>\n<p>回到我们之前的 <code>EnemyWrapper</code> 代码：</p>\n<pre><code class=\"language-cpp\">EnemyWrapper(EnemyWrapper&amp;&amp; other) noexcept {\n    // 1. 接过房产证\n    this-&gt;ptr = other.ptr; \n    \n    // 2. 原主注销，从此这房子和你无关了\n    other.ptr = nullptr; \n}\n\n</code></pre>\n<p>这里体现了 C++ 最硬核的契约精神：</p>\n<blockquote>\n<p><strong>\"我移动了你，你就不再拥有它。后续的清理工作由我负责，你只需安静地离开。\"</strong></p>\n</blockquote>\n<p>这解决了 C++ 长期以来的<strong>“双重释放” (Double Free)</strong> 问题：因为原主变成了 <code>nullptr</code>，它的析构函数 <code>delete nullptr</code> 不会产生任何副作用。</p>\n<h3 id=\"28-总结\">2.8. 总结</h3>\n<ol>\n<li><strong>裸指针</strong>：虽快，但无法保证内存一定会释放（容易泄漏）。</li>\n<li><strong>RAII</strong>：通过包装类保证了内存一定释放，但在 C++98 中，为了保证安全（防止多次释放），传递对象时必须进行<strong>深拷贝</strong>，导致性能低下。</li>\n<li><strong>右值 (Rvalue)</strong>：指那些没有名字、即将销毁的临时对象（不能取地址）。</li>\n<li><strong>移动语义 (Move)</strong>：是完美的折中方案。它允许 RAII 对象在“交接班”时，通过识别右值，直接把内部的指针所有权<strong>转移</strong>给对方，既保留了 RAII 的外壳（安全），又只传递了指针（高效）。</li>\n</ol>\n<h2 id=\"3-智能指针与-java-gc\">3. 智能指针与 Java GC</h2>\n<p>在前两章节中，我们已经掌握了 <strong>RAII（利用栈管理堆）</strong> 和 <strong>移动语义（所有权转移）</strong>。如果仔细观察，会发现我们手写的 <code>EnemyWrapper</code> 其实就是一个简陋的“智能指针”。</p>\n<p>C++ 标准库把这种模式标准化了，提供了三个现成的工具，统称为 <strong>智能指针 (Smart Pointers)</strong>。它们彻底终结了手动写 <code>delete</code> 的历史。</p>\n<h3 id=\"31-什么是智能指针\">3.1. 什么是智能指针？</h3>\n<p>智能指针不是指针，它是一个 <strong>C++ 类（Class）</strong>。</p>\n<ul>\n<li>它在栈上（像个普通变量）。</li>\n<li>它里面藏着一个裸指针（指向堆）。</li>\n<li>它利用 RAII，在析构函数里自动 <code>delete</code> 那个裸指针。</li>\n<li>它重载了 <code>*</code> 和 <code>-&gt;</code> 运算符，让你用起来感觉像个指针。</li>\n</ul>\n<p>C++ 提供了三种智能指针，分别对应三种<strong>所有权模式</strong>：</p>\n<ol>\n<li><strong><code>std::unique_ptr</code></strong>：你是我的唯一（独占所有权）。</li>\n<li><strong><code>std::shared_ptr</code></strong>：我们共享它（共享所有权）。</li>\n<li><strong><code>std::weak_ptr</code></strong>：我就静静地看着你（弱引用，不增加计数）。</li>\n</ol>\n<h3 id=\"32-stdunique_ptr-独占\">3.2. <code>std::unique_ptr</code> (独占)</h3>\n<p>这是 C++ 中<strong>最推荐、最常用</strong>的智能指针。90% 的场景都应该用它。</p>\n<h4 id=\"321-核心特性\">3.2.1. 核心特性</h4>\n<ul>\n<li><strong>独占性</strong>：同一时间，只能有一个 <code>unique_ptr</code> 指向那个对象。</li>\n<li><strong>不可拷贝</strong>：你不能复制它（否则会有两个主人，这就是我们之前手动禁用的拷贝构造）。</li>\n<li><strong>可移动</strong>：你可以把所有权移交给别人（利用移动语义）。</li>\n<li><strong>零开销</strong>：它的性能和裸指针<strong>完全一样</strong>。它只是多了一层编译期的检查，运行时没有任何额外负担。</li>\n</ul>\n<h4 id=\"322-代码示例\">3.2.2. 代码示例</h4>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;memory&gt; // 必须包含这个头文件\n\n// 模拟一个“昂贵”的资源\nclass Enemy {\npublic:\n    Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 new 出来了 (耗时操作...)\" &lt;&lt; std::endl; }\n    ~Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 delete 掉了\" &lt;&lt; std::endl; }\n    void attack() { std::cout &lt;&lt; \"Enemy attacks!\" &lt;&lt; std::endl; }\n};\n\n\nvoid uniqueDemo() {\n    // 1. 创建 (推荐用 make_unique，不要直接 new)\n    std::unique_ptr&lt;Enemy&gt; boss = std::make_unique&lt;Enemy&gt;(); \n    \n    boss-&gt;attack(); // 用起来像指针\n    \n    // 2. 禁止拷贝！\n    // std::unique_ptr&lt;Enemy&gt; boss2 = boss; // ❌ 编译报错！\n    \n    // 3. 可以移动！\n    // 这里的 move 就像我们在 Part 2 学的那样，把所有权转给 p2\n    std::unique_ptr&lt;Enemy&gt; boss2 = std::move(boss); \n    \n    // 此时：\n    // boss 变成了 nullptr (空)\n    // boss2 拥有了对象\n    \n} // 函数结束 -&gt; boss2 析构 -&gt; 自动 delete Enemy\n\nint main() {\n    uniqueDemo();\n    return 0;\n}\n\n</code></pre>\n<p>运行结果如下：</p>\n<pre><code class=\"language-text\">  [堆资源] Enemy 被 new 出来了 (耗时操作...)\nEnemy attacks!\n  [堆资源] Enemy 被 delete 掉了\n</code></pre>\n<p><img alt=\"uniq_ptr\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224619193-1813415551.jpg\" /></p>\n<h3 id=\"33-stdshared_ptr-共享\">3.3. <code>std::shared_ptr</code> (共享)</h3>\n<p>这货看起来最像 Java 的引用。它允许多个指针指向同一个对象。</p>\n<h4 id=\"331-核心特性\">3.3.1. 核心特性</h4>\n<ul>\n<li>\n<p><strong>引用计数 (Reference Counting)</strong>：它内部维护一个计数器。</p>\n</li>\n<li>\n<p>每多一个人指向它，计数 +1。</p>\n</li>\n<li>\n<p>每有一个人销毁或不再指向它，计数 -1。</p>\n</li>\n<li>\n<p><strong>当计数变成 0 时，自动 <code>delete</code> 对象。</strong></p>\n</li>\n<li>\n<p><strong>有开销</strong>：为了维护这个计数器（而且要保证多线程安全），它比 <code>unique_ptr</code> 慢一点点，内存也多一点（因为要存计数器）。</p>\n</li>\n</ul>\n<h4 id=\"332-代码示例\">3.3.2. 代码示例</h4>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;memory&gt; // 必须包含这个头文件\n\n// 模拟一个“昂贵”的资源\nclass Enemy {\npublic:\n    Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 new 出来了 (耗时操作...)\" &lt;&lt; std::endl; }\n    ~Enemy() { std::cout &lt;&lt; \"  [堆资源] Enemy 被 delete 掉了\" &lt;&lt; std::endl; }\n    void attack() { std::cout &lt;&lt; \"Enemy attacks!\" &lt;&lt; std::endl; }\n};\n\n\nvoid sharedDemo() {\n    // 1. 创建 (引用计数 = 1)\n    std::shared_ptr&lt;Enemy&gt; p1 = std::make_shared&lt;Enemy&gt;();\n    \n    {\n        // 2. 拷贝 (引用计数 = 2)\n        // 注意：这里是可以直接 \"=\" 赋值的，因为它是共享的\n        std::shared_ptr&lt;Enemy&gt; p2 = p1; \n        \n        p2-&gt;attack();\n        std::cout &lt;&lt; \"当前引用数: \" &lt;&lt; p1.use_count() &lt;&lt; std::endl; // 输出 2\n    } \n    // p2 离开作用域，引用计数 -1 (变回 1)。对象还活着！\n    \n    p1-&gt;attack(); \n    \n} // 函数结束，p1 离开，引用计数 -1 (变成 0) -&gt; delete Enemy\n\nint main() {\n    sharedDemo();\n    return 0;\n}\n</code></pre>\n<p>运行结果如下：</p>\n<pre><code class=\"language-text\">  [堆资源] Enemy 被 new 出来了 (耗时操作...)\nEnemy attacks!\n当前引用数: 2\nEnemy attacks!\n  [堆资源] Enemy 被 delete 掉了\n</code></pre>\n<h3 id=\"34-c-shared_ptr-vs-java-gc\">3.4. C++ shared_ptr vs Java GC</h3>\n<p>这是面试和架构设计中的核心考点。C++ 的 <code>shared_ptr</code> 和 Java 的引用看起来很像，但底层逻辑完全不同。</p>\n<h4 id=\"341-机制对比引用计数-vs-可达性分析\">3.4.1. 机制对比：引用计数 vs 可达性分析</h4>\n<table>\n<thead>\n<tr>\n<th>特性</th>\n<th><strong>C++ (<code>shared_ptr</code>)</strong></th>\n<th><strong>Java (Garbage Collection)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>核心算法</strong></td>\n<td><strong>引用计数 (Reference Counting)</strong></td>\n<td><strong>可达性分析 (Tracing / Reachability)</strong></td>\n</tr>\n<tr>\n<td><strong>判定死亡</strong></td>\n<td>只要计数器归零，<strong>立刻</strong>死亡。</td>\n<td>从 GC Roots (如栈变量) 出发，<strong>找</strong>不到的对象才算死。</td>\n</tr>\n<tr>\n<td><strong>释放时机</strong></td>\n<td><strong>确定性 (Deterministic)</strong>。最后一个指针销毁的那一瞬间，对象必死。</td>\n<td><strong>不确定性</strong>。看 GC 心情，可能几秒后，可能内存不够时。</td>\n</tr>\n<tr>\n<td><strong>性能开销</strong></td>\n<td><strong>平摊</strong>。每次赋值都有微小的原子操作开销。</td>\n<td><strong>集中</strong>。平时很快，但 GC 运行时可能导致 \"Stop The World\" (卡顿)。</td>\n</tr>\n<tr>\n<td><strong>循环引用</strong></td>\n<td><strong>无法处理</strong>。A 指向 B，B 指向 A，两人计数都是 1，永远不归零 -&gt; <strong>内存泄漏</strong>。</td>\n<td><strong>完美处理</strong>。GC 发现这俩货虽然互相指，但外面没人指它们，直接一锅端。</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"342-场景演示循环引用-c-的阿喀琉斯之踵\">3.4.2. 场景演示：循环引用 (C++ 的阿喀琉斯之踵)</h4>\n<p>这是 C++ <code>shared_ptr</code> 最大的坑。</p>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;memory&gt;\n\n// 前置声明：因为 A 里面要用 B，B 里面要用 A，必须先告诉编译器 B 是个类\nclass B; \n\nclass A {\npublic:\n    // A 持有 B 的强引用 (shared_ptr)\n    std::shared_ptr&lt;B&gt; ptrB; \n    \n    A() { std::cout &lt;&lt; \"A Created (构造)\" &lt;&lt; std::endl; }\n    ~A() { std::cout &lt;&lt; \"A Destroyed (析构) &lt;--- 如果看到这句话，说明没泄露\" &lt;&lt; std::endl; }\n};\n\nclass B {\npublic:\n    // B 持有 A 的强引用 (shared_ptr) -&gt; 导致死锁\n    std::shared_ptr&lt;A&gt; ptrA; \n    \n    B() { std::cout &lt;&lt; \"B Created (构造)\" &lt;&lt; std::endl; }\n    ~B() { std::cout &lt;&lt; \"B Destroyed (析构) &lt;--- 如果看到这句话，说明没泄露\" &lt;&lt; std::endl; }\n};\n\nint main() {\n    std::cout &lt;&lt; \"=== 进入作用域 ===\" &lt;&lt; std::endl;\n    \n    {\n        // 1. 创建对象\n        // 此时 A 的计数 = 1 (只有变量 a 指向它)\n        // 此时 B 的计数 = 1 (只有变量 b 指向它)\n        std::shared_ptr&lt;A&gt; a = std::make_shared&lt;A&gt;();\n        std::shared_ptr&lt;B&gt; b = std::make_shared&lt;B&gt;();\n\n        std::cout &lt;&lt; \"1. 初始引用计数:\" &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   A counts: \" &lt;&lt; a.use_count() &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   B counts: \" &lt;&lt; b.use_count() &lt;&lt; std::endl;\n\n        // 2. 建立循环引用 (互相锁死)\n        std::cout &lt;&lt; \"2. 建立循环引用 (a-&gt;ptrB = b; b-&gt;ptrA = a;)\" &lt;&lt; std::endl;\n        a-&gt;ptrB = b; // B 的计数 +1 -&gt; 变成 2 (b 变量 + a.ptrB)\n        b-&gt;ptrA = a; // A 的计数 +1 -&gt; 变成 2 (a 变量 + b.ptrA)\n\n        std::cout &lt;&lt; \"   A counts: \" &lt;&lt; a.use_count() &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   B counts: \" &lt;&lt; b.use_count() &lt;&lt; std::endl;\n\n        std::cout &lt;&lt; \"--- 准备离开作用域 ---\" &lt;&lt; std::endl;\n    } // 3. 这里！离开作用域！\n    \n    // 正常逻辑：\n    // - 栈变量 a 销毁 -&gt; A 计数减 1 (2 -&gt; 1) -&gt; 不为 0，A 不死！\n    // - 栈变量 b 销毁 -&gt; B 计数减 1 (2 -&gt; 1) -&gt; 不为 0，B 不死！\n    \n    // 结果：A 拿着 B，B 拿着 A，谁也撒不开手。堆内存永远无法释放。\n\n    std::cout &lt;&lt; \"=== 离开作用域 (main 结束) ===\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"警告：你没有看到析构函数的日志，说明发生了内存泄漏！\" &lt;&lt; std::endl;\n\n    return 0;\n}\n\n</code></pre>\n<p>运行结果如下：</p>\n<pre><code class=\"language-text\">=== 进入作用域 ===\nA Created (构造)\nB Created (构造)\n1. 初始引用计数:\n   A counts: 1\n   B counts: 1\n2. 建立循环引用 (a-&gt;ptrB = b; b-&gt;ptrA = a;)\n   A counts: 2\n   B counts: 2\n--- 准备离开作用域 ---\n=== 离开作用域 (main 结束) ===\n警告：你没有看到析构函数的日志，说明发生了内存泄漏！\n</code></pre>\n<p><strong>而Java 对此表示毫无压力</strong>：Java GC 由于有GC Root，会发现 A 和 B 这一坨东西和外界断开了联系，直接把它俩都回收了。</p>\n<p><img alt=\"shared_ptr\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224713082-1422598190.jpg\" /></p>\n<h3 id=\"35-stdweak_ptr-打破循环的救星\">3.5. <code>std::weak_ptr</code> (打破循环的救星)</h3>\n<p>为了解决上面的循环引用问题，C++ 引入了 <code>weak_ptr</code>。</p>\n<ul>\n<li><strong>弱引用</strong>：它指向 <code>shared_ptr</code> 管理的对象，但是<strong>不增加引用计数</strong>。</li>\n<li><strong>旁观者</strong>：它只是看着对象，不能直接用。如果要用，必须先“升级”为 <code>shared_ptr</code>（并通过升级结果判断对象是否已经死了）。</li>\n</ul>\n<p><strong>修复上面的代码：</strong></p>\n<p>我们只需要把 B 里面的指针改成 <code>weak_ptr</code>：</p>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;memory&gt;\n\nclass B; // 前置声明\n\nclass A {\npublic:\n    // A 持有 B 的【强引用】(shared_ptr)\n    // 意味着：只要 A 活着，B 就不能死\n    std::shared_ptr&lt;B&gt; ptrB; \n    \n    A() { std::cout &lt;&lt; \"A Created (构造)\" &lt;&lt; std::endl; }\n    ~A() { std::cout &lt;&lt; \"A Destroyed (析构)\" &lt;&lt; std::endl; }\n};\n\nclass B {\npublic:\n    // 关键修改：B 持有 A 的【弱引用】(weak_ptr)\n    // 意味着：B 只是看着 A，但 B 不决定 A 的生死。\n    // weak_ptr 不会增加 shared_ptr 的引用计数！\n    std::weak_ptr&lt;A&gt; ptrA; \n    \n    B() { std::cout &lt;&lt; \"B Created (构造)\" &lt;&lt; std::endl; }\n    ~B() { std::cout &lt;&lt; \"B Destroyed (析构)\" &lt;&lt; std::endl; }\n};\n\nint main() {\n    std::cout &lt;&lt; \"=== 进入作用域 ===\" &lt;&lt; std::endl;\n    \n    {\n        // 1. 创建对象\n        std::shared_ptr&lt;A&gt; a = std::make_shared&lt;A&gt;();\n        std::shared_ptr&lt;B&gt; b = std::make_shared&lt;B&gt;();\n\n        // 2. 建立引用\n        std::cout &lt;&lt; \"--- 建立连接 ---\" &lt;&lt; std::endl;\n        \n        a-&gt;ptrB = b; // A 强引用 B。B 的计数 = 2 (main里的b + A里的ptrB)\n        b-&gt;ptrA = a; // B 弱引用 A。A 的计数 = 1 (只有main里的a) !!!\n        \n        std::cout &lt;&lt; \"当前引用计数 (关键点):\" &lt;&lt; std::endl;\n        // A 的计数只有 1，因为 weak_ptr 不算数\n        std::cout &lt;&lt; \"   A counts: \" &lt;&lt; a.use_count() &lt;&lt; \" (只有 main 持有它)\" &lt;&lt; std::endl; \n        // B 的计数是 2，因为 A 强引用着它\n        std::cout &lt;&lt; \"   B counts: \" &lt;&lt; b.use_count() &lt;&lt; \" (main 和 A 都持有它)\" &lt;&lt; std::endl;\n\n        std::cout &lt;&lt; \"--- 准备离开作用域 ---\" &lt;&lt; std::endl;\n    } \n    // 3. 离开作用域的过程：\n    // Step 1: 变量 'a' 销毁。\n    //    A 的引用计数从 1 变成 0。\n    //    -&gt; A 死了！打印 \"A Destroyed\"。\n    //    -&gt; A 析构时，会自动销毁它的成员 ptrB。\n    \n    // Step 2: A 的成员 ptrB 被销毁。\n    //    B 的引用计数从 2 减为 1。\n    \n    // Step 3: 变量 'b' 销毁。\n    //    B 的引用计数从 1 变成 0。\n    //    -&gt; B 死了！打印 \"B Destroyed\"。\n\n    std::cout &lt;&lt; \"=== 离开作用域 (main 结束) ===\" &lt;&lt; std::endl;\n    \n    return 0;\n}\n\n</code></pre>\n<p>运行结果如下（可以看到清晰的析构日志，证明没有内存泄漏：）：</p>\n<pre><code class=\"language-text\">=== 进入作用域 ===\nA Created (构造)\nB Created (构造)\n--- 建立连接 ---\n当前引用计数 (关键点):\n   A counts: 1 (只有 main 持有它)\n   B counts: 2 (main 和 A 都持有它)\n--- 准备离开作用域 ---\nA Destroyed (析构)\nB Destroyed (析构)\n=== 离开作用域 (main 结束) ===\n</code></pre>\n<p><img alt=\"weak_ptr\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260208224729997-336213178.jpg\" /></p>\n<h3 id=\"36-总结与最佳实践\">3.6. 总结与最佳实践</h3>\n<h4 id=\"361-对比总结\">3.6.1. 对比总结</h4>\n<ol>\n<li><strong>C++ RAII / 智能指针</strong>：</li>\n</ol>\n<ul>\n<li><strong>优点</strong>：<strong>即时释放</strong>（不用等 GC），<strong>资源利用率极高</strong>，<strong>无 STW 卡顿</strong>。非常适合做实时系统、游戏引擎、高频交易。</li>\n<li><strong>缺点</strong>：有思维负担，需要手动处理循环引用（<code>weak_ptr</code>）。</li>\n</ul>\n<ol start=\"2\">\n<li><strong>Java GC</strong>：</li>\n</ol>\n<ul>\n<li><strong>优点</strong>：<strong>开发效率高</strong>，不用关心循环引用，只要不瞎搞很难内存泄漏。</li>\n<li><strong>缺点</strong>：释放时机不可控，GC 运行时有性能波动，内存占用通常比 C++ 高。</li>\n</ul>\n<blockquote>\n<p><strong>关于开销的真相</strong>：<br />\n很多人认为 C++ 一定比 Java 快，但在内存分配上，Java 其实往往更快。Java 的 <code>new</code> 只是指针后移（Pointer Bump），极其廉价；而 C++ 的 <code>malloc/new</code> 需要去空闲链表中寻找合适的内存块。<br />\nC++ 的优势在于<strong>运行时期的平稳</strong>：它没有 GC 那个不定时触发的“大扫除”，因此非常适合对<strong>延迟 (Latency)</strong> 极度敏感的场景（如高频交易、游戏引擎、实时控制系统），而 Java 更适合追求<strong>吞吐量 (Throughput)</strong> 的后端服务。</p>\n</blockquote>\n<h4 id=\"362-c-避坑指南\">3.6.2. C++ 避坑指南</h4>\n<ol>\n<li>**默认首选 <code>std::unique_ptr**</code>。除非你真的需要多个人共享所有权，否则别用 <code>shared_ptr</code>。</li>\n<li>**绝不使用 <code>new**</code>。</li>\n</ol>\n<ul>\n<li>用 <code>std::make_unique&lt;T&gt;()</code> 代替 <code>new T()</code>。</li>\n<li>用 <code>std::make_shared&lt;T&gt;()</code> 代替 <code>new T()</code>。</li>\n<li>这不仅代码短，而且能防止某些极端情况下的内存泄漏。</li>\n</ul>\n<ol start=\"3\">\n<li><strong>遇到循环引用</strong>，立刻想到把其中一边换成 <code>std::weak_ptr</code>。</li>\n</ol>\n<p>现在，我们已经掌握了 C++ 内存管理的核心：<strong>对象默认在栈上，堆对象用 unique_ptr 管，共享对象用 shared_ptr 管，循环引用用 weak_ptr 破。</strong></p>\n<h2 id=\"4-结语\">4. 结语</h2>\n<p>从 Java 的“全自动驾驶”切换到 C++ 的“手动挡”，最大的挑战往往不在于语法，而在于思维模式的转变。</p>\n<p>C++ 将内存的控制权完全交还给了程序员，这既是绝对的自由，也是沉重的责任。通过本文，我们看到 RAII 赋予了我们确定性的资源释放能力，而移动语义和智能指针则在“极致性能”与“内存安全”之间架起了桥梁。</p>\n<p>记住 C++ 现代开发的黄金法则：<strong>默认使用栈对象，堆内存首选 <code>unique_ptr</code>，共享资源用 <code>shared_ptr</code>，循环引用靠 <code>weak_ptr</code> 打破。</strong> 掌握了这些，我们就真正驾驭了这门语言最锋利的双刃剑。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-08 22:51</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kaiux\">念风零壹</a>&nbsp;\n阅读(<span id=\"post_view_count\">3</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}