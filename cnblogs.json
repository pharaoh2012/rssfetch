{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "Windows#Office 一键免费安装与激活！",
      "link": "https://www.cnblogs.com/gegeblog/p/19444651",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/gegeblog/p/19444651\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 20:30\">\n    <span>Windows#Office 一键免费安装与激活！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>本文所介绍的内容仅供技术交流学习使用，请勿用于企业/线上生产环境。如有需求，请购买微软正版系统！”</p>\n</blockquote>\n<p>在数字化时代，许多用户都会面临Windows或Office安装与激活的问题。今天介绍的这个网站它以简单、一键式的操作，帮助用户快速激活微软产品，同时强调仅供技术交流和学习使用。</p>\n<h2 id=\"一主要功能\">一、主要功能</h2>\n<ul>\n<li>Windows下载<br />\n<img alt=\"1.png\" src=\"https://img2024.cnblogs.com/blog/3418714/202601/3418714-20260105202926168-1258256684.png\" /></li>\n<li>Windows 激活<br />\n<img alt=\"2.png\" src=\"https://img2024.cnblogs.com/blog/3418714/202601/3418714-20260105202926195-1481611383.png\" /></li>\n<li>office 安装<br />\n<img alt=\"3.png\" src=\"https://img2024.cnblogs.com/blog/3418714/202601/3418714-20260105202926172-518135139.png\" /></li>\n</ul>\n<ul>\n<li>office 激活<br />\n<img alt=\"4.png\" src=\"https://img2024.cnblogs.com/blog/3418714/202601/3418714-20260105202926199-46045626.png\" /></li>\n<li>Mac Office 安装激活<br />\n<img alt=\"5.png\" src=\"https://img2024.cnblogs.com/blog/3418714/202601/3418714-20260105202926625-760296104.png\" /></li>\n</ul>\n<h2 id=\"2使用教程\">2、使用教程</h2>\n<p>操作教程请前往<a href=\"https://www.gegeblog.top/article/53\" rel=\"noopener nofollow\" target=\"_blank\">Windows#Office 免费安装与激活！</a></p>\n<p><img alt=\"7.png\" src=\"https://img2024.cnblogs.com/blog/3418714/202601/3418714-20260105202926230-1912193272.png\" /></p>\n<p>网站地址也在其中，赶快试试吧！</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 20:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/gegeblog\">半页の时光</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "开源 NamBlog：一个博客外壳下的体验编译器",
      "link": "https://www.cnblogs.com/wlkw/p/19444515/namblog-open-source-experience-compiler-in-blog-shell",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wlkw/p/19444515/namblog-open-source-experience-compiler-in-blog-shell\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 19:35\">\n    <span>开源 NamBlog：一个博客外壳下的体验编译器</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        写作正从生产静态文本转向设计可交互的数字原型。开源项目 NamBlog 作为一个文档体验编译器，将 Markdown 视为人机协作的协议，通过 Markdown 与 Prompt 的结合，将文档实时编译为具备完整样式与交互的 HTML 应用。系统基于 .NET 10 与 GraphQL 构建，支持 AI 驱动的实时编译与多态转换，旨在探索 AI 时代写作的终极形态，让创作者的思想能以人为本通过 AI 增强，转化为多样化的数字体验。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h2>写作的裂变：从静态文本到动态原型</h2>\n<p>现阶段，我们见证了许多生成式 AI 带来的范式转移：聊天、绘图、编程等等。我关注写作这一行为，写作的定义也在悄然地裂变。过去，写作意味着生产静态文本；现在，写作是在设计可交互的数字体验原型。过去，作者交付的是内容；现在，作者交付的是调教 AI 的规则。</p>\n<p>差异将体现在交互方式和对资源整合的想象力上。聊天对话框把思维压缩成线性 prompt，是 AI 时代的“命令行”，能用，但远远不够。我们需要一种能同时承载人类意图的模糊性和机器执行的精确性的媒介——一种既是底稿又是源代码、既写给人类也写给 AI 的双重文本。</p>\n<p>这就是为什么 Markdown 值得被重视。它可以被视为是一种允许留白和扩展的社群协商式的符号中介层。那些 `#`、`*`、`![]()` 不是死板的语法规则，而是人机对“如何共同理解一段文本”达成的动态协议。那些排版是为了流畅阅读，也可以为了工作流编排；那些嵌入块是思维关联，也可以是微服务容器。</p>\n<p>受此理念驱使，我开发了一个实验性项目。它始于博客，因为博客是最朴素的 MVP。</p>\n<p>一份 Markdown + 一段提示词 → 一个样式与交互自包含的 HTML。</p>\n<p>这就是它最简单的表现形式，剩下的全靠用户发挥。这与当下 AIGC 的泛滥有本质不同。那些 AI 生成的内容，缺乏创作谱系，很容易被归类为垃圾内容被整个互联网排斥。而在这里，Markdown 是源真相。AI 不是替代创作者，而是以人为本的增强。整个生成链条从作者真实的写作开始，所使用的中间提示词都是可以自定义的。AI 的所有增强都被追踪、版本化、元数据化。MD 文档是核心，甚至，你还可以为一个文档库启动多个容器，例如创建多语言版。</p>\n<p>这个项目不是静态博客生成器，因为它拥抱多样化；不是 Notion 式的富文本编辑器，因为它坚持文档的纯粹性。实验旨在探索一个问题：当文档可以被 AI 编译成任何可交付的成果时，写作的终极形态是什么？</p>\n<p>Markdown + Prompt → HTML，是这种想象力的最小可行载体。</p>\n<h2>NamBlog：一个文档体验编译器</h2>\n<p>NamBlog 是我基于这一理念构建的开源原型。读者不妨试试当文章不再仅仅排版美化，而是作为一种“意图指令”时，会发生什么。</p>\n<p>在 NamBlog 中，内置的 AI Agent 和可热重载的提示词系统构成了一个实时编译环境。当你提交一篇文档时，系统会根据你的指令——“生成一个交互式图表”、“设计一个沉浸式阅读页”或“构建一个带动画的卡片布局”——实时调用 AI 将 Markdown 编译为包含完整样式和脚本的 HTML 应用。这让“写作”的过程，在某种程度上变成了用自然语言进行编程。</p>\n<p>对于开发者而言，这也是一个现代化的技术实验场。后端基于 .NET 10 构建，采用了 DDD（领域驱动设计）分层架构。数据层摒弃了传统的 RESTful 接口，全面采用 GraphQL，让前端可以按需查询数据，不再受限于预定义的模板结构。同时，无论是 AI 的提示词还是系统配置，都支持热重载——修改配置就像修改代码一样，拥有即时的反馈循环。</p>\n<p>在体验上，NamBlog 试图弥合 Web 与原生应用的鸿沟。它是一个单页应用（SPA），提供如同原生 App 般的流畅体验和离线访问能力（PWA），同时内置了针对爬虫的静态交付机制，确保内容能被搜索引擎索引。它也不强迫你改变工作流：你可以使用 Web 编辑器，也可以通过 MCP 协议直接在 Claude/Cherry Studio 中操作博客，或者仅仅将它作为一个文件流监控器，配合 Obsidian 等流行的 Markdown 工具使用。</p>\n<p>移动端编辑体验：</p>\n<p><video controls=\"controls\" height=\"630\" preload=\"none\" src=\"https://nigzu.com/file/edit(phone).mp4\" width=\"300\"></video></p>\n<p>项目发布在 GitHub：<a href=\"https://github.com/code-gal/namblog\" rel=\"noopener nofollow\" target=\"_blank\">code-gal/namblog</a><br />演示站点：<a href=\"https://namblog.nigzu.com\" rel=\"noopener nofollow\" target=\"_blank\">namblog</a></p>\n<h2>关于未来的一点畅想</h2>\n<p>这个世界也许早晚要统一语言，但不是统一符号或发音，而是统一转换的范式。这种统一将以一种极为高效的方式进行，因为人工智能革命正在发生。在这种统一下，所有的语言只是一种方言，它会被自动翻译成目标对象可以接受的方式。</p>\n<p>这场革命如果不由人主导，人至少可以抓住一点主动权——提供原材料。不是食物链中的有机物，而是信息要素。将感觉的刺激，在脑海中的涟漪，转换成表达的内容，这方面人可以维持自己独特的优势。这个项目就是那个“转换器”的原型，它让你的思想（Markdown）可以无损地、多态地转换成读者（未来可以是计算机）需要的形式。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 19:35</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wlkw\">怀川</a>&nbsp;\n阅读(<span id=\"post_view_count\">10</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【面试题】MySQL 三层 B+ 树能存多少数据？",
      "link": "https://www.cnblogs.com/sun-10387834/p/19388703",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19388703\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 18:57\">\n    <span>【面试题】MySQL 三层 B+ 树能存多少数据？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这是一个经典的面试题，但实际估算需要考虑多个变量。下面我将详细拆解计算过程：</p>\n<h2 id=\"核心计算模型\"><strong>核心计算模型</strong></h2>\n<p>MySQL B+树存储量 = 根节点扇出 × 中间节点扇出 × 叶子节点容量</p>\n<hr />\n<h2 id=\"关键假设以innodb默认配置为例\"><strong>关键假设（以InnoDB默认配置为例）</strong></h2>\n<ol>\n<li><strong>页大小</strong>：16KB（16384字节）</li>\n<li><strong>主键类型</strong>：BIGINT（8字节）</li>\n<li><strong>指针大小</strong>：6字节（InnoDB页指针）</li>\n<li><strong>行数据大小</strong>：1KB（1024字节） - <em>这是关键变量</em></li>\n<li><strong>页空间利用率</strong>：约70%（需扣除页头、页尾等元数据）</li>\n</ol>\n<hr />\n<h2 id=\"三层b树结构\"><strong>三层B+树结构</strong></h2>\n<pre><code>第1层：根节点（1个）\n第2层：中间节点（fan_out个）\n第3层：叶子节点（fan_out²个） ← 存储实际数据\n</code></pre>\n<hr />\n<h2 id=\"详细计算步骤\"><strong>详细计算步骤</strong></h2>\n<h3 id=\"1-计算单个非叶子节点能存储的键值对数量fan_out\"><strong>1. 计算单个非叶子节点能存储的键值对数量（fan_out）</strong></h3>\n<p>每个索引项大小 = 主键(8B) + 指针(6B) = 14B<br />\n可用空间 = 16KB × 70% = 11.2KB ≈ 11468字节<br />\n单个节点索引项数 = 11468 / 14 ≈ <strong>819</strong></p>\n<p>即：<strong>每个非叶子节点可指向约819个子节点</strong></p>\n<h3 id=\"2-计算单个叶子节点能存储的数据行数\"><strong>2. 计算单个叶子节点能存储的数据行数</strong></h3>\n<p>可用空间 = 16KB × 70% = 11.2KB<br />\n假设每行数据1KB → 每页约存储 <strong>11行</strong><br />\n假设每行数据200字节 → 每页约存储 <strong>57行</strong><br />\n假设每行数据800字节 → 每页约存储 <strong>14行</strong></p>\n<h3 id=\"3-三层b树总容量计算\"><strong>3. 三层B+树总容量计算</strong></h3>\n<p><strong>公式</strong>：总行数 = fan_out² × 每页行数</p>\n<ul>\n<li>若每页11行：819² × 11 ≈ <strong>730万行</strong></li>\n<li>若每页57行：819² × 57 ≈ <strong>3800万行</strong></li>\n<li>若每页14行：819² × 14 ≈ <strong>940万行</strong></li>\n</ul>\n<hr />\n<h2 id=\"更精确的估算考虑真实innodb结构\"><strong>更精确的估算（考虑真实InnoDB结构）</strong></h2>\n<p>实际InnoDB叶子节点存储的是完整数据行，需要考虑：</p>\n<ul>\n<li>行格式开销（行头约23字节）</li>\n<li>事务系统开销（MVCC的隐藏列：DB_TRX_ID 6B + DB_ROLL_PTR 7B）</li>\n<li>可能的NULL位图、变长字段列表等</li>\n</ul>\n<p><strong>保守估算</strong>：<br />\n假设主键为BIGINT，每行额外开销约50字节：</p>\n<ul>\n<li>行大小 = 数据(1024B) + 行开销(50B) = 1074B</li>\n<li>每页行数 = (16384×70%) / 1074 ≈ 10行</li>\n<li>总行数 = 819² × 10 ≈ <strong>670万行</strong></li>\n</ul>\n<hr />\n<h2 id=\"场景分析表\"><strong>场景分析表</strong></h2>\n<table>\n<thead>\n<tr>\n<th>行大小</th>\n<th>每页行数</th>\n<th>三层B+树容量</th>\n<th>四层B+树容量</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>200B（小记录）</td>\n<td>~57行</td>\n<td>约3800万行</td>\n<td>约310亿行</td>\n</tr>\n<tr>\n<td>1KB（典型记录）</td>\n<td>~10行</td>\n<td>约670万行</td>\n<td>约55亿行</td>\n</tr>\n<tr>\n<td>2KB（较大记录）</td>\n<td>~5行</td>\n<td>约335万行</td>\n<td>约27亿行</td>\n</tr>\n<tr>\n<td>8KB（大记录）</td>\n<td>~1行</td>\n<td>约67万行</td>\n<td>约5.5亿行</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"重要说明\"><strong>重要说明</strong></h2>\n<ol>\n<li>\n<p><strong>实际容量可能更大</strong>：</p>\n<ul>\n<li>若使用INT主键（4字节），fan_out ≈ 1365，容量提升近3倍</li>\n<li>若行记录更紧凑，每页存储行数更多</li>\n</ul>\n</li>\n<li>\n<p><strong>B+树层数增长</strong>：</p>\n<ul>\n<li>当数据量超过三层容量时，B+树变为四层</li>\n<li>四层B+树容量 = fan_out³ × 每页行数</li>\n<li>对于1KB行，四层B+树可存储约 <strong>55亿行</strong></li>\n</ul>\n</li>\n<li>\n<p><strong>聚簇索引 vs 二级索引</strong>：</p>\n<ul>\n<li>上述计算针对<strong>聚簇索引</strong>（叶子节点存完整数据）</li>\n<li>二级索引叶子节点存储主键值，容量会更大</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"结论\"><strong>结论</strong></h2>\n<p>在典型的配置下（BIGINT主键、1KB行数据）：</p>\n<ul>\n<li><strong>三层B+树大约能存储600万～1000万行数据</strong></li>\n<li><strong>四层B+树可存储数十亿行数据</strong></li>\n</ul>\n<p>这也是为什么我们常说：</p>\n<ul>\n<li>单表千万级别数据时，查询性能仍能保持良好（三层B+树）</li>\n<li>数据量过亿时，可能需要考虑分库分表或优化索引设计</li>\n</ul>\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19388703\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19388703</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 18:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第一周：循环神经网络 （一）序列数据与序列模型",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19437798",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19437798\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 18:52\">\n    <span>吴恩达深度学习课程五：自然语言处理  第一周：循环神经网络 （一）序列数据与序列模型</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课的第一周内容，<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&amp;vd_source=e035e9878d32f414b4354b839a4c31a4&amp;p=151\" rel=\"noopener nofollow\" target=\"_blank\">1.1</a>的内容以及一些基础的补充。</p>\n<hr />\n<p>本周为第五课的第一周内容，与 CV 相对应的，这一课所有内容的中心只有一个：<strong>自然语言处理（Natural Language Processing，NLP）</strong>。<br />\n应用在深度学习里，它是专门用来进行<strong>文本与序列信息建模</strong>的模型和技术，本质上是在全连接网络与统计语言模型基础上的一次“结构化特化”，也是人工智能中<strong>最贴近人类思维表达方式</strong>的重要研究方向之一。<br />\n<strong>这一整节课同样涉及大量需要反复消化的内容，横跨机器学习、概率统计、线性代数以及语言学直觉。</strong><br />\n语言不像图像那样“直观可见”，更多是抽象符号与上下文关系的组合，因此<strong>理解门槛反而更高</strong>。<br />\n因此，我同样会尽量补足必要的背景知识，尽可能用比喻和实例降低理解难度。<br />\n本篇的内容关于<strong>序列数据和序列模型</strong>，是自然语言处理中基础内容。</p>\n<h1 id=\"1-序列数据\">1. 序列数据</h1>\n<p>在 NLP 中，一个最基础、也最核心的问题是：<strong>语言数据，和我们之前见过的数据，有什么本质不同？</strong><br />\n答案可以简单概括为：<strong>它是有顺序的。</strong></p>\n<p>在机器学习中，我们把 <strong>”顺序本身携带信息”</strong> 的数据称为<strong>序列数据</strong>。<br />\n最直观的例子就是一句话，同样是这几个词：</p>\n<blockquote>\n<p>“我 吃 饭”<br />\n“饭 吃 我”</p>\n</blockquote>\n<p>包含的词完全一样，但表达的含义却天差地别，这说明：<strong>在语言中，信息不仅存在于“有哪些元素”，还存在于“元素出现的顺序”。</strong></p>\n<p>这与我们之前在 CV 中常见的数据有所不同。<br />\n一张图像在进入模型之前，通常已经被表示为一个<strong>固定尺寸的二维像素网格</strong>。<br />\n无论我们先看左上角还是右下角，<strong>整幅图像的所有信息在输入时是同时存在的</strong>，模型面对的是一个“完整画面”。<br />\n在这种设定下，卷积网络更关注的是<strong>空间结构关系</strong>：哪些像素彼此相邻、哪些局部区域可以组成更高层的形状。</p>\n<p>而语言数据的形式则不同，一句话并不是一个天然的“整体对象”，而是由词语<strong>按顺序依次出现</strong>的。<br />\n简单来说：在按序建模的假设下，模型对当前词的理解，往往依赖于<strong>之前已经出现的所有词所构成的上下文</strong>。</p>\n<p>需要说明的是，这里的“按顺序”并不一定意味着模型必须<strong>像人一样一个词一个词地读</strong>。<br />\n在后续将要介绍的 <strong>Transformer</strong> 模型中，整句话的所有词可以被<strong>同时送入模型进行处理</strong>，但模型仍然需要通过<strong>显式地引入位置信息</strong>，来区分“哪个词在前、哪个词在后”。</p>\n<p>再打个比方：<br />\n图像更像是一张<strong>已经摊开在桌面上的地图</strong>，所有信息一眼都在，模型在处理时不依赖显式的时间顺序，而是直接建模整体的空间结构关系。<br />\n而语言更像是一段<strong>正在播放的语音或文字流</strong>，我们从哪里听，哪里看，结果是截然不同的。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260104144013115-1425405995.png\" /><br />\n因此，在语言任务中，“先出现什么、后出现什么”本身就构成了信息的一部分，而不能被随意打乱<br />\n正因为这种差异，让CV 模型更擅长处理<strong>空间结构与局部模式</strong>，而 NLP 模型必须重点解决<strong>顺序、依赖关系以及上下文记忆</strong>的问题。</p>\n<p>我们总结语言、语音、时间等序列数据的特征如下：</p>\n<ol>\n<li>数据是<strong>按顺序排列</strong>的。</li>\n<li>当前信息往往依赖于<strong>之前已经出现的内容</strong>。</li>\n<li>数据长度通常<strong>不固定</strong>。</li>\n</ol>\n<p>这些特征决定了：<strong>在处理序列数据时，模型必须显式地考虑顺序与上下文，而不能仅把输入当作一个无序的特征集合来处理。</strong></p>\n<h1 id=\"2-序列模型\">2. 序列模型</h1>\n<p>我们分别看看，如果使用我们已经了解过的<strong>全连接网络</strong>和<strong>卷积网络</strong>来处理序列数据，效果会怎么样。</p>\n<h2 id=\"21-全连接网络无法自然处理顺序\">2.1 全连接网络：无法自然处理“顺序”</h2>\n<p>如果要应用全连接网络，最直接的想法是：  把一句话中的每个词表示成向量，再把这些向量<strong>拼接成一个长向量</strong>，送进全连接网络。</p>\n<p>这种做法在形式上是可行的，但问题也非常明显：<br />\n首先，全连接网络要求<strong>固定长度输入</strong>，而语言序列的长度是天然不固定的。<br />\n一句话可以只有几个词，也可以非常长。为了满足输入要求，我们不得不进行截断或填充，这本身就引入了额外的工程复杂度。</p>\n<p>其次，更关键的是：<strong>全连接网络并不具备“顺序感知”能力</strong>。在它看来，输入只是一个高维向量，各个维度之间没有“先后”这一概念。<br />\n模型本身并不知道：“这是第一个词”“这是第三个词”。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260104144012968-399183777.png\" /></p>\n<p>因此，这种处理方式天然忽略了语言中最重要的结构信息——顺序与依赖关系。不能用来处理序列数据。</p>\n<h2 id=\"22-卷积网络擅长局部模式但缺乏长期依赖\">2.2 卷积网络：擅长局部模式，但缺乏长期依赖</h2>\n<p>那卷积网络呢？  既然 CNN 能在图像中建模局部结构，是否也可以用于序列数据？<br />\n答案是：<strong>部分可以，但不够自然。</strong></p>\n<p>在序列上使用一维卷积时，卷积核可以捕捉<strong>局部连续片段</strong>，例如相邻几个词构成的短语或固定搭配。 从这个角度看，CNN 确实能够建模<strong>局部上下文信息</strong>。</p>\n<p>在这里，我们需要引入一个概念：<strong>感受野（receptive field）</strong>。<br />\n感受野指的是卷积层中某个神经元<strong>能够“看到”的输入区域范围</strong>。<br />\n打个比方：</p>\n<ul>\n<li>在图像中，如果一个卷积神经元的感受野是 <span class=\"math inline\">\\(3\\times3\\)</span>，它只能感知这九个像素的局部信息；</li>\n<li>类似地，在序列上，一个卷积核的感受野就是它<strong>一次性能看到的连续词的数量</strong>。<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260104144316440-1063086196.png\" /><br />\n这就意味着，卷积网络在处理序列时天然擅长捕捉<strong>局部模式或短距离依赖</strong>，但如果想让模型理解“句首的词”与“句尾的词”之间的关系，就必须<strong>堆叠很多层卷积</strong>或<strong>人为扩大卷积核范围</strong>，才能覆盖整个序列。<br />\n简单来说，感受野越大，模型越容易捕捉<strong>长距离依赖</strong>，但这也带来了计算和训练上的问题。<br />\n这使得模型：</li>\n<li>对<strong>短距离依赖</strong>敏感。</li>\n<li>对<strong>长距离依赖</strong>不够高效。</li>\n<li>并且仍然缺乏一种明确的“时间状态”概念。</li>\n</ul>\n<p>可以这样理解：<br />\n卷积网络更像是在<strong>扫描局部片段</strong>，而不是在<strong>沿着时间轴逐步理解一句话的发展过程</strong>，因此，虽然卷积对序列数据的处理能力强于全连接网络，但是它仍有所局限。</p>\n<h2 id=\"23-序列模型要解决的核心问题\">2.3 序列模型要解决的核心问题</h2>\n<p>通过以上对比可以看到，全连接网络和卷积网络并不是“不能”处理序列数据，而是<strong>处理方式与序列数据的本质存在冲突</strong>。</p>\n<p>序列数据的核心特点在于：信息是<strong>随顺序逐步展开的</strong>、当前理解依赖于<strong>历史上下文</strong>且序列长度<strong>不固定</strong>。<br />\n因此，我们真正需要的是这样一类模型：  <strong>在处理当前输入的同时，能够保留并更新对“过去信息”的表示。</strong><br />\n也就是说，序列模型的核心能力并不在于“输入形式”，  而在于它是否具备一种<strong>可随时间演化的内部状态</strong>，用来承载上下文信息，并参与后续决策。<br />\n后续我们将看到的 RNN、LSTM、GRU 以及 Transformer，  虽然实现方式不同，但都围绕着同一个目标展开：  <strong>让模型在理解当前内容时，不是孤立地“看这一刻”，而是基于整个上下文来判断。</strong></p>\n<p>这就是序列模型所具备的能力。</p>\n<h1 id=\"3-序列模型的应用领域\">3. 序列模型的应用领域</h1>\n<p>序列模型在 NLP 中应用广泛，但需要注意的是：<strong>序列模型不一定要求输入和输出都是序列</strong>。它的核心能力在于能够<strong>保留上下文信息并处理随时间展开的数据</strong>。只要输入或输出中存在序列性质，序列模型就能发挥作用。<br />\n从输入和输出的角度，可以分为以下几类情况：</p>\n<ol>\n<li><strong>序列→序列：</strong> 输入和输出都是序列，例如机器翻译。模型需要根据输入序列的上下文生成对应的输出序列。</li>\n<li><strong>序列→标量或类别：</strong> 输入是序列，输出是单个值或类别，例如情感分析、文本分类。模型需要理解整段序列的语义，并输出整体判断。</li>\n<li><strong>标量或固定输入→序列：</strong> 输入不是序列，但模型需要生成序列作为输出，例如文本生成或对话系统中根据提示生成完整回答。</li>\n</ol>\n<p>由此可见，序列模型的核心能力不是“必须处理序列输入或输出”，而是<strong>能够在处理过程中维护上下文信息</strong>。<br />\n来看看序列模型的一些常见应用领域：</p>\n<table>\n<thead>\n<tr>\n<th>任务</th>\n<th>输入类型</th>\n<th>输出类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>文本分类</td>\n<td>序列</td>\n<td>类别</td>\n<td>如情感分析、新闻分类，理解整段文本并输出单一标签</td>\n</tr>\n<tr>\n<td>命名实体识别 (NER)</td>\n<td>序列</td>\n<td>序列</td>\n<td>对每个词进行标注，如“人名”“地名”等</td>\n</tr>\n<tr>\n<td>机器翻译</td>\n<td>序列</td>\n<td>序列</td>\n<td>将源语言句子转换为目标语言句子</td>\n</tr>\n<tr>\n<td>文本生成</td>\n<td>序列或标量</td>\n<td>序列</td>\n<td>根据输入文本或提示生成完整文本</td>\n</tr>\n<tr>\n<td>语音识别</td>\n<td>序列</td>\n<td>序列</td>\n<td>将语音信号转为文字序列</td>\n</tr>\n<tr>\n<td>问答系统</td>\n<td>序列</td>\n<td>序列或标量</td>\n<td>根据问题生成答案，答案可以是短文本或单一类别</td>\n</tr>\n<tr>\n<td>时间序列预测</td>\n<td>序列</td>\n<td>序列或标量</td>\n<td>如股价预测，根据历史序列预测未来数值</td>\n</tr>\n</tbody>\n</table>\n<p>通过这个分类，可以清晰地看到：<strong>序列模型的核心是处理顺序和上下文，不必限制输入输出都为序列</strong>。只要有序列信息存在，它就可以发挥价值。</p>\n<h1 id=\"4-总结\">4. 总结</h1>\n<table>\n<thead>\n<tr>\n<th>概念</th>\n<th>原理</th>\n<th>比喻</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>序列数据</td>\n<td>数据元素按顺序排列，当前理解依赖历史上下文，长度不固定</td>\n<td>图像像摊开的地图，一眼可见整体；语言像正在播放的语音或文字流，需要顺序感知</td>\n</tr>\n<tr>\n<td>全连接网络处理序列</td>\n<td>只能接受固定长度输入，无法天然感知顺序</td>\n<td>只是把所有词拼成一个长向量，模型看不到先后顺序</td>\n</tr>\n<tr>\n<td>卷积网络处理序列</td>\n<td>能捕捉局部连续模式（短距离依赖），感受野有限，长距离依赖不高效</td>\n<td>卷积像扫描局部片段，而不是沿时间轴理解整句话的发展</td>\n</tr>\n<tr>\n<td>感受野 (Receptive Field)</td>\n<td>一个卷积神经元一次能够看到的输入区域</td>\n<td>图像：3×3像素只能看到局部；序列：卷积核一次看到几个连续词</td>\n</tr>\n<tr>\n<td>序列模型核心能力</td>\n<td>通过可随时间演化的内部状态，保留并更新上下文信息，理解当前输入时考虑历史信息</td>\n<td>模型像带记忆的阅读者，理解每个词时参考整段上下文</td>\n</tr>\n<tr>\n<td>输入/输出类型灵活性</td>\n<td>序列模型不要求输入输出都为序列，只要一方为序列即可发挥作用</td>\n<td>输入是流，输出是判断或生成，模型记忆历史信息</td>\n</tr>\n<tr>\n<td>序列模型应用</td>\n<td>NLP、语音、时间序列等领域，如文本分类、NER、机器翻译、文本生成、语音识别、问答、时间序列预测</td>\n<td>依赖上下文信息，模型像“顺序感知器”，根据过去信息做当前决策</td>\n</tr>\n</tbody>\n</table>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 18:52</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "NVIDIA CUDA 高性能计算笔记（一）cuda编程简介及矩阵赋值案例",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19444388",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19444388\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 18:33\">\n    <span>NVIDIA CUDA 高性能计算笔记（一）cuda编程简介及矩阵赋值案例</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        CUDA （Compute  Unified Device Architecture）是NIVIDIA 推出的通用并行计算平台，支持C，C++，Python等语言，实现CPU和GPU协同计算。其架构采用Grid-Blocks-Threads线程层次结构和SIMT并行模式，在给出CUDA的编程实例之前，需要给出模型的基础知识做个简单的介绍。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"nvidia-cuda-高性能计算笔记一\">NVIDIA CUDA 高性能计算笔记（一）</h1>\n<p>​       CUDA （Compute  Unified Device Architecture）是NIVIDIA 推出的通用并行计算平台，支持C，C++，Python等语言，实现CPU和GPU协同计算。其架构采用Grid-Blocks-Threads线程层次结构和SIMT并行模式，在给出CUDA的编程实例之前，需要给出模型的基础知识做个简单的介绍。</p>\n<h2 id=\"11cuda编程模型简介\">1.1CUDA编程模型简介</h2>\n<p>​      CUDA编程模型是一个异构模型，需要GPU和CPU协同工作。在CUDA架构中，我们用host端指代CPU及其内存的，用device指代GPU及其内存。CUDA程序中即包含Host程序，又包含device程序，它们分别在CPU与GPU上运行。同时，host与device之间进行通信，这样它们之间可以进行数据拷贝。典型的CUDA程序的执行的程序的流程为：</p>\n<ol>\n<li>分配host内存，并进行数据初始化；</li>\n<li>分配device内存（显存、共享内存），并从host端将数据拷贝到device端；</li>\n<li>调用CUDA的核函数在device函数上完成指定的运算；</li>\n<li>将device上的运算结果拷贝到host上；</li>\n<li>释放device和host上分配的内存。</li>\n</ol>\n<p>​        由于CUDA编程模型实际上是异构编程模型，所以需要区分host和device上的代码，在CUDA中是通过函数类型限定词区别开host和device上的函数，主要的三个函数类型限定词如下：</p>\n<ul>\n<li><code>__global__</code>: 在device端上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须为 <code>void</code> , 不支持可变参数，不能成为类成员函数。注意<code>__global__</code> 定义的kernel是异步的，这意味着host端不会等待kernel执行完就执行下一步；</li>\n<li><code>__device__</code>: 在device端上执行，但仅可以从device中调用，不可以和 <code>__global__</code> 同时用；</li>\n<li><code>__host__</code>: 在host上执行，仅可以从host中调用，一般省略不写，不可以和 <code>__global__</code>同时用，但可以和 <code>__device__</code>，此时函数会在device和host都编译。</li>\n</ul>\n<p>​         上面的流程中最重要的一个过程是调用CUDA的核函数来执行并行计算，kernel是CUDA中的一个重要的概念，kernel是在device上线程中并行执行的函数，在调用时需要用 <code>&lt;&lt;&lt;grid,block&gt;&gt;&gt; </code> 来指定kernel要执行的线程数量，在CUDA中，每个线程都要执行核函数，并且每个线程会分配一个唯一的<span class=\"math inline\">\\(thread\\space ID\\)</span> ,这个<span class=\"math inline\">\\(ID\\)</span> 值可以通过核函数的内置变量 <code>thread Idx</code> 来获得。</p>\n<p>​       要深刻理解<span class=\"math inline\">\\(kernel\\)</span>，必须要对<span class=\"math inline\">\\(kernel\\)</span> 的线程层次结构有一个清晰的认识。首先，<span class=\"math inline\">\\(GPU\\)</span>上很多并形化的轻量级线程。<span class=\"math inline\">\\(kernel\\)</span> 在device上执行时实际上是启动很多线程，一个<span class=\"math inline\">\\(kernel\\)</span> 所启动的所有线程称为<strong>网格</strong><span class=\"math inline\">\\(grid\\)</span> ，同一个网格的线程共享相同的全局内存空间，grid是线程结构的第一个层次，而网格又可以分为很多<strong>线程块</strong>(block)，一个线程块里面包含很多线程，这是第二个层次。  为了编程方便，<span class=\"math inline\">\\(grid\\)</span> 和<span class=\"math inline\">\\(block\\)</span> 都是定义为 <code>dim3</code> 类型的变量，<code>dim3</code> 可以看成是包含三个无符号整数<span class=\"math inline\">\\((x,y,z)\\)</span> 成员的结构体变量，在定义时，缺失值初始化为1。因此，grid和block可以灵活地定义为1-dim，2-dim以及3-dim的结构，对于，<span class=\"math inline\">\\(knernel\\)</span>在定义调用时也必须通过执行配置 <code>&lt;&lt;&lt;grid,block&gt;&gt;&gt;</code>来指定kernel所使用的线程数及结构。</p>\n<p><img alt=\"fHaSP2zNs\" class=\"lazyload\" /></p>\n<p>​    所以，为了方便编程，CUDA中使用了 <code>dim3</code> 类型（<code>dim3</code> 是基于unit3定义的矢量类型，相当于由3个 <code>unsigned int</code>类型组成的结构体）的内建变量 <code>threadIdx</code> 和 <code>blockIdx</code>。这样，就可以使用一维、二维或三维的索引来标识线程，构成 一维、二维或三维线程块。使得线程组织形式对各种域（向量、矩阵，或者高维张量）中数据的划分变得直观、自然。</p>\n<ul>\n<li>对于一维的block，线程的<span class=\"math inline\">\\(threadID\\)</span>就是<span class=\"math inline\">\\(threadId.x\\)</span>;</li>\n<li>对于大小为<span class=\"math inline\">\\((Dx,Dy)\\)</span>的二维线程块block，线程的<span class=\"math inline\">\\(threadID\\)</span> 是 <span class=\"math inline\">\\((threadIdx.x+threadIdx.x\\times{Dx})\\)</span>;</li>\n<li>对于大小为<span class=\"math inline\">\\((Dx,Dy,Dz)\\)</span>的三维线程块block, 线程的<span class=\"math inline\">\\(threadID\\)</span>是（<span class=\"math inline\">\\(threadIdx.x+threadIdx.y\\times{Dx}+threadIdx.z\\times{Dx}\\times{Dy}\\)</span>）;</li>\n</ul>\n<p>另外，线程还有内置变量gridDim，用于获取网格块各个维度的大小。</p>\n<p>​       此外，这里简单介绍一下CUDA的内存模块，如图所示。可以看到，每个线程有自己的私有本地内存（<span class=\"math inline\">\\(Local Memory\\)</span>）, 而每个线程块有包含共享内存（<span class=\"math inline\">\\(Shared \\space Memory\\)</span>）。还可以访问一些只读内存块：常用内存（<span class=\"math inline\">\\(Constant \\space Memory\\)</span>）和纹理内存 （<span class=\"math inline\">\\(Texture \\space Memory\\)</span>）。内存结构涉及到程序优化，这里就过多讨论。</p>\n<p><img alt=\"fHaRlklWa\" class=\"lazyload\" /></p>\n<p>​       还有重要一点，你需要对<span class=\"math inline\">\\(GPU\\)</span>的硬件实现有一个基本的认识。上面说到了<span class=\"math inline\">\\(kernel\\)</span>的线程组织层次，那么一个<span class=\"math inline\">\\(kernel\\)</span> 实际上会启动很多线程，这些线程是逻辑上是并行的，但是在物理层也是无法却并不一定。这其实和CPU的多线程有类似之处，多线程如果没有多核支持，在物理层也无法实现并行的。但是好在<span class=\"math inline\">\\(GPU\\)</span> 存在很多CUDA核心，充分利用CUDA核心可以充分发挥GPU的并行计算能力。GPU硬件的一个核心组件是SM，前面已经说过，SM是Streaming Multiprocessor，SM的核心组件包括的CUDA核心、共享内存、寄存器等，SM可以并发的执行上，一个线程块只能在一个SM上被调度。SM一般可以调度多个线程块，这要看SM本身的能力。那么有可能一个kernel的各个线程块被分配多个SM，所以grid只是逻辑层，而SM才是执行的物理层。SM采用的是<a href=\"https://link.zhihu.com/?target=http%3A//docs.nvidia.com/cuda/cuda-c-programming-guide/index.html%23simt-architecture\" rel=\"noopener nofollow\" target=\"_blank\">SIMT</a>(Single-Instruction, Multiple-Thread，单指令多线程)架构，基本的执行单元是线程束（warps)，线程束包含32个线程，这些线程同时执行相同的指令，但是每个线程都包含自己的指令地址计数器和寄存器状态，也有自己独立的执行路径。所以尽管线程束中的线程同时从同一程序地址执行，但是可能具有不同的行为，比如遇到了分支结构，一些线程可能进入这个分支，但是另外一些有可能不执行，它们只能死等，因为GPU规定线程束中所有线程在同一周期执行相同的指令，线程束分化会导致性能下降。当线程块被划分到某个SM上时，它将进一步划分为多个线程束，因为这才是SM的基本执行单元，但是一个SM同时并发的线程束数是有限的。这是因为资源限制，SM要为每个线程块分配共享内存，而也要为每个线程束中的线程分配独立的寄存器。所以SM的配置会影响其所支持的线程块和线程束并发数量。总之，就是网格和线程块只是逻辑划分，一个kernel的所有线程其实在物理层是不一定同时并发的。所以kernel的grid和block的配置不同，性能会出现差异，这点是要特别注意的。还有，由于SM的基本执行单元是包含32个线程的线程束，所以block大小一般要设置为32的倍数。</p>\n<table>\n<thead>\n<tr>\n<th>内存类型：</th>\n<th>内存作用：</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>全局内存（Global Memory）</strong></td>\n<td><strong>容量最大（通常数GB），所有线程可访问，但延迟高（400-800周期）</strong></td>\n</tr>\n<tr>\n<td><strong>共享内存（shared Memory）</strong></td>\n<td><strong>片上内存，速度比全局内存快100倍，但容量有限（每SM通常16-64KB）</strong></td>\n</tr>\n<tr>\n<td><strong>寄存器（Registers）</strong></td>\n<td><strong>最快的存储，每个线程私有</strong></td>\n</tr>\n<tr>\n<td><strong>常量内存（Constant Memory）</strong></td>\n<td><strong>只读缓存，适合广播数据</strong></td>\n</tr>\n<tr>\n<td><strong>纹理内存（Texture Memory）</strong></td>\n<td><strong>专为图形处理优化的特殊缓存</strong></td>\n</tr>\n</tbody>\n</table>\n<p>​     内存访问特性比较：</p>\n<table>\n<thead>\n<tr>\n<th>内存类型</th>\n<th>物理位置</th>\n<th>作用域</th>\n<th>带宽、速度</th>\n<th>使用场景</th>\n<th>显式控制关键字</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>寄存器</td>\n<td>GPU芯片寄存器</td>\n<td>线程私有</td>\n<td>最高（1周期）</td>\n<td>高频访问的私有变量（如循环计数器）</td>\n<td>自动分配（局部变量）</td>\n</tr>\n<tr>\n<td>共享内存</td>\n<td>GPU芯片上的SM处理器</td>\n<td>线程块共享</td>\n<td>高（1-32周期）</td>\n<td>线程协作（如规约运算、矩阵分块）</td>\n<td><code>__share__</code></td>\n</tr>\n<tr>\n<td>本地内存</td>\n<td>实际在全局内存中内存</td>\n<td>线程私有</td>\n<td>中低（<span class=\"math inline\">\\(\\approx\\)</span>全局内存）</td>\n<td>大数组或寄存器不足时的溢出变量</td>\n<td>编译器自动分配</td>\n</tr>\n<tr>\n<td>全局内存</td>\n<td>GPU设备显存</td>\n<td>所有线程+主机</td>\n<td>中（400~800周期）</td>\n<td>大规模数据存储，需要频繁访问时需合并访问优化</td>\n<td><code>cudaMalloc</code>分配</td>\n</tr>\n<tr>\n<td>常量内存</td>\n<td>GPU芯片上的缓存</td>\n<td>所有线程只读</td>\n<td>中（缓存加速）</td>\n<td>需要广播给所有线程的至多</td>\n<td><code>__constant__</code></td>\n</tr>\n<tr>\n<td>纹理内存</td>\n<td>GPU专用缓存</td>\n<td>所有线程</td>\n<td>中 （优化访存）</td>\n<td>图形处理、具有空间局部性的非对齐访问</td>\n<td>纹理API绑定</td>\n</tr>\n<tr>\n<td>主机内存</td>\n<td>CPU内存</td>\n<td>主机+设备（需要拷贝）</td>\n<td>最低（PCLe瓶颈）</td>\n<td>CPU-GPU数据传输的中间存储</td>\n<td>malloc、cudaHostAlloc</td>\n</tr>\n</tbody>\n</table>\n<p>下面我将详细地介绍CUDA中各种内存管理函数的功能、参数和使用方法。</p>\n<p><strong>CUDA</strong>是一种用于异构并行计算的编程模型，经常需要在主机端（host）和设备端（Device）之间进行数据传输。这是因为CUDA核函数传入的必须是指向其中处理GPU显存的三个关键的API：<code>cudaMalloc</code>,<code>cudaMemcpy</code>和 <code>cudaFree</code>。</p>\n<ul>\n<li><code>cudaMalloc</code>：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">其接口API形式：</th>\n<th style=\"text-align: left;\">cudaError_t  cudaMalloc(void ** <em>devPtr</em>,size_t <em>size</em> )</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>函数功能：</strong></td>\n<td style=\"text-align: left;\"><strong>在设备上分配线性内存size字节，并通过指针返回分配的内存devPtr。分配的内存对应任何类型的变量。记忆没有被清除。失败时返回 cudaErrorMemoryAllocation。</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>参数：</strong></td>\n<td style=\"text-align: left;\"><strong><code>devPtr</code> 设备内存分配指针；<code>size</code> ：分配的字节数</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>返回值：</strong></td>\n<td style=\"text-align: left;\"><strong><code>cudaSuccess</code> , <code>cudaErrorMemoryAllocation</code></strong></td>\n</tr>\n</tbody>\n</table>\n<p>注意事项：</p>\n<p>分配的内存</p>\n<ul>\n<li>\n<p><code>cudaMemcpy</code> ：</p>\n<table>\n<thead>\n<tr>\n<th>其接口形式：</th>\n<th>cudaError_t cudaMemcpy(void * dist, const void * src,size_t count,CudaMemcpyKind kind)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>函数功能：</strong></td>\n<td><strong>将指向的内存区域的字节复制到指向的存储区域</strong></td>\n</tr>\n<tr>\n<td><strong>参数：</strong></td>\n<td><strong>dist-目的存储地址；src -源内存地址；count-复制内存的字节数； kind-传输类型</strong></td>\n</tr>\n<tr>\n<td><strong>返回值：</strong></td>\n<td><strong>cudaSuccess，cudaErrorInvalidValue，cudaErrorInvalidDevicePointer，cudaErrorInvalidMemcpyDirection</strong></td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>\n<p><code>cudaFree</code>：</p>\n<table>\n<thead>\n<tr>\n<th>其接口形式：</th>\n<th>cudaError_t cudaFree(void * devPtr)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>函数功能</strong>：</td>\n<td><strong>释放由 指向的内存空间，该空间必须是之前调用cudaMalloc()或cudaMallocPitch()时返回过的。否则，或者如果cudaFree()之前已被调用过，则返回错误。如果 为 0，则不执行作。cudaFree() 在失败时返回cudaErrorInvalidDevicePointer。</strong></td>\n</tr>\n<tr>\n<td><strong>参数:</strong></td>\n<td><strong><code>devPtr</code> -设备指针指向内存释放</strong></td>\n</tr>\n<tr>\n<td><strong>返回值：</strong></td>\n<td><strong>cudaSuccess，cudaErrorInvalidDevicePointer, cudaErrorInitialization</strong></td>\n</tr>\n</tbody>\n</table>\n<p>​</p>\n</li>\n</ul>\n<h2 id=\"12-cuda的第一个程序矩阵赋值matrix-assign\">1.2 CUDA的第一个程序—矩阵赋值(Matrix Assign)</h2>\n<p>​            在本节通过一个矩阵赋值（matrix Assign）例子开始真正的CUDA程序实现，本例是在SDK中template程序的基础上修改得到的。<span class=\"math inline\">\\(template\\)</span> 是 <span class=\"math inline\">\\(NVIDIA\\)</span> 公司提供的CUDA程序模板，也就是CUDA程序最基本的框架。要创建一个CUDA程序，可以把整个template文件复制一份。在一个CUDA程序中，基本的主机端代码主要完成以下的功能：</p>\n<ul>\n<li>启动CUDA，使用多卡时应该时应该加上设备号，或使用<span class=\"math inline\">\\(cudaSetDevice()\\)</span>设备GPU设备；</li>\n<li>为输入数据分配内存空间；</li>\n<li>初始化输入数据；</li>\n<li>为GPU分配内存，用于存放输入数据；</li>\n<li>将内存中的输入数据拷贝到显存；</li>\n<li>为GPU分配显存，用于存放输出数据；</li>\n<li>调用device端的kernel进行计算，将结果写到显存中的对应区域；</li>\n<li>为CPU分配内存，用于存放GPU传回来的输出数据；</li>\n<li>将显存中的结果读取到内存；</li>\n<li>释放内存和显存空间；</li>\n<li>退出CUDA；</li>\n</ul>\n<p>最简单的设备端代码主要完成以下功能：</p>\n<ul>\n<li>\n<p>从显存读取数据到GPU片内；</p>\n</li>\n<li>\n<p>对数据进行处理；</p>\n</li>\n<li>\n<p>将处理后的数据写回显存；</p>\n<p>其整个工程包含了三：</p>\n<p>（1）主程序文件CPU-Host端程序（example1main.cu）；</p>\n</li>\n</ul>\n<p>​       （2）GPU设备端函数的处理函数头文件（example_matrixassign_kernel.cuh）；</p>\n<p>​       （3）GPU设备端函数的处理函数文件（example_matrixassign_kernel.cu）；</p>\n<p>File1：主程序文件CPU-Host端程序（example1main.cu）；</p>\n<pre><code class=\"language-c\">#include&lt;stdio.h&gt; //系统头文件\n#include&lt;stdlib.h&gt;\n#include&lt;string.h&gt;\n#include&lt;math.h&gt;\n\n#include\"cuda_runtime.h\" //cuda项目头文件\n#include\"device_launch_parameters.h\"\n#include\"example_matrixassign_kernel.cuh\"  //核函数的数据的头文件\n\n\nvoid runTest(int argc, char** argv);\n\nint main(int argc,char** argv){\n\n\trunTest(argc,argv);\n\n}\n\nvoid runTest(int argc, char** argv){\n\n\tunsigned int num_blocks = 4;  //定义网格中的线程块数量\n\tunsigned int num_threads= 4;  //定义每个线程块中的线程数量\n\n\tunsigned int mem_size = sizeof(float) * num_blocks * num_threads; //为了数据分配的存储器大小，这里每一个人线程计算一个flaot\n\n\t//在host端分配内存，h_表示host端，i表示input，o表示output\n\tfloat* h_idata = nullptr;\n\tfloat* h_odata = nullptr;\n\n\th_idata =(float *)malloc(mem_size);\n\th_odata = (float*)malloc(mem_size);\n\n\tif(h_idata != nullptr) {\n\t   memset(h_idata, 0, mem_size);\n\t}else{\n\t\treturn;\n\t}\n\tif(h_odata!=nullptr){\n\t\tmemset(h_odata, 0, mem_size);\n\t}else{\n\t\treturn;\n\t}\n\t\n\t//在device端分配显存，d_表示device端，i表示input，o表示output\n\tfloat* d_idata = nullptr;\n\tfloat* d_odata = nullptr;\n\n\tcudaError_t cudaStatus;  //cuda状态判断\n\n\tcudaStatus=cudaMalloc((void**)&amp;d_idata, mem_size);\n\tif(cudaStatus != cudaSuccess){\n\t\tprintf(\"d_idata is cudaMalloc failed!\\n\");\n\t\treturn;\n\t}\n\tcudaStatus=cudaMalloc((void**)&amp;d_odata, mem_size);\n\tif(cudaStatus!=cudaSuccess){\n\t\tprintf(\"d_odata is cudaMalloc failed!\\n\");\n\t\treturn;\n\t}\n\t\n\t//初始化内存中的值\n\tfor(unsigned int i = 0; i &lt; num_threads * num_blocks;i++){\n\t\th_idata[i] =1.0f;\n\t}//end for(unsigned int i = 0; i &lt; num_threads * num_blocks;i++)\n\n\t//将内存中的输入数据读入设备端显存，这样就完成了主机对设备的数据写入\n\tcudaStatus=cudaMemcpy(d_idata,h_idata,mem_size,cudaMemcpyHostToDevice);\n\n\t//设置运行参数，即网格的形状和线程块的形状\n\tdim3 grid(num_blocks,1,1);\n\tdim3 block(num_threads,1,1);\n\n\t// 运行核函数，调用GPU进行运算\n\ttestMatrixAssignKernel &lt;&lt;&lt;grid, block&gt;&gt;&gt; (d_idata,d_odata);\n\n\t//将结果从显存写入内存\n\tcudaStatus = cudaMemcpy(h_odata,d_odata,mem_size,cudaMemcpyDeviceToHost);\n\n\t//打印结果\n\tprintf(\"赋值前的矩阵：\\n\");\n\tfor (unsigned int iblock = 0; iblock &lt; num_blocks; iblock++) {\n\t\tfor (unsigned int ithread = 0; ithread &lt; num_threads; ithread++) {\n\t\t\tprintf(\"%5.0f\", h_idata[iblock * num_threads + ithread]);\n\t\t}//end for(unsigned int ithread = 0; ithread &lt; num_threads; ithread++)\n\t\tprintf(\"\\n\");\n\t}//end for(unsigned int iblock = 0; iblock &lt; num_blocks; iblock++)\n\n\tprintf(\"赋值后的矩阵：\\n\");\n\tfor(unsigned int iblock = 0; iblock &lt; num_blocks; iblock++){\n\t\tfor(unsigned int ithread = 0; ithread &lt; num_threads; ithread++){\n\t\t\tprintf(\"%5.0f\",h_odata[iblock*num_threads+ithread]);\n\t\t}//end for(unsigned int ithread = 0; ithread &lt; num_threads; ithread++)\n\t\tprintf(\"\\n\");\n\t}//end for(unsigned int iblock = 0; iblock &lt; num_blocks; iblock++)\n\n\t//输出存储器指针\n\tfree(h_idata);\n\tfree(h_odata);\n\tcudaFree(d_idata);\n\tcudaFree(d_odata);\n}\n\n</code></pre>\n<p>从代码中看出，CUDA的主机端代码与C语言非常相似。但也有一部分C语言中没有的语句，下面逐一进行分析。</p>\n<p>​      （1）<code>cudaMalloc(size)</code>在显存global memory上分配大小为size字节的线性空间。需要注意的是，与malloc和free一样，cudaMalloc() 也必须与cudaFree()成对使用，否则无法释放显存空间，运行几次程序以后显卡上就没有显存可供分配，程序也就无法正常运行了。另外，为了杜绝指针指费的情况现象，最好在程序结束前将指针赋空并摧毁。</p>\n<p>​      （2） <code>cudaMemcpy()</code>用于拷贝存储器中的数据，其中第二参数是指向目标的指针，第二个参数是指向源的指针，第三个参数是需要拷贝的字节数，第四个参数是拷贝操作的类型。拷贝操作类型共有三种：</p>\n<ul>\n<li>cudaMemcpyDeviceToHost 将显存中的数据拷贝内存中；</li>\n<li>cudaMemcpyHostToDevice 将内存中的数据拷贝到显存中；</li>\n<li>cudaMemcpyDeviceToDevice将global memory中的数据拷贝到同一个CUDA上下文的global的另一个区域中；</li>\n</ul>\n<p>​      （3）<code>&lt;&lt;&lt;&gt;&gt;&gt;</code>运算符对kernel函数完整的执行参数配置形式是<code>&lt;&lt;&lt;Dg,Db,Ns,S&gt;&gt;&gt;</code>，其中各个参数的含义是：</p>\n<ul>\n<li>参数Dg用于定义整个grid的维度和尺寸，为dim3类型，但实际上只有前两维可以不为1。<code>Dim3 Dg(Dg.x,Dg.y,1)</code>中每行有Dg.x个block，每列有Dg.y个block的维度，第三维恒为1。</li>\n<li>参数Db为dim3类型，用于定义每个block的维度与尺寸。<code>Dim3 Db(Db.x,Db.y,Db.z)</code> 中每行有<code>Db.x</code>个thread，每列<code>Db.y</code>个thread，高为<code>Db.z</code>，可以定义三维尺寸。整个block中共有<code>Db.x*Db.y*Db.z</code> 个线程；</li>\n<li>参数Ns是一个可选参数，用于设置每个block的共享内存shared memory以外，最多能够动态分配的shared memory大小，单位为Byte。</li>\n<li>参数<span class=\"math inline\">\\(s\\)</span>是一个cudaStream_t类型的可选参数，初始值为0。在本案例中没有用到Stream的相关内容因此这个参数不填，默认为0号流。</li>\n</ul>\n<p>File2：主程序文件CPU-Host端程序（example1main.cu）；</p>\n<p>​</p>\n<pre><code class=\"language-c\">\n#pragma once\n#ifndef EXAMPLE_MATRIXASSIGN_KERNEL_H\n#define EXAMPLE_MATRIXASSIGN_KERNEL_H\n\n#include&lt;stdio.h&gt;\n#include\"cuda_runtime.h\"\n\n__global__ void testMatrixAssignKernel(float* data_input, float* data_output);\n\n\n#endif // !_EXAMPLE_MATRIXASSIGN_KERNEL_H_\n</code></pre>\n<p>File2：主程序文件CPU-Host端程序（example1main.cu）；</p>\n<pre><code class=\"language-C\">\n__global__ void testMatrixAssignKernel(float *data_input,float *data_output){\n\n\t//shared memory,extern表示大小由host端的Ns参数确定\n\textern __shared__ float sdata[];\n\n\tconst unsigned int bid = blockIdx.x; //线程所在的block的索引号\n\tconst unsigned int tid_in_block = threadIdx.x; //线程在block中的位置\n\tconst unsigned int tid_in_grid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t//按行划分任务时，线程在整个grid中的位置\n\n  // 将数据从global memory读入shared memory\n\tsdata[tid_in_block] = data_input[tid_in_grid];\n\t//读入数据后进行一次同步，保证计算时所有数据均已到位\n\t__syncthreads();\n\n\t// 计算\n\tsdata[tid_in_block] = (float)tid_in_grid;\n\t//  sdata[tid_in_block] *= (float)tid_in_block;\n\t//  sdata[tid_in_block] *= (float)tid_in_grid;\n\n\t  //进行同步，确保要写入的数据已经被更新\n\t__syncthreads();\n\n\t// 将shared memory中的数据写到global memory\n\tdata_output[tid_in_grid] = sdata[tid_in_block];\n\n\n}\n</code></pre>\n<p>由上可知，最简单的<code>__gloabal__</code>程序由以下的过程组成：</p>\n<ol>\n<li>分配<span class=\"math inline\">\\(shared \\space memory\\)</span>；</li>\n<li>将<span class=\"math inline\">\\(global\\space memory\\)</span> 中的数据读入<span class=\"math inline\">\\(shared \\space memory\\)</span>;</li>\n<li>将进行计算，将结果写到<span class=\"math inline\">\\(shared \\space memory\\)</span>;</li>\n<li>将<span class=\"math inline\">\\(shared\\)</span>中的结果写到<span class=\"math inline\">\\(global \\space memory\\)</span> ;</li>\n</ol>\n<p>​         进行一次GPU计算，要在多种存储器进行几次数据传输，要消耗相当多的时间。这导致了较大的延迟，这导致使<span class=\"math inline\">\\(GPU\\)</span> 不适合处理一些实时性要求很高的应用。不同存储器间的数据传输速率和使用方法有很大差异，开发人员需要根据硬件的特点来设计算法，以优化存储器访问。在理想情况下，在所有的存储器传输进行的同时，GPU的各个核心也始终在进行计算，这样就能够很好的隐藏各种访问延迟。CUDA 并不是一种完全硬件透明的语言，程序员需要根据硬件特征将任务进行合理的分解，在编程时对数据传输和寄存器访问进行优化。</p>\n<p>​       <code>__global__</code>前缀表示这一段代码是cuda GPU端内核函数。内核函数运行在设备上，其返回类型必须为void。<code>__global__</code>函数中是每一个线程要执行的语句，但由于<span class=\"math inline\">\\(shared\\space memory\\)</span>和同步的存在，在最好将<code>__global__</code>函数理解为对每一个block的行为的描述。</p>\n<p>​        在这一端内核函数中，首先定义了<span class=\"math inline\">\\(shared \\space memory\\)</span> 中的变量；然后根据内建变量定义每一个block和thread的索引，对任务进行划分；最后，每一个线程执行了相同的求和运算，但处理数据不同，由线程的索引决定的。程序员在编写<code>__global__</code>函数之前，要先对任务进行划分，设计各个block的工作流程后，做到成竹在胸。</p>\n<p>​        由于CUDA采用了两层并行，因此本例在划分任务时，每个thread在grid中的索引<span class=\"math inline\">\\(tid\\_in\\_grid\\)</span> 是由thread所在block内编号tid计算得来的。计算出每个线程的索引后，就可以根据索引处理线程中不同的数据，请读者好好体会这一点。</p>\n<p>​      <code>extern __shared__ float sdata[]</code> 在shared  memory中为数组data动态分配了空间。<code>extern</code> 在设备端和主机端有不同的含义：<code>__device__</code>和<code>__global__</code> 函数中表示动态分配，而在主机端函数中表示外部变量。如果要静态分配一块 <code>shared memory</code>，那么在<code>__shared__</code>之前就不加<code>extern</code>，还必须在[]中写上要分配的字节数。动态分配的shared memory大小，是&lt;&lt;&lt;&gt;&gt;&gt;的执行参数中第三个参数规定的大小。关于<code>shared memory</code>大小。</p>\n<p>​        CUDA定义了一些内建变量如下：</p>\n<ol>\n<li>gridDim： 网格的维度的变量，dim3类型</li>\n<li>blockIdx:    块的索引变量，unit3类型</li>\n<li>blockDim：块的维度变量，dim3类型</li>\n<li>threadIdx：块内的线程索引变量，unit3类型</li>\n<li>warpSize：线程中的warp大小，int类型</li>\n</ol>\n<p>其输出结果：</p>\n<p><img alt=\"输出结果\" class=\"lazyload\" /></p>\n<p>​</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 18:33</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">7</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET 10 New feature 新增功能介绍-WebSocket功能增强",
      "link": "https://www.cnblogs.com/tianqing/p/19439916",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tianqing/p/19439916\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 14:02\">\n    <span>.NET 10 New feature 新增功能介绍-WebSocket功能增强</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>今天整理了.NET 10类库新增的几个常用功能，按老规矩，分享给大家：</p>\n<div>\n<p>.NET 10 新增了&nbsp;<a class=\"no-loc\" href=\"https://learn.microsoft.com/zh-cn/dotnet/api/system.net.websockets.websocketstream\" rel=\"noopener nofollow\">WebSocketStream</a>一个新的 API，用于简化 .NET 中一些最常见的<a class=\"no-loc\" href=\"https://learn.microsoft.com/zh-cn/dotnet/api/system.net.websockets.websocket\" rel=\"noopener nofollow\">WebSocket</a>&nbsp;的流式处理方案。</p>\n<p>传统&nbsp;<code>WebSocket</code>&nbsp;API 级别较低，需要大量的代码：处理缓冲和框架、重建消息、管理编码/解码以及编写自定义包装器以与流、通道或其他传输抽象集成。</p>\n<p>这些复杂性使得很难将 WebSocket 用作传输，尤其是对于具有流式处理或基于文本的协议或事件驱动的处理程序的应用。</p>\n<p><code>WebSocketStream</code>&nbsp;通过提供&nbsp;<a class=\"no-loc\" href=\"https://learn.microsoft.com/zh-cn/dotnet/api/system.io.stream\" rel=\"noopener nofollow\">Stream</a>基于 WebSocket 的抽象来解决这个难题。</p>\n<p>这样就可以与现有 API 无缝集成，以便读取、写入和分析数据，无论是二进制数据还是文本，并减少了手动管道的需求。</p>\n<p><code>WebSocketStream</code>&nbsp;为常见的 WebSocket 生产环境应用启用了高级高阶API。</p>\n<p class=\"p1\"><strong>WebSocketStream 到底解决了什么问题</strong></p>\n<p>在 .NET 10 之前：</p>\n<ul>\n<li>\n<p class=\"p1\">System.Net.WebSockets.WebSocket</p>\n<ul>\n<li>\n<p class=\"p1\"><strong>消息模型（Message-based）</strong></p>\n</li>\n<li>\n<p class=\"p1\">必须自己处理：</p>\n<ul>\n<li>\n<p class=\"p1\">分片（Fragment）</p>\n</li>\n<li>\n<p class=\"p1\">消息边界</p>\n</li>\n<li>\n<p class=\"p1\">循环 Receive / Send</p>\n</li>\n</ul>\n</li>\n<li>\n<p class=\"p1\"><strong>无法像 Stream 一样统一抽象</strong></p>\n</li>\n</ul>\n</li>\n</ul>\n<p class=\"p3\">结果是：</p>\n<ul>\n<li>\n<p class=\"p1\">WebSocket 写法 <span class=\"s1\"><strong>复杂、重复、易错</strong></span></p>\n</li>\n<li>\n<p class=\"p1\">很难和现有 <span class=\"s1\"><strong>Stream 生态</strong>（压缩、加密、管道、序列化）整合</span></p>\n</li>\n<li>\n<p class=\"p1\">WebSocket 和 TCP / NamedPipe / HTTP Body 的编程模型割裂</p>\n</li>\n</ul>\n<p class=\"p1\">&nbsp;<strong>WebSocketStream 的本质变化</strong></p>\n<p>&nbsp;<span class=\"s2\">.NET 10 提供的 WebSocketStream<span class=\"s2\">：</span></span></p>\n<blockquote><strong>把 WebSocket 连接抽象为一个真正的 Stream</strong></blockquote>\n<p class=\"p5\">这意味着：</p>\n<ul>\n<li>\n<p class=\"p1\">不再关心消息帧、分片、边界</p>\n</li>\n<li>\n<p class=\"p1\">可以直接：</p>\n<ul>\n<li>\n<p class=\"p1\">ReadAsync</p>\n</li>\n<li>\n<p class=\"p1\">WriteAsync</p>\n</li>\n</ul>\n</li>\n<li>\n<p class=\"p1\">能无缝接入：</p>\n<ul>\n<li>\n<p class=\"p1\">PipeReader / PipeWriter</p>\n</li>\n<li>\n<p class=\"p1\">System.IO.Stream<span class=\"s1\"> 全套中间件</span></p>\n</li>\n</ul>\n<p>&nbsp;<span class=\"s2\">这是一次<strong>模型级升级，而不是语法糖</strong><span class=\"s2\">。</span></span></p>\n</li>\n</ul>\n<p>&nbsp;给出一个示例代码：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Streaming binary protocol (for example, AMQP).</span>\nStream transportStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.Create(\n    connectedWebSocket,\n    WebSocketMessageType.Binary,\n    closeTimeout: TimeSpan.FromSeconds(</span><span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\">));\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> message.SerializeToStreamAsync(transportStream, cancellationToken);\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> receivePayload = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> <span style=\"color: rgba(0, 0, 255, 1);\">byte</span><span style=\"color: rgba(0, 0, 0, 1);\">[payloadLength];\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> transportStream.ReadExactlyAsync(receivePayload, cancellationToken);\ntransportStream.Dispose();\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> `Dispose` automatically handles closing handshake.</span></pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"streaming-text-protocol-for-example-stomp\">流式处理文本协议（例如 STOMP）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Streaming text protocol (for example, STOMP).</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">using</span> Stream transportStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.Create(\n    connectedWebSocket, \n    WebSocketMessageType.Text,\n    ownsWebSocket: </span><span style=\"color: rgba(0, 0, 255, 1);\">true</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Integration with Stream-based APIs.\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Don't close the stream, as it's also used for writing.</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">using</span> <span style=\"color: rgba(0, 0, 255, 1);\">var</span> transportReader = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> StreamReader(transportStream, leaveOpen: <span style=\"color: rgba(0, 0, 255, 1);\">true</span><span style=\"color: rgba(0, 0, 0, 1);\">); \n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> line = <span style=\"color: rgba(0, 0, 255, 1);\">await</span> transportReader.ReadLineAsync(cancellationToken); <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Automatic UTF-8 and new line handling.</span>\ntransportStream.Dispose(); <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Automatic closing handshake handling on `Dispose`.</span></pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"streaming-binary-protocol-for-example-amqp\">流式处理二进制协议（例如 AMQP）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Streaming binary protocol (for example, AMQP).</span>\nStream transportStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.Create(\n    connectedWebSocket,\n    WebSocketMessageType.Binary,\n    closeTimeout: TimeSpan.FromSeconds(</span><span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\">));\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> message.SerializeToStreamAsync(transportStream, cancellationToken);\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> receivePayload = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> <span style=\"color: rgba(0, 0, 255, 1);\">byte</span><span style=\"color: rgba(0, 0, 0, 1);\">[payloadLength];\n</span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> transportStream.ReadExactlyAsync(receivePayload, cancellationToken);\ntransportStream.Dispose();\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> `Dispose` automatically handles closing handshake.</span></pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"read-a-single-message-as-a-stream-for-example-json-deserialization\">以流形式读取单个消息（例如 JSON 反序列化）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Text.Json;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Reading a single message as a stream (for example, JSON deserialization).</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">using</span> Stream messageStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.CreateReadableMessageStream(connectedWebSocket, WebSocketMessageType.Text);\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> JsonSerializer.DeserializeAsync reads until the end of stream.</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> appMessage = <span style=\"color: rgba(0, 0, 255, 1);\">await</span> JsonSerializer.DeserializeAsync&lt;AppMessage&gt;(messageStream);</pre>\n</div>\n<h5 class=\"heading-anchor\" id=\"write-a-single-message-as-a-stream-for-example-binary-serialization\">将单个消息编写为流（例如，二进制序列化）</h5>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.IO;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.WebSockets;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading;\n</span><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Threading.Tasks;\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Writing a single message as a stream (for example, binary serialization).</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">async</span><span style=\"color: rgba(0, 0, 0, 1);\"> Task SendMessageAsync(AppMessage message, CancellationToken cancellationToken)\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">using</span> Stream messageStream =<span style=\"color: rgba(0, 0, 0, 1);\"> WebSocketStream.CreateWritableMessageStream(_connectedWebSocket, WebSocketMessageType.Binary);\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (ReadOnlyMemory&lt;<span style=\"color: rgba(0, 0, 255, 1);\">byte</span>&gt; chunk <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> message.SplitToChunks())\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> messageStream.WriteAsync(chunk, cancellationToken);\n    }\n} </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> EOM sent on messageStream.Dispose().</span></pre>\n</div>\n<p>总结：<strong>WebSocketStream 的真实应用场景</strong></p>\n<p><strong>场景一：实时数据流（Streaming Data）</strong></p>\n<p><strong>典型业务</strong></p>\n<ul>\n<li>\n<p class=\"p1\">充电站实时状态推送（功率、电流、电压）</p>\n</li>\n<li>\n<p class=\"p1\">实时监控大屏（指标流）</p>\n</li>\n<li>\n<p class=\"p1\">行情 / 订单流</p>\n</li>\n<li>\n<p class=\"p1\">日志 / Trace 实时订阅</p>\n</li>\n</ul>\n<p>&nbsp;<strong>使用 WebSocketStream 后</strong>WebSocket = <span class=\"s2\"><strong>一条持续的数据流</strong></span></p>\n<p class=\"p1\">&nbsp;<strong>场景二：AI / LLM 实时输出（Token Streaming）</strong></p>\n<p>&nbsp;<strong>典型业务</strong></p>\n<ul>\n<li>\n<p class=\"p1\">大模型推理流式返回</p>\n</li>\n<li>\n<p class=\"p1\">Copilot / Chat / Agent 推理过程</p>\n</li>\n<li>\n<p class=\"p1\">SSE + WebSocket 混合方案</p>\n</li>\n</ul>\n<p>&nbsp;<strong>场景三：大文件 / 二进制流实时传输</strong></p>\n<p>using var file = File.OpenRead(path);<br />await file.CopyToAsync(webSocketStream);</p>\n<p class=\"p1\">&nbsp;更像 TCP，但仍是 WebSocket</p>\n<p class=\"p1\">&nbsp;<strong>场景四：RPC / 协议隧道（Protocol Tunneling）</strong></p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">可以直接跑 <strong>已有 Stream 协议</strong></span></p>\n<ul>\n<li>\n<p class=\"p1\">gRPC-like</p>\n</li>\n<li>\n<p class=\"p1\">自定义 framing</p>\n</li>\n<li>\n<p class=\"p1\">设备通信协议</p>\n</li>\n</ul>\n<p>&nbsp;&nbsp;await protocolHandler.RunAsync(webSocketStream);</p>\n</li>\n</ul>\n<p><strong>场景五：与 System.IO.Pipelines 深度整合</strong></p>\n<p><strong>构建</strong><strong>高性能服务端</strong></p>\n<p>var reader = PipeReader.Create(webSocketStream);<br />var writer = PipeWriter.Create(webSocketStream);</p>\n<ul>\n<li>\n<p class=\"p1\">用 Pipelines 做：</p>\n<ul>\n<li>\n<p class=\"p1\">高性能解析</p>\n</li>\n<li>\n<p class=\"p1\">零拷贝处理</p>\n</li>\n</ul>\n</li>\n<li>\n<p class=\"p1\">和 Kestrel / gRPC / 自研协议一致</p>\n</li>\n</ul>\n<p class=\"p1\">&nbsp;<strong>适合：</strong></p>\n<ul>\n<li>\n<p class=\"p1\">高频实时通信</p>\n</li>\n<li>\n<p class=\"p1\">百万级连接服务</p>\n</li>\n<li>\n<p class=\"p1\">核心中枢服务</p>\n</li>\n</ul>\n<p>&nbsp;以上总结，分享给大家。</p>\n<p>&nbsp;</p>\n<p>周国庆</p>\n<p>2026/1/5</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 14:02</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tianqing\">Eric zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">208</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从安装到上线：一份 Nginx 实战指南，让你的 Web 应用稳建安全",
      "link": "https://www.cnblogs.com/ymtianyu/p/19442584",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19442584\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 13:40\">\n    <span>从安装到上线：一份 Nginx 实战指南，让你的 Web 应用稳建安全</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        这是一份面向开发者和运维新手的 Nginx 实战指南。文章详细讲解了在 Windows 和 Linux 系统下安装配置 Nginx 的步骤，提供了核心的安全加固配置，并重点演示了如何将 Nginx 作为反向代理与 Flask 或 FastAPI 等 Python Web 应用结合部署。同时，文中总结了常见的错误与排查方法，帮助你快速上手并避免常见陷阱。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>你有没有遇到过网站突然变卡，或者千辛万苦写好的 Flask/FastAPI 应用，却不知道怎么优雅地部署到公网？今天，我们就来聊聊那个在背后默默支撑全球近三分之一活跃网站的“无名英雄”——Nginx。</p>\n<p>对于很多开发者和运维新手来说，Nginx 的配置常常让人头疼：安装报错、配置文件复杂、安全设置无从下手……别担心，作为你的老朋友，这篇指南将用最直白的语言，带你从零开始，彻底搞定 Nginx 的安装、配置和实战应用。🎯</p>\n<hr />\n<h2>🎯 本文摘要</h2>\n<p>本文是一份面向实践的 Nginx 综合指南。你将系统学习到如何在 Windows 和 Linux 系统上安装与配置 Nginx，掌握核心的安全加固技巧，并学会将 Nginx 与 Flask 或 FastAPI 等 Python Web 框架无缝结合，用于生产环境部署。同时，文中提供了常见问题的排查思路，帮助你快速定位和解决难题。</p>\n<hr />\n<h2>🚀 Nginx：不只是个“发文件的”</h2>\n<p>很多人初识 Nginx，以为它只是个高性能的静态文件服务器。其实，它更像一个<strong style=\"color: rgba(186, 55, 42, 1);\">万能的“接线员”或“交通警察”</strong>。它能处理并发连接（事件驱动、异步非阻塞），能做反向代理（把你后端的应用“藏”起来），能负载均衡（把流量合理分发给多个后端），还能缓存内容、压缩数据、终结 SSL 加密……</p>\n<p>理解这一点，再看它的配置文件，你就会明白那些 <code style=\"color: rgba(186, 55, 42, 1);\">location</code>、<code style=\"color: rgba(186, 55, 42, 1);\">proxy_pass</code> 指令都是在指挥“交通”。</p>\n<hr />\n<h2>🔧 第一部分：安装与配置（Windows &amp; Linux）</h2>\n<h3>1. Linux 下安装（以 Ubuntu/Debian 为例）</h3>\n<p>Linux 是 Nginx 的主战场，安装最简单。</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 1. 更新包列表\nsudo apt update\n\n# 2. 安装 Nginx\nsudo apt install nginx -y\n\n# 3. 启动并设置开机自启\nsudo systemctl start nginx\nsudo systemctl enable nginx\n\n# 4. 检查状态\nsudo systemctl status nginx</code></pre>\n<p>安装完成后，浏览器访问你的服务器 IP，看到“Welcome to nginx!”页面，就说明成功了。</p>\n<h3>2. Windows 下安装</h3>\n<p>Windows 下通常用于开发测试。直接从官网下载压缩包：</p>\n<ul>\n<li>访问 <a href=\"https://nginx.org/en/download.html\" rel=\"noopener nofollow\">nginx.org/en/download.html</a></li>\n<li>下载 <code style=\"color: rgba(186, 55, 42, 1);\">nginx/Windows-x.x.x</code> 版本</li>\n<li>解压到任意目录（<strong style=\"color: rgba(186, 55, 42, 1);\">路径不要有中文或空格！</strong>）</li>\n</ul>\n<p>启动方法：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 进入解压目录，打开命令行\ncd C:\\你的路径\\nginx-1.xx.x\nstart nginx          # 启动（窗口一闪而过是正常的）\nnginx.exe -s stop    # 快速停止\nnginx.exe -s quit    # 优雅停止（处理完当前请求）\nnginx.exe -s reload  # 重新加载配置（最常用！）</code></pre>\n<p>如果启动后，未能正常访问，可查看解压后目录下的<code>logs</code>文件夹下日志记录以排查错误原因，如：80端口占用等</p>\n<hr />\n<h2>⚙️ 第二部分：核心配置与安全设置</h2>\n<p>Nginx 的核心是配置文件，通常位于：</p>\n<ul>\n<li>Linux: <code style=\"color: rgba(186, 55, 42, 1);\">/etc/nginx/nginx.conf</code></li>\n<li>Windows: <code style=\"color: rgba(186, 55, 42, 1);\">conf/nginx.conf</code></li>\n</ul>\n<h3>🎯 基础安全加固（必做项！）</h3>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># 在 http{ } 或 server{ } 块中添加\n\n# 1. 隐藏 Nginx 版本号（避免信息泄露）\nserver_tokens off;\n\n# 2. 设置安全头部（防止一些常见 Web 攻击）\nadd_header X-Frame-Options \"SAMEORIGIN\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\n\n# 3. 限制请求方法（只允许常用的）\nif ($request_method !~ ^(GET|HEAD|POST)$ ) {\n    return 405;\n}\n\n# 4. 限制客户端请求体大小（防文件上传攻击）\nclient_max_body_size 10m;</code></pre>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">警告：</strong>修改配置文件后，务必使用 <code style=\"color: rgba(186, 55, 42, 1);\">nginx -t</code> 测试语法，确认无误后再 <code style=\"color: rgba(186, 55, 42, 1);\">nginx -s reload</code> 重载配置。</p>\n<hr />\n<h2>🚀 第三部分：与 Flask / FastAPI 结合（实战演示）</h2>\n<p>这是 Python 开发者最关心的部分。我们通常<strong style=\"color: rgba(186, 55, 42, 1);\">不直接让 Nginx 运行 Python</strong>，而是让 Nginx 作为<strong style=\"color: rgba(186, 55, 42, 1);\">反向代理</strong>，将动态请求转发给后端的 Python 应用服务器（如 Gunicorn 或 Uvicorn）。</p>\n<h3>🎯 部署架构图</h3>\n<p><span style=\"color: rgba(224, 62, 45, 1);\"><strong>用户 → Nginx (80/443端口) → 反向代理 → Gunicorn/Uvicorn (本地某个端口，如 8000) → 你的 Flask/FastAPI 应用</strong></span></p>\n<h3>1. 准备你的 Python 应用</h3>\n<p>假设你有一个 FastAPI 应用 <code style=\"color: rgba(186, 55, 42, 1);\">main.py</code>：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code># main.py\nfrom fastapi import FastAPI\napp = FastAPI()\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}</code></pre>\n<p>使用 Uvicorn 启动它（监听本机 8000 端口）：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>uvicorn main:app --host 127.0.0.1 --port 8000</code></pre>\n<h3>2. 配置 Nginx 反向代理</h3>\n<p>在 <code style=\"color: rgba(186, 55, 42, 1);\">/etc/nginx/sites-available/</code>（Linux）或 <code style=\"color: rgba(186, 55, 42, 1);\">conf/</code> 目录下（Windows），创建一个配置文件，如 <code style=\"color: rgba(186, 55, 42, 1);\">myapp.conf</code>：<br />（建议直接复制<code>nginx.conf</code>建立复本，然后修改指定<code>server</code>部分即可，以防止未知的语法错误，如：分号缺失等）</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>server {\n    listen 80; # 监听80端口（HTTP）\n    server_name your_domain.com; # 你的域名或服务器IP\n\n    # 静态文件（可选，Nginx直接处理效率更高）\n    location /static {\n        alias /path/to/your/static/files;\n        expires 30d;\n    }\n\n    # 动态请求，全部代理给后端的 FastAPI 应用\n    location / {\n        # 后端应用服务器的地址\n        proxy_pass http://127.0.0.1:8000;\n\n        # 以下是关键代理设置，确保信息正确传递\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # 超时设置\n        proxy_connect_timeout 60s;\n        proxy_read_timeout 60s;\n    }\n}</code></pre>\n<p>在 Linux 上，需要创建符号链接启用该配置：</p>\n<pre class=\"highlighter-hljs\" style=\"background-color: rgba(246, 248, 250, 1); padding: 15px; border-radius: 5px;\"><code>sudo ln -s /etc/nginx/sites-available/myapp.conf /etc/nginx/sites-enabled/\nsudo nginx -t\nsudo systemctl reload nginx</code></pre>\n<p>在 Windows 上，同样需要重新指定配置文件路径：</p>\n<pre class=\"language-bash highlighter-hljs\"><code>.\\nginx.exe -t -c .\\conf\\myapp.conf\n.\\nginx.exe -s reload</code></pre>\n<p>现在，访问你的服务器 IP 或域名，Nginx 就会把请求透明地转发给运行在 8000 端口的 FastAPI 应用了！Flask 应用配置方法完全一致。</p>\n<hr />\n<h2>⚠️ 第四部分：常见问题与排查（踩坑指南）</h2>\n<h3>1. 访问出现 502 Bad Gateway</h3>\n<ul>\n<li><strong style=\"color: rgba(186, 55, 42, 1);\">原因99%：</strong>后端应用（Gunicorn/Uvicorn）没启动，或者端口没对上。</li>\n<li><strong>排查：</strong>检查后端服务是否在运行 (<code style=\"color: rgba(186, 55, 42, 1);\">ps aux | grep uvicorn</code>)，并确认 <code style=\"color: rgba(186, 55, 42, 1);\">proxy_pass</code> 的地址和端口是否正确。</li>\n</ul>\n<h3>2. 403 Forbidden</h3>\n<ul>\n<li><strong>排查：</strong>检查 Nginx 进程用户（通常是 <code style=\"color: rgba(186, 55, 42, 1);\">www-data</code> 或 <code style=\"color: rgba(186, 55, 42, 1);\">nginx</code>）是否有权限读取你配置的静态文件或目录。</li>\n</ul>\n<h3>3. 静态文件加载不了，CSS/JS 失效</h3>\n<ul>\n<li><strong>排查：</strong>检查 <code style=\"color: rgba(186, 55, 42, 1);\">location /static</code> 的 <code style=\"color: rgba(186, 55, 42, 1);\">alias</code> 路径是否正确，以及文件是否存在。</li>\n</ul>\n<h3>4. 配置修改后不生效</h3>\n<ul>\n<li><strong>牢记流程：</strong>改配置 → <code style=\"color: rgba(186, 55, 42, 1);\">nginx -t</code> 测试 → <code style=\"color: rgba(186, 55, 42, 1);\">nginx -s reload</code> 重载。</li>\n<li>如果还不生效，尝试重启 Nginx 服务，并检查错误日志：<code style=\"color: rgba(186, 55, 42, 1);\">tail -f /var/log/nginx/error.log</code>。</li>\n</ul>\n<hr />\n<h2>💎 总结与升华</h2>\n<p>Nginx 的学习曲线看似陡峭，但一旦理解了它的“交通警察”角色和配置文件的块结构（<code style=\"color: rgba(186, 55, 42, 1);\">http{}</code>, <code style=\"color: rgba(186, 55, 42, 1);\">server{}</code>, <code style=\"color: rgba(186, 55, 42, 1);\">location{}</code>），很多问题都会迎刃而解。</p>\n<p>记住，<strong style=\"color: rgba(186, 55, 42, 1);\">最好的学习方式是动手</strong>。先在本地虚拟机或测试环境折腾，从最简单的静态服务开始，再到反向代理一个本地应用，逐步加上 SSL（HTTPS）、负载均衡等高级功能。</p>\n<p>技术之路，坑总是要踩的。但希望我这篇“老友记”式的分享，能为你点亮一盏灯，让你在摸爬滚打时，少一分迷茫，多一份从容。如果在实践中遇到新问题，随时可以再来聊聊，咱们一起探讨。</p>\n<p>祝你配置顺利，上线大吉！🚀</p>\n<p style=\"text-align: center;\">---<strong>写在最后</strong>---<br />希望这份总结能帮你避开一些坑。如果觉得有用，不妨点个 赞👍 或 收藏⭐ 标记一下，方便随时回顾。也欢迎关注我，后续为你带来更多类似的实战解析。有任何疑问或想法，我们评论区见，一起交流开发中的各种心得与问题。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 13:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">220</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "使用 C# 和 SQL Server 自动化邮件中的用户分配数据处理",
      "link": "https://www.cnblogs.com/powertoolsteam/p/19444281",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/powertoolsteam/p/19444281\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 18:09\">\n    <span>使用 C# 和 SQL Server 自动化邮件中的用户分配数据处理</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"引言\">引言</h2>\n<p>在金融应用领域，通过电子邮件手动管理用户分配数据不仅耗时而且容易出错。传统的人工处理方式需要工作人员每天检查邮件、下载附件、解析数据并更新数据库，这一系列重复性工作既低效又存在数据录入错误的风险。本文将介绍如何利用 C# 和 SQL Server 构建一个自动化解决方案，实现从邮件读取、附件下载到数据库更新的全流程自动化处理。该系统特别适用于处理主题包含\"AllotmentsFiles\"的邮件，并更新 SQL Server 中的 bidfiledetails 表，显著提高数据处理效率和准确性。</p>\n<h2 id=\"正文内容\">正文内容</h2>\n<h3 id=\"1-系统概述与优势\">1. 系统概述与优势</h3>\n<h4 id=\"11-处理流程\">1.1 处理流程</h4>\n<p>该自动化系统主要包含三个核心处理步骤：</p>\n<ol>\n<li><strong>连接邮件服务器</strong>：使用 POP3 协议连接到邮件服务器，支持 Gmail 等常见邮件服务提供商。</li>\n<li><strong>筛选目标邮件</strong>：自动筛选出当天收到的、主题包含\"AllotmentsFiles\"的邮件。</li>\n<li><strong>处理附件并更新数据库</strong>：下载邮件中的 CSV 附件，解析内容并更新 SQL Server 数据库中的分配数据。</li>\n</ol>\n<h4 id=\"12-系统优势\">1.2 系统优势</h4>\n<ul>\n<li><strong>自动化重复工作</strong>：取代人工检查邮件和处理附件的过程</li>\n<li><strong>减少人为错误</strong>：自动化的数据处理流程避免了手工录入可能导致的错误</li>\n<li><strong>全天候运行</strong>：系统可配置为每日自动运行，无需人工干预</li>\n<li><strong>高效数据处理</strong>：批量处理大量分配数据，显著提高工作效率</li>\n</ul>\n<h3 id=\"2-开发环境与工具配置\">2. 开发环境与工具配置</h3>\n<h4 id=\"21-所需工具\">2.1 所需工具</h4>\n<ul>\n<li><strong>开发工具</strong>：Visual Studio（C#）</li>\n<li><strong>数据库</strong>：SQL Server</li>\n<li><strong>NuGet 包</strong>：\n<ul>\n<li>OpenPop.NET：用于通过 POP3 协议读取邮件</li>\n<li>System.Data.SqlClient：用于数据库连接和操作</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"22-配置设置\">2.2 配置设置</h4>\n<p>系统配置存储在 web.config 文件中，包含邮件服务器连接信息：</p>\n<pre><code class=\"language-xml\">&lt;appSettings&gt;\n  &lt;add key=\"HostServer\" value=\"pop.gmail.com\" /&gt;\n  &lt;add key=\"MailPort\" value=\"995\" /&gt;\n  &lt;add key=\"MailUser\" value=\"your-email@gmail.com\" /&gt;\n  &lt;add key=\"MailPwd\" value=\"your-password\" /&gt;\n&lt;/appSettings&gt;\n</code></pre>\n<p>此配置允许灵活更改邮件服务器设置而无需修改代码。</p>\n<h3 id=\"3-邮件处理核心代码实现\">3. 邮件处理核心代码实现</h3>\n<h4 id=\"31-读取邮件功能\">3.1 读取邮件功能</h4>\n<p>以下 C# 代码实现了从邮件服务器读取并处理目标邮件的功能：</p>\n<pre><code class=\"language-csharp\">public void ReadTheDataFromTheMail()\n{\n    try\n    {\n        string mailHost = ConfigurationManager.AppSettings[\"HostServer\"];\n        int mailPort = Convert.ToInt32(ConfigurationManager.AppSettings[\"MailPort\"]);\n        string mailID = ConfigurationManager.AppSettings[\"MailUser\"];\n        string mailPwd = ConfigurationManager.AppSettings[\"MailPwd\"];\n\n        using (Pop3Client client = new Pop3Client())\n        {\n            client.Connect(mailHost, mailPort, true);\n            client.Authenticate(mailID, mailPwd);\n\n            int messageCount = client.GetMessageCount();\n            DateTime today = DateTime.UtcNow.Date;\n\n            for (int i = messageCount; i &gt; 0; i--)\n            {\n                MessageHeader headers = client.GetMessageHeaders(i);\n                string subject = headers.Subject;\n                DateTime emailDate = headers.DateSent;\n\n                if (!string.IsNullOrEmpty(subject) &amp;&amp; subject.Contains(\"AllotmentsFiles\") &amp;&amp; emailDate.Date == today)\n                {\n                    OpenPop.Mime.Message message = client.GetMessage(i);\n\n                    foreach (var attachment in message.FindAllAttachments())\n                    {\n                        if (attachment.FileName.Contains(\"AllotmentsFiles_\") &amp;&amp; attachment.FileName.EndsWith(\".csv\"))\n                        {\n                            string baseDirectory = @\"E:\\Allotment - Applns\\Allotmentfiles\";\n                            string dateFolder = DateTime.Now.ToString(\"yyyy-MM-dd\");\n                            string fileFolder = Path.Combine(baseDirectory, dateFolder);\n\n                            if (!Directory.Exists(fileFolder))\n                                Directory.CreateDirectory(fileFolder);\n\n                            string filePath = Path.Combine(fileFolder, attachment.FileName);\n                            File.WriteAllBytes(filePath, attachment.Body);\n\n                            errorlog($\"CSV file '{attachment.FileName}'\", \"Downloaded successfully!\");\n                            ProcessAllotmentData(filePath);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    catch (Exception ex)\n    {\n        errorlog(\"Error reading emails\", ex.Message);\n    }\n}\n</code></pre>\n<p>这段代码实现了以下功能：</p>\n<ol>\n<li>从配置读取邮件服务器连接信息</li>\n<li>使用 POP3 连接到邮件服务器</li>\n<li>筛选当天且主题包含\"AllotmentsFiles\"的邮件</li>\n<li>下载符合条件的 CSV 附件并保存到按日期组织的文件夹中</li>\n<li>调用数据处理方法处理下载的附件</li>\n</ol>\n<h3 id=\"4-csv数据处理与数据库更新\">4. CSV数据处理与数据库更新</h3>\n<h4 id=\"41-数据处理流程\">4.1 数据处理流程</h4>\n<p>下载的 CSV 文件需要被解析并更新到数据库中，以下是实现代码：</p>\n<pre><code class=\"language-csharp\">public void ProcessAllotmentData(string filePath)\n{\n    try\n    {\n        string fileName = Path.GetFileName(filePath);\n        string[] parts = fileName.Split('_');\n        string scriptName = parts.Length &gt; 0 ? parts[0] : null;\n\n        using (StreamReader sr = new StreamReader(filePath))\n        {\n            string[] rows = sr.ReadToEnd().Split('\\n');\n\n            for (int i = 1; i &lt; rows.Length; i++)\n            {\n                string[] rowValues = rows[i].Split(',');\n                if (rowValues.Length &gt; 7)\n                {\n                    string appNo = rowValues[2].Trim();\n                    string pan = rowValues[4].Trim();\n                    string qty = rowValues[5].Trim();\n                    string clientName = rowValues[6].Trim();\n                    string reason = rowValues[7].Trim();\n\n                    SqlParameter[] param = {\n                        new SqlParameter(\"@symbol\", scriptName),\n                        new SqlParameter(\"@appno\", appNo),\n                        new SqlParameter(\"@pan\", pan),\n                        new SqlParameter(\"@qty\", qty),\n                        new SqlParameter(\"@reason\", reason)\n                    };\n\n                    string statusQuery = @\"SELECT * FROM bidfiledetails  (NOLOCK)\n                                           WHERE AppNo=@appno AND Symbol=@symbol AND PanNo=@pan AND AllotmentFlag != 'Y'\";\n\n                    DataSet ds = SqlHelper.ExecuteDataset(SqlCon, CommandType.Text, statusQuery, param);\n\n                    if (ds.Tables[0].Rows.Count &gt; 0)\n                    {\n                        string updateQuery = @\"UPDATE bidfiledetails\n                                               SET AllotmentFlag='Y', SharesAlloted=@qty, Sharesrej_reason=@reason\n                                               WHERE AppNo=@appno AND PanNo=@pan AND Symbol=@symbol\";\n\n                        SqlHelper.ExecuteNonQuery(SqlCon, CommandType.Text, updateQuery, param);\n                        errorlog(\"Updated Record\", $\"PanNo: {pan}, ApplicationNo: {appNo}, Symbol: {scriptName}\");\n                    }\n                    else\n                    {\n                        string header = \"ApplicationNo|ClientName|Quantity|Reason|PanNo\";\n                        string message = $\"{appNo}|{clientName}|{qty}|{reason}|{pan}{Environment.NewLine}\";\n                        errorlog(header, message);\n                    }\n                }\n                else\n                {\n                    errorlog(\"Row does not have enough columns\", \"\");\n                }\n            }\n        }\n    }\n    catch (Exception ex)\n    {\n        ExceptionLogging.Exceptionlog(\"Exception in ProcessAllotmentData\", ex.Message);\n    }\n}\n</code></pre>\n<p>此代码实现了：</p>\n<ol>\n<li>从CSV文件名提取脚本名称</li>\n<li>逐行读取CSV文件内容</li>\n<li>验证数据完整性（确保有足够列数）</li>\n<li>检查数据库中的记录状态</li>\n<li>更新符合条件的记录或记录未匹配的情况</li>\n<li>全面的错误处理和日志记录</li>\n</ol>\n<h3 id=\"5-关键技术与实现要点\">5. 关键技术与实现要点</h3>\n<h4 id=\"51-核心技术组件\">5.1 核心技术组件</h4>\n<ul>\n<li><strong>邮件处理</strong>：使用 OpenPop.NET 库通过 POP3 协议读取邮件</li>\n<li><strong>文件处理</strong>：系统自动按日期组织下载的附件文件</li>\n<li><strong>数据验证</strong>：严格检查CSV文件结构和数据完整性</li>\n<li><strong>数据库操作</strong>：使用参数化查询确保SQL注入防护</li>\n<li><strong>错误处理</strong>：全面的异常捕获和日志记录机制</li>\n</ul>\n<h4 id=\"52-系统部署方式\">5.2 系统部署方式</h4>\n<ul>\n<li><strong>任务计划程序</strong>：配置为每日自动运行的Windows计划任务</li>\n<li><strong>Windows服务</strong>：可转换为服务实现24/7运行</li>\n<li><strong>日志监控</strong>：通过日志文件监控系统运行状态</li>\n</ul>\n<h3 id=\"6-系统扩展与优化方向\">6. 系统扩展与优化方向</h3>\n<h4 id=\"61-功能增强建议\">6.1 功能增强建议</h4>\n<ol>\n<li><strong>转换为Windows服务</strong>：实现完全自动化的后台处理</li>\n<li><strong>邮件通知功能</strong>：在处理完成或出现错误时发送通知邮件</li>\n<li><strong>日志数据库存储</strong>：将日志存入SQL表便于历史查询和分析</li>\n<li><strong>重试机制</strong>：为失败的邮件下载实现自动重试逻辑</li>\n</ol>\n<h4 id=\"62-性能优化建议\">6.2 性能优化建议</h4>\n<ul>\n<li>实现批量更新操作减少数据库往返</li>\n<li>添加并发处理能力提高大量邮件的处理速度</li>\n<li>优化内存使用处理超大附件文件</li>\n</ul>\n<h2 id=\"结论\">结论</h2>\n<p>本文详细介绍了一个基于C#和SQL Server的自动化邮件处理系统，能够高效地从邮件中提取分配数据并更新数据库。该系统通过自动化取代了繁琐的手工操作，显著提高了金融应用中分配数据处理的效率和准确性。核心功能包括邮件服务器连接、目标邮件筛选、CSV附件下载与解析以及数据库更新等完整流程。系统采用模块化设计，具有良好的可扩展性，可通过转换为Windows服务、添加通知功能等方式进一步增强。该解决方案不仅适用于金融领域的分配数据处理，其设计思路和实现方法也可应用于其他需要从邮件自动提取数据并更新数据库的类似场景。</p>\n\n</div>\n<div id=\"MySignature\">\n    <hr />\n<br />\n<p>本文是由葡萄城技术开发团队发布，转载请注明出处：<a href=\"https://www.grapecity.com.cn/\" target=\"_blank\">葡萄城官网</a></p>\n<!--p style=\"font-size: 16px; font-family: 微软雅黑, 黑体, Arial; color: #000\">了解企业级低代码开发平台，请前往<a href=\"https://www.grapecity.com.cn/solutions/huozige\" target=\"_blank\">活字格</a>\n</p><p style=\"font-size: 16px; font-family: 微软雅黑, 黑体, Arial; color: #000\">了解可嵌入您系统的在线 Excel，请前往<a href=\"https://www.grapecity.com.cn/developer/spreadjs\" target=\"_blank\">SpreadJS纯前端表格控件</a></p>\n<p style=\"font-size: 16px; font-family: 微软雅黑, 黑体, Arial; color: #000\">了解嵌入式的商业智能和报表软件，请前往<a href=\"https://www.grapecity.com.cn/solutions/wyn\" target=\"_blank\">Wyn Enterprise\n</a></p-->\n\n<br />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 18:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/powertoolsteam\">葡萄城技术团队</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "抛弃 Electron！3MB 体积实现 Web 转 EXE 极致封装（支持源码加密+离线跨域+原生API）",
      "link": "https://www.cnblogs.com/sensorwu/p/-/H2E_Studio",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sensorwu/p/-/H2E_Studio\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 18:00\">\n    <span>抛弃 Electron！3MB 体积实现 Web 转 EXE 极致封装（支持源码加密+离线跨域+原生API）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"抛弃 Electron！3MB 体积实现 Web 转 EXE 极致封装（支持源码加密+离线跨域+原生API）\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2355251/202601/2355251-20260105175540314-1728805626.png\" />\n        针对 Web 转 EXE 场景中 Electron 体积大、源码易泄露的痛点，本文介绍一种基于 WebView2 的工程化解决方案——H2E Studio。该方案实现了 3MB 独立进程封装，核心特性包括：1. 源码防御（资源加密打包，运行时内存流解密，无磁盘残留）；2. 虚拟文件系统（完美解决 file 协议跨域，支持 Krpano/Vue 路由离线运行）；3. HostObjects 桥接（JS 直接调用系统 API）。内置 DRM 授权闭环，是企业级桌面端交付的最佳实践。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h2>前言</h2>\n<p>在桌面应用开发领域，Electron 曾是霸主，但其动辄 <strong>150MB+</strong> 的安装包体积和每个窗口独立的 Chrome 进程带来的高内存占用，一直被开发者诟病。更致命的是，Electron 的 ASAR 归档本质上只是简单的拼接，<strong>源码几乎等于“裸奔”</strong>，极易被反编译窃取。</p>\n<p>随着 Windows 10/11 的普及，基于系统原生 Edge 运行时的 <strong>WebView2</strong> 技术逐渐成熟。</p>\n<p>今天给大家介绍一款基于 WebView2 深度重构的工具——<strong>H2E Studio (原HTML2EXE)</strong>。它不仅仅是一个打包壳，更是一套完整的 <strong>Web 桌面端交付解决方案</strong>，完美解决了<strong>源码加密保护、本地文件跨域、JS 调用系统 API、机器码授权</strong>等工程难题。</p>\n<p><img alt=\"help_PackIndex\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n<h2>一、 为什么选择 H2E Studio (WebView2) 方案？</h2>\n<p>相比于 Electron 或 C# WinForm 自带的 WebBrowser，H2E Studio 的核心优势在于**“轻量”<strong>与</strong>“安全”**的平衡。</p>\n<table>\n<thead>\n<tr>\n<td><strong>特性</strong></td>\n<td><strong>Electron</strong></td>\n<td><strong>H2E Studio (WebView2)</strong></td>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><span><strong>内核依赖</strong></span></td>\n<td><span>需自带 Chromium 内核</span></td>\n<td><span>共享系统 Edge 运行时</span></td>\n</tr>\n<tr>\n<td><span><strong>打包体积</strong></span></td>\n<td><span>&gt; 150 MB</span></td>\n<td><span><strong>~ 3 MB</strong> (极致轻量)</span></td>\n</tr>\n<tr>\n<td><span><strong>源码安全</strong></span></td>\n<td><span>ASAR 易解包，源码易泄露</span></td>\n<td><span><strong>高强度加密 + 内存流加载</strong></span></td>\n</tr>\n<tr>\n<td><span><strong>启动速度</strong></span></td>\n<td><span>较慢</span></td>\n<td><span><strong>秒级开</strong></span></td>\n</tr>\n<tr>\n<td><span><strong>兼容性</strong></span></td>\n<td><span>Win 7+</span></td>\n<td><span>Win 10/11 及 Server</span></td>\n</tr>\n</tbody>\n</table>\n<h2>二、 解决了哪些“掉头发”的技术痛点？</h2>\n<p>在重构 H2E Studio 2026 版的过程中，重点攻克了以下几个 Web 开发者最头疼的问题：</p>\n<h3>1. 🛡️ 源代码硬核加密 (Memory Stream Protection)</h3>\n<p><strong>痛点：</strong> 传统的打包工具（包括某些 Electron 打包器），运行原理是将文件释放到系统的 <code>%Temp%</code> 临时文件夹中再读取。懂行的人只要去临时文件夹一看，你的 HTML/JS/CSS 源码一览无余，毫无机密可言。 <strong>H2E 硬核方案：</strong> H2E Studio 采用了**“全资源加密 + 内存流映射”**技术：</p>\n<ul>\n<li>\n<p><strong>高强度加密：</strong> 所有 Web 资源在打包时会被高强度加密算法压缩进 EXE 资源段中。</p>\n</li>\n<li>\n<p><strong>无临时文件 (核心优势)：</strong> 程序运行时，通过拦截 WebView2 的网络层，直接在<strong>内存 (RAM)</strong> 中解密数据流并喂给浏览器内核。<strong>全过程不会在硬盘上释放任何明文文件</strong>。</p>\n</li>\n<li>\n<p><strong>黑盒交付：</strong> 配合“禁用 F12”和“禁止右键”选项，让你的程序真正成为一个无法窥探源码的“黑盒”。</p>\n</li>\n</ul>\n<h3>2. ⚡ 彻底解决本地跨域 (Virtual File System)</h3>\n<p><strong>痛点：</strong> 直接用浏览器打开本地 HTML (<code>file:///</code>)，Ajax 请求、Canvas 纹理（如 WebGL）、Cookie 往往会因为安全策略失效。 <strong>H2E 方案：</strong> 内置高性能<strong>虚拟文件系统</strong>。它将本地加密资源映射为虚拟域名（如 <code>https://app.local/</code>）。</p>\n<ul>\n<li>\n<p><strong>效果：</strong> Vue 路由、Krpano XML 加载、本地 JSON 读取完美运行。</p>\n</li>\n<li>\n<p><strong>纯离线：</strong> <strong>即使拔掉网线，程序依然能正常运行。</strong> 非常适合展厅、保密内网等无网环境。</p>\n</li>\n</ul>\n<h3>3. 🔌 零门槛的 Native API 调用</h3>\n<p><strong>痛点：</strong> 网页想要关机、打印、读取本地文件，通常需要写复杂的 C++ 插件或 Node.js 桥接。 <strong>H2E 方案：</strong>&nbsp;通过 <code>HostObjects</code> 技术打通了 JS 与 Windows 底层的通信。前端只需写标准 JS 即可调用系统能力：</p>\n<div class=\"code-block ng-tns-c2283161342-75 ng-animate-disabled ng-trigger ng-trigger-codeBlockRevealAnimation\">\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 前端直接调用：关闭程序</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">await chrome.webview.hostObjects.Demo.CloseProgram();\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 前端直接调用：系统关机 (适合展厅中控)</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">await chrome.webview.hostObjects.Demo.PowerOff();\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 前端直接调用：网页另存为 PDF</span>\nawait chrome.webview.hostObjects.Demo.Page_printToPDF(\"D:\\\\report.pdf\");</pre>\n</div>\n<h3>4. 🔑 商业级授权闭环 (DRM)</h3>\n<p><strong>痛点：</strong> 辛辛苦苦写的软件发给客户，结果被随意拷贝、白嫖。 <strong>H2E 方案：</strong> 内置了<strong>机器码授权系统</strong>。</p>\n<ul>\n<li>\n<p><strong>一机一码：</strong> 基于 CPU/硬盘生成唯一指纹。</p>\n</li>\n<li>\n<p><strong>离线验证：</strong> 生成 <code>.lic</code> 授权文件，无需部署验证服务器。</p>\n</li>\n<li>\n<p><strong>灵活控制：</strong> 支持设置“过期时间”（订阅制）或“运行次数”（试用版）。</p>\n</li>\n</ul>\n&nbsp;\n<h2>三、 H2E Studio 2026 新版特性概览</h2>\n<p>此次从 HTML2EXE 升级到 H2E Studio，UI 交互和功能进行了全面重构：</p>\n<ul>\n<li>\n<p><strong>⚡ 全局拖拽交互：</strong> 无论是 HTML 入口文件、图标还是证书，直接从资源管理器拖入软件即可，无需繁琐点击。</p>\n</li>\n<li>\n<p><strong>👁️ 真·实时预览：</strong> 内置模拟器。修改代码 -&gt; 点击预览 -&gt; 即时生效。<strong>预览功能完全免费且不限次数</strong>，调试到满意为止。</p>\n</li>\n<li>\n<p><strong>🛠️ 开发者工具箱：</strong> 内置了 <strong>图片转 ICO</strong>、<strong>安装包生成器 (Setup)</strong>、<strong>EXE 信息查看器</strong> 等实用工具，无需寻找第三方软件。</p>\n</li>\n<li>\n<p><strong>⌨️ 摸鱼神器：</strong> 支持自定义 <strong>“老板键”</strong> (如 Ctrl+Q)，一键隐藏窗口和托盘图标。</p>\n</li>\n</ul>\n<h2>四、 适用场景</h2>\n<ol start=\"1\">\n<li>\n<p><strong>前端开发者/外包团队：</strong> 利用<strong>机器码授权</strong>和<strong>源码加密</strong>，确保尾款结清前客户只能试用，且无法窃取代码。</p>\n</li>\n<li>\n<p><strong>全景摄影师：</strong> 解决 Krpano 本地播放黑屏问题，加密交付全景图。</p>\n</li>\n<li>\n<p><strong>企业 IT 运维：</strong> 快速制作内部使用的查询工具、大屏展示端（支持 Kiosk 全屏模式）。</p>\n</li>\n</ol></div>\n<h2>五、 下载与体验</h2>\n<p>软件采用 <strong>“预览免费 + 按次构建”</strong> 的模式。你可以无限次免费调试预览，只有生成最终交付 EXE 时才扣除次数，极大降低了个人开发者的试错成本。</p>\n<ul>\n<li>\n<p><strong>软件名称：</strong> H2E Studio (Web打包神器)</p>\n</li>\n<li>\n<p><strong>最新版本：</strong> 2026.1.5.0</p>\n</li>\n<li>\n<p><strong>官方下载：</strong> <a class=\"ng-star-inserted\" href=\"http://szhnnas.abitsoft.com:55554/wordpress/?sdm_process_download=1&amp;download_id=797\" rel=\"noopener nofollow\" target=\"_blank\">点击此处下载绿色版</a></p>\n</li>\n<li><strong>主页网址：</strong><a href=\"http://html2exe.abitsoft.com\" rel=\"noopener nofollow\" target=\"_blank\">http://html2exe.abitsoft.com</a></li>\n</ul>\n<p>作为一名开发者，我深知工具“安全”与“顺手”的重要性。希望 H2E Studio 能成为你工具箱里那个“小而美”的存在。欢迎在评论区交流技术细节！</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 18:00</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sensorwu\">sensor吴</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "上周热点回顾（12.29-1.4）",
      "link": "https://www.cnblogs.com/cmt/p/19443852",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/cmt/p/19443852\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 16:58\">\n    <span>上周热点回顾（12.29-1.4）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>热点随笔：</p>\n<p> · <a href=\"https://www.cnblogs.com/liyq666/archive/2025/12/31/19427476.html\" target=\"_blank\">2025 年终总结｜30岁</a> (<a href=\"https://www.cnblogs.com/liyq666/\" target=\"_blank\">香煎藕饼</a>) <br />\n · <a href=\"https://www.cnblogs.com/xdesigner/archive/2026/01/04/Make_WinForms_Great_Again.html\" target=\"_blank\">让WinForms再次伟大</a>\n(<a href=\"https://www.cnblogs.com/xdesigner/\" target=\"_blank\">袁永福 电子病历，医疗信息化</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/chengzp/archive/2025/12/29/stock-sdk.html\" target=\"_blank\">写给前端的股票行情 SDK: stock-sdk，终于不用再求后端帮忙了</a>\n(<a href=\"https://www.cnblogs.com/chengzp/\" target=\"_blank\">程序猿的程</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/datacool/archive/2026/01/01/19430534.html\" target=\"_blank\">2025再见，码农当自强，47岁尚能饭否</a>\n(<a href=\"https://www.cnblogs.com/datacool/\" target=\"_blank\">数据酷软件</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/msdeveloper/archive/2025/12/31/make-dotnet-great-again-2026.html\" target=\"_blank\">2026年，让.NET再次伟大</a>\n(<a href=\"https://www.cnblogs.com/msdeveloper/\" target=\"_blank\">TypingLearn</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/sheng_chao/archive/2026/01/02/19431954.html\" target=\"_blank\">独立开发者的 2025：我为什么还在做一个“看起来很普通”的客服系统</a>\n(<a href=\"https://www.cnblogs.com/sheng_chao/\" target=\"_blank\">升讯威在线客服系统</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/hyb1/archive/2025/12/29/19415077.html\" target=\"_blank\">当我试图搞清楚 FFmpeg 的硬件加速时，我写了一个能自动检测所有 GPU 编码器的小工具</a>\n(<a href=\"https://www.cnblogs.com/hyb1/\" target=\"_blank\">重庆Debug</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/sunhui/archive/2025/12/29/19415298.html\" target=\"_blank\">所有64位WinForm应用都是Chromium浏览器（2）</a>\n(<a href=\"https://www.cnblogs.com/sunhui/\" target=\"_blank\">Exe2WebBrowser</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/ChenAI-TGF/archive/2025/12/29/19413216.html\" target=\"_blank\">开源项目分享：Gitee热榜项目 2025年12月第四周 周榜</a>\n(<a href=\"https://www.cnblogs.com/ChenAI-TGF/\" target=\"_blank\">TTGF</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/yupi/archive/2025/12/30/19420512.html\" target=\"_blank\">让 AI 分析我 3 年前写的代码，全是漏洞！</a>\n(<a href=\"https://www.cnblogs.com/yupi/\" target=\"_blank\">程序员鱼皮</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/xzqcsj/archive/2025/12/29/19413883.html\" target=\"_blank\">Spring AOP + Guava RateLimiter：我是如何用注解实现优雅限流的？</a>\n(<a href=\"https://www.cnblogs.com/xzqcsj/\" target=\"_blank\">一旅人</a>)                    <br />\n · <a href=\"https://www.cnblogs.com/chengxy-nds/archive/2025/12/30/19419342.html\" target=\"_blank\">无成本搭建 AI 画图神器！我以后再也不会手绘架构图了</a>\n(<a href=\"https://www.cnblogs.com/chengxy-nds/\" target=\"_blank\">程序员小富</a>)                    <br />\n            </p>\n<p>热点新闻：</p>\n<p>\n · <a href=\"https://news.cnblogs.com/n/812198/\" target=\"_blank\">信息量太大！雷军一口气讲了260分钟，关于小米汽车都说了什么</a><br />\n · <a href=\"https://news.cnblogs.com/n/812181/\" target=\"_blank\">一个字证明，你不是AI！54份高中生回信火爆成b站Top 5，全网泪目</a><br />\n · <a href=\"https://news.cnblogs.com/n/812016/\" target=\"_blank\">AI领域重大并购！Meta斥资数十亿美元，收购中国背景Manus！</a><br />\n · <a href=\"https://news.cnblogs.com/n/811924/\" target=\"_blank\">宇宙可能不是想象的那么“匀称”</a><br />\n · <a href=\"https://news.cnblogs.com/n/812038/\" target=\"_blank\">同事猝死只换来1分钟默哀！40岁架构师宁愿被裁，年薪百万活得像机器</a><br />\n · <a href=\"https://news.cnblogs.com/n/812130/\" target=\"_blank\">蜜蜂的自我牺牲行为，与肠道菌群有关</a><br />\n · <a href=\"https://news.cnblogs.com/n/812041/\" target=\"_blank\">贝壳核心员工举报：公司大肆做空房地产</a><br />\n · <a href=\"https://news.cnblogs.com/n/812184/\" target=\"_blank\">豆包一声声“OK”把罗永浩搞破防，不就是大型现场直播版图灵测试</a><br />\n · <a href=\"https://news.cnblogs.com/n/811933/\" target=\"_blank\">国产芯片最大金主诞生，字节400亿豪赌华为，首批百亿即将到货</a><br />\n · <a href=\"https://news.cnblogs.com/n/812233/\" target=\"_blank\">25亿美元卖给美国，武汉起家的Manus为什么出走？</a><br />\n · <a href=\"https://news.cnblogs.com/n/812109/\" target=\"_blank\">钱烧了，人跑了……曾经风光的Kimi，一年后沦为了二线？</a><br />\n · <a href=\"https://news.cnblogs.com/n/812084/\" target=\"_blank\">DeepSeek，居然只是个副项目？</a></p>\n<p>推广项目：</p>\n<p>· <a href=\"https://www.ebcloud.com/chn_xhpwpopm\" rel=\"noopener nofollow\" target=\"_blank\">英博云GPU容器服务平台，智能算力即开即用，立即免费试用</a><br />· <a href=\"https://ais.cn/u/VZZZJj\" rel=\"noopener nofollow\" target=\"_blank\">科研领域的连接者艾思科蓝，一站式科研学术服务数字化平台</a><br />· <a href=\"https://www.cnblogs.com/cmt/p/19165152\" rel=\"noopener\" target=\"_blank\">诚邀您体验阿里巴巴推出的新一代 Agentic 编程平台 Qoder</a><br />· <a href=\"https://dis.chatdesks.cn/chatdesk/jmcnblogs.html\" rel=\"noopener nofollow\" target=\"_blank\">人像高清输出，百变风格随心换，快来即梦试试吧</a><br />·&nbsp;<a href=\"https://www.trae.com.cn/?utm_source=advertising&amp;utm_medium=cnblogs_ug_cpa&amp;utm_term=hw_trae_cnblogs\" rel=\"noopener nofollow\" target=\"_blank\">TRAE SOLO 中国版正式上线，全面免费</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 16:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/cmt\">博客园团队</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}