{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "零门槛部署本地 AI 助手：Clawdbot/Meltbot 部署深度保姆级教程",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19545952",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19545952\" id=\"cb_post_title_url\" title=\"发布于 2026-01-29 00:14\">\n    <span>零门槛部署本地 AI 助手：Clawdbot/Meltbot 部署深度保姆级教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Clawdbot是一个多功能智能体（Agent），具备文件操作、代码执行、联网搜索等能力。本文详细介绍了其安装配置流程： 环境准备：全新安装Node.js（v22+/v24+）或彻底卸载旧版后安装新版，需确保环境变量配置正确； 权限设置：在PowerShell中解锁脚本执行权限； 一键安装：通过官方脚本自动部署主程序； 初始化向导：选择QuickStart模式，配置基础技能（Skills）和API（如Qwen或OpenAI），暂跳过高级选项。 完成上述步骤后即可启动Clawdbot，后续可扩展远程控制等功能\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<hr />\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h1 id=\"前言为什么选择-clawdbot-moltbot\">前言：为什么选择 Clawdbot (Moltbot)？</h1>\n<p>Clawdbot 不仅仅是一个聊天框。它是一个 <strong>智能体（Agent）</strong>，意味着它有“手”和“脚”：</p>\n<ul>\n<li><strong>手</strong>：它可以读写你电脑上的文件、执行代码、操控命令行。</li>\n<li><strong>脚</strong>：它可以联网搜索、访问 Google、分析网页。</li>\n<li><strong>大脑</strong>：你可以接入云端的 <strong>API</strong>，也可以利用自己的 <strong>GPU</strong> 运行本地模型。</li>\n</ul>\n<hr />\n<h1 id=\"第一阶段基建工程环境准备\">第一阶段：基建工程（环境准备）</h1>\n<h2 id=\"11-解决-nodejs-安装与版本问题\">1.1 解决 Node.js 安装与版本问题</h2>\n<h3 id=\"111全新安装nodejs电脑未安装过nodejs时\">1.1.1全新安装Node.js（电脑未安装过Node.js时）</h3>\n<p>如果你的电脑上从来没装过Node.js，无需执行卸载、删残留的步骤，直接按以下流程全新安装即可，步骤适配Windows系统，新手友好、全程默认下一步即可。</p>\n<p><strong>1. 下载适配的Node.js安装包</strong></p>\n<ol>\n<li>\n<p>打开<a href=\"https://nodejs.org/\" rel=\"noopener nofollow\" target=\"_blank\">Node.js 官方官网</a>，官网页面会自动识别你的系统（Windows）；<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>点击下载<strong>Windows Installer (64-bit)</strong> 格式的安装包（.msi后缀，64位是目前Windows电脑的主流，无需选32位）；</p>\n<blockquote>\n<p>小贴士：下载时建议保存到桌面/下载文件夹，方便找到安装包。</p>\n</blockquote>\n</li>\n</ol>\n<p><strong>2. 安装Node.js（全程新手友好，默认下一步即可）</strong></p>\n<ol>\n<li>双击刚下载的.msi安装包，弹出安装向导，点击<strong>Next</strong>；</li>\n<li>勾选同意协议（I accept the terms in the License Agreement），点击<strong>Next</strong>；</li>\n<li><strong>关键点1</strong>：确认安装路径（默认是<code>C:\\Program Files\\nodejs\\</code>，新手<strong>不要修改</strong>，避免后续环境变量出问题），直接<strong>Next</strong>；</li>\n<li><strong>关键点2</strong>：进入「Custom Setup」自定义安装页，<strong>所有选项默认勾选即可</strong>（重点确认<code>Add Node.js to PATH</code>已勾选，这一步会自动把Node.js加入系统环境变量，不用手动配置，是最关键的一步），直接<strong>Next</strong>；</li>\n<li>后续页面无需修改任何高级选项，一直点击<strong>Next</strong>，最后点击<strong>Install</strong>开始安装，等待10-30秒（安装速度看电脑配置）；</li>\n<li>安装完成后，点击<strong>Finish</strong>关闭向导即可。</li>\n</ol>\n<p><strong>3. 版本验证</strong><br />\n<strong>必须重启终端</strong>（关闭所有已打开的PowerShell/CMD，重新打开），否则系统识别不到新安装的Node.js！</p>\n<ol>\n<li>按下<code>Win+R</code>，输入<code>PowerShell</code>，打开普通权限的PowerShell即可；</li>\n<li>输入验证命令：<pre><code class=\"language-powershell\">node -v\n</code></pre>\n</li>\n<li>回车后，若显示<code>v22.x.x</code>或<code>v24.x.x</code>（比如v22.10.0、v24.4.0），说明安装成功且版本符合要求；\n<blockquote>\n<p>可选验证：输入<code>npm -v</code>，会显示配套的npm版本（Node.js安装包会自动附带npm，无需单独安装），能正常输出版本即代表环境变量配置无误。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</blockquote>\n</li>\n</ol>\n<hr />\n<h3 id=\"112卸载旧版nodejs-安装新版电脑安装过nodejs但是版本不够新时\">1.1.2卸载旧版Node.js 安装新版（电脑安装过Node.js但是版本不够新时）</h3>\n<p>如果版本不够新，执行安装命令的时候程序会尝试安装新版的Node.js，但是大概率会失败，还是手动比较好，失败的话会显示以下界面：<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n<strong>操作：</strong><br />\n1.可以直接通过新的安装包对上一个版本的Node.js进行remove<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>去“控制面板”卸载旧的 Node.js。</li>\n<li><strong>关键点：</strong> 手动进入 <code>C:\\Program Files\\nodejs</code> 文件夹，把残留的文件全部删干净！</li>\n<li>前往 <a href=\"https://nodejs.org/\" rel=\"noopener nofollow\" target=\"_blank\">Node.js 官网</a> 下载最新的 <strong>v22 或 v24</strong> 稳定版并安装。</li>\n<li><strong>清楚之前的旧的环境变量</strong>（这一步非常重要！）</li>\n</ol>\n<ul>\n<li><strong>验证：</strong> 重新打开 PowerShell，输入 <code>node -v</code>。看到显示 <code>v22.x</code> 或 <code>v24.x</code> 才算过关。</li>\n</ul>\n<ol start=\"6\">\n<li>版本验证（和卸载旧版后的验证步骤一致）<br />\n<strong>必须重启终端</strong>（关闭所有已打开的PowerShell/CMD，重新打开），否则系统识别不到新安装的Node.js！</li>\n<li>按下<code>Win+R</code>，输入<code>PowerShell</code>，打开普通权限的PowerShell即可；</li>\n<li>输入验证命令：<pre><code class=\"language-powershell\">node -v\n</code></pre>\n</li>\n<li>回车后，若显示<code>v22.x.x</code>或<code>v24.x.x</code>（比如v22.10.0、v24.4.0），说明安装成功且版本符合要求；\n<blockquote>\n<p>可选验证：输入<code>npm -v</code>，会显示配套的npm版本（Node.js安装包会自动附带npm，无需单独安装），能正常输出版本即代表环境变量配置无误。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</blockquote>\n</li>\n</ol>\n<h2 id=\"12-解锁脚本执行权限\">1.2 解锁脚本执行权限</h2>\n<ul>\n<li><strong>问题：</strong> Windows 默认禁止运行脚本，会导致安装指令失效。</li>\n<li><strong>操作：</strong> 以管理员身份运行 PowerShell，执行：<pre><code class=\"language-powershell\">Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n</code></pre>\n</li>\n</ul>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<p><strong>完成以上步骤后，你的Node.js环境就完全满足Clawdbot的要求了，可以直接进入后续的项目安装环节。</strong></p>\n<hr />\n<h1 id=\"第二阶段正式安装与初始化\">第二阶段：正式安装与初始化</h1>\n<h2 id=\"21-执行一键安装\">2.1 执行一键安装</h2>\n<ul>\n<li><strong>操作：</strong> 在 PowerShell 输入：<pre><code class=\"language-powershell\">iwr -useb https://clawd.bot/install.ps1 | iex\n</code></pre>\n</li>\n<li><strong>作用：</strong> 这行代码会自动下载主程序并配置环境变量。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n这个会持续一会才有进展，不要担心，如果太久可以按按回车看看是不是powershell刷新的问题<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n这个会持续一段时间才有进展，不要担心，</li>\n</ul>\n<h2 id=\"22-运行向导-onboarding\">2.2 运行向导 (Onboarding)</h2>\n<ul>\n<li><strong>操作：</strong> 输入 <code>moltbot onboard</code>。</li>\n<li><strong>详细选项说明：</strong>\n<ol>\n<li>\n<p><strong>Mode</strong>：选 <code>QuickStart</code>。</p>\n</li>\n<li>\n<p><strong>Provider (大脑)</strong>：建议选 <code>Qwen</code>。</p>\n<ul>\n<li><strong>注意：</strong> 此时会跳出网页让你授权，登录或者注册Qwen的账号既可。这步是为了先让机器人有个“临时大脑”跑起来。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n选择OpenAI Chat，拿到Key之后输入到界面中给Clawdbot。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n选择这个直接按回车即可。</li>\n</ul>\n</li>\n<li>\n<p><strong>Channels (远程控制)</strong>：选 <code>Skip for now</code>。我们先在本地跑通，以后再连 Telegram。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p><strong>Skills (技能)</strong>：选 <code>Yes</code>。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" />这些是最基本的Skill选择，选择Yes就好</p>\n</li>\n<li>\n<p><strong>Skill install</strong>：选 <code>npm</code>。</p>\n</li>\n</ol>\n</li>\n</ul>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<ol start=\"5\">\n<li><strong>Skill Dependencies</strong>：选 <code>Skip for now</code>。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n这些是扩展的，目前配置比较麻烦，可以后续再配置<br />\n6. 一些其他配置<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n选择No，尽量都留到后面再配置<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></li>\n</ol>\n<h2 id=\"23-成功界面\">2.3 成功界面</h2>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" />、<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"第三阶段破解命令找不到与网关未授权\">第三阶段：破解“命令找不到”与“网关未授权”</h1>\n<h2 id=\"31-解决-moltbot-命令失效\">3.1 解决 moltbot 命令失效</h2>\n<ul>\n<li>\n<p><strong>现象：</strong> 安装完输入 <code>moltbot open</code> 提示“无法识别”。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p><strong>原因：</strong> 环境变量未刷新。</p>\n</li>\n<li>\n<p><strong>对策：</strong> 重启 PowerShell 窗口。如果还不行，执行npx moltbot open。</p>\n</li>\n</ul>\n<h2 id=\"32-提取身份令牌-token-登录网页\">3.2 提取身份令牌 (Token) 登录网页</h2>\n<ul>\n<li>\n<p><strong>现象：</strong> 访问 <code>http://localhost:18789</code> 显示“未授权：网关令牌缺失”。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p><strong>操作：</strong></p>\n<ol>\n<li>\n<p>打开文件夹 <code>C:\\Users\\你的用户名\\.clawdbot</code>。</p>\n</li>\n<li>\n<p>右键点击 <code>clawdbot.json</code>，用记事本打开。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>找到 <code>\"token\": \"xxxxxxx\"</code> 这一行，复制那串长代码。<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>回到浏览器，点击右上角红色状态，把 Token 贴进去。<strong>一旦变绿，恭喜你，你的助理正式上线了！</strong><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n</ol>\n</li>\n</ul>\n<hr />\n<h1 id=\"第四阶段配置各种api\">第四阶段：配置各种API</h1>\n<ul>\n<li><strong>操作步骤：</strong>\n<ol>\n<li>在网页后台点击左侧 <strong>Skill(技能)</strong><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n可以看到有非常多的API可以配置，过程相对来说还是比较繁琐的，有机会的话下次专门再出一期博客来讲，目前的话他可以实现通过对话来进行一些本地的文件操作，命令操作等等。整体来说还是不错的</li>\n</ol>\n</li>\n</ul>\n<hr />\n<hr />\n<h2 id=\"总结你的-ai-现在能干什么\">总结：你的 AI 现在能干什么？</h2>\n<ol>\n<li><strong>对话</strong>：你可以问它任何问题。</li>\n<li><strong>读文件</strong>：把代码发给它，或者让它读你 F 盘的文档。</li>\n<li><strong>本地代码执行</strong>：让它用 Python 画一个股价走势图。</li>\n</ol>\n<p><strong>部署贴士总结：</strong></p>\n<ul>\n<li><strong>Node 版本必须 v22+</strong></li>\n<li><strong>Token 在配置文件里找</strong></li>\n<li><strong>本地 GPU 模型用 Ollama 桥接</strong></li>\n<li><strong>Google 搜索一定要开“搜索全网”开关</strong></li>\n</ul>\n<hr />\n<p><em>恭喜你完成了部署！现在，你的 Windows 已经不仅仅是一台电脑，而是一个拥有最强国产模型大脑和本地硬件加速的超级助手了。</em></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-29 00:14</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "揭秘 Codex Agent 的核心运行机制：从循环到智能决策",
      "link": "https://www.cnblogs.com/smartloli/p/19530777",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/smartloli/p/19530777\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 23:32\">\n    <span>揭秘 Codex Agent 的核心运行机制：从循环到智能决策</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1>1.概述</h1>\n<p>&nbsp;在人工智能快速发展的今天，AI不再仅仅是回答问题的聊天机器人，而是正在演变为能够主动完成复杂任务的智能代理。OpenAI的Codex CLI就是这一趋势的典型代表——一个跨平台的本地软件代理，能够在用户的机器上安全高效地生成高质量的软件变更。</p>\n<h1>2.内容</h1>\n<p>如果你只把 Codex 当成“更会写代码的 ChatGPT”，那你只理解了它 10% 的价值。真正让 Codex 不同的，是它背后那套完整、可运行、可反复思考的 Agent Loop（智能体循环）系统。</p>\n<h2>2.1&nbsp;Codex 到底和普通大模型有什么区别？</h2>\n<p>我们先看一个最普通的大模型交互流程：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 0, 1);\">你：帮我写一个 Python 脚本\n模型：给你一段代码\n结束</span></pre>\n</div>\n<p>这是一次性生成，模型：</p>\n<ul>\n<li>不知道代码能不能运行</li>\n<li>不知道有没有报错</li>\n<li>更不知道“下一步该干什么”</li>\n</ul>\n<p><strong>1. Codex 的真实工作方式完全不同</strong></p>\n<p>Codex 的思路更像一个新手工程师坐在你电脑前：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 128, 1);\">1</span> <span style=\"color: rgba(0, 0, 0, 1);\">看需求\n</span><span style=\"color: rgba(0, 128, 128, 1);\">2</span> <span style=\"color: rgba(0, 0, 0, 1);\">写点代码\n</span><span style=\"color: rgba(0, 128, 128, 1);\">3</span> <span style=\"color: rgba(0, 0, 0, 1);\">运行一下\n</span><span style=\"color: rgba(0, 128, 128, 1);\">4</span> <span style=\"color: rgba(0, 0, 0, 1);\">报错了？看看错误\n</span><span style=\"color: rgba(0, 128, 128, 1);\">5</span> <span style=\"color: rgba(0, 0, 0, 1);\">改代码\n</span><span style=\"color: rgba(0, 128, 128, 1);\">6</span> <span style=\"color: rgba(0, 0, 0, 1);\">再运行\n</span><span style=\"color: rgba(0, 128, 128, 1);\">7</span> 直到成功</pre>\n</div>\n<p>这个「反复尝试」的过程，就是 Codex Agent Loop。</p>\n<h2>2.2&nbsp;什么是 Agent Loop？</h2>\n<p><strong>Agent Loop = 让模型在一个循环里，不断思考 → 行动 → 看结果 → 再思考</strong>。Codex CLI 的核心不是“一次推理”，而是反复展开这个循环，模型不是直接给答案，而是每一轮只决定：我下一步该干什么？</p>\n<p><strong>1.&nbsp;先忘掉「大模型」，把 Codex 当成一个“新人程序员”</strong></p>\n<p>想象一个<strong>刚入职的初级工程师</strong>，你给他一个任务：</p>\n<div class=\"cnblogs_code\">\n<pre>“帮我把这个项目跑起来，并写一个 README。”</pre>\n</div>\n<p>他会怎么做？一定不是：</p>\n<div class=\"cnblogs_code\">\n<pre>“我闭上眼睛，一次性把所有事情做对。”</pre>\n</div>\n<p>而是更接近下面这个过程：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 128, 1);\">1</span> <span style=\"color: rgba(0, 0, 0, 1);\">先看看项目目录结构\n</span><span style=\"color: rgba(0, 128, 128, 1);\">2</span> <span style=\"color: rgba(0, 0, 0, 1);\">猜一猜怎么运行\n</span><span style=\"color: rgba(0, 128, 128, 1);\">3</span> <span style=\"color: rgba(0, 0, 0, 1);\">真的运行一下\n</span><span style=\"color: rgba(0, 128, 128, 1);\">4</span> <span style=\"color: rgba(0, 0, 0, 1);\">发现报错\n</span><span style=\"color: rgba(0, 128, 128, 1);\">5</span> <span style=\"color: rgba(0, 0, 0, 1);\">根据报错改代码\n</span><span style=\"color: rgba(0, 128, 128, 1);\">6</span> <span style=\"color: rgba(0, 0, 0, 1);\">再运行\n</span><span style=\"color: rgba(0, 128, 128, 1);\">7</span> <span style=\"color: rgba(0, 0, 0, 1);\">直到跑通\n</span><span style=\"color: rgba(0, 128, 128, 1);\">8</span> 最后再总结，写 README</pre>\n</div>\n<p><strong>注意：</strong><br />这个过程中，每一步都依赖上一步的结果。这，就是 Agent Loop 的直觉来源。</p>\n<p><strong>2.普通 ChatBot VS Agent：根本区别在哪？</strong></p>\n<p>普通 ChatBot 的工作方式</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 0, 1);\">输入问题\n↓\n模型“想一想”\n↓\n一次性输出答案\n↓\n结束</span></pre>\n</div>\n<p>它的特点是：</p>\n<ul>\n<li>只能“想”，不能“做”</li>\n<li>没有真实世界的反馈</li>\n<li>更像是在考试答题</li>\n</ul>\n<p>Codex Agent 的工作方式</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 0, 1);\">目标\n↓\n想一小步\n↓\n做一小步\n↓\n看结果\n↓\n再想一小步\n↓\n……\n↓\n完成</span></pre>\n</div>\n<p>它的特点是：</p>\n<ul>\n<li>每一轮只解决一个非常小的问题</li>\n<li>每一步都基于真实执行结果</li>\n<li>更像是在真实工作</li>\n</ul>\n<p>Agent Loop，本质上就是把“一次性回答问题”，拆成了“多轮小决策”。</p>\n<p><strong>3.&nbsp;「Loop」这个词，为什么这么重要？</strong></p>\n<p>我们先看一个不展开的情况：</p>\n<div class=\"cnblogs_code\">\n<pre>模型在脑子里想 <span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\"> 步\n↓\n一次性输出最终答案</span></pre>\n</div>\n<p>这种方式的问题是：</p>\n<ul>\n<li>中间哪一步想错了，你完全不知道</li>\n<li>没有机会修正</li>\n<li>对复杂任务非常不稳定</li>\n</ul>\n<p>而 Agent Loop 是把这 10 步“摊开”：</p>\n<div class=\"cnblogs_code\">\n<pre>第 <span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\"> 步：我该不该看目录？\n↓\n第 </span><span style=\"color: rgba(128, 0, 128, 1);\">2</span><span style=\"color: rgba(0, 0, 0, 1);\"> 步：我该不该运行测试？\n↓\n第 </span><span style=\"color: rgba(128, 0, 128, 1);\">3</span><span style=\"color: rgba(0, 0, 0, 1);\"> 步：这个报错是什么意思？\n↓\n第 </span><span style=\"color: rgba(128, 0, 128, 1);\">4</span> 步：我该改哪个文件？</pre>\n</div>\n<p>这就是 unrolling the loop 的含义：把模型原本“在脑子里一次性完成的思考”，拆成一轮一轮、可执行、可观察的步骤。</p>\n<p><strong>4.为什么说「模型不是直接给答案」？</strong></p>\n<p>复杂问题，没有人能在“看都没看现场”的情况下，一次就给出完美答案。Agent Loop 的设计，正是承认了这一点。所以 Codex 的策略是：</p>\n<ul>\n<li>不追求“一次答对”</li>\n<li>而是追求：\n<ul>\n<li>每一步都有依据</li>\n<li>每一步都能被验证</li>\n<li>每一步错了都能修</li>\n</ul>\n</li>\n</ul>\n<p>假设你的项目现在是这样：</p>\n<div class=\"cnblogs_code\">\n<pre>“一个 Node 项目，运行 npm start 会报错”</pre>\n</div>\n<p>Codex 的内心独白，并不是一句话，而是类似这样一轮一轮展开：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 128, 1);\">1</span> 我不知道项目结构，我需要先看看 → 调用工具：<span style=\"color: rgba(0, 0, 255, 1);\">ls</span>\n<span style=\"color: rgba(0, 128, 128, 1);\">2</span> <span style=\"color: rgba(0, 0, 0, 1);\">看起来是 Node 项目，我应该试着运行 → 调用工具：npm start\n</span><span style=\"color: rgba(0, 128, 128, 1);\">3</span> 报错说缺依赖 → 调用工具：npm <span style=\"color: rgba(0, 0, 255, 1);\">install</span>\n<span style=\"color: rgba(0, 128, 128, 1);\">4</span> <span style=\"color: rgba(0, 0, 0, 1);\">再运行一次 → npm start\n</span><span style=\"color: rgba(0, 128, 128, 1);\">5</span> 现在跑通了，我可以总结了 → 输出最终回答</pre>\n</div>\n<h2>2.3&nbsp;把 Agent Loop 拆成 5 个步骤</h2>\n<h3>2.3.1 接收用户目标（不是马上干活）</h3>\n<p><strong>1 用户输入 ≠ 模型直接思考的内容</strong></p>\n<p>当你在 Codex CLI（或任何 Agent 系统）里输入一句话，比如：</p>\n<div class=\"cnblogs_code\">\n<pre>“帮我给这个项目补一个 README。”</pre>\n</div>\n<p>很多人会误以为：</p>\n<div class=\"cnblogs_code\">\n<pre>这句话直接被送进模型，然后模型开始思考。</pre>\n</div>\n<p>但实际上，在 Agent 系统里，这句话的角色更接近于：</p>\n<div class=\"cnblogs_code\">\n<pre>“任务目标（Goal）”</pre>\n</div>\n<p>也就是说，它只是告诉系统：</p>\n<div class=\"cnblogs_code\">\n<pre>最终你要把事情做到什么状态</pre>\n</div>\n<p><strong>2 为什么要把“目标”和“过程”分开？</strong></p>\n<p>因为 Agent Loop 的设计理念是：</p>\n<ul>\n<li>目标是稳定的</li>\n<li>过程是动态变化的</li>\n</ul>\n<p>举个生活化的例子：</p>\n<div class=\"cnblogs_code\">\n<pre>你的目标是“把房间收拾干净”</pre>\n</div>\n<p>你并不会一开始就决定：</p>\n<ul>\n<li>先扫地还是先整理桌子</li>\n<li>垃圾有多少</li>\n<li>要不要换垃圾袋</li>\n</ul>\n<p>你只是知道：最后要干净</p>\n<p>Codex 也是一样。</p>\n<div class=\"cnblogs_code\">\n<pre>用户输入只负责定义“终点”，不负责定义“路径”。</pre>\n</div>\n<h3>2.3.2&nbsp;构造当前上下文（Prompt）</h3>\n<p><strong>1.Prompt 是“模型看世界的全部信息”</strong></p>\n<p>这是 Agent Loop 里最关键、也最容易被低估的一步。</p>\n<p>我们先说一句非常重要的话：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 0, 1);\">对模型来说，它并不知道“刚刚发生了什么”，\n除非你把这些信息放进 Prompt。</span></pre>\n</div>\n<p>所以，每一轮 Agent Loop，都会重新构造一个 Prompt。</p>\n<p><strong>2.Prompt 里通常包含哪些东西？</strong></p>\n<p>一个完整的 Prompt，通常包含：</p>\n<ol>\n<li>你是谁（系统设定）<ol>\n<li>你是一个 coding agent</li>\n<li>你可以修改文件、运行命令</li>\n</ol></li>\n<li>你能用什么工具<ol>\n<li>shell</li>\n<li>文件读写</li>\n<li>测试运行</li>\n</ol></li>\n<li>用户目标<ol>\n<li>比如：补 README</li>\n</ol></li>\n<li>到目前为止发生了什么<ol>\n<li>我刚才运行了什么命令</li>\n<li>输出结果是什么</li>\n<li>有没有报错</li>\n</ol></li>\n</ol>\n<p>对模型来说，这些内容就是它的“记忆”。</p>\n<p><strong>3.为什么每一轮都要“重新构造” Prompt？</strong></p>\n<p>举个例子：</p>\n<ul>\n<li>第一轮：你还没看过项目结构</li>\n<li>第二轮：你已经知道有哪些文件</li>\n<li>第三轮：你已经看到测试报错</li>\n</ul>\n<p>如果 Prompt 不更新，模型就会：</p>\n<ul>\n<li>永远以为自己什么都不知道</li>\n</ul>\n<p>所以 Agent Loop 的一个核心动作就是：</p>\n<ul>\n<li>把“刚刚发生的现实结果”，翻译成模型能理解的文字，再塞回 Prompt。</li>\n</ul>\n<h3>2.3.3&nbsp;让模型做“下一步决策”</h3>\n<p><strong>1.模型在这一轮，只回答一个问题</strong></p>\n<p>这是 Agent Loop 的灵魂所在。</p>\n<ul>\n<li>模型不会在这一轮里把所有事情想完。</li>\n</ul>\n<p>它只做一个非常具体、非常有限的判断：</p>\n<ul>\n<li>“在当前信息条件下，我下一步该做什么？”</li>\n</ul>\n<p><strong>2.这个“下一步”，通常只有两种可能</strong></p>\n<p><strong>情况一：我还需要更多信息 / 行动</strong></p>\n<p>模型会说类似：</p>\n<ul>\n<li>“我需要看看目录结构”</li>\n<li>“我需要跑一下测试”</li>\n<li>“我需要打开某个文件看看内容”</li>\n</ul>\n<p>在系统层面，这会被表达为：</p>\n<ul>\n<li>Tool Call（工具调用）</li>\n</ul>\n<p><strong>情况二：信息已经够了，可以结束</strong></p>\n<p>模型会说类似：</p>\n<ul>\n<li>“现在我可以写 README 了”</li>\n<li>“问题已经修复完成”</li>\n</ul>\n<p>这时，它会直接输出最终回答，Agent Loop 结束。</p>\n<p><strong>3.为什么要限制成“只想一步”？</strong></p>\n<p>因为这是控制复杂度的关键。</p>\n<p>如果模型一次性想 10 步：</p>\n<ul>\n<li>中间哪一步错了，你不知道</li>\n<li>无法插入真实反馈</li>\n<li>很难纠正</li>\n</ul>\n<p>而“一步一想”的好处是：</p>\n<ul>\n<li>每一步都可以被验证</li>\n<li>错了就马上修</li>\n<li>对复杂任务更稳</li>\n</ul>\n<h3>2.3.4&nbsp;如果要干活 → 调工具</h3>\n<p><strong>1.模型自己“不会干活”</strong></p>\n<p>模型 ≠ 能执行命令的程序，模型只能输出文字（或结构化指令），但：</p>\n<ul>\n<li>它不能真的运行 ls</li>\n<li>不能真的执行 npm install</li>\n<li>不能真的写文件</li>\n</ul>\n<p><strong>2.Tool 的作用：把“建议”变成“现实动作”</strong></p>\n<p>当模型说：“我需要运行 ls 看看目录”，Agent 系统会：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 128, 1);\">1</span> <span style=\"color: rgba(0, 0, 0, 1);\">解析模型输出\n</span><span style=\"color: rgba(0, 128, 128, 1);\">2</span> <span style=\"color: rgba(0, 0, 0, 1);\">发现这是一个 tool call\n</span><span style=\"color: rgba(0, 128, 128, 1);\">3</span> <span style=\"color: rgba(0, 0, 0, 1);\">在真实环境里执行命令\n</span><span style=\"color: rgba(0, 128, 128, 1);\">4</span> 收集真实输出</pre>\n</div>\n<h3>2.3.5&nbsp;把结果塞回上下文，继续循环</h3>\n<p><strong>1.这是 Agent Loop 最“反直觉”的一步</strong></p>\n<p>很多人会以为：工具执行完，模型“就知道结果了”，其实不然。模型并不知道工具执行结果，除非你把结果写进 Prompt。</p>\n<p><strong>2.现实 → 文本 → Prompt</strong></p>\n<p>Agent 会把刚才的执行结果，转成类似这样的内容：</p>\n<div class=\"cnblogs_code\">\n<pre>你刚刚运行了 <span style=\"color: rgba(0, 0, 255, 1);\">ls</span><span style=\"color: rgba(0, 0, 0, 1);\">\n输出是：\nsrc</span>/<span style=\"color: rgba(0, 0, 0, 1);\">\npackage.json</span></pre>\n</div>\n<p>然后：</p>\n<ul>\n<li>把这段文字加入 Prompt</li>\n<li>再发起下一轮模型推理</li>\n</ul>\n<p>这一步完成后，新的一轮 Loop 开始。</p>\n<p>我们现在可以把这 5 步，用一句非常生活化的话说清楚：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 128, 128, 1);\">1</span> <span style=\"color: rgba(0, 0, 0, 1);\">把当前情况告诉模型\n</span><span style=\"color: rgba(0, 128, 128, 1);\">2</span> <span style=\"color: rgba(0, 0, 0, 1);\">让模型决定下一小步\n</span><span style=\"color: rgba(0, 128, 128, 1);\">3</span> <span style=\"color: rgba(0, 0, 0, 1);\">把真实结果反馈回去\n</span><span style=\"color: rgba(0, 128, 128, 1);\">4</span> 直到模型觉得“可以收工了”</pre>\n</div>\n<h1>3.Agent Loop代码示例</h1>\n<p>前面我们讲了很多概念：<br />Agent Loop、目标、Prompt、工具、反馈……<br />现在我们用一段最小但完整的代码，把这些概念全部落到实处。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> SimpleAgent:\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">def</span> <span style=\"color: rgba(128, 0, 128, 1);\">__init__</span><span style=\"color: rgba(0, 0, 0, 1);\">(self, llm):\n        self.llm </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> llm\n        self.history </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> []\n\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">def</span><span style=\"color: rgba(0, 0, 0, 1);\"> run(self, goal):\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">while</span><span style=\"color: rgba(0, 0, 0, 1);\"> True:\n            prompt </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> self.build_prompt(goal)\n            response </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> self.llm(prompt)\n\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 如果模型说“完成了”</span>\n            <span style=\"color: rgba(0, 0, 255, 1);\">if</span> response[<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">type</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>] == <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">final</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">:\n                </span><span style=\"color: rgba(0, 0, 255, 1);\">print</span>(response[<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">text</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">])\n                </span><span style=\"color: rgba(0, 0, 255, 1);\">break</span>\n\n            <span style=\"color: rgba(0, 128, 0, 1);\">#</span><span style=\"color: rgba(0, 128, 0, 1);\"> 如果模型要用工具</span>\n            <span style=\"color: rgba(0, 0, 255, 1);\">if</span> response[<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">type</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>] == <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">tool_call</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">:\n                result </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> self.execute_tool(response)\n                self.history.append(result)\n\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">def</span><span style=\"color: rgba(0, 0, 0, 1);\"> build_prompt(self, goal):\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> {\n            </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">goal</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">: goal,\n            </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">history</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">: self.history\n        }\n\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">def</span><span style=\"color: rgba(0, 0, 0, 1);\"> execute_tool(self, call):\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">if</span> call[<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">name</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>] == <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">shell</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">:\n            </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span> os.popen(call[<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">command</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>]).read()</pre>\n</div>\n<p>这段代码不是生产级，但它100%体现了 Agent Loop 的本质结构。下面我们从整体 → 局部 → 每一行的“为什么”来拆。</p>\n<h3>1.先整体理解：这段代码在干什么？</h3>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 0, 1);\">它在做一件事：\n不断把“当前状态”交给模型，让模型决定下一步，\n然后根据结果更新状态，直到模型说“可以结束了”。</span></pre>\n</div>\n<p>可以理解为：“你先想一步 → 我帮你干 → 把结果告诉你 → 你再想一步”</p>\n<h3>2.class SimpleAgent：Agent 不是模型，而是“调度者”</h3>\n<p>Agent ≠ 模型（LLM）</p>\n<ul>\n<li>llm：负责“思考 / 决策”</li>\n<li>Agent：负责“循环 / 执行 / 状态管理”</li>\n</ul>\n<p>Agent 的角色更像是一个项目经理 + 执行助理。</p>\n<h3>3.__init__：Agent 的“长期记忆”在哪里？</h3>\n<p>self.llm 是什么？</p>\n<ul>\n<li>它是一个函数或对象</li>\n<li>输入：Prompt</li>\n<li>输出：模型的“下一步决策”</li>\n</ul>\n<p>你可以把它理解成：</p>\n<div class=\"cnblogs_code\">\n<pre>response = 大模型(prompt)</pre>\n</div>\n<h3>4.self.history 为什么这么重要？</h3>\n<p>这是整个 Agent Loop 的核心状态。</p>\n<p>history 里存的不是聊天记录，而是：</p>\n<ul>\n<li>你刚刚执行了什么命令</li>\n<li>命令输出了什么</li>\n<li>有没有报错</li>\n</ul>\n<p>它是“现实世界发生过的事情”的文本化记录</p>\n<p>如果没有 history：</p>\n<ul>\n<li>模型每一轮都会“失忆”</li>\n<li>永远不知道自己刚才干过什么</li>\n</ul>\n<h3>5.run 方法：Agent Loop 的真正入口</h3>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">def</span> run(self, goal):</pre>\n</div>\n<p>这里的 goal，就是你输入的那句：</p>\n<div class=\"cnblogs_code\">\n<pre>“帮我给这个项目加一个 README”</pre>\n</div>\n<p>它只做一件事：定义终点，不定义路径。</p>\n<h3>6.while True：为什么 Agent 必须是“死循环”？</h3>\n<p>这行代码非常关键。</p>\n<p>很多人一看到“死循环”会下意识觉得不优雅，但在 Agent 里：</p>\n<ul>\n<li>没有循环，就没有 Agent</li>\n</ul>\n<p>为什么？</p>\n<p>因为 Agent 的工作模式是：</p>\n<ul>\n<li>不知道要循环多少轮</li>\n<li>不知道什么时候信息才“足够”</li>\n<li>只能一轮一轮试</li>\n</ul>\n<p>结束条件不是写死的，而是由模型决定的。</p>\n<h3>7.build_prompt：模型“看到的世界”是怎么来的？</h3>\n<div class=\"cnblogs_code\">\n<pre>prompt = self.build_prompt(goal)</pre>\n</div>\n<p>这是 Agent Loop 中最容易被忽略，但最重要的一步。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">def</span><span style=\"color: rgba(0, 0, 0, 1);\"> build_prompt(self, goal):\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> {\n        </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">goal</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">: goal,\n        </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">history</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">: self.history\n    }</span></pre>\n</div>\n<p>它做的事情非常简单，但意义非常大：把“目标 + 已发生的事实”打包，交给模型。</p>\n<h3>8.response = self.llm(prompt)：模型只做一件事</h3>\n<div class=\"cnblogs_code\">\n<pre>response = self.llm(prompt)</pre>\n</div>\n<p>这一行，看似简单，其实决定了整个 Agent 的风格。</p>\n<p>模型在这里不会：</p>\n<ul>\n<li>写完整代码</li>\n<li>一次性解决所有问题</li>\n</ul>\n<p>它只回答一个问题：</p>\n<ul>\n<li>“在当前 prompt 条件下，我下一步该做什么？”</li>\n</ul>\n<p>我们用一句完整的流程复述：</p>\n<ul>\n<li>Agent 把目标 + 历史交给模型</li>\n<li>模型说：“下一步干这个”</li>\n<li>Agent 去真实执行</li>\n<li>Agent 把结果记录下来</li>\n<li>回到第 1 步</li>\n<li>直到模型说：</li>\n<li>“可以结束了。”</li>\n</ul>\n<h1>4.总结</h1>\n<p>Codex Agent 的真正价值，并不在于它“写代码有多快”，而在于它被设计成一个可以反复思考和行动的系统。通过 Agent Loop，模型不再试图一次性给出完美答案，而是像真实工程师一样：先尝试、再观察、再修正，逐步推进目标完成。这种“思考 → 执行 → 反馈 → 再思考”的循环机制，让复杂问题被自然拆解成一连串可验证的小步骤，也让错误变成系统的一部分，而不是失败的终点。</p>\n<h1>5.结束语</h1>\n<p>这篇博客就和大家分享到这里，如果大家在研究学习的过程当中有什么问题，可以加群进行讨论或发送邮件给我，我会尽我所能为您解答，与君共勉！</p>\n<p>另外，博主出新书了《<span style=\"color: rgba(255, 0, 0, 1);\"><strong><a href=\"https://item.jd.com/14421833.html\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(255, 0, 0, 1);\">Hadoop与Spark大数据全景解析</span></a></strong></span>》、同时已出版的《<span style=\"color: rgba(0, 0, 255, 1);\"><strong><a href=\"https://item.jd.com/14699434.html\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">深入理解Hive</span></a></strong></span>》、《<span style=\"color: rgba(0, 0, 255, 1);\"><strong><a href=\"https://item.jd.com/12455361.html\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">Kafka并不难学</span></a></strong></span>》和《<span style=\"color: rgba(0, 0, 255, 1);\"><strong><a href=\"https://item.jd.com/12371763.html\" rel=\"noopener nofollow\" target=\"_blank\"><span style=\"color: rgba(0, 0, 255, 1);\">Hadoop大数据挖掘从入门到进阶实战</span></a></strong></span>》也可以和新书配套使用，喜欢的朋友或同学， 可以<span style=\"color: rgba(255, 0, 0, 1);\"><strong>在公告栏那里点击购买链接购买博主的书</strong></span>进行学习，在此感谢大家的支持。关注下面公众号，根据提示，可免费获取书籍的教学视频。</p>\n<p>&nbsp;</p>\n\n</div>\n<div id=\"MySignature\">\n    <div>\n<b class=\"b1\"></b><b class=\"b2 d1\"></b><b class=\"b3 d1\"></b><b class=\"b4 d1\"></b>\n<div class=\"b d1 k\">  \n联系方式：\n<br />\n邮箱：smartloli.org@gmail.com\n<br />\n<strong style=\"color: green;\">QQ群（Hive与AI实战【新群】）：935396818</strong>\n<br />\nQQ群（Hadoop - 交流社区1）：424769183\n<br />\nQQ群（Kafka并不难学）：825943084\n<br />\n温馨提示：请大家加群的时候写上加群理由（姓名＋公司/学校），方便管理员审核，谢谢！\n<br />\n<h3>热爱生活，享受编程，与君共勉！</h3>  \n</div>\n<b class=\"b4b d1\"></b><b class=\"b3b d1\"></b><b class=\"b2b d1\"></b><b class=\"b1b\"></b>\n</div>\n<br />\n<div>\n<b class=\"b1\"></b><b class=\"b2 d1\"></b><b class=\"b3 d1\"></b><b class=\"b4 d1\"></b>\n<div class=\"b d1 k\">\n<h3>公众号：</h3>\n<h3><img src=\"https://www.cnblogs.com/images/cnblogs_com/smartloli/1324636/t_qr.png\" style=\"width: 8%; margin-left: 10px;\" /></h3>\n</div>\n<b class=\"b4b d1\"></b><b class=\"b3b d1\"></b><b class=\"b2b d1\"></b><b class=\"b1b\"></b>\n</div>\n<br />\n<div>\n<b class=\"b1\"></b><b class=\"b2 d1\"></b><b class=\"b3 d1\"></b><b class=\"b4 d1\"></b>\n<div class=\"b d1 k\">\n<h3>作者：哥不是小萝莉 ［<a href=\"http://www.kafka-eagle.org/\" style=\"color: green;\" target=\"_blank\">关于我</a>］［<a href=\"http://www.cnblogs.com/smartloli/p/4241701.html\" style=\"color: green;\" target=\"_blank\">犒赏</a>］</h3>\n<h3>出处：<a href=\"http://www.cnblogs.com/smartloli/\" style=\"color: green;\" target=\"_blank\">http://www.cnblogs.com/smartloli/</a></h3>\n<h3>转载请注明出处，谢谢合作！</h3>\n</div>\n<b class=\"b4b d1\"></b><b class=\"b3b d1\"></b><b class=\"b2b d1\"></b><b class=\"b1b\"></b>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 23:32</span>&nbsp;\n<a href=\"https://www.cnblogs.com/smartloli\">哥不是小萝莉</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "使用 JYPPX.DeploySharp 高效部署 PaddleOCR，解锁多种高性能 OCR 文字识别方案",
      "link": "https://www.cnblogs.com/guojin-blogs/p/19545866",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/guojin-blogs/p/19545866\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 22:40\">\n    <span>使用 JYPPX.DeploySharp 高效部署 PaddleOCR，解锁多种高性能 OCR 文字识别方案</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"使用 JYPPX.DeploySharp 高效部署 PaddleOCR，解锁多种高性能 OCR 文字识别方案\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2933426/202601/2933426-20260128223946237-441095120.png\" />\n        本文介绍了基于DeploySharp框架在.NET环境下部署PaddleOCR模型的解决方案。该框架通过统一接口封装了OpenVINO、TensorRT、ONNX Runtime等多种推理引擎，支持百毫秒级文字识别。文章详细解析了PaddleOCR三阶段工作流程（检测-分类-识别）及性能优化策略，阐述了DeploySharp\"统一接口、灵活部署\"的架构优势。演示程序支持多种推理后端，涵盖CPU/GPU不同硬件场景，提供模型加载、图片推理、性能测试等功能。通过该方案，开发者可根据实际硬件环\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"使用-jyppxdeploysharp-高效部署-paddleocr解锁多种高性能-ocr-文字识别方案\">使用 JYPPX.DeploySharp 高效部署 PaddleOCR，解锁多种高性能 OCR 文字识别方案</h1>\n<blockquote>\n<p>本文介绍如何通过 DeploySharp 框架在 .NET 环境下部署 PaddleOCR 模型，支持 OpenVINO、TensorRT、ONNX Runtime 等多种推理引擎，实现百毫秒级文字识别。</p>\n</blockquote>\n<hr />\n<h2 id=\"目录\">目录</h2>\n<ul>\n<li><a href=\"#%E4%B8%80%E5%89%8D%E8%A8%80\" rel=\"noopener nofollow\">一、前言</a></li>\n<li><a href=\"#%E4%BA%8C%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90\" rel=\"noopener nofollow\">二、核心技术原理解析</a></li>\n<li><a href=\"#%E4%B8%89deploysharp-%E6%9E%B6%E6%9E%84%E4%BC%98%E5%8A%BF\" rel=\"noopener nofollow\">三、DeploySharp 架构优势</a></li>\n<li><a href=\"#%E5%9B%9B%E6%94%AF%E6%8C%81%E7%9A%84%E6%8E%A8%E7%90%86%E8%AE%BE%E5%A4%87\" rel=\"noopener nofollow\">四、支持的推理设备</a></li>\n<li><a href=\"#%E4%BA%94%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B%E6%8C%87%E5%8D%97\" rel=\"noopener nofollow\">五、快速开始指南</a></li>\n<li><a href=\"#%E5%85%AD%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%8E%E5%88%86%E6%9E%90\" rel=\"noopener nofollow\">六、性能测试与分析</a></li>\n<li><a href=\"#%E4%B8%83%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94\" rel=\"noopener nofollow\">七、常见问题解答</a></li>\n<li><a href=\"#%E5%85%AB%E8%BD%AF%E4%BB%B6%E8%8E%B7%E5%8F%96\" rel=\"noopener nofollow\">八、软件获取</a></li>\n<li><a href=\"#%E4%B9%9D%E6%8A%80%E6%9C%AF%E6%94%AF%E6%8C%81\" rel=\"noopener nofollow\">九、技术支持</a></li>\n</ul>\n<hr />\n<h2 id=\"一前言\">一、前言</h2>\n<p>OCR（光学字符识别）技术在数字化办公、文档管理、票据识别等场景中发挥着重要作用。百度飞桨开源的 <strong>PaddleOCR</strong> 作为业界领先的 OCR 框架，以其优异的识别精度和丰富的功能特性深受开发者喜爱。</p>\n<p>一年前，我基于自己开发的 OpenVINO C# API 项目，在 .NET 框架下使用 OpenVINO 部署工具部署 PaddleOCR 系列模型，推出了 <strong>PaddleOCR-OpenVINO-CSharp</strong> 项目。借助 OpenVINO 在 CPU 上的强大推理优化能力，该项目成功实现了在纯 CPU 环境下完成图片文字识别、版面分析及表格识别等功能，推理速度可控制在 300 毫秒以内。</p>\n<p>随着项目的发展和应用场景的多样化，单一推理引擎已无法满足所有需求。近期，我将 OpenVINO、TensorRT、ONNX Runtime 等主流推理工具进行了统一封装，推出了 <strong>DeploySharp</strong> 开源项目。该项目的核心优势在于：</p>\n<ul>\n<li><strong>统一接口</strong>：通过底层接口抽象，实现一套代码适配多种推理引擎</li>\n<li><strong>灵活部署</strong>：开发者可根据实际硬件环境选择最优推理方案</li>\n<li><strong>性能优化</strong>：充分发挥各推理引擎的硬件加速能力</li>\n</ul>\n<p>得益于 DeploySharp 底层接口统一的优势，开发者现在可以用同一段代码在 OpenVINO、TensorRT、ONNX Runtime 等多种推理引擎间自由切换。近期，我们完成了 PaddleOCR 模型的支持更新，为 .NET 开发者提供了一套完整的 OCR 解决方案。</p>\n<p>目前，PaddleOCR 功能已集成至 DeploySharp 开源项目中（代码已上传至仓库，NuGet 包正在筹备中）。为了让大家快速体验新版 PaddleOCR 的极致性能，我们特别准备了 <strong>JYPPX.DeploySharp.OpenCvSharp.PaddleOcr.TestDemo</strong> 演示程序，支持即开即用，无需复杂配置。</p>\n<hr />\n<h2 id=\"二核心技术原理解析\">二、核心技术原理解析</h2>\n<h3 id=\"21-paddleocr-工作流程\">2.1 PaddleOCR 工作流程</h3>\n<p>PaddleOCR 采用经典的「检测-分类-识别」三阶段流水线架构：</p>\n<pre><code>输入图片\n    │\n    ▼\n┌─────────────┐\n│ 文本检测     │ → 检测图片中的文本区域位置\n│ (Detection) │\n└─────────────┘\n    │\n    ▼\n┌─────────────┐\n│ 文本方向分类 │ → 判断文本方向（180度翻转等）\n│ (Classifier)│\n└─────────────┘\n    │\n    ▼\n┌─────────────┐\n│ 文本识别     │ → 识别文本区域的具体内容\n│ (Recognition)│\n└─────────────┘\n    │\n    ▼\n输出识别结果\n</code></pre>\n<h3 id=\"22-三阶段模型详解\">2.2 三阶段模型详解</h3>\n<table>\n<thead>\n<tr>\n<th>阶段</th>\n<th>模型名称</th>\n<th>输入</th>\n<th>输出</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>检测</td>\n<td>PP-OCRv5_det</td>\n<td>原始图片 (3xHxW)</td>\n<td>文本框坐标</td>\n<td>定位文本区域</td>\n</tr>\n<tr>\n<td>分类</td>\n<td>PP-OCRv5_cls</td>\n<td>裁剪文本框 (3x80x160)</td>\n<td>方向标签</td>\n<td>纠正文本方向</td>\n</tr>\n<tr>\n<td>识别</td>\n<td>PP-OCRv5_rec</td>\n<td>裁剪文本框 (3x48xL)</td>\n<td>文本内容</td>\n<td>识别字符序列</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"23-性能优化策略\">2.3 性能优化策略</h3>\n<ol>\n<li><strong>模型量化</strong>：使用 int8 量化减小模型体积，提升推理速度</li>\n<li><strong>动态批处理</strong>：支持 Batch Size &gt; 1，提高 GPU 利用率</li>\n<li><strong>并发推理</strong>：支持多线程并发处理，充分利用多核性能</li>\n<li><strong>硬件加速</strong>：针对不同硬件选择最优计算后端</li>\n</ol>\n<hr />\n<h2 id=\"三deploysharp-架构优势\">三、DeploySharp 架构优势</h2>\n<p>DeploySharp 的核心设计理念是「<strong>统一接口，灵活部署</strong>」，其架构如下图所示：</p>\n<pre><code>┌─────────────────────────────────────────────────────────┐\n│                    应用层 (Application)                  │\n│            PaddleOCR 文字识别 / 其他模型应用              │\n└─────────────────────────────────────────────────────────┘\n                            │\n                            ▼\n┌─────────────────────────────────────────────────────────┐\n│                 DeploySharp 抽象接口层                    │\n│  统一的模型加载 / 推理执行 / 资源管理接口                 │\n└─────────────────────────────────────────────────────────┘\n                            │\n            ┌───────────────┼───────────────┐\n            ▼               ▼               ▼\n┌───────────────┐ ┌───────────────┐ ┌───────────────┐\n│   OpenVINO    │ │   TensorRT    │ │ ONNX Runtime  │\n│   Engine      │ │   Engine      │ │    Engine     │\n│  (CPU 优化)   │ │ (GPU 加速)    │ │ (跨平台支持)   │\n└───────────────┘ └───────────────┘ └───────────────┘\n            │               │               │\n            ▼               ▼               ▼\n┌───────────────┐ ┌───────────────┐ ┌───────────────┐\n│  Intel CPU    │ │  NVIDIA GPU   │ │ 多种硬件设备   │\n│               │ │               │ │ (CPU/GPU/DML) │\n└───────────────┘ └───────────────┘ └───────────────┘\n</code></pre>\n<p><strong>主要优势：</strong></p>\n<ul>\n<li><strong>零代码切换</strong>：更换推理引擎无需修改业务代码</li>\n<li><strong>资源高效利用</strong>：自动管理模型生命周期和计算资源</li>\n<li><strong>扩展性强</strong>：易于添加新的推理引擎支持</li>\n<li><strong>生产就绪</strong>：经过充分测试，可直接用于生产环境</li>\n</ul>\n<hr />\n<h2 id=\"四支持的推理设备\">四、支持的推理设备</h2>\n<p>本演示程序支持多种主流推理后端，覆盖从入门级设备到高性能服务器的各种场景：</p>\n<table>\n<thead>\n<tr>\n<th>推理引擎</th>\n<th>支持设备</th>\n<th>适用场景</th>\n<th>性能特点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>OpenVINO</strong></td>\n<td>CPU</td>\n<td>无 GPU 环境、Intel 处理器</td>\n<td>CPU 优化，启动快，稳定</td>\n</tr>\n<tr>\n<td><strong>TensorRT</strong></td>\n<td>CUDA 11/12</td>\n<td>NVIDIA GPU 高性能场景</td>\n<td>GPU 加速，极致性能，需模型转换</td>\n</tr>\n<tr>\n<td><strong>ONNX Runtime CPU</strong></td>\n<td>CPU</td>\n<td>跨平台部署</td>\n<td>通用性强，性能中等</td>\n</tr>\n<tr>\n<td><strong>ONNX Runtime CUDA</strong></td>\n<td>CUDA 12</td>\n<td>NVIDIA GPU 环境部署</td>\n<td>GPU 加速，开箱即用</td>\n</tr>\n<tr>\n<td><strong>ONNX Runtime TensorRT</strong></td>\n<td>CUDA 12</td>\n<td>NVIDIA GPU 高性能场景</td>\n<td>GPU 加速 + TensorRT 优化</td>\n</tr>\n<tr>\n<td><strong>ONNX Runtime DML</strong></td>\n<td>DML GPU</td>\n<td>Windows 平台多厂商 GPU</td>\n<td>支持 AMD/NVIDIA/Intel GPU</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p><strong>性能提示</strong>：首次加载模型和推理时会较慢，这是正常现象（模型初始化和 JIT 编译）。首次运行时请避免频繁操作，待模型预热完成后性能将显著提升。</p>\n</blockquote>\n<hr />\n<h2 id=\"五快速开始指南\">五、快速开始指南</h2>\n<h3 id=\"51-程序界面概览\">5.1 程序界面概览</h3>\n<p>运行程序后，主界面如下图所示：</p>\n<img alt=\"image-20260128211529014\" class=\"lazyload\" />\n<p><strong>核心操作说明：</strong></p>\n<table>\n<thead>\n<tr>\n<th>操作项</th>\n<th>说明</th>\n<th>注意事项</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>推理后端</td>\n<td>选择使用的推理引擎</td>\n<td>切换后需重新加载模型</td>\n</tr>\n<tr>\n<td>模型路径</td>\n<td>预置模型路径，一般无需修改</td>\n<td>支持自定义模型路径</td>\n</tr>\n<tr>\n<td>图像路径</td>\n<td>选择待识别的图片</td>\n<td>支持 JPG/PNG/BMP 等格式</td>\n</tr>\n<tr>\n<td>加载模型</td>\n<td>加载指定模型到内存</td>\n<td>首次使用必须执行</td>\n</tr>\n<tr>\n<td>推理图片</td>\n<td>执行单次图片识别</td>\n<td>首次需预热</td>\n</tr>\n<tr>\n<td>时间测试</td>\n<td>连续推理十次并统计平均耗时</td>\n<td>用于性能评估</td>\n</tr>\n<tr>\n<td>并发数量</td>\n<td>调整推理并发线程数</td>\n<td>修改后需重新加载模型</td>\n</tr>\n<tr>\n<td>BatchSize</td>\n<td>批量处理大小</td>\n<td>可动态调整</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h3 id=\"52-openvino-推理\">5.2 OpenVINO 推理</h3>\n<p>OpenVINO 是 Intel 推出的开源工具套件，针对 CPU 和Intel IGPU进行了深度优化，特别适合无 GPU 环境下的高性能推理。</p>\n<p><strong>CPU使用步骤：</strong></p>\n<p>1.运行程序</p>\n<p><img alt=\"程序主界面\" class=\"lazyload\" /></p>\n<p>2.在「推理后端」下拉框中选择 <strong>OpenVINO</strong></p>\n<p>3.点击「加载模型」</p>\n<p>4.点击「推理图片」开始识别</p>\n<img alt=\"image-20260128221119962\" class=\"lazyload\" />\n<p><strong>IGPU使用步骤：</strong></p>\n<p>英特尔集显使用流程与上述一致，主要是设备要选择<strong>GPU0</strong>：</p>\n<img alt=\"image-20260128221345165\" class=\"lazyload\" />\n<p><strong>混合设备使用步骤：</strong></p>\n<p>英特尔OpenVINO支持CPU+IGPU混合设备推理，即<strong>AUTO</strong>模式，OpenVINO会根据设备情况自主选择，使用方式与上述一致，主要是设备要选择<strong>AUTO</strong>：</p>\n<img alt=\"image-20260128221535531\" class=\"lazyload\" />\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>服务器环境部署</li>\n<li>低功耗设备</li>\n<li>Intel CPU 用户</li>\n<li>对启动速度要求高的场景</li>\n</ul>\n<hr />\n<h3 id=\"53-onnx-runtime-cpu-推理\">5.3 ONNX Runtime CPU 推理</h3>\n<p>ONNX Runtime 是微软推出的跨平台推理引擎，支持多种硬件加速后端，CPU 模式无需任何依赖即可使用。</p>\n<p><strong>使用步骤：</strong></p>\n<ol>\n<li>运行程序</li>\n<li>在「推理后端」下拉框中选择 <strong>ONNX Runtime CPU</strong></li>\n<li>点击「加载模型」</li>\n<li>点击「推理图片」开始识别</li>\n</ol>\n<p><img alt=\"ONNX Runtime CPU 选择界面\" class=\"lazyload\" /></p>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>跨平台部署需求</li>\n<li>无 GPU 加速环境</li>\n<li>需要快速原型验证</li>\n</ul>\n<hr />\n<h3 id=\"54-onnx-runtime-cuda-推理\">5.4 ONNX Runtime CUDA 推理</h3>\n<p>CUDA 是 NVIDIA 提供的并行计算平台，可充分利用 GPU 的并行计算能力实现显著加速。</p>\n<h4 id=\"配置步骤\">配置步骤</h4>\n<ol>\n<li>\n<p><strong>安装 CUDA 驱动</strong></p>\n<ul>\n<li>访问 <a href=\"https://developer.nvidia.com/cuda-downloads\" rel=\"noopener nofollow\" target=\"_blank\">NVIDIA CUDA 官网</a></li>\n<li>下载并安装 CUDA 12.x 版本（测试环境：CUDA 12.3）</li>\n</ul>\n</li>\n<li>\n<p><strong>复制依赖文件</strong></p>\n<p>将以下 CUDA 相关 DLL 文件复制到程序运行目录：</p>\n<p><img alt=\"CUDA 依赖文件\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p><strong>启动推理</strong></p>\n<p>运行程序，在「推理后端」下拉框中选择 <strong>ONNX Runtime CUDA</strong></p>\n<p><img alt=\"ONNX Runtime CUDA 选择界面\" class=\"lazyload\" /></p>\n</li>\n</ol>\n<p><strong>依赖说明：</strong></p>\n<table>\n<thead>\n<tr>\n<th>NuGet 包名</th>\n<th>版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Microsoft.ML.OnnxRuntime.Gpu.Windows</td>\n<td>1.23.0</td>\n</tr>\n<tr>\n<td>Microsoft.ML.OnnxRuntime.Managed</td>\n<td>1.23.0</td>\n</tr>\n</tbody>\n</table>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>拥有 NVIDIA 显卡的设备</li>\n<li>对推理速度有较高要求</li>\n<li>需要快速部署无需模型转换</li>\n</ul>\n<hr />\n<h3 id=\"55-onnx-runtime-tensorrt-推理\">5.5 ONNX Runtime TensorRT 推理</h3>\n<p>TensorRT 是 NVIDIA 推出的高性能深度学习推理优化器，结合 CUDA 加速可达到极致性能。</p>\n<h4 id=\"配置步骤-1\">配置步骤</h4>\n<p>依赖文件复制方式与 CUDA 模式一致。</p>\n<h4 id=\"使用步骤\">使用步骤</h4>\n<ol>\n<li>运行程序</li>\n<li>在「推理后端」下拉框中选择 <strong>ONNX Runtime TensorRT</strong></li>\n<li>点击「加载模型」</li>\n<li>点击「推理图片」开始识别</li>\n</ol>\n<p><img alt=\"ONNX Runtime TensorRT 选择界面\" class=\"lazyload\" /></p>\n<blockquote>\n<p><strong>重要提示</strong>：首次运行推理时，TensorRT 会自动对 ONNX 模型进行优化编译，此过程可能需要数分钟，请耐心等待。编译后的引擎文件会被缓存，后续推理速度将大幅提升。</p>\n</blockquote>\n<p><strong>依赖说明：</strong></p>\n<table>\n<thead>\n<tr>\n<th>NuGet 包名</th>\n<th>版本</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Microsoft.ML.OnnxRuntime.Gpu.Windows</td>\n<td>1.23.2</td>\n</tr>\n<tr>\n<td>Microsoft.ML.OnnxRuntime.Managed</td>\n<td>1.23.2</td>\n</tr>\n</tbody>\n</table>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>对推理速度要求极高的生产环境</li>\n<li>NVIDIA GPU 设备</li>\n<li>可接受首次运行较长的编译时间</li>\n</ul>\n<hr />\n<h3 id=\"56-onnx-runtime-dml-推理\">5.6 ONNX Runtime DML 推理</h3>\n<p>DirectML（DML）是 Windows 平台的高性能硬件加速接口，支持 AMD、NVIDIA 和 Intel 多厂商显卡。</p>\n<h4 id=\"配置步骤-2\">配置步骤</h4>\n<p>将 DML 相关 DLL 文件复制到程序运行目录：</p>\n<p><img alt=\"DML 依赖文件\" class=\"lazyload\" /></p>\n<h4 id=\"使用步骤-1\">使用步骤</h4>\n<ol>\n<li>运行程序</li>\n<li>在「推理后端」下拉框中选择 <strong>ONNX Runtime DML</strong></li>\n<li>点击「加载模型」</li>\n<li>点击「推理图片」开始识别</li>\n</ol>\n<p><img alt=\"ONNX Runtime DML 选择界面\" class=\"lazyload\" /></p>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>Windows 平台用户</li>\n<li>AMD 显卡用户</li>\n<li>需要统一接口支持多品牌显卡</li>\n</ul>\n<hr />\n<h3 id=\"57-tensorrtsharp-推理\">5.7 TensorRTSharp 推理</h3>\n<p>TensorRTSharp 是对 NVIDIA TensorRT 的 C# 封装，提供原生的 TensorRT 引擎加载和推理能力，支持 FP16 精度进一步提升性能。</p>\n<h4 id=\"环境准备\">环境准备</h4>\n<p>详细的安装和配置指南请参考：</p>\n<pre><code>https://mp.weixin.qq.com/s/D0c6j5MmraJO4Eza7tWm1A\n</code></pre>\n<p>TensorRTSharp 支持 CUDA 11 和 CUDA 12 两个系列，请根据系统安装的 CUDA 版本选择对应的 DLL 文件。</p>\n<h4 id=\"配置步骤-3\">配置步骤</h4>\n<ol>\n<li>\n<p><strong>替换 DLL 文件</strong></p>\n<p>根据安装的 CUDA 版本，将对应的 TensorRT DLL 文件复制到程序目录：</p>\n<p><img alt=\"TensorRT DLL 文件\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p><strong>模型转换</strong></p>\n<p>使用 <code>trtexec</code> 工具将 ONNX 模型转换为 TensorRT 引擎文件：</p>\n<p><img alt=\"trtexec 转换工具\" class=\"lazyload\" /></p>\n</li>\n</ol>\n<h4 id=\"模型转换指令\">模型转换指令</h4>\n<p><strong>文本检测模型（Det）：</strong></p>\n<pre><code class=\"language-bash\">trtexec.exe --onnx=PP-OCRv5_mobile_det_onnx.onnx \\\n  --minShapes=x:1x3x32x32 \\\n  --optShapes=x:4x3x640x640 \\\n  --maxShapes=x:8x3x960x960 \\\n  --fp16 \\\n  --memPoolSize=workspace:1024 \\\n  --sparsity=disable \\\n  --saveEngine=PP-OCRv5_mobile_det_f16_onnx.engine\n</code></pre>\n<p><strong>文本分类模型（Cls）：</strong></p>\n<pre><code class=\"language-bash\">trtexec.exe --onnx=PP-OCRv5_mobile_cls_onnx.onnx \\\n  --minShapes=x:1x3x80x160 \\\n  --optShapes=x:8x3x80x160 \\\n  --maxShapes=x:64x3x80x160 \\\n  --fp16 \\\n  --memPoolSize=workspace:1024 \\\n  --sparsity=disable \\\n  --saveEngine=PP-OCRv5_mobile_cls_f16_onnx.engine\n</code></pre>\n<p><strong>文本识别模型（Rec）：</strong></p>\n<pre><code class=\"language-bash\">trtexec.exe --onnx=PP-OCRv5_mobile_rec_onnx.onnx \\\n  --minShapes=x:1x3x48x48 \\\n  --optShapes=x:8x3x48x1024 \\\n  --maxShapes=x:64x3x48x1024 \\\n  --fp16 \\\n  --memPoolSize=workspace:1024 \\\n  --sparsity=disable \\\n  --saveEngine=PP-OCRv5_mobile_rec_f16_onnx.engine\n</code></pre>\n<h4 id=\"开始推理\">开始推理</h4>\n<p>模型转换完成后，在程序中选择对应的 <code>.engine</code> 文件即可开始推理：</p>\n<p><img alt=\"TensorRT 引擎文件选择\" class=\"lazyload\" /></p>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li>追求极致推理性能</li>\n<li>NVIDIA GPU 环境</li>\n<li>允许离线模型转换</li>\n</ul>\n<hr />\n<h2 id=\"六性能测试与分析\">六、性能测试与分析</h2>\n<h3 id=\"61-性能测试工具\">6.1 性能测试工具</h3>\n<p>演示程序内置了完整的性能测试工具，支持两种测试模式：</p>\n<ol>\n<li><strong>整体耗时统计</strong>：计算从图片输入到结果输出的完整端到端耗时</li>\n<li><strong>详细阶段分析</strong>：记录预处理、推理、后处理各阶段的具体耗时</li>\n</ol>\n<p><img alt=\"整体耗时统计\" class=\"lazyload\" /></p>\n<p><img alt=\"详细性能记录\" class=\"lazyload\" /></p>\n<h3 id=\"62-tensorrtsharp-性能示例\">6.2 TensorRTSharp 性能示例</h3>\n<p>以下为使用 TensorRTSharp 在 4 并发配置下的性能测试数据：</p>\n<pre><code>Inference time: 53 ms\n\n---- Detection ----\n\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         2.01              6.37              0.57              8.96\n2         2.23              5.51              0.68              8.43\n\n---- Classification ----\n\nDevice/Worker 0:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         1.84              6.89              0.00              8.73\n2         1.99              6.97              0.01              8.96\n\nDevice/Worker 1:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         1.79              6.66              0.00              8.46\n2         1.66              7.60              0.00              9.26\n\nDevice/Worker 2:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         1.61              5.31              0.00              6.92\n2         1.51              8.01              0.00              9.53\n\nDevice/Worker 3:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         1.24              7.73              0.00              8.98\n2         1.82              8.35              0.00              10.17\n\n---- Recognition ----\n\nDevice/Worker 0:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         0.00              41.97             1.42              43.39\n2         0.00              14.50             2.30              16.81\n\nDevice/Worker 1:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         0.00              47.40             6.81              54.21\n2         0.00              19.42             2.76              22.18\n\nDevice/Worker 2:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         0.00              38.10             3.42              41.52\n2         0.00              22.36             3.37              25.73\n\nDevice/Worker 3:\nInference Time Records:\nIndex    Preprocess(ms)    Inference(ms)    Postprocess(ms)    Total(ms)\n1         0.00              109.94            4.58              114.52\n2         0.00              26.59             4.55              31.14\n</code></pre>\n<h3 id=\"63-性能对比总结\">6.3 性能对比总结</h3>\n<p>下表为使用洗发水图片，跑10次的平均时间测试：</p>\n<table>\n<thead>\n<tr>\n<th>推理引擎</th>\n<th>设备</th>\n<th>平均耗时</th>\n<th>设备类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OpenVINO</td>\n<td>CPU</td>\n<td>288ms</td>\n<td>Intel(R) Core(TM) Ultra 9 288V  8核</td>\n</tr>\n<tr>\n<td>OpenVINO</td>\n<td>IGPU</td>\n<td>99ms</td>\n<td>Intel(R) Arc(TM) 140V GPU (16GB)</td>\n</tr>\n<tr>\n<td>OpenVINO</td>\n<td>混合 AUTO：IGPU+CPU</td>\n<td>100ms</td>\n<td>Intel(R) Core(TM) Ultra 9 288V  8核  <br />Intel(R) Arc(TM) 140V GPU (16GB)</td>\n</tr>\n<tr>\n<td>ONNX Runtime</td>\n<td>CPU</td>\n<td>656ms</td>\n<td>AMD Ryzen 7 5800H with Radeon Graphics 8核</td>\n</tr>\n<tr>\n<td>ONNX Runtime DML</td>\n<td>GPU</td>\n<td>114ms</td>\n<td>NVIDIA GeForce RTX 3060 Laptop GPU</td>\n</tr>\n<tr>\n<td>ONNX Runtime DML</td>\n<td>IGPU</td>\n<td>331ms</td>\n<td>Intel(R) Arc(TM) 140V GPU (16GB)</td>\n</tr>\n<tr>\n<td>ONNX Runtime CUDA</td>\n<td>GPU</td>\n<td>93ms</td>\n<td>NVIDIA GeForce RTX 3060 Laptop GPU</td>\n</tr>\n<tr>\n<td>ONNX Runtime TensorRT</td>\n<td>GPU</td>\n<td>52ms</td>\n<td>NVIDIA GeForce RTX 3060 Laptop GPU</td>\n</tr>\n<tr>\n<td>TensorRTSharp</td>\n<td>GPU</td>\n<td>51ms</td>\n<td>NVIDIA GeForce RTX 3060 Laptop GPU</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p><strong>性能测试征集</strong>：我们欢迎广大开发者分享各自的测试数据。请在评论区提供您的测试配置（硬件型号、并发数、Batch Size）和实测耗时，后续我们将整理成性能基准对比表。</p>\n</blockquote>\n<hr />\n<h2 id=\"七常见问题解答\">七、常见问题解答</h2>\n<h3 id=\"q1-首次推理为什么特别慢\">Q1: 首次推理为什么特别慢？</h3>\n<p><strong>A:</strong> 首次推理时需要进行以下操作：</p>\n<ul>\n<li>模型加载到内存</li>\n<li>推理引擎初始化</li>\n<li>JIT 编译（部分引擎）</li>\n</ul>\n<p>这是正常现象，后续推理速度会显著提升。</p>\n<hr />\n<h3 id=\"q2-如何选择合适的推理引擎\">Q2: 如何选择合适的推理引擎？</h3>\n<p><strong>A:</strong> 根据硬件环境和需求选择：</p>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>推荐引擎</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>无 GPU，有Intel CPU,追求稳定性</td>\n<td>OpenVINO</td>\n</tr>\n<tr>\n<td>有Intel GPU，需要跨平台</td>\n<td>OpenVINO</td>\n</tr>\n<tr>\n<td>无 GPU，需要跨平台</td>\n<td>ONNX Runtime CPU</td>\n</tr>\n<tr>\n<td>有 NVIDIA 显卡，快速部署</td>\n<td>ONNX Runtime CUDA</td>\n</tr>\n<tr>\n<td>有 NVIDIA 显卡，追求性能</td>\n<td>ONNX Runtime TensorRT / TensorRTSharp</td>\n</tr>\n<tr>\n<td>Windows 平台，AMD 显卡</td>\n<td>ONNX Runtime DML</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h3 id=\"q3-切换推理引擎时为什么需要重新加载模型\">Q3: 切换推理引擎时为什么需要重新加载模型？</h3>\n<p><strong>A:</strong> 不同推理引擎对模型格式的内部表示和优化策略不同，因此需要重新解析和加载模型。点击「加载模型」即可完成切换。</p>\n<hr />\n<h3 id=\"q4-batchsize-和并发数量有什么区别\">Q4: BatchSize 和并发数量有什么区别？</h3>\n<p><strong>A:</strong> 两个参数的作用不同：</p>\n<ul>\n<li><strong>BatchSize</strong>：单次推理处理的图片数量，提升 GPU 利用率</li>\n<li><strong>并发数量</strong>：同时运行的推理引擎数量，设置几个就会生成几个推理引擎进行同时推理，提升多核/CPU 利用率</li>\n</ul>\n<p>调整 BatchSize 不需要重新加载模型，但调整并发数量后需要重新加载。</p>\n<hr />\n<h3 id=\"q5-tensorrt-模型转换失败怎么办\">Q5: TensorRT 模型转换失败怎么办？</h3>\n<p><strong>A:</strong> 检查以下几点：</p>\n<ol>\n<li>确保 CUDA 版本与 TensorRT 版本匹配</li>\n<li>检查 ONNX 模型文件是否完整</li>\n<li>确认 <code>trtexec</code> 参数中输入尺寸范围合理</li>\n<li>如显存不足，减小 <code>--memPoolSize</code> 参数</li>\n</ol>\n<hr />\n<h3 id=\"q6-推理结果为空或识别不准确怎么办\">Q6: 推理结果为空或识别不准确怎么办？</h3>\n<p><strong>A:</strong> 常见原因和解决方法：</p>\n<ol>\n<li><strong>图片质量</strong>：检查图片是否模糊、倾斜或光照不足</li>\n<li><strong>输入尺寸</strong>：确保图片尺寸符合模型输入要求</li>\n<li><strong>语言支持</strong>：确认模型是否支持目标语言</li>\n<li><strong>模型版本</strong>：尝试使用不同版本的 PaddleOCR 模型</li>\n</ol>\n<hr />\n<h2 id=\"八软件获取\">八、软件获取</h2>\n<h3 id=\"81-源码下载\">8.1 源码下载</h3>\n<p>DeploySharp 项目已完全开源，可通过以下方式获取：</p>\n<p><strong>主仓库：</strong></p>\n<pre><code>https://github.com/guojin-yan/DeploySharp.git\n</code></pre>\n<p><strong>PaddleOCR 演示程序：</strong></p>\n<pre><code>https://github.com/guojin-yan/DeploySharp/tree/DeploySharpV1.0/applications/JYPPX.DeploySharp.OpenCvSharp.PaddleOcr\n</code></pre>\n<h3 id=\"82-可执行程序\">8.2 可执行程序</h3>\n<p>如需直接获取编译好的可执行程序，请加入技术交流群，从群文件下载最新版本。</p>\n<hr />\n<h2 id=\"九技术支持\">九、技术支持</h2>\n<h3 id=\"91-反馈与交流\">9.1 反馈与交流</h3>\n<ul>\n<li><strong>GitHub Issues</strong>：在项目仓库提交 Issue 或 Pull Request</li>\n<li><strong>QQ 交流群</strong>：加入 <strong>945057948</strong>，获取实时技术支持</li>\n</ul>\n<p><img alt=\"QQ群二维码\" class=\"lazyload\" /></p>\n<h3 id=\"92-相关资源\">9.2 相关资源</h3>\n<ul>\n<li><strong>PaddleOCR 官方项目</strong>：<a href=\"https://github.com/PaddlePaddle/PaddleOCR\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/PaddlePaddle/PaddleOCR</a></li>\n<li><strong>OpenVINO 官方文档</strong>：<a href=\"https://docs.openvino.ai/\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.openvino.ai/</a></li>\n<li><strong>TensorRT 官方文档</strong>：<a href=\"https://docs.nvidia.com/deeplearning/tensorrt/\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.nvidia.com/deeplearning/tensorrt/</a></li>\n<li><strong>ONNX Runtime 官方文档</strong>：<a href=\"https://onnxruntime.ai/docs/\" rel=\"noopener nofollow\" target=\"_blank\">https://onnxruntime.ai/docs/</a></li>\n</ul>\n<hr />\n<h2 id=\"结语\">结语</h2>\n<p>通过 DeploySharp 框架，我们成功实现了 PaddleOCR 在 .NET 环境下的高效部署。无论是纯 CPU 环境下的稳定运行，还是 GPU 加速下的极致性能，开发者都可以根据实际需求灵活选择。</p>\n<p>未来，我们将持续优化框架性能，支持更多模型类型和推理引擎，为 .NET 开发者提供更完善的 AI 模型部署解决方案。</p>\n<hr />\n<p><em>作者：Guojin Yan</em><br />\n<em>最后更新：2026年1月</em></p>\n<hr />\n<p><strong>【文章声明】</strong></p>\n<p>本文主要内容基于作者的研究与实践，部分表述借助 AI 工具进行了辅助优化。由于技术局限性，文中可能存在错误或疏漏之处，恳请各位读者批评指正。如果内容无意中侵犯了您的权益，请及时通过公众号后台与我们联系，我们将第一时间核实并妥善处理。感谢您的理解与支持！</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 22:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/guojin-blogs\">椒颜皮皮虾</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "为什么 Kubernetes 服务中断通常是人为失误，而不是平台自身原因？",
      "link": "https://www.cnblogs.com/manuscript/p/19544375",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/manuscript/p/19544375\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 16:07\">\n    <span>为什么 Kubernetes 服务中断通常是人为失误，而不是平台自身原因？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>本文基于对 <a href=\"https://hackernoon.com/why-kubernetes-outages-are-usually-human-failures-not-platform-bugs\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Why Kubernetes Outages Are Usually Human Failures, Not Platform Bugs？\">Why Kubernetes Outages Are Usually Human Failures, Not Platform Bugs</a> 这篇文章的翻译。与机翻不同，本文在翻译的基础上进行了大量本土化的润色，使内容更符合中文母语读者的阅读习惯，大大提升了阅读体验。此外，对于一些较为专业或难以理解的术语，本文也附上了相关的维基百科链接，帮助读者更好地理解相关概念。需要说明的是，本文仅为原文的润色翻译，并未改变原文的表达内容。</p>\n<h1 id=\"前言\">前言</h1>\n<p>Kubernetes 本身并不复杂，是我们把它搞复杂的。无论是刻意为之还是那种虽然出于好意却将优雅的原语堆砌成 <a href=\"https://en.wikipedia.org/wiki/Rube_Goldberg_machine\" rel=\"noopener nofollow\" target=\"_blank\">鲁布·戈德堡机械</a> 的狂热。平台最初提供的 ReplicaSets、Services、ConfigMaps，这些基础组件简单直接，甚至显得有些枯燥。但后来我们引入了 Operators、Service Meshes，以及那些仅仅为了更新一个 Deployment 就需要三个独立控制器参与的 GitOps Pipelines。如今我们深陷在堆积如山的 YAML 配置文件中，既看不懂，也改不动，而写下这些配置的外包早在半年前就已经离职了。</p>\n<p>我曾在凌晨两点排查过这类集群故障。明明只是一个 Pod 重启，却因为有人给一个在高峰期需要 4 秒才能建立数据库连接的服务配置了 2 秒超时的 Liveness Probe，最终导致雪崩，引发了长达 30 分钟的服务中断。这锅 Kubernetes 不背，是我们对分布式系统时序的理解出了问题。Uptime Institute 报告指出，40% 的重大故障源于人为错误：配置失误、手滑敲错 kubectl 命令、发布前测试不充分。这不是危言耸听。导致宕机的往往不是 Kernel Panic，也不是 etcd 数据损坏，而是我们自己！</p>\n<p>安全领域的情况更不容乐观。93% 的企业承认其 Kubernetes 安全事故与操作失误有关，这说明我们面对的是流程管理的灾难，而非软件本身的缺陷。被遗忘的 RBAC 规则、直接提交到 Git 的 Secrets、在测试环境配置了却从未同步到生产的 Network Policies ...，我甚至见过有的团队直接使用特权容器（Privileged Containers）运行生产负载，理由仅仅是 \"开发时这样比较方便，上线后忘了关\"。这不能怪 Kubernetes 不安全，这就是披着平台复杂性外衣的制度性疏忽。</p>\n<h1 id=\"英雄工程师的陷阱\">\"英雄工程师\"的陷阱</h1>\n<p>剧情通常是这样发展的：团队里有一位才华横溢的工程师，我们姑且叫她 Maya，她决定要打造一个\"业界最强平台\"。她通读了 CNCF Landscape 的各类技术文章，然后大显身手，引入 Istio 做 Service Mesh，用 Argo 做发布，在 Vault 管理 Secrets，部署 Prometheus + Thanos 做可观测性，还有 cert-manager 处理 TLS，external-dns 管理域名，Velero 搞定备份。平心而论，每个组件都解决了一个实际问题，但同时也引入了一个全新的故障类型。</p>\n<p>六个月后，Maya 被一家初创公司用期权和更高的 Title 挖走了。留下了一套精密复杂的系统，却没人知道各个组件是如何咬合的：</p>\n<ul>\n<li>\n<p>observability stack？是 Maya 用自定义 Recording Rules 和 Federation Endpoints 配置的，逻辑只有她自己懂。</p>\n</li>\n<li>\n<p>GitOps pipeline？依赖着她某个周末手搓的 Custom Operator 实现的 Slack Webhook 通知系统，除此之外没人碰过代码。</p>\n</li>\n</ul>\n<p>当系统故障时整个团队两眼一抹黑。大家只知道 <code>kubectl get pods</code> 显示状态是 <code>CrashLoopBackOff</code>，却根本搞不清为什么改了一个有三层嵌套的配置，Liveness Probe 就突然挂了。</p>\n<p>Portainer 的 CEO 完美地捕捉到了这一点：那些由个人为了追求技术极致而搭建的 Kubernetes 环境，往往埋藏着巨大的风险，因为其复杂度会让后续的维护工作变成一场噩梦。我想进一步补充的是，真正致命的问题不在复杂性本身，而在于那些<strong>未被文档化</strong>的复杂性，也就是只存在于 Maya 脑子里的<strong>隐秘经验</strong>。面对一个复杂的系统，我们尚能抽丝剥茧找到出路；但面对一个<strong>完全不透明的黑盒</strong>，一旦出事，往往是无解的死局。</p>\n<p>各种一键安装工具更是雪上加霜。一个 Helm Chart 能瞬间拉起 50 个资源，默认配置看起来也像模像样；Terraform Module 把底层网络配置封装得严严实实。这对提升交付速度确实有效，但对理解系统架构却是毁灭性的。当 Ingress Controller 突然无法转发流量时，你能判断出是 LoadBalancer Service 的 Annotation 写错了，还是后端 Health Check 挂了，亦或是 cert-manager 的 ClusterIssuer 丢了 ACME 凭证导致证书过期？如果你当初只是敲了一行 <code>helm install nginx-ingress stable/nginx-ingress</code> 却从未审视过生成的 Manifests，那你大概率是懵圈的。</p>\n<h1 id=\"认知过载与微服务税\">认知过载与微服务税</h1>\n<p>真正的幕后黑手其实不是 Kubernetes，而是 Kubernetes 所催生的产物：规模超出人类认知极限的微服务架构。现在的开发者，光懂业务逻辑已经不够了，还得精通：Service Discovery、Circuit Breaking、Retry Policies、分布式 Tracing 的 Context Propagation、Metrics 数据格式、Health Check 的各种语义（Readiness vs Liveness vs Startup）、Resource Requests 与 Limits 的区别、Pod 调度约束、Network Policies、Secret 轮转，以及 Graceful Shutdown 流程等等。</p>\n<p>这哪里还是写代码？分明是披着应用开发外衣的分布式系统工程。</p>\n<p>Komodor 关于认知负荷的研究一针见血：开发者正被这些分布式系统压得喘不过气。我曾亲眼目睹初级工程师花了两天排查服务连不上 Postgres 的问题，最后发现竟然是 Network Policy 阻断了通往数据库 Namespace 的 Egress 流量。他们懂 SQL，也理解 ORM，但脑子里完全没有 Kubernetes 网络隔离的概念，因为没人教过他们，而报错信息只是一个毫无信息量的“连接超时”。</p>\n<p>这种问题会不断累积。当团队里的每个人都在其能力边缘操作时，小失误就会被无限放大：有人把内存 Limit 设得太低 -&gt; 高负载下 JVM OOM -&gt; Pod 重启 -&gt; 恰逢节点压力大，Startup Probe 超时 -&gt; Kubernetes kill Pod -&gt; Metrics-server 有延迟，HPA 还没来得及扩容 -&gt; 流量全部打到剩余的 Pod 上 -&gt; 剩余 Pod 集体 OOM -&gt; 雪崩。这一连串事件中，每一个单独的环节看起来都挺合理，但它们组合在一起的交互复杂度却是指数级的。</p>\n<p>回想虚拟机时代。如果服务器抽风就 SSH 上去，查查日志，重启进程，或者干脆重启机器。变量少，抽象层也少。当年我维护跑着单体 Rails 应用的虚拟机集群时，我对每一个依赖、每一个 Cron Job、每一个日志文件的路径都了如指掌。排查问题就像在走一个只有 20 个分支的决策树。而 Kubernetes 的故障排查则是一张充满了循环、死胡同和误导信息的庞大决策图。</p>\n<p>有些人更怀念虚拟机模式。虽然弹性差了点，但你拥有对单个实例的绝对控制权。我非常理解这种想法。当你的容器化应用包含十几个相互依赖的组件，而你搞不清到底是哪个 Sidecar 导致了认证失败时，一台机器跑一个进程的简单模式简直太诱人了。编排系统充满了不确定性：比如 Pod 会因为你没察觉到的资源压力而被重新调度。这让人感觉失去了对系统的掌控感。</p>\n<h1 id=\"破局之道\">破局之道</h1>\n<p>解决方案并不是放弃 Kubernetes。对于许多业务场景而言，它依然是最佳选择。但前提是需要建立起工程纪律：</p>\n<ul>\n<li>其一：尽可能使用托管服务。Portainer 的建议非常中肯，如果你没有深厚的 Kubernetes 功底，请直接使用 EKS、AKS 或 GKE。把 Control Plane 升级、etcd 备份、Node 生命周期管理这些工作交给云厂商。虽然你仍需面对业务层面的复杂性，但至少基础设施层的锅有人背了。我见过一些小团队为了所谓的完全掌控非要在裸机上自建集群，结果遇到内核 Bug 搞坏了 etcd 数据，又没有灾备方案，硬生生停机了三周。</li>\n<li>其二：激进地简化架构。对引入的每个 Operator、CRD、基础设施代码 都要保持质疑。你真的需要 Service Mesh 吗？还是仅因为 Netflix 用了，所以就盲目跟风？能否用更简单的方式，比如标准的 Ingress 和设计合理的 Service 来满足需求？我曾经把整套复杂的监控技术栈拆掉，换成了最基础的 Prometheus + Grafana，以 20% 的运维成本实现了原系统 80% 的功能。相信我，为了那剩下 20% 的功能而被凌晨 3 点的告警电话吵醒，绝对不值。</li>\n<li>其三：将文档视为基础设施的一部分。我指的不是那些 API 文档，而是架构决策记录。解释清楚为什么选 Istio 而不是 Linkerd、权衡了什么、常见故障如何排查。要有针对高频故障的 Runbooks，要有清晰展示流量从 Ingress 到 Service 再到 Pod 的架构图。把写文档作为强制性要求，并按季度审查。目标是让新入职的同事在几周内就能上手，而不是耗费几个月摸索。</li>\n<li>其四：灰度发布与极限测试。采用 Blue-green Deployments，使用带有自动回滚机制的 Canary Releases。引入混沌工程，在工作时间随机 kill Pod，看看环境有多脆弱。如果连 Pod 挂了都扛不住，那你构建的根本不是 Kubernetes 应用，而是一个分布式单体应用。Kubernetes 随时可能重新调度 Pod，你的应用必须能够优雅地处理这种情况。</li>\n<li>其五：在培训上投入真金白银。是真正的实战培训，而不是丢下一句看文档。请那些真正维护过生产环境 Kubernetes 多年的人来讲经验，进行关于故障排查、网络原理、容量规划的研讨会。通过 on-call 轮换团队成员，让每个人都切身体会一下糟糕的设计带来的痛苦。那些真正把 Kubernetes 当作一门严肃工程学科来对待、并持续提升技能的团队，很少抱怨 K8s 复杂。因为他们的能力已经成长到足以驾驭这个工具了。</li>\n</ul>\n<h1 id=\"警惕新奇陷阱\">警惕新奇陷阱</h1>\n<p>Kubernetes 生态发展极快，总有新项目在说可以解决你的痛点。Progressive Delivery 框架、Policy Engines、作为 Admission Controllers 运行的安全扫描器...，单看每个都很诱人。CNCF Landscape 上已经有几百个项目了，而且还在不断增加。</p>\n<p>忍住别乱动。对那些仅仅因为\"新\"而存在的东西保持警惕。引入每一个新工具都是一场豪赌：你赌的是团队能学会它、能维护它，并且在压力下能搞定它的故障。有时候你赌赢了，但更多时候，它只是增加了系统的攻击面和故障点。我见过有的团队两年换了 5 个 GitOps 工具，每次都信誓旦旦地说这个才是终极方案。结果这种折腾本身带来的问题比工具解决的问题还要多。</p>\n<p>去用那些\"无聊\"的技术吧。用那些久经沙场的 Kubernetes 版本，用那些社区活跃的主流工具，用那些被成千上万个团队验证过的默认配置。虽然这些东西写不成能在技术大会上吹嘘的 PPT，但能让你睡个好觉。</p>\n<h1 id=\"到底是谁的锅\">到底是谁的锅？</h1>\n<p>当你的集群失控时：Pod 无限重启、诡异的网络故障、随机失败的部署动作 ...，在把锅甩给开源项目前，先审视一下你是怎么搭建的它。Kubernetes 给了你一把趁手的工具，但你却造出了一台精密却脆弱的仪器。也许它确实需要这么复杂，但多数情况下并不需要。</p>\n<p>所谓的\"Kubernetes 复杂性问题\"，归根结底是人的问题。培训不足、个人英雄主义、缺乏运维纪律、盲目追新、误读真实需求...，这些是可以纠正的。但并不仅是换个工具就能解决的，需要对某些 Feature 说不，对那些看似聪明的解决方案说不，对自动化越多越好这种诱人的鬼话保持清醒。</p>\n<p>我们的目标是构建一个团队里大多数人都能维护的平台，而不是只有那个读遍了所有 SIG 会议纪要的 Staff Engineer 才能搞定的系统。系统的易用性与<a href=\"https://en.wikipedia.org/wiki/Bus_factor\" rel=\"noopener nofollow\" target=\"_blank\">公交因素</a>很重要。如果你的 Kubernetes 架构复杂到只有 Maya 一个人能看懂，那你拥有的根本不是基础设施，而是一个穿着连帽衫的单点故障。</p>\n<p>修复工作从周一早上开始，好好审视一下你的集群。仔细看看到底需要多少个组件？哪些是必须的，哪些是锦上添花的？如果砍掉一半组件会发生什么？你现在的文档能让下周入职的新人处理线上故障吗？</p>\n<p>Kubernetes 的工作负载扩展能力非常出色，但它无法扩展我们对它的理解能力，这是我们自己的问题。我们深陷其中的每一分复杂性，都是我们通过一个个看似合理的决策亲手埋下的。平台本身没有失败，是我们辜负了它：我们缺乏清晰的规划、严谨的纪律，以及只构建我们能够维护的系统这种谦逊的态度。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 16:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/manuscript\">怎么还在写代码</a>&nbsp;\n阅读(<span id=\"post_view_count\">16</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "千万级大表如何删除数据？",
      "link": "https://www.cnblogs.com/12lisu/p/19544371",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/12lisu/p/19544371\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 16:07\">\n    <span>千万级大表如何删除数据？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>今天我们来聊聊一个让很多DBA和开发者头疼的话题——千万级大表的数据删除。</p>\n<p>有些小伙伴在工作中，一遇到大表数据删除就手足无措，要么直接<code>DELETE</code>导致数据库卡死，要么畏手畏脚不敢操作。</p>\n<p>我见过太多因为大表删除操作不当导致的\"血案\"：数据库长时间锁表、业务系统瘫痪、甚至主从同步延迟。</p>\n<p>今天跟大家一起专门聊聊千万级大表数据删除的话题，希望对你会有所帮助。</p>\n<h2 id=\"一为什么大表删除这么难\">一、为什么大表删除这么难？</h2>\n<p>在深入技术方案之前，我们先搞清楚为什么千万级大表的数据删除会如此困难。</p>\n<p>有些小伙伴可能会想：\"不就是个DELETE语句吗，有什么难的？\"</p>\n<p>其实这里面大有学问。</p>\n<h3 id=\"数据库删除操作的底层原理\">数据库删除操作的底层原理</h3>\n<p>为了更直观地理解数据库删除操作的工作原理，我画了一个删除操作的底层流程图：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>从这张图可以看出，一个简单的DELETE语句背后隐藏着这么多复杂的操作。</p>\n<p>让我们详细分析每个环节的挑战：</p>\n<h3 id=\"1-事务和锁的挑战\">1. 事务和锁的挑战</h3>\n<pre><code class=\"language-sql\">-- 一个看似简单的删除操作\nDELETE FROM user_operation_log \nWHERE create_time &lt; '2023-01-01';\n\n-- 实际上MySQL会这样处理：\n-- 1. 获取表的写锁\n-- 2. 逐行扫描10,000,000条记录\n-- 3. 对每条匹配的记录：\n--    - 写入undo log（用于回滚）\n--    - 写入redo log（用于恢复）\n--    - 更新所有相关索引\n--    - 标记记录为删除状态\n-- 4. 事务提交后才真正释放空间\n</code></pre>\n<h3 id=\"2-资源消耗问题\">2. 资源消耗问题</h3>\n<ul>\n<li><strong>磁盘I/O</strong>：undo log、redo log、数据文件、索引文件的大量写入</li>\n<li><strong>CPU</strong>：索引维护、条件判断、事务管理</li>\n<li><strong>内存</strong>：Buffer Pool管理、锁信息维护</li>\n<li><strong>网络</strong>：主从同步数据量巨大</li>\n</ul>\n<h3 id=\"3-业务影响风险\">3. 业务影响风险</h3>\n<ul>\n<li><strong>锁等待超时</strong>：其他查询被阻塞</li>\n<li><strong>主从延迟</strong>：从库同步跟不上</li>\n<li><strong>磁盘空间</strong>：undo log暴增导致磁盘写满</li>\n<li><strong>性能下降</strong>：数据库整体性能受影响</li>\n</ul>\n<p>有些小伙伴可能会问：\"我们用的是云数据库，这些问题还存在吗？\"</p>\n<p>我的经验是：<strong>云数据库只是降低了运维复杂度，但底层原理和限制依然存在</strong>。</p>\n<h2 id=\"二方案一分批删除最常用\">二、方案一：分批删除（最常用）</h2>\n<p>分批删除是最基础也是最常用的方案，核心思想是\"化整为零\"，将大操作拆分成多个小操作。</p>\n<h3 id=\"实现原理\">实现原理</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"具体实现\">具体实现</h3>\n<h4 id=\"方法1基于主键分批\">方法1：基于主键分批</h4>\n<pre><code class=\"language-sql\">-- 存储过程实现分批删除\nDELIMITER $$\nCREATE PROCEDURE batch_delete_by_id()\nBEGIN\n    DECLARE done INT DEFAULT FALSE;\n    DECLARE batch_size INT DEFAULT 1000;\n    DECLARE max_id BIGINT;\n    DECLARE min_id BIGINT;\n    DECLARE current_id BIGINT DEFAULT 0;\n    \n    -- 获取需要删除的数据范围\n    SELECT MIN(id), MAX(id) INTO min_id, max_id \n    FROM user_operation_log \n    WHERE create_time &lt; '2023-01-01';\n    \n    WHILE current_id &lt; max_id DO\n        -- 每次删除一个批次\n        DELETE FROM user_operation_log \n        WHERE id BETWEEN current_id AND current_id + batch_size - 1\n        AND create_time &lt; '2023-01-01';\n        \n        -- 提交事务，释放锁\n        COMMIT;\n        \n        -- 休眠一下，让数据库喘口气\n        DO SLEEP(0.1);\n        \n        -- 更新进度\n        SET current_id = current_id + batch_size;\n        \n        -- 记录日志（可选）\n        INSERT INTO delete_progress_log \n        VALUES (NOW(), current_id, batch_size);\n    END WHILE;\nEND$$\nDELIMITER ;\n</code></pre>\n<h4 id=\"方法2基于时间分批\">方法2：基于时间分批</h4>\n<pre><code class=\"language-java\">// Java代码实现基于时间的分批删除\n@Service\n@Slf4j\npublic class BatchDeleteService {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    /**\n     * 基于时间范围的分批删除\n     */\n    public void batchDeleteByTime(String tableName, String timeColumn, \n                                  Date startTime, Date endTime, \n                                  int batchDays) {\n        \n        Calendar calendar = Calendar.getInstance();\n        calendar.setTime(startTime);\n        \n        int totalDeleted = 0;\n        long startMs = System.currentTimeMillis();\n        \n        while (calendar.getTime().before(endTime)) {\n            Date batchStart = calendar.getTime();\n            calendar.add(Calendar.DAY_OF_YEAR, batchDays);\n            Date batchEnd = calendar.getTime();\n            \n            // 确保不超过结束时间\n            if (batchEnd.after(endTime)) {\n                batchEnd = endTime;\n            }\n            \n            String sql = String.format(\n                \"DELETE FROM %s WHERE %s BETWEEN ? AND ? LIMIT 1000\",\n                tableName, timeColumn\n            );\n            \n            int deleted = jdbcTemplate.update(sql, batchStart, batchEnd);\n            totalDeleted += deleted;\n            \n            log.info(\"批次删除完成: {}-{}, 删除{}条, 总计{}条\",\n                    batchStart, batchEnd, deleted, totalDeleted);\n            \n            // 控制删除频率，避免对数据库造成过大压力\n            if (deleted &gt; 0) {\n                try {\n                    Thread.sleep(500); // 休眠500ms\n                } catch (InterruptedException e) {\n                    Thread.currentThread().interrupt();\n                    break;\n                }\n            } else {\n                // 没有数据可删，跳到下一个时间段\n                continue;\n            }\n            \n            // 每删除10000条记录一次进度\n            if (totalDeleted % 10000 == 0) {\n                logProgress(totalDeleted, startMs);\n            }\n        }\n        \n        log.info(\"删除任务完成! 总计删除{}条记录, 耗时{}秒\",\n                totalDeleted, (System.currentTimeMillis() - startMs) / 1000);\n    }\n    \n    private void logProgress(int totalDeleted, long startMs) {\n        long costMs = System.currentTimeMillis() - startMs;\n        double recordsPerSecond = totalDeleted * 1000.0 / costMs;\n        \n        log.info(\"删除进度: {}条, 速率: {}/秒, 耗时: {}秒\",\n                totalDeleted, String.format(\"%.2f\", recordsPerSecond), costMs / 1000);\n    }\n}\n</code></pre>\n<h4 id=\"方法3使用limit分批删除\">方法3：使用LIMIT分批删除</h4>\n<pre><code class=\"language-sql\">-- 简单的LIMIT分批删除\nDELIMITER $$\nCREATE PROCEDURE batch_delete_with_limit()\nBEGIN\n    DECLARE done INT DEFAULT 0;\n    DECLARE batch_size INT DEFAULT 1000;\n    DECLARE total_deleted INT DEFAULT 0;\n    \n    WHILE done = 0 DO\n        -- 每次删除1000条\n        DELETE FROM user_operation_log \n        WHERE create_time &lt; '2023-01-01' \n        LIMIT batch_size;\n        \n        -- 检查是否还有数据\n        SET done = ROW_COUNT() = 0;\n        SET total_deleted = total_deleted + ROW_COUNT();\n        \n        -- 提交释放锁\n        COMMIT;\n        \n        -- 休眠控制频率\n        DO SLEEP(0.1);\n        \n        -- 每删除10000条输出日志\n        IF total_deleted % 10000 = 0 THEN\n            SELECT CONCAT('已删除: ', total_deleted, ' 条记录') AS progress;\n        END IF;\n    END WHILE;\n    \n    SELECT CONCAT('删除完成! 总计: ', total_deleted, ' 条记录') AS result;\nEND$$\nDELIMITER ;\n</code></pre>\n<h3 id=\"分批删除的最佳实践\">分批删除的最佳实践</h3>\n<ol>\n<li>\n<p><strong>批次大小选择</strong></p>\n<ul>\n<li>小表：1000-5000条/批次</li>\n<li>大表：100-1000条/批次</li>\n<li>需要根据实际情况调整</li>\n</ul>\n</li>\n<li>\n<p><strong>休眠时间控制</strong></p>\n<ul>\n<li>业务高峰期：休眠1-2秒</li>\n<li>业务低峰期：休眠100-500毫秒</li>\n<li>夜间维护：可不休眠或短暂休眠</li>\n</ul>\n</li>\n<li>\n<p><strong>监控和调整</strong></p>\n<ul>\n<li>监控数据库负载</li>\n<li>观察主从同步延迟</li>\n<li>根据实际情况动态调整参数</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"三方案二创建新表重命名\">三、方案二：创建新表+重命名</h2>\n<p>当需要删除表中大部分数据时，创建新表然后重命名的方式往往更高效。</p>\n<h3 id=\"实现原理-1\">实现原理</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"具体实现-1\">具体实现</h3>\n<pre><code class=\"language-sql\">-- 步骤1: 创建新表（结构同原表）\nCREATE TABLE user_operation_log_new LIKE user_operation_log;\n\n-- 步骤2: 导入需要保留的数据\nINSERT INTO user_operation_log_new \nSELECT * FROM user_operation_log \nWHERE create_time &gt;= '2023-01-01';\n\n-- 步骤3: 创建索引（在数据导入后创建，效率更高）\nALTER TABLE user_operation_log_new ADD INDEX idx_create_time(create_time);\nALTER TABLE user_operation_log_new ADD INDEX idx_user_id(user_id);\n\n-- 步骤4: 数据验证\nSELECT \n    (SELECT COUNT(*) FROM user_operation_log_new) as new_count,\n    (SELECT COUNT(*) FROM user_operation_log WHERE create_time &gt;= '2023-01-01') as expected_count;\n\n-- 步骤5: 原子切换（需要很短的表锁）\nRENAME TABLE \n    user_operation_log TO user_operation_log_old,\n    user_operation_log_new TO user_operation_log;\n\n-- 步骤6: 删除旧表（可选立即删除或延后删除）\nDROP TABLE user_operation_log_old;\n</code></pre>\n<h3 id=\"java代码辅助实现\">Java代码辅助实现</h3>\n<pre><code class=\"language-java\">@Service  \n@Slf4j\npublic class TableRebuildService {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    /**\n     * 重建表方式删除数据\n     */\n    public void rebuildTableForDeletion(String sourceTable, String condition) {\n        String newTable = sourceTable + \"_new\";\n        String oldTable = sourceTable + \"_old\";\n        \n        try {\n            // 1. 创建新表\n            log.info(\"开始创建新表: {}\", newTable);\n            jdbcTemplate.execute(\"CREATE TABLE \" + newTable + \" LIKE \" + sourceTable);\n            \n            // 2. 导入需要保留的数据\n            log.info(\"开始导入保留数据\");\n            String insertSql = String.format(\n                \"INSERT INTO %s SELECT * FROM %s WHERE %s\", \n                newTable, sourceTable, condition\n            );\n            int keptCount = jdbcTemplate.update(insertSql);\n            log.info(\"成功导入{}条保留数据\", keptCount);\n            \n            // 3. 创建索引（可选，在导入后创建索引效率更高）\n            log.info(\"开始创建索引\");\n            createIndexes(newTable);\n            \n            // 4. 数据验证\n            log.info(\"开始数据验证\");\n            if (!validateData(sourceTable, newTable, condition)) {\n                throw new RuntimeException(\"数据验证失败\");\n            }\n            \n            // 5. 原子切换\n            log.info(\"开始表切换\");\n            switchTables(sourceTable, newTable, oldTable);\n            \n            // 6. 删除旧表（可选立即或延后）\n            log.info(\"开始删除旧表\");\n            dropTableSafely(oldTable);\n            \n            log.info(\"表重建删除完成!\");\n            \n        } catch (Exception e) {\n            log.error(\"表重建过程发生异常\", e);\n            // 清理临时表\n            cleanupTempTable(newTable);\n            throw e;\n        }\n    }\n    \n    private void createIndexes(String tableName) {\n        // 根据业务需要创建索引\n        String[] indexes = {\n            \"CREATE INDEX idx_create_time ON \" + tableName + \"(create_time)\",\n            \"CREATE INDEX idx_user_id ON \" + tableName + \"(user_id)\"\n        };\n        \n        for (String sql : indexes) {\n            jdbcTemplate.execute(sql);\n        }\n    }\n    \n    private boolean validateData(String sourceTable, String newTable, String condition) {\n        // 验证新表数据量是否正确\n        Integer newCount = jdbcTemplate.queryForObject(\n            \"SELECT COUNT(*) FROM \" + newTable, Integer.class);\n        \n        Integer expectedCount = jdbcTemplate.queryForObject(\n            \"SELECT COUNT(*) FROM \" + sourceTable + \" WHERE \" + condition, Integer.class);\n        \n        return newCount.equals(expectedCount);\n    }\n    \n    private void switchTables(String sourceTable, String newTable, String oldTable) {\n        // 原子性的表重命名操作\n        String sql = String.format(\n            \"RENAME TABLE %s TO %s, %s TO %s\", \n            sourceTable, oldTable, newTable, sourceTable\n        );\n        jdbcTemplate.execute(sql);\n    }\n    \n    private void dropTableSafely(String tableName) {\n        try {\n            jdbcTemplate.execute(\"DROP TABLE \" + tableName);\n        } catch (Exception e) {\n            log.warn(\"删除表失败: {}, 需要手动清理\", tableName, e);\n        }\n    }\n    \n    private void cleanupTempTable(String tableName) {\n        try {\n            jdbcTemplate.execute(\"DROP TABLE IF EXISTS \" + tableName);\n        } catch (Exception e) {\n            log.warn(\"清理临时表失败: {}\", tableName, e);\n        }\n    }\n}\n</code></pre>\n<h3 id=\"适用场景\">适用场景</h3>\n<ul>\n<li>需要删除表中超过50%的数据</li>\n<li>业务允许短暂的写停顿（重命名时需要）</li>\n<li>有足够的磁盘空间存储新旧两个表</li>\n</ul>\n<h2 id=\"四方案三分区表删除\">四、方案三：分区表删除</h2>\n<p>如果表已经做了分区，或者可以改造为分区表，那么删除数据就会变得非常简单。</p>\n<h3 id=\"实现原理-2\">实现原理</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"具体实现-2\">具体实现</h3>\n<h4 id=\"方法1使用现有分区表\">方法1：使用现有分区表</h4>\n<pre><code class=\"language-sql\">-- 查看表的分区情况\nSELECT table_name, partition_name, table_rows\nFROM information_schema.partitions \nWHERE table_name = 'user_operation_log';\n\n-- 直接删除整个分区（秒级完成）\nALTER TABLE user_operation_log DROP PARTITION p202201, p202202;\n\n-- 定期删除过期分区的存储过程\nDELIMITER $$\nCREATE PROCEDURE auto_drop_expired_partitions()\nBEGIN\n    DECLARE expired_partition VARCHAR(64);\n    DECLARE done INT DEFAULT FALSE;\n    \n    -- 查找需要删除的分区（保留最近12个月）\n    DECLARE cur CURSOR FOR \n    SELECT partition_name \n    FROM information_schema.partitions \n    WHERE table_name = 'user_operation_log' \n    AND partition_name LIKE 'p%'\n    AND STR_TO_DATE(REPLACE(partition_name, 'p', ''), '%Y%m') &lt; DATE_SUB(NOW(), INTERVAL 12 MONTH);\n    \n    DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;\n    \n    OPEN cur;\n    \n    read_loop: LOOP\n        FETCH cur INTO expired_partition;\n        IF done THEN\n            LEAVE read_loop;\n        END IF;\n        \n        -- 删除过期分区\n        SET @sql = CONCAT('ALTER TABLE user_operation_log DROP PARTITION ', expired_partition);\n        PREPARE stmt FROM @sql;\n        EXECUTE stmt;\n        DEALLOCATE PREPARE stmt;\n        \n        -- 记录日志\n        INSERT INTO partition_clean_log \n        VALUES (NOW(), expired_partition, 'DROPPED');\n    END LOOP;\n    \n    CLOSE cur;\nEND$$\nDELIMITER ;\n</code></pre>\n<h4 id=\"方法2改造普通表为分区表\">方法2：改造普通表为分区表</h4>\n<pre><code class=\"language-sql\">-- 将普通表改造成分区表\n-- 步骤1: 创建分区表\nCREATE TABLE user_operation_log_partitioned (\n    id BIGINT AUTO_INCREMENT,\n    user_id BIGINT,\n    operation VARCHAR(100),\n    create_time DATETIME,\n    PRIMARY KEY (id, create_time)  -- 分区键必须包含在主键中\n) PARTITION BY RANGE (YEAR(create_time)*100 + MONTH(create_time)) (\n    PARTITION p202201 VALUES LESS THAN (202202),\n    PARTITION p202202 VALUES LESS THAN (202203),\n    PARTITION p202203 VALUES LESS THAN (202204),\n    PARTITION p202204 VALUES LESS THAN (202205),\n    PARTITION pfuture VALUES LESS THAN MAXVALUE\n);\n\n-- 步骤2: 导入数据\nINSERT INTO user_operation_log_partitioned \nSELECT * FROM user_operation_log;\n\n-- 步骤3: 切换表\nRENAME TABLE \n    user_operation_log TO user_operation_log_old,\n    user_operation_log_partitioned TO user_operation_log;\n\n-- 步骤4: 定期维护：添加新分区\nALTER TABLE user_operation_log REORGANIZE PARTITION pfuture INTO (\n    PARTITION p202205 VALUES LESS THAN (202206),\n    PARTITION p202206 VALUES LESS THAN (202207),\n    PARTITION pfuture VALUES LESS THAN MAXVALUE\n);\n</code></pre>\n<h3 id=\"java代码实现分区管理\">Java代码实现分区管理</h3>\n<pre><code class=\"language-java\">@Service\n@Slf4j\npublic class PartitionManagerService {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    /**\n     * 自动管理分区\n     */\n    @Scheduled(cron = \"0 0 2 * * ?\")  // 每天凌晨2点执行\n    public void autoManagePartitions() {\n        log.info(\"开始分区维护任务\");\n        \n        try {\n            // 1. 删除过期分区（保留最近12个月）\n            dropExpiredPartitions();\n            \n            // 2. 创建未来分区\n            createFuturePartitions();\n            \n            log.info(\"分区维护任务完成\");\n            \n        } catch (Exception e) {\n            log.error(\"分区维护任务失败\", e);\n        }\n    }\n    \n    private void dropExpiredPartitions() {\n        String sql = \"SELECT partition_name \" +\n                    \"FROM information_schema.partitions \" +\n                    \"WHERE table_name = 'user_operation_log' \" +\n                    \"AND partition_name LIKE 'p%' \" +\n                    \"AND STR_TO_DATE(REPLACE(partition_name, 'p', ''), '%Y%m') &lt; DATE_SUB(NOW(), INTERVAL 12 MONTH)\";\n        \n        List&lt;String&gt; expiredPartitions = jdbcTemplate.queryForList(sql, String.class);\n        \n        for (String partition : expiredPartitions) {\n            try {\n                jdbcTemplate.execute(\"ALTER TABLE user_operation_log DROP PARTITION \" + partition);\n                log.info(\"成功删除分区: {}\", partition);\n                \n                // 记录操作日志\n                logPartitionOperation(\"DROP\", partition, \"SUCCESS\");\n                \n            } catch (Exception e) {\n                log.error(\"删除分区失败: {}\", partition, e);\n                logPartitionOperation(\"DROP\", partition, \"FAILED: \" + e.getMessage());\n            }\n        }\n    }\n    \n    private void createFuturePartitions() {\n        // 创建未来3个月的分区\n        for (int i = 1; i &lt;= 3; i++) {\n            LocalDate futureDate = LocalDate.now().plusMonths(i);\n            String partitionName = \"p\" + futureDate.format(DateTimeFormatter.ofPattern(\"yyyyMM\"));\n            int partitionValue = futureDate.getYear() * 100 + futureDate.getMonthValue();\n            int nextPartitionValue = partitionValue + 1;\n            \n            try {\n                String sql = String.format(\n                    \"ALTER TABLE user_operation_log REORGANIZE PARTITION pfuture INTO (\" +\n                    \"PARTITION %s VALUES LESS THAN (%d), \" +\n                    \"PARTITION pfuture VALUES LESS THAN MAXVALUE)\",\n                    partitionName, nextPartitionValue\n                );\n                \n                jdbcTemplate.execute(sql);\n                log.info(\"成功创建分区: {}\", partitionName);\n                logPartitionOperation(\"CREATE\", partitionName, \"SUCCESS\");\n                \n            } catch (Exception e) {\n                log.warn(\"创建分区失败（可能已存在）: {}\", partitionName, e);\n            }\n        }\n    }\n    \n    private void logPartitionOperation(String operation, String partition, String status) {\n        jdbcTemplate.update(\n            \"INSERT INTO partition_operation_log(operation, partition_name, status, create_time) VALUES (?, ?, ?, NOW())\",\n            operation, partition, status\n        );\n    }\n}\n</code></pre>\n<h3 id=\"分区表的优势\">分区表的优势</h3>\n<ol>\n<li><strong>删除效率极高</strong>：直接删除分区文件</li>\n<li><strong>不影响业务</strong>：无锁表风险</li>\n<li><strong>管理方便</strong>：可以自动化管理</li>\n<li><strong>查询优化</strong>：分区裁剪提升查询性能</li>\n</ol>\n<h2 id=\"五方案四使用临时表同步\">五、方案四：使用临时表同步</h2>\n<p>对于需要在线删除且不能停止服务的场景，可以使用临时表同步的方式。</p>\n<h3 id=\"实现原理-3\">实现原理</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"具体实现-3\">具体实现</h3>\n<pre><code class=\"language-java\">@Service\n@Slf4j\npublic class OnlineTableMigrationService {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    /**\n     * 在线表迁移删除\n     */\n    public void onlineMigrationDelete(String sourceTable, String condition) {\n        String newTable = sourceTable + \"_new\";\n        String tempTable = sourceTable + \"_temp\";\n        \n        try {\n            // 阶段1: 准备阶段\n            log.info(\"=== 阶段1: 准备阶段 ===\");\n            prepareMigration(sourceTable, newTable, tempTable);\n            \n            // 阶段2: 双写阶段\n            log.info(\"=== 阶段2: 双写阶段 ===\");\n            enableDoubleWrite(sourceTable, newTable);\n            \n            // 阶段3: 数据同步阶段\n            log.info(\"=== 阶段3: 数据同步阶段 ===\");\n            syncExistingData(sourceTable, newTable, condition);\n            \n            // 阶段4: 验证阶段\n            log.info(\"=== 阶段4: 验证阶段 ===\");\n            if (!validateDataSync(sourceTable, newTable)) {\n                throw new RuntimeException(\"数据同步验证失败\");\n            }\n            \n            // 阶段5: 切换阶段\n            log.info(\"=== 阶段5: 切换阶段 ===\");\n            switchToNewTable(sourceTable, newTable, tempTable);\n            \n            // 阶段6: 清理阶段\n            log.info(\"=== 阶段6: 清理阶段 ===\");\n            cleanupAfterSwitch(sourceTable, tempTable);\n            \n            log.info(\"在线迁移删除完成!\");\n            \n        } catch (Exception e) {\n            log.error(\"在线迁移过程发生异常\", e);\n            // 回滚双写\n            disableDoubleWrite();\n            throw e;\n        }\n    }\n    \n    private void prepareMigration(String sourceTable, String newTable, String tempTable) {\n        // 备份原表\n        jdbcTemplate.execute(\"CREATE TABLE \" + tempTable + \" LIKE \" + sourceTable);\n        jdbcTemplate.execute(\"INSERT INTO \" + tempTable + \" SELECT * FROM \" + sourceTable);\n        \n        // 创建新表\n        jdbcTemplate.execute(\"CREATE TABLE \" + newTable + \" LIKE \" + sourceTable);\n    }\n    \n    private void enableDoubleWrite(String sourceTable, String newTable) {\n        // 这里需要修改应用层代码，实现双写\n        // 或者在数据库层使用触发器（不推荐，影响性能）\n        log.info(\"请配置应用层双写: 同时写入 {} 和 {}\", sourceTable, newTable);\n        \n        // 等待双写配置生效\n        sleep(5000);\n    }\n    \n    private void syncExistingData(String sourceTable, String newTable, String condition) {\n        log.info(\"开始同步存量数据\");\n        \n        // 同步符合条件的数据到新表\n        String syncSql = String.format(\n            \"INSERT IGNORE INTO %s SELECT * FROM %s WHERE %s\", \n            newTable, sourceTable, condition\n        );\n        \n        int syncedCount = jdbcTemplate.update(syncSql);\n        log.info(\"存量数据同步完成: {} 条记录\", syncedCount);\n        \n        // 等待双写追平增量数据\n        log.info(\"等待增量数据追平...\");\n        sleep(30000); // 等待30秒，根据业务调整\n        \n        // 检查数据一致性\n        checkDataConsistency(sourceTable, newTable);\n    }\n    \n    private void checkDataConsistency(String sourceTable, String newTable) {\n        // 检查关键业务数据的一致性\n        Integer sourceCount = jdbcTemplate.queryForObject(\n            \"SELECT COUNT(*) FROM \" + sourceTable, Integer.class);\n        \n        Integer newCount = jdbcTemplate.queryForObject(\n            \"SELECT COUNT(*) FROM \" + newTable, Integer.class);\n        \n        log.info(\"数据一致性检查: 原表{}条, 新表{}条\", sourceCount, newCount);\n        \n        // 这里可以添加更详细的一致性检查\n    }\n    \n    private boolean validateDataSync(String sourceTable, String newTable) {\n        // 验证数据同步的正确性\n        // 这里可以实现更复杂的验证逻辑\n        \n        log.info(\"数据同步验证通过\");\n        return true;\n    }\n    \n    private void switchToNewTable(String sourceTable, String newTable, String tempTable) {\n        // 短暂停写（根据业务情况，可能不需要）\n        log.info(\"开始停写切换...\");\n        sleep(5000); // 停写5秒\n        \n        // 原子切换\n        jdbcTemplate.execute(\"RENAME TABLE \" + \n            sourceTable + \" TO \" + sourceTable + \"_backup, \" +\n            newTable + \" TO \" + sourceTable);\n        \n        log.info(\"表切换完成\");\n    }\n    \n    private void cleanupAfterSwitch(String sourceTable, String tempTable) {\n        // 关闭双写\n        disableDoubleWrite();\n        \n        // 延迟删除备份表（保留一段时间）\n        log.info(\"备份表保留: {}_backup\", sourceTable);\n        log.info(\"临时表已删除: {}\", tempTable);\n        \n        jdbcTemplate.execute(\"DROP TABLE \" + tempTable);\n    }\n    \n    private void disableDoubleWrite() {\n        log.info(\"请关闭应用层双写配置\");\n    }\n    \n    private void sleep(long millis) {\n        try {\n            Thread.sleep(millis);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        }\n    }\n}\n</code></pre>\n<h2 id=\"六方案五使用专业工具\">六、方案五：使用专业工具</h2>\n<p>对于特别大的表或者复杂的删除需求，可以使用专业的数据库工具。</p>\n<h3 id=\"1-pt-archiverpercona-toolkit\">1. pt-archiver（Percona Toolkit）</h3>\n<pre><code class=\"language-bash\"># 安装Percona Toolkit\n# Ubuntu/Debian: \nsudo apt-get install percona-toolkit\n\n# 使用pt-archiver归档删除数据\npt-archiver \\\n    --source h=localhost,D=test,t=user_operation_log \\\n    --where \"create_time &lt; '2023-01-01'\" \\\n    --limit 1000 \\\n    --commit-each \\\n    --sleep 0.1 \\\n    --statistics \\\n    --progress 10000 \\\n    --why-not \\\n    --dry-run  # 先试运行，确认无误后移除此参数\n\n# 实际执行删除\npt-archiver \\\n    --source h=localhost,D=test,t=user_operation_log \\\n    --where \"create_time &lt; '2023-01-01'\" \\\n    --limit 1000 \\\n    --commit-each \\\n    --sleep 0.1 \\\n    --purge\n</code></pre>\n<h3 id=\"2-自定义工具类\">2. 自定义工具类</h3>\n<pre><code class=\"language-java\">@Component\n@Slf4j\npublic class SmartDeleteTool {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    /**\n     * 智能删除决策\n     */\n    public void smartDelete(String tableName, String condition) {\n        try {\n            // 1. 分析表状态\n            TableAnalysisResult analysis = analyzeTable(tableName, condition);\n            \n            // 2. 根据分析结果选择最佳方案\n            DeleteStrategy strategy = chooseBestStrategy(analysis);\n            \n            // 3. 执行删除\n            executeDelete(strategy, tableName, condition);\n            \n        } catch (Exception e) {\n            log.error(\"智能删除失败\", e);\n            throw e;\n        }\n    }\n    \n    private TableAnalysisResult analyzeTable(String tableName, String condition) {\n        TableAnalysisResult result = new TableAnalysisResult();\n        \n        // 分析表大小\n        result.setTotalRows(getTableRowCount(tableName));\n        result.setDeleteRows(getDeleteRowCount(tableName, condition));\n        result.setDeleteRatio(result.getDeleteRows() * 1.0 / result.getTotalRows());\n        \n        // 分析表结构\n        result.setHasPartition(isTablePartitioned(tableName));\n        result.setHasPrimaryKey(hasPrimaryKey(tableName));\n        result.setIndexCount(getIndexCount(tableName));\n        \n        // 分析系统负载\n        result.setSystemLoad(getSystemLoad());\n        \n        return result;\n    }\n    \n    private DeleteStrategy chooseBestStrategy(TableAnalysisResult analysis) {\n        if (analysis.isHasPartition() &amp;&amp; analysis.getDeleteRatio() &gt; 0.3) {\n            return DeleteStrategy.PARTITION_DROP;\n        }\n        \n        if (analysis.getDeleteRatio() &gt; 0.5) {\n            return DeleteStrategy.TABLE_REBUILD;\n        }\n        \n        if (analysis.getTotalRows() &gt; 10_000_000) {\n            return DeleteStrategy.BATCH_DELETE_WITH_PAUSE;\n        }\n        \n        return DeleteStrategy.BATCH_DELETE;\n    }\n    \n    private void executeDelete(DeleteStrategy strategy, String tableName, String condition) {\n        switch (strategy) {\n            case PARTITION_DROP:\n                executePartitionDrop(tableName, condition);\n                break;\n            case TABLE_REBUILD:\n                executeTableRebuild(tableName, condition);\n                break;\n            case BATCH_DELETE_WITH_PAUSE:\n                executeBatchDeleteWithPause(tableName, condition);\n                break;\n            default:\n                executeBatchDelete(tableName, condition);\n        }\n    }\n    \n    // 各种策略的具体实现...\n    \n    private long getTableRowCount(String tableName) {\n        String sql = \"SELECT COUNT(*) FROM \" + tableName;\n        return jdbcTemplate.queryForObject(sql, Long.class);\n    }\n    \n    private long getDeleteRowCount(String tableName, String condition) {\n        String sql = \"SELECT COUNT(*) FROM \" + tableName + \" WHERE \" + condition;\n        return jdbcTemplate.queryForObject(sql, Long.class);\n    }\n    \n    private boolean isTablePartitioned(String tableName) {\n        String sql = \"SELECT COUNT(*) FROM information_schema.partitions \" +\n                    \"WHERE table_name = ? AND partition_name IS NOT NULL\";\n        Integer count = jdbcTemplate.queryForObject(sql, Integer.class, tableName);\n        return count != null &amp;&amp; count &gt; 0;\n    }\n    \n    // 其他分析方法...\n}\n\nenum DeleteStrategy {\n    BATCH_DELETE,           // 普通分批删除\n    BATCH_DELETE_WITH_PAUSE, // 带休眠的分批删除\n    TABLE_REBUILD,          // 重建表\n    PARTITION_DROP,         // 删除分区\n    ONLINE_MIGRATION        // 在线迁移\n}\n\n@Data\nclass TableAnalysisResult {\n    private long totalRows;\n    private long deleteRows;\n    private double deleteRatio;\n    private boolean hasPartition;\n    private boolean hasPrimaryKey;\n    private int indexCount;\n    private double systemLoad;\n}\n</code></pre>\n<h2 id=\"七方案对比与选择指南\">七、方案对比与选择指南</h2>\n<p>为了帮助大家选择合适的方案，我整理了详细的对比表：</p>\n<h3 id=\"方案对比矩阵\">方案对比矩阵</h3>\n<table>\n<thead>\n<tr>\n<th>方案</th>\n<th>适用场景</th>\n<th>优点</th>\n<th>缺点</th>\n<th>风险等级</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>分批删除</td>\n<td>小批量删除，<br />删除比例&lt;30%</td>\n<td>实现简单，<br />无需停服</td>\n<td>执行时间长，<br />可能锁表</td>\n<td>中</td>\n</tr>\n<tr>\n<td>重建表</td>\n<td>删除比例&gt;50%，<br />可接受短暂停写</td>\n<td>执行速度快，<br />整理表碎片</td>\n<td>需要停写，<br />需要额外空间</td>\n<td>高</td>\n</tr>\n<tr>\n<td>分区删除</td>\n<td>表已分区或可分区</td>\n<td>秒级完成，<br />无性能影响</td>\n<td>需要前期规划，<br />改造成本</td>\n<td>低</td>\n</tr>\n<tr>\n<td>在线同步</td>\n<td>要求零停机，<br />重要业务表</td>\n<td>业务无感知，<br />安全可靠</td>\n<td>实现复杂，<br />周期较长</td>\n<td>中</td>\n</tr>\n<tr>\n<td>专业工具</td>\n<td>复杂场景，<br />超大表操作</td>\n<td>功能强大，<br />自动优化</td>\n<td>学习成本，<br />依赖外部工具</td>\n<td>中</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"选择决策流程图\">选择决策流程图</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"实战建议\">实战建议</h3>\n<ol>\n<li><strong>测试环境验证</strong>：任何删除方案都要先在测试环境验证</li>\n<li><strong>备份优先</strong>：删除前一定要备份数据</li>\n<li><strong>业务低峰期</strong>：选择业务低峰期执行删除操作</li>\n<li><strong>监控告警</strong>：实时监控数据库状态，设置告警阈值</li>\n<li><strong>回滚预案</strong>：准备完善的回滚方案</li>\n</ol>\n<p>更多项目实战：susan.net.cn/project</p>\n<h2 id=\"总结\">总结</h2>\n<p>经过上面的详细分析，我们来总结一下千万级大表数据删除的核心要点。</p>\n<h3 id=\"核心原则\">核心原则</h3>\n<ol>\n<li><strong>安全第一</strong>：任何删除操作都要确保数据安全</li>\n<li><strong>影响最小</strong>：尽量减少对业务的影响</li>\n<li><strong>效率优先</strong>：选择最适合的高效方案</li>\n<li><strong>可监控</strong>：整个过程要可监控、可控制</li>\n</ol>\n<h3 id=\"技术选型口诀\">技术选型口诀</h3>\n<p>根据多年的实战经验，我总结了一个简单的选型口诀：</p>\n<blockquote>\n<p><strong>看分区，判比例，定方案</strong></p>\n<ul>\n<li><strong>有分区</strong>：直接删除分区最快</li>\n<li><strong>删的少</strong>：分批删除最稳妥</li>\n<li><strong>删的多</strong>：重建表最高效</li>\n<li><strong>不能停</strong>：在线同步最安全</li>\n</ul>\n</blockquote>\n<h3 id=\"最后的建议\">最后的建议</h3>\n<p>大表数据删除是一个需要谨慎对待的操作，我建议大家：</p>\n<ol>\n<li><strong>预防优于治疗</strong>：通过数据生命周期管理，定期清理数据</li>\n<li><strong>架构要合理</strong>：在设计阶段就考虑数据清理策略</li>\n<li><strong>工具要熟练</strong>：掌握各种删除工具的使用方法</li>\n<li><strong>经验要积累</strong>：每次操作后都要总结经验教训</li>\n</ol>\n<p>记住：<strong>没有最好的方案，只有最适合的方案</strong>。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 16:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/12lisu\">苏三说技术</a>&nbsp;\n阅读(<span id=\"post_view_count\">120</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "逆向三剑客：keystone，capstone，unicorn",
      "link": "https://www.cnblogs.com/ClownLMe/p/19544039",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ClownLMe/p/19544039\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 15:44\">\n    <span>逆向三剑客：keystone，capstone，unicorn</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"简介\">简介</h1>\n<p><strong>keystone</strong> 是一个<strong>汇编器</strong>，能够将汇编代码转换成硬编码。<br />\n<strong>capstone</strong> 是一个<strong>反汇编器</strong>，能够将硬编码转换为汇编代码。<br />\n<strong>unicorn</strong> 是一个<strong>模拟器</strong>，能够模拟cpu执行汇编指令。</p>\n<p>通过这3个工具，能够帮助我们逆向模拟分析代码，绕过动态的反调试，简化静态的vm和混淆的困扰。</p>\n<h1 id=\"环境安装\">环境安装</h1>\n<pre><code class=\"language-bash\">pip install keystone-engine capstone unicorn\n</code></pre>\n<p>这3个工具用法<strong>极其简单</strong>，下面通过示例来演示其用法。</p>\n<h1 id=\"keystone\">Keystone</h1>\n<h3 id=\"示例\">示例</h3>\n<pre><code class=\"language-python\">from keystone import *\n\nCODE = b\"INC ECX; ADD EDX, ECX\"\n\ntry:\n    ks = Ks(KS_ARCH_X86, KS_MODE_64)\n    \n    encoding, count = ks.asm(CODE)\n    \n    print(f\"汇编指令数量: {count}\")\n    print(f\"机器码 (十进制): {encoding}\")\n    print(f\"机器码 (Hex): {''.join(f'{x:02x}' for x in encoding)}\")\n\nexcept KsError as e:\n    print(f\"ERROR: {e}\")\n</code></pre>\n<h3 id=\"代码解释\">代码解释</h3>\n<p>代码流程十分简单：<br />\n<strong>初始化keystone-&gt;编译代码-&gt;输出结果</strong></p>\n<h5 id=\"初始化keystone\">初始化keystone</h5>\n<pre><code class=\"language-python\">ks = Ks(KS_ARCH_X86, KS_MODE_64)\n</code></pre>\n<p>初始化<code>keystone</code>引擎：</p>\n<ul>\n<li>第一个参数：选择指令架构例如：x86，arm......</li>\n<li>第二个参数：选择模式，例如：64位，32位，小端序......</li>\n</ul>\n<h5 id=\"编译代码\">编译代码</h5>\n<p>将汇编转换为16进制的shellcode</p>\n<pre><code class=\"language-python\">encoding, count = ks.asm(CODE)\n</code></pre>\n<ul>\n<li>第一个返回值：机器码指令的数组</li>\n<li>第二个返回值：汇编指令数量</li>\n</ul>\n<h1 id=\"capstone\">Capstone</h1>\n<p><code>capstone</code>的用法和<code>keystone</code>差不多。</p>\n<h3 id=\"示例-1\">示例</h3>\n<pre><code class=\"language-python\">from capstone import *\n\nCODE = b\"\\xff\\xc1\\x01\\xca\"\n\nmd = Cs(CS_ARCH_X86, CS_MODE_64)\n\nprint(\"地址\\t\\t指令\\t\\t操作数\")\nprint(\"-\" * 30)\n\nfor i in md.disasm(CODE, 0x1000):\n    print(f\"0x{i.address:x}:\\t{i.mnemonic}\\t{i.op_str}\")\n</code></pre>\n<h3 id=\"代码解释-1\">代码解释</h3>\n<p>代码流程跟<code>keystone</code>差不多：<br />\n<strong>初始化capstone-&gt;反编译代码-&gt;输出结果</strong></p>\n<h5 id=\"初始化capstone\">初始化capstone</h5>\n<pre><code class=\"language-python\">md = Cs(CS_ARCH_X86, CS_MODE_64)\n</code></pre>\n<p>初始化<code>capstone</code>引擎：</p>\n<ul>\n<li>第一个参数：选择指令架构例如：x86，arm......</li>\n<li>第二个参数：选择模式，例如：64位，32位，小端序......</li>\n</ul>\n<h5 id=\"反编译代码\">反编译代码</h5>\n<pre><code class=\"language-python\">for i in md.disasm(CODE, 0x1000):\n    print(f\"0x{i.address:x}:\\t{i.mnemonic}\\t{i.op_str}\")\n</code></pre>\n<p>使用方法<code>disasm</code>反汇编：</p>\n<ul>\n<li>第一个参数：机器码</li>\n<li>第二个参数：第一条指令的基地址</li>\n<li>返回：一个包含指令对象的数组</li>\n</ul>\n<h1 id=\"unicorn\">unicorn</h1>\n<p>unicorn提供的方法使用也不复杂，但需要一定的内存基础知识。<br />\n下面用一个案例解释。</p>\n<h3 id=\"示例-2\">示例</h3>\n<p><strong>情景模拟：</strong> 我逆向过程中发现一个xor加密代码，我需要通过模拟执行，对密文进行解密。<br />\n根据汇编代码可以得知：<br />\n<code>0x20000</code>存放密文<br />\n<code>0x30000</code>存放结果<br />\n<code>0x10000</code>中读取密钥key</p>\n<pre><code class=\"language-python\">from unicorn import *\nfrom unicorn.x86_const import *\nimport struct\nfrom keystone import *\n\nASM_CODE = \"\"\"\n&nbsp; &nbsp; MOV ECX, 5\n&nbsp; &nbsp; MOV ESI, 0x20000\n&nbsp; &nbsp; MOV EDI, 0x30000\n&nbsp; &nbsp; MOV BL, byte ptr [0x10000]\nloop_start:\n&nbsp; &nbsp; LODSB\n&nbsp; &nbsp; XOR AL, BL\n&nbsp; &nbsp; STOSB\n&nbsp; &nbsp; LOOP loop_start\n\"\"\"\n\ndef get_code():\n&nbsp; &nbsp; ks = Ks(KS_ARCH_X86, KS_MODE_32)\n&nbsp; &nbsp; encoding, count = ks.asm(ASM_CODE)\n&nbsp; &nbsp; return bytes(encoding)\n\nCODE = get_code()\n\nADDRESS_CODE = 0x400000 &nbsp; &nbsp;\nADDRESS_KEY &nbsp;= 0x10000 &nbsp; &nbsp; &nbsp;\nADDRESS_IN &nbsp; = 0x20000 &nbsp; &nbsp; &nbsp;\nADDRESS_OUT &nbsp;= 0x30000 &nbsp; &nbsp; &nbsp;\nREAL_KEY = 0x77 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n\nCIPHER_TEXT = b\"\\x3F\\x12\\x1B\\x1B\\x18\"\n\ndef hook_code(uc, access, address, size, value, user_data):\n&nbsp; &nbsp; if address == ADDRESS_KEY:\n&nbsp; &nbsp; &nbsp; &nbsp; key_value = uc.mem_read(address, size)\n&nbsp; &nbsp; &nbsp; &nbsp; print(f\"key: {hex(key_value[0])}\")\n\ndef start_emulation():\n&nbsp; &nbsp; try:\n&nbsp; &nbsp; &nbsp; &nbsp; print(\"初始化环境...\")\n&nbsp; &nbsp; &nbsp; &nbsp; mu = Uc(UC_ARCH_X86, UC_MODE_32)\n\n&nbsp; &nbsp; &nbsp; &nbsp; mu.mem_map(0x0, 1 * 1024 * 1024)\n&nbsp; &nbsp; &nbsp; &nbsp; mu.mem_map(ADDRESS_CODE, 2 * 1024 * 1024)\n\n&nbsp; &nbsp; &nbsp; &nbsp; mu.mem_write(ADDRESS_CODE, CODE)\n&nbsp; &nbsp; &nbsp; &nbsp; mu.mem_write(ADDRESS_IN, CIPHER_TEXT)\n&nbsp; &nbsp; &nbsp; &nbsp; mu.mem_write(ADDRESS_KEY, struct.pack(\"B\", REAL_KEY))\n\n&nbsp; &nbsp; &nbsp; &nbsp; mu.hook_add(UC_HOOK_MEM_READ, hook_code)\n&nbsp; &nbsp; &nbsp; &nbsp; \n&nbsp; &nbsp; &nbsp; &nbsp; mu.emu_start(ADDRESS_CODE, ADDRESS_CODE + len(CODE))\n\n&nbsp; &nbsp; &nbsp; &nbsp; decrypted_text = mu.mem_read(ADDRESS_OUT, 5)\n&nbsp; &nbsp; &nbsp; &nbsp; print(f\"解密后的文本: {decrypted_text.decode()}\")\n\n&nbsp; &nbsp; except UcError as e:\n&nbsp; &nbsp; &nbsp; &nbsp; print(f\"模拟错误: {e}\")\n\nif __name__ == \"__main__\":\n&nbsp; &nbsp; start_emulation()\n</code></pre>\n<h3 id=\"代码解释-2\">代码解释</h3>\n<p>代码流程：<br />\n<strong>初始化环境-&gt;分配虚拟内存-&gt;写入数据-&gt;添加捕获操作-&gt;模拟执行指令-&gt;读取内存结果</strong></p>\n<h5 id=\"初始化环境\">初始化环境</h5>\n<p>这个跟上面的<code>keystone</code>和<code>capstone</code>一样，就不解释了</p>\n<pre><code class=\"language-python\">mu = Uc(UC_ARCH_X86, UC_MODE_32)\n</code></pre>\n<h5 id=\"分配虚拟内存\">分配虚拟内存</h5>\n<p>第一行是用于存放<strong>堆内存数据</strong>，第二行是用于存放执行的<strong>代码</strong></p>\n<pre><code class=\"language-python\">mu.mem_map(0x0, 1 * 1024 * 1024)\nmu.mem_map(ADDRESS_CODE, 2 * 1024 * 1024)\n</code></pre>\n<p><code>mem_map</code>用于初始化虚拟内存</p>\n<ul>\n<li>第一个参数：内存的虚拟地址基址</li>\n<li>第二个参数：内存的大小</li>\n</ul>\n<h5 id=\"内写入数据\">内写入数据</h5>\n<p>第一行写入代码，第二行写入密文，第三行写入解密key</p>\n<pre><code class=\"language-python\">mu.mem_write(ADDRESS_CODE, CODE)\nmu.mem_write(ADDRESS_IN, CIPHER_TEXT)\nmu.mem_write(ADDRESS_KEY, struct.pack(\"B\", REAL_KEY))\n</code></pre>\n<p><code>mem_write</code>用于写入虚拟内存</p>\n<ul>\n<li>第一个参数：写入内存的地址</li>\n<li>第二个参数：写入内存的数据</li>\n</ul>\n<h5 id=\"添加捕获操作\">添加捕获操作</h5>\n<p>hook用于捕获数据，这里用于捕获key</p>\n<pre><code class=\"language-python\">def hook_code(uc, access, address, size, value, user_data):\n&nbsp; &nbsp; if address == ADDRESS_KEY:\n&nbsp; &nbsp; &nbsp; &nbsp; key_value = uc.mem_read(address, size)\n&nbsp; &nbsp; &nbsp; &nbsp; print(f\"key: {hex(key_value[0])}\")\nmu.hook_add(UC_HOOK_MEM_READ, hook_code)\n</code></pre>\n<p><code>hook_add</code>添加hook</p>\n<ul>\n<li>第一个参数：捕获模式，规定什么时候触发hook，例如：读取内存，中断捕获......</li>\n<li>第二个参数：触发的回调函数，回调函数各个参数如下：</li>\n</ul>\n<pre><code class=\"language-python\">def hook_code(uc, access, address, size, value, user_data):\n</code></pre>\n<ul>\n<li><code>uc</code>：模拟器对象</li>\n<li><code>access</code>：当前访问类型：<code>UC_MEM_READ</code>，<code>UC_MEM_WRITE</code>......</li>\n<li><code>address</code>：当前访问的虚拟地址</li>\n<li><code>size</code>：当前访问数据大小</li>\n<li><code>value</code>：access为<code>UC_MEM_WRITE</code>，则这里为要写入的值</li>\n<li><code>user_data</code>：用户在<code>add_hook</code>时传进去的自定义数据</li>\n</ul>\n<h5 id=\"模拟执行指令\">模拟执行指令</h5>\n<pre><code class=\"language-python\">mu.emu_start(ADDRESS_CODE, ADDRESS_CODE + len(CODE))\n</code></pre>\n<ul>\n<li>第一个参数：模拟执行的起始地址</li>\n<li>第二个参数：模拟执行的代码大小</li>\n</ul>\n<h5 id=\"读取内存结果\">读取内存结果</h5>\n<pre><code class=\"language-python\">decrypted_text = mu.mem_read(ADDRESS_OUT, 5)\n</code></pre>\n<ul>\n<li>第一个参数：读取内存的地址</li>\n<li>第二个参数：读取内存的大小</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 15:44</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ClownLMe\">ClownLMe</a>&nbsp;\n阅读(<span id=\"post_view_count\">19</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "抖音数据采集方案研究：从 API 逆向到 WebSocket 环境注入",
      "link": "https://www.cnblogs.com/fonks/p/19543725",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/fonks/p/19543725\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 15:14\">\n    <span>抖音数据采集方案研究：从 API 逆向到 WebSocket 环境注入</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1-现状背景与痛点\">1. 现状背景与痛点</h2>\n<p>在针对抖音平台进行视频播放量、评论等数据抓取时，传统的爬虫方案面临极其严峻的风控挑战：</p>\n<ul>\n<li><strong>API 协议高度加密</strong>：核心接口（如 <code>detail</code> 和 <code>comment/list</code>）强制校验动态参数 <code>msToken</code> 和 <code>a_bogus</code>。</li>\n<li><strong>算法迭代快</strong>：即便成功还原了旧版 JS 逆向逻辑，官方也会频繁更新加密算法导致代码失效。</li>\n<li><strong>风控检测严</strong>：即使参数生成正确，若请求缺少真实的浏览器指纹或动态维护的 Cookie，依然会被拦截返回空数据或触发人机验证。</li>\n</ul>\n<h2 id=\"2-核心思路websocket-环境中继方案\">2. 核心思路：WebSocket 环境中继方案</h2>\n<p>与其费力去还原复杂的加密算法，不如<strong>“借力打力”</strong>。</p>\n<p>通过建立一个 <strong>WebSocket (WS) 通道</strong>，将后端爬虫逻辑与真实的浏览器环境连接起来。利用浏览器原生环境自动补全加密参数和状态，实现“无感知”的数据抓取。</p>\n<h3 id=\"方案优势\">方案优势</h3>\n<ol>\n<li><strong>避开逆向难题</strong>：直接在浏览器内发起请求，由浏览器原生 JS 自动生成 <code>a_bogus</code> 等加密字段，无需手动还原。</li>\n<li><strong>原生状态保持</strong>：请求自动携带当前浏览器的真实 Cookie，解决了登录态失效和指纹检测问题。</li>\n<li><strong>多节点扩展</strong>：支持通过一个后端服务端连接多个浏览器（多账号、多设备），实现任务的统一分发与结果聚合。</li>\n</ol>\n<hr />\n<h2 id=\"3-技术实现\">3. 技术实现</h2>\n<h3 id=\"31-服务端-python\">3.1 服务端 (Python)</h3>\n<p>使用 <code>websockets</code> 库搭建中控台，负责任务下发和数据接收。</p>\n<pre><code class=\"language-python\">import asyncio\nimport websockets\nimport json\nimport logging\n\n# 配置日志\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nasync def server_handler(websocket, path):\n    logger.info(\"📡 浏览器客户端已连接\")\n    # 模拟任务分发逻辑\n    # await websocket.send(json.dumps({\"type\": \"get_detail\", \"aweme_id\": \"71234567890\"}))\n    \n    async for message in websocket:\n        data = json.loads(message)\n        if data['type'] in [\"detail_result\", \"comments_result\"]:\n            # 处理回传的数据\n            logger.info(f\"✅ 收到数据回传 | 类型: {data['type']} | ID: {data['aweme_id']}\")\n            # 在此处编写存库逻辑（如写入 MongoDB/MySQL）\n            # save_data(data['payload'])\n\nasync def main():\n    # 启动 WebSocket 服务\n    async with websockets.serve(server_handler, \"127.0.0.1\", 8765):\n        logger.info(\"🚀 自动监控分发服务已启动，等待浏览器连接...\")\n        await asyncio.Future()  # 永久运行\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>\n<h3 id=\"客户端注入脚本-javascript\">客户端注入脚本 (JavaScript)</h3>\n<pre><code class=\"language-js\">(function() {\n    const WS_URL = \"ws://127.0.0.1:8765\";\n    let socket;\n\n    function connect() {\n        socket = new WebSocket(WS_URL);\n        \n        socket.onopen = () =&gt; {\n            console.log(\"%c✅ 浏览器全自动代发服务已就绪\", \"color: #2ecc71; font-weight: bold;\");\n        };\n\n        socket.onmessage = (event) =&gt; {\n            const task = JSON.parse(event.data);\n            const commonParams = `device_platform=webapp&amp;aid=6383&amp;channel=channel_pc_web&amp;pc_client_type=1&amp;version_code=190500&amp;browser_name=Chrome&amp;browser_version=144.0.0.0`;\n            let url = \"\";\n\n            // 根据任务类型构造 URL\n            if (task.type === \"get_detail\") {\n                url = `https://www.douyin.com/aweme/v1/web/aweme/detail/?${commonParams}&amp;aweme_id=${task.aweme_id}`;\n            } else if (task.type === \"get_comments\") {\n                url = `https://www.douyin.com/aweme/v1/web/comment/list/?${commonParams}&amp;aweme_id=${task.aweme_id}&amp;cursor=${task.cursor || 0}&amp;count=20`;\n            }\n\n            if (url) {\n                const xhr = new XMLHttpRequest();\n                xhr.open(\"GET\", url, true);\n                xhr.withCredentials = true; // 关键：自动携带当前域名的原生 Cookie\n                xhr.setRequestHeader(\"accept\", \"application/json, text/plain, */*\");\n                \n                xhr.onreadystatechange = function() {\n                    if (xhr.readyState === 4 &amp;&amp; xhr.status === 200) {\n                        // 将获取的 JSON 数据通过 WebSocket 回传给服务端\n                        socket.send(JSON.stringify({\n                            type: task.type === \"get_detail\" ? \"detail_result\" : \"comments_result\",\n                            aweme_id: task.aweme_id,\n                            payload: JSON.parse(xhr.responseText)\n                        }));\n                    }\n                };\n                xhr.send();\n            }\n        };\n\n        socket.onclose = () =&gt; {\n            console.warn(\"🔌 连接断开，3秒后尝试重连...\");\n            setTimeout(connect, 3000);\n        };\n    }\n\n    connect();\n})();\n</code></pre>\n<p>通过这种 Socket 服务模式，我们成功避开了复杂的反爬算法分析。它将 <strong>数据逻辑（Python）与环境渲染（浏览器）</strong> 完美解耦：</p>\n<p>Python 负责：任务调度、频率控制、数据清洗、入库。</p>\n<p>浏览器负责：解决签名、携带 Cookie、绕过环境检测。</p>\n<p>这种方式非常适合小规模的高质量数据采集，且由于请求发自真实浏览器，被封禁的风险显著降低。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 15:14</span>&nbsp;\n<a href=\"https://www.cnblogs.com/fonks\">NillSpack</a>&nbsp;\n阅读(<span id=\"post_view_count\">66</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "RKNN Toolkit lite2工具详解与工程应用",
      "link": "https://www.cnblogs.com/ttkwzyttk/p/19542834",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ttkwzyttk/p/19542834\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 12:03\">\n    <span>RKNN Toolkit lite2工具详解与工程应用</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文详细介绍了RKNN Toolkit Lite2这一嵌入式人工智能开发工具，重点分析了其功能特点、使用方法以及在实际工程中的应用。首先，本文对RKNN Toolkit Lite2的安装与配置过程进行了详细讲解，并阐述了如何使用该工具对深度学习模型进行优化和部署。接着，通过一系列实际案例，展示了RKNN Toolkit Lite2在RK3576平台上的应用效果。最后，文章总结了RKNN Toolkit Lite2的开发流程。本文适合从事嵌入式AI开发的工程师和研究人员，帮助读者快速掌握RKNN Toolkit Lite2的核心技术，并将其应用于实际项目中。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"一rknn-toolkit-lite2介绍\">一、RKNN Toolkit lite2介绍</h1>\n<p>在之前的博客中，有对rknn-toolkit lite2工具进行简要介绍，rknn-toolkit lite2在嵌入式平台上进行模型推理，它主要用来部署已经转换好的rknn模型。使用python接口对模型进行调用，实现模型推理，瑞芯微提供了两种模型部署到嵌入式平台上的工具，一种是RKNPU使用C/C++接口，另一种就是rknn toolkit lite2使用python接口。RKNN-Toolkit Lite2为用户提供板端模型推理的Python接口,方便用户使用Python语言进行AI应用开发。本博文中将详细对rknn toolkit lite2进行介绍</p>\n<p>rknn-toolkit lite2工具的具体代码在瑞芯微AI github仓库中<code>https://github.com/airockchip/rknn-toolkit2</code>，可以通过clone的方式或者直接下载zip压缩包文件</p>\n<p><img alt=\"Pasted image 20260128093520.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202601/2652772-20260128120231893-1475640739.png\" /></p>\n<table>\n<thead>\n<tr>\n<th>文件夹名称</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CHANGELOG.TXT</td>\n<td>主要记录了工具的版本更新内容</td>\n</tr>\n<tr>\n<td>example</td>\n<td>存放了rknn-toolkit lite2的示例工程文件</td>\n</tr>\n<tr>\n<td>packages</td>\n<td>存放了rknn-toolkit lite2的python安装whl文件以及环境依赖文件</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"二环境搭建\">二、环境搭建</h1>\n<p>rknn-toolkit lite2的环境搭建与rkknn-toolkit2工具的搭建流程类似只不过是平台换成了嵌入式平台，主要分为两个部分，第一就是python环境的搭建包括python的安装还有对应依赖模块的板状，第二就是rkknn-toolkit lite2 whl文件的安装，这里的使用的是rk3576，烧录的系统为debain系统，注意如果使用buildroot可能会缺少一些系统依赖导致后续出现奇奇怪怪的问题，这里博主没有深入研究buildroot系统下的情况。</p>\n<h2 id=\"21-rknn-toolkit-lite2环境的搭建\">2.1 rknn-toolkit lite2环境的搭建</h2>\n<p><strong>1、miniconda安装</strong><br />\n从anaconda官网上下载miniconda，需要注意的是现在是需要将miniconda安装在rk3576上，所以下载aarch64版本，也就是arm64版<br />\n<img alt=\"Pasted image 20260128095820.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202601/2652772-20260128120231918-1846953096.png\" /><br />\n将下载好的<code>miniconda.sh</code>脚本上传到嵌入式平台上，进行安装，之后的安装流程与在X86上安装miniconda的步骤相同，这里就不赘述了，可以参考我之前的<code>rknn toolkit2</code>的博客</p>\n<p><strong>2、rknn-toolkit lite2 whl文件安装</strong><br />\n在SDK中找到官方提供的<code>rknn-toolkit lite2</code>的whl软件包，这个文件主要用来安装<code>rknn-toolkit lite2 </code>的python模块，具体路径在<code>rknn-toolkit2-master/rknn-toolkit-lite2/packages/</code>下</p>\n<p>在安装并配置好的conda环境中，具体conda环境配置可以参考之前的<code>rknn toolkit2</code>的博客，执行如下命令</p>\n<pre><code class=\"language-shell\">pip install rknn_toolkit_lite2-2.3.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\n</code></pre>\n<p>安装完成之后，如下图所示<br />\n<img alt=\"Pasted image 20260128110646.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202601/2652772-20260128120231957-1392282814.png\" /></p>\n<p>执行以下命令查看<code>rknn-toolkit lite2 </code>模块是否安装成功</p>\n<pre><code class=\"language-shell\">\n# 先在conda环境中执行python3\npython3\n\n# 在python3环境中输入以下命令\nfrom rknnlite.api import RKNNLite\nRKNNLite(verbose=True)\n</code></pre>\n<p>如果成功打印处<code>rknn-toolkit-lite2</code>的版本号，说明环境已经安装完成，接下来就可以直接部署python接口的模型推理程序了<br />\n<img alt=\"Pasted image 20260128111144.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202601/2652772-20260128120231877-671276579.png\" /></p>\n<h1 id=\"三rknn-toolkit-lite2工具使用与rknn模型部署\">三、rknn-toolkit-lite2工具使用与RKNN模型部署</h1>\n<p>注意使用<code>rknn-toolkit-lite2</code>时，部分API接口与<code>rknn-toolkit2</code>不同，编写应用程序时，需要注意以下两点</p>\n<p><strong>1、导入模块不同</strong></p>\n<pre><code class=\"language-python\">import numpy as np  \nimport cv2  \n# rknn-toolkit-lite2导入的模块是RKNNLite\nfrom rknnlite.api import RKNNLite\n\n# 将详细的日志信息输出到屏幕,并写到inference.log文件中\nrknn_lite = RKNNLite(verbose=True, verbose_file='./inference.log')\n# 只在屏幕打印详细的日志信息\nrknn_lite = RKNNLite(verbose=True)\n\nrknn_lite.release()\n</code></pre>\n<p><strong>2、<code>init_runtime</code>函数接口不同</strong><br />\n在使用<code>rknn-toolkit-lite2</code>时，<code>init_runtime</code>没有target参数，只需要使用<code>core_mask</code>指定运行的NPU模式就行</p>\n<pre><code class=\"language-python\"># 初始化运行时环境\nret = rknn_lite.init_runtime(core_mask=RKNNLite.NPU_CORE_AUTO)\nif ret != 0:\nprint('Init runtime environment failed')\nexit(ret)\n</code></pre>\n<p>示例代码如下</p>\n<pre><code class=\"language-python\">import numpy as np  \nimport cv2  \nfrom rknnlite.api import RKNNLite  \nimport os  \ndef show_outputs(output):  \n    index = sorted(range(len(output)), key=lambda k : output[k], reverse=True)  \n    fp = open('./labels.txt', 'r')  \n    labels = fp.readlines()  \n    top5_str = 'resnet18\\n-----TOP 5-----\\n'  \n    for i in range(5):  \n        value = output[index[i]]  \n        if value &gt; 0:  \n            topi = '[{:&gt;3d}] score:{:.6f} class:\"{}\"\\n'.format(index[i], value, labels[index[i]].strip().split(':')[-1])  \n        else:  \n            topi = '[ -1]: 0.0\\n'  \n        top5_str += topi  \n    print(top5_str.strip())  \n  \ndef show_perfs(perfs):  \n    perfs = 'perfs: {}\\n'.format(perfs)  \n    print(perfs)  \n  \ndef softmax(x):  \n    return np.exp(x)/sum(np.exp(x))  \n  \nif __name__ == '__main__':  \n  \n    # Create RKNN object  \n    rknn = RKNNLite(verbose=True)  \n  \n    rknn.load_rknn(path='./resnet_18.rknn')  \n    # Set inputs  \n    img = cv2.imread('./space_shuttle_224.jpg')  \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n    img = np.expand_dims(img, 0)  \n  \n    # Init runtime environment  \n    print('--&gt; Init runtime environment')  \n    ret = rknn.init_runtime(core_mask=RKNNLite.NPU_CORE_AUTO)  \n    if ret != 0:  \n        print('Init runtime environment failed!')  \n        exit(ret)  \n    print('done')  \n  \n    # Inference  \n    print('--&gt; Running model')  \n    outputs = rknn.inference(inputs=[img])  \n    show_outputs(softmax(np.array(outputs[0][0])))  \n    print('done')  \n  \n    rknn.release()\n</code></pre>\n<p>通过ADB将例程程序运行需要的文件以及模型上传到嵌入式板卡中，激活conda环境，使用以下命令运行程序</p>\n<pre><code class=\"language-shell\">wzy@wzy-JiaoLong:~/rknn/rknn-toolkit2-master/rknn-toolkit2/examples/pytorch/resnet18$ adb shell\nroot@linaro-alip:/# cd rknn/  \nroot@linaro-alip:/rknn# conda activate rknn  \n(rknn) root@linaro-alip:/rknn# ls  \nlabels.txt &nbsp;resnet_18.rknn &nbsp;space_shuttle_224.jpg &nbsp;test_rknn_lite2.py  \n(rknn) root@linaro-alip:/rknn# python3 test_rknn_lite2.py\n</code></pre>\n<p>附上rk3576嵌入式平台上官方例程的运行结果</p>\n<pre><code class=\"language-shell\">wzy@wzy-JiaoLong:~/rknn/rknn-toolkit2-master/rknn-toolkit2/examples/pytorch/resnet18$ adb shell\nroot@linaro-alip:/# cd rknn/  \nroot@linaro-alip:/rknn# conda activate rknn  \n(rknn) root@linaro-alip:/rknn# ls  \nlabels.txt &nbsp;resnet_18.rknn &nbsp;space_shuttle_224.jpg &nbsp;test_rknn_lite2.py  \n(rknn) root@linaro-alip:/rknn# python3 test_rknn_lite2.py\nW rknn-toolkit-lite2 version: 2.3.2\nW Verbose file path is invalid, debug info will not dump to file.  \n--&gt; Init runtime environment  \nD target set by user is: None  \nD Starting ntp or adb, target soc is RK3576, device id is: None  \nI RKNN: [03:36:13.388] RKNN Runtime Information, librknnrt version: 2.3.2 (429f97ae6b@2025-04-09T09:09:27)  \nI RKNN: [03:36:13.388] RKNN Driver Information, version: 0.9.8  \nI RKNN: [03:36:13.388] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU f2, target platform: rk3576, fram  \nework name: PyTorch, framework layout: NCHW, model inference type: static_shape  \nD RKNN: [03:36:13.389] allocated memory, name: task, virt addr: 0x7fb7ea5000, dma addr: 0xfffff000, obj addr: 0xffffff80c921a000, size: 4080, aligned size: 4096, fd: 4, handle: 1, flags: 0  \nx40b, gem name: 1, iommu domain id: 0  \nD RKNN: [03:36:13.406] allocated memory, name: weight, virt addr: 0x7f9a0a6000, dma addr: 0xff495000, obj addr: 0xffffff80c9218400, size: 11968000, aligned size: 11968512, fd: 5, handle: 2  \n, flags: 0x403, gem name: 2, iommu domain id: 0  \nD RKNN: [03:36:13.421] subgraph0 regcmdbuffer size: 110464, taskbuffer size: 4080  \nD RKNN: [03:36:13.423] allocated memory, name: internal, virt addr: 0x7fb420b000, dma addr: 0xff37b000, obj addr: 0xffffff80c921ec00, size: 1154048, aligned size: 1155072, fd: 6, handle: 3  \n, flags: 0x403, gem name: 3, iommu domain id: 0  \nD RKNN: [03:36:13.424] -------------------------------------------------------------------------------------------------------------------------------  \nD RKNN: [03:36:13.424] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Tensor Information Table &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.424] ---------------------------------------------------------------------------------------------+---------------------------------  \nD RKNN: [03:36:13.424] ID &nbsp;User &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tensor &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DataType &nbsp;DataFormat &nbsp;&nbsp;OrigShape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NativeShape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| &nbsp;&nbsp;&nbsp;&nbsp;[Start &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;End) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Size  \nD RKNN: [03:36:13.424] ---------------------------------------------------------------------------------------------+---------------------------------  \nD RKNN: [03:36:13.424] 1 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x.3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,3,224,224) &nbsp;(1,1,224,224,3) &nbsp;| 0xff37b000 0xff39fc00 0x00024c00  \nD RKNN: [03:36:13.424] 2 &nbsp;&nbsp;MaxPool &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;82 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,112,112) (1,4,112,112,16) | 0xff39fc00 0xff463c00 0x000c4000  \nD RKNN: [03:36:13.424] 3 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input.13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff463c00*0xff494c00 0x00031000  \nD RKNN: [03:36:13.424] 4 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;120 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff37b000 0xff3ac000 0x00031000  \nD RKNN: [03:36:13.424] 4 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;input.13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff463c00*0xff494c00 0x00031000  \nD RKNN: [03:36:13.424] 5 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;142 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff3ac000 0xff3dd000 0x00031000  \nD RKNN: [03:36:13.424] 6 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;169 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff37b000 0xff3ac000 0x00031000  \nD RKNN: [03:36:13.424] 6 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;142 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff3ac000 0xff3dd000 0x00031000  \nD RKNN: [03:36:13.424] 7 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;191 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff3dd000 0xff40e000 0x00031000  \nD RKNN: [03:36:13.424] 8 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;222 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff37b000 0xff393800 0x00018800  \nD RKNN: [03:36:13.424] 9 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;191 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;(1,4,56,56,16) &nbsp;&nbsp;| 0xff3dd000 0xff40e000 0x00031000  \nD RKNN: [03:36:13.424] 9 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;out.7 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff393800 0xff3ac000 0x00018800  \nD RKNN: [03:36:13.424] 10 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;267 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff37b000 0xff393800 0x00018800  \nD RKNN: [03:36:13.424] 11 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;294 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff393800 0xff3ac000 0x00018800  \nD RKNN: [03:36:13.424] 11 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;267 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff37b000 0xff393800 0x00018800  \nD RKNN: [03:36:13.424] 12 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;316 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff3ac000 0xff3c4800 0x00018800  \nD RKNN: [03:36:13.424] 13 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;347 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff37b000 0xff387400 0x0000c400  \nD RKNN: [03:36:13.424] 14 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;316 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;(1,8,28,28,16) &nbsp;&nbsp;| 0xff3ac000 0xff3c4800 0x00018800  \nD RKNN: [03:36:13.424] 14 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;out.11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff387400 0xff393800 0x0000c400  \nD RKNN: [03:36:13.424] 15 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;392 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff37b000 0xff387400 0x0000c400  \nD RKNN: [03:36:13.424] 16 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;419 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff387400 0xff393800 0x0000c400  \nD RKNN: [03:36:13.424] 16 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;392 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff37b000 0xff387400 0x0000c400  \nD RKNN: [03:36:13.424] 17 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;441 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff393800 0xff39fc00 0x0000c400  \nD RKNN: [03:36:13.424] 18 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;472 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;(1,33,7,7,16) &nbsp;&nbsp;&nbsp;| 0xff37b000 0xff381800 0x00006800  \nD RKNN: [03:36:13.424] 19 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;441 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;(1,16,14,14,16) &nbsp;| 0xff393800 0xff39fc00 0x0000c400  \nD RKNN: [03:36:13.424] 19 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;out.2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;(1,33,7,7,16) &nbsp;&nbsp;&nbsp;| 0xff381800 0xff388000 0x00006800  \nD RKNN: [03:36:13.424] 20 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;517 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;(1,33,7,7,16) &nbsp;&nbsp;&nbsp;| 0xff37b000 0xff381800 0x00006800  \nD RKNN: [03:36:13.424] 21 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;544 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;(1,33,7,7,16) &nbsp;&nbsp;&nbsp;| 0xff381800 0xff388000 0x00006800  \nD RKNN: [03:36:13.424] 21 &nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;517 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;(1,33,7,7,16) &nbsp;&nbsp;&nbsp;| 0xff37b000 0xff381800 0x00006800  \nD RKNN: [03:36:13.424] 22 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;566 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;(1,33,7,7,16) &nbsp;&nbsp;&nbsp;| 0xff388000 0xff38e800 0x00006800  \nD RKNN: [03:36:13.424] 23 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,1,1) &nbsp;&nbsp;&nbsp;(1,32,1,1,16) &nbsp;&nbsp;&nbsp;| 0xff37b000 0xff37b200 0x00000200  \nD RKNN: [03:36:13.424] 24 &nbsp;Reshape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;572_mm &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NC1HWC2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,1000,1,1) &nbsp;&nbsp;(1,64,1,1,16) &nbsp;&nbsp;&nbsp;| 0xff37b200 0xff37b600 0x00000400  \nD RKNN: [03:36:13.424] 25 &nbsp;OutputOperator 572 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UNDEFINED &nbsp;&nbsp;&nbsp;(1,1000) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,1000) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xff37b600 0xff37ba00 0x00000400  \nD RKNN: [03:36:13.424] ---------------------------------------------------------------------------------------------+---------------------------------  \nD RKNN: [03:36:13.424] -----------------------------------------------------------------------------------------------------------  \nD RKNN: [03:36:13.424] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Const Tensor Information Table &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.424] -------------------------------------------------------------------------+---------------------------------  \nD RKNN: [03:36:13.424] ID &nbsp;User &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tensor &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DataType &nbsp;OrigShape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| &nbsp;&nbsp;&nbsp;&nbsp;[Start &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;End) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Size  \nD RKNN: [03:36:13.424] -------------------------------------------------------------------------+---------------------------------  \nD RKNN: [03:36:13.424] 1 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(64,3,7,7) &nbsp;&nbsp;&nbsp;&nbsp;| 0xfffb8000 0xfffbf000 0x00007000  \nD RKNN: [03:36:13.424] 1 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.8_1_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbf000 0xfffbf200 0x00000200  \nD RKNN: [03:36:13.424] 3 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.20 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(64,64,3,3) &nbsp;&nbsp;&nbsp;| 0xfffaf000 0xfffb8000 0x00009000  \nD RKNN: [03:36:13.424] 3 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.6_5_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbf200 0xfffbf400 0x00000200  \nD RKNN: [03:36:13.424] 4 &nbsp;&nbsp;ConvAddRelu weight.16 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(64,64,3,3) &nbsp;&nbsp;&nbsp;| 0xfffa6000 0xfffaf000 0x00009000  \nD RKNN: [03:36:13.424] 4 &nbsp;&nbsp;ConvAddRelu bias.10_8_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbf400 0xfffbf600 0x00000200  \nD RKNN: [03:36:13.424] 5 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.24 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(64,64,3,3) &nbsp;&nbsp;&nbsp;| 0xfff9d000 0xfffa6000 0x00009000  \nD RKNN: [03:36:13.424] 5 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.12_12_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbf600 0xfffbf800 0x00000200  \nD RKNN: [03:36:13.424] 6 &nbsp;&nbsp;ConvAddRelu weight.28 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(64,64,3,3) &nbsp;&nbsp;&nbsp;| 0xfff94000 0xfff9d000 0x00009000  \nD RKNN: [03:36:13.424] 6 &nbsp;&nbsp;ConvAddRelu bias.14_15_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbf800 0xfffbfa00 0x00000200  \nD RKNN: [03:36:13.424] 7 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.32 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(128,64,3,3) &nbsp;&nbsp;| 0xfff82000 0xfff94000 0x00012000  \nD RKNN: [03:36:13.424] 7 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.16_19_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbfa00 0xfffbfe00 0x00000400  \nD RKNN: [03:36:13.424] 8 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight.36 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(128,128,3,3) &nbsp;| 0xfff5e000 0xfff82000 0x00024000  \nD RKNN: [03:36:13.424] 8 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias.18_22_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffbfe00 0xfffc0200 0x00000400  \nD RKNN: [03:36:13.424] 9 &nbsp;&nbsp;ConvAddRelu weight.40 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(128,64,1,1) &nbsp;&nbsp;| 0xfff5c000 0xfff5e000 0x00002000  \nD RKNN: [03:36:13.424] 9 &nbsp;&nbsp;ConvAddRelu bias.20_24_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc0200 0xfffc0600 0x00000400  \nD RKNN: [03:36:13.424] 10 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.44 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(128,128,3,3) &nbsp;| 0xfff38000 0xfff5c000 0x00024000  \nD RKNN: [03:36:13.424] 10 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.22_28_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc0600 0xfffc0a00 0x00000400  \nD RKNN: [03:36:13.424] 11 &nbsp;ConvAddRelu weight.48 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(128,128,3,3) &nbsp;| 0xfff14000 0xfff38000 0x00024000  \nD RKNN: [03:36:13.424] 11 &nbsp;ConvAddRelu bias.24_31_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc0a00 0xfffc0e00 0x00000400  \nD RKNN: [03:36:13.424] 12 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.52 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(256,128,3,3) &nbsp;| 0xffecc000 0xfff14000 0x00048000  \nD RKNN: [03:36:13.424] 12 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.26_35_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc0e00 0xfffc1600 0x00000800  \nD RKNN: [03:36:13.424] 13 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight.56 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(256,256,3,3) &nbsp;| 0xffe3c000 0xffecc000 0x00090000  \nD RKNN: [03:36:13.424] 13 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias.28_38_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc1600 0xfffc1e00 0x00000800  \nD RKNN: [03:36:13.424] 14 &nbsp;ConvAddRelu weight.60 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(256,128,1,1) &nbsp;| 0xffe34000 0xffe3c000 0x00008000  \nD RKNN: [03:36:13.424] 14 &nbsp;ConvAddRelu bias.30_40_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc1e00 0xfffc2600 0x00000800  \nD RKNN: [03:36:13.424] 15 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.64 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(256,256,3,3) &nbsp;| 0xffda4000 0xffe34000 0x00090000  \nD RKNN: [03:36:13.424] 15 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.32_44_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc2600 0xfffc2e00 0x00000800  \nD RKNN: [03:36:13.424] 16 &nbsp;ConvAddRelu weight.68 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(256,256,3,3) &nbsp;| 0xffd14000 0xffda4000 0x00090000  \nD RKNN: [03:36:13.424] 16 &nbsp;ConvAddRelu bias.34_47_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc2e00 0xfffc3600 0x00000800  \nD RKNN: [03:36:13.424] 17 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(512,256,3,3) &nbsp;| 0xffbf4000 0xffd14000 0x00120000  \nD RKNN: [03:36:13.424] 17 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.3_51_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc3600 0xfffc4600 0x00001000  \nD RKNN: [03:36:13.424] 18 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight.7 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(512,512,3,3) &nbsp;| 0xff9b4000 0xffbf4000 0x00240000  \nD RKNN: [03:36:13.424] 18 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias.4_54_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc4600 0xfffc5600 0x00001000  \nD RKNN: [03:36:13.424] 19 &nbsp;ConvAddRelu weight.3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(512,256,1,1) &nbsp;| 0xff994000 0xff9b4000 0x00020000  \nD RKNN: [03:36:13.424] 19 &nbsp;ConvAddRelu bias.5_56_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc5600 0xfffc6600 0x00001000  \nD RKNN: [03:36:13.424] 20 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;weight.2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(512,512,3,3) &nbsp;| 0xff754000 0xff994000 0x00240000  \nD RKNN: [03:36:13.424] 20 &nbsp;ConvRelu &nbsp;&nbsp;&nbsp;bias.2_60_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc6600 0xfffc7600 0x00001000  \nD RKNN: [03:36:13.424] 21 &nbsp;ConvAddRelu weight.6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(512,512,3,3) &nbsp;| 0xff514000 0xff754000 0x00240000  \nD RKNN: [03:36:13.424] 21 &nbsp;ConvAddRelu bias.36_63_bias &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffc7600 0xfffc8600 0x00001000  \nD RKNN: [03:36:13.424] 22 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x.1_GlobalAveragePool_2conv0_i1 INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;| 0xfffc8600 0xfffd4a00 0x0000c400  \nD RKNN: [03:36:13.424] 22 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x.1_GlobalAveragePool_2conv0_i2 INT32 &nbsp;&nbsp;&nbsp;&nbsp;(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffd4a00 0xfffd5600 0x00000c00  \nD RKNN: [03:36:13.424] 23 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weight.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1000,512,1,1) | 0xff497000 0xff514000 0x0007d000  \nD RKNN: [03:36:13.424] 23 &nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT32 &nbsp;&nbsp;&nbsp;&nbsp;(1000) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xff495000 0xff497000 0x00002000  \nD RKNN: [03:36:13.424] 24 &nbsp;Reshape &nbsp;&nbsp;&nbsp;&nbsp;572_mm_tp_rs_i1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT64 &nbsp;&nbsp;&nbsp;&nbsp;(2) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| 0xfffd5600 0xfffd5610 0x00000010  \nD RKNN: [03:36:13.424] -------------------------------------------------------------------------+---------------------------------  \nD RKNN: [03:36:13.424] ----------------------------------------  \nD RKNN: [03:36:13.424] Total Internal Memory Size: 1127KB  \nD RKNN: [03:36:13.424] Total Weight Memory Size: 11550.8KB  \nD RKNN: [03:36:13.425] ----------------------------------------  \nD RKNN: [03:36:13.425] The RKNN_FLAG_EXECUTE_FALLBACK_PRIOR_DEVICE_GPU is not set and without GPU op in Graphs, OpenCL will not be initialized  \nW RKNN: [03:36:13.426] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes  \nW Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)  \ndone  \n--&gt; Running model  \nD RKNN: [03:36:13.428] allocated memory, name: x.3, virt addr: 0x7fb41e6000, dma addr: 0xff356000, obj addr: 0xffffff80c9228800, size: 150528, aligned size: 151552, fd: 7, handle: 4, flags  \n: 0x403, gem name: 4, iommu domain id: 0  \nD RKNN: [03:36:13.428] allocated memory, name: 572, virt addr: 0x7fb7ea4000, dma addr: 0xff355000, obj addr: 0xffffff80c922c400, size: 1024, aligned size: 4096, fd: 8, handle: 5, flags: 0x  \n403, gem name: 5, iommu domain id: 0  \nD RKNN: [03:36:13.428] enable argb mode, dtype: UINT8, channel: 3  \nD RKNN: [03:36:13.428] normalize target: NPU  \nD RKNN: [03:36:13.428] update cvt sign: 0  \nD RKNN: [03:36:13.429] Get NPU frequency: 950MHz  \nD RKNN: [03:36:13.429] Get DDR frequency: 528MHz  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n---------------------------------------------------------------------  \nD RKNN: [03:36:13.439] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Network Layer Information Table &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n---------------------------------------------------------------------  \nD RKNN: [03:36:13.439] ID &nbsp;&nbsp;OpType &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DataType Target InputShape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OutputShape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cycles(DDR/NPU/Total) &nbsp;&nbsp;&nbsp;Time(us) &nbsp;&nbsp;&nbsp;&nbsp;MacUsage(%) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Wo  \nrkLoad(0/1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparseRatio &nbsp;RW(KB) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FullName &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n---------------------------------------------------------------------  \nD RKNN: [03:36:13.439] 1 &nbsp;&nbsp;&nbsp;InputOperator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UINT8 &nbsp;&nbsp;&nbsp;CPU &nbsp;&nbsp;&nbsp;\\ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,3,224,224) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0/0/0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.  \n0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;InputOperator:x.3  \nD RKNN: [03:36:13.439] 2 &nbsp;&nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UINT8 &nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,3,224,224),(64,3,7,7),(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,112,112) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;569350/1229312/1229312 &nbsp;&nbsp;418 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;29.02/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;946 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.21_Conv  \nD RKNN: [03:36:13.439] 3 &nbsp;&nbsp;&nbsp;MaxPool &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,112,112) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0/0/0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;454 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;980 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MaxPool:input.13_MaxPool  \nD RKNN: [03:36:13.439] 4 &nbsp;&nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,56,56),(64,64,3,3),(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;205825/112896/205825 &nbsp;&nbsp;&nbsp;&nbsp;315 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37.73/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;429 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.17_Conv  \nD RKNN: [03:36:13.439] 5 &nbsp;&nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,56,56),(64,64,3,3),(64),... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;270306/112896/270306 &nbsp;&nbsp;&nbsp;&nbsp;255 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;46.60/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;625 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.23_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 6 &nbsp;&nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,56,56),(64,64,3,3),(64) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;205825/112896/205825 &nbsp;&nbsp;&nbsp;&nbsp;254 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;46.79/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;429 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.27_Conv  \nD RKNN: [03:36:13.439] 7 &nbsp;&nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,56,56),(64,64,3,3),(64),... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,64,56,56) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;270306/112896/270306 &nbsp;&nbsp;&nbsp;&nbsp;268 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;44.34/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;625 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.31_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 8 &nbsp;&nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,56,56),(128,64,3,3),(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;153352/56448/153352 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;274 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;21.69/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;368 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.35_Conv  \nD RKNN: [03:36:13.439] 9 &nbsp;&nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,128,28,28),(128,128,3,3),(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;144799/112896/144799 &nbsp;&nbsp;&nbsp;&nbsp;305 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;38.96/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;342 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.39_Conv  \nD RKNN: [03:36:13.439] 10 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,64,56,56),(128,64,1,1),(128),... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;162255/12544/162255 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;187 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.53/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;395 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.41_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 11 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,128,28,28),(128,128,3,3),(128) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;144799/112896/144799 &nbsp;&nbsp;&nbsp;&nbsp;246 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;48.31/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;342 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.45_Conv  \nD RKNN: [03:36:13.439] 12 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,128,28,28),(128,128,3,3),(128),... &nbsp;&nbsp;&nbsp;(1,128,28,28) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;177039/112896/177039 &nbsp;&nbsp;&nbsp;&nbsp;249 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;47.73/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;440 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.49_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 13 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,128,28,28),(256,128,3,3),(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;160261/59904/160261 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;195 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;30.47/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;438 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.53_Conv  \nD RKNN: [03:36:13.439] 14 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,256,14,14),(256,256,3,3),(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;238888/119808/238888 &nbsp;&nbsp;&nbsp;&nbsp;318 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;37.37/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;677 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.57_Conv  \nD RKNN: [03:36:13.439] 15 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,128,28,28),(256,128,1,1),(256),... &nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;89900/6656/89900 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;138 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.78/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;224 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.59_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 16 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,256,14,14),(256,256,3,3),(256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;238888/119808/238888 &nbsp;&nbsp;&nbsp;&nbsp;259 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;45.88/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;677 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.63_Conv  \nD RKNN: [03:36:13.439] 17 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,256,14,14),(256,256,3,3),(256),... &nbsp;&nbsp;&nbsp;(1,256,14,14) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;255008/119808/255008 &nbsp;&nbsp;&nbsp;&nbsp;330 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;36.01/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;726 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.67_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 18 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,256,14,14),(512,256,3,3),(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;412919/73728/412919 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;532 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11.17/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1230 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.6_Conv  \nD RKNN: [03:36:13.439] 19 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,512,7,7),(512,512,3,3),(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;783846/147456/783846 &nbsp;&nbsp;&nbsp;&nbsp;915 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12.99/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2358 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.9_Conv  \nD RKNN: [03:36:13.439] 20 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,256,14,14),(512,256,1,1),(512),... &nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;81881/8192/81881 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;229 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.88/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;224 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.10_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 21 &nbsp;&nbsp;ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,512,7,7),(512,512,3,3),(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;783846/147456/783846 &nbsp;&nbsp;&nbsp;&nbsp;894 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13.29/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2358 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.5_Conv  \nD RKNN: [03:36:13.439] 22 &nbsp;&nbsp;ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,512,7,7),(512,512,3,3),(512),... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,7,7) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;791907/147456/791907 &nbsp;&nbsp;&nbsp;&nbsp;888 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;13.38/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2382 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:input.1_Conv_ConvAddRelu  \nD RKNN: [03:36:13.439] 23 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,512,7,7),(1,512,7,7),(512) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,512,1,1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;25872/6272/25872 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;170 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.02/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;78 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:x.1_GlobalAveragePool_2conv0  \nD RKNN: [03:36:13.439] 24 &nbsp;&nbsp;Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,512,1,1),(1000,512,1,1),(1000) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,1000,1,1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;168249/8192/168249 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;278 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.19/0.00 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;510 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv:572_Gemm#2 &nbsp;  \nD RKNN: [03:36:13.439] 25 &nbsp;&nbsp;Reshape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;NPU &nbsp;&nbsp;&nbsp;(1,1000,1,1),(2) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1,1000) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0/0/0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;82 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10  \n0.0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reshape:572_mm_tp_rs  \nD RKNN: [03:36:13.439] 26 &nbsp;&nbsp;OutputOperator &nbsp;&nbsp;&nbsp;&nbsp;INT8 &nbsp;&nbsp;&nbsp;&nbsp;CPU &nbsp;&nbsp;&nbsp;(1,1000) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\\ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0/0/0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.  \n0%/0.0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OutputOperator:572  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n---------------------------------------------------------------------  \nD RKNN: [03:36:13.439] Total Operator Elapsed Per Frame Time(us): 8476  \nD RKNN: [03:36:13.439] Total Internal Memory Read/Write Per Frame Size(KB): 6354.34  \nD RKNN: [03:36:13.439] Total Weight Memory Read/Write Per Frame Size(KB): 11459.00  \nD RKNN: [03:36:13.439] Total Memory Read/Write Per Frame Size(KB): 17813.34  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------------------------------------------------------------------------  \n---------------------------------------------------------------------  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------  \nD RKNN: [03:36:13.439] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Operator Time Consuming Ranking Table &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------  \nD RKNN: [03:36:13.439] OpType &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CallNumber &nbsp;&nbsp;CPUTime(us) &nbsp;GPUTime(us) &nbsp;NPUTime(us) &nbsp;TotalTime(us) &nbsp;TimeRatio(%) &nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------  \nD RKNN: [03:36:13.439] ConvRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3387 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3387 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;39.96% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ConvAddRelu &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2544 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2544 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;30.01% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] Conv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1986 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1986 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23.43% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] MaxPool &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;454 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;454 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.36% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] Reshape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;82 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;82 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.97% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] InputOperator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.14% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] OutputOperator &nbsp;&nbsp;&nbsp;&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.13% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------  \nD RKNN: [03:36:13.439] Total &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;23 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8453 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8476 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \nD RKNN: [03:36:13.439] ---------------------------------------------------------------------------------------------------  \nresnet18  \n-----TOP 5-----  \n[812] score:0.999638 class:\"space shuttle\"  \n[404] score:0.000281 class:\"airliner\"  \n[657] score:0.000014 class:\"missile\"  \n[466] score:0.000010 class:\"bullet train, bullet\"  \n[833] score:0.000010 class:\"submarine, pigboat, sub, U-boat\"  \ndone  \nD RKNN: [03:36:13.444] free memory, name: internal, virt addr: 0x7fb420b000, dma addr: 0xff37b000, obj addr: 0xffffff80c921ec00, size: 1154048, aligned size: 1155072, fd: 6, handle: 3, fla  \ngs: 0x403, gem name: 3, iommu domain id: 0  \nD RKNN: [03:36:13.445] free memory, name: weight, virt addr: 0x7f9a0a6000, dma addr: 0xff495000, obj addr: 0xffffff80c9218400, size: 11968000, aligned size: 11968512, fd: 5, handle: 2, fla  \ngs: 0x403, gem name: 2, iommu domain id: 0  \nD RKNN: [03:36:13.452] free memory, name: task, virt addr: 0x7fb7ea5000, dma addr: 0xfffff000, obj addr: 0xffffff80c921a000, size: 4080, aligned size: 4096, fd: 4, handle: 1, flags: 0x40b,  \ngem name: 1, iommu domain id: 0  \nD RKNN: [03:36:13.453] free memory, name: x.3, virt addr: 0x7fb41e6000, dma addr: 0xff356000, obj addr: 0xffffff80c9228800, size: 150528, aligned size: 151552, fd: 7, handle: 4, flags: 0x4  \n03, gem name: 4, iommu domain id: 0  \nD RKNN: [03:36:13.453] free memory, name: 572, virt addr: 0x7fb7ea4000, dma addr: 0xff355000, obj addr: 0xffffff80c922c400, size: 1024, aligned size: 4096, fd: 8, handle: 5, flags: 0x403,  \ngem name: 5, iommu domain id: 0  \n(rknn) root@linaro-alip:/rknn#\n</code></pre>\n<p>可以看见，加载的resnet18 rknn模型正确将space shuttle图片分类出来，到这里，<code>rknn-toolkit-lite2</code>工具的使用，环境搭建以及rknn模型在嵌入式平台python接口部署就介绍完成了</p>\n<h1 id=\"四总结\">四、总结</h1>\n<p>如果后续需要在嵌入式平台上使用python接口来部署rknn模型，一般的流程为<br />\n1、先在x86平台上使用<code>rknn-toolkit2</code>工具将模型调试好<br />\n2、在同一python文件内修改模块名称为<code>rknn-toolkit-lite2</code>，修改一些接口环境，就转换成了<code>rknn-toolkit-lite2</code>相应程序<br />\n3、拷贝所需依赖资源与文件到嵌入式开发平台上，之后直接运行<code>rknn-toolkit-lite2</code>对应的程序就可以直接在开发板上使用了</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 12:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ttkwzyttk\">ttkwzyttk</a>&nbsp;\n阅读(<span id=\"post_view_count\">69</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "一天一个Python库：cryptography - 安全地进行加密和解密",
      "link": "https://www.cnblogs.com/min2k/p/19542793",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/min2k/p/19542793\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 11:58\">\n    <span>一天一个Python库：cryptography - 安全地进行加密和解密</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"cryptography---安全地进行加密和解密\">cryptography - 安全地进行加密和解密</h1>\n<h2 id=\"一什么是cryptography\">一、什么是cryptography？</h2>\n<p><strong>cryptography</strong> 是一个用于在Python中实现各种加密和解密算法的库。<br />\n它可以帮助你：</p>\n<ul>\n<li>安全地存储敏感数据</li>\n<li>验证数据的完整性</li>\n<li>确保通信的隐私性</li>\n</ul>\n<h2 id=\"二应用场景\">二、应用场景</h2>\n<p><strong>cryptography</strong> 广泛应用于以下实际场景：</p>\n<ul>\n<li><strong>密码哈希</strong>: 存储用户密码时，不直接存储明文，而是存储其哈希值。</li>\n<li><strong>数据加密</strong>: 对存储在磁盘上的文件或数据库中的敏感信息进行加密。</li>\n<li><strong>数字签名</strong>: 验证数据的来源和完整性，防止数据被篡改。</li>\n<li><strong>TLS/SSL</strong>: 用于HTTPS连接，确保网页浏览安全。</li>\n</ul>\n<h2 id=\"三如何安装\">三、如何安装</h2>\n<ol>\n<li>使用 pip 安装</li>\n</ol>\n<pre><code class=\"language-bash\">pip install cryptography\n\n# 如果安装慢的话，推荐使用国内镜像源\npip install cryptography -i https://www.python64.cn/pypi/simple/\n</code></pre>\n<ol start=\"2\">\n<li>使用 <a href=\"https://www.min2k.com/tools/python-run/\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a> 在线运行代码（无需本地安装）</li>\n</ol>\n<h2 id=\"四示例代码\">四、示例代码</h2>\n<p>使用 Fernet 加密和解密字符串</p>\n<pre><code class=\"language-python\">from cryptography.fernet import Fernet\n\n# 生成一个密钥（只生成一次并妥善保管）\n# key = Fernet.generate_key()\n# print(key) # 通常你会把这个保存到一个安全的地方，而不是每次都生成\n\n# 为了示例，我们使用一个预设的密钥\nkey = b'YOUR_256_BIT_KEY_HERE_THAT_IS_BASE64_ENCODED=' # 替换成你实际生成的或预设的密钥\nf = Fernet(key)\n\n# 要加密的数据\nmessage = b\"I want to encrypt this secret message.\"\n\n# 加密数据\nencrypted_message = f.encrypt(message)\nprint(f\"加密后的数据: {encrypted_message}\")\n\n# 判断是否成功加密，如果加密后的数据格式正确，通常是成功的\nif encrypted_message.startswith(b'gAAAAA'): # Fernet加密后的数据通常以 'gAAAAA' 开头\n    print(\"数据似乎已成功加密！\")\nelse:\n    print(\"数据加密可能存在问题。\")\n\n# 解密数据\ndecrypted_message = f.decrypt(encrypted_message)\nprint(f\"解密后的数据: {decrypted_message}\")\n\n# 验证解密后的数据是否与原始数据匹配\nif decrypted_message == message:\n    print(\"解密成功，数据完整一致。\")\nelse:\n    print(\"解密失败或数据不一致。\")\n</code></pre>\n<p>使用 <a href=\"https://www.min2k.com/tools/python-run/?code=from%20cryptography.fernet%20import%20Fernet%0A%0A%23%20%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AA%E5%AF%86%E9%92%A5%EF%BC%88%E5%8F%AA%E7%94%9F%E6%88%90%E4%B8%80%E6%AC%A1%E5%B9%B6%E5%A6%A5%E5%96%84%E4%BF%9D%E7%AE%A1%EF%BC%89%0A%23%20key%20%3D%20Fernet.generate_key%28%29%0A%23%20print%28key%29%20%23%20%E9%80%9A%E5%B8%B8%E4%BD%A0%E4%BC%9A%E6%8A%8A%E8%BF%99%E4%B8%AA%E4%BF%9D%E5%AD%98%E5%88%B0%E4%B8%80%E4%B8%AA%E5%AE%89%E5%85%A8%E7%9A%84%E5%9C%B0%E6%96%B9%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E6%AF%8F%E6%AC%A1%E9%83%BD%E7%94%9F%E6%88%90%0A%0A%23%20%E4%B8%BA%E4%BA%86%E7%A4%BA%E4%BE%8B%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA%E9%A2%84%E8%AE%BE%E7%9A%84%E5%AF%86%E9%92%A5%28%E5%BF%85%E9%A1%BB%E6%98%AF32%E5%AD%97%E8%8A%82%E7%9A%84url-safe%20base64%E7%BC%96%E7%A0%81%29%0Akey%20%3D%20b'Uu_No1PKBlOXOF_IQzPYEDZCH4AssuoLsPQds84I_Co%3D'%20%20%23%20%E6%AD%A4%E5%A4%84%E8%AF%B7%E7%94%A8%E5%AE%9E%E9%99%85Fernet%E5%AF%86%E9%92%A5%EF%BC%8C%E9%95%BF%E5%BA%A6%E5%92%8C%E6%A0%BC%E5%BC%8F%E5%A6%82%E7%A4%BA%E4%BE%8B%0Af%20%3D%20Fernet%28key%29%0A%0A%23%20%E8%A6%81%E5%8A%A0%E5%AF%86%E7%9A%84%E6%95%B0%E6%8D%AE%0Amessage%20%3D%20b%22I%20want%20to%20encrypt%20this%20secret%20message.%22%0A%0A%23%20%E5%8A%A0%E5%AF%86%E6%95%B0%E6%8D%AE%0Aencrypted_message%20%3D%20f.encrypt%28message%29%0Aprint%28f%22%E5%8A%A0%E5%AF%86%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%3A%20%7Bencrypted_message%7D%22%29%0A%0A%23%20%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F%E5%8A%A0%E5%AF%86%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%8A%A0%E5%AF%86%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E6%AD%A3%E7%A1%AE%EF%BC%8C%E9%80%9A%E5%B8%B8%E6%98%AF%E6%88%90%E5%8A%9F%E7%9A%84%0Aif%20encrypted_message.startswith%28b'gAAAAA'%29%3A%0A%20%20%20%20print%28%22%E6%95%B0%E6%8D%AE%E4%BC%BC%E4%B9%8E%E5%B7%B2%E6%88%90%E5%8A%9F%E5%8A%A0%E5%AF%86%EF%BC%81%22%29%0Aelse%3A%0A%20%20%20%20print%28%22%E6%95%B0%E6%8D%AE%E5%8A%A0%E5%AF%86%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98%E3%80%82%22%29%0A%0A%23%20%E8%A7%A3%E5%AF%86%E6%95%B0%E6%8D%AE%0Adecrypted_message%20%3D%20f.decrypt%28encrypted_message%29%0Aprint%28f%22%E8%A7%A3%E5%AF%86%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%3A%20%7Bdecrypted_message%7D%22%29%0A%0A%23%20%E9%AA%8C%E8%AF%81%E8%A7%A3%E5%AF%86%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E4%B8%8E%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E5%8C%B9%E9%85%8D%0Aif%20decrypted_message%20%3D%3D%20message%3A%0A%20%20%20%20print%28%22%E8%A7%A3%E5%AF%86%E6%88%90%E5%8A%9F%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E4%B8%80%E8%87%B4%E3%80%82%22%29%0Aelse%3A%0A%20%20%20%20print%28%22%E8%A7%A3%E5%AF%86%E5%A4%B1%E8%B4%A5%E6%88%96%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E3%80%82%22%29\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a> 在线运行这段代码，结果如下：</p>\n<pre><code class=\"language-text\">加密后的数据: b'gAAAAABpeYaJTPQfcp2pac2dEjYv4rd4TrzqTctsPsZsDDl-rtOLcbpNJXGNShgARjEcodK2h_O7nu3PaT3wXMwlxuUSWAlPvww-C4CbuoMfCYraX0jMHNpL4H1uNx1adG_BgRBYK5SX'\n数据似乎已成功加密！\n解密后的数据: b'I want to encrypt this secret message.'\n解密成功，数据完整一致。\n</code></pre>\n<p>使用 <a href=\"https://www.min2k.com/tools/mermaid/?code=flowchart%20TB%0A%20%20A%5B%E5%BC%80%E5%A7%8B%5D%20--%3E%20B%7B%E5%88%9D%E5%A7%8B%E5%8C%96Fernet%7D%3B%0A%20%20B%20--%3E%20C%5B%E8%AE%BE%E7%BD%AE%E8%A6%81%E5%8A%A0%E5%AF%86%E7%9A%84%E6%98%8E%E6%96%87%5D%3B%0A%20%20C%20--%3E%20D%5B%E6%89%A7%E8%A1%8C%E5%8A%A0%E5%AF%86%5D%3B%0A%20%20D%20--%3E%20E%7B%E5%8A%A0%E5%AF%86%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E4%BB%A5%20'gAAAAA'%20%E5%BC%80%E5%A4%B4%3F%7D%3B%0A%20%20E%20--%20%E6%98%AF%20--%3E%20F%5B%E6%89%93%E5%8D%B0%E5%8A%A0%E5%AF%86%E6%88%90%E5%8A%9F%5D%3B%0A%20%20E%20--%20%E5%90%A6%20--%3E%20G%5B%E6%89%93%E5%8D%B0%E5%8A%A0%E5%AF%86%E5%A4%B1%E8%B4%A5%5D%3B%0A%20%20F%20--%3E%20H%5B%E6%89%A7%E8%A1%8C%E8%A7%A3%E5%AF%86%5D%3B%0A%20%20G%20--%3E%20H%5B%E6%89%A7%E8%A1%8C%E8%A7%A3%E5%AF%86%5D%3B%0A%20%20H%20--%3E%20I%7B%E8%A7%A3%E5%AF%86%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E4%B8%8E%E6%98%8E%E6%96%87%E4%B8%80%E8%87%B4%3F%7D%3B%0A%20%20I%20--%20%E6%98%AF%20--%3E%20J%5B%E6%89%93%E5%8D%B0%E8%A7%A3%E5%AF%86%E6%88%90%E5%8A%9F%5D%3B%0A%20%20I%20--%20%E5%90%A6%20--%3E%20K%5B%E6%89%93%E5%8D%B0%E8%A7%A3%E5%AF%86%E5%A4%B1%E8%B4%A5%5D%3B%0A%20%20J%20--%3E%20L%5B%E7%BB%93%E6%9D%9F%5D%3B%0A%20%20K%20--%3E%20L%5B%E7%BB%93%E6%9D%9F%5D%3B\" rel=\"noopener nofollow\" target=\"_blank\">MermaidGo</a> 绘制示例代码的流程图，结果如下：</p>\n<p><img alt=\"MermerGo的cryptography流程图\" class=\"lazyload\" /></p>\n<h2 id=\"五学习资源\">五、学习资源</h2>\n<ol>\n<li>开源项目：<a href=\"https://github.com/pyca/cryptography\" rel=\"noopener nofollow\" target=\"_blank\">cryptography</a></li>\n<li>中文自述：<a href=\"https://www.python64.cn/readme/cryptography/\" rel=\"noopener nofollow\" target=\"_blank\">REMDME</a></li>\n<li>在线运行：<a href=\"https://www.min2k.com/tools/python-run/\" rel=\"noopener nofollow\" target=\"_blank\">PythonRun</a></li>\n</ol>\n<blockquote>\n<p>如果这篇文章对你有帮助，欢迎点赞、收藏、转发！<br />\n学习过程中有任何问题，欢迎在评论区留言交流～</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 11:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/min2k\">敏编程</a>&nbsp;\n阅读(<span id=\"post_view_count\">149</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "idea优化之标签页显示优化，让查找更高效",
      "link": "https://www.cnblogs.com/zhangchengzi/p/19541926",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/zhangchengzi/p/19541926\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 10:11\">\n    <span>idea优化之标签页显示优化，让查找更高效</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        IntelliJ IDEA默认将多个标签页堆叠在编辑器顶部，当标签页过多时查找文件效率低下。通过修改设置(Editor→General→Editor Tabs)，将Tab placement设为左侧显示，使标签页纵向排列更直观；设置Tab Order为字母排序提升查找效率；可选启用预览标签功能实现类似VS Code的代码预览效果。这些调整能显著提升在多个打开文件中导航的效率。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>使用idea开发时不可避免的要打开多个标签页，idea默认的是将这些打开的标签页显示在代码编辑器的顶部，如果标签页多的时候会使用滚动条隐藏一部分标签页，如果再多一些甚至会将一部分标签页从滚动条里转移到一个下拉选框中，像下面这张图一样</p>\n<p><img alt=\"屏幕截图 2026-01-28 095237\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n<p>这个时候，如果需要找一个已经打开的文件，是非常痛苦的。如果能一眼在顶部标签页中看到还好，如果看不到，如果还想在顶部标签页中找的话，就需要先左右滚动标签页进行查找，如果找不到再去下拉选框中查找，非常的繁琐并且低效。</p>\n<p>那么接下来我将通过修改idea自带的设置，使得从已打开的标签页中查找代码文件变得非常轻松。</p>\n<ol>\n<li>file → Settings，打开设置页面</li>\n<li>Editor → General → Editor Tabs ，打开标签页设置页面</li>\n<li>Tab placement 选择 left，让标签页显示在左侧，这样显示的标签页一行一个，非常直观，而且让标签页显示在左侧还有一个好处，如果在已经打开的标签页中找不到目前代码文件，视线直接再向左移，在项目文件列表中查找。</li>\n<li>Tab Order 选择 Sort tabs alphabetically，让标签页按字母排序，让查找更加方便。</li>\n<li>（可选）勾选 Enable preview tab，实现类似VS code中代码预览的效果，即点击项目文件会使用一个公共标签页打代码预览，这个时候标签页上的代码文件的名字是斜体的，只有双击时才会真正的新建一个标签页打开代码。</li>\n</ol>\n<p>参考效果：</p>\n<p><img alt=\"屏幕截图 2026-01-28 100501\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n\n\n</div>\n<div id=\"MySignature\">\n    更多干货，请查阅<a href=\"https://www.cnblogs.com/zhangchengzi/p/9661504.html\" style=\"color: #e33100; font-size: 19px;\">目录</a>。<br />\n才疏学浅，如有错误，欢迎大家留言评论。<br />\n如果大家觉得我的文章写的不错，<span style=\"color: #e33100; font-size: 19px;\">“关注我”</span>或者<span style=\"color: #2daebf; font-size: 19px;\">“推荐一下”</span>吧，我会继续努力写出更好的文章。<br />\n觉得哪里写的不好的，可以留言或者加我微信<span style=\"color: #ff0000; font-size: 19px;\">告诉我。</span><br />\n另外我建立一个技术讨论群，欢迎大家来学习探讨，<span style=\"color: #ff0000; font-size: 19px;\">微信:fcg600800</span>。<br />\n<a href=\"http://www.leitingpro.top/\" style=\"color: #e33100; font-size: 19px;\">我的个人主页</a>\n<hr />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 10:11</span>&nbsp;\n<a href=\"https://www.cnblogs.com/zhangchengzi\">张橙子</a>&nbsp;\n阅读(<span id=\"post_view_count\">221</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}