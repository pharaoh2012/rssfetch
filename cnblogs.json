{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "利用 Worker Threads 优化 Vite 构建性能的实战",
      "link": "https://www.cnblogs.com/newbe36524/p/19541521",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19541521\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 09:05\">\n    <span>利用 Worker Threads 优化 Vite 构建性能的实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"120秒到45秒利用-worker-threads-优化-vite-构建性能的实战\">120秒到45秒：利用 Worker Threads 优化 Vite 构建性能的实战</h1>\n<blockquote>\n<p>在处理大型前端项目时，生产环境的代码构建往往让人望眼欲穿。本文分享如何通过 Node.js Worker Threads 将 Vite 构建中的代码混淆环节耗时从 120 秒降低至 45 秒，并详细介绍 HagiCode 项目中的实施细节与踩坑经验。</p>\n</blockquote>\n\n<h2 id=\"背景\">背景</h2>\n<p>在我们的前端工程化实践中，随着项目规模的扩大，构建效率问题逐渐凸显。特别是在生产环境构建流程中，为了保护源码逻辑，我们通常会引入 JavaScript 混淆工具（如 <code>javascript-obfuscator</code>）。这一步虽然必要，但计算量巨大，极其消耗 CPU 资源。</p>\n<p>在<strong>HagiCode</strong>项目的早期开发阶段，我们遇到了一个非常棘手的性能瓶颈：生产构建时间随着代码量的增加迅速恶化。</p>\n<p><strong>具体痛点如下</strong>：</p>\n<ul>\n<li>单线程串行执行混淆任务，CPU 单核跑满，其他核心闲置</li>\n<li>构建时间从最初的 30 秒飙升至 110-120 秒</li>\n<li>每次修改代码后的构建验证流程极其漫长，严重拖慢了开发迭代效率</li>\n<li>CI/CD 流水线中，构建环节成为最耗时的部分</li>\n</ul>\n<p><strong>为什么 HagiCode 会有这个需求？</strong><br />\nHagiCode 是一款 AI 驱动的代码智能助手，其前端架构包含复杂的业务逻辑和 AI 交互模块。为了确保核心代码的安全性，我们在生产发布时强制开启了高强度混淆。面对长达两分钟的构建等待，我们决定对构建系统进行一次深度的性能优化。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<blockquote>\n<p>既然提到了这个项目，不妨多介绍两句。</p>\n</blockquote>\n<p>如果你在开发中遇到过这些烦恼：</p>\n<ul>\n<li>多项目、多技术栈，构建脚本维护成本高</li>\n<li>CI/CD 流水线配置繁琐，每次改都要查文档</li>\n<li>跨平台兼容性问题层出不穷</li>\n<li>想让 AI 帮忙写代码，但现有工具不够智能</li>\n</ul>\n<p>那么我们正在做的 <strong>HagiCode</strong> 可能你会感兴趣。</p>\n<p><strong>HagiCode 是什么？</strong></p>\n<ul>\n<li>一款 AI 驱动的代码智能助手</li>\n<li>支持多语言、跨平台的代码生成与优化</li>\n<li>内置游戏化机制，让编码不再枯燥</li>\n</ul>\n<p><strong>为什么在这里提它？</strong><br />\n本文分享的 <strong>JavaScript 并行混淆方案</strong>，正是我们在开发 HagiCode 过程中实践总结出来的。如果你觉得这套工程化方案有价值，说明我们的技术品味还不错——那么 HagiCode 本身也值得关注一下。</p>\n<p><strong>想了解更多？</strong></p>\n<ul>\n<li>GitHub: <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">github.com/HagiCode-org/site</a>（求 Star）</li>\n<li>官网: <a href=\"https://hagicode-org.github.io/site\" rel=\"noopener nofollow\" target=\"_blank\">hagicode-org.github.io/site</a></li>\n<li>视频演示: <a href=\"https://www.bilibili.com/video/BV1pirZBuEzq/\" rel=\"noopener nofollow\" target=\"_blank\">www.bilibili.com/video/BV1pirZBuEzq/</a>（30 分钟实战演示）</li>\n<li>安装指南: <a href=\"https://hagicode-org.github.io/site/docs/installation/docker-compose\" rel=\"noopener nofollow\" target=\"_blank\">hagicode-org.github.io/site/docs/installation/docker-compose</a></li>\n<li>公测已开始：现在安装即可参与公测</li>\n</ul>\n<hr />\n<h2 id=\"分析寻找性能瓶颈的突破口\">分析：寻找性能瓶颈的突破口</h2>\n<p>在着手解决性能问题之前，我们需要先理清思路，确定最优的技术方案。</p>\n<h3 id=\"核心决策为什么选择-worker-threads\">核心决策：为什么选择 Worker Threads？</h3>\n<p>Node.js 环境下实现并行计算主要有三种方案：</p>\n<ol>\n<li><strong>child_process</strong>：创建独立的子进程</li>\n<li><strong>Web Workers</strong>：主要用于浏览器端</li>\n<li><strong>worker_threads</strong>：Node.js 原生多线程支持</li>\n</ol>\n<p>经过对比分析，HagiCode 最终选择了 <strong>Worker Threads</strong>，原因如下：</p>\n<ul>\n<li><strong>零序列化开销</strong>：Worker Threads 位于同一进程，可以通过 <code>SharedArrayBuffer</code> 或转移控制权的方式共享内存，避免了进程间通信的大额序列化成本。</li>\n<li><strong>原生支持</strong>：Node.js 12+ 版本内置支持，无需引入额外的重依赖。</li>\n<li><strong>上下文统一</strong>：调试和日志记录比子进程更方便。</li>\n</ul>\n<h3 id=\"任务粒度如何拆分混淆任务\">任务粒度：如何拆分混淆任务？</h3>\n<p>混淆一个巨大的 JS Bundle 文件很难并行（因为代码有依赖关系），但 Vite 的构建产物是由多个 <strong>Chunk</strong> 组成的。这给了我们一个天然的并行边界：</p>\n<ul>\n<li><strong>独立性</strong>：Vite 打包后的不同 Chunk 之间依赖关系已解耦，可以安全地并行处理。</li>\n<li><strong>粒度适中</strong>：通常项目会有 10-30 个 Chunk，这个数量级非常适合并行调度。</li>\n<li><strong>易于集成</strong>：Vite 插件的 <code>generateBundle</code> 钩子允许我们在文件生成前拦截并处理这些 Chunk。</li>\n</ul>\n<h3 id=\"架构设计\">架构设计</h3>\n<p>我们设计了一个包含四个核心组件的并行处理系统：</p>\n<ol>\n<li><strong>Task Splitter</strong>：遍历 Vite 的 bundle 对象，过滤不需要混淆的文件（如 vendor），生成任务队列。</li>\n<li><strong>Worker Pool Manager</strong>：管理 Worker 的生命周期，负责任务的分发、回收和错误重试。</li>\n<li><strong>Progress Reporter</strong>：实时输出构建进度，消除用户的等待焦虑。</li>\n<li><strong>ObfuscationWorker</strong>：实际执行混淆逻辑的工作线程。</li>\n</ol>\n<h2 id=\"解决实战编码与实施\">解决：实战编码与实施</h2>\n<p>基于上述分析，我们开始动手实现这套并行混淆系统。</p>\n<h3 id=\"1-配置-vite-插件\">1. 配置 Vite 插件</h3>\n<p>首先，我们在 <code>vite.config.ts</code> 中集成并行混淆插件。配置非常直观，只需指定 Worker 数量和混淆规则。</p>\n<pre><code class=\"language-typescript\">import { defineConfig } from 'vite'\nimport { parallelJavascriptObfuscator } from './buildTools/plugin'\n\nexport default defineConfig(({ mode }) =&gt; {\n  const isProduction = mode === 'production'\n  \n  return {\n    build: {\n      rollupOptions: {\n        ...(isProduction\n          ? {\n              plugins: [\n                parallelJavascriptObfuscator({\n                  enabled: true,\n                  // 根据 CPU 核心数自动调整，建议留出一个核心给主线程\n                  workerCount: 4, \n                  retryAttempts: 3,\n                  fallbackToMainThread: true, // 出错时自动降级为单线程\n                  // 过滤掉 vendor chunk，通常不需要混淆第三方库\n                  isVendorChunk: (fileName: string) =&gt; fileName.includes('vendor-'),\n                  obfuscationConfig: {\n                    compact: true,\n                    controlFlowFlattening: true,\n                    deadCodeInjection: true,\n                    disableConsoleOutput: true,\n                    // ... 更多混淆选项\n                  },\n                }),\n              ],\n            }\n          : {}),\n      },\n    },\n  }\n})\n</code></pre>\n<h3 id=\"2-实现-worker-逻辑\">2. 实现 Worker 逻辑</h3>\n<p>Worker 是执行任务的单元。我们需要定义好输入和输出的数据结构。</p>\n<p><strong>注意</strong>：这里的代码虽然简单，但有几个坑点需要注意。比如 <code>parentPort</code> 的空值检查，以及错误处理。在 HagiCode 的实践中，我们发现有些特殊的 ES6 语法可能会导致混淆器崩溃，所以加上了 <code>try-catch</code> 保护。</p>\n<pre><code class=\"language-typescript\">import { parentPort } from 'worker_threads'\nimport javascriptObfuscator from 'javascript-obfuscator'\n\nexport interface ObfuscationTask {\n  chunkId: string\n  code: string\n  config: any\n}\n\nexport interface ObfuscationResult {\n  chunkId: string\n  obfuscatedCode: string\n  error?: string\n}\n\n// 监听主线程发来的任务\nif (parentPort) {\n  parentPort.on('message', async (task: ObfuscationTask) =&gt; {\n    try {\n      // 执行混淆\n      const obfuscated = javascriptObfuscator.obfuscate(task.code, task.config)\n      const result: ObfuscationResult = {\n        chunkId: task.chunkId,\n        obfuscatedCode: obfuscated.getObfuscatedCode(),\n      }\n      // 将结果发回主线程\n      parentPort?.postMessage(result)\n    } catch (error) {\n      // 处理异常，确保单个 Worker 崩溃不会阻塞整个构建\n      const result: ObfuscationResult = {\n        chunkId: task.chunkId,\n        obfuscatedCode: '',\n        error: error instanceof Error ? error.message : 'Unknown error',\n      }\n      parentPort?.postMessage(result)\n    }\n  })\n}\n</code></pre>\n<h3 id=\"3-worker-池管理器\">3. Worker 池管理器</h3>\n<p>这是整个方案的核心。我们需要维护一个固定大小的 Worker 池，采用 <strong>FIFO（先进先出）</strong> 策略调度任务。</p>\n<pre><code class=\"language-typescript\">import { Worker } from 'worker_threads'\nimport os from 'os'\n\nexport class WorkerPool {\n  private workers: Worker[] = []\n  private taskQueue: Array&lt;{\n    task: ObfuscationTask\n    resolve: (result: ObfuscationResult) =&gt; void\n    reject: (error: Error) =&gt; void\n  }&gt; = []\n  \n  constructor(options: WorkerPoolOptions = {}) {\n    // 默认为核心数 - 1，给主线程留一点喘息的空间\n    const workerCount = options.workerCount ?? Math.max(1, (os.cpus().length || 4) - 1)\n    \n    for (let i = 0; i &lt; workerCount; i++) {\n      this.createWorker()\n    }\n  }\n\n  private createWorker() {\n    const worker = new Worker('./worker.ts')\n    \n    worker.on('message', (result) =&gt; {\n      // 任务完成后，从队列中取出下一个任务\n      const nextTask = this.taskQueue.shift()\n      if (nextTask) {\n        this.dispatchTask(worker, nextTask)\n      } else {\n        // 如果没有待处理任务，标记 Worker 为空闲\n        this.activeWorkers.delete(worker)\n      }\n    })\n    \n    this.workers.push(worker)\n  }\n\n  // 提交任务到池中\n  public runTask(task: ObfuscationTask): Promise&lt;ObfuscationResult&gt; {\n    return new Promise((resolve, reject) =&gt; {\n      const job = { task, resolve, reject }\n      const idleWorker = this.workers.find(w =&gt; !this.activeWorkers.has(w))\n      \n      if (idleWorker) {\n        this.dispatchTask(idleWorker, job)\n      } else {\n        this.taskQueue.push(job)\n      }\n    })\n  }\n\n  private dispatchTask(worker: Worker, job: any) {\n    this.activeWorkers.set(worker, job.task)\n    worker.postMessage(job.task)\n  }\n}\n</code></pre>\n<h3 id=\"4-进度报告\">4. 进度报告</h3>\n<p>等待是痛苦的，尤其是不知道还要等多久。我们增加了一个简单的进度报告器，实时反馈当前状态。</p>\n<pre><code class=\"language-typescript\">export class ProgressReporter {\n  private completed = 0\n  private readonly total: number\n  private readonly startTime: number\n\n  constructor(total: number) {\n    this.total = total\n    this.startTime = Date.now()\n  }\n\n  increment(): void {\n    this.completed++\n    this.report()\n  }\n\n  private report(): void {\n    const now = Date.now()\n    const elapsed = now - this.startTime\n    const percentage = (this.completed / this.total) * 100\n    \n    // 简单的 ETA 估算\n    const avgTimePerChunk = elapsed / this.completed\n    const remaining = (this.total - this.completed) * avgTimePerChunk\n\n    console.log(\n      `[Parallel Obfuscation] ${this.completed}/${this.total} chunks completed (${percentage.toFixed(1)}%) | ETA: ${(remaining / 1000).toFixed(1)}s`\n    )\n  }\n}\n</code></pre>\n<h2 id=\"实践效果与踩坑\">实践：效果与踩坑</h2>\n<p>部署这套方案后，HagiCode 项目的构建性能有了立竿见影的提升。</p>\n<h3 id=\"性能基准数据\">性能基准数据</h3>\n<p>我们在以下环境进行了测试：</p>\n<ul>\n<li>CPU：Intel Core i7-12700K (12 cores / 20 threads)</li>\n<li>RAM：32GB DDR4</li>\n<li>Node.js：v18.17.0</li>\n<li>OS：Ubuntu 22.04</li>\n</ul>\n<p><strong>结果对比</strong>：</p>\n<ul>\n<li><strong>单线程（优化前）</strong>：118 秒</li>\n<li><strong>4 Workers</strong>：55 秒（提升 <strong>53%</strong>）</li>\n<li><strong>8 Workers</strong>：48 秒（提升 <strong>60%</strong>）</li>\n<li><strong>12 Workers</strong>：45 秒（提升 <strong>62%</strong>）</li>\n</ul>\n<p>可以看出，收益并不是线性的。当 Worker 数量超过 8 个后，提升幅度变小。这主要受限于任务分配的均匀度和内存带宽瓶颈。</p>\n<h3 id=\"常见问题与解决方案\">常见问题与解决方案</h3>\n<p>在 HagiCode 的实际使用中，我们也遇到了一些坑，这里分享给大家：</p>\n<p><strong>Q1: 构建时间没有明显减少，反而变慢了？</strong></p>\n<ul>\n<li><strong>原因</strong>：Worker 创建本身有开销，或者 Worker 数量设置过多导致上下文切换频繁。</li>\n<li><strong>解决</strong>：建议 Worker 数量设置为 <code>CPU 核心数 - 1</code>。同时检查是否有单个 Chunk 特别大（例如 &gt; 5MB），这种\"巨无霸\"文件会成为短板，可以考虑优化代码分割策略。</li>\n</ul>\n<p><strong>Q2: 偶尔出现 Worker 崩溃，构建失败？</strong></p>\n<ul>\n<li><strong>原因</strong>：某些特殊的代码语法可能导致混淆器内部报错。</li>\n<li><strong>解决</strong>：我们实现了 <strong>自动降级机制</strong>。当 Worker 连续失败次数达到阈值时，插件会自动回退到单线程模式，确保构建不中断。同时记录下错误的文件名，方便后续针对性修复。</li>\n</ul>\n<p><strong>Q3: 内存占用过高（OOM）？</strong></p>\n<ul>\n<li><strong>原因</strong>：每个 Worker 都需要独立内存空间来加载混淆器和解析 AST。</li>\n<li><strong>解决</strong>：\n<ul>\n<li>减少 Worker 数量。</li>\n<li>增加 Node.js 的内存限制：<code>NODE_OPTIONS=\"--max-old-space-size=4096\" npm run build</code>。</li>\n<li>确保不在 Worker 内部持有不必要的大对象引用。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"总结\">总结</h2>\n<p>通过引入 Node.js Worker Threads，我们成功将 HagiCode 项目的生产构建时间从 120 秒降低到了 45 秒左右，极大提升了开发体验和 CI/CD 效率。</p>\n<p>这套方案的核心在于：</p>\n<ol>\n<li><strong>合理拆分任务</strong>：利用 Vite 的 Chunk 作为并行单元。</li>\n<li><strong>资源控制</strong>：使用 Worker 池避免资源耗尽。</li>\n<li><strong>容错设计</strong>：自动降级机制确保构建稳定性。</li>\n</ol>\n<p>如果你也在为前端构建效率发愁，或者你的项目也在做重度代码处理，不妨试试这套方案。当然，更推荐你直接关注我们的 HagiCode 项目，这些工程化的细节都已经集成在里面了。</p>\n<p>如果本文对你有帮助，欢迎来 GitHub 给个 Star，或者参与公测体验一下～</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>Node.js Worker Threads 官方文档: <a href=\"https://nodejs.org/api/worker_threads.html\" rel=\"noopener nofollow\" target=\"_blank\">nodejs.org/api/worker_threads.html</a></li>\n<li>javascript-obfuscator 文档: <a href=\"https://github.com/javascript-obfuscator/javascript-obfuscator\" rel=\"noopener nofollow\" target=\"_blank\">github.com/javascript-obfuscator/javascript-obfuscator</a></li>\n<li>Vite 插件开发指南: <a href=\"https://vitejs.dev/guide/api-plugin.html\" rel=\"noopener nofollow\" target=\"_blank\">vitejs.dev/guide/api-plugin.html</a></li>\n<li><strong>HagiCode GitHub</strong>: <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">github.com/HagiCode-org/site</a></li>\n<li><strong>HagiCode 官网</strong>: <a href=\"https://hagicode-org.github.io/site\" rel=\"noopener nofollow\" target=\"_blank\">hagicode-org.github.io/site</a></li>\n<li><strong>安装指南</strong>: <a href=\"https://hagicode-org.github.io/site/docs/installation/docker-compose\" rel=\"noopener nofollow\" target=\"_blank\">hagicode-org.github.io/site/docs/installation/docker-compose</a></li>\n</ul>\n<hr />\n<p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p>\n<p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p>\n<ul>\n<li><strong>本文作者:</strong> <a href=\"https://www.newbe.pro\" rel=\"noopener nofollow\" target=\"_blank\">newbe36524</a></li>\n<li><strong>本文链接:</strong> <a href=\"https://hagicode-org.github.io/site/blog/2026/01/27/optimizing-vite-build-with-worker-threads\" rel=\"noopener nofollow\" target=\"_blank\">https://hagicode-org.github.io/site/blog/2026/01/27/optimizing-vite-build-with-worker-threads</a></li>\n<li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 09:05</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "FastAPI异步多线程：从踩坑到精通，解锁高性能API的正确姿势",
      "link": "https://www.cnblogs.com/ymtianyu/p/19541438",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19541438\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 08:39\">\n    <span>FastAPI异步多线程：从踩坑到精通，解锁高性能API的正确姿势</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文深入探讨了FastAPI异步（async/await）和多线程的正确使用场景。通过分析ASGI原理、区分I/O密集与CPU密集型任务，提供了具体的代码示例和配置建议，并列举了常见的坑点（如阻塞操作、连接池配置、GIL限制），帮助开发者充分发挥FastAPI的高性能潜力，避免误用导致的性能下降。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>你有没有遇到过这种情况：<strong style=\"color: rgba(186, 55, 42, 1);\">明明用了FastAPI的async，压测时性能却毫无提升，甚至更糟了？</strong> 🎯</p>\n<p>去年我做了一个实时数据推送的项目，上线前信心满满，结果第一波流量涌进来，接口响应时间直接从100ms飙到10s+，监控报警短信像除夕夜的鞭炮一样响个不停。排查后发现，罪魁祸首正是我“想当然”地乱用<span style=\"color: rgba(186, 55, 42, 1);\"><code>async</code></span>。</p>\n<p>今天，我就以踩过坑的老朋友身份，跟你好好聊聊FastAPI异步（<span style=\"color: rgba(186, 55, 42, 1);\"><code>async/await</code></span>）和多线程那点事。这不是教科书式的罗列，而是可以直接抄作业的实战经验。</p>\n<div class=\"summary\">\n<h2>📖 本文能帮你解决什么？</h2>\n<p>1. 搞懂FastAPI异步（<span style=\"color: rgba(186, 55, 42, 1);\"><code>async/await</code></span>）到底在什么场景下能真正提升性能。</p>\n<p>2. 掌握在FastAPI中正确使用多线程处理CPU密集型任务的方法。</p>\n<p>3. 避开常见的坑（比如阻塞操作、数据库连接池耗尽、GIL限制）。</p>\n<p>4. 获得可直接复用的代码片段和配置建议。</p>\n</div>\n<h2>🚀 主要内容脉络</h2>\n<p>一、问题与背景：为什么你的async可能“假生效”？</p>\n<p>二、核心原理：<span style=\"color: rgba(186, 55, 42, 1);\"><code>ASGI</code></span>、<span style=\"color: rgba(186, 55, 42, 1);\"><code>async/await</code></span>与多线程的关系</p>\n<p>三、实战演示：I/O密集型 vs CPU密集型任务的正确处理姿势</p>\n<p>四、注意事项与进阶思考：那些容易翻车的点</p>\n<h2>一、问题与背景：为什么你的async可能“假生效”？</h2>\n<p>很多人以为，只要给FastAPI的路由函数加上<code class=\"inline-code\">async def</code>，就自动获得了高并发能力。其实不然。FastAPI基于ASGI（异步服务器网关接口），它确实允许异步处理请求。但<strong style=\"color: rgba(186, 55, 42, 1);\">异步不等于多线程，更不等于性能无限提升。</strong></p>\n<p>它的核心是“非阻塞”：当一个请求在等待I/O（比如查数据库、调外部API）时，事件循环（Event Loop）会去处理其他请求，而不是干等着。这意味着，如果你的async函数里干的是<strong style=\"color: rgba(186, 55, 42, 1);\">CPU密集型</strong>的活儿（比如复杂的计算、图像处理），那它依然会阻塞整个事件循环，其他请求照样排队。</p>\n<p>官方文档虽然说了FastAPI支持异步，但没明确告诉你：<strong style=\"color: rgba(186, 55, 42, 1);\">异步的优势仅限于I/O密集型场景。</strong> 这是我用真金白银的线上故障换来的教训。</p>\n<h2>二、核心原理：ASGI、async/await与多线程的关系</h2>\n<p>好，咱们先来理清几个关键概念：</p>\n<p>🔸 <strong>ASGI（Asynchronous Server Gateway Interface）</strong>：这是FastAPI的底层协议。你可以把它想象成一个<strong style=\"color: rgba(186, 55, 42, 1);\">高效的餐厅调度系统</strong>。服务员（事件循环）负责接待顾客（请求），如果某位顾客点菜后需要等厨房做菜（I/O等待），服务员不会傻等，而是先去接待其他顾客。厨房做好菜会通知服务员，服务员再回来上菜。这样，一个服务员就能同时照顾多桌客人。</p>\n<p>🔸 <strong>async/await</strong>：这是Python的语法糖，用来定义协程（Coroutine）。<code class=\"inline-code\">async def</code>声明一个函数是“可暂停的”，<code class=\"inline-code\">await</code>表示“在这里可以暂停，去干别的”。</p>\n<p>🔸 <strong>多线程/多进程</strong>：当你的任务主要是<strong style=\"color: rgba(186, 55, 42, 1);\">CPU密集型</strong>（比如大量数学计算）时，异步帮不上忙。这时就需要请出多线程或多进程，把计算任务分摊到多个CPU核心上去。FastAPI本身不直接管理线程，但我们可以利用Python的<code class=\"inline-code\">concurrent.futures</code>或<code class=\"inline-code\">asyncio.to_thread</code>来实现。</p>\n<p>简单总结：<strong style=\"color: rgba(186, 55, 42, 1);\">I/O密集型用async，CPU密集型用多线程/多进程，混合型任务两者结合。</strong></p>\n<h2>三、实战演示：I/O密集型 vs CPU密集型任务的正确处理姿势</h2>\n<p>接下来重点来了，怎么在代码里落实？</p>\n<h3>场景1：纯I/O密集型（推荐使用async）</h3>\n<p>比如调用外部API、查询数据库。这是async的主场。</p>\n<div class=\"code-block\">\n<pre class=\"language-python highlighter-hljs\"><code>import asyncio\nfrom fastapi import FastAPI\nimport httpx  # 异步HTTP客户端\n\napp = FastAPI()\n\n@app.get(\"/fetch-data\")\nasync def fetch_data():\n    # 模拟并发调用三个外部API\n    async with httpx.AsyncClient() as client:\n        tasks = [\n            client.get(\"https://api.example.com/data1\"),\n            client.get(\"https://api.example.com/data2\"),\n            client.get(\"https://api.example.com/data3\")\n        ]\n        responses = await asyncio.gather(*tasks)\n    return {\"results\": [r.json() for r in responses]}</code></pre>\n</div>\n<p class=\"note\">💡 这里千万别用同步的<code class=\"inline-code\">requests</code>库，否则会阻塞事件循环。务必使用<code class=\"inline-code\">httpx</code>或<code class=\"inline-code\">aiohttp</code>这种异步客户端。</p>\n<h3>场景2：CPU密集型（必须用多线程/多进程）</h3>\n<p>比如图像处理、数据分析。这时候就得请出线程池。</p>\n<div class=\"code-block\">\n<pre class=\"language-python highlighter-hljs\"><code>from fastapi import FastAPI\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\napp = FastAPI()\nexecutor = ThreadPoolExecutor(max_workers=4)  # 根据CPU核心数调整\n\ndef cpu_intensive_task(n: int):\n    \"\"\"模拟CPU密集型任务，比如图像处理\"\"\"\n    time.sleep(n)  # 这里用sleep模拟计算耗时\n    return f\"Task {n} completed\"\n\n@app.get(\"/process-image\")\nasync def process_image():\n    # 将阻塞函数提交到线程池，避免阻塞事件循环\n    future = executor.submit(cpu_intensive_task, 2)\n    result = future.result()\n    return {\"result\": result}</code></pre>\n</div>\n<p class=\"note\">🚨 这里有个坑：线程池大小<code class=\"inline-code\">max_workers</code>不是越大越好。设置太大反而会增加上下文切换开销。一般建议设置为CPU核心数+1。</p>\n<h3>场景3：混合型（async + 多线程）</h3>\n<p>实际项目中，很多任务既涉及I/O又涉及计算。这时可以结合两者。</p>\n<div class=\"code-block\">\n<pre class=\"language-python highlighter-hljs\"><code>import asyncio\nfrom fastapi import FastAPI\nfrom concurrent.futures import ThreadPoolExecutor\nimport httpx\n\napp = FastAPI()\nexecutor = ThreadPoolExecutor(max_workers=4)\n\nasync def fetch_url(client: httpx.AsyncClient, url: str):\n    \"\"\"异步获取数据\"\"\"\n    response = await client.get(url)\n    return response.json()\n\ndef heavy_computation(data: dict):\n    \"\"\"模拟CPU密集型计算\"\"\"\n    time.sleep(1)  # 模拟计算\n    return {\"processed\": data}\n\n@app.get(\"/complex-task\")\nasync def complex_task():\n    # 步骤1：并发I/O（异步）\n    async with httpx.AsyncClient() as client:\n        data = await fetch_url(client, \"https://api.example.com/data\")\n    \n    # 步骤2：CPU计算（扔到线程池）\n    loop = asyncio.get_event_loop()\n    result = await loop.run_in_executor(executor, heavy_computation, data)\n    \n    return result</code></pre>\n</div>\n<p>如果你用的是Python 3.9+，还可以用<code class=\"inline-code\">asyncio.to_thread</code>让代码更简洁。</p>\n<h2>四、注意事项与进阶思考：那些容易翻车的点</h2>\n<p>再说几个容易出问题的地方，都是血泪史：</p>\n<p>🔸 <strong>阻塞操作绝对不能放在async函数里</strong>：比如<code class=\"inline-code\">time.sleep()</code>、同步的数据库驱动（如<span style=\"color: rgba(186, 55, 42, 1);\"><code>psycopg2</code></span>）、同步的文件读写等。要用<code class=\"inline-code\">await asyncio.sleep()</code>、异步驱动（如<span style=\"color: rgba(186, 55, 42, 1);\"><code>asyncpg</code></span>）和<code class=\"inline-code\">aiofiles</code>替代。</p>\n<p>🔸 <strong>数据库连接池配置</strong>：异步环境下，数据库连接池的大小需要重新评估。我遇到过因为连接池太小，高并发下所有请求都在等连接，导致服务雪崩的情况。建议根据实际压力测试调整。</p>\n<p>🔸 <strong>GIL（全局解释器锁）限制</strong>：Python的GIL会让多线程在纯CPU任务上效率打折。如果计算极其密集，考虑用<code class=\"inline-code\">multiprocessing</code>启动多进程，但要注意进程间通信的成本。</p>\n<p>🔸 <strong>Uvicorn配置</strong>：生产环境运行FastAPI，通常用Uvicorn。建议设置<code class=\"inline-code\">--workers</code>（进程数）为CPU核心数，<code class=\"inline-code\">--loop uvloop</code>（使用更高效的事件循环）。例如：</p>\n<div class=\"code-block\">\n<pre class=\"language-powershell highlighter-hljs\"><code>uvicorn main:app --workers 4 --loop uvloop --host 0.0.0.0 --port 8000</code></pre>\n</div>\n<p>🔸 <strong>监控与日志</strong>：异步环境下，错误栈可能不那么直观。一定要打好日志，尤其是耗时操作。可以用<code class=\"inline-code\">asyncio.create_task</code>时附加错误回调，避免任务静默失败。</p>\n<div class=\"highlight\">\n<p><strong>最后啰嗦一句：</strong>技术选型好比选工具，不是越新越酷就好。FastAPI的异步特性是一把利器，但用对了场景才是关键。I/O密集型任务，async能让你如虎添翼；CPU密集型任务，老老实实用多线程/多进程。混合任务则要灵活组合。</p>\n</div>\n<hr />\n<p>好了，今天就聊到这里。希望这篇“踩坑指南”能帮你少走弯路。如果你在实战中遇到其他诡异问题，欢迎留言交流。老规矩，<strong style=\"color: rgba(186, 55, 42, 1);\">点赞、收藏、关注</strong>，下次遇到性能问题，随时回来翻这篇，保证不迷路！</p>\n<p>—— 你的老朋友，一名程序媛 🚀</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 08:39</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">36</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "《HelloGitHub》第 118 期",
      "link": "https://www.cnblogs.com/xueweihan/p/19535889",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xueweihan/p/19535889\" id=\"cb_post_title_url\" title=\"发布于 2026-01-28 08:15\">\n    <span>《HelloGitHub》第 118 期</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>兴趣是最好的老师，<strong>HelloGitHub</strong> 让你对开源感兴趣！</p>\n</blockquote>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"简介\">简介</h2>\n<p><strong>HelloGitHub</strong> 分享 GitHub 上有趣、入门级的开源项目。</p>\n<blockquote>\n<p><a href=\"https://github.com/521xueweihan/HelloGitHub\" rel=\"noopener nofollow\" target=\"_blank\">github.com/521xueweihan/HelloGitHub</a></p>\n</blockquote>\n<p>这里有实战项目、入门教程、黑科技、开源书籍、大厂开源项目等，涵盖多种编程语言 Python、Java、Go、C/C++、Swift...让你在短时间内感受到开源的魅力，爱上开源！</p>\n<hr />\n<blockquote>\n<p>以下为本期内容｜每月 <strong>28</strong> 号更新</p>\n</blockquote>\n<h3 id=\"c-项目\">C 项目</h3>\n<p>1、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/leo-arch/clifm\" rel=\"noopener nofollow\" target=\"_blank\">clifm</a>：纯命令行的文件管理器。这是一款 C 语言写的命令行文件管理工具，使用起来比 Shell 更高效、比 TUI 工具更轻便。它没有复杂的菜单和图形界面，用户只需输入简单的命令即可快速完成文件操作，支持条目数字索引、自动补全、语法高亮和文件预览等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"c-项目-1\">C# 项目</h3>\n<p>2、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/umlx5h/LLPlayer\" rel=\"noopener nofollow\" target=\"_blank\">LLPlayer</a>：自动生成双语字幕的视频播放器。这是一款基于 C# 开发的 Windows 视频播放器，可实时生成双语字幕。它通过 Whisper 语音转文字模型，能够为无字幕视频实时生成字幕，并结合上下文通过大语言模型提供更准确的翻译，支持接入 Google、DeepL、OpenAI 及本地 LLM 服务。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>3、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/Archeb/opentrace\" rel=\"noopener nofollow\" target=\"_blank\">opentrace</a>：跨平台的可视化路由追踪工具。这是一款基于 NextTrace 开发的可视化路由追踪工具，能够直观展示数据包从本地到目标服务器的传输路径，显示每一跳的 IP 地址、延迟和地理位置信息，支持 MTR 实时诊断、自定义 DNS 解析等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>4、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/tixl3d/tixl\" rel=\"noopener nofollow\" target=\"_blank\">tixl</a>：开源的实时动态图形创作工具。这是一款免费开源的实时动态图形创作工具，可用于制作随音乐变化的视觉背景和特效。它内置基于节点的程序化内容生成（PCG）和编辑关键帧动画等功能，支持 MIDI、OSC、Spout 等多源输入，适用于 VJ 现场表演、交互式艺术创作和动态图形设计等场景。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"c-项目-2\">C++ 项目</h3>\n<p>5、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/allenk/GeminiWatermarkTool\" rel=\"noopener nofollow\" target=\"_blank\">GeminiWatermarkTool</a>：Gemini 生成图片水印清除工具。这是一款用于移除 Gemini Nano Banana 和 Pro 生成图片右下角可见水印的工具，不支持隐形水印（SynthID）。它跨平台、无需联网、开箱即用，支持自动识别图片尺寸和批量处理等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>6、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/dmcke5/Hapticpad\" rel=\"noopener nofollow\" target=\"_blank\">Hapticpad</a>：自制带力反馈旋钮的宏键盘。这是一款配备力反馈旋钮和 OLED 显示屏的 6 键宏键盘，支持 256 个配置文件切换、三种旋钮模式和自定义 RGB 灯环。可通过修改 SD 卡上的 XML 文件进行配置，无需安装特殊驱动或客户端即插即用。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>7、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/shanselman/toasty\" rel=\"noopener nofollow\" target=\"_blank\">toasty</a>：轻量级 Windows 通知命令行工具。这是一款零依赖、轻量级的 Windows 平台 Toast 通知命令行工具，体积仅 230KB。它能够自动检测并集成 Claude Code、Gemini CLI 和 GitHub Copilot 等主流 AI 命令行编程助手，在任务完成时发送带对应图标的桌面通知，让你无需守在终端前等待 AI 结果。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"go-项目\">Go 项目</h3>\n<p>8、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/maxpert/marmot\" rel=\"noopener nofollow\" target=\"_blank\">marmot</a>：让 SQLite 秒变分布式数据库。这是一款基于 Go 语言开发的轻量级分布式 SQLite 系统，通过无主架构将 SQLite 转化为高可用的分布式数据库。它采用 Gossip 协议进行集群管理和数据同步，支持最终一致性和多点写入，并通过 CDC 实现行级复制，兼容 MySQL 协议，现有的 MySQL 客户端和应用可无缝迁移至 SQLite 集群。</p>\n<p>9、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/QuantumNous/new-api\" rel=\"noopener nofollow\" target=\"_blank\">new-api</a>：新一代 AI 模型聚合管理与分发系统。该项目是基于 One API 二次开发的 AI 模型接口管理与分发平台。它将 OpenAl、Claude、Gemini、DeepSeek 等多种主流大模型与 AI 服务封装为统一接口，并兼容 OpenAI、Claude、Gemini 等常见接口格式。同时提供数据看板、智能路由分发、令牌分组、模型访问限制和在线充值等功能，适合用于企业或个人搭建 LLM 统一调用平台。来自 <a href=\"https://hellogithub.com/user/tbFPfKIDHpc4TzR\" rel=\"noopener nofollow\" target=\"_blank\">@Calcium-Ion</a> 的分享</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>10、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/likaia/nginxpulse\" rel=\"noopener nofollow\" target=\"_blank\">nginxpulse</a>：轻量级 Nginx 日志可视化平台。该项目是用 Go、Vue3 和 PostgreSQL 构建的轻量级 Nginx 日志分析和可视化平台，支持 PV/UV 统计、IP 归属地分析、客户端设备解析等功能，适合个人站长和小型团队使用。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>11、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/karol-broda/snitch\" rel=\"noopener nofollow\" target=\"_blank\">snitch</a>：更友好的网络连接查看器。该项目是用 Go 语言开发的网络连接监控命令行工具，可作为 ss 和 netstat 的替代品。它开箱即用、界面简洁直观，支持实时刷新、过滤、排序、导出和搜索 TCP/UDP 连接等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>12、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/tus/tusd\" rel=\"noopener nofollow\" target=\"_blank\">tusd</a>：大文件断点续传的服务端实现。该项目是 tus 协议（基于 HTTP 的文件断点续传协议）官方开源的 Go 语言实现，专为解决大文件上传易中断、需从头重传的问题而设计，支持本地磁盘、AWS S3、Google Cloud Storage 等多种存储，可作为独立服务或 Go 库使用。来自 <a href=\"https://hellogithub.com/user/TJ65FfbQU09PLHM\" rel=\"noopener nofollow\" target=\"_blank\">@刘睿华</a> 的分享</p>\n<h3 id=\"java-项目\">Java 项目</h3>\n<p>13、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/emichael/dslabs\" rel=\"noopener nofollow\" target=\"_blank\">dslabs</a>：分布式系统课程配套实验框架。该项目是华盛顿大学专为分布式系统教学和学习而设计的 Java 框架，提供网络模拟、自动化测试和可视化调试等功能，帮助初学者从零实现一个具备容错、分片和事务性的 KV 存储系统，在实践中掌握分布式协议的实现原理。</p>\n<p>14、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/tess1o/geopulse\" rel=\"noopener nofollow\" target=\"_blank\">geopulse</a>：自托管的个人足迹分析平台。这是一款采用 Java（Quarkus）和 PostGIS 构建的位置追踪和分析平台，可作为 Google Timeline 的开源替代品。它运行时占用内存低（40-100MB），提供自动行程检测、实时位置分享、多源数据导入、Immich 集成和 AI 问答助手等功能，支持 Docker 和 K8s 部署。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"javascript-项目\">JavaScript 项目</h3>\n<p>15、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/ChromeDevTools/chrome-devtools-mcp\" rel=\"noopener nofollow\" target=\"_blank\">chrome-devtools-mcp</a>：AI 与 Chrome 浏览器之间的桥梁。该项目是 Chrome DevTools 团队开源的官方 MCP 服务实现，将 Chrome DevTools 的能力以 MCP 工具的形式提供给 AI 编程助手，支持自动化操作、调试和性能分析。</p>\n<pre><code>{\n  \"mcpServers\": {\n    \"chrome-devtools\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"chrome-devtools-mcp@latest\"]\n    }\n  }\n}\n</code></pre>\n<p>16、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/MotiaDev/motia\" rel=\"noopener nofollow\" target=\"_blank\">motia</a>：终结后端碎片化的框架。这是一款一站式后端框架，集成了 API、事件驱动、定时任务、实时数据流和 AI Agent 等能力，支持 TypeScript、Python 等多语言混合开发。它内置状态管理、结构化日志、端到端链路追踪与可视化调试器，支持流程图、日志流和实时测试等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>17、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/PDFCraftTool/pdfcraft\" rel=\"noopener nofollow\" target=\"_blank\">pdfcraft</a>：无需上传文件的 PDF 全能工具箱。这是一款基于 Next.js 和 WebAssembly 构建的开源 PDF 工具箱，所有文件操作均在本地浏览器内完成，无需上传到外部服务器。它提供节点式编排 PDF 文件处理工作流，支持合并、拆分、OCR、格式转换等 90 多种功能。来自 <a href=\"https://hellogithub.com/user/8yYRcxLuSdPJFDv\" rel=\"noopener nofollow\" target=\"_blank\">@pccprint</a> 的分享</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>18、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/puckeditor/puck\" rel=\"noopener nofollow\" target=\"_blank\">puck</a>：React 可视化编辑器组件。这是一款基于 TypeScript 和 React 构建的可视化编辑器，可轻松将拖拽式页面构建功能集成到 Next.js、Remix 等 React 应用中，并可直接复用现有 React 组件，将其转化为可拖拽的编辑单元。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>19、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/Rabithua/Rote\" rel=\"noopener nofollow\" target=\"_blank\">Rote</a>：看起来不太一样的碎碎念本子。这是一款追求极简和优雅体验的个人笔记平台，采用 React 和 Node.js 构建支持 Docker 一键部署，提供开放的 API 接口，方便用户通过多种方式录入或获取数据。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"kotlin-项目\">Kotlin 项目</h3>\n<p>20、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/Turbo1123/roubao\" rel=\"noopener nofollow\" target=\"_blank\">roubao</a>：开源的 AI 手机自动化助手。这是一款开源的 Android AI 手机自动化助手，无需电脑即可让用户通过自然语言指令操控手机自动完成任务。它基于视觉语言模型识别屏幕截图，结合委托执行或 GUI 自动化，能够完成复杂的 App 交互任务。来自 <a href=\"https://hellogithub.com/user/TXJgfoRNWa8vmF4\" rel=\"noopener nofollow\" target=\"_blank\">@只是肚子太寂寞</a> 的分享</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>21、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/leekleak/traffic-light\" rel=\"noopener nofollow\" target=\"_blank\">traffic-light</a>：极简的 Android 流量监控应用。这是一款免费开源、体积小且无广告的 Android 网络流量监控工具，支持状态栏显示实时网速、历史数据和应用级流量统计等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"python-项目\">Python 项目</h3>\n<p>22、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/maurosoria/dirsearch\" rel=\"noopener nofollow\" target=\"_blank\">dirsearch</a>：命令行 Web 路径扫描工具。该项目是用 Python 开发的 Web 路径扫描工具，支持多线程和异步模式，并提供多种报告输出格式。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>23、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/keephq/keep\" rel=\"noopener nofollow\" target=\"_blank\">keep</a>：更智能的告警管理平台。这是一个智能告警管理和 AIOps 平台，运用 AI 技术实现告警关联和分析。它提供了统一的操作界面，便于集中管理各种告警和事件，支持告警去重、过滤、相关性分析和自动化处理等功能，可与多种监控工具、数据库、通信平台和事件管理工具集成。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>24、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/originalankur/maptoposter\" rel=\"noopener nofollow\" target=\"_blank\">maptoposter</a>：极简的城市地图海报生成器。该项目是用 Python 开发的城市地图海报生成器，可将城市地图数据转化为美观、极简风格的艺术海报。它利用 OpenStreetMap 的数据，自动绘制指定城市的道路网络、水域和公园，提供赛博朋克、水墨风格等 17 种主题风格可供选择。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>25、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/elapouya/python-docx-template\" rel=\"noopener nofollow\" target=\"_blank\">python-docx-template</a>：Python 结合 Jinja2 生成 Word 文档。该项目是结合 python-docx 和 Jinja2 库的 Word 文档渲染库。它能够将 .docx 文档作为模板，在其中嵌入 Jinja2 语法标签，自动生成格式复杂的 Word 文档，支持图片、富文本、页眉页脚和表格等。</p>\n<pre><code class=\"language-python\">from docxtpl import DocxTemplate\n\ndoc = DocxTemplate(\"my_word_template.docx\")\ncontext = { 'name' : \"HelloGitHub\" }\ndoc.render(context)\ndoc.save(\"generated_doc.docx\")\n</code></pre>\n<p>26、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/Maxteabag/sqlit\" rel=\"noopener nofollow\" target=\"_blank\">sqlit</a>：终端里的 SQL 数据库管理工具。这是一款用 Python 开发的终端 TUI 数据库客户端，致力于成为数据库领域的 lazygit。它开箱即用、操作简单，支持查询历史、自动补全、语法高亮和多种主流数据库，适合开发者在懒得启动 GUI 客户端时快速查询数据库。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"rust-项目\">Rust 项目</h3>\n<p>27、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/lusingander/serie\" rel=\"noopener nofollow\" target=\"_blank\">serie</a>：可视化展示 Git 提交历史的工具。该项目能够将 Git 提交历史以可视化图表方式展示，可作为 git log --graph 命令的替代品，支持灵活排序、自定义快捷键和外部命令扩展。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>28、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/zensical/zensical\" rel=\"noopener nofollow\" target=\"_blank\">zensical</a>：开箱即用的静态网站生成器。该项目是由 Material for MkDocs 团队用 Rust 和 Pyhton 重写的静态网站生成器，可基于 Markdown 文件构建出美观、专业且具备搜索功能的静态文档网站。它开箱即用、可自定义，兼容现有 Material for MkDocs 项目配置方便迁移。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"swift-项目\">Swift 项目</h3>\n<p>29、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/ronitsingh10/FineTune\" rel=\"noopener nofollow\" target=\"_blank\">FineTune</a>：让 macOS 拥有应用级音量控制。这是一款 Swift 开发的 macOS 菜单栏音频控制工具，支持为每个应用独立调节音量、设置不同输出设备等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>30、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/debugtheworldbot/keyStats\" rel=\"noopener nofollow\" target=\"_blank\">keyStats</a>：开源的键鼠统计工具。这是一款轻量级的 macOS/Windows 应用，在不记录具体输入内容的前提下，量化用户的输入行为，支持统计键盘敲击次数、鼠标点击次数、鼠标移动和滚动距离。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>31、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/nguyenphutrong/quotio\" rel=\"noopener nofollow\" target=\"_blank\">quotio</a>：macOS 切换 AI 账号的工具。这是一款用 Swift 开发的 macOS 菜单栏工具，支持统一管理 Claude、Gemini、OpenAI、Qwen 等 AI 服务的账号和 API Key，提供实时 Token 消耗统计、自动故障转移和 CLI 编程助手自动化配置等功能。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"人工智能\">人工智能</h3>\n<p>32、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/AI-Cultivation/cultivation-world-simulator\" rel=\"noopener nofollow\" target=\"_blank\">cultivation-world-simulator</a>：AI 驱动的修仙世界模拟器。这是一款基于 LLM 的修仙模拟器游戏，不同于传统 RPG，游戏内的 NPC 均是 AI 智能体，有独立的性格、记忆和行为逻辑，而玩家在游戏中扮演“天道”，以上帝视角观察并干预 AI 修仙者和仙界规则，见证门派兴衰与天骄崛起。来自 <a href=\"https://hellogithub.com/user/DogxfCROM1PBL89\" rel=\"noopener nofollow\" target=\"_blank\">@4thfever</a> 的分享</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>33、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/slopus/happy\" rel=\"noopener nofollow\" target=\"_blank\">happy</a>：用手机操控 Claude Code 和 Codex。这是一款可以远程操作 Claude Code 或 Codex 的工具，让你随时随地通过手机查看和远程控制 AI 编程助手，提供了 iOS、Android 和 Web 客户端。来自 <a href=\"https://hellogithub.com/user/pwgB6EFlZnvxGku\" rel=\"noopener nofollow\" target=\"_blank\">@Jeff Xun</a> 的分享</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>34、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/apple/ml-sharp\" rel=\"noopener nofollow\" target=\"_blank\">ml-sharp</a>：不到一秒生成 3D 场景。该项目是 Apple 开源的单目视角合成技术的配套代码，能够在短时间内根据单张图片生成高质量的 3D 场景。它通过神经网络从单张照片中回归出 3D 高斯参数，输出可供 3DGS 渲染器使用的 ply 文件。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>35、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/inisis/OnnxSlim\" rel=\"noopener nofollow\" target=\"_blank\">OnnxSlim</a>：轻量高效的 ONNX 模型优化工具。这是一个纯 Python 实现的 ONNX 模型精简与结构优化工具，无需额外的编译依赖。它通过分析与重写计算图，自动移除冗余节点、无效分支和多余参数，在保证模型精度不变的前提下，减少模型体积并提升推理速度，适用于模型发布、推理部署和工程化场景。来自 <a href=\"https://hellogithub.com/user/DC9XV2w4dSHy6Qm\" rel=\"noopener nofollow\" target=\"_blank\">@Desmond</a> 的分享</p>\n<pre><code class=\"language-python\">import onnx\nimport onnxslim\n\nmodel = onnx.load(\"model.onnx\")\nslimmed_model = onnxslim.slim(model)\n\nif slimmed_model:\n    onnx.save(slimmed_model, \"slimmed_model.onnx\")\n</code></pre>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>36、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code\" rel=\"noopener nofollow\" target=\"_blank\">Papers-in-100-Lines-of-Code</a>：百行代码复现经典深度学习论文。该项目通过约 100 行 Python 代码复现了 60+ 篇深度学习领域的经典论文，提供极简、可运行的代码实现，帮助研究员、学生和开发者快速理解经典论文的核心思想和实现细节。</p>\n<h3 id=\"其它\">其它</h3>\n<p>37、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/cavi-au/Consent-O-Matic\" rel=\"noopener nofollow\" target=\"_blank\">Consent-O-Matic</a>：告别烦人的 Cookie 授权弹窗。这是一款自动跳过 Cookie 授权弹窗的浏览器插件，用户只需在插件中设置一次隐私偏好，即可自动识别并跳过各种网站的 Cookie 弹框，免去手动处理 Cookie 授权的烦恼。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>38、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/SteamDeckHomebrew/decky-loader\" rel=\"noopener nofollow\" target=\"_blank\">decky-loader</a>：解锁 Steam Deck 潜能的插件加载器。该项目是专为 Steam Deck 设备打造的插件加载工具，可在 SteamOS 原生界面中无缝加载第三方功能模块，支持界面美化、性能优化和实用工具等插件。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>39、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/simonoppowa/OpenNutriTracker\" rel=\"noopener nofollow\" target=\"_blank\">OpenNutriTracker</a>：免费开源的饮食日记应用。这是一款免费开源的移动端营养和热量追踪应用，支持拍照记录每日饮食、扫描食品条形码快速录入营养信息并制定饮食计划。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>40、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/obra/superpowers\" rel=\"noopener nofollow\" target=\"_blank\">superpowers</a>：让 AI 编程工具按流程工作。该项目是专为 AI 编程智能体打造的完整软件开发工作流，通过组合技能（skills）和指令，让智能体不只是生成代码，而是按照流程进行设计、规划和实现。</p>\n<p>41、<a href=\"https://hellogithub.com/periodical/statistics/click?target=https://github.com/xai-org/x-algorithm\" rel=\"noopener nofollow\" target=\"_blank\">x-algorithm</a>：X 平台的信息流推荐算法。该项目是 xAI 官方开源的 X 平台信息流（For You）核心推荐系统和关键组件的技术细节，展示了如何构建生产级、基于大语言模型排序的推荐引擎。</p>\n<h2 id=\"最后\">最后</h2>\n<p>感谢参与分享开源项目的小伙伴们，欢迎更多的开源爱好者来 HelloGitHub 自荐/推荐开源项目。如果你发现了 GitHub 上有趣的项目，就<a href=\"https://hellogithub.com/periodical\" rel=\"noopener nofollow\" target=\"_blank\">点击这里</a>分享给大家伙吧！</p>\n<p>本期有你感兴趣的开源项目吗？如果有的话就留言告诉我吧～如果还没看过瘾，可以<a href=\"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA5MzYyNzQ0MQ==&amp;action=getalbum&amp;album_id=1331197538447310849&amp;scene=173&amp;from_msgid=2247511076&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect\" rel=\"noopener nofollow\" target=\"_blank\">点击阅读</a>往期内容。</p>\n<p>感谢您的阅读，如果觉得本期内容还不错的话 <strong>求赞、求分享</strong> ❤️</p>\n\n</div>\n<div id=\"MySignature\">\n    <div>    \n    <p id=\"PSignature\">\n    <br />\n    作者：<a href=\"https://github.com/521xueweihan\" target=\"_blank\">削微寒</a>\n\n    <br />\n    <strong>扫描左侧的二维码可以联系到我</strong>\n    <br />\n\n    <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh\" rel=\"license\"><img alt=\"知识共享许可协议\" src=\"https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png\" style=\"border-width: 0;\" /></a><br />本作品采用<a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh\" rel=\"license\">署名-非商业性使用-禁止演绎 4.0 国际 </a>进行许可。\n    </p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-28 08:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xueweihan\">削微寒</a>&nbsp;\n阅读(<span id=\"post_view_count\">174</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程五：自然语言处理  第二周：词嵌入 课后习题与代码实践",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19540925",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19540925\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 23:25\">\n    <span>吴恩达深度学习课程五：自然语言处理  第二周：词嵌入 课后习题与代码实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第五课第二周的课后习题和代码实践部分。</p>\n<hr />\n<h1 id=\"1-理论习题\">1. 理论习题</h1>\n<p><a href=\"https://blog.csdn.net/u013733326/article/details/83089164\" rel=\"noopener nofollow\" target=\"_blank\">【中英】【吴恩达课后测验】Course 5 -序列模型 - 第二周测验 </a><br />\n本周习题同样较为简单，就不再展开了。</p>\n<h1 id=\"2-代码实践\">2. 代码实践</h1>\n<p><a href=\"https://blog.csdn.net/u013733326/article/details/83341643\" rel=\"noopener nofollow\" target=\"_blank\">词向量与Emoji生成器-CSDN博客</a><br />\n在本周的编程作业里，链接里的博主除了编码演示关于词向量的一些基本应用外，主要是实现了一个表情生成器。<br />\n其原理是通过文本和相应的表情标签进行监督学习，构建分类模型，在完成训练后，通过对模型输出的下游加工，可以实现“输入文本，输出配有表情的文本”的效果。感兴趣可以进入了解。</p>\n<p>同样，我们还是使用成熟框架来演示本周的内容，得益于 PyTorch 对基础模块的封装非常完善，我们可以较简洁地完成本周内容的演示，主要内容列举如下：</p>\n<ol>\n<li><strong>如何在代码中使用词嵌入？</strong></li>\n<li><strong>使用词向量取代独热编码对命名实体识别模型性能的影响。</strong></li>\n<li><strong>使用词向量进行情绪分类。</strong></li>\n</ol>\n<h2 id=\"21-在pytorch-中使用词嵌入\">2.1 在PyTorch 中使用词嵌入</h2>\n<p>在 PyTorch 调用词嵌入的方法被封装在模型模块中，就像我们调用方法创建全连接层和卷积层一样，现在，我们要做的就是<strong>创建嵌入层</strong>。</p>\n<p>先来单独看看创建嵌入层的方法本身：</p>\n<pre><code class=\"language-python\">self.embedding = nn.Embedding(  \n    num_embeddings=vocab_size,  # 词典大小\n    embedding_dim=embed_dim,    # 词向量维度，既一个词用多少维的向量表示。\n    # 上面这两个参数就划定好了词嵌入矩阵的大小。\n    padding_idx=word_vocab[\"&lt;PAD&gt;\"]  # 获取填充符索引，固定其向量为 0 ，并屏蔽梯度计算。 \n)\n</code></pre>\n<p>这里有一点需要强调，如果你对我们<a href=\"https://www.cnblogs.com/Goblinscholar/p/19484728\" target=\"_blank\">上周的实践内容</a>还有印象，会发现我们其实已经在前面的代码了显式定义了 <code>&lt;PAD&gt;</code> 的索引：</p>\n<pre><code class=\"language-python\">word_vocab[\"&lt;PAD&gt;\"] = 0\n</code></pre>\n<p>也就是说，在方法的参数里，我们可以直接写成：</p>\n<pre><code class=\"language-python\">padding_idx= 0\n</code></pre>\n<p><strong>但是，我们基本不会这么做。</strong><br />\n这其实是代码规范里一个老生常谈的问题：<strong>避免硬编码</strong>。<br />\n在这里，一旦词表构建策略发生调整（例如交换 <code>&lt;PAD&gt;</code> 与 <code>&lt;UNK&gt;</code> 的索引），参数就会被错误使用，<strong>却不会触发任何报错</strong>，最终导致模型在训练过程中学到错误的表示。<br />\n因此，我们在实践中更倾向使用统一的变量，来显式表达语义依赖，避免在调整时引入隐蔽错误。</p>\n<p>回到正题，了解了嵌入层方法本身后，现在就来看看如何将其应用在模型中，先看看我们<strong>上周使用独热编码的模型代码：</strong></p>\n<pre><code class=\"language-python\">class RNNTagger(nn.Module):  \n    def __init__(self, vocab_size, hidden_dim, num_classes,  \n                 rnn_type='RNN', bidirectional=False, num_layers=1):  \n        super().__init__()  \n        self.vocab_size = vocab_size  \n        self.bidirectional = bidirectional  \n        self.rnn_type = rnn_type.upper()  \n  \n        input_size = vocab_size  # 独热编码输入维度 = 词表大小  \n  \n        if self.rnn_type == 'RNN':  \n            self.rnn = nn.RNN(input_size, hidden_dim, batch_first=True,  \n                              bidirectional=bidirectional, num_layers=num_layers)  \n        ......其他模型选择\n        \n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)  \n  \n    def forward(self, x):   \n        x_onehot = torch.nn.functional.one_hot(x, num_classes=self.vocab_size).float() # 传播第一步，将输入从索引转换为独热编码。\n        out, _ = self.rnn(x_onehot)  \n        out = self.fc(out)  \n        return out\n</code></pre>\n<p>而把使用独热编码改为使用词向量的工作量也并不大，我们需要：</p>\n<ol>\n<li><strong>新增参数定义词向量维度。</strong></li>\n<li><strong>创建嵌入层。</strong></li>\n<li><strong>在传播的第一步将索引从转换为独热编码改为输入嵌入层提取词向量。</strong></li>\n</ol>\n<p>更改完的代码如下：</p>\n<pre><code class=\"language-python\">class RNNTagger(nn.Module):  \n    def __init__(self, vocab_size, hidden_dim, num_classes,  \n                 rnn_type='RNN', bidirectional=False, num_layers=1,  \n                 embed_dim=300):  # ← 新增一个嵌入维度参数  \n        super().__init__()  \n        self.bidirectional = bidirectional  \n        self.rnn_type = rnn_type.upper()  \n  \n        # 新增：词嵌入层  \n        self.embedding = nn.Embedding(  \n            num_embeddings=vocab_size,  \n            embedding_dim=embed_dim,  \n            padding_idx=word_vocab[\"&lt;PAD&gt;\"]  \n        )  \n  \n        input_size = embed_dim  # ← RNN 输入改为 embedding 维度  \n  \n        if self.rnn_type == 'RNN':  \n            self.rnn = nn.RNN(input_size, hidden_dim, batch_first=True,  \n                              bidirectional=bidirectional, num_layers=num_layers)  \n        elif self.rnn_type == 'LSTM':  \n            self.rnn = nn.LSTM(input_size, hidden_dim, batch_first=True,  \n                               bidirectional=bidirectional, num_layers=num_layers)  \n        elif self.rnn_type == 'GRU':  \n            self.rnn = nn.GRU(input_size, hidden_dim, batch_first=True,  \n                              bidirectional=bidirectional, num_layers=num_layers)  \n        else:  \n            raise ValueError(\"rnn_type must be 'RNN','LSTM','GRU'\")  \n  \n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)  \n  \n    def forward(self, x):  \n        x_embed = self.embedding(x) #在传播中首先输入嵌入层提取词向量。\n        out, _ = self.rnn(x_embed)  \n        out = self.fc(out)  \n        return out\n</code></pre>\n<p>这样，只需要在模型部分完成改动，我们便可以直接应用上周的代码框架直接进行训练。<br />\n下面就来看看效果：</p>\n<h2 id=\"22-使用词嵌入进行命名实体识别\">2.2 使用词嵌入进行命名实体识别</h2>\n<p>我们先使用<strong>普通的双向 RNN</strong> 来看看效果，多次实验部分结果如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231952652-728374191.png\" /><br />\n可以看出，相比独热编码，虽然在指标上并没有明显的提升，但是使用 300 维的词向量<strong>完成相同的训练，只需要独热编码训练用时的约 65%</strong> ，这种优势会随着词表规模增加而更明显。<br />\n显然，词向量避免了独热编码向量的极高维度且极其稀疏缺陷，这是在计算性能上的极大提升。<br />\n简单打印一些训练后的词向量如下：（只截取了前 20 维）<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231746057-63686229.png\" /><br />\n然后，我们再试试上周综合表现最好的 GRU ，结果如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127232402014-1527482926.png\" /><br />\n训练用时同样得到了极大提升，但是，好像出现问题了：<br />\n<strong>在使用了词嵌入后，明明还增加了训练轮次，但指标反而不如使用独热编码高</strong>，这是为什么？</p>\n<p>实际上，<strong>词嵌入并不天然适用于所有 NLP 任务</strong>。对于实体命名识别这类以<strong>词和标签强对齐</strong>为主的任务，one-hot 表示由于其<strong>完全区分词身份的特性</strong>，反而可能取得更好的效果。<br />\n说简单些，由于<strong>命名实体识别任务更关注“这个词是什么”，而不是“词之间的关系”</strong>，使用完全正交的独热编码反而让界限更明显。<br />\n来简单看个例子：</p>\n<p>假设<strong>在训练语料中</strong>，<code>Apple</code> 大量以 <code>B-ORG</code>（组织）标签出现，而 <code>Google</code>、<code>Microsoft</code> 等词在词嵌入空间中与 <code>Apple</code> 距离很近，这是因为它们共享了“公司”“科技”“产品”等相似上下文。但在具体句子中：</p>\n<ul>\n<li><code>Apple released a new product.</code> → <code>Apple</code> 是 <code>ORG</code>（苹果公司）</li>\n<li><code>I ate an apple after lunch.</code> → <code>apple</code> 是 <code>O</code>（食物苹果）</li>\n</ul>\n<p>对于 NER 来说，关键不是“这个词在语义上像什么”，而是<strong>在当前任务标注体系下，它在这个位置对应什么标签</strong>。<br />\n而词嵌入会引入一种强烈的归纳偏置：<strong>语义相近的词，其表示也应当相近</strong>。当模型的上下文建模能力有限时，这种相似性结构可能被过度利用，使<strong>模型倾向于根据词向量的邻近关系做出判断，而不是严格依赖监督信号本身</strong>，从而在某些语境下产生错误的实体类型预测。</p>\n<p>比如词嵌入会天然鼓励模型<strong>将 <code>Apple</code> 与其他科技公司词拉近</strong>，从而放大“公司语义”的共性，而如果模型设计<strong>对大小写不敏感</strong>，另外的部分语料里又让<strong>水果间的距离更近</strong>，就可能导致 <strong>“香蕉公司”，“菠萝公司”</strong> 等错误识别。<br />\n而在 one-hot 表示下，<code>Apple</code> 的表示与任何其他词完全独立，模型只能依赖监督信号本身去学习它在不同上下文中与标签之间的对应关系，<strong>反而避免了这种误解</strong>。</p>\n<p>总结来说，在不进行进一步上下文建模或结构化约束的情况下，词嵌入由于为<strong>多义词</strong>提供了共享的连续表示，可能在某些任务中引入语义混淆，从而影响模型对具体标签的判别。<br />\n而 one-hot 表示通过其完全正交的设计，显式区分了不同词项的身份，在词—标签强对齐的任务中反而在一定程度上缓解这一问题。</p>\n<p>现在，我们在词嵌入的强项：情绪分类上再来看看其效果：</p>\n<h2 id=\"23-使用词向量进行情绪分类\">2.3 使用词向量进行情绪分类</h2>\n<p>要进行新的任务，自然首先要引入新的数据集，这里我们使用情绪分类中的经典数据集：<strong>IMDb</strong><br />\nIMDb 数据集是一个经典的<strong>二分类</strong>情绪分析任务数据集，它的输入是电影评论文本，输出是情绪标签，<code>0</code> 表示负面（negative），<code>1</code> 表示正面（positive）。<br />\n训练集和测试集各包含 25,000 条评论，评论长度不固定，从几十词到几百词不等，文本中包含标点、大小写、数字等元素。数据类别平衡。比较适合我们的演示。<br />\n同样，我们使用之前介绍过的 HuggingFace Datasets 来下载，完整代码附在最后，这里展示几条样本数据：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231746713-502919155.png\" /><br />\n现在，同样使用 <strong>单层双向 GRU</strong> 来进行实验，设置<strong>词表大小为 20000，批次大小为 32</strong>，部分训练结果如下：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260127231746505-1423343285.png\" /><br />\n可以在较少的轮次中，实现较好的拟合。<br />\n而在同等参数下使用独热编码则会爆内存，以我的电脑配置需要将词表缩小到 5000 以下，并将批次大小降至 6，才勉强可以运行且单轮时间较长，这样的配置并不适配一般的使用场景，因此就不再展示独热编码的效果了。</p>\n<p><strong>词向量在计算效率与大词表适应性上拥有极大优势</strong>，可以在保持模型性能的同时，大幅降低显存消耗与训练时间。<br />\n如果你的资源足够，可以进行更多的尝试看看效果。</p>\n<h1 id=\"3-附录\">3. 附录</h1>\n<h2 id=\"31-使用词嵌入进行情绪分类-pytorch版\">3.1 使用词嵌入进行情绪分类 PyTorch版</h2>\n<pre><code class=\"language-python\">import torch  \nimport torch.nn as nn  \nfrom torch.utils.data import DataLoader  \nfrom torch.nn.utils.rnn import pad_sequence  \nfrom datasets import load_dataset  \nfrom collections import Counter  \nfrom sklearn.metrics import accuracy_score, f1_score  \nimport time  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \ndataset = load_dataset(\"mteb/imdb\")  \ntrain_data = dataset['train']  \ntest_data  = dataset['test']  \n   \ndef build_vocab(dataset, max_vocab_size=5000):  \n    counter = Counter()  \n    for item in dataset:  \n        counter.update(item['text'].split())  \n    most_common = counter.most_common(max_vocab_size)  \n    word_vocab = {w:i+2 for i,(w,_) in enumerate(most_common)}  \n    word_vocab[\"&lt;PAD&gt;\"] = 0  \n    word_vocab[\"&lt;UNK&gt;\"] = 1  \n    return word_vocab  \n  \nword_vocab = build_vocab(train_data)  \nvocab_size = len(word_vocab)  \n  \ndef encode(item):  \n    x = torch.tensor([word_vocab.get(w,1) for w in item['text'].split()], dtype=torch.long)  \n    y = torch.tensor(item['label'], dtype=torch.long)  \n    return x, y  \n  \ntrain_dataset = [encode(item) for item in train_data]  \ntest_dataset  = [encode(item) for item in test_data]  \n  \ndef collate_fn(batch):  \n    xs, ys = zip(*batch)  \n    xs_pad = pad_sequence(xs, batch_first=True, padding_value=word_vocab[\"&lt;PAD&gt;\"])  \n    ys = torch.tensor(ys, dtype=torch.long)  \n    return xs_pad.to(device), ys.to(device)  \n  \ntrain_loader = DataLoader(train_dataset, batch_size=6, shuffle=True, collate_fn=collate_fn)  \ntest_loader  = DataLoader(test_dataset, batch_size=6, shuffle=False, collate_fn=collate_fn)  \n  \nclass GRUSentiment(nn.Module):  \n    def __init__(self, vocab_size, hidden_dim, num_classes,  \n                 bidirectional=True, embed_dim=300):  \n        super().__init__()  \n        self.bidirectional = bidirectional  \n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)  \n        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True,  \n                          bidirectional=bidirectional, num_layers=1)  \n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)  \n  \n    def forward(self, x):  \n        x = self.embedding(x)           \n        out, _ = self.rnn(x)            \n        if self.bidirectional:  \n            out = torch.cat([out[:, -1, :self.rnn.hidden_size],  \n                             out[:, 0, self.rnn.hidden_size:]], dim=1)  \n        else:  \n            out = out[:, -1, :]  \n        out = self.fc(out)  \n        return out  \n\ndef train_validate(model, train_loader, test_loader, epochs=3, lr=0.001):  \n    model.to(device)  \n    criterion = nn.CrossEntropyLoss()  \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n  \n    for epoch in range(epochs):  \n        model.train()  \n        total_loss = 0  \n        total_correct = 0  \n        total_tokens = 0  \n        start_time = time.time()  \n  \n        for x_batch, y_batch in train_loader:  \n            optimizer.zero_grad()  \n            outputs = model(x_batch)  \n            loss = criterion(outputs, y_batch)  \n            loss.backward()  \n            optimizer.step()  \n            total_loss += loss.item()  \n  \n            preds = outputs.argmax(dim=-1)  \n            total_correct += (preds == y_batch).sum().item()  \n            total_tokens += y_batch.numel()  \n  \n        train_acc = total_correct / total_tokens  \n        avg_loss = total_loss / len(train_loader)  \n  \n        # 验证  \n        model.eval()  \n        all_preds, all_labels = [], []  \n        val_total_correct = 0  \n        val_total_tokens = 0  \n  \n        with torch.no_grad():  \n            for x_batch, y_batch in test_loader:  \n                outputs = model(x_batch)  \n                preds = outputs.argmax(dim=-1)  \n                all_preds.extend(preds.cpu().tolist())  \n                all_labels.extend(y_batch.cpu().tolist())  \n                val_total_correct += (preds == y_batch).sum().item()  \n                val_total_tokens += y_batch.numel()  \n  \n        val_acc = val_total_correct / val_total_tokens  \n        val_f1  = f1_score(all_labels, all_preds, average='macro')  \n        epoch_time = time.time() - start_time  \n  \n        print(  \n            f\"轮次 {epoch+1} | \"            f\"训练损失: {avg_loss:.4f} | \"            f\"训练准确率: {train_acc:.4f} | \"            f\"验证准确率: {val_acc:.4f} | \"            f\"验证F1: {val_f1:.4f} | \"            f\"本轮耗时: {epoch_time:.2f} 秒\"  \n        )  \n  \n    print(\"\\n训练完成！\")  \n    print(f\"最终验证准确率: {val_acc:.4f}, F1-macro: {val_f1:.4f}\")  \n    return model  \n  \n\nif __name__ == \"__main__\":  \n    model = GRUSentiment(  \n        vocab_size=vocab_size,  \n        hidden_dim=128,  \n        num_classes=2,  \n        bidirectional=True,  \n        embed_dim=300  \n    )  \n    model = train_validate(model, train_loader, test_loader, epochs=10, lr=0.001)\n</code></pre>\n<h2 id=\"32-使用词嵌入进行情绪分类-tf版\">3.2 使用词嵌入进行情绪分类 TF版</h2>\n<pre><code class=\"language-python\">import tensorflow as tf  \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences  \nfrom tensorflow.keras.utils import to_categorical  \nfrom datasets import load_dataset  \nfrom collections import Counter  \nimport numpy as np  \nimport time  \n  \ndevice = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"  \n  \n  \ndataset = load_dataset(\"mteb/imdb\")  \ntrain_data = dataset['train']  \ntest_data  = dataset['test']  \n  \ndef build_vocab(dataset, max_vocab_size=5000):  \n    counter = Counter()  \n    for item in dataset:  \n        counter.update(item['text'].split())  \n    most_common = counter.most_common(max_vocab_size)  \n    word_vocab = {w:i+2 for i,(w,_) in enumerate(most_common)}  \n    word_vocab[\"&lt;PAD&gt;\"] = 0  \n    word_vocab[\"&lt;UNK&gt;\"] = 1  \n    return word_vocab  \n  \nword_vocab = build_vocab(train_data, max_vocab_size=20000)  \nvocab_size = len(word_vocab)  \nprint(\"词表大小:\", vocab_size)  \n  \ndef encode(item):  \n    x = [word_vocab.get(w, 1) for w in item['text'].split()]  \n    y = item['label']  \n    return x, y  \n  \ntrain_encoded = [encode(item) for item in train_data]  \ntest_encoded  = [encode(item) for item in test_data]  \n  \nmax_len = 200  X_train = pad_sequences([x for x, _ in train_encoded], maxlen=max_len, padding='post', truncating='post')  \ny_train = np.array([y for _, y in train_encoded])  \nX_test  = pad_sequences([x for x, _ in test_encoded], maxlen=max_len, padding='post', truncating='post')  \ny_test  = np.array([y for _, y in test_encoded])  \n  \ndef build_model(vocab_size, embed_dim=300, hidden_dim=128, bidirectional=True, num_classes=2):  \n    inputs = tf.keras.Input(shape=(max_len,), dtype=tf.int32)  \n    x = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)(inputs)  \n    if bidirectional:  \n        x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(hidden_dim))(x)  \n    else:  \n        x = tf.keras.layers.GRU(hidden_dim)(x)  \n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)  \n    model = tf.keras.Model(inputs, outputs)  \n    return model  \n  \nmodel = build_model(vocab_size=vocab_size, embed_dim=300, hidden_dim=128, bidirectional=True, num_classes=2)  \nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.001),  \n              loss='sparse_categorical_crossentropy',  \n              metrics=['accuracy'])  \n  \nmodel.summary()  \n  \nstart_time = time.time()  \nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test),  \n                    epochs=10, batch_size=32)  \ntotal_time = time.time() - start_time  \nprint(f\"训练完成，用时 {total_time:.2f} 秒\")  \n  \ny_pred = np.argmax(model.predict(X_test), axis=1)  \nfrom sklearn.metrics import f1_score  \nf1 = f1_score(y_test, y_pred, average='macro')  \nacc = np.mean(y_pred == y_test)  \nprint(f\"验证准确率: {acc:.4f}, F1-macro: {f1:.4f}\")\n</code></pre>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 23:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET 虚拟单体存储库 (VMR)架构演进、同步机制与统一构建策略",
      "link": "https://www.cnblogs.com/shanyou/p/19540873",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shanyou/p/19540873\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 22:42\">\n    <span>.NET 虚拟单体存储库 (VMR)架构演进、同步机制与统一构建策略</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        .NET 虚拟单体存储库 (VMR) 代表了大型开源软件工程领域的一次大胆尝试与创新。它并未盲目照搬 Google 的闭源单体模式，也没有固守传统的多仓库泥潭，而是开创了一条“中间道路”\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"摘要\"><strong>摘要</strong></h2>\n<p>本文对.NET 平台的构建架构转型进行了详尽的剖析，特别是从分布式多存储库模式向<strong>虚拟单体存储库 (Virtual Monolithic Repository, VMR)</strong> 的战略迁移。随着.NET 从 Windows 专有框架演变为跨平台、开源的开发生态系统，其底层的工程复杂性呈指数级增长。传统的依赖图构建模型导致了严重的“一致性延迟”和维护碎片化问题。VMR 作为一种创新的混合架构模式，旨在通过“虚拟化”手段，在保留原有各产品存储库（Product Repositories）独立开发灵活性的同时，实现单体存储库（Monorepo）所具备的统一构建、原子级版本控制和供应链安全优势。</p>\n<h2 id=\"1-架构背景与演进动力\"><strong>1. 架构背景与演进动力</strong></h2>\n<h3 id=\"11-从单体到碎片化net-的开源征程\"><strong>1.1 从单体到碎片化：.NET 的开源征程</strong></h3>\n<p>在.NET Framework 时代，构建系统主要围绕 Windows 操作系统紧密集成，采用传统的封闭式开发模式。然而，随着.NET Core 的推出，微软开启了彻底的开源与跨平台转型。为了适应开源社区的协作习惯，并实现不同组件（如 Runtime, SDK, ASP.NET Core, Roslyn 编译器等）的独立迭代，.NET 团队最初采用了极为分散的多存储库（Multi-Repo）策略1。</p>\n<p>在这种模式下，.NET 平台被拆解为数十甚至上百个独立的 Git 存储库。每个存储库拥有独立的构建管道、版本控制历史和发布周期。这种架构在初期极大地促进了各个组件团队的敏捷性，使得负责 JIT 编译器的团队与负责 ASP.NET 路由的团队能够互不干扰地并行开发 。</p>\n<h3 id=\"12-分布式依赖图的系统性崩溃\"><strong>1.2 分布式依赖图的系统性崩溃</strong></h3>\n<p>随着.NET 生态系统的壮大，这种完全解耦的架构逐渐暴露出严重的系统性缺陷，特别是在构建整个.NET SDK 产品时。这些存储库并非真正独立，而是通过复杂的依赖关系相互连接，形成了一个庞大的<strong>有向无环图 (DAG)</strong> 3。</p>\n<h4 id=\"121-一致性延迟-coherency-latency\"><strong>1.2.1 一致性延迟 (Coherency Latency)</strong></h4>\n<p>在分布式图中，变更的传播是线性的且极其缓慢。例如，当 Roslyn 编译器团队修复了一个底层 Bug 并发布新版本后，该变更必须沿着依赖链逐级向下传播：首先更新 Runtime，Runtime 构建发布后更新 ASP.NET Core，最后才能到达 SDK 和 Installer。这个过程可能长达数天甚至数周。在此期间，处于依赖树不同层级的组件可能基于不同版本的上游组件构建，导致整个产品在任意时间点都处于“非一致性”状态。</p>\n<h4 id=\"122-钻石依赖与版本地狱\"><strong>1.2.2 钻石依赖与版本地狱</strong></h4>\n<p>分布式架构最典型的问题是<strong>钻石依赖 (Diamond Dependency)</strong>。假设存储库 A 和存储库 B 都依赖于存储库 C 的不同版本，而下游的存储库 D 同时依赖于 A 和 B。当 D 尝试构建时，就会遇到版本冲突（NuGet Hell）。解决这种冲突通常需要人工介入，强制统一依赖版本，这不仅耗时，还容易引入运行时错误。</p>\n<h4 id=\"123-跨栈重构的死锁\"><strong>1.2.3 跨栈重构的死锁</strong></h4>\n<p>当开发人员需要进行跨越多个技术栈的重构时（例如，在 Runtime 中引入新 API 并在 SDK 中立即使用），分布式架构构成了巨大的阻碍。开发者必须先在 Runtime 提交代码，等待构建发布，然后在 SDK 中升级依赖。这种“多阶段提交”不仅效率低下，而且使得原子性变更变得不可能，严重阻碍了架构层面的技术演进。</p>\n<h3 id=\"13-统一构建-unified-build-的战略转折\"><strong>1.3 统一构建 (Unified Build) 的战略转折</strong></h3>\n<p>为了解决上述问题，微软提出了 <strong>统一构建 (Unified Build)</strong> 愿景，其核心目标是能够从<strong>单一的源码提交 (Single Commit)</strong> 构建出完整的.NET SDK 产品。这不仅是内部工程效率的需求，也是为了满足 Linux 发行版（如 Fedora, Debian, Ubuntu）的合规性要求。Linux 社区有着严格的“源码构建”政策，要求软件包必须能够在其基础设施上从源代码从头编译，而不依赖预构建的二进制文件（Binary Blobs）。</p>\n<p>为了实现这一目标，必须打破物理存储库的边界，建立一个逻辑上的统一视图。<strong>虚拟单体存储库 (VMR)</strong> 应运而生，它成为了 Unified Build 的物理载体和操作核心。</p>\n<h2 id=\"2-虚拟单体存储库-vmr-的架构解析\"><strong>2. 虚拟单体存储库 (VMR) 的架构解析</strong></h2>\n<p>VMR (dotnet/dotnet) 并非传统意义上的单体存储库，而是一种混合架构模式。它巧妙地平衡了现有工程流程的惯性与统一构建的需求。</p>\n<h3 id=\"21-定义-虚拟-与-单体\"><strong>2.1 定义 \"虚拟\" 与 \"单体\"</strong></h3>\n<p>VMR 的设计哲学包含两个核心维度：</p>\n<ul>\n<li><strong>单体性 (Monolithic):</strong> 从构建系统的角度看，VMR 就是一个标准的单体库。它包含了构建.NET SDK 所需的<strong>所有</strong>源代码、构建脚本、基础设施定义和测试用例。在这个存储库上的任意一个 Git Commit SHA，都唯一且完整地定义了该时刻.NET 产品的全貌。</li>\n<li><strong>虚拟性 (Virtual):</strong> 从开发工作流的角度看，它是一个“投影”或“镜像”。原始的产品存储库（如 dotnet/runtime, dotnet/sdk）依然存在，并且是大多数开发人员日常工作的“主战场”。VMR 中的代码并非凭空产生，而是通过自动化机制从这些产品存储库同步而来的。因此，VMR 是各组件的聚合体，而非替代品 。</li>\n</ul>\n<h3 id=\"22-文件系统与存储模型\"><strong>2.2 文件系统与存储模型</strong></h3>\n<p>VMR 的目录结构经过精心设计，以映射并整合来自数十个上游存储库的内容。</p>\n<ul>\n<li><strong>src/ 目录：</strong> 这是 VMR 的核心。每个上游产品存储库的内容被映射到 src/ 下的一个子目录中。例如，dotnet/runtime 的源码被放置在 src/runtime，dotnet/aspnetcore 被放置在 src/aspnetcore。这种物理上的聚合使得跨组件的搜索、重构和构建成为可能。</li>\n<li><strong>eng/ 目录：</strong> 包含共享的工程基础设施，特别是 Arcade 工具集。这是.NET 团队通用的构建系统核心。</li>\n<li><strong>eng/common/：</strong> 这是一个特殊的引导目录，包含用于启动构建过程的脚本。这些文件通常从 Arcade 存储库同步而来，用于确保所有组件使用一致的构建工具版本。</li>\n<li><strong>source-manifest.json：</strong> 这是 VMR 的“数据库”或“注册表”。由于 VMR 是由多个上游仓库聚合而成，系统必须精确记录 VMR 当前状态对应于上游仓库的哪个 Commit SHA。该 JSON 文件维护了组件名称、远程仓库 URL 以及当前同步的 Git Hash 的映射关系，是实现双向同步的关键元数据。</li>\n</ul>\n<h3 id=\"23-存储模型的特殊处理\"><strong>2.3 存储模型的特殊处理</strong></h3>\n<p>为了适应.NET 的庞大规模和特殊构建需求，VMR 在存储模型上做了一些非标准 Git 的处理：</p>\n<ul>\n<li><strong>子模块实体化 (Hard Copy vs Pointers):</strong> 与 Git Submodules 仅存储指向外部仓库的指针不同，VMR 将子模块的代码<strong>物理复制</strong>并提交到 VMR 的 Git 树中。这意味着 src/runtime 下不仅有文件，而且这些文件是 VMR 历史的一部分。这样做是为了支持离线构建（Source Build），确保即使在没有网络连接的环境下，只要克隆了 VMR，就拥有了构建所需的一切代码。</li>\n<li><strong>文件屏蔽与路径映射 (Cloaking):</strong> 上游存储库中可能包含一些不适合放入 VMR 的文件，例如大尺寸的二进制测试数据、Windows 专用的闭源组件，或者违反 Linux 发行版许可协议的文件。VMR 的同步机制支持配置“屏蔽规则”，在同步过程中自动剔除这些路径/文件。这类似于 .gitignore，但发生在同步逻辑层面。</li>\n</ul>\n<h2 id=\"3-同步机制详解maestro-与-darc\"><strong>3. 同步机制详解：Maestro 与 Darc</strong></h2>\n<p>VMR 的生命力在于其同步机制。如果没有高效、准确的同步，VMR 将迅速与上游存储库脱节，失去其作为“真相来源”的价值。微软为此构建了一套复杂的依赖流系统，核心组件包括云服务 <strong>Maestro</strong> 和命令行工具 <strong>Darc</strong>。</p>\n<h3 id=\"31-同步架构的演进阶段\"><strong>3.1 同步架构的演进阶段</strong></h3>\n<p>VMR 的同步机制并非一蹴而就，而是经历了三个阶段的迭代 ：</p>\n<ul>\n<li><strong>阶段一：Source Build Tarball (源码构建压缩包)</strong><br />\n在.NET 6 时代，所谓的“单体”仅仅是一个巨大的 Tarball 压缩包，专门提供给 Linux 合作伙伴。它通过一系列补丁（Patches）将各个仓库的源码拼凑在一起。这种方式缺乏版本控制历史，调试极其困难，被描述为“脆弱且不透明”。</li>\n<li><strong>阶段二：VMR-lite (单向只读镜像)</strong><br />\n2022 年 10 月，微软建立了只读的 VMR。同步是单向的：从产品存储库流向 VMR。这解决了代码可见性和历史追踪问题，但由于是单向的，开发者无法直接在 VMR 中修复集成错误，必须回到原仓库修改，导致反馈循环过长。</li>\n<li><strong>阶段三：Writable VMR (双向读写同步)</strong> 从.NET 10 Preview 5 开始，VMR 变为可读写。引入了“扁平化流 (Flat Flow)”模型，允许代码在产品存储库和 VMR 之间双向流动。这标志着 VMR 正式成为生产级的基础设施。</li>\n</ul>\n<h3 id=\"32-控制平面maestro-产品构建服务\"><strong>3.2 控制平面：Maestro (产品构建服务)</strong></h3>\n<p><strong>Maestro</strong>（也被称为产品构建服务，Product Construction Service）是编排整个.NET 构建生态系统的“大脑”。它是一个运行在 Azure 上的微服务，负责监听存储库状态、计算依赖关系并触发代码流。</p>\n<p><strong>Maestro 的核心职责：</strong></p>\n<ol>\n<li><strong>订阅管理 (Subscription Management):</strong> Maestro 维护着一张庞大的订阅图。订阅定义了“源仓库”与“目标仓库”之间的关系。例如，dotnet/runtime 的 main 分支订阅了 dotnet/dotnet (VMR) 的 main 分支。</li>\n<li><strong>自动 PR 创建:</strong> 当源仓库产生新的构建时，Maestro 会计算差异，并自动在目标仓库创建 Pull Request (PR)。</li>\n<li><strong>冲突检测:</strong> 如果同步过程中发现文件冲突，Maestro 会标记 PR 并通知相关维护者（通常是 @dotnet/product-construction 团队）。</li>\n</ol>\n<h3 id=\"33-开发者工具darc-cli\"><strong>3.3 开发者工具：Darc CLI</strong></h3>\n<p><strong>Darc</strong> 是开发者与 Maestro 服务交互的本地命令行接口。它允许开发者查看、添加或更新订阅，并在本地模拟同步过程。</p>\n<p>核心命令解析 :</p>\n<ul>\n<li>darc get-subscriptions: 列出当前仓库或指定仓库的所有活跃订阅。输出通常包含源仓库 URL、目标分支、更新频率等信息。</li>\n<li>darc add-subscription: 创建新的依赖流通道。例如，将 dotnet/arcade 的更新流向 dotnet/msbuild。</li>\n<li>darc update-subscription: 修改现有订阅的参数，如排除特定的资产（Excluded Assets）或调整批处理策略。</li>\n<li>darc vmr forwardflow / backflow: （虽然文档未详细展开，但推测存在）用于在本地触发 VMR 的正向或反向同步逻辑，帮助开发者验证变更 。</li>\n</ul>\n<h3 id=\"34-代码流算法-code-flow-algorithm\"><strong>3.4 代码流算法 (Code Flow Algorithm)</strong></h3>\n<p>VMR 的同步通过两种主要的代码流模式实现：<strong>正向流 (Forward Flow)</strong> 和 <strong>反向流 (Backflow)</strong>。</p>\n<h4 id=\"341-正向流-forward-flow-产品库---vmr\"><strong>3.4.1 正向流 (Forward Flow): 产品库 -&gt; VMR</strong></h4>\n<p>当开发者在 dotnet/runtime 合并了一个 PR 后：</p>\n<ol>\n<li><strong>触发:</strong> Maestro 检测到构建成功。</li>\n<li><strong>补丁生成:</strong> 系统根据 VMR 中记录的 source-manifest.json 获取上一次同步的 Commit SHA，并与当前最新的 Commit SHA 进行对比。使用 git diff --patch --binary 生成包含了二进制差异的补丁文件。</li>\n<li><strong>路径重写:</strong> 补丁中的文件路径会被重写，加上前缀（如 src/runtime/），以匹配 VMR 的目录结构。</li>\n<li><strong>应用与提交:</strong> 补丁应用到 VMR 分支上，并更新 source-manifest.json 中的 SHA 记录。这个过程是自动化的。</li>\n</ol>\n<h4 id=\"342-反向流-backflow-vmr---产品库\"><strong>3.4.2 反向流 (Backflow): VMR -&gt; 产品库</strong></h4>\n<p>当开发者直接在 VMR 中进行跨组件修改（例如同时修改 Runtime 和 SDK）并合并后：</p>\n<ol>\n<li><strong>逆向映射:</strong> 系统识别出哪些文件属于哪个子组件。</li>\n<li><strong>分支与 PR:</strong> 针对每个受影响的产品存储库，系统会创建一个包含源码变更的 PR。</li>\n<li><strong>依赖更新:</strong> 关键点在于，反向流不仅包含<strong>源码</strong>，还包含 VMR 构建出的<strong>新二进制包版本</strong>。这意味着，当反向流回到 dotnet/runtime 时，该仓库的 Version.Details.xml 也会被更新，指向 VMR 构建出的最新依赖。这保证了产品库始终基于最新的全栈环境进行构建。</li>\n</ol>\n<h3 id=\"35-状态追踪与防环路设计\"><strong>3.5 状态追踪与防环路设计</strong></h3>\n<p>双向同步最容易导致的问题是死循环（Ping-Pong Effect）：A 的变更同步给 B，B 的构建触发同步回 A。为了防止这种情况，.NET 团队采用了严格的状态追踪机制。</p>\n<ul>\n<li><strong>eng/Version.Details.xml:</strong> 在产品库中，此文件记录了该仓库依赖的 VMR 版本。</li>\n<li><strong>src/source-manifest.json:</strong> 在 VMR 中，此文件记录了包含的各产品库版本。</li>\n</ul>\n<p>同步逻辑会检查这些元数据。如果 Maestro 发现 VMR 中的变更实际上就是源自产品库最近的一次提交，它会识别为“已同步”，从而通过空操作（No-Op）切断循环。</p>\n<h2 id=\"4-统一构建-unified-build-与供应链安全\"><strong>4. 统一构建 (Unified Build) 与供应链安全</strong></h2>\n<p>VMR 的建立不仅仅是为了方便代码管理，更是 <strong>Unified Build</strong> 的基石。它改变了.NET 产品的构建范式，从水平分层构建转向垂直切片构建。</p>\n<h3 id=\"41-垂直构建-vertical-builds\"><strong>4.1 垂直构建 (Vertical Builds)</strong></h3>\n<p>在旧的模式下，构建是水平的：先构建所有 Runtime，再构建所有 ASP.NET。而在 VMR 中，构建是<strong>垂直</strong>的。 一个垂直构建会基于 VMR 的单一 Commit，按照依赖顺序（Toolset -&gt; Runtime -&gt; ASP.NET -&gt; SDK）在一次构建流水线中从源码编译出整个栈。</p>\n<p><strong>优势：</strong></p>\n<ul>\n<li><strong>消除时间差:</strong> 任何代码变更都会立即在全栈范围内进行验证。</li>\n<li><strong>简化发布:</strong> 发布.NET 10 Preview 1 只需要对 VMR 的特定 Commit 打标签，而不需要协调几十个仓库的 Commit 组合。</li>\n</ul>\n<h3 id=\"42-linux-源码构建-source-build-与发行版合规\"><strong>4.2 Linux 源码构建 (Source Build) 与发行版合规</strong></h3>\n<p>Linux 发行版（如 Fedora, Red Hat）对软件包有严格的“源码构建”要求。他们不信任上游厂商提供的预编译二进制文件，因为这些文件可能包含后门或未修补的漏洞，且无法审计。</p>\n<p>VMR 通过提供一个自包含的 Git 仓库，完美支持了这一需求：</p>\n<ol>\n<li><strong>离线能力:</strong> VMR 包含了所有必要的源码（通过实体化的子模块），不依赖构建时的 git clone 操作。</li>\n<li><strong>预制脚本:</strong> prep-source-build.sh 脚本用于准备环境。</li>\n<li><strong>引用包 (Reference Packages):</strong> 为了解决循环依赖（如构建 C# 编译器需要 C# 编译器），Unified Build 引入了 dotnet/source-build-reference-packages。这些是仅包含 API 定义（元数据）的文本格式包，可以轻易地从源码生成，作为自举（Bootstrapping）的起点 5。</li>\n</ol>\n<h3 id=\"43-可重现构建-reproducible-builds\"><strong>4.3 可重现构建 (Reproducible Builds)</strong></h3>\n<p>供应链安全的核心是<strong>可重现性</strong>。即：在不同环境、不同时间，使用相同的源码应当生成比特级完全一致（Bit-for-bit identical）的二进制文件 15。</p>\n<p>VMR 架构极大地促进了这一点：</p>\n<ul>\n<li><strong>输入确定性:</strong> 单一 Commit 锁定了所有源代码输入。</li>\n<li><strong>环境一致性:</strong> eng/common 锁定了所有构建工具链版本。</li>\n<li><strong>路径规范化:</strong> 编译器配置被调整为忽略绝对路径（如 /home/user/src），使用相对路径或确定性路径映射（Source Link），确保构建产物不包含构建机器的元数据 16。</li>\n</ul>\n<p>这使得第三方（如企业安全团队或政府机构）可以独立验证微软发布的.NET SDK 是否真的由公开的源码构建而来，从而防止类似 SolarWinds 的供应链攻击。</p>\n<h2 id=\"5-开发者工作流与体验\"><strong>5. 开发者工作流与体验</strong></h2>\n<p>VMR 的引入对开发者的日常工作流产生了深远影响，形成了“内循环”与“外循环”并存的局面。</p>\n<h3 id=\"51-内循环-inner-loop产品库开发\"><strong>5.1 内循环 (Inner Loop)：产品库开发</strong></h3>\n<p>对于绝大多数日常任务（如修复 System.String 中的 Bug），开发者依然工作在 dotnet/runtime 等独立产品库中。</p>\n<ul>\n<li><strong>流程:</strong> Fork -&gt; Clone -&gt; Branch -&gt; Commit -&gt; PR。</li>\n<li><strong>优势:</strong> 保持了较小的仓库体积（相比 VMR），IDE 加载速度快，构建时间短。</li>\n<li><strong>同步:</strong> 变更合并后，开发者无需手动操作，Maestro 会自动将其正向流转到 VMR。</li>\n</ul>\n<h3 id=\"52-外循环-outer-loopvmr-开发\"><strong>5.2 外循环 (Outer Loop)：VMR 开发</strong></h3>\n<p>当任务涉及跨仓库修改时，开发者切换到 VMR。</p>\n<ul>\n<li><strong>场景:</strong> 修改 Roslyn 编译器的一个接口，并同时更新 Runtime 中对该接口的调用。</li>\n<li><strong>流程:</strong> Clone dotnet/dotnet -&gt; 修改 src/roslyn 和 src/runtime -&gt; 本地全量构建验证 -&gt; 提交 PR 给 VMR。</li>\n<li><strong>优势:</strong> 原子性提交，一次性解决所有破坏性变更（Breaking Changes），无需临时向后兼容代码 。</li>\n</ul>\n<h3 id=\"53-痛点与挑战\"><strong>5.3 痛点与挑战</strong></h3>\n<p>尽管 VMR 解决了架构问题，但也给开发者带来了一些“痛点”：</p>\n<ol>\n<li><strong>仓库体积:</strong> VMR 非常庞大，Clone 和 Checkout 的时间显著增加。</li>\n<li><strong>构建时间:</strong> 垂直构建整个.NET 栈需要消耗大量的计算资源和时间，普通开发者的笔记本电脑可能难以通过 VMR 进行全量调试。</li>\n<li><strong>权限控制:</strong> 在多仓库模式下，权限可以细分（如只有特定团队能合并 Runtime 代码）。在 VMR 中，权限管理变得更加复杂，需要通过 CODEOWNERS 文件精细控制目录级权限，防止误操作 。</li>\n</ol>\n<h2 id=\"6-架构对比分析\"><strong>6. 架构对比分析</strong></h2>\n<p>为了更清晰地定位 VMR 的架构属性，我们将其与业界其他主流方案进行对比。</p>\n<h3 id=\"表-1vmr-与-传统-monorepo-及-git-submodules-的深度对比\"><strong>表 1：VMR 与 传统 Monorepo 及 Git Submodules 的深度对比</strong></h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">分布式多仓库 (Legacy.NET)</th>\n<th style=\"text-align: left;\">标准 Monorepo (Google/Meta)</th>\n<th style=\"text-align: left;\">虚拟单体库 (.NET VMR)</th>\n<th style=\"text-align: left;\">Git Submodules 方案</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>代码存储</strong></td>\n<td style=\"text-align: left;\">物理分散，逻辑连接</td>\n<td style=\"text-align: left;\">物理集中，单一仓库</td>\n<td style=\"text-align: left;\"><strong>物理集中（镜像），逻辑分散（开发）</strong></td>\n<td style=\"text-align: left;\">物理分散，指针连接</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>版本控制工具</strong></td>\n<td style=\"text-align: left;\">Standard Git</td>\n<td style=\"text-align: left;\">Custom (Piper, Mononoke) + Virtual FS</td>\n<td style=\"text-align: left;\">Standard Git (需启用长路径支持)</td>\n<td style=\"text-align: left;\">Standard Git</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>构建一致性</strong></td>\n<td style=\"text-align: left;\">低 (存在一致性延迟)</td>\n<td style=\"text-align: left;\">极高 (原子性)</td>\n<td style=\"text-align: left;\"><strong>高 (通过 Maestro 同步保障)</strong></td>\n<td style=\"text-align: left;\">低 (依赖指针更新，易碎)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>离线构建支持</strong></td>\n<td style=\"text-align: left;\">困难 (需拉取 NuGet 包)</td>\n<td style=\"text-align: left;\">原生支持</td>\n<td style=\"text-align: left;\"><strong>原生支持 (代码实体化)</strong></td>\n<td style=\"text-align: left;\">中等 (需递归 Clone)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>开发环境成本</strong></td>\n<td style=\"text-align: left;\">低 (仅需 Clone 相关库)</td>\n<td style=\"text-align: left;\">高 (需专用工具支持大库)</td>\n<td style=\"text-align: left;\"><strong>中/高 (VMR 庞大，但可选产品库)</strong></td>\n<td style=\"text-align: left;\">低</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>跨组件重构</strong></td>\n<td style=\"text-align: left;\">极难 (多阶段提交)</td>\n<td style=\"text-align: left;\">容易 (原子提交)</td>\n<td style=\"text-align: left;\"><strong>容易 (在 VMR 中原子提交)</strong></td>\n<td style=\"text-align: left;\">困难 (需多库协调)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>文件屏蔽 (Cloaking)</strong></td>\n<td style=\"text-align: left;\">不适用</td>\n<td style=\"text-align: left;\">支持 (构建规则控制)</td>\n<td style=\"text-align: left;\"><strong>原生支持 (同步时过滤)</strong></td>\n<td style=\"text-align: left;\">不支持 (全量拉取)</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"61-与-google-模式的区别\"><strong>6.1 与 Google 模式的区别</strong></h3>\n<p>Google 和 Meta 使用单一的巨型仓库（Monolith），所有开发者直接在其中工作。这需要极其昂贵的定制基础设施（如虚拟文件系统 VFS for Git, Piper）。微软并未强制.NET 社区使用这种重型设施，因为开源贡献者通常只使用标准的 Git 客户端。VMR 作为一个“投影”，兼容了标准 Git 工具链，虽然牺牲了一定的实时性（同步延迟），但换取了对开源社区的友好度 。</p>\n<h3 id=\"62-为什么不直接使用-git-submodules\"><strong>6.2 为什么不直接使用 Git Submodules？</strong></h3>\n<p>Git Submodules 在处理大规模项目时非常脆弱。如果上游仓库重写了历史（Force Push），子模块指针就会失效。此外，Submodules 无法处理“文件屏蔽”需求（即在 Linux 构建中剔除 Windows 二进制文件）。VMR 通过物理复制和补丁机制，彻底解耦了对上游 Git 历史的依赖，实现了更健壮的控制。</p>\n<h2 id=\"7-挑战局限性与未来展望\"><strong>7. 挑战、局限性与未来展望</strong></h2>\n<h3 id=\"71-分支对齐与-snapping\"><strong>7.1 分支对齐与 \"Snapping\"</strong></h3>\n<p>一个主要挑战是如何保持 VMR 分支与数十个产品库分支的精确对齐。特别是在发布窗口期（Snap），所有仓库必须几乎同时切出 release/x.y 分支。现在，这一过程由 VMR 中心化驱动：VMR 先切分支，然后通过自动化工具强制所有下游产品库切分，以防止历史错位 。</p>\n<h3 id=\"72-合并冲突的复杂性\"><strong>7.2 合并冲突的复杂性</strong></h3>\n<p>随着 VMR 变为可写，双向同步带来的合并冲突不可避免。如果一个文件在 VMR 中被修改（重构），同时在产品库中被修改（Bug修复），同步 PR 就会失败。目前这主要依赖人工介入解决。未来的改进方向可能是引入更智能的语义合并工具。</p>\n<h3 id=\"73-基础设施成本\"><strong>7.3 基础设施成本</strong></h3>\n<p>运行 Maestro 服务和频繁的垂直构建对 CI/CD 资源（Azure DevOps）构成了巨大压力。每次同步都需要大量的计算资源来生成补丁、应用补丁并运行全套测试。优化构建效率（如增量构建、缓存复用）是持续优化的重点。</p>\n<h3 id=\"74-未来展望\"><strong>7.4 未来展望</strong></h3>\n<p>展望未来，VMR 可能会逐渐从“镜像”过渡为“主源”。随着 Git 对大仓库支持的改进（如 Scalar, Sparse Checkout 的普及），也许有一天微软会建议所有核心开发者直接在 VMR 上工作，而将拆分的产品库作为只读镜像提供给只需关注特定组件的社区成员。这将彻底反转目前的拓扑结构，进一步简化架构 。</p>\n<h2 id=\"结论\"><strong>结论</strong></h2>\n<p>.NET 虚拟单体存储库 (VMR) 代表了大型开源软件工程领域的一次大胆尝试与创新。它并未盲目照搬 Google 的闭源单体模式，也没有固守传统的多仓库泥潭，而是开创了一条“中间道路”。</p>\n<p>通过 <strong>Maestro</strong> 的智能编排和 <strong>VMR</strong> 的结构化映射，微软成功地在不破坏现有开发生态的前提下，解决了一致性延迟和供应链安全的难题。VMR 不仅实现了 Linux 发行版的合规性要求，更为.NET 平台未来的长期演进提供了坚实的架构基础。对于任何面临微服务碎片化治理、跨组件协作困难以及构建一致性挑战的大型软件组织而言，.NET VMR 的架构设计都提供了极具价值的参考范式。</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>\n<img src=\"https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg\" width=\"170\" />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 22:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shanyou\">张善友</a>&nbsp;\n阅读(<span id=\"post_view_count\">98</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI Agent 框架探秘：拆解 OpenHands（3）--- 启动",
      "link": "https://www.cnblogs.com/rossiXYZ/p/19530105",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/rossiXYZ/p/19530105\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 20:55\">\n    <span>AI Agent 框架探秘：拆解 OpenHands（3）--- 启动</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"ai-agent-框架探秘拆解-openhands3----启动\">AI Agent 框架探秘：拆解 OpenHands（3）--- 启动</h1>\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">目录</div><ul><li><a href=\"#ai-agent-框架探秘拆解-openhands3----启动\" rel=\"noopener nofollow\">AI Agent 框架探秘：拆解 OpenHands（3）--- 启动</a><ul><li><a href=\"#0x00-概要\" rel=\"noopener nofollow\">0x00 概要</a></li><li><a href=\"#0x01-背景\" rel=\"noopener nofollow\">0x01 背景</a><ul><li><a href=\"#11-总体架构\" rel=\"noopener nofollow\">1.1 总体架构</a></li><li><a href=\"#12-切入点\" rel=\"noopener nofollow\">1.2 切入点</a></li></ul></li><li><a href=\"#0x02-初始化--run_controller\" rel=\"noopener nofollow\">0x02 初始化 @ run_controller</a><ul><li><a href=\"#21-总体流程\" rel=\"noopener nofollow\">2.1 总体流程</a></li><li><a href=\"#22-创建注册中心\" rel=\"noopener nofollow\">2.2 创建注册中心</a></li><li><a href=\"#23-创建agent\" rel=\"noopener nofollow\">2.3 创建Agent</a></li><li><a href=\"#24-构建runtime\" rel=\"noopener nofollow\">2.4 构建Runtime</a></li><li><a href=\"#25-构建memory--microagent\" rel=\"noopener nofollow\">2.5 构建Memory &amp; Microagent</a><ul><li><a href=\"#251-创建-memory\" rel=\"noopener nofollow\">2.5.1 创建 Memory</a></li><li><a href=\"#252-创建microagent\" rel=\"noopener nofollow\">2.5.2 创建Microagent</a></li></ul></li><li><a href=\"#26-创建mcp\" rel=\"noopener nofollow\">2.6 创建MCP</a></li><li><a href=\"#27-创建controller\" rel=\"noopener nofollow\">2.7 创建Controller</a></li><li><a href=\"#28-发送启动事件\" rel=\"noopener nofollow\">2.8 发送启动事件</a></li><li><a href=\"#29-订阅事件流注册用户输入回调函数\" rel=\"noopener nofollow\">2.9 订阅事件流：注册用户输入回调函数</a></li><li><a href=\"#210-运行代理\" rel=\"noopener nofollow\">2.10 运行代理</a></li><li><a href=\"#211-run_controller全部代码\" rel=\"noopener nofollow\">2.11 run_controller全部代码</a></li></ul></li><li><a href=\"#0xff-参考\" rel=\"noopener nofollow\">0xFF 参考</a></li></ul></li></ul></div><p></p>\n<h2 id=\"0x00-概要\">0x00 概要</h2>\n<p>当分析一个系统时，启动部分和用户典型使用场景是比较理想的切入点，因为这两个部分可以覆盖系统大部分功能模块，可以借此深入架构。</p>\n<p>因为本系列借鉴的文章过多，可能在参考文献中有遗漏的文章，如果有，还请大家指出。</p>\n<h2 id=\"0x01-背景\">0x01 背景</h2>\n<h3 id=\"11-总体架构\">1.1 总体架构</h3>\n<p>以下是 OpenHands 的架构图，这是一个复杂的系统。</p>\n<p><img alt=\"Openhands-arch\" class=\"lazyload\" /></p>\n<p>抛开复杂的技术细节，OpenHands Agent 的交互逻辑可提炼为 “初始化 - 事件注入 - 协同处理 - 等待” 的极简流程，核心围绕 EventStream 实现模块联动：</p>\n<ul>\n<li>初始化就绪：用户创建会话时，系统自动完成 Agent、AgentController、Runtime、Memory 有核心模块的初始化，且每个模块都会自动订阅 EventStream，确保能捕获相关事件；</li>\n<li>任务发起：用户发送消息本质是向 EventStream 中注入一条事件，这条事件会触发所有订阅相关回调函数的模块，启动协同处理；</li>\n<li>多模块协同响应：\n<ul>\n<li>Session 模块持续上报事件流中的各类状态事件，保障全局可观测；</li>\n<li>若用户开启 Security Analyzer，该模块会通过安全分析，自动确认低风险任务，减少用户手动干预；</li>\n<li>AgentController 向事件流注入 RecallAction，Memory 模块判断是否为首次接收的用户信息，据此补充相关记忆并返回 RecallObservation 事件；</li>\n</ul>\n</li>\n<li>状态同步：AgentController 更新任务当前状态，并将相关信息传递给 Agent。即AgentController 调用 <code>Agent.step</code> 方法处理当前事件，生成 Action 并注入事件流。</li>\n<li>行动决策：Agent 基于接收的状态信息，向 LLM 发起请求，生成下一步具体行动方案；</li>\n<li>行动输出：Agent 明确输出行动指令，可能是运行系统命令、读取文件、调用工具等具体操作；</li>\n<li>行动分发：该行动指令通过 EventStream 传递至 Runtime 组件，等待执行；</li>\n<li>执行与反馈：Runtime 执行行动指令，生成包含执行结果、错误信息等内容的观察结果；</li>\n<li>结果回传：观察结果通过 EventStream 回传给 AgentController，完成一次执行闭环；</li>\n<li>循环或终止：AgentController 根据观察结果判断任务是否完成，若未完成则重复上述流程；若需协同，则委派给其他 Agent，直至任务结束。</li>\n</ul>\n<h3 id=\"12-切入点\">1.2 切入点</h3>\n<p>以下是一个例子。我们由此进入，看看OpenHands如何启动，也可以从此处看看OpenHands的基本逻辑。</p>\n<pre><code class=\"language-python\">config = load_openhands_config()\naction = MessageAction(content=\"Write a hello world program\")\nstate = await run_controller(config=config, initial_user_action=action)\n</code></pre>\n<p>上述代码是直接命令行调用 run_controller，因此我们从run_controller入手。</p>\n<h2 id=\"0x02-初始化--run_controller\">0x02 初始化 @ run_controller</h2>\n<p>run_controller 作为 OpenHands 后端单个会话的核心入口协程，核心职责是依据预设配置启动运行时环境、智能体及对应控制器，搭建起从接收用户指令到多步骤执行任务，再到最终将会话状态持久化存储的完整处理链路。其核心设计亮点体现在三方面：</p>\n<ul>\n<li>实现会话全生命周期的一体化管理，集中完成会话标识（SID）生成、运行时连接建立、代码仓库克隆、MCP 工具嵌入及任务执行轨迹重放等关键操作；</li>\n<li>构建双重安全管控机制，通过设置最大迭代次数（max_iterations）与单任务最高预算（max_budget_per_task）的硬性限制，有效规避无限循环执行与资源费用超额的风险；</li>\n<li>强化全流程可观测性，借助 EventStream 实现事件实时分发，支持命令行界面（CLI）、前端界面、日志系统等多端同步订阅，同时生成可回放、可审计的 JSON 格式执行轨迹，便于后续追溯与核查。</li>\n</ul>\n<h3 id=\"21-总体流程\">2.1 总体流程</h3>\n<p>openhands\\core\\main.py 的 run_controller 的总体流程如下。</p>\n<ul>\n<li>初始化系统组件\n<ul>\n<li>创建Agent。</li>\n<li>创建runtime和内存系统</li>\n<li>创建controller。</li>\n</ul>\n</li>\n<li>运行Agent，具体会:\n<ul>\n<li>管理任务执行流程。\n<ul>\n<li>接收初始用户操作</li>\n<li>处理事件流中的各种事件。</li>\n<li>监听agent状态变化，特别是等待用户输入的状态。</li>\n</ul>\n</li>\n<li>处理用户交互。\n<ul>\n<li>当agent需要用户输入时，依据配置进行自动响应或者等待真实用户输入。</li>\n<li>支持mock用户响应函数fake_user_response_fn，这样可以自动化测试。</li>\n</ul>\n</li>\n<li>状态管理和持久化。\n<ul>\n<li>保存会话状态到文件。</li>\n<li>记录执行轨迹，这样可以分析调试。</li>\n<li>支持轨迹重放。</li>\n</ul>\n</li>\n<li>资源管理。\n<ul>\n<li>管理MCP集成。</li>\n<li>控制执行预算（迭代次数和费用限制）</li>\n<li>正确关闭资源。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>具体流程图如下。</p>\n<p><img alt=\"OpenHands-3-1\" class=\"lazyload\" /></p>\n<p>我们接下来看看具体流程细节。</p>\n<h3 id=\"22-创建注册中心\">2.2 创建注册中心</h3>\n<p>下面语句会创建 LLM 注册中心 &amp; 对话统计实例。</p>\n<pre><code class=\"language-python\">    sid = sid or generate_sid(config)\n\n    llm_registry, conversation_stats, config = create_registry_and_conversation_stats(\n        config,\n        sid,\n        None,\n    )\n</code></pre>\n<p>具体代码如下，其功能是:</p>\n<ol>\n<li>根据用户设置调整基础配置</li>\n<li>初始化LLM注册表（管理所有LLM实例）</li>\n<li>初始化文件存储和对话统计器（跟踪对话数据）</li>\n<li>建立注册表与统计器的订阅关系</li>\n</ol>\n<pre><code class=\"language-python\">def create_registry_and_conversation_stats(\n    config: OpenHandsConfig,\n    sid: str,\n    user_id: Optional[str],\n    user_settings: Optional[Settings] = None,\n) -&gt; tuple[LLMRegistry, ConversationStats, OpenHandsConfig]:\n    \"\"\"\n    创建LLM注册表、对话统计实例和用户配置的组合函数。\n    \n    参数：\n        config: 基础配置对象\n        sid: 会话ID（用于标识当前对话）\n        user_id: 用户ID（可选，用于用户级数据跟踪）\n        user_settings: 用户自定义设置（可选，用于覆盖默认配置）\n    \n    返回：\n        三元组 (LLM注册表, 对话统计实例, 最终用户配置)\n    \"\"\"\n    # 初始化用户配置（优先使用用户设置覆盖默认配置）\n    user_config = config\n    if user_settings:\n        user_config = setup_llm_config(config, user_settings)\n\n    # 确定代理类型（从用户设置或默认配置中获取）\n    agent_cls = user_settings.agent if user_settings else None\n    # 创建LLM注册表，关联配置和代理类型\n    llm_registry = LLMRegistry(user_config, agent_cls)\n    \n    # 初始化文件存储（用于持久化对话数据）\n    file_store = get_file_store(\n        file_store_type=config.file_store,\n        file_store_path=config.file_store_path,\n        file_store_web_hook_url=config.file_store_web_hook_url,\n        file_store_web_hook_headers=config.file_store_web_hook_headers,\n        file_store_web_hook_batch=config.file_store_web_hook_batch,\n    )\n    \n    # 创建对话统计实例（绑定文件存储、会话ID和用户ID）\n    conversation_stats = ConversationStats(file_store, sid, user_id)\n    # 订阅注册表事件：当新LLM注册时，自动记录到对话统计中\n    llm_registry.subscribe(conversation_stats.register_llm)\n    \n    return llm_registry, conversation_stats, user_config\n</code></pre>\n<h3 id=\"23-创建agent\">2.3 创建Agent</h3>\n<p>此处会根据config信息来创建agent。</p>\n<pre><code class=\"language-python\">agent = create_agent(config, llm_registry)\n</code></pre>\n<p>create_agent代码如下，从缺省配置可以看到，默认生成CodeActAgent。</p>\n<pre><code class=\"language-python\">#default_agent = \"CodeActAgent\"\n\ndef create_agent(config: OpenHandsConfig, llm_registry: LLMRegistry) -&gt; Agent:\n    agent_cls: type[Agent] = Agent.get_cls(config.default_agent)\n    agent_config = config.get_agent_config(config.default_agent)\n    # Pass the runtime information from the main config to the agent config\n    agent_config.runtime = config.runtime\n    config.get_llm_config_from_agent(config.default_agent)\n    agent = agent_cls(config=agent_config, llm_registry=llm_registry)\n    return agent\n</code></pre>\n<p>CodeActAgent 定义如下。</p>\n<pre><code class=\"language-python\">class CodeActAgent(Agent):\n    \"\"\"\n    CodeActAgent：极简主义的智能代理，基于 CodeAct 理念实现。\n    核心逻辑：将模型的行动统一到“代码执行”这一单一行动空间，通过传递“行动-观察”对列表，\n    引导模型决策下一步操作，兼顾简洁性与执行性能。\n\n    核心理念（源自论文：https://arxiv.org/abs/2402.01030）：\n    打破传统代理多行动类型的复杂设计，用代码执行统一所有行动，既简化架构又提升效率。\n\n    每一轮交互中，代理可执行两种操作：\n    1. **对话（Converse）**：用自然语言与人类沟通，例如请求澄清需求、确认操作等。\n    2. **代码行动（CodeAct）**：通过执行代码完成任务，支持两种形式：\n       - 执行任意有效的 Linux bash 命令\n       - 执行任意有效的 Python 代码（通过交互式 IPython 解释器模拟，\n         实际通过 bash 命令实现，详见插件系统说明）\n    \"\"\"\n    VERSION = '2.2'  # 代理版本号\n\n    # 沙盒环境所需插件依赖（按初始化顺序排列）\n    sandbox_plugins: list[PluginRequirement] = [\n        # 注意：AgentSkillsRequirement 需在 JupyterRequirement 之前初始化\n        # 原因：AgentSkillsRequirement 提供大量 Python 工具函数，\n        # Jupyter 环境需要依赖这些函数才能正常工作\n        AgentSkillsRequirement(),  # 提供代理核心技能函数的插件\n        JupyterRequirement(),      # 提供交互式 Python 执行环境的插件\n    ]\n\n    def __init__(self, config: AgentConfig, llm_registry: LLMRegistry) -&gt; None:\n        \"\"\"\n        初始化 CodeActAgent 实例。\n\n        参数：\n            config (AgentConfig)：当前代理的配置对象（包含模型路由、记忆策略等）\n            llm_registry (LLMRegistry)：LLM 注册表实例，用于获取所需 LLM 或路由 LLM\n        \"\"\"\n        # 调用父类 Agent 的初始化方法，完成基础配置（如 LLM 注册、提示词管理器初始化）\n        super().__init__(config, llm_registry)\n        \n        self.pending_actions: deque['Action'] = deque()  # 待执行的行动队列（双端队列，支持高效进出）\n        self.reset()  # 重置代理状态（初始化行动历史、观察记录等）\n        self.tools = self._get_tools()  # 获取代理可使用的工具集（从插件或配置中提取）\n\n        # 初始化对话记忆实例：存储“行动-观察”对，支持记忆压缩、上下文管理\n        self.conversation_memory = ConversationMemory(self.config, self.prompt_manager)\n\n        # 初始化上下文压缩器：根据配置创建 Condenser 实例，用于压缩长对话历史\n        self.condenser = Condenser.from_config(self.config.condenser, llm_registry)\n\n        # 覆盖父类的 LLM 实例：如需模型路由，优先使用路由 LLM（根据代理配置动态选择模型）\n        self.llm = self.llm_registry.get_router(self.config)\n</code></pre>\n<p>具体参见下图。</p>\n<p><img alt=\"image-20251019171311325\" class=\"lazyload\" /></p>\n<p>CodeActAgent的初始化流程图如下。</p>\n<p><img alt=\"Openhands-3-2\" class=\"lazyload\" /></p>\n<h3 id=\"24-构建runtime\">2.4 构建Runtime</h3>\n<p>create_runtime()构建了AI 代理的 “专属工作间”Runtime。在OpenHands系统中，Runtime扮演着至关重要的角色，它为人工智能代理提供了一个稳定且可控的操作平台。</p>\n<pre><code class=\"language-python\">    # 运行时创建后会自动连接并克隆选定的代码仓库\n    repo_directory = None\n    if runtime is None:\n        # 初始化代码仓库（如需）\n        repo_tokens = get_provider_tokens()\n        # 创建运行时实例\n        runtime = create_runtime(\n            config,\n            llm_registry,\n            sid=sid,\n            headless_mode=headless_mode,\n            agent=agent,\n            git_provider_tokens=repo_tokens,\n        )\n        # 同步调用异步的运行时连接方法\n        call_async_from_sync(runtime.connect)\n\n        # 初始化代码仓库（如需）\n        if config.sandbox.selected_repo:\n            repo_directory = initialize_repository_for_runtime(\n                runtime,\n                immutable_provider_tokens=repo_tokens,\n                selected_repository=config.sandbox.selected_repo,\n            )\n            \n    # event_stream 是  event_stream = EventStream(session_id, file_store)        \n    event_stream = runtime.event_stream        \n</code></pre>\n<p>Runtime 的<code>__init__</code>会注册EventStreamSubscriber.RUNTIME。</p>\n<pre><code class=\"language-python\">        self.event_stream = event_stream\n        if event_stream:\n            event_stream.subscribe(\n                EventStreamSubscriber.RUNTIME, self.on_event, self.sid\n            )\n</code></pre>\n<p><code>Runtime</code>只处理可运行的<code>Action</code>事件，执行动作拿到输出<code>Observation</code>发送回事件流中</p>\n<ul>\n<li><code>isinstance(event, MCPAction)</code>执行MCP获取结果</li>\n</ul>\n<ul>\n<li>其他runtime支持的action则执行获取结果</li>\n</ul>\n<h3 id=\"25-构建memory--microagent\">2.5 构建Memory &amp; Microagent</h3>\n<p>接下来初始化memory，</p>\n<pre><code class=\"language-python\">    # when memory is created, it will load the microagents from the selected repository\n    if memory is None:\n        memory = create_memory(\n            runtime=runtime,\n            event_stream=event_stream,\n            sid=sid,\n            selected_repository=config.sandbox.selected_repo,\n            repo_directory=repo_directory,\n            conversation_instructions=conversation_instructions,\n            working_dir=str(runtime.workspace_root),\n        )\n\n</code></pre>\n<h4 id=\"251-创建-memory\">2.5.1 创建 Memory</h4>\n<p>create_memory 函数会创建memory。</p>\n<pre><code class=\"language-python\">def create_memory(\n    runtime: Runtime,\n    event_stream: EventStream,\n    sid: str,\n    selected_repository: str | None = None,\n    repo_directory: str | None = None,\n    status_callback: Callable | None = None,\n    conversation_instructions: str | None = None,\n    working_dir: str = DEFAULT_WORKSPACE_MOUNT_PATH_IN_SANDBOX,\n) -&gt; Memory:\n    \"\"\"Create a memory for the agent to use.\n\n    Args:\n        runtime: The runtime to use.\n        event_stream: The event stream it will subscribe to.\n        sid: The session id.\n        selected_repository: The repository to clone and start with, if any.\n        repo_directory: The repository directory, if any.\n        status_callback: Optional callback function to handle status updates.\n        conversation_instructions: Optional instructions that are passed to the agent\n    \"\"\"\n    memory = Memory(\n        event_stream=event_stream,\n        sid=sid,\n        status_callback=status_callback,\n    )\n\n    memory.set_conversation_instructions(conversation_instructions)\n\n    if runtime:\n        # sets available hosts\n        memory.set_runtime_info(runtime, {}, working_dir)\n\n        # loads microagents from repo/.openhands/microagents\n        microagents: list[BaseMicroagent] = runtime.get_microagents_from_selected_repo(\n            selected_repository\n        )\n        memory.load_user_workspace_microagents(microagents)\n\n        if selected_repository and repo_directory:\n            memory.set_repository_info(selected_repository, repo_directory)\n\n    return memory\n\n\n</code></pre>\n<p>memory初始化的时候有一个event_stream的订阅，会注册 EventStreamSubscriber.MEMORY，当有event的时候Memory 的<code>on_event</code>方法会被调用。</p>\n<pre><code class=\"language-python\">self.event_stream.subscribe(\n            EventStreamSubscriber.MEMORY,\n            self.on_event,\n            self.sid,\n        )\n\n\n</code></pre>\n<p><code>Memory</code>只处理<code>RecallAction</code>，对于用户首次输入信息则将一些额外的工作空间上下文信息添加到<code>RecallObservation</code>发送回事件流中，对于其他非用户首次的输入信息则加入<code>microagent knowledge(领域强化提示词)</code>到<code>RecallObservation</code>发送回事件流中。</p>\n<h4 id=\"252-创建microagent\">2.5.2 创建Microagent</h4>\n<p>create_memory函数中会加载Microagent。</p>\n<pre><code class=\"language-python\">        # loads microagents from repo/.openhands/microagents\n        microagents: list[BaseMicroagent] = runtime.get_microagents_from_selected_repo(\n            selected_repository\n        )\n        memory.load_user_workspace_microagents(microagents)\n\n</code></pre>\n<p>Microagent是主代理的“专业合作伙伴”。</p>\n<p>为了高效完成复杂任务，通常需要专业的分工协作，Microagent正是为了这一目的而设计的“专业执行者”。当主代理在执行任务时遇到特定领域的细分工作，它不必亲自处理，而是可以将这部分任务“委托”给相应的Microagent，从而利用其专业能力提高效率和准确性。</p>\n<p>从本质上讲，Microagent同样基于大型语言模型构建，比如，其独特之处可以是其内置的专业提示词（Prompt）。这些提示词中融入了特定领域的知识准则与操作规范，例如，与Git相关的Microagent，其提示词会包含Git操作的核心技巧与最佳实践，能够引导模型更精确地处理与Git相关的任务，成为主代理应对细分场景的“得力助手”。</p>\n<p>BaseMicroagent 定义如下：</p>\n<pre><code class=\"language-python\">class BaseMicroagent(BaseModel):\n    \"\"\"Base class for all microagents.\"\"\"\n\n    name: str\n    content: str\n    metadata: MicroagentMetadata\n    source: str  # path to the file\n    type: MicroagentType\n\n    PATH_TO_THIRD_PARTY_MICROAGENT_NAME: ClassVar[dict[str, str]] = {\n        '.cursorrules': 'cursorrules',\n        'agents.md': 'agents',\n        'agent.md': 'agents',\n    }\n\n</code></pre>\n<h3 id=\"26-创建mcp\">2.6 创建MCP</h3>\n<p>接下来会创建MCP相关部分。</p>\n<pre><code class=\"language-python\">    # Add MCP tools to the agent\n    if agent.config.enable_mcp:\n        # Add OpenHands' MCP server by default\n        _, openhands_mcp_stdio_servers = (\n            OpenHandsMCPConfigImpl.create_default_mcp_server_config(\n                config.mcp_host, config, None\n            )\n        )\n        runtime.config.mcp.stdio_servers.extend(openhands_mcp_stdio_servers)\n\n        await add_mcp_tools_to_agent(agent, runtime, memory)\n\n</code></pre>\n<h3 id=\"27-创建controller\">2.7 创建Controller</h3>\n<p>接下来会创建AgentController。</p>\n<p>AgentController 是 OpenHands 系统中的核心控制器组件，负责管理代理（Agent）的整个生命周期和行为。是代理与系统其他组件之间的桥梁，确保代理可以安全有效地执行任务，同时管理系统资源。</p>\n<p><code>AgentController</code>作为主要状态管理模块，</p>\n<ul>\n<li>根据<code>Observation</code>事件进行状态变换</li>\n<li>根据<code>Action</code>进行状态变换和以下处理：\n<ul>\n<li>对于<code>MessageAction</code>发送<code>RecallAction</code>到事件流中</li>\n<li>对于<code>AgentDelegateAction</code>做Agent路由（后续机制解读中再详细介绍）</li>\n</ul>\n</li>\n<li>根据当前的<code>event</code>判断进行调用<code>agent.step</code></li>\n</ul>\n<pre><code class=\"language-python\">    controller, initial_state = create_controller(\n        agent, runtime, config, conversation_stats, replay_events=replay_events\n    )\n\n</code></pre>\n<p>create_controller代码如下。</p>\n<pre><code class=\"language-python\">def create_controller(\n    agent: Agent,\n    runtime: Runtime,\n    config: OpenHandsConfig,\n    conversation_stats: ConversationStats,\n    headless_mode: bool = True,\n    replay_events: list[Event] | None = None,\n) -&gt; tuple[AgentController, State | None]:\n    event_stream = runtime.event_stream\n    initial_state = None\n    initial_state = State.restore_from_session(\n            event_stream.sid, event_stream.file_store)\n    controller = AgentController(\n        agent=agent,\n        conversation_stats=conversation_stats,\n        iteration_delta=config.max_iterations,\n        budget_per_task_delta=config.max_budget_per_task,\n        agent_to_llm_config=config.get_agent_to_llm_config_map(),\n        event_stream=event_stream,\n        initial_state=initial_state,\n        headless_mode=headless_mode,\n        confirmation_mode=config.security.confirmation_mode,\n        replay_events=replay_events,\n        security_analyzer=runtime.security_analyzer,\n    )\n    return (controller, initial_state)\n\n\n</code></pre>\n<p>在 AgentController 的<code>__init__</code>中，会注册EventStreamSubscriber.AGENT_CONTROLLER。</p>\n<pre><code class=\"language-python\">        # subscribe to the event stream if this is not a delegate\n        if not self.is_delegate:\n            self.event_stream.subscribe(\n                EventStreamSubscriber.AGENT_CONTROLLER, self.on_event, self.id\n            )\n\n</code></pre>\n<h3 id=\"28-发送启动事件\">2.8 发送启动事件</h3>\n<p>发送一个启动事件MessageAction。</p>\n<pre><code class=\"language-python\">    # start event is a MessageAction with the task, either resumed or new\n    if initial_state is not None and initial_state.last_error:\n        # we're resuming the previous session\n        event_stream.add_event(\n            MessageAction(\n                content=(\n                    \"Let's get back on track. If you experienced errors before, do \"\n                    'NOT resume your task. Ask me about it.'\n                ),\n            ),\n            EventSource.USER,\n        )\n    else:\n        # init with the provided actions\n        event_stream.add_event(initial_user_action, EventSource.USER)\n\n</code></pre>\n<h3 id=\"29-订阅事件流注册用户输入回调函数\">2.9 订阅事件流：注册用户输入回调函数</h3>\n<p>把自己注册为 EventStreamSubscriber.MAIN。</p>\n<pre><code class=\"language-python\">    def on_event(event: Event) -&gt; None:\n        if isinstance(event, AgentStateChangedObservation):\n            if event.agent_state == AgentState.AWAITING_USER_INPUT:\n                if exit_on_message:\n                    message = '/exit'\n                elif fake_user_response_fn is None:\n                    message = read_input(config.cli_multiline_input)\n                else:\n                    message = fake_user_response_fn(controller.get_state())\n                action = MessageAction(content=message)\n                event_stream.add_event(action, EventSource.USER)\n\n    event_stream.subscribe(EventStreamSubscriber.MAIN, on_event, sid)\n\n    end_states = [\n        AgentState.FINISHED,\n        AgentState.REJECTED,\n        AgentState.ERROR,\n        AgentState.PAUSED,\n        AgentState.STOPPED,\n    ]\n\n</code></pre>\n<p>几个模块的初始化范式基本一致，在<code>__init__</code>函数中完成模块的初始化准备工作，并且向事件流中订阅消息并注册各自模块的消息处理函数。事件回调函数会根据当前的事件进行状态机的状态转移。</p>\n<ul>\n<li>Runtime 在事件流中订阅 EventStreamSubscriber.RUNTIME，事件回调函数会处理需要runtine处理的action，比如mcp/tool等等。</li>\n<li>Memory 在事件流中订阅 EventStreamSubscriber.MEMORY。事件回调函数根据当前的<code>event</code>生成一个带<code>microagent_knowledge</code>的<code>Observation</code>并以<code>ENVIRONMENT</code>作为源添加回事件流中，这里的<code>microagent_knowledge</code>是一种特定提示词增强的方法。</li>\n<li>AgentController 在事件流中订阅 EventStreamSubscriber.AGENT_CONTROLLER。</li>\n<li>run_controller 在事件流中订阅 EventStreamSubscriber.MAIN。</li>\n</ul>\n<h3 id=\"210-运行代理\">2.10 运行代理</h3>\n<p>运行代理直到进入结束状态。</p>\n<pre><code class=\"language-python\">    try:\n        await run_agent_until_done(controller, runtime, memory, end_states)\n    except Exception as e:\n        logger.error(f'Exception in main loop: {e}')\n\n    # save session when we're about to close\n    if config.file_store is not None and config.file_store != 'memory':\n        end_state = controller.get_state()\n        # NOTE: the saved state does not include delegates events\n        end_state.save_to_session(\n            event_stream.sid, event_stream.file_store, event_stream.user_id\n        )\n\n    await controller.close(set_stop_state=False)\n\n</code></pre>\n<h3 id=\"211-run_controller全部代码\">2.11 run_controller全部代码</h3>\n<p>run_controller全部代码如下：</p>\n<pre><code class=\"language-python\">async def run_controller(\n    config: OpenHandsConfig,\n    initial_user_action: Action,\n    sid: str | None = None,\n    runtime: Runtime | None = None,\n    exit_on_message: bool = False,\n    fake_user_response_fn: FakeUserResponseFunc | None = None,\n    headless_mode: bool = True,\n    memory: Memory | None = None,\n    conversation_instructions: str | None = None,\n) -&gt; State | None:\n    \"\"\"主协程，用于运行代理控制器，支持灵活的任务输入。\n    仅在通过命令行直接启动 OpenHands 后端时使用。\n\n    参数:\n        config: 应用配置实例\n        initial_user_action: 包含初始用户输入的 Action 对象\n        sid: (可选) 会话 ID。重要提示：非必要请勿手动设置，\n             错误设置可能导致 RemoteRuntime 出现异常行为\n        runtime: (可选) 代理运行的运行时环境实例\n        exit_on_message: 当代理请求用户消息时退出（可选）\n        fake_user_response_fn: (可选) 接收当前状态并返回模拟用户响应的函数\n        headless_mode: 代理是否以无头模式运行\n\n    返回:\n        代理的最终状态；若发生错误则返回 None\n\n    异常:\n        AssertionError: 若 initial_user_action 不是 Action 实例\n        Exception: 执行过程中可能抛出各类异常，均会被记录日志\n\n    注意:\n        - 状态持久化：若配置了 config.file_store，代理状态将在会话间保存\n        - 执行轨迹：若配置了 config.trajectories_path，执行历史将以 JSON 格式保存用于分析\n        - 预算控制：执行受 config.max_iterations 和 config.max_budget_per_task 限制\n\n    示例:\n        &gt;&gt;&gt; config = load_openhands_config()\n        &gt;&gt;&gt; action = MessageAction(content=\"Write a hello world program\")\n        &gt;&gt;&gt; state = await run_controller(config=config, initial_user_action=action)\n    \"\"\"\n    # 若未提供会话ID，则生成一个\n    sid = sid or generate_sid(config)\n\n    # 创建 LLM 注册中心、对话统计实例，并处理配置\n    llm_registry, conversation_stats, config = create_registry_and_conversation_stats(\n        config,\n        sid,\n        None,\n    )\n\n    # 基于配置和 LLM 注册中心创建代理实例\n    agent = create_agent(config, llm_registry)\n\n    # 运行时创建后会自动连接并克隆选定的代码仓库\n    repo_directory = None\n    if runtime is None:\n        # 初始化代码仓库（如需）\n        repo_tokens = get_provider_tokens()\n        # 创建运行时实例\n        runtime = create_runtime(\n            config,\n            llm_registry,\n            sid=sid,\n            headless_mode=headless_mode,\n            agent=agent,\n            git_provider_tokens=repo_tokens,\n        )\n        # 同步调用异步的运行时连接方法\n        call_async_from_sync(runtime.connect)\n\n        # 初始化代码仓库（如需）\n        if config.sandbox.selected_repo:\n            repo_directory = initialize_repository_for_runtime(\n                runtime,\n                immutable_provider_tokens=repo_tokens,\n                selected_repository=config.sandbox.selected_repo,\n            )\n\n    # 从运行时获取事件流实例（组件间通信核心）\n    event_stream = runtime.event_stream\n\n    # 记忆系统创建后会从选定仓库加载微代理\n    if memory is None:\n        # 创建记忆系统实例\n        memory = create_memory(\n            runtime=runtime,\n            event_stream=event_stream,\n            sid=sid,\n            selected_repository=config.sandbox.selected_repo,\n            repo_directory=repo_directory,\n            conversation_instructions=conversation_instructions,\n            working_dir=str(runtime.workspace_root),\n        )\n\n    # 为代理添加 MCP 工具（若启用）\n    if agent.config.enable_mcp:\n        # 默认添加 OpenHands 的 MCP 服务器配置\n        _, openhands_mcp_stdio_servers = (\n            OpenHandsMCPConfigImpl.create_default_mcp_server_config(\n                config.mcp_host, config, None\n            )\n        )\n        runtime.config.mcp.stdio_servers.extend(openhands_mcp_stdio_servers)\n\n        # 异步将 MCP 工具添加到代理\n        await add_mcp_tools_to_agent(agent, runtime, memory)\n\n    # 加载回放事件（若启用轨迹回放）\n    replay_events: list[Event] | None = None\n    if config.replay_trajectory_path:\n        logger.info('Trajectory replay is enabled')\n        # 断言初始用户动作必须是空动作（回放场景）\n        assert isinstance(initial_user_action, NullAction)\n        # 从指定路径加载回放日志和初始用户动作\n        replay_events, initial_user_action = load_replay_log(\n            config.replay_trajectory_path\n        )\n\n    # 创建控制器和初始状态\n    controller, initial_state = create_controller(\n        agent, runtime, config, conversation_stats, replay_events=replay_events\n    )\n\n    # 断言初始用户动作必须是 Action 实例，否则抛出异常\n    assert isinstance(initial_user_action, Action), (\n        f'initial user actions must be an Action, got {type(initial_user_action)}'\n    )\n    # 记录调试日志：控制器初始化信息\n    logger.debug(\n        f'Agent Controller Initialized: Running agent {agent.name}, model '\n        f'{agent.llm.config.model}, with actions: {initial_user_action}'\n    )\n\n    # 发送启动事件（恢复会话或新会话）\n    if initial_state is not None and initial_state.last_error:\n        # 恢复之前的会话（存在历史错误）\n        event_stream.add_event(\n            MessageAction(\n                content=(\n                    \"Let's get back on track. If you experienced errors before, do \"\n                    'NOT resume your task. Ask me about it.'\n                ),\n            ),\n            EventSource.USER,\n        )\n    else:\n        # 新会话：添加初始用户动作到事件流\n        event_stream.add_event(initial_user_action, EventSource.USER)\n\n    # 定义事件回调函数：处理代理等待用户输入的场景\n    def on_event(event: Event) -&gt; None:\n        # 监听代理状态变更事件\n        if isinstance(event, AgentStateChangedObservation):\n            # 当代理进入等待用户输入状态时\n            if event.agent_state == AgentState.AWAITING_USER_INPUT:\n                if exit_on_message:\n                    # 需退出时发送 /exit 指令\n                    message = '/exit'\n                elif fake_user_response_fn is None:\n                    # 读取真实用户输入\n                    message = read_input(config.cli_multiline_input)\n                else:\n                    # 调用模拟用户响应函数\n                    message = fake_user_response_fn(controller.get_state())\n                # 创建消息动作并添加到事件流\n                action = MessageAction(content=message)\n                event_stream.add_event(action, EventSource.USER)\n\n    # 订阅事件流：注册 MAIN 订阅者和回调函数\n    event_stream.subscribe(EventStreamSubscriber.MAIN, on_event, sid)\n\n    # 定义代理结束状态列表\n    end_states = [\n        AgentState.FINISHED,\n        AgentState.REJECTED,\n        AgentState.ERROR,\n        AgentState.PAUSED,\n        AgentState.STOPPED,\n    ]\n\n    try:\n        # 运行代理直到进入结束状态\n        await run_agent_until_done(controller, runtime, memory, end_states)\n    except Exception as e:\n        # 记录主循环异常日志\n        logger.error(f'Exception in main loop: {e}')\n\n    # 关闭前保存会话（若配置文件存储）\n    if config.file_store is not None and config.file_store != 'memory':\n        end_state = controller.get_state()\n        # 注意：保存的状态不包含委托事件\n        end_state.save_to_session(\n            event_stream.sid, event_stream.file_store, event_stream.user_id\n        )\n\n    # 关闭控制器（不设置停止状态）\n    await controller.close(set_stop_state=False)\n\n    # 获取控制器最终状态\n    state = controller.get_state()\n\n    # 保存执行轨迹（若配置）\n    if config.save_trajectory_path is not None:\n        # 若路径是文件夹，则以会话ID为文件名\n        if os.path.isdir(config.save_trajectory_path):\n            file_path = os.path.join(config.save_trajectory_path, sid + '.json')\n        else:\n            file_path = config.save_trajectory_path\n        # 创建目录（如需）\n        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n        # 获取执行轨迹历史\n        histories = controller.get_trajectory(config.save_screenshots_in_trajectory)\n        # 写入 JSON 文件\n        with open(file_path, 'w') as f:  # noqa: ASYNC101\n            json.dump(histories, f, indent=4)\n\n    # 返回最终状态\n    return state\n\n</code></pre>\n<h2 id=\"0xff-参考\">0xFF 参考</h2>\n<p><a href=\"https://docs.all-hands.dev/openhands/usage/architecture/backend\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.all-hands.dev/openhands/usage/architecture/backend</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1936485868761257658\" rel=\"noopener nofollow\" target=\"_blank\">当AI Agent从“玩具”走向“工具”，我们该关注什么？Openhands架构解析【第二篇：Agent 相关核心概念】</a>  <a href=\"https://www.zhihu.com/people/dreamrenderx\" rel=\"noopener nofollow\" target=\"_blank\">克里</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1936175201323825087\" rel=\"noopener nofollow\" target=\"_blank\">当AI Agent从“玩具”走向“工具”，我们该关注什么？Openhands架构解析【第一篇：系列导读】</a> <a href=\"https://www.zhihu.com/people/dreamrenderx\" rel=\"noopener nofollow\" target=\"_blank\">克里</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1940436682949244630\" rel=\"noopener nofollow\" target=\"_blank\">Coding Agent之Openhands解析(含代码)</a>  <a href=\"https://www.zhihu.com/people/wu-long-ming-cha-56\" rel=\"noopener nofollow\" target=\"_blank\">Arrow</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/1940824548485347192\" rel=\"noopener nofollow\" target=\"_blank\">OpenHands 源码解读</a>  <a href=\"https://www.zhihu.com/people/xiao-hui-66-72\" rel=\"noopener nofollow\" target=\"_blank\">一力辉</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 20:55</span>&nbsp;\n<a href=\"https://www.cnblogs.com/rossiXYZ\">罗西的思考</a>&nbsp;\n阅读(<span id=\"post_view_count\">32</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "并查集及其应用专题--全网最详细版",
      "link": "https://www.cnblogs.com/hicode002/p/-/union_set",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/hicode002/p/-/union_set\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 19:57\">\n    <span>并查集及其应用专题--全网最详细版</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"并查集\">并查集</h1>\n<p>并查集是用来查找和合并集合关系的<br />\n这个集合必须是不交集<br />\n支持查找和合并两种操作，修改后可以支持删除单个元素并分离集合。<br />\n使用动态开点线段树还可以实现可持久化并查集</p>\n<p>来自 <a href=\"https://oi-wiki.org/ds/dsu/\" rel=\"noopener nofollow\" target=\"_blank\">https://oi-wiki.org/ds/dsu/</a></p>\n<p>并查集类似于树，普通并查集是无向的，但是加权并查集是可以做到有向的，详见NOI2001食物链</p>\n<h2 id=\"查找操作查找两个元素是否在同一集合\">查找操作：查找两个元素是否在同一集合</h2>\n<p>假设有一个集合，元素是{1,2,3}<br />\n还有一个集合元素是{4,5,6}<br />\n现在查找2和4在不在同一个集合，则需要枚举2所在或4所在集合所有元素直到找到4或到最后也没有4<br />\n太慢了，有一个更好的方法，如果我们随便选一个集合中的某个元素作为该集合的代表元素，<br />\n其它该集合中的元素都指向这个元素<br />\n当查找元素所在集合时，只要找到这个元素的指向的元素的最顶级元素即根，这个根就是代表节点<br />\n最后判断这两个元素的根是否相同即可<br />\n这里遇到一个问题，就是这个根元素怎么标记呢，可以让它所指向的元素是自己，这样询问时只要遇到指向元素是自己的元素，那么说明找到根了，即可停止<br />\n我们把这个指向的元素叫做这个元素的父亲<br />\n注意树不只有两层，因为在合并操作时集合被合并，原先两个集合的根中有一个变成了子节点，此时层数会增加，而这个代表元素是整棵树的根，这个点的父亲只是它的原来的集合的根，因为集合已经合并，所以判断两个元素是否在同一集合中时要用整棵树的根，因此要递归寻找这个元素的父亲直到元素的父亲是自身时停止寻找并返回该元素。当然这个过程可以循环解决，只需要定义临时变量为该元素的父亲，然后这个变量不断等于这个变量的父亲，直到其父亲等于自身为止，然后返回该变量即可<br />\n举例：<br />\n假设集合1以3为根，集合2以6为根，则<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162032821-1549875642.png\" /><br />\n2和4的根分别是3和6，不等，所以不在一个集合<br />\n1和3的根分别是3和3，相等，所以在一个集合。</p>\n<h2 id=\"合并操作\">合并操作：</h2>\n<p>把两个元素 所在集合 合并为一个集合，合并后两个集合等同于在一个大集合中，此时一个元素所在集合的根要变成子节点，另一个作为大集合的根。<br />\n如何合并：<br />\n很简单，先查找两个元素的根，然后把一个根的父亲改为另一个根，这样就完成了合并 ，但是如果两个元素的根相同说明在一个集合就直接返回不用合并<br />\n例：<br />\n以查找时为例<br />\n合并前：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162032821-1549875642.png\" /><br />\n假设新根是6<br />\n合并后：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162149379-1024618492.png\" /><br />\n再查找2和4：<br />\n2的父亲是3，3的父亲是6，6的父亲是6<br />\n4的父亲是6<br />\n在一个集合<br />\n注意合并时要把一个根直接接到另一个根上，而不是接到子节点上！！</p>\n<h2 id=\"路径压缩\">路径压缩</h2>\n<p>在查找时我们不关心这个元素的父亲，只要这个元素通过找父亲能找到根即可，所以每次查找后把查找的这条链上的元素的父亲直接改为根，这样不影响查找，而且减少以后查找的次数（减小树高）<br />\n递归时只要返回时return fa[x]=find(fa[x])即可，这样会递归到最后找到根把父亲从上往下回溯着改<br />\n循环法要找到根后再开一个循环，先让循环变量=它的父亲，然后把它的父亲改为根，直到 父亲=父亲 时停止（到根了），这是自下往上的。<br />\n但是一次只能保证这条链上的，不能是全树都改好，所以后面删除元素时比较麻烦</p>\n<h2 id=\"按秩合并启发式合并\">按秩合并：(启发式合并）</h2>\n<p>在合并时我们要将其中一个元素所在集合的根变为子节点，另一个变为新根，可是哪一个变为子节点呢？<br />\n显然将尺寸小的接到尺寸大的集合上更好，这样查找大的时还是那个复杂度，可反之要花更多的时间，但是尺寸小的集合造成影响小，所以要把尺寸小的接到尺寸大的集合上<br />\n但是尺寸是什么呢？<br />\n尺寸既可以是一个集合的元素个数即点数，也可以是树的高度，它们优化的效果是等价的<br />\n如果以点数为尺寸，那么合并时把点数小的根父亲等于点数大的根，点数大的根的点数+=点数小的根的点数，这个叫做启发式合并，其他数据结构也常用<br />\n如果以高度为尺寸，那么合并时把高度小的根父亲等于高度大的根，但是高度不变，为什么？ 这个叫做按秩合并，不是很常用<br />\n只要a的高度小于b，因为高度是整数，所以a的高度比b至少少一，把a接到b的下面，此时这个高度不能超过b<br />\n什么时候高度改变？当a和b高度相等时，可以随便接，但是无论怎么接高度都增加1<br />\n假如a接在b下面，那么b的这个子树的高度为b，而b的其他子树中最大的高度是b-1，因此b的高度变为b+1!</p>\n<h2 id=\"复杂度\">复杂度：</h2>\n<p><span class=\"math inline\">\\(n\\)</span>个元素，<span class=\"math inline\">\\(m\\)</span>次操作（查找或合并）<br />\n空间复杂度：<br />\n由于每个元素都有一个父亲，所以<span class=\"math inline\">\\(fa\\)</span>数组大小是<span class=\"math inline\">\\(n\\)</span>，故空间复杂度<span class=\"math inline\">\\(O（n）\\)</span><br />\n时间复杂度：<br />\n既使用路径压缩，又使用按秩合并:<br />\n每个操作平均时间复杂度<span class=\"math inline\">\\(O(α(n))\\)</span><br />\n<span class=\"math inline\">\\(α\\)</span>是反阿克曼函数，近似于常数</p>\n<p>总操作平均复杂度<span class=\"math inline\">\\(O(mα(n))\\)</span><br />\n只使用路径压缩：<br />\n总操作平均复杂度<span class=\"math inline\">\\(O(mα(n))\\)</span><br />\n总操作最坏复杂度<span class=\"math inline\">\\(O(m log⁡n )\\)</span><br />\n只使用按秩合并：<br />\n总操作平均复杂度<span class=\"math inline\">\\(O(m log⁡n )\\)</span></p>\n<h2 id=\"删除操作\">删除操作：</h2>\n<p>修改后的并查集支持单个元素的删除<br />\n但是需要注意的是删除不是说删除这个点和这个点所连的点，而是仅仅删除这个点，其余与他相连的点仍然在原并查集中，但这个点独立成一个集合<br />\n在完美形态的并查集中，每个节点的父亲都是根，此时删除一个节点就是把这个节点的父亲改为自己，这样不影响其他节点，但是实际上路径压缩只能将这条链上的节点的父亲改为根，所以实际并查集形态不可估计<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162414092-577349486.png\" /><br />\n删除2后<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162431589-133329972.png\" /><br />\n那么我们可以用盒子来代替这个真正的节点去合并，而我们真正的每一个节点都指向每一个盒子<br />\n详细：<br />\n每一个节点都对应一个盒子，每个节点的父亲起初都是对应的一个新盒子<br />\n当我们合并集合时，我们只合并节点指向的盒子的所在集合，仍然符合按秩合并<br />\n当我们删除时把节点的父亲改为一个新的，从未使用过的盒子，原盒子保持空，这样原来集合的关系可以通过这个空盒子保留<br />\n当我们查找时查找节点所在盒子的根<br />\n仍然可以用路径压缩<br />\n一旦这个节点被删除，就到了新盒子，此时这个节点和原来的集合并不在一个集合中，所以删除有效<br />\n删除的节点再和别的节点合并改变的是它新盒子的集合<br />\n与原来集合无关<br />\n还可以有还原操作，就是删除后把这个节点还原到它最近被删除的集合中，显然可以再合并 ，但也可以数组记录每个节点上一次被删除的盒子编号，然后把这个节点的指向改为上一次被删除的盒子编号，这样就完全还原上一次这个节点的形态，不需要合并了</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\nusing namespace std;\nint fa[10006],fa1[90006],t=10007,lasts[10006];\t\ninline int finds(int x ){\n\tif(fa1[x]==x)return x;\n\treturn fa1[x]=finds(fa1[x]);\n}\ninline void inserts(int x,int y){\n\tint a=finds(x),b=finds(y);\n\tif(a==b)return;\n\tfa1[a]=b;\n}\ninline void deletes(int x){\n\tlasts[x]=fa[x];\n\tfa[x]=t;\n\t++t;\n}\ninline void restore(int x){\n\tfa[x]=lasts[x];\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(lasts,0,sizeof lasts);\n\tfor(int i=0;i&lt;90006;++i){\n\t\tfa1[i]=i;\n\t}\n\tint m;\n\tcin&gt;&gt;m;\n\tfor(int i=0;i&lt;m;++i){\n\t\tchar op ;int x,y;\n\t\tcin&gt;&gt;op;\n\t\tif(op=='U'){\n\t\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\t\tif(fa[x]==-1)fa[x]=x;\n\t\t\tif(fa[y]==-1)fa[y]=y;\n\t\t\tinserts(fa[x],fa[y]);\n\t\t\t\n\t\t}else if(op=='F'){\n\t\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\t\tif(fa[x]==-1)fa[x]=x;\n\t\t\tif(fa[y]==-1)fa[y]=y;\n\t\t\tif(finds(fa[x])!=finds(fa[y])){\n\t\t\t\tcout&lt;&lt;0&lt;&lt;endl;\n\t\t\t}else{\n\t\t\t\tcout&lt;&lt;1&lt;&lt;endl;\n\t\t\t}\n\t\t}else if(op=='D'){\n\t\t\tcin&gt;&gt;x;\n\t\t\tdeletes(x);\n\t\t}else{\n\t\t\tcin&gt;&gt;x;\n\t\t\trestore(x);\n\t\t}\n\t}\n\treturn 0;\n}\n</code></pre>\n<h2 id=\"带权并查集\">带权并查集：</h2>\n<p>本质是并查集的向量拓展<br />\n把树看成dag图，每个元素的权值记录的是它和它父亲之间的边权，主要记录的是一种关系，这里是一些普通的数字，但在实际问题中边权往往是一些关系，最后可能还要取模<br />\n目的是利用路径压缩求出元素到根节点的边权和，然后给定任意两个元素求出这两个元素之间的某些关系（与根有关的和差）<br />\n假设权值数组为<span class=\"math inline\">\\(w\\)</span><br />\n路径压缩时可以先递归找根并存储，然后把w[x]+=w[fa[x]]，最后把fa[x]改成根<br />\n因为是递归，所以会先找到根，然后回溯像前缀和一样层层加，直到加到当前元素为止，此时w[x]就为x到根节点的权值和，同时这条链上的元素都把权值改了<br />\n但是重点在合并<br />\n合并两个元素x，y所在集合，其中x，y两个元素之间权值为有向值s（把x合并到y或把y合并到x）<br />\n由于x到y和y到x只需调换顺序即可，所以只考虑x到y<br />\n假如x的根是px，，y的根是py，省略中间的链，因为路径压缩时会改，问题在于x到y的权值明确，x到px的权值明确，y到py的权值明确，但是px到py就不知道了<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124162708674-1940796842.png\" /><br />\n可以辅助线来解决<br />\n先求x到py，这里x到y和y到py等价于x到py，所以x到py权值用向量加法为s+v2<br />\n同理，x到py又等于v1+px到py<br />\n所以px到py=s+v2-v1<br />\n这是个抽象问题，这里加的是向量，而不是向量的模，很懵逼<br />\n但是实际问题往往要取模或者是压根再开一个数组，详见NOI2002银河英雄传说<br />\n基础操作就是这些，还有一些例题</p>\n<h3 id=\"hdu-3038-how-many-answers-are-wrong\">HDU-3038-How Many Answers Are Wrong</h3>\n<p>来自 <a href=\"https://blog.csdn.net/yjr3426619/article/details/82315133\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/yjr3426619/article/details/82315133</a></p>\n<p>有M个数，不知道它们具体的值，但是知道某两个数之间（包括这两个数）的所有数之和，现在给出N个这样的区间和信息，需要判断有多少个这样的区间和与前边已知的区间和存在矛盾。例如给出区间和<span class=\"math inline\">\\([1,4]\\)</span>为20，<span class=\"math inline\">\\([3,4]\\)</span>为15，再给出<span class=\"math inline\">\\([1,2]\\)</span>为30，显然这个<span class=\"math inline\">\\([1,2]\\)</span>的值就有问题，它应该为20-15=5。<br />\n由于不知道每句区间是否正确，所以要根据先前的正确的区间来推出这个区间，如果推不出就是对的，因为是新的，如果推出了，若题目给的与之前的正确的区间推出的区间的值相等就说明正确，可以忽略，若不相等，则不正确，也忽略，留下正确的值<br />\n注意不相等是唯一矛盾的时候，<span class=\"math inline\">\\([1,10]=50\\)</span>  ,<span class=\"math inline\">\\([1,5]=100\\)</span>这看起来不对，但实际上题目没说每个数是正数，所以这也是对的，可能<span class=\"math inline\">\\([6,10]=-50\\)</span><br />\n我们想到区间的合并，很像并查集<br />\n但是这是个闭区间，没有公共点，我们需要半开半闭区间，不能全开区间，这样<span class=\"math inline\">\\([1,4]=(0,5)\\)</span>   <span class=\"math inline\">\\([3,4]=(2,5)\\)</span>   <span class=\"math inline\">\\([1,2]=(0,3)\\)</span>，没有公共点<br />\n常见左闭右开区间，这样<span class=\"math inline\">\\([1,4]=[1,5)\\)</span>  <span class=\"math inline\">\\([1,2]=[1,3)\\)</span>   <span class=\"math inline\">\\([3,4]=[3，5)\\)</span><br />\n可以把1 3和3 5合成1 5<br />\n所以要先改区间<br />\n然后就可以用并查集了。<br />\n看图：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163306555-1040943616.png\" /><br />\n这两种都是对的<br />\n都是向量的加法<br />\n第一种以5为根，合并时并没有真正1 3连边和求值，要 求 1 3时只需要用1 5的和减去3 5的和即可<br />\n第二种以1为根，合并时用公式s+v2-v1，因为3是孤立点，所以v2=0，即s-v1，这就算出了1 3<br />\n然后求1 3的和用1 3的和 减去 1 1的和即可<br />\n由此可见询问区间x y时是sum x  -  sum y还是反过来完全取决于合并时把x的集合并到y还是把y的集合并到x，如果x-》y就sum x  -sum y<br />\n如果y-》x就sum y -sum x<br />\n所以不能启发式合并<br />\n那么什么时候算不出x y的和？<br />\n当区间两个端点在一个集合时说明两个sum可以用向量求，而不在一个集合时求不出，因为两个集合没有交集，中间的数不知道是多少<br />\n因此，思路如下：<br />\n读入区间<br />\n合并两个区间端点，若在一个集合中时公式算出和，比对给出的，不合法记录下来<br />\n不在一个集合时认为这个和是对的，把这两个合并，以这个和为权值<br />\n合并时用基本向量公式<br />\n若x-&gt;y就用w(x,y)+w（y,py)-w(x,px)<br />\n若y-&gt;x就用w(x,y)+w(x,px)-w(y,py)<br />\npx就是x的根<br />\nw就是之间的和<br />\n初始化把w数组置为0，即使是根节点到自身也满足上面的公式<br />\n把fa【i】=i不要等于-1，容易出错</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\nusing namespace std;\nint fa[2000003],v[2000003];\ninline int find(int x){\n\tif(fa[x]==x)return x;\n\tint k=find(fa[x]);\n\tv[x]+=v[fa[x]];\n\tfa[x]=k;\n\treturn k;\n}\ninline void inserts(int x,int y,int a,int b,int z){\n\tfa[a]=b;\n\tv[a]=z+v[y]-v[x];\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(v,0,sizeof v);\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tint cnt=0;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y,z;\n\t\tcin&gt;&gt;x&gt;&gt;y&gt;&gt;z;\n\t\ty=y+1;//闭区间改成开区间 \n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=find(x),b=find(y);\t\n\t\tif(a!=b){\n\t\t\tinserts(x,y,a,b,z);\n\t\t}else{\n\t\t\tif(v[x]-v[y]!=z)cnt++;\n\t\t}\n\t}\n\tcout&lt;&lt;cnt&lt;&lt;endl;\n\treturn 0;\n}\n\n</code></pre>\n<p>另一个例题：</p>\n<h3 id=\"hihocoder-1515-分数调查\">HihoCoder-1515-分数调查</h3>\n<p>描述<br />\n小Hi的学校总共有N名学生，编号1-N。学校刚刚进行了一场全校的古诗文水平测验。</p>\n<p>学校没有公布测验的成绩，所以小Hi只能得到一些小道消息，例如X号同学的分数比Y号同学的分数高S分。</p>\n<p>小Hi想知道利用这些消息，能不能判断出某两位同学之间的分数高低？</p>\n<p>输入<br />\n第一行包含三个整数N, M和Q。N表示学生总数，M表示小Hi知道消息的总数，Q表示小Hi想询问的数量。</p>\n<p>以下M行每行三个整数，X, Y和S。表示X号同学的分数比Y号同学的分数高S分。</p>\n<p>以下Q行每行两个整数，X和Y。表示小Hi想知道X号同学的分数比Y号同学的分数高几分。</p>\n<p>对于50%的数据，$1 &lt;= N, M, Q &lt;= 1000 $</p>\n<p>对于100%的数据，<span class=\"math inline\">\\(1 &lt;= N, M, Q&lt;= 100000 1 &lt;= X, Y &lt;= N -1000 &lt;= S &lt;= 1000\\)</span></p>\n<p>数据保证没有矛盾。</p>\n<p>输出<br />\n对于每个询问，如果不能判断出X比Y高几分输出-1。否则输出X比Y高的分数。</p>\n<p>样例输入</p>\n<p>10 5 3<br />\n1 2 10<br />\n2 3 10<br />\n4 5 -10<br />\n5 6 -10<br />\n2 5 10<br />\n1 10<br />\n1 5<br />\n3 5<br />\n样例输出</p>\n<p>-1<br />\n20<br />\n0</p>\n<p>分析一下：<br />\n考虑传递性和向量性<br />\n显然是图，x比y高可以x-》y连一条边，权值是x比y高的分数<br />\n看图：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163431046-1074997319.png\" /><br />\n3比2高3分，2比1高5分，所以3比1高8分<br />\n具有传递性</p>\n<p>向量合并：<br />\n对于1比2高8分<br />\n3比4高3分<br />\n1比3高3分<br />\n则1比4高6分<br />\n则2比4高-2分<br />\n注意当x比y低时就是x比y高y比x高的分数的相反数<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163544199-37076875.png\" /><br />\n具有向量性<br />\n因此可以用并查集<br />\n那么怎么由x到根节点权值和y到根节点权值推出x比y高的分呢?<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124163601865-836423128.png\" /><br />\n即w【x】-w【y】<br />\n什么时候无解呢？<br />\n当x与y在一个并查集时可以根据根节点来求x与y的权值，当x与y不在一个并查集时不能得出x到y的权值，<br />\n如：<br />\n1比2高3分，3比4高2分，无法求出2比3高的分数<br />\nw数组代表x比x的父亲高的分数<br />\n路径压缩时统计和，得知x到根的权值<br />\n合并时同样不能启发式合并，要把x合并到y<br />\n向量法计算合并后的权值<br />\n合并x和y所在集合<br />\n询问时先判断x与y是否在一个并查集，是输出w[x]-w[y]<br />\n不是输出-1!</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\n\nusing namespace std;\nint fa[100003],v[100003];\ninline int find(int x){\n\tif(fa[x]==x)return x;\n\tint k=find(fa[x]);\n\tv[x]+=v[fa[x]];\n\treturn fa[x]=k;\n}\ninline void inserts(int a,int b,int x,int y,int z){\n\tfa[a]=b;\n\tv[a]=z+v[y]-v[x];\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(v,0,sizeof v);\n\tint n,m,q;\n\tcin&gt;&gt;n&gt;&gt;m&gt;&gt;q;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y,k;\n\t\tcin&gt;&gt;x&gt;&gt;y&gt;&gt;k;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=find(x),b=find(y);\n\t\tif(a!=b){\n\t\t\tinserts(a,b,x,y,k);\n\t\t}\n\t}\n\tfor(int i=0;i&lt;q;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n//\t\tcout&lt;&lt;9;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\t//这里注意可能x和y还没出现过，所以要检验-1，因为-1做下标会re \n\t\tint g=find(x),f=find(y);\n\t\tif(g!=f){\n\t\t\tcout&lt;&lt;-1&lt;&lt;endl;\n\t\t}else{\n\t\t\tcout&lt;&lt;v[x]-v[y]&lt;&lt;endl;\n\t\t}\n\t\t\n\t}\n\treturn 0;\n}\n</code></pre>\n<h2 id=\"种类并查集\">种类并查集：</h2>\n<p>当我们在维护一些复杂的传递关系时，普通的并查集无法满足需求<br />\n维护朋友的朋友是朋友，敌人的敌人是朋友，<br />\n异性的异性是同性<br />\n<span class=\"math inline\">\\(a\\)</span>吃<span class=\"math inline\">\\(b\\)</span> <span class=\"math inline\">\\(b\\)</span>吃<span class=\"math inline\">\\(c\\)</span> 则<span class=\"math inline\">\\(c\\)</span>吃<span class=\"math inline\">\\(a\\)</span><br />\n这种具有反向传递性的关系时，可以用加权并查集<br />\n当然很复杂<br />\n于是有一种占空间更大但是简单的种类并查集<br />\n我们可以根据关系的数目确定出要把fa数组开一定的倍数<br />\n然后把这个数组分成几类，用来维护反向传递性<br />\n洛谷P1525 关押罪犯</p>\n<p>来自 <a href=\"https://zhuanlan.zhihu.com/p/97813717\" rel=\"noopener nofollow\" target=\"_blank\">https://zhuanlan.zhihu.com/p/97813717</a></p>\n<p>团伙<br />\n食物链<br />\n异性问题<br />\n这是最简单的<br />\n因为只有男和女两种<br />\n当a和b同性b和c同性时a和c同性，这是基础并查集的合并<br />\n当a和b异性b和c异性时a和c同性<br />\n当a和b同性b和c异性则a和c异性<br />\n后两个具有反向传递性<br />\n这里我们fa多开一倍数组<br />\n我们假定<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(a+n\\)</span>为异性，<span class=\"math inline\">\\(n\\)</span>是正常开的数组大小<br />\n所以当<span class=\"math inline\">\\(a\\)</span>为<span class=\"math inline\">\\(n-1\\)</span>时<span class=\"math inline\">\\(a+n=2n-1\\)</span>，因此需要开两倍数组<br />\n当<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>是同性时，我们可以合并<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>所在集合，因为都是同性<br />\n还可以合并<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>所在集合，因为<span class=\"math inline\">\\(a+n\\)</span>是与<span class=\"math inline\">\\(a\\)</span>异性的，<span class=\"math inline\">\\(b+n\\)</span>是与<span class=\"math inline\">\\(b\\)</span>异性的，当<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>同性时，<span class=\"math inline\">\\(a\\)</span>的异性和<span class=\"math inline\">\\(b\\)</span>的异性是同性<br />\n而<span class=\"math inline\">\\(a+n\\)</span>里的所有元素全是一个性别<br />\n<span class=\"math inline\">\\(b+n\\)</span>也是<br />\n所以可以合并<br />\n当<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>异性时<br />\n那么把<span class=\"math inline\">\\(a\\)</span>的异性和<span class=\"math inline\">\\(b\\)</span>合并，把<span class=\"math inline\">\\(b\\)</span>的异性和<span class=\"math inline\">\\(a\\)</span>合并<br />\n即合并<span class=\"math inline\">\\(a+n,b\\)</span>      ;   <span class=\"math inline\">\\(b+n,a\\)</span><br />\n因为<span class=\"math inline\">\\(a\\)</span>的异性肯定和<span class=\"math inline\">\\(b\\)</span>同性<br />\n<span class=\"math inline\">\\(b\\)</span>的异性肯定和<span class=\"math inline\">\\(a\\)</span>同性</p>\n<p>为什么这样可以做到那三条？<br />\n第一条显然满足<br />\n第三条<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>同性则<span class=\"math inline\">\\(a,b\\)</span>    <span class=\"math inline\">\\(a+n,b+n\\)</span>分别在一个并查集，<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c\\)</span>异性则<span class=\"math inline\">\\(b+n  ,c\\)</span>           <span class=\"math inline\">\\(c+n,b\\)</span>分别在一个并查集，所以<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(c\\)</span>     <span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c+n\\)</span>分别在一个并查集，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c\\)</span>不在一个并查集，所以<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c\\)</span>是异性<br />\n第二条比较复杂<br />\n<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>是异性时<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>不在一个并查集，但是<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(a+n\\)</span>，，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>分别都在一个并查集<br />\n<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c\\)</span>异性时<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c\\)</span>不在一个并查集，但是<span class=\"math inline\">\\(b\\)</span>和<span class=\"math inline\">\\(c+n\\)</span> ，，<span class=\"math inline\">\\(c\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>分别在一个并查集<br />\n所以<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(c+n\\)</span>在一个并查集，，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(c\\)</span>也在一个并查集<br />\n所以<span class=\"math inline\">\\(a+n\\)</span>和<span class=\"math inline\">\\(c+n\\)</span>,,,<span class=\"math inline\">\\(a\\)</span>,<span class=\"math inline\">\\(c\\)</span>分别在一个并查集<br />\n即它们分别同性<br />\n所以第二条满足</p>\n<p>那么查找时问<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>同性还是异性只需要看：<br />\n<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>在一个并查集时说明是同性，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>不在一个并查集时若<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b+n\\)</span>同性<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>就是异性（就两种性别）<br />\n注意<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>不在一个并查集不能说明是异性<br />\n因为如1 2同性<br />\n3 4同性<br />\n再说2 3同性，2和3<br />\n不在一个并查集中，而2的异性集合中没有3，所以2 3同性这是对的</p>\n<p>但是原题：<br />\n每次给出两个昆虫的关系（异性关系），然后发现这些条件中是否有悖论</p>\n<p>来自 <a href=\"https://blog.csdn.net/sunmaoxiang/article/details/80959300?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control\" rel=\"noopener nofollow\" target=\"_blank\">https://blog.csdn.net/sunmaoxiang/article/details/80959300?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control</a></p>\n<p>所以要动态判断<br />\n当输入<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>后<br />\n若<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>有一个没有初始化就先初始化（<span class=\"math inline\">\\(a，b，a+n，b+n\\)</span>中没有初始化的都要初始化）然后把<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>按照前面的规则合并<br />\n然后这个数据是对的</p>\n<p>若<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>已经初始化也不能说明它们的关系已经确定，如上面的例子，此时判断<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>关系是否与输入的相符，若相符就是对的，若不符就是不对的，就跳过。若不在一个并查集中且<span class=\"math inline\">\\(a\\)</span>的异性和<span class=\"math inline\">\\(b\\)</span>也不在一个并查集中关系就未确定，此时<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>的关系再合并，<span class=\"math inline\">\\(a\\)</span>和<span class=\"math inline\">\\(b\\)</span>的关系是对的<br />\n这时路径压缩和按秩合并都可以用</p>\n<pre><code>#include&lt;iostream&gt; \n#include&lt;cstdio&gt; \n#include&lt;cstring&gt;\nusing namespace std;\nint fa[200002];\ninline int find(int x){\n\tif(fa[x]==x)return x;\n\treturn fa[x]=find(fa[x]);\n}\ninline void inserts(int x,int y){\n\tint a=find(x),b=find(y);\n\tif(a==b)return;\n\tfa[a]=b;\n}\nint main(){\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tmemset(fa,-1,sizeof fa);\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=find(x),b=find(y);\n\t\tif(a==b)cout&lt;&lt;\"N\"&lt;&lt;endl;\n\t\telse{\n\t\t\tif(fa[y+n]==-1)fa[y+n]=y+n;//注意y+n x+n可能没用过，所以要先初始化 \n\t\t\tif(fa[x+n]==-1)fa[x+n]=x+n;\n\t\t\tinserts(x,y+n);\n\t\t\tinserts(x+n,y);\n\t\t\tcout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t}\n\t}\n\treturn 0;\n} \n</code></pre>\n<p>再用加权并查集做一下：<br />\nw数组记录x到x父亲的关系（1异性 0同性）<br />\n路径压缩时求和，但是要取模2<br />\n为什么？<br />\n有1号 2号 3号<br />\n成链状，现在把3路径压缩，使得w【3】是1与3的关系<br />\n1与2同性且2与3同性时：w[1]=0   w[2]=0       w[3]=0      w[3new]=w[1]+w[2]+w[3]=0  0%2=0      满足1 3同性<br />\n1与2同性且2与3异性时  w[1]=0  w[2]=0  w[3]=1   w[3new]=w[1]+w[2]+w[3]=1  1%2=1  满足1 3异性<br />\n1与2异性且2与3同性时w[1]=0  w[2]=1  w[3]=0   w[3new]=w[1]+w[2]+w[3]=1   1%2=1  满足1 3异性<br />\n1与2异性且2与3异性时最重要  w[1]=0  w[2]=1  w[3]=1  w[3new]=w[1]+w[2]+w[3]=2  2%2=0   满足异性的异性是同性<br />\n可见在压缩求和时可以顺便%2，这样最后的关系是正确的，实际上这是分了两类，所以%2</p>\n<p>然后合并，同样不能按秩合并<br />\n向量法<br />\n具有向量性，但要取模<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3026852/202601/3026852-20260124164323599-1904309385.png\" /><br />\n由此可见，我们把y连到x的向量公式<span class=\"math inline\">\\(w[py]=w(x,y)+w[x]-w[y]+2\\)</span>再取模2即可，这样合并后px和py的关系是正确的<br />\n+2是为了防止<span class=\"math inline\">\\(w[x]\\)</span>与<span class=\"math inline\">\\(w(x,y)\\)</span>都是为0，而<span class=\"math inline\">\\(w[y]=1\\)</span>，会出现负数</p>\n<p>那么询问关系时怎么处理？<br />\n询问<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系<br />\n当<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>在一个并查集时即<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系确定<br />\n当<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>不在一个并查集时<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系不确定，给出的这个关系是对的，然后合并<br />\n注意与种类并查集不同的是：<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>在一个并查集并不能说明x和y的关系是同性，只能说明它们有明确的关系，而同异性是根据权值数组w来确定的<br />\n当关系确定时<br />\n若<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的共同根节点是<span class=\"math inline\">\\(px\\)</span>，那么<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的关系就是$(w[x]-w[y]+2) \\mod 2 $<br />\n+2同样防止出现负数<br />\n如<span class=\"math inline\">\\(x\\)</span>到<span class=\"math inline\">\\(px\\)</span>是1，y到py是1<br />\n则<span class=\"math inline\">\\(x\\)</span>到<span class=\"math inline\">\\(y\\)</span>是1-1=0 0%2=0<br />\n符合要求<br />\n然后判断与给出的是否符合即可<br />\n注意初始化每个节点的w都是0，即根节点和它自己是同性，否则会造成问题。<br />\n注意这里给出<span class=\"math inline\">\\(x\\)</span> <span class=\"math inline\">\\(y\\)</span>时我们把<span class=\"math inline\">\\(y\\)</span>连向<span class=\"math inline\">\\(x\\)</span></p>\n<pre><code>#include&lt;iostream&gt;//x连接向y\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\nusing namespace std;\nint fa[1006],w[1006];\ninline int finds(int x){\n\tif(fa[x]==x)return x;\n\tint k=finds(fa[x]);\n\tw[x]=(w[x]+w[fa[x]])%2;\n\treturn fa[x]=k;\n}\ninline void inserts(int x ,int y,int a,int b,int z){\n\tfa[a]=b;\n\tw[a]=z+w[y]-w[x];\n\tw[a]=w[a]+2;\n\tw[a]=w[a]%2;\n}\nint main(){\n\tmemset(fa,-1,sizeof fa);\n\tmemset(w,0,sizeof w);\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\tif(fa[x]==-1)fa[x]=x;\n\t\tif(fa[y]==-1)fa[y]=y;\n\t\tint a=finds(x),b=finds(y);\n\t\tif(a!=b){\n\t\t\tinserts(x,y,a,b,1);\n\t\t\tcout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t\t\n\t\t}else{\n\t\t\tif((w[y]-w[x]+2)%2==1){\n\t\t\t\tcout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t\t}else{\n\t\t\t\tcout&lt;&lt;\"N\"&lt;&lt;endl;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n</code></pre>\n<p>种类并查集可以维护敌人的敌人是朋友这样的关系，这种说法不够准确，较为本质地说，种类并查集（包括普通并查集）维护的是一种循环对称的关系。</p>\n<p>来自 <a href=\"https://zhuanlan.zhihu.com/p/97813717\" rel=\"noopener nofollow\" target=\"_blank\">https://zhuanlan.zhihu.com/p/97813717</a></p>\n<p>还有一类问题：<br />\n拆地毯</p>\n<p>修复公路   贪心<br />\n||<br />\n营救   贪心<br />\n这两道题等价，都是最大值的最小化<br />\n星球大战   倒推</p>\n<p>这些题都是些思维题，主要是倒推和贪心<br />\n拆地毯是星球大战和修复公路结合</p>\n<h2 id=\"并查集联通块数量统计\">并查集联通块数量统计</h2>\n<p>关于并查集联通块数量统计，首先要知道初始状态的联通块个数，然后每一次合并是若不在一个并查集则合并能使联通块数量减少<span class=\"math inline\">\\(1\\)</span>，若在一个并查集则没有贡献，切忌哈希统计<br />\n这指的是一个节点原先是独立的集合时。<br />\n但是如果是一个节点从原先不存在到出现并连边，联通块的数量要分类讨论<br />\n若这个点没有任何边将要和它相连，那么出现后联通块个数反而加一，，若这个节点出现并连第一条边，则联通块数量不变，因为节点出现相当于增加了一个联通块，连一条边合并后联通块减少了<span class=\"math inline\">\\(1\\)</span>，所以不变<br />\n若这个节点已经出现且连的不是第一条边，那么合并（当然不在一个集合时）后联通块数量减少<span class=\"math inline\">\\(1\\)</span>，因为此时这个节点已经在一个集合中了，若再与另一个集合连边，就会使得集合数目减少<span class=\"math inline\">\\(1\\)</span></p>\n<p>当遇到拆毁/彻底删除（连着点和边一起删除，破坏了集合关系）时，应该倒推，寻求全部<br />\n删除后的状态，然后倒着合并<br />\n当遇到移动集合元素，分离单一元素为独立集合（保持原来集合关系，只是那一个元素空了）时，应该用盒子来做，，即源节点指向盒子，对于合并与查找都是操作盒子，当移动或分离改变源节点指向的盒子，就可以保留原来集合关系，但是实现源节点的转移或分离。</p>\n<h2 id=\"并查集的另一种写法\">并查集的另一种写法</h2>\n<p>就是路径压缩 启发式合并  找父亲 使用了一个数组完成<br />\n当f【i】为负数时，说明这个节点是根节点，此时f[i]的值是这个根节点的树的节点个数的相反数<br />\n当f[i]为正数时，f[i]是i的父亲<br />\n这样查找x的根时，当f[x]&lt;0时返回x，是根节点，其余情况照常路径压缩return f[x]=find(f[x])<br />\n合并时x y先找根节点，如果根节点不同，那么就进行合并<br />\n设x的根为rx<br />\ny的根为ry<br />\n如果f[rx]&gt;f[ry]  就交换rx和ry<br />\n这样f[rx]一定&lt;=f[ry]<br />\n即-f[rx]&gt;=-f[ry]<br />\n此时rx的树的尺寸大小&gt;=ry的树的尺寸大小<br />\nrx做根<br />\nf[rx]+=f[ry]<br />\n更新rx的尺寸的相反数<br />\nf[ry]=rx<br />\n此时ry就指向了rx，做了儿子<br />\n这两步顺序不能错，因为在第二步之前f[ry]记录的是ry下的树尺寸的相反数，f[rx]+=f[ry]可以更新尺寸，而第二步是因为ry做了儿子，所以f[ry]成了ry的父亲，如果颠倒，那么f[rx]就可能变成正数从而误认为不是根节点</p>\n<p>理解：<br />\n对于两个集合的根节点rx，ry<br />\n它们的f已经计算好，是它们的树的尺寸的相反数，合并是通过比较这个尺寸来实现启发式 合并，然后假设rx做新根<br />\n那么rx的尺寸相反数自然要更新，加上ry的尺寸的相反数（都是负数），然后ry的f就变成了指向父亲的作用，ry的父亲是rx<br />\n查找时若x是根节点，f[x]不一定=-1，也有可能&lt;-1，代表的是尺寸的相反数，同时能说明找到了根节点<br />\n当f[x]&gt;0时说明f【x】是x的父亲，要继续递归并路径压缩<br />\n初始化时f[]要置为-1，代表每个树尺寸为1</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\n#include&lt;algorithm&gt;\nusing namespace std;\nint f[10006];\ninline int finds(const int&amp;x ){\n\tif(f[x]&lt;0)return x;\n\treturn f[x]=finds(f[x]);\n}\ninline void unions(const int&amp;x,const int &amp;y){\n\tint rx=finds(x);\n\tint ry=finds(y);\n\tif(rx==ry)return;\n\tif(f[rx]&gt;f[ry])swap(rx,ry);\n\tf[rx]+=f[ry];\n\tf[ry]=rx;\n\t\n}\nint main(){\n\tmemset(f,-1,sizeof f);\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tfor(int i=1;i&lt;=m;++i){\n\t\tint opt;\n\t\tcin&gt;&gt;opt;\n\t\tint x1,y1;\n\t\tcin&gt;&gt;x1&gt;&gt;y1;\n\t\tif(opt==1){\n\t\t\tunions(x1,y1);\n\t\t}else{\n\t\t\tint rx1=finds(x1);\n\t\t\tint ry1=finds(y1);\n\t\t\tif(rx1==ry1)cout&lt;&lt;\"Y\"&lt;&lt;endl;\n\t\t\telse cout&lt;&lt;\"N\"&lt;&lt;endl;\n\t\t}\n\t}\n\treturn 0;\n}\n</code></pre>\n<hr />\n<h2 id=\"例题详解\">例题详解</h2>\n<h3 id=\"p1197-jsoi2008星球大战\">P1197 [JSOI2008]星球大战</h3>\n<p><a href=\"https://www.luogu.com.cn/problem/P1197\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1197</a></p>\n<p>特殊的倒推法<br />\n问题等价于<span class=\"math inline\">\\(n\\)</span>个节点<span class=\"math inline\">\\(m\\)</span>条无向边<br />\n然后拆掉一些点和它们相连的所有边，每拆一个点就输出联通块个数<br />\n暴力肯定超时<br />\n有合并且无向，可以用并查集<br />\n需要想一个特殊的方法<br />\n我们不拆点，这样很困难<br />\n我们倒着加点<br />\n先把除了所有拆的点有关的所有边之外的剩下的边用并查集合并<br />\n这是拆掉这些点后的状态，枚举剩下的点求出联通块个数<br />\n然后从后往前加点，因为前面的点拆掉时后面的点还要连着<br />\n接下来每加一个点就把它们相连的边合并一下，然后合并时若两个点都在一个并查集则合并这两个点对联通块没有影响，若不在一个并查集那么合并，注意加一个节点可能合并多条边并减小多个联通块数目<br />\n然后把这个减小后的变量记录 下来逆序输出<br />\n我们要把所有要摧毁的点所相连的边存起来，以便于后面倒推加边，并且剩下的边要合并起来作为所有都拆毁后的联通块，联通块一定要边合并边统计，切忌最后哈希统计<br />\n我们如果哈希记下边，读拆毁点时找边太难了，但我们可以哈希记下拆毁点，再遍历边时找出拆毁点相连的边会容易，同时还可以合并剩下的边，这是哈希的第一个妙用<br />\n原来<span class=\"math inline\">\\(n\\)</span>个点<br />\n去掉<span class=\"math inline\">\\(k\\)</span>个后<span class=\"math inline\">\\(n-k\\)</span>个，此时每合并一次减小一个联通块</p>\n<p>接下来倒着加点，把点所连的边合并<br />\n注意：<br />\n有时一条边的另一个点也是拆毁点，此时要看先后顺序来决定是否连边<br />\n当拆毁点靠前时，实际上这个点现在已经被拆毁，不能向他连边<br />\n当拆毁点靠后时，这个点已经恢复，所以要向他连边<br />\n因为从后往前，所以每恢复一个点就要把<span class=\"math inline\">\\(hash\\)</span>改为<span class=\"math inline\">\\(2\\)</span>，即已恢复，此时可以向他连边，而非拆毁点肯定要向他连边，而<span class=\"math inline\">\\(hash\\)</span>为<span class=\"math inline\">\\(1\\)</span>的还处于拆毁状态，不连边<br />\n然后算联通块的个数<br />\n注意：<br />\n这里拆毁节点不是把边断开，而是连同点一块删除，因此加边后联通块不能减1</p>\n<pre><code>#include&lt;iostream&gt;\n#include&lt;cstdio&gt;\n#include&lt;cstring&gt;\n#include&lt;vector&gt;\nusing namespace std;\nint fa[400006];\nstruct edge{\n\tint a,b;\n}edges[200006];\nint goal[400006];\nint hash1[400006];//hash1数组记录这个节点状态，0为不是要摧毁的节点，1为当前已摧毁的节点，2为当前未摧毁的节点（即已倒退回来到这个节点）\nvector&lt;int&gt; edge2[400006];//每一个要摧毁的节点所相连的边\nint out[400006];//因为从后往前加边，所以要逆序输出\nint num=0;\ninline int finds(int x){\n\tif(fa[x]==x)return x;\n\treturn fa[x]=finds(fa[x]);\n}\ninline void inserts(int x,int y,int a,int b){\n//\tif(a==b)return ;\n\tfa[a]=b;\n}\nint main(){\n\tmemset(hash1,0,sizeof hash1);\n\tfor(int i=0;i&lt;400006;++i){\n\t\tfa[i]=i;\n\t}//不要memset -1，这样后面要一个个改，要提前初始化好\n\tint n,m;\n\tcin&gt;&gt;n&gt;&gt;m;\n\tfor(int i=0;i&lt;m;++i){\n\t\tint x,y;\n\t\tcin&gt;&gt;x&gt;&gt;y;\n\t\tedges[i].a =x;//edge数组存边\n\t\tedges[i].b=y;\n\t}\n\tint k;\n\tcin&gt;&gt;k;\n\tfor(int i=0;i&lt;k;++i){\n\t\tcin&gt;&gt;goal[i];\n\t\thash1[goal[i]]=1;//哈希表定为1因为这个点是已经拆毁了的\n\t}\n\tint lian1=n-k;\n\tfor(int i=0;i&lt;m;++i){\n\t\tif(hash1[edges[i].a ]==1){\n\t\t\tedge2[edges[i].a].push_back(edges[i].b );\n\t\t\t \n\t\t}//这两个if要并列不要else，因为两个a b点有可能都是要拆毁的点\n\t\tif(hash1[edges[i].b ]==1){\n\t\t\tedge2[edges[i].b].push_back(edges[i].a );\n\t\t\t \n\t\t}\n\t\tif((!hash1[edges[i].a ])&amp;&amp;(!hash1[edges[i].b ])){\n\t\t\tint root1=finds(edges[i].a ),root2=finds(edges[i].b);//如果两个都不拆毁，那么就要合并来算出联通块\n\t\t\tif(root1!=root2){//根节点相同时合并没有用，联通块不变\n\t\t\t\tinserts(edges[i].a,edges[i].b,root1,root2);\n\t\t\t\tlian1-=1;\t\n\t\t\t}\n\t\t}\n\t}\n\t//cout&lt;&lt;lian1&lt;&lt;endl;\n\tout[num]=lian1;\n\t++num;\n\tfor(int i=k-1;i&gt;=0;--i){//要等于0，因为全部恢复后是全连好的联通块，是要求输出的\n\t\tint root1=finds(goal[i] );\n\t\tint fl1=1,fl2=1;//fl1是看这个点是否孤立，若整个遍历没有可以连的边说明它是孤立的，此时恢复后联通块反而加1，fl2看这个点是否是第一次连边\n\t\t若是，说明这是把原先不存在的点和一个集合连边，此时一旦连起之后联通块不减少，因为原先这个点不存在，而现在连起之后就存在了\n\t\t而若不是第一次连边，那么这个点已经存在了，此时它与其他点构成了集合\n\t\t那么这是连边就能将联通块个数减一\n\t\tfor(int j=0;j&lt;edge2[goal[i]].size();++j){\n\t\t\tif(hash1[edge2[goal[i]][j]]!=1){\n\t\t\t\tfl1=0;\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tint root2=finds(edge2[goal[i]][j]);\n\t\t\t\t\n\t\t\t\tif(root1!=root2){\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tinserts(edge2[goal[i]][j],goal[i],root2,root1);\n\t\t\t\t\tif(fl2){\n\t\t\t\t\t\tfl2=0;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tlian1-=1;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\tif(fl1)lian1+=1;\n\t\thash1[goal[i]]=2;\n\t\tout[num++]=lian1;\n\t}\n\tfor(int i=num-1;i&gt;=0;--i){\n\t\tcout&lt;&lt;out[i]&lt;&lt;endl;\n\t}\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"p1111-修复公路\">P1111 修复公路</h3>\n<p><a href=\"https://www.luogu.com.cn/problem/P1111\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1111</a></p>\n<p>这是并查集的贪心算法<br />\n<span class=\"math inline\">\\(n\\)</span>个节点<span class=\"math inline\">\\(m\\)</span>条无向边，给定边的修好时间<br />\n求最小能使<span class=\"math inline\">\\(n\\)</span>个节点相互连通的时间<br />\n无向图，连边相当于合并，可以使用并查集<br />\n因为是最小。可以考虑贪心，先把边按时间由小到大排序并遍历<br />\n然后从小开始遍历，每遍历一条边就把这两个节点合并起来，用<span class=\"math inline\">\\(size\\)</span>数组记录根的尺寸，启发式合并，如果这个根的<span class=\"math inline\">\\(size\\)</span>是<span class=\"math inline\">\\(n\\)</span>，那就说明所有节点都在一个并查集中，就输出此时的时间，否则若到最后也没有联通，就输出<span class=\"math inline\">\\(-1\\)</span></p>\n<p>为什么贪心正确?<br />\n我们选择的时间是从小到大中刚刚保持联通的时间，假设有完成联通的时间比这个小的情况，那么之前遍历到的时间中就必定有这个时间，那么答案就会更小，而如果有联通时间比这个大的话那么这个时间下已经保持联通，再加边也没有用，不如这个更小的时间<br />\n虽然前面合并的时候有一些对联通无用的重复边被加上了，但这并不影响答案，因为我们不求和，而是求一个满足条件的最小值，时间是一点点流逝的，修建公路是同步进行的，修这些无用的公路之时也在修有用的公路，所以这些重复边对答案没有影响<br />\n这个题与<br />\nP1396 营救</p>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P1396\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1396</a><br />\n有相似之处</p>\n<h3 id=\"p1396-营救\">P1396 营救</h3>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P1396\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P1396</a></p>\n<p>这是个重点题<br />\n题目的意思是说找一条从<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>的路径使其边权的最大值是所有每条<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>的路径中边权最大值最小的那个<br />\n就是说<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>的某条路径权值是这条<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span> 路径中边权的最大值<br />\n而要求一条路径使其权值最小，输出这个最小值</p>\n<p>而最小值最大是指<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>某条路径权值是这条路径中边权的最小值<br />\n要求1条路径使得权值最大</p>\n<p>也可以按边权从小到大排序，从小开始合并，直到刚好<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>联通，输出这个权值</p>\n<p>为什么成立呢？</p>\n<p>考虑这个权值显然是这里<span class=\"math inline\">\\(s\\)</span>到<span class=\"math inline\">\\(t\\)</span>边权中的最大值，但如何保证它是所有路径中最小的？<br />\n假设还有联通路径的最大值比这个还小，那么这条路径的所有边权都比这个还小，那么它们应该在这个的前面访问到，如果前面能构成联通，那么就会更早选择，而不会选择这个，所以是这个最小的</p>\n<p>最小值最大就应该从大到小排序合并到刚好联通为止<br />\n而这个权值也是当前路径的最小值。<br />\n假设还有联通路径的最小值比这个还大，那么路径所有边权都比这个大，那么它们就会在这个之前访问，若能构成联通就会更早选择，可是选择了这个就说明没有比这个还大的解</p>\n<h3 id=\"p2330-scoi2005繁忙的都市\">P2330 [SCOI2005]繁忙的都市</h3>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P2330\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P2330</a></p>\n<p>改造的道路尽量少就是要刚好保持联通不要有无用的边<br />\n所以从小到大排序合并时如果当前的两个点已经在一个并查集中就说明这条边无用，不要统计数量，跳过</p>\n<h3 id=\"p2121-拆地毯\">P2121 拆地毯</h3>\n<p>来自 <a href=\"https://www.luogu.com.cn/problem/P2121\" rel=\"noopener nofollow\" target=\"_blank\">https://www.luogu.com.cn/problem/P2121</a></p>\n<p>不要求联通，只是要求取的点不能有环<br />\n所以就像星球大战那样先把所有边拆掉，然后按权值从大到小排序<br />\n注意这里统计和，从大到小遍历，把当前两个点合并，如果发现已经在一个并查集就说明已经联通，再加边就会形成环，就不要把这个权值加进去</p>\n<p>一直加到<span class=\"math inline\">\\(k\\)</span>个真正的地毯（不成环），输出和<br />\n因为这是从大到小最大的<span class=\"math inline\">\\(k\\)</span>个或是除去一些之后最大的<span class=\"math inline\">\\(k\\)</span>个<br />\n所以和是最大的</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>黄粱一梦，终是一空</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/hicode002/\" target=\"_blank\">hicode002</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/hicode002/p/-/union_set\" target=\"_blank\">https://www.cnblogs.com/hicode002/p/-/union_set</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 19:57</span>&nbsp;\n<a href=\"https://www.cnblogs.com/hicode002\">hicode002</a>&nbsp;\n阅读(<span id=\"post_view_count\">33</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "PostgreSQL：新增语句：特殊处理：ON CONFLICT ... DO (UPDATE SET ...)/(NOTHING)",
      "link": "https://www.cnblogs.com/kakarotto-chen/p/19538290",
      "published": "",
      "description": "<h2>\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kakarotto-chen/p/19538290\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 15:16\">\n    <span>PostgreSQL：新增语句：特殊处理：ON CONFLICT ... DO (UPDATE SET ...)/(NOTHING)</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"postbody\">\n            <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1普通的insert-into\">1、普通的insert into</h2>\n<ul>\n<li>如果（主键/唯一建）存在，则会报错</li>\n<li>新需求：就算冲突也不报错，用其他处理逻辑</li>\n</ul>\n<h2 id=\"2基本语法insert-into--on-conflict--do-update-set-nothing\">2、基本语法（INSERT INTO ... ON CONFLICT (...) DO (UPDATE SET ...)/(NOTHING)）</h2>\n<ul>\n<li>语法图</li>\n</ul>\n<div class=\"mermaid\">flowchart TD\n    A[开始: INSERT发生主键/唯一冲突] --&gt; B{冲突后的期望是?}\n    B --&gt;|“保留旧数据，&lt;br&gt;静默跳过”| C[使用 ON CONFLICT DO NOTHING]\n    B --&gt;|“用新数据替换或修改旧数据”| D[使用 ON CONFLICT DO UPDATE SET]\n    \n    D --&gt; E{需要精细控制吗?}\n    E --&gt;|“是，只更新部分字段”| F[在SET中仅指定目标字段]\n    E --&gt;|“是，需满足条件才更新”| G[添加WHERE子句]\n    E --&gt;|“否，全量覆盖”| H[使用EXCLUDED.*或指定所有字段]\n</div><ul>\n<li>🔀 两种核心处理逻辑<br />\n为了方便你对比和理解，我将它们总结在下表中：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">处理逻辑</th>\n<th style=\"text-align: left;\">关键字</th>\n<th style=\"text-align: left;\">核心行为与目的</th>\n<th style=\"text-align: left;\">类比</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>1. 静默放弃</strong></td>\n<td style=\"text-align: left;\"><strong><code>DO NOTHING</code></strong></td>\n<td style=\"text-align: left;\">如果冲突（数据已存在），就<strong>什么也不做</strong>，静默地保留现有数据，并让语句成功结束。</td>\n<td style=\"text-align: left;\"><strong>“无视”</strong>：看到店里已有同样的商品，就决定不放了，直接离开。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>2. 更新覆盖</strong></td>\n<td style=\"text-align: left;\"><strong><code>DO UPDATE SET ...</code></strong></td>\n<td style=\"text-align: left;\">如果冲突（数据已存在），就用<strong>新值更新</strong>已有的那条记录。</td>\n<td style=\"text-align: left;\"><strong>“置换”</strong>：看到店里已有同样的商品，就用你手里的新款替换掉旧款。</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>语法1：DO UPDATE SET</li>\n</ul>\n<pre><code class=\"language-sql\">INSERT INTO 表名 (列1, 列2, ...)\nVALUES (值1, 值2, ...)\nON CONFLICT (冲突列[可以多个]) \nDO UPDATE SET\n    列1 = EXCLUDED.列1,\n    列2 = EXCLUDED.列2,\n    ...;\n</code></pre>\n<ul>\n<li>语法2：DO NOTHING</li>\n</ul>\n<pre><code class=\"language-sql\">INSERT INTO table_name (column1, column2, ...)\nVALUES (value1, value2, ...)\nON CONFLICT (冲突列[可以多个])\nDO NOTHING;\n</code></pre>\n<h2 id=\"3示例\">3、示例</h2>\n<h3 id=\"31简单示例\">3.1、简单示例</h3>\n<pre><code class=\"language-sql\">-- 示例1: DO NOTHING - 确保数据唯一，重复则忽略\n-- 场景：收集用户邮箱，同一邮箱只记录第一次出现\nINSERT INTO user_emails (email, collected_at, source)\nVALUES ('alice@example.com', NOW(), '官网抽奖')\nON CONFLICT (email) \nDO NOTHING; -- 如果邮箱已存在，则静默跳过，不报错\n\n-- 示例2: DO UPDATE SET - 用最新信息覆盖旧记录\n-- 场景：更新用户的最后登录状态\nINSERT INTO user_sessions (user_id, last_login_ip, last_login_time, login_count)\nVALUES (123, '192.168.1.100', NOW(), 1)\nON CONFLICT (user_id) \nDO UPDATE SET\n    last_login_ip = EXCLUDED.last_login_ip, -- 使用本次尝试插入的新IP\n    last_login_time = EXCLUDED.last_login_time, -- 更新时间\n    login_count = user_sessions.login_count + 1; -- 在原有次数上累加\n</code></pre>\n<h3 id=\"32on-conflict-多列组合唯一约束示例\">3.2、ON CONFLICT 多列组合唯一约束示例</h3>\n<p><strong>场景说明</strong><br />\n假设我们有一个<strong>学生选课记录表</strong>，设计逻辑是：</p>\n<ul>\n<li>单个学生可以选多门课</li>\n<li>单门课程可以被多个学生选</li>\n<li>但 <strong>一个学生不能重复选同一门课</strong>（即 <code>(student_id, course_id)</code> 组合必须唯一）</li>\n</ul>\n<p><strong>示例表结构</strong></p>\n<pre><code class=\"language-sql\">CREATE TABLE student_courses (\n    -- 自增主键，但不是业务唯一键\n    id SERIAL PRIMARY KEY,\n    student_id INT NOT NULL,\n    course_id INT NOT NULL,\n    selected_at TIMESTAMP DEFAULT NOW(),\n    status VARCHAR(20) DEFAULT 'active',\n\n    -- 关键：为(student_id, course_id)创建组合唯一约束\n    CONSTRAINT unique_student_course UNIQUE (student_id, course_id)\n);\n</code></pre>\n<p><strong>示例数据</strong><br />\n假设表中已有数据：</p>\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>student_id</th>\n<th>course_id</th>\n<th>selected_at</th>\n<th>status</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1001</td>\n<td>101</td>\n<td>2024-01-01</td>\n<td>active</td>\n</tr>\n<tr>\n<td>2</td>\n<td>1001</td>\n<td>102</td>\n<td>2024-01-02</td>\n<td>active</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1002</td>\n<td>101</td>\n<td>2024-01-03</td>\n<td>active</td>\n</tr>\n</tbody>\n</table>\n<p><strong>场景1：尝试重复选课 → 使用 DO NOTHING</strong><br />\n学生1001想再次选择课程101（已存在），我们静默拒绝：</p>\n<pre><code class=\"language-sql\">INSERT INTO student_courses (student_id, course_id, selected_at)\nVALUES (1001, 101, NOW()) -- (1001,101)组合已存在！\nON CONFLICT (student_id, course_id) -- 指定两列组合为冲突目标\nDO NOTHING; -- 什么都不做，防止重复选课\n\n-- 结果：语句执行成功，但没有插入新行\n-- 表数据保持不变\n</code></pre>\n<p><strong>场景2：尝试重复选课 → 使用 DO UPDATE SET</strong><br />\n学生1001重复选课101，但我们允许更新选择时间和状态：</p>\n<pre><code class=\"language-sql\">INSERT INTO student_courses (student_id, course_id, selected_at, status)\nVALUES (1001, 101, NOW(), 'renewed') -- 再次尝试选择已选课程\nON CONFLICT (student_id, course_id) -- 检测(student_id, course_id)组合冲突\nDO UPDATE SET\n    selected_at = EXCLUDED.selected_at, -- 更新时间戳\n    status = EXCLUDED.status, -- 更新状态\n    id = student_courses.id -- 保持原id不变，避免主键冲突\n    \nRETURNING *; -- 返回更新后的行\n\n-- 结果：不会创建新行，而是更新id=1的记录\n-- 将selected_at更新为当前时间，status更新为'renewed'\n</code></pre>\n<p><strong>场景3：混合情况处理</strong><br />\n批量插入选课记录，处理各种冲突情况：</p>\n<pre><code class=\"language-sql\">INSERT INTO student_courses (student_id, course_id, selected_at)\nVALUES \n    (1001, 103, NOW()), -- 新组合：插入成功\n    (1001, 101, NOW()), -- 已存在组合：触发ON CONFLICT\n    (1002, 102, NOW())  -- 新组合：插入成功\nON CONFLICT (student_id, course_id)\nDO UPDATE SET\n    selected_at = EXCLUDED.selected_at,\n    status = 'refreshed'\nRETURNING student_id, course_id, selected_at;\n</code></pre>\n<p><strong>输出结果可能：</strong></p>\n<pre><code> student_id | course_id |       selected_at       \n------------+-----------+-------------------------\n       1001 |       103 | 2024-06-15 10:30:00.000  -- 新插入\n       1001 |       101 | 2024-06-15 10:30:00.000  -- 更新（冲突处理）\n       1002 |       102 | 2024-06-15 10:30:00.000  -- 新插入\n</code></pre>\n<h3 id=\"33其他多列唯一约束示例\">3.3、其他多列唯一约束示例</h3>\n<p>示例1：会议室预订系统</p>\n<pre><code class=\"language-sql\">-- 确保同一会议室在同一时间段不被重复预订\n-- 唯一约束：(room_id, date, time_slot)\nINSERT INTO room_bookings (room_id, date, time_slot, booker_name)\nVALUES (101, '2024-06-20', '09:00-10:00', '张三')\nON CONFLICT (room_id, date, time_slot)\nDO NOTHING; -- 时间段冲突则直接拒绝\n</code></pre>\n<p><strong>示例2：用户-产品评分表</strong></p>\n<pre><code class=\"language-sql\">-- 确保一个用户对同一产品只能评分一次\n-- 唯一约束：(user_id, product_id)\nINSERT INTO product_ratings (user_id, product_id, rating, review)\nVALUES (5001, 3005, 5, '非常好用')\nON CONFLICT (user_id, product_id)\nDO UPDATE SET\n    rating = EXCLUDED.rating,\n    review = EXCLUDED.review,\n    rated_at = NOW();\n</code></pre>\n<p><strong>关键要点总结</strong></p>\n<ol>\n<li><strong>语法格式</strong>：<code>ON CONFLICT (column1, column2, ...)</code> 用括号包含多个列</li>\n<li><strong>约束要求</strong>：这些列必须已定义组合唯一约束（可以是复合主键或复合唯一约束）</li>\n<li><strong>冲突检测</strong>：只有当<strong>所有指定列的值都完全匹配</strong>时，才被认为是冲突</li>\n<li><strong>常见场景</strong>：多对多关系表、时间-资源组合、用户-实体关联表等</li>\n</ol>\n<p>这种多列约束特别适合处理<strong>业务层面的组合唯一性要求</strong>，而不仅仅是技术上的主键唯一性。</p>\n<h2 id=\"4特殊参数解析冲突列可以多个\">4、特殊参数解析：冲突列[可以多个]</h2>\n<ul>\n<li>ON CONFLICT 后面必须指定一个：唯一约束（主键也可以）字段\n<ul>\n<li>多个字段唯一也可以</li>\n</ul>\n</li>\n</ul>\n<p><strong>关键机制</strong>：</p>\n<ul>\n<li>\n<p><strong>冲突目标</strong>：<code>ON CONFLICT</code> 后面必须指定一个<strong>唯一约束</strong>，通常是主键或唯一索引。当插入的数据在这个约束上与已有数据冲突时，就会触发 <code>UPDATE</code> 操作。</p>\n</li>\n<li>\n<p><strong>约束要求：这些列必须已定义组合唯一约束（可以是复合主键或复合唯一约束）</strong></p>\n</li>\n<li>\n<p><strong>EXCLUDED 伪表</strong>：在 <code>DO UPDATE SET</code> 子句中，你可以使用 <code>EXCLUDED.列名</code> 来引用<strong>本次尝试插入但发生了冲突的那些值</strong>，这是实现“用新值覆盖旧值”的关键。</p>\n</li>\n</ul>\n<h2 id=\"returning参数见下篇\">RETURNING参数，见下篇</h2>\n\n</div>\n<div class=\"clear\"></div>\n\n        </div>\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-01-27 15:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kakarotto-chen\">C_C_菜园</a>&nbsp;\n阅读(<span id=\"post_view_count\">165</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "langchain 快速入门(六)：实现多agent协作",
      "link": "https://www.cnblogs.com/ClownLMe/p/19538384",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ClownLMe/p/19538384\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 14:27\">\n    <span>langchain 快速入门(六)：实现多agent协作</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"简介\">简介</h1>\n<p><strong>多Agent协作</strong>能够将一个复杂的任务拆解成一个个子任务给专门的agent，能够解决复杂问题，实现复杂的ai工作流。</p>\n<h1 id=\"多agent协作\">多Agent协作</h1>\n<p>不同的Agent，有不同的能力，我们可能会有各种实际需求，例如：实时识别车牌位置（Yolo）-&gt;识别车牌内容（qwen-vl）-&gt; LLM管理记录车牌信息。通过多Agent协作的工作流，能够实现拍照答题，自动剪辑，ppt生成等一系列复杂问题。</p>\n<p>下面用一个简单的案例，来说明。</p>\n<h1 id=\"简单的多agent协作\">简单的多Agent协作</h1>\n<h3 id=\"示例\">示例</h3>\n<p>需求：查一下阿里、腾讯、百度的PE，并计算平均值。</p>\n<pre><code class=\"language-python\">import os\nimport operator\nfrom pydantic import BaseModel, Field\nfrom langchain_community.chat_models.tongyi import ChatTongyi\nfrom langchain_core.tools import tool\nfrom langchain_core.messages import HumanMessage, BaseMessage, ToolMessage, SystemMessage\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom typing import Annotated, List, Literal, TypedDict\nfrom langgraph.graph import StateGraph, END\n\nos.environ[\"DASHSCOPE_API_KEY\"] = \"apikey\"\nllm = ChatTongyi(model=\"qwen-plus\")\n\n@tool\ndef web_search(query: str):\n    \"\"\"用于查找最新的股票数据、公司财报信息。\"\"\"\n    results = []\n    if \"阿里\" in query: results.append(\"阿里巴巴(BABA) PE: 15.5\")\n    if \"腾讯\" in query: results.append(\"腾讯控股(0700) PE: 18.2\")\n    if \"百度\" in query: results.append(\"百度(BIDU) PE: 11.8\")\n    \n    if not results:\n        return \"未找到数据\"\n    return \" ; \".join(results)\n\n@tool\ndef python_calculator(code: str):\n    \"\"\"用于计算。输入必须是 python 代码。\"\"\"\n    try:\n        result = eval(code)\n        return f\"计算结果: {result}\"\n    except Exception as e:\n        return f\"计算错误: {e}\"\n\ndef create_agent(state: dict, llm, tools, system_prompt):\n    llm_tools = llm.bind_tools(tools)\n    \n    prompt = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n    response = llm_tools.invoke(prompt)\n\n    results = [response]\n\n    for tool_call in response.tool_calls:\n        func_name = tool_call[\"name\"]\n        args = tool_call[\"args\"]\n        call_id = tool_call[\"id\"]\n        \n        func = next((t for t in tools if t.name == func_name), None)\n\n        if func:\n            tool_output = func.invoke(args)\n            tool_msg = ToolMessage(\n                content=str(tool_output),\n                name=func_name,\n                tool_call_id=call_id\n            )\n            results.append(tool_msg)\n\n    return {\"messages\": results}\n\nclass State(TypedDict):\n    messages: Annotated[List[BaseMessage], operator.add]\n    next: str\n\ndef researcher_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[web_search],\n        system_prompt=\"你是一个研究员。只负责查数据，找到数据后直接输出原话，不需要计算。\"\n    )\n\ndef coder_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[python_calculator],\n        system_prompt=\"你是一个程序员。根据上面研究员查到的数据，写代码计算平均值。\"\n    )\n\ndef finish_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[],\n        system_prompt=\"任务完成，简短的总结最终结果。\"\n    )\n\ndef supervisor_node(state):\n    system_prompt = (\n        \"你是项目经理。根据对话历史决定下一步交给谁。\"\n        \"查数据找 Researcher，计算找 Coder，识别图片找 Photographer。\"\n        \"如果任务完成，必须选择 FINISH。\"\n    )\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\"),\n        (\"system\", \"根据以上情况，请做出选择。\"),\n    ])\n\n    class RouteResponse(BaseModel):\n        next: Literal[\"Researcher\", \"Coder\", \"FINISH\"] = Field(\n            ..., \n            description=\"下一步交给谁？如果任务完成请选 FINISH\"\n        )\n\n    chain = prompt | llm.with_structured_output(RouteResponse)\n\n    response = chain.invoke(state)\n\n    return {\"next\": response.next}\n\ndef init_agent():\n    workflow = StateGraph(State)\n    workflow.add_node(\"Researcher\", researcher_node)\n    workflow.add_node(\"Coder\", coder_node)\n    workflow.add_node(\"Supervisor\", supervisor_node)\n    workflow.add_node(\"Finish\", finish_node)\n\n    workflow.add_edge(\"Researcher\", \"Supervisor\")\n    workflow.add_edge(\"Coder\", \"Supervisor\")\n    workflow.add_edge(\"Finish\", END)\n    workflow.add_conditional_edges(\n        \"Supervisor\",\n        lambda state: state[\"next\"],{\n        \"Researcher\": \"Researcher\",\n        \"Coder\": \"Coder\",\n        \"FINISH\": \"Finish\",\n    })\n\n    workflow.set_entry_point(\"Supervisor\")\n\n    return workflow.compile()\n\nif __name__ == \"__main__\":\n    agent = init_agent()\n    for result in agent.stream({\n        \"messages\": [HumanMessage(content=\"查一下阿里、腾讯、百度的PE，并计算平均值。\")]\n        }):\n        for key, value in result.items():\n            if key == \"Supervisor\":\n                print(\"[\" + key + \"] 去向: \" + value[\"next\"])\n            else:\n                print(\"[\" + key + \"] 回复: \" + value['messages'][-1].content)\n\n</code></pre>\n<h3 id=\"代码解释\">代码解释</h3>\n<p>代码一共用到了4个agent：</p>\n<ol>\n<li>agent Researcher，其有一个工具，负责搜索某些内容</li>\n<li>agent coder，其有一个工具，负责进行精确计算</li>\n<li>agent finish，其没有工具，负责总结内容</li>\n<li>agent Supervisor，其没有工具，负责管理上面3个agent，决定任务的去向<br />\n上面案例使用的是langgraph组件，这里就不详细讲解了，请看之前文章。</li>\n</ol>\n<p><strong>代码流程：</strong> 初始化工具库-&gt;初始化agent-&gt;构建图-&gt;运行</p>\n<h3 id=\"初始化工具库\">初始化工具库</h3>\n<pre><code class=\"language-python\">@tool\ndef web_search(query: str):\n    \"\"\"用于查找最新的股票数据、公司财报信息。\"\"\"\n    results = []\n    if \"阿里\" in query: results.append(\"阿里巴巴(BABA) PE: 15.5\")\n    if \"腾讯\" in query: results.append(\"腾讯控股(0700) PE: 18.2\")\n    if \"百度\" in query: results.append(\"百度(BIDU) PE: 11.8\")\n    \n    if not results:\n        return \"未找到数据\"\n    return \" ; \".join(results)\n\n@tool\ndef python_calculator(code: str):\n    \"\"\"用于计算。输入必须是 python 代码。\"\"\"\n    try:\n        result = eval(code)\n        return f\"计算结果: {result}\"\n    except Exception as e:\n        return f\"计算错误: {e}\"\n</code></pre>\n<p>这里的<code>web_search</code>使用的是虚假的模拟信息，上面的工具描述不够完整，但是能用，如果用实际案例，请描述完整，工具的描述参考之前文章。</p>\n<h1 id=\"初始化agent\">初始化agent</h1>\n<h5 id=\"其他3个agent\">其他3个agent</h5>\n<pre><code class=\"language-python\">def create_agent(state: dict, llm, tools, system_prompt):\n    llm_tools = llm.bind_tools(tools)\n    \n    prompt = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n    response = llm_tools.invoke(prompt)\n\n    results = [response]\n\n    for tool_call in response.tool_calls:\n        func_name = tool_call[\"name\"]\n        args = tool_call[\"args\"]\n        call_id = tool_call[\"id\"]\n        \n        func = next((t for t in tools if t.name == func_name), None)\n\n        if func:\n            tool_output = func.invoke(args)\n            tool_msg = ToolMessage(\n                content=str(tool_output),\n                name=func_name,\n                tool_call_id=call_id\n            )\n            results.append(tool_msg)\n\ndef researcher_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[web_search],\n        system_prompt=\"你是一个研究员。只负责查数据，找到数据后直接输出原话，不需要计算。\"\n    )\n\ndef coder_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[python_calculator],\n        system_prompt=\"你是一个程序员。根据上面研究员查到的数据，写代码计算平均值。\"\n    )\n\ndef finish_node(state):\n    return create_agent(\n        state=state,\n        llm=llm,\n        tools=[],\n        system_prompt=\"任务完成，简短的总结最终结果。\"\n    )\n</code></pre>\n<p>流程相对简单，<code>create_agent</code>细节前面文章已经讲解，这里就不废话了。</p>\n<h5 id=\"管理agent\">管理agent</h5>\n<pre><code class=\"language-python\">def supervisor_node(state):\n    system_prompt = (\n        \"你是项目经理。根据对话历史决定下一步交给谁。\"\n        \"查数据找 Researcher，计算找 Coder，识别图片找 Photographer。\"\n        \"如果任务完成，必须选择 FINISH。\"\n    )\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\"),\n        (\"system\", \"根据以上情况，请做出选择。\"),\n    ])\n\n    class RouteResponse(BaseModel):\n        next: Literal[\"Researcher\", \"Coder\", \"FINISH\"] = Field(\n            ..., \n            description=\"下一步交给谁？如果任务完成请选 FINISH\"\n        )\n\n    chain = prompt | llm.with_structured_output(RouteResponse)\n\n    response = chain.invoke(state)\n\n    return {\"next\": response.next}\n</code></pre>\n<p>这一步需要简单说明：</p>\n<pre><code class=\"language-python\">class RouteResponse(BaseModel):\n    next: Literal[\"Researcher\", \"Coder\", \"FINISH\"] = Field(\n        ..., \n        description=\"下一步交给谁？如果任务完成请选 FINISH\"\n    )\nchain = prompt | llm.with_structured_output(RouteResponse)\n</code></pre>\n<ul>\n<li>LLM中的<code>with_structured_output</code>方法是langchain提供的一个组件，功能是，限定LLM的输出格式，返回相应格式的字典。</li>\n<li>定义输出格式限定的类：</li>\n</ul>\n<ol>\n<li>该类是<code>BaseModel</code>的子类</li>\n<li><code>Literal</code>是选择，要求ai从<code>\"Researcher\", \"Coder\", \"FINISH\"</code>三选一</li>\n<li><code>Field</code>描述变量，尽量详尽，描述+例子，因为是给大模型看的</li>\n</ol>\n<pre><code class=\"language-python\">class classname(BaseModel):\n\tfieldname: fieldtype = Field(..., description=\"描述\")\n</code></pre>\n<h3 id=\"构建图重要\">构建图（重要）</h3>\n<pre><code class=\"language-python\">def init_agent():\n    workflow = StateGraph(State)\n    workflow.add_node(\"Researcher\", researcher_node)\n    workflow.add_node(\"Coder\", coder_node)\n    workflow.add_node(\"Supervisor\", supervisor_node)\n    workflow.add_node(\"Finish\", finish_node)\n\n    workflow.add_edge(\"Researcher\", \"Supervisor\")\n    workflow.add_edge(\"Coder\", \"Supervisor\")\n    workflow.add_edge(\"Finish\", END)\n    workflow.add_conditional_edges(\n        \"Supervisor\",\n        lambda state: state[\"next\"],{\n        \"Researcher\": \"Researcher\",\n        \"Coder\": \"Coder\",\n        \"FINISH\": \"Finish\",\n    })\n\n    workflow.set_entry_point(\"Supervisor\")\n\n    return workflow.compile()\n</code></pre>\n<p>这一步相当于连接工作流，构建的流程图如下：</p>\n<pre><code>       +---------------------------+\n       |           开始             |\n       +-------------+-------------+\n                     |\n                     v\n       +---------------------------+\n       |       Supervisor          |&lt;----------------+\n       | (通过当前任务状态，返回next) |                 |\n       +-------------+-------------+                 |\n                     |(根据state中next判断去向)        |\n        _____________|_____________                  |\n       /             |             \\                 |\n      /              |              \\                |\n     v               v               v               |\n+------------+  +------------+  +------------+       |\n| Researcher |  |   Coder    |  |   Finish   |       |\n|  (Agent)   |  |  (Agent)   |  | (Cleanup)  |       |\n+-----+------+  +-----+------+  +-----+------+       |\n      |               |               |              |\n      |               |               v              |\n      |               |         +------------+       |\n      +---------------+         |    END     |       |\n              |                 +------------+       |\n              |                                      |\n              +--------------------------------------+\n                    (返回重新选择下一个agent)\n</code></pre>\n<p><strong>如果❤喜欢❤本系列教程，就点个关注吧，后续不定期更新~</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 14:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ClownLMe\">ClownLMe</a>&nbsp;\n阅读(<span id=\"post_view_count\">158</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "spring boot3--自动配置与手动配置",
      "link": "https://www.cnblogs.com/alineverstop/p/19537574",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/alineverstop/p/19537574\" id=\"cb_post_title_url\" title=\"发布于 2026-01-27 11:50\">\n    <span>spring boot3--自动配置与手动配置</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"springboot自动配置\">springboot自动配置</h1>\n<p>自动配置了大量组件，配置信息可以在application.properties文件中修改。</p>\n<p>当添加了特定的Starter POM后，springboot会根据类路径上的jar包来自动配置bean（比如：springboot发现类路径上的MyBatis相关类，springboot会自动配置MyBatis相关的bean）。</p>\n<p>springboot使用默认配置来设置这些功能，开发人员也可以自定义配置来覆盖默认配置。</p>\n<h2 id=\"这些配置信息如何生效的\">这些配置信息如何生效的？</h2>\n<p>通过@ConfigurationProperties注解将配置信息注入到组件中的属性类的。属性类一般以Properties结尾。比如tomcat组件的ServerProperties类，就是将配置信息中server开头的配置注入到属性中，比如server.port=8080会被绑定到属性中</p>\n<pre><code class=\"language-java\">@ConfigurationProperties(\"server\")\npublic class ServerProperties {\n    private @Nullable Integer port;\n    private @Nullable InetAddress address;\n  .....\n}\n</code></pre>\n<h2 id=\"自动配置是按需加载的\">自动配置是按需加载的</h2>\n<p>springboot提供很多自动配置类，这些自动配置不是全部生效，它是按需加载的，导入了哪个启动器，则该启动器对应的配置类才会被加载。</p>\n<p>任何启动器都会关联一个启动器：spring-boot-Starter，它是springboot框架最核心的启动器。</p>\n<p>spring-boot-Starter又关联引入spring-boot-auto从figure。所有的自动配置类都在这里。</p>\n<p>自动配置类用来创建相应的组件。</p>\n<h2 id=\"按需加载如何实现\">按需加载如何实现？</h2>\n<p>使用条件注解可以实现按需加载。</p>\n<p>条件注解基于某些条件决定是否应该创建一个bean。这些注解通常用在自动配置类上，以确保只有在特定条件满足时才会应用相应的配置。</p>\n<p>条件注解可以用在类上，也可以用在方法上。</p>\n<p>常见的条件注解有：</p>\n<ul>\n<li>@ConditionalOnClass 指定类存在时才创建bean</li>\n<li>@ConditionalOnMissingClass 指定类不存在时才创建bean</li>\n<li>@ConditionalOnBean 容器中存在指定bean时才创建bean</li>\n<li>@ConditionalOnMissingBean 容器中不存在指定bean时才创建bean</li>\n<li>@ConditionalOnProperty 配置文件中存在指定属性时，才创建bean</li>\n<li>@ConditionalOnResource 指定资源存在时才创建bean</li>\n<li>@ConditionalOnWebApplication 应用程序是Web应用时才创建bean</li>\n<li>@ConditionalOnNotWebApplication 应用程序不是Web应用时才创建bean</li>\n</ul>\n<h2 id=\"修改默认的包扫描规则\">修改默认的包扫描规则</h2>\n<p>修改扫描规则有2种方式：</p>\n<p>在主入口类上添加以下注解的任意一个都可以修改包扫描规则（扫描com包及其子孙包）</p>\n<ol>\n<li>\n<pre><code class=\"language-java\">@ComponentScan(\"com\")\n</code></pre>\n</li>\n<li>\n<pre><code class=\"language-java\">@SpringBootApplication(scanBasePackages = \"com\")\n</code></pre>\n</li>\n</ol>\n<h1 id=\"自动配置的实现原理\">自动配置的实现原理</h1>\n<ol>\n<li>\n<p>程序从main方法开始执行，主入口类上使用@SpringBootApplication进行标注</p>\n</li>\n<li>\n<p>@SpringBootApplication是复合注解，代表以下三个注解的功能</p>\n<p>a. @SpringBootConfiguration:它被@Configuration标注。表明主入口类是一个配置类，此时该配置开始加载。</p>\n<p>b. @ComponentScan 默认扫描主入口类所在包及其子孙包，因此spring-boot-autoconfigure 自动配置类是无法加载的，那么这些自动配置类又是怎么生效的呢？</p>\n<p>c. <strong>@EnableAutoConfiguration 该注解的作用就是启用自动配置</strong></p>\n</li>\n<li>\n<p>@EnableAutoConfiguration  被@Import({AutoConfigurationImportSelector.class})标注</p>\n</li>\n</ol>\n<p>​        @Import({AutoConfigurationImportSelector.class})的作用是将AutoConfigurationImportSelector作为一个bean加载到Ioc容器中</p>\n<p>​        这个bean的作用是：负责收集和选择所有符合条件的自动配置类。</p>\n<h2 id=\"总结\">总结</h2>\n<ol>\n<li>运行环境准备阶段\n<ul>\n<li>引入Web启动器</li>\n<li>最终传递引入了自动配置的jar包</li>\n<li>自动配置的jar包中有152个自动配置类，到此运行环境准备完毕</li>\n</ul>\n</li>\n<li>运行阶段\n<ul>\n<li>@EnableAutoConfiguration  启用自动配置，将152个自动配置类全部加载到Ioc容器中。然后根据开发场景筛选出必须得自动配置类</li>\n<li>自动配置类加载了很多组件</li>\n<li>每个组件需要的数据来自属性类</li>\n<li>属性类的属性来自配置文件</li>\n</ul>\n</li>\n</ol>\n<p>总之一句话。导入启动器，修改配置文件。就可以完成对应功能的开发。</p>\n<h1 id=\"springmvc配置\">springmvc配置</h1>\n<pre><code class=\"language-properties\"># 让springboot的静态资源处理失效\nspring.web.resources.add-mappings=false\n# 配置静态资源的访问URL\nspring.mvc.static-path-pattern=/**\n#  静态资源文件存储位置默认配置\nspring.web.resources.static-locations=classpath:/META-INF/resources/, classpath:/resources/, classpath:/static/, classpath:/public/\n\n</code></pre>\n<p>springboot对静态资源是如何处理的？</p>\n<p>什么样的URL ？访问哪个位置上的资源文件？</p>\n<h2 id=\"webjars\">webjars</h2>\n<p>webjars是现在前后端分离中比较重要的一种静态资源打包方式。</p>\n<p>webjars是一种常用的前端库（如jQuery）打包成jar包的形式，方便在java程序中使用。</p>\n<p>webjars提供了一种标准化的方式来管理前端库，使其更容易集成到java项目中，并且可以利用Maven的依赖管理功能。</p>\n<pre><code class=\"language-xml\">&lt;!--        webjars,将前端库打成jar包--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.webjars.npm&lt;/groupId&gt;\n            &lt;artifactId&gt;vue&lt;/artifactId&gt;\n            &lt;version&gt;3.5.12&lt;/version&gt;\n        &lt;/dependency&gt;\n</code></pre>\n<p>默认规则是：当请求路径是/wbjars/**,则会去classpath:/MEAT-INF/resources/webjars/找。</p>\n<h2 id=\"静态资源缓存处理\">静态资源缓存处理</h2>\n<p>静态资源缓存是指浏览器的缓存行为，浏览器可以缓存（js、CSS、图片、声音、视频）到浏览器中，下一次用户访问同样的资源就直接从缓存中获取，不再从服务器获取，这样能减少服务器压力，提高相应效率。</p>\n<p>可以通过配置来修改默认的缓存机制。</p>\n<pre><code class=\"language-properties\">＃静态资源缓存设置\n＃缓存有效期设置\nspring.web.resources.cache.period=3600\n# 缓存控制设置\nspring.web.resources.cache.cachecontrol.max-age=20\n# 是否启用最后一次修改时间的比对\nspring.web.resources.cache.use-last-modified=true\n</code></pre>\n<h2 id=\"静态indexhtml的支持\">静态index.html的支持</h2>\n<p>spring会自动处理位于静态资源目录下的index.html（文件名必须是index.html），使其成为应用程序的主页。</p>\n<p>注意：此时不能配置静态资源访问url（spring.mvc.static-path-pattern），必须使用默认的配置</p>\n<h2 id=\"faviconico\">favicon.ico</h2>\n<p>将favicon.ico放在静态资源根目录下，就会自动生效。</p>\n<h1 id=\"spring-boot的web手动配置静态资源处理\">spring boot的web手动配置（静态资源处理）</h1>\n<h2 id=\"编写代码的方式\">编写代码的方式</h2>\n<h3 id=\"第一种方式-实现webmvcconfigurer接口\">第一种方式 实现WebMvcConfigurer接口</h3>\n<pre><code class=\"language-java\">// 添加这个注解后，表示不再使用springboot提供的默认配置\n// @EnableWebMvc\n@Configuration\npublic class WebConfig implements WebMvcConfigurer {\n    \n    // 静态资源处理需要重写的方法\n    @Override\n    public void addResourceHandlers(ResourceHandlerRegistry registry) {\n        // 使用注册器registry 绑定 pathPatterns 以及真实的静态资源文件存储路径\n        registry.addResourceHandler(\"/abc/**\") // 配置路径访问模式\n                .addResourceLocations(\"classpath:/static1/\", \"classpath:/static2/\", \"classpath:/static3/\"); // 配置静态资源路径\n    }\n}\n</code></pre>\n<h3 id=\"第二种方式\">第二种方式</h3>\n<pre><code class=\"language-java\">@Configuration\npublic class WebConfig2 {\n\n    @Bean\n    public WebMvcConfigurer addResourceHandlers() {\n        return new WebMvcConfigurer() {\n            @Override\n            public void addResourceHandlers(ResourceHandlerRegistry registry) {\n                registry.addResourceHandler(\"/abc/**\") // 配置路径访问模式\n                        .addResourceLocations(\"classpath:/static1/\", \"classpath:/static2/\", \"classpath:/static3/\"); // 配置静态资源路径\n            }\n        };\n    }\n}\n</code></pre>\n<h1 id=\"web请求的路径匹配\">web请求的路径匹配</h1>\n<pre><code class=\"language-properties\"># 前端请求的url 匹配到controller中的某个方法\n# 使用ant风格的路径匹配规则，默认值是path_pattern_matcher\n# path_pattern_matcher兼容且支持ant风格\n# 在ant风格中** 可以出现在任何位置，但在path_pattern_matcher风格中，** 只能出现在末尾\n# spring6 下的ant风格 ** 也只能出现在末尾\nspring.mvc.pathmatch.matching-strategy=ant_path_matcher\n</code></pre>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/alineverstop/\" target=\"_blank\">NE_STOP</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/alineverstop/p/19537574\" target=\"_blank\">https://www.cnblogs.com/alineverstop/p/19537574</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-27 11:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/alineverstop\">NE_STOP</a>&nbsp;\n阅读(<span id=\"post_view_count\">129</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}