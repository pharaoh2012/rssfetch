{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "Lab4-Lab: traps && MIT6.1810操作系统工程【持续更新】 _",
      "link": "https://www.cnblogs.com/xiaobai1523/p/19610063",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaobai1523/p/19610063\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 23:12\">\n    <span>Lab4-Lab: traps &amp;&amp; MIT6.1810操作系统工程【持续更新】 _</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"lab-traps\">Lab: traps</h1>\n<p>​\t在这一个lab当中<a href=\"https://pdos.csail.mit.edu/6.828/2025/labs/traps.html\" rel=\"noopener nofollow\" target=\"_blank\">6.1810 / Fall 2025</a>它要求我们理解xv6当中函数调用时的堆栈情况以及如何操控内存寻找多级函数调用的起始，更重要的是它带我们直观地感受到了<strong>中断的全过程</strong>。</p>\n<p>​\t在此之前，官网给出了一些提示：</p>\n<ul>\n<li>在开始编程之前，\t<a href=\"https://pdos.csail.mit.edu/6.828/2025/xv6/book-riscv-rev5.pdf\" rel=\"noopener nofollow\" target=\"_blank\">请阅读xv6教程的第4章</a>，以及相关的源码文件<code>kernel/trampoline.S</code>。</li>\n<li><code>kernel/trap.c</code>当中是处理所有中断的代码。</li>\n</ul>\n<h2 id=\"risc-v-assembly-简单\">RISC-V assembly (简单)</h2>\n<p>​\t在这个lab当中，要求我们阅读一些汇编代码，并且了解c语言的某些语句对应的汇编是怎样的，同时了解不同寄存器的不同职责（例如<strong>ra</strong>寄存器是存放返回地址的寄存器）。然后带我们了解了一下编译器在编译代码时，如何优化/简化我们的代码。最后带我们直观地理解了一下大端模式和小端模式的区别以及两者在面对<strong>多字节存储</strong>和<strong>单个数值</strong>存储所造成的不同的影响。</p>\n<h2 id=\"如何阅读汇编代码\">如何阅读汇编代码</h2>\n<p>​\t以下是截取了<code>call.asm</code>当中的一部分代码，这类代码是反汇编得来的结果。接下来将开始解析这段程序。</p>\n<pre><code class=\"language-assembly\">##这是c语言函数f的反汇编代码（通过截取编译器输出得到，不是手写的汇编代码，手写的汇编只有助记符，没有地址码和机器码）。\nint f(int x) {\n  ##对于这一行，e是十六进制的内存地址/偏移，1141是十六进制机器码。\n  ##再往后的addi  sp,sp,-16是将栈指针sp减16。（一般只有压栈的情况下才会修改栈指针）\n   e:\t1141                \taddi\tsp,sp,-16\n  ##对于这一行，10是十六进制的内存地址/偏移，e422是十六进制机器码。\n  ##再往后的sd\ts0,8(sp)是将寄存器s0的内容保存到栈的8偏移处（sp+8）。\n  10:\te422                \tsd\ts0,8(sp)\n  ##对于这一行，12是十六进制的内存地址/偏移，0800是十六进制机器码。\n  ##再往后的addi  sp,sp,16是将栈指针sp加16。（一般只有出栈的情况下才会修改栈指针）\n  12:\t0800                \taddi\ts0,sp,16\n  ##调用函数g\n  return g(x);\n}\n</code></pre>\n<h2 id=\"问题解答\">问题解答：</h2>\n<p>一、Which registers contain arguments to functions? For example, which register holds 13 in main's call to <code>printf</code>?（哪些寄存器包含函数的参数？例如，在main调用printf时，哪个寄存器存放着13？）</p>\n<p><strong>答：</strong>从main函数开始，有如下寄存器：</p>\n<ol>\n<li><strong>sp</strong>栈指针寄存器，用于存储当前栈顶地址。（入栈先减地址再入，出栈先出再增）。</li>\n<li><strong>ra</strong>返回地址寄存器，专门用于保存函数调用返回地址的寄存器。</li>\n<li><strong>s0</strong>保存寄存器，用于保存函数执行过程中需要持续使用的中间值、帧指针等。</li>\n<li><strong>a0~a7</strong>是函数的参数寄存器，传递函数参数时会用到。</li>\n</ol>\n<p>​\t在main调用printf时，寄存器<strong>a2</strong>存放着13。</p>\n<p>二、Where is the call to function <code>f</code> in the assembly code for main? Where is the call to <code>g</code>? (Hint: the compiler may inline functions.)（在main函数的汇编代码中，对函数f的调用在哪里？对g的调用又在哪里？（提示：编译器可能会内联函数。））</p>\n<p><strong>答</strong>：在main函数当中，对<strong>f</strong>的调用被简化为了一条指令：<code>li\ta1,12</code>，因为编译器在编译代码时，对于非常简单的函数数会进行<strong>内联优化</strong>（算出其结果，然后直接写入对于寄存器中，无需生成<strong><code>jal</code>/<code>jalr</code>调用指令</strong>）。对于<strong>g</strong>的调用会在<strong>f</strong>当中，但是由于函数<strong>g</strong>过于简单，所以对函数<strong>f</strong>进行了<strong>指令融合</strong>，即将函数<strong>g</strong>当中的指令逻辑融合到<strong>f</strong>当中。在本例子当中，<strong>g</strong>会做加3操作然后返回，然后我们可以在<strong>f</strong>当中直接进行加三操作，无需调用<strong>g</strong>。</p>\n<p>三、At what address is the function printf located?（函数printf位于哪个地址？）</p>\n<p><strong>答：</strong>在<code>call.asm</code>当中，有以下一行代码：</p>\n<pre><code class=\"language-assembly\">30:\t6c4000ef          \tjal\tra,6f4 &lt;printf&gt;\n</code></pre>\n<p>​\t其中<code>jal</code>是跳转指令，指令格式为：<code>jal ra 目标地址</code>,再结合后面的<code>&lt;printf&gt;</code>我们可以得知<strong><code>0x6f4</code></strong>是printf的地址，对应printf的入口。</p>\n<p>四、What value is in the register <code>ra</code> just after the <code>jalr</code> to <code>printf</code> in <code>main</code>?（在main函数中执行jalr到printf之后，寄存器ra中的值是什么？）</p>\n<p><strong>答：</strong>因为<strong>ra</strong>是返回地址寄存器，也就是说它里面保存的是执行完函数调用后应该返回的地址，所以此时在执行到printf后，<strong>ra</strong>内的值应该是指令<code>jal\tra,6f4 &lt;printf&gt;</code>的下一条指令的地址，也就是<strong><code>0x34</code></strong>。</p>\n<p>五、Run the following code.（运行接下来的代码）</p>\n<pre><code class=\"language-c\">\tunsigned int i = 0x00646c72;\n\tprintf(\"H%x Wo%s\", 57616, (char *) &amp;i);\n</code></pre>\n<p>What is the output? <a href=\"https://www.asciitable.com/\" rel=\"noopener nofollow\" target=\"_blank\">Here's an ASCII table</a> that maps bytes to characters.（输出是什么？这是一个将字节映射到字符的ASCII表。）</p>\n<p>The output depends on that fact that the RISC-V is little-endian. If the RISC-V were instead big-endian what would you set <code>i</code> to in order to yield the same output? Would you need to change <code>57616</code> to a different value?（输出取决于 RISC-V 是小端字节序这一事实。如果 RISC-V 是大端字节序，那么为了得到相同的输出，你会将 i 设为多少？你需要将 57616 改成其他值吗？）</p>\n<p><strong>答：</strong>输出内容如下（xv6默认小端模式）：</p>\n<pre><code class=\"language-powershell\">He110,World\n</code></pre>\n<ul>\n<li>小端模式：低地址存放低位，高地址存放高位。</li>\n<li>大端模式：低地址存放高位，高地址存放低位。</li>\n</ul>\n<p>​\t依照大端模式，我们需要将<strong>i</strong>进行修改，大小端模式只影响多字节的存储，而<strong>57616</strong>只是单个数值，不涉及多字节存储。为符合大端要求，我们需要将<strong>i</strong>修改为：<strong><code>0x726c6400</code></strong>即可。</p>\n<p>六、In the following code, what is going to be printed after <code>'y='</code>? (note: the answer is not a specific value.) Why does this happen?（在下面的代码中，'y='后面将会打印出什么？（注意：答案不是一个具体的值。）为什么会出现这种情况？）</p>\n<pre><code class=\"language-c\">\tprintf(\"x=%d y=%d\", 3);\n</code></pre>\n<p><strong>答：</strong>因为变量<strong>y</strong>没有对应的赋值，所以会输出一个<strong>未初始化的随机的值</strong>（类似：0,1385，-2294）。在汇编时，printf函数会用到两个寄存器，其中 a1负责存放3，a2没有指定要存放谁，所以里面的值是未知的。</p>\n<h2 id=\"backtrace中等\">Backtrace（中等）</h2>\n<p>​\t当一个函数调用另一个函数时，CPU 会将调用点的返回地址保存到栈上，这样被调用函数执行完后才能回到原来的位置继续执行。每次调用都会创建新的栈帧，并在栈帧中保存返回地址和上一层的栈帧指针。因此，如果我们知道当前函数的栈帧位置，就可以顺着栈帧链“回溯”，找到上一层函数的返回地址，再继续向上，直到遍历完整个调用链。我们把这个过程形象地称为“顺腾摸瓜”，意思是沿着栈帧链，一层层找到调用关系。</p>\n<p>​\t本 Lab 要求实现一个 <code>backtrace()</code> 函数，它从当前栈帧出发，沿着栈帧链打印每一层函数的返回地址。输出顺序应与调用链一致（从当前函数向上直到最初调用的内核入口）。</p>\n<p>​\t<strong>栈帧：</strong>指<strong>函数栈帧</strong>，是函数在运行时在栈上分配的一段内存，用来保存函数调用需要的信息（例如：返回地址，上一层函数的栈帧指针，局部变量，保存的寄存器）。</p>\n<h3 id=\"官网提示和个人解析\">官网提示和个人解析</h3>\n<p>​\t1、在<code>kernel/defs.h</code>在声明 <code>backtrace()</code> 函数原型，这样其他文件可以调用，并且在<code>kernel/printf.c</code>当中实现该函数。</p>\n<p>​\t2、由于我们需要获取当前的栈帧地址，所以官网给我们提供了一个<code>r_fp</code>函数，用于返回当前的栈帧地址。我们需要将这个函数复制到<code>kernel/riscv.h</code>当中的<strong><code>#ifndef __ASSEMBLER__ ... #endif</code></strong> 定义当中。</p>\n<p>​\t3、在实现该功能时，我们需要获取当前栈帧的地址，好在官网提供了<code>r_fp</code>函数，它返回一个<strong>uint64</strong>类型的数据（这是栈帧指针，指向的位置存放着真正的栈帧地址），对其解引用会得到当前的栈帧地址。</p>\n<p>​\t4、接下来我们开始“向上”寻找调用链上的函数，根据官网的提示，在<strong>“栈帧地址 - 8”</strong>的位置上存放的是上一层函数的返回地址，也是我们要打印的地址。在<strong>“栈帧地址 - 16”</strong>的位置上存放的是上一层函数栈帧的地址，在打印完毕后我们切换到上一层函数的栈帧，然后继续打印返回地址，然后再次向上寻找栈帧，直至到达顶端。</p>\n<p>​\t以下是xv6内核的相关约定（几乎每个函数调用的时候都会伴随以下汇编代码）：</p>\n<pre><code class=\"language-assembly\">addi sp, sp, -X    # 分配栈帧\nsd ra, 8(sp)       # 保存返回地址\nsd s0, 0(sp)       # 保存旧的 frame pointer（栈帧指针，指向存放栈帧的内存）\nmv s0, sp          # 更新 frame pointer（栈帧指针）\n</code></pre>\n<p>​\t更直观点：</p>\n<pre><code class=\"language-nginx\">s0 → 指向自己栈帧的 s0 存放位置 + 8\ns0-8 → ra\ns0-16 → 上一级 s0\n</code></pre>\n<p>​\t5、在向上寻找时也要注意越界的问题，在xv6当中，整个栈都在同一个页面当中，因此所有的栈帧都是在一个页面中（这也解释了为什么递归的层级多了会爆栈的原因，因为调用新的函数会创建新的栈帧，占用同一个栈的内存），所以我们需要保证我们在获取到新的栈帧的同时，要保证与刚才才处理过的栈帧处于同一页面，官网当中给出了<code>PGROUNDDOWN(fp)</code>宏来帮助我们判断当前fp的页面。同时也有一个忽略的点就是要保证地址是递减的，这样总会递减到当前页的边界，使得循环终止，如果忽略该条件，可能会导致地址加加减减跳不出本页，进而无限循环。</p>\n<p>​\t6、通过当前栈帧获取上一层函数的返回地址，并且打印。</p>\n<p>​\t7、通过当前栈帧获取上一层函数的栈帧，然后继续寻找。</p>\n<h3 id=\"相关代码\">相关代码</h3>\n<p>​\t在<code>kernel/printf.c</code>当中。</p>\n<pre><code class=\"language-c\">void backtrace(){\n  // 当前的栈帧\n  uint64 s0 = r_fp();\n  // 临时变量，最新的函数栈帧\n  uint64 temp = s0;\n  // 临时变量，用于接下来的比较\n  uint64 log = s0;\n  printf(\"backtrace:\\n\");\n  // 确保找到的栈帧和最新的栈帧是同一页，并且栈帧只能单调递减，不能出现环路，防止死循环。\n  while((PGROUNDDOWN(s0) == PGROUNDDOWN(temp)) &amp;&amp; (s0 &gt;= log )){\n    // 栈帧-8是返回地址，取出返回地址当中的值，以地址形式打印\n    uint64 ra = *(uint64 *)(s0 - 8);\n    printf(\"%p\\n\", (void *)ra);\n    // 临时变量保存当前栈帧，在保证栈帧单调递减的判断中使用\n    log = s0;\n    // 栈帧-16是上一层函数的栈帧\n    s0 = *(uint64*)(s0 - 16);\n  }\n}\n</code></pre>\n<p>​\t<strong>之后根据官网的提示进行实验结果的验证即可。</strong></p>\n<h2 id=\"alarm困难\">Alarm（困难）</h2>\n<p>​\t在这一lab当中，要求我们<strong>实现用户态的定时“中断”功能</strong>。用户进程可以向操作系统注册一个函数（handler），并且要求CPU在每隔n个tick后执行该函数一次，在handler在被执行时，用户程序需要“被暂停”，直到handler执行完毕后再返回用户程序，这个过程类似于硬硬件中断机制，只不过采用了软件的方法实现。</p>\n<h3 id=\"官网提示和个人解析-1\">官网提示和个人解析：</h3>\n<p>​\t1、首先要求我们新添加两个系统调用，分别是：<strong><code>sigalarm(interval, handler)</code>和<code>sigreturn(void)</code></strong>，具体的添加方式详见：<a href=\"https://www.cnblogs.com/xiaobai1523/p/19530432\" target=\"_blank\">Lab2-system calls &amp;&amp; MIT6.1810操作系统工程【持续更新】 - 小白同学_C - 博客园</a>。与此同时，<code>sigalarm(interval, handler)</code>函数的第一个参数interval代表每隔多少和tick执行handler，第二个参数handler就代表CPU每个n个tick要执行函数的地址了。这就需要我们在进程的<code>proc</code>当中添加新的成员用于记录当前tick和当前已经过去了多少tick以及注册的函数指针。</p>\n<p>​\t2、如果应用程序调用 sigalarm (0, 0)，内核应停止生成周期性的警报调用。</p>\n<p>​\t3、handler执行时，需要我们暂停用户程序，也就是先将用户程序的代码保护起来，替换为handler的代码。待handler执行完毕后再将用户程序的代码恢复，这就要求我们在进程的<code>proc</code>当中添加相应的trapframe帧用于保存用户程序状态（和中断的思想一样，打断当前执行的程序→保护断点和现场→获得中断向量→执行中断处理程序→恢复断点和现场→被打断的程序继续执行）。</p>\n<p>​\t4、把<code>user/alarmtest.c</code> 添加到 Makefile 中。</p>\n<p>​\t5、记得把<code>sigalarm(interval, handler)</code>和<code>sigreturn(void)</code>添加到<code>user/user.h</code>当中。，格式如下：</p>\n<pre><code class=\"language-c\">\tint sigalarm(int ticks, void (*handler)());\n    int sigreturn(void);\n</code></pre>\n<p>​\t6、每过一个tick，硬件时钟就会触发一次中断，该中断在<code> kernel/trap.c</code> 的 <code>usertrap () </code>中处理，所以我们需要在这里进行修改。官网说了，只要发生定时器中断时，我们才需要修改/对比进程的时钟tick数。在如下判断体内实现“判断handler是否执行的相关逻辑”，并且保存用户程序的断点和将用户程序代码替换为handler就在此执行。</p>\n<pre><code class=\"language-c\">\tif(which_dev == 2) ...\n</code></pre>\n<p>​\t7、 当handler执行完毕后，也是调用了<code>sigreturn</code>函数时，要求我们返回当前进程的<strong>a0</strong>寄存器。</p>\n<h3 id=\"相关代码-1\">相关代码</h3>\n<p>​\t有关添加系统调用的代码在这里就先跳过了，可以翻翻博主之前的文章<a href=\"https://www.cnblogs.com/xiaobai1523/p/19530432\" target=\"_blank\">Lab2-system calls &amp;&amp; MIT6.1810操作系统工程【持续更新】 - 小白同学_C - 博客园</a>。</p>\n<p>​\t一、kernel/proc.h</p>\n<pre><code class=\"language-c\">// 在进程的proc当中新添加如下内容：\n  int alarmticks;              // 警报之间的滴答声\n  int alarmtickscount;         // 上次警报后的滴答声次数\n  uint64 alarmhandler;      // 闹钟滴答声过去时调用的处理程序\n  int inhandler;               // 是否正在处理alarm\n  struct trapframe alarm_tf; // 用于保存被 alarm 打断时的 trapframe\n</code></pre>\n<p>​\t二、kernel/sysproc.c</p>\n<pre><code class=\"language-c\">uint64\nsys_sigalarm(void)\n{\n  int ticks;\n  uint64 handler;\n\n  // 读取用户传入参数\n  argint(0, &amp;ticks);\n  argaddr(1, &amp;handler);\n\n  struct proc *p = myproc();\n\n  // 设置 alarmticks 和 alarmhandler\n  p-&gt;alarmticks = ticks;\n  p-&gt;alarmtickscount = 0;\n  // 如果 ticks 和 handler 都为 0，表示取消 alarm，所以将 alarmhandler 设置为 -1，表示不调用 handler\n  if(ticks == 0 &amp;&amp; handler == 0) {\n    p-&gt;alarmhandler = -1;\n  }else{\n    p-&gt;alarmhandler = handler;\n  }\n\n  return 0;\n}\n\nuint64 \nsys_sigreturn(void)\n{\n  struct proc *p = myproc();\n  // 恢复被 alarm 打断时的 trapframe，以便在 handler 处理完后继续被打断的程序\n  memmove(p-&gt;trapframe, &amp;p-&gt;alarm_tf, sizeof(struct trapframe));\n  // 处理完 alarm 后，重置 inhandler 和 alarmtickscount\n  p-&gt;inhandler = 0;\n  p-&gt;alarmtickscount = 0;\n  return p-&gt;trapframe-&gt;a0; // 返回用户程序中 a0 的值\n}\n</code></pre>\n<p>​\t三、kernel/trap.c</p>\n<pre><code class=\"language-c\">// 在usertrap函数的 if(which_dev == 2)... 当中添加如下内容：\n// 在时钟中断时，检查是否需要处理 alarm\n  if(which_dev == 2){\n    // 获取当前进程的指针\n    struct proc *p = myproc();\n    // 如果当前进程设置了 alarmhandler，并且不在处理 alarm 的过程中，就检查是否需要调用 alarmhandler\n    // 注意，alarmhandler 的值为 -1 表示没有设置 handler（不调用），值为 0 表示正在处理 alarm，\n    // 所以只有当 alarmhandler 大于 0 时才表示设置了 handler 并且不在处理 alarm 的过程中\n    if(p-&gt;alarmhandler == 0 || p-&gt;alarmhandler != -1){\n      // 增加滴答声计数，并检查是否达到了 alarmticks，如果达到了，并且 alarmticks 大于 0，就调用 handler\n      p-&gt;alarmtickscount++;\n      // 如果达到了设定的滴答数，且设置了 alarmticks（大于 0），就调用 handler\n      if(p-&gt;alarmtickscount &gt;= p-&gt;alarmticks &amp;&amp; p-&gt;alarmticks &gt; 0 ){\n        p-&gt;alarmtickscount = 0;\n        // 调用用户设置的 alarm 处理程序\n        if(!p-&gt;inhandler){\n          // 设置当前正在处理 alarm，防止在处理 alarm 的过程中被再次打断调用 handler\n          p-&gt;inhandler = 1;\n          // 保存被打断时的 trapframe 到 alarm_tf 中，以便在 handler 处理完后恢复\n          memmove(&amp;p-&gt;alarm_tf, p-&gt;trapframe, sizeof(struct trapframe));\n          // 设置 trapframe 的 epc 为 handler 的地址，这样在 usertrapret() 时就会跳转到 handler 处执行\n          p-&gt;trapframe-&gt;epc = (uint64)p-&gt;alarmhandler;  \n\n        }\n        \n      }\n    }\n    yield();\n  }\n</code></pre>\n<h3 id=\"验收成果\">验收成果</h3>\n<pre><code class=\"language-shell\">xiaobai@***:~/xv6-labs-2025$ ./grade-lab-traps alarm\nmake: 'kernel/kernel' is up to date.\n== Test running alarmtest == (4.1s)\n== Test   alarmtest: test0 ==\n  alarmtest: test0: OK\n== Test   alarmtest: test1 ==\n  alarmtest: test1: OK\n== Test   alarmtest: test2 ==\n  alarmtest: test2: OK\n== Test   alarmtest: test3 ==\n  alarmtest: test3: OK\nxiaobai@***:~/xv6-labs-2025$\n</code></pre>\n<h2 id=\"写在最后\">写在最后</h2>\n<p>​\t这一lab可以说很直观地让我们感受到中断的过程是怎样的，特别是涉及“保护断点/现场”，“获取中断服务程序入口地址”，“恢复断点/现场”等内容。</p>\n<p>​\t快过年了，争取大年三十前尽快赶出下一个lab。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 23:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaobai1523\">小白同学_C</a>&nbsp;\n阅读(<span id=\"post_view_count\">5</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "RAG 时代的“破壁人”：为什么你的大模型应用急需 Docling？",
      "link": "https://www.cnblogs.com/jyzhao/p/19610038/rag-shi-dai-de-po-bi-ren-wei-shen-me-ni-de-da-mo-x",
      "published": "",
      "description": "<a name=\"top\"></a>\n    <h2><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jyzhao/p/19610038/rag-shi-dai-de-po-bi-ren-wei-shen-me-ni-de-da-mo-x\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 22:58\">\n    <span>RAG 时代的“破壁人”：为什么你的大模型应用急需 Docling？</span>\n    \n\n</a>\n</h2>\n    <small>\n<span id=\"post-date\">2026-02-12 22:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jyzhao\">AlfredZhao</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</small>\n    <div class=\"entry\">\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在 RAG（检索增强生成）的开发圈子里，有一句流传甚广的“黑话”：<strong>“垃圾进，垃圾出（Garbage In, Garbage Out）。”</strong> 无论你的向量数据库有多快，大模型（LLM）的推理能力有多强，如果最开始喂给它的文档数据是一团乱麻，那最终的回答效果一定不尽如人意。正是在这种背景下，IBM 开源的 <strong>Docling</strong> 像一匹黑马，迅速成为了 RAG 领域的“新宠”。</p>\n<p>今天，笔者就带大家拆解一下：为什么在 RAG 流程中，Docling 是不可或缺的底层支柱。</p>\n<hr />\n<h2 id=\"01--痛点被忽视的文档解析最后一公里\">01 | 痛点：被忽视的文档解析“最后一公里”</h2>\n<p>做过 RAG 的同学都知道，第一步通常是解析 PDF。但传统的解析方式往往会让开发者头秃：</p>\n<ul>\n<li><strong>PDF 格式的“非结构化”本质</strong>：PDF 本质上是给打印机看的。普通解析工具（如 PyPDF 等）往往会按物理坐标抓取文本，导致分栏混淆、页眉页脚横插在正文中间。</li>\n<li><strong>“结构化”的彻底丢失</strong>：最典型的就是表格。一旦解析成乱序纯文本，行与列的关系就会灰飞烟灭，大模型看到的只是一堆毫无关联的数字“天书”。</li>\n</ul>\n<hr />\n<h2 id=\"02--核心亮点docling-凭什么被称为降维打击\">02 | 核心亮点：Docling 凭什么被称为“降维打击”？</h2>\n<p>Docling 不仅仅是一个转换工具，它更像是一个拥有“透视眼”的智能文档翻译官。</p>\n<h3 id=\"-语义布局分析而非字符抓取\">① 语义布局分析，而非字符抓取</h3>\n<p>Docling 采用了先进的人工智能视觉模型（基于 DocLayNet 数据集）。它不是硬生生地“扣”字，而是像人眼一样去理解布局：<strong>“这里是分栏标题，那里是跨行表格，右边是配图的注释。”</strong> 这种对文档拓扑结构的深刻理解，是保留原文逻辑的关键。</p>\n<h3 id=\"-表格解析的天花板tableformer\">② 表格解析的“天花板”：TableFormer</h3>\n<p>这是 Docling 的杀手锏。它内置了 IBM 专门针对复杂表格研发的 <strong>TableFormer</strong> 模型。即便是没有边框线的表格、含有复杂合并单元格的报表，它都能精准还原并转换为 Markdown 或 JSON。</p>\n<ul>\n<li><strong>为什么 Markdown 对 RAG 至关重要？</strong> 大模型天生对 Markdown 格式的表格有极强的感知力。通过 Docling，大模型终于能读懂“2025年Q3的纯A率比Q2增长了多少”这种涉及跨行跨列对比的复杂逻辑。</li>\n</ul>\n<h3 id=\"-极简的-pipeline-与-v2-统一架构\">③ 极简的 Pipeline 与 v2 统一架构</h3>\n<p>在最新的 <strong>v2 版本</strong>中，Docling 引入了统一的中间表示（<code>DoclingDocument</code>）。这意味着无论你输入的是 PDF、Word、PPT 还是 HTML，输出的结构化抽象是完全一致的。这种“万物归一”的特性，极大简化了 RAG 后端的数据处理逻辑。</p>\n<hr />\n<h2 id=\"03--进阶理解docling-在-rag-工作流中的化学反应\">03 | 进阶理解：Docling 在 RAG 工作流中的化学反应</h2>\n<h3 id=\"-原生语义切片smart-chunking\">① 原生语义切片（Smart Chunking）</h3>\n<p>传统的切片是按字数硬切，常导致语义断裂。Docling 现在的强大之处在于它<strong>自带切片逻辑</strong>。因为它知道哪里是标题、哪里是段落，所以它可以执行<strong>基于结构的切片</strong>：</p>\n<blockquote>\n<p><strong>笔者见解</strong>：通过 Docling，我们可以确保每一个 Knowledge Chunk 都是一个完整的语义单元（例如：整个二级标题下的所有段落），这能从源头上消除大模型在检索后的幻觉。</p>\n</blockquote>\n<h3 id=\"-元数据与坐标映射\">② 元数据与坐标映射</h3>\n<p>Docling 解析时会保留每一个元素在原件中的坐标。这使得在 RAG 的“引用来源”功能中，应用不仅能告诉用户答案在哪个文档，甚至能直接在 PDF 预览中<strong>高亮显示</strong>出那一行文字的位置。</p>\n<hr />\n<h2 id=\"04--最新动态向全能多模态跨越\">04 | 最新动态：向全能多模态跨越</h2>\n<p>相比早期的解析工具，Docling 正在向“多模态”进化。它不仅加强了对 <strong>OCR（光学字符识别）</strong> 的支持，解决扫描件难题，甚至开始支持处理复杂的 <strong>LaTeX 公式</strong>。它不再依赖昂贵的商业闭源方案（如 Adobe Extract），而是为开源社区提供了一个在性能上完全对标的高质量选择。</p>\n<hr />\n<h2 id=\"05--总结rag-工程师的标配工具\">05 | 总结：RAG 工程师的标配工具</h2>\n<p>如果说向量数据库是 RAG 的大脑，那么 Docling 就是那双 <strong>“极其敏锐的手”</strong>，负责把粗糙的原材料加工成精致的饵料。</p>\n<p><strong>笔者的建议：</strong><br />\n如果你现在的 RAG 系统还在为“表格识别不准”或“文档结构混乱”而烦恼，不要急着砸钱去换更贵的 LLM 接口，试着在解析层引入 Docling。你会发现，有时候底层的“基建”优化，比上层的“炼丹”更有奇效。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <a href=\"https://www.cnblogs.com/jyzhao/\" target=\"_blank\">AlfredZhao</a>©版权所有「从Oracle起航，领略精彩的IT技术。」<br />\n转载请注明原文链接：<a href=\"https://www.cnblogs.com/jyzhao/p/19610038/rag-shi-dai-de-po-bi-ren-wei-shen-me-ni-de-da-mo-x\" target=\"_blank\">https://www.cnblogs.com/jyzhao/p/19610038/rag-shi-dai-de-po-bi-ren-wei-shen-me-ni-de-da-mo-x</a>\n<hr />\n<div style=\"text-align: center; margin-top: 30px;\">\n  <p style=\"font-size: 14px; color: #555;\">\n    👋 感谢阅读，欢迎关注我的公众号 <b>「赵靖宇」</b>\n  </p>\n  <img src=\"https://images.cnblogs.com/cnblogs_com/jyzhao/824234/o_250208075013_qrcode-zjy.jpg\" style=\"border: 1px solid #ddd; border-radius: 8px;\" width=\"160\" />\n</div>\n</div>\n<div class=\"clear\"></div>\n\n        <div class=\"clear\"></div>\n        \n</div>\n    <ul class=\"postmetadata\">\n        \n    </ul>"
    },
    {
      "title": "3年，从0到全球领跑：万字长文拆解DeepSeek大模型技术演进",
      "link": "https://www.cnblogs.com/aifrontiers/p/19608897",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/aifrontiers/p/19608897\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 16:15\">\n    <span>3年，从0到全球领跑：万字长文拆解DeepSeek大模型技术演进</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>原文: <a href=\"https://mp.weixin.qq.com/s/MG9nB7VYK-N4Q3RQFiwcuw\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/MG9nB7VYK-N4Q3RQFiwcuw</a></p>\n<p>关注gzh: AI-Frontiers</p>\n<p>自2022年chatgpt发布以来，全球人工智能领域进入了以大语言模型（LLM）为核心的激烈军备竞赛。OpenAI、Google、Anthropic等硅谷巨头，通过数百亿美元的资本投入和数万张H100GPU的算力堆叠，不断刷新着模型智能的上限。在这种大力出奇迹（Scaling Laws）的主流叙事下，算力成为了制约模型发展的核心硬通货，也构建了极高的行业准入门槛。</p>\n<p>不同于国外通过堆砌硬件来解决问题的传统路径，中国杭州的AI初创公司Deepseek，走出了一条截然不同的技术演进路线，即对极致效率的追求和对算法边界的探索，其技术哲学可以概括为「算法-硬件协同优化的极致主义」。</p>\n<p>DeepSeek作为一家源自量化对冲基金High-Flyer的AI研究机构，成立于2023年，在短短三年内从跟随者迅速蜕变为全球大模型架构创新的引领者。其技术路线展现出鲜明的长期主义与极致效率特征，通过在模型架构、推理算法、多模态及训练基础设施四个维度的持续突破，成功重塑了开源大模型的性能天花板。</p>\n<p>DeepSeek的技术演进可清晰地划分为四个阶段：</p>\n<ul>\n<li>\n<p><strong>基石奠定模型（2023年）：</strong> 以DeepSeek-Coder和DeepSeek-LLM为代表，验证了在有限算力下训练高质量稠密模型的能力，确立了「代码+数学」为核心竞争力的差异化路线。</p>\n</li>\n<li>\n<p><strong>架构革新与<strong><strong>MOE</strong></strong>化（2024年）：</strong> 通过DeepSeek-V2和V3，在大模型架构底层进行了革命性创新。提出了多头潜在注意力和细粒度专家混合架构，彻底解决了长上下文推理的显存瓶颈与训练成本问题，以极低的成本实现了对标顶尖闭源模型GPT-4 Turbo的效果。</p>\n</li>\n<li>\n<p><strong>推理与系统2思维（2025年）：</strong> 以DeepSeek-R1为里程碑，探索出纯强化学习驱动的推理能力涌现路径，证明了无需大规模监督微调，即可激发模型的自我反思与修正能力。随后通过V3.1、V3.2系列将这种「思考」能力泛化至工具调用与Agent场景。</p>\n</li>\n<li>\n<p><strong>记忆与因果视觉（2025末-2026初）：</strong> 在DeepSeek-OCR-2中引入视觉因果流，在Engram架构中提出基于查表的可扩展条件记忆机制，试图从根本上突破Transformer的上下文长度限制与视觉理解的逻辑缺陷，为下一代模型DeepSeek-V4奠定基础。</p>\n</li>\n</ul>\n<p>官网发布信息，见：<a href=\"https://api-docs.deepseek.com/news/news251201\" rel=\"noopener nofollow\" target=\"_blank\">https://api-docs.deepseek.com/news/news251201</a></p>\n<h1 id=\"tl-dr总结版\">TL; DR（总结版）</h1>\n<h2 id=\"deepseek模型演进时间线汇总2023-20260210\">DeepSeek模型演进时间线汇总（2023-2026.02.10）</h2>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>发布日期</td>\n<td>模型名称</td>\n<td>核心参数/架构</td>\n<td>关键技术创新</td>\n<td>对标/性能亮点</td>\n</tr>\n<tr>\n<td>2023/11/2</td>\n<td>DeepSeek Coder</td>\n<td>1.3B/6.7B/33B</td>\n<td>FIM预训练, 项目级上下文</td>\n<td>代码能力超越CodeLlama-34B</td>\n</tr>\n<tr>\n<td>2023/11/29</td>\n<td>DeepSeek LLM</td>\n<td>7B/67B</td>\n<td>稠密架构, 中英双语对齐</td>\n<td>67B打破LLaMA 2 70B垄断</td>\n</tr>\n<tr>\n<td>2023/12/18</td>\n<td>DreamCraft3D</td>\n<td>N/A</td>\n<td>3D一致性生成</td>\n<td>高质量文生3D资产</td>\n</tr>\n<tr>\n<td>2024/2/5</td>\n<td>DeepSeek-Math</td>\n<td>7B</td>\n<td>GRPO强化学习, 拒绝采样</td>\n<td>数学能力逼近GPT-4，RL技术验证</td>\n</tr>\n<tr>\n<td>2024/3/11</td>\n<td>DeepSeek-VL</td>\n<td>1.3B/7B</td>\n<td>混合视觉编码器</td>\n<td>真实世界视觉理解，高分辨率处理</td>\n</tr>\n<tr>\n<td>2024/5/7</td>\n<td>DeepSeek-V2</td>\n<td>236B (21B激活)</td>\n<td>MLA, DeepSeekMoE</td>\n<td>重新定义MoE架构，显存占用降93%</td>\n</tr>\n<tr>\n<td>2024/6/17</td>\n<td>DeepSeek-Coder-V2</td>\n<td>16B/236B</td>\n<td>MoE for Code, 338种语言</td>\n<td>开源模型首次在代码领域对齐GPT-4 Turbo</td>\n</tr>\n<tr>\n<td>2024/9/6</td>\n<td>DeepSeek-V2.5</td>\n<td>236B</td>\n<td>Chat与Coder合并</td>\n<td>通用与垂类能力统一，硬盘缓存API</td>\n</tr>\n<tr>\n<td>2024/10/18</td>\n<td>Janus</td>\n<td>1.3B</td>\n<td>视觉理解/生成解耦</td>\n<td>解决多模态理解与生成的冲突</td>\n</tr>\n<tr>\n<td>2024/12/13</td>\n<td>DeepSeek-VL2</td>\n<td>1B/2.8B/4.5B (激活)</td>\n<td>MoE多模态, 动态分辨率</td>\n<td>提升OCR与图表理解能力</td>\n</tr>\n<tr>\n<td>2024/12/26</td>\n<td>DeepSeek-V3</td>\n<td>671B (37B激活)</td>\n<td>FP8训练, MTP, 无损负载均衡</td>\n<td>557万美元练出GPT-4o级模型，开源新基座</td>\n</tr>\n<tr>\n<td>2025/1/20</td>\n<td>DeepSeek-R1</td>\n<td>671B</td>\n<td>纯RL训练, 思维链涌现, 蒸馏</td>\n<td>Aha Moment，开启推理大模型时代</td>\n</tr>\n<tr>\n<td>2025/1/27</td>\n<td>Janus-Pro</td>\n<td>1B/7B</td>\n<td>多模态Scaling</td>\n<td>更强的文生图与指令遵循</td>\n</tr>\n<tr>\n<td>2025/5/1</td>\n<td>DeepSeek-Prover-V2</td>\n<td>671B</td>\n<td>形式化证明 (Lean 4)</td>\n<td>解决数学证明步骤分解问题</td>\n</tr>\n<tr>\n<td>2025/8/21</td>\n<td>DeepSeek-V3.1</td>\n<td>671B</td>\n<td>混合思维模式, Agent优化</td>\n<td>将R1的思考能力泛化至Agent任务</td>\n</tr>\n<tr>\n<td>2025/12/1</td>\n<td>DeepSeek-V3.2</td>\n<td>671B</td>\n<td>DeepSeek Sparse Attention (DSA)</td>\n<td>长上下文效率突破，Thinking in Tool-Use</td>\n</tr>\n<tr>\n<td>2026/1/3</td>\n<td>mHC</td>\n<td>N/A</td>\n<td>引入几何约束</td>\n<td>超大规模模型的信号发散与训练不稳定性</td>\n</tr>\n<tr>\n<td>2026/1/14</td>\n<td>Engram (论文)</td>\n<td>N/A</td>\n<td>可扩展查表记忆</td>\n<td>解决超长上下文记忆遗忘问题</td>\n</tr>\n<tr>\n<td>2026/1/27</td>\n<td>DeepSeek-OCR-2</td>\n<td>3B</td>\n<td>视觉因果流</td>\n<td>模拟人类阅读顺序，极致文档理解</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"deepseek模型功能分类汇总\">DeepSeek模型功能分类汇总</h2>\n<p><img alt=\"image\" class=\"lazyload\" /><br />\n<img alt=\"8b843b06359b40d7ba1a91a59a820af1\" class=\"lazyload\" /></p>\n<h1 id=\"2023年基石奠定与稠密模型时代\">2023年：基石奠定与稠密模型时代</h1>\n<p>2023年是大模型爆发的元年。在LLaMA等开源模型引发「百模大战」的背景下，DeepSeek并未急于发布对话模型，而是敏锐地选择了代码作为切入点，基于两个核心判断：① 代码数据具有极强的逻辑性，是提升模型推理能力的最佳语料；② 代码生成是开发者最高频的刚需，且当时开源界尚缺乏能真正对标OpenAI Codex的模型。</p>\n<h2 id=\"deepseek-coder代码智能的崛起\">DeepSeek Coder：代码智能的崛起</h2>\n<ul>\n<li>\n<p>发布时间: 2023年11月2日</p>\n</li>\n<li>\n<p>核心定位： 垂类代码大模型</p>\n</li>\n<li>\n<p>技术创新： Fill-In-the-Middle (FIM) / Project-Level Context</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2401.14196\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2401.14196</a></p>\n</li>\n<li>\n<p>gitbub：<a href=\"https://github.com/deepseek-ai/DeepSeek-Coder\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-Coder</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek Coder是DeepSeek推出的首个具有广泛影响力的模型系列，包含1.3B、6.7B、33B等多种尺寸。该系列模型并非简单的微调，而是从零开始预训练。</p>\n<ul>\n<li>\n<p><strong>数据构成与训练策略：</strong> 模型使用了2万亿（2T）Token的高质量数据进行训练，其中87%为代码，13%为中英文自然语言。这种配比确保了模型既具备深厚的编程知识，又拥有流畅的指令遵循能力 。</p>\n</li>\n<li>\n<p><strong>架构亮点：</strong></p>\n<ul>\n<li>\n<p><strong>Fill-In-the-Middle (FIM)：</strong> 为了适应IDE中的代码补全场景，DeepSeek Coder在预训练阶段引入了FIM任务，即让模型根据上下文填补中间缺失的代码片段。这一能力使其在实际编程辅助中表现远超仅支持「从左到右」生成的模型。</p>\n</li>\n<li>\n<p><strong>项目级上下文（Project-Level Context）：</strong> 模型支持16K的上下文窗口，能够理解跨文件的代码依赖关系，这在当时是开源代码模型中的领先水平。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现：</strong> 在HumanEval和MBPP等基准测试中，DeepSeek Coder 33B不仅超越了同量级的CodeLlama-34B，甚至在部分指标上逼近了GPT-3.5 Turbo，确立了DeepSeek在代码领域的领先地位。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-llm-67b通用能力的全面对标\">DeepSeek LLM (67B)：通用能力的全面对标</h2>\n<ul>\n<li>\n<p>发布时间： 2023年11月29日</p>\n</li>\n<li>\n<p>核心定位： 通用稠密大模型</p>\n</li>\n<li>\n<p>技术创新： 中英双语对齐/规模化训练稳定性</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2401.02954\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2401.02954</a></p>\n</li>\n<li>\n<p>github：<a href=\"https://github.com/deepseek-ai/DeepSeek-LLM\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-LLM</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>在代码模型取得成功后，DeepSeek迅速发布了通用大模型DeepSeek LLM 67B。这是中国首个完全开源参数量达到670亿级别的模型，直接对标Meta的LLaMA-2 70B。</p>\n<ul>\n<li>\n<p><strong>双语优势：</strong> 相比LLaMA-2主要以英语为主，DeepSeek LLM在预训练数据中大幅增加了中文语料的权重，使其在中文理解、文化常识及逻辑推理上表现出显著优势。</p>\n</li>\n<li>\n<p><strong>推理与数学能力：</strong> 继承了DeepSeek Coder的基因，DeepSeek LLM在数学推理（GSM8K）和逻辑推断任务上表现出色，证明了「代码训练提升通用推理」的假设。</p>\n</li>\n<li>\n<p><strong>开源策略：</strong> DeepSeek不仅开源了模型权重，还开放了中间检查点（Checkpoints），极大地促进了学术界对大模型训练动态的研究，展示了DeepSeek独特的开源精神，提供结果，更提供过程。</p>\n</li>\n</ul>\n<h2 id=\"dreamcraft3d多模态生成的早期探索\">DreamCraft3D：多模态生成的早期探索</h2>\n<ul>\n<li>\n<p>发布时间： 2023年12月18日</p>\n</li>\n<li>\n<p>核心定位： 文生3D内容生成</p>\n</li>\n<li>\n<p>技术创新： 3D一致性优化</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2310.16818\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2310.16818</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DreamCraft3D\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DreamCraft3D</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>除了语言模型，DeepSeek在2023年底还探索了多模态生成领域。DreamCraft3D是一个能够从文本描述生成高保真3D资产的模型。它通过解决多视角一致性问题，实现了从2D图像到3D几何的高质量转换，为后续的Janus系列奠定了多模态技术积累。</p>\n<ul>\n<li>\n<p><strong>架构亮点</strong>：</p>\n<ul>\n<li>\n<p>分层优化流水线：几何雕刻阶段融合 2D+3D 混合 SDS 损失、扩散时间步退火、渐进式视角训练等策略，从 NeuS 隐式表面表示过渡到 DMTet 网格表示，确保 3D 几何的多视角一致性；纹理增强阶段提出自举式分数蒸馏（BSD），通过交替优化 3D 场景与 DreamBooth 个性化扩散模型，实现纹理细节与视角一致性的相互强化。</p>\n</li>\n<li>\n<p>3D 感知先验融合：引入 Zero-1-to-3 视图条件扩散模型提供丰富 3D 先验，缓解单图生成的视角模糊性；利用多视图渲染增强与高斯噪声扰动，让扩散模型学习场景专属 3D 知识，突破固定分布蒸馏的局限。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现</strong>：在包含 300 张图像的测试基准上，CLIP 得分（0.896）、PSNR（31.801）和 LPIPS（0.005）均显著超越 Make-it-3D、Magic123 等主流方法；用户研究中 92% 的参与者更偏好其生成结果，在 360° 渲染中展现出更锐利的几何细节和逼真纹理，有效解决了传统模型的语义不一致问题，推进了 3D 生成的技术上限。</p>\n</li>\n</ul>\n<h1 id=\"2024年上架构革命与moemla的提出\">2024年（上）：架构革命与MoE/MLA的提出</h1>\n<p>进入2024年，大模型竞争进入深水区。随着模型参数量的膨胀，训练成本和推理显存占用成为制约发展的核心瓶颈。DeepSeek在这一阶段完成了从「架构跟随」到「架构创新」的华丽转身，提出了改变行业的MLA和DeepSeekMoE架构。</p>\n<h2 id=\"deepseek-math强化学习推理的先声\">DeepSeek-Math：强化学习推理的先声</h2>\n<ul>\n<li>\n<p>发布时间： 2024年2月5日</p>\n</li>\n<li>\n<p>核心定位： 数学推理模型</p>\n</li>\n<li>\n<p>技术创新： Group Relative Policy Optimization (GRPO)</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2402.03300\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2402.03300</a></p>\n</li>\n<li>\n<p>gitbub：<a href=\"https://github.com/deepseek-ai/DeepSeek-Math\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-Math</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-Math 7B虽然参数规模不大，但其技术意义深远。它是DeepSeek首次大规模应用强化学习（RL）来提升推理能力，并为此发明了GRPO（Group Relative Policy Optimization）算法。</p>\n<ul>\n<li>\n<p><strong>GRPO算法详解：</strong> 传统的RLHF（基于人类反馈的强化学习）通常依赖PPO算法，需要训练一个与策略模型同等大小的评论家模型，这会带来双倍的显存和计算开销。DeepSeek-Math提出的GRPO算法摒弃了评论家模型，而是通过对同一问题采样多组输出（Group Sampling），利用组内输出的相对优劣来计算优势函数。这一创新不仅大幅降低了RL训练成本，还提高了训练稳定性，为2025年DeepSeek-R1的爆发埋下了伏笔。</p>\n</li>\n<li>\n<p><strong>性能：</strong> 在MATH基准测试中，DeepSeek-Math 7B凭借GRPO和精选的数理数据，击败了众多70B级别的开源模型，甚至在部分指标上逼近GPT-4。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-vl迈向真实世界的视觉理解\">DeepSeek-VL：迈向真实世界的视觉理解</h2>\n<ul>\n<li>\n<p>发布时间： 2024年3月11日</p>\n</li>\n<li>\n<p>核心定位： 多模态理解模型</p>\n</li>\n<li>\n<p>技术创新： 混合视觉编码器（Hybrid Vision Encoder）</p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/abs/2403.05525\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2403.05525</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-VL\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-VL</a></p>\n</li>\n</ul>\n<p>DeepSeek-VL（1.3B/7B）的设计哲学是实用主义。不同于当时许多多模态模型专注于简短的看图说话，DeepSeek-VL着重于处理真实世界中的复杂视觉任务，如逻辑图表分析、网页代码转换、OCR识别等。</p>\n<ul>\n<li><strong>架构设计：</strong> 采用了混合视觉编码器架构，结合了用于提取高层语义的SigLIP和用于捕捉低层细节的SAM-B（Segment Anything Model）。这种设计使得模型在处理高分辨率（1024x1024）图像时，既能保持全局理解，又不会丢失关键的文字和细节信息。</li>\n</ul>\n<h2 id=\"deepseek-v2moe与mla的里程碑\">DeepSeek-V2：MoE与MLA的里程碑</h2>\n<ul>\n<li>\n<p>发布时间： 2024年5月</p>\n</li>\n<li>\n<p>核心定位： 经济高效的MoE通用大模型</p>\n</li>\n<li>\n<p>技术创新： Multi-Head Latent Attention (MLA) / DeepSeekMoE</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2405.04434\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2405.04434</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V2</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-V2是DeepSeek发展史上的关键转折点。它不仅是一个模型，更是一套全新的高效架构标准。</p>\n<ul>\n<li>\n<p><strong>Multi-Head Latent Attention (<strong><strong>MLA</strong></strong>)：</strong></p>\n<ul>\n<li>\n<p><strong>背景：</strong> 在长上下文推理中，KV Cache（键值缓存）会占用海量显存，限制了Batch Size和推理速度。</p>\n</li>\n<li>\n<p><strong>原理：</strong> MLA通过低秩压缩技术，将KV Cache压缩为一个潜在向量（Latent Vector），大幅减少了推理时的显存占用。</p>\n</li>\n<li>\n<p><strong>效果：</strong> 相比标准多头注意力技术，MLA将KV Cache减少了93.3%，使得DeepSeek-V2在单卡上就能支持极长的上下文窗口，并将推理吞吐量提升了5.76倍。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>DeepSeekMoE：</strong></p>\n<ul>\n<li>\n<p><strong>细粒度专家（Fin****e-grained Experts）：</strong> 不同于Mixtral等模型将FFN作为一个大专家，DeepSeekMoE将专家切分得更细，使得知识分配更加灵活。</p>\n</li>\n<li>\n<p><strong>共享专家（Share****d Experts）：</strong> 专门设置一部分专家始终处于激活状态，用于捕捉通用知识，而路由专家专注于特定领域知识。这种“共享+路由”的机制有效解决了MoE模型训练中的知识冗余和路由坍缩问题。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>综合效能：</strong> DeepSeek-V2总参数236B，激活参数仅21B，训练成本节省了42.5%，性能却超越了LLaMA 3 70B，不仅成为当时最强的开源MoE模型，更将API价格打到了白菜价1元/百万Tokens。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-coder-v2代码能力的全面爆发\">DeepSeek-Coder-V2：代码能力的全面爆发</h2>\n<ul>\n<li>\n<p>发布时间： 2024年6月17日</p>\n</li>\n<li>\n<p>核心定位： 代码MoE模型</p>\n</li>\n<li>\n<p>技术创新： 338种编程语言支持</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2406.11931\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2406.11931</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-Coder-V2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-Coder-V2</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-Coder-V2是V2架构在代码领域的延续。它在DeepSeek-V2的中间检查点基础上，额外使用了6万亿（6T）Token的高质量代码和数学数据进行持续预训练。</p>\n<ul>\n<li>\n<p><strong>多语言支持：</strong> 支持的编程语言从86种扩展到了338种，几乎覆盖了所有主流及冷门语言。</p>\n</li>\n<li>\n<p><strong>性能跃升：</strong> 首个在代码生成和数学推理能力上能与闭源模型GPT-4 Turbo一较高下的开源模型。在HumanEval、MBPP+等榜单上，其表现令人震惊，证明了MoE架构在垂类任务上的巨大潜力 。</p>\n</li>\n</ul>\n<h1 id=\"2024年下融合优化与v3的诞生\">2024年（下）：融合、优化与V3的诞生</h1>\n<p>2024年下半年，DeepSeek一方面致力于模型功能的融合与对齐，另一方面在基础设施层面进行底层优化，为V3的发布积蓄力量。</p>\n<h2 id=\"deepseek-v25chat与coder的合二为一\">DeepSeek-V2.5：Chat与Coder的合二为一</h2>\n<ul>\n<li>\n<p>发布时间： 2024年9月6日</p>\n</li>\n<li>\n<p>核心定位： 融合模型</p>\n</li>\n<li>\n<p>技术创新： 人类偏好对齐优化</p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/pdf/2405.04434\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2405.04434</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V2</a></p>\n</li>\n<li>\n<p>HuggingFace1: <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V2.5\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/deepseek-ai/DeepSeek-V2.5</a></p>\n</li>\n<li>\n<p>HuggingFace2: <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>此前，DeepSeek同时维护Chat（通用）和Coder（代码）两条产品线。DeepSeek-V2.5的发布标志着这两条路线的合并。通过精细的数据配比和强化学习对齐，V2.5在保留Coder-V2强大代码能力的同时，大幅提升了通用对话和指令遵循能力，使得用户不再需要在不同模型间切换。这一版本也引入了针对API用户的硬盘缓存（Context Caching on Disk）技术，进一步降低了使用成本 。</p>\n<ul>\n<li>\n<p><strong>数据构成与训练策略</strong>：基于8.1T高质量多源 Token 预训练（中文Token占比略高于英文），经去偏和质量筛选；通过150万会话SFT及两阶段RL对齐人类偏好，分别聚焦推理优化与多奖励信号融合。</p>\n</li>\n<li>\n<p><strong>架构亮点</strong>：</p>\n<ul>\n<li>\n<p>MLA：低秩 KV 联合压缩 + 解耦RoPE，减少93.3%KV 缓存，兼顾性能与推理效率。</p>\n</li>\n<li>\n<p>DeepSeekMoE 稀疏架构：细粒度专家分割 + 多重负载均衡策略，降低训练成本并避免路由崩溃与通信过载。</p>\n</li>\n<li>\n<p>128K 长上下文：基于YaRN方法扩展，32K训练序列实现128K稳定性能，“Needle In A Haystack” 测试表现优异。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现</strong>：在仅21B激活参数的情况下，基座模型在 MMLU、BBH 等基准跻身开源第一梯队；Chat（RL）版本 MT-Bench 8.97 分、AlpacaEval 2.0 胜率 38.9%，中文 AlignBench 7.91 分超多数闭源模型；训练成本降 42.5%，生成吞吐量提升至 5.76 倍。</p>\n</li>\n</ul>\n<h2 id=\"janus--janusflow多模态理解与生成的解耦\">Janus &amp; JanusFlow：多模态理解与生成的解耦</h2>\n<ul>\n<li>\n<p>发布时间： 2024年10月（Janus），11月（JanusFlow）</p>\n</li>\n<li>\n<p>核心定位： 统一多模态模型</p>\n</li>\n<li>\n<p>技术创新： 解耦视觉编码（Decoupling Visual Encoding）</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2410.13848\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2410.13848</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/Janus\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/Janus</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>在Janus之前，业界的多模态模型通常难以兼顾理解（看图）和生成（画图），因为两者的视觉表征需求截然不同。DeepSeek提出了Janus架构，创造性地将视觉编码解耦：</p>\n<ul>\n<li>\n<p><strong>理解路径：</strong> 使用SigLIP提取高维语义特征。</p>\n</li>\n<li>\n<p><strong>生成路径：</strong> 使用VQ Tokenizer提取离散视觉Token。 两者通过同一个Transformer基座进行处理，互不干扰。随后发布的<strong>JanusFlow</strong>更是引入了整流流（Rectified Flow）技术，替代传统的自回归生成，大幅提升了图像生成的质量和速度。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-v3定义开源新标准\">DeepSeek-V3：定义开源新标准</h2>\n<ul>\n<li>\n<p>发布时间： 2024年12月26日</p>\n</li>\n<li>\n<p>核心定位： 旗舰MoE模型</p>\n</li>\n<li>\n<p>技术创新： FP8训练/无辅助损失负载均衡/多Token预测</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2412.19437\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2412.19437</a></p>\n</li>\n<li>\n<p>github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V3\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V3</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-V3是2024年的收官之作，也是DeepSeek技术实力的集大成者。它不仅是一个模型，更是一次对AI基础设施的极限挑战。</p>\n<ul>\n<li>\n<p><strong>FP8混合精度训练：</strong> V3是全球首个在超大规模（671B参数）上成功验证FP8（8位浮点数）训练的模型。通过深度优化的FP8 GEMM内核，V3极大减少了显存带宽压力和通信开销，使得训练成本仅为557万美元（278.8万H800 GPU时），震惊了全球业界。</p>\n</li>\n<li>\n<p><strong>无辅助损失<strong><strong>负载均衡</strong></strong>（Auxiliary-Loss-Free Load Balancing）：</strong> 传统MoE依赖辅助损失（Auxiliary Loss）来强迫专家负载均衡，但会干扰模型的主任务学习。V3创新性地采用了基于偏置的动态均衡策略，在不牺牲模型性能的前提下实现了完美的负载均衡。</p>\n</li>\n<li>\n<p><strong>多Token预测（Multi-Token Prediction, MTP）：</strong> V3在训练时不再只预测下一个Token，而是同时预测后续多个Token。这种机制增加了训练信号的密度，提升了模型的长程规划能力，并支持推理时的投机解码，使生成速度提升了3倍。</p>\n</li>\n<li>\n<p><strong>DualPipe：</strong>为了解决大规模MoE训练中的跨节点通信瓶颈，DeepSeek研发了DualPipe算法，实现了计算与通信的完全重叠，将硬件利用率推向极致。</p>\n</li>\n</ul>\n<p>DeepSeek-V3在百科知识、数学、代码等维度的表现全面对标GPT-4o和Claude 3.5 Sonnet，成为当时最强的开源基座模型。</p>\n<h1 id=\"2025年上推理模型与agent的全面进化\">2025年（上）：推理模型与Agent的全面进化</h1>\n<p>2025年，DeepSeek引领了从「知识积累（System 1）」向「深度推理（System 2）」的范式转移。通过强化学习激发模型的思考能力成为这一阶段的主旋律。</p>\n<h2 id=\"deepseek-r1纯强化学习的奇点\">DeepSeek-R1：纯强化学习的奇点</h2>\n<ul>\n<li>\n<p>发布时间： 2025年1月20日</p>\n</li>\n<li>\n<p>核心定位： 推理模型（Reasoning Model）</p>\n</li>\n<li>\n<p>技术创新： 纯RL训练/思维链涌现/蒸馏</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2501.12948\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2501.12948</a></p>\n</li>\n<li>\n<p>GitHub代码：<a href=\"https://github.com/deepseek-ai/DeepSeek-R1\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-R1</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-R1的发布引发了全球范围内的「 R1时刻」。它证明了推理能力可以通过纯强化学习涌现，而无需大量的人工标注数据。</p>\n<ul>\n<li>\n<p><strong>DeepSeek-R1-Zero：</strong> R1的前身，通过在V3基座上直接应用GRPO算法进行纯RL训练。模型在训练过程中自然涌现出了自我反思、验证和长思维链（Chain-of-Thought）能力，甚至出现了「顿悟，Aha Moment」现象。虽然R1-Zero存在语言混杂和可读性差的问题，但验证了RL激发推理潜力的可行性。</p>\n</li>\n<li>\n<p><strong>DeepSeek-R1正式版：</strong> 为了解决Zero版的问题，正式版R1采用了「冷启动数据+RL」的多阶段训练管线。</p>\n<ul>\n<li>\n<p><strong>冷启动：</strong> 使用少量高质量的长思维链数据微调V3，使其学会规范的思考格式。</p>\n</li>\n<li>\n<p><strong>推理<strong><strong>RL</strong></strong>：</strong> 使用GRPO进行大规模强化学习，提升解决复杂数学和代码问题的能力。</p>\n</li>\n<li>\n<p><strong>对齐：</strong> 结合通用数据进行最终微调，兼顾推理能力与通用对话体验。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>模型蒸馏：</strong> DeepSeek不仅开源了R1（671B），还开源了利用R1生成的推理数据蒸馏出的一系列小模型：Qwen和Llama架构，1.5B-70B。这些小模型在推理能力上大幅超越了同尺寸的基座模型，甚至优于OpenAI o1-mini。</p>\n</li>\n</ul>\n<h2 id=\"janus-pro多模态的尺度定律\">Janus-Pro：多模态的尺度定律</h2>\n<ul>\n<li>\n<p>发布时间： 2025年1月27日</p>\n</li>\n<li>\n<p>核心定位： 增强版多模态模型</p>\n</li>\n<li>\n<p>技术创新： 数据与模型规模化</p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/pdf/2501.17811v1\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2501.17811v1</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/Janus\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/Janus</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>Janus-Pro是Janus架构的升级版。通过优化训练策略、扩展训练数据和增大模型参数（1B -&gt; 7B），Janus-Pro在多模态理解和文生图指令遵循能力上取得了显著提升，证明了Janus架构具有良好的Scaling Law（尺度定律）特性 。</p>\n<h2 id=\"deepseek-v31--terminusagent能力的觉醒\">DeepSeek-V3.1 &amp; Terminus：Agent能力的觉醒</h2>\n<ul>\n<li>\n<p>发布时间： 2025年8月21日（V3.1），9月22日（Terminus）</p>\n</li>\n<li>\n<p>核心定位： Agent基座模型</p>\n</li>\n<li>\n<p>技术创新： 混合思维模式/工具调用优化</p>\n</li>\n<li>\n<p>Huggingface: <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus</a></p>\n</li>\n<li>\n<p>论文: <a href=\"https://arxiv.org/pdf/2412.19437\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2412.19437</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/deepseek-v3\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/deepseek-v3</a></p>\n</li>\n</ul>\n<p>随着推理能力的成熟，DeepSeek开始探索将「思考」应用于Agent（智能体）场景。</p>\n<ul>\n<li>\n<p><strong>DeepSeek-V3.1：</strong> 引入了「DeepThink」模式，用户可以在对话中一键开启深度思考。该版本重点提升了工具使用（Tool Use）能力，使其能够处理多步复杂的Agent任务。</p>\n</li>\n<li>\n<p><strong>DeepSeek-V3.1-Terminus：</strong> 针对V3.1存在的语言混杂（中英夹杂）和Agent执行不稳定的问题进行了专项修复。Terminus版本在Code Agent和Search Agent任务上的表现更加鲁棒，SWE-bench Verified分数达到66.0，标志着DeepSeek正式进入Agent时代。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-v32--speciale稀疏注意力的突破\">DeepSeek-V3.2 &amp; Speciale：稀疏注意力的突破</h2>\n<ul>\n<li>\n<p>发布时间： 2025年12月1日</p>\n</li>\n<li>\n<p>核心定位： 长上下文Agent模型</p>\n</li>\n<li>\n<p>技术创新： DeepSeek Sparse Attention (DSA) /Thinking in Tool-Use</p>\n</li>\n<li>\n<p>论文: <a href=\"https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/DeepSeek-V3.2-Exp\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-V3.2-Exp</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>DeepSeek-V3.2着重解决了长上下文下的计算效率问题，并进一步强化了Agent的推理能力。</p>\n<ul>\n<li>\n<p><strong>DeepSeek</strong> <strong>Sparse</strong> <strong>Attention (DSA)：</strong> 一种细粒度的稀疏注意力机制。与标准全注意力相比，DSA在处理128K甚至更长上下文时，能显著降低计算复杂度和显存占用，且几乎不损失模型性能。这使得V3.2在长文档分析和RAG（检索增强生成）场景下极具优势。</p>\n</li>\n<li>\n<p><strong>Thinking in Tool-Use：</strong> V3.2不仅会思考，还能在调用工具的过程中进行思考。例如，在执行代码解释器之前，会先推演代码逻辑；在获得工具返回结果后，会再次思考下一步行动。</p>\n</li>\n<li>\n<p><strong>DeepSeek-V3.2-Speciale：</strong> 一个专为极高难度推理任务设计的版本，虽然成本较高，但在IMO 2025（国际数学奥林匹克）和IOI 2025（国际信息学奥林匹克）中均获得了金牌级表现，推理能力对标Gemini-3.0-Pro。</p>\n</li>\n</ul>\n<h1 id=\"2026年1月-2月突破记忆与视觉的极限\">2026年1月-2月：突破记忆与视觉的极限</h1>\n<p>截至发稿日，DeepSeek在保持语言模型优势的同时，开始向大模型最底层的三个痛点：记忆遗忘、视觉逻辑和Transformer底层架构，发起全面冲击。</p>\n<h2 id=\"深度解析manifold-constrained-hyper-connections-mhc\">深度解析：Manifold-Constrained Hyper-Connections (mHC)</h2>\n<ul>\n<li>\n<p>发布日期：2026年1月3日</p>\n</li>\n<li>\n<p>核心定位：超大规模模型的信号发散与训练不稳定性。</p>\n</li>\n<li>\n<p>技术创新：引入几何约束</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2512.24880\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2512.24880</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>mHC 的提出解决了困扰深度学习界十年的“深度-宽度”权衡问题。它证明了通过施加严格的几何约束，我们可以在不牺牲训练稳定性的前提下，极大地扩展模型的宽度和容量。这为 DeepSeek V4 训练万亿参数模型奠定了数学基础。</p>\n<ul>\n<li>\n<p><strong>架构亮点</strong>：</p>\n<ul>\n<li>\n<p>流形约束机制：通过Sinkhorn-Knopp算法将残差映射投影到双随机矩阵流形，恢复恒等映射特性，解决 HC 架构的训练不稳定性。</p>\n</li>\n<li>\n<p>高效基础设施优化：融合核函数减少内存带宽瓶颈，选择性重计算降低显存占用，扩展DualPipe调度实现通信与计算重叠，仅增加6.7%训练开销。</p>\n</li>\n<li>\n<p>多流残差设计：扩展残差流宽度（n=4），同时通过非负约束避免信号抵消，兼顾拓扑复杂度与传播稳定性。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>性能表现</strong>：27B 模型在BBH、DROP等8项基准中全面超越基线和HC架构，推理性能提升2.1%-2.3%；在3B到 27B规模下保持稳定性能优势，信号增益幅度从HC的3000降至1.6，大幅提升训练scalability。</p>\n</li>\n</ul>\n<h2 id=\"deepseek-ocr-2视觉因果流\">DeepSeek-OCR-2：视觉因果流</h2>\n<ul>\n<li>\n<p>发布时间： 2026年1月27日</p>\n</li>\n<li>\n<p>核心定位： 下一代视觉理解模型</p>\n</li>\n<li>\n<p>技术创新： 视觉因果流（Visual Causal Flow）</p>\n</li>\n<li>\n<p>论文1：<a href=\"https://arxiv.org/abs/2601.20552\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2601.20552</a></p>\n</li>\n<li>\n<p>github2: <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR-2\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-OCR-2</a></p>\n</li>\n<li>\n<p>论文2：<a href=\"https://arxiv.org/abs/2510.18234\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2510.18234</a></p>\n</li>\n<li>\n<p>github2: <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepSeek-OCR</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>传统的视觉编码器（如ViT）通常将图像视为无序的补丁（Patches）集合。DeepSeek-OCR-2（3B参数）颠覆了这一范式，引入了<strong>视觉因果流</strong>概念。</p>\n<ul>\n<li>\n<p><strong>核心逻辑：</strong> 强制模型按照人类的阅读顺序（如从左到右、从上到下、先标题后正文）来处理视觉信息，而不是并行处理。这种有序的因果处理方式使得模型在理解多栏排版、复杂表格、嵌套公式等文档结构时，准确率实现了质的飞跃。</p>\n</li>\n<li>\n<p><strong>性能：</strong> 尽管参数仅为3B，但在复杂文档理解任务上超越了许多百亿级模型。</p>\n</li>\n</ul>\n<h2 id=\"engram无限记忆的曙光\">Engram：无限记忆的曙光</h2>\n<ul>\n<li>\n<p>发布时间： 2026年1月14日（论文发布）</p>\n</li>\n<li>\n<p>核心定位： 新型记忆架构研究</p>\n</li>\n<li>\n<p>技术创新： 可扩展查表条件记忆（Conditional Memory via Scalable Lookup）</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2601.07372\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2601.07372</a></p>\n</li>\n<li>\n<p>Github: <a href=\"https://github.com/deepseek-ai/Engram\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/Engram</a></p>\n</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>Transformer的注意力机制虽然强大，但其计算复杂度随长度呈二次方增长，限制了上下文的无限扩展。DeepSeek提出了<strong>Engram</strong>架构。</p>\n<ul>\n<li>\n<p><strong>原理：</strong> 放弃了让模型时刻记住所有信息，而是建立了一个外挂的静态N-gram记忆库。模型通过高效的查表机制（Lookup）按需检索记忆，并将其与当前的动态隐藏状态融合。</p>\n</li>\n<li>\n<p><strong>意义：</strong> 这种设计将记忆存储从昂贵的GPU显存转移到了廉价的CPU内存甚至硬盘上，理论上可以支持无限的上下文长度，为处理代码库级别的超长任务扫清了障碍。这也是即将发布的DeepSeek-V4的核心技术储备 ()。</p>\n</li>\n</ul>\n<h1 id=\"基础设施与生态护城河\">基础设施与生态护城河</h1>\n<p>DeepSeek 的成功离不开其底层基础设施的极致优化。这些工具库均已开源，构成了其技术护城河。</p>\n<ul>\n<li>\n<p><strong>DeepGEMM</strong>：专为FP8优化的矩阵乘法库，支持细粒度缩放（Fine-grained Scaling），是V3/V4高效训练的基石。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/DeepGEMM\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepGEMM</a></li>\n</ul>\n</li>\n<li>\n<p><strong>FlashMLA</strong>：针对Hopper架构 GPU 优化的 MLA 解码内核，极大提升了推理吞吐量。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/FlashMLA\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/FlashMLA</a></li>\n</ul>\n</li>\n<li>\n<p><strong>DeepEP</strong>：高效的专家并行（Expert Parallel）通信库，解决了MoE模型中专家路由带来的巨大通信开销。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/DeepEP\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DeepEP</a></li>\n</ul>\n</li>\n<li>\n<p><strong>DualPipe</strong>：双向流水线并行算法，实现了计算与通信的完美重叠（Overlap）。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/DualPipe\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/DualPipe</a></li>\n</ul>\n</li>\n<li>\n<p><strong>3FS</strong>：高性能分布式文件系统，专为 AI 训练的海量数据吞吐设计。</p>\n<ul>\n<li><a href=\"https://github.com/deepseek-ai/3FS\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepseek-ai/3FS</a></li>\n</ul>\n</li>\n</ul>\n<p>从2023年到2026年，DeepSeek走过了一条从跟随者到颠覆者的道路。如果说V2和V3是通过工程极致优化（MLA, FP8, MoE）来打破算力垄断，那么2026年mHC和Engram的提出，则标志着DeepSeek开始触碰深度学习的理论天花板。</p>\n<p>mHC通过引入流形约束，数学上保证了万亿参数模型的信号稳定性；Engram通过引入外部记忆，打破了 Transformer仅仅依赖参数记忆知识的低效范式。这两项技术不仅为即将到来的 DeepSeek V4奠定了基础，更为整个AI行业在后 「Scaling Law」时代指明了新的方向：向几何要稳定性，向内存要知识容量。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 16:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/aifrontiers\">AI-Frontiers</a>&nbsp;\n阅读(<span id=\"post_view_count\">213</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "数据库算子",
      "link": "https://www.cnblogs.com/aslanvon/p/19608578",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/aslanvon/p/19608578\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 15:18\">\n    <span>数据库算子</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"回表\">回表</h1>\n<h2 id=\"1-为什么会发生回表\">1. 为什么会发生回表？</h2>\n<p>想象你在图书馆查书：</p>\n<ol>\n<li><strong>索引（Index）</strong>：就像图书馆的<strong>索引卡片</strong>。卡片上写着：书名《数据库原理》，存放位置：3排-B架-12号。</li>\n<li><strong>表（Table/Heap）</strong>：就像<strong>书架上的实物书</strong>。书里才有具体的内容（作者、出版社、正文）。</li>\n</ol>\n<p>如果你只想知道书名，看卡片（索引）就够了。但如果你想看“作者是谁”或者“具体内容”，你就必须拿着卡片上的位置，走到书架前把那本书抽出来翻开。<strong>这个“从索引到书架取书”的过程，就是回表。</strong></p>\n<hr />\n<h2 id=\"2-回表的过程以-postgresqlmysql-为例\">2. 回表的过程（以 PostgreSQL/MySQL 为例）</h2>\n<p>假设你有一张表 <code>users</code>，在 <code>username</code> 字段上有索引：</p>\n<pre><code class=\"language-sql\">-- 查询语句\nSELECT id, username, age FROM users WHERE username = 'a';\n</code></pre>\n<ol>\n<li><strong>第一步：查索引。</strong> 数据库在 <code>username</code> 索引树中快速定位到 <code>'a'</code>。</li>\n<li><strong>第二步：拿指针。</strong> 索引节点里存储着该行数据的物理地址（在 MySQL 中是主键 ID，在 PostgreSQL 中是 CTID/TID）。</li>\n<li><strong>第三步：回表。</strong> 索引里<strong>没有 <code>age</code> 字段</strong>。数据库根据物理地址，回到原始数据表（Heap）中找到这一行，把 <code>age</code> 的值读出来。</li>\n</ol>\n<hr />\n<h2 id=\"3-回表有什么代价\">3. 回表有什么代价？</h2>\n<p>回表是数据库性能优化的<strong>头号公敌</strong>，主要原因有两个：</p>\n<ul>\n<li><strong>随机 I/O 增加</strong>：索引通常是顺序排列的，但数据行在磁盘上的分布是零散的。每回表一次，可能都要进行一次磁盘随机读，这比顺序读慢得多。</li>\n<li><strong>性能损耗</strong>：如果查询结果有 10,000 行，数据库就要执行 10,000 次“回表”动作。</li>\n</ul>\n<hr />\n<h2 id=\"4-如何避免回表\">4. 如何避免回表？</h2>\n<p>最有效的方案是：<strong>覆盖索引（Covering Index）</strong>。</p>\n<p>如果你经常需要根据 <code>username</code> 查 <code>age</code>，你可以建立一个包含这两个字段的索引：</p>\n<pre><code class=\"language-sql\">-- PostgreSQL 语法\nCREATE INDEX idx_user_age ON users(username) INCLUDE (age);\n\n-- 或者通用的复合索引\nCREATE INDEX idx_user_age_composite ON users(username, age);\n</code></pre>\n<p><strong>发生了什么变化？</strong></p>\n<p>现在，<code>age</code> 字段的信息直接存在了索引树里。数据库查到 <code>username</code> 时，顺手就能把旁边的 <code>age</code> 带走，再也不用去翻原始表了。这种算子在执行计划中会显示为 <strong>Index Only Scan</strong>。</p>\n<hr />\n<h2 id=\"5-什么时候回表比不回表还快\">5. 什么时候“回表”比“不回表”还快？</h2>\n<p>并不是所有时候都要避免回表。</p>\n<ul>\n<li>如果你的 <code>WHERE</code> 条件过滤后，<strong>只剩下几行数据</strong>，回表的代价微乎其微。</li>\n<li>如果表很小，数据库可能会直接放弃索引，选择 <strong>Seq Scan（全表扫描）</strong>。因为它觉得“与其先看卡片再翻书，不如直接把这本薄书从头到尾翻一遍”。</li>\n</ul>\n<h2 id=\"总结\">总结</h2>\n<ul>\n<li><strong>回表</strong> = 在索引里没找全，得回原表取。</li>\n<li><strong>后果</strong> = 产生随机 I/O，变慢。</li>\n<li><strong>对策</strong> = 覆盖索引（把查的字段都塞进索引里）。</li>\n</ul>\n<h1 id=\"算子\">算子</h1>\n<p>在 PostgreSQL 中，算子（Operators/Nodes）是构成执行计划的最小单元。为了方便记忆，我们可以按照它们在数据处理流中的<strong>功能角色</strong>，将其分为四大类：<strong>数据扫描</strong>、<strong>连接查询</strong>、<strong>集合/聚合操作</strong>、以及<strong>辅助控制算子</strong>。</p>\n<hr />\n<h2 id=\"1-数据扫描算子-scan-nodes\">1. 数据扫描算子 (Scan Nodes)</h2>\n<p>这类算子负责从物理存储（磁盘或内存缓冲区）中读取原始数据。</p>\n<table>\n<thead>\n<tr>\n<th><strong>算子名称</strong></th>\n<th><strong>英文名</strong></th>\n<th><strong>功能描述</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>全表扫描</strong></td>\n<td><strong>Seq Scan</strong></td>\n<td>顺序读取整个表的所有数据页。</td>\n</tr>\n<tr>\n<td><strong>索引扫描</strong></td>\n<td><strong>Index Scan</strong></td>\n<td>先扫描索引找到位置，再回表读取数据行。</td>\n</tr>\n<tr>\n<td><strong>索引覆盖扫描</strong></td>\n<td><strong>Index Only Scan</strong></td>\n<td>仅通过索引就能拿到所有所需字段，无需回表。</td>\n</tr>\n<tr>\n<td><strong>位图扫描</strong></td>\n<td><strong>Bitmap Heap/Index Scan</strong></td>\n<td>先在内存中构建位图标记匹配行，再批量回表，减少随机 IO。</td>\n</tr>\n<tr>\n<td><strong>TID 扫描</strong></td>\n<td><strong>Tid Scan</strong></td>\n<td>通过行标识符（Tuple ID）直接定位数据。</td>\n</tr>\n</tbody>\n</table>\n<p>在 PostgreSQL 中，<strong>扫描算子（Scan Nodes）</strong>是执行计划的“地基”。所有数据的处理都始于扫描，它的效率直接决定了查询的生死。</p>\n<p>PostgreSQL 会根据数据量的大小、过滤条件的筛选率以及索引的分布，从以下几种主要扫描方式中选择最优解。</p>\n<hr />\n<h3 id=\"1-全表扫描-seq-scan\">1. 全表扫描 (Seq Scan)</h3>\n<p>这是最原始的扫描方式。</p>\n<ul>\n<li><strong>工作原理：</strong> 数据库从磁盘上顺序读取该表的所有数据页（Blocks），并对每一行进行条件检查。</li>\n<li><strong>适用场景：</strong>\n<ul>\n<li>表非常小（加载索引的代价反而比全表扫描高）。</li>\n<li>查询条件没有索引。</li>\n<li>返回的数据占全表比例很高（例如超过 20%-30%），此时顺序 IO 比频繁的随机 IO 更快。</li>\n</ul>\n</li>\n<li><strong>EXPLAIN 标志：</strong> <code>Seq Scan on table_name</code>。</li>\n</ul>\n<hr />\n<h3 id=\"2-索引扫描-index-scan\">2. 索引扫描 (Index Scan)</h3>\n<p>当查询条件命中索引时，数据库会先去查索引。</p>\n<ul>\n<li><strong>工作原理：</strong>\n<ol>\n<li>在 B-Tree 索引中找到匹配条件的 Entry（条目）。</li>\n<li>根据 Entry 中的指针（TID），回表（Heap）读取完整的数据行。</li>\n</ol>\n</li>\n<li><strong>优缺点：</strong> 适合返回少量数据的查询。如果返回行数太多，频繁的“回表”会导致大量随机 IO，性能反而不如 Seq Scan。</li>\n<li><strong>EXPLAIN 标志：</strong> <code>Index Scan using index_name on table_name</code>。</li>\n</ul>\n<hr />\n<h3 id=\"3-索引覆盖扫描-index-only-scan\">3. 索引覆盖扫描 (Index Only Scan)</h3>\n<p>这是性能优化的“天花板”。</p>\n<ul>\n<li><strong>工作原理：</strong> 如果你查询的字段全都在索引里（例如 <code>SELECT id FROM users WHERE id &lt; 10</code>），数据库直接从索引树拿到结果就返回，<strong>完全不需要回表</strong>。</li>\n<li><strong>关键点：</strong> 受 <strong>Visibility Map</strong> 的影响。如果某些数据页刚被更新过，数据库还是得回表确认数据的可见性（MVCC）。</li>\n<li><strong>EXPLAIN 标志：</strong> <code>Index Only Scan using index_name on table_name</code>。</li>\n</ul>\n<hr />\n<h3 id=\"4-位图扫描-bitmap-scan\">4. 位图扫描 (Bitmap Scan)</h3>\n<p>这是 PostgreSQL 的一大特色，专门解决“索引扫描导致随机 IO 太多”的问题。</p>\n<ul>\n<li><strong>工作原理（分两步）：</strong>\n<ol>\n<li><strong>Bitmap Index Scan：</strong> 扫描索引，但不立刻回表。它在内存中创建一个“位图”，标记哪些数据页包含符合条件的行。</li>\n<li><strong>Bitmap Heap Scan：</strong> 根据位图，按磁盘顺序访问数据页。</li>\n</ol>\n</li>\n<li><strong>意义：</strong> 它将随机 IO 转换成了<strong>局部顺序 IO</strong>。它比 Index Scan 更适合查询“中等规模”的数据（既不太多也不太少）。</li>\n<li><strong>EXPLAIN 标志：</strong> 往往成对出现，先有 <code>Bitmap Index Scan</code>，后有 <code>Bitmap Heap Scan</code>。</li>\n</ul>\n<hr />\n<h3 id=\"5-常见扫描算子对比表\">5. 常见扫描算子对比表</h3>\n<p>为了直观理解，我们假设有一张 100 万行的表：</p>\n<table>\n<thead>\n<tr>\n<th><strong>扫描类型</strong></th>\n<th><strong>动作比喻</strong></th>\n<th><strong>适用情况</strong></th>\n<th><strong>性能瓶颈</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Seq Scan</strong></td>\n<td>翻完整本书找一个词</td>\n<td>查大量数据/小表</td>\n<td>磁盘总 IO 量</td>\n</tr>\n<tr>\n<td><strong>Index Scan</strong></td>\n<td>看目录，查到一个页码翻一下书</td>\n<td>查极少量数据</td>\n<td>随机读取延迟</td>\n</tr>\n<tr>\n<td><strong>Index Only Scan</strong></td>\n<td>只看目录就找到了答案</td>\n<td>覆盖索引查询</td>\n<td>索引页的大小</td>\n</tr>\n<tr>\n<td><strong>Bitmap Scan</strong></td>\n<td>看目录，把所有页码记在纸上，按页码从小到大翻书</td>\n<td>查中等量数据</td>\n<td>内存 (Work_mem)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"2-连接算子-join-nodes\">2. 连接算子 (Join Nodes)</h2>\n<p>连接算子（Join Nodes）是数据库执行计划中最核心的部分之一。当你的 SQL 查询涉及两张或更多的表时，数据库必须决定<strong>“用什么算法把这两堆数据拼在一起”</strong>。PostgreSQL（以及大多数关系型数据库）主要支持三种连接算法。理解它们的区别，是优化多表查询的关键。</p>\n<table>\n<thead>\n<tr>\n<th><strong>算子名称</strong></th>\n<th><strong>英文名</strong></th>\n<th><strong>功能描述</strong></th>\n<th><strong>适用场景</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>嵌套循环连接</strong></td>\n<td><strong>Nested Loop</strong></td>\n<td>对外表的每一行，去内表中查找匹配行。</td>\n<td>小数据集连接，或内表有索引。</td>\n</tr>\n<tr>\n<td><strong>哈希连接</strong></td>\n<td><strong>Hash Join</strong></td>\n<td>为内表在内存建立哈希表，扫描外表进行匹配。</td>\n<td>大表关联，且无索引支持。</td>\n</tr>\n<tr>\n<td><strong>归并连接</strong></td>\n<td><strong>Merge Join</strong></td>\n<td>将两个有序集合像拉链一样合并。</td>\n<td>两表在关联键上均已有序（如已有索引）。</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"1-嵌套循环连接-nested-loop-join\">1. 嵌套循环连接 (Nested Loop Join)</h3>\n<p>这是最简单、最直观，但在特定场景下也是最快的一种方式。</p>\n<ul>\n<li>\n<p><strong>直观理解：</strong> 就像写代码时的“双层 <code>for</code> 循环”。</p>\n<pre><code class=\"language-Python\"># 伪代码逻辑\nfor outer_row in Outer_Table:        # 外层循环（驱动表）\n    for inner_row in Inner_Table:    # 内层循环（被驱动表）\n        if outer_row.id == inner_row.id:\n            yield (outer_row, inner_row)\n</code></pre>\n</li>\n<li>\n<p><strong>工作流程：</strong></p>\n<ol>\n<li>优化器选择一张表作为<strong>驱动表（Outer Table）</strong>，通常是过滤后结果集较小的那张表。</li>\n<li>逐行读取驱动表的数据。</li>\n<li>拿着这一行数据的关联键，去<strong>被驱动表（Inner Table）</strong>中查找匹配的行。</li>\n</ol>\n</li>\n<li>\n<p><strong>性能关键点：</strong></p>\n<ul>\n<li><strong>被驱动表必须有索引！</strong> 如果内层循环每次都要全表扫描，性能就是灾难级的 O(N*M)。</li>\n<li>如果有索引，复杂度降为 O(N*log M)。</li>\n</ul>\n</li>\n<li>\n<p><strong>适用场景：</strong></p>\n<ul>\n<li><strong>“小表驱动大表”</strong>：驱动表只有几百行，被驱动表有几亿行但有索引。</li>\n<li><strong>首行快速响应</strong>：因为它不需要预处理，找到第一行匹配就能立即返回，适合分页查询的第一页。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"2-哈希连接-hash-join\">2. 哈希连接 (Hash Join)</h3>\n<p>这是处理<strong>大数据量</strong>连接的神器，也是现代数据库最常用的算法之一。</p>\n<ul>\n<li><strong>工作流程（分两个阶段）：</strong>\n<ol>\n<li><strong>构建阶段 (Build Phase)：</strong> 选择较小的那张表，在<strong>内存</strong>中建立一张<strong>哈希表（Hash Table）</strong>。键是连接字段，值是行数据。</li>\n<li><strong>探测阶段 (Probe Phase)：</strong> 扫描较大的那张表，对每一行计算连接字段的哈希值，去内存的哈希表中查找是否存在。</li>\n</ol>\n</li>\n<li><strong>性能关键点：</strong>\n<ul>\n<li><strong>内存（work_mem）：</strong> 哈希表必须能装入内存。如果内存不够，数据库会把哈希表切分写入磁盘（临时文件），性能会急剧下降（你会看到 <code>Disk: xxx kB</code>）。</li>\n<li><strong>只支持等值连接：</strong> 只能用于 <code>ON a.id = b.id</code>，不支持 <code>&gt;</code> 或 <code>&lt;</code>。</li>\n</ul>\n</li>\n<li><strong>适用场景：</strong>\n<ul>\n<li><strong>两张表都很大</strong>，且被驱动表上没有合适的索引。</li>\n<li>查询结果集很大，索引扫描产生的随机 I/O 代价太高。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"3-归并连接-merge-join--sort-merge-join\">3. 归并连接 (Merge Join / Sort Merge Join)</h3>\n<p>这是一种优雅的算法，前提是数据<strong>已经排好序</strong>。</p>\n<ul>\n<li><strong>工作流程：</strong>\n<ol>\n<li>如果不有序，先对两张表分别进行<strong>排序 (Sort)</strong>。</li>\n<li>使用双指针算法，同时遍历两张表。</li>\n<li>如果 <code>A.id &lt; B.id</code>，A 的指针往下移；如果 <code>A.id &gt; B.id</code>，B 的指针往下移；如果相等，输出结果。</li>\n</ol>\n</li>\n<li><strong>性能关键点：</strong>\n<ul>\n<li><strong>排序成本：</strong> 如果数据本身没排序，排序的代价非常高。</li>\n<li><strong>索引优势：</strong> 如果连接字段上本来就有 B-Tree 索引（索引本质就是有序的），那么可以直接跳过排序步骤，性能极快。</li>\n</ul>\n</li>\n<li><strong>适用场景：</strong>\n<ul>\n<li>连接字段上有<strong>索引</strong>（天然有序）。</li>\n<li>SQL 中包含 <code>ORDER BY</code>，正好利用连接后的有序结果。</li>\n<li><strong>非等值连接</strong>中的范围连接（如 <code>BETWEEN</code> ）。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"4-三种算子对比总结表\">4. 三种算子对比总结表</h3>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>Nested Loop (嵌套循环)</strong></th>\n<th><strong>Hash Join (哈希连接)</strong></th>\n<th><strong>Merge Join (归并连接)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>核心逻辑</strong></td>\n<td>双层循环</td>\n<td>内存哈希表匹配</td>\n<td>排序后拉链式合并</td>\n</tr>\n<tr>\n<td><strong>适用数据量</strong></td>\n<td><strong>小数据量</strong> (小表驱动大表)</td>\n<td><strong>大数据量</strong> (两表均大)</td>\n<td><strong>大数据量</strong> (且有序)</td>\n</tr>\n<tr>\n<td><strong>索引依赖</strong></td>\n<td>强依赖 (被驱动表需索引)</td>\n<td>不依赖</td>\n<td>最好有 (可免去排序)</td>\n</tr>\n<tr>\n<td><strong>内存消耗</strong></td>\n<td>极低</td>\n<td><strong>高</strong> (需构建哈希表)</td>\n<td>中 (若需排序则高)</td>\n</tr>\n<tr>\n<td><strong>支持条件</strong></td>\n<td>任何 (等值/不等值/范围)</td>\n<td><strong>仅限等值</strong> (<code>=</code>)</td>\n<td>等值或范围</td>\n</tr>\n<tr>\n<td><strong>启动速度</strong></td>\n<td>快 (立即返回首行)</td>\n<td>慢 (需先构建哈希表)</td>\n<td>慢 (需先排序)</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h3 id=\"5-如何根据算子优化-sql\">5. 如何根据算子优化 SQL？</h3>\n<p>当你在 <code>EXPLAIN</code> 中看到以下情况时，可以尝试优化：</p>\n<ol>\n<li><strong>看到 <code>Nested Loop</code> 但很慢：</strong>\n<ul>\n<li>检查被驱动表（Inner Table）的连接字段是否有<strong>索引</strong>。如果没有，数据库在疯狂做全表扫描。</li>\n</ul>\n</li>\n<li><strong>看到 <code>Hash Join</code> 且带有 <code>Batches</code> 或 <code>Disk</code>：</strong>\n<ul>\n<li>说明内存不够用了，数据溢出到了磁盘。尝试调大 <code>work_mem</code> 参数，或者优化 WHERE 条件减少参与连接的数据量。</li>\n</ul>\n</li>\n<li><strong>看到 <code>Merge Join</code> 之前有一个巨大的 <code>Sort</code>：</strong>\n<ul>\n<li>排序非常消耗 CPU 和内存。如果在连接字段建立索引，可以消除这个排序步骤，直接利用 Index Scan 进行 Merge Join。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-集合与聚合算子-aggregation--set-nodes\">3. 集合与聚合算子 (Aggregation &amp; Set Nodes)</h2>\n<p>这类算子负责对数据进行去重、分组计算或合并多个结果集。</p>\n<ul>\n<li><strong>聚合类：</strong>\n<ul>\n<li><strong>Aggregate:</strong> 实现 <code>COUNT</code>, <code>SUM</code>, <code>AVG</code> 等。</li>\n<li><strong>GroupAggregate:</strong> 针对<strong>已排序</strong>的数据进行分组聚合。</li>\n<li><strong>HashAggregate:</strong> 针对<strong>未排序</strong>的数据，利用哈希表在内存中进行分组。</li>\n</ul>\n</li>\n<li><strong>集合类：</strong>\n<ul>\n<li><strong>Unique:</strong> 对有序数据进行去重（如 <code>DISTINCT</code>）。</li>\n<li><strong>HashSetOp:</strong> 利用哈希表进行集合操作（如 <code>INTERSECT</code> 或 <code>EXCEPT</code>）。</li>\n<li><strong>Append:</strong> 将多个子查询的结果集（如 <code>UNION ALL</code>）简单堆叠在一起。</li>\n</ul>\n</li>\n</ul>\n<p>在数据库执行计划中，<strong>集合与聚合算子（Aggregation &amp; Set Nodes）</strong> 负责对扫描或连接后的“原材料”数据进行深加工。</p>\n<p>简单来说：</p>\n<ul>\n<li><strong>聚合算子</strong>是做“数学题”的（求和、计数、平均、分组）。</li>\n<li><strong>集合算子</strong>是做“拼图”的（合并、交集、去重）。</li>\n</ul>\n<h3 id=\"第一部分聚合算子-aggregation-nodes\">第一部分：聚合算子 (Aggregation Nodes)</h3>\n<p>当你使用 <code>GROUP BY</code>、<code>COUNT</code>、<code>SUM</code>、<code>AVG</code> 等语句时，就会触发此类算子。数据库通常有两种策略来处理聚合：<strong>哈希（Hash）</strong> 和 <strong>排序（Sort/Group）</strong>。</p>\n<h5 id=\"1-hashaggregate-哈希聚合\">1. HashAggregate (哈希聚合)</h5>\n<p>这是处理<strong>未排序数据</strong>最常用的聚合方式。</p>\n<ul>\n<li><strong>工作原理（桶排序思想）：</strong>\n<ol>\n<li>数据库在内存（<code>work_mem</code>）中创建一个哈希表。</li>\n<li>扫描每一行数据，计算 <code>GROUP BY</code> 字段的哈希值。</li>\n<li>将数据丢进对应的“桶”里，并实时更新聚合状态（例如：如果是 <code>COUNT</code> 就 +1，如果是 <code>SUM</code> 就累加）。</li>\n<li>扫描结束后，遍历哈希表输出结果。</li>\n</ol>\n</li>\n<li><strong>优点：</strong> 不需要数据预先排序，速度通常很快。</li>\n<li><strong>缺点：</strong> <strong>非常吃内存</strong>。如果分组的数量太多（比如按 UserID 分组，有 100 万个用户），哈希表会撑爆内存，导致溢出到磁盘（Disk Spill），性能急剧下降。</li>\n<li><strong>场景：</strong> 数据无序，且分组基数（Cardinality）适中。</li>\n</ul>\n<h5 id=\"2-groupaggregate-分组聚合\">2. GroupAggregate (分组聚合)</h5>\n<p>这是基于<strong>有序数据</strong>的聚合方式。</p>\n<ul>\n<li><strong>工作原理（流水线思想）：</strong>\n<ol>\n<li><strong>前提：</strong> 输入的数据必须已经按 <code>GROUP BY</code> 字段排好序了（通常由下层的 <code>Sort</code> 算子或 <code>Index Scan</code> 保证）。</li>\n<li>数据库逐行读取数据。</li>\n<li>如果当前行的分组键和上一行一样，就累加；如果不一样，说明上一个组结束了，输出结果，开始下一个组。</li>\n</ol>\n</li>\n<li><strong>优点：</strong> <strong>内存占用极低</strong>（只需要存当前这一组的状态），且可以流式输出（不用等所有数据读完就能出第一行结果）。</li>\n<li><strong>缺点：</strong> 强依赖数据有序。如果数据本身没序，前面必须加一个昂贵的 <code>Sort</code> 算子。</li>\n<li><strong>场景：</strong> <code>GROUP BY</code> 字段上有索引，或者数据量大到内存装不下哈希表。</li>\n</ul>\n<h5 id=\"3-plain-aggregate-普通聚合\">3. Plain Aggregate (普通聚合)</h5>\n<ul>\n<li><strong>含义：</strong> 没有 <code>GROUP BY</code>，只算一个全局的总数。例如 <code>SELECT COUNT(*) FROM table</code>。</li>\n<li><strong>特点：</strong> 最简单，扫一遍全表，维护一个计数器即可。</li>\n</ul>\n<hr />\n<h3 id=\"第二部分集合与去重算子-set--unique-nodes\">第二部分：集合与去重算子 (Set &amp; Unique Nodes)</h3>\n<p>当你使用 <code>UNION</code>、<code>INTERSECT</code>、<code>EXCEPT</code> 或 <code>DISTINCT</code> 时，会用到这些算子。</p>\n<h4 id=\"1-append-追加\">1. Append (追加)</h4>\n<ul>\n<li><strong>对应 SQL：</strong> <code>UNION ALL</code></li>\n<li><strong>工作原理：</strong> 极其简单。先把第一个子查询的结果吐出来，再把第二个子查询的结果吐出来。不做去重，不做排序。</li>\n<li><strong>性能：</strong> <strong>极快</strong>。只要不需要去重，尽量用 <code>UNION ALL</code> 代替 <code>UNION</code>。</li>\n</ul>\n<h4 id=\"2-unique-去重\">2. Unique (去重)</h4>\n<ul>\n<li><strong>对应 SQL：</strong> <code>DISTINCT</code> 或 <code>UNION</code>（不带 ALL）。</li>\n<li><strong>工作原理：</strong> 类似于 <code>GroupAggregate</code>，它要求输入数据是有序的。它对比当前行和上一行，如果相同就丢弃，不同就输出。</li>\n<li><strong>注意：</strong> 如果数据没序，通常会先看到 <code>Sort</code>，再看到 <code>Unique</code>。</li>\n</ul>\n<h4 id=\"3-hashsetop--sortsetop-集合操作\">3. HashSetOp / SortSetOp (集合操作)</h4>\n<ul>\n<li><strong>对应 SQL：</strong> <code>INTERSECT</code> (交集) 或 <code>EXCEPT</code> (差集)。</li>\n<li><strong>HashSetOp：</strong> 用哈希表来判断元素是否存在于两个集合中。</li>\n<li><strong>SortSetOp：</strong> 先把两个集合排序，然后用双指针算法比对。</li>\n</ul>\n<hr />\n<h4 id=\"第三部分实战中的性能博弈\">第三部分：实战中的性能博弈</h4>\n<p>在看执行计划时，你需要关注以下几点：</p>\n<h4 id=\"1-内存-vs-排序-hashagg-vs-groupagg\">1. 内存 vs 排序 (HashAgg vs GroupAgg)</h4>\n<ul>\n<li>如果你的 SQL 跑得很慢，且看到 <strong>HashAggregate</strong> 下方有 <code>Disk: xxx kB</code>，说明内存不够了。\n<ul>\n<li><strong>优化：</strong> 调大 <code>work_mem</code> 参数，让哈希表能装入内存。</li>\n</ul>\n</li>\n<li>如果你看到 <strong>GroupAggregate</strong> 下方有一个巨大的 <strong>Sort</strong>，且 <code>Sort Method: external merge</code>。\n<ul>\n<li><strong>优化：</strong> 尝试在 <code>GROUP BY</code> 字段上加索引。有了索引，数据天然有序，<code>Sort</code> 算子就会消失，直接进行 <code>GroupAggregate</code>，性能起飞。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-distinct-的代价\">2. DISTINCT 的代价</h4>\n<p><code>DISTINCT</code> 本质上就是一次聚合或排序。</p>\n<ul>\n<li><code>SELECT DISTINCT user_id ...</code> 等价于 <code>SELECT user_id ... GROUP BY user_id</code>。</li>\n<li>千万不要滥用 <code>DISTINCT</code>。如果你写了 <code>DISTINCT</code>，数据库就必须把所有数据拿来进行一次昂贵的去重计算。</li>\n</ul>\n<h4 id=\"总结对比表\">总结对比表</h4>\n<table>\n<thead>\n<tr>\n<th><strong>算子名称</strong></th>\n<th><strong>功能</strong></th>\n<th><strong>依赖条件</strong></th>\n<th><strong>内存消耗</strong></th>\n<th><strong>适用场景</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>HashAggregate</strong></td>\n<td>分组/去重</td>\n<td>无</td>\n<td><strong>高</strong> (受基数影响)</td>\n<td>无索引，分组数量适中</td>\n</tr>\n<tr>\n<td><strong>GroupAggregate</strong></td>\n<td>分组/去重</td>\n<td><strong>数据必须有序</strong></td>\n<td>低</td>\n<td>有索引，或数据量极大</td>\n</tr>\n<tr>\n<td><strong>Append</strong></td>\n<td>合并结果</td>\n<td>无</td>\n<td>极低</td>\n<td><code>UNION ALL</code></td>\n</tr>\n<tr>\n<td><strong>Unique</strong></td>\n<td>排序去重</td>\n<td><strong>数据必须有序</strong></td>\n<td>低</td>\n<td><code>DISTINCT</code> (配合排序)</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"4-辅助与控制算子-materialize--control-nodes\">4. 辅助与控制算子 (Materialize &amp; Control Nodes)</h2>\n<p>这类算子不直接产生新数据，而是为了满足特定语法（排序、分页）或优化执行效率。</p>\n<ul>\n<li><strong>排序 (Sort):</strong> 执行 <code>ORDER BY</code>，如果内存装不下会触发磁盘排序。</li>\n<li><strong>物化 (Materialize):</strong> 将下层算子的结果缓存到内存中，供上层算子重复读取（常见于 Nested Loop）。</li>\n<li><strong>限制 (Limit):</strong> 处理 <code>LIMIT</code> 和 <code>OFFSET</code>，达到行数后立即停止下层算子。</li>\n<li><strong>锁定 (LockRows):</strong> 处理 <code>SELECT FOR UPDATE</code> 等锁定行操作。</li>\n<li><strong>结果 (Result):</strong> 处理不涉及表的计算（如 <code>SELECT 1+1</code>）。</li>\n</ul>\n<p>在 PostgreSQL 的执行计划中，<strong>辅助与控制算子（Auxiliary &amp; Control Nodes）</strong> 虽然不直接负责“找数据”或“拼数据”，但它们是整个流水线的<strong>调度员</strong>和<strong>加工厂</strong>。它们决定了数据如何排序、何时停止、如何并行处理以及如何锁定。</p>\n<p>以下是这类核心算子的详细讲解：</p>\n<hr />\n<h3 id=\"1-排序算子-sort-node\">1. 排序算子 (Sort Node)</h3>\n<p>这是最常见，也是最容易成为性能瓶颈的辅助算子。</p>\n<ul>\n<li>\n<p><strong>功能：</strong> 对下层算子返回的数据集进行排序（响应 <code>ORDER BY</code>，或者为 <code>Merge Join</code> 做准备）。</p>\n</li>\n<li>\n<p><strong>关键算法与内存机制：</strong></p>\n<ul>\n<li><strong>Quicksort (内存排序):</strong> 当数据量小于 <code>work_mem</code> 参数时，PostgreSQL 会在内存中完成快速排序。<strong>这是最快的。</strong></li>\n<li><strong>External Merge Sort (磁盘排序):</strong> 当数据量超过 <code>work_mem</code> 时，数据库被迫把数据写到临时文件（Disk），排好序后再合并。<strong>这会产生大量磁盘 I/O，非常慢。</strong></li>\n<li><strong>Top-N Heapsort:</strong> 当 SQL 包含 <code>ORDER BY ... LIMIT n</code> 时，数据库不需要全排，只需要维护一个大小为 N 的堆。这比全排快得多。</li>\n</ul>\n</li>\n<li>\n<p><strong>性能警报：</strong></p>\n<p>如果在 EXPLAIN 中看到 <code>Sort Method: external merge Disk: 25000kB</code>，说明内存不够用了。</p>\n<ul>\n<li><strong>优化：</strong> 调大 <code>work_mem</code>，或者建立索引（索引本身就是有序的，可以消除 Sort 算子）。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"2-限制算子-limit-node\">2. 限制算子 (Limit Node)</h3>\n<p>它是查询优化的“刹车片”。</p>\n<ul>\n<li><strong>功能：</strong> 对应 SQL 中的 <code>LIMIT</code> 和 <code>OFFSET</code>。</li>\n<li><strong>工作原理：</strong> 它像一个计数器，紧盯着下层算子吐出来的数据。一旦拿到了指定的行数（比如 10 行），它会立即<strong>切断</strong>下层算子的执行，不再让它们继续工作。</li>\n<li><strong>性能意义：</strong>\n<ul>\n<li>这是一个“逻辑算子”，本身消耗极小。</li>\n<li>它的价值在于<strong>“短路效应”</strong>。比如 <code>SELECT * FROM billion_table LIMIT 1</code>，Limit 算子会让 Seq Scan 在读到第一行时就停止，而不是扫完十亿行。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"3-物化算子-materialize-node\">3. 物化算子 (Materialize Node)</h3>\n<p>注意，这跟“物化视图”是两码事。这里的 Materialize 是执行计划中的一个<strong>临时缓存机制</strong>。</p>\n<ul>\n<li><strong>功能：</strong> 将下层算子的结果<strong>完整地读取并暂存</strong>（在内存或磁盘中），以便上层算子可以<strong>反复读取</strong>这些数据。</li>\n<li><strong>典型场景：</strong>\n<ul>\n<li>出现在 <strong>Nested Loop Join</strong>（嵌套循环连接）中。</li>\n<li>如果内表（被驱动表）是一个复杂的子查询或计算结果，数据库不希望每处理外表的一行，内表就重新计算一次。</li>\n<li><strong>优化逻辑：</strong> 内表计算一次 -&gt; Materialize 存起来 -&gt; 外表每行去 Materialize 里查。</li>\n</ul>\n</li>\n<li><strong>EXPLAIN 特征：</strong> 通常夹在 Nested Loop 和内层扫描之间。</li>\n</ul>\n<hr />\n<h3 id=\"4-并行控制算子-parallel-nodes\">4. 并行控制算子 (Parallel Nodes)</h3>\n<p>当 PostgreSQL 决定动用多个 CPU 核心来加速查询时，就会出现这些算子。它们负责协调“领队”和“工人”之间的关系。</p>\n<ul>\n<li><strong>Gather (收集):</strong>\n<ul>\n<li><strong>角色：</strong> 它是“工头”（Leader Process）。</li>\n<li><strong>功能：</strong> 启动多个并行工作线程（Workers），等待它们干完活，把结果汇总到这里，再发给上层。</li>\n</ul>\n</li>\n<li><strong>Gather Merge (有序收集):</strong>\n<ul>\n<li><strong>功能：</strong> 类似于 Gather，但它要求所有 Worker 返回的数据是有序的，并且它在汇总时会保持这种顺序（类似于归并排序的最后一步）。</li>\n<li><strong>场景：</strong> 并行查询且带有 <code>ORDER BY</code> 时。</li>\n</ul>\n</li>\n<li><strong>Parallel Seq Scan / Parallel Hash Join:</strong>\n<ul>\n<li>这些带有 <code>Parallel</code> 前缀的算子，说明它们是在 Worker 线程内部执行的。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"5-结果算子-result-node\">5. 结果算子 (Result Node)</h3>\n<p>这是最简单的算子，通常处理不涉及表扫描的计算。</p>\n<ul>\n<li><strong>功能：</strong> 计算并返回一个常量或表达式。</li>\n<li><strong>场景：</strong>\n<ul>\n<li><code>SELECT 1;</code></li>\n<li><code>SELECT version();</code></li>\n<li>某些复杂的 <code>CASE WHEN</code> 逻辑，如果优化器认为不需要查表，也会用 Result。</li>\n<li><strong>One-Time Filter:</strong> 如果 <code>WHERE</code> 条件是常量且为假（如 <code>WHERE 1=2</code>），Result 算子会直接返回空，整个查询瞬间结束。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h3 id=\"6-锁定算子-lockrows-node\">6. 锁定算子 (LockRows Node)</h3>\n<p>这是为了并发控制而存在的。</p>\n<ul>\n<li><strong>功能：</strong> 对应 SQL 中的 <code>SELECT ... FOR UPDATE</code> 或 <code>FOR SHARE</code>。</li>\n<li><strong>工作原理：</strong>\n<ul>\n<li>它会去访问数据行，并尝试在行头（Tuple Header）打上锁标记。</li>\n<li>如果有其他事务锁住了这行，它会在这里<strong>等待</strong>（Blocked），直到锁释放或超时。</li>\n</ul>\n</li>\n<li><strong>位置：</strong> 通常位于执行计划的最顶层附近，确保数据在返回给用户前已经被锁住。</li>\n</ul>\n<hr />\n<h3 id=\"总结如何通过这些算子诊断问题\">总结：如何通过这些算子诊断问题？</h3>\n<table>\n<thead>\n<tr>\n<th><strong>算子</strong></th>\n<th><strong>看到的现象</strong></th>\n<th><strong>潜在问题</strong></th>\n<th><strong>解决方案</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Sort</strong></td>\n<td><code>Disk: xxx kB</code></td>\n<td>内存溢出，磁盘排序</td>\n<td>调大 <code>work_mem</code> 或加索引</td>\n</tr>\n<tr>\n<td><strong>Materialize</strong></td>\n<td>耗时很久</td>\n<td>内层子查询太重</td>\n<td>优化子查询，或改写 JOIN 逻辑</td>\n</tr>\n<tr>\n<td><strong>Gather</strong></td>\n<td><code>Workers Planned: 2, Launched: 0</code></td>\n<td>并行未生效</td>\n<td>检查服务器负载或并行参数配置</td>\n</tr>\n<tr>\n<td><strong>LockRows</strong></td>\n<td>查询卡死不返回</td>\n<td>锁竞争</td>\n<td>检查是否有长事务未提交</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"5并行算子-parallel-nodes\">5.并行算子 (Parallel Nodes)</h2>\n<p>在开启并行查询时，你会看到带 <code>Gather</code> 前缀的特殊算子：</p>\n<ul>\n<li><strong>Gather:</strong> 汇总节点。收集所有并行工作线程（Workers）的结果。</li>\n<li><strong>Gather Merge:</strong> 收集结果的同时保持数据的有序性。</li>\n<li><strong>Parallel Seq Scan:</strong> 多个线程同时分段扫描一张表。</li>\n</ul>\n<p>在 PostgreSQL 9.6 之前，无论服务器有多少个 CPU 核心，一条 SQL 查询只能使用<strong>一个 CPU 核</strong>（单线程）。这就像让你一个人搬一万块砖，哪怕旁边站着 10 个人也没用。<strong>并行算子 (Parallel Nodes)</strong> 的引入彻底改变了这一点。它允许数据库启动多个后台工作线程（Background Workers），大家一起干活，最后由“包工头”汇总结果。以下是并行查询的核心架构与关键算子详解：</p>\n<hr />\n<h3 id=\"1-核心架构领队与工人-leader--workers\">1. 核心架构：领队与工人 (Leader &amp; Workers)</h3>\n<p>理解并行算子，首先要理解 PostgreSQL 的并行模型：</p>\n<ol>\n<li><strong>Leader Process (领队进程):</strong>\n<ul>\n<li>这是你连接数据库的那个主会话进程。</li>\n<li>它负责制定计划、分配任务、启动 Worker、收集结果，并把最终结果返回给客户端。</li>\n</ul>\n</li>\n<li><strong>Worker Processes (工人进程):</strong>\n<ul>\n<li>由 Leader 动态启动。</li>\n<li>它们执行计划中标记为 <code>Parallel</code> 的部分（如扫描、聚合、连接）。</li>\n<li>它们通过<strong>动态共享内存 (Dynamic Shared Memory, DSM)</strong> 与 Leader 交换数据。</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h3 id=\"2-关键算子详解\">2. 关键算子详解</h3>\n<p>在执行计划树中，并行部分通常位于树的<strong>下半部分</strong>，顶部总会有一个 <code>Gather</code> 类的节点作为分界线。</p>\n<h5 id=\"a-gather-汇总算子\">A. Gather (汇总算子)</h5>\n<p>这是并行执行的<strong>总出口</strong>，也是 Leader 进程主要工作的地方。</p>\n<ul>\n<li><strong>功能：</strong>\n<ol>\n<li>启动 N 个 Worker 线程。</li>\n<li>等待所有 Worker 把数据处理完。</li>\n<li>把 Worker 传回来的数据（以及 Leader 自己处理的一部分数据）合并在一起。</li>\n<li>向上层算子输出非并行的结果流。</li>\n</ol>\n</li>\n<li><strong>EXPLAIN 关键信息：</strong>\n<ul>\n<li><code>Workers Planned: 2</code>: 计划启动 2 个工人。</li>\n<li><code>Workers Launched: 2</code>: 实际启动了 2 个。如果系统负载太高，Launched 可能小于 Planned，甚至为 0（降级为单线程）。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"b-gather-merge-有序汇总算子\">B. Gather Merge (有序汇总算子)</h5>\n<p>这是 <code>Gather</code> 的升级版，用于需要<strong>保留顺序</strong>的场景。</p>\n<ul>\n<li><strong>功能：</strong>\n<ul>\n<li>假设下层的每个 Worker 返回的数据都已经局部排好序了。</li>\n<li><code>Gather Merge</code> 就像归并排序的最后一步，它读取所有 Worker 的输出，通过比较，按顺序把数据吐给上层。</li>\n</ul>\n</li>\n<li><strong>适用场景：</strong> SQL 中有 <code>ORDER BY</code>，且下层走了 <code>Parallel Index Scan</code> 或做过并行排序。</li>\n</ul>\n<h5 id=\"c-parallel-seq-scan-并行全表扫描\">C. Parallel Seq Scan (并行全表扫描)</h5>\n<p>这是 Worker 们最常干的活。</p>\n<ul>\n<li><strong>工作原理：</strong>\n<ul>\n<li>并不是把表切成 N 份固定分配给 N 个 Worker。</li>\n<li>而是采用<strong>“抢任务”模式（Block-by-Block）</strong>。</li>\n<li>所有 Worker（加上 Leader）共享一个扫描游标。谁扫完一个数据块（Block），就向系统申请下一个块。这样能防止有的 Worker 扫到了空闲页很快干完，有的 Worker 扫到了大对象页累死。</li>\n</ul>\n</li>\n<li><strong>优势：</strong> 极大地提高了 IO吞吐量（如果磁盘撑得住）和 CPU 过滤速度。</li>\n</ul>\n<h5 id=\"d-parallel-hash--parallel-hash-join-并行哈希连接\">D. Parallel Hash / Parallel Hash Join (并行哈希连接)</h5>\n<p>这是 PostgreSQL 11+ 引入的重磅功能。</p>\n<ul>\n<li><strong>传统 Hash Join：</strong> 一个进程构建哈希表，构建完再探测。</li>\n<li><strong>并行 Hash Join：</strong>\n<ol>\n<li><strong>Shared Hash Table:</strong> 所有 Worker 共同在共享内存中构建<strong>同一个</strong>巨大的哈希表。</li>\n<li><strong>协同探测:</strong> 构建完成后，所有 Worker 再并行去扫描外表，利用这个共享哈希表进行探测。</li>\n</ol>\n</li>\n<li><strong>注意：</strong> 这非常消耗内存！</li>\n</ul>\n<hr />\n<h3 id=\"3-一个典型的并行执行计划\">3. 一个典型的并行执行计划</h3>\n<p>假设我们要统计一张 1 亿行大表 <code>big_table</code> 的行数：</p>\n<p>SQL</p>\n<pre><code class=\"language-sql\">EXPLAIN SELECT count(*) FROM big_table;\n</code></pre>\n<p><strong>执行计划可能长这样：</strong></p>\n<pre><code class=\"language-sql\">Finalize Aggregate  (cost=... rows=1 ...)\n  -&gt;  Gather  (cost=... rows=3 ...)\n        Workers Planned: 2\n        -&gt;  Partial Aggregate  (cost=... rows=1 ...)\n              -&gt;  Parallel Seq Scan on big_table  (cost=... rows=41666666 ...)\n</code></pre>\n<p><strong>解读（自下而上）：</strong></p>\n<ol>\n<li>\n<p><strong>Parallel Seq Scan:</strong> 表被分成了很多块，3 个进程（1 个 Leader + 2 个 Workers）同时去抢着扫描。</p>\n</li>\n<li>\n<p><strong>Partial Aggregate (部分聚合):</strong> 每个 Worker 扫完自己那部分数据后，先在本地算一个 <code>count</code>（比如 Worker A 算出 3000 万，Worker B 算出 3500 万）。</p>\n</li>\n<li>\n<p><strong>Partial Aggregate (部分聚合):</strong> 是<strong>工人</strong>（Worker）在干活。每个人只算自己手头那一小堆数据的“小账”。</p>\n<p><strong>Aggregate / Finalize Aggregate (最终聚合):</strong> 是<strong>老板</strong>（Leader）在干活。他把工人们报上来的“小账”加在一起，算出“总账”。</p>\n</li>\n<li>\n<p><strong>Gather:</strong> Leader 进程把这 3 个部分结果收上来。</p>\n</li>\n<li>\n<p><strong>Finalize Aggregate (最终聚合):</strong> Leader 把收上来的 3 个数字加在一起，得到最终的 1 亿，返回给用户。</p>\n</li>\n</ol>\n<hr />\n<h3 id=\"4-并行算子的坑与调优\">4. 并行算子的“坑”与调优</h3>\n<p>虽然并行很快，但它不是银弹，使用时需注意：</p>\n<ol>\n<li><strong>启动成本：</strong> 启动 Worker 进程是有开销的。如果查询本身只需 10ms，开启并行可能反而要花 20ms。PostgreSQL 会通过 <code>min_parallel_table_scan_size</code> 参数自动判断表够不够大，小表不会走并行。</li>\n<li><strong>内存倍增风险 (work_mem):</strong>\n<ul>\n<li><strong>切记：</strong> <code>work_mem</code> 是限制<strong>每个进程</strong>的内存。</li>\n<li>如果你设置 <code>work_mem = 1GB</code>，并启动了 4 个 Worker。那么这个查询理论上最高可能消耗 <code>(4 + 1) * 1GB = 5GB</code> 内存。容易导致 OOM（内存溢出）。</li>\n</ul>\n</li>\n<li><strong>写操作限制：</strong> 目前，并行查询主要用于 <code>SELECT</code>。对于 <code>UPDATE</code> / <code>DELETE</code>，只有在 <code>RETURNING</code> 子句后的部分或者子查询中才能利用并行，修改数据本身的操作通常是单线程的。</li>\n</ol>\n<h3 id=\"总结-1\">总结</h3>\n<ul>\n<li><strong>Gather</strong> = 包工头（汇总）。</li>\n<li><strong>Parallel Scan</strong> = 工人（干苦力）。</li>\n<li><strong>核心优势</strong> = OLAP 类查询（大表扫描、聚合、大连接）速度成倍提升。</li>\n<li><strong>代价</strong> = CPU 飙升，内存消耗翻倍。</li>\n</ul>\n<h1 id=\"阻塞算子和非阻塞算子\">阻塞算子和非阻塞算子</h1>\n<p>这是一个非常关键的概念，它直接决定了你的 SQL 查询是<strong>“马上就有结果蹦出来”</strong>，还是<strong>“等了半天没反应，然后哗啦一下全出来了”</strong>。</p>\n<p>在数据库执行计划中，算子根据处理数据的方式，分为<strong>阻塞（Blocking）</strong>和<strong>非阻塞（Non-Blocking / Pipelined）</strong>两大类。</p>\n<p>我们可以用<strong>“自来水管”</strong>和<strong>“蓄水池”</strong>来比喻。</p>\n<hr />\n<h2 id=\"1-非阻塞算子-non-blocking-operators--自来水管\">1. 非阻塞算子 (Non-Blocking Operators) —— 自来水管</h2>\n<p><strong>特点：</strong></p>\n<ul>\n<li><strong>即时性：</strong> 只要从下层拿到了<strong>一行</strong>数据，处理完马上就吐给上层（或者返回给用户）。</li>\n<li><strong>流式处理 (Pipelined)：</strong> 数据像水流一样，源源不断地穿过算子。</li>\n<li><strong>低延迟：</strong> 用户能很快看到第一条结果（First Row Time 极短）。</li>\n</ul>\n<p><strong>典型算子：</strong></p>\n<ul>\n<li><strong>Seq Scan / Index Scan:</strong> 读到一行，就给一行。</li>\n<li><strong>Nested Loop Join:</strong> 只要外表找到一行，去内表匹配到了，就立马返回这一行结果。</li>\n<li><strong>Limit:</strong> 拿到一行算一行，数够了就关门。</li>\n<li><strong>Append:</strong> (<code>UNION ALL</code>) 读完这表读那表，中间不停顿。</li>\n</ul>\n<p><strong>场景举例：</strong></p>\n<pre><code class=\"language-sql\">SELECT * FROM users WHERE age &gt; 20 LIMIT 10;\n</code></pre>\n<p>数据库扫到第一条 <code>age &gt; 20</code> 的人，你马上就能在屏幕上看到。不需要等全表扫完。</p>\n<hr />\n<h2 id=\"2-阻塞算子-blocking-operators--蓄水池\">2. 阻塞算子 (Blocking Operators) —— 蓄水池</h2>\n<p><strong>特点：</strong></p>\n<ul>\n<li><strong>全量等待：</strong> 必须把下层传上来的<strong>所有数据</strong>都读完、存下来（通常在内存或磁盘），处理完毕后，才能吐出<strong>第一行</strong>结果。</li>\n<li><strong>物化 (Materialization)：</strong> 数据在这个算子这里“停滞”了，被堆积成了临时结果集。</li>\n<li><strong>高延迟：</strong> 在处理完最后一行数据之前，用户什么都看不到。</li>\n</ul>\n<p><strong>典型算子：</strong></p>\n<ul>\n<li><strong>Sort (排序):</strong> 这是最典型的阻塞算子。你想输出“最贵”的商品，必须把<strong>所有</strong>商品都看一遍并排好序，才能知道谁是第一名。</li>\n<li><strong>Aggregate (聚合):</strong> 比如 <code>COUNT</code>, <code>SUM</code>, <code>AVG</code>。你必须数完所有豆子，才能告诉我总共有多少颗。</li>\n<li><strong>Hash Join (Build Phase):</strong> 哈希连接的第一步是构建哈希表。它必须把一张表完全读入内存构建好 Hash Map，才能开始探测第二张表。</li>\n<li><strong>Unique / DISTINCT:</strong> 为了去重，通常需要把数据全看一遍（除非基于有序索引）。</li>\n</ul>\n<p><strong>场景举例：</strong></p>\n<pre><code class=\"language-sql\">SELECT * FROM users ORDER BY age;\n</code></pre>\n<p>哪怕你只看前 10 行，数据库也得把 100 万行用户全读出来，排好序，才能给你最年轻的那 10 个。</p>\n<hr />\n<h2 id=\"3-半阻塞算子-hash-join-的特殊性\">3. 半阻塞算子 (Hash Join 的特殊性)</h2>\n<p><strong>Hash Join</strong> 是个有趣的混合体：</p>\n<ol>\n<li><strong>阶段一（阻塞）：</strong> 构建哈希表（Build Hash Table）。\n<ul>\n<li>数据库读取<strong>右表（内表）</strong>的所有数据。此时，查询处于“卡顿”状态，没有任何输出。</li>\n</ul>\n</li>\n<li><strong>阶段二（非阻塞）：</strong> 探测（Probe）。\n<ul>\n<li>哈希表建好后，数据库开始扫描<strong>左表（外表）</strong>。每读一行左表，去哈希表里查一下。查到了，<strong>立刻输出</strong>。</li>\n</ul>\n</li>\n</ol>\n<p>所以，Hash Join 的启动速度取决于右表的大小。这也解释了为什么优化器总是喜欢用<strong>小表</strong>来做 Hash Join 的构建表。</p>\n<hr />\n<h2 id=\"4-为什么要区分这个\">4. 为什么要区分这个？</h2>\n<p>理解阻塞与非阻塞，对性能优化有两大指导意义：</p>\n<h3 id=\"a-响应时间-vs-总时间-response-time-vs-total-time\">A. 响应时间 vs. 总时间 (Response Time vs. Total Time)</h3>\n<ul>\n<li><strong>OLTP 系统（Web 应用）：</strong> 用户希望点开页面立马看到内容。\n<ul>\n<li><strong>目标：</strong> 尽量使用<strong>非阻塞算子</strong>。</li>\n<li><strong>策略：</strong> 利用索引消除 <code>Sort</code>，利用 Nested Loop 代替 Hash Join（在数据量小时）。</li>\n</ul>\n</li>\n<li><strong>OLAP 系统（报表分析）：</strong> 用户可以等 10 秒，但必须跑完几亿行数据。\n<ul>\n<li><strong>目标：</strong> 吞吐量优先。</li>\n<li><strong>策略：</strong> <strong>阻塞算子</strong>（如 Hash Join, Sort Merge Join）通常在处理大数据量时效率更高。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"b-内存消耗-work_mem\">B. 内存消耗 (<code>work_mem</code>)</h3>\n<ul>\n<li><strong>非阻塞算子</strong>通常不怎么吃内存，因为它们只处理当前这一行。</li>\n<li><strong>阻塞算子</strong>是<strong>内存杀手</strong>。<code>Sort</code> 需要内存排序，<code>Hash Agg</code> 需要内存存哈希表。如果内存 (<code>work_mem</code>) 不够，它们就会把数据写到<strong>磁盘临时文件</strong>，导致性能从“内存级”跌落到“磁盘级”（慢 1000 倍）。</li>\n</ul>\n<h2 id=\"5-如何在-explain-中看出来\">5. 如何在 EXPLAIN 中看出来？</h2>\n<p>看 <code>cost</code> 的两个数字：</p>\n<pre><code>cost=启动代价..总代价\n</code></pre>\n<ul>\n<li><strong>非阻塞算子：</strong> 启动代价（第一个数字）通常很小，接近 <strong>0.00</strong>。\n<ul>\n<li><code>Seq Scan (cost=0.00..145.00)</code> -&gt; 马上开始。</li>\n</ul>\n</li>\n<li><strong>阻塞算子：</strong> 启动代价通常<strong>很大</strong>，接近总代价。\n<ul>\n<li><code>Sort (cost=1000.00..1050.00)</code> -&gt; 前 1000 的代价都在等它排序，排完才开始输出。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"总结图表\">总结图表</h3>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>非阻塞算子 (Pipeline)</strong></th>\n<th><strong>阻塞算子 (Blocking)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>比喻</strong></td>\n<td>水管流过</td>\n<td>蓄水池蓄满</td>\n</tr>\n<tr>\n<td><strong>首行输出</strong></td>\n<td>极快 (0ms 级别)</td>\n<td>慢 (需处理完所有数据)</td>\n</tr>\n<tr>\n<td><strong>内存消耗</strong></td>\n<td>低 (处理完即丢)</td>\n<td>高 (需缓存所有数据)</td>\n</tr>\n<tr>\n<td><strong>典型代表</strong></td>\n<td>Nested Loop, Seq/Index Scan</td>\n<td>Sort, Hash Agg, Hash Join(构建端)</td>\n</tr>\n<tr>\n<td><strong>优化方向</strong></td>\n<td>适合分页、快速响应</td>\n<td>适合全量统计、大数据吞吐</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"执行计划分析\">执行计划分析</h1>\n<h2 id=\"第一维度explain\">第一维度：EXPLAIN</h2>\n<p>在使用之前，你必须知道你手里拿的是哪一把“手术刀”。不同的参数组合，看到的深度完全不同。</p>\n<ol>\n<li><strong>Level 1: <code>EXPLAIN SELECT ...</code> (静态推演)</strong>\n<ul>\n<li><strong>发生了什么：</strong> 数据库<strong>没有</strong>执行 SQL。它只是根据统计信息（Statistics）“脑补”了一个计划。</li>\n<li><strong>能看什么：</strong> 优化器打算怎么做、预估的成本（Cost）、预估的行数。</li>\n<li><strong>缺点：</strong> 它是猜的。如果统计信息过期，看到的计划可能完全是错的。</li>\n<li><strong>适用场景：</strong> SQL 跑得太慢不敢运行，或者涉及 <code>DELETE</code>/<code>UPDATE</code> 不想弄脏数据。</li>\n</ul>\n</li>\n<li><strong>Level 2: <code>EXPLAIN (ANALYZE) SELECT ...</code> (实战复盘)</strong>\n<ul>\n<li><strong>发生了什么：</strong> 数据库<strong>真的</strong>执行了 SQL（注意：如果是修改语句，数据真的会变！）。</li>\n<li><strong>能看什么：</strong> 除了预估值，还能看到<strong>实际耗时（Actual Time）</strong>、<strong>实际行数（Actual Rows）</strong>、<strong>循环次数（Loops）</strong>。</li>\n<li><strong>核心价值：</strong> 对比“预估”和“实际”的差异，这是调优的根基。</li>\n</ul>\n</li>\n<li><strong>Level 3: <code>EXPLAIN (ANALYZE, BUFFERS) SELECT ...</code> (IO 透视)</strong> —— <strong>最推荐！</strong>\n<ul>\n<li><strong>发生了什么：</strong> 在执行的基础上，统计了<strong>内存和磁盘的交互</strong>。</li>\n<li><strong>能看什么：</strong> 数据是从内存（Shared Buffers）读的，还是从硬盘（Disk）读的。</li>\n<li><strong>核心价值：</strong> 数据库慢，90% 是因为 IO。不看 Buffers 就无法精准定位 IO 瓶颈。</li>\n</ul>\n</li>\n<li><strong>Level 4: <code>EXPLAIN (ANALYZE, VERBOSE, SETTINGS) SELECT ...</code> (全息视图)</strong>\n<ul>\n<li><strong>VERBOSE:</strong> 显示每个算子具体输出了哪些列（Output List），有助于分析是否查了不该查的字段。</li>\n<li><strong>SETTINGS:</strong> 显示哪些非默认参数影响了这次计划（比如你临时把 <code>enable_seqscan</code> 关了）。</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第二维度解构树状执行流\">第二维度：解构树状执行流</h2>\n<p>执行计划是一个嵌套的树状结构。理解它的阅读顺序至关重要。</p>\n<h4 id=\"1-阅读法则由内向外自下而上\">1. 阅读法则：由内向外，自下而上</h4>\n<ul>\n<li><strong>缩进最深</strong>的节点，通常是“叶子节点”，最先开始工作（通常是扫描表）。</li>\n<li><strong>缩进相同</strong>的节点，通常按顺序执行（对于 Hash Join，上面的分支是 Build，下面的分支是 Probe）。</li>\n<li><strong>父节点</strong>依赖子节点的输出。</li>\n</ul>\n<h4 id=\"2-箭头---的含义\">2. 箭头 <code>-&gt;</code> 的含义</h4>\n<p>它代表数据的<strong>流动方向</strong>。子节点把处理好的数据“喂”给父节点。</p>\n<h4 id=\"3-示例结构解析\">3. 示例结构解析</h4>\n<p>Plaintext</p>\n<pre><code class=\"language-sql\">-&gt;  Sort  (Level 1: 最后执行，等待 Hash Join 的结果)\n    -&gt;  Hash Join  (Level 2: 它是 Sort 的孩子，等待 Hash 和 Seq Scan 的结果)\n          Hash Cond: (t1.id = t2.uid)\n          -&gt;  Seq Scan on large_table t1  (Level 3: 和下面的 Hash 处于同一级)\n          -&gt;  Hash  (Level 3: 它是 Hash Join 的内表构建过程)\n                -&gt;  Seq Scan on small_table t2 (Level 4: 最先执行，扫描小表)\n</code></pre>\n<p><strong>真实执行逻辑：</strong></p>\n<ol>\n<li>先扫描 <code>small_table t2</code>。</li>\n<li>将 t2 的数据构建成一个内存哈希表（Hash 节点）。</li>\n<li>扫描 <code>large_table t1</code>。</li>\n<li>每扫描一行 t1，就去哈希表里比对（Hash Join）。</li>\n<li>比对成功的结果，交给 <code>Sort</code> 节点排序。</li>\n<li>排序完返回给用户。</li>\n</ol>\n<hr />\n<h2 id=\"第三维度核心参数深度解码\">第三维度：核心参数深度解码</h2>\n<p>我们来看一行典型的输出，把它像拆炸弹一样拆解开：</p>\n<pre><code class=\"language-sql\">-&gt;  Seq Scan on orders  (cost=0.00..188.00 rows=1000 width=45) (actual time=0.006..2.500 rows=1200 loops=1)\n</code></pre>\n<h4 id=\"a-预估部分-括号第一部分\">A. 预估部分 (括号第一部分)</h4>\n<ol>\n<li><strong><code>cost=0.00..188.00</code> (代价)</strong>\n<ul>\n<li><strong>单位：</strong> 这是一个抽象值，没有单位（通常 1.0 代表读取一个磁盘页的代价）。</li>\n<li><strong>0.00 (Startup Cost - 启动代价)：</strong> 拿到<strong>第一行</strong>数据前需要多长时间。\n<ul>\n<li><code>Seq Scan</code> 是 0，因为我们要的第一行就在第一页。</li>\n<li><code>Sort</code> 节点这里会很大，因为它必须把所有数据排完序才能吐出第一行。</li>\n</ul>\n</li>\n<li><strong>188.00 (Total Cost - 总代价)：</strong> 拿到<strong>所有</strong>数据需要的总代价。优化器（Planner）就是凭这个数字选路，它会选 Total Cost 最小的那条路。</li>\n</ul>\n</li>\n<li><strong><code>rows=1000</code> (预估行数)</strong>\n<ul>\n<li>优化器根据统计信息（pg_statistic）猜出来的。</li>\n<li><strong>重要性：</strong> 它是决定走 Nested Loop 还是 Hash Join 的关键。如果这里猜错了，计划就会选错。</li>\n</ul>\n</li>\n<li><strong><code>width=45</code> (行宽度)</strong>\n<ul>\n<li>平均每一行数据占用 45 字节。</li>\n<li><strong>重要性：</strong> <code>rows * width</code> = 预估的总数据量。这决定了需不需要把数据写到临时文件（Disk Spill），因为内存（work_mem）是有限的。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"b-实际执行部分-括号第二部分仅在-analyze-模式下出现\">B. 实际执行部分 (括号第二部分，仅在 ANALYZE 模式下出现)</h4>\n<ol>\n<li>\n<p><strong><code>actual time=0.006..2.500</code> (实际时间)</strong></p>\n<ul>\n<li><strong>单位：</strong> 毫秒 (ms)。</li>\n<li><strong>0.006 (Start Time)：</strong> 拿到第一行花了 0.006ms。</li>\n<li><strong>2.500 (Total Time)：</strong> <strong>平均每次循环</strong>拿到所有数据花了 2.5ms。</li>\n<li><strong>坑点：</strong> 如果 <code>loops &gt; 1</code>，真实总时间 = <code>Total Time * loops</code>。</li>\n</ul>\n</li>\n<li>\n<p><strong><code>rows=1200</code> (实际行数)</strong></p>\n<ul>\n<li>真实返回了多少行。</li>\n</ul>\n</li>\n<li>\n<p><strong><code>loops=1</code> (循环次数)</strong></p>\n<ul>\n<li>\n<p>这个算子被执行了几次。</p>\n</li>\n<li>\n<p><strong>Nested Loop 中的大坑：</strong></p>\n<pre><code class=\"language-sql\">-&gt;  Index Scan on child_table ... (actual time=0.005..0.010 rows=1 loops=10000)\n</code></pre>\n<p>乍一看只花了 0.01ms？<strong>错！</strong> 真实的耗时是 <code>0.010 * 10000 = 100ms</code>。<strong>一定要乘 Loops！</strong></p>\n</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第四维度buffers--io-的秘密\">第四维度：Buffers —— IO 的秘密</h2>\n<p>加上 <code>BUFFERS</code> 选项后，你会看到类似这样的输出：</p>\n<pre><code>Buffers: shared hit=5 read=10 dirtied=2 written=1\n</code></pre>\n<p>这是判断性能瓶颈的金标准：</p>\n<ol>\n<li><strong>Shared Hit (内存命中):</strong>\n<ul>\n<li>数据直接从 PostgreSQL 的共享内存（Shared Buffers）里拿到了。</li>\n<li><strong>评价：</strong> 很好，极快。我们希望 Hit 越高越好。</li>\n</ul>\n</li>\n<li><strong>Read (磁盘读取):</strong>\n<ul>\n<li>内存里没有，必须向操作系统申请从磁盘读。</li>\n<li><strong>评价：</strong> 慢。如果 Read 很高，说明内存不够用，或者索引没建好导致扫描了太多冷数据。</li>\n</ul>\n</li>\n<li><strong>Dirtied (脏页):</strong>\n<ul>\n<li>查询过程中，发现数据页被修改了（通常是未提交的事务），需要标记为脏页。</li>\n<li><strong>评价：</strong> 在 <code>SELECT</code> 查询中不应该大量出现。</li>\n</ul>\n</li>\n<li><strong>Temp Read / Written (临时文件读写):</strong>\n<ul>\n<li><strong>评价：</strong> <strong>灾难级</strong>。</li>\n<li>说明 <code>work_mem</code> 太小，排序（Sort）或哈希表（Hash）在内存装不下，被迫把数据写到硬盘上再读回来。这会让查询慢几个数量级。</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第五维度警示信号--看到这些要报警\">第五维度：警示信号 —— 看到这些要报警</h2>\n<p>在审视长篇大论的计划时，请带上“找茬”的眼镜，寻找以下红线：</p>\n<h4 id=\"1-估算与实际的巨大偏差-estimation-skew\">1. 估算与实际的巨大偏差 (Estimation Skew)</h4>\n<ul>\n<li><strong>现象：</strong> <code>rows=1</code>，但 <code>actual rows=1000000</code>。</li>\n<li><strong>后果：</strong> 优化器以为数据很少，选了 Nested Loop，结果被海量数据教做人。</li>\n<li><strong>对策：</strong> <code>ANALYZE table_name;</code> 更新统计信息。</li>\n</ul>\n<h4 id=\"2-高-filter-移除率-high-filter-ratio\">2. 高 Filter 移除率 (High Filter Ratio)</h4>\n<ul>\n<li><strong>现象：</strong> <code>Rows Removed by Filter: 99999</code> (Seq Scan 返回了 10 万行，过滤丢掉了 9 万 9 千行)。</li>\n<li><strong>含义：</strong> 数据库做了大量无用功。它像个笨拙的图书管理员，把整架书搬下来，一本本看，最后只给你一本。</li>\n<li><strong>对策：</strong> 针对 Filter 的条件建立索引。</li>\n</ul>\n<h4 id=\"3-临时文件溢出-disk-spill\">3. 临时文件溢出 (Disk Spill)</h4>\n<ul>\n<li><strong>现象：</strong> <code>Disk: 10240kB</code> (出现在 Sort 或 Hash 节点)。</li>\n<li><strong>对策：</strong> 调大 <code>work_mem</code> 参数，或者优化 SQL 减少排序/聚合的数据量。</li>\n</ul>\n<h4 id=\"4-错误的连接方式\">4. 错误的连接方式</h4>\n<ul>\n<li><strong>现象：</strong> 两个大表连接（比如各 100 万行），却用了 <code>Nested Loop</code>。</li>\n<li><strong>原因：</strong> 通常是因为上述的“估算偏差”导致的。</li>\n</ul>\n<hr />\n<h2 id=\"第六维度实战逐行拆解案例\">第六维度：实战逐行拆解案例</h2>\n<p>让我们来看一个包含“坑”的真实复杂案例。</p>\n<pre><code class=\"language-sql\">SELECT * FROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE u.age &gt; 20 AND o.status = 'paid'\nORDER BY o.create_time LIMIT 10;\n</code></pre>\n<p><strong>Execution Plan:</strong></p>\n<pre><code class=\"language-sql\">Limit  (cost=100.50..100.60 rows=10) (actual time=55.000..55.010 rows=10 loops=1)\n  -&gt;  Sort  (cost=100.50..105.00 rows=500) (actual time=55.000..55.005 rows=10 loops=1)\n        Sort Key: o.create_time\n        Sort Method: external merge  Disk: 800kB  &lt;-- 警报 1\n        -&gt;  Hash Join  (cost=20.00..80.00 rows=500) (actual time=10.000..45.000 rows=10000 loops=1)\n              Hash Cond: (o.user_id = u.id)\n              -&gt;  Seq Scan on orders o  (cost=0.00..50.00 rows=2000) (actual time=0.005..15.000 rows=50000 loops=1) &lt;-- 警报 2\n                    Filter: (status = 'paid')\n                    Rows Removed by Filter: 100000  &lt;-- 警报 3\n              -&gt;  Hash  (cost=15.00..15.00 rows=100) (actual time=5.000..5.000 rows=100 loops=1)\n                    Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                    -&gt;  Seq Scan on users u  (cost=0.00..15.00 rows=100) (actual time=0.004..3.000 rows=100 loops=1)\n                          Filter: (age &gt; 20)\n</code></pre>\n<p><strong>逐行侦探分析：</strong></p>\n<ol>\n<li><strong>看最下面 (users):</strong> <code>Seq Scan on users</code>。扫了 users 表，过滤 <code>age &gt; 20</code>，剩 100 行。速度挺快 (3ms)，没大毛病。</li>\n<li><strong>看中间 (Hash):</strong> 把这 100 个 user 放入内存哈希表。内存只用了 9kB，很健康。</li>\n<li><strong>看下面 (orders) - [警报 2 &amp; 3]:</strong>\n<ul>\n<li><code>Seq Scan on orders</code>。</li>\n<li><code>Filter: status='paid'</code>。</li>\n<li><code>Rows Removed by Filter: 100000</code>。</li>\n<li><strong>解读：</strong> 为了找 'paid' 的订单，全表扫描并扔掉了 10 万行废数据！</li>\n<li><strong>优化：</strong> 应该在 <code>orders(status)</code> 上加索引。</li>\n</ul>\n</li>\n<li><strong>看 Join (Hash Join):</strong>\n<ul>\n<li><code>actual rows=10000</code>。Join 完有 1 万行数据。</li>\n</ul>\n</li>\n<li><strong>看排序 (Sort) - [警报 1]:</strong>\n<ul>\n<li><code>Sort Method: external merge Disk: 800kB</code>。</li>\n<li><strong>解读：</strong> 这里的 1 万行数据要排序，但是内存不够用了，数据溢出到了磁盘（Disk）。这严重拖慢了速度。</li>\n<li><strong>优化：</strong> 调大 <code>work_mem</code>，或者给 <code>orders(user_id, status, create_time)</code> 加复合索引，可能直接消除排序。</li>\n</ul>\n</li>\n<li><strong>看顶层 (Limit):</strong> 取了前 10 条。</li>\n</ol>\n<h2 id=\"总结-2\">总结</h2>\n<p>看执行计划，本质上是在回答三个问题：</p>\n<ol>\n<li><strong>数据怎么找的？</strong> (Scan: 是傻傻的扫全表，还是聪明的查索引？)</li>\n<li><strong>数据怎么连的？</strong> (Join: 是双层循环，还是哈希匹配？)</li>\n<li><strong>资源够不够？</strong> (Buffer/Disk: 内存命中率高吗？有没有溢出到磁盘？)</li>\n</ol>\n<p>只要抓住了 <code>Actual Time</code>（真实耗时）、<code>Rows Removed</code>（过滤浪费）和 <code>Disk/Buffers</code>（资源瓶颈），你就掌握了性能优化的钥匙。</p>\n<h1 id=\"查询优化器\">查询优化器</h1>\n<p>简单来说，数据库做决定的过程，就像是你在用地图软件导航。</p>\n<ul>\n<li><strong>起点</strong>是数据现在的状态。</li>\n<li><strong>终点</strong>是你想要的查询结果。</li>\n<li><strong>路径</strong>就是各种“执行计划”。</li>\n<li><strong>优化器</strong>就是那个算法，它需要在成千上万条可能的路线中，算出一条<strong>“代价（Cost）最低”</strong>的路。</li>\n</ul>\n<p>这个过程被称为 <strong>CBO (Cost-Based Optimization，基于代价的优化)</strong>。以下是它做决定的完整逻辑链条：</p>\n<hr />\n<h2 id=\"第一阶段预处理与逻辑优化-query-rewriting\">第一阶段：预处理与逻辑优化 (Query Rewriting)</h2>\n<p>在计算代价之前，优化器会先对你的 SQL 做“整形手术”，把它改写成逻辑上等价但更容易优化的形式。这叫<strong>逻辑优化</strong>。</p>\n<ul>\n<li><strong>去除多余条件：</strong> 比如 <code>WHERE 1=1</code> 会被删掉。</li>\n<li><strong>常量折叠：</strong> <code>WHERE id = 1 + 2</code> 会变成 <code>WHERE id = 3</code>。</li>\n<li><strong>视图合并 (View Merging)：</strong> 如果查询里用了视图，优化器会试图把视图拆开，把里面的表直接拿出来和外面的表连接，扩大选择空间。</li>\n<li><strong>子查询扁平化 (Subquery Unnesting)：</strong> 尽量把子查询改写成 JOIN，因为数据库处理 JOIN 的算法比处理子查询丰富得多。</li>\n</ul>\n<hr />\n<h2 id=\"第二阶段枚举候选计划-plan-enumeration\">第二阶段：枚举候选计划 (Plan Enumeration)</h2>\n<p>这是最耗时的步骤。优化器会像变魔术一样，排列组合出各种可能的执行路径。</p>\n<p>如果不加限制，一个涉及 5 张表的查询，可能的连接顺序就有 5! = 120 种，再乘以每两张表可能有 3 种连接方式（Hash/Nested/Merge），再乘以每张表可能有 2-3 种扫描方式（Seq/Index/Bitmap）……<strong>搜索空间是指数级爆炸的</strong>。</p>\n<p>优化器主要考虑三个维度的组合：</p>\n<ol>\n<li><strong>访问路径 (Access Path)：</strong>\n<ul>\n<li>表 A：是用全表扫描，还是用索引 X，还是用索引 Y？</li>\n</ul>\n</li>\n<li><strong>连接顺序 (Join Order)：</strong>\n<ul>\n<li>是先 A Join B，结果再 Join C？</li>\n<li>还是先 B Join C，结果再 Join A？</li>\n</ul>\n</li>\n<li><strong>连接算法 (Join Method)：</strong>\n<ul>\n<li>是用 Nested Loop，还是 Hash Join，还是 Merge Join？</li>\n</ul>\n</li>\n</ol>\n<hr />\n<h2 id=\"第三阶段代价估算-cost-estimation--核心中的核心\">第三阶段：代价估算 (Cost Estimation) —— 核心中的核心</h2>\n<p>面对生成的一堆候选计划，优化器怎么知道哪个好？它需要给每个计划算一个分（Cost）。</p>\n<p><strong>公式大致如下（简化版）：</strong></p>\n<p>Cost = (IO代价 \\times IO权重) + (CPU代价 \\times CPU权重)</p>\n<p>为了算出这个公式，优化器必须依赖<strong>统计信息 (Statistics)</strong>。如果统计信息不准，优化器就会变成“盲人”。</p>\n<h4 id=\"1-统计信息-the-fuel\">1. 统计信息 (The Fuel)</h4>\n<p>数据库会定期（通过 <code>ANALYZE</code> 命令）收集每张表的情报，存放在系统表里（如 PG 的 <code>pg_statistic</code>）：</p>\n<ul>\n<li><strong>行数 (Tuples):</strong> 表里大概有多少行？</li>\n<li><strong>页面数 (Pages):</strong> 表占了多少磁盘块？</li>\n<li><strong>唯一值个数 (n_distinct):</strong> 某一列有多少个不同的值？（决定了过滤性）</li>\n<li><strong>高频值 (MCV - Most Common Values):</strong> 哪几个值出现得最多？（比如“状态”字段，90% 都是 'success'）</li>\n<li><strong>直方图 (Histogram):</strong> 数据的分布情况是怎样的？（用于范围查询估算）</li>\n</ul>\n<h4 id=\"2-推算过程-the-calculation\">2. 推算过程 (The Calculation)</h4>\n<p>优化器利用统计信息进行<strong>基数估算 (Cardinality Estimation)</strong>，也就是猜每一各步骤会返回多少行。</p>\n<ul>\n<li><strong>例子：</strong> <code>SELECT * FROM users WHERE age &gt; 20 AND city = 'Beijing'</code>\n<ul>\n<li>统计信息说：<code>age &gt; 20</code> 的大概占 50%，<code>city = 'Beijing'</code> 的大概占 10%。</li>\n<li>优化器假设两列不相关，估算出符合条件的行数 = 总行数 $\\times$ 50% $\\times$ 10%。</li>\n<li>如果算出来只有 10 行，它可能选 <strong>Index Scan</strong>。</li>\n<li>如果算出来有 100 万行，它可能选 <strong>Seq Scan</strong>。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"第四阶段搜索算法-search-algorithms\">第四阶段：搜索算法 (Search Algorithms)</h2>\n<p>因为候选计划太多了，不可能真的把每一个都算一遍（那光是生成计划就要几分钟）。数据库使用高效的算法来“剪枝”和搜索。</p>\n<h4 id=\"1-动态规划-dynamic-programming--system-r-风格\">1. 动态规划 (Dynamic Programming) —— System R 风格</h4>\n<p>这是大多数数据库（包括 PostgreSQL 和 Oracle）处理中小型查询（通常 &lt; 12 张表）的标准算法。</p>\n<ul>\n<li><strong>思路：</strong> 自底向上。\n<ul>\n<li>先算出访问单表 A、B、C 的最优路径。</li>\n<li>再基于此，算出 {A, B} 连接的最优路径，和 {B, C} 连接的最优路径。</li>\n<li>再算出 {A, B, C} 的最优路径。</li>\n</ul>\n</li>\n<li><strong>优势：</strong> 能保证找到<strong>全局最优解</strong>。</li>\n</ul>\n<h4 id=\"2-遗传算法-genetic-algorithm--geqo\">2. 遗传算法 (Genetic Algorithm / GEQO)</h4>\n<p>当表非常多（比如 PostgreSQL 默认超过 12 张表 JOIN）时，动态规划太慢了。优化器会切换到遗传算法。</p>\n<ul>\n<li><strong>思路：</strong> 随机生成几个计划（种群），让它们“变异”和“杂交”（交换连接顺序），保留 Cost 低的，淘汰高的，迭代几轮后，选一个“足够好”的（但不一定是最优的）。</li>\n<li><strong>优势：</strong> 速度快，避免优化过程本身把数据库搞死。</li>\n</ul>\n<hr />\n<h2 id=\"第五阶段最终决策-plan-selection\">第五阶段：最终决策 (Plan Selection)</h2>\n<p>经过上述步骤，优化器手里捏着几个经过筛选的“决赛圈”计划。它会简单粗暴地比较它们的 <strong>Total Cost</strong>：</p>\n<ul>\n<li>计划 A (Hash Join): Cost = 500</li>\n<li>计划 B (Nested Loop): Cost = 2000</li>\n<li>计划 C (Merge Join): Cost = 480</li>\n</ul>\n<p><strong>决定：</strong> 选用计划 C。</p>\n<hr />\n<h2 id=\"总结为什么优化器有时候会犯傻\">总结：为什么优化器有时候会“犯傻”？</h2>\n<p>了解了原理，你就知道为什么数据库有时候会选错计划（比如选了全表扫描而不走索引）：</p>\n<ol>\n<li><strong>统计信息过期：</strong> 数据变了，但没运行 <code>ANALYZE</code>，优化器以为表是空的，结果表里有 1 亿行。它会错误地选择 Nested Loop，导致系统卡死。</li>\n<li><strong>数据相关性 (Correlation)：</strong> 优化器默认假设列与列之间是独立的。\n<ul>\n<li>比如查询“省份=湖北 AND 城市=武汉”。</li>\n<li>优化器觉得这两个概率要相乘（0.03 * 0.01 = 0.0003），认为结果极少。</li>\n<li>实际上这两个条件是强相关的，结果很多。估算错误导致选错索引。</li>\n</ul>\n</li>\n<li><strong>代价模型偏差：</strong> 传统的 Cost 模型主要看 IO。现在的 SSD 很快，有时候随机读（Index Scan）比顺序读（Seq Scan）快，但旧的代价参数可能还觉得机械硬盘的随机读很慢，从而不敢用索引。</li>\n</ol>\n<h2 id=\"一图胜千言\">一图胜千言</h2>\n<p>可以将整个过程想象成一个漏斗：</p>\n<ol>\n<li><strong>SQL 文本</strong> (输入)</li>\n<li><strong>Parser</strong> (语法树)</li>\n<li><strong>Rewriter</strong> (逻辑优化后的树)</li>\n<li><strong>Planner</strong> (生成 1000 个路径 -&gt; 估算 Cost -&gt; 动态规划剪枝 -&gt; 剩 1 个路径)</li>\n<li><strong>Executor</strong> (执行选定的那个计划)</li>\n</ol>\n<h1 id=\"hash-join的buckets和batches\">Hash Join的Buckets和Batches</h1>\n<p>在 PostgreSQL 的 <code>EXPLAIN (ANALYZE)</code> 输出中，<code>Buckets</code> 和 <code>Batches</code> 是 Hash Join（哈希连接）算子下两个至关重要的参数。它们直接揭示了你的查询是<strong>“在内存里飞”</strong>，还是<strong>“在硬盘里爬”</strong>。</p>\n<p>简单总结：</p>\n<ul>\n<li><strong>Buckets (桶):</strong> 是哈希表的<strong>“房间数”</strong>。它决定了 CPU 查找的效率（解决哈希冲突）。</li>\n<li><strong>Batches (批次):</strong> 是哈希表的<strong>“分身数”</strong>。它决定了内存够不够用（解决内存溢出）。<strong>这是性能杀手。</strong></li>\n</ul>\n<hr />\n<h2 id=\"1-buckets-桶--内存里的门牌号\">1. Buckets (桶) —— 内存里的“门牌号”</h2>\n<p>Hash Join 的第一步是构建哈希表（Build Phase）。数据库会申请一块内存，把这块内存划分为 N 个槽位，每个槽位就是一个 <strong>Bucket</strong>。</p>\n<ul>\n<li>\n<p><strong>工作原理：</strong></p>\n<ol>\n<li>数据库读取内表（Build Table）的一行数据。</li>\n<li>对连接键（Join Key）算出一个哈希值。</li>\n<li>用 <code>哈希值 % Bucket总数</code> 算出这行数据该进哪个桶。</li>\n<li>把数据挂在这个桶的链表后面。</li>\n</ol>\n</li>\n<li>\n<p><strong>理想情况：</strong></p>\n<p>每个桶里只有 1 行数据。这样探测（Probe）的时候，算一次哈希就能直接定位到数据，复杂度是 O(1)。</p>\n</li>\n<li>\n<p><strong>糟糕情况（哈希冲突）：</strong></p>\n<p>如果 Buckets 太少，或者哈希函数不好，导致几千行数据都挤在一个桶里（冲突）。那在这个桶内部查找就变成了线性扫描，CPU 消耗剧增。</p>\n</li>\n<li>\n<p><strong>EXPLAIN 中的表现：</strong></p>\n<p>PostgreSQL 通常会自动调整 Buckets 的数量以保持较高的效率（通常是 2 的幂次方）。</p>\n<blockquote>\n<p><code>Buckets: 1024  Memory Usage: 50kB</code></p>\n</blockquote>\n<blockquote>\n<ul>\n<li>这说明申请了 1024 个槽位，内存用了 50kB。这通常不是瓶颈。</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<hr />\n<h2 id=\"2-batches-批次--内存不够时的分身术\">2. Batches (批次) —— 内存不够时的“分身术”</h2>\n<p>这是最需要警惕的指标。</p>\n<p>Hash Join 必须把整个哈希表建在内存里。但是，如果你的 <code>work_mem</code>（工作内存）只有 4MB，而内表有 100MB，怎么办？内存装不下！</p>\n<p>这时候，PostgreSQL 就会启动 <strong>Batching（分批）机制</strong>，也就是<strong>把大象切块装进冰箱</strong>。</p>\n<ul>\n<li><strong>工作原理（分治法）：</strong>\n<ol>\n<li><strong>切分：</strong> 数据库根据哈希值，将内表（Build Table）和外表（Probe Table）切分成 N 个 <strong>Batches</strong>。</li>\n<li><strong>驻留与落盘：</strong>\n<ul>\n<li><strong>Batch 0</strong>：留在内存里，立刻开始做连接。</li>\n<li><strong>Batch 1 ~ N</strong>：内存放不下了，<strong>写到磁盘临时文件（Temp Files）里</strong>。</li>\n</ul>\n</li>\n<li><strong>轮询：</strong> 等 Batch 0 处理完，清空内存，把 Batch 1 从磁盘读回内存，构建哈希表，再处理……直到所有 Batch 处理完。</li>\n</ol>\n</li>\n<li><strong>Batches = 1 (完美状态)：</strong>\n<ul>\n<li>说明所有数据都能装进内存 (<code>work_mem</code>)。</li>\n<li>没有磁盘 I/O，速度最快。</li>\n<li><strong>EXPLAIN:</strong> <code>Batches: 1  Memory Usage: ...</code></li>\n</ul>\n</li>\n<li><strong>Batches &gt; 1 (溢出状态)：</strong>\n<ul>\n<li>说明内存不够，触发了磁盘读写。</li>\n<li><strong>EXPLAIN:</strong> <code>Batches: 4  Disk: 2500kB</code>。</li>\n<li>这意味着你的查询正在经历“写盘 -&gt; 读盘”的折磨，性能会下降几个数量级。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"3-实战案例如何通过这两个参数调优\">3. 实战案例：如何通过这两个参数调优？</h2>\n<p>让我们看一个发生“内存溢出”的 Hash Join 执行计划：</p>\n<p>Plaintext</p>\n<pre><code class=\"language-sql\">-&gt;  Hash Join  (cost=...) (actual time=...)\n      Hash Cond: (outer.id = inner.id)\n      -&gt;  Seq Scan on outer_table ...\n      -&gt;  Hash  (cost=...) (actual time=...)\n            Buckets: 65536  Batches: 8  Memory Usage: 4096kB  &lt;-- 关键点在这里！\n            Disk: 12000kB                                     &lt;-- 证据确凿\n            -&gt;  Seq Scan on inner_table ...\n</code></pre>\n<h4 id=\"分析\">分析：</h4>\n<ol>\n<li><strong>Buckets: 65536</strong>\n<ul>\n<li>桶很多，说明数据量不小，PostgreSQL 试图分散哈希冲突。</li>\n</ul>\n</li>\n<li><strong>Batches: 8</strong>\n<ul>\n<li><strong>报警！</strong> 这意味着数据被分成了 8 份。</li>\n<li>第 1 份在内存处理了，剩下 7 份被写到了磁盘上。</li>\n</ul>\n</li>\n<li><strong>Disk: 12000kB</strong>\n<ul>\n<li>为了做这个 Join，数据库临时写了 12MB 的数据到硬盘。</li>\n</ul>\n</li>\n<li><strong>Memory Usage: 4096kB</strong>\n<ul>\n<li>当前的 <code>work_mem</code> 设置限制了它只能用 4MB 内存。因为装不下 16MB（12MB+4MB）的数据，所以被迫分批。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"优化方案\">优化方案：</h4>\n<p>为了让 <code>Batches</code> 变回 1，我们需要增加 <code>work_mem</code>。</p>\n<pre><code class=\"language-sql\">-- 临时调大当前会话的内存限制（比如调到 32MB）\nSET work_mem = '32MB';\n\n-- 再次运行 EXPLAIN ANALYZE\nEXPLAIN ANALYZE SELECT ...\n</code></pre>\n<p><strong>优化后的可能结果：</strong></p>\n<p>Plaintext</p>\n<pre><code class=\"language-sql\">-&gt;  Hash  (cost=...) (actual time=...)\n      Buckets: 65536  Batches: 1  Memory Usage: 16100kB  &lt;-- 舒服了\n      Disk: 0kB                                          &lt;-- 磁盘 I/O 消失\n</code></pre>\n<ul>\n<li><strong>Batches: 1</strong>: 所有数据都在内存里。</li>\n<li><strong>Memory Usage: 16100kB</strong>: 实际上只用了 16MB 内存，完全在我们的预算（32MB）之内。</li>\n<li><strong>性能提升</strong>: 查询速度通常会提升 2-10 倍。</li>\n</ul>\n<hr />\n<h2 id=\"4-深度机制dynamic-growing-动态增长\">4. 深度机制：Dynamic Growing (动态增长)</h2>\n<p>有时候你会看到这样的输出：</p>\n<pre><code class=\"language-sql\">Buckets: 1024  Batches: 1 (originally 1)  Memory Usage: ...\n</code></pre>\n<p>或者：</p>\n<pre><code class=\"language-sql\">Buckets: 1024  Batches: 2 (originally 1)  Memory Usage: ...\n</code></pre>\n<p><strong>这是什么意思？</strong></p>\n<p>PostgreSQL 的优化器在开始执行前，只是<strong>估算</strong>需要多少 Buckets 和 Batches。</p>\n<ul>\n<li>如果执行过程中发现：“哎呀，估算少了，内存快爆了！”</li>\n<li>它会<strong>动态增加 Batches</strong>（Doubling strategy，通常翻倍）。</li>\n<li>它会将当前哈希表里的数据“分裂”，把一半的数据赶出内存（写到磁盘的新 Batch 里），从而腾出空间。</li>\n</ul>\n<p><strong>这说明：</strong> 你的统计信息（Statistics）可能严重过期了，导致优化器低估了行数。</p>\n<p><strong>对策：</strong> 运行 <code>ANALYZE table_name;</code>。</p>\n<h2 id=\"总结-3\">总结</h2>\n<table>\n<thead>\n<tr>\n<th><strong>参数</strong></th>\n<th><strong>含义</strong></th>\n<th><strong>理想值</strong></th>\n<th><strong>异常值</strong></th>\n<th><strong>影响</strong></th>\n<th><strong>解决方案</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Buckets</strong></td>\n<td>哈希表槽位数</td>\n<td>2^N (如 1024)</td>\n<td>无特定异常</td>\n<td>影响 CPU (哈希冲突)</td>\n<td>通常无需手动干预</td>\n</tr>\n<tr>\n<td><strong>Batches</strong></td>\n<td>分批处理数</td>\n<td><strong>1</strong></td>\n<td><strong>&gt; 1</strong></td>\n<td><strong>严重影响 IO</strong> (写磁盘)</td>\n<td><strong>调大 <code>work_mem</code></strong></td>\n</tr>\n</tbody>\n</table>\n<p>看到 <code>Batches &gt; 1</code>，就是看到数据库在向你求救：“给我点内存吧！”</p>\n<h1 id=\"hash-join-hash-冲突\">Hash Join Hash 冲突</h1>\n<p>在数据库的 Hash Join 中，<strong>Hash 冲突（Hash Collision）</strong> 是不可避免的物理现象。</p>\n<p>简单回顾一下定义：<strong>不同的 Join Key（比如 ID=10 和 ID=100），经过哈希函数计算后，得到了完全相同的哈希值（比如都等于 5），于是它们都要挤进同一个 Bucket（桶）里。</strong></p>\n<p>数据库（以 PostgreSQL 为例）解决这个问题的标准方案是：<strong>拉链法（Separate Chaining）</strong> + <strong>值比较（Recheck）</strong>。</p>\n<h2 id=\"1-核心机制拉链法-separate-chaining\">1. 核心机制：拉链法 (Separate Chaining)</h2>\n<p>想象一下，Hash Table 是一个巨大的<strong>“快递柜”</strong>，每个格子就是一个 <strong>Bucket</strong>。</p>\n<p>如果两个包裹（数据行）的取件码（Hash 值）算出来都是“5号柜”，怎么办？</p>\n<p>数据库不会把后来的包裹扔掉，也不会覆盖前面的，而是<strong>在 5 号柜后面挂一条长长的链子（Linked List）</strong>。</p>\n<ul>\n<li><strong>Bucket 的结构：</strong> 它不再是一个只能存一行数据的“死格子”，而是一个<strong>链表头指针</strong>。</li>\n<li><strong>冲突处理：</strong>\n<ul>\n<li>第一个冲突的行，挂在 Bucket 后面。</li>\n<li>第二个冲突的行，挂在第一个行后面。</li>\n<li>以此类推……</li>\n</ul>\n</li>\n</ul>\n<pre><code>Bucket 0: [ NULL ]\nBucket 1: [ Row A (id=10) ] -&gt; [ Row B (id=100) ] -&gt; [ Row C (id=999) ] -&gt; NULL\nBucket 2: [ Row D (id=5) ] -&gt; NULL\n...\n</code></pre>\n<p>在上面的例子中，Row A、Row B、Row C 的 ID 不同，但哈希值都撞到了 Bucket 1。这就是哈希冲突。</p>\n<hr />\n<h2 id=\"2-探测阶段必须进行验身-recheck\">2. 探测阶段：必须进行“验身” (Recheck)</h2>\n<p>解决了“存”的问题，关键在于“取”（Probe 阶段）。</p>\n<p>当外表（Outer Table）的一行数据来匹配时，数据库如何区分链表里的 A、B、C 谁才是真正的“亲人”？</p>\n<p><strong>步骤如下：</strong></p>\n<ol>\n<li><strong>算哈希：</strong> 拿外表数据的 Join Key（比如 ID=100），算出哈希值 -&gt; <code>Bucket 1</code>。</li>\n<li><strong>找桶：</strong> CPU 定位到内存中的 Bucket 1。</li>\n<li><strong>遍历链表（关键步骤）：</strong>\n<ul>\n<li><strong>看第一个节点 (Row A)：</strong> 它的哈希值匹配，但数据库<strong>不敢确信</strong>。必须拿出原始值比对：<code>Outer.ID (100) == Inner.ID (10)</code> 吗？<strong>不相等</strong>。跳过。</li>\n<li><strong>看第二个节点 (Row B)：</strong> 拿出原始值比对：<code>Outer.ID (100) == Inner.ID (100)</code> 吗？<strong>相等！</strong> 匹配成功，返回结果。</li>\n<li><strong>看第三个节点 (Row C)：</strong> ...</li>\n</ul>\n</li>\n</ol>\n<p><strong>结论：</strong> Hash Join 在匹配时，<strong>不仅仅比较哈希值，还必须在内存中比较原始的 Join Key</strong>。</p>\n<hr />\n<h2 id=\"3-性能影响冲突是-cpu-杀手\">3. 性能影响：冲突是 CPU 杀手</h2>\n<p>理解了上述过程，你就明白了为什么哈希冲突是性能的敌人：</p>\n<ul>\n<li><strong>理想情况 (无冲突)：</strong> Bucket 里只有 1 个节点。\n<ul>\n<li>复杂度：<strong>O(1)</strong>。算一次哈希，比对一次，搞定。</li>\n</ul>\n</li>\n<li><strong>糟糕情况 (严重冲突)：</strong> Bucket 后面挂了 1000 个节点。\n<ul>\n<li>复杂度：<strong>O(N)</strong>。算一次哈希，然后要进行 1000 次 CPU 比较操作（遍历链表）。</li>\n<li><strong>后果：</strong> 这实际上把高效的 Hash Join 退化成了低效的 <strong>Nested Loop</strong>（在桶内部做循环）。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"4-极端案例数据倾斜-data-skew\">4. 极端案例：数据倾斜 (Data Skew)</h2>\n<p>有时候，哈希冲突不是因为运气不好，而是因为<strong>数据本身的问题</strong>。</p>\n<p><strong>场景：</strong></p>\n<p>你连接的字段是 <code>status</code>（状态），且 99% 的数据都是 <code>'Success'</code>，只有 1% 是 <code>'Failed'</code>。</p>\n<ul>\n<li>Hash('Success') = Bucket 5</li>\n<li>Hash('Failed') = Bucket 8</li>\n</ul>\n<p><strong>结果：</strong></p>\n<ul>\n<li>Bucket 5 后面挂了一个<strong>长达几百万行</strong>的链表（因为 99% 的数据都一样）。</li>\n<li>Bucket 8 只有寥寥几行。</li>\n<li>其他 Bucket 全是空的。</li>\n</ul>\n<p><strong>这是 Hash Join 的噩梦。</strong> 在这种情况下，Hash Join 的性能会急剧下降，甚至比 Nested Loop 还要慢（因为还多了解析哈希和维护链表的开销）。</p>\n<p><strong>PostgreSQL 的对策：</strong></p>\n<p>PostgreSQL 的优化器（Planner）通常会利用<strong>高频值统计（MCV - Most Common Values）</strong>。如果它发现 Join Key 分布极度不均匀（倾斜严重），它可能会：</p>\n<ol>\n<li><strong>放弃 Hash Join</strong>，改用 Merge Join 或 Nested Loop。</li>\n<li>或者在 Hash Join 之前，对高频值做特殊处理（但这比较复杂）。</li>\n</ol>\n<hr />\n<h2 id=\"5-怎么避免冲突数据库在做什么\">5. 怎么避免冲突？(数据库在做什么)</h2>\n<p>虽然我们改变不了数据，但数据库内核在努力减少“意外冲突”：</p>\n<ol>\n<li><strong>优秀的哈希算法：</strong> PostgreSQL 使用 <code>Jenkins Hash</code> 或 <code>MurmurHash</code> 等算法，确保哈希值像“撒胡椒面”一样均匀分布，避免不同的值算出一样的哈希。</li>\n<li><strong>动态扩容 (Resizing)：</strong> 如果发现数据量比预期的多，导致 Bucket 不够用了（比如每个桶都挂了 5 个节点），数据库可能会重新申请更大的内存，把 Bucket 数量翻倍（比如从 1024 扩到 2048），然后把数据重新撒一遍（Rehash）。\n<ul>\n<li><em>注：PostgreSQL 的 Hash Join 更多是通过 Batches（分批）来解决内存不足，通过预估足够大的 Buckets 来解决冲突。</em></li>\n</ul>\n</li>\n</ol>\n<h2 id=\"总结-4\">总结</h2>\n<p>Hash Join 遇到冲突时：</p>\n<ol>\n<li><strong>存：</strong> 用<strong>链表</strong>把冲突的数据串起来。</li>\n<li><strong>取：</strong> 遍历链表，逐个进行<strong>原始值比较 (Recheck)</strong>。</li>\n<li><strong>代价：</strong> 冲突越多，链表越长，CPU 遍历越慢，性能越差。</li>\n</ol>\n<h1 id=\"parallel和partial\">Parallel和Partial</h1>\n<p><strong>\"Parallel\"</strong>（并行）和 <strong>\"Partial\"</strong>（部分）经常成对出现，但它们描述的是完全不同的两个维度：</p>\n<ul>\n<li><strong>Parallel (并行):</strong> 描述的是<strong>“动作的方式”</strong> —— <strong>大家一起干</strong>。</li>\n<li><strong>Partial (部分):</strong> 描述的是<strong>“结果的状态”</strong> —— <strong>干了一半，还没完</strong>。</li>\n</ul>\n<h2 id=\"1-parallel动作怎么干\">1. \"Parallel\"：动作（怎么干？）</h2>\n<p>当你在执行计划中看到 <strong>Parallel</strong>（如 <code>Parallel Seq Scan</code>），它意味着<strong>“分身术”</strong>。</p>\n<ul>\n<li><strong>含义：</strong> 数据库启动了多个工人（Worker Processes），大家<strong>同时</strong>去干这一件事。</li>\n<li><strong>场景：</strong>\n<ul>\n<li><strong>Parallel Seq Scan:</strong> 3 个工人，每人负责扫 1/3 的表。</li>\n<li><strong>Parallel Hash Join:</strong> 3 个工人，每人负责连接 1/3 的数据。</li>\n</ul>\n</li>\n<li><strong>关键点：</strong> 它的反义词是 \"Serial\"（串行，单线程）。</li>\n</ul>\n<h2 id=\"2-partial结果干成啥样了\">2. \"Partial\"：结果（干成啥样了？）</h2>\n<p>当你在执行计划中看到 <strong>Partial</strong>（如 <code>Partial Aggregate</code>），它意味着<strong>“半成品”</strong>。</p>\n<ul>\n<li><strong>含义：</strong> 因为数据是大家分开处理的，所以每个人算出来的结果<strong>只是局部的</strong>，不是最终答案。</li>\n<li><strong>场景：</strong>\n<ul>\n<li><strong>Partial Aggregate:</strong> 工人 A 算出他那部分有 100 票，工人 B 算出他那部分有 200 票。</li>\n<li><strong>注意：</strong> 这时候谁都不知道总票数是多少。</li>\n</ul>\n</li>\n<li><strong>关键点：</strong> 它的反义词是 \"Finalize\"（最终汇总）。</li>\n</ul>\n<hr />\n<h2 id=\"3-为什么有时候有-partial有时候没有\">3. 为什么有时候有 Partial，有时候没有？</h2>\n<p>这取决于你的 SQL <strong>是否需要“聚合”（Aggregation）</strong>。</p>\n<h4 id=\"情况-a有-parallel也有-partial-聚合查询\">情况 A：有 Parallel，也有 Partial (聚合查询)</h4>\n<p><strong>SQL:</strong> <code>SELECT count(*) FROM big_table;</code></p>\n<p>你想要一个<strong>汇总的数字</strong>。</p>\n<ol>\n<li><strong>Parallel Seq Scan:</strong> 大家分头去数票（动作是并行的）。</li>\n<li><strong>Partial Aggregate:</strong> 每个人先把手里的票数加一加，记在小本本上（结果是局部的）。\n<ul>\n<li><em>如果不做这一步，每个人都要把几百万张选票扔给领导，领导会被砸死。</em></li>\n</ul>\n</li>\n<li><strong>Gather:</strong> 领导把小本本收上来。</li>\n<li><strong>Finalize Aggregate:</strong> 领导把小本本上的数字加在一起（最终结果）。</li>\n</ol>\n<p><strong>执行计划长这样：</strong></p>\n<pre><code class=\"language-sql\">Finalize Aggregate          &lt;-- 4. 算出总账\n  -&gt; Gather                 &lt;-- 3. 收小本本\n       -&gt; Partial Aggregate &lt;-- 2. 记小本本 (Partial出现了！)\n            -&gt; Parallel Seq Scan &lt;-- 1. 分头数票 (Parallel出现了！)\n</code></pre>\n<h4 id=\"情况-b有-parallel但没有-partial-明细查询\">情况 B：有 Parallel，但没有 Partial (明细查询)</h4>\n<p><strong>SQL:</strong> <code>SELECT * FROM big_table WHERE id &gt; 1000;</code></p>\n<p>你只想要<strong>原始数据</strong>，不需要汇总。</p>\n<ol>\n<li><strong>Parallel Seq Scan:</strong> 大家分头去找 <code>id &gt; 1000</code> 的行。</li>\n<li><strong>Gather:</strong> 找到一行，就直接扔给领导。</li>\n<li><strong>Result:</strong> 领导直接发给用户。</li>\n</ol>\n<p><strong>执行计划长这样：</strong></p>\n<pre><code class=\"language-sql\">Gather                      &lt;-- 2. 收原始票据\n  -&gt; Parallel Seq Scan      &lt;-- 1. 分头找票 (只有Parallel，没有Partial)\n</code></pre>\n<p><strong>为什么这里没有 Partial？</strong></p>\n<p>因为不需要计算 <code>SUM</code> 或 <code>COUNT</code>，不需要“中间状态”。工人找到的就是最终需要的行。</p>\n<hr />\n<h2 id=\"4-深度对比表\">4. 深度对比表</h2>\n<table>\n<thead>\n<tr>\n<th><strong>关键词</strong></th>\n<th><strong>词性</strong></th>\n<th><strong>潜台词</strong></th>\n<th><strong>典型算子</strong></th>\n<th><strong>出现位置</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Parallel</strong></td>\n<td><strong>副词</strong> (Adverb)</td>\n<td>\"我不孤单，有兄弟帮我一起做\"</td>\n<td><code>Parallel Seq Scan</code> <code>Parallel Index Scan</code> <code>Parallel Hash Join</code></td>\n<td>树的<strong>底层</strong> (干苦力的地方)</td>\n</tr>\n<tr>\n<td><strong>Partial</strong></td>\n<td><strong>形容词</strong> (Adjective)</td>\n<td>\"这不是最终答案，还要再加工\"</td>\n<td><code>Partial Aggregate</code> <code>Partial HashAggregate</code></td>\n<td>夹在 Parallel 和 Gather <strong>中间</strong> (为了压缩数据)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"总结-5\">总结</h2>\n<ul>\n<li>看到 <strong>Parallel</strong>，说明<strong>“为了快，人多力量大”</strong>。</li>\n<li>看到 <strong>Partial</strong>，说明<strong>“为了省，先在本地算个小账”</strong>。</li>\n</ul>\n<p><strong>Partial 是 Parallel 在做聚合运算时的“必经之路”。</strong> 如果你只是简单地搬运数据（SELECT *），就不需要 Partial 这个步骤。</p>\n<h1 id=\"数据库缓存和操作系统缓存的关系\">数据库缓存和操作系统缓存的关系</h1>\n<p>简单来说，它们是<strong>两层防御体系</strong>，既有合作，也有竞争。</p>\n<p>我们可以用一个<strong>“图书馆复习”</strong>的例子来打比方：</p>\n<ul>\n<li><strong>硬盘 (Disk):</strong> 图书馆的<strong>闭架书库</strong>。书很多，但取书非常慢（毫秒级）。</li>\n<li><strong>操作系统缓存 (OS Page Cache):</strong> 图书馆的<strong>还书手推车</strong>。\n<ul>\n<li>虽然书还没归架，但就在手边，拿起来很快。</li>\n<li>这里书很杂，什么都有，而且管理员（OS）会定期把车清空。</li>\n</ul>\n</li>\n<li><strong>数据库缓存 (DB Buffer Pool):</strong> 你自己的<strong>书桌</strong>。\n<ul>\n<li>这是你精心挑选的、马上要用的书。</li>\n<li>你知道哪一页最重要，你会一直把它们摊开放在桌上。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"1-核心架构数据的流动路径\">1. 核心架构：数据的流动路径</h2>\n<p>当数据库想要读取一行数据时，并不是直接从硬盘变到数据库里的。这中间经过了层层关卡。</p>\n<p><strong>读取路径 (Read Path):</strong></p>\n<ol>\n<li><strong>App 请求数据:</strong> SQL 发给数据库。</li>\n<li><strong>DB Cache (Shared Buffers):</strong> 数据库先查自己的内存（书桌）。\n<ul>\n<li><em>Hit:</em> 直接返回。速度最快（纳秒级）。</li>\n<li><em>Miss:</em> 需要去读文件。</li>\n</ul>\n</li>\n<li><strong>System Call (read):</strong> 数据库发起系统调用，请求操作系统读文件。</li>\n<li><strong>OS Cache (Page Cache):</strong> 操作系统查自己的内存（手推车）。\n<ul>\n<li><em>Hit:</em> 操作系统发现这页数据刚好在内存里（可能是刚才有人读过，或者刚写进去还没落盘）。直接拷贝给数据库。</li>\n<li><em>Miss:</em> 操作系统真的去读硬盘。</li>\n</ul>\n</li>\n<li><strong>Disk I/O:</strong> 硬盘旋转，磁头寻道，把数据读入 OS Cache。</li>\n<li><strong>Copy:</strong> 操作系统把数据从 <strong>OS Cache</strong> 复制到 <strong>DB Cache</strong>。</li>\n</ol>\n<p><strong>关键点：</strong> 如果数据在 DB Cache 没命中，但在 OS Cache 命中，虽然比直接读内存慢一点（因为有系统调用和内存拷贝的开销），但比读硬盘快 1000 倍。</p>\n<hr />\n<h2 id=\"2-双重缓存-double-buffering-现象\">2. “双重缓存” (Double Buffering) 现象</h2>\n<p>仔细看上面的第 6 步，你会发现一个尴尬的现象：</p>\n<p><strong>同一份数据，在内存里存了两份！</strong></p>\n<ul>\n<li>一份在 OS Page Cache 里。</li>\n<li>一份在 DB Buffer Pool 里。</li>\n</ul>\n<p>这就叫 <strong>Double Buffering</strong>。</p>\n<h4 id=\"这种冗余是好是坏\">这种冗余是好是坏？</h4>\n<ul>\n<li><strong>坏处：</strong> 浪费内存。如果你的服务器有 64GB 内存，结果 30GB 存的是重复数据，那是极大的浪费。</li>\n<li><strong>好处：</strong> 互补。\n<ul>\n<li>DB Cache 满了要淘汰数据时，被淘汰的数据只是从“书桌”移回了“手推车”（OS Cache）。</li>\n<li>下次如果又突然需要这页数据，虽然书桌上没有，但手推车里有，还是很快。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"3-postgresql-的策略依赖与合作\">3. PostgreSQL 的策略：依赖与合作</h2>\n<p>PostgreSQL 在这方面非常特别。它<strong>默认不使用 Direct I/O</strong>（即不绕过 OS Cache），而是选择利用它。</p>\n<ul>\n<li><strong>配置策略：</strong>\n<ul>\n<li>这就是为什么 PostgreSQL 官方建议 <code>shared_buffers</code>（DB Cache）只设置为总内存的 <strong>25% - 40%</strong>。</li>\n<li><strong>剩下的内存去哪了？</strong> 留给操作系统！PostgreSQL 指望操作系统用剩下的内存做 Page Cache，来做它的“二级缓存”。</li>\n</ul>\n</li>\n<li><strong>优点：</strong> 代码简单，利用了操作系统成熟的预读（Prefetching）算法。</li>\n<li><strong>缺点：</strong> 存在双重缓存带来的内存浪费和 CPU 拷贝开销。</li>\n</ul>\n<hr />\n<h2 id=\"4-其他数据库的策略direct-io-绕过\">4. 其他数据库的策略：Direct I/O (绕过)</h2>\n<p>很多其他数据库（如 Oracle, MySQL InnoDB）倾向于一种更霸道的做法：<strong>O_DIRECT</strong>。</p>\n<ul>\n<li><strong>Direct I/O:</strong> 数据库告诉操作系统：“我要读写文件，但你别管闲事，别给我做缓存，直接把硬盘数据读到我的内存里。”</li>\n<li><strong>效果：</strong>\n<ul>\n<li><strong>消除了双重缓存：</strong> 数据只存在于 DB Buffer Pool 中。</li>\n<li><strong>内存利用率高：</strong> 数据库可以把 80% 甚至 90% 的物理内存都据为己有。</li>\n</ul>\n</li>\n<li><strong>代价：</strong> 数据库必须自己实现极其复杂的缓存管理、预读算法和刷盘策略。因为一旦离开了 OS 的保护，自己必须全权负责。</li>\n</ul>\n<hr />\n<h2 id=\"5-写入与刷盘-write--fsync\">5. 写入与刷盘 (Write &amp; Fsync)</h2>\n<p>在写入数据时，两者的关系更加微妙，关乎<strong>数据安全</strong>。</p>\n<ol>\n<li><strong>DB Write:</strong> 数据库修改了 Buffer Pool 里的数据（变成了脏页 Dirty Page）。此时数据还在用户空间内存。</li>\n<li><strong>OS Write:</strong> 数据库调用 <code>write()</code>。操作系统把数据从 DB Cache 拷贝到 OS Cache。<strong>注意：此时数据还没到硬盘！</strong> 如果这时候拔电源，数据就丢了。</li>\n<li><strong>Fsync (刷盘):</strong> 为了保证 ACID 中的 D（持久性），数据库必须显式调用 <code>fsync()</code>。\n<ul>\n<li>这就像是对操作系统大喊：“别只放在手推车里，现在、立刻、马上把它放回闭架书库（硬盘）去！”</li>\n<li>只有 <code>fsync</code> 返回成功，数据库才敢告诉用户“事务提交成功”。</li>\n</ul>\n</li>\n</ol>\n<p><strong>WAL (预写日志) 的角色：</strong></p>\n<p>因为 <code>fsync</code> 随机写数据文件太慢了，数据库会先顺序写 WAL 日志，并频繁 <code>fsync</code> WAL 文件。至于真正的数据页（Data Page），可以在 OS Cache 里多待一会儿，由操作系统的 pdflush 线程或者数据库的 Checkpointer 慢慢刷盘。</p>\n<h2 id=\"总结谁更聪明\">总结：谁更聪明？</h2>\n<table>\n<thead>\n<tr>\n<th><strong>特性</strong></th>\n<th><strong>OS Cache (傻快)</strong></th>\n<th><strong>DB Cache (精明)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>置换算法</strong></td>\n<td>LRU (最近最少使用) 的通用变种。比较简单粗暴。</td>\n<td><strong>Clock-Sweep / ARC</strong>。数据库知道哪是索引，哪是全表扫描。它会保护索引页，快速淘汰全表扫描的页。</td>\n</tr>\n<tr>\n<td><strong>预读能力</strong></td>\n<td>基于文件偏移量的简单预读（往下读 128KB）。</td>\n<td>理解 B+ 树结构，知道下一个叶子节点在磁盘的什么位置，预读更精准。</td>\n</tr>\n<tr>\n<td><strong>内存控制</strong></td>\n<td>动态抢占，应用内存不够时会压缩 Cache。</td>\n<td>大小固定（通常启动时分配）。</td>\n</tr>\n<tr>\n<td><strong>适用场景</strong></td>\n<td>文件服务器、通用计算。</td>\n<td>复杂的查询处理。</td>\n</tr>\n</tbody>\n</table>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>未经作者同意请勿转载</p>\n<p>本文来自博客园作者：<a href=\"https://www.cnblogs.com/aslanvon/\" target=\"_blank\">aixueforever</a>，原文链接：<a href=\"https://www.cnblogs.com/aslanvon/p/19608578\" target=\"_blank\">https://www.cnblogs.com/aslanvon/p/19608578</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 15:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/aslanvon\">aixueforever</a>&nbsp;\n阅读(<span id=\"post_view_count\">60</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "韩国国民搜索 NAVER：使用 JuiceFS 打通 Hadoop 与 Kubernetes 存储实践",
      "link": "https://www.cnblogs.com/JuiceData/p/19607717",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/JuiceData/p/19607717\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:45\">\n    <span>韩国国民搜索 NAVER：使用 JuiceFS 打通 Hadoop 与 Kubernetes 存储实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>NAVER 是韩国领先的互联网科技公司，运营着韩国最大的搜索引擎，并在人工智能、自动驾驶等高科技领域积极布局。作者 Nam Kyung-wan 来自 NAVER Infra 团队，自 2023 年参与 JuiceFS 社区代码贡献 (GitHub: <a href=\"https://github.com/kyungwan-nam\" rel=\"noopener nofollow\" target=\"_blank\">kyungwan-nam</a>)，为 Hadoop 场景提出了多项改进。本文是作者继“ <a href=\"https://juicefs.com/zh-cn/blog/user-stories/naver-storage-solution-juicefs-ai-platforms\" rel=\"noopener nofollow\" target=\"_blank\">为 AI 平台引入存储方案 JuiceFS</a>”后的第二篇博客。</p>\n<p>NAVER Infra 团队负责运营公共 Hadoop 集群，使用 Spark、Hive、MapReduce 等 Hadoop 应用处理数据，并将数据存储在 HDFS 中。HDFS 在 Hadoop 生态系统中通过数据本地性支持高性能，具备优异的容错性和可扩展性。</p>\n<p><strong>随着人工智能服务的普及，数据规模急剧增长，对多样化数据存储的需求也日益增加。同时，如何高效地共享 Hadoop 集群外部 AI 平台（如 Kubernetes）中的数据，成为了一项重要挑战。在这一背景下，NAVER 探讨了对象存储是否可以替代 HDFS，并明确了 JuiceFS 结合对象存储的适用场景</strong>。</p>\n<h2 id=\"01-hdfs-的局限\">01 HDFS 的局限</h2>\n<p><strong>存储成本上升</strong></p>\n<p>AI 开发需要以高效且经济的方式存储不断增长的数据，并在某些情况下长期保留原始数据，以便进行模型改进和重新训练。</p>\n<p>然而，Hadoop 的计算和存储是紧密耦合的，导致存储扩展难以独立进行。当没有计算需求时，仅为扩展存储空间而增加节点会造成不必要的成本。此外，HDFS 默认保留三重副本，进一步增加了存储成本。</p>\n<p><strong>文件数量限制</strong></p>\n<p>AI 开发涉及数千万个小文件，如图像、音频和文本等。HDFS 存在著名的<a href=\"https://www.cloudera.com/blog/technical/the-small-files-problem.html\" rel=\"noopener nofollow\" target=\"_blank\">小文件问题</a>，因为所有文件和块的元数据都存储在 NameNode 的内存中。例如，管理 1000 万个文件大约需要 3GB 的内存。因此，HDFS 可管理的文件数量受到单个 NameNode 内存容量的限制。</p>\n<p><strong>数据中心容灾能力弱</strong></p>\n<p>HDFS 通常由单个数据中心的节点组成。为应对数据中心故障或灾难，需使用额外方案将数据复制到其他数据中心，从而产生增加成本。</p>\n<p><strong>运营成本增加</strong></p>\n<p>NAVER 由专业人员运营公共 Hadoop 集群，负担相对较小，但通常 Hadoop 集群的构建和运营非常复杂且成本高昂。若要单独构建和运营稳定的 Hadoop 环境，需要专业知识和较高的维护成本。</p>\n<p><strong>Kubernetes 中的生态兼容性差</strong></p>\n<p>NAVER AI 平台基于 Kubernetes 构建，并利用 Kubeflow、KServe 等多种 AI 开源工具及 GPU 支持。但 HDFS 不支持 POSIX API 和 CSI 驱动，无法作为 Kubernetes 常规存储方式（即 PersistentVolume）使用。因此，在 Kubernetes 中使用 HDFS 需在容器中准备 Hadoop 包、配置和认证信息，并编写 HDFS API 代码，非常繁琐且会降低 AI 开发效率。</p>\n<h2 id=\"02-对象存储的优势与劣势\">02 对象存储的优势与劣势</h2>\n<p>Hadoop 通过数据本地性提供高性能，但由于 HDFS 与计算节点耦合，计算和存储资源难以独立扩展。因此，扩展存储空间时，仍需增加额外的计算节点。</p>\n<p>相比之下，云环境支持计算和存储的独立扩展。通常，数据存储在对象存储中而非 HDFS，计算可以通过托管服务（如 AWS EMR、Google Dataproc）或基于 Kubernetes 的数据处理引擎进行，数据则存储在 S3、GCS 等对象存储中。这种架构支持灵活扩展计算和存储资源。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>此外，Hadoop 社区和云供应商提供了 <a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aws/tools/hadoop-aws/index.html\" rel=\"noopener nofollow\" target=\"_blank\">S3A</a>、<a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-azure/index.html\" rel=\"noopener nofollow\" target=\"_blank\">Azure Blob</a>、<a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aliyun/tools/hadoop-aliyun/index.html\" rel=\"noopener nofollow\" target=\"_blank\">Aliyun OSS</a> 等 HDFS 兼容文件系统，使得对象存储可以像 HDFS 一样使用。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>对象存储作为远程存储，虽然难以实现数据本地性，但具有以下优势：</p>\n<ol>\n<li><strong>存储成本降低</strong>：计算和存储分离，可独立扩展。对象存储通常成本较低，并能根据需要选择不同的存储类别。例如，对于访问频率低但需长期保留的数据，可使用低成本存储类别（如 S3 Glacier）。</li>\n<li><strong>出色的扩展性和弹性</strong>：对象存储设计上支持近乎无限的扩展。对象数量和容量无限制，可根据工作负载变化轻松扩展或缩减。</li>\n<li><strong>数据中心灾难恢复支持</strong>：S3 等对象存储提供跨区域复制功能，可防止数据中心故障或灾难导致的数据丢失。</li>\n<li><strong>运营成本降低</strong>：避免 Hadoop 集群的构建和运营负担，从而降低运营成本。</li>\n</ol>\n<p>但对象存储替代 HDFS 是好的选择吗？</p>\n<p><strong>不支持目录</strong>：<br />\n在文件系统中，文件通过目录进行组织，列出目录下的文件是一项基本操作，通常速度较快。<br />\n而对象存储没有目录的概念，所有对象是独立的扁平结构。列出文件时需要通过对象前缀搜索，速度较慢。此外，为模拟目录结构而临时创建的 Directory Marker 对象也会影响性能。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p><strong>不支持重命名</strong>：<br />\n在文件系统中，重命名是基本操作，以 O(1) 级别的原子事务快速执行。但对象存储不支持重命名，需通过复制全部数据再删除原数据的方式处理，导致速度非常慢且可能中途失败。</p>\n<p>这一问题对于 MapReduce 和 Spark 等大数据框架影响尤为明显(<a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aws/tools/hadoop-aws/committers.html#Introduction:_The_Commit_Problem\" rel=\"noopener nofollow\" target=\"_blank\">Apache Hadoop Amazon Web Services support – Committing work to S3 with the S3A Committers</a>)。文件输出操作通常依赖重命名来保证一致性，FileOutputFormatCommitter 就是基于重命名实现的。因此，在对象存储中直接使用 FileOutputFormatCommitter 会显著降低性能。</p>\n<p>为了解决这一问题，可以使用 <a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-aws/tools/hadoop-aws/committers.html#The_Magic_Committer\" rel=\"noopener nofollow\" target=\"_blank\">Magic Committer</a>，它避免了重命名操作，并针对对象存储进行了优化。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ol start=\"3\">\n<li>\n<p><strong>不支持文件权限</strong>：<br />\nHDFS 支持 POSIX 权限体系，可以设置文件和目录的所有者、组以及其他用户的权限。而对象存储不提供此功能，因此文件的所有者和组通常被视为当前用户，所有文件和目录的权限默认为 666 和 777（即文件可读写，目录可读写并可执行）(参考: <a href=\"https://hadoop.apache.org/docs/r3.4.1/hadoop-project-dist/hadoop-common/filesystem/introduction.html#Object_Stores_vs._Filesystems\" rel=\"noopener nofollow\" target=\"_blank\">Object Stores vs. Filesystems</a>).。</p>\n</li>\n<li>\n<p><strong>数据访问速度慢</strong>：<br />\n对象存储作为远程存储，无法保证数据本地性，并且每次访问都涉及网络传输，因此相较于 HDFS，其数据访问速度较慢，性能受到网络延迟和带宽限制的影响。</p>\n</li>\n<li>\n<p><strong>Kubernetes 中的低可用性</strong>：<br />\n一些工具，如 Mountpoint for Amazon S3 和 s3fs，支持通过 POSIX API 将对象存储挂载为类似本地文件系统的方式。AWS S3 还通过 Mountpoint for Amazon S3 CSI 驱动 支持将对象存储作为 Kubernetes 卷使用。</p>\n</li>\n</ol>\n<p>然而，由于对象存储与传统文件系统存在根本差异，它无法完全兼容 POSIX API，且性能较低。因此，在使用这些工具时，需要充分了解它们的工作原理和局限性。最终，即使在 Kubernetes 环境中使用对象存储，低可用性问题仍然无法解决。</p>\n<ol start=\"6\">\n<li><strong>S3 兼容对象存储的 API 兼容性</strong>：<br />\nS3 已成为对象存储的事实标准，被多种应用广泛支持。因此，许多云供应商和开源项目提供 S3 兼容对象存储。然而，S3 兼容对象存储并不完全等同于原生 S3 服务。在使用时，需要确认其是否与 S3AFileSystem 或其他应用所使用的 S3 API 兼容。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>综上，对象存储可以像 HDFS 一样使用，但需要充分理解其局限性。现有 Hadoop 应用难以直接迁移，仍需额外的开发和适配工作。对于直接使用 HDFS API 编写的代码，需要避免重命名操作，并减少文件列表操作，以适应对象存储的特性。为避免现有 Spark 应用性能下降，需考虑使用 Magic Committer，但它并非总是有效，特别是在不支持 Spark 动态分区覆盖的情况下。</p>\n<p>此外，虽然 Spark 和 Hadoop 社区持续改进对象存储相关问题，但更新软件包版本和解决问题仍然面临挑战。使用 S3 兼容的对象存储时，还需验证其与 S3 API 的兼容性。</p>\n<h2 id=\"03-在-hadoop-中使用-juicefs\">03 在 Hadoop 中使用 JuiceFS</h2>\n<p>JuiceFS 是一款分布式文件系统，架构由客户端、元数据引擎和数据存储组成。对象存储仅用于存储数据块，而文件系统所需的元数据则由数据库管理。</p>\n<p><strong>需注意 JuiceFS 是与 HDFS 类似的分布式文件系统。因此，与直接使用对象存储不同，JuiceFS 能完美支持 HDFS API、POSIX API 和 Kubernetes CSI 驱动</strong>。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>为了在速度慢且修改困难的对象存储上实现分布式文件系统，JuiceFS 引入了 chunk、slice 和 block 概念。</p>\n<ul>\n<li>chunk（64MB）：将文件分割为 64MB 单位，支持基于偏移的并行处理。</li>\n<li>slice：chunk 内的修改单位，写入时创建新 slice 并优先使用最新版本。</li>\n<li>block（默认 4MB）：实际存储在对象存储中的最小单位，通过并行处理缩短上传时间。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>此外，从远程对象存储读取数据较慢，JuiceFS 支持多级缓存，以此弥补此性能不足。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>NAVER 内部 AI 平台已使用 JuiceFS。更多关于 JuiceFS 的详细信息及 AI 平台引入过程可参考<a href=\"https://juicefs.com/zh-cn/blog/user-stories/naver-storage-solution-juicefs-ai-platforms\" rel=\"noopener nofollow\" target=\"_blank\">为 AI 平台引入存储方案 JuiceFS</a>。</p>\n<p>JuiceFS 支持 Hadoop SDK，通过配置 JuiceFS 后，用户即可在 Hadoop 环境中使用它。</p>\n<h3 id=\"配置-juicefs\">配置 JuiceFS</h3>\n<p>为使 Hadoop 识别 JuiceFS 文件系统，需在 core-site.xml 文件中添加以下内容。其中 <a href=\"https://juicefs.com/docs/community/hadoop_java_sdk/#core-configurations\" rel=\"noopener nofollow\" target=\"_blank\">fs.jfs.impl、fs.AbstractFileSystem.jfs.impl 和 juicefs.meta</a> 是必需的。</p>\n<pre><code>&lt;!-- Configure JuiceFS to be available via jfs:// --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;fs.jfs.impl&lt;/name&gt;  \n    &lt;value&gt;io.juicefs.JuiceFileSystem&lt;/value&gt;  \n  &lt;/property&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;fs.AbstractFileSystem.jfs.impl&lt;/name&gt;  \n    &lt;value&gt;io.juicefs.JuiceFS&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- juicefs meta url --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.meta&lt;/name&gt;  \n    &lt;value&gt;redis://:password@addr&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- In this example, grant access permissions to all users to avoid permission issues. --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.umask&lt;/name&gt;  \n    &lt;value&gt;000&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Cache up to 100 GiB. --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.cache-size&lt;/name&gt;  \n    &lt;value&gt;102400&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Cache under the temporary path of YARN containers, so the cache is removed when the container terminates.    \nSince it's a shared Hadoop, caching is temporary only during job execution. --&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.cache-dir&lt;/name&gt;  \n    &lt;value&gt;${env.PWD}/tmp&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Prometheus remote write configuration for metrics collection --&gt;    \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.push-remote-write&lt;/name&gt;  \n    &lt;value&gt;http://host:port&lt;/value&gt;  \n  &lt;/property&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.push-remote-write-auth&lt;/name&gt;  \n    &lt;value&gt;username:password&lt;/value&gt;  \n  &lt;/property&gt;  \n&lt;!-- Additionally collect Hadoop user and YARN container ID.    \nFor shared Hadoop to distinguish users and applications. --&gt;  \n  &lt;property&gt;  \n    &lt;name&gt;juicefs.push-labels&lt;/name&gt;  \n    &lt;value&gt;user:${env.USER};container_id:${env.CONTAINER_ID}&lt;/value&gt;  \n  &lt;/property&gt;  \n</code></pre>\n<p>以上为单文件系统的默认配置，但也可根据需要配置多个文件系统同时使用。<br />\n更多配置选项可参考“<a href=\"https://juicefs.com/docs/community/hadoop_java_sdk/#client-configurations\" rel=\"noopener nofollow\" target=\"_blank\">客户端配置</a>”。</p>\n<h3 id=\"hadoop-sdk\">Hadoop SDK</h3>\n<p>Hadoop SDK 的 JAR 文件可以通过下载预编译客户端或自行编译源代码获取。为了简化部署，通常可以在所有 Hadoop 节点的 Hadoop 发行版安装路径中预先安装。然而，在大规模 Hadoop 集群中，这种方法操作繁琐，尤其是对于公共 Hadoop 环境，它会限制所有用户使用特定版本。</p>\n<p>大多数 Hadoop 应用支持将所需 JAR 文件部署并添加到 classpath 中，用户可根据实际需要选择部署方式。以下是 HDFS CLI、MapReduce 和 Spark 中的具体部署方法。</p>\n<h3 id=\"hdfs-cli\">HDFS CLI</h3>\n<p>配置完上述 <code>core-site.xml</code> 文件后，需要在 <code>HADOOP_CLASSPATH</code> 环境变量中设置 Hadoop SDK 文件路径。完成此设置后，您可以使用 <code>hdfs</code> 命令操作 <code>hdfs://</code> 和 <code>jfs://</code> 文件系统。</p>\n<pre><code>$ export HADOOP_CLASSPATH=/home/juicefs/juicefs-hadoop-1.2.3.jar  \n$ hdfs dfs -ls hdfs://home/foo  \nFound 6 items    \n...  \ndrwx------   - foo users          0 2022-10-14 20:55 hdfs://home/foo/.Trash    \ndrwx------   - foo users          0 2022-01-06 10:18 hdfs://home/foo/dfsio    \ndrwx------   - foo users          0 2025-01-22 17:54 hdfs://home/foo/tpcds\n\n$ hdfs dfs -ls jfs://default/  \n2025-08-25 19:15:43,964 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 60 minutes, Emptier interval = 60 minutes.    \nFound 8 items    \n...  \ndrwxrwxrwx   - 10000 hadoop-admins       4096 2025-06-10 18:06 jfs://default/nyc    \ndrwxrwxrwx   - 10000 hadoop-admins       4096 2025-05-15 19:42 jfs://default/subdir    \n</code></pre>\n<h3 id=\"mapreduce\">MapReduce</h3>\n<p>MapReduce 在 Hadoop 的多个节点上并行运行，因此所有分配任务的节点都需要部署 JAR 文件。推荐的方法是通过分布式缓存进行部署。使用此方法时，任务执行时会自动将 <code>mapreduce.application.framework.path</code> 中设置的 MapReduce 框架部署到任务节点。</p>\n<p>以下是 <code>mapred-site.xml</code> 文件的示例配置：</p>\n<ul>\n<li><code>mapreduce.application.framework.path</code>：指定包含 Hadoop SDK 的 MapReduce 框架的 HDFS 路径。</li>\n<li><code>mapreduce.application.classpath</code>：配置为包含 Hadoop SDK 的路径。</li>\n</ul>\n<pre><code>&lt;property&gt;  \n   &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;  \n   &lt;value&gt;$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*&lt;/value&gt;  \n &lt;/property&gt;  \n &lt;property&gt;  \n   &lt;name&gt;mapreduce.application.framework.path&lt;/name&gt;  \n   &lt;value&gt;hdfs://mapred/framework/hadoop-mapreduce-3.1.2-juicefs-1.2.3.tar.gz#mrframework&lt;/value&gt;  \n &lt;/property&gt;  \n</code></pre>\n<h3 id=\"spark\">Spark</h3>\n<p>Spark 的基本配置文件是 <code>spark-defaults.conf</code>。在该文件中，可以替代 <code>core-site.xml</code> 进行如下设置：</p>\n<ul>\n<li>任意 Hadoop 设置可以通过 <code>spark.hadoop.key=value</code> 形式添加。</li>\n<li><code>spark.jars</code>：指定要部署到 Spark driver 和 executor，并包含在 classpath 中的 JAR 文件。</li>\n</ul>\n<pre><code>spark.hadoop.fs.jfs.impl io.juicefs.JuiceFileSystem    \nspark.hadoop.fs.AbstractFileSystem.jfs.impl io.juicefs.JuiceFS    \nspark.hadoop.juicefs.meta redis://:password@addr    \nspark.hadoop.juicefs.umask 000    \nspark.hadoop.juicefs.push-remote-write http://host:port    \nspark.hadoop.juicefs.push-remote-write-auth username:password    \nspark.hadoop.juicefs.push-labels user:${env.USER};container_id:${env.CONTAINER_ID}    \nspark.hadoop.juicefs.cache-size 102400    \nspark.hadoop.juicefs.cache-dir ${env.PWD}/tmp    \nspark.jars hdfs://juicefs/juicefs-hadoop/juicefs-hadoop-1.2.3.jar  \n</code></pre>\n<h2 id=\"04-juicefs-改进事项\">04 JuiceFS 改进事项</h2>\n<p>JuiceFS 提供多种接口，支持跨平台的数据共享。例如，在 Hadoop 中使用 MapReduce 或 Spark 处理的数据存储到 JuiceFS 后，可以轻松在 Kubernetes 环境中访问和使用这些数据。</p>\n<p>为使 NAVER 公共 Hadoop 和基于 Kubernetes 的 AI 平台顺畅共享数据，需要进行一些改进。（已经全部贡献到社区版。）</p>\n<h3 id=\"支持-all-squash-挂载5394\"><a href=\"https://github.com/juicedata/juicefs/issues/5394\" rel=\"noopener nofollow\" target=\"_blank\">支持 all-squash 挂载</a>（#5394）</h3>\n<p>NAVER 公共 Hadoop 与 LDAP 集成管理用户账户，因此 Hadoop 中创建的数据由相应用户的 LDAP UID 和 GID 所有。然而，在 Kubernetes 中，容器可以使用任意 UID 和 GID 运行，这可能导致访问 Hadoop 创建的数据时产生权限问题。</p>\n<p>为了解决这个问题，我们增加了挂载选项 <code>--all-squash</code>。该选项使得访问挂载路径时，操作不会以当前账户的 UID 和 GID 进行，而是使用指定的 UID:GID。因此，设置 Hadoop 用户的 LDAP UID 和 GID 后，Kubernetes 中的容器可以无权限问题地访问数据。</p>\n<h3 id=\"改进-juicefsusers-和-juicefsgroup-设置方式4723\"><a href=\"https://github.com/juicedata/juicefs/issues/4723\" rel=\"noopener nofollow\" target=\"_blank\">改进 juicefs.users 和 juicefs.group 设置方式</a>（#4723）</h3>\n<p>如前所述，在 Hadoop 集群中执行任务时，数据归 Hadoop 用户的 LDAP UID 和 GID 所有。但在 Hadoop 集群外部使用 Hadoop SDK 时，数据归任意 UID 和 GID 所有。例如，在 Docker 容器中使用 HDFS 命令存储数据时，所有者为容器内部账户的 UID 和 GID。</p>\n<p>为了解决这个问题，用户需要通过 <code>juicefs.users</code> 和 <code>juicefs.groups</code> 设置指定所需的 UID 和 GID。之前，这要求用户编写 <code>&lt;用户名&gt;:&lt;UID&gt;</code> 和 <code>&lt;组名&gt;:&lt;GID&gt;</code> 格式的文件，并设置文件路径，这个过程非常繁琐。现在，我们增加了直接通过配置值来指定 UID 和 GID 的功能，简化了操作。</p>\n<h3 id=\"支持-subdir6096\"><a href=\"https://github.com/juicedata/juicefs/issues/6096\" rel=\"noopener nofollow\" target=\"_blank\">支持 subdir</a>（#6096）</h3>\n<p>在基于 Kubernetes 的 AI 平台中，JuiceFS 以动态供应方式使用。创建 PersistentVolumeClaim（PVC）时，会在 JuiceFS 文件系统内生成与该卷对应的子目录。若要在 Hadoop 中共享该 PVC，需仅安全地共享该卷对应的目录。</p>\n<p>然而，Hadoop SDK 并不提供类似 <code>--subdir</code> 的挂载选项，无法限制 Hadoop 仅访问 JuiceFS 的特定子路径。为了解决这个问题，我们在 Hadoop SDK 中增加了 <code>juicefs.subdir</code> 设置，使用此设置可以限制仅访问指定路径。</p>\n<h3 id=\"通过-hdfs-命令查看配额5937\"><a href=\"https://github.com/juicedata/juicefs/issues/5937\" rel=\"noopener nofollow\" target=\"_blank\">通过 hdfs 命令查看配额</a>（#5937）</h3>\n<p>JuiceFS 可以为整个文件系统或特定目录设置配额。在 Kubernetes 中，PVC 的 <code>spec.resources.requests.storage</code> 值将设置为该目录的配额。</p>\n<p>在 Hadoop 与 PVC 共享时，也需要查看配额信息。然而，原有的 HDFS 命令 <code>hdfs dfs -count -q</code> 无法查看 JuiceFS 的配额。为了解决这个问题，我们对该功能进行了改进，现在可以通过相同的命令查看 JuiceFS 的配额信息。</p>\n<h3 id=\"支持-prometheus-remote_write-协议6295\"><a href=\"https://github.com/juicedata/juicefs/issues/6295\" rel=\"noopener nofollow\" target=\"_blank\">支持 Prometheus remote_write 协议</a>（#6295）</h3>\n<p>使用 JuiceFS Hadoop SDK 时，可以将指标发送到 Pushgateway 和 Graphite。但 Pushgateway 需要定期清理指标，且 Graphite 格式独特，使用起来较为困难。</p>\n<p>许多系统支持 Prometheus <code>remote_write</code> 协议。为了解决这个问题，我们在 JuiceFS 中增加了通过该协议发送指标的功能。通过 <code>juicefs.push-remote-write</code> 和 <code>juicefs.push-remote-write-auth</code> 设置，用户可以指定 VictoriaMetrics  <code>vmagent</code> 或 Prometheus。这一功能不仅整合了跨平台数据，还能整合监控系统。</p>\n<h2 id=\"05-juicefs-的优势\">05 JuiceFS 的优势</h2>\n<h3 id=\"优势-1通过并行处理和缓存克服对象存储的性能瓶颈\">优势 1：通过并行处理和缓存克服对象存储的性能瓶颈</h3>\n<p>JuiceFS 需要通过网络与远程对象存储交换数据块，因此在性能上难以超越具有数据本地性优势的 HDFS。<strong>然而，通过将数据分块并行处理以及缓存已读取数据，可以克服这一性能瓶颈</strong>。我们通过性能测试验证了 HDFS 和 JuiceFS 在不同场景下的表现。</p>\n<h4 id=\"dfsio\">DFSIO</h4>\n<p>使用 10 个 map task，针对 100GB 文件测量 HDFS 和 JuiceFS 的顺序数据写入和读取的吞吐量。数值越高性能越好。为适应顺序写入/读取，将 JuiceFS 的块大小设为 16MB。</p>\n<ul>\n<li>写入：JuiceFS 的吞吐量是 HDFS 的 1.7 倍。这是因为数据被分割成小块并行上传。</li>\n<li>读取：JuiceFS 的吞吐量是 HDFS 的 0.75 倍。但如果数据已缓存，预期性能与 HDFS 相似。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h4 id=\"tpc-ds\">TPC-DS</h4>\n<p>使用 Spark SQL 测量对存储在 HDFS 和 JuiceFS 的 100GB 规模表的查询响应时间。数值越低性能越好。</p>\n<ul>\n<li>JuiceFS 的响应时间是 HDFS 的 1.8 倍，这是由于数据本地性差异所致。</li>\n<li>已缓存的 JuiceFS 表现出与 HDFS 相似的性能。</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"优势-2与-hdfs-完全兼容无需修改现有-hadoop-应用即可使用\">优势 2：与 HDFS 完全兼容，无需修改现有 Hadoop 应用即可使用</h3>\n<p>NAVER 拥有稳定运营的公共 Hadoop 集群，运行着多种服务的 Hadoop 应用。如果仅将不常用的数据存储在对象存储中以降低存储成本，可能会出现问题。正如前所述，对象存储不是文件系统，无法保证现有 Hadoop 应用的性能和运行。为此，需要重写代码或检查数据处理引擎是否支持对象存储。此外，还需根据存储类型单独运行和管理 Hadoop 应用，增加了管理负担。</p>\n<p>与之相反，使用 JuiceFS 可以保持现有 Hadoop 应用不变。用户只需将输入输出路径指定为 <code>hdfs://</code> 或 <code>jfs://</code>，即可以相同方式运行应用。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>HDFS 基于数据本地性保证高性能，而对象存储则在低成本和扩展性方面具有优势。两者各有所长，难以完全替代，需要根据需求选择。使用 JuiceFS 可以在不修改现有 Hadoop 应用的情况下，同时利用 HDFS 和对象存储的优势。</p>\n<h3 id=\"优势-3支持多种接口可作为跨平台集成存储\">优势 3：支持多种接口，可作为跨平台集成存储</h3>\n<p>NAVER 使用多种平台进行服务开发和运营。例如，在开发/运营 AI 服务时，需要在数据处理平台中清洗数据，在 AI 平台中训练模型，并通过容器平台提供服务。</p>\n<p>在 NAVER，各个平台提供独立的存储，平台内部易于使用，但难以访问其他平台的存储。不同平台的存储隔离导致了数据孤岛现象，并容易造成数据重复和资源浪费。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>JuiceFS 不仅支持 HDFS，还完美兼容 POSIX 和 Kubernetes CSI 驱动，适合作为跨平台的集成存储。通过在多个平台间顺畅使用 JuiceFS 共享数据，可大幅提升 AI 服务开发效率，实现数据统一管理。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h2 id=\"06-结语\">06 结语</h2>\n<p>本文探讨了 JuiceFS 在 Hadoop 环境中的使用方法及其优势，而在部分业务场景下，直接采用 HDFS 或对象存储会是更适配的选择。例如，当业务需要依托数据本地性实现高效快速处理时，建议将数据存储于 HDFS 中；此外，针对访问频率较低的数据，或采用 Iceberg 等专为对象存储优化的数据格式时，直接使用对象存储则更为简便。</p>\n<p>而在以下场景中，JuiceFS 会是更优选择：</p>\n<ol>\n<li>需在 Kubernetes 与 Hadoop 环境之间实现数据共享时；</li>\n<li>希望在不修改现有 Hadoop 应用代码的前提下，与 HDFS 并行部署使用时；</li>\n<li>处理存在重复读取行为、可通过缓存显著提升效率的数据作业时；</li>\n<li>业务所用 S3 API 无法被底层 S3 兼容存储良好支持时。</li>\n</ol>\n<p>本文介绍了在 NAVER 内部本地环境中的应用案例，但在 AWS、Google Cloud 等公有云环境中同样适用。希望对有类似困扰的读者有所帮助。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/JuiceData\">JuiceFS</a>&nbsp;\n阅读(<span id=\"post_view_count\">117</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "布谷鸟过滤器原理详解",
      "link": "https://www.cnblogs.com/lxl-233/p/19607712",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lxl-233/p/19607712\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:46\">\n    <span>布谷鸟过滤器原理详解</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div>\n<div><span style=\"font-size: 18px;\"><strong>布谷鸟过滤器 vs 布隆过滤器 核心原理与特性解析</strong></span></div>\n</div>\n<p>与布隆过滤器一样,布谷鸟过滤器也是用来快速判断一个元素是否存在的,但是解决了布隆过滤器\"无法删除\"的痛点</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>一、底层数据结构对比</strong></span></div>\n</div>\n<p>底层数据结构中,布隆过滤器采用的是一维bit数组,每个位只能存储01状态,通过若干hash函数命中多个位来判断元素是否存在,具有存在的误判风险<br />而布谷鸟过滤器采用的是一维桶数组,每个bucket存储元素的\"指纹\"fingerprint,也就是将元素值做了一边hash,是一个8位2进制数,而且只有两个hash函数,同样也具有存在误判风险</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>二、布谷鸟过滤器核心操作</strong></span></div>\n</div>\n<p>1. 插入数据：“双哈希找巢，指纹占位置” 对要存入的任意值（比如字符串 “user123”）：<br />① 生成指纹：先通过哈希函数把值转化为短且固定长度的 “指纹”（比如把 “user123” 哈希成 8 位二进制数 “10110010”）—— 指纹是值的 “精简版”，比原值小得多，目的是节省内存； <br />② 双哈希定位桶：用两个独立的哈希函数（Hash1、Hash2），计算出这个值在 “桶数组” 里的两个候选桶位置（比如 Hash1 算出来是第 10 号桶，Hash2 算出来是第 25 号桶）； <br />③ 存入规则：把指纹放进任意一个候选桶（只要桶里还有空位）；如果两个桶都满了，就 “踢走” 其中一个桶里已有的指纹（类似布谷鸟占别的鸟的巢），被踢走的指纹再用它自己的另一个候选桶位置重新插入，直到找到空位（或重试上限，说明过滤器满了）。</p>\n<p>2. 查询数据：“双桶找指纹，有则判存在”（对应官方 “membership query”） 要判断 “值 x 是否存在”：<br />① 生成 x 的指纹（和插入时的规则一致）；<br />② 用 Hash1、Hash2 算出 x 的两个候选桶；<br />③ 只要其中一个桶里能找到和 x 完全匹配的指纹，就返回 “存在”；两个桶都没有，就返回 “不存在”。 关键特性：只有 “假阳性”，没有 “假阴性” 和布隆过滤器一样，布谷鸟过滤器的判断结果规则是： 说 “不存在”：100% 准确（绝对不存在）； 说 “存在”：可能误判（实际不存在，但指纹巧合匹配）—— 这就是 “假阳性（false positive）”。</p>\n<p>3. 删除数据:&nbsp; &nbsp;\"生成待删除元素指纹, 双哈希找巢, 找到两个候选桶, 桶中找到任意相同指纹,删除一个即可\"<br />为什么传统布隆过滤器无法删除呢? 因为布隆过滤器依靠bit数组hash命中,多个元素可能命中相同位置,那么这个位置实际包含了两个元素存在的信息,是\"共享\"的,删除一个元素,需要把对应位置置为0,就会影响到其他元素的判断<br />而布谷鸟过滤器不同,它使用的是桶数组,就算两个元素恰好计算的两个候选桶是相同的,恰好计算出的指纹也是相同的,且恰好存放指纹的实际桶也是同一个,也没关系,直接往桶里塞<br />因为桶是可以存放多个的,存放多个相同的指纹也没关系,天然支持存放相同指纹<br />删除的时候,直接找到候选桶,删除对应的一个指纹就行了<br />但也正因如此,只删除一个对应指纹,再去判断此元素是否存在时,有其他元素恰好指纹是相同的,且存于同一个桶中,这样可能会存在误判,官方论文中称为\"假阳性\"</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>三、误判率：指纹长度的核心影响</strong></span></div>\n</div>\n<p>官方明确 “fingerprint size will directly determine the false positive rate”，意思是 指纹是值的 “精简标识”，长度越短（比如 4 位），不同值生成相同指纹的概率越高，误判率就越高； 指纹越长（比如 16 位），相同指纹的概率越低，误判率就越低，但每个元素生成的指纹越长,&nbsp; 占用的内存也越多。 <br />举个实际数值（Redis 中常用配置）：<br />8 位指纹：误判率≈1/256（0.39%），适合对误判率要求不高、追求内存极致节省的场景； <br />16 位指纹：误判率≈1/65536（0.0015%），适合对误判率敏感的场景（比如黑名单校验）。</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>四、Redis 中布谷鸟过滤器的优劣势</strong></span></div>\n</div>\n<p>支持删除数据：布隆过滤器的位数组一旦置 1 无法回退，无法删除；布谷鸟过滤器只需删除对应桶里的指纹即可，适合需要动态更新的场景（比如黑名单新增 / 删除）；<br />空间效率更高：指纹是紧凑存储的，相比布隆过滤器的稀疏位数组(存在大量浪费) 相同误判率下，布谷鸟过滤器的内存占用约为布隆过滤器的 1/2~2/3；<br />哈希函数更少：固定 2 个哈希函数，计算开销比布隆过滤器（3-5 个）更低。<br />性能: 布谷鸟过滤器只需要计算一次找到hash桶,且各个桶的位置较为集中,内存上较为靠近,CPU的缓存命中率更高,查询速度快于布隆过滤器<br /><br />劣势:<br />在接近满时,布谷鸟过滤器插入元素可能会频繁占巢,导致后续指纹不得不移动自己的位置,导致插入性能大幅下降(由于布谷鸟过滤器的\"占巢\"特点,元素越多,越趋向于满时,插入数据的性能会越来越低,因为插入一个就要占别人的巢,别人又要去找另一个巢,重复如此,性能会越来越低)<br />而且布谷鸟过滤器的容量大小必须为2的幂<br />可惜的是现在的具体实现并不多,GitHub上只有零星几个Go,C++,Java的实现</p>\n<div>\n<div><span style=\"font-size: 16px;\"><strong>五、核心总结</strong></span></div>\n</div>\n<p>布谷鸟过滤器底层是桶数组 + 指纹，靠 2 个哈希函数定位桶，不同于布隆过滤器的 “位数组 + 多哈希”；<br />查询逻辑：双桶找匹配指纹，有则判存在，无则判不存在（仅可能假阳性）； <br />误判率核心：指纹长度越短，误判率越高，内存占用越少，可按需平衡；<br />核心优势：支持删除、内存效率高，是 Redis 中布隆过滤器的升级版, 但是插入性能略逊于传统布隆过滤器</p>\n<p>官方文档: <a href=\"https://redis.io/docs/latest/develop/data-types/probabilistic/cuckoo-filter/\" rel=\"noopener nofollow\" target=\"_blank\">https://redis.io/docs/latest/develop/data-types/probabilistic/cuckoo-filter/</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:46</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lxl-233\">风乐</a>&nbsp;\n阅读(<span id=\"post_view_count\">140</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "鸿蒙应用开发UI基础第六节:Want拉起应用跳转传参匹配规则实战",
      "link": "https://www.cnblogs.com/san-xiu/p/19607664",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/san-xiu/p/19607664\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:41\">\n    <span>鸿蒙应用开发UI基础第六节:Want拉起应用跳转传参匹配规则实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"学习目标\">【学习目标】</h2>\n<ol>\n<li>理解 Want 本质：掌握 Want 作为组件间信息传递载体的核心作用，明确显式/隐式 Want 的划分与适用场景；</li>\n<li>掌握显式启动：精通跨应用通过 <code>bundleName+abilityName</code> 精准启动组件；</li>\n<li>掌握隐式启动：吃透 <code>linkFeature</code>、<code>action</code>、<code>entities</code>、<code>uri</code>、<code>type</code> 的完整层级匹配规则；</li>\n<li>数据传递与校验：规范使用 <code>parameters</code> 传递数据，合理运用功能标识实现精准匹配。</li>\n</ol>\n<h2 id=\"内容铺垫\">【内容铺垫】</h2>\n<p>在 HarmonyOS 中，<strong>Want 是组件（Ability/Extension）间交互的标准信息载体</strong>，核心用于描述“操作目标”“操作意图”和“附加数据”，是应用内/跨应用组件通信的核心桥梁。无论是应用内页面跳转、跨应用功能调用（如打开文档、分享内容），本质都是通过传递 Want 对象实现的。</p>\n<p>在之前的章节中，我们已多次使用 Want 实现 Ability 拉起操作，本节将所有 Want 核心能力直接在 <code>Index</code> 页演示，无需额外跳转页面。</p>\n<blockquote>\n<p>核心规范提示：从 API 12 开始，已不再推荐三方应用使用指定 Ability 方式（即显式 Want）拉起其他应用，推荐使用指定应用链接方式（下一节讲），但作为开发者，我们仍需掌握显式/隐式 Want 的核心原理，以便应对各类组件通信场景。</p>\n</blockquote>\n<p>示意图如下：</p>\n<p><img alt=\"StartAbility调用原理\" class=\"lazyload\" /></p>\n<h2 id=\"一want-核心概念与结构\">一、Want 核心概念与结构</h2>\n<p>Want 是对象类型，核心字段决定组件匹配与启动逻辑，关键字段及约束如下：</p>\n<h3 id=\"1-核心字段解析\">1. 核心字段解析</h3>\n<table>\n<thead>\n<tr>\n<th>字段名</th>\n<th>类型</th>\n<th>核心作用</th>\n<th>必选性</th>\n<th>核心说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>deviceId</code></td>\n<td>string</td>\n<td>目标设备ID</td>\n<td>否</td>\n<td>空字符串表示本机，跨设备场景需指定设备标识；隐式 Want 暂不支持跨设备调用</td>\n</tr>\n<tr>\n<td><code>bundleName</code></td>\n<td>string</td>\n<td>目标应用包名</td>\n<td>显式必选</td>\n<td>显式 Want 必须指定</td>\n</tr>\n<tr>\n<td><code>abilityName</code></td>\n<td>string</td>\n<td>目标组件名称</td>\n<td>显式必选</td>\n<td>显式 Want 核心字段；API 12+ 跨应用场景不推荐使用</td>\n</tr>\n<tr>\n<td><code>moduleName</code></td>\n<td>string</td>\n<td>目标模块名称</td>\n<td>否</td>\n<td>同一应用多模块存在重名组件时，需指定，否则默认匹配第一个模块</td>\n</tr>\n<tr>\n<td><code>uri</code></td>\n<td>string</td>\n<td>统一资源标识符</td>\n<td>隐式可选</td>\n<td>格式为 <code>scheme://host:port/path</code>；自定义 scheme 不可与系统应用重复（如 <code>ohos</code> 前缀）</td>\n</tr>\n<tr>\n<td><code>action</code></td>\n<td>string</td>\n<td>操作意图</td>\n<td>隐式核心</td>\n<td>常用值：<code>ohos.want.action.viewData</code>（查看数据）、<code>ohos.want.action.share</code>（分享）、<code>ohos.want.action.search</code>（搜索）</td>\n</tr>\n<tr>\n<td><code>entities</code></td>\n<td>Array</td>\n<td>组件类别约束</td>\n<td>隐式可选</td>\n<td>常用值：<code>entity.system.browsable</code>（浏览器类组件）、<code>entity.system.home</code>（桌面应用）</td>\n</tr>\n<tr>\n<td><code>type</code></td>\n<td>string</td>\n<td>数据MIME类型</td>\n<td>隐式可选</td>\n<td>如 <code>text/plain</code>（纯文本）、<code>image/png</code>（PNG图片），需与 <code>uri</code> 协同匹配</td>\n</tr>\n<tr>\n<td><code>parameters</code></td>\n<td>Object</td>\n<td>自定义附加数据</td>\n<td>否</td>\n<td>支持基础数据类型（字符串、数字、布尔值等）；可通过 <code>linkFeature</code> 字段标记功能类型（隐式匹配最高优先级）</td>\n</tr>\n<tr>\n<td><code>flags</code></td>\n<td>number</td>\n<td>启动模式标记</td>\n<td>否</td>\n<td>仅 <code>FLAG_START_WITHOUT_TIPS</code> 支持隐式 Want 取消“暂无可用打开方式”弹框；无法取消“是否允许跳转”系统弹框</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"2-want-的两种核心类型\">2. Want 的两种核心类型</h3>\n<ul>\n<li><strong>显式 Want</strong>：同时指定 <code>bundleName</code> 和 <code>abilityName</code>，直接定位目标组件，无需系统遍历匹配，匹配效率高、无系统开销。</li>\n<li><strong>隐式 Want</strong>：不指定 <code>abilityName</code>，通过 <code>linkFeature</code>、<code>action</code>、<code>entities</code>、<code>uri</code>、<code>type</code> 描述操作意图，由系统匹配声明对应 <code>skills</code> 的组件，<strong>适用于跨应用通用功能调用</strong>（如调用系统分享、打开浏览器）。</li>\n</ul>\n<h3 id=\"3-隐式-want-匹配规则核心重点\">3. 隐式 Want 匹配规则（核心重点）</h3>\n<h4 id=\"1匹配基础前提\">（1）匹配基础前提</h4>\n<p>隐式 Want 匹配的基础前提：若 <code>action</code>/<code>entities</code>/<code>uri</code>/<code>type</code>/<code>parameters(linkFeature)</code> 五个属性均未配置，系统直接判定匹配失败，无需后续校验。</p>\n<h4 id=\"2匹配优先级从高到低\">（2）匹配优先级（从高到低）</h4>\n<p><code>linkFeature（parameters 内置字段）</code> → <code>action</code> → <code>entities</code> → <code>uri + type</code></p>\n<blockquote>\n<p><code>linkFeature</code> 是 HarmonyOS API 11+ 新增的最高优先级匹配字段，通过 <code>parameters</code> 传递，专门解决传统隐式匹配范围过宽的问题，适用于跨应用固定功能的精准隐式调用。</p>\n</blockquote>\n<h4 id=\"3分步详细规则\">（3）分步详细规则</h4>\n<p>表格中 action 值如 <code>abc</code> 仅为表达匹配，工程中取值要规范。</p>\n<h5 id=\"-linkfeature-匹配最高优先级\">① linkFeature 匹配（最高优先级）</h5>\n<h6 id=\"核心匹配字段及校验逻辑精准匹配为唯一规则\">核心匹配字段及校验逻辑（精准匹配为唯一规则）</h6>\n<table>\n<thead>\n<tr>\n<th>校验字段</th>\n<th>触发校验条件</th>\n<th>匹配规则</th>\n<th>失败判定</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>linkFeature</td>\n<td>调用方传该参数则必校验</td>\n<td>需与 skills 配置值完全一致</td>\n<td>配置值≠调用方值（如 link≠errLink）</td>\n</tr>\n<tr>\n<td>scheme（URI）</td>\n<td>调用方传 uri 则必校验 scheme</td>\n<td>需与 uri 的 scheme 完全一致</td>\n<td>scheme≠uri 的 scheme（如 https≠file）</td>\n</tr>\n<tr>\n<td>type</td>\n<td>调用方传 type 则必校验</td>\n<td>需与调用方 type 完全一致</td>\n<td>type≠调用方值（如 text/plain≠image/png）</td>\n</tr>\n</tbody>\n</table>\n<h6 id=\"分场景匹配规则\">分场景匹配规则</h6>\n<ol>\n<li><strong>场景1（仅传 linkFeature）</strong>：仅校验 linkFeature，scheme/type 不参与，一致则成功，否则失败；</li>\n<li><strong>场景2（传 uri+linkFeature）</strong>：需同时满足 scheme 匹配 + linkFeature 匹配，任一不满足则失败；</li>\n<li><strong>场景3（传 type+linkFeature）</strong>：需同时满足 type 匹配 + linkFeature 匹配，任一不满足则失败；</li>\n<li><strong>场景4（传 uri+type+linkFeature）</strong>：需同时满足 scheme 匹配 + type 匹配 + linkFeature 匹配，任一不满足则失败。</li>\n</ol>\n<h6 id=\"补充说明\">补充说明</h6>\n<ul>\n<li>无通配符、前缀匹配等宽松规则，所有参与校验的字段均为<strong>精准完全匹配</strong>；</li>\n<li>调用方未传的字段（如 uri/type），skills 中对应字段不参与校验；</li>\n<li>无“部分匹配”“降级匹配”逻辑，任一需校验字段不匹配则整体失败。</li>\n</ul>\n<h5 id=\"-action-匹配规则\">② action 匹配规则</h5>\n<table>\n<thead>\n<tr>\n<th>调用方 <code>want</code> 的 <code>action</code></th>\n<th>目标方 <code>skills.actions</code></th>\n<th>匹配结果</th>\n<th>核心说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>空值 <code>action:\"\"</code></td>\n<td>空值 <code>actions: []</code></td>\n<td>失败</td>\n<td>双方均未声明操作意图，系统无法匹配</td>\n</tr>\n<tr>\n<td>空值 <code>action:\"\"</code></td>\n<td>非空值 <code>actions: [\"abc\"]</code></td>\n<td>成功</td>\n<td>调用方未指定意图，目标方声明了能力，默认匹配</td>\n</tr>\n<tr>\n<td>非空值 <code>action:\"abc\"</code></td>\n<td>空值 <code>actions: []</code></td>\n<td>失败</td>\n<td>调用方指定了意图，目标方未声明对应能力</td>\n</tr>\n<tr>\n<td>非空值 <code>action:\"abc\"</code></td>\n<td>包含调用方 <code>actions: [\"abc\"]</code></td>\n<td>成功</td>\n<td>目标方声明的能力包含调用方意图</td>\n</tr>\n<tr>\n<td>非空值 <code>action:\"abc\"</code></td>\n<td>不包含调用方 <code>actions: [\"bcd\"]</code></td>\n<td>失败</td>\n<td>目标方未声明调用方所需能力</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"-entities-匹配规则\">③ entities 匹配规则</h5>\n<table>\n<thead>\n<tr>\n<th>调用方 <code>entities</code></th>\n<th>目标方 <code>skills.entities</code></th>\n<th>匹配结果</th>\n<th>核心说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>空（<code>entities: []</code>）</td>\n<td>非空（<code>entities: [\"a\",\"b\"]</code>）</td>\n<td>成功</td>\n<td>调用方未限定组件类别，目标方无论是否声明类别均匹配</td>\n</tr>\n<tr>\n<td>空（<code>entities: []</code>）</td>\n<td>空（<code>entities: []</code>）</td>\n<td>成功</td>\n<td>调用方未限定组件类别，目标方无论是否声明类别均匹配</td>\n</tr>\n<tr>\n<td>非空（<code>entities: [\"a\"]</code>）</td>\n<td>空（<code>entities: []</code>）</td>\n<td>失败</td>\n<td>调用方限定了组件类别，目标方未声明任何类别</td>\n</tr>\n<tr>\n<td>非空（<code>entities: [\"a\",\"b\"]</code>）</td>\n<td>包含所有调用方（<code>entities: [\"a\",\"b\",\"c\"]</code>）</td>\n<td>成功</td>\n<td>目标方声明的类别完全包含调用方需求</td>\n</tr>\n<tr>\n<td>非空（<code>entities: [\"a\",\"b\"]</code>）</td>\n<td>未包含所有调用方（<code>entities: [\"a\",\"c\"]</code>）</td>\n<td>失败</td>\n<td>目标方声明的类别缺失调用方所需类别（如调用方要 <code>browsable</code>，目标方仅声明 <code>home</code>）</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"-uri--type-匹配规则协同校验\">④ uri + type 匹配规则（协同校验）</h5>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>调用方配置</th>\n<th>匹配规则</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>场景1</td>\n<td>uri 空 + type 空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 成功；<br />2. 目标方 <code>skills.uris</code> 存在「scheme 和 type 均空」的元素 → 成功；<br />3. 其他情况 → 失败</td>\n</tr>\n<tr>\n<td>场景2</td>\n<td>uri 非空 + type 空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 失败；<br />2. 目标方 <code>skills.uris</code> 存在「uri 匹配 + type 空」的元素 → 成功；<br />3. 前两步失败且 uri 为文件路径 → 按后缀推导 MIME 类型，匹配目标方 <code>type</code> → 成功/失败</td>\n</tr>\n<tr>\n<td>场景3</td>\n<td>uri 空 + type 非空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 失败；<br />2. 目标方 <code>skills.uris</code> 存在「scheme 空 + type 匹配」的元素 → 成功；<br />3. 其他情况 → 失败</td>\n</tr>\n<tr>\n<td>场景4</td>\n<td>uri 非空 + type 非空</td>\n<td>1. 目标方 <code>skills.uris</code> 为空 → 失败；<br />2. 目标方 <code>skills.uris</code> 存在「uri 匹配 + type 匹配」的元素 → 成功；<br />3. 其他情况 → 失败</td>\n</tr>\n</tbody>\n</table>\n<h6 id=\"type-单独匹配规则仅调用方-type-非空时生效\">Type 单独匹配规则（仅调用方 <code>type</code> 非空时生效）</h6>\n<p>Type 匹配核心为 <strong>MIME 媒体类型匹配</strong>，遵循 HarmonyOS 官方规范，无降级匹配逻辑，规则如下：</p>\n<ol>\n<li><strong>精准匹配（最高优先级）</strong>：调用方 <code>type</code> 与目标方 <code>skills.uris</code> 中 <code>type</code> 完全一致 → 匹配成功；</li>\n<li><strong>通配符匹配</strong>：仅支持「主类型/*」格式，目标方 <code>type</code> 为此格式且调用方 <code>type</code> 属于该主类型范畴 → 成功；不支持 <code>*/子类型</code> 格式；</li>\n<li><strong>匹配失败场景</strong>：\n<ul>\n<li>目标方 <code>type</code> 为具体值但与调用方 <code>type</code> 不一致；</li>\n<li>目标方 <code>type</code> 通配符格式不规范；</li>\n<li>调用方 <code>type</code> 为复合 MIME 类型，目标方无对应配置。</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>补充说明：Type 匹配仅在「调用方传递 type」且「进入 uri+type 协同校验环节」时触发；若目标方 <code>type</code> 为空，仅当调用方 <code>type</code> 也为空时匹配成功。</p>\n</blockquote>\n<h6 id=\"uri-匹配规则\">uri 匹配规则</h6>\n<p>URI 匹配以 <code>scheme → host → port → 路径</code> 为核心层级，仅当前一级匹配通过时触发下一级校验，任一层级失败则整体 URI 匹配失败，具体规则：</p>\n<ol>\n<li><strong>scheme 层级（首验层级）</strong>：\n<ul>\n<li>目标 URI 项 <code>scheme</code> 为空 → 仅调用方 <code>uri</code> 为空时匹配成功，否则失败；</li>\n<li>目标 URI 项 <code>scheme</code> 非空 → 调用方 <code>uri</code> 的 <code>scheme</code> 需与其完全一致（大小写敏感，官方建议全小写），否则失败。</li>\n</ul>\n</li>\n<li><strong>host 层级（仅 scheme 匹配成功后触发）</strong>：\n<ul>\n<li>目标 URI 项 <code>host</code> 为空 → 直接匹配成功；</li>\n<li>目标 URI 项 <code>host</code> 非空 → 调用方 <code>uri</code> 的 <code>host</code> 需与其完全一致，否则失败。</li>\n</ul>\n</li>\n<li><strong>port 层级（仅 scheme+host 匹配成功后触发）</strong>：\n<ul>\n<li>目标 URI 项 <code>port</code> 为空 → 直接匹配成功；</li>\n<li>目标 URI 项 <code>port</code> 非空 → 调用方 <code>uri</code> 的 <code>port</code> 需与其完全一致（数字格式），否则失败。</li>\n</ul>\n</li>\n<li><strong>路径层级（仅 scheme+host+port 匹配成功后触发）</strong>：<br />\n按 <code>path → pathStartWith → pathRegex</code> 优先级校验，任一规则匹配成功则终止校验，全部失败则 URI 匹配失败：\n<ul>\n<li><strong>path 精准匹配</strong>：目标 URI 项 <code>path</code> 非空 → 调用方 <code>uri</code> 全路径与其完全一致 → 成功，否则进入下一级；</li>\n<li><strong>pathStartWith 前缀匹配</strong>：目标 URI 项 <code>pathStartWith</code> 非空 → 调用方 <code>uri</code> 路径包含该前缀 → 成功，否则进入下一级；</li>\n<li><strong>pathRegex 正则匹配</strong>：目标 URI 项 <code>pathRegex</code> 非空 → 调用方 <code>uri</code> 路径符合该正则表达式 → 成功，否则 URI 匹配失败；</li>\n<li><strong>路径字段均为空</strong>：目标 URI 项 <code>path</code>、<code>pathStartWith</code>、<code>pathRegex</code> 均为空 → 直接匹配成功。</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p>补充说明：</p>\n<ol>\n<li>最左 URI 匹配：仅当目标 URI 项仅配置 <code>scheme</code>/<code>scheme+host</code>/<code>scheme+host+port</code>（路径字段均为空）时生效，调用方 <code>uri</code> 需以目标配置为前缀；</li>\n<li>文件 URI 解析：<code>file://</code> 开头的 URI，系统自动解析文件后缀推导 MIME 类型，用于补充场景2的 type 匹配；</li>\n<li>URI 格式规范：自定义 <code>scheme</code> 不可与系统内置（<code>ohos</code>/<code>http</code>/<code>https</code>/<code>file</code>）重复。</li>\n</ol>\n</blockquote>\n<h4 id=\"4匹配结果说明\">（4）匹配结果说明</h4>\n<p>根据系统中待匹配应用组件的匹配情况不同，使用隐式 Want 启动应用组件时会出现以下三种情况：</p>\n<ul>\n<li>未匹配到满足条件的应用组件：启动失败。</li>\n<li>匹配到一个满足条件的应用组件：直接启动该应用组件。</li>\n<li>匹配到多个满足条件的应用组件（UIAbility）：弹出选择框让用户选择。</li>\n</ul>\n<h2 id=\"二本节工程\">二、本节工程</h2>\n<h3 id=\"一工程创建\">（一）工程创建</h3>\n<h4 id=\"1-调用方工程wantandlinkingdemo\">1. 调用方工程：WantAndLinkingDemo</h4>\n<ul>\n<li>基础配置：HarmonyOS 5.0+、API 18+、Stage 模型；</li>\n<li>核心用途：演示显式/隐式 Want 启动；</li>\n<li>包名：<code>com.example.wantandlinkingdemo</code>。</li>\n</ul>\n<h4 id=\"2-接收方工程implicitreceiverdemo\">2. 接收方工程：ImplicitReceiverDemo</h4>\n<ul>\n<li>基础配置：HarmonyOS 5.0+、API 18+、Stage 模型；</li>\n<li>核心用途：作为跨应用显式/隐式启动的目标应用，接收并展示传递的参数；</li>\n<li>包名：<code>com.example.implicitreceiverdemo</code>。</li>\n</ul>\n<h3 id=\"二调用方工程核心目录结构\">（二）调用方工程核心目录结构</h3>\n<pre><code>WantAndLinkingDemo/                  # 项目根目录（Want实战Demo）\n├─ AppScope/                        # 应用全局配置目录（多模块应用共享）\n│  ├─ resources/                    # 应用全局资源文件（如全局样式、多语言字符串）\n│  └─ app.json5                     # 应用级配置文件（应用名称、版本号等）\n├─ entry/                           # 主模块目录（核心代码所在）\n│  ├─ src/\n│  │  ├─ main/                      # 主代码目录（应用运行的核心代码）\n│  │  │  ├─ ets/                    # ArkTS代码目录（逻辑实现核心）\n│  │  │  │  ├─ entryability/        # 主Ability目录（应用入口）\n│  │  │  │  │  └─ EntryAbility.ets  # 应用入口Ability（处理启动初始化）\n│  │  │  │  └─ pages/               # 主Ability对应的页面目录\n│  │  │  │     └─ Index.ets          # 核心功能页（整合显式/隐式Want启动所有案例）\n│  │  │  ├─ resources/              # 模块级资源目录（页面布局、图片、局部样式）\n│  │  │  └─ module.json5            # 模块配置文件（核心！配置skills、exported等）\n│  ├─ build-profile.json5           # 模块构建配置文件（编译、打包参数）\n│  ├─ hvigorfile.ts                 # 模块构建脚本（hvigor构建任务配置）\n│  ├─ obfuscation-rules.txt         # 代码混淆规则文件（发布时加密代码，可选）\n│  └─ oh-package.json5              # 模块依赖配置文件（第三方库、工具依赖）\n</code></pre>\n<h3 id=\"三隐式显示拉起应用传参示例\">（三）隐式/显示拉起应用传参示例</h3>\n<h4 id=\"调用方wantandlinkingdemo-indexets\">调用方：WantAndLinkingDemo Index.ets</h4>\n<p>构造Want数据，演示显式/隐式不同模式拉起应用，通过不同匹配规则。</p>\n<pre><code class=\"language-javascript\">import { BusinessError } from '@ohos.base';\nimport { common, Want, wantConstant } from '@kit.AbilityKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\nimport { promptAction } from '@kit.ArkUI';\n\nconst DOMAIN = 0xFF00;\nconst TAG = 'WantAndLinkingDemo';\n\n@Entry\n@Component\nstruct Index {\n  // 获取UIAbility上下文\n  private context = this.getUIContext().getHostContext() as common.UIAbilityContext;\n\n  build() {\n    Column({ space: 15 }) {\n      // 页面标题\n      Text('Want 显式/隐式启动实战（匹配规则修正版）')\n        .fontSize(30)\n        .fontWeight(FontWeight.Bold)\n        .margin({ bottom: 30 })\n\n      // 1. 显式Want（精准匹配，无规则问题）\n      Button('1. 显式Want跨应用拉起传参')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.crossAppExplicitStart();\n        })\n\n      // 2. 隐式Want - linkFeature（最高优先级，需精准匹配）\n      Button('2. 隐式Want-linkFeature匹配（最高优先级）')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartShare();\n        })\n\n      // 3. 隐式Want - action单独匹配（核心：仅传action，无其他干扰字段）\n      Button('3. 隐式Want-action单独匹配')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartActionMatch();\n        })\n\n      // 4. 隐式Want - entities单独匹配\n      Button('4. 隐式Want-entities单独匹配')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartEntitiesMatch();\n        })\n\n      // 5. 隐式Want - uri+type协同匹配（核心：仅传uri+type，配通用action）\n      Button('5. 隐式Want-uri+type协同匹配')\n        .width('80%')\n        .height(50)\n        .fontSize(18)\n        .backgroundColor('#1890ff')\n        .fontColor('#ffffff')\n        .onClick(() =&gt; {\n          this.implicitStartUriTypeMatch();\n        })\n    }\n    .width('100%')\n    .height('100%')\n    .justifyContent(FlexAlign.Center)\n    .backgroundColor('#f5f5f5')\n  }\n\n  /**\n   * 场景1：显式Want\n   * 规则：指定bundleName+abilityName，无需匹配skills，仅需接收方设置 exported=true\n   */\n  private async crossAppExplicitStart() {\n    try {\n      const want: Want = {\n        bundleName: \"com.example.implicitreceiverdemo\", // 接收方包名（必须与实际一致）\n        abilityName: \"EntryAbility\", // 接收方组件名（必须与实际一致）\n        parameters: {\n          \"shareContent\": \"显式Want测试：跨应用精准传递内容\",\n          \"linkFeature\": \"Explicit\"\n        }\n      };\n\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"显式Want跨应用拉起成功\");\n    } catch (err) {\n      const businessErr = err as BusinessError;\n      promptAction.showToast({\n        message: `启动失败：${businessErr.message}`,\n        duration: 3000\n      });\n    }\n  }\n\n  /**\n   * 场景2：隐式Want - linkFeature（最高优先级）\n   * 规则：uri和type均为空时，仅校验linkFeature精准匹配\n   * 规则：uri或type不为空时，需同时满足linkFeature精准匹配 + uri的scheme匹配 + type精准匹配\n   */\n  private async implicitStartShare() {\n    const want: Want = {\n      uri: \"data://com.example.wantandlinkingdemo/share/text\", // scheme/host需匹配\n      type: \"text/plain\", // 必须精准匹配\n      parameters: {\n        shareContent: \"隐式Want测试：linkFeature匹配成功！\",\n        linkFeature: \"Share\" // 最高优先级，接收方必须精准配置\n      },\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(linkFeature)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `linkFeature匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到支持分享的应用',\n        duration: 3000\n      });\n    }\n  }\n\n  /**\n   * 场景3：隐式Want - action单独匹配\n   * 规则：调用方action需匹配接收方skills中的action配置\n   */\n  private async implicitStartActionMatch() {\n    const want: Want = {\n      action: 'ohos.want.action.viewData',\n      parameters: {\n        \"shareContent\": \"隐式Want测试：action匹配成功！\",\n      }\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(action)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `action匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到支持查看数据的应用',\n        duration: 3000\n      });\n    }\n  }\n  \n  /**\n   * 场景4：隐式Want - entities匹配\n   * entities匹配规则：调用方传递的所有entities值，需被目标方skills.entities完全包含才匹配成功（本示例为\"abc\"）\n   * 系统标准值参考：entity.system.browsable（浏览器类别，处理网页链接）、entity.system.home（应用主入口组件）\n   */\n  private async implicitStartEntitiesMatch() {\n    const want: Want = {\n      action: 'ohos.want.action.viewData', // 查看数据\n      entities: [\"abc\"],\n      parameters: {\n        \"shareContent\": \"隐式Want测试：entities匹配成功！\",\n      }\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(entities)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `entities匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到浏览器类应用',\n        duration: 3000\n      });\n    }\n  }\n\n  /**\n   * 场景5：隐式Want - uri+type协同匹配\n   * 核心：需同时满足uri层级匹配（scheme→host→port→路径） + type精准匹配\n   */\n  private async implicitStartUriTypeMatch() {\n    const want: Want = {\n      action: 'ohos.want.action.viewData',\n      uri: \"data://com.implicitreceiverdemo:8080/detail/page123\",\n      type: \"text/plain\",\n      flags: wantConstant.Flags.FLAG_START_WITHOUT_TIPS // 取消失败弹窗提示\n    };\n\n    try {\n      await this.context.startAbility(want);\n      hilog.info(DOMAIN, TAG, \"隐式Want(uri+type)跨应用拉起成功\");\n    } catch (error) {\n      const businessErr = error as BusinessError;\n      hilog.error(DOMAIN, TAG, `uri+type匹配失败：${businessErr.message}`);\n      promptAction.showToast({\n        message: '启动失败，未匹配到符合uri+type规则的应用',\n        duration: 3000\n      });\n    }\n  }\n}\n</code></pre>\n<h5 id=\"2接收方implicitreceiverdemo\">（2）接收方：ImplicitReceiverDemo</h5>\n<p>跨应用接收调用方Want传递的参数（拉起组件内Ability接收参数同理，本节不做示例演示）</p>\n<pre><code class=\"language-javascript\">import { AbilityConstant, UIAbility, Want } from '@kit.AbilityKit';\nimport { hilog } from '@kit.PerformanceAnalysisKit';\nimport { ConfigurationConstant } from '@kit.AbilityKit';\nimport { window } from '@kit.ArkUI';\n\nconst DOMAIN = 0x0000;\nconst TAG = 'ImplicitReceiverDemo';\n\nexport default class EntryAbility extends UIAbility {\n  onCreate(want: Want, launchParam: AbilityConstant.LaunchParam): void {\n    hilog.info(DOMAIN, TAG, '%{public}s', 'ImplicitReceiverDemo onCreate 触发');\n    try {\n      // 解析 Want 中的参数（显式传递的 data + 隐式传递的 shareContent）\n      const parameters = want.parameters as Record&lt;string, Object&gt;;\n      // 存储参数到 AppStorage，供 UI 页面展示（默认值避免空显示）\n      AppStorage.setOrCreate(\"shareContent\", parameters[\"shareContent\"] || '未接收分享数据');\n\n      // 设置应用颜色模式（可选，保持系统默认）\n      this.context.getApplicationContext().setColorMode(ConfigurationConstant.ColorMode.COLOR_MODE_NOT_SET);\n    } catch (err) {\n      hilog.error(DOMAIN, TAG, 'Failed to set colorMode. Cause: %{public}s', JSON.stringify(err));\n    }\n  }\n\n  /**\n   * 已启动时接收新的 Want 参数（如隐式启动多次触发）\n   */\n  onNewWant(want: Want, launchParam: AbilityConstant.LaunchParam): void {\n    hilog.info(DOMAIN, TAG, '%{public}s', 'ImplicitReceiverDemo onNewWant 触发');\n    const parameters = want.parameters as Record&lt;string, Object&gt;;\n    // 更新参数（实时同步到 UI 页面）\n    AppStorage.setOrCreate(\"shareContent\", parameters[\"shareContent\"] || '未接收分享数据');\n    // 打印接收的参数\n    console.log(`ImplicitReceiverDemo 接收参数：${JSON.stringify(want.parameters)}`);\n  }\n\n  /**\n   * 加载 UI 页面\n   */\n  onWindowStageCreate(windowStage:  window.WindowStage): void {\n    windowStage.loadContent('pages/Index', (err) =&gt; {\n      if (err.code) {\n        hilog.error(DOMAIN, TAG, 'Failed to load the content. Cause: %{public}s', JSON.stringify(err));\n        return;\n      }\n      hilog.info(DOMAIN, TAG, 'Succeeded in loading the content: Index');\n    });\n  }\n}\n</code></pre>\n<h6 id=\"-接收方indexets展示跨应用接收的参数\">② 接收方：Index.ets（展示跨应用接收的参数）</h6>\n<pre><code class=\"language-javascript\">@Entry\n@Component\nstruct Index {\n  @StorageProp('shareContent') shareContent: string = '隐式/显式分享数据未接收';\n\n  build() {\n    Column({ space: 20 }) {\n      Text('ImplicitReceiverDemo（参数接收）')\n        .fontSize(25)\n        .fontWeight(FontWeight.Bold)\n        .margin({ bottom: 10 })\n\n      Text(`接收的内容：${this.shareContent}`)\n        .fontColor(Color.Red)\n        .fontSize(18)\n        .textWrap(true)\n        .padding(10)\n    }.justifyContent(FlexAlign.Center)\n    .height('100%')\n    .width('100%')\n    .padding(20)\n  }\n}\n</code></pre>\n<h6 id=\"-接收方modulejson5配置\">③ 接收方：module.json5配置</h6>\n<pre><code class=\"language-json\">{\n  \"module\": {\n    \"name\": \"entry\",\n    \"type\": \"entry\",\n    \"description\": \"$string:module_desc\",\n    \"mainElement\": \"EntryAbility\",\n    \"deviceTypes\": [\n      \"phone\"\n    ],\n    \"deliveryWithInstall\": true,\n    \"installationFree\": false,\n    \"pages\": \"$profile:main_pages\",\n    \"abilities\": [\n      {\n        \"name\": \"EntryAbility\",\n        \"srcEntry\": \"./ets/entryability/EntryAbility.ets\",\n        \"description\": \"$string:EntryAbility_desc\",\n        \"icon\": \"$media:layered_image\",\n        \"label\": \"$string:EntryAbility_label\",\n        \"startWindowIcon\": \"$media:startIcon\",\n        \"startWindowBackground\": \"$color:start_window_background\",\n        \"exported\": true, // 必须开启：允许外部应用调用（显式/隐式均需）\n        \"skills\": [\n          {\n            // 基础技能：桌面应用（默认配置）\n            \"entities\": [\"entity.system.home\"],\n            \"actions\": [\"ohos.want.action.home\"]\n          },\n          // 场景2：linkFeature匹配规则\n          {\n            \"uris\": [\n              {\n                \"scheme\": \"data\",\n                \"host\": \"com.example.wantandlinkingdemo\",\n                \"type\": \"text/plain\",\n                \"linkFeature\": \"Share\"\n              }\n            ]\n          },\n          // 场景3：action单独匹配规则\n          {\n            \"actions\": [\"ohos.want.action.viewData\"]\n          },\n          // 场景4：entities单独匹配规则\n          {\n            \"actions\": [\"ohos.want.action.viewData\"],\n            \"entities\": [\"abc\"]\n          },\n          // 场景5：uri+type协同匹配规则\n          {\n            \"actions\": [\"ohos.want.action.viewData\"],\n            \"uris\": [\n              {\n                \"scheme\": \"data\",                   // 协议必须完全一致\n                \"host\": \"com.implicitreceiverdemo\", // 域名需完整匹配\n                \"port\": \"8080\",                     // 端口不可省略\n                \"path\": \"detail/page123\",            // 路径需完全一致或使用通配符\n                \"type\": \"text/plain\"                // MIME类型需严格匹配\n              }\n            ]\n          }\n        ]\n      }\n    ],\n    \"extensionAbilities\": [\n      {\n        \"name\": \"EntryBackupAbility\",\n        \"srcEntry\": \"./ets/entrybackupability/EntryBackupAbility.ets\",\n        \"type\": \"backup\",\n        \"exported\": false,\n        \"metadata\": [\n          {\n            \"name\": \"ohos.extension.backup\",\n            \"resource\": \"$profile:backup_config\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>\n<h4 id=\"运行结果\">运行结果</h4>\n<p><img alt=\"Want显式隐式拉起应用\" class=\"lazyload\" /></p>\n<p><img alt=\"Want显式/隐式拉起应用\" class=\"lazyload\" /></p>\n<h2 id=\"四开发核心规范与避坑指南\">四、开发核心规范与避坑指南</h2>\n<h3 id=\"1-核心约束\">1. 核心约束</h3>\n<ul>\n<li>所有对外提供调用的 Ability（显式/隐式），必须在 <code>module.json5</code> 中配置 <code>exported: true</code>，否则无法被外部调用；</li>\n<li>自定义 scheme 不可与系统内置 scheme（如 <code>ohos</code>、<code>http</code>、<code>https</code>、<code>file</code>）重复，建议采用“应用标识+功能”命名（如 <code>harmonydemo</code>）；</li>\n<li>隐式 Want 若使用 <code>linkFeature</code> 匹配，<code>actions</code> 字段可忽略；使用 <code>action/entities/uri+type</code> 匹配时，对应字段不可为空。</li>\n</ul>\n<h3 id=\"2-避坑指南\">2. 避坑指南</h3>\n<table>\n<thead>\n<tr>\n<th>问题现象</th>\n<th>排查/解决方法</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>隐式启动匹配失败</td>\n<td>检查 <code>linkFeature</code>、<code>action</code>、<code>entities</code>、<code>uri</code>、<code>type</code> 是否与接收方配置一致，尤其是 <code>scheme</code>、<code>host</code> 大小写（建议全小写）；</td>\n</tr>\n<tr>\n<td>参数传递失败</td>\n<td>确保传递的参数为基础数据类型（避免传递复杂对象），接收方通过 <code>want.parameters</code> 解析时需做类型断言；</td>\n</tr>\n<tr>\n<td>跨应用显式启动失败</td>\n<td>确认目标应用已安装、<code>bundleName</code> 和 <code>abilityName</code> 配置正确，且目标 Ability 已设置 <code>exported: true</code>；</td>\n</tr>\n<tr>\n<td>uri 匹配失败</td>\n<td>按 <code>scheme→host→port→路径</code> 层级逐一校验，路径匹配优先精准匹配，前缀/正则匹配需确保规则正确。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"五内容总结\">五、内容总结</h2>\n<ol>\n<li>核心载体：Want 是组件间通信的核心载体，显式 Want 用于跨应用精准启动，隐式 Want 用于跨应用通用功能调用；</li>\n<li>隐式匹配规则：按 <code>linkFeature→action→entities→uri+type</code> 优先级校验，前序字段匹配失败则整体失败，所有参与匹配的字段均为精准匹配（uri路径除外）；</li>\n<li>配置关键：对外调用的 Ability 需设 <code>exported: true</code>，隐式启动需保证调用方 Want 字段与接收方 <code>skills</code> 配置完全一致；</li>\n<li>实践原则：按场景选择匹配规则，重视异常处理和用户体验，遵循 API 12+ 规范（优先使用应用链接替代显式 Want）。</li>\n</ol>\n<h2 id=\"六代码仓库\">六、代码仓库</h2>\n<ul>\n<li>调用方工程：WantAndLinkingDemo</li>\n<li>接收方工程：ImplicitReceiverDemo</li>\n<li>仓库地址：<a href=\"https://gitee.com/HarmonyOS-UI-Basics/harmony-os-ui-basics.git\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/HarmonyOS-UI-Basics/harmony-os-ui-basics.git</a></li>\n</ul>\n<h2 id=\"七下节预告\">七、下节预告</h2>\n<p>下一节我们将学习 <strong>Deep Linking 与 App Linking 应用链接</strong> 的完整配置与调用，重点包括：</p>\n<ol>\n<li>掌握 Deep Linking 自定义 scheme 配置、<code>openLink</code> 调用及 <code>canOpenLink</code> 校验；</li>\n<li>掌握 App Linking HTTPS 域名配置、域名校验、参数解析及未安装应用的降级处理；</li>\n<li>明晰 Deep Linking 与 App Linking 的安全性、适用场景核心差异，能按需选型；</li>\n<li>掌握应用链接与 Want 结合的最佳实践，实现跨应用通信的解耦与高安全性。</li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/san-xiu\">鸿蒙-散修</a>&nbsp;\n阅读(<span id=\"post_view_count\">45</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "认识区块链和比特币（一）：余额与小票",
      "link": "https://www.cnblogs.com/ofnoname/p/19592966",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ofnoname/p/19592966\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 11:07\">\n    <span>认识区块链和比特币（一）：余额与小票</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这篇文章不谈价格涨跌和投资讨论。只做一件事：把比特币的基本原理讲清楚。读完你应该能看懂区块浏览器里一笔交易的“输入/输出”，能理解为什么在没有银行的情况下，比特币也能维护余额和支付。</p>\n<p>需要的前置知识不多，你只需要了解三件基础概念即可：<strong>公钥/私钥与数字签名（私钥像“签名章”，用来证明你有权花钱）</strong>、<strong>哈希（像数据指纹）</strong>、以及<strong>分布式系统的入门概念</strong>。这不是密码学课程，所以我们不会推导数学证明，只用直觉和例子把机制讲明白。</p>\n<h2 id=\"比特币是什么\">比特币是什么？</h2>\n<p>在完整理解<strong>比特币是一个去中心化的账本/交易数据库/支付系统</strong>之前，你可以先把比特币当成：<strong>一份公开的、全网同步的“历史记录”</strong>，上面只写两类信息——“哪些钱还没被花掉”和“这些钱未来需要满足什么条件才允许被花”。任何人都可以保存一份副本（运行节点），并用同一套公开规则检查：新来的记录有没有作弊、有没有双花、有没有伪造签名。它不像银行系统那样由某个机构维护“账户余额表”，更像一个班级共同维护的共享记账本：没有班长能单方面改分数，每个人都可以拿规则对照检查。不过这个“共享账本为什么不会乱、为什么最后大家能收敛到同一份版本、为什么有人愿意付出成本来维护它”，要到后面讲完网络规则与挖矿机制后，你才会彻底吃透——而今天我们先从最底层的“钱的形态”开始：UTXO。</p>\n<h2 id=\"比特币与区块链的关系\">比特币与区块链的关系</h2>\n<p><strong>区块链（blockchain）</strong>：从字面上看就是“区块组成的链”。它是一种数据组织方式：把一批记录打包成“区块”，再用哈希把新区块和前一个区块链接起来，让历史记录更难被悄悄篡改。你可以把它理解为一种“按时间顺序装订成册、每页都盖了前一页指纹”的账本结构。</p>\n<p>而 <strong>比特币（Bitcoin）</strong>：是一套运行在互联网上的系统（协议 + 软件 + 节点网络 + 规则），它<strong>用区块链来保存交易历史</strong>，并用一套公开规则让全网在“哪些交易有效、哪些区块算数”上达成一致。换句话说：<strong>区块链是比特币使用的一种账本结构，但比特币不仅仅是区块链</strong>——它还有交易格式、验证规则、网络传播、挖矿激励等一整套机制。在比特币系统里，词语 <strong>比特币（bitcoin / BTC）</strong>：这个词也是这个系统里的“记账单位/资产”。</p>\n<p>比特币是区块链思想最早的大规模成功落地之一，因此影响力最大、生态最成熟；但区块链后来被许多系统采用并拓展了用途（不止做转账，还尝试做更通用的“可验证记录”），如<strong>以太坊（Ethereum）</strong>。同时也出现了大量基于比特币技术理念衍生出来的其他币种与系统，如<strong>莱特币（Litecoin）</strong>、<strong>门罗币（Monero）</strong>。</p>\n<h2 id=\"utxo比特币里的钱\">UTXO：比特币里的“钱”</h2>\n<p>在比特币里，“你有多少钱”不是写在某张<strong>账户余额表</strong>上，而是散落在账本历史里的一堆“小票”。这些小票的正式名字叫：</p>\n<p><strong>UTXO（Unspent Transaction Output，未花费交易输出）</strong>：一笔交易产生的每个“输出（output）”，只要还没有被后续交易花掉，就处于“未花费”状态，它就是一个 UTXO。</p>\n<p>所以钱包里显示的“余额”，本质上是：</p>\n<blockquote>\n<p><strong>你所控制的私钥，能够解锁的一组 UTXO 的总和。</strong></p>\n</blockquote>\n<p>这里有一个非常关键但容易忽略的点：UTXO 不是“记在你名下的余额”，而是“带着使用条件的价值片段”。这份“使用条件”通常会指向某个公钥哈希（也就是我们日常看到的“地址”），意思是：<strong>未来想花这笔钱的人，必须拿出能满足条件的证明（通常就是签名）</strong>。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212111529650-1331403071.png\" /></p>\n<h3 id=\"utxo-里到底包含了什么\">UTXO 里到底包含了什么</h3>\n<p>把 UTXO 当成“小票”，这张小票上至少写了两样最重要的东西：</p>\n<ol>\n<li><strong>金额（value）</strong>：比如 0.5 BTC</li>\n<li><strong>锁定条件（locking condition）</strong>：例如“能提供某个公钥对应的有效签名的人才能花”（在这个场景下，可以简单类比普通支付系统，理解为“钱属于谁”）。</li>\n</ol>\n<h3 id=\"utxo-从哪里来交易输出如何变成可花的小票\">UTXO 从哪里来：交易输出如何变成“可花的小票”</h3>\n<p>UTXO 的来源非常朴素：<strong>每一笔交易的每一个输出，都有可能变成未来的 UTXO</strong>。</p>\n<p>举个最简单的“收款”场景：</p>\n<ul>\n<li>\n<p>小明拥有自己的公钥和私钥，他把自己的公钥（即收款地址）给小红</p>\n</li>\n<li>\n<p>小红生成一笔交易，在交易里写一个输出：</p>\n<ul>\n<li>金额：0.5 BTC</li>\n<li>锁定条件：只能由“小明的公钥”对应的私钥花掉</li>\n</ul>\n</li>\n<li>\n<p>这笔交易一旦被网络接受并最终写进区块链历史里，这个输出就成了一个 UTXO</p>\n</li>\n<li>\n<p>小明的钱包之所以“看到余额增加”，是因为它扫描网络历史记录时发现：“有一张新的小票锁给我，而且还没被花掉”。钱包并不是从“某个中心服务器”读取余额，而是在本地（或通过服务）根据历史记录推导“哪些 UTXO 属于我”。之后，小明也可以花掉这个 UTXO（也只有他可以花，因为只有他有收款公钥对应的私钥）。</p>\n</li>\n</ul>\n<h2 id=\"utxo-的花费和找零\">UTXO 的花费和找零</h2>\n<p>你不能“从一个 UTXO 里只花一部分”。花它的方式只有一种：整张用掉。相比微信支付，这其实更类似现金支付：你用一张 100 去买 30 的东西，收银台不会“把纸币剪掉 30”，而是收走 100，再找你 70。</p>\n<p>比特币交易也是同样的逻辑：</p>\n<ul>\n<li><strong>输入（inputs）</strong>：你这次准备“用掉”的若干张旧小票（旧 UTXO）</li>\n<li><strong>输出（outputs）</strong>：这次交易“新生成”的若干张新小票（新的 UTXO）</li>\n</ul>\n<p>一个典型的简单支付几乎总会出现两个输出：</p>\n<ol>\n<li><strong>给收款人</strong>：比如给小红 0.7 BTC（锁给小红的条件）</li>\n<li><strong>找零给自己</strong>：比如找回 0.399 BTC（锁给小明自己的另一个地址）</li>\n</ol>\n<p>绝大多数时候，一笔支付总会有找零。你在区块浏览器里看到“一笔交易输出 2 个”时，十有八九就是“付款 + 找零”。</p>\n<p><img alt=\"典型的 UTXO 交易链条\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212104533493-1727523767.png\" /></p>\n<h3 id=\"手续费\">手续费</h3>\n<p>一笔支付合法的基本逻辑是：<strong>输入金额总和 &gt;= 输出金额总和</strong>，即你不能多花，当然你可以少花（不过没人会主动把自己的钱丢了）。</p>\n<p>更多的时候，输入输出的金额差被作为<strong>手续费</strong>。</p>\n<blockquote>\n<p><strong>手续费 = 输入金额总和 − 输出金额总和</strong></p>\n</blockquote>\n<p>它不是写在某个“手续费字段”里，而是由差额自然形成的。</p>\n<ul>\n<li>\n<p>小明手里有两张 UTXO：0.6 BTC 和 0.5 BTC（共 1.1 BTC）</p>\n</li>\n<li>\n<p>小明要付给小红 0.7 BTC</p>\n</li>\n<li>\n<p>小明创建交易：</p>\n<ul>\n<li>输入：0.6 + 0.5</li>\n<li>输出：0.7 给小红 + 0.399 给自己</li>\n</ul>\n</li>\n<li>\n<p>输入总额 1.1，输出总额 1.099，差额 0.001 BTC</p>\n</li>\n<li>\n<p>这 0.001 BTC 就是手续费。<strong>手续费本质上就是“你少找回来的那点零钱”</strong>。</p>\n</li>\n</ul>\n<p>为什么不全部找零给自己，而是要留一些手续费呢？这类似于现实消费的交税。留出一些钱作为交易费可以让矿工更愿意打包这次交易，有利于维护整个比特币网络的运行。</p>\n<h3 id=\"防双花节点维护-utxo-set\">防“双花”：节点维护 UTXO Set</h3>\n<p>没有银行，谁来防止同一笔钱被花两次？</p>\n<p>每个全节点都在检查各个想被确认的交易的合法性，<strong>都在维护一份“当前（所有人）仍然未花费的小票清单”——UTXO Set。</strong></p>\n<p>当节点收到一笔新交易时，它做的核心检查之一就是：</p>\n<ol>\n<li>这笔交易引用的每一个输入，对应的那张旧小票（旧 UTXO）真的存在吗？</li>\n<li>它还在 UTXO Set 里吗？（如果不在，说明早就被花过了，或者压根不存在）</li>\n<li>你是否提供了满足锁定条件的证明（签名等）？</li>\n<li>金额是否正确？（不能多花）</li>\n</ol>\n<p>一旦这笔交易被接受并最终进入区块，节点就会更新自己的 UTXO Set：</p>\n<ul>\n<li>把被花掉的旧 UTXO 从集合里移除</li>\n<li>把交易新产生的 outputs 加进集合里</li>\n</ul>\n<p>这里没有任何“中心裁判”。每个节点都在做同一套确定性的检查，所以“双花”不是靠“相信某个机构”解决的，而是靠“所有人按规则验算”解决的。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212105542420-446956606.png\" /></p>\n<p>一个 UTXO 只能花费一次，因此有了交易 2 后，交易 3 就是非法的，不能被确认了（除非你直接丢弃交易 2，切换到交易 3）。</p>\n<h2 id=\"utxo-vs-余额账本\">UTXO vs 余额账本</h2>\n<p>通常理解的支付系统（包括银行、支付宝/微信）更像“账户模型”：维护一张表，写着“张三余额 100”。转账时就是把一个账户减、另一个账户加。</p>\n<p>比特币不这么做。它更像“票据模型”：账本不写“你有多少钱”，而是写“哪些票据还没用掉，以及每张票据的使用条件”。所谓“余额”，是你把“自己能解锁的所有未花费票据（UTXO）”加总出来的结果。</p>\n<p>这两种模型并没有绝对优劣，但对理解比特币来说很关键：</p>\n<ul>\n<li>\n<p>在账户模型里，“余额”是系统的显式字段；</p>\n</li>\n<li>\n<p>在 UTXO 模型里，“余额”是从历史记录推导出来的（因此钱包需要扫描/同步/索引）。</p>\n</li>\n</ul>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260212110631731-1587525664.png\" /></p>\n<h3 id=\"影响一utxo-越碎花钱越重\">影响一：UTXO 越碎，花钱越“重”</h3>\n<p>UTXO 模型有个很现实的副作用：如果你的 UTXO 很碎，付款时可能需要拼很多张“小票”。而每多用一个输入，就要在交易里多写一段“我引用的是哪张旧票据 + 我如何解锁它”的数据，交易体积通常会变大。体积变大，矿工打包的成本也更高，于是你往往需要付更高的手续费，交易才更容易被尽快确认。</p>\n<p>所以同样是“转 0.7 BTC”，有时你只需要 1 个输入（恰好有一张 0.7 的票据），有时却需要 10 个输入（十张 0.07 的碎票据）。<br />\n这就是为什么很多钱包会在合适的时候做“合并 UTXO”（把多张碎票据整合成更少的、面额更合适的票据），从体验上看就像“整理零钱”。</p>\n<h3 id=\"影响二隐私线索\">影响二：隐私线索</h3>\n<p>绝大多数交易都会存在找零。一笔“付款”常常会有两个输出——给对方 + 找零给自己。现实里这是常识，但在链上它会变成线索：旁观者可以尝试猜测哪个输出是找零，从而把多笔交易串成“同一个人/同一钱包”的行为轨迹。</p>\n<p>早期钱包之所以倾向于把找零打到一个“新地址”，部分原因就是为了减少“把所有行为都绑在同一个地址上”的明显痕迹——但注意，这并不等于真正匿名：交易本身是公开可查的，地址之间仍可能被启发式规则关联。因此，比特币的\"匿名与安全\"并不能让人高枕无忧。他更像“假名制”而不是“匿名制”：你不写姓名，但你写了可被分析的行为轨迹。其中的攻防逻辑门道很深，这里不讲。</p>\n<h2 id=\"查看一个典型的-utxo\">查看一个典型的 UTXO</h2>\n<p>有很多网站都可以查看比特币主链的信息。以 <a href=\"https://mempool.space\" rel=\"noopener nofollow\" target=\"_blank\">mempool.space</a> 为例子：</p>\n<p>我们随意选择一个已经确认的区块。向下滚动，就可以看到本区块确认的所有交易，每个交易引用一个或多个 UTXO，并生成新的 UTXO：</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1545207/202602/1545207-20260211214405360-554665115.png\" /></p>\n<p>上图中我随手截取了两笔交易（上、下各一笔）。</p>\n<p>先看第一笔交易（交易哈希以 <code>fb2628a7…</code> 开头）。它只有 <strong>1 个输入</strong>：来自地址 <code>bc1qvtdvv…zdd70msz</code>，金额 0.03382740 BTC。这表示：此前账本里存在一张面额 0.03382740 BTC、锁给这个地址的“旧小票”，现在被这笔交易整张用掉了。然后它生成了 2 个输出：一个输出转到地址 <code>3NCU3KvX…W5tm3</code>，金额 0.00089565 BTC；另一个输出又回到了 <code>bc1qvtdvv…zdd70msz</code>，金额 0.03229910 BTC。这就是典型的“<strong>付款 + 找零</strong>”：前者是付给对方的金额，后者是找回给自己的零钱。页面右下角蓝色框显示这笔交易的 输出总额为 0.03319475 BTC（也就是两笔输出相加）。</p>\n<p>这笔交易的手续费：输入是 0.03382740，输出是 0.03319475，相减得到 0.00063265 BTC，换算成 satoshi 就是 63,265 sats（BTC 是比特币，而 Satoshi 是比特币系统的最小单位，1 BTC 等于 1亿 Satoshi）。交易里手续费往往不是一个单独的字段，而是由“少找回来的零钱”自然形成的。</p>\n<p>再看第二笔交易（交易哈希以 <code>d9195032…</code> 开头）。它有 2 个输入，而且两张旧小票都来自同一个地址 <code>bc1qvtdvv…zdd70msz</code>，金额分别是 0.00003777 BTC 和 0.00642833 BTC。两张加起来输入总额是 0.00646610 BTC。它同样产生了 2 个输出：一个输出到 <code>bc1qzgqf…njp90rhl</code>，金额 0.00004840 BTC（这是付款）；另一个输出回 <code>bc1qvtdvv…zdd70msz</code>，金额 0.00578845 BTC（这显然是找零）。输出总额 0.00583685 BTC（页面右下蓝框），因此手续费就是 0.00646610 − 0.00583685 = 0.00062925 BTC = 62,925 sats。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 11:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ofnoname\">Ofnoname</a>&nbsp;\n阅读(<span id=\"post_view_count\">181</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Docker Compose部署多.NET后端API+多Vue前端Web 完整记录（含多数据库扩展+实用场景，亲测无坑）",
      "link": "https://www.cnblogs.com/huyong/p/19607257",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/huyong/p/19607257\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 10:44\">\n    <span>Docker Compose部署多.NET后端API+多Vue前端Web 完整记录（含多数据库扩展+实用场景，亲测无坑）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"Docker Compose部署多.NET后端API+多Vue前端Web 完整记录（含多数据库扩展+实用场景，亲测无坑）\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/157572/202602/157572-20260212102740614-1259695947.png\" />\n        本文介绍在Linux 服务器上，基于 Docker Compose 部署多.NET 后端 API 与多 Vue 前端 Web 的方案，解决多服务端口冲突、配置混乱问题，适配个人测试、小型项目部署场景。\n先完成环境准备：安装配置 Docker CE、升级 Docker Compose 至 V2，配置镜像加速，整理服务器目录结构并上传本地打包文件。核心通过 docker-compose.yml 编排 MySQL/Redis/ 多后端 / 多前端 / Nginx 服务，借助 Nginx 实现前端代理和后端 API 分流，设置健康检查保障服务启动顺序。此外，提供 PostgreSQL、SQL Server 数据库替换方案，仅需修改编排文件和后端连接串，无需调整前端与 Nginx 配置，全程可复现，便于扩展服务数量。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>接上篇文章：<a href=\"http://www.rdiframework.net/article/detail/772191512834117\" rel=\"noopener nofollow\" target=\"_blank\">Linux Docker Compose 部署.NET+Vue+MySQL+Redis+Nginx 完整记录（亲测无坑）</a></p>\n<p>写在前面：在实际开发和测试中，经常会遇到需要在同一台服务器部署多个后端API（如主服务+附属服务、测试服务+生产服务）和多个前端Web（如管理端+用户端、PC端+移动端适配版）的场景。单纯靠docker run命令逐个启动容器，会面临端口冲突、配置混乱、维护困难等问题。</p>\n<p><img alt=\"封面\" src=\"https://img2024.cnblogs.com/blog/157572/202602/157572-20260212102640551-992507078.png\" /></p>\n<p>本文基于Docker Compose，实现「2个及以上.NET8后端API + 2个及以上Vue前端Web」的容器化部署，核心解决端口隔离、配置统一、Nginx分流等问题；同时扩展PostgreSQL、SQL Server两种数据库的替换方案，补充多个实用部署场景（如子域名访问、HTTPS、日志集中），全程亲测可复现，用于后期查阅，也希望能帮到有同样需求的同行。</p>\n<p>适用场景：个人测试、小型项目多服务部署、企业内部多环境（测试+开发）部署，可灵活扩展服务数量，无需重新搭建整体环境。</p>\n<h1 id=\"一部署环境准备提前确认避免兼容问题\">一、部署环境准备（提前确认，避免兼容问题）</h1>\n<h2 id=\"1-服务器环境通用测试小型生产均适用\">1. 服务器环境（通用，测试/小型生产均适用）</h2>\n<ul>\n<li>\n<p>系统：CentOS 7.9（最小化安装，已配置静态IP：192.168.1.100，替换为自身服务器真实IP）</p>\n</li>\n<li>\n<p>内存：8G（建议不低于4G，多服务同时运行需足够内存，避免卡顿）</p>\n</li>\n<li>\n<p>硬盘：100G（存放多个服务的镜像、打包文件、数据库数据，预留冗余）</p>\n</li>\n<li>\n<p>网络：能访问外网（前期拉取镜像、安装依赖，后期可断网运行；若内网服务器，提前准备离线镜像）</p>\n</li>\n<li>\n<p>权限：root用户（或具备Docker、目录操作权限的普通用户，生产环境建议用普通用户）</p>\n</li>\n</ul>\n<h2 id=\"2-软件版本全程统一避免兼容问题\">2. 软件版本（全程统一，避免兼容问题）</h2>\n<ul>\n<li>\n<p>Docker：Docker CE 24.0.7（CentOS7稳定版，兼容性强）</p>\n</li>\n<li>\n<p>Docker Compose：V2.27.1（支持新版配置，解决多服务依赖、健康检查兼容问题）</p>\n</li>\n<li>\n<p>后端：.NET 8（本地VS2022发布为publish文件夹，无源码，多后端需单独发布）</p>\n</li>\n<li>\n<p>前端：Vue3（本地yarn/npm打包为dist文件夹，无源码，多前端需单独打包）</p>\n</li>\n<li>\n<p>数据库（多版本可选）：MySQL 8.0、PostgreSQL 15、SQL Server 2022（Docker镜像，数据持久化）</p>\n</li>\n<li>\n<p>缓存：Redis 7-alpine（轻量版，占用资源少，适配多服务共享/隔离缓存）</p>\n</li>\n<li>\n<p>代理：Nginx alpine（轻量版，实现多前端代理、多后端分流）</p>\n</li>\n</ul>\n<h2 id=\"3-本地准备文件提前打包上传到服务器\">3. 本地准备文件（提前打包，上传到服务器）</h2>\n<p>所有文件统一放在本地易找到的目录（如桌面），后续用Xftp/WinSCP上传到服务器，避免混乱，文件清单如下：</p>\n<ul>\n<li>\n<p>后端文件：backend1-publish、backend2-publish（2个后端的.NET8发布文件，可新增backend3-publish等，命名区分）</p>\n</li>\n<li>\n<p>前端文件：frontend1-dist、frontend2-dist（2个前端的Vue打包文件，可新增，命名区分）</p>\n</li>\n<li>\n<p>镜像tar包（离线备用）：multi-service-images.tar（含所有所需镜像：后端运行时、前端代理、3种数据库、Redis，解决网络拉取超时）</p>\n</li>\n<li>\n<p>配置文件：</p>\n<ul>\n<li>\n<p>nginx.conf（Nginx核心配置，实现多前端/多后端分流）</p>\n</li>\n<li>\n<p>数据库配置：my.cnf（MySQL）、postgresql.conf（PostgreSQL）、sqlserver.conf（SQL Server，可选）</p>\n</li>\n<li>\n<p>数据库初始化SQL：init-mysql.sql、init-postgresql.sql、init-sqlserver.sql（对应不同数据库，创建库、表、初始化数据）</p>\n</li>\n<li>\n<p>docker-compose.yml（核心编排文件，管理所有服务，含多数据库可选配置）</p>\n</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/157572/202602/157572-20260212102640244-1087151636.png\" /></p>\n<h1 id=\"二前期基础准备工作必做奠定部署基础\">二、前期基础准备工作（必做，奠定部署基础）</h1>\n<p>无论后续用哪种数据库、部署多少服务，这部分工作都是基础，一次性做好，避免后续重复操作。</p>\n<h2 id=\"1-centos7系统基础配置补充依赖避免报错\">1. CentOS7系统基础配置（补充依赖，避免报错）</h2>\n<p>最小化安装的CentOS7缺少很多基础工具，先安装必要依赖，确保Docker、命令执行正常：</p>\n<pre><code class=\"language-bash\"># 更新系统软件包（可选，建议执行，避免依赖版本过低）\nyum update -y\n\n# 安装基础工具（wget、vim、net-tools等，后续编辑配置、查看端口常用）\nyum install -y wget vim net-tools epel-release\n\n# 安装Docker依赖所需的额外工具（避免后续安装Docker失败）\nyum install -y curl policycoreutils-python-utils\n</code></pre>\n<h2 id=\"2-安装docker-ce稳定版步骤固定\">2. 安装Docker CE（稳定版，步骤固定）</h2>\n<pre><code class=\"language-bash\"># 1. 卸载旧版本Docker（如果之前装过，避免冲突，没装过可跳过）\nyum remove -y docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine\n\n# 2. 配置Docker官方源（CentOS7专属）\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\n# 3. 安装Docker CE 24.0.7（指定版本，避免自动更新到不稳定版本）\nyum install -y docker-ce-24.0.7 docker-ce-cli-24.0.7 containerd.io\n\n# 4. 启动Docker服务，并设置开机自启（关键，多服务需随Docker自动启动）\nsystemctl start docker\nsystemctl enable docker\n\n# 5. 验证Docker安装成功（输出版本号即成功）\ndocker --version\n</code></pre>\n<p>✅ 成功标识：<code>Docker version 24.0.7, build afdd53b</code></p>\n<h2 id=\"3-配置docker镜像加速国内必做避免镜像拉取超时\">3. 配置Docker镜像加速（国内必做，避免镜像拉取超时）</h2>\n<p>Docker默认拉取国外镜像源，国内访问极慢，甚至超时，配置阿里云专属加速（比公共源更稳定）。登录阿里云官网（<a href=\"https://www.aliyun.com/%EF%BC%89%EF%BC%8C%E6%90%9C%E7%B4%A2\" rel=\"noopener nofollow\" target=\"_blank\">https://www.aliyun.com/），搜索</a> “容器镜像服务”，进入 “镜像加速器”，复制自己的专属加速地址（示例：<a href=\"https://xxxxxx.mirror.aliyuncs.com\" rel=\"noopener nofollow\" target=\"_blank\">https://xxxxxx.mirror.aliyuncs.com</a>，替换成自己的）；</p>\n<p><img alt=\"镜像加速器\" src=\"https://img2024.cnblogs.com/blog/157572/202602/157572-20260212102640329-1145206426.png\" /></p>\n<pre><code class=\"language-bash\"># 1. 创建Docker配置目录（如果不存在）\nmkdir -p /etc/docker\n\n# 2. 写入加速配置（替换成自己的阿里云专属加速地址，获取方式：阿里云→容器镜像服务→镜像加速器）\ntee /etc/docker/daemon.json &lt;&lt;-'EOF'\n{\n  \"registry-mirrors\": [\"https://xxxxxx.mirror.aliyuncs.com\", \"https://mirror.ccs.tencentyun.com\"]\n}\nEOF\n\n# 3. 重新加载配置，重启Docker，让加速生效\nsystemctl daemon-reload\nsystemctl restart docker\n\n# 4. 验证加速配置是否生效（输出配置的加速地址即成功）\ndocker info | grep -A 2 \"Registry Mirrors\"\n</code></pre>\n<p>✅ 成功标识：输出中包含自己配置的阿里云加速地址，无报错。</p>\n<p><img alt=\"阿里云加速地址\" src=\"https://img2024.cnblogs.com/blog/157572/202602/157572-20260212102640225-1082113952.png\" /></p>\n<h2 id=\"4-升级docker-composev2版本支持多服务配置\">4. 升级Docker Compose（V2版本，支持多服务配置）</h2>\n<p>CentOS7默认安装的Docker Compose是1.x版本，不支持多服务的健康检查、依赖条件等配置，升级到V2版本：</p>\n<pre><code class=\"language-bash\"># 1. 删除旧版docker-compose（如果之前装过）\nrm -f /usr/local/bin/docker-compose\n\n# 2. 安装Docker Compose V2（插件形式，稳定，和Docker联动更好）\nyum install -y docker-compose-plugin\n\n# 3. 建立软链接，保持docker-compose命令可用（和旧版用法一致，无需改命令）\nln -s /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose\n\n# 4. 验证升级成功（输出V2版本号即成功）\ndocker-compose --version\n</code></pre>\n<p>✅ 成功标识：<code>Docker Compose version v2.27.1</code>（版本号可略有差异，只要是V2即可）</p>\n<h2 id=\"5-关闭防火墙测试环境-开放端口生产环境\">5. 关闭防火墙（测试环境）/ 开放端口（生产环境）</h2>\n<p>测试环境：直接关闭防火墙，避免端口被拦截，简化配置；生产环境：仅开放所需端口，提升安全性。</p>\n<pre><code class=\"language-bash\"># 测试环境：关闭防火墙并禁止开机自启\nsystemctl stop firewalld\nsystemctl disable firewalld\nsystemctl status firewalld  # 验证，输出inactive即成功\n\n# 生产环境：开放所需端口（示例，根据自己的端口修改）\n# 后端端口：58588、58589；前端端口：6866、6867；数据库端口：3306（MySQL）、5432（PostgreSQL）、1433（SQL Server）；Redis端口：6379\nfirewall-cmd --add-port=58588/tcp --permanent\nfirewall-cmd --add-port=58589/tcp --permanent\nfirewall-cmd --add-port=6866/tcp --permanent\nfirewall-cmd --add-port=6867/tcp --permanent\nfirewall-cmd --add-port=3306/tcp --permanent\nfirewall-cmd --add-port=5432/tcp --permanent\nfirewall-cmd --add-port=1433/tcp --permanent\nfirewall-cmd --add-port=6379/tcp --permanent\nfirewall-cmd --reload  # 生效配置\nfirewall-cmd --list-ports  # 验证，查看开放的端口清单\n</code></pre>\n<h2 id=\"6-服务器目录结构整理规范目录避免后期混乱\">6. 服务器目录结构整理（规范目录，避免后期混乱）</h2>\n<p>将本地准备的所有文件，上传到服务器的<code>/root/multi-service-docker</code>目录（自定义目录，方便记忆），最终目录结构如下（支持多后端、多前端、多数据库）：</p>\n<pre><code class=\"language-bash\">multi-service-docker/                # 项目根目录（所有文件都放在这里）\n├── docker-compose.yml               # 核心编排文件（管理所有服务，含多数据库配置）\n# 后端目录（2个，可扩展更多）\n├── backend1/                        # 第一个后端API服务\n│   └── publish/                     # 后端1的.NET8发布文件（含核心DLL、appsettings.json）\n├── backend2/                        # 第二个后端API服务\n│   └── publish/                     # 后端2的.NET8发布文件\n# 前端目录（2个，可扩展更多）\n├── frontend1/                       # 第一个前端Web（如管理端）\n│   └── dist/                        # 前端1的Vue打包文件（index.html、css、js）\n├── frontend2/                       # 第二个前端Web（如用户端）\n│   └── dist/                        # 前端2的Vue打包文件\n# Nginx配置目录\n├── nginx/\n│   └── nginx.conf                   # Nginx核心配置（多前端/多后端分流）\n# 数据库配置目录（3种数据库，按需使用）\n├── mysql/\n│   ├── my.cnf                       # MySQL配置文件\n│   └── init-mysql.sql               # MySQL初始化SQL\n├── postgresql/\n│   ├── postgresql.conf              # PostgreSQL配置文件\n│   └── init-postgresql.sql          # PostgreSQL初始化SQL\n├── sqlserver/\n│   ├── sqlserver.conf               # SQL Server配置文件（可选）\n│   └── init-sqlserver.sql           # SQL Server初始化SQL\n# 离线镜像包（备用）\n└── multi-service-images.tar         # 所有所需镜像的离线包\n</code></pre>\n<p>✅ 上传方法：用 MobaXterm/Xftp/WinSCP连接服务器（IP：服务器真实IP，账号：root，密码：自己的服务器密码），将本地准备的文件，按上述目录结构，拖到对应文件夹中即可。</p>\n<h1 id=\"三核心方案2个net8后端api--2个vue前端web-基础部署mysql版\">三、核心方案：2个.NET8后端API + 2个Vue前端Web 基础部署（MySQL版）</h1>\n<p>先实现最基础的多服务部署（2后端+2前端+MySQL+Redis+Nginx），掌握核心逻辑后，再扩展其他数据库和场景，新手建议先按此方案部署成功，再进行扩展。</p>\n<h2 id=\"1-编写docker-composeyml核心编排文件\">1. 编写docker-compose.yml（核心编排文件）</h2>\n<p>该文件是多服务部署的核心，管理所有容器的启动、依赖、端口、挂载等配置，注释详细，可直接复制使用，关键配置已标注：</p>\n<pre><code class=\"language-yaml\">version: '3.8'\n\n# 所有服务的集合（多后端、多前端、数据库、Redis、Nginx）\nservices:\n  # === 公共依赖服务：MySQL（基础版，后续可替换为PostgreSQL/SQL Server） ===\n  mysql:\n    image: mysql:8.0                  # 使用MySQL 8.0镜像\n    container_name: multi-mysql       # 自定义容器名，唯一，方便管理\n    restart: always                   # 容器异常退出/服务器重启后，自动重启\n    environment:\n      MYSQL_ROOT_PASSWORD: Root@123456  # MySQL root密码（自定义，建议复杂密码）\n      MYSQL_USER: appuser             # 项目访问MySQL的用户名（自定义）\n      MYSQL_PASSWORD: App@123456      # 项目访问MySQL的密码（自定义）\n      MYSQL_DATABASE: app_db1         # 后端1所用数据库名\n      MYSQL_DATABASE2: app_db2        # 后端2所用数据库名（分库部署，可选）\n      TZ: Asia/Shanghai               # 强制容器时区为东八区（解决时差问题）\n    ports:\n      - \"3306:3306\"                   # 端口映射：宿主机3306 → 容器内3306（本地工具可连接）\n    volumes:\n      - ./mysql/my.cnf:/etc/mysql/conf.d/my.cnf  # 挂载MySQL配置文件\n      - ./mysql/init-mysql.sql:/docker-entrypoint-initdb.d/init-mysql.sql  # 挂载初始化SQL\n      - mysql-data:/var/lib/mysql     # 数据卷：持久化MySQL数据（容器删除不丢失）\n      - /etc/localtime:/etc/localtime:ro  # 挂载宿主机时区文件，双重保障时差\n    command: --lower_case_table_names=1  # MySQL不区分大小写（避免表名大小写问题）\n    networks:\n      - multi-service-network         # 加入自定义网络，实现所有容器互通\n    # 健康检查：检测MySQL是否真正就绪，避免后端启动早于MySQL，导致连接失败\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-uappuser\", \"-pApp@123456\"]\n      interval: 5s                    # 每5秒检测一次\n      timeout: 30s                    # 超时时间30秒\n      retries: 10                     # 重试10次，失败则认为容器未就绪\n      start_period: 20s               # 容器启动后，延迟20秒开始检测\n\n  # === 公共依赖服务：Redis（缓存，多后端可共享/隔离） ===\n  redis:\n    image: redis:7-alpine             # 轻量版Redis，占用资源少\n    container_name: multi-redis       # 唯一容器名\n    restart: always                   # 自动重启\n    ports:\n      - \"6379:6379\"                   # 端口映射：宿主机6379 → 容器内6379\n    volumes:\n      - redis-data:/data              # 数据卷：持久化Redis数据\n    command: redis-server --requirepass \"Redis@123456\"  # Redis密码（自定义）\n    networks:\n      - multi-service-network         # 加入自定义网络\n    environment:\n      TZ: Asia/Shanghai               # 同步东八区时区\n    # Redis健康检查（可选，优化多后端依赖）\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\", \"-a\", \"Redis@123456\"]\n      interval: 3s\n      timeout: 10s\n      retries: 5\n\n  # === 后端API 1（第一个服务，如管理端后端） ===\n  backend1:\n    image: mcr.microsoft.com/dotnet/aspnet:8.0  # .NET8运行时镜像（无需构建，直接运行发布文件）\n    container_name: multi-backend1    # 唯一容器名，区分其他后端\n    restart: always                   # 自动重启\n    ports:\n      - \"58588:58588\"                 # 唯一端口，避免和其他后端冲突\n    depends_on:\n      mysql:\n        condition: service_healthy    # 仅在MySQL健康检查通过（真正就绪）后，才启动后端1\n      redis:\n        condition: service_healthy    # Redis就绪后，启动后端1\n    volumes:\n      - ./backend1/publish:/app       # 挂载后端1的发布目录（核心，容器直接运行发布文件）\n      - /wwwroot/Resources1:/wwwroot/Resources  # 挂载后端1的文件目录（如用户头像，按需挂载）\n    environment:\n      TZ: Asia/Shanghai               # 同步时区\n      ASPNETCORE_URLS: \"http://*:58588\"  # 强制后端1监听58588端口（解决端口不通问题）\n      ASPNETCORE_ENVIRONMENT: Production  # .NET环境（生产环境）\n      # 后端1的MySQL连接字符串（连接MySQL的app_db1库，server用容器名mysql）\n      ConnectionStrings__MySQL: \"server=mysql;port=3306;database=app_db1;user=appuser;password=App@123456;charset=utf8mb4;AllowPublicKeyRetrieval=True;SslMode=None\"\n      # 后端1的Redis连接字符串（server用容器名redis，密码对应上面的Redis密码）\n      ConnectionStrings__Redis: \"redis:6379,password=Redis@123456,defaultDatabase=0,ssl=false,abortConnect=false\"\n    working_dir: /app                 # 容器工作目录，指向挂载的发布目录\n    entrypoint: [\"dotnet\", \"Backend1.WebHost.dll\"]  # 启动后端1的核心DLL（替换为自己的DLL名）\n    networks:\n      - multi-service-network         # 加入自定义网络，可访问MySQL/Redis/其他后端\n\n  # === 后端API 2（第二个服务，如用户端后端） ===\n  backend2:\n    image: mcr.microsoft.com/dotnet/aspnet:8.0  # 和后端1共用.NET8运行时镜像\n    container_name: multi-backend2    # 唯一容器名，区分后端1\n    restart: always                   # 自动重启\n    ports:\n      - \"58589:58589\"                 # 唯一端口，避免和后端1冲突（不可重复）\n    depends_on:\n      mysql:\n        condition: service_healthy    # 依赖MySQL就绪\n      redis:\n        condition: service_healthy    # 依赖Redis就绪\n    volumes:\n      - ./backend2/publish:/app       # 挂载后端2的发布目录（独立目录，避免代码覆盖）\n      - /wwwroot/Resources2:/wwwroot/Resources  # 后端2的文件目录（独立挂载，避免文件混乱）\n    environment:\n      TZ: Asia/Shanghai\n      ASPNETCORE_URLS: \"http://*:58589\"  # 强制后端2监听58589端口\n      ASPNETCORE_ENVIRONMENT: Production\n      # 后端2的MySQL连接字符串（可连接不同库app_db2，实现分库部署）\n      ConnectionStrings__MySQL: \"server=mysql;port=3306;database=app_db2;user=appuser;password=App@123456;charset=utf8mb4;AllowPublicKeyRetrieval=True;SslMode=None\"\n      # 后端2的Redis连接字符串（可指定不同数据库defaultDatabase=1，实现缓存隔离）\n      ConnectionStrings__Redis: \"redis:6379,password=Redis@123456,defaultDatabase=1,ssl=false,abortConnect=false\"\n    working_dir: /app\n    entrypoint: [\"dotnet\", \"Backend2.WebHost.dll\"]  # 后端2的核心DLL（替换为自己的）\n    networks:\n      - multi-service-network\n\n  # === Nginx服务（核心：多前端代理+多后端分流） ===\n  nginx:\n    image: nginx:alpine               # 轻量版Nginx\n    container_name: multi-nginx       # 唯一容器名\n    restart: always                   # 自动重启\n    ports:\n      - \"6866:6866\"                   # 前端1访问端口（唯一）\n      - \"6867:6867\"                   # 前端2访问端口（唯一，避免冲突）\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf  # 挂载Nginx分流配置\n      - ./frontend1/dist:/usr/share/nginx/html/web1  # 挂载前端1的静态文件\n      - ./frontend2/dist:/usr/share/nginx/html/web2  # 挂载前端2的静态文件\n    depends_on:\n      - backend1                      # 后端1启动后，再启动Nginx（避免前端访问后端失败）\n      - backend2                      # 后端2启动后，再启动Nginx\n    networks:\n      - multi-service-network\n    environment:\n      TZ: Asia/Shanghai\n\n# 数据卷：持久化MySQL、Redis数据（容器删除、docker-compose down不会删除数据）\nvolumes:\n  mysql-data:\n  redis-data:\n\n# 自定义网络：所有服务加入同一网络，容器间可通过「容器名」直接通信，无需配置IP\nnetworks:\n  multi-service-network:\n    driver: bridge\n</code></pre>\n<h2 id=\"2-编写nginx配置nginxconf多服务分流核心\">2. 编写Nginx配置（nginx.conf，多服务分流核心）</h2>\n<p>Nginx的核心作用是：代理多个前端静态文件，将前端的API请求，按路径前缀分流到对应后端，避免端口混乱，配置如下（注释详细）：</p>\n<pre><code class=\"language-nginx\">worker_processes 1;  # 按服务器CPU核心数调整，1核用1，2核用2\n\nevents {\n    worker_connections 1024;  # 最大连接数，足够多服务使用\n}\n\nhttp {\n    include       /etc/nginx/mime.types;  # 引入MIME类型（支持前端静态文件）\n    default_type  application/octet-stream;\n\n    sendfile        on;  # 开启高效文件传输\n    keepalive_timeout  65;  # 连接超时时间\n\n    # === 前端1配置（访问端口：6866，对应管理端） ===\n    server {\n        listen       6866;  # 前端1的访问端口（和docker-compose.yml中Nginx的端口映射一致）\n        server_name  localhost;  # 测试环境用localhost，生产环境可改为域名\n\n        # 前端1的静态文件代理（加载Vue打包后的index.html、css、js）\n        location / {\n            root   /usr/share/nginx/html/web1;  # 对应前端1的dist目录（docker-compose.yml中挂载的路径）\n            index  index.html index.htm;\n            try_files $uri $uri/ /index.html;  # 解决Vue路由刷新404问题（关键）\n        }\n\n        # 前端1调用的后端1API（路径前缀：/api1/，分流到backend1）\n        location /api1/ {\n            proxy_pass http://multi-backend1:58588/;  # 转发到后端1容器（容器名+端口）\n            # 转发请求头，确保后端能获取客户端真实IP、请求地址等信息\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n\n        # 前端1如需调用后端2API（可选，按需配置）\n        location /api2/ {\n            proxy_pass http://multi-backend2:58589/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n    }\n\n    # === 前端2配置（访问端口：6867，对应用户端） ===\n    server {\n        listen       6867;  # 前端2的访问端口（唯一，不重复）\n        server_name  localhost;\n\n        # 前端2的静态文件代理\n        location / {\n            root   /usr/share/nginx/html/web2;  # 对应前端2的dist目录\n            index  index.html index.htm;\n            try_files $uri $uri/ /index.html;  # Vue路由兼容\n        }\n\n        # 前端2调用的后端2API（路径前缀：/api2/，分流到backend2）\n        location /api2/ {\n            proxy_pass http://multi-backend2:58589/;  # 转发到后端2容器\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n\n        # 前端2如需调用后端1API（可选，按需配置）\n        location /api1/ {\n            proxy_pass http://multi-backend1:58588/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n    }\n}\n</code></pre>\n<h2 id=\"3-启动所有服务并验证\">3. 启动所有服务并验证</h2>\n<p>所有配置完成后，一键启动所有服务，然后逐个验证，确保所有服务正常运行。</p>\n<pre><code class=\"language-bash\"># 1. 进入项目根目录（必须在docker-compose.yml所在目录执行命令）\ncd /root/multi-service-docker\n\n# 2. 后台启动所有服务（-d：后台运行，无需手动值守）\ndocker-compose up -d\n\n# 3. 查看所有服务运行状态（关键，确认所有服务都启动成功）\ndocker-compose ps\n</code></pre>\n<p>✅ 成功标识：<code>docker-compose ps</code>输出中，multi-mysql、multi-redis、multi-backend1、multi-backend2、multi-nginx 5个服务的State列，均为<code>Up (healthy)</code>或<code>Up</code>，无Exited状态。</p>\n<h3 id=\"31-逐个验证服务确保无问题\">3.1 逐个验证服务（确保无问题）</h3>\n<ul>\n<li><strong>验证后端1</strong>：访问地址<code>http://服务器IP:58588/swagger</code>（如：<a href=\"http://192.168.1.100:58588/swagger%EF%BC%89\" rel=\"noopener nofollow\" target=\"_blank\">http://192.168.1.100:58588/swagger）</a></li>\n</ul>\n<p>​\t\t✅ 成功标识：浏览器能正常打开Swagger页面，无报错，能看到后端1的所有接口。</p>\n<ul>\n<li>\n<p><strong>验证后端2</strong>：访问地址 <code>http://服务器IP:58589/swagger</code><br />\n✅ 成功标识：正常打开Swagger页面，接口能正常显示。</p>\n</li>\n<li>\n<p><strong>验证前端1</strong>：访问地址 <code>http://服务器IP:6866</code><br />\n✅ 成功标识：能正常打开Vue页面，样式、图片正常，调用<code>/api1/xxx</code>接口能返回正常数据。</p>\n</li>\n<li>\n<p><strong>验证前端2</strong>：访问地址 <code>http://服务器IP:6867</code><br />\n✅ 成功标识：能正常打开Vue页面，调用<code>/api2/xxx</code>接口能返回正常数据。</p>\n</li>\n<li>\n<p><strong>验证MySQL</strong>：用Navicat/DBeaver连接服务器IP:3306，用户名appuser，密码App@123456，能正常连接，能看到app_db1、app_db2两个数据库，以及初始化的表和数据。</p>\n</li>\n<li>\n<p><strong>验证Redis</strong>：用Redis客户端连接服务器IP:6379，密码Redis@123456，能正常执行set、get命令，后端1/2的缓存能正常生效。</p>\n</li>\n</ul>\n<p>❌ 失败排查：若某个服务启动失败或访问不通，执行<code>docker-compose logs -f 服务名</code>（如<code>docker-compose logs -f multi-backend1</code>），查看实时日志，根据日志提示排查问题（如端口冲突、连接串错误、目录挂载失败）。</p>\n<h1 id=\"四扩展方案1替换数据库postgresql--sql-server\">四、扩展方案1：替换数据库（PostgreSQL / SQL Server）</h1>\n<p>实际项目中，可能会用到PostgreSQL（开源、适合复杂查询）或SQL Server（微软生态、适合.NET项目），以下是完整的替换方案，只需修改docker-compose.yml和后端连接串，无需修改前端和Nginx配置。</p>\n<h2 id=\"1-替换为postgresql开源首选适配net6\">1. 替换为PostgreSQL（开源首选，适配.NET6+）</h2>\n<p>PostgreSQL是开源的高性能数据库，兼容性强，适合大多数.NET项目，替换步骤如下：</p>\n<h3 id=\"11-修改docker-composeyml替换mysql为postgresql\">1.1 修改docker-compose.yml（替换MySQL为PostgreSQL）</h3>\n<p>删除原有的mysql服务，新增postgresql服务，其他服务（后端1/2、前端1/2、Redis、Nginx）无需修改，仅修改后端的连接串：</p>\n<pre><code class=\"language-yaml\">version: '3.8'\n\nservices:\n  # === 替换为PostgreSQL服务（替换原有的MySQL） ===\n  postgresql:\n    image: postgres:15                # PostgreSQL 15镜像（稳定版，适配.NET8）\n    container_name: multi-postgresql  # 唯一容器名\n    restart: always\n    environment:\n      POSTGRES_USER: appuser          # 项目访问PostgreSQL的用户名\n      POSTGRES_PASSWORD: App@123456   # 密码（和之前MySQL一致，方便记忆）\n      POSTGRES_DB: app_db1            # 后端1所用数据库\n      POSTGRES_DB2: app_db2           # 后端2所用数据库（分库部署）\n      TZ: Asia/Shanghai               # 同步东八区时区\n    ports:\n      - \"5432:5432\"                   # PostgreSQL默认端口5432\n    volumes:\n      - ./postgresql/postgresql.conf:/var/lib/postgresql/data/postgresql.conf  # 挂载配置文件\n      - ./postgresql/init-postgresql.sql:/docker-entrypoint-initdb.d/init-postgresql.sql  # 挂载初始化SQL\n      - postgresql-data:/var/lib/postgresql/data  # 数据卷：持久化数据\n      - /etc/localtime:/etc/localtime:ro\n    networks:\n      - multi-service-network\n    # 健康检查：检测PostgreSQL是否就绪\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U appuser -d app_db1\"]\n      interval: 5s\n      timeout: 30s\n      retries: 10\n      start_period: 20s\n\n  # === Redis服务（不变） ===\n  redis:\n    image: redis:7-alpine\n    container_name: multi-redis\n    restart: always\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis-data:/data\n    command: redis-server --requirepass \"Redis@123456\"\n    networks:\n      - multi-service-network\n    environment:\n      TZ: Asia/Shanghai\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\", \"-a\", \"Redis@123456\"]\n      interval: 3s\n      timeout: 10s\n      retries: 5\n\n  # === 后端1服务（仅修改MySQL连接串为PostgreSQL连接串） ===\n  backend1:\n    image: mcr.microsoft.com/dotnet/aspnet:8.0\n    container_name: multi-backend1\n    restart: always\n    ports:\n      - \"58588:58588\"\n    depends_on:\n      postgresql:  # 依赖改为postgresql，而非mysql\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    volumes:\n      - ./backend1/publish:/app\n      - /wwwroot/Resources1:/wwwroot/Resources\n    environment:\n      TZ: Asia/Shanghai\n      ASPNETCORE_URLS: \"http://*:58588\"\n      ASPNETCORE_ENVIRONMENT: Production\n      # 后端1的PostgreSQL连接串（替换原有的MySQL连接串）\n      ConnectionStrings__PostgreSQL: \"Host=postgresql;Port=5432;Database=app_db1;Username=appuser;Password=App@123456;Pooling=true;Timeout=30;\"\n      # Redis连接串（不变）\n      ConnectionStrings__Redis: \"redis:6379,password=Redis@123456,defaultDatabase=0,ssl=false,abortConnect=false\"\n    working_dir: /app\n    entrypoint: [\"dotnet\", \"Backend1.WebHost.dll\"]\n    networks:\n      - multi-service-network\n\n  # === 后端2服务（仅修改连接串） ===\n  backend2:\n    image: mcr.microsoft.com/dotnet/aspnet:8.0\n    container_name: multi-backend2\n    restart: always\n    ports:\n      - \"58589:58589\"\n    depends_on:\n      postgresql:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    volumes:\n      - ./backend2/publish:/app\n      - /wwwroot/Resources2:/wwwroot/Resources\n    environment:\n      TZ: Asia/Shanghai\n      ASPNETCORE_URLS: \"http://*:58589\"\n      ASPNETCORE_ENVIRONMENT: Production\n      # 后端2的PostgreSQL连接串\n      ConnectionStrings__PostgreSQL: \"Host=postgresql;Port=5432;Database=app_db2;Username=appuser;Password=App@123456;Pooling=true;Timeout=30;\"\n      # Redis连接串（不变）\n      ConnectionStrings__Redis: \"redis:6379,password=Redis@123456,defaultDatabase=1,ssl=false,abortConnect=false\"\n    working_dir: /app\n    entrypoint: [\"dotnet\", \"Backend2.WebHost.dll\"]\n    networks:\n      - multi-service-network\n\n  # === Nginx服务（不变） ===\n  nginx:\n    image: nginx:alpine\n    container_name: multi-nginx\n    restart: always\n    ports:\n      - \"6866:6866\"\n      - \"6867:6867\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./frontend1/dist:/usr/share/nginx/html/web1\n      - ./frontend2/dist:/usr/share/nginx/html/web2\n    depends_on:\n      - backend1\n      - backend2\n    networks:\n      - multi-service-network\n    environment:\n      TZ: Asia/Shanghai\n\n# 数据卷：替换为postgresql-data，删除mysql-data\nvolumes:\n  postgresql-data:\n  redis-data:\n\n# 自定义网络（不变）\nnetworks:\n  multi-service-network:\n    driver: bridge\n</code></pre>\n<h3 id=\"12-后端项目修改关键\">1.2 后端项目修改（关键）</h3>\n<ul>\n<li>\n<ol>\n<li>后端项目中，安装PostgreSQL依赖包：在VS2022中，右键项目→管理NuGet程序包，搜索并安装<code>Npgsql.EntityFrameworkCore.PostgreSQL</code>（适配.NET8的版本）；</li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li>修改appsettings.json：将原来的<code>ConnectionStrings:MySQL</code>，改为<code>ConnectionStrings:PostgreSQL</code>，对应docker-compose.yml中的连接串；</li>\n</ol>\n</li>\n<li>\n<ol start=\"3\">\n<li>\n<p>修改Program.cs：如使用EF Core的数据库提供器，从MySQL改为PostgreSQL，示例：</p>\n<blockquote>\n<p>// 原来的MySQL配置<br />\nbuilder.Services.AddDbContext(options =&gt; options.UseMySql(builder.Configuration.GetConnectionString(\"MySQL\"), new MySqlServerVersion(new Version(8, 0, 36))));</p>\n<p>// 改为PostgreSQL配置<br />\nbuilder.Services.AddDbContext(options =&gt; options.UseNpgsql(builder.Configuration.GetConnectionString(\"PostgreSQL\")));</p>\n</blockquote>\n</li>\n</ol>\n</li>\n<li>\n<ol start=\"4\">\n<li>重新发布后端1/2项目，将新的publish文件夹，上传到服务器对应目录，覆盖原来的文件。</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"13-启动并验证\">1.3 启动并验证</h3>\n<pre><code class=\"language-bash\">cd /root/multi-service-docker\n# 停止并删除原有容器（避免冲突）\ndocker-compose down\n# 启动新服务\ndocker-compose up -d\n# 查看状态\ndocker-compose ps\n</code></pre>\n<p>✅ 验证：和基础方案一致，访问前端、后端、PostgreSQL（用Navicat连接服务器IP:5432），确认所有服务正常。</p>\n<h2 id=\"2-替换为sql-server微软生态适合net项目\">2. 替换为SQL Server（微软生态，适合.NET项目）</h2>\n<p>SQL Server是微软推出的关系型数据库，和.NET生态兼容性极佳，适合企业级.NET项目，替换步骤如下（类似PostgreSQL）：</p>\n<h3 id=\"21-修改docker-composeyml替换mysql为sql-server\">2.1 修改docker-compose.yml（替换MySQL为SQL Server）</h3>\n<pre><code class=\"language-yaml\">version: '3.8'\n\nservices:\n  # === 替换为SQL Server服务 ===\n  sqlserver:\n    image: mcr.microsoft.com/mssql/server:2022-latest  # SQL Server 2022镜像\n    container_name: multi-sqlserver  # 唯一容器名\n    restart: always\n    environment:\n      ACCEPT_EULA: \"Y\"                # 必须设置为Y，接受SQL Server许可协议\n      SA_PASSWORD: \"App@12345678\"     # SA密码（复杂度要求：至少8位，含字母+数字+特殊符号）\n      MSSQL_PID: \"Express\"            # 版本：Express（免费版，适合测试/小型项目）\n      TZ: Asia/Shanghai               # 同步时区\n    ports:\n      - \"1433:1433\"                   # SQL Server默认端口1433\n    volumes:\n      - ./sqlserver/sqlserver.conf:/var/opt/mssql/mssql.conf  # 挂载配置文件\n      - ./sqlserver/init-sqlserver.sql:/docker-entrypoint-initdb.d/init-sqlserver.sql  # 初始化SQL\n      - sqlserver-data:/var/opt/mssql  # 数据卷：持久化数据\n      - /etc/localtime:/etc/localtime:ro\n    networks:\n      - multi-service-network\n    # 健康检查：检测SQL Server是否就绪\n    healthcheck:\n      test: [\"CMD-SHELL\", \"/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P App@12345678 -Q 'SELECT 1'\"]\n      interval: 10s\n      timeout: 30s\n      retries: 10\n      start_period: 30s  # SQL Server启动较慢，延迟30秒开始检测\n\n  # === Redis服务（不变） ===\n  redis:\n    image: redis:7-alpine\n    container_name: multi-redis\n    restart: always\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis-data:/data\n    command: redis-server --requirepass \"Redis@123456\"\n    networks:\n      - multi-service-network\n    environment:\n      TZ: Asia/Shanghai\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\", \"-a\", \"Redis@123456\"]\n      interval: 3s\n      timeout: 10s\n      retries: 5\n\n  # === 后端1服务（仅修改连接串） ===\n  backend1:\n    image: mcr.microsoft.com/dotnet/aspnet:8.0\n    container_name: multi-backend1\n    restart: always\n    ports:\n      - \"58588:58588\"\n    depends_on:\n      sqlserver:  # 依赖改为sqlserver\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    volumes:\n      - ./backend1/publish:/app\n      - /wwwroot/Resources1:/wwwroot/Resources\n    environment:\n      TZ: Asia/Shanghai\n      ASPNETCORE_URLS: \"http://*:58588\"\n      ASPNETCORE_ENVIRONMENT: Production\n      # 后端1的SQL Server连接串\n      ConnectionStrings__SQLServer: \"Server=sqlserver,1433;Database=app_db1;User ID=sa;Password=App@12345678;TrustServerCertificate=True;\"\n      # Redis连接串（不变）\n      ConnectionStrings__Redis: \"redis:6379,password=Redis@123456,defaultDatabase=0,ssl=false,abortConnect=false\"\n    working_dir: /app\n    entrypoint: [\"dotnet\", \"Backend1.WebHost.dll\"]\n    networks:\n      - multi-service-network\n\n  # === 后端2服务（仅修改连接串） ===\n  backend2:\n    image: mcr.microsoft.com/dotnet/aspnet:8.0\n    container_name: multi-backend2\n    restart: always\n    ports:\n      - \"58589:58589\"\n    depends_on:\n      sqlserver:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    volumes:\n      - ./backend2/publish:/app\n      - /wwwroot/Resources2:/wwwroot/Resources\n    environment:\n      TZ: Asia/Shanghai\n      ASPNETCORE_URLS: \"http://*:58589\"\n      ASPNETCORE_ENVIRONMENT: Production\n      # 后端2的SQL Server连接串\n      ConnectionStrings__SQLServer: \"Server=sqlserver,1433;Database=app_db2;User ID=sa;Password=App@12345678;TrustServerCertificate=True;\"\n      # Redis连接串（不变）\n      ConnectionStrings__Redis: \"redis:6379,password=Redis@123456,defaultDatabase=1,ssl=false,abortConnect=false\"\n    working_dir: /app\n    entrypoint: [\"dotnet\", \"Backend2.WebHost.dll\"]\n    networks:\n      - multi-service-network\n\n  # === Nginx服务（不变） ===\n  nginx:\n    image: nginx:alpine\n    container_name: multi-nginx\n    restart: always\n    ports:\n      - \"6866:6866\"\n      - \"6867:6867\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./frontend1/dist:/usr/share/nginx/html/web1\n      - ./frontend2/dist:/usr/share/nginx/html/web2\n    depends_on:\n      - backend1\n      - backend2\n    networks:\n      - multi-service-network\n    environment:\n      TZ: Asia/Shanghai\n\n# 数据卷：替换为sqlserver-data\nvolumes:\n  sqlserver-data:\n  redis-data:\n\n# 自定义网络（不变）\nnetworks:\n  multi-service-network:\n    driver: bridge\n</code></pre>\n<h3 id=\"22-后端项目修改\">2.2 后端项目修改</h3>\n<ul>\n<li>\n<p>安装SQL Server依赖包：在VS2022中，安装<code>Microsoft.EntityFrameworkCore.SqlServer</code>（适配.NET8的版本）；</p>\n</li>\n<li>\n<p>修改appsettings.json：将<code>ConnectionStrings:MySQL</code>改为<code>ConnectionStrings:SQLServer</code>，对应docker-compose.yml中的连接串；</p>\n</li>\n</ul>\n<h1 id=\"五相关参考\">五、相关参考</h1>\n<p>如果本文对你有一点点帮助，点个赞支持一下吧，你的每一个【赞】都是我创作的最大动力 _</p>\n<p>更多技术文章请往:</p>\n<p><a href=\"http://www.guosisoft.com/article\" rel=\"noopener nofollow\" target=\"_blank\">http://www.guosisoft.com/article</a></p>\n<p><a href=\"http://www.rdiframework.net/article\" rel=\"noopener nofollow\" target=\"_blank\">http://www.rdiframework.net/article</a></p>\n<p>大家一起共同交流和进步呀!!</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <span style=\"font-size: 10pt;\">\n</span>\n<p>\n\t<br />\n</p>\n<p id=\"mySignature\">\n\t<span style=\"font-size: 10pt;\">作者：</span>\n\t<strong>\n\t\t<span style=\"color: red; font-size: 12px;\">\n\t\t\t<a href=\"http://www.guosisoft.com/\" target=\"_blank\">\n\t\t\t\t<span>\n\t\t\t\t\t<span style=\"font-size: 10pt;\">RDIF</span>\n\t\t\t\t</span>\n\t\t\t</a>\n\t\t</span>\n\t</strong>\n\t<br />\n\t<span style=\"font-size: 10pt;\">出处：</span>\n\t<a href=\"http://www.cnblogs.com/huyong/\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">http://www.cnblogs.com/huyong/</span>\n\t</a>\n\t<br />\n\t<span style=\"font-size: 10pt;\">Email：</span>\n\t<a href=\"mailto:406590790@qq.com\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">406590790@qq.com</span>\n\t</a>\n\t<br />\n\t<span style=\"font-size: 10pt;\">QQ：</span>\n\t<span style=\"font-size: 10pt;\">406590790</span>\n\t<br />\n\t<span style=\"font-size: 10pt;\">微信：</span>\n\t<span style=\"font-size: 10pt;\">13005007127(同手机号)</span>\n\t<br />\n\t<span style=\"font-size: 10pt;\">框架官网：</span>  \n   <a href=\"http://www.guosisoft.com/\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">http://www.guosisoft.com/</span>\n\t</a>\n  &nbsp;&nbsp;&nbsp;\n\t<a href=\"http://www.rdiframework.net/\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">http://www.rdiframework.net/</span>\n\t</a>\n\t<br />\n\t<span style=\"font-size: 10pt;\">框架其他博客：</span>\n\t<a href=\"http://blog.csdn.net/chinahuyong\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">http://blog.csdn.net/chinahuyong</span>\n\t</a>\n\t<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t<a href=\"http://www.cnblogs.com/huyong\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">http://www.cnblogs.com/huyong</span>\n\t</a>\n\t<br />\n\t<a href=\"http://www.guosisoft.com/\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">国思RDIF开发框架</span>\n\t</a>，\n\t<span style=\"font-size: 10pt; color: #FFFFFF; background-color: #009900;\">给用户和开发者最佳的.Net框架平台方案，为企业快速构建跨平台、企业级的应用提供强大支持。</span>\n\t<br />\n\t<span style=\"font-size: 10pt;\">关于作者：系统架构师、信息系统项目管理师、DBA。专注于微软平台项目架构、管理和企业解决方案，多年项目开发与管理经验，曾多次组织并开发多个大型项目，在面向对象、面向服务以及数据库领域有一定的造诣。现主要从事基于</span>\n\t<a href=\"http://www.guosisoft.com/\" target=\"_blank\">\n\t\t<span style=\"font-size: 10pt;\">RDIF</span>\n\t</a>\n\t<span style=\"font-size: 10pt;\">框架的技术开发、咨询工作，主要服务于金融、医疗卫生、铁路、电信、物流、物联网、制造、零售等行业。</span>\n\t<br />\n\t<span style=\"font-size: 10pt;\">如有问题或建议，请多多赐教！</span>\n\t<br />\n\t<span style=\"font-size: 10pt;\">本文版权归作者和CNBLOGS博客共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，如有问题，可以通过微信、邮箱、QQ等联系我，非常感谢。</span>\n</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 10:44</span>&nbsp;\n<a href=\"https://www.cnblogs.com/huyong\">.NET快速开发框架</a>&nbsp;\n阅读(<span id=\"post_view_count\">168</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "为每个同事部署一个 OpenClaw，安全快速的体验 OpenClaw的魅力",
      "link": "https://www.cnblogs.com/xguo/p/19607199",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xguo/p/19607199\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 10:20\">\n    <span>为每个同事部署一个 OpenClaw，安全快速的体验 OpenClaw的魅力</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"为每个同事部署一个 OpenClaw，安全快速的体验 OpenClaw的魅力\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/57355/202602/57355-20260212101930780-112933356.png\" />\n        最快速度拉起 OpenClaw（Clawdbot, Moltbot）。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"agent-sandbox部署神器为你公司每个同事部署一个openclawclawdbot-moltbot快速体验openclawclawdbot-moltbot的魅力\">Agent-Sandbox部署神器，为你公司每个同事部署一个OpenClaw（Clawdbot, Moltbot），快速体验OpenClaw（Clawdbot, Moltbot）的魅力</h1>\n<p>名字变迁：Clawdbot -&gt; Moltbot -&gt; OpoenClaw</p>\n<p>用到的工具：<a href=\"https://github.com/agent-sandbox/agent-sandbox\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/agent-sandbox/agent-sandbox</a></p>\n<h2 id=\"效果\">效果：</h2>\n<p><img alt=\"20260130165008\" height=\"1020\" src=\"https://img2024.cnblogs.com/blog/57355/202602/57355-20260212101717131-648382280.png\" width=\"1300\" /></p>\n<p><img alt=\"20260130165103\" height=\"1020\" src=\"https://img2024.cnblogs.com/blog/57355/202602/57355-20260212101724909-1058470393.png\" width=\"1300\" /></p>\n<h2 id=\"一用agent-sandbox-中创建一个-openclaw-沙箱\">一，用Agent-Sandbox 中创建一个 OpenClaw 沙箱</h2>\n<p>在 Agent-Sandbox 中，所有沙箱的创建都通过同一个 RESTful API：<code>POST /api/v1/sandbox</code>。</p>\n<p>当你安装好 Agent-Sandbox，只需要一行 <code>curl</code> 就能在集群中拉起一个 OpenClaw 实例：</p>\n<pre><code class=\"language-shell\">curl --location 'http://agent-sandbox.your-host.com/api/v1/sandbox' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\"name\":\"openclaw1\",\"template\":\"openclaw\"}'\n</code></pre>\n<pre><code class=\"language-json\">{\n  \"code\": \"0\",\n  \"data\": \"Sandbox openclaw-alice created successfully\"\n}\n</code></pre>\n<p>这一步，就已经在你的 Kubernetes 集群里为某位同事拉起了一个完整可用的 OpenClaw 实例。</p>\n<h2 id=\"他的访问地址会是\">他的访问地址会是：</h2>\n<p><a href=\"http://localhost:10000/sandbox/openclaw1\" rel=\"noopener nofollow\" target=\"_blank\">http://localhost:10000/sandbox/openclaw1</a></p>\n<h2 id=\"二openclaw-配置\">二、OpenClaw 配置</h2>\n<p>默认配置示例如下：</p>\n<pre><code class=\"language-json\">{\n  \"models\": {\n    \"providers\": {\n      \"custom-1\": {\n        \"baseUrl\": \"https://xxx.com/v1\",\n        \"apiKey\": \"fe87c9e9-f399-49ca-98da-2f2404a249c2\",\n        \"auth\": \"api-key\",\n        \"api\": \"openai-completions\",\n        \"models\": []\n      }\n    }\n  },\n  \"agents\": {\n    \"defaults\": {\n      \"model\": {\"primary\": \"custom-1/glm-4.7\" },\n      \"workspace\": \"/root/.openclaw/workspace\",\n      \"maxConcurrent\": 4,\n      \"subagents\": {\n        \"maxConcurrent\": 8\n      }\n    }\n  },\n  \"gateway\": {\n    \"port\": 18789,\n    \"mode\": \"local\",\n    \"bind\": \"lan\",\n    \"controlUi\": {\n      \"allowInsecureAuth\": true\n    }\n  }\n}\n</code></pre>\n<p>模板中的 <code>openclaw.json</code> 给出了一个默认配置示例，包括：</p>\n<ul>\n<li><strong>模型配置</strong>：示例中使用了名为 <code>custom-1/glm-4.7</code> 的模型，你可以根据公司内部模型网关进行调整。</li>\n<li><strong>网关参数</strong>：\n<ul>\n<li>端口：<code>18789</code></li>\n<li>绑定模式：<code>lan</code></li>\n<li>认证方式：密码登录（示例密码为 <code>1</code>）。</li>\n</ul>\n</li>\n</ul>\n<p>之后访问 <a href=\"http://localhost:10000/sandbox/openclaw1\" rel=\"noopener nofollow\" target=\"_blank\">http://localhost:10000/sandbox/openclaw1</a> 即可进入 OpenClaw 界面，修改大模型参数，</p>\n<h3 id=\"1修改大模型provider\">1，修改大模型Provider</h3>\n<p><img alt=\"img_1\" src=\"https://img2024.cnblogs.com/blog/57355/202602/57355-20260212101755519-621083252.png\" /></p>\n<h3 id=\"2修改agent默认大模型名称\">2，修改Agent默认大模型名称</h3>\n<p><img alt=\"img\" src=\"https://img2024.cnblogs.com/blog/57355/202602/57355-20260212101805822-1587622280.png\" /></p>\n<p>根据需要调整模型和网关配置，即可开始使用 OpenClaw 了！</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 10:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xguo\">i'm老土豆</a>&nbsp;\n阅读(<span id=\"post_view_count\">315</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}