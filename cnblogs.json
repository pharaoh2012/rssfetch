{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "接口测试基础概念",
      "link": "https://www.cnblogs.com/xi-yongqi/p/19623710",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xi-yongqi/p/19623710\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 23:43\">\n    <span>接口测试基础概念</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h3 id=\"接口测试\">接口测试</h3>\n<h4 id=\"接口的概念\">接口的概念</h4>\n<ul>\n<li>接口⼀般来说有两种，⼀种是程序内部的接口，⼀种是系统对外的接口。</li>\n<li>程序内部的接口：方法与方法之间，模块与模块之间的交互，程序内部抛出的接口，比如贴吧系统，有登录模块、发帖模块等等，那你要发帖就必须先登录，要发帖就得登录，那么这两个模块就得有交互，它就会抛出⼀个接⼝，供内部系统进行调用。</li>\n<li>系统对外的接口：比如你要从别的⽹站或服务器上获取资源或信息，别人肯定不会把数据库共享给你，他只能给你提供⼀个他们写好的方法来获取数据，你引用他提供的接口就能使用他写好的⽅法，从而达到数据共享的⽬的，比如说咱们用的app、网址这些它在进⾏数据处理的时候都是通过接⼝来进行调用的。</li>\n<li>接口类型有很多，如HTTP\u0001API接口、RPC等等。</li>\n</ul>\n<h4 id=\"接口测试-1\">接口测试</h4>\n<h5 id=\"概念\">概念</h5>\n<ul>\n<li>接口测试是测试系统组件间接口的⼀种测试。接⼝测试主要⽤于检测外部系统与系统之间以及内部各个子系统之间的交互点。测试的重点是要检查数据的交换，传递和控制管理过程，以及系统间的相互逻辑依赖关系等。</li>\n<li>简而言之，所谓接⼝测试就是通过测试不同情况下的⼊参与之相应的出参信息来判断接口是否符合或满足相应的功能性、安全性要求。</li>\n</ul>\n<h5 id=\"接口组成\">接口组成</h5>\n<ul>\n<li>接口文档示例：<a href=\"https://developers.weixin.qq.com/minigame/dev/api-backend/open-api/access-token/auth.getAccessToken.html\" rel=\"noopener nofollow\" target=\"_blank\">https://developers.weixin.qq.com/minigame/dev/api-backend/open-api/access-token/auth.getAccessToken.html</a></li>\n<li>由接口文档可知，接口至少应有请求地址、请求⽅法、请求参数（⼊参和出参）组成，部分接口有请求头 header 。</li>\n</ul>\n<h5 id=\"接口测试重要性\">接口测试重要性</h5>\n<ul>\n<li>可以发现很多在页面上操作发现不了的bug</li>\n<li>检查系统的异常处理能力</li>\n<li>检查系统的安全性、稳定性</li>\n<li>前端随便变，接口测好了，后端不用变</li>\n</ul>\n<h5 id=\"如何执行接口测试\">如何执行接口测试</h5>\n<ul>\n<li>在进行接口测试前，还需要了解以下内容</li>\n</ul>\n<ol>\n<li><a href=\"https://www.cnblogs.com/xi-yongqi/p/19161070\" target=\"_blank\">get和post请求</a></li>\n<li>http状态码：</li>\n</ol>\n<ul>\n<li>每发出⼀个http请求之后，都会有⼀个响应，http本⾝会有⼀个状态码，来标识这个请求是否成功，常见的状态码有以下几种：\n<ul>\n<li>2开头的都表示这个请求发送成功，最常见的就是200，就代表这个请求是ok的，服务器也返回了。</li>\n<li>3开头的代表重定向，常见的有301永久重定向，302临时重定向。</li>\n<li>400代表客⼾端发送的请求有语法错误，401代表访问的页面没有授权，403表示没有权限访问这个页面，404代表没有这个页面</li>\n<li>5开头的代表服务器有异常，500代表服务器内部异常，504代表服务器端超时，没返回结果</li>\n</ul>\n</li>\n<li>接口测试分两步走：通过接口设计用例+结合业务逻辑来设计用例</li>\n</ul>\n<h3 id=\"接口自动化测试\">接口自动化测试</h3>\n<h4 id=\"概念-1\">概念</h4>\n<ul>\n<li>接口自动化是通过对接口进行测试和模拟，以确保软件系统内部的各个组件能够正确地相互通信和交换数据。接口自动化测试可以显著提⾼测试效率和准确性。因为接⼝测试专注于测试系统内部的逻辑和数据传输，而不是像UI测试那样关注⽤⼾的操作和交互。同时，由于接口测试直接针对系统内部的结构和功能，可以更容易地发现和定位问题，减少测试成本和时间。</li>\n</ul>\n<h4 id=\"接口自动化流程\">接口自动化流程</h4>\n<ol>\n<li>需求分析</li>\n</ol>\n<ul>\n<li>分析请求：明确接口的URL、请求方法（如get、post、PUT、DELETE等）、请求头、请求参数和请求体等信息。</li>\n<li>分析响应：确定接口返回的数据格式、状态码以及可能的错误信息。</li>\n</ul>\n<ol start=\"2\">\n<li>挑选自动化接口</li>\n</ol>\n<ul>\n<li>根据项目的时间、人员安排和接口的复杂度，挑选适合自动化测试的接口。</li>\n<li>优先选择核心业务接口、频繁使用的接口以及容易出错的接⼝进行自动化测试。\n<ul>\n<li>功能复杂度：优先选择功能复杂、逻辑分⽀多的接口进行自动化测试。例如，涉及多种支付方式、多种订单状态转换的订单管理接口，⼿动测试难以全面覆盖所有场景，⾃动化测试可以更高效地进行测试.</li>\n<li>高风险功能：选择对业务影响⼤、风险高的接口进行自动化测试，确保其稳定性和可靠性。例如，涉及资金操作的⽀付接口，⼀旦出现问题可能导致严重的经济损失，因此需要进行充分的自动化测试。</li>\n<li>重复性高：对于需要频繁执行的测试任务，如回归测试中的接口测试，自动化测试可以避免重复手动测试的繁琐和低效，提高测试效率。</li>\n</ul>\n</li>\n</ul>\n<ol start=\"3\">\n<li>设计自动化测试用例</li>\n</ol>\n<ul>\n<li>如果在功能测试阶段已经设计了测试用例，可以直接拿来使用。</li>\n<li>根据接口需求和功能，设计正向测试用例（正常场景）和反向测试用例（异常场景），包括边界值测试、参数组合测试等。</li>\n</ul>\n<ol start=\"4\">\n<li>搭建自动化测试环境</li>\n</ol>\n<ul>\n<li>选择合适的编程语言（如Python、Java等）和开发环境（如PyCharm、IntelliJ IDEA等）来实现自动化测试。</li>\n<li>以Python为例，安装必要的依赖库，如requests用于发送HTTP请求，pytest用于测试框架。</li>\n</ul>\n<ol start=\"5\">\n<li>设计自动化执行框架</li>\n</ol>\n<ul>\n<li>设计⼀个框架来执行测试⽤例，包括报告生成、参数化处理和用例执行逻辑。</li>\n</ul>\n<ol start=\"6\">\n<li>编写代码</li>\n</ol>\n<ul>\n<li>根据设计好的测试用例和框架编写自动化测试脚本。</li>\n</ul>\n<ol start=\"7\">\n<li>执行用例</li>\n</ol>\n<ul>\n<li>使用测试框架（如unittest、pytest）来执行编写的测试用例。</li>\n</ul>\n<ol start=\"8\">\n<li>生成测试报告</li>\n</ol>\n<ul>\n<li>测试完成后，生成测试报告。可以使用工具如HtmlTestRunner或Allure来生成易于阅读的报告。</li>\n</ul>\n<h3 id=\"自动化测试框架---pytest\">自动化测试框架---pytest</h3>\n<h4 id=\"pytest介绍\">pytest介绍</h4>\n<ul>\n<li>pytest 是⼀个非常流行且高效的Python测试框架，它提供了丰富的功能和灵活的用法，使得编写和运行测试用例变得简单而高效。</li>\n<li><a href=\"https://docs.pytest.org/en/stable/getting-started.html\" rel=\"noopener nofollow\" target=\"_blank\">pytest官方文档</a></li>\n</ul>\n<h4 id=\"pytest用例运行规则\">pytest用例运行规则</h4>\n<ol>\n<li>文件名必须以 test_ 开头或者 _test 结尾</li>\n<li>测试类必须以 Test 开头，并且不能有 <strong>init</strong> 方法。</li>\n<li>测试方法必须以 test 开头</li>\n<li>Python类中不可以添加init方法</li>\n</ol>\n<ul>\n<li>由于 pytest 的测试收集机制，测试类中不可以定义 <strong>init</strong> 方法。 pytest 采用自动发现机制来收集测试用例。它会自动实例化测试类并调用其所有以 test 结尾的方法作为测试用例。如果测试类中定义了 <strong>init</strong> 方法，那么当 pytest 实例化该类时， <strong>init</strong> 方法会被调⽤，这可能会掩盖测试类的实际测试逻辑，并引⼊额外的副作用，影响测试结果的准确性。</li>\n</ul>\n<h4 id=\"pytest命令参数\">pytest命令参数</h4>\n<ul>\n<li>pytest 提供了丰富的命令行选项来控制测试的执行。以下是⼀些常用的pytest 命令行参数及其使用说明。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pytest</td>\n<td>在当前目录及其子目录中搜索并运行测试。</td>\n</tr>\n<tr>\n<td>pytest -v</td>\n<td>增加输出的详细程度</td>\n</tr>\n<tr>\n<td>pytest -s</td>\n<td>显示测试中的print语句</td>\n</tr>\n<tr>\n<td>pytest test_module.py</td>\n<td>运行指定的测试模块。</td>\n</tr>\n<tr>\n<td>pytest test_dir/</td>\n<td>运行指定目录下的所有测试。</td>\n</tr>\n<tr>\n<td>pytest -k </td>\n<td>只运行测试名包含指定关键字的测试。</td>\n</tr>\n<tr>\n<td>pytest -m </td>\n<td>只运行标记为指定标记的测试。</td>\n</tr>\n<tr>\n<td>pytest -q</td>\n<td>减少输出的详细程度。</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"pytest配置文件\">pytest配置文件</h4>\n<ul>\n<li>在当前项目下创建 pytest.ini 文件，该文件为 pytest 的配置文件，以下为常见的配置选项：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>addopts</td>\n<td>指定在命令行中默认包含的选项。</td>\n</tr>\n<tr>\n<td>testpaths</td>\n<td>指定搜索测试的目录。</td>\n</tr>\n<tr>\n<td>python_files</td>\n<td>指定发现测试模块时使用的文件匹配模式。</td>\n</tr>\n<tr>\n<td>python_classes</td>\n<td>指定发现测试类时使用的类名前缀或模式。</td>\n</tr>\n<tr>\n<td>python_functions</td>\n<td>指定发现测试函数和方法时使用的函数名前缀或模式。</td>\n</tr>\n<tr>\n<td>norecursedirs</td>\n<td>指定在搜索测试时应该避免递归进入的目录模式。</td>\n</tr>\n<tr>\n<td>markers</td>\n<td>定义测试标记，用于标记测试用例。</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>示例：详细输出 cases 包下文件名以 test_ 开头且方法名以 Test 开头的所有用例</li>\n</ul>\n<pre><code class=\"language-.ini\">[pytest]\naddopts = -vs\ntestpaths = ./cases\npython_files = test_*.py\npython_classes = Test*\n</code></pre>\n<ul>\n<li>配置好 pytest.ini 文件后，命令行执行 pytest 命令即可，无需再额外指定其他参数</li>\n</ul>\n<h4 id=\"前后置\">前后置</h4>\n<ul>\n<li>在测试框架中，前后置是指在执行测试用例前和测试用例后执行⼀些额外的操作，这些操作可以用于设置测试环境、准备测试数据等，以确保测试的可靠性</li>\n<li>pytest 框架提供三种方法做前后置的操作：\n<ul>\n<li>setup_method 和 teardown_method ：这两个方法用于类中的每个测试方法的前置和后置操作。</li>\n<li>setup_class 和 teardown_class ：这两个方法用于整个测试类的前置和后置操作。</li>\n<li>fixture ：这是 pytest 推荐的方式来实现测试用例的前置和后置操作。 fixture 提供了更灵活的控制和更强大的功能。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"参数化\">参数化</h4>\n<ul>\n<li>参数化设计是自动化设计中的⼀个重要组成部分，它通过定义设计参数和规则，使得设计过程更加灵活和可控。pytest中内置的 pytest.mark.parametrize 装饰器允许对测试函数的参数进行参数化。</li>\n<li>在用例上使用参数化</li>\n</ul>\n<pre><code class=\"language-python\">import pytest\n@pytest.mark.parametrize(\"test_input,expected\", [(\"3+5\", 8), (\"2+4\", 6), \n(\"6*9\", 42)])\ndef test_eval(test_input, expected):\n assert eval(test_input) == expected\n</code></pre>\n<ul>\n<li>@parametrize 装饰器定义了三个不同的 (test_input,expected) 元组，以便test_eval 函数将依次使⽤它们运行三次。</li>\n<li>在类上使用参数化</li>\n</ul>\n<pre><code class=\"language-python\">import pytest\n@pytest.mark.parametrize(\"n,expected\", [(1, 2), (3, 4)])\nclass TestClass:\n def test_simple_case(self, n, expected):\n assert n + 1 == expected\n def test_weird_simple_case(self, n, expected):\n assert (n * 1) + 1 == expected\n</code></pre>\n<ul>\n<li>要对模块中的所有测试进行参数化，可以将 pytestmark 全局变量赋值</li>\n</ul>\n<pre><code class=\"language-python\">import pytest\npytestmark = pytest.mark.parametrize(\"n,expected\", [(1, 2), (3, 4)])\nclass TestClass:\n def test_simple_case(self, n, expected):\n assert n + 1 == expected\n def test_weird_simple_case(self, n, expected):\n assert (n * 1) + 1 == expected\n</code></pre>\n<p><strong>除了使用 @parametrize 添加参数化外， pytest.fixture() 允许对 fixture 函数进行参数化。</strong></p>\n<ul>\n<li>自定义参数化数据源</li>\n</ul>\n<pre><code class=\"language-python\">def data_provider():\n return [\"a\", \"b\"]\n# 定义⼀个测试函数，它依赖于上⾯函数的返回值 \n@pytest.mark.parametrize(\"data\", data_provider())\ndef test_data(data):\n assert data != None\n print(f\"Testing with data provider: {data}\")\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 23:43</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xi-yongqi\">我会替风去</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 学习笔记：Agent 的基础应用",
      "link": "https://www.cnblogs.com/owlman/p/19623216",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19623216\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 16:09\">\n    <span>AI 学习笔记：Agent 的基础应用</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记对应的是《[[关于 AI 的学习路线图]]》一文中所规划的第四个学习阶段。其中记录了我学习 AI Agent 的工作原理，并将其应用于实际工作场景的全过程，以及在该过程中所获得的心得体会。同样的，这些内容也将成为我 AI 系列笔记的一部分，被存储在本人 Github 上的<a href=\"https://github.com/owlman/CS_StudyNotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机学习笔记库</a>中，并予以长期维护。</p>\n</blockquote>\n<h2 id=\"ai-agent-简介\">AI Agent 简介</h2>\n<p>在理解了 LLM 在生产环境中所扮演的角色之后，初学者们接下来要思考的问题是：如何让它参与到自己的实际工作中？到目前为止（截至 2026 年 2 月），这个问题最具可行性的解决方案是：构建并使用 AI Agent。</p>\n<h3 id=\"为什么需要-ai-agent\">为什么需要 AI Agent</h3>\n<p>在早期，大多数用户是通过 Web 端或移动端的即时通信应用，主要以文本聊天的方式来使用 LLM 的（例如 ChatGPT、豆包等）。这类应用本质上是基于 HTTP API 构建的人机交互界面，其主要交互模式是“输入文本—生成文本”的往返过程。我们之前在《[[LLM 的部署与测试]]》一文中基于 PyTest 框架编写的测试用例，实际上模拟的就是这种交互模式。</p>\n<p>尽管，这类应用极大地降低了 LLM 的使用门槛，使其成为了一种能惠及普通用户的智能问答工具，但 AI 所能带来的生产力也在很大程度上被局限在了这种即时通信式的交互模式中。因为在这种交互模式下，LLM 只能根据用户当前的输入来生成文本结果，无法主动访问本地环境、调用系统资源或执行实际任务。更重要的是，LLM 在这种模式下并不处于一个持续运行的控制结构之中，它只在收到请求时做出一次性响应，无法负责具体的工作流程与状态管理。</p>\n<p>试想一下，如果 LLM 已经具备了复杂的任务规划与执行能力，我们却把它限制在聊天窗口中，这岂不是太浪费了？正是为了避免这种浪费，并赋予 LLM 在特定环境中“执行操作”的能力，AI 的研究者们重新审视了 AI Agent 这一在 20 世纪 80-90 年代就已经形成体系的概念，并在工程实践领域给了它全新的实现形式。</p>\n<p>关于 AI Agent 这个概念，读者可以参考我之前在《[[关于 AI 的学习路线图]]》中推荐的《人工智能：现代方法》一书给出的定义，原文如下：</p>\n<blockquote>\n<p>An agent is anything that can perceive its environment through sensors and act upon that environment through actuators.</p>\n<p>翻译过来就是：</p>\n<p>任何能够通过传感器感知环境，并通过执行器对环境产生影响的实体，都可以称为 Agent。</p>\n</blockquote>\n<p>这个定义成为了后来所有 AI Agent 应用的理论基础。由此也可以看出，AI Agent 的核心功能并不是提升 LLM 本身的智能水平，而是赋予它与外部系统交互的能力，使其能够参与到真实的工作流程之中。从本质上来说，这其实是 AI 应用在客户端方面的一次角色转变，它现在从单纯的答题工具被转变成了一个可以参与任务执行的系统组件。在特定的应用场景中，这种架构上的转变为工作流程的自动化提供了可行的工程路径。</p>\n<h3 id=\"ai-agent-的工作原理\">AI Agent 的工作原理</h3>\n<p>下面，让我们来了解一下 AI Agent 具体是怎么工作的。在传统聊天式的 AI 应用中，我们可以将其基本的执行模式简单概括为：</p>\n<blockquote>\n<p>用户输入 → 模型推理 → 输出结果 → 结束</p>\n</blockquote>\n<p>这种执行模式本质上是一次性的请求—响应（request-response）结构。即在这种执行模式下，LLM 会在接收到用户输入后生成文本，然后就立即退出当前工作流程，不再参与后续状态管理了。AI Agent 与这类应用的核心差异就在于：它在执行模式中引入了一个可持续运行的控制循环（control loop）。这种循环结构将 LLM 从被动接收用户输入的文本生成器，转变成了用于驱动整个程序执行结构的决策组件。换言之，Agent 的存在将 AI 应用的基本执行模式从“请求—响应”转变成了下面这样一个“感知—决策—执行”的循环结构：</p>\n<blockquote>\n<p>感知环境 → 生成决策 → 执行动作 → 更新环境状态 → 再次感知</p>\n</blockquote>\n<p>这个循环结构会持续运行下去，直到任务完成或满足终止条件。从该执行模式可以看出，一个典型的 AI Agent 应用通常包含以下几个核心组件：</p>\n<ul>\n<li><strong>LLM</strong>：该组件负责理解当前任务目标、分析上下文状态并生成下一步行动决策，不负责直接执行外部操作；</li>\n<li><strong>工具接口</strong>：该组件负责将 LLM 生成的结构化指令转换为实际可执行的操作，例如：调用 API、访问数据库、读写文件、执行系统命令、触发外部服务等。它们通常由开发者定义，并通过函数调用或插件机制暴露给模型；</li>\n<li><strong>状态管理</strong>：该组件负责维护任务的中间状态，例如：当前任务进度、已执行步骤、外部环境变化、历史决策记录等。这些状态通常会被存储在内存变量、数据库、向量存储、文件系统等介质中，如果缺乏有效的状态管理机制，我们就难以构建一个真正的 Agent 应用；</li>\n<li><strong>控制器</strong>：该组件负责驱动循环、判断是否继续执行、解析模型输出、调用对应工具、处理异常与失败重试。从架构角度来看，控制器可被视为 Agent 系统的“骨架”，而 LLM 只是其中的决策模块。</li>\n</ul>\n<p>基于以上核心组件，我们就可以简单地归纳出一个 Agent 应用的工作流程，其主要步骤如下：</p>\n<ol>\n<li>接收任务目标</li>\n<li>将目标与当前状态输入 LLM</li>\n<li>LLM 输出下一步行动计划（通常为结构化格式）</li>\n<li>控制器解析输出</li>\n<li>调用相应工具执行</li>\n<li>更新状态</li>\n<li>判断是否完成任务</li>\n<li>若未完成，则进入下一轮循环</li>\n</ol>\n<p>从工程角度来看，AI Agent 是一种新的系统架构模式，它通过持续运行的控制循环，使模型能够参与真实任务的执行过程，而不仅仅是生成文本结果。</p>\n<h2 id=\"ai-agent-的使用方法\">AI Agent 的使用方法</h2>\n<p>在了解了使用 AI Agent 的必要性及其工作原理之后，接下来就可以正式开始研究如何将它运用到自己的日常工作中了。而当我们要讨论 AI Agent 在实际工作中的使用方法时，首先需要回答的问题是“它运行在哪里、由谁控制、承担什么责任”。不同的运行形态，决定了它在工程系统中的角色边界。下面，让我们按照\"运行在哪里\"这个维度分三类来介绍 AI Agent 的使用方法，以及它们在这些应用场景中所承担的任务角色。</p>\n<h3 id=\"命令行工具型-agent\">命令行工具型 Agent</h3>\n<p>对于大多数开发者而言，以命令行工具的形式使用 AI Agent 是一种更符合工程直觉的方式。它运行在熟悉的终端环境中，可以直接访问文件系统与系统命令，因此看起来类似于自动化脚本。当然了，与传统脚本不同的是，AI Agent 的内部决策路径并非预先编写，而是由 LLM 在循环结构中动态生成。这类 AI Agent 应用的典型代表是 <a href=\"https://github.com/anthropics/claude-code\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code</a>，目前同类的主流应用还包括 <a href=\"https://github.com/anomalyco/opencode\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode</a>、<a href=\"https://github.com/openai/codex\" rel=\"noopener nofollow\" target=\"_blank\">Codex CLI</a>、<a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener nofollow\" target=\"_blank\">Gemini CLI</a>、<a href=\"https://github.com/iflow-ai/iflow-cli\" rel=\"noopener nofollow\" target=\"_blank\">iFlow CLI</a> 等。下面，我们首先要做的就是：先将这些工具安装到自己所在的操作系统中。</p>\n<h4 id=\"安装与配置\">安装与配置</h4>\n<p>命令行工具型 Agent 的安装方式其实是非常简单的。因为，虽然它们各自针对 MacOS/Linux/Windows 系统提供了不同的 bash/powershell 安装脚本，或者基于 homeberw/pacman/scoop 等针对不同操作系统平台的包管理器安装命令，但基本都提供了基于 NPM 这一包管理器的跨平台安装方式。所以，读者在大多数情况下都可以按照以下步骤来安装并使用这些工具：</p>\n<ol>\n<li>\n<p>确保自己所在的操作系统中已经安装了版本在 20.0.0 之上的 Node.js 运行环境，其中自带了 NPM 包管理器；</p>\n</li>\n<li>\n<p>在管理员权限下执行<code>npm install -g &lt;agent-name&gt;@&lt;version&gt;</code>命令，在这里，<code>&lt;agent-name&gt;</code>可以通过查询相关工具的官方网站来获得，而<code>&lt;version&gt;</code>则除了可以是我们在工具官网中查到的具体版本号之外，也可以用<code>latest</code>来表示最新版本。例如，如果我们需要安装最新版本的 OpenCode，就只需要在命令行终端中使用管理员权限执行<code>npm install -g opencode@latest</code>命令即可。</p>\n</li>\n</ol>\n<p>在安装完成之后，我们就可以用 CLI 和 TUI 两种方式来使用这种命令行工具型的 Agent 了。其中，TUI 的方式已经被大家所熟知，它实际上就是一个基于命令行界面的交互式程序，运作方式类似于 Python Shell 或 Node.js REPL，拥有属于自己的独立线程。例如在安装完 OpenCode 之后，我们只需要直接在命令行终端中输入<code>opencode</code>命令（如果想延续之前与 OpenCode 的会话，还在该命令后面加上一个<code>--continue</code>或<code>-c</code>参数），就可以启动它的 TUI 界面了，具体如图 1 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：OpenCode TUI 界面</p>\n<p>在初次进入上次界面时，我们可以对自己使用的 AI Agent 进行一些基本的配置，这些工具的配置方式基本上是大同小异的。一般来说，我们会先使用<code>/model</code>命令设置以下自己默认要使用的 LLM，例如您在图 2 中所看到的就是 OpenCode 的 LLM 选择界面：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：OpenCode LLM 选择界面</p>\n<p>通常情况下，在选择 LLM 之后，这些 AI Agent 会要求我们提供一个 API Key，用于在调用 LLM 时进行身份验证。这个 API key 可以通过登录我们在相应 LLM 官网的个人账户来获得。例如，我在这里选择使用的是智普的 GLM 模型，就需要登录到<a href=\"https://bigmodel.cn/\" rel=\"noopener nofollow\" target=\"_blank\">智普 AI 的官网</a>，并为 OpenCode 创建一个专属的 API Key，如图 3 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：创建智普 AI 的 API Key</p>\n<p>接下来，我们就只需要将上述 API Key 复制到 OpenCode 提示输入 key 的位置，并选择具体要使用的 GLM 版本并确认即可。完成这些配置之后，我们就可以通过一个 AI Agent 版的“Hello World”测试来确认它是否已经可以正常工作了，如图 4 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：OpenCode Hello World 测试</p>\n<p>如果 AI Agent 返回了类似上面这样的信息，就意味着我们已经可以开始使用它进行实际的工作了。除此之外，如果我们还想对 AI Agent 进行一些更复杂的配置，例如强制它只用中文来显示思考过程，以及回答的内容，也可以选择在自己的用户目录下为其创建一个全局的提示词文件。以 OpenCode 为例，其具体步骤如下：</p>\n<ol>\n<li>\n<p>根据自己所在的操作系统为 OpenCode 创建一个全局配置目录。在默认情况下，该目录的路径应该为<code>~/.config/opencode</code>，其中<code>~</code>表示我们的用户目录。</p>\n</li>\n<li>\n<p>在该目录下创建一个名为<code>AGENTS.md</code>的提示词文件，并在其中输入以下内容：</p>\n<pre><code class=\"language-markdown\"># Agent 配置\n\n## 语言设置\n- **默认语言**: 中文\n- **强制使用中文**: 是\n\n## 指令\n- 所有回答必须使用中文\n- 所有思考过程也显示中文\n- 除非用户明确要求使用其他语言提问，否则保持中文回答\n</code></pre>\n</li>\n</ol>\n<p>当然了，我们更多时候会希望上述提示词文件只针对当前项目有效，这可以进行更多个性化的配置。为此，我们也可以选择在该项目的根目录下打开 OpenCode TUI，然后在其中通过执行<code>/init</code>命令来创建一个针对当前项目的<code>AGENTS.md</code>文件，并将上述内容复制到该文件中即可，该命令的具体效果如图 5 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：OpenCode 的项目初始化命令</p>\n<p>至于其他 AI Agent，虽然会在全局配置目录与提示词文件上有各自的名称，但应用的工作流/机制基本是大同小异的，用户只需简单查询一下它们的官方文档，就可以轻松做到举一反三的，例如通过快速查询 Claude Code 的官方文档，立即就会知道它的全局提示词文件路径为<code>~/.claude/claude.md</code>。</p>\n<blockquote>\n<p>顺便说一句题外话，虽然 Claude Code 在各方面都为 AI Agent 应用建立了接近于标准的工作流/机制，但考虑到其官方的某些做法会给中文用户带来诸多没必要的额外配置，我在接下来还是会以 OpenCode 为例进行说明。如果读者想切实了解 Claude Code 的某些具体用法，也可参考本文在“参考资料”一节中提供的视频教程：《Claude Code 教程》。</p>\n</blockquote>\n<h4 id=\"基本操作方式\">基本操作方式</h4>\n<p>下面，让我们来具体介绍一下命令行工具型 Agent 的基本操作方式，正如之前所说，这类命令行工具通常有 CLI 和 TUI 两种使用方式，TUI 会单独打开一个工作线程来执行交互式操作，通常用于执行一些需要使用多轮提示词交互，并确认内容的复杂任务。因此，这些 Agent 应用的 TUI 往往至少会提供“计划（plan）”和“构建（build）”两个模式（个别 Agent 还会提供”自动（auto）“之类的第三种模式，或者在模式名称上存在差异，但其在基本使用逻辑上是一致的），其中，”计划“模式通常没有执行外部命令的权限，主要用于与 LLM 执行多轮交互，并确认某一杂任务的解决方案。例如在之前展示的 OpenCode TUI 中，读者可以在其输入框的下方看到，它默认处于“构建”模式。现在，我们可以通过输入<code>&lt;tab&gt;</code>键来将其切换到“计划”模式，然后再试着让它执行“使用 Python 编写并执行一个 hello world 程序”的操作，就会得到类似图 5 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：OpenCode 的计划模式</p>\n<p>正如读者所见，现在 OpenCode TUI 输入框下面提示其当前处于“计划”模式，并且告诉用户自己当前不能编辑文件和执行程序，然后开始与用户讨论任务的具体解决方案。而当我们切换到“构建”模式时，OpenCode 就会直接执行这个解决方案，并输出类似图 7 的结果：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：OpenCode 的构建模式</p>\n<p>当然了，就上面这种仅需一句简短的提示词就可以完成的任务而言，我们实际上更适合使用 CLI 的方式来执行。这种方式允许我们在 bash/powershell 这类命令行终端程序所在的当前线程中直接执行 AI Agent，并输出结果。例如，如果我们想使用 OpenCode CLI 的方式来编写并执行上面那个 Python 程序，可以直接在命令行终端中输入<code>opencode run \"使用 Python 编写并执行一个 hello world 程序\"</code>命令，并得到类似图 8 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：OpenCode 的 CLI 模式</p>\n<p>如读者所见，上述命令直接在 powershell 所在的当前线程中输出了 OpenCode 的执行结果。这样做的好处，除了避免因一些简单的任务反复启动和关闭 OpenCode TUI 之外，在必要情况下还可以使用 Shell/Python 这样的脚本语言来实现对 AI Agent 应用的批量调用，例如，如果我们想使用 Python 脚本批量调用 OpenCode CLI 来执行 5 个不同的任务，就可以像下面这样编写一个简单的 Python 脚本：</p>\n<pre><code class=\"language-python\">import subprocess\n\ntasks = [\n    \"使用 Python 编写并执行一个 hello world 程序\",\n    \"使用 Python 编写并执行一个计算斐波那契数列的程序\",\n    \"使用 Python 编写并执行一个计算阶乘的程序\",\n    \"使用 Python 编写并执行一个计算素数的程序\",\n    \"使用 Python 编写并执行一个计算回文数的程序\",\n]\n\nfor task in tasks:\n    try:\n        result = subprocess.run(\n            [\"opencode\", \"run\", task],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=120\n        )\n        print(f\"任务成功: {task}\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(f\"任务失败: {task}\")\n        print(e.stderr)\n    except subprocess.TimeoutExpired:\n        print(f\"任务超时: {task}\")\n</code></pre>\n<p>除了<code>opencode run</code>命令之外，我们还可以通过执行<code>opencode -h</code>命令来查看其他可用 CLI 方式执行的 OpenCode 操作，如图 9 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 9</strong>：OpenCode 的 CLI 帮助信息</p>\n<p>虽然，上面这种多次调用<code>opencode run</code>命令的做法，在某些特定的情况下并不是最佳的任务编排方式。例如在某些时候，先将所有的需求写入一个 Markdown 文档中，再将其作为提示词一次性发给 AI Agent 可能会是一种更合适的做法。但是，我们可以基于这一思路发展出许多更复杂的 AI Agent 工作流，例如利用部署在服务端的 Agent 来操作这些命令行工具型的 Agent。下面，就让我们基于 OpenClaw 这一可部署服务型的 AI Agent 来了解一下这一工作流的具体实现方式。</p>\n<h3 id=\"可部署服务型-agent\">可部署服务型 Agent</h3>\n<p>如果我们将命令行工具型的 AI Agent 视为一种增强型的自动化工具，那么以 OpenClaw 为代表的、可在服务端部署的 AI Agent 则就是一种系统级执行单元，二者的差异主要在于运行形态与系统边界。具体来说就是，命令行工具型 Agent 的运行方式通常是：</p>\n<ul>\n<li>被用户触发</li>\n<li>执行一轮或多轮任务</li>\n<li>输出结果</li>\n<li>退出进程</li>\n</ul>\n<p>而可部署服务型 Agent 则具有以下完全不同的特征：</p>\n<ul>\n<li>常驻运行</li>\n<li>通过 HTTP / RPC / WebSocket 等方式对外提供能力</li>\n<li>持续维护会话状态</li>\n<li>支持多用户并发访问</li>\n<li>可以被其他系统调用</li>\n</ul>\n<p>在这种形态下，Agent 就不再是一个功能类似于自动化脚本的增强型工具了，它成为了常驻在操作系统中的一个服务组件。具体来说，如果从程序架构的角度来看，这两种 Agent 的差别主要体现在以下几个方面：</p>\n<ol>\n<li>\n<p>生命周期管理：命令行工具型 Agent 的生命周期通常是一次性的，执行完成即销毁，而可部署服务型 Agent 则具有长生命周期，需要考虑健康检查、日志管理、异常恢复机制。</p>\n</li>\n<li>\n<p>会话与状态管理：命令行工具型 Agent 的状态通常也是一次性的，而可部署服务型 Agent 则需要维护会话状态，这意味着它需要支持用户级会话隔离、长期上下文存储、记忆机制（Memory）以及外部数据库支持。</p>\n</li>\n<li>\n<p>多 Agent 编排能力：一旦 Agent 以系统服务组件的形式存在，它就可以调用其他 Agent，被其他 Agent 调用，参与更复杂的任务链。例如像这样：</p>\n<pre><code class=\"language-plaintext\">用户请求\n↓\n调度 Agent\n↓\n分析 Agent → 代码生成 Agent → 测试 Agent\n↓\n结果汇总\n</code></pre>\n<p>这种执行结构显然已经不再是单纯的工具调用，它关注的实际上已经是任务的编排与调度了。这也就意味着，我们需要在服务型的 Agent 中引入任务队列、消息队列、异步任务调度系统等机制。</p>\n</li>\n</ol>\n<p>下面，让我们以 OpenClaw 为例来具体介绍一下使用这种服务型 Agent 的一些基本工作流。假设，我们现在想使用 OpenClaw 指挥 OpenCode 来完成一个简单的网站重构任务，通常需要按照以下步骤来完成。</p>\n<h4 id=\"步骤-1安装并配置一个-openclaw-服务\">步骤 1：安装并配置一个 OpenClaw 服务</h4>\n<p>正如之前所说，OpenClaw 本质上是一个系统服务，这意味着免不了要赋予它较大的操作权限，基于安全方面的考虑，我个人不建议用户将其安装在自己日常的工作设备上。另外，如果想最大限度地发挥 OpenClaw 的功能，最好要能让它长时间持续运行，并执行一定程度的实际设备管理能力。因此，我们在安装 OpenClaw 时通常需要执行的操作如下：</p>\n<ul>\n<li>\n<p>配置好一台可与我们日常工作设备相连通的独立计算机（如果仅用于学习目的，也可以是一台虚拟机），并在其中安装好操作系统与 Node.js 22.x 以上版本的运行环境。</p>\n</li>\n<li>\n<p>在这台独立计算机上打开命令行终端，并执行<code>npm install -g openclaw@latest</code>命令来安装 OpenClaw。当然了，这是使用跨平台的方式。如果读者不想使用 NPM，也可以通过直接执行 bash/powershell 的安装脚本来完成这个操作，相关命令如下：</p>\n<pre><code class=\"language-bash\"># MacOS/Linux 系统下使用 bash 脚本安装：\ncurl -fsSL https://openclaw.ai/install.sh | bash\n# Windows 系统下使用 powershell 脚本安装：\niwr -useb https://openclaw.ai/install.ps1 | iex\n</code></pre>\n</li>\n<li>\n<p>待安装完成之后，继续执行<code>openclaw onboard --install-daemon</code>命令来启动新手安装向导（如图 10 所示），进一步安装 OpenClaw 的服务端组件（例如飞书机器人、WhatsApp 机器人等），关于这方面的内容，读者可参考本文在“参考资料”一节中提供的视频教程：《OpenClaw +飞书的工具流搭建过程》。</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 10</strong>：OpenClaw 的安装向导</p>\n</li>\n<li>\n<p>在配置完相关服务端组件之后，我们还需要通过执行如下命令来配置 OpenClaw 的 Gateway 网关：</p>\n<pre><code class=\"language-bash\">openclaw channels login\nopenclaw gateway --port 18789\n</code></pre>\n<p>在这里，<code>--port</code>参数用于指定 OpenClaw Gateway 的监听端口，如果读者希望使用默认的 18789 端口，则可以省略该参数。</p>\n</li>\n<li>\n<p>待 Gateway 启动之后，我们就可以使用浏览器打开<code>http://localhost:18789</code>来访问 OpenClaw 的 Web 端了，如果我们能看到如图 11 所示的界面，就说明 OpenClaw 已经成功安装并完成了初步的配置工作。</p>\n  \n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 11</strong>：OpenClaw 的 Web 端</p>\n</li>\n</ul>\n<h4 id=\"步骤-2配置-openclaw-调用-opencode-的方式\">步骤 2：配置 OpenClaw 调用 OpenCode 的方式</h4>\n<p>截止到目前为止，我们主要有<strong>两种方式</strong>可以让 OpenClaw 使用 OpenCode 来连接 LLM 并执行指定的任务。如果用户已购买了 OpenCode 的官方模型服务（即 OpenCode Zen），可以选择直接使用 OpenClaw 自带的 Zen 插件来调用 OpenCode，这种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>先获取到 OpenCode Zen 的 API Key，然后通过执行如下命令之一，将其添加到 OpenClaw 的配置中：</p>\n<pre><code class=\"language-bash\"># 使用交互式命令，这需要根据该命令的提示输入你的 API Key\nopenclaw onboard --auth-choice opencode-zen\n# 或非交互式命令，直接将 API Key 作为参数传入\nopenclaw onboard --opencode-zen-api-key \"&lt;你的 API Key&gt;\"\n</code></pre>\n</li>\n<li>\n<p>如果需要的话，还可以通过执行如下命令来设置自己要使用的默认模型：</p>\n<pre><code class=\"language-bash\">openclaw config set agents.defaults.model.primary \"opencode/claude-opus-4-6\"\n</code></pre>\n</li>\n</ul>\n<p>当然了，选择上述方式需要用户不计较按量计费所带来的开销。如果我们想使用免费的 LLM 的话（譬如  kimi-k2.5-free），也可以通过给 OpenClaw 安装 <code>opencode-to-openai</code>这样的第三方插件来实现。这第二种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>安装<code>opencode-to-openai</code>插件，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/dxxzst/opencode-to-openai\ncd opencode-to-openai\nopenclaw plugins install .\n</code></pre>\n</li>\n<li>\n<p>安装完成后，需要执行如下命令来重启 OpenClaw，并确保插件已启用：</p>\n<pre><code class=\"language-bash\">openclaw gateway restart\n</code></pre>\n<p>在这里，如果我们在 OpenClaw 中启用了插件白名单，就还需要通过执行如下命令将该加入该白名单：</p>\n<pre><code class=\"language-bash\">openclaw config get plugins.allow --json\n# 假设返回 [\"a\",\"b\"]\n\nopenclaw config set plugins.allow '[\"a\",\"b\",\"opencode-to-openai\"]' --json\nopenclaw gateway restart\n</code></pre>\n</li>\n<li>\n<p>同步模型并认证 LLM 服务，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local\n</code></pre>\n<p>如果你想顺便设置默认模型：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local --set-default\n</code></pre>\n</li>\n<li>\n<p>选择模型，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models set opencode-to-openai/opencode/kimi-k2.5-free\n</code></pre>\n<p>在这里，如果担心对 LLM 的请求会被卡住，也可以用<code>useIsolatedHome=false</code>这个插件配置让 OpenCode 使用真实 HOME，具体配置命令如下：</p>\n<pre><code class=\"language-bash\">openclaw config set plugins.opencode-to-openai.useIsolatedHome false\n</code></pre>\n</li>\n</ul>\n<h4 id=\"步骤-3与-openclaw-进行对话\">步骤 3：与 OpenClaw 进行对话</h4>\n<p>如果上述操作一切顺利，我们就可以在步骤 1 中配置好的 Web 端或飞书之类的应用中打开与 OpenClaw 的对话窗口，通过发送提示词来调度 OpenCode 完成相关任务了，如图 12 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 12</strong>：与 OpenClaw 的对话窗口</p>\n<p>当然了，如果想让提示词发挥到最大的作用，并在生产环境中实际使用 OpenClaw/OpenCode 来完成具体的项目任务，我们还需要再配置一下 OpenClaw/OpenCode 所接入的 MCP 服务和 Agent Skills 机制了。关于这部分的内容，我将会在《[[Agent 的进阶应用]]》这一篇笔记中进行详细介绍。</p>\n<h2 id=\"结束语\">结束语</h2>\n<p>在完成了对 AI Agent 的学习与实践之后，我最为明显的体会之一是：Agent 并没有让系统变得更简单，反而让系统的边界变得更加清晰。与传统的自动化脚本或工具不同，Agent 并不是一组固定规则的集合，而是一个基于语言模型进行任务理解、规划与执行的系统组件。这意味着，在很多场景下，它所做的并不是“按预期运行”，而是“尽力完成任务”。</p>\n<p>正因如此，Agent 的引入并没有削弱人类在系统中的作用，反而对人的判断能力提出了更高要求：<br />\n我们需要能够理解 Agent 在做什么、为什么这么做，以及在什么情况下应该介入、修正甚至中止它的行为。从这个角度来看，学习和使用 AI Agent，并不意味着把控制权完全交给 AI，而是学会如何在一个由 AI 参与执行的系统中，重新定位人的职责与边界。这也正是本学习阶段的核心目标。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>\n<p>官方文档：</p>\n<ul>\n<li><a href=\"https://code.claude.com/docs/zh-CN/overview?utm_source=copilot.com\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code 官方文档</a></li>\n<li><a href=\"https://opencode.doczh.com/docs/\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode 官方文档</a></li>\n<li><a href=\"https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers\" rel=\"noopener nofollow\" target=\"_blank\">基于 Agent skills 和 MCP 服务的协同工作流</a></li>\n<li><a href=\"https://docs.openclaw.ai/zh-CN\" rel=\"noopener nofollow\" target=\"_blank\">OpenClaw 官方文档</a></li>\n</ul>\n</li>\n<li>\n<p>视频教程：</p>\n<ul>\n<li>Claude Code 教程：<a href=\"https://www.youtube.com/watch?v=AT4b9kLtQCQ\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV14rzQB9EJj\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n<li>OpenClaw +飞书的工具流搭建过程：<a href=\"https://www.youtube.com/watch?v=giv63OtX720\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV1rvcpzDEsH\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n</ul>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-18 16:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": ".NET 10 & C# 14 New Features 新增功能介绍-扩展成员Extension Members",
      "link": "https://www.cnblogs.com/tianqing/p/19622970",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tianqing/p/19622970\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 11:20\">\n    <span>.NET 10 &amp; C# 14 New Features 新增功能介绍-扩展成员Extension Members</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"p1\"><span class=\"s1\">C# 14 引入了对扩展成员（Extension Members）的增强支持，本质上是对传统“扩展方法”模型的一次语言级升级，使其可以定义的不再仅限于方法，</span></p>\n<p class=\"p1\"><span class=\"s1\">而是可以扩展更多成员形态（例如属性、运算符等）。</span></p>\n<p class=\"p1\"><strong><span class=\"s1\" style=\"font-size: 16px;\">一、从扩展方法到扩展成员</span></strong></p>\n<p class=\"p1\">早在 <a><span class=\"s1\">C# 3.0</span></a> 中，就引入了“扩展方法（Extension Methods）”，其底层机制是：</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">必须定义在 static class</span></p>\n</li>\n<li>\n<p class=\"p1\">方法必须是 <span class=\"s1\">static</span></p>\n</li>\n<li>\n<p class=\"p1\">第一个参数使用 <span class=\"s1\">this T</span></p>\n</li>\n</ul>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> StringExtensions\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsNullOrEmptyEx(<span style=\"color: rgba(0, 0, 255, 1);\">this</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\"> value)\n        </span>=&gt; <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">.IsNullOrEmpty(value);\n}</span></pre>\n</div>\n<p>从本质上看：</p>\n<blockquote>编译器在语法层面做“糖化处理”，最终仍然是静态方法调用。</blockquote>\n<p><span class=\"s1\">LINQ就是最大的应用场景。</span></p>\n<p><strong><span class=\"s1\" style=\"font-size: 16px;\">二、C# 14中引入扩展成员和示例说明</span></strong></p>\n<p class=\"p1\">C# 14 允许在更自然的语法结构中声明扩展成员，不再局限于“静态类 + this 参数”模式，而是支持类似：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Enumerable\n{\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension block</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension members for IEnumerable&lt;TSource&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsEmpty =&gt; !<span style=\"color: rgba(0, 0, 0, 1);\">source.Any();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, <span style=\"color: rgba(0, 0, 255, 1);\">bool</span>&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> predicate) { ... }\n    }\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension block, with a receiver type only</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension members for IEnumerable&lt;Source&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Combine(IEnumerable&lt;TSource&gt; first, IEnumerable&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> second) { ... }\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Identity =&gt; Enumerable.Empty&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static user defined operator:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; <span style=\"color: rgba(0, 0, 255, 1);\">operator</span> + (IEnumerable&lt;TSource&gt; left, IEnumerable&lt;TSource&gt; right) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> left.Concat(right);\n    }\n}</span></pre>\n</div>\n<p class=\"p1\"><span class=\"s1\">定义的是一个 extension block<span class=\"s1\">，目标类型是：IEnumerable&lt;TSource&gt;</span></span></p>\n<p class=\"p1\">代码分成两类 extension block：　　</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\"><strong>实例扩展成员</strong></p>\n</li>\n<li>\n<p class=\"p1\"><strong>静态扩展成员</strong></p>\n</li>\n</ol>\n<p>① 实例扩展成员：extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)&nbsp;</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">source 是接收者（receiver）</span></p>\n</li>\n<li>\n<p class=\"p1\"><span class=\"s1\">类似旧语法的 this IEnumerable&lt;TSource&gt; source</span></p>\n</li>\n<li>\n<p class=\"p1\">但语法更接近真正“为类型添加成员”</p>\n</li>\n</ul>\n<p>&nbsp;扩展属性：public bool IsEmpty =&gt; !source.Any();</p>\n<p class=\"p1\">&nbsp;编译器会生成：public static bool get_IsEmpty&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)</p>\n<p class=\"p1\">&nbsp;代码调用：list.IsEmpty</p>\n<p class=\"p1\">&nbsp;会被编译为：Enumerable.get_IsEmpty(list)</p>\n<p class=\"p1\">&nbsp;其本质仍然是：</p>\n<blockquote>静态方法 + 语法糖绑定</blockquote>\n<p class=\"p1\">但在语义层面：它已经不再是“工具方法”，而是“类型能力”。</p>\n<p class=\"p1\">扩展方法：public IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, bool&gt; predicate)</p>\n<p class=\"p1\">即增强原有LINQ的Where功能</p>\n<p class=\"p1\"><span class=\"s1\">如果系统中已有 System.Linq.Enumerable.Where<span class=\"s1\">：</span></span></p>\n<ul>\n<li>\n<p class=\"p1\">实例成员优先</p>\n</li>\n<li>\n<p class=\"p1\">然后才是 extension block</p>\n</li>\n<li>\n<p class=\"p1\">再是 using 引入的扩展方法</p>\n</li>\n</ul>\n<p>&nbsp;不会破坏已有 API，只是参与候选集。</p>\n<p class=\"p1\">② 静态扩展成员</p>\n<p class=\"p1\">extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;)</p>\n<p class=\"p1\">这里没有 receiver 变量名。</p>\n<blockquote>为类型本身添加“静态扩展成员”</blockquote>\n<p class=\"p1\">找一个静态扩展方法</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Combine(...)</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Combine(a, b);</p>\n<p class=\"p1\">编译器会转化为：Enumerable.Combine(a, b);</p>\n<p class=\"p1\">再看一个静态扩展属性</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Identity</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Identity</p>\n<p class=\"p1\">这在旧扩展方法体系中是无法表达的。</p>\n<p class=\"p1\">再看一个扩展运算符</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; operator +</p>\n<p class=\"p1\">这是 C# 14 的重大增强点。现在你可以写：</p>\n<p class=\"p1\">var result = list1 + list2;</p>\n<p class=\"p1\">等价于：Enumerable.op_Addition(list1, list2);</p>\n<p class=\"p1\"><strong><span style=\"font-size: 16px;\">三、底层编译机制</span></strong></p>\n<p class=\"p1\">&nbsp;<strong>不修改 CLR 元数据</strong></p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">不改变 IEnumerable&lt;T&gt;</span></p>\n</li>\n<li>\n<p class=\"p1\">不增加真实成员</p>\n</li>\n</ul>\n<p>&nbsp;<strong>IL 仍然是静态方法</strong></p>\n<p>&nbsp; &nbsp;所有成员都会生成：&nbsp;public static ...</p>\n<p class=\"p1\">&nbsp;<strong>语义绑定由编译器完成</strong></p>\n<p class=\"p1\">扩展成员解析规则：</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\">实例真实成员</p>\n</li>\n<li>\n<p class=\"p1\">同 namespace extension block</p>\n</li>\n<li>\n<p class=\"p1\">using 导入 extension block</p>\n</li>\n</ol>\n<p>&nbsp;<strong><span style=\"font-size: 16px;\">四、与传统扩展方法对比</span></strong></p>\n<p>&nbsp; &nbsp;<img alt=\"image\" height=\"246\" src=\"https://img2024.cnblogs.com/blog/23525/202602/23525-20260218111804828-477864692.png\" width=\"657\" /></p>\n<p>同时，零运行时开销。</p>\n<ul>\n<li>\n<p class=\"p1\">无反射</p>\n</li>\n<li>\n<p class=\"p1\">无动态代理</p>\n</li>\n<li>\n<p class=\"p1\">无装饰器</p>\n</li>\n<li>\n<p class=\"p1\">无运行时注入</p>\n</li>\n</ul>\n<p>&nbsp;完全编译期绑定。</p>\n<blockquote>编译器级语义增强，不改变运行时类型结构。</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;以上分享给大家。</p>\n<p>&nbsp;</p>\n<p>周国庆</p>\n<p>20260218</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 11:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tianqing\">Eric zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">87</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "这也行？按键动作模式识别也能用贝叶斯？",
      "link": "https://www.cnblogs.com/pie-o/p/19622890",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/pie-o/p/19622890\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:38\">\n    <span>这也行？按键动作模式识别也能用贝叶斯？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        基于朴素贝叶斯对按键动作进行模式识别的一次学习实验\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><a href=\"https://bbs.21ic.com/icview-3503975-1-1.html\" rel=\"noopener nofollow\" target=\"_blank\">首发于21ic论坛</a></p>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>之前学习了贝叶斯更新的相关内容，正好现在也在玩开发板，板子上面有几个小的单击按键，一般识别按键动作的做法就很简单，不是中断就是查询，基本都是靠边沿或者电平的状态来进行的，这一套就很无聊，没有实现的欲望，所以想用点不一样的方法。</p>\n<p>这就有了本片文章的出现，基于<code>朴素贝叶斯分类</code>，使用滑动窗口捕捉电平序列，提取特征进行模式识别，理想情况下识别效果杠杠的，但是出现边界以及混合的情况，效果一言难尽，目前水平不够，这应该也是后续需要解决的主要问题了。</p>\n<h2 id=\"技术要点\">技术要点</h2>\n<h3 id=\"核心原理\">核心原理</h3>\n<ol>\n<li>贝叶斯定理</li>\n</ol>\n<p>本文实现的方法基于朴素贝叶斯分类器，主要就是两方面内容：<code>贝叶斯定理</code>与<code>条件独立假设</code>，涉及的概念有<strong>先验概率</strong>、<strong>后验概率</strong>和<strong>条件概率</strong>，其中先验和条件概率都是提前准备好的，可以是主观经验的，也可以是统计量化的，而贝叶斯定理中的条件概率(不是后验概率)，又称为似然概率。</p>\n<p>这个方法的基本思想是：对于给定的待分类项(就是窗口中的电平序列)，求解当这个待分类项出现时，各个<strong>已经定义过</strong>的模式类别出现的概率，哪个概率最大，那么这个待分类项就属于哪个模式。</p>\n<p>在开始分类之前需要一些必要的准备工作：</p>\n<ul>\n<li>定义有哪些模式类别，这些模式边界要明确，不然不容易分析特征</li>\n<li>定义这些模式的特征属性，这些属性在不同模式下的表现是不同的，这是识别的关键，对应了贝叶斯定理中的似然概率</li>\n</ul>\n<ol start=\"2\">\n<li>滑动窗口</li>\n</ol>\n<p>这里的窗口是实时更新的窗口，老数据移出，新数据加入，滑动窗口确定电平序列数据的范围，只有处在窗口中的序列数据才会得到特征提取的机会，它的长度与序列的时间长度成比例，也就是说采样频率会影响到窗口时效性。</p>\n<p>它需要考虑的问题是怎么捕捉到完整的信号，对应于滑动的步长，以及特征提取的周期。</p>\n<h3 id=\"基本步骤\">基本步骤</h3>\n<p>通过以下步骤实现按键动作模式识别：</p>\n<ol>\n<li><strong>滑动窗口采集</strong>：使用固定大小的滑动窗口持续采集按键状态数据</li>\n<li><strong>特征提取</strong>：从窗口数据中提取多个维度的特征</li>\n<li><strong>概率计算</strong>：基于先验概率和<strong>似然概率</strong>计算后验概率</li>\n<li><strong>模式判断</strong>：根据后验概率和<strong>阈值</strong>确定当前按键模式</li>\n</ol>\n<h2 id=\"具体实现\">具体实现</h2>\n<p>为了验证设想的可行性，通过逻辑分析仪记录按键的引脚电平变化，低电平表示按键按下，高电平表示无按键动作，采样率1MHz，时长20s，在后面的实验中，认为序列是连续的，这就是电平序列的来源，具体序列如下图所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上面记录的数据可以作为一个样本，我通过观察和测量确定了几种模式，以及一些帮助识别的特征属性，在实验过程中使用<code>python</code>进行了方法验证。</p>\n<h3 id=\"模式定义\">模式定义</h3>\n<p>我在设计过程中定义了四种按键模式，分别如下：</p>\n<ul>\n<li><strong>无效</strong>：无有效按键动作</li>\n<li><strong>单击</strong>：单次短暂按键动作</li>\n<li><strong>双击</strong>：快速连续两次按键动作</li>\n<li><strong>长按</strong>：持续时间较长的按键动作</li>\n</ul>\n<p>动作的实施都是通过一个单按键来进行的，其中单击和双击涉及到电平的较快速变化，是识别的难点</p>\n<h3 id=\"特征选择\">特征选择</h3>\n<p>基于对提取的特征包括：</p>\n<ul>\n<li><strong>高电平占比</strong>：窗口内高电平信号的比例</li>\n<li><strong>上升沿数量</strong>：信号从低到高的转换次数</li>\n<li><strong>下降沿数量</strong>：信号从高到低的转换次数</li>\n<li><strong>最长连续高电平持续时间</strong>：窗口内持续高电平的最长时间</li>\n</ul>\n<h3 id=\"概率模型\">概率模型</h3>\n<ul>\n<li><strong>先验概率</strong>：初始假设四种模式等概率出现，即每个模式的先验都是0.25。并且和一般的贝叶斯方法不同的是，在实现过程中认为先验是不需要更新的，也就是在每一次识别时认为每个模式都是<strong>等概率</strong>出现的，没有转移概率或者历史因素影响</li>\n<li><strong>似然概率</strong>：基于<strong>特征分布参数</strong>计算观测到当前特征的概率，其中的分布参数是根据实际捕捉的序列数据来设计的，概率分布模型采用正态分布来<strong>近似</strong>，需要均值和标准差，统一使用<em>概率密度</em>表达似然结果\n<ul>\n<li>高电平占比的分布参数\n<ul>\n<li>无效：0.05，0.2</li>\n<li>单击：0.2，0.2</li>\n<li>双击：0.3，0.2</li>\n<li>长按：0.9，0.2</li>\n</ul>\n</li>\n<li>(上升沿/下降沿)数量的分布参数\n<ul>\n<li>无效：0.1，0.3</li>\n<li>单击：1，0.3</li>\n<li>双击：2，0.3</li>\n<li>长按：0.7，0.3</li>\n</ul>\n</li>\n<li>最长高电平持续时间的分布参数\n<ul>\n<li>无效：0，2</li>\n<li>单击：0.2，5</li>\n<li>双击：0.17，3</li>\n<li>长按：0.9，10</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>后验概率</strong>：使用贝叶斯公式计算各模式的后验概率，先计算提取的特征在每个模式下的<em>联合似然</em>，基于条件独立假设，可以直接相乘，然后计算后验并归一化可得最终的概率表</li>\n</ul>\n<h3 id=\"代码实现\">代码实现</h3>\n<ol>\n<li>数据采集与预处理</li>\n</ol>\n<p>把逻辑分析仪中的数据导出为csv文件，代码首先实现了&nbsp;read_sigrok_csv_simple&nbsp;函数，用于读取 sigrok CSV 格式的按键数据：</p>\n<pre><code class=\"language-python\">def&nbsp;read_sigrok_csv_simple(filename):\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data&nbsp;=&nbsp;[]\n&nbsp;&nbsp;&nbsp;&nbsp;signal_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;open(filename,&nbsp;'r',&nbsp;newline='')&nbsp;as&nbsp;csvfile:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reader&nbsp;=&nbsp;csv.reader(csvfile)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;row&nbsp;in&nbsp;reader:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过注释行和空行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;row&nbsp;or&nbsp;row[0].startswith(';'):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;确保行有两个列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(row)&nbsp;&gt;=&nbsp;2:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_val&nbsp;=&nbsp;float(row[0])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data_val&nbsp;=&nbsp;float(row[1])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_data.append(time_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;signal_data.append(data_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;except&nbsp;ValueError:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过无法转换为数字的行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;time_data,&nbsp;signal_data\n</code></pre>\n<p>该函数读取 CSV 文件中的时间戳和信号值，返回两个列表分别存储时间数据和信号数据，通过plot输出采样的数据图如下所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>识别器类设计</li>\n</ol>\n<p>核心实现是&nbsp;BayesianButtonRecognizer&nbsp;类，用于实现基于贝叶斯分类的按键模式识别：</p>\n<pre><code class=\"language-python\">class&nbsp;BayesianButtonRecognizer:\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"基于滑动窗口和贝叶斯更新的按键模式识别器\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;__init__(self,&nbsp;window_size=20,&nbsp;sample_interval=0.01,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.7):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;初始化识别器\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Args:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;window_size:&nbsp;滑动窗口大小\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_interval:&nbsp;采样间隔(秒)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;threshold:&nbsp;判定阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window_size&nbsp;=&nbsp;window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.sample_interval&nbsp;=&nbsp;sample_interval\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.threshold&nbsp;=&nbsp;threshold\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;滑动窗口存储最近的观测序列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window&nbsp;=&nbsp;deque(maxlen=window_size)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;模式类别\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.modes&nbsp;=&nbsp;['无效',&nbsp;'单击',&nbsp;'双击',&nbsp;'长按']\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;先验概率&nbsp;-&nbsp;初始等可能\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.prior&nbsp;=&nbsp;np.array([0.25,&nbsp;0.25,&nbsp;0.25,&nbsp;0.25])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征提取相关的参数(单位:采样点数)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.short_press_max&nbsp;=&nbsp;15&nbsp;&nbsp;#&nbsp;短按最大持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.long_press_min&nbsp;=&nbsp;30&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按最小持续时间&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.double_click_interval&nbsp;=&nbsp;10&nbsp;&nbsp;#&nbsp;双击间隔阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;初始化特征分布参数(基于物理理解预设)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self._init_feature_distributions()\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征权重\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.featwight={\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"无效\":np.array([1.2,0.8,0.8,1.2]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"单击\":np.array([1,1.2,1.2,1]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"双击\":np.array([1,1.2,1.2,0.8]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"长按\":np.array([1.2,0.8,0.8,1.2])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"3\">\n<li>特征分布初始化</li>\n</ol>\n<p>识别器初始化时设置了各模式下特征的概率分布参数：</p>\n<pre><code class=\"language-python\">def&nbsp;_init_feature_distributions(self):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"初始化各模式下特征的概率分布参数\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;高电平占比的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.high_ratio_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.05,&nbsp;&nbsp;&nbsp;#&nbsp;无效时高电平占比很低\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;0.2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有短暂高电平\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;0.3,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时高电平占比稍高\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按时高电平占比很高\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;上升沿数量的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.rise_count_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时几乎无上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时有2个上升沿&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;最长高电平持续时间的分布参数(正态分布:均值,标准差)\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.max_duration_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;(0,&nbsp;2),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时持续时间很短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;(0.2,&nbsp;5),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击中等持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;(0.17,&nbsp;3),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击每次按下时间短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;(0.9,&nbsp;10)&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按持续时间长\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"4\">\n<li>特征提取</li>\n</ol>\n<p>从滑动窗口数据中提取特征，其中高电平占比是通过求序列平均值来获得的，然后边沿计数对应了记录序列跳变数量，最长高电平时间通过记录连续高电平时长获取：</p>\n<pre><code class=\"language-python\">def&nbsp;extract_features(self,&nbsp;window_data):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"从滑动窗口数据中提取特征\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(window_data)&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;None\n\n&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;=&nbsp;np.array(window_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征1:&nbsp;高电平占比\n\n&nbsp;&nbsp;&nbsp;&nbsp;high_ratio&nbsp;=&nbsp;np.mean(data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征2:&nbsp;上升沿数量(0-&gt;1的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;0&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征3:&nbsp;下降沿数量(1-&gt;0的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;1&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征4:&nbsp;最长连续高电平持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;val&nbsp;in&nbsp;data:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;val&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;max(max_duration,&nbsp;current_duration)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'high_ratio':&nbsp;high_ratio,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'rise_count':&nbsp;rises,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'fall_count':&nbsp;falls,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'max_duration':&nbsp;max_duration\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"5\">\n<li>似然概率计算</li>\n</ol>\n<p>计算给定模式下观测到特征值的似然概率，即条件概率，通过上面定义的分布参数，使用<code>正态分布</code>近似，在python中通过<code>stats.norm.pdf</code>求特征对应每个模式的似然程度，然后基于条件独立的假设，求解联合似然，表示样本对某一模式的最终似然结果：</p>\n<pre><code class=\"language-python\">def&nbsp;calculate_likelihood(self,&nbsp;features,&nbsp;mode):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"计算给定模式下观测到特征值的似然概率\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;features&nbsp;is&nbsp;None:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1.0&nbsp;&nbsp;#&nbsp;无特征时返回中性似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用概率密度函数计算各特征的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;1.&nbsp;高电平占比的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_ratio&nbsp;=&nbsp;self.high_ratio_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用正态分布近似,&nbsp;标准差根据经验设定\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_ratio&nbsp;=&nbsp;stats.norm.pdf(features['high_ratio'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_ratio,&nbsp;0.2)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_ratio&nbsp;+&nbsp;1e-10)&nbsp;&nbsp;#&nbsp;避免零\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;2.&nbsp;上升沿数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_rises&nbsp;=&nbsp;stats.norm.pdf(features['rise_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_rises&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;3.&nbsp;下降沿(同上升沿)数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_falls&nbsp;=&nbsp;stats.norm.pdf(features['fall_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_falls&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;4.&nbsp;最长持续时间的似然(使用正态分布)\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur&nbsp;=&nbsp;self.max_duration_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur&nbsp;*=&nbsp;self.window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_duration&nbsp;=&nbsp;stats.norm.pdf(features['max_duration'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_duration&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;组合各特征的似然(假设特征条件独立)\n\n&nbsp;&nbsp;&nbsp;&nbsp;total_likelihood&nbsp;=&nbsp;np.prod(np.array(likelihoods))\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征在mode[%s]的似然：\"%{mode},likelihoods,\"最终联合似然:%.\n\n&nbsp;&nbsp;&nbsp;&nbsp;3f\"%total_likelihood)\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;total_likelihood\n</code></pre>\n<ol start=\"6\">\n<li>滑动窗口更新</li>\n</ol>\n<pre><code class=\"language-python\">def&nbsp;slide_window(self,io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;移除最旧的值\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.popleft()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;将新观测值加入滑动窗口\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.append(io_state)\n</code></pre>\n<ol start=\"7\">\n<li>信念更新与模式判断</li>\n</ol>\n<p>计算完样本对每个模式的似然后，就于先验概率相乘，就得到了后验概率，然后归一化得到最终结果，同时使用阈值判定机制，当最大后验超过判定阈值后，才会识别具体模式，否则就是不确定</p>\n<pre><code class=\"language-python\">def&nbsp;update_belief(self,&nbsp;io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"根据新观测值更新信念\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;提取当前窗口的特征\n\n&nbsp;&nbsp;&nbsp;&nbsp;features&nbsp;=&nbsp;self.extract_features(self.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征提取：\",features)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;计算各模式的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;np.array([self.calculate_likelihood(features,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;mode)&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;mode&nbsp;in&nbsp;self.modes])\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;贝叶斯更新:&nbsp;后验&nbsp;∝&nbsp;似然&nbsp;×&nbsp;先验\n\n&nbsp;&nbsp;&nbsp;&nbsp;unnormalized_posterior&nbsp;=&nbsp;likelihoods&nbsp;*&nbsp;self.prior\n\n&nbsp;&nbsp;&nbsp;&nbsp;evidence&nbsp;=&nbsp;np.sum(unnormalized_posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;evidence&nbsp;&gt;&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;unnormalized_posterior&nbsp;/&nbsp;evidence\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;self.prior.copy()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;更新先验(用于下一次迭代)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;self.prior&nbsp;=&nbsp;posterior\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;判断当前模式\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_mode_idx&nbsp;=&nbsp;np.argmax(posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_prob&nbsp;=&nbsp;posterior[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"后验：\",posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;best_prob&nbsp;&gt;&nbsp;self.threshold:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;self.modes[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;'不确定'\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;detected_mode,&nbsp;posterior\n</code></pre>\n<ol start=\"8\">\n<li>主函数与演示</li>\n</ol>\n<p>因为定义了高电平为有效电平，但实际中低电平，或者说下降沿是按键动作的反应，所以处理数据序列时做了相应的取反处理。</p>\n<pre><code class=\"language-python\">if&nbsp;__name__&nbsp;==&nbsp;\"__main__\":\n\n&nbsp;&nbsp;&nbsp;&nbsp;DeltaT&nbsp;=&nbsp;0.01 # 采样间隔\n\n&nbsp;&nbsp;&nbsp;&nbsp;UnitTime&nbsp;=&nbsp;1e-06 # 原始数据点的时基\n\n&nbsp;&nbsp;&nbsp;&nbsp;SampleInterval&nbsp;=&nbsp;math.floor(DeltaT&nbsp;/&nbsp;UnitTime)\n\n&nbsp;&nbsp;&nbsp;&nbsp;filename&nbsp;=&nbsp;\"key_data_20s_all.csv\"&nbsp;&nbsp;#&nbsp;逻辑分析仪导出的数据\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer&nbsp;=&nbsp;BayesianButtonRecognizer(window_size=100,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.8)\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer.reset()\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data,&nbsp;signal_data&nbsp;=&nbsp;read_sigrok_csv_simple(filename)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"成功读取数据，共&nbsp;{len(time_data)}&nbsp;个数据点\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"时间范围:&nbsp;{time_data[0]}s&nbsp;到&nbsp;{time_data[-1]}s\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;res_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_num&nbsp;=&nbsp;math.floor(len(signal_data)&nbsp;/&nbsp;SampleInterval)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"sample&nbsp;size&nbsp;is:\",sample_num)\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(sample_num-1):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_data.append(int(not&nbsp;signal_data[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;recognizer.slide_window(int(not&nbsp;signal_data\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;i%recognizer.window_size==0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res,postrior=recognizer.update_belief(i)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(res&nbsp;not&nbsp;in[\"不确定\",\"无效\"]):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res_data.append(res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(\"win[%d]:\"%i,res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(recognizer.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(sample_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(res_data)\n</code></pre>\n<p>当窗口中样本序列是理想情况时，识别效果相当好：</p>\n<p>无效样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个无效按键样本序列图，保持无效电平，没有边沿变化。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，高电平占比为0，边沿计数为0，最长高电平延时为0，在各个模式的似然列表中，给出了对应的似然结果，同时从列数据对比来看，也可以直接从数值上看出样本特征更偏向哪个模式，最终的后验结果，确实是无效模式的概率最高，即判定窗口中的序列为无效。</p>\n<p>单击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个单击按键样本序列图，有边沿变化，一个上升沿，一个下降沿，高电平占比大约0.2。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，最终的识别结果也是正确的</p>\n<p>双击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个双击样本的示例图，可以看到由两个高电平组成，下图给出识别过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出特征提取信息正确，有两个上升沿和两个下降沿，然后最终的后验概率中也是双击的概率最大，并且超过阈值判定正确。</p>\n<p>下面给出一些因为信号完整性缺失造成的误判示例。</p>\n<p>边界双击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图中可以看出很明显是一个双击的动作，但是由于窗口长度固定的原因，导致一部分序列缺失，下图给出识别结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征提取的信息倒是正确的，识别出下降沿只有1个，在计算似然过程中，相应位置的似然结果也反应了这一点，最终的后验表中可以看到前两个大的概率是单击和双击，但是都没超过阈值，所以判定为不确定</p>\n<p>边界单击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出这个情况像是单击，但是实际上是一段长按序列，下图给出识别过程：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征信息提取是正确的，然后似然结果都偏低，表示不偏向某一个模式，但在最终的后验结果中单击的后验概率异常的高，应该是在归一化过程中，单击概率占比比其他概率大很多导致的，这也是同样的问题，也就是信号完整性缺失导致了误判</p>\n<h2 id=\"总结\">总结</h2>\n<p>在这次实验中，基于朴素贝叶斯分类方法，通过<em>滑动窗口</em>采集数据、提取多维度特征、计算概率分布和应用贝叶斯更新，学到了不少，也融合了很多内容，算是一次不小的学习体验吧，虽然目前测试下来效果有限，还无法真正用在项目中，也总结了一些不足的地方。</p>\n<p>比如信号完整性保证不了，不同特征属性对不同模式的权重实际并不一致等，这些都是需要解决的问题，虽然对现在的我来说很困难，但探索新方法的过程还是蛮喜欢的，也可能是对现有方法的审美疲劳导致的吧。</p>\n<p>但有一说一，传统的方法，还是简单高效的，也不涉及到什么数学的内容，全凭逻辑加判断就可以搞定了，真是省时省力啊。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/pie-o/\" target=\"_blank\">pie_thn</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/pie-o/p/19622890\" target=\"_blank\">https://www.cnblogs.com/pie-o/p/19622890</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:38</span>&nbsp;\n<a href=\"https://www.cnblogs.com/pie-o\">pie_thn</a>&nbsp;\n阅读(<span id=\"post_view_count\">43</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Linux下GNU Autotools工具基础教程",
      "link": "https://www.cnblogs.com/ttkwzyttk/p/19621799",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ttkwzyttk/p/19621799\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:24\">\n    <span>Linux下GNU Autotools工具基础教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本博客介绍了Linux下GNU Autotools工具的基础用法，涵盖了autoconf、automake等工具的功能及作用。通过实例演示，讲解了如何使用autoconf生成配置脚本，以及如何通过automake和Makefile.am定制构建过程。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>对于我们平时写的小的测试Demo程序，可能自己手动编写一个<code>Makefile</code>文件就可以编译整个项目了，但是对于一些大型的工程，包含多个源码文件夹、头文件文件夹、库文件文件夹，如果我们每个源码文件的<code>Makefile</code>文件都自己去编写会非常繁琐，所以这时候需要一些自动化工具来帮助我们简化项目的构建，这里比较主流的有两种工具一个是GNU下的Autotools工具，一个是CMake工具。</p>\n<p>Autotools工具是一些版本比较老的工具了，遗留了很多问题，包括他的语法复杂(m4宏语言)，涉及的工具种类太多，生成的<code>configure</code>脚本非常庞大等问题，在2000年后出现的新一代构建系统包括CMake、Meson、Ninja等能够有效解决Autotools的历史疑难杂症，并且语法更加现代化、生成速度更快。那我们为什么还要学习了解Autotools呢？因为历史原因，早年很多的开源软件都是使用的Autotools来构建的，并且Autotools目前在GNU体系中还是大量使用，并且在嵌入式Linux中非常常见，而且在一些老牌的C项目中也非常常见，所以还是非常有必要了解Autotools。</p>\n<p>这里给出官方的Autotools的文档连接 <a href=\"https://www.gnu.org/software/autoconf/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/software/autoconf/</a></p>\n<h1 id=\"一autotools工具详细介绍\">一、Autotools工具详细介绍</h1>\n<h2 id=\"11-autotools工具组成\">1.1 Autotools工具组成</h2>\n<p>GNU Autotools并不是一个工具，而是由一系列的工具合集组成，在现如今的Linux发行版中，大概率是自带这些工具的，如果没有可以自行下载</p>\n<ul>\n<li><code>autoscan</code>：这个工具主要是用来扫描查找源代码目录下的源文件用来生成<code>configure.scan</code>文件。<code>configure.scan</code>文件是自动生成的模板，里面包含了一些系统配置的基本选项都是一些宏定义，这些宏通过<code>autoconf</code>工具处理后会变成检查系统特性、环境变量的shell脚本，我们可以根据这个模板修改，最后将<code>configure.scan</code>重新命名为<code>configure.ac</code>文件</li>\n<li><code>aclocal</code>：这个工具是一个<code>perl</code>脚本程序，他主要用来根据上一步的<code>configure.ac</code>文件的内容，自动生成<code>aclocal.m4</code>文件</li>\n<li><code>autoconf</code>：这个工具会使用<code>configure.ac</code>文件来生成名称为<code>configure</code>的shell脚本文件用来检查系统特性与环境变量，运行这个脚本文件之后，就会生成<code>Makefile</code>文件，之后我们就可以执行<code>make</code>和<code>make install</code>命令了</li>\n<li><code>autoheader</code>：这个工具主要是用来自动生成<code>config.h.in</code>文件的，当我们执行了<code>./configure</code>之后，会生成一个<code>config.h</code>文件，在调用<code>autoheader</code>工具之后，就会生成<code>config.h.in</code>文件</li>\n<li><code>automake</code>：使用<code>automake</code>来产生<code>Makefile.in</code>文件，需要注意的是<code>Makefile.in</code>是由<code>Makefile.am</code>生成的这个需要我们手动来编写</li>\n</ul>\n<p>这里可以注意到，最后工具用到的文件都是以<code>.in</code>结尾的文件，这些文件相当于我们最后需要的目标文件的输入文件</p>\n<h2 id=\"12-configure脚本制作流程\">1.2 <code>configure</code>脚本制作流程</h2>\n<p>这块内容可以参考 <a href=\"https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html</a> 文档的第三章内容，详细阐述了<code>configure</code>脚本的制作流程，下面简单介绍一下，以下图流程图中，带<code>*</code>的是执行的命令，带<code>[]</code>的表示可选项</p>\n<p><img alt=\"Pasted image 20260216122316.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209097-1180976358.png\" /><br />\n首先根据文档中的这个流程图，可以看见用我们的源文件，通过<code>autoscan</code>命令生成<code>configure.scan</code>文件，然后我们再修改这个模板，生成我们的<code>configure.ac</code>文件，在通过<code>autoconf</code>命令生成<code>configure</code>脚本的时候，<code>aclocal.m4</code>和<code>acsite.m4</code>这两个文件为可选项，如果我们后续需要使用<code>automake</code>工具，那么还需要在执行<code>autoconf</code>前使用<code>aclocal</code>工具生成<code>aclocal.m4</code>文件</p>\n<p>在执行<code>autoconf</code>命令的同时，我们可以选择使用<code>autoheader</code>来生成<code>config.h.in</code>文件。这个文件的作用是为 configure 提供一个模板，告诉它哪些宏需要根据系统环境进行检测，从而生成最终的<code>config.h</code>文件，供代码在条件编译中使用，后需会详细讲解这部分内容。</p>\n<p>如果我们还需要使用<code>automake</code>工具来生成<code>Makefile.in</code>文件，那么需要在<code>autoscan</code>生成了<code>configure.ac</code>文件之后追加以下的流程<br />\n<img alt=\"Pasted image 20260216132616.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209304-1030423812.png\" /><br />\n第一步，我们需要使用<code>aclocal</code>命令来生成<code>aclocal.m4</code>文件，有了这个文件之后，我们在生成<code>configure</code>的时候会使用到这个文件，然后第二步我们需要自己编写一个<code>Makefile.am</code>文件，然后执行<code>automake</code>命令来生成<code>Makefile.in</code></p>\n<p>做完上述两个流程之后，我们就可以得到两个关键文件了一个是<code>configure</code>脚本文件，一个是<code>Makefile.in</code>模板文件，在通过以下流程，生成最后的<code>Makefile</code>文件<br />\n<img alt=\"Pasted image 20260216133225.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209082-1911362763.png\" /><br />\n直接执行<code>configure</code>脚本文件，脚本会去找<code>config.h.in</code>和<code>Makefile.in</code>文件进行文件生成，最后生成<code>config.h</code>和<code>Makefile</code>文件，之后我们就可以执行<code>make</code>命令来编译工程了</p>\n<p>可能这里三个图的关系比较混乱，后面会通过一个工程上的实例，来具体演示<code>Autotools</code>的使用以及流程</p>\n<h2 id=\"13-autoheader工具与confighin文件\">1.3 <code>autoheader</code>工具与<code>config.h.in</code>文件</h2>\n<p>前面我们提到了使用<code>autoconf</code>生成<code>configure</code>的同时，可以使用<code>autoheader</code>来生成<code>config.h.in</code>文件，这个文件到底是用来干什么的呢？这一小节详细讲解一下。</p>\n<p>例如，现在有一个场景：我们的应用代码需要跨平台，在 Linux 环境下，会使用到 <code>&lt;unistd.h&gt;</code> 头文件。不同系统可能是否存在这个头文件不同，因此我们希望通过自动化的方式进行检测和适配。我们需要先在<code>configure.ac</code>文件中添加配置项</p>\n<pre><code>AC_INIT([example], [1.0])\nAC_CONFIG_HEADERS([config.h])\nAC_CHECK_HEADERS([unistd.h])\nAC_OUTPUT\n</code></pre>\n<ul>\n<li><code>AC_CONFIG_HEADERS([config.h])</code>：告诉 Autotools 最终需要生成 <code>config.h</code> 文件</li>\n<li><code>AC_CHECK_HEADERS([unistd.h])</code>：告知 Autotools 需要检测系统是否有 <code>&lt;unistd.h&gt;</code>，并生成相应宏 <code>HAVE_UNISTD_H</code></li>\n</ul>\n<p>当我们在<code>configure.ac</code>中添加了这些选项之后，可以运行<code>autoheader</code>命令来生成<code>config.h.in</code>，这时的模板文件中会有以下这样的记录</p>\n<pre><code>/* Define to 1 if you have the &lt;unistd.h&gt; header file. */\n#undef HAVE_UNISTD_H\n</code></pre>\n<ul>\n<li>注意：<code>#undef HAVE_UNISTD_H</code> 只是占位宏，值还没有确定</li>\n<li>这个宏的名字是由 AC_CHECK_HEADERS 自动生成的</li>\n</ul>\n<p>有了<code>config.h.in</code>文件之后，如果我们运行了<code>./configure</code>后，工具会检测系统中是否有<code>&lt;unistd.h&gt;</code>根据最终结果来生成<code>config.h</code>头文件，如果包含有那么在<code>config.h</code>文件中，就会多出</p>\n<pre><code class=\"language-c\">#define HAVE_UNISTD_H 1\n\n//如果没有该头文件的话\n/* #undef HAVE_UNISTD_H */\n</code></pre>\n<p>后续我们就可以通过包含<code>config.h</code>文件来进行条件编译了，这样代码可以在不同平台上自动适配，而不需要手动修改</p>\n<pre><code class=\"language-c\">#include \"config.h\"\n\n#ifdef HAVE_UNISTD_H\n#include &lt;unistd.h&gt;\n#endif\n\nint main() {\n#ifdef HAVE_UNISTD_H\n    write(1, \"unistd.h exists\\n\", 16);\n#else\n    printf(\"unistd.h not found\\n\");\n#endif\n    return 0;\n}\n</code></pre>\n<p>总结：</p>\n<ul>\n<li><code>config.h.in</code> = <strong>模板文件</strong>，列出待检测的宏</li>\n<li><code>./configure</code> = <strong>系统检测器</strong>，把模板宏填上实际值</li>\n<li><code>config.h</code> = <strong>最终宏定义文件</strong>，代码条件编译使用</li>\n<li>条件编译语句 (<code>#ifdef</code>) 永远需要开发者在代码里自己写</li>\n</ul>\n<h1 id=\"二autotools实例分析\">二、Autotools实例分析</h1>\n<p>这一章节主要是对autotools的具体使用举例。</p>\n<p><strong>第一步</strong>：创建demo工程项目，新建了一个源码文件夹，创建一个c文件，编写了一个简单的代码。<br />\n<img alt=\"Pasted image 20260216140420.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209096-1334942740.png\" /></p>\n<p><strong>第二步</strong>：生成<code>configure.ac</code>文件。在源码路径下执行了<code>autoscan</code>命令之后，可以看见<code>configure.scan</code>文件已经生成出来了<br />\n<img alt=\"Pasted image 20260216141414.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209334-698108259.png\" /><br />\n可以打开这个文件查看，就是一些功能宏定义<br />\n<img alt=\"Pasted image 20260216141527.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209314-113774963.png\" /><br />\n宏解释：</p>\n<ul>\n<li><code>AC_PREREQ()</code>宏声明本文件要求的autoconf版本，本例使用的版本为2.71</li>\n<li><code>AC_INIT()</code>中分别的是: 软件包的名字，版本，作者的联系方式(一般是Email)</li>\n<li><code>AC_CONFIG_SRCDIR</code>宏用来侦测所指定的源码文件是否存在，来确定源码目录的有效性。此处为当前目录下的test.c，如果有多个源文件的话选择一个主要的文件，通常是 <code>main.c</code> 或其他代表源代码位置的文件。</li>\n<li><code>AC_CONFIG_HEADER</code>宏用于生成config.h文件，以便autoheader使用</li>\n<li><code>AC_PROG_CC</code>用来指定编译器，如果不指定，选用默认gcc。 比如: AC_PROG_CC(gcc)</li>\n<li><code>AC_OUTPUT</code>用来设定 configure 所要产生的文件，如果是makefile，configure会把它检查出来的结果带入makefile.in文件产生合适的makefile。使用Automake时，还需要一些其他的参数，这些额外的宏用aclocal工具产生</li>\n</ul>\n<p>这些宏可以直接到 <a href=\"https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html#Making-configure-Scripts\" rel=\"noopener nofollow\" target=\"_blank\">https://www.gnu.org/savannah-checkouts/gnu/autoconf/manual/autoconf-2.72/autoconf.html#Making-configure-Scripts</a> 官方文档中去查询</p>\n<p>最后修改这个模板文件，填入自己的软件信息，并将<code>configure.scan</code>重命名为<code>configure.ac</code>文件<br />\n<img alt=\"Pasted image 20260216160011.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209315-856118383.png\" /><br />\n这里有几点需要注意，第一就是注意填写好自己软件的信息，第二就是如果我们后续要使用<code>automake</code>工具的话，需要添加一行<code>AM_INIT_AUTOMAKE</code>，并且需要指定构建行为常用的选项为<code>[foreign]</code>如果不指定的话，就是<code>[gnu]</code>严格模式，会检查AUTHORS、NEWS、README、ChangeLog、COPYING、INSTALL等文件，如果缺失的话，后续使用<code>automake</code>就会报错，这是我踩的一个坑，对于现代的项目，大多数使用<code>git</code>代码管理，对于这些文件有一些是不必要的，所以这里可以关闭GNU strict模式，如果你需要使用GNU的严格模式的话，创建这些所需文件就可以解决报错。第三点就是记得添加输出文件列表的宏<code>AC_CONFIG_FILES([文件名])</code>这三点编辑好之后，一个基础的<code>configure.ac</code>就编辑好了</p>\n<p><strong>第三步</strong>：生成<code>aclocal.m4</code>文件，因为我们后续要使用到<code>automake</code>工具，需要依赖<code>aclocal.m4</code>文件，所以这一步通过<code>aclocal</code>来生成<code>aclocal.m4</code>文件<br />\n<img alt=\"Pasted image 20260216144207.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209281-1527369101.png\" /></p>\n<p>可以看见执行了<code>aclocal</code>之后，<code>aclocal.m4</code>文件成功输出了</p>\n<p><strong>第四步</strong>：生成<code>config.h.in</code>文件，因为我们在<code>configure</code>中使用了宏检查，需要输出<code>config.h</code>，所以我们需要先生成<code>config.h.in</code><br />\n<img alt=\"Pasted image 20260216144505.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209256-1503264093.png\" /><br />\n执行<code>autoheader</code>命令之后，<code>config.h.in</code>也成功生成了</p>\n<p><strong>第五步</strong>：生成<code>configure</code>文件，使用<code>autoconf</code>命令得到<code>configure</code>脚本文件<br />\n<img alt=\"Pasted image 20260216145556.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209281-1821923245.png\" /><br />\n如果这时候我们直接运行这个脚本，可以发现，缺少<code>install-sh</code>脚本，这个脚本就是通过<code>automake</code>来生成的<br />\n<img alt=\"Pasted image 20260216145731.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209052-662252426.png\" /></p>\n<p><strong>第六步</strong>：编写<code>Makefile.am</code>文件，执行<code>automake</code>命令。这里只写了一个比较简单的<code>Makefile.am</code>进行测试<br />\n<img alt=\"Pasted image 20260216161303.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209025-2002039184.png\" /><br />\n<code>Makefile.am</code>文件编写规范非常重要，这里指出我踩到的另外一个坑，<code>Makefile.am</code>文件中的这两个宏定义，必须得规范否则也会爆出错误或者警告。</p>\n<p><code>bin_PROGRAMS</code>的含义是生成一个可执行文件 test，并在 <code>make install</code> 时安装到<code>$(bindir)</code>，一般情况下<code>$(bindir) = /usr/local/bin</code><br />\n<code>test_SOURCES</code>的结构为<code>&lt;目标名&gt;_SOURCES</code>目标名必须和<code>bin_PROGRAMS</code>的程序名完全一致，否则 Automake 会报错</p>\n<p>除了<code>bin_PROGRAMS</code>还有其他Automake内部已经定义好的安装目录变量</p>\n<table>\n<thead>\n<tr>\n<th>变量</th>\n<th>安装目录</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bin_PROGRAMS</td>\n<td>$(bindir) → /usr/local/bin</td>\n</tr>\n<tr>\n<td>sbin_PROGRAMS</td>\n<td>$(sbindir)</td>\n</tr>\n<tr>\n<td>libexec_PROGRAMS</td>\n<td>$(libexecdir)</td>\n</tr>\n<tr>\n<td>noinst_PROGRAMS</td>\n<td>不安装，只编译</td>\n</tr>\n<tr>\n<td>check_PROGRAMS</td>\n<td>测试程序</td>\n</tr>\n<tr>\n<td>具体其他宏的功能，大家可以查看官方的文档，这篇文章主要是autotools工具的使用，这里就不深入剖析底层了</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>还有一个需要注意的点是，如果我们这时候直接使用<code>automake</code>命令，会提示报错，工具也对我们继续了提示需要加上<code>--add-missing</code>选项，添加选项--add-missing 可以让automake工具自动添加必要的脚本文件，这里也可以看见如果<code>AM_INIT_AUTOMAKE</code>没有关闭GNU的严格模式，会报出缺失必要文件的错误。这里是因为这张图是没有修改的时候截取的，修改之后我没有重新<code>automake</code><br />\n<img alt=\"Pasted image 20260216150528.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209349-1310847039.png\" /><br />\n加上该选项，并修改了<code>AM_INIT_AUTOMAKE</code>之后，再次执行<code>automake</code>命令执行成功，并成功生成<code>Makefile.in</code>文件和<code>install-sh</code>文件<br />\n<img alt=\"Pasted image 20260216151252.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209051-539778253.png\" /></p>\n<p><strong>第七步</strong>：执行<code>configure</code>脚本，更具<code>Makfile.in</code>、<code>config.h.in</code>生成最后的文件。<br />\n<img alt=\"Pasted image 20260216163034.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209360-2035713464.png\" /><br />\n可以看见成功生成了<code>config.status</code>以及<code>Makefile</code>文件，打开该<code>Makefile</code>文件，可以看见生成了700多行<br />\n<img alt=\"Pasted image 20260216164053.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209182-33307432.png\" /><br />\n我们非常简单的一个代码，<code>autotools</code>工具给我们生成了700多行的<code>Makefile</code>文件，其中大量的代码都是用来检测环境和编译器相关的内容。有了<code>Makefile</code>之后，我们就可以直接使用<code>make</code>命令来编译了<br />\n<img alt=\"Pasted image 20260216164308.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209147-1035686151.png\" /><br />\n并且生成了对应的可执行文件，同时我们可以执行<code>make install</code>进行系统安装，默认安装到<code>/user/local/bin</code>下，需要注意的是使用<code>make install</code>时需要权限。<br />\n<img alt=\"Pasted image 20260216164615.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209129-81980537.png\" /></p>\n<p>我们可以使用<code>make dist</code>用来生成一个源码压缩包，拿到这个包之后，我们就可以将工程发布给别人或者发布成release版本了<br />\n<img alt=\"Pasted image 20260216164748.png\" src=\"https://img2024.cnblogs.com/blog/2652772/202602/2652772-20260217172209359-157961370.png\" /><br />\n至此整个<code>Autotools</code>最基本的流程与用法就结束了，当然在实际开发当中，我们不可能只有一个源文件，之后的博客会对实际工程项目情况举例与分析。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:24</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ttkwzyttk\">ttkwzyttk</a>&nbsp;\n阅读(<span id=\"post_view_count\">49</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "零代码零基础！小红书MCP全自动化运营【保姆级安装教程】",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19621617",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19621617\" id=\"cb_post_title_url\" title=\"å‘å¸ƒäºŽ 2026-02-17 13:49\">\n    <span>é›¶ä»£ç é›¶åŸºç¡€ï¼å°çº¢ä¹¦MCPå…¨è‡ªåŠ¨åŒ–è¿è¥ã€ä¿å§†çº§å®‰è£…æ•™ç¨‹ã€‘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        å°çº¢ä¹¦MCPè‡ªåŠ¨åŒ–å·¥å…·éƒ¨ç½²æŒ‡å— æ‘˜è¦ï¼šæœ¬æ–‡è¯¦ç»†ä»‹ç»å¦‚ä½•å¿«é€Ÿéƒ¨ç½²å°çº¢ä¹¦MCPè‡ªåŠ¨åŒ–è¿è¥å·¥å…·ã€‚é€šè¿‡ä¸‹è½½é¢„ç¼–è¯‘å®‰è£…åŒ…ï¼Œå®ŒæˆNode.jsçŽ¯å¢ƒé…ç½®åŽï¼Œè¿è¡Œç™»å½•å·¥å…·èŽ·å–cookies.jsonè®¤è¯æ–‡ä»¶ï¼Œå¯åŠ¨MCPä¸»æœåŠ¡å¹¶éªŒè¯è¿žæŽ¥ã€‚æœ€åŽæŽ¥å…¥Cursorç¼–è¾‘å™¨å®žçŽ°è‡ªç„¶è¯­è¨€æŽ§åˆ¶ï¼Œæ¼”ç¤ºäº†è´¦å·çŠ¶æ€æ£€æŸ¥å’Œå›¾æ–‡å‘å¸ƒç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€å¤æ‚é…ç½®ï¼Œé€‚åˆæ–°æ‰‹å¿«é€Ÿå®žçŽ°å°çº¢ä¹¦å†…å®¹è‡ªåŠ¨åŒ–ç®¡ç†ã€‚\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>@</p><div class=\"toc\"><div class=\"toc-container-header\">ç›®å½•</div><ul><li><a href=\"#ä¸€å‰è¨€\" rel=\"noopener nofollow\">ä¸€ã€å‰è¨€</a></li><li><a href=\"#äºŒå‡†å¤‡å·¥ä½œ\" rel=\"noopener nofollow\">äºŒã€å‡†å¤‡å·¥ä½œ</a><ul><li><a href=\"#21-ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž\" rel=\"noopener nofollow\">2.1 ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž</a></li><li><a href=\"#22-å¿…è£…ä¾èµ–ä»…2ä¸ªæžç®€\" rel=\"noopener nofollow\">2.2 å¿…è£…ä¾èµ–ï¼ˆä»…2ä¸ªï¼Œæžç®€ï¼‰</a><ul><li><a href=\"#1nodejsç”¨äºŽmcpè¿žæŽ¥éªŒè¯\" rel=\"noopener nofollow\">ï¼ˆ1ï¼‰Node.jsï¼ˆç”¨äºŽMCPè¿žæŽ¥éªŒè¯ï¼‰</a></li><li><a href=\"#2ç½‘ç»œçŽ¯å¢ƒ\" rel=\"noopener nofollow\">ï¼ˆ2ï¼‰ç½‘ç»œçŽ¯å¢ƒ</a></li></ul></li><li><a href=\"#23-ä¸‹è½½å°çº¢ä¹¦mcpå®‰è£…åŒ\" rel=\"noopener nofollow\">2.3 ä¸‹è½½å°çº¢ä¹¦MCPå®‰è£…åŒ…</a></li></ul></li><li><a href=\"#ä¸‰éƒ¨ç½²å°çº¢ä¹¦mcpæœåŠ¡\" rel=\"noopener nofollow\">ä¸‰ã€éƒ¨ç½²å°çº¢ä¹¦MCPæœåŠ¡</a><ul><li><a href=\"#31-è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„\" rel=\"noopener nofollow\">3.1 è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„</a></li><li><a href=\"#32-è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯\" rel=\"noopener nofollow\">3.2 è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯</a></li><li><a href=\"#33-å¯åŠ¨mcpä¸»æœåŠ¡\" rel=\"noopener nofollow\">3.3 å¯åŠ¨MCPä¸»æœåŠ¡</a></li><li><a href=\"#34-éªŒè¯mcpæœåŠ¡æ˜¯å¦æ­£å¸¸\" rel=\"noopener nofollow\">3.4 éªŒè¯MCPæœåŠ¡æ˜¯å¦æ­£å¸¸</a></li></ul></li><li><a href=\"#å››æŽ¥å…¥cursorç¼–è¾‘å™¨\" rel=\"noopener nofollow\">å››ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨</a><ul><li><a href=\"#41-æ‰¾åˆ°cursorçš„mcpé…ç½®æ–‡ä»¶\" rel=\"noopener nofollow\">4.1 æ‰¾åˆ°Cursorçš„MCPé…ç½®æ–‡ä»¶</a></li><li><a href=\"#42-é…ç½®mcpè¿žæŽ¥ä¿¡æ¯\" rel=\"noopener nofollow\">4.2 é…ç½®MCPè¿žæŽ¥ä¿¡æ¯</a></li><li><a href=\"#43-éªŒè¯cursorä¸Žmcpçš„è¿žæŽ¥\" rel=\"noopener nofollow\">4.3 éªŒè¯Cursorä¸ŽMCPçš„è¿žæŽ¥</a></li></ul></li><li><a href=\"#äº”cursorä¸­ä½¿ç”¨å°çº¢ä¹¦mcpå®žæˆ˜\" rel=\"noopener nofollow\">äº”ã€Cursorä¸­ä½¿ç”¨å°çº¢ä¹¦MCPå®žæˆ˜</a><ul><li><a href=\"#51-åŸºç¡€åŠŸèƒ½æ£€æŸ¥ç™»å½•çŠ¶æ€\" rel=\"noopener nofollow\">5.1 åŸºç¡€åŠŸèƒ½ï¼šæ£€æŸ¥ç™»å½•çŠ¶æ€</a></li><li><a href=\"#52-æ ¸å¿ƒåŠŸèƒ½å‘å¸ƒå°çº¢ä¹¦å›¾æ–‡\" rel=\"noopener nofollow\">5.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å¸ƒå°çº¢ä¹¦å›¾æ–‡</a><ul><li><a href=\"#æ­¥éª¤1å‡†å¤‡å‘å¸ƒç´ æ\" rel=\"noopener nofollow\">æ­¥éª¤1ï¼šå‡†å¤‡å‘å¸ƒç´ æ</a></li><li><a href=\"#æ­¥éª¤2åœ¨cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤\" rel=\"noopener nofollow\">æ­¥éª¤2ï¼šåœ¨Cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤</a></li><li><a href=\"#æ­¥éª¤3æŸ¥çœ‹å‘å¸ƒç»“æžœ\" rel=\"noopener nofollow\">æ­¥éª¤3ï¼šæŸ¥çœ‹å‘å¸ƒç»“æžœ</a></li></ul></li><li><a href=\"#53-å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨\" rel=\"noopener nofollow\">5.3 å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨</a></li></ul></li><li><a href=\"#å…­å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ\" rel=\"noopener nofollow\">å…­ã€å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ</a><ul><li><a href=\"#é—®é¢˜1ç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—ä¸‹è½½æµè§ˆå™¨å¤±è´¥\" rel=\"noopener nofollow\">é—®é¢˜1ï¼šç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—/ä¸‹è½½æµè§ˆå™¨å¤±è´¥</a></li><li><a href=\"#é—®é¢˜2cursoræç¤ºæ— æ³•è¿žæŽ¥åˆ°mcpæœåŠ¡\" rel=\"noopener nofollow\">é—®é¢˜2ï¼šCursoræç¤ºã€Œæ— æ³•è¿žæŽ¥åˆ°MCPæœåŠ¡ã€</a></li><li><a href=\"#é—®é¢˜3å‘å¸ƒå›¾æ–‡æç¤ºå›¾ç‰‡è·¯å¾„é”™è¯¯\" rel=\"noopener nofollow\">é—®é¢˜3ï¼šå‘å¸ƒå›¾æ–‡æç¤ºã€Œå›¾ç‰‡è·¯å¾„é”™è¯¯ã€</a></li><li><a href=\"#é—®é¢˜4è´¦å·è¢«è¸¢ä¸‹çº¿\" rel=\"noopener nofollow\">é—®é¢˜4ï¼šè´¦å·è¢«è¸¢ä¸‹çº¿</a></li></ul></li><li><a href=\"#ä¸ƒæ€»ç»“\" rel=\"noopener nofollow\">ä¸ƒã€æ€»ç»“</a></li></ul></div><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><p></p>\n<h1 id=\"ä¸€å‰è¨€\">ä¸€ã€å‰è¨€</h1>\n<p>å°çº¢ä¹¦MCPï¼ˆxiaohongshu-mcpï¼‰æ˜¯ä¸€æ¬¾èƒ½å®žçŽ°å°çº¢ä¹¦è‡ªåŠ¨åŒ–è¿è¥çš„å·¥å…·ï¼Œæ”¯æŒç™»å½•éªŒè¯ã€å›¾æ–‡/è§†é¢‘å‘å¸ƒã€è¯„è®ºäº’åŠ¨ã€ç”¨æˆ·ä¿¡æ¯æŸ¥è¯¢ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚ç›¸æ¯”æºç ç¼–è¯‘ã€Dockeréƒ¨ç½²ï¼Œ<strong>ä¸‹è½½é¢„ç¼–è¯‘å®‰è£…åŒ…</strong>æ˜¯æœ€å¿«æ·çš„æ–¹å¼ï¼Œæ— éœ€é…ç½®å¼€å‘çŽ¯å¢ƒï¼Œæ–°æ‰‹ä¹Ÿèƒ½å¿«é€Ÿä¸Šæ‰‹ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>æœ¬æ–‡å°†å…¨ç¨‹åŸºäºŽã€Œå®‰è£…åŒ…ä¸‹è½½ã€çš„æ–¹å¼ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ å®Œæˆå°çº¢ä¹¦MCPçš„éƒ¨ç½²ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨ï¼Œå¹¶æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½çš„ä½¿ç”¨ï¼Œè®©ä½ è½»æ¾å®žçŽ°å°çº¢ä¹¦å†…å®¹çš„è‡ªåŠ¨åŒ–ç®¡ç†ã€‚</p>\n<h1 id=\"äºŒå‡†å¤‡å·¥ä½œ\">äºŒã€å‡†å¤‡å·¥ä½œ</h1>\n<h2 id=\"21-ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž\">2.1 ç³»ç»ŸçŽ¯å¢ƒè¯´æ˜Ž</h2>\n<p>æ”¯æŒçš„ç³»ç»Ÿç‰ˆæœ¬ï¼ˆè¯·å¯¹åº”ä¸‹è½½ï¼‰ï¼š</p>\n<ul>\n<li>macOSï¼šApple Siliconï¼ˆarm64ï¼‰/ Intelï¼ˆamd64ï¼‰</li>\n<li>Windowsï¼šx64ï¼ˆWindows 10/11 å‡å¯ï¼‰</li>\n<li>Linuxï¼šx64</li>\n</ul>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"22-å¿…è£…ä¾èµ–ä»…2ä¸ªæžç®€\">2.2 å¿…è£…ä¾èµ–ï¼ˆä»…2ä¸ªï¼Œæžç®€ï¼‰</h2>\n<h3 id=\"1nodejsç”¨äºŽmcpè¿žæŽ¥éªŒè¯\">ï¼ˆ1ï¼‰Node.jsï¼ˆç”¨äºŽMCPè¿žæŽ¥éªŒè¯ï¼‰</h3>\n<p>æ— è®ºå“ªä¸ªç³»ç»Ÿï¼Œå»ºè®®é€šè¿‡å®˜æ–¹æŽ¨èæ–¹å¼å®‰è£…Node.js LTSç‰ˆæœ¬ï¼Œç¡®ä¿çŽ¯å¢ƒå˜é‡è‡ªåŠ¨é…ç½®ï¼š</p>\n<ul>\n<li>Windowsï¼šæ‰“å¼€ã€Œç®¡ç†å‘˜å‘½ä»¤è¡Œã€æ‰§è¡Œ<pre><code class=\"language-bash\">winget install OpenJS.NodeJS.LTS\n</code></pre>\n</li>\n<li>macOS/Linuxï¼šå‚è€ƒ <a href=\"https://nodejs.org/zh-cn/download/\" rel=\"noopener nofollow\" target=\"_blank\">Node.jså®˜æ–¹ä¸‹è½½é¡µ</a> å®‰è£…LTSç‰ˆæœ¬</li>\n</ul>\n<h3 id=\"2ç½‘ç»œçŽ¯å¢ƒ\">ï¼ˆ2ï¼‰ç½‘ç»œçŽ¯å¢ƒ</h3>\n<p>é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆçº¦150MBï¼‰ï¼Œéœ€ç¡®ä¿ç½‘ç»œé€šç•…ï¼ŒåŽç»­æ— éœ€é‡å¤ä¸‹è½½ã€‚</p>\n<h2 id=\"23-ä¸‹è½½å°çº¢ä¹¦mcpå®‰è£…åŒ…\">2.3 ä¸‹è½½å°çº¢ä¹¦MCPå®‰è£…åŒ…</h2>\n<ol>\n<li>æ‰“å¼€ <a href=\"https://github.com/xpzouying/xiaohongshu-mcp/releases\" rel=\"noopener nofollow\" target=\"_blank\">xiaohongshu-mcpçš„GitHub Releasesé¡µé¢</a></li>\n<li>æ ¹æ®è‡ªå·±çš„ç³»ç»Ÿä¸‹è½½å¯¹åº”å®‰è£…åŒ…ï¼š\n<ul>\n<li>Windows x64ï¼š<code>xiaohongshu-mcp-windows-amd64.zip</code></li>\n<li>macOS Apple Siliconï¼š<code>xiaohongshu-mcp-darwin-arm64.zip</code></li>\n<li>macOS Intelï¼š<code>xiaohongshu-mcp-darwin-amd64.zip</code></li>\n<li>Linux x64ï¼š<code>xiaohongshu-mcp-linux-amd64.zip</code></li>\n</ul>\n</li>\n<li>ä¸‹è½½å®ŒæˆåŽï¼Œå°†åŽ‹ç¼©åŒ…è§£åŽ‹åˆ°ä»»æ„ç›®å½•ï¼ˆå»ºè®®è·¯å¾„ä¸å«ä¸­æ–‡/ç©ºæ ¼ï¼Œæ¯”å¦‚ <code>D:\\xiaohongshu-mcp</code> æˆ– <code>/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp</code>ï¼‰ã€‚</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>æ³¨æ„cookies.jsonæ˜¯ç™»å½•ä¹‹åŽæ‰ä¼šæœ‰çš„ï¼Œåˆšåˆšè§£åŽ‹å®Œåªä¼šæœ‰æˆ‘åœˆèµ·æ¥çš„è¿™ä¸¤ä¸ª</p>\n<h1 id=\"ä¸‰éƒ¨ç½²å°çº¢ä¹¦mcpæœåŠ¡\">ä¸‰ã€éƒ¨ç½²å°çº¢ä¹¦MCPæœåŠ¡</h1>\n<h2 id=\"31-è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„\">3.1 è§£åŽ‹å®‰è£…åŒ…å¹¶ç¡®è®¤æ–‡ä»¶ç»“æž„</h2>\n<p>è§£åŽ‹åŽç›®å½•å†…ä¼šåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼ˆä»¥Windowsä¸ºä¾‹ï¼‰ï¼š</p>\n<ul>\n<li><code>xiaohongshu-login-windows-amd64.exe</code>ï¼šç™»å½•å·¥å…·ï¼ˆå¿…å…ˆè¿è¡Œï¼‰</li>\n<li><code>xiaohongshu-mcp-windows-amd64.exe</code>ï¼šMCPä¸»æœåŠ¡ç¨‹åº</li>\n</ul>\n<blockquote>\n<p>å…¶ä»–ç³»ç»Ÿå¯¹åº”æ–‡ä»¶ï¼šmacOSæ˜¯<code>xiaohongshu-login-darwin-arm64</code>/<code>xiaohongshu-mcp-darwin-arm64</code>ï¼ŒLinuxæ˜¯<code>xiaohongshu-login-linux-amd64</code>/<code>xiaohongshu-mcp-linux-amd64</code>ã€‚</p>\n</blockquote>\n<h2 id=\"32-è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯\">3.2 è¿è¡Œç™»å½•å·¥å…·å®Œæˆå°çº¢ä¹¦è®¤è¯</h2>\n<p>è¿™æ˜¯æ ¸å¿ƒæ­¥éª¤ï¼ŒMCPæœåŠ¡ä¾èµ–ç™»å½•åŽçš„Cookiesæ‰èƒ½æ­£å¸¸å·¥ä½œï¼š</p>\n<ol>\n<li>æ‰“å¼€ç»ˆç«¯/å‘½ä»¤è¡Œï¼Œè¿›å…¥è§£åŽ‹ç›®å½•ï¼š\n<ul>\n<li>Windowsï¼šåœ¨è§£åŽ‹æ–‡ä»¶å¤¹ç©ºç™½å¤„å³é”® â†’ ã€Œåœ¨ç»ˆç«¯ä¸­æ‰“å¼€ã€</li>\n<li>macOS/Linuxï¼šæ‰“å¼€ç»ˆç«¯ï¼Œæ‰§è¡Œ <code>cd /ä½ çš„è§£åŽ‹è·¯å¾„/xiaohongshu-mcp</code></li>\n</ul>\n</li>\n<li>è¿è¡Œç™»å½•å·¥å…·ï¼š\n<ul>\n<li>Windowsï¼š<pre><code class=\"language-bash\">./xiaohongshu-login-windows-amd64.exe\n</code></pre>\n</li>\n<li>macOS/Linuxï¼š<pre><code class=\"language-bash\">chmod +x xiaohongshu-login-darwin-arm64  # èµ‹äºˆæ‰§è¡Œæƒé™ï¼ˆä»…é¦–æ¬¡ï¼‰\n./xiaohongshu-login-darwin-arm64\n</code></pre>\n</li>\n</ul>\n</li>\n<li>ç™»å½•æµç¨‹ï¼š\n<ul>\n<li>è¿è¡ŒåŽä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆè€å¿ƒç­‰å¾…ï¼‰ï¼›</li>\n<li>å¼¹å‡ºå°çº¢ä¹¦ç™»å½•é¡µé¢ï¼ˆæ‰«ç /æ‰‹æœºå·ç™»å½•å‡å¯ï¼‰ï¼›</li>\n<li>ç™»å½•æˆåŠŸåŽï¼Œç»ˆç«¯ä¼šæç¤ºã€Œç™»å½•æˆåŠŸã€ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆ <code>cookies.json</code> æ–‡ä»¶ï¼ˆä¿å­˜åœ¨å½“å‰ç›®å½•ï¼Œåˆ‡å‹¿åˆ é™¤ï¼‰ã€‚</li>\n</ul>\n</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<blockquote>\n<p>âš ï¸ é‡è¦æé†’ï¼šå°çº¢ä¹¦è´¦å·ä¸å…è®¸å¤šç½‘é¡µç«¯ç™»å½•ï¼Œç™»å½•MCPåŽï¼Œä¸è¦åœ¨å…¶ä»–æµè§ˆå™¨ç™»å½•åŒä¸€è´¦å·ï¼Œå¦åˆ™ä¼šè¢«è¸¢ä¸‹çº¿ï¼ˆæ‰‹æœºAppç™»å½•ä¸å—å½±å“ï¼‰ã€‚</p>\n</blockquote>\n<h2 id=\"33-å¯åŠ¨mcpä¸»æœåŠ¡\">3.3 å¯åŠ¨MCPä¸»æœåŠ¡</h2>\n<p>ç™»å½•æˆåŠŸåŽï¼Œç»§ç»­åœ¨ç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨MCPæœåŠ¡ï¼š</p>\n<ul>\n<li>Windowsï¼š<pre><code class=\"language-bash\"># æ— å¤´æ¨¡å¼ï¼ˆæ— æµè§ˆå™¨ç•Œé¢ï¼ŒæŽ¨èç”Ÿäº§ä½¿ç”¨ï¼‰\n./xiaohongshu-mcp-windows-amd64.exe\n\n# éžæ— å¤´æ¨¡å¼ï¼ˆæœ‰æµè§ˆå™¨ç•Œé¢ï¼Œè°ƒè¯•ç”¨ï¼‰\n./xiaohongshu-mcp-windows-amd64.exe -headless=false\n</code></pre>\n</li>\n<li>macOS/Linuxï¼š<pre><code class=\"language-bash\">chmod +x xiaohongshu-mcp-darwin-arm64  # èµ‹äºˆæ‰§è¡Œæƒé™ï¼ˆä»…é¦–æ¬¡ï¼‰\n# æ— å¤´æ¨¡å¼\n./xiaohongshu-mcp-darwin-arm64\n# éžæ— å¤´æ¨¡å¼\n./xiaohongshu-mcp-darwin-arm64 -headless=false\n</code></pre>\n</li>\n</ul>\n<p>å¯åŠ¨æˆåŠŸçš„æ ‡å¿—ï¼šç»ˆç«¯æ— æŠ¥é”™ï¼Œä¸”æ˜¾ç¤ºã€ŒMCPæœåŠ¡å¯åŠ¨æˆåŠŸï¼Œç«¯å£ï¼š18060ã€ï¼ˆé»˜è®¤ç«¯å£18060ï¼Œè¯·å‹¿å ç”¨ï¼‰ã€‚<br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"34-éªŒè¯mcpæœåŠ¡æ˜¯å¦æ­£å¸¸\">3.4 éªŒè¯MCPæœåŠ¡æ˜¯å¦æ­£å¸¸</h2>\n<p>æ‰§è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯æœåŠ¡å¯ç”¨æ€§ï¼š</p>\n<pre><code class=\"language-bash\">npx @modelcontextprotocol/inspector\n</code></pre>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\nå·¦ä¸Šè§’<strong>Transport Type</strong>ä¸‹æ‹‰æ¡†ï¼ŒæŠŠSTDIOæ”¹æˆ<strong>Streamable HTTP</strong>ï¼›<br />\næ”¹å®ŒåŽç•Œé¢ä¼šå‡ºçŽ°URLè¾“å…¥æ¡†ï¼ŒæŠŠhttp://localhost:18060/mcpå¡«åˆ°è¿™ä¸ª <strong>URL æ¡†é‡Œ</strong>ï¼›<br />\nç‚¹å‡»å·¦ä¾§çš„<strong>Connect</strong>æŒ‰é’®ã€‚<br />\næˆåŠŸæ ‡å¿—ï¼š<strong>å·¦ä¸‹è§’æ˜¾ç¤ºConnected</strong><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<p>ç‚¹å‡»ä¸­é—´çš„List Tools<br />\nä¸­é—´åŒºåŸŸåŠ è½½å‡ºå°çº¢ä¹¦ MCP çš„æ‰€æœ‰å·¥å…· / èƒ½åŠ›åˆ—è¡¨ã€<br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h1 id=\"å››æŽ¥å…¥cursorç¼–è¾‘å™¨\">å››ã€æŽ¥å…¥Cursorç¼–è¾‘å™¨</h1>\n<p>Cursoræ˜¯æ”¯æŒMCPåè®®çš„AIç¼–è¾‘å™¨ï¼ŒæŽ¥å…¥åŽå¯ç›´æŽ¥åœ¨Cursorä¸­é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨å°çº¢ä¹¦MCPçš„æ‰€æœ‰åŠŸèƒ½ï¼Œæ— éœ€æ‰‹åŠ¨å†™æŽ¥å£è¯·æ±‚ã€‚</p>\n<h2 id=\"41-æ‰¾åˆ°cursorçš„mcpé…ç½®æ–‡ä»¶\">4.1 æ‰¾åˆ°Cursorçš„MCPé…ç½®æ–‡ä»¶</h2>\n<ol>\n<li>æ‰“å¼€Cursorç¼–è¾‘å™¨ï¼›</li>\n<li>ç¡®è®¤Cursorçš„MCPé…ç½®ç›®å½•ï¼š\n<ul>\n<li>æ ¸å¿ƒé…ç½®æ–‡ä»¶è·¯å¾„å‚è€ƒï¼š<code>.cursor/mcp.json</code>ï¼ˆå¯åœ¨Cursorçš„ã€Œè®¾ç½®â†’MCPã€ä¸­æ‰¾åˆ°é…ç½®å…¥å£ï¼Œæˆ–ç›´æŽ¥åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºè¯¥æ–‡ä»¶ï¼‰ã€‚</li>\n</ul>\n</li>\n</ol>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"42-é…ç½®mcpè¿žæŽ¥ä¿¡æ¯\">4.2 é…ç½®MCPè¿žæŽ¥ä¿¡æ¯</h2>\n<p>åˆ›å»º/ç¼–è¾‘ <code>.cursor/mcp.json</code> æ–‡ä»¶ï¼Œå†™å…¥ä»¥ä¸‹å†…å®¹ï¼š</p>\n<pre><code class=\"language-json\">{\n    \"mcpServers\": {\n        \"xiaohongshu-mcp\": {\n            \"url\": \"http://localhost:18060/mcp\",\n            \"description\": \"å°çº¢ä¹¦å†…å®¹å‘å¸ƒæœåŠ¡ - MCP Streamable HTTP\"\n        }\n    }\n}\n</code></pre>\n<p>ä¿å­˜æ–‡ä»¶åŽï¼Œé‡å¯Cursorè®©é…ç½®ç”Ÿæ•ˆã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"43-éªŒè¯cursorä¸Žmcpçš„è¿žæŽ¥\">4.3 éªŒè¯Cursorä¸ŽMCPçš„è¿žæŽ¥</h2>\n<ol>\n<li>æ‰“å¼€Cursorï¼Œæ–°å»ºä¸€ä¸ªå¯¹è¯çª—å£ï¼›</li>\n<li>åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ï¼š<code>æ£€æŸ¥å°çº¢ä¹¦MCPçš„ç™»å½•çŠ¶æ€</code>ï¼›</li>\n<li>å‘é€æŒ‡ä»¤åŽï¼ŒCursorä¼šè‡ªåŠ¨è°ƒç”¨å°çº¢ä¹¦MCPçš„ã€Œæ£€æŸ¥ç™»å½•çŠ¶æ€ã€åŠŸèƒ½ï¼Œè¿”å›žã€Œå½“å‰è´¦å·å·²ç™»å½•ã€å³ä»£è¡¨æŽ¥å…¥æˆåŠŸã€‚</li>\n</ol>\n<h1 id=\"äº”cursorä¸­ä½¿ç”¨å°çº¢ä¹¦mcpå®žæˆ˜\">äº”ã€Cursorä¸­ä½¿ç”¨å°çº¢ä¹¦MCPå®žæˆ˜</h1>\n<h2 id=\"51-åŸºç¡€åŠŸèƒ½æ£€æŸ¥ç™»å½•çŠ¶æ€\">5.1 åŸºç¡€åŠŸèƒ½ï¼šæ£€æŸ¥ç™»å½•çŠ¶æ€</h2>\n<p>åœ¨Cursorå¯¹è¯æ¡†ä¸­è¾“å…¥ï¼š</p>\n<pre><code>æ£€æŸ¥æˆ‘çš„å°çº¢ä¹¦è´¦å·ç™»å½•çŠ¶æ€\n</code></pre>\n<p>å‘é€åŽï¼ŒMCPä¼šè¿”å›žå½“å‰è´¦å·çš„ç™»å½•çŠ¶æ€ï¼ˆå·²ç™»å½•/æœªç™»å½•ï¼‰ï¼Œå¦‚æžœæœªç™»å½•ï¼Œéœ€é‡æ–°è¿è¡Œç™»å½•å·¥å…·ã€‚</p>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /><br />\n<img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h2 id=\"52-æ ¸å¿ƒåŠŸèƒ½å‘å¸ƒå°çº¢ä¹¦å›¾æ–‡\">5.2 æ ¸å¿ƒåŠŸèƒ½ï¼šå‘å¸ƒå°çº¢ä¹¦å›¾æ–‡</h2>\n<h3 id=\"æ­¥éª¤1å‡†å¤‡å‘å¸ƒç´ æ\">æ­¥éª¤1ï¼šå‡†å¤‡å‘å¸ƒç´ æ</h3>\n<ul>\n<li>æœ¬åœ°å›¾ç‰‡ï¼šå°†å›¾ç‰‡æ”¾åˆ°MCPè§£åŽ‹ç›®å½•çš„ <code>images</code> æ–‡ä»¶å¤¹ï¼ˆæ²¡æœ‰åˆ™æ–°å»ºï¼‰ï¼›</li>\n<li>æ–‡æ¡ˆï¼šæ ‡é¢˜ï¼ˆâ‰¤20å­—ï¼‰+ æ­£æ–‡ï¼ˆâ‰¤1000å­—ï¼‰+ æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰ã€‚</li>\n</ul>\n<h3 id=\"æ­¥éª¤2åœ¨cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤\">æ­¥éª¤2ï¼šåœ¨Cursorä¸­å‘é€å‘å¸ƒæŒ‡ä»¤</h3>\n<pre><code>@xiaohongshu-mcp å‘å¸ƒä¸€ç¯‡å°çº¢ä¹¦å›¾æ–‡ï¼Œæ ‡é¢˜ï¼šã€Œæ–°æ‰‹å¿…çœ‹çš„MCPéƒ¨ç½²æ•™ç¨‹ã€ï¼Œæ­£æ–‡ï¼šã€Œæ— éœ€ç¼–è¯‘æºç ï¼Œä¸‹è½½å®‰è£…åŒ…å°±èƒ½éƒ¨ç½²å°çº¢ä¹¦MCPï¼Œé™„CursoræŽ¥å…¥å…¨æµç¨‹ï½žã€ï¼Œå›¾ç‰‡ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp/images/æ•™ç¨‹å°é¢.jpgï¼Œæ·»åŠ æ ‡ç­¾ï¼š#MCP #å°çº¢ä¹¦è‡ªåŠ¨åŒ– #Cursor\n</code></pre>\n<blockquote>\n<p>æ³¨æ„ï¼š</p>\n<ul>\n<li>å›¾ç‰‡è·¯å¾„éœ€å†™ç»å¯¹è·¯å¾„ï¼ˆWindowsç¤ºä¾‹ï¼š<code>D:\\xiaohongshu-mcp\\images\\æ•™ç¨‹å°é¢.jpg</code>ï¼‰ï¼›</li>\n<li>æ ‡é¢˜å’Œæ­£æ–‡éœ€ç¬¦åˆå°çº¢ä¹¦å­—æ•°é™åˆ¶ï¼ˆæ ‡é¢˜â‰¤20å­—ï¼Œæ­£æ–‡â‰¤1000å­—ï¼‰ã€‚</li>\n</ul>\n</blockquote>\n<p><img alt=\"åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°\" class=\"lazyload\" /></p>\n<h3 id=\"æ­¥éª¤3æŸ¥çœ‹å‘å¸ƒç»“æžœ\">æ­¥éª¤3ï¼šæŸ¥çœ‹å‘å¸ƒç»“æžœ</h3>\n<p>å‘é€æŒ‡ä»¤åŽï¼ŒCursorä¼šè¿”å›žå‘å¸ƒè¿›åº¦ï¼ŒæˆåŠŸåŽå¯åœ¨å°çº¢ä¹¦Appä¸­æŸ¥çœ‹å‘å¸ƒçš„ç¬”è®°ã€‚</p>\n<h2 id=\"53-å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨\">5.3 å…¶ä»–å¸¸ç”¨åŠŸèƒ½è°ƒç”¨</h2>\n<ul>\n<li>å‘å¸ƒè§†é¢‘ï¼š<pre><code>@xiaohongshu-mcp å‘å¸ƒå°çº¢ä¹¦è§†é¢‘ï¼Œæ ‡é¢˜ï¼šã€ŒMCPéƒ¨ç½²å®žæ“æ¼”ç¤ºã€ï¼Œæ­£æ–‡ï¼šã€Œæ‰‹æŠŠæ‰‹æ•™ä½ éƒ¨ç½²å°çº¢ä¹¦MCPï½žã€ï¼Œè§†é¢‘è·¯å¾„ï¼š/Users/ä½ çš„ç”¨æˆ·å/xiaohongshu-mcp/videos/æ¼”ç¤º.mp4\n</code></pre>\n</li>\n<li>èŽ·å–ç”¨æˆ·ä¸ªäººä¸»é¡µï¼š<pre><code>@xiaohongshu-mcp èŽ·å–ç”¨æˆ·IDä¸º123456çš„å°çº¢ä¹¦ä¸ªäººä¸»é¡µä¿¡æ¯\n</code></pre>\n</li>\n<li>å‘è¡¨è¯„è®ºï¼š<pre><code>@xiaohongshu-mcp ç»™å¸–å­IDä¸º741852çš„å°çº¢ä¹¦ç¬”è®°å‘è¡¨è¯„è®ºï¼šã€Œæ•™ç¨‹è¶…å®žç”¨ï¼ã€\n</code></pre>\n</li>\n</ul>\n<h1 id=\"å…­å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ\">å…­ã€å¸¸è§é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ</h1>\n<h2 id=\"é—®é¢˜1ç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—ä¸‹è½½æµè§ˆå™¨å¤±è´¥\">é—®é¢˜1ï¼šç™»å½•å·¥å…·è¿è¡ŒåŽæ— å¼¹çª—/ä¸‹è½½æµè§ˆå™¨å¤±è´¥</h2>\n<ul>\n<li>åŽŸå› ï¼šç½‘ç»œé™åˆ¶æˆ–æƒé™ä¸è¶³ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>ç¡®ä¿ç½‘ç»œèƒ½è®¿é—®å¤–ç½‘ï¼Œæˆ–åˆ‡æ¢ç½‘ç»œé‡è¯•ï¼›</li>\n<li>Windowséœ€ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œç»ˆç«¯ï¼ŒmacOS/Linuxéœ€èµ‹äºˆæ–‡ä»¶æ‰§è¡Œæƒé™ï¼ˆ<code>chmod +x æ–‡ä»¶å</code>ï¼‰ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜2cursoræç¤ºæ— æ³•è¿žæŽ¥åˆ°mcpæœåŠ¡\">é—®é¢˜2ï¼šCursoræç¤ºã€Œæ— æ³•è¿žæŽ¥åˆ°MCPæœåŠ¡ã€</h2>\n<ul>\n<li>åŽŸå› ï¼šMCPæœåŠ¡æœªå¯åŠ¨/ç«¯å£è¢«å ç”¨/é…ç½®æ–‡ä»¶è·¯å¾„é”™è¯¯ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>æ£€æŸ¥MCPæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼ˆç»ˆç«¯æ˜¯å¦æ˜¾ç¤ºç«¯å£18060ï¼‰ï¼›</li>\n<li>ç¡®è®¤ <code>.cursor/mcp.json</code> ä¸­çš„URLæ˜¯ <code>http://localhost:18060/mcp</code>ï¼›</li>\n<li>æ£€æŸ¥18060ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼ˆWindowsï¼š<code>netstat -ano | findstr 18060</code>ï¼ŒmacOS/Linuxï¼š<code>lsof -i:18060</code>ï¼‰ï¼Œå ç”¨åˆ™å…³é—­å¯¹åº”è¿›ç¨‹ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜3å‘å¸ƒå›¾æ–‡æç¤ºå›¾ç‰‡è·¯å¾„é”™è¯¯\">é—®é¢˜3ï¼šå‘å¸ƒå›¾æ–‡æç¤ºã€Œå›¾ç‰‡è·¯å¾„é”™è¯¯ã€</h2>\n<ul>\n<li>åŽŸå› ï¼šå›¾ç‰‡è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„/æœªæ”¾åˆ°æŒ‡å®šç›®å½•ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ˆå¦‚ <code>D:\\xiaohongshu-mcp\\images\\test.jpg</code>ï¼‰ï¼›</li>\n<li>ç¡®ä¿å›¾ç‰‡æ–‡ä»¶å­˜åœ¨ï¼Œä¸”è·¯å¾„æ— ä¸­æ–‡/ç©ºæ ¼ã€‚</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"é—®é¢˜4è´¦å·è¢«è¸¢ä¸‹çº¿\">é—®é¢˜4ï¼šè´¦å·è¢«è¸¢ä¸‹çº¿</h2>\n<ul>\n<li>åŽŸå› ï¼šåŒä¸€è´¦å·åœ¨å…¶ä»–ç½‘é¡µç«¯ç™»å½•ï¼›</li>\n<li>è§£å†³æ–¹æ¡ˆï¼š\n<ol>\n<li>é€€å‡ºå…¶ä»–ç½‘é¡µç«¯çš„å°çº¢ä¹¦ç™»å½•ï¼›</li>\n<li>é‡æ–°è¿è¡Œç™»å½•å·¥å…·ï¼Œé‡æ–°ç”ŸæˆCookiesã€‚</li>\n</ol>\n</li>\n</ul>\n<h1 id=\"ä¸ƒæ€»ç»“\">ä¸ƒã€æ€»ç»“</h1>\n<p>é€šè¿‡ã€Œä¸‹è½½å®‰è£…åŒ…ã€çš„æ–¹å¼éƒ¨ç½²å°çº¢ä¹¦MCPï¼Œå…¨ç¨‹æ— éœ€é…ç½®å¤æ‚çš„å¼€å‘çŽ¯å¢ƒï¼ˆå¦‚Golangã€Dockerï¼‰ï¼Œæ–°æ‰‹ä¹Ÿèƒ½åœ¨10åˆ†é’Ÿå†…å®Œæˆéƒ¨ç½²ã€‚æŽ¥å…¥CursoråŽï¼Œå¯ç›´æŽ¥é€šè¿‡è‡ªç„¶è¯­è¨€è°ƒç”¨MCPçš„æ‰€æœ‰åŠŸèƒ½ï¼Œå®žçŽ°å°çº¢ä¹¦ç™»å½•éªŒè¯ã€å›¾æ–‡/è§†é¢‘å‘å¸ƒã€è¯„è®ºäº’åŠ¨ç­‰è‡ªåŠ¨åŒ–æ“ä½œã€‚</p>\n<p>âš ï¸ é£Žé™©æç¤ºï¼šè¯¥å·¥å…·ä»…ç”¨äºŽå­¦ä¹ å’Œä¸ªäººåˆæ³•è¿è¥ï¼Œè¯·å‹¿ç”¨äºŽè¿è§„æ“ä½œï¼›Cookiesè¿‡æœŸåŽéœ€é‡æ–°ç™»å½•ï¼Œæ­£å¸¸ä½¿ç”¨ä¸‹ä¸ä¼šå¯¼è‡´è´¦å·å°ç¦ã€‚</p>\n<p>å¦‚æžœåœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯å‚è€ƒé¡¹ç›®çš„å®˜æ–¹æ–‡æ¡£ï¼ˆ<a href=\"https://github.com/xpzouying/xiaohongshu-mcp\" rel=\"noopener nofollow\" target=\"_blank\">xiaohongshu-mcp README</a>ï¼‰ï¼Œæˆ–åœ¨GitHub Issuesä¸­æé—®ã€‚</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 13:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\né˜…è¯»(<span id=\"post_view_count\">112</span>)&nbsp;\nè¯„è®º(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">æ”¶è—</a>&nbsp;\n<a href=\"\">ä¸¾æŠ¥</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]静态上下文在Pregel中的应用",
      "link": "https://www.cnblogs.com/jaydenai/p/19621105/static-context-in-pregel",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19621105/static-context-in-pregel\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 08:23\">\n    <span>[拆解LangChain执行引擎]静态上下文在Pregel中的应用</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在 Pregel 模型中，静态上下文是一个专门设计的依赖注入容器。它的出现是为了解决在复杂的图计算中，如何优雅地处理“不属于图状态，但Node运行又必须依赖的外部环境信息”这一痛点。这些数据具有一个共同的性质，那就是在整个运行生命周期内只读且固定。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在 Pregel 模型中，静态上下文是一个专门设计的依赖注入容器。它的出现是为了解决在复杂的图计算中，如何优雅地处理“不属于图状态，但Node运行又必须依赖的外部环境信息”这一痛点。这些数据具有一个共同的性质，那就是在整个运行生命周期内只读且固定，比如：</p>\n<ul>\n<li>身份信息：当前发起请求的user_id、org_id。</li>\n<li>外部客户端：已实例化的db_connection、redis_client、vector_store。</li>\n<li>策略约束：当前任务的safety_level或budget_limit。</li>\n</ul>\n<p>静态上下文是 Pregel 运行时提供的一个类型安全的环境变量容器。它将执行环境（Context）与业务轨迹（State）物理隔离，使得大型 Agent 系统的架构更加模块化，也更容易在复杂的生产环境下进行测试和调试。</p>\n<p>不同于以往字典形式的配置，静态上下文采用强类型 Schema 定义方法。由于其静态只读的特性，它在整个生命周期内保持一致性。静态上下文具有<code>单次运行锁定</code>机制，这保证Pregel对象一旦被调用，上下文对象在所有Node、所有 Superstep中引用的是同一个内存地址。它的<code>非持久化</code>特性进一步确保它不会被写入Checkpoint，所以当Pregel因为错误停止并从断点恢复时，我们必须重新提供一个相同的上下文对象。综上所示，静态上下文作为非序列化的、运行时的<code>旁路注入</code>而存在。</p>\n<p>静态上下文在Pregel被作为<code>Runtime</code>的一部分来传递的。如下所示的Runtime类的泛型参数ConextT指的就是静态上下文数据类型。除了返回该上下文的<code>context</code>字段，Runtime还具有额外三个字段分别返回用于长期存储的<code>store</code>字段（返回一个BaseStore对象）、实现“custom”流模式的<code>stream_writer</code>字段（返回一个StreamWriter对象），以及提供当前会话上一个返回值的<code>previous</code>字段。</p>\n<pre><code class=\"language-python\">@dataclass(**_DC_KWARGS)\nclass Runtime(Generic[ContextT]):\n    context: ContextT = field(default=None\n    store: BaseStore | None = field(default=None)\n    stream_writer: StreamWriter = field(default=_no_op_stream_writer)\n    previous: Any = field(default=None)\n</code></pre>\n<p>Pregel节点的处理函数读取静态上下文比较繁琐，以为除了承载输入的参数（一般是一个字典），我们只能额外定义一个<code>RunnableConfig</code>类型的参数，意味着基本上出原始输入外的其他任务信息都得从这个RunnableConfig配置中提取。RunnableConfig是一个字典，所以我们要提取所需数据的前提是得预先知道对用得Key。这样设计也能理解，因为LangGraph.Prege在整个<code>LangChain宇宙</code>中作为<code>执行引擎</code>而存在，它相当于LangChain体系的<code>内核</code>。Pregel提供的API本就不是针对Agent应用开发者，对开发者友好不是Pregel得设计目标，保持这个内核足够简洁更重要。</p>\n<p>RunnableConfig对象会贯穿整个Pregel引擎的执行，上游流程利用这个它像下游传递所需的组件和控制信息，传递的信息大都被至于<code>configurable</code>子节点下。如果对应的Key以<code>__pregel_</code>作为前缀，表示该条目其实是由Pregel内部使用的。Runtime对应的Key为<code>__pregel_runtime</code>。</p>\n<p>如下这个例子演示了如何声明、指定和读取静态上下文。我们定义一个承载基本用户信息的UserInfo数据类型作为静态上下文的Schema。作为Pregel唯一的Node，其处理函数提供了一个<code>RunnableConfig</code>类型的参数，我们从中提供作为运行时的Runtime对象，进而得到作为静态上下文的UserInfo对象。</p>\n<pre><code class=\"language-python\">from langchain_core.runnables import RunnableConfig\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom typing import Any, Literal\nfrom langgraph.channels import LastValue\nfrom langgraph.runtime import Runtime\nfrom dataclasses import dataclass\n\n@dataclass\nclass UserInfo:\n    id: str\n    name: str\n    gender: Literal[\"male\", \"female\"]\n\ndef handle(args: dict[str, Any], config: RunnableConfig) -&gt; str:\n    runtime: Runtime = config[\"configurable\"][\"__pregel_runtime\"]\n    return runtime.context.__repr__()\n\nnode = (NodeBuilder()\n    .subscribe_only(\"start\")\n    .write_to(\"output\")\n    .do(handle))\n    \napp = Pregel(\n    nodes={\"body\": node},\n    channels={\"start\": LastValue(None), \"output\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[\"output\"],\n    context_schema=UserInfo,\n)\n\nuser = UserInfo(id=\"123\", name=\"Alice\", gender=\"female\")\nresult = app.invoke(input={\"start\": None}, context=user)\nassert result[\"output\"] == user.__repr__()\n</code></pre>\n<p>在创建Pregel对象的时候，作为静态上下文的UserInfo类型直接以构造函数的<code>context_schema</code>参数进行声明。在调用其<code>invoke</code>方法的时候就通过context参数将指定的UserInfo对象作为静态上下文传递。静态上下文的设计初衷就是为了规避序列化的限制。它允许我们将复杂的、重量级的、带有外部依赖的对象的直接注入，而不会破坏 Pregel 模型对<code>状态一致性</code>和<code>可持久化</code>的要求。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 08:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">46</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "OpenClaw+OpenViking + NVIDIA API 配置教程",
      "link": "https://www.cnblogs.com/swizard/p/19622926",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/swizard/p/19622926\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:56\">\n    <span>OpenClaw+OpenViking + NVIDIA API 配置教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>本教程介绍如何在 OpenClaw 环境中配置 OpenViking，使用 NVIDIA NIM API 作为 Embedding 和 VLM 后端。</p>\n</blockquote>\n<h2 id=\"什么是-openviking\">什么是 OpenViking？</h2>\n<p>OpenViking 是火山引擎开源的 <strong>AI Agent 上下文数据库</strong>。它用\"虚拟文件系统\"的方式管理 Agent 的记忆、资源和技能，提供：</p>\n<ul>\n<li><strong>分层上下文</strong>：L0摘要 / L1概览 / L2全文，按需加载节省 Token</li>\n<li><strong>语义搜索</strong>：融合目录定位与向量检索</li>\n<li><strong>自动摘要</strong>：VLM 自动生成文档摘要和概览</li>\n<li><strong>会话记忆</strong>：自动提取对话中的长期记忆</li>\n</ul>\n<p>GitHub: <a href=\"https://github.com/volcengine/OpenViking\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/volcengine/OpenViking</a></p>\n<h2 id=\"前置条件\">前置条件</h2>\n<ul>\n<li>Python 3.9+</li>\n<li>NVIDIA NIM API Key（<a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">免费注册</a>）</li>\n<li>稳定的网络连接</li>\n</ul>\n<hr />\n<h2 id=\"第一步安装-openviking\">第一步：安装 OpenViking</h2>\n<pre><code class=\"language-bash\">pip install openviking\n</code></pre>\n<hr />\n<h2 id=\"第二步创建配置文件\">第二步：创建配置文件</h2>\n<p>创建目录和配置文件：</p>\n<pre><code class=\"language-bash\">mkdir -p ~/.openviking\n</code></pre>\n<p>编辑 <code>~/.openviking/ov.conf</code>：</p>\n<pre><code class=\"language-json\">{\n  \"embedding\": {\n    \"dense\": {\n      \"api_base\": \"https://integrate.api.nvidia.com/v1\",\n      \"api_key\": \"你的NVIDIA_API_KEY\",\n      \"provider\": \"openai\",\n      \"dimension\": 4096,\n      \"model\": \"nvidia/nv-embed-v1\"\n    }\n  },\n  \"vlm\": {\n    \"api_base\": \"https://integrate.api.nvidia.com/v1\",\n    \"api_key\": \"你的NVIDIA_API_KEY\",\n    \"provider\": \"openai\",\n    \"model\": \"meta/llama-3.3-70b-instruct\"\n  }\n}\n</code></pre>\n<h3 id=\"配置说明\">配置说明</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>api_base</code></td>\n<td>NVIDIA NIM API 端点</td>\n</tr>\n<tr>\n<td><code>api_key</code></td>\n<td>从 NVIDIA Build 平台获取</td>\n</tr>\n<tr>\n<td><code>dimension</code></td>\n<td>Embedding 维度，nv-embed-v1 固定为 4096</td>\n</tr>\n<tr>\n<td><code>embedding.model</code></td>\n<td>推荐使用 <code>nvidia/nv-embed-v1</code>（对称模型，不需要 input_type 参数）</td>\n</tr>\n<tr>\n<td><code>vlm.model</code></td>\n<td>用于生成摘要的语言模型，推荐 <code>meta/llama-3.3-70b-instruct</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"为什么不用-kimi-k25\">为什么不用 kimi-k2.5？</h3>\n<p>NVIDIA 上的推理模型（如 kimi-k2.5）返回的 <code>content</code> 字段为空，内容在 <code>reasoning</code> 字段里。OpenViking 期望标准的 <code>message.content</code> 格式，所以要用非推理模型。</p>\n<h3 id=\"如何获取-nvidia-api-key\">如何获取 NVIDIA API Key</h3>\n<ol>\n<li>访问 <a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://build.nvidia.com/</a></li>\n<li>登录/注册账号</li>\n<li>点击右上角用户名 → API Keys → Generate Key</li>\n<li>复制保存（只显示一次）</li>\n</ol>\n<hr />\n<h2 id=\"第三步设置环境变量\">第三步：设置环境变量</h2>\n<pre><code class=\"language-bash\">export OPENVIKING_CONFIG_FILE=~/.openviking/ov.conf\n</code></pre>\n<p>建议添加到 <code>~/.bashrc</code>：</p>\n<pre><code class=\"language-bash\">echo 'export OPENVIKING_CONFIG_FILE=~/.openviking/ov.conf' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>\n<hr />\n<h2 id=\"第四步验证安装\">第四步：验证安装</h2>\n<p>创建测试脚本 <code>test_openviking.py</code>：</p>\n<pre><code class=\"language-python\">import openviking as ov\n\n# 初始化客户端，数据存储在当前目录的 openviking_data 文件夹\nclient = ov.SyncOpenViking(path=\"./openviking_data\")\n\ntry:\n    client.initialize()\n    print(\"✅ OpenViking 初始化成功！\")\n    \n    # 添加一个测试文件\n    result = client.add_resource(path=\"./your_file.md\")\n    print(f\"添加文件: {result}\")\n    \n    # 等待处理完成\n    print(\"等待处理...\")\n    client.wait_processed()\n    print(\"✅ 处理完成！\")\n    \n    # 搜索测试\n    results = client.find(\"测试关键词\", limit=3)\n    print(f\"\\n搜索结果:\")\n    for r in results.resources:\n        print(f\"  {r.uri} (score: {r.score:.4f})\")\n    \n    client.close()\n    print(\"\\n🎉 OpenViking 配置成功！\")\n\nexcept Exception as e:\n    print(f\"错误: {e}\")\n    import traceback\n    traceback.print_exc()\n</code></pre>\n<p>运行：</p>\n<pre><code class=\"language-bash\">python test_openviking.py\n</code></pre>\n<hr />\n<h2 id=\"第五步核心-api-用法\">第五步：核心 API 用法</h2>\n<h3 id=\"添加资源\">添加资源</h3>\n<pre><code class=\"language-python\"># 添加单个文件\nresult = client.add_resource(path=\"./docs/readme.md\")\n\n# 添加 URL\nresult = client.add_resource(path=\"https://example.com/article.html\")\n</code></pre>\n<h3 id=\"目录浏览\">目录浏览</h3>\n<pre><code class=\"language-python\"># 列出根目录\nls_result = client.ls(\"viking://resources\")\n\n# 列出子目录\nls_result = client.ls(\"viking://resources/my_project\")\n</code></pre>\n<h3 id=\"语义搜索\">语义搜索</h3>\n<pre><code class=\"language-python\"># 搜索相关内容\nresults = client.find(\"如何配置 embedding\", limit=5)\n\nfor r in results.resources:\n    print(f\"URI: {r.uri}\")\n    print(f\"Score: {r.score}\")\n    print(f\"Content: {client.read(r.uri)[:200]}...\")\n</code></pre>\n<h3 id=\"获取摘要概览\">获取摘要/概览</h3>\n<pre><code class=\"language-python\"># L0 层：一句话摘要\nabstract = client.abstract(\"viking://resources/my_project\")\n\n# L1 层：详细概览\noverview = client.overview(\"viking://resources/my_project\")\n</code></pre>\n<h3 id=\"读取内容\">读取内容</h3>\n<pre><code class=\"language-python\"># 读取完整内容（L2 层）\ncontent = client.read(\"viking://resources/my_project/readme.md\")\n</code></pre>\n<hr />\n<h2 id=\"常见问题\">常见问题</h2>\n<h3 id=\"q-embedding-维度不匹配\">Q: Embedding 维度不匹配</h3>\n<p><strong>错误</strong>: <code>Dense vector dimension mismatch: expected 2048, got 4096</code></p>\n<p><strong>解决</strong>: 在配置文件中明确指定 <code>dimension: 4096</code>，匹配 <code>nvidia/nv-embed-v1</code> 的输出维度。</p>\n<h3 id=\"q-vlm-返回-nonetype-错误\">Q: VLM 返回 NoneType 错误</h3>\n<p><strong>错误</strong>: <code>'NoneType' object is not subscriptable</code></p>\n<p><strong>原因</strong>: 使用了推理模型（如 kimi-k2.5），其返回格式与 OpenViking 不兼容。</p>\n<p><strong>解决</strong>: 换用标准模型如 <code>meta/llama-3.3-70b-instruct</code>。</p>\n<h3 id=\"q-nvidia-api-报错-input_type-required\">Q: NVIDIA API 报错 input_type required</h3>\n<p><strong>错误</strong>: <code>'input_type' parameter is required for asymmetric models</code></p>\n<p><strong>原因</strong>: 某些 Embedding 模型（如 nv-embedqa-e5-v5）是非对称模型，需要指定 query 或 document。</p>\n<p><strong>解决</strong>: 使用对称模型 <code>nvidia/nv-embed-v1</code>，不需要 input_type。</p>\n<h3 id=\"q-文件名冲突\">Q: 文件名冲突</h3>\n<p><strong>错误</strong>: <code>directory already exists: /resources/第01章</code></p>\n<p><strong>原因</strong>: OpenViking 用文件名（不含路径）作为 URI，不同目录下的同名文件会冲突。</p>\n<p><strong>解决</strong>:</p>\n<ul>\n<li>方案一：重命名文件，使用唯一名称</li>\n<li>方案二：分批导入，避免同时添加同名文件</li>\n<li>方案三：等待官方修复此设计问题</li>\n</ul>\n<hr />\n<h2 id=\"为什么用-openviking替代-openclaw-默认的-qmd-记忆后端\">为什么用 OpenViking？——替代 OpenClaw 默认的 qmd 记忆后端</h2>\n<h3 id=\"openclaw-现有记忆方案的局限\">OpenClaw 现有记忆方案的局限</h3>\n<p>OpenClaw 默认使用 <code>qmd</code> 作为记忆后端，配合手动维护的 <code>MEMORY.md</code> 和 <code>memory/*.md</code> 文件。这套方案够用，但有几个痛点：</p>\n<ol>\n<li><strong>搜索精度有限</strong> — qmd 基于简单向量匹配，缺乏层次化理解</li>\n<li><strong>手动维护成本高</strong> — 记忆文件需要人工整理，容易遗漏</li>\n<li><strong>缺乏自动摘要</strong> — Agent 需要读取整个文件才能了解内容</li>\n<li><strong>无法管理大量文档</strong> — 当 workspace 文件很多时，qmd 不够用</li>\n</ol>\n<h3 id=\"openviking-的优势\">OpenViking 的优势</h3>\n<table>\n<thead>\n<tr>\n<th>能力</th>\n<th>qmd</th>\n<th>OpenViking</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>语义搜索</td>\n<td>✅ 基础</td>\n<td>✅ 目录递归 + 语义融合</td>\n</tr>\n<tr>\n<td>自动摘要</td>\n<td>❌</td>\n<td>✅ L0/L1/L2 三层</td>\n</tr>\n<tr>\n<td>结构化浏览</td>\n<td>❌</td>\n<td>✅ 虚拟文件系统</td>\n</tr>\n<tr>\n<td>Token 节省</td>\n<td>❌</td>\n<td>✅ 按需加载</td>\n</tr>\n<tr>\n<td>会话记忆自动提取</td>\n<td>❌</td>\n<td>✅ 自动提取长期记忆</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"集成方式\">集成方式</h3>\n<h4 id=\"方式一作为-openclaw-的补充记忆推荐\">方式一：作为 OpenClaw 的补充记忆（推荐）</h4>\n<p>保留 qmd 作为日常轻量记忆，用 OpenViking 管理大型文档库：</p>\n<pre><code class=\"language-python\"># 把 workspace 里的书籍、项目文档等大型资源导入 OpenViking\nimport glob, openviking as ov\n\nclient = ov.SyncOpenViking(path=\"./openviking_data\")\nclient.initialize()\n\nfor f in glob.glob(\"./books/**/*.md\", recursive=True):\n    client.add_resource(path=f)\n\nfor f in glob.glob(\"./docs/**/*.md\", recursive=True):\n    client.add_resource(path=f)\n\nclient.wait_processed()\nclient.close()\n</code></pre>\n<p>Agent 工作流：</p>\n<ol>\n<li>日常对话 → qmd 记忆（轻量、快速）</li>\n<li>需要查阅文档 → OpenViking 语义搜索（精准、分层）</li>\n<li>Sub-agent 写作/研究 → OpenViking 提供上下文（节省 Token）</li>\n</ol>\n<h4 id=\"方式二完全替代-qmd\">方式二：完全替代 qmd</h4>\n<p>将 OpenClaw 的所有记忆文件也导入 OpenViking：</p>\n<pre><code class=\"language-python\"># 导入记忆文件\nfor f in glob.glob(\"./memory/*.md\"):\n    client.add_resource(path=f)\n\n# 导入 workspace 所有 markdown\nfor f in glob.glob(\"./**/*.md\", recursive=True):\n    client.add_resource(path=f)\n</code></pre>\n<blockquote>\n<p>⚠️ 目前 OpenViking 还不能直接作为 OpenClaw 的 <code>memory.backend</code> 配置项。需要通过 skill 的 CLI 工具间接调用。未来如果 OpenClaw 支持自定义记忆后端插件，可以更深度集成。</p>\n</blockquote>\n<h4 id=\"方式三给-sub-agent-提供上下文\">方式三：给 Sub-agent 提供上下文</h4>\n<p>写书、做研究等任务时，sub-agent 可以先搜索 OpenViking 获取相关上下文，而不是把整本书塞进 prompt：</p>\n<pre><code class=\"language-bash\"># Sub-agent 先搜索相关内容\npython3 scripts/viking.py search \"武松的性格分析\" --limit 3\n\n# 然后只读取最相关的段落\npython3 scripts/viking.py read viking://resources/第01章/张三的叙事.md\n</code></pre>\n<p>这样一个 sub-agent 只需要加载几千 token 的相关内容，而不是整本书的 10 万+ token。</p>\n<h3 id=\"已封装的-openclaw-skill\">已封装的 OpenClaw Skill</h3>\n<p>我们已经把 OpenViking 封装为 OpenClaw skill，安装后 Agent 可以直接使用：</p>\n<pre><code class=\"language-bash\"># 安装 skill\ngit clone https://github.com/swizardlv/openclaw_openviking_skill.git\ncp -r openclaw_openviking_skill/openviking ~/.openclaw/workspace/skills/\n</code></pre>\n<p>Skill 提供的命令：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>viking.py add &lt;file&gt;</code></td>\n<td>索引文件</td>\n</tr>\n<tr>\n<td><code>viking.py add-dir &lt;dir&gt;</code></td>\n<td>批量索引目录</td>\n</tr>\n<tr>\n<td><code>viking.py search &lt;query&gt;</code></td>\n<td>语义搜索</td>\n</tr>\n<tr>\n<td><code>viking.py ls [uri]</code></td>\n<td>浏览资源</td>\n</tr>\n<tr>\n<td><code>viking.py abstract &lt;uri&gt;</code></td>\n<td>获取摘要</td>\n</tr>\n<tr>\n<td><code>viking.py overview &lt;uri&gt;</code></td>\n<td>获取概览</td>\n</tr>\n<tr>\n<td><code>viking.py read &lt;uri&gt;</code></td>\n<td>读取全文</td>\n</tr>\n<tr>\n<td><code>viking.py info</code></td>\n<td>查看配置状态</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"附录可用的-nvidia-embedding-模型\">附录：可用的 NVIDIA Embedding 模型</h2>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>维度</th>\n<th>类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>nvidia/nv-embed-v1</code></td>\n<td>4096</td>\n<td>对称</td>\n<td>✅ 推荐，无需 input_type</td>\n</tr>\n<tr>\n<td><code>nvidia/nv-embedqa-e5-v5</code></td>\n<td>1024</td>\n<td>非对称</td>\n<td>需要 input_type 参数</td>\n</tr>\n<tr>\n<td><code>nvidia/llama-3.2-nv-embedqa-1b-v2</code></td>\n<td>2048</td>\n<td>非对称</td>\n<td>需要 input_type 参数</td>\n</tr>\n<tr>\n<td><code>nvidia/nv-embedcode-7b-v1</code></td>\n<td>4096</td>\n<td>对称</td>\n<td>适合代码</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"附录可用的-nvidia-chat-模型用于-vlm\">附录：可用的 NVIDIA Chat 模型（用于 VLM）</h2>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>meta/llama-3.3-70b-instruct</code></td>\n<td>✅ 推荐，标准格式</td>\n</tr>\n<tr>\n<td><code>meta/llama-3.1-70b-instruct</code></td>\n<td>稳定版本</td>\n</tr>\n<tr>\n<td><code>meta/llama-3.1-8b-instruct</code></td>\n<td>轻量版</td>\n</tr>\n<tr>\n<td><code>mistralai/mistral-large</code></td>\n<td>Mistral 系列</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>⚠️ 避免使用推理模型（如 kimi-k2.5、deepseek-r1），它们返回的格式与 OpenViking 不兼容。</p>\n</blockquote>\n<hr />\n<h2 id=\"参考链接\">参考链接</h2>\n<ul>\n<li>OpenViking 官网: <a href=\"https://www.openviking.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://www.openviking.ai</a></li>\n<li>OpenViking GitHub: <a href=\"https://github.com/volcengine/OpenViking\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/volcengine/OpenViking</a></li>\n<li>NVIDIA NIM API: <a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://build.nvidia.com/</a></li>\n<li>NVIDIA API 文档: <a href=\"https://docs.api.nvidia.com/nim/\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.api.nvidia.com/nim/</a></li>\n</ul>\n<hr />\n<p><em>本教程基于 OpenViking 0.1.17 和 NVIDIA NIM API 测试通过。</em></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/swizard\">Swizard</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Maui 实践：趣谈 map 的取值特权，藏着 Go 的设计取舍",
      "link": "https://www.cnblogs.com/zhally/p/19622722",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/zhally/p/19622722\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:05\">\n    <span>Maui 实践：趣谈 map 的取值特权，藏着 Go 的设计取舍</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"maui-实践趣谈-map-的取值特权藏着-go-的设计取舍\">Maui 实践：趣谈 map 的取值特权，藏着 Go 的设计取舍</h1>\n<p>原创 夏群林  2026.2.18</p>\n<p>长期深耕 Go 开发的开发者，大多能体会到 Go 编译器的极致克制——它不像其他语言那般灵活奔放，反而像一位严谨的架构师，对语法边界、语义一致性有着近乎苛刻的要求。其中，函数签名的刚性约束与重载特性的缺失，是 Go 最具辨识度的设计之一；但唯独 map 的取值操作，Go 编译器却打破了自己定下的规则，赋予了其独一份的语法特权。</p>\n<p>Go 的函数签名规则，是 Go 语法体系的核心基石，也是其区别于 C# 等语言的关键。在 Go 中，函数签名的定义极为严格，完整包含三部分：函数名、参数列表（参数的类型、数量、顺序必须完全一致）、返回值列表（返回值的类型、数量、顺序同样不可偏差）。换句话说，只要这三者中有任何一处不同，即便函数名一致，在 Go 编译器眼中也是两个完全独立的函数。</p>\n<p>更关键的是， Go 明确不支持函数重载（Function Overloading）——这一点与 C# 形成了鲜明对比。在 C# 中，开发者可以定义多个同名函数，只要它们的参数列表（参数数量、类型、顺序）不同，编译器就能通过函数签名自动匹配调用；甚至可以通过可选参数、参数默认值等特性，进一步简化同名函数的调用逻辑。比如在 C# 中，我们可以这样定义重载函数：</p>\n<pre><code class=\"language-csharp\">// 重载1：无参数，返回默认值\npublic int GetValue() { return 0; }\n// 重载2：带参数，返回指定值\npublic int GetValue(int key) { return key * 2; }\n// 重载3：参数类型不同，返回值类型一致\npublic int GetValue(string key) { return int.Parse(key); }\n</code></pre>\n<p>这种设计在复杂业务场景中能有效减少函数名冗余，提升代码可读性。但 Go 却主动放弃了这一特性，核心原因在于 Go 追求语法简洁、语义清晰、无歧义——重载看似灵活，实则会增加编译器的解析成本，也可能让开发者在调用时陷入隐性匹配的困惑，尤其在多协程、高并发场景下，简洁无歧义的语法能大幅降低调试成本。</p>\n<p>回到 Go 的语法规则中，函数签名的刚性约束体现得淋漓尽致。比如我们定义两个同名函数，仅返回值数量不同：</p>\n<pre><code class=\"language-go\">// 函数1：单返回值\nfunc getInfo() *subscriberInfo { return nil }\n// 函数2：双返回值，与函数1同名\nfunc getInfo() (*subscriberInfo, bool) { return nil, false }\n</code></pre>\n<p>这段代码会直接编译报错，编译器会明确提示function getInfo redeclared in this block——在 Go 的规则里，这是典型的重复声明，哪怕返回值不同，也绝不允许。这种死板的约束，贯穿了 Go 的整个语法体系，却唯独在 map 取值时，被编译器悄悄打破。</p>\n<p>Go 中map的取值操作，存在两种完全合法的语法形式，这在其他任何语法场景中都是不可想象的。以我们之前实现的消息订阅系统中的<code>m.subscriberInfos</code>（类型为<code>map[MsgType]*subscriberInfo</code>）为例，第一种是单返回值取值：</p>\n<pre><code class=\"language-go\">info := m.subscriberInfos[msgType]\n</code></pre>\n<p>第二种是双返回值取值，额外获取 key 的存在性标记：</p>\n<pre><code class=\"language-go\">info, exists := m.subscriberInfos[msgType]\n</code></pre>\n<p>从函数签名的角度来看，这相当于同一个操作，拥有两个不同的返回值签名，若是放在普通函数中，早已违反了 Go 的语法规则。但对于 map，编译器却做了特殊适配——这并非 Go 语法的疏漏，而是编译器为高频场景量身打造的语法特权，本质上是一种封装好的语法糖。</p>\n<p>这种特权的设计，恰恰贴合了实际开发中的高频需求，也避免了开发者陷入冗余的校验逻辑。我自己的消息订阅系统中，这种适配的价值体现得淋漓尽致：</p>\n<pre><code class=\"language-go\">\t// 初始化当前MsgType的订阅者信息（首次订阅时）\n\tif _, exists := m.subscriberInfos[msgType]; !exists {\n\t\tm.subscriberInfos[msgType] = &amp;subscriberInfo{\n\t\t\tsubIDs: make(map[uint64]bool), // 初始化有效ID集合\n\t\t}\n\t}\n\tinfo := m.subscriberInfos[msgType] // 拿到当前MsgType的订阅者信息\n</code></pre>\n<p>在 Register 方法中，通过前置校验，若 msgType 不存在，则初始化并插入 map，确保了 msgType 一定存在于<code>m.subscriberInfos</code>中，此时使用单返回值取值，既能简化代码，又能避免无用变量的冗余。</p>\n<p>而在 cancel 函数中，</p>\n<pre><code class=\"language-go\">var once sync.Once // 保证取消逻辑仅执行一次\ncancel := func() { // 返回给用户的取消函数\n    once.Do(func() { // 核心：不管用户调多少次cancel，这里只执行一次\n        // 写锁：修改订阅者信息，需排他锁\n        m.Lock()\n        defer m.Unlock()\n\n        // 校验1：当前MsgType的订阅者信息是否存在（防止已销毁后取消）\n        info, infoExists := m.subscriberInfos[msgType]\n        // 校验2：当前subID是否在有效集合中（防越权/重复取消）\n        if !infoExists || !info.subIDs[subID] {\n            log.Printf(\"【%s】订阅者ID:%d取消失败（非有效订阅者）\", msgType, subID)\n            return // 校验失败，直接返回，不执行后续逻辑\n        }\n\n        // 步骤a：移除当前订阅者的ID（取消自己的订阅）\n        delete(info.subIDs, subID)\n        // 步骤b：订阅数-1\n        info.count--\n        log.Printf(\"【%s】订阅者ID:%d退出，当前订阅数：%d\", msgType, subID, info.count)\n\n        // 步骤c：所有订阅者都取消 → 销毁Channel+清理信息\n        if info.count == 0 {\n            close(m.globalChannels[msgType])          // 关闭Channel，监听协程自动退出\n            delete(m.globalChannels, msgType)         // 移除Channel映射，释放资源\n            delete(m.subscriberInfos, msgType)        // 移除订阅者信息，释放资源\n            log.Printf(\"【%s】最后一位订阅者退出，销毁全局Channel\", msgType)\n        }\n    })\n}\n</code></pre>\n<p>由于 msgType 可能已被销毁（所有订阅者取消后，msgType 会从 map 中删除），我们无法保证 key 的存在性，此时使用双返回值取值，通过 exists 标记判断 key 是否有效，既能安全获取 value，又能避免 nil 指针解引用导致的 panic，实现了简洁与安全的平衡。</p>\n<p>深入底层来看，编译器在处理 map 取值时，会根据接收方式自动适配逻辑：当使用单返回值时，编译器仅执行 key 查找-返回 value 的逻辑，若 key 不存在，则返回对应 value 类型的零值（如<code>*subscriberInfo</code>的零值为 nil）；当使用双返回值时，编译器会先判断 key 是否存在，再返回 value + 存在性标记，相当于将开发者手动编写的校验逻辑，内置到了语法层面，既提升了开发效率，又保证了代码的鲁棒性。</p>\n<p>值得注意的是，这份特权具有极强的排他性——仅针对 map 取值，其他数据类型（数组、切片、结构体等）均不具备。比如数组取值，若尝试使用双返回值<code>v, exists := arr[0]</code>，会直接编译报错；普通函数调用若尝试省略返回值（如函数返回两个值，却只接收一个），同样会被编译器拒绝。这种区别对待，恰恰体现了 Go 的设计逻辑：不搞一刀切的灵活，只针对高频场景做优化，其余场景严格遵守语法规则，兼顾效率与一致性。</p>\n<p>对比C#的重载特性， Go 的这种设计看似笨拙，实则是一种取舍——放弃重载带来的灵活，换来了语法的简洁、解析的高效和语义的无歧义；而给map赋予取值特权，则是在不破坏整体规则的前提下，对高频场景的精准适配。这种克制中的灵活，正是 Go 能够在高并发、后端开发中脱颖而出的核心原因之一。</p>\n<p>对于资深 Go 开发者而言，map 的这份特权早已不是什么秘密，而是日常开发中高效避坑的工具。它背后藏着的，是 Go 编译器铁面无私之下的细致考量，也是 Go 大道至简设计哲学的生动诠释——规矩是为了保证一致性，而特权是为了解决实际问题，二者并行不悖，才造就了 Go 简洁、高效、可靠的特性。</p>\n<p>毕竟，好的语言设计，从来不是面面俱到，而是取舍有道；编译器的特权，从来不是破坏规则，而是优化体验——这也是 map 的取值特权，能被资深开发者广泛认可的核心原因。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:05</span>&nbsp;\n<a href=\"https://www.cnblogs.com/zhally\">zhally</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]基于Checkpoint的持久化",
      "link": "https://www.cnblogs.com/jaydenai/p/19622525/checkpoint-persistent",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19622525/checkpoint-persistent\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 08:40\">\n    <span>[拆解LangChain执行引擎]基于Checkpoint的持久化</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Pregel基于Checkpoint的持久化机制是实现Agent应用`高可用性`和`长期记忆`的基础，它本质上是将 不断向前推进的图在“Superstep”之间将其状态固化的过程。和很多数据库持久化类似，Pregel采用`基于全量数据的状态快照+基于增量更新的操作日志`的持久化策略。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Pregel基于Checkpoint的持久化机制是实现Agent应用<code>高可用性</code>和<code>长期记忆</code>的基础，它本质上是将 不断向前推进的图在“Superstep”之间将其状态固化的过程。和很多数据库持久化类似，Pregel采用<code>基于全量数据的状态快照+基于增量更新的操作日志</code>的持久化策略。</p>\n<h2 id=\"1-持久化channel状态\">1. 持久化Channel状态</h2>\n<p>Pregel将状态“焊死”在Channel上，这使持久化变得很简单，它只要针对每个Superstep将每个Channel状态存下来就可以了。为了提高性能，它只需要考虑有过更新的Channel，而确Channel是否更新可以利用它的版本来决定。每个Channel都具有一个不断更新的版本，如果某个Channel在某个Superstep内有过更新，版本会往前更替。至于这个版本采用何种格式，具体如何管理，执行引擎将其下放到具体的Checkpointer实现中。</p>\n<p>作为Checkpointer的基类，<code>BaseCheckpointSaver</code>将基于更新快照的存储实现在如下所示的<code>put</code>方法中。待持久化的数据被封装在一个<code>Checkpoint</code>对象中以<code>checkpoint</code>参数传入该方法，<code>config</code>和<code>metadata</code>参数提供描述该Checkpoint的配置和元数据，而<code>new_versions</code>以一个字典的形式提供了涉及的每个Channel的版本。config参数提供的RunnableConfig主要提供标识当前调用会话的<code>Thread ID</code>和<code>Checkpoint命名空间</code>。方法会返回的RunnableConfig对象一般会携带<code>Thread ID</code>、<code>Checkpoint命名空间</code>和<code>Checkpoint ID</code>。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def put(\n        self,\n        config: RunnableConfig,\n        checkpoint: Checkpoint,\n        metadata: CheckpointMetadata,\n        new_versions: ChannelVersions,\n    ) -&gt; RunnableConfig\n\n    async def aput(\n        self,\n        config: RunnableConfig,\n        checkpoint: Checkpoint,\n        metadata: CheckpointMetadata,\n        new_versions: ChannelVersions,\n    ) -&gt; RunnableConfig\n    …\nChannelVersions = dict[str, str | int | float]\n</code></pre>\n<h3 id=\"11-checkpointmetadata\">1.1 CheckpointMetadata</h3>\n<p>描述Checkpoint元数据的<code>CheckpointMetadata</code>类型定义如下，其三个成员构成了图执行的谱系追踪（Lineage Tracking）和控制流导航的核心。它们不参与业务逻辑计算，但决定了如何管理、回溯和审计图的状态。</p>\n<pre><code class=\"language-python\">class CheckpointMetadata(TypedDict, total=False):\n    source: Literal[\"input\", \"loop\", \"update\", \"fork\"]\n    step: int\n    parents: dict[str, str]\n</code></pre>\n<p>CheckpointMetadata的<code>step</code>字段返回Superstep编号，代表当前Checkpoint在逻辑时间轴上的位置。<code>source</code>字段定义了当前这个Checkpoint是由哪种类型的操作触发生成的，它是理解图<code>生命历程</code>的关键，具体的选项包括：</p>\n<ul>\n<li>\n<p>input: 首次调用invoke或stream方法时触发，代表图的“创世点”。这是由外部初始数据输入产生的第一个Checkpoint（Superstep序号为 -1）；</p>\n</li>\n<li>\n<p>loop：内部根据 Node 和 Channel 的订阅关系进行迭代时触发，代表图在正常执行流程中的自动化流转。大多数中间步骤的 source 都是此值。</p>\n</li>\n<li>\n<p>update：用户手动调用了update_state方法时触发，代表一种“非自然”的状态变更。这通常用于人为干预、修正数据或在中断后注入信息。</p>\n</li>\n<li>\n<p>fork: 当用户从历史中的某个非最新Checkpoint重新启动执行时触发，代表图产生了分支。它标记了执行流从主线脱离，开启了一个独立的时间线。</p>\n</li>\n</ul>\n<p>CheckpointMetadata的<code>parents</code>字段返回一个字典，记录了当前Checkpoint与之前Checkpoint之间的拓扑关系，其结果通常为通常形式为dict[namespace, parent_checkpoint_id]。由于 采用增量持久化，当我们需要恢复一个完整的状态视图时，引擎必须知道去哪里找那些没变动的数据，parents字典提供了回溯路径。如果当前 Checkpoint 没有 某个Channel的值，引擎就会根据parents指引，跳转到父级Checkpoint去查找，直到找到该 Channel最近一次被更新的版本。</p>\n<p>在包含子图的复杂场景中，parents字段会记录父图命名空间对应的Checkpoint ID，确保父子图之间的状态逻辑能够跨层级对齐。当source为“fork”时，parents字段指向的是那个被分叉的历史点，而不是时间线上的物理前一个点。</p>\n<p>当我们查看一个CheckpointMetadata对象时，可以构建出如下逻辑：这个状态是由于<code>source</code>产生的，目前处于第<code>step</code>步。如果你想知道这个状态从何而来，或者想找回那些没变的数据，请根据<code>parents</code>列表向回追溯。</p>\n<h3 id=\"12-channel版本\">1.2 Channel版本</h3>\n<p>执行引擎将Channel版本的格式化权力下放给具体的Checkpointer实现，它们通过重写如下这个<code>get_next_version</code>方法提供某个Channel的下一个版本。如果表示当前版本的current参数为None，该方法会返回Channel的初始版本。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def get_next_version(self, current: V | None, channel: None) -&gt; V\n</code></pre>\n<p>以InMemorySaver为例，它会将Channel版本格式化成一个由51个字符组成的字符串，具体格式为<code>f\"{sequence:032}.{random:016}\"</code>。sequence从1开始递增，代表了“物理状态的演进顺序”。在顺序执行时反映了Superstep的进度，但是在遇到人为干预、中断、分叉或重试的情况下，物理序列号仅能反映“存盘的次数”。Superstep序号反映的是“算法迭代的深度”，所以不能将两者等同起来，前者是大于或等于Superstep序号的。</p>\n<p>“random”部分是一个0-1之间的随机数。如果说Channel版本前 32 位（第一部分）是时间轴上的<code>大刻度</code>，那么这第二部分就是确保状态在微观层面绝对唯一且可追溯的<code>防伪码</code>。由于 CPU 处理速度极快，多个并行任务可能在极短的微秒级时间内尝试触发写入。如果仅依靠前 32 位的递增序列号，在Superstep内部的多次写入可能会因为序列号来不及递增或在高并发下产生冲突。第二部分包含的随机数（源自浮点数的小数位）确保了即使第一部分相同，物理上的 Checkpoint ID 也是全球唯一的，这保证了UUID 级别的碰撞安全性。</p>\n<p>从支持<code>时间旅行</code>与<code>状态分叉</code>的角度来看，第二部分就显得更加重要了。当我们从某个历史点重启时流程时，假设从历史上的“00...001”处分叉出两条不同的执行路径，两条路径的序列号可能都会递增到“00...002”，但通过第二部分的随机随机值，系统能以如下形式物理隔离这两条路径。所以版本的第二部分的内容不仅仅为了解决冲突而存在，它使得持久化层可以同时存储同一逻辑步下的多个平行宇宙而不会发生覆盖。</p>\n<ul>\n<li>路径 A: 00...002.0.8494...</li>\n<li>路径 B: 00...002.0.1234...</li>\n</ul>\n<p>有的实现会严格采用类似于<code>{ sequence}.{step_index}.{random_entropy}</code>这样的三段式的版本格式化，第二部分通常包含了.0. 或.1.这样的前缀，它还兼具如下的功能：</p>\n<ul>\n<li>子图导航：当主图调用子图时，子图产生的Checkpoint会通过第二部分的特定位来标识它属于哪个父级任务的“逻辑分支”。</li>\n<li>任务索引：在同一个Superstep中，如果一个Node产生了多条Pending Write，第二部分可以用来索引这些写入的先后次序，确保在恢复合并时不会错位。</li>\n</ul>\n<h3 id=\"13-checkpoint\">1.3 Checkpoint</h3>\n<p>如下所示的是Checkpoint类型的定义。它的<code>v</code>字段表示决定Checkpoint结构的版本号，用于后向兼容性。如果未来改变了存储格式，运行时会根据这个值决定如何正确地反序列化旧数据。<code>id</code>和<code>ts</code>分别表示Checkpoint的唯一标识和生成时间戳。<code>updated_channels</code>字段返回的本Superstep内涉及更新的Channel列表。引擎根据订阅它们的Node来创建下一步执行的任务。<code>channel_values</code>字段存储了“涉及更新”的每个Channel的更新值。<code>channel_versions</code>字段返回所有Channel的版本。</p>\n<pre><code class=\"language-python\">class Checkpoint(TypedDict):\n    v : int\n    id : str\n    ts : str\t\t\n    channel_values : dict[str, Any]\n    channel_versions : ChannelVersions\n    versions_seen : dict[str, ChannelVersions]\n    updated_channels : list[str] | None\n</code></pre>\n<p>Node并不能实时观察到Channel的变化，<code>versions_seen</code>字段以<code>{ \"Node名\": { \"依赖Channel名\": \"版本ID\" } }</code>这样的结构返回每个Node执行时所能“看到”的Channel版本， 它记录了Node完成计算时的前置条件。在中断恢复时，引擎对比<code>versions_seen</code>，如果Node看到的输入版本没变，且它已经有了输出记录，那么就无需重复执行，所以这是实现因果一致性和幂等性的关键。如下的JSON是由Pregel生成的一个Checkpoint对象序列化后的结果。</p>\n<pre><code class=\"language-json\">{\n  \"v\": 4,\n  \"ts\": \"2026-01-18T13:42:07.542155+00:00\",\n  \"id\": \"1f0f4737-b4b1-6bbb-8001-1e44d720a9df\",\n  \"channel_versions\": {\n    \"foo\": \"00000000000000000000000000000001.0.6943525017042773\",\n    \"bar\": \"00000000000000000000000000000002.0.24038201058058928\",\n    \"baz\": \"00000000000000000000000000000003.0.8444674692332181\"\n  },\n\n  \"versions_seen\": {\n    \"__input__\": {},\n    \"foo\": { \"foo\": \"00000000000000000000000000000001.0.6943525017042773\" },\n    \"bar\": { \"bar\": \"00000000000000000000000000000002.0.24038201058058928\" }\n  },\n\n  \"updated_channels\": [ \"baz\" ],\n  \"channel_values\": {\n    \"foo\": \"begin\",\n    \"bar\": \"bar\",\n    \"baz\": \"baz\"\n  }\n}\n</code></pre>\n<h3 id=\"14存储结构\">1.4\t存储结构</h3>\n<p>接下来，我们以<code>InMemorySaver</code>为例看看Checkpoint会采用怎样的存储结构，以及以此结构基础的读取方式。InMemorySave针对Checkpoint的存储涉及两个字典。一个名为<code>blobs</code>的字典用于存储Channel的荷载内容（值），采用的Key是由<code>Thread ID</code>、<code>Checkpoint命名空间</code>、<code>Channel名称</code>和<code>版本</code>构成的四元组。另一个名为<code>storage</code>的字典时一个具有四层结构的字典，具体类型为<code>defaultdict[str, dict[str, dict[str, tuple[tuple[str, bytes], tuple[str, bytes], str | None]]]]</code>，每一层字典的Key顶如下。我们可以认为blobs用于存储数据，storage为索引表。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">层级</th>\n<th style=\"text-align: left;\">Key 类型</th>\n<th style=\"text-align: left;\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">第一层</td>\n<td style=\"text-align: left;\">Thread_id</td>\n<td style=\"text-align: left;\">会话隔离，区分不同的用户或对话流</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">第二层</td>\n<td style=\"text-align: left;\">Checkpoint_ns</td>\n<td style=\"text-align: left;\">命名空间隔离，支持子图或不同模块的独立状态空间</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">第三层</td>\n<td style=\"text-align: left;\">checkpoint_id</td>\n<td style=\"text-align: left;\">版本隔离，用于定位特定版本的快照</td>\n</tr>\n</tbody>\n</table>\n<p>最后一层字典的值是一个三元组<code>tuple[tuple[str, bytes], tuple[str, bytes], str | None]</code>，它们将数据序列化后存储，以确保内存中的数据是不可变且易于复制的，三个部分包括：</p>\n<ul>\n<li>tuple[str, bytes]：前一部分表示的序列化类型（通常是json或msgpack），第二部分表示经过序列化后的Checkpoint对象（由于具体的值已经存储在blobs中了，所以此时的Checkpoint的channel_values字段已经被移除）。这里不再存储 Python 字典对象，而是存储字节流。这模拟了数据库存取过程，并防止了Node在内存中意外修改已存盘的状态，实现对象的深度隔离。</li>\n<li>tuple[str, bytes]：Checkpoint元数据，前一部分同样表示序列化类型，第二部分为经过序列化后的CheckpointMetadata对象。</li>\n<li>str | None：父级checkpoint_id（这里的Parent与是否以子图形式执行没有关系，这里代表作为调用者的Node），InMemorySaver可以通过这个 ID在内存中顺着链条向上追溯，从而在恢复时合并增量状态。</li>\n</ul>\n<h2 id=\"2-持久化pending-write\">2. 持久化Pending Write</h2>\n<p>Checkpoint是在Superstep成功结束时针对Channel状态创建的，它并不能反映一个尚未结束Superstep内的真实状态。Pregel在执行过程中可以能出现不可预期的错误，或者需要人为介入导致可预期的中断，并行执行的任务就会出现部分部分成功、部分失败和中断的情况。对于成功执行的操作，它们针对目标Channel的写入并没有通过一个Checkpoint固定下来，仅仅属于一个<code>Pending Write</code>。如果这种中间状态没有被持久化，等下次恢复执行的时候，本来已经成功执行的任务还会重复执行，这是无法接受的。</p>\n<p>如果某个任务涉及到多次人为中断，每次恢复执行都需要提供<code>Resume Value</code>。如果这些Resume Value没有持久化，那么每次恢复调用提供的Resume Value永远都会提供给第一个中断，多次中断根本就没法实现，所以提供的Resume Value也需要以Pending Write的形式存储下来。</p>\n<p>持久化不仅仅需要将Superstep完成时将Channel的状态以Checkpoint固定下来，还需要将涉及到的所有Pending Write按照先后顺序记录下来。Pending Write不仅仅限于描述成功任务针对目标Channel的写入和依序提供Resume Value，任务在执行中抛出的异常和中断也会以Pending Write的形式被记录下来。</p>\n<p>实际上这种基于全量基础数据和增量操作日志相结合的持久化形式，在很多内存数据库中得到了广泛的应用。以Redis为例，它会采用相应的策略每隔一段时间将当前时间点的内存快照以<code>RDB</code>形式固化下来，同时针对数据库所作的每个操作都会按照时间顺序以<code>AOL</code>的形式存储下来。对于Pregel来说，Checkpoint就是RDB，Pending Wrtes就是AOL。当Pregel以恢复形式执行的时候，它会先提取并应用指定的Checkpoint快照，然后对状态为成功执行的Pending Write进行重放就能恢复中断时的状态。</p>\n<p>针对Pending Write的持久化通过调用BaseCheckpointSaver如下所示的put_writes/aput_writes方法完成。Pending Write的持久化是基于任务进行的，所以我们需要指定任务的ID和路径。config参数提供RunnableConfig对象携带了所需的Thread ID， Checkpoint命名空间和Checkpoint ID。具体针对Channel的Pending Write由writes参数提供的， 这是一个由Channel名称和值的二元组组成的序列。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):\n    def put_writes(\n        self,\n        config: RunnableConfig,\n        writes: Sequence[tuple[str, Any]],\n        task_id: str,\n        task_path: str = \"\",\n    ) -&gt; None\n    async def aput_writes(\n        self,\n        config: RunnableConfig,\n        writes: Sequence[tuple[str, Any]],\n        task_id: str,\n        task_path: str = \"\",\n    ) -&gt; None\n</code></pre>\n<p>对于InMemorySaver来说，它将PendingWrite存储于一个结构为<code>defaultdict[tuple[str, str, str], dict[tuple[str, int], tuple[str, str, tuple[str, bytes], str]]]</code>的两层字典中。第一层字典的Key为<code>Thread ID</code>， <code>Checkpoint命名空间</code>和<code>Checkpoint ID</code>三元组。第二层元组的第一个部分为Task ID，第二部分是当前Pending Write在writes序列中的索引。真正存储的内容是由如下四部分组成的元组：</p>\n<ul>\n<li>task_id：冗余存储任务 ID，便于快速检索。</li>\n<li>channel： Channel的名称。</li>\n<li>tuple[str, bytes]：前部分表示序列化格式（如\"json\"或\"pickle\"）。后一部分为序列化后的字节。</li>\n<li>task_path：任务在图结构中的完整路径。</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 08:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">24</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}