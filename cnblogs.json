{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "【本台讯】C++界现“神秘代码”：一行指令唤醒沉睡的数学之美",
      "link": "https://www.cnblogs.com/lixingqiu/p/19627496",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lixingqiu/p/19627496\" id=\"cb_post_title_url\" title=\"发布于 2026-02-21 08:34\">\n    <span>【本台讯】C++界现“神秘代码”：一行指令唤醒沉睡的数学之美</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<img alt=\"2026-02-21_081653\" class=\"lazyload\" />\n<p><span><span>​</span></span></p>\n<p>注意：以下记者与报道纯属虚构，但C++精灵库和它的案例与抖音号里视频却是真实存在的。</p>\n<h2>（本台记者 2026年2月21日 报道）<br />\n有记者报道，一个神秘的“精灵库”近日“涌现”在抖音。传说作者用这个精灵库做了几百个作品，有些作品已录成视频进行展示，瞬间在程序员圈子和数学爱好者中引发了“地震”。</h2>\n<p><span>要看抖音</span>视频在这里：<span class=\"cke_widget_wrapper cke_widget_inline cke_widget_csdnlink cke_widget_selected\"><a class=\"cke_widget_editable cke_widget_element\" href=\"https://v.douyin.com/IEr8F2q2oic/\" rel=\"noopener nofollow\" title=\"https://v.douyin.com/IEr8F2q2oic/\">https://v.douyin.com/IEr8F2q2oic/</a></span></p>\n<p>记者在一段时长仅10秒的视频中看到，无数条翠绿色与银白色的线条，如同被赋予了生命的丝带，在纯黑的虚空中交织、旋转、绽放。它们时而如DNA双螺旋般精密缠绕，时而如飞鸟振翅般舒展灵动。令人震惊的是，这并非出自专业的图形设计软件，也不是Python或JavaScript的杰作，而是由古老而严谨的C++语言，通过一个名为sprites.h的“精灵库”实时渲染而成。</p>\n<h2>“格子衫”程序员的逆袭：从枯燥代码到视觉艺术</h2>\n<p>“以前我们教C++，学生面对的是黑底白字的控制台，输出个'Hello World'都要半天。”一位不愿透露姓名的资深计算机教师在接受本台记者采访时感叹道，“但这个‘精灵库’的出现，彻底打破了C++‘枯燥、难学、只能做后端’的刻板印象。”<br />\n记者深入研究了流出的核心代码，发现其简洁程度令人咋舌。传统的C++图形编程往往需要配置复杂的OpenGL环境、处理晦涩的窗口消息循环，动辄数百行代码才能画出一个圆。而在“精灵库”的加持下，一切变得像搭积木一样简单：</p>\n<div class=\"cke_widget_wrapper cke_widget_block cke_widget_codeSnippet cke_widget_selected\">\n<pre class=\"cke_widget_element\"><code class=\"hljs language-cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include <span class=\"hljs-string\">\"sprites.h\"  <span class=\"hljs-comment\">// 仿佛一句咒语，打开了图形世界的大门\nScreen s;             <span class=\"hljs-comment\">// 屏幕对象，呼之即来\nSprite r;             <span class=\"hljs-comment\">// 画笔角色，听候差遣</span></span></span></span></span></span></code></pre>\n<span class=\"cke_reset cke_widget_drag_handler_container\"><img class=\"cke_reset cke_widget_drag_handler lazyload\" height=\"15\" title=\"点击并拖拽以移动\" width=\"15\" /></span></div>\n<p>仅仅三行代码，一个图形化界面就已准备就绪。这种“链式调用”的写法——如<code>s.bgcolor(\"black\").tracer(0)</code>——被业内专家称为“让C++说人话”的革命性设计。</p>\n<h2><strong>数学公式的“舞蹈编排”</strong></h2>\n<p>视频中那令人眼花缭乱的动态效果，背后其实是严谨数学公式的狂欢。代码中的<code>draw_curver</code>函数，实际上是在指挥两个不同频率的正弦波进行一场探戈舞。</p>\n<p><code>float x = A * sin(30*t + 3);</code> 与 <code>float y = k*A * sin(10*t);</code>，这两行代码分别控制了X轴和Y轴的波动。而在<code>rotate_point</code>函数中，正弦与余弦的精密计算，让每一个坐标点都在空间中完成了华丽的转身。</p>\n<p>“这不仅仅是编程，这是数学的可视化艺术。”一位数学系教授在观看视频后评价道，“作者通过<code>rotate_angle += 0.02</code>这样简单的累加，就让静态的公式‘活’了过来，变成了流动的视觉盛宴。”</p>\n<h2><strong>教育界的新宠：让创意飞一会儿</strong></h2>\n<p>据悉，这个“精灵库”最大的价值在于极大地降低了C++编程的门槛。它屏蔽了底层复杂的图形渲染机制，让使用者只需关注逻辑与创意。</p>\n<p>在代码的<code>main</code>函数中，一个简洁的<code>while(s.exitonclick())</code>循环，就构建起了一个完整的动画引擎。清屏、绘制、刷新、延时，一气呵成。这意味着，即使是编程初学者，也能在第一课就做出属于自己的动画作品，而不是对着控制台发呆。</p>\n<p>目前，关于这个“精灵库”的下载方式和完整文档仍在技术社区中疯传。有评论家预测，这可能会引发一场C++教学法的革新——从此，C++不再只是工程师手中的锤子，更是艺术家手中的画笔。</p>\n<p>截至发稿时，记者再次观看那段视频，那些绿色的线条依然在屏幕上不知疲倦地旋转着，仿佛在无声地诉说着：<strong>代码，原来可以如此性感。</strong></p>\n<p><strong>程序所有代码在此：</strong></p>\n<p><span><span>​</span></span></p>\n<div class=\"cnblogs_code\">\n<pre>#include <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">sprites.h</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">包含C++精灵库 </span>\nScreen s;      <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">建立屏幕对象叫s</span>\nSprite r;      <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">建立角色叫r\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 旋转函数，输入原始坐标和旋转角度，返回旋转后的坐标</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">void</span> rotate_point(<span style=\"color: rgba(0, 0, 255, 1);\">float</span>&amp; x, <span style=\"color: rgba(0, 0, 255, 1);\">float</span>&amp; y, <span style=\"color: rgba(0, 0, 255, 1);\">float</span><span style=\"color: rgba(0, 0, 0, 1);\"> angle) {\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> cos_a = cos(angle);  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 角度的余弦值</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">float</span> sin_a = sin(angle);  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 角度的正弦值\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 保存原始坐标（避免计算时覆盖）</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">float</span> x_original =<span style=\"color: rgba(0, 0, 0, 1);\"> x;\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> y_original =<span style=\"color: rgba(0, 0, 0, 1);\"> y;\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 应用旋转变换公式</span>\n    x = x_original * cos_a - y_original *<span style=\"color: rgba(0, 0, 0, 1);\"> sin_a;\n    y </span>= x_original * sin_a + y_original *<span style=\"color: rgba(0, 0, 0, 1);\"> cos_a;\n}\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">void</span> draw_curver(<span style=\"color: rgba(0, 0, 255, 1);\">float</span> k, <span style=\"color: rgba(0, 0, 255, 1);\">float</span><span style=\"color: rgba(0, 0, 0, 1);\"> rotate_angle){    \n   </span><span style=\"color: rgba(0, 0, 255, 1);\">for</span>(<span style=\"color: rgba(0, 0, 255, 1);\">int</span> A=<span style=\"color: rgba(128, 0, 128, 1);\">0</span>;A&lt;=<span style=\"color: rgba(128, 0, 128, 1);\">100</span>;A+=<span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\">){       \n       </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> t=-<span style=\"color: rgba(128, 0, 128, 1);\">2.0</span><span style=\"color: rgba(0, 0, 0, 1);\">;      \n       </span><span style=\"color: rgba(0, 0, 255, 1);\">while</span>(t&lt;=<span style=\"color: rgba(128, 0, 128, 1);\">2.0</span><span style=\"color: rgba(0, 0, 0, 1);\">){\n          </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> x = A * sin(<span style=\"color: rgba(128, 0, 128, 1);\">30</span>*t + <span style=\"color: rgba(128, 0, 128, 1);\">3</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n          </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> y = k*A * sin(<span style=\"color: rgba(128, 0, 128, 1);\">10</span>*<span style=\"color: rgba(0, 0, 0, 1);\">t);          \n          </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 对每个点进行旋转变换</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">          rotate_point(x, y, rotate_angle);          \n          r.penshade(x</span>+y).go(y,x);    <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">.dot(1);</span>\n          <span style=\"color: rgba(0, 0, 255, 1);\">if</span>(!<span style=\"color: rgba(0, 0, 0, 1);\">r.isdown())r.pendown();\n          t </span>= t + <span style=\"color: rgba(128, 0, 128, 1);\">0.01</span><span style=\"color: rgba(0, 0, 0, 1);\">;                  \n       }    \n       r.penup();  \n    }\n}\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">int</span> main(){        <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">主功能块 </span>\n   s.bgcolor(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">black</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).tracer(<span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n   r.speed(</span><span style=\"color: rgba(128, 0, 128, 1);\">0</span>).color(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">lime</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">).pu().hide();\n   </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> k=<span style=\"color: rgba(128, 0, 128, 1);\">0</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n   </span><span style=\"color: rgba(0, 0, 255, 1);\">float</span> rotate_angle = <span style=\"color: rgba(128, 0, 128, 1);\">0</span>;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">旋转角度变量，初始为0</span>\n   <span style=\"color: rgba(0, 0, 255, 1);\">while</span>(s.exitonclick()){  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">单击窗口按钮返回家false，所以while循环结束</span>\n      s.clear();            <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">清除所有画的东西\n      </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 传入旋转角度，让本次绘制的所有点都旋转</span>\n      draw_curver(<span style=\"color: rgba(128, 0, 128, 1);\">3</span>*<span style=\"color: rgba(0, 0, 0, 1);\">sin(k), rotate_angle);\n      s.update().wait(</span><span style=\"color: rgba(128, 0, 128, 1);\">0.01</span>);   <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">刷新并等待0.01秒，固定帧率</span>\n      k = k + <span style=\"color: rgba(128, 0, 128, 1);\">0.01</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n      rotate_angle </span>+= <span style=\"color: rgba(128, 0, 128, 1);\">0.02</span>;  <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 控制旋转速度（值越大转得越快）</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">   }    \n   </span><span style=\"color: rgba(0, 0, 255, 1);\">return</span> <span style=\"color: rgba(128, 0, 128, 1);\">0</span>;    <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\">返回0</span>\n}</pre>\n</div>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-21 08:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lixingqiu\">李兴球</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "模拟退火算法",
      "link": "https://www.cnblogs.com/PaperPlaneFly/p/19626799",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/PaperPlaneFly/p/19626799\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 20:14\">\n    <span>模拟退火算法</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"模拟退火算法\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220201320618-591678279.png\" />\n        模拟退火算法最早的思想由**Metropolis **等（** **1953** **）提出，** **1983** **年** **Kirkpatrick** **等将其应用于组合优化。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"模拟退火算法\">模拟退火算法</h1>\n<p>​    <strong>模拟退火算法最早的思想由</strong>Metropolis <strong>等（</strong> <strong>1953</strong> <strong>）提出，</strong> <strong>1983</strong> <strong>年</strong> <strong>Kirkpatrick</strong> <strong>等将其应用于组合优化。</strong></p>\n<p><strong>算法的目的</strong>：</p>\n<p><strong>克服优化过程陷入局部极小；</strong></p>\n<p><strong>克服初值依赖性。</strong></p>\n<h2 id=\"物理退火过程\">物理退火过程</h2>\n<p>在物理学中，<strong>退火</strong>是将金属加热到极高温度，然后让其<strong>极其缓慢</strong>地冷却的过程。</p>\n<ul>\n<li><strong>高温状态</strong>：原子运动剧烈，处于无序状态（高能量）。</li>\n<li><strong>等温过程</strong>  <strong>对于与环境换热而温度不变的封闭系统，系统状态的自发变化总是朝自由能减少的方向进行，当自由能达到最小时，系统达到平衡态；</strong></li>\n<li><strong>缓慢冷却</strong>：原子逐渐找到最稳定的位置，形成整齐的晶体结构。</li>\n<li><strong>最终状态</strong>：系统的<strong>内能最低</strong>（全局最优）。</li>\n</ul>\n<p>如果冷却得太快（<strong>淬火</strong>，Quenching），原子来不及调整位置就被“冻结”在杂乱的状态，系统处于亚稳态（局部最优，内能较高，材料脆）。</p>\n<p>温度越低，物体的能量状态越低，到达足够的低点时，液体开始冷凝与结晶，在结晶状态时，系统的能量状态最低。缓慢降温（退火时，可达到最低能量状态；但如果快速降温（淬火，会导致不是最低能态的非晶形。</p>\n<h2 id=\"boltzmann概率分布\"><strong>Boltzmann</strong>概率分布</h2>\n<p>在温度T，分子停留在状态r满足Boltzmann概率分布</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200000416-839968077.png\" /></p>\n<p><img alt=\"科学网—科学史-物理学编年史-80玻尔兹曼分布律 - 张延年的博文\" src=\"https://ts3.tc.mm.bing.net/th/id/OIP-C.F28T_kCjs5-MqGcOpdgA9wHaE1?rs=1&amp;pid=ImgDetMain&amp;o=7&amp;rm=3\" /></p>\n<p>在同一个温度T，选定两个能量E1&lt;E2，有</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200026317-2005365913.png\" /></p>\n<p><strong>（</strong>1<strong>）在同一个温度，分子停留在能量小状态的概率大于停留在能量大状态的概率</strong></p>\n<p><strong>（</strong>2<strong>）温度越高，不同能量状态对应的概率相差越小；温度足够高时，各状态对应概率基本相同。</strong></p>\n<p><strong>（</strong>3<strong>）随着温度的下降，能量最低状态对应概率越来越大；温度趋于</strong>0<strong>时，其状态趋于</strong>1</p>\n<h2 id=\"metropolis准则\"><strong>Metropolis</strong>准则</h2>\n<p><strong>以概率接受新状态</strong></p>\n<p>假设当前状态为 x，能量为 E(x)。</p>\n<p>我们随机生成了一个邻域新解 x'，能量为 E(x')。</p>\n<p>定义能量差为：</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200221455-1081080706.png\" /></p>\n<p>简单来说，它的核心数学思想是：<strong>以一定的概率接受一个“更差”的解，从而跳出局部最优陷阱，最终趋向全局最优。</strong></p>\n<h4 id=\"情况-a新解更好-δe0\">情况 A：新解更好 (Δ<em>E</em>&lt;0)</h4>\n<p>如果新解的能量更低（比如在下山），我们<strong>100% 接受</strong>这个新解。</p>\n<p><em>P</em>(accept)=1</p>\n<p>这对应了贪心算法（Gradient Descent）的部分。</p>\n<h4 id=\"情况-b新解更差-δe0\">情况 B：新解更差 (Δ<em>E</em>&gt;0)</h4>\n<p>如果新解的能量更高（比如要爬坡，反方向），我们<strong>不是直接拒绝</strong>，而是<strong>以一定的概率接受它</strong>。这个概率 <em>P</em> 服从 <strong>玻尔兹曼分布 (Boltzmann Distribution)</strong>：</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200357347-1971444950.png\" /></p>\n<ul>\n<li>\n<p>Δ<em>E</em>：能量差（肯定为正）。</p>\n</li>\n<li>\n<p><em>T</em>：当前的温度。</p>\n</li>\n<li>\n<p><em>k</em>：物理中的玻尔兹曼常数（在算法中通常设为 1）。</p>\n</li>\n</ul>\n<h4 id=\"1-温度-t-极高时-探索阶段\">(1) 温度 T 极高时 (探索阶段)</h4>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200411620-1794628474.png\" /></p>\n<p>接受概率接近 100%。哪怕新解比旧解差很多，算法也会接受。</p>\n<p>算法在搜索空间中<strong>随机游走 (Random Walk)</strong>，像个醉汉。这保证了它能翻越极高的山峰，从深坑里跳出来，遍历整个空间。</p>\n<h4 id=\"2-温度-t-降低时-过渡阶段\">(2) 温度 T 降低时 (过渡阶段)</h4>\n<p>随着 T 变小，分母变小，指数部分变成较大的负数。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200433875-1909155565.png\" /></p>\n<p>如果Delta E 很大（解变差很多），概率 P<span class=\"math inline\">\\(就会很小；如果 \\Delta E\\)</span>很小（只差一点点），概率 P$还比较大。</p>\n<p>算法开始变得挑剔。它仍然允许跳出浅坑（局部最优），但不再接受那些太离谱的差解。</p>\n<h4 id=\"3-温度-t-极低时-收敛阶段\">(3) 温度 T 极低时 (收敛阶段)</h4>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200452308-1356373863.png\" /></p>\n<p>接受更差解的概率几乎为 0。</p>\n<p>算法退化为<strong>贪心算法 (Hill Climbing)</strong>。它只接受好解，不再爬坡。这时候它应该已经落入了全局最优</p>\n<h2 id=\"降温系数\">降温系数</h2>\n<p>在每一个固定的温度 T下，算法进行多次迭代。这实际上是在生成一个马尔可夫链。 如果迭代次数足够多，系统会达到服从玻尔兹曼分布<strong>热平衡分布 (Stationary Distribution)</strong>。</p>\n<p>当 T缓慢下降时，概率分布图会变得越来越尖（Peaked），大部分概率密度会集中在全局最小值的附近。</p>\n<p>引入冷却系数：</p>\n<p><strong>数学上的最优降温 (对数冷却)</strong>： Geman 在 1984 年证明，如果降温速度足够慢，满足：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200507935-837856176.png\" /></p>\n<p>那么模拟退火以<strong>概率 1 收敛到全局最优解</strong>。 <em>缺点</em>：这个速度太慢了，慢到实际上无法使用（可能需要几百年）。</p>\n<p><strong>工程上的降温 (指数冷却)</strong>：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200518474-1965198914.png\" /></p>\n<p>这是对收敛速度和求解质量的折衷。虽然理论上不保证 100% 找到全局最优，但在有限时间内能找到“足够好”的解。</p>\n<h2 id=\"rosenbrock-函数验证\">Rosenbrock 函数验证</h2>\n<p>N 维 Rosenbrock 函数的通常定义如下：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{x}) = \\sum_{i=1}^{N-1} [100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2]\n\\]</div><p></p><p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200541507-1548156741.png\" /></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/3540252/202602/3540252-20260220200605031-939946155.png\" /></p>\n<h2 id=\"c库代码如下\">c++库代码如下</h2>\n<p>sa.hpp</p>\n<pre><code>#ifndef SA_SA_HPP\n#define SA_SA_HPP\n\n\n#include \"params.hpp\"\n#include \"policies.hpp\"\n#include \"detail/solver.hpp\"\n\nnamespace sa {\n\n\n    /**\n     * @brief 模拟退火通用求解函数\n     * * @tparam State 状态类型 (自动推导)\n     * @tparam EnergyFunc 能量函数类型 (自动推导)\n     * @tparam NeighborFunc 邻域函数类型 (可选)\n     * @tparam CoolingPolicy 降温策略 (可选)\n     * @tparam ConstraintPolicy 约束策略 (可选)\n     * * @param initial_state 初始状态值\n     * @param energy_func 能量函数句柄\n     * @param params 算法参数配置\n     * @param neighbor 邻域生成器实例\n     * @param cooling 降温器实例\n     * @param constraint 约束器实例\n     * @return std::pair&lt;State, double&gt; {最优状态, 最优能量值}\n     */\n    template&lt;\n            typename State,\n            typename EnergyFunc,\n            typename NeighborFunc = DefaultNeighbor&lt;State&gt;,\n            typename CoolingPolicy = ExponentialCooling,\n            typename ConstraintPolicy = std::nullptr_t\n    &gt;\n    auto solve(\n            const State&amp; initial_state,\n            EnergyFunc energy_func,\n            Params params = Params{},\n            NeighborFunc neighbor = NeighborFunc{},\n            CoolingPolicy cooling = CoolingPolicy{},\n            ConstraintPolicy constraint = ConstraintPolicy{}\n    ) {\n        using AcceptancePolicy = MetropolisAcceptance;\n\n        detail::Solver&lt;State, EnergyFunc, NeighborFunc, CoolingPolicy, AcceptancePolicy, ConstraintPolicy&gt;\n                solver(params, energy_func, neighbor, cooling, AcceptancePolicy{}, constraint);\n\n        return solver.solve(initial_state);\n    }\n\n} // namespace sa\n\n#endif // SA_SA_HPP\n</code></pre>\n<p>policies.hpp</p>\n<pre><code>#ifndef SA_POLICIES_HPP\n#define SA_POLICIES_HPP\n\n#include \"params.hpp\"\n#include \"detail/traits.hpp\"\n\n#include &lt;cmath&gt;\n#include &lt;random&gt;\n#include &lt;algorithm&gt;\n#include &lt;stdexcept&gt;\n#include &lt;vector&gt;\n\nnamespace sa {\n\n    // 默认降温策略\n    struct ExponentialCooling {\n        inline double operator()(double T, const Params&amp; p) const noexcept {\n            return T * p.alpha;\n        }\n    };\n\n\n    // 默认接受策略 (Metropolis 准则)\n    struct MetropolisAcceptance {\n        template&lt;typename RNG&gt;\n        bool operator()(double delta_E,\n                        double T,\n                        RNG&amp; rng,\n                        std::uniform_real_distribution&lt;double&gt;&amp; dist) const\n        {\n            if (delta_E &lt; 0.0) return true;\n            return std::exp(-delta_E / T) &gt; dist(rng);\n        }\n    };\n\n\n    // 默认连续邻域生成策略\n    template&lt;typename State&gt;\n    struct DefaultNeighbor {\n        double sigma = 1.0;\n\n        State operator()(const State&amp; current,\n                         double T,\n                         std::mt19937&amp; rng) const\n        {\n            if constexpr (std::is_arithmetic_v&lt;State&gt;) {\n                std::normal_distribution&lt;double&gt; dist(0.0, sigma * T);\n                return static_cast&lt;State&gt;(current + dist(rng));\n            }\n            else if constexpr (detail::is_std_vector_v&lt;State&gt;) {\n                using ValueType = typename State::value_type;\n                static_assert(std::is_arithmetic_v&lt;ValueType&gt;,\n                              \"vector value type must be arithmetic\");\n\n                std::normal_distribution&lt;double&gt; dist(0.0, sigma * T);\n                State candidate = current;\n                for (auto&amp; v : candidate)\n                    v = static_cast&lt;ValueType&gt;(v + dist(rng));\n                return candidate;\n            }\n            else {\n                static_assert(sizeof(State) == 0, \"No default neighbor for this State type\");\n                return current;\n            }\n        }\n    };\n\n\n    // 离散翻转邻域策略 (针对 vector&lt;bool&gt; 或 vector&lt;int&gt;)\n    template&lt;typename State&gt;\n    struct DiscreteFlipNeighbor {\n        State operator()(const State&amp; current,\n                         double T,\n                         std::mt19937&amp; rng) const\n        {\n            static_assert(detail::is_std_vector_v&lt;State&gt;, \"DiscreteFlipNeighbor requires std::vector\");\n            using ValueType = typename State::value_type;\n\n            static_assert(\n                    std::is_same_v&lt;ValueType, int&gt; || std::is_same_v&lt;ValueType, bool&gt;,\n                    \"DiscreteFlipNeighbor requires vector&lt;int&gt; or vector&lt;bool&gt;\"\n            );\n\n            State candidate = current;\n            std::uniform_int_distribution&lt;std::size_t&gt; dist(0, candidate.size() - 1);\n            std::size_t idx = dist(rng);\n\n            if constexpr (std::is_same_v&lt;ValueType, bool&gt;)\n                candidate[idx] = !candidate[idx];\n            else\n                candidate[idx] = 1 - candidate[idx];\n\n            return candidate;\n        }\n    };\n\n\n    // 边界约束策略 (Box Constraint)\n    template&lt;typename State&gt;\n    class BoxConstraintPolicy {\n    public:\n        using ValueType = std::conditional_t&lt;\n                std::is_arithmetic_v&lt;State&gt;,\n                State,\n                typename State::value_type&gt;;\n\n        BoxConstraintPolicy(ValueType lower, ValueType upper)\n                : lower_(lower), upper_(upper) {}\n\n        void apply(State&amp; state) const noexcept {\n            if constexpr (std::is_arithmetic_v&lt;State&gt;) {\n                state = std::clamp(state, lower_, upper_);\n            }\n            else {\n                for (auto&amp; v : state)\n                    v = std::clamp(v, lower_, upper_);\n            }\n        }\n\n    private:\n        ValueType lower_;\n        ValueType upper_;\n    };\n\n} // namespace sa\n\n#endif // SA_POLICIES_HPP\n</code></pre>\n<p>params.hpp</p>\n<pre><code>//\n// Created by 31007 on 2026/2/12.\n//\n\n#ifndef MATH_TYPES_HPP\n#define MATH_TYPES_HPP\n#include &lt;cstddef&gt;\n#include &lt;cstdint&gt;\nnamespace sa {\n    struct Params {\n        double      initial_temp     = 100.0;       // 初始温度\n        double      final_temp       = 1e-6;        // 终止温度\n        double      alpha            = 0.98;        // 降温系数\n        std::size_t iter_per_temp    = 100;         // 每个温度下的迭代次数\n        std::size_t max_total_iters  = 1'000'000;   // 最大总迭代次数 (防止死循环)\n        std::uint32_t seed           = 0;           // 随机种子 (0表示随机)\n    };\n\n} // namespace sa\n#endif //MATH_TYPES_HPP\n</code></pre>\n<p>solver.hpp</p>\n<pre><code>#ifndef SA_DETAIL_SOLVER_HPP\n#define SA_DETAIL_SOLVER_HPP\n\n#include \"../params.hpp\"\n#include &lt;random&gt;\n#include &lt;utility&gt;\n#include &lt;stdexcept&gt;\n\nnamespace sa::detail {\n\n    template&lt;\n            typename State,\n            typename EnergyFunc,\n            typename NeighborFunc,\n            typename CoolingPolicy,\n            typename AcceptancePolicy,\n            typename ConstraintPolicy\n    &gt;\n    class Solver {\n    public:\n        Solver(Params params,\n               EnergyFunc energy,\n               NeighborFunc neighbor,\n               CoolingPolicy cooling,\n               AcceptancePolicy acceptance,\n               ConstraintPolicy constraint)\n                : params_(params),\n                  energy_(energy),\n                  neighbor_(neighbor),\n                  cooling_(cooling),\n                  acceptance_(acceptance),\n                  constraint_(constraint),\n                  dist_(0.0, 1.0)\n        {\n            validate_params();\n\n            if (params_.seed == 0) {\n                std::random_device rd;\n                rng_ = std::mt19937(rd());\n            } else {\n                rng_ = std::mt19937(params_.seed);\n            }\n        }\n\n        std::pair&lt;State, double&gt; solve(const State&amp; initial_state) {\n            State current = initial_state;\n            double current_energy = energy_(current);\n\n            State best = current;\n            double best_energy = current_energy;\n\n            double T = params_.initial_temp;\n            std::size_t total_iters = 0;\n\n            while (T &gt; params_.final_temp &amp;&amp; total_iters &lt; params_.max_total_iters) {\n                for (std::size_t i = 0;\n                     i &lt; params_.iter_per_temp &amp;&amp; total_iters &lt; params_.max_total_iters;\n                     ++i, ++total_iters)\n                {\n                    State candidate = neighbor_(current, T, rng_);\n\n                    // 编译期判断是否存在约束策略\n                    if constexpr (!std::is_same_v&lt;ConstraintPolicy, std::nullptr_t&gt;) {\n                        constraint_.apply(candidate);\n                    }\n\n                    double candidate_energy = energy_(candidate);\n                    double delta = candidate_energy - current_energy;\n\n                    if (acceptance_(delta, T, rng_, dist_)) {\n                        current = std::move(candidate);\n                        current_energy = candidate_energy;\n\n                        if (current_energy &lt; best_energy) {\n                            best = current;\n                            best_energy = current_energy;\n                        }\n                    }\n                }\n                T = cooling_(T, params_);\n            }\n\n            return {std::move(best), best_energy};\n        }\n\n    private:\n        void validate_params() {\n            if (params_.initial_temp &lt;= 0.0) throw std::invalid_argument(\"initial_temp must be &gt; 0\");\n            if (params_.final_temp &lt;= 0.0) throw std::invalid_argument(\"final_temp must be &gt; 0\");\n            if (params_.alpha &lt;= 0.0 || params_.alpha &gt;= 1.0) throw std::invalid_argument(\"alpha must be in (0,1)\");\n            if (params_.iter_per_temp == 0) throw std::invalid_argument(\"iter_per_temp must be &gt; 0\");\n        }\n\n        Params params_;\n        EnergyFunc energy_;\n        NeighborFunc neighbor_;\n        CoolingPolicy cooling_;\n        AcceptancePolicy acceptance_;\n        ConstraintPolicy constraint_;\n\n        std::mt19937 rng_;\n        std::uniform_real_distribution&lt;double&gt; dist_;\n    };\n\n} // namespace sa::detail\n\n#endif // SA_DETAIL_SOLVER_HPP\n</code></pre>\n<p>traits.hpp</p>\n<pre><code>#ifndef SA_DETAIL_TRAITS_HPP\n#define SA_DETAIL_TRAITS_HPP\n\n#include &lt;vector&gt;\n#include &lt;type_traits&gt;\n\nnamespace sa::detail {\n\n    // 类型萃取：判断是否为 std::vector\n\n    template&lt;typename T&gt;\n    struct is_std_vector : std::false_type {};\n\n    template&lt;typename T, typename Alloc&gt;\n    struct is_std_vector&lt;std::vector&lt;T, Alloc&gt;&gt; : std::true_type {};\n\n    template&lt;typename T&gt;\n    inline constexpr bool is_std_vector_v = is_std_vector&lt;T&gt;::value;\n\n} // namespace sa::detail\n\n#endif // SA_DETAIL_TRAITS_HPP\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 20:14</span>&nbsp;\n<a href=\"https://www.cnblogs.com/PaperPlaneFly\">纸飞机低空飞行</a>&nbsp;\n阅读(<span id=\"post_view_count\">56</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "9、PipedInputStream和PipedOutputStream的源码分析和使用方法详细分析",
      "link": "https://www.cnblogs.com/Carey-ccl/p/19625392",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Carey-ccl/p/19625392\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 22:07\">\n    <span>9、PipedInputStream和PipedOutputStream的源码分析和使用方法详细分析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>  在多线程编程中，线程间的数据交换是一个常见需求。Java IO包中的PipedInputStream和PipedOutputStream提供了一种高效的线程间通信机制，允许一批（多个）线程向PipedOutputStream写入数据，另一批（多个）线程从PipedInputStream读取数据。<br />\n  但是，同一批（多个）线程相互之间会存在竞争，比如，同一批向PipedOutputStream写入数据的线程会存在竞争，同一批从PipedInputStream读取数据的线程也会存在竞争。因此PipedInputStream和PipedOutputStream中的线程安全需要通过synchronized关键字和wait()/notifyAll()机制实现。不建议在一个线程中同时使用PipedInputStream和PipedOutputStream，因为这样可能会导致这个线程陷入死锁状态。<br />\n  PipedInputStream和PipedOutputStream之间的通信本质上是一个生产者-消费者模型，其中PipedOutputStream作为生产者，PipedInputStream作为消费者。两者通过一个循环缓冲区（byte[]数组）进行数据交换，PipedOutputStream将数据缓存在PipedInputStream的数组当中，等待PipedInputStream的读取。<br />\n  PipedInputStream和PipedOutputStream的UML关系图，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h4 id=\"一pipedoutputstream生产者源码向pipedinputstream消费者中的缓冲区byte数组写入字节数据的输出stream生产者\">一、PipedOutputStream（生产者）源码——向PipedInputStream（消费者）中的缓冲区（byte[]数组）写入字节数据的输出Stream（生产者）</h4>\n<pre><code>package java.io;\n\nimport java.io.*;\n\npublic\nclass PipedOutputStream extends OutputStream {\n    //与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）\n    private PipedInputStream sink;\n    \n    //构造函数\n    public PipedOutputStream(PipedInputStream snk)  throws IOException {\n        connect(snk);//调用connect()函数，来改变PipedInputStream （消费者）中一些变量的值\n    }\n    \n    //构造函数\n    public PipedOutputStream() {\n    }\n    \n    //线程同步函数：用来改变将要关联的PipedInputStream （消费者）中一些变量的值\n    public synchronized void connect(PipedInputStream snk) throws IOException {\n        if (snk == null) {\n            throw new NullPointerException();//如果将要关联的PipedInputStream （消费者）为null，抛出NullPointerException\n        } else if (sink != null || snk.connected) {\n            //如果与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）!=null或者将要关联的PipedInputStream （消费者）的boolean connected变量为true，则抛出IOException\n            throw new IOException(\"Already connected\");\n        }\n        sink = snk;//将这个PipedOutputStream（生产者）与这个PipedInputStream （消费者）相关联\n        snk.in = -1;//改变PipedInputStream （消费者）中的变量int in=-1\n        snk.out = 0;//改变PipedInputStream （消费者）中的变量int out=0\n        snk.connected = true;//改变PipedInputStream （消费者）中的变量boolean connected=true\n    }\n    \n    //向与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）的缓冲区（byte[]数组）写入1个字节\n    public void write(int b)  throws IOException {\n        if (sink == null) {\n             //如果与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）== null，抛出IOException\n            throw new IOException(\"Pipe not connected\");\n        }\n        sink.receive(b);//最终调用的是这个相关联的 PipedInputStream （消费者）的receive(int b)函数\n    }\n    \n    //向与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）的缓冲区（byte[]数组）写入byte[]数组b的[off,off+len)（左闭右开，不包括off+len）索引位置的字节\n    public void write(byte b[], int off, int len) throws IOException {\n        if (sink == null) {\n            //如果与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）== null，抛出IOException\n            throw new IOException(\"Pipe not connected\");\n        } else if (b == null) {\n            throw new NullPointerException();//如果byte[]数组b==null，抛出一个NullPointerException\n        } else if ((off &lt; 0) || (off &gt; b.length) || (len &lt; 0) ||\n                   ((off + len) &gt; b.length) || ((off + len) &lt; 0)) {//byte[]数组b的[off,off+len)（左闭右开）索引位置是否有越界的检查\n            throw new IndexOutOfBoundsException();//越界的话，抛出一个IndexOutOfBoundsException\n        } else if (len == 0) {\n            return;//如果len==0，结束本次函数调用\n        }\n        sink.receive(b, off, len);//最终调用的是这个相关联的 PipedInputStream （消费者）的receive(byte b[], int off, int len)函数\n    }\n    \n    //线程同步函数：使用notifyAll()函数唤醒所有与这个PipedOutputStream（生产者）相关联的 PipedInputStream （消费者）线程（这个消费者可以绑定1~多个线程）\n    public synchronized void flush() throws IOException {\n        if (sink != null) {\n            synchronized (sink) {\n                sink.notifyAll();\n            }\n        }\n    }\n    //关闭这个PipedOutputStream（生产者），这个PipedOutputStream（生产者）不能再向与它相关联的PipedInputStream（消费者）中的缓冲区（byte[]数组）写入字节数据\n    public void close()  throws IOException {\n        if (sink != null) {\n            sink.receivedLast();\n        }\n    }\n}\n</code></pre>\n<h4 id=\"二pipedinputstream消费者源码从自己的缓冲区byte数组读取字节数据的输入stream消费者\">二、PipedInputStream（消费者）源码——从自己的缓冲区（byte[]数组）读取字节数据的输入Stream（消费者）</h4>\n<pre><code>package java.io;\n\npublic class PipedInputStream extends InputStream {\n    //标记符：true表示与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）已经关闭，反之，反之\n    boolean closedByWriter = false;\n    //标记符：true表示当前这个 PipedInputStream （消费者）已经关闭了，反之，反之\n    volatile boolean closedByReader = false;\n    //标记符：true表示与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）已经持有了这个PipedInputStream （消费者）对象（或者叫已经连接上了），反之，反之\n    boolean connected = false;\n\n    Thread readSide;//当前消费的线程\n    Thread writeSide;//当前生产者的线程\n    \n    //默认的PipedInputStream （消费者）的缓冲区（byte[]数组）的长度\n    private static final int DEFAULT_PIPE_SIZE = 1024;\n\n    //PipedInputStream （消费者）的缓冲区（byte[]数组）\n    protected byte buffer[];\n    //缓冲区（byte[]数组）的写指针\n    protected int in = -1;\n    //缓冲区（byte[]数组）的读指针\n    protected int out = 0;\n    //构造函数\n    public PipedInputStream(PipedOutputStream src) throws IOException {\n        this(src, DEFAULT_PIPE_SIZE);//缓冲区（byte[]数组）的长度使用默认值1024\n    }\n\n    //构造函数\n    public PipedInputStream(PipedOutputStream src, int pipeSize)\n            throws IOException {\n         initPipe(pipeSize);//缓冲区（byte[]数组）的长度使用指定的长度\n         //最终还是调用PipedOutputStream（生产者）的connect()函数，并把自身对象this传递进去，然后在PipedOutputStream（生产者）的connect()函数中，改变自己的3个变量int in=-1、int out=0、boolean connected=true\n         connect(src);\n    }\n    \n    //构造函数，缓冲区（byte[]数组）的长度使用默认值1024\n    public PipedInputStream() {\n        initPipe(DEFAULT_PIPE_SIZE);\n    }\n\n    //构造函数，缓冲区（byte[]数组）的长度使用指定的长度\n    public PipedInputStream(int pipeSize) {\n        initPipe(pipeSize);\n    }\n    \n    //初始化缓冲区（byte[]数组）\n    private void initPipe(int pipeSize) {\n         if (pipeSize &lt;= 0) {\n            throw new IllegalArgumentException(\"Pipe Size &lt;= 0\");\n         }\n         buffer = new byte[pipeSize];\n    }\n\n    public void connect(PipedOutputStream src) throws IOException {\n        src.connect(this); //最终还是调用PipedOutputStream（生产者）的connect()函数，并把自身对象this传递进去，然后在PipedOutputStream（生产者）的connect()函数中，改变自己的3个变量int in=-1、int out=0、boolean connected=true\n    }\n    \n    //线程同步函数：该函数只被PipedOutputStream（生产者）的write(int b)函数调用\n    protected synchronized void receive(int b) throws IOException {\n        checkStateForReceive();//检查PipedInputStream （消费者）的状态\n        writeSide = Thread.currentThread();//当前执行该函数的线程，就是生产者线程\n        if (in == out)\n            //如果缓冲区（byte[]数组）的读指针==缓冲区（byte[]数组）的写指针，唤醒所有消费者线程，自己这个生产者线程调用wait(1000)函数\n            awaitSpace();\n        if (in &lt; 0) {//缓冲区（byte[]数组）的写指针&lt;0时，设置缓冲区（byte[]数组）的写指针=0，缓冲区（byte[]数组）的读指针=0\n            in = 0;\n            out = 0;\n        }\n        buffer[in++] = (byte)(b &amp; 0xFF);//向缓冲区的写指针位置写入1个字节\n        if (in &gt;= buffer.length) {\n            in = 0;//如果缓冲区满了，设置缓冲区的写指针=0\n        }\n    }\n\n    //线程同步函数：该函数只被PipedOutputStream（生产者）的write(byte b[], int off, int len)函数调用\n    synchronized void receive(byte b[], int off, int len)  throws IOException {\n        checkStateForReceive();//检查PipedInputStream （消费者）的状态\n        writeSide = Thread.currentThread();//当前执行该函数的线程，就是生产者线程\n        int bytesToTransfer = len;//生产者线程要写入到缓冲区（byte[]数组）中的字节总量\n        while (bytesToTransfer &gt; 0) {\n            if (in == out)\n                //如果缓冲区（byte[]数组）的读指针==缓冲区（byte[]数组）的写指针，唤醒所有消费者线程，自己这个生产者线程调用wait(1000)函数\n                awaitSpace();\n            int nextTransferAmount = 0;//本次生产者线程要写入到缓冲区（byte[]数组）中的字节数量\n            if (out &lt; in) {\n                //如果缓冲区的读指针&lt;缓冲区的写指针，本次要写入到缓冲区（byte[]数组）中的字节数量=缓冲区的长度-缓冲区的写指针\n                nextTransferAmount = buffer.length - in;\n            } else if (in &lt; out) {\n                if (in == -1) {\n                    in = out = 0;\n                    //如果缓冲区的读指针（out）&gt; 缓冲区的写指针（in）并且缓冲区的写指针（in）=-1，先设置缓冲区的读（out）、写（in）指针=0，本次要写入到缓冲区（byte[]数组）中的字节数量=缓冲区的长度\n                    nextTransferAmount = buffer.length - in;\n                } else {\n                    //如果缓冲区的读指针（out）&gt; 缓冲区的写指针（in）并且缓冲区的写指针（in）=-1，本次要写入到缓冲区（byte[]数组）中的字节数量=读指针（out）-写指针（in）\n                    nextTransferAmount = out - in;\n                }\n            }\n            //本次生产者线程要写入到缓冲区（byte[]数组）中的字节数量最多为len，下次为len-本次写入到缓冲区（byte[]数组）中的字节数量，也就是每次写入的基于len个字节循环递减上一次写入的\n            if (nextTransferAmount &gt; bytesToTransfer)\n                nextTransferAmount = bytesToTransfer;\n            assert(nextTransferAmount &gt; 0);\n            System.arraycopy(b, off, buffer, in, nextTransferAmount);//向缓冲区（byte[]数组）的[in,in+nextTransferAmount)索引位置写入byte[]数组b中[off,off+nextTransferAmount)索引位置的字节，都是左闭右开。\n            bytesToTransfer -= nextTransferAmount;//每一次都基于len个字节循环递减本次写入到缓冲区（byte[]数组）中的字节数量nextTransferAmount\n            off += nextTransferAmount;//将下次要从byte[]数组b中取字节的起始索引的位置（偏移量）+本次写入到缓冲区（byte[]数组）中的字节数量nextTransferAmount\n            in += nextTransferAmount;//将缓冲区的写指针（in）+本次写入到缓冲区（byte[]数组）中的字节数量nextTransferAmount\n            if (in &gt;= buffer.length) {\n                in = 0;//如果缓冲区的写指针（in）&gt; 缓冲区（byte[]数组）的长度，设置缓冲区的写指针（in）=0\n            }\n        }\n    }\n\n    //检查PipedInputStream （消费者）的状态\n    private void checkStateForReceive() throws IOException {\n        if (!connected) {\n            throw new IOException(\"Pipe not connected\");\n        } else if (closedByWriter || closedByReader) {\n            throw new IOException(\"Pipe closed\");\n        } else if (readSide != null &amp;&amp; !readSide.isAlive()) {\n            throw new IOException(\"Read end dead\");\n        }\n    }\n    \n    //如果缓冲区（byte[]数组）的读指针==缓冲区（byte[]数组）的写指针，唤醒所有消费者线程，自己这个生产者线程调用wait(1000)函数\n    private void awaitSpace() throws IOException {\n        while (in == out) {\n            checkStateForReceive();\n\n            /* full: kick any waiting readers */\n            notifyAll();\n            try {\n                wait(1000);\n            } catch (InterruptedException ex) {\n                throw new java.io.InterruptedIOException();\n            }\n        }\n    }\n    //关闭与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）\n    synchronized void receivedLast() {\n        closedByWriter = true;\n        notifyAll();//唤醒所有消费者线程\n    }\n    //线程同步函数：消费者线程每次从缓冲区（byte[]数组）中读取1个字节\n    public synchronized int read()  throws IOException {\n        if (!connected) {//检查标记符connected，如果为false，抛出IOException\n            throw new IOException(\"Pipe not connected\");\n        } else if (closedByReader) {//检查标记符closedByReader，如果为true，抛出IOException\n            throw new IOException(\"Pipe closed\");\n        } else if (writeSide != null &amp;&amp; !writeSide.isAlive()\n                   &amp;&amp; !closedByWriter &amp;&amp; (in &lt; 0)) {\n           //检查当前这个PipedInputStream （消费者）对象中引用的生产者线程和生产者线程的状态，如果和标记符closedByWriter还有缓冲区（byte[]数组）的写指针（in）不能对应的话，抛出一个IOException\n            throw new IOException(\"Write end dead\");\n        }\n\n        readSide = Thread.currentThread();//当前执行该函数的线程，就是消费者线程\n        int trials = 2;//这是一个多次检测的策略变量，防止生产者线程没有关闭了与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）时便抛出IOException\n        //in=-1的情况有种：\n        //①、生产者线程还没有向缓冲区（byte[]数组）中写任何字节\n        //②、消费者线程从缓冲区（byte[]数组）中读完字节（byte）数据以后读指针（out）=写指针（in），那么，当前消费者线程会设置写指针（in）=-1\n        //③、消费者线程执行PipedInputStream 的close()函数后，关闭了这个 PipedInputStream （消费者）\n        while (in &lt; 0) {\n            if (closedByWriter) {\n                /* closed by writer, return EOF */\n                return -1;\n            }\n            if ((writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)) {\n                //多个消费者线程从缓冲区（byte[]数组）中读的时候，并且前一个消费者线程已经把缓冲区（byte[]数组）中写入的字节读完了，并且前一个线程设置了写指针（in）=-1，生产者线程也关闭了与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）时，抛出一个IOException\n                throw new IOException(\"Pipe broken\");\n            }\n            /* might be a writer waiting */\n            notifyAll();//此处的目的是为了唤醒所有生产者线程\n            try {\n                wait(1000);\n            } catch (InterruptedException ex) {\n                throw new java.io.InterruptedIOException();\n            }\n        }\n        int ret = buffer[out++] &amp; 0xFF;//获取缓冲区（byte[]数组）中读指针（out）索引位置的字节,并且将读指针（out）+1\n        if (out &gt;= buffer.length) {\n            out = 0;//如果读指针（out）&gt;=缓冲区（byte[]数组）的长度，设置读指针（out）=0\n        }\n        if (in == out) {\n            /* now empty */\n            in = -1;//如果消费者线程从缓冲区（byte[]数组）中读完字节（byte）数据以后读指针（out）=写指针（in），那么，当前消费者线程会设置写指针（in）=-1\n        }\n\n        return ret;\n    }\n\n    //线程同步函数：如果缓冲区（byte[]数组）中有足够多的字节的话（数量&gt;len），消费者线程每次从缓冲区（byte[]数组）中读取len个字节放到byte[]数组b的[off, off+len)索引位置（左闭右开，不包括off+len）\n    //如果缓冲区（byte[]数组）中字节的数量&lt;len个（比如有in（写指针）-out（读指针）个），消费者线程每次从缓冲区（byte[]数组）中读取（in-out）个字节放到byte[]数组b的[off, off+in-out)索引位置（左闭右开，不包括off+in-out）\n    public synchronized int read(byte b[], int off, int len)  throws IOException {\n        if (b == null) {\n            throw new NullPointerException();\n        } else if (off &lt; 0 || len &lt; 0 || len &gt; b.length - off) {//byte[]数组b的[off,off+len)（左闭右开）索引位置是否有越界的检查\n            throw new IndexOutOfBoundsException();//越界的话，抛出一个IndexOutOfBoundsException\n        } else if (len == 0) {\n            return 0;//如果len==0，返回0\n        }\n\n        /* possibly wait on the first character */\n        int c = read();//先调用read()函数试探性从缓冲区（byte[]数组）中读1个字节\n        if (c &lt; 0) {\n            return -1;//如果试探性的从缓冲区（byte[]数组）中都读不到1个字节，返回-1\n        }\n        b[off] = (byte) c;//把试探性从缓冲区（byte[]数组）中读到的第1个字节放到byte[]数组b的off索引位置\n        int rlen = 1;//累计从缓冲区（byte[]数组）中读到的所有字节数量\n        while ((in &gt;= 0) &amp;&amp; (len &gt; 1)) {\n\n            int available;//本次执行System.arraycopy()函数可以从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n\n            if (in &gt; out) {\n                available = Math.min((buffer.length - out), (in - out));\n            } else {\n                available = buffer.length - out;\n            }\n\n            // A byte is read beforehand outside the loop\n            if (available &gt; (len - 1)) {//减掉试探性从缓冲区（byte[]数组）中读到的第1个字节\n                available = len - 1;\n            }\n            System.arraycopy(buffer, out, b, off + rlen, available);\n            out += available;//读指针（out）+System.arraycopy()函数从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n            rlen += available;//累计从缓冲区（byte[]数组）中读到的所有字节数量 + System.arraycopy()函数从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n            len -= available;//len - System.arraycopy()函数从缓冲区（byte[]数组）中读到byte[]数组b中的字节数量\n\n            if (out &gt;= buffer.length) {\n                out = 0;//如果读指针（out）&gt;=缓冲区（byte[]数组）的长度，设置读指针（out）=0\n            }\n            if (in == out) {\n                /* now empty */\n                in = -1;//如果消费者线程从缓冲区（byte[]数组）中读完字节（byte）数据以后读指针（out）=写指针（in），那么，当前消费者线程会设置写指针（in）=-1\n            }\n        }\n        return rlen;//返回累计从缓冲区（byte[]数组）中读到的所有字节数量\n    }\n    \n    //线程同步函数：返回缓冲区（byte[]数组）中可以被消费者线程读取的字节数量\n    public synchronized int available() throws IOException {\n        if(in &lt; 0)\n            return 0;\n        else if(in == out)\n            return buffer.length;\n        else if (in &gt; out)\n            return in - out;\n        else\n            return in + buffer.length - out;\n    }\n    \n    //关闭这个 PipedInputStream （消费者），其实就是设置标记符closedByReader=true， 设置写指针（in）=-1\n    public void close()  throws IOException {\n        closedByReader = true;\n        synchronized (this) {\n            in = -1;\n        }\n    }\n}\n</code></pre>\n<h4 id=\"三1个线程向pipedoutputstream生产者写字节数据1个线程从pipedinputstream消费者读取字节数据的过程\">三、1个线程向PipedOutputStream（生产者）写字节数据，1个线程从PipedInputStream（消费者）读取字节数据的过程</h4>\n<h5 id=\"31非循环直接写和非循环直接读\">3.1、非循环直接写和非循环直接读</h5>\n<pre><code>package com.chelong.StreamAndReader;\n\nimport java.io.IOException;\nimport java.io.PipedInputStream;\nimport java.io.PipedOutputStream;\n\npublic class PipedTest {\n   public static void main(String[] args) throws IOException {\n      final PipedOutputStream output = new PipedOutputStream();\n      final PipedInputStream input = new PipedInputStream(output);\n      Thread thread1 = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               output.write(\"Hello world, pipe!\".getBytes());//write()函数是阻塞的\n            } catch (IOException e) {\n            }\n         }\n      });\n\n      Thread thread2 = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               int data = -1;\n               while ((data = input.read()) != -1) {//read()函数是阻塞的\n                  System.out.print((char) data);\n               }\n            } catch (IOException e) {\n            }\n         }\n      });\n\n      thread1.start();\n      thread2.start();\n   }\n}\n</code></pre>\n<p>程序运行结果，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  main线程构造PipedOutputStream（生产者）和PipedInputStream（消费者）的过程如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  向PipedOutputStream（生产者）写字节数据的生产者线程的执行过程如下：</p>\n<p><img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  从PipedInputStream（消费者）读取字节数据的消费者线程的执行过程如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h6 id=\"311非循环直接写和非循环直接读时1个生产者线程和1个消费者线程处理数据的过程\">3.1.1、非循环直接写和非循环直接读时1个生产者线程和1个消费者线程处理数据的过程</h6>\n<p>  Java 语言定义了 6 种线程状态, 在任意一个时间点, 一个线程只能有且只有其中的一种状态, 这 6 种状态分别如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>这 6 种线程状态的简单介绍，如下所示<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  JVM运行时内存结构主要包含了五个部分：程序计数器 （PC寄存器）、 JVM栈、Native方法栈、堆、 方法区。如下图所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>图中红色部分是线程私有区域，进入这个区域的数据不会出现线程竞争的关系。而绿色区域中的数据则被所有线程共享，其中Java堆中存放的是大量对象，方法区中存放class信息、常量、静态变量等数据。<br />\n  每个线程的线程栈中会存放函数（方法）的描述符，成员（本地）变量等，函数（方法）在线程栈中会通过压栈和弹栈来执行，除了8种（byte、short、int、long、float、double、boolean、char）基本的数据类型存储在线程栈中以外，其余的引用数据类型（对象）都存储在堆中，然后通过引用将堆中的对象和线程栈中的变量关联起来（也可以叫线程栈中的引用指向堆中的对象）。<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>那么，当使用者执行3.1中的代码时，1个生产者线程和1个消费者线程处理数据的过程如下：<br />\n①、main线程初始化一个缓冲区（byte[]数组），长度为1024（默认值），然后生产者线程通过不断的压栈来完成函数之间的调用，最终执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>②、当生产者线程填充完缓冲区之后，写指针变量int in=17，读指针变量int out=0，Thread writeSide = 当前这个生产者线程（Thread）对象，生产者线程会把自己线程栈中修改的变量最终刷新到堆中PipedInputStream对象中，以确保其它消费者线程的线程栈从堆中读取这3个变量时，这3个变量已经为修改后的值，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>③、消费者线程读缓冲区（byte[]数组）的过程中会不断地执行out++（读指针）以读取缓冲区（byte[]数组）中的可用字节并返回，直到out（读指针）==in（写指针），修改in（写指针）=-1，并且每次同步执行PipedInputStream.class::read()函数时，都会更新Thread readSide = 当前这个消费者线程（Thread）对象，消费者线程也会把自己线程栈中修改的变量最终刷新到堆中PipedInputStream对象中，以确保其它消费者线程的线程栈从堆中读取这3个变量时，这3个变量已经为修改后的值，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>④、更新in（写指针）=-1后，消费者线程再次同步执行PipedInputStream.class::read()函数时，如果PipedInputStream::boolean closedByWriter变量为true，则会返回-1</p>\n<h5 id=\"32加锁循环写和非加锁循环读到byte数组b中再处理\">3.2、加锁循环写和非加锁循环读到byte[]数组b中再处理</h5>\n<pre><code>package com.chelong.pipe;\nimport java.io.IOException;\nimport java.io.PipedInputStream;\nimport java.io.PipedOutputStream;\n\npublic class PipeForTransferInThread {\n   public static void main(String[] args) throws IOException, InterruptedException {\n      final PipedOutputStream output = new PipedOutputStream();\n      final PipedInputStream input = new PipedInputStream(output);\n      //生产者线程\n      Thread producer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            for (int i = 0; i &lt; 3; i++) {\n               synchronized (input) {\n                  try {\n//                    input.wait();\n                     output.write(\"Hello world, pipe!\".getBytes());\n                     input.wait();//释放锁并无限等待，直到消费者线程consumer 执行notifyAll()函数来唤醒当前阻塞\n                  } catch (Exception e) {\n                     e.printStackTrace();\n                  }\n               }\n            }\n         }\n      },\"生产者线程\");\n      \n      //消费者线程\n      Thread consumer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               byte[] b = new byte[1024];//1KB\n               int readBytes = -1;\n               long lastTime = System.currentTimeMillis();\n               while ((readBytes = input.read(b, 0, b.length)) != -1) {\n                  long curTime = System.currentTimeMillis();\n                  System.out.print(Thread.currentThread().getName()+\"本次读取花费时间：\" + (curTime - lastTime) + \"ms，读到的数据是：\");\n                  lastTime = curTime;\n                  for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n                  System.out.println();\n               }\n            } catch (IOException e) {\n               e.printStackTrace();\n            }\n         }\n      },\"消费者线程\");\n      producer.start();//生产者线程启动\n      consumer.start();//消费者线程启动\n   }\n}\n</code></pre>\n<p>程序运行结果，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  main线程构造PipedOutputStream（生产者）和PipedInputStream（消费者）的过程可以参考3.1；<br />\n  向PipedOutputStream（生产者）写字节数据的生产者线程的执行过程可以参考3.1；<br />\n  从PipedInputStream（消费者）读取字节数据的消费者线程的执行过程如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h6 id=\"321加锁循环写和非加锁循环读到byte数组b中再处理时1个生产者线程和1个消费者线程处理数据的过程\">3.2.1、加锁循环写和非加锁循环读到byte[]数组b中再处理时1个生产者线程和1个消费者线程处理数据的过程</h6>\n<p>  标题3.2中的代码的整个执行过程如下：<br />\n①、main线程初始化一个缓冲区（byte[]数组），长度为1024（默认值），如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>②、然后生产者线程通过不断的压栈来完成函数之间的调用，最终执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，并且先在自己的线程栈中更新in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程（Thread）对象 如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>当生产者线程对缓冲区（byte[]数组）填充完成之后，再执行标题3.2中的代码</p>\n<pre><code>input.wait();\n</code></pre>\n<p>这行代码会释放锁并让生产者线程进入无限等待，直到消费者线程consumer执行notifyAll()函数来唤醒当前这个生产者线程。在这之前，生产者线程会将自己线程栈中的in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>③、消费者线程读缓冲区（byte[]数组）的过程也是通过不断的压栈来完成函数之间的调用，最终执行PipedInputStream::read()函数（试探性的读取1个字节）和PipedInputStream::read(byte b[], int off, int len)函数（读取剩余其它的字节）将步骤②中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<blockquote>\n<p>附言：最终消费者线程也会将自己线程栈中的in（写指针）= -1，out（读指针）= 17，writeSide=当前这个消费者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。</p>\n</blockquote>\n<p>因此，本次消费者线程从缓冲区（byte[]数组）中读数据的过程中没有执行read()函数中的wait(1000)这一行代码，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>所以，本次消费者线程从缓冲区（byte[]数组）中读取数据到消费者线程中自己创建的byte[]数组中时，只花费了0ms：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>接下来，当消费者线程将步骤②中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来以后（通过System.arraycopy()函数复制到了消费者线程中自己创建的byte[]数组中），消费者线程会遍历从缓冲区读到的这个byte[]数组，来处理这些数据，如下所示（标题3.2中的代码片段）：</p>\n<pre><code>                   //标题3.2中的代码片段\n                   for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n</code></pre>\n<p>然后，当消费者线程再次执行</p>\n<pre><code>//标题3.2中的代码片段\ninput.read(b, 0, b.length)\n</code></pre>\n<p>从缓冲区（byte[]数组）中读数据到自己创建的byte[]数组中时，由于此时in（写指针）=-1，并且当下图中的其它5个条件都不成立时，唤醒执行了</p>\n<pre><code>input.wait()\n</code></pre>\n<p>的生产者线程，然后当前这个正在从缓冲区(byte数组)中读数据的消费者线程执行wait 1000ms ，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>④、当生产者线程被消费者线程执行的</p>\n<pre><code>notifyAll();\n</code></pre>\n<p>唤醒之后，会再次通过不断的压栈来完成函数之间的调用，再次执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，并且先在自己的线程栈中先更新in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程（Thread）对象 如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>当生产者线程对缓冲区（byte[]数组）填充完成之后，再执行标题3.2中的代码</p>\n<pre><code>input.wait();\n</code></pre>\n<p>这行代码会释放锁并让生产者线程进入无限等待，直到消费者线程consumer执行notifyAll()函数来唤醒当前这个生产者线程。在这之前，生产者线程会将自己线程栈中的in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑤、消费者线程在第③步执行了</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>在等待了1000ms之后，消费者线程会自动唤醒继续执行，此时自己线程栈中的in（写指针）= -1，out（读指针）= 17已经被第④步中的生产者线程修改为in（写指针）=17，out（读指针）=0（生产者线程不会直接修改消费者线程栈中的变量，生产者线程会先将自己线程栈中in（写指针），out（读指针）变量的值修改到主内存中，然后消费者线程会自己将主内存中的这2个变量值刷新到消费者自己的线程栈中），如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>然后执行PipedInputStream::read()函数（试探性的读取1个字节）和PipedInputStream::read(byte b[], int off, int len)函数（读取剩余其它的字节）将步骤④中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<blockquote>\n<p>附言：最终消费者线程也会将自己线程栈中的in（写指针）= -1，out（读指针）= 17，writeSide=当前这个消费者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。</p>\n</blockquote>\n<p>由于，本次消费者线程从缓冲区（byte[]数组）中读数据的过程是从步骤③中自动唤醒继续执行的，所以，本次消费者线程从缓冲区（byte[]数组）中读取数据到消费者线程中自己创建的byte[]数组中时，花费了1015ms：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>接下来，当消费者线程将步骤④中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来以后（通过System.arraycopy()函数复制到了消费者线程中自己创建的byte[]数组中），消费者线程会遍历从缓冲区读到的这个byte[]数组，来处理这些数据，如下所示（标题3.2中的代码片段）：</p>\n<pre><code>                   //标题3.2中的代码片段\n                   for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n</code></pre>\n<p>然后，当消费者线程再次执行</p>\n<pre><code>//标题3.2中的代码片段\ninput.read(b, 0, b.length)\n</code></pre>\n<p>从缓冲区（byte[]数组）中读数据到自己创建的byte[]数组中时，由于此时in（写指针）=-1，并且当下图中的其它5个条件都不成立时，唤醒执行了</p>\n<pre><code>input.wait()\n</code></pre>\n<p>的生产者线程，然后当前这个正在从缓冲区(byte[]数组)中读数据的消费者线程执行wait 1000ms ，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑥、当生产者线程被消费者线程执行的</p>\n<pre><code>notifyAll();\n</code></pre>\n<p>唤醒之后，会再次通过不断的压栈来完成函数之间的调用，再次执行PipedInputStream.class::receive(byte b[], int off, int len)函数来对缓冲区（byte[]数组）进行填充，并且先在自己的线程栈中先更新in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程（Thread）对象 如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>当生产者线程对缓冲区（byte[]数组）填充完成之后，再执行标题3.2中的代码</p>\n<pre><code>input.wait();\n</code></pre>\n<p>这行代码会释放锁并让生产者线程进入无限等待，直到消费者线程consumer执行notifyAll()函数来唤醒当前这个生产者线程。在这之前，生产者线程会将自己线程栈中的in（写指针）=17，out（读指针）=0，writeSide=当前这个生产者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑦、消费者线程在第⑤步执行了</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>在等待了1000ms之后，消费者线程会自动唤醒继续执行，此时自己线程栈中的in（写指针）= -1，out（读指针）= 17已经被第⑥步中的生产者线程修改为in（写指针）=17，out（读指针）=0（生产者线程不会直接修改消费者线程栈中的变量，生产者线程会先将自己线程栈中in（写指针），out（读指针）变量的值修改到主内存中，然后消费者线程会自己将主内存中的这2个变量值刷新到消费者自己的线程栈中），然后执行PipedInputStream::read()函数（试探性的读取1个字节）和PipedInputStream::read(byte b[], int off, int len)函数（读取剩余其它的字节）将步骤⑥中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<blockquote>\n<p>附言：最终消费者线程也会将自己线程栈中的in（写指针）= -1，out（读指针）= 17，writeSide=当前这个消费者线程，这3个变量更新到主内存（也就是堆）中的PipedInputStream对象中。</p>\n</blockquote>\n<p>由于，本次消费者线程从缓冲区（byte[]数组）中读数据的过程是从步骤⑤中自动唤醒继续执行的，所以，本次消费者线程从缓冲区（byte[]数组）中读取数据到消费者线程中自己创建的byte[]数组中时，花费了1017ms：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>接下来，当消费者线程将步骤⑥中生产者线程写入到缓冲区（byte[]数组）中的17个字节读取出来以后（通过System.arraycopy()函数复制到了消费者线程中自己创建的byte[]数组中），消费者线程会遍历从缓冲区读到的这个byte[]数组，来处理这些数据，如下所示（标题3.2中的代码片段）：</p>\n<pre><code>                   //标题3.2中的代码片段\n                   for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n</code></pre>\n<p>然后，当消费者线程再次执行</p>\n<pre><code>//标题3.2中的代码片段\ninput.read(b, 0, b.length)\n</code></pre>\n<p>从缓冲区（byte[]数组）中读数据到自己创建的byte[]数组中时，由于此时in（写指针）=-1，并且当下图中的其它5个条件都不成立时，唤醒执行了</p>\n<pre><code>input.wait()\n</code></pre>\n<p>的生产者线程，然后当前这个正在从缓冲区(byte[]数组)中读数据的消费者线程执行wait 1000ms ，如下：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /><br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>⑧、当生产者线程被消费者线程执行的</p>\n<pre><code>notifyAll();\n</code></pre>\n<p>唤醒之后，会跳出for循环，结束生产者线程的生命周期，之后，该线程对象会被操作系统回收。<br />\n⑨、消费者线程在第⑦步执行了</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>在等待了1000ms之后，消费者线程会自动唤醒继续执行，此时自己线程栈中的in（写指针）= -1，out（读指针）= 17，并且从</p>\n<pre><code>wait(1000);\n</code></pre>\n<p>的代码之后，继续执行，执行过程如下（从下图的紫色流程继续执行）：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>在执行了2个循环后，直到int trials = 0时，执行到判断(writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)这个条件时就会为true（下图的红色流程）<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>然后，抛出了一个IOException(\"Pipe broken\")，因此，可以得出int trials变量的含义：这个变量是一个多次检测的策略变量，当生产者线程没有关闭了与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）时，并且writeSide变量指向的当前生产者线程已经被操作系统回收时（此时当前生产者线程对象的isAlive()函数会返回false），消费者线程会抛出1个IOException(\"Pipe broken\")，并结束while循环，进而结束消费者线程的生命周期。之后，该线程对象也会被操作系统回收。如下图所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<h6 id=\"322怎样防止321中第步的生产者线程抛出ioexceptionpipe-broken\">3.2.2、怎样防止3.2.1中第⑨步的生产者线程抛出IOException(\"Pipe broken\")</h6>\n<p>  回顾3.2.1中第⑨步中的消费者线程抛出IOException(\"Pipe broken\")的产生过程：当执行到判断(writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)这个条件时就会为true（下图的红色流程）<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>那么，使用者就可以将上图中红色流程的前一步变成true即可，如下代码所示（只修改了生产者线程中的代码，消费者线程中的代码没有变化）：</p>\n<pre><code>package com.chelong.pipe;\nimport java.io.IOException;\nimport java.io.PipedInputStream;\nimport java.io.PipedOutputStream;\n   public static void main(String[] args) throws IOException, InterruptedException {\n      final PipedOutputStream output = new PipedOutputStream();\n      final PipedInputStream input = new PipedInputStream(output);\n      //生产者线程\n      Thread producer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               for (int i = 0; i &lt; 3; i++) {\n                  synchronized (input) {\n//                    input.wait();\n                     output.write(\"Hello world, pipe!\".getBytes());\n                     input.wait();//释放锁并无限等待，直到消费者线程thread2执行notifyAll()函数来唤醒当前阻塞\n                  }\n               }\n            } catch (Exception e) {\n               e.printStackTrace();\n            } finally {\n               try {\n                  if (output != null) output.close();//调用close()函数关闭生产者对象\n               } catch (IOException e) {\n                  e.printStackTrace();\n               }\n            }\n         }\n      }, \"生产者线程\");\n\n      //消费者线程\n      Thread consumer = new Thread(new Runnable() {\n         @Override\n         public void run() {\n            try {\n               byte[] b = new byte[1024];//1KB\n               int readBytes = -1;\n               long lastTime = System.currentTimeMillis();\n               while ((readBytes = input.read(b, 0, b.length)) != -1) {\n                  long curTime = System.currentTimeMillis();\n                  System.out.print(Thread.currentThread().getName() + \"本次读取花费时间：\" + (curTime - lastTime) + \"ms，读到的数据是：\");\n                  lastTime = curTime;\n                  for (int i = 0; i &lt; readBytes; i++) {\n                     System.out.print((char) b[i]);//模拟处理字节数据\n                  }\n                  System.out.println();\n               }\n            } catch (IOException e) {\n               e.printStackTrace();\n            }\n         }\n      }, \"消费者线程\");\n      producer.start();//生产者线程启动\n      consumer.start();//消费者线程启动\n   }\n}\n</code></pre>\n<p>程序运行结果，如下所示：<br />\n<img alt=\"clipboard\" class=\"lazyload\" /></p>\n<p>  通过PipedOutputStream.class::close()的源码可以看到这样修改后消费者线程不再抛出IOException(\"Pipe broken\")原因：<br />\nPipedOutputStream.class（生产者类）的源码</p>\n<pre><code>package java.io;\n\nimport java.io.*;\n\npublic\nclass PipedOutputStream extends OutputStream {\n    ...省略部分代码...\n    //关闭这个PipedOutputStream（生产者），这个PipedOutputStream（生产者）不能再向与它相关联的PipedInputStream（消费者）中的缓冲区（byte[]数组）写入字节数据\n    public void close()  throws IOException {\n        if (sink != null) {\n            sink.receivedLast();//调用PipedInputStream.class::receivedLast()函数\n        }\n    }\n}\n</code></pre>\n<p>PipedInputStream .class（消费者类）的源码</p>\n<pre><code>package java.io;\n\npublic class PipedInputStream extends InputStream {\n    //标记符：true表示与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）已经关闭，反之，反之\n    boolean closedByWriter = false;\n    ...省略部分代码...\n    //关闭与这个 PipedInputStream （消费者）相关联的PipedOutputStream（生产者）\n    synchronized void receivedLast() {\n        closedByWriter = true;//关闭后消费者再从缓冲区（byte[]）数组中读取字节数据时，会返回-1，不会抛出IOException了\n        notifyAll();//唤醒所有消费者线程\n    }\n    ...省略部分代码...\n</code></pre>\n<h4 id=\"四多个线程向pipedoutputstream生产者写字节数据多个线程从pipedinputstream消费者读取字节数据的过程\">四、多个线程向PipedOutputStream（生产者）写字节数据，多个线程从PipedInputStream（消费者）读取字节数据的过程</h4>\n<p>  略（待补充）</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 22:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Carey-ccl\">Carey_ccl</a>&nbsp;\n阅读(<span id=\"post_view_count\">55</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2023年电赛国赛经历",
      "link": "https://www.cnblogs.com/badboy02/p/19623709",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/badboy02/p/19623709\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 14:06\">\n    <span>2023年电赛国赛经历</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"2023年电赛国赛经历\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3763221/202602/3763221-20260219000428689-1446099918.png\" />\n        2023年全国大学生电子设计竞赛经历，D题信号题，国赛二等奖。\n一些比赛经历和经验技巧\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>--- markdown描述<br />\ntitle: 电赛2023国赛D题比赛经历<br />\ndate: 2023/8/15 11:52:25<br />\ncover: true<br />\nmathjax: false<br />\nsummary: 比赛过程和一些准备工作的碎碎念<br />\ncategories: Note<br />\ntags:</p>\n<ul>\n<li>电赛</li>\n<li>信号</li>\n</ul>\n<hr />\n<h2 id=\"补档声明\">补档声明</h2>\n<p>由于我的博客服务器和备案到期，所以选择转移到博客园平台来进行保存和记录。以后也有可能会在上面不定期更新一些技术类博客。</p>\n<h2 id=\"写在前面\">写在前面</h2>\n<p>🪓突然意识到自己已经8个月没更新博客了，这段时间其实也没遇上啥太复杂的事，大概就是一些沉淀之类的，决定了之后的学业去向，推免了本校的研究生。进一步认识了一群未来志同道合的的同门，激情爽玩塞尔达旷野之息和王国之泪，狠狠地治愈了一阵子的电子阳痿，以及开始健身（存疑）。<br />\n当然，电赛什么的也是有在准备的，由于团队其他两个都是硬件佬，他们承受着画板与焊接调试的水深火热，我只需要安安静静的写代码就足够了（笑），每天实验室上下班，把自己的部分搞定，然后去健身房锻炼一会，回来美美加个餐洗个澡，然后打打机去睡觉，也算是某种意义上的平静的生活，求之不得。毕竟当初决定打电赛说到底也只是为了提升自己，探索一下电子世界的奥妙，这么久走过来也是重在坚持，也希望最后能有一个好结果。<br />\n截止到写博客的时候，我们组的成绩省赛以省一并列第一出线，综合测评应该也能过线，山东大学国测复测不出意外的话，应该是国二以上。</p>\n<p>这篇博客会分为上下两部分，上篇主要是比赛的过程和一些前置的准备(没有营养的碎碎念)，下篇主要是一些算法具体的实现(一些情急之下的灵机一动，大佬轻锤)。</p>\n<h2 id=\"比赛过程\">比赛过程</h2>\n<ol>\n<li>准备阶段</li>\n</ol>\n<p>我们队伍一直以来训练的是仪表和高频题，一开始侧重FPGA高速信号采集和数字域处理这一块，但是后面逐渐意识到，对于电赛的指标范围内好像也不需要这么高的频率，高载波带来的高采样率问题可以通过下混频缓解，而高频直采带来是的FIR滤波器的资源消耗成倍增加，以及数字域处理带来的资源占用和量化噪声问题。</p>\n<p><img alt=\"ZYNQ7100平台\" class=\"lazyload\" /><br />\n这是我们准备的ZYNQ7100的平台，可以外接高速ADDA，板载DDR3.<br />\n但是吧，ZYNQ平台的综合速度和固化难度以及Verilog代码的验证难度，在分秒必争的竞赛里，如果没有长期的训练和准备，在比赛那四天着急上头去写，恐怕会翻车。</p>\n<p>于是在训练后期又重回STM32H743的单片机平台，侧重模块叠加后的健壮性和代码的可复用性。</p>\n<p>从训练开始，🪓就有意识地把一些算法，尤其是FFT分析这一块，写成了独立的函数去进行一些参数的分析，然后把其他的像是屏幕显示，按键输入，外设驱动，都封装成主循环中的函数，用参数和标志位去控制。不得不说在电赛的信号分析题中还是一种很好用的代码架构。</p>\n<p><img alt=\"Main函数截图\" class=\"lazyload\" /></p>\n<p>本次代码的组织结构，可以清楚的看到，是首先进行ADC采集，FFT计算，然后将参数传入Judge_ModeType函数计算出调制类型，然后进入相应的部分去进行分析和显示。</p>\n<p>2.正式开始</p>\n<p>比赛的那几天，第一天上午8点队友一拿到题目基本上就确定了是D题，然后就开始画系统框图，找模块，搭系统。<br />\n🪓是九点钟到的实验室。然后一看题，哦豁，Ma和Mf！ 这不是老朋友吗，去年省赛这两位重量级，特别是Mf，让无数队伍刹羽而归。<br />\n其奇妙的多值和莫名其妙的算不准问题，难到了一大批电赛壬。<br />\n不过算法方面🪓早有应对，具体请看后文分析。<br />\n队友把混频模块弄好，确定好中频频率后，把混频后的信号通入ADC模块，此时🪓进行了简单的测试，确定了ADC采样率。<br />\n然后就开始了算法的编写。在第一天的中午就把Ma的计算搞定了，精度误差大概在0.05左右。<br />\n然后下午把Mf的算法也基本调试正确了，精度误差在0.2左右，有少量的多值问题，这时候时间已经是第一天晚上的8点，🪓进行了第一次备份。（时常备份真是好习惯）<br />\n<img alt=\"备份截图\" class=\"lazyload\" /><br />\n这是工程的几次备份图，可以看到从7月17日确定了基本平台之后，就是几天一备份，在比赛那几天更是一天备份几次。<br />\n为什么没有使用git之类的版本控制工具呢，因为我不会（其实是懒得建仓库+没找到合适的托管平台，github连不上，gitee不想用）<br />\n然后就是ASK，FSK，PSK的判别、解调以及FSK的h参数计算问题，总的说来，这个花费了🪓一番功夫，也算是最核心的代码部分。<br />\n第二天的中午完成了模拟调制和数字调制两大类的初步判断，下午进一步完成了模拟的AM，FM，CW的进一步判断，以及数字的ASK，FSK，PSK的进一步判断和解调。(充实的一天)<br />\n<img alt=\"PSK解调\" class=\"lazyload\" /><br />\n第二天晚上回寝室的时候🪓在和队友闲扯的时候突然想到了FSK的h参数计算方法，然后在小本本上记了下来。<br />\n第三天，🪓一到实验室就开始着手验证自己的想法，发现完全可以，直接芜湖起飞。<br />\n然后下午的时间就是加入射频开关和滤波器，放大器等原件，完成了系统的整体级联和最后解调波形的实时切换。<br />\n第三天的晚上其实整个系统已经级联并且测试好了。<br />\n最后一天就是一些锦上添花的功能，比如实时频谱显示和QPSK的判断以及高频载波下的解调以及准度的修正，在下午三点左右完成了最后的测试和封箱。<br />\n<img alt=\"封箱\" class=\"lazyload\" /><br />\n总的来说这几天的流程还是稳扎稳打，逐步推进的。我们团队一直以来配合的也很不错，效率贼高，最后呈现出来的效果就是电赛这三天每天晚上11点都回寝室睡觉了，第二天9点再到实验室，也还能完成所有的基础和提高指标并做出3项其他指标。不知不觉中完成了我们团队刚开始接触电赛的时的一个玩笑-希望以后能不熬夜就打完电赛。<br />\n<img alt=\"交作品\" class=\"lazyload\" /><br />\n作为东道主，半夜交作品也是很合理的罢。</p>\n<p>3.省赛测评</p>\n<p>封箱后的第二天就是省测了，总的来说还是蛮顺利的，所有功能都演示出来了，测评表的指标也没有很难的点。<br />\n测完直接和朋友出去快乐吃喝，等待综合测评名单。</p>\n<p>4.综合测评<br />\n由于🪓理论上是纯软件队员(其实🪓也会画板子和焊板子，这就是EEer的素养)，综合测评的硬件大业当然就交给我的两位大爹队友了，🪓只需要在旁边写个报告算个参数就好。<br />\n在准备硬件测评器件，我们测试了各种555电路，二极管检波，微分积分器，加法器，带通滤波器的电路图。<br />\n综合测评那天，一进现场，发现题目竟然是模拟计算器，用来解一个微分方程。<br />\n不过稍加分析，就会发现其本质是文氏桥正弦发生器，三角波发生器，两个积分器，一个微分器，一个加法器的组合。<br />\n这一里面的每一项单独拎出来都很简单，但是在当时时间比较紧促的情况下，我们虽然把电路全部级联出来了，但是在零状态的时候，并没有像计算的那样，产生一个33Hz的自激波形。<br />\n也许是中间的某项RC常数没有配置正确，也许是某一段未修正相差，也许是某一段的偏置需要消除，总是零状态的时候就是妹有出波形。<br />\n说到模拟计算电路，其实这是个展开来讲有非常多可以讲的话题，想进一步研究的同学可以移步CNPP大佬的模拟计算 <a href=\"https://hackaday.io/project/191142-analog-lorenz-attractor-computer/details\" rel=\"noopener nofollow\" target=\"_blank\">https://hackaday.io/project/191142-analog-lorenz-attractor-computer/details</a><br />\n我们也就停止了后面的输入激励。静待比赛时间结束，毕竟这只是一个达标测试，就不冒进去做进一步的冒险了。</p>\n<p>有一说一中午学校提供的饭菜还可以，菜品有土豆烧牛肉，木耳炒蛋，水煮虾，还有酸奶和水果，我TM吃吃吃。</p>\n<p>4.国赛评测</p>\n<p>等🪓玩回来更新</p>\n<h2 id=\"题目分析\">题目分析</h2>\n<p><img alt=\"题目描述1\" class=\"lazyload\" /></p>\n<p><img alt=\"题目描述2\" class=\"lazyload\" /></p>\n<p><strong>题目分析（*的数量为重要程度）</strong></p>\n<ul>\n<li>题目的输入信号有100mv，属于一个比较大的信号，从信号源直出，通过SMA线输入，<strong>信噪比非常高，不需要考虑信号在无线传输过程中被干扰和多径效应等问题</strong></li>\n<li>载波频率2MHz，说实话，是一个比较微妙的频率，刚好超过了市面上单片机内置ADC的最大采样频率，但是对于FPGA外挂的50M左右的高速ADC来说(AD9225:没错正是在下)，又看上去是一个很合适的频率。所以使用单片机的组一般会<strong>选择下混频</strong>，而使用FPGA的组如果选择直采，经过我们当时的分析，可能会遇到一些问题问题，比如FFT后频率分辨率不够，FIR资源消耗大带来的综合慢，数字下混频相位不对齐造成的失真和误差(更别提Vivado的FFT的IP核要想用好其实并不容易，定点FFT很容易产生很大的舍入误差)。肯定有FPGA佬能想到规避或者解决的办法。但是受限与我们当时知识理解的程度，我们还是选择了单片机平台。所以从这也可以看出电赛的出题并不一味地要求好的器件，而更多的是<strong>因地制宜选择方案</strong></li>\n<li><strong>要计算调幅度Ma，这就要求获得调制后信号的频谱，也就是要做FFT</strong>。这就要求ADC的采样频率能够高于中心频点+最大频偏之和的两倍。当然，实际上为了频谱的可读性和频率精确度的考量，一般选择4至6倍的采样频率*</li>\n<li>要计算调频度Mf和最大频偏Δf，同上，还涉及到一些算法的<strong>多值问题</strong>，在后面详细讨论</li>\n<li>要进行模拟调制的解调，可以先通过混频**把信号混到10.7M高中频，使用ADL5511 ，NE564等芯片进行解调</li>\n<li>要识别ASK，FSK，PSK等调制方式，这就要求<strong>把它们的频谱差异提取出来并做好特征区分，以及对于某些非常相似情况下引入多重判断维度来进行区分</strong> 。</li>\n<li>要通过频谱进行FSK的h参数的计算，其实在单片机里做是很难的，但是我们可以<strong>通过FM和FSK的相似性，来进行一些取巧的操作</strong>，这个后面详细讨论**</li>\n<li>要识别待调制波的频率，其实就是<strong>计算调制后波形的FFT相邻频点之间的间隔</strong>，这一点是由调制的性质所导致的，所有调制方式都能通过这种方式判断待调制波的频率*</li>\n<li>要进行数字调制波形的解调，<strong>要结合不同调制方式的特点，混合使用模拟模块和数字域判决的方式来进行解调</strong>，比如ASK使用的是先通过模拟AD8310检波后通过直流量高低来判断0，1波形。FSK使用了数字FIR把频率转变为包络的变化，进行0，1的判决。而PSK使用了先数字域下混频和FIR的方式，把相位的跳变导致的相乘后的包络变化通过滤波器检出</li>\n<li>要综合上述的识别和计算，通<strong>过模拟开关将解调结果通过一个通道显示</strong>在示波器上，并通过AGC等手段，保证电压大于1Vpp*</li>\n</ul>\n<h2 id=\"系统架构\">系统架构</h2>\n<p><img alt=\"系统架构\" class=\"lazyload\" /></p>\n<p>本系统硬件框图如图所示，乍一看非常复杂(实际上也确实很复杂，最后数了一下，作品上一共有26块板子)。别急，让我们慢慢来，一步步分析，<br />\n由于输入信号的峰峰值是100mV，换算一下也就是-16dbm，所以首先经过24dB增益的低噪放ERA-3SM进行放大。<br />\n此时的信号幅度有8dbm，也就是峰峰值1.5Vpp，正好适合后面的各种器件的电压范围。<br />\n然后将信号通过功分器，同时混频到50kHz中频和10.7MHz中频。这是为了一路用来分析，一路用来模拟解调。<br />\n50kHz 的中频信号，经过滤波、放大和电平搬移后，一路经过ADS8688变为数字信号送入单片机。另一路经过检波器 AD8310 和滤波器 UAF42 后检出 ASK 的直流，并送给单片机进一步完成 ASK 信号的定时抽判。<br />\n10.7MHz 的中频信号经过陶瓷滤波器、放大器和射频开关后，分别进行基于 ADL5511 的 AM 包络检波解调和基于 NE564 的FM 解调.<br />\n最后通过 MCU 控制的模拟开关TMUX1109，将解调结果送给示波器显示。在单片机内，通过对 50kHz 的中频信号的频谱分析，得到调制信号类型和调制参数，<br />\n以及FSK和PSK的解调结果的输出，并控制其他模块完成最后结果的汇总输出，以及控制液晶屏显示识别结果和参数。</p>\n<h2 id=\"一些准备工作和小寄巧\">一些准备工作和小寄巧</h2>\n<h3 id=\"电压和dbm的换算\">电压和dbm的换算</h3>\n<p>在射频电路中，为了表示比较小的电压，一般采用对数形式，其中dbm是一个常用的单位，它是在某一阻抗匹配系统下，功率相对于1mW的比值，而由于已经射频电路阻抗一般是50欧姆，所以相当于也知道了电压。<br />\n不过由于功率的计算还涉及到波形的有效值啥的，方波1，正弦0.707，三角波0.57，实际中一般不会自己去算，都是使用这种在线计算器。<br />\n可以记忆一下一些常见的值</p>\n<table>\n<thead>\n<tr>\n<th>正弦波</th>\n<th>50欧姆阻抗下</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-116dbm</td>\n<td>1uVpp</td>\n</tr>\n<tr>\n<td>-56dbm</td>\n<td>1mVpp</td>\n</tr>\n<tr>\n<td>-36dbm</td>\n<td>10mVpp</td>\n</tr>\n<tr>\n<td>-16dbm</td>\n<td>100mVpp</td>\n</tr>\n<tr>\n<td>0dbm</td>\n<td>632mVpp</td>\n</tr>\n<tr>\n<td>4dbm</td>\n<td>1Vpp</td>\n</tr>\n<tr>\n<td>14dbm</td>\n<td>3.3Vpp</td>\n</tr>\n</tbody>\n</table>\n<p>实用小工具 电压和dbm的换算<br />\n<a href=\"https://www.analog.com/cn/design-center/interactive-design-tools/dbconvert.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.analog.com/cn/design-center/interactive-design-tools/dbconvert.html</a></p>\n<p><img alt=\"ADI电压换算工具\" class=\"lazyload\" /><br />\n注意这里的VPeak是峰值，换算成峰峰值的话要乘以2</p>\n<h3 id=\"adc的一些准备工作\">ADC的一些准备工作</h3>\n<p><img alt=\"ADS8688手册\" class=\"lazyload\" /></p>\n<h4 id=\"adc选型\">ADC选型</h4>\n<p>我们本次使用的是ADS8688A作为系统的ADC，它是一个16bit，500KSPS采样率的SAR型ADC。<br />\n它的特点有双极性输入，可配置动态范围，内部基准，八通道MUX采样，误差和漂移都很低，对于本题来说肯定是够用的。<br />\n我们用它主要还是看上了它支持双极性输入和可变动态范围这一点，这样就不用自己做前级的搬移和放大。<br />\n而且自带过压保护，比较耐造。<br />\nPS.我们的STM32H743平台的内置ADC，在某次测试的时候，对单频大幅值信号采样做FFT后，其二次谐波值会大的超出常理，理论上来说是不会有这么大的。<br />\n怀疑内置SAR积分电路被过压橄榄了😓<br />\n所以换用了这个外置的ADC，以后可以开一篇文章讲一下ADC的各种参数，以及这种失真是怎么来的，此时就要请出另一位小信号领域的expert，FloydFish🐟<br />\n可以移步<a href=\"https://www.emoe.xyz/opamp-noise-analyze/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.emoe.xyz/opamp-noise-analyze/</a> ，以及相关的小信号测量。</p>\n<p>驱动代码<br />\n这个的驱动我已经打包好了，下载下来改一下管脚直接用就可以了 <a href=\"https://megrez-hong.oss-cn-shanghai.aliyuncs.com/blogs/ADS8688_Driver.zip\" rel=\"noopener nofollow\" target=\"_blank\">https://megrez-hong.oss-cn-shanghai.aliyuncs.com/blogs/ADS8688_Driver.zip</a><br />\n<strong>ADC的驱动要注意的两点是，一是这个ADC的数据Latch和吐出是根据SPI的速率来的</strong><br />\n所以为了控制采样速率，需要自己控制其中的IO操作后的Delay函数，经过测试，在ARMCC6编译器，O2水平的优化下，使用volatile参数，下面这种delay方法依然可以达到延时效果。</p>\n<p><img alt=\"Delay的实现\" class=\"lazyload\" /></p>\n<p><img alt=\"ADS8688的采样函数\" class=\"lazyload\" /><br />\n二是采样的时候需要关闭中断响应，因为我们不希望采样的时候定时器中断什么的把采样操作打扰了。</p>\n<p>这里的采样率根据实测大概在250K左右，达不到官方的标称的500K。应该是已经达到了软件SPI的IO速度上限了，250kSPS*16bit = 4Mbit的速度了。</p>\n<p>如果要更快一点，可以使用硬件SPI+DMA的方式，但是比赛当前，就不折腾花活了，能用就好。</p>\n<p>另外一点是STM32的H7系列的软SPI的会有的一个毛病，在CubeMX中需要把这些个管脚(CLK,MISO,MOSI,CS)的最大频率设置成Low，否则如果设置为High之类的。</p>\n<p>较大的驱动电流会造成信号的过冲和振铃，造成读出的数据有时是对的，有时读出的会是全1或者全0。</p>\n<p>这一点我是在调试RDA5820的时候发现的，之前用STM32U5驱动RDA5820是正常的，同样的代码在H7下就会有时正确有时不能读出。后来在思考信号完整性链路的时候有了新的想法。</p>\n<p>我个人的看法是，可能由于是H7的驱动电流能力比较强，IO翻转的上升沿相比F1，F7这些要陡峭很多，而数字信号链路是通过一段比较长的XH2.54线接到了外部的模块上，<br />\n根据传输线模型的推论，当传输线长度和1/6上升沿波长可以相比拟时，就有可能造成信号完整性问题。<br />\n所以这时IO驱出来的数字波形会有过冲和振铃等信号完整性问题也是可以理解的。</p>\n<p>验证ADC采集时候，一般会串口打印波形，再使用SerialPlot查看，是不是和理论符合，比如下图就是ASK波形的采样结果。</p>\n<p><img alt=\"ASK的采集到的波形\" class=\"lazyload\" /></p>\n<h3 id=\"fft的准备工作\">FFT的准备工作</h3>\n<ul>\n<li>使用Cmsis DSP库，在Keil的包管理里面勾选即可，最新版本有窗函数的需要从官网上下载（怎么感觉有点似曾相识，我去年暑假好像也写过）</li>\n</ul>\n<p><img alt=\"Keil添加Pack\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>在Keil的设置里面，加入ARM_MATH_CM7, ARM_MATH_LOOPUNROLL这两条宏定义，前面是Cortex版本，需要是MCU的内核版本，可以是CM1，CM4，CM7,后面的是控制数学舍入的，一般来说不用动。<br />\n<img alt=\"keil的编译设置\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>然后在include的地方加入 #include \"arm_math.h\"   和  #include \"arm_const_structs.h\"，然后开辟一个fft的全局数组，就可以愉快的调用啦。</p>\n</li>\n<li>\n<p><strong>FFT的调用</strong>**</p>\n</li>\n</ul>\n<pre><code class=\"language-C\">/* ADC采样并做FFT 结果放在全局数组fft_outputbuf中 */\n/* 做FFT 结果放在全局数组fft_outputbuf中 一次4096个点 */\nvoid FFT(unsigned short *ADC_Buffer, unsigned int SampleRate, unsigned int len, int debug, int serialplot)\n{\n    for(int i=0;i&lt;Sampling_CNT;i++)\n    Global_ADC_Value[i] = ADC_Buffer[i]*3.3/4096;   // 将采样结果转化到0-3.3V\n    \n    for(int i=0;i &lt; FFT_LENGTH;i++)   \n    {\n    fft_inputbuf[i*2] = Global_ADC_Value[i];  // 按手册要求的实部虚部交替的方法填充数组\n    fft_inputbuf[2*i +1] = 0;\n    }\n\n    arm_cfft_f32(&amp;arm_cfft_sR_f32_len4096,fft_inputbuf,0,1); // 执行FFT变换，arm_cfft_sR_f32_len4096为宏，定义旋转因子\n    arm_cmplx_mag_f32(fft_inputbuf,fft_outputbuf,FFT_LENGTH);    // 把运算结果复数求模得幅值\n\n    /* Debug打印区 */\n    \n    if(debug == 1)\n     for(int i=0;i &lt; FFT_LENGTH/2;i++)       // 是否打印FFT每个频点的幅值信息\n       printf(\"%d  %.3lf KHz Mag %.3f\\n\", i,SampleRate*1.0/len*i, fft_outputbuf[i] );\n    \n    if(serialplot == 1)\n     for(int i=0;i &lt; FFT_LENGTH;i++)       //  是否打印fft结果到到SerialPlot\n        printf(\"%.3f\\n\", fft_outputbuf[i]);\n\n}\n</code></pre>\n<p>做完FFT后，我们一般会通过SerialPlot软件来查看FFT的结果和和理论估计是否符合。<br />\n下图是1KHz载波，3KHz频偏的FM频谱的实测图<br />\n<img alt=\"FM的频谱\" class=\"lazyload\" /></p>\n<h3 id=\"代码组织的思路\">代码组织的思路</h3>\n<p>这题是一个经典的测量-分析-显示的题目，所以采用的思路就是先采集，判断调制类型后，进一步去对应的部分进行进一步的分析和显示。<br />\n由于FFT分析后给的参数值不止一个，所以使用了函数传地址的办法。<br />\n<img alt=\"函数传参参数\" class=\"lazyload\" /><br />\n而且由于Keil没有比较方便的代码补全和快捷提示功能，如果所有的算法都在main中实现，会导致代码实现那一段到下面的main函数的里调用段，有一段非常长的距离，所以我个人的建议是把一些更基础的算法代码另外封装到一个Algorithm文件里。<br />\n<img alt=\"Algorithm.c截图\" class=\"lazyload\" /></p>\n<h3 id=\"下节预告鸽了实际上因为神秘赛制的原因我们没有去到比赛现场但是还是国赛二等奖就不献丑了\">下节预告（鸽了，实际上因为神秘赛制的原因，我们没有去到比赛现场，但是还是国赛二等奖，就不献丑了）</h3>\n<ul>\n<li>模拟调制和数字调制两个大类的区分(中心载频与相邻频点之间的距离)</li>\n<li>三种模拟调制的区分(CW, AM, FM)</li>\n<li>三种数字调制的区分(ASK, FSK, PSK)</li>\n<li>各种调制载波频率的计算(频谱最近相邻谱线的距离)</li>\n<li>AM调制的Ma的计算(寻峰算法)</li>\n<li>FM调制的Mf的计算(基于模式匹配的思想)</li>\n<li>FSK调制的h参数的计算(基于和FM的相似带来的模式复用)</li>\n<li>ASK的抽判(基于直流量的定时抽判)</li>\n<li>FSK的抽判(两路FIR后的抽判)</li>\n<li>PSK的抽判(满足特定频率的相位突变点抽判法)</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 14:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/badboy02\">Badboy02</a>&nbsp;\n阅读(<span id=\"post_view_count\">104</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从零开始学Flink：实时数仓与维表时态Join实战",
      "link": "https://www.cnblogs.com/daimajiangxin/p/19624638",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/daimajiangxin/p/19624638\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 12:58\">\n    <span>从零开始学Flink：实时数仓与维表时态Join实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"从零开始学Flink：实时数仓与维表时态Join实战\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3365149/202602/3365149-20260219125729266-340455730.png\" />\n        以电商订单实时数仓为例，演示如何在 Flink SQL 中通过维表时态 Join 将事实流与维度数据关联，构建带用户属性的明细宽表，并结合 Kafka 与 MySQL 环境完成一套可落地的实时数仓入门实践。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在前一篇 <a href=\"https://mp.weixin.qq.com/s/kLxoo6mHi49HvrrmaOdTsA\" rel=\"noopener nofollow\" target=\"_blank\">《Flink 双流 JOIN 实战详解》</a> 中，我们用「订单流 + 支付流」搞懂了事实双流之间的时间关联。</p>\n<p>但在真实的实时数仓项目里，光有事实流还不够，业务同学更关心的是：</p>\n<ul>\n<li>下单用户是新客还是老客</li>\n<li>用户当前的等级、城市、渠道</li>\n<li>商品所属品类、类目层级</li>\n</ul>\n<p>这些信息通常存放在 <strong>维度表</strong>（维表）中，例如 MySQL 的 <code>dim_user</code>、<code>dim_product</code> 等。我们希望在实时计算时，能把「事实流」和「维表」在时间维度上正确地关联起来，构建一张带有完整业务属性的<strong>明细宽表</strong>。</p>\n<p>这就是 <strong>维表时态 Join（Temporal Table Join）</strong> 要解决的问题。</p>\n<p>本文我们就以「订单事实流 + 用户维表」为例，完成一个从 Kafka 到 MySQL 的简易实时数仓 Demo，并重点理解 Flink SQL 中维表时态 Join 的语法和注意事项。</p>\n<h2 id=\"一业务场景与数仓目标\">一、业务场景与数仓目标</h2>\n<p>设想一个简化的电商业务场景：</p>\n<ul>\n<li>Kafka 中有实时写入的 <code>orders</code> 订单事实流</li>\n<li>MySQL 中维护一张 <code>dim_user</code> 用户维表，包含用户等级、所属城市、注册渠道等信息</li>\n</ul>\n<p>我们想要在 Flink 中构建一张「<strong>订单明细宽表</strong>」，字段大致包括：</p>\n<ul>\n<li>订单信息：订单号、下单用户、下单金额、下单时间</li>\n<li>用户属性：用户昵称、等级、城市、注册渠道</li>\n</ul>\n<p>并且要求：</p>\n<ul>\n<li>当我们回看 10 分钟前的某条订单时，看到的是 <strong>当时</strong> 用户的等级和城市，而不是被后续变更“冲掉”的最新值</li>\n</ul>\n<p>这正是 <strong>时态 Join</strong> 和「实时数仓」的关键：<strong>按事件发生时刻回放维度视图</strong>。</p>\n<h2 id=\"二环境前提与依赖准备\">二、环境前提与依赖准备</h2>\n<h3 id=\"1-基础组件\">1. 基础组件</h3>\n<p>本篇默认你已经完成前几篇中的环境准备：</p>\n<ul>\n<li>Flink 1.20.1（WSL2 Ubuntu 下部署）</li>\n<li>Kafka 集群已启动，且能正常写入 / 读取 Topic</li>\n<li>Flink SQL Client 可以正常连接集群</li>\n</ul>\n<p>在此基础上，我们还需要：</p>\n<ul>\n<li>一套可访问的 MySQL（本地或远程均可）</li>\n<li>Flink 的 JDBC Connector JAR 包</li>\n</ul>\n<h3 id=\"2-安装-flink-jdbc-connector\">2. 安装 Flink JDBC Connector</h3>\n<p>和 Kafka 一样，JDBC 连接器也需要以 JAR 包形式放到 Flink 的 <code>lib</code> 目录中。</p>\n<p>以 Flink 1.20.x 对应的 <code>flink-connector-jdbc</code> 为例：</p>\n<ol>\n<li>\n<p>确认 Flink 安装目录（假设为 <code>/opt/flink</code>）：</p>\n<pre><code class=\"language-bash\">export FLINK_HOME=/opt/flink\n</code></pre>\n</li>\n<li>\n<p>下载 JDBC Connector JAR 到 Flink 的 <code>lib</code> 目录：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME/lib\nwget https://repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc/3.3.0-1.20/flink-connector-jdbc-3.3.0-1.20.jar\n</code></pre>\n</li>\n<li>\n<p>如果你使用的是独立集群或远程集群，需要重启 Flink 集群，让新 JAR 在 JobManager/TaskManager 上生效：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME\nbin/stop-cluster.sh\nbin/start-cluster.sh\n</code></pre>\n</li>\n<li>\n<p>重启 Flink SQL Client，使用新 Connector：</p>\n<pre><code class=\"language-bash\">cd $FLINK_HOME\nbin/sql-client.sh\n</code></pre>\n</li>\n</ol>\n<p>如果你在 Windows + WSL2 上部署，只需在 WSL2 内执行上述命令即可；或者手动下载 JAR 后拷贝到 <code>lib</code> 目录，步骤完全一致。</p>\n<h2 id=\"三准备-mysql-用户维度表-dim_user\">三、准备 MySQL 用户维度表 dim_user</h2>\n<p>首先在 MySQL 中准备一张简单的用户维度表，用来存用户的基础属性。</p>\n<p>在 MySQL 中执行：</p>\n<pre><code class=\"language-sql\">CREATE DATABASE IF NOT EXISTS realtime_dwh;\nUSE realtime_dwh;\n\nCREATE TABLE dim_user (\n  user_id      VARCHAR(32)  PRIMARY KEY,\n  user_name    VARCHAR(64),\n  user_level   VARCHAR(16),\n  city         VARCHAR(64),\n  register_time DATETIME\n);\n\nINSERT INTO dim_user (user_id, user_name, user_level, city, register_time) VALUES\n('u_1', '张三', 'VIP1', '北京', '2025-12-01 10:00:00'),\n('u_2', '李四', 'VIP2', '上海', '2025-12-05 11:00:00'),\n('u_3', '王五', 'VIP1', '广州', '2025-12-10 12:00:00');\n</code></pre>\n<p>为了演示「时态」效果，你可以在后续实验中手动更新某个用户的等级或城市，例如：</p>\n<pre><code class=\"language-sql\">UPDATE dim_user\nSET user_level = 'VIP3'\nWHERE user_id = 'u_2';\n</code></pre>\n<p>这样我们在 Flink 里做时态 Join 时，就能观察“变更前后”的区别。</p>\n<h2 id=\"四在-flink-中注册事实流与维表\">四、在 Flink 中注册事实流与维表</h2>\n<p>接下来回到 Flink SQL Client，把 Kafka 中的订单事实流和 MySQL 中的维表都注册成 Flink 表。</p>\n<h3 id=\"1-kafka-订单事实表-orders\">1. Kafka 订单事实表 orders</h3>\n<p>和上一篇双流 JOIN 类似，我们假设 Kafka 中有一个 <code>orders</code> Topic，写入订单事实数据。</p>\n<p>在 Flink SQL Client 中执行：</p>\n<pre><code class=\"language-sql\">CREATE TABLE orders (\n  order_id     STRING,\n  user_id      STRING,\n  order_amount DECIMAL(10, 2),\n  order_time   TIMESTAMP_LTZ(3),\n  WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND,\n  proc_time AS PROCTIME()\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'orders',\n  'properties.bootstrap.servers' = '127.0.0.1:9092',\n  'properties.group.id' = 'flink-orders-dim',\n  'scan.startup.mode' = 'earliest-offset',\n  'format' = 'json',\n  'json.timestamp-format.standard' = 'ISO-8601'\n);\n</code></pre>\n<p>你可以沿用上一篇中 Kafka 造数的方式，用 <code>kafka-console-producer.sh</code> 发送 JSON 订单数据，只需要保证字段名一致。</p>\n<h3 id=\"2-mysql-用户维表-dim_userjdbc-lookup-表\">2. MySQL 用户维表 dim_user（JDBC Lookup 表）</h3>\n<p>然后把刚才在 MySQL 中建好的 <code>dim_user</code> 注册为 Flink 的 JDBC 表：</p>\n<pre><code class=\"language-sql\">CREATE TABLE dim_user (\n  user_id       STRING,\n  user_name     STRING,\n  user_level    STRING,\n  city          STRING,\n  register_time TIMESTAMP(3),\n  PRIMARY KEY (user_id) NOT ENFORCED\n) WITH (\n  'connector' = 'jdbc',\n  'url' = 'jdbc:mysql://127.0.0.1:3306/realtime_dwh',\n  'table-name' = 'dim_user',\n  'driver' = 'com.mysql.cj.jdbc.Driver',\n  'username' = 'root',\n  'password' = '1qaz@WSX'\n);\n</code></pre>\n<p>注意几点：</p>\n<ul>\n<li><code>PRIMARY KEY (user_id) NOT ENFORCED</code> 告诉 Flink 这是一张以 <code>user_id</code> 为主键的表，是做时态 Join 的前提</li>\n<li>这里使用的是典型的 JDBC Lookup 模式，Flink 会在 Join 时按需去 MySQL 查维度信息</li>\n</ul>\n<p>在生产环境中，你可以把 MySQL 作为维度存储，或者通过 CDC 把维表变更同步到 Kafka，构造成 changelog 流，这些都可以和 Temporal Join 结合使用。</p>\n<h2 id=\"五维表时态-join把订单打上用户维度\">五、维表时态 Join：把订单打上用户维度</h2>\n<p>有了订单事实表 <code>orders</code> 和维度表 <code>dim_user</code>，就可以通过时态 Join 来构建订单明细宽表。</p>\n<h3 id=\"1-基础时态-join-语法\">1. 基础时态 Join 语法</h3>\n<p>Flink SQL 中的 Temporal Table Join 对于 JDBC 这类 <strong>外部维表</strong>，通常采用「处理时间（Processing Time）」语义来做 Lookup Join，典型写法如下：</p>\n<pre><code class=\"language-sql\">SELECT\n  o.order_id,\n  o.user_id,\n  d.user_name,\n  d.user_level,\n  d.city,\n  o.order_amount,\n  o.order_time\nFROM orders AS o\nLEFT JOIN dim_user FOR SYSTEM_TIME AS OF o.proc_time AS d\nON o.user_id = d.user_id;\n</code></pre>\n<p><img alt=\"FlinkJoin\" class=\"lazyload\" /><br />\n这里有几个关键点：</p>\n<ul>\n<li><code>proc_time AS PROCTIME()</code> 是在 <code>orders</code> 上定义的处理时间字段</li>\n<li><code>FOR SYSTEM_TIME AS OF o.proc_time</code> 表示“以 Flink 处理这条订单记录的当前时间，去查维表的一个快照”，这是 JDBC Lookup 支持的典型用法</li>\n<li>Join 条件依然是 <code>user_id</code> 等值关联</li>\n<li>使用 <code>LEFT JOIN</code> 可以保留找不到维度的订单，并用空值来表示“维度缺失”</li>\n</ul>\n<p>在 SQL Client 中执行这段查询，会看到实时流式刷新的结果，每一行订单都带上了对应的用户属性。</p>\n<h3 id=\"2-验证时态效果修改维表再观察-join\">2. 验证时态效果：修改维表再观察 Join</h3>\n<p>为了验证这是“时态 Join”而不是“始终查最新维度”，可以按下面步骤操作：</p>\n<ol>\n<li>\n<p>先往 Kafka 的 <code>orders</code> Topic 写入几条订单数据，例如用户 <code>u_2</code> 下单的记录</p>\n</li>\n<li>\n<p>观察 Flink SQL 中 Join 后的结果，此时 <code>u_2</code> 的等级是 <code>VIP2</code></p>\n</li>\n<li>\n<p>回到 MySQL，执行：</p>\n<pre><code class=\"language-sql\">UPDATE dim_user\nSET user_level = 'VIP3'\nWHERE user_id = 'u_2';\n</code></pre>\n</li>\n<li>\n<p>再写入一批新的订单，仍然是用户 <code>u_2</code></p>\n</li>\n</ol>\n<pre><code class=\"language-bash\">bin/kafka-console-producer.sh --bootstrap-server 127.0.0.1:9092 --topic orders\n</code></pre>\n<p>在命令行中输入一条 JSON 数据（按回车发送一条）：</p>\n<pre><code class=\"language-json\">{\"order_id\":\"o_3\",\"user_id\":\"u_2\",\"order_amount\":200.00,\"order_time\":\"2026-02-19T14:42:00Z\"}\n</code></pre>\n<p><img alt=\"FlinkJoin\" class=\"lazyload\" /><br />\n这时你会看到：</p>\n<ul>\n<li>变更前的订单，维度字段仍然显示 <code>VIP2</code></li>\n<li>变更后的订单，维度字段变成了 <code>VIP3</code></li>\n</ul>\n<p>这就说明 Flink 的时态 Join 确实是“按订单发生时刻去回放维度视图”的，而不是简单查当前最新值。</p>\n<h2 id=\"六把结果写回-kafka-或-mysql形成实时数仓明细层\">六、把结果写回 Kafka 或 MySQL，形成实时数仓明细层</h2>\n<p>在真实项目中，我们不会只在 SQL Client 里 <code>SELECT</code> 一下就结束，而是要把 Join 后的订单明细宽表，写回到下游存储，形成实时数仓的一个层级。</p>\n<p>例如，可以把结果写回 Kafka，作为 DWD 层的订单宽表：</p>\n<pre><code class=\"language-sql\">CREATE TABLE dwd_order_user_wide (\n  order_id     STRING,\n  user_id      STRING,\n  user_name    STRING,\n  user_level   STRING,\n  city         STRING,\n  order_amount DECIMAL(10, 2),\n  order_time   TIMESTAMP_LTZ(3),\n  WATERMARK FOR order_time AS order_time - INTERVAL '5' SECOND\n) WITH (\n  'connector' = 'kafka',\n  'topic' = 'dwd_order_user_wide',\n  'properties.bootstrap.servers' = '127.0.0.1:9092',\n  'properties.group.id' = 'flink-dwd-order-wide',\n  'scan.startup.mode' = 'earliest-offset',\n  'format' = 'json',\n  'json.timestamp-format.standard' = 'ISO-8601'\n);\n\nINSERT INTO dwd_order_user_wide\nSELECT\n  o.order_id,\n  o.user_id,\n  d.user_name,\n  d.user_level,\n  d.city,\n  o.order_amount,\n  o.order_time\nFROM orders AS o\nLEFT JOIN dim_user FOR SYSTEM_TIME AS OF o.proc_time AS d\nON o.user_id = d.user_id;\n</code></pre>\n<p>这样，下游的实时应用或 BI 查询就可以直接订阅 <code>dwd_order_user_wide</code> 这个 Topic，拿到已经打好用户标签的订单明细数据。</p>\n<p>你也可以把结果同步到 MySQL、ClickHouse 等分析型数据库中，构建实时明细表，为报表和可视化提供数据。</p>\n<h2 id=\"七小结与下一步建议\">七、小结与下一步建议</h2>\n<p>通过这篇文章，我们完成了这样一件事：</p>\n<ul>\n<li>在 Kafka 中维护订单事实流 <code>orders</code></li>\n<li>在 MySQL 中维护用户维度表 <code>dim_user</code></li>\n<li>使用 Flink SQL 的 JDBC Connector 把 MySQL 注册为维表</li>\n<li>利用 <code>FOR SYSTEM_TIME AS OF</code> 语法做维表时态 Join</li>\n<li>将 Join 结果写回 Kafka，形成实时数仓中的一张订单明细宽表</li>\n</ul>\n<p>这背后有几个非常重要的实时数仓设计理念：</p>\n<ul>\n<li>事实流是不断追加的事件序列，维表是相对缓慢变更的业务视图</li>\n<li>时态 Join 让你能够“按事件发生的时间点”，回看当时的维度快照</li>\n<li>实时数仓的 DWD 层，往往就是「事实表 + 多个维表时态 Join」后形成的明细宽表</li>\n</ul>\n<p>在后续的文章中，我们可以继续沿着这个方向深入：</p>\n<ul>\n<li>在一个任务里同时关联多张维表，构建更宽的明细表</li>\n<li>引入 CDC，把维表变更实时同步到 Kafka，再在 Flink 中构建 changelog 维表</li>\n<li>把实时数仓的明细层、汇总层（DWS）、指标主题层（ADS）串起来，做一个端到端的实时数仓小项目</li>\n</ul>\n<p>如果你已经跑通了本文的 Demo，不妨试着自己设计一张商品维表 <code>dim_product</code>，再给订单打上商品品类维度，体验一下“事实 + 多维表时态 Join”在 Flink SQL 里的完整味道。</p>\n<hr />\n<p><a href=\"http://blog.daimajiangxin.com.cn\" rel=\"noopener nofollow\" target=\"_blank\">原文来自:http://blog.daimajiangxin.com.cn</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 12:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/daimajiangxin\">代码匠心</a>&nbsp;\n阅读(<span id=\"post_view_count\">81</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "赋予 AI Agent “无限续航”：语义保护型上下文压缩技术解析",
      "link": "https://www.cnblogs.com/noear/p/19624614",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19624614\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 12:21\">\n    <span>赋予 AI Agent “无限续航”：语义保护型上下文压缩技术解析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Solon AI框架的SummarizationInterceptor创新性地解决了AI长对话中的\"上下文窗口爆炸\"问题。这套智能记忆管理系统通过四步策略：锁定核心任务指令、确保行动-结果完整性、保持语义连贯性、添加系统提示，实现了优雅的记忆压缩。其采用插件式设计，支持层级压缩、关键信息提取和向量库归档等策略组合，让AI既能记住核心目标，又能处理超长任务。这种\"有逻辑地遗忘\"机制，有效避免了传统粗暴裁剪导致的逻辑混乱，为AI处理复杂任务提供了\"无限续航\"\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>想象一下，你正在指挥一个超级聪明的AI助手（我们称之为Agent）帮你完成一项复杂任务，比如策划一次跨国旅行。一开始，它记得你的所有要求：想去哪些国家、预算多少、喜欢什么类型的酒店。但随着任务的进行，它需要查询航班、比较酒店、查看天气……每一次查询和思考都会增加它的“记忆负担”。</p>\n<p>如果它“记性”不好，聊到一半就会忘了最开始的要求，或者陷入混乱的逻辑中，这就是开发者常说的“上下文窗口爆炸”问题。</p>\n<p>Solon AI 框架里有一个秘密武器——<code>SummarizationInterceptor</code>（智能记忆压缩器），它能让AI助手像人一样，<strong>既不会忘记初心，又能轻装上阵，实现真正的“无限续航”</strong>。它不是简单粗暴地“断片”，而是一套优雅的“记忆管理大师”。</p>\n<h3 id=\"1为什么不能简单粗暴地断片\">1、为什么不能简单粗暴地“断片”？</h3>\n<p>处理长对话，最直接的想法是：对话太长？那就删掉前面一半吧！但这种“暴力裁剪”对AI来说，会带来两个致命伤：</p>\n<ul>\n<li><strong>忘本（失去初心）：</strong> AI Agent 最开头的系统设定和你交给它的第一个任务，如果被删掉，它就会像无头苍蝇一样，完全不知道自己要干嘛了。</li>\n<li><strong>断片（逻辑断层）：</strong> AI Agent 的工作模式通常是“思考 -&gt; 行动 -&gt; 观察结果”（ReAct）。如果你恰好把它的某个“行动”和对应的“观察结果”给拆散了，它看到结果却不知道为什么会有这个结果，逻辑瞬间混乱，甚至陷入死循环，无法自拔。</li>\n</ul>\n<p>所以，忘记也是一门艺术，需要有策略地忘记。</p>\n<h3 id=\"2智能记忆压缩器是如何工作的\">2、智能记忆压缩器是如何工作的？</h3>\n<p><code>SummarizationInterceptor</code> 就像一个聪明的图书管理员，它不会随意丢弃书籍，而是按照一套精密的流程来整理书架。它的工作分为四步：</p>\n<h4 id=\"第一步锁死初心锚点锁定\">第一步：锁死“初心”（锚点锁定）</h4>\n<p>无论后面的对话有多长，管理员都会第一时间找到两样东西并永久保留：</p>\n<ul>\n<li><strong>任务指令：</strong> 你第一次给AI布置的任务（UserMessage），这是它的“初心”。</li>\n<li><strong>基本守则：</strong> AI的系统设定（SystemMessage），这是它的“行为准则”。</li>\n</ul>\n<p>这两样东西被牢牢锁定，确保AI永不迷失方向。</p>\n<h4 id=\"第二步禁止断片原子对齐\">第二步：禁止“断片”（原子对齐）</h4>\n<p>这是整个机制最核心的“黑科技”。当管理员决定要清理一部分旧内容时，他不会直接动手。他会仔细检查，确保永远不会把 <strong>“行动”</strong> 和 <strong>“结果”</strong> 这对“连体婴儿”给拆散。</p>\n<ul>\n<li><strong>智能检查：</strong> 如果发现准备清理的起点正好落在一个“观察结果”（<code>ToolMessage</code>）或者一个“行动指令”（<code>AssistantMessage</code>）上，管理员会立刻把清理起点向后挪，直到确保每一对“行动-结果”都完整地保留下来。</li>\n</ul>\n<h4 id=\"第三步让记忆更连贯语义补齐\">第三步：让记忆更连贯（语义补齐）</h4>\n<p>为了让你和AI的对话读起来更通顺，管理员还会再多做一步“人情味”的检查。如果清理后的第一条记录是一个“行动结果”，管理员会看看它前面是不是紧跟着一条AI的“思考过程”（Thought）。如果是，他会把这条“思考”也一并留下。这样一来，AI看到的历史永远是从一个思考片段开始的，理解起来更自然。</p>\n<h4 id=\"第四步贴个便利贴提醒断裂感知\">第四步：贴个“便利贴”提醒（断裂感知）</h4>\n<p>在永久保存的“初心”和压缩后的“最近记忆”之间，管理员会贴上一张醒目的 <strong>“小贴士”</strong>：</p>\n<pre><code>--- [系统提示：中间部分历史对话已优化压缩，请根据当前计划和剩余历史继续任务...] ---\n</code></pre>\n<p>这张“小贴士”非常重要，它用AI能理解的语言告诉它：“别担心，中间有些细节我帮你精简了，你专注眼前的任务和核心目标就好。”这能有效防止AI因为记忆断层而产生困惑和幻觉。</p>\n<h3 id=\"3如何实现无限续航\">3、如何实现“无限续航”？</h3>\n<p>通过这套“记忆管理术”，SummarizationInterceptor 把AI的内存变成了一个动态的“新陈代谢系统”：</p>\n<ul>\n<li><strong>内存恒定：</strong> 无论AI运行了10步还是1000步，它一次“思考”所需要处理的信息量（Token数）始终维持在一个安全的范围内。</li>\n<li><strong>逻辑清晰：</strong> 因为“原子对齐”机制，AI看到的每一段记忆都是完整的“思考-行动-反馈”闭环，逻辑链条非常稳固。</li>\n<li><strong>目标永存：</strong> “系统设定”和“用户任务”这两大核心目标永远在线，AI永远不会忘记“我是谁”和“我要去哪”。</li>\n</ul>\n<h3 id=\"4更强大的组合插件式的记忆策略\">4、更强大的组合：插件式的记忆策略</h3>\n<p>这个“记忆管理器”最妙的地方在于，它采用了 <strong>策略模式</strong>，就像手机可以安装不同的APP来扩展功能一样，你可以给它接入不同的“记忆处理插件”。框架已经为我们准备了几款强大的插件：</p>\n<ul>\n<li><strong>层级压缩器：</strong> 它会像滚雪球一样，把旧的记忆摘要和新的对话历史不断融合、压缩，生成一个始终更新的“全局进度摘要”，让记忆像洋葱一样层层包裹，永不丢失核心。</li>\n<li><strong>关键信息提取器：</strong> 它像一个信息审计员，只从对话中提取最核心的“干货”，比如用户要求、获取到的数据、已经失败的尝试等，过滤掉那些啰嗦的思考过程。</li>\n<li><strong>向量库记忆师：</strong> 它会将被清理的详细对话“归档”到一个巨大的知识库里（向量数据库）。当AI需要回忆某个细节时，可以通过一个专门的“召回历史”工具，像用搜索引擎一样把它找回来。</li>\n</ul>\n<p>你可以把这些插件组合起来使用，比如先归档，再提纯，最后压缩，打造一个最适合你AI助手的记忆管理方案。</p>\n<p>应用示例：</p>\n<pre><code class=\"language-java\">import org.noear.solon.ai.agent.react.ReActAgent;\nimport org.noear.solon.ai.agent.react.intercept.SummarizationInterceptor;\nimport org.noear.solon.ai.agent.react.intercept.summarize.*;\nimport org.noear.solon.ai.agent.session.InMemoryAgentSession;\nimport org.noear.solon.ai.chat.ChatModel;\n\nCompositeSummarizationStrategy compositeStrategy = new CompositeSummarizationStrategy();\ncompositeStrategy.addStrategy(new KeyInfoExtractionStrategy(chatModel));\ncompositeStrategy.addStrategy(new HierarchicalSummarizationStrategy(chatModel));\nSummarizationInterceptor summarizationInterceptor = new SummarizationInterceptor(12, compositeStrategy);\n\nReActAgent agent = ReActAgent.of(chatModel)\n        .defaultInterceptorAdd(summarizationInterceptor)\n        .build();\n</code></pre>\n<h3 id=\"5总结\">5、总结</h3>\n<p><code>SummarizationInterceptor</code> 的设计哲学是：<strong>有尊严地裁剪，有逻辑地遗忘</strong>。</p>\n<p>它不仅仅是一个节省计算资源的工具，更是AI能够保持逻辑连贯、处理超长复杂任务的“护航者”。有了它，开发者可以放心地让AI助手去处理那些需要几个小时甚至几天才能完成的、真正复杂和智能化的工作，而不用担心它会中途“失忆”或“精神错乱”。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 12:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">77</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]持久化状态的提取",
      "link": "https://www.cnblogs.com/jaydenai/p/19623976/read-state",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19623976/read-state\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 07:58\">\n    <span>[拆解LangChain执行引擎]持久化状态的提取</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        前面以`写入`的角度介绍了BaseCheckpointSaver的`put/aput`和`put_writes/aput_writes`方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面以<code>写入</code>的角度介绍了BaseCheckpointSaver的<code>put/aput</code>和<code>put_writes/aput_writes</code>方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。</p>\n<h2 id=\"1-读取checkpoint和pinding-write\">1. 读取Checkpoint和Pinding Write</h2>\n<p>如下这个<code>CheckpointTuple</code>用来表示Checkpoint和Pending Write的结合体。除了这两个核心成员，它还包括当前的执行配置（config和parent_config）和元数据。具体的Pending Write由Task ID、Channel名称和写入数组组成的三元组PendingWrite表示。</p>\n<pre><code class=\"language-python\">class CheckpointTuple(NamedTuple):\n    config: RunnableConfig\n    checkpoint: Checkpoint\n    metadata: CheckpointMetadata\n    parent_config: RunnableConfig | None = None\n    pending_writes: list[PendingWrite] | None = None\nPendingWrite = tuple[str, str, Any]\n</code></pre>\n<p>BaseCheckpointSaver提供了用于读取CheckpointTuple的<code>get_tuple/aget_tuple</code>方法。作为参数的RunnableConfig对象需要提供Thread ID（必需）和Checkpoint 命名空间（可选）。如果没有提供Checkpoint ID，方法会返回最终的状态，如果尚未完成，得到的CheckpointTuple元组可能包含Pending Write。如果提供了Checkpoint ID, 只有在此ID对应最新的Checkpoint且后一Superstep尚未完成，返回的CheckpointTuple元组才有可能包含Pending Write。对于实现在BaseCheckpointSaver中的另一组方法<code>get/aget</code>，会在内部调用<code>get_tuple/aget_tuple</code>方法，并返回CheckpointTuple元组封装的Checkpoint对象。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):    \n    def get(self, config: RunnableConfig) -&gt; Checkpoint | None\n    async def aget(self, config: RunnableConfig) -&gt; Checkpoint | None\n\n    def get_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n    async def aget_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n\n    def list(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[CheckpointTuple]:\n    async def alist(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[CheckpointTuple]\n</code></pre>\n<p>对于InMemorySaver来说，它的get_tuple/aget_tuple方法会从RunnableConfig配置中提取Thread ID和Checkpoint命名空间，如果指定了Checkpoint ID，它们会利用这三个值从storage和blobs字典中提取相应数据组成返回的CheckpointTuple对象。如果没有指定Checkpoint ID，就选择最近的那一个Checkpoint的ID。</p>\n<p>BaseCheckpointSaver的alist方法会列出并检索与指定条件匹配的所有CheckpointTuple，这些元组构成了一段 “历史” 。该方法主要用于会话管理、审计历史轨迹以及状态回溯，它具有如下的参数：</p>\n<ul>\n<li>config：如果RunnableConfig如果提供了Thread ID，该方法将仅返回该特定线程下的Checkpoint。如果不提供，在某些实现中会列出所有线程的最新Checkpoint（取决于具体的实现逻辑）。</li>\n<li>filter：提供基于元数据的过滤功能，例如 {\"status\": \"completed”} ，这在需要筛选特定业务状态的Checkpoint时非常有用。</li>\n<li>before：以RunnableConfig对象的形式提供Checkpoint ID，返回在此 之前创建的记录。这对于实现 “时间旅行” 功能至关重要，允许你查看图执行历史中的旧版本。</li>\n<li>limit：用于限制返回数据的数量。</li>\n</ul>\n<p>我们通过如下的实例演示来进一步了解持久化。我们构建了一个由foo、bar1和bar2这三个Node组成的Pregel，启动的时候利用输入针对通道foo的写入驱动执行节点foo，后者完成后写入通道bar驱动节点bar1和bar2并行执行。三个Node的处理函数都是handle，它会将传入的Node名称写入一个BinaryOperatorAggregate类型Channel（nodes），由此确定成功执行的Node。如果调用handle函数将interrupt参数指定为True，它会通过抛出一个GraphInterrupt异常模拟一个中断。在我们的演示实例中，节点foo和bar2会执行成功，中断会发生在节点bar1上。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue, BinaryOperatorAggregate\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.errors import GraphInterrupt\nimport operator, json\n\ndef handle(node_name: str, interrupt: bool = False) -&gt; list[str]:\n    if interrupt:\n        raise GraphInterrupt(\"manual interrupt\")\n    return [node_name]\n\nfoo = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: handle(\"foo\"))\n    .write_to(nodes=lambda x: x, bar=lambda _: \"triggered by foo\")\n)\n\nbar1 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar1\", interrupt=True))\n    .write_to(\"nodes\")\n)\n\nbar2 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar2\", interrupt=False))\n    .write_to(\"nodes\")\n)\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar1\": bar1, \"bar2\": bar2},\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n        \"nodes\": BinaryOperatorAggregate(list, operator.add),\n    },\n    checkpointer=InMemorySaver(),\n    input_channels=[\"foo\"],\n    output_channels=[\"nodes\"],\n)\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke({\"foo\": \"triggered by user\"}, config=config)\nassert result[\"nodes\"] == [\"foo\", \"bar2\"]\n\n(config, checkpoint, metadata, parent_config, pending_writes) = (\n    app.checkpointer.get_tuple(config)\n)\nprint(f\"config:\\n{json.dumps(config, indent=4)}\")\nprint(f\"checkpoint:\\n{json.dumps(checkpoint, indent=4)}\")\nprint(f\"metadata:\\n{json.dumps(metadata, indent=4)}\")\nprint(f\"parent_config:\\n{json.dumps(parent_config, indent=4)}\")\nprint(f\"pending_writes:\\n{json.dumps(pending_writes, indent=4)}\")\n</code></pre>\n<p>我们为创建的Pregel对象提供了一个InMemorySaver作为它的Checkpointer，并在调用时利用提供的RunnableConfig设置了Thread ID。由于我们将通道nodes作为输出，所以调用结果会反映三个Node的执行状态（只有节点foo和bar2成功执行）。我们随后传入相同的配置调用Checkpointer的get_tuple方法，并将得到的CheckpointTuple元组进行拆包输出。</p>\n<pre><code class=\"language-json\">config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\"\n    }\n}\ncheckpoint:\n{\n    \"v\": 4,\n    \"ts\": \"2026-01-19T10:17:07.498064+00:00\",\n    \"id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\",\n    \"channel_versions\": {\n        \"foo\": \"00000000000000000000000000000001.0.06769883673554666\",\n        \"nodes\": \"00000000000000000000000000000002.0.3174924500871408\",\n        \"bar\": \"00000000000000000000000000000002.0.3174924500871408\"\n    },\n    \"versions_seen\": {\n        \"__input__\": {},\n        \"foo\": {\n            \"foo\": \"00000000000000000000000000000001.0.06769883673554666\"\n        }\n    },\n    \"updated_channels\": [\n        \"bar\",\n        \"nodes\"\n    ],\n    \"channel_values\": {\n        \"foo\": \"triggered by user\",\n        \"nodes\": [\n            \"foo\"\n        ],\n        \"bar\": \"triggered by foo\"\n    }\n}\nmetadata:\n{\n    \"source\": \"loop\",\n    \"step\": 0,\n    \"parents\": {}\n}\nparent_config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24ee-671f-bfff-2e9f3ca91778\"\n    }\n}\npending_writes:\n[\n    [\n        \"30b17cb1-76f1-3c5a-0d32-33f544fcabdf\",\n        \"nodes\",\n        [\n            \"bar2\"\n        ]\n    ],\n    [\n        \"e126d089-c354-0ac8-bb9e-b12bbe3f20b8\",\n        \"__interrupt__\",\n        \"manual interrupt\"\n    ]\n]\n</code></pre>\n<p>整个执行过程涉及三个Superstep，会创建两个Checkpoint。第一个Checkpoint的创建发生在调用invoke方法的时候，此时提供的输入被写入Channel，首批待执行的Node（foo）准备就绪，此时创建的Checkpoint 记录了 <code>接收到了初始任务，但尚未开始执行任何Node</code> 的状态。此时对应的Superstep序号为-1，输出结果的parent_config部分提供了此Checkpoint的ID。</p>\n<p>第二个Checkpoint是为序号为0的Superstep创建的，此时节点foo成功执行，执行结果最终被输入目标Channel，创建的Checkpoint反映的就是的状态，config部分提供了此Checkpoint的ID。上面的输出还提供了这个Checkpoint的时间戳、Channel的版本和值、涉及Node的可见Channel（f和版本，以及涉及更新的Channel列表。</p>\n<p>由于最后一个Superstep（序号为1）没有完全结束，它们会利用对应的Pending Write来描述。上面输出的第一个Pending Write表示成功执行的节点bar针对通道nodes的写入，第二个针对特殊系统Channel <code>__interrupt__</code>的写入很明显就是因为节点bar1的中断导致。</p>\n<h2 id=\"2-读取状态快照\">2. 读取状态快照</h2>\n<p>BaseCheckpointSaver提供了get_tuple/aget_tuple方法以Checkpoint_Tuple的形式返回最新或者基于过去时间点的状态。对于CheckpointTuple这个五元组，除了Checkpoint和PendingWrite列表，还包括Checkpoint的元数据和相关配置。这个元组主要由执行引擎内部使用的，针对最终开发者来说可读性差点，所以Pregel类定义了如下所示的<code>get_state/aget_state</code>方法，它们提供的StateSnapshot类型更具可读性。</p>\n<pre><code class=\"language-python\">class Pregel(\n    PregelProtocol[StateT, ContextT, InputT, OutputT],\n    Generic[StateT, ContextT, InputT, OutputT]): \n\n    def get_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n    async def aget_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n\n    def get_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[StateSnapshot]\n    async def aget_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[StateSnapshot]\n</code></pre>\n<p>当我们调用Pregel对象的<code>get_state/aget_state</code>方法的时候，它会将指定的RunnableConfig对象作为参数调用Checkpointer的<code>get_tuple/aget_tuple</code>方法，并利用返回的Checkpoint_Tuple元组生成StateSnapshot对象。StateSnapshot的<code>values</code>字段提供的值来源于Checkpoint对象的channel_values字段，它的<code>metadata</code>字段表示的CheckpointMetadata 直接来源于Checkpoint_Tuple的同名字段，而<code>config</code>和<code>parent_config</code>返回的RunnableConfig则是由Checkpoint_Tuple同名字段于元数据合并而成。表示快照创建时间的<code>created_at</code>对应于Checkpoint_Tuple表示时间戳的ts字段，而interrupts返回的Interrupt列表是根据中断类型的PendingWrite构建的。</p>\n<pre><code class=\"language-python\">class StateSnapshot(NamedTuple):\n    values: dict[str, Any] | Any\n    next: tuple[str, ...]\n    config: RunnableConfig\n    metadata: CheckpointMetadata | None\n    created_at: str | None\n    parent_config: RunnableConfig | None\n    tasks: tuple[PregelTask, ...]\n    interrupts: tuple[Interrupt, ...]\n\nclass PregelTask(NamedTuple):\n    id: str\n    name: str\n    path: tuple[str | int | tuple, ...]\n    error: Exception | None = None\n    interrupts: tuple[Interrupt, ...] = ()\n    state: None | RunnableConfig | StateSnapshot = None\n    result: Any | None = None\n</code></pre>\n<p>StateSnapshot的<code>tasks</code>字段返回一组PregelTask对象，它们表示根据Checkpoint创建的待执行任务，<code>next</code>字段以元组的形式返回这些任务的Node名称。对于最新的Checkpoint，若下一个Superstep尚未完成，PregelTask的信息还会利用对应的Pending Write进一步完善。我们可以利用PregelTask对象得到每个任务的ID、Node名称、执行路径、抛出的异常和中断（根据异常和中断类型的PendingWrite创建），而<code>state</code>和<code>result</code>分别承载这任务的状态和输出结果。如果整个执行流程结束，自然就没有所谓后续任务的说法，此时StateSnapshot的tasks字段为空。</p>\n<p>除了返回一个具体的状态快照，Pregel类还定义了<code>get_state_history/aget_state_history</code>，它们的参数列表与BaseCheckpointSaver的<code>list/alist</code>方法完全一致。当这两个方法被调用的时候，Pregel会调用Checkpointer的<code>list/alist</code>方法，并将得到Checkpoint_Tuple元组转换成StateSnapshot对象。<code>get_state_history/aget_state_history</code>方法返回的迭代器以时间逆序的方式返回对应的状态快照。</p>\n<p>如下这个程序演示了一个具体的Pregel对象的历史由哪些快照组成，每个快照又反映当时的状态。我们构建的Pregel对象由四个Node组成，调用时指定通道foo会驱动执行节点foo，它执行结束后写入通道bar驱动bar1、bar2和bar3并行执行。除了bar1能够顺利执行外，我们为bar2设置了一个中断，让bar3抛出异常。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.checkpoint.memory import  InMemorySaver\nfrom langgraph.types import interrupt\n    \ndef handle(node_name: str, halt : bool, raise_error: bool) -&gt; None:\n    if halt:\n        _ = interrupt(f\"Manually be interrupted at {node_name}\")\n    if raise_error:\n        raise Exception(f\"Manually raised error at {node_name}\")\n\nfoo = (NodeBuilder()\n       .subscribe_to(\"foo\", read=False)\n       .do(lambda _: handle(\"foo\", halt=False, raise_error=False))\n       .write_to(bar = lambda _:None))\nbar1 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar1\", halt=False, raise_error=False)))\nbar2 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar2\", halt=True, raise_error=False)))\nbar3 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar3\", halt=False, raise_error=True)))\napp = Pregel(\n    nodes={\n        \"foo\": foo,\n        \"bar1\": bar1,\n        \"bar2\": bar2,\n        \"bar3\": bar3\n    },\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer= InMemorySaver())\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\n\ntry:\n    app.invoke(input={\"foo\": \"begin\"},config=config)\nexcept Exception as e:\n    pass\n\nfor snapshot in app.get_state_history(config):\n    print(f\"\"\"\nvalues: {snapshot.values}\nnext: {snapshot.next}\ninterrupts: {snapshot.interrupts}   \ntasks:\"\"\")\n    for task in snapshot.tasks:\n        print(f\"\"\"  id: {task.id}\n    name: {task.name}\n    path: {task.path}\n    error: {task.error} \n    interrupts: {task.interrupts}\n    state: {task.state}\n    result: {task.result}\"\"\")\n</code></pre>\n<p>在完成了针对Pregel对象的调用后，我们采用相同的配置调用它的<code>get_state_history</code>方法得到完整的历史，并将承载历史片段的StateSnapshot信息打印出来。整个过程涉及三个Superstep，前两个成功完成的Superstep会提供两个Checkpoint，第三个尚未完成的Superstep只提供针对三个Node任务的Pending Write。</p>\n<pre><code class=\"language-json\">values: {'start': 'begin', 'bar': None}\nnext: ('bar1', 'bar2', 'bar3')\ninterrupts: (Interrupt(value='Manually be interrupted at bar2', \n    id='26f309d618c42ff31d2b3404369232e4'),)\ntasks:\n  id: dbb24ec5-f1ba-f845-7351-54e88f34db0f\n    name: bar1\n    path: ('__pregel_pull', 'bar1')\n    error: None\n    interrupts: ()\n    state: None\n    result: {}\n  id: 794fffda-2e6c-0685-0d44-3ed6c57ca366\n    name: bar2\n    path: ('__pregel_pull', 'bar2')\n    error: None\n    interrupts: (Interrupt(value='Manually be interrupted at bar2', \n        id='26f309d618c42ff31d2b3404369232e4'),)\n    state: None\n    result: None\n  id: 1055ec55-49dc-0629-86b5-661a2614f349\n    name: bar3\n    path: ('__pregel_pull', 'bar3')\n    error: Exception('Manually raised error at bar3')\n    interrupts: ()\n    state: None\n    result: None\n\nvalues: {'start': 'begin'}\nnext: ('foo',)\ninterrupts: ()\ntasks:\n  id: 88904475-3edc-733a-d84d-98aa6d3f5e80\n    name: foo\n    path: ('__pregel_pull', 'foo')\n    error: None\n    interrupts: ()\n    state: None\n    result: {'bar': None}\n</code></pre>\n<h2 id=\"3任务路径\">3.任务路径</h2>\n<p>还记得我们前面说个任务的两种创建方式，一种是站在Node的角度，通过查看订阅Channel的更新状态确定是否应该执行，我们称这种任务创建模式为<code>Pull模式</code>。与之相对的则是<code>Push模式</code>，Node利用写入<code>__pregel_tasks</code>这个特殊Channel的Send对象决定后续执行的Node，执行引擎会从此Channel读取Send对象的来创建对应的任务。任务路径的第一部分通常就反映了任务的驱动模式，对应的值为<code>__pregel_pull</code>和<code>__pregel_push</code>。</p>\n<p>由于前面演示的都是基于Channel订阅驱动的任务，所以路径采用(“__pregel_pull”,{node})的形式。如下的程序演示“Push任务”的路径，我们构建的Pregel由四个Node（foo、bar1、bar2和bar3）组成，节点foo的处理函数最终会生成三个针对其他Node的Send对象，并写入“__pregel_tasks”Channel以驱动它们并行执行。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.pregel._read import PregelNode\nfrom langgraph.pregel._write import ChannelWrite, ChannelWriteTupleEntry\nfrom langgraph.types import Send\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nentry = ChannelWriteTupleEntry(lambda args: [(\"__pregel_tasks\", args)])\nwriter = ChannelWrite(writes=[entry])\nfoo: PregelNode = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: [Send(node=node, arg=\"foo\") for node in [\"bar1\", \"bar2\", \"bar3\"]])\n).build()\nfoo.writers.append(writer)\n\nbars = {name: NodeBuilder() for name in [\"bar1\", \"bar2\", \"bar3\"]}\n\napp = Pregel(\n    nodes={\"foo\": foo, **bars},\n    channels={\n        \"foo\": LastValue(None),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer=InMemorySaver(),\n)\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke(input={\"foo\": None}, config=config, interrupt_before=\"bar2\")\nsnapshot = app.get_state(config)\nfor task in snapshot.tasks:\n    print(f\"{task.name}:{task.path}\")\n</code></pre>\n<p>为了能看到三个任务，我们在在最后一个Superstep中产生一个中断，为此我们在调用的时候通过指定<code>interrupt_before</code>参数在执行节点bar2前中断。我们随后调用Pregel的get_state方法得到描述最终状态的StateSnapshot，并输出所有任务的执行路径。从如下的输出可以看出，由于是三个基于Push模式的任务，所以组成路径的第一个部分内容为 <code>__pregel_push</code> 。每个任务由 <code>__pregel_tasks</code> Channel的Send对象构建而成，第二部分的数组代表对应的Send对象在Channel中的索引。由于整个程序只有唯一的Pregel对象，不设置子图调用，所以第三部分返回False。</p>\n<pre><code>bar1:('__pregel_push', 0, False)\nbar2:('__pregel_push', 1, False)\nbar3:('__pregel_push', 2, False)\n</code></pre>\n<h2 id=\"4状态嵌套\">4.状态嵌套</h2>\n<p>这里我们有必要提一下PregelTask类的<code>state</code>字段。从给出的定义可以看出，它可以返回一个RunnableConfig配置，也可以返回一个StateSnapshot对象。如果任务涉及子图的调用，并且在调用get_state/aget_state方法时将subgraphs参数设置为True，它的state字段就会返回一个描述子图当前状态的<code>StateSnapshot</code>对象。借助于反映执行链路和调用顺序的Checkpoint命名空间，就可以形成的嵌套层次结构（state =&gt;task=&gt;state）使我们可以可以看到一个任务完整的调用链条。</p>\n<p><img alt=\"Alternative Text\" class=\"lazyload\" /></p>\n<p>以如下这个验证程序为例。我们构建了两个具有单一Node的Pregel对象app和sub_graph，前者的节点main_node以子图调用的方式调用sub_graph，后者的Node命名为 “sub_node”。为了在StateSnapshot中将任务保留下来，我们在两个Node中引入了中断。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import interrupt\nfrom typing import Any\nfrom langgraph.types import StateSnapshot\n\nsub_node = (NodeBuilder()\n    .subscribe_to(\"start\")\n    .do(lambda _: interrupt(\"manual interrupt\"))\n)\nsub_graph = Pregel(\n    nodes={\"sub_node\": sub_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n)\n\ndef handle(args: dict[str, Any]) -&gt; None:\n    sub_graph.invoke(input={\"start\": \"begin\"})\n    interrupt(\"main graph interrupt\")\n\nmain_node = NodeBuilder().subscribe_to(\"start\").do(handle)\napp = Pregel(\n    nodes={\"main_node\": main_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n    checkpointer=InMemorySaver())\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\napp.invoke(input={\"start\": \"begin\"}, config=config)\nsnapshot = app.get_state(config, subgraphs=True)\n\nindent = -1\ndef print_snapshot(snapshot: StateSnapshot) -&gt; None:\n    global indent\n    indent += 1\n    config = snapshot.config[\"configurable\"]\n    print(f\"{'  ' * indent}checkpoint_ns: {config.get('checkpoint_ns', None)}\")\n    for task in snapshot.tasks:\n        print(f\"{'  ' * indent}task: {task.name}:{task.id}\")\n        if sub_snapshot := task.state:\n            print_snapshot(sub_snapshot)\n\nprint_snapshot(snapshot)\n</code></pre>\n<p>在完成调用后，我们调用作为主图的Pregel对象的<code>get_state</code>方法，并将参数subgraphs设置为True。我们调用print_snapshot函数输出StateSnapshot提供的Checkpoint命名空间和任务的名称与ID。如果描述任务的PregelTask对象的state字段也是一个StateSnapshot对象，那么继续递归调用此函数。从如下的输出可以看出，作为子图的Pregel将当前任务的名称和ID的组合作为Checkpoint命名空间，这样的结构确保了 “主图” 恢复的时候能够精准地加载 “子图” 的状态。</p>\n<pre><code>checkpoint_ns: \ntask: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    checkpoint_ns: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    task: sub_node:a483bfb8-bcc6-92b3-2f64-9f9e9f4fe158\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 07:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">54</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 学习笔记：Agent 的基础应用",
      "link": "https://www.cnblogs.com/owlman/p/19623216",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19623216\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 16:09\">\n    <span>AI 学习笔记：Agent 的基础应用</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记对应的是《[[关于 AI 的学习路线图]]》一文中所规划的第四个学习阶段。其中记录了我学习 AI Agent 的工作原理，并将其应用于实际工作场景的全过程，以及在该过程中所获得的心得体会。同样的，这些内容也将成为我 AI 系列笔记的一部分，被存储在本人 Github 上的<a href=\"https://github.com/owlman/CS_StudyNotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机学习笔记库</a>中，并予以长期维护。</p>\n</blockquote>\n<h2 id=\"ai-agent-简介\">AI Agent 简介</h2>\n<p>在理解了 LLM 在生产环境中所扮演的角色之后，初学者们接下来要思考的问题是：如何让它参与到自己的实际工作中？到目前为止（截至 2026 年 2 月），这个问题最具可行性的解决方案是：构建并使用 AI Agent。</p>\n<h3 id=\"为什么需要-ai-agent\">为什么需要 AI Agent</h3>\n<p>在早期，大多数用户是通过 Web 端或移动端的即时通信应用，主要以文本聊天的方式来使用 LLM 的（例如 ChatGPT、豆包等）。这类应用本质上是基于 HTTP API 构建的人机交互界面，其主要交互模式是“输入文本—生成文本”的往返过程。我们之前在《[[LLM 的部署与测试]]》一文中基于 PyTest 框架编写的测试用例，实际上模拟的就是这种交互模式。</p>\n<p>尽管，这类应用极大地降低了 LLM 的使用门槛，使其成为了一种能惠及普通用户的智能问答工具，但 AI 所能带来的生产力也在很大程度上被局限在了这种即时通信式的交互模式中。因为在这种交互模式下，LLM 只能根据用户当前的输入来生成文本结果，无法主动访问本地环境、调用系统资源或执行实际任务。更重要的是，LLM 在这种模式下并不处于一个持续运行的控制结构之中，它只在收到请求时做出一次性响应，无法负责具体的工作流程与状态管理。</p>\n<p>试想一下，如果 LLM 已经具备了复杂的任务规划与执行能力，我们却把它限制在聊天窗口中，这岂不是太浪费了？正是为了避免这种浪费，并赋予 LLM 在特定环境中“执行操作”的能力，AI 的研究者们重新审视了 AI Agent 这一在 20 世纪 80-90 年代就已经形成体系的概念，并在工程实践领域给了它全新的实现形式。</p>\n<p>关于 AI Agent 这个概念，读者可以参考我之前在《[[关于 AI 的学习路线图]]》中推荐的《人工智能：现代方法》一书给出的定义，原文如下：</p>\n<blockquote>\n<p>An agent is anything that can perceive its environment through sensors and act upon that environment through actuators.</p>\n<p>翻译过来就是：</p>\n<p>任何能够通过传感器感知环境，并通过执行器对环境产生影响的实体，都可以称为 Agent。</p>\n</blockquote>\n<p>这个定义成为了后来所有 AI Agent 应用的理论基础。由此也可以看出，AI Agent 的核心功能并不是提升 LLM 本身的智能水平，而是赋予它与外部系统交互的能力，使其能够参与到真实的工作流程之中。从本质上来说，这其实是 AI 应用在客户端方面的一次角色转变，它现在从单纯的答题工具被转变成了一个可以参与任务执行的系统组件。在特定的应用场景中，这种架构上的转变为工作流程的自动化提供了可行的工程路径。</p>\n<h3 id=\"ai-agent-的工作原理\">AI Agent 的工作原理</h3>\n<p>下面，让我们来了解一下 AI Agent 具体是怎么工作的。在传统聊天式的 AI 应用中，我们可以将其基本的执行模式简单概括为：</p>\n<blockquote>\n<p>用户输入 → 模型推理 → 输出结果 → 结束</p>\n</blockquote>\n<p>这种执行模式本质上是一次性的请求—响应（request-response）结构。即在这种执行模式下，LLM 会在接收到用户输入后生成文本，然后就立即退出当前工作流程，不再参与后续状态管理了。AI Agent 与这类应用的核心差异就在于：它在执行模式中引入了一个可持续运行的控制循环（control loop）。这种循环结构将 LLM 从被动接收用户输入的文本生成器，转变成了用于驱动整个程序执行结构的决策组件。换言之，Agent 的存在将 AI 应用的基本执行模式从“请求—响应”转变成了下面这样一个“感知—决策—执行”的循环结构：</p>\n<blockquote>\n<p>感知环境 → 生成决策 → 执行动作 → 更新环境状态 → 再次感知</p>\n</blockquote>\n<p>这个循环结构会持续运行下去，直到任务完成或满足终止条件。从该执行模式可以看出，一个典型的 AI Agent 应用通常包含以下几个核心组件：</p>\n<ul>\n<li><strong>LLM</strong>：该组件负责理解当前任务目标、分析上下文状态并生成下一步行动决策，不负责直接执行外部操作；</li>\n<li><strong>工具接口</strong>：该组件负责将 LLM 生成的结构化指令转换为实际可执行的操作，例如：调用 API、访问数据库、读写文件、执行系统命令、触发外部服务等。它们通常由开发者定义，并通过函数调用或插件机制暴露给模型；</li>\n<li><strong>状态管理</strong>：该组件负责维护任务的中间状态，例如：当前任务进度、已执行步骤、外部环境变化、历史决策记录等。这些状态通常会被存储在内存变量、数据库、向量存储、文件系统等介质中，如果缺乏有效的状态管理机制，我们就难以构建一个真正的 Agent 应用；</li>\n<li><strong>控制器</strong>：该组件负责驱动循环、判断是否继续执行、解析模型输出、调用对应工具、处理异常与失败重试。从架构角度来看，控制器可被视为 Agent 系统的“骨架”，而 LLM 只是其中的决策模块。</li>\n</ul>\n<p>基于以上核心组件，我们就可以简单地归纳出一个 Agent 应用的工作流程，其主要步骤如下：</p>\n<ol>\n<li>接收任务目标</li>\n<li>将目标与当前状态输入 LLM</li>\n<li>LLM 输出下一步行动计划（通常为结构化格式）</li>\n<li>控制器解析输出</li>\n<li>调用相应工具执行</li>\n<li>更新状态</li>\n<li>判断是否完成任务</li>\n<li>若未完成，则进入下一轮循环</li>\n</ol>\n<p>从工程角度来看，AI Agent 是一种新的系统架构模式，它通过持续运行的控制循环，使模型能够参与真实任务的执行过程，而不仅仅是生成文本结果。</p>\n<h2 id=\"ai-agent-的使用方法\">AI Agent 的使用方法</h2>\n<p>在了解了使用 AI Agent 的必要性及其工作原理之后，接下来就可以正式开始研究如何将它运用到自己的日常工作中了。而当我们要讨论 AI Agent 在实际工作中的使用方法时，首先需要回答的问题是“它运行在哪里、由谁控制、承担什么责任”。不同的运行形态，决定了它在工程系统中的角色边界。下面，让我们按照\"运行在哪里\"这个维度分三类来介绍 AI Agent 的使用方法，以及它们在这些应用场景中所承担的任务角色。</p>\n<h3 id=\"命令行工具型-agent\">命令行工具型 Agent</h3>\n<p>对于大多数开发者而言，以命令行工具的形式使用 AI Agent 是一种更符合工程直觉的方式。它运行在熟悉的终端环境中，可以直接访问文件系统与系统命令，因此看起来类似于自动化脚本。当然了，与传统脚本不同的是，AI Agent 的内部决策路径并非预先编写，而是由 LLM 在循环结构中动态生成。这类 AI Agent 应用的典型代表是 <a href=\"https://github.com/anthropics/claude-code\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code</a>，目前同类的主流应用还包括 <a href=\"https://github.com/anomalyco/opencode\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode</a>、<a href=\"https://github.com/openai/codex\" rel=\"noopener nofollow\" target=\"_blank\">Codex CLI</a>、<a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener nofollow\" target=\"_blank\">Gemini CLI</a>、<a href=\"https://github.com/iflow-ai/iflow-cli\" rel=\"noopener nofollow\" target=\"_blank\">iFlow CLI</a> 等。下面，我们首先要做的就是：先将这些工具安装到自己所在的操作系统中。</p>\n<h4 id=\"安装与配置\">安装与配置</h4>\n<p>命令行工具型 Agent 的安装方式其实是非常简单的。因为，虽然它们各自针对 MacOS/Linux/Windows 系统提供了不同的 bash/powershell 安装脚本，或者基于 homeberw/pacman/scoop 等针对不同操作系统平台的包管理器安装命令，但基本都提供了基于 NPM 这一包管理器的跨平台安装方式。所以，读者在大多数情况下都可以按照以下步骤来安装并使用这些工具：</p>\n<ol>\n<li>\n<p>确保自己所在的操作系统中已经安装了版本在 20.0.0 之上的 Node.js 运行环境，其中自带了 NPM 包管理器；</p>\n</li>\n<li>\n<p>在管理员权限下执行<code>npm install -g &lt;agent-name&gt;@&lt;version&gt;</code>命令，在这里，<code>&lt;agent-name&gt;</code>可以通过查询相关工具的官方网站来获得，而<code>&lt;version&gt;</code>则除了可以是我们在工具官网中查到的具体版本号之外，也可以用<code>latest</code>来表示最新版本。例如，如果我们需要安装最新版本的 OpenCode，就只需要在命令行终端中使用管理员权限执行<code>npm install -g opencode@latest</code>命令即可。</p>\n</li>\n</ol>\n<p>在安装完成之后，我们就可以用 CLI 和 TUI 两种方式来使用这种命令行工具型的 Agent 了。其中，TUI 的方式已经被大家所熟知，它实际上就是一个基于命令行界面的交互式程序，运作方式类似于 Python Shell 或 Node.js REPL，拥有属于自己的独立线程。例如在安装完 OpenCode 之后，我们只需要直接在命令行终端中输入<code>opencode</code>命令（如果想延续之前与 OpenCode 的会话，还在该命令后面加上一个<code>--continue</code>或<code>-c</code>参数），就可以启动它的 TUI 界面了，具体如图 1 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：OpenCode TUI 界面</p>\n<p>在初次进入上次界面时，我们可以对自己使用的 AI Agent 进行一些基本的配置，这些工具的配置方式基本上是大同小异的。一般来说，我们会先使用<code>/model</code>命令设置以下自己默认要使用的 LLM，例如您在图 2 中所看到的就是 OpenCode 的 LLM 选择界面：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：OpenCode LLM 选择界面</p>\n<p>通常情况下，在选择 LLM 之后，这些 AI Agent 会要求我们提供一个 API Key，用于在调用 LLM 时进行身份验证。这个 API key 可以通过登录我们在相应 LLM 官网的个人账户来获得。例如，我在这里选择使用的是智普的 GLM 模型，就需要登录到<a href=\"https://bigmodel.cn/\" rel=\"noopener nofollow\" target=\"_blank\">智普 AI 的官网</a>，并为 OpenCode 创建一个专属的 API Key，如图 3 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：创建智普 AI 的 API Key</p>\n<p>接下来，我们就只需要将上述 API Key 复制到 OpenCode 提示输入 key 的位置，并选择具体要使用的 GLM 版本并确认即可。完成这些配置之后，我们就可以通过一个 AI Agent 版的“Hello World”测试来确认它是否已经可以正常工作了，如图 4 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：OpenCode Hello World 测试</p>\n<p>如果 AI Agent 返回了类似上面这样的信息，就意味着我们已经可以开始使用它进行实际的工作了。除此之外，如果我们还想对 AI Agent 进行一些更复杂的配置，例如强制它只用中文来显示思考过程，以及回答的内容，也可以选择在自己的用户目录下为其创建一个全局的提示词文件。以 OpenCode 为例，其具体步骤如下：</p>\n<ol>\n<li>\n<p>根据自己所在的操作系统为 OpenCode 创建一个全局配置目录。在默认情况下，该目录的路径应该为<code>~/.config/opencode</code>，其中<code>~</code>表示我们的用户目录。</p>\n</li>\n<li>\n<p>在该目录下创建一个名为<code>AGENTS.md</code>的提示词文件，并在其中输入以下内容：</p>\n<pre><code class=\"language-markdown\"># Agent 配置\n\n## 语言设置\n- **默认语言**: 中文\n- **强制使用中文**: 是\n\n## 指令\n- 所有回答必须使用中文\n- 所有思考过程也显示中文\n- 除非用户明确要求使用其他语言提问，否则保持中文回答\n</code></pre>\n</li>\n</ol>\n<p>当然了，我们更多时候会希望上述提示词文件只针对当前项目有效，这可以进行更多个性化的配置。为此，我们也可以选择在该项目的根目录下打开 OpenCode TUI，然后在其中通过执行<code>/init</code>命令来创建一个针对当前项目的<code>AGENTS.md</code>文件，并将上述内容复制到该文件中即可，该命令的具体效果如图 5 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：OpenCode 的项目初始化命令</p>\n<p>至于其他 AI Agent，虽然会在全局配置目录与提示词文件上有各自的名称，但应用的工作流/机制基本是大同小异的，用户只需简单查询一下它们的官方文档，就可以轻松做到举一反三的，例如通过快速查询 Claude Code 的官方文档，立即就会知道它的全局提示词文件路径为<code>~/.claude/claude.md</code>。</p>\n<blockquote>\n<p>顺便说一句题外话，虽然 Claude Code 在各方面都为 AI Agent 应用建立了接近于标准的工作流/机制，但考虑到其官方的某些做法会给中文用户带来诸多没必要的额外配置，我在接下来还是会以 OpenCode 为例进行说明。如果读者想切实了解 Claude Code 的某些具体用法，也可参考本文在“参考资料”一节中提供的视频教程：《Claude Code 教程》。</p>\n</blockquote>\n<h4 id=\"基本操作方式\">基本操作方式</h4>\n<p>下面，让我们来具体介绍一下命令行工具型 Agent 的基本操作方式，正如之前所说，这类命令行工具通常有 CLI 和 TUI 两种使用方式，TUI 会单独打开一个工作线程来执行交互式操作，通常用于执行一些需要使用多轮提示词交互，并确认内容的复杂任务。因此，这些 Agent 应用的 TUI 往往至少会提供“计划（plan）”和“构建（build）”两个模式（个别 Agent 还会提供”自动（auto）“之类的第三种模式，或者在模式名称上存在差异，但其在基本使用逻辑上是一致的），其中，”计划“模式通常没有执行外部命令的权限，主要用于与 LLM 执行多轮交互，并确认某一杂任务的解决方案。例如在之前展示的 OpenCode TUI 中，读者可以在其输入框的下方看到，它默认处于“构建”模式。现在，我们可以通过输入<code>&lt;tab&gt;</code>键来将其切换到“计划”模式，然后再试着让它执行“使用 Python 编写并执行一个 hello world 程序”的操作，就会得到类似图 5 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：OpenCode 的计划模式</p>\n<p>正如读者所见，现在 OpenCode TUI 输入框下面提示其当前处于“计划”模式，并且告诉用户自己当前不能编辑文件和执行程序，然后开始与用户讨论任务的具体解决方案。而当我们切换到“构建”模式时，OpenCode 就会直接执行这个解决方案，并输出类似图 7 的结果：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：OpenCode 的构建模式</p>\n<p>当然了，就上面这种仅需一句简短的提示词就可以完成的任务而言，我们实际上更适合使用 CLI 的方式来执行。这种方式允许我们在 bash/powershell 这类命令行终端程序所在的当前线程中直接执行 AI Agent，并输出结果。例如，如果我们想使用 OpenCode CLI 的方式来编写并执行上面那个 Python 程序，可以直接在命令行终端中输入<code>opencode run \"使用 Python 编写并执行一个 hello world 程序\"</code>命令，并得到类似图 8 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：OpenCode 的 CLI 模式</p>\n<p>如读者所见，上述命令直接在 powershell 所在的当前线程中输出了 OpenCode 的执行结果。这样做的好处，除了避免因一些简单的任务反复启动和关闭 OpenCode TUI 之外，在必要情况下还可以使用 Shell/Python 这样的脚本语言来实现对 AI Agent 应用的批量调用，例如，如果我们想使用 Python 脚本批量调用 OpenCode CLI 来执行 5 个不同的任务，就可以像下面这样编写一个简单的 Python 脚本：</p>\n<pre><code class=\"language-python\">import subprocess\n\ntasks = [\n    \"使用 Python 编写并执行一个 hello world 程序\",\n    \"使用 Python 编写并执行一个计算斐波那契数列的程序\",\n    \"使用 Python 编写并执行一个计算阶乘的程序\",\n    \"使用 Python 编写并执行一个计算素数的程序\",\n    \"使用 Python 编写并执行一个计算回文数的程序\",\n]\n\nfor task in tasks:\n    try:\n        result = subprocess.run(\n            [\"opencode\", \"run\", task],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=120\n        )\n        print(f\"任务成功: {task}\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(f\"任务失败: {task}\")\n        print(e.stderr)\n    except subprocess.TimeoutExpired:\n        print(f\"任务超时: {task}\")\n</code></pre>\n<p>除了<code>opencode run</code>命令之外，我们还可以通过执行<code>opencode -h</code>命令来查看其他可用 CLI 方式执行的 OpenCode 操作，如图 9 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 9</strong>：OpenCode 的 CLI 帮助信息</p>\n<p>虽然，上面这种多次调用<code>opencode run</code>命令的做法，在某些特定的情况下并不是最佳的任务编排方式。例如在某些时候，先将所有的需求写入一个 Markdown 文档中，再将其作为提示词一次性发给 AI Agent 可能会是一种更合适的做法。但是，我们可以基于这一思路发展出许多更复杂的 AI Agent 工作流，例如利用部署在服务端的 Agent 来操作这些命令行工具型的 Agent。下面，就让我们基于 OpenClaw 这一可部署服务型的 AI Agent 来了解一下这一工作流的具体实现方式。</p>\n<h3 id=\"可部署服务型-agent\">可部署服务型 Agent</h3>\n<p>如果我们将命令行工具型的 AI Agent 视为一种增强型的自动化工具，那么以 OpenClaw 为代表的、可在服务端部署的 AI Agent 则就是一种系统级执行单元，二者的差异主要在于运行形态与系统边界。具体来说就是，命令行工具型 Agent 的运行方式通常是：</p>\n<ul>\n<li>被用户触发</li>\n<li>执行一轮或多轮任务</li>\n<li>输出结果</li>\n<li>退出进程</li>\n</ul>\n<p>而可部署服务型 Agent 则具有以下完全不同的特征：</p>\n<ul>\n<li>常驻运行</li>\n<li>通过 HTTP / RPC / WebSocket 等方式对外提供能力</li>\n<li>持续维护会话状态</li>\n<li>支持多用户并发访问</li>\n<li>可以被其他系统调用</li>\n</ul>\n<p>在这种形态下，Agent 就不再是一个功能类似于自动化脚本的增强型工具了，它成为了常驻在操作系统中的一个服务组件。具体来说，如果从程序架构的角度来看，这两种 Agent 的差别主要体现在以下几个方面：</p>\n<ol>\n<li>\n<p>生命周期管理：命令行工具型 Agent 的生命周期通常是一次性的，执行完成即销毁，而可部署服务型 Agent 则具有长生命周期，需要考虑健康检查、日志管理、异常恢复机制。</p>\n</li>\n<li>\n<p>会话与状态管理：命令行工具型 Agent 的状态通常也是一次性的，而可部署服务型 Agent 则需要维护会话状态，这意味着它需要支持用户级会话隔离、长期上下文存储、记忆机制（Memory）以及外部数据库支持。</p>\n</li>\n<li>\n<p>多 Agent 编排能力：一旦 Agent 以系统服务组件的形式存在，它就可以调用其他 Agent，被其他 Agent 调用，参与更复杂的任务链。例如像这样：</p>\n<pre><code class=\"language-plaintext\">用户请求\n↓\n调度 Agent\n↓\n分析 Agent → 代码生成 Agent → 测试 Agent\n↓\n结果汇总\n</code></pre>\n<p>这种执行结构显然已经不再是单纯的工具调用，它关注的实际上已经是任务的编排与调度了。这也就意味着，我们需要在服务型的 Agent 中引入任务队列、消息队列、异步任务调度系统等机制。</p>\n</li>\n</ol>\n<p>下面，让我们以 OpenClaw 为例来具体介绍一下使用这种服务型 Agent 的一些基本工作流。假设，我们现在想使用 OpenClaw 指挥 OpenCode 来完成一个简单的网站重构任务，通常需要按照以下步骤来完成。</p>\n<h4 id=\"步骤-1安装并配置一个-openclaw-服务\">步骤 1：安装并配置一个 OpenClaw 服务</h4>\n<p>正如之前所说，OpenClaw 本质上是一个系统服务，这意味着免不了要赋予它较大的操作权限，基于安全方面的考虑，我个人不建议用户将其安装在自己日常的工作设备上。另外，如果想最大限度地发挥 OpenClaw 的功能，最好要能让它长时间持续运行，并执行一定程度的实际设备管理能力。因此，我们在安装 OpenClaw 时通常需要执行的操作如下：</p>\n<ul>\n<li>\n<p>配置好一台可与我们日常工作设备相连通的独立计算机（如果仅用于学习目的，也可以是一台虚拟机），并在其中安装好操作系统与 Node.js 22.x 以上版本的运行环境。</p>\n</li>\n<li>\n<p>在这台独立计算机上打开命令行终端，并执行<code>npm install -g openclaw@latest</code>命令来安装 OpenClaw。当然了，这是使用跨平台的方式。如果读者不想使用 NPM，也可以通过直接执行 bash/powershell 的安装脚本来完成这个操作，相关命令如下：</p>\n<pre><code class=\"language-bash\"># MacOS/Linux 系统下使用 bash 脚本安装：\ncurl -fsSL https://openclaw.ai/install.sh | bash\n# Windows 系统下使用 powershell 脚本安装：\niwr -useb https://openclaw.ai/install.ps1 | iex\n</code></pre>\n</li>\n<li>\n<p>待安装完成之后，继续执行<code>openclaw onboard --install-daemon</code>命令来启动新手安装向导（如图 10 所示），进一步安装 OpenClaw 的服务端组件（例如飞书机器人、WhatsApp 机器人等），关于这方面的内容，读者可参考本文在“参考资料”一节中提供的视频教程：《OpenClaw +飞书的工具流搭建过程》。</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 10</strong>：OpenClaw 的安装向导</p>\n</li>\n<li>\n<p>在配置完相关服务端组件之后，我们还需要通过执行如下命令来配置 OpenClaw 的 Gateway 网关：</p>\n<pre><code class=\"language-bash\">openclaw channels login\nopenclaw gateway --port 18789\n</code></pre>\n<p>在这里，<code>--port</code>参数用于指定 OpenClaw Gateway 的监听端口，如果读者希望使用默认的 18789 端口，则可以省略该参数。</p>\n</li>\n<li>\n<p>待 Gateway 启动之后，我们就可以使用浏览器打开<code>http://localhost:18789</code>来访问 OpenClaw 的 Web 端了，如果我们能看到如图 11 所示的界面，就说明 OpenClaw 已经成功安装并完成了初步的配置工作。</p>\n  \n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 11</strong>：OpenClaw 的 Web 端</p>\n</li>\n</ul>\n<h4 id=\"步骤-2配置-openclaw-调用-opencode-的方式\">步骤 2：配置 OpenClaw 调用 OpenCode 的方式</h4>\n<p>截止到目前为止，我们主要有<strong>两种方式</strong>可以让 OpenClaw 使用 OpenCode 来连接 LLM 并执行指定的任务。如果用户已购买了 OpenCode 的官方模型服务（即 OpenCode Zen），可以选择直接使用 OpenClaw 自带的 Zen 插件来调用 OpenCode，这种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>先获取到 OpenCode Zen 的 API Key，然后通过执行如下命令之一，将其添加到 OpenClaw 的配置中：</p>\n<pre><code class=\"language-bash\"># 使用交互式命令，这需要根据该命令的提示输入你的 API Key\nopenclaw onboard --auth-choice opencode-zen\n# 或非交互式命令，直接将 API Key 作为参数传入\nopenclaw onboard --opencode-zen-api-key \"&lt;你的 API Key&gt;\"\n</code></pre>\n</li>\n<li>\n<p>如果需要的话，还可以通过执行如下命令来设置自己要使用的默认模型：</p>\n<pre><code class=\"language-bash\">openclaw config set agents.defaults.model.primary \"opencode/claude-opus-4-6\"\n</code></pre>\n</li>\n</ul>\n<p>当然了，选择上述方式需要用户不计较按量计费所带来的开销。如果我们想使用免费的 LLM 的话（譬如  kimi-k2.5-free），也可以通过给 OpenClaw 安装 <code>opencode-to-openai</code>这样的第三方插件来实现。这第二种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>安装<code>opencode-to-openai</code>插件，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/dxxzst/opencode-to-openai\ncd opencode-to-openai\nopenclaw plugins install .\n</code></pre>\n</li>\n<li>\n<p>安装完成后，需要执行如下命令来重启 OpenClaw，并确保插件已启用：</p>\n<pre><code class=\"language-bash\">openclaw gateway restart\n</code></pre>\n<p>在这里，如果我们在 OpenClaw 中启用了插件白名单，就还需要通过执行如下命令将该加入该白名单：</p>\n<pre><code class=\"language-bash\">openclaw config get plugins.allow --json\n# 假设返回 [\"a\",\"b\"]\n\nopenclaw config set plugins.allow '[\"a\",\"b\",\"opencode-to-openai\"]' --json\nopenclaw gateway restart\n</code></pre>\n</li>\n<li>\n<p>同步模型并认证 LLM 服务，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local\n</code></pre>\n<p>如果你想顺便设置默认模型：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local --set-default\n</code></pre>\n</li>\n<li>\n<p>选择模型，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models set opencode-to-openai/opencode/kimi-k2.5-free\n</code></pre>\n<p>在这里，如果担心对 LLM 的请求会被卡住，也可以用<code>useIsolatedHome=false</code>这个插件配置让 OpenCode 使用真实 HOME，具体配置命令如下：</p>\n<pre><code class=\"language-bash\">openclaw config set plugins.opencode-to-openai.useIsolatedHome false\n</code></pre>\n</li>\n</ul>\n<h4 id=\"步骤-3与-openclaw-进行对话\">步骤 3：与 OpenClaw 进行对话</h4>\n<p>如果上述操作一切顺利，我们就可以在步骤 1 中配置好的 Web 端或飞书之类的应用中打开与 OpenClaw 的对话窗口，通过发送提示词来调度 OpenCode 完成相关任务了，如图 12 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 12</strong>：与 OpenClaw 的对话窗口</p>\n<p>当然了，如果想让提示词发挥到最大的作用，并在生产环境中实际使用 OpenClaw/OpenCode 来完成具体的项目任务，我们还需要再配置一下 OpenClaw/OpenCode 所接入的 MCP 服务和 Agent Skills 机制了。关于这部分的内容，我将会在《[[Agent 的进阶应用]]》这一篇笔记中进行详细介绍。</p>\n<h2 id=\"结束语\">结束语</h2>\n<p>在完成了对 AI Agent 的学习与实践之后，我最为明显的体会之一是：Agent 并没有让系统变得更简单，反而让系统的边界变得更加清晰。与传统的自动化脚本或工具不同，Agent 并不是一组固定规则的集合，而是一个基于语言模型进行任务理解、规划与执行的系统组件。这意味着，在很多场景下，它所做的并不是“按预期运行”，而是“尽力完成任务”。</p>\n<p>正因如此，Agent 的引入并没有削弱人类在系统中的作用，反而对人的判断能力提出了更高要求：<br />\n我们需要能够理解 Agent 在做什么、为什么这么做，以及在什么情况下应该介入、修正甚至中止它的行为。从这个角度来看，学习和使用 AI Agent，并不意味着把控制权完全交给 AI，而是学会如何在一个由 AI 参与执行的系统中，重新定位人的职责与边界。这也正是本学习阶段的核心目标。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>\n<p>官方文档：</p>\n<ul>\n<li><a href=\"https://code.claude.com/docs/zh-CN/overview?utm_source=copilot.com\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code 官方文档</a></li>\n<li><a href=\"https://opencode.doczh.com/docs/\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode 官方文档</a></li>\n<li><a href=\"https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers\" rel=\"noopener nofollow\" target=\"_blank\">基于 Agent skills 和 MCP 服务的协同工作流</a></li>\n<li><a href=\"https://docs.openclaw.ai/zh-CN\" rel=\"noopener nofollow\" target=\"_blank\">OpenClaw 官方文档</a></li>\n</ul>\n</li>\n<li>\n<p>视频教程：</p>\n<ul>\n<li>Claude Code 教程：<a href=\"https://www.youtube.com/watch?v=AT4b9kLtQCQ\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV14rzQB9EJj\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n<li>OpenClaw +飞书的工具流搭建过程：<a href=\"https://www.youtube.com/watch?v=giv63OtX720\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV1rvcpzDEsH\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n</ul>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-18 16:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">276</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "从挖矿木马入侵到 Docker Rootless 加固，我的服务器安全复盘",
      "link": "https://www.cnblogs.com/deali/p/19626849",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/deali/p/19626849\" id=\"cb_post_title_url\" title=\"发布于 2026-02-20 20:45\">\n    <span>从挖矿木马入侵到 Docker Rootless 加固，我的服务器安全复盘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>最近我连续几台服务器被挂了挖矿木马，CPU、带宽、磁盘 IO 被拉满，服务器直接卡死无法连接。</p>\n<p>排查后发现，核心诱因是 Docker 权限过高 + 服务漏洞暴露，导致攻击者通过容器突破权限控制。</p>\n<p><img alt=\"\" src=\"https://blog.deali.cn/media/blog/cec878553480eb4f/1097027d157aa49e.jpg\" /></p>\n<blockquote>\n<p>PS：本来想写一篇文章介绍排查过程的，不过还是嫌麻烦没写，放在本文一起讲吧~</p>\n</blockquote>\n<p>重装系统后，我在部署 Docker 时注意到官方提示的 Rootless（无根）模式 —— 这一模式能从根本上降低容器逃逸风险，遂深入研究并落地配置，现将完整过程整理分享，希望能帮到同样关注 Docker 安全的开发者。</p>\n<h2 id=\"rootless-模式是什么\">Rootless 模式是什么</h2>\n<p>普通情况下，Docker 守护进程（dockerd）是用 <code>root</code> 权限运行的，哪怕你用普通用户执行 <code>docker run</code>，底层还是 root 权限，这有安全风险（比如容器逃逸可能拿到主机 root）。</p>\n<p>Rootless 模式让 Docker 守护进程以<strong>普通用户权限</strong>运行，哪怕容器出问题，也无法获取主机的 root 权限，安全性大幅提升。</p>\n<p>有好处自然有代价，rootless 的代价是配置复杂，且部分功能受限（比如无法端口映射 &lt; 1024）。</p>\n<p>不过没关系，这些也可以通过配置解决。先从安装开始吧。</p>\n<h2 id=\"安装docker\">安装docker</h2>\n<p>本来安装是很简单的，不过加个定语：在国内网络环境，那就非常复杂了。</p>\n<p>本文介绍最简单的安装方式：使用docker官方脚本+清华镜像。</p>\n<pre><code class=\"language-bash\">export DOWNLOAD_URL=\"https://mirrors.tuna.tsinghua.edu.cn/docker-ce\"\n# 如您使用 curl\ncurl -fsSL https://ghfast.top/https://raw.githubusercontent.com/docker/docker-install/master/install.sh | sh\n# 如您使用 wget\nwget -O- https://ghfast.top/https://raw.githubusercontent.com/docker/docker-install/master/install.sh | sh\n</code></pre>\n<p>注意 <code>raw.githubusercontent.com</code> 这个域名也是无法访问的，可以使用 ghproxy 来加速。</p>\n<h2 id=\"安装完成提示\">安装完成提示</h2>\n<p>安装完成会有一个提示，这也是开启 Rootless 模式的关键入口：</p>\n<pre><code class=\"language-bash\">================================================================================\n\nTo run Docker as a non-privileged user, consider setting up the\nDocker daemon in rootless mode for your user:\n\n    dockerd-rootless-setuptool.sh install\n\nVisit https://docs.docker.com/go/rootless/ to learn about rootless mode.\n\n\nTo run the Docker daemon as a fully privileged service, but granting non-root\nusers access, refer to https://docs.docker.com/go/daemon-access/\n\nWARNING: Access to the remote API on a privileged Docker daemon is equivalent\n         to root access on the host. Refer to the 'Docker daemon attack surface'\n         documentation for details: https://docs.docker.com/go/attack-surface/\n\n================================================================================\n</code></pre>\n<p>我就是在这里开始使用 rootless 模式的。</p>\n<p>提示核心解读：</p>\n<ol>\n<li>推荐通过<code>dockerd-rootless-setuptool.sh install</code>开启 Rootless 模式，让普通用户无 root 权限运行 Docker；</li>\n<li>若坚持 root 权限运行 Docker，可参考文档给普通用户授权（如加入 docker 组），但风险更高；</li>\n<li>重点警告：暴露 Docker 远程 API（如 2375 端口）= 直接开放主机 root 权限，这是服务器被入侵的高频诱因！</li>\n</ol>\n<h2 id=\"安装必要依赖\">安装必要依赖</h2>\n<p>我直接运行 <code>dockerd-rootless-setuptool.sh install</code> 的时候，提示要缺乏依赖</p>\n<pre><code class=\"language-bash\">$ dockerd-rootless-setuptool.sh install\n[ERROR] Missing system requirements. Run the following commands to\n[ERROR] install the requirements and run this tool again.\n\n########## BEGIN ##########\nsudo sh -eux &lt;&lt;EOF\n# Install newuidmap &amp; newgidmap binaries\napt-get install -y uidmap\nEOF\n########## END ##########\n</code></pre>\n<p>输入提示的这行命令：</p>\n<pre><code class=\"language-bash\">sudo sh -eux &lt;&lt;EOF\n# Install newuidmap &amp; newgidmap binaries\napt-get install -y uidmap\nEOF\n</code></pre>\n<p>安装完成后，再次执行 <code>dockerd-rootless-setuptool.sh install</code></p>\n<p>以后操作 docker 服务，要加上 <code>--user</code></p>\n<pre><code class=\"language-bash\">systemctl --user start docker.service\n</code></pre>\n<h2 id=\"配置\">配置</h2>\n<p>rootless 模式下：</p>\n<ul>\n<li>所有 Docker 命令都要在<strong>安装 Rootless 的普通用户</strong>下执行（不要用 root）；</li>\n<li>如果重启服务器后 Docker 没自动启动，执行：<code>systemctl --user enable --now docker</code>；</li>\n<li>数据备份要找 <code>~/.local/share/docker</code> 目录（而非 <code>/var/lib/docker</code>）。</li>\n</ul>\n<h3 id=\"镜像加速器\">镜像加速器</h3>\n<p>默认情况下，Rootless Docker 的配置文件存放在当前用户的 <strong>XDG 配置目录</strong> 下，路径是：<code>~/.config/docker/daemon.json</code></p>\n<pre><code class=\"language-bash\"># 先创建目录（如果不存在）\nmkdir -p ~/.config/docker\n\n# 编辑配置文件（用 nano 或 vim 都可以）\nnano ~/.config/docker/daemon.json\n</code></pre>\n<p>配置加速器</p>\n<pre><code class=\"language-json\">{\n  \"registry-mirrors\": [\"https://你的阿里云镜像加速地址.mirror.aliyuncs.com\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"100m\",\n    \"max-file\": \"3\"\n  }\n}\n</code></pre>\n<p>注意：之前大部分稳定好用的加速器都停止服务了，现在就没法推荐啥，大家各凭本事吧。</p>\n<h3 id=\"解决-无法绑定-1-1023-端口-的问题\">解决 “无法绑定 1-1023 端口” 的问题</h3>\n<p>需要给当前用户 “绑定低端口” 的权限：</p>\n<pre><code class=\"language-bash\"># 给当前用户授权绑定 1-1023 端口（仅对当前会话生效）\nsudo sysctl net.ipv4.ip_unprivileged_port_start=0\n\n# 永久生效（重启后也有效）\necho \"net.ipv4.ip_unprivileged_port_start=0\" | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p  # 立即生效\n</code></pre>\n<p>执行后，你就能正常映射 80、443 等端口了。</p>\n<h3 id=\"重启生效\">重启生效</h3>\n<p>Rootless 模式的 Docker 重启命令和系统级不同，执行：</p>\n<pre><code class=\"language-bash\"># 重启当前用户的 Docker 服务\nsystemctl --user restart docker\n\n# 验证配置是否生效\ndocker info\n# 能在 \"Registry Mirrors\" 部分看到你配置的镜像加速地址就是成功的\n</code></pre>\n<p>正常输出示例：</p>\n<pre><code class=\"language-plaintext\">Rootless: true\nRegistry Mirrors:\n https://你的阿里云镜像加速地址.mirror.aliyuncs.com/\n</code></pre>\n<h3 id=\"rootless-模式不支持的配置项\">Rootless 模式不支持的配置项</h3>\n<p>部分系统级配置在 Rootless 下无效（因为没有 root 权限），比如：</p>\n<ul>\n<li><code>iptables: false</code>（网络规则由 slirp4netns 管理，而非 iptables）；</li>\n<li><code>storage-driver: overlay2</code>（默认已启用，无需手动配置）；</li>\n<li>远程 API 相关配置（如 <code>hosts: [\"tcp://0.0.0.0:2375\"]</code>，Rootless 下不建议开启）。</li>\n<li>任何涉及系统级目录（如<code>/var/run/docker.sock</code>）的配置。</li>\n</ul>\n<h2 id=\"volume问题\">volume问题</h2>\n<p>切换到 rootless 之后，我还发现了 swag 的 config 无法读写了。</p>\n<p>swag 的 compose.yaml 配置是这样：</p>\n<pre><code class=\"language-yaml\">services:\n  swag:\n    image: linuxserver/swag\n    container_name: swag\n    cap_add:\n      - NET_ADMIN\n    environment:\n      - PUID=1000\n      - PGID=1000\n    volumes:\n      - ./config:/config\n</code></pre>\n<p><strong>rootless Docker 里，容器内的 UID=1000 ≠ 宿主机的 UID=1000</strong></p>\n<p>所以 <strong>SWAG 在容器里 chown 了 <code>/config</code>，宿主机看到的是一个“映射后的陌生 UID（100999）”</strong></p>\n<h3 id=\"解决方法\">解决方法</h3>\n<p>rootless 官方推荐使用命名卷，但我要经常修改 config 里的文件，这个肯定不现实。</p>\n<p>那么还有一个方法，使用 ACL 放行。</p>\n<p>先安装相关工具：</p>\n<pre><code class=\"language-bash\">sudo apt update\nsudo apt install -y acl\n</code></pre>\n<p>在 swag 目录下执行</p>\n<pre><code class=\"language-bash\">setfacl -m u:ecs-user:rwx config\nsetfacl -R -m u:ecs-user:rwx config\nsetfacl -d -m u:ecs-user:rwx config\n</code></pre>\n<p>验证：</p>\n<pre><code class=\"language-bash\">getfacl config | sed -n '1,20p'\n</code></pre>\n<p>看到类似：</p>\n<pre><code>user::rwx\nuser:ecs-user:rwx\ngroup::r-x\nmask::rwx\nother::r-x\n</code></pre>\n<h2 id=\"小结\">小结</h2>\n<p>Rootless 模式虽比普通 Docker 配置稍繁琐，但能从根本上降低容器逃逸风险，尤其适合对外提供服务的生产服务器。核心总结：</p>\n<ol>\n<li>安装：结合清华镜像源解决国内下载问题，优先用普通用户安装 Rootless 模式；</li>\n<li>权限：禁止暴露 Docker 远程 API，给普通用户授权低端口绑定权限即可满足日常使用；</li>\n<li>配置：牢记 Rootless 模式的配置文件、数据目录均在用户目录下，与系统级 Docker 区分开；</li>\n<li>安全：即便开启 Rootless，运行容器时仍需注意服务安全（如 Redis 加密码、安全组限制端口访问）。</li>\n</ol>\n<p>此次踩坑让我深刻意识到：服务器安全无小事，哪怕是 Docker 这样的基础工具，也需从权限层面做好最小化管控，才能避免被挖矿木马等恶意程序趁虚而入。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    微信公众号：「程序设计实验室」\n专注于互联网热门新技术探索与团队敏捷开发实践，包括架构设计、机器学习与数据分析算法、移动端开发、Linux、Web前后端开发等，欢迎一起探讨技术，分享学习实践经验。\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 20:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/deali\">程序设计实验室</a>&nbsp;\n阅读(<span id=\"post_view_count\">19</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "手把手教你使用vscode开发stm32！",
      "link": "https://www.cnblogs.com/chenyouyuan/p/19626759",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/chenyouyuan/p/19626759\" id=\"cb_post_title_url\" title=\"å‘å¸ƒäºŽ 2026-02-20 19:31\">\n    <span>æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨vscodeå¼€å‘stm32ï¼</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        å·²ç»2026å¹´äº†ï¼Œä½ æ˜¯å¦è¿˜åœ¨ä½¿ç”¨å¤è€çš„keil5çš„è°ƒè¯•å‘¢ï¼Ÿæ˜¯å¦è¿˜åœ¨ä¸ºkeil5å¤åˆ¶ç²˜è´´ä»£ç åˆ°èŠå¤©å¼aiå†ç²˜è´´å›žæ¥è€Œçƒ¦æ¼å‘¢ï¼Ÿå¿«å¿«åŠ å…¥vscodeå¼€å‘stm32çš„å¤§éƒ¨é˜ŸæŽ¥å—å…‰è£çš„è¿›åŒ–å§ï¼\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"å¼€å‘å·¥å…·é…ç½®ç¯‡è¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32\">å¼€å‘å·¥å…·é…ç½®ç¯‡ï¼šè¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32</h1>\n<blockquote>\n<p>å·²ç»2026å¹´äº†ï¼Œä½ æ˜¯å¦è¿˜åœ¨ä½¿ç”¨å¤è€çš„keil5çš„è°ƒè¯•å‘¢ï¼Ÿæ˜¯å¦è¿˜åœ¨ä¸ºkeil5å¤åˆ¶ç²˜è´´ä»£ç åˆ°èŠå¤©å¼aiå†ç²˜è´´å›žæ¥è€Œçƒ¦æ¼å‘¢ï¼Ÿå¿«å¿«åŠ å…¥vscodeå¼€å‘stm32çš„å¤§éƒ¨é˜ŸæŽ¥å—å…‰è£çš„è¿›åŒ–å§ï¼</p>\n</blockquote>\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">ç›®å½•</div><ul><li><a href=\"#å¼€å‘å·¥å…·é…ç½®ç¯‡è¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32\" rel=\"noopener nofollow\">å¼€å‘å·¥å…·é…ç½®ç¯‡ï¼šè¿ŽæŽ¥æ–°æ—¶ä»£--ä½¿ç”¨vscodeå¼€å‘stm32</a><ul><li><a href=\"#å‰è¨€\" rel=\"noopener nofollow\">å‰è¨€</a></li><li><a href=\"#æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘\" rel=\"noopener nofollow\">æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘</a></li><li><a href=\"#ä¸€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“\" rel=\"noopener nofollow\">ä¸€ã€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“</a></li><li><a href=\"#äºŒä¸‹è½½vscodeä»¥åŠæ’ä»¶\" rel=\"noopener nofollow\">äºŒã€ä¸‹è½½vscodeä»¥åŠæ’ä»¶</a><ul><li><a href=\"#stm32-for-vscode\" rel=\"noopener nofollow\">stm32 for vscode</a></li><li><a href=\"#makefiel\" rel=\"noopener nofollow\">makefiel</a></li></ul></li><li><a href=\"#ä¸‰stlinké©±åŠ¨å®‰è£\" rel=\"noopener nofollow\">ä¸‰ã€stlinké©±åŠ¨å®‰è£…</a></li><li><a href=\"#å››-é…ç½®å¼€å‘çŽ¯å¢ƒ\" rel=\"noopener nofollow\">å››ã€ é…ç½®å¼€å‘çŽ¯å¢ƒ</a><ul><li><a href=\"#é…ç½®çŽ¯å¢ƒå˜é‡\" rel=\"noopener nofollow\">é…ç½®çŽ¯å¢ƒå˜é‡</a></li><li><a href=\"#å…³äºŽlaunchjsonæ–‡ä»¶\" rel=\"noopener nofollow\">å…³äºŽlaunch.jsonæ–‡ä»¶</a></li><li><a href=\"#å…³äºŽtasksjsonæ–‡ä»¶\" rel=\"noopener nofollow\">å…³äºŽtasks.jsonæ–‡ä»¶</a></li></ul></li><li><a href=\"#å¼€å§‹è°ƒè¯•\" rel=\"noopener nofollow\">å¼€å§‹è°ƒè¯•</a><ul><li><a href=\"#stm32-svdæ–‡ä»¶\" rel=\"noopener nofollow\">stm32 svdæ–‡ä»¶</a></li></ul></li></ul></li></ul></div><p></p>\n<p>æœ¬ç¯‡æ–‡ç« ä¸»è¦å‚è€ƒæ¹–å—å¤§å­¦robomasterè·ƒé¹¿æˆ˜é˜Ÿçš„ç”µæŽ§å¼€æºéƒ¨åˆ†</p>\n<p><a href=\"https://gitee.com/hnuyuelurm/basic_framework/blob/master/.Doc/VSCode+Ozone%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.md\" rel=\"noopener nofollow\" target=\"_blank\">.Doc/VSCode+Ozoneä½¿ç”¨æ–¹æ³•.md Â· HNUYueLuRM/basic_framework - Gitee.com</a></p>\n<h2 id=\"å‰è¨€\">å‰è¨€</h2>\n<p>æœ¬ç¯‡æ–‡ç« ä¸»è¦ä½¿ç”¨vscode + cubemxå¹³æ›¿keil5ï¼Œå®žçŽ°å¿«é€Ÿå¼€å‘ã€å®žæ—¶å¯è§†åŒ–å˜é‡ï¼ˆå…¨å±€ï¼‰ã€å¯ä»¥æŸ¥çœ‹å¯„å­˜å™¨å†…å®¹ã€copilotè¾…åŠ©å¼€å‘....</p>\n<p>æ”¯æŒstlinkï¼Œjlinkï¼Œdaplinkè°ƒè¯•å™¨ï¼Œæš‚æ—¶æ²¡æœ‰æ‰¾åˆ°çº¯é vscodeçš„å®žæ—¶å¯è§†åŒ–å‚æ•°æ³¢å½¢å›¾åŠŸèƒ½çš„æ’ä»¶</p>\n<p>å¦‚æžœå¤§å®¶è¿˜æœ‰å…¶ä»–å¥½ç”¨çš„æ–¹æ¡ˆæ¬¢è¿Žè®¨è®ºå™¢~</p>\n<h2 id=\"æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘\">æ‰€æœ‰ä¾èµ–çš„è½¯ä»¶ç™¾åº¦ç½‘ç›˜é“¾æŽ¥ä»¥åŠé…å¥—bç«™æ‰‹æŠŠæ‰‹è®²è§£è§†é¢‘</h2>\n<p>å¯èƒ½ç½‘ç»œåŽŸå› å¯¼è‡´ä¸€äº›å®‰è£…æ— æ³•å®Œæˆï¼Œæ‰€ä»¥è¿™è¾¹æä¾›æ‰€ç”¨åˆ°çš„æ‰€æœ‰åŒ…ï¼Œæ ¹æ®éœ€è¦å®‰è£…å³å¯<br />\né€šè¿‡ç½‘ç›˜åˆ†äº«çš„æ–‡ä»¶ï¼šall_in_one.zip<br />\né“¾æŽ¥: <a href=\"https://pan.baidu.com/s/12brC2bPmu9wWa2h-VgIZmg?pwd=9xah\" rel=\"noopener nofollow\" target=\"_blank\">https://pan.baidu.com/s/12brC2bPmu9wWa2h-VgIZmg?pwd=9xah</a> æå–ç : 9xah<br />\n--æ¥è‡ªç™¾åº¦ç½‘ç›˜è¶…çº§ä¼šå‘˜v3çš„åˆ†äº«<br />\nbç«™è§†é¢‘é“¾æŽ¥<br />\n<a href=\"https://www.bilibili.com/video/BV1ZMfGBrEFy/?vd_source=f553a12b04c16a678ddc0064cc04563c\" rel=\"noopener nofollow\" target=\"_blank\">https://www.bilibili.com/video/BV1ZMfGBrEFy/?vd_source=f553a12b04c16a678ddc0064cc04563c</a></p>\n<h2 id=\"ä¸€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“\">ä¸€ã€ä¸‹è½½cubemxä»¥åŠå¯¹åº”stm32çš„halåº“</h2>\n<p>cubemxå®˜ç½‘(éœ€è¦ç®€å•çš„æ³¨å†Œå³å¯)ï¼š</p>\n<p><a href=\"https://www.st.com/en/development-tools/stm32cubemx.html#get-software\" rel=\"noopener nofollow\" target=\"_blank\">https://www.st.com/en/development-tools/stm32cubemx.html#get-software</a></p>\n<p>ä¸‹è½½å®Œæˆä¹‹åŽç‚¹å‡»</p>\n<p><img alt=\"\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220181610339.png\" /></p>\n<p>ç›´æŽ¥åœ¨æœç´¢æ æœç´¢ä½ ä½¿ç”¨çš„stm32çš„åž‹å·ï¼Œä»¥f103ä½œä¸ºä¾‹å­</p>\n<p><img alt=\"image-20260220181746320\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220181746320.png\" /></p>\n<p>åŒå‡»è¦é€‰æ‹©çš„æ¿å­å³å¯è¿›å…¥</p>\n<p>å…¶ä½™è¯¦ç»†çš„é…ç½®å¯ä»¥å‚è€ƒå…¶ä»–æ•™ç¨‹</p>\n<p>ä¸»è¦æ³¨æ„çš„æ˜¯ï¼š</p>\n<p>sysçš„é…ç½®è¦é…ç½®æˆswæ¨¡å¼ï¼Œä¸ç„¶ä¼šåªèƒ½çƒ§å½•ä¸€æ¬¡</p>\n<p><img alt=\"image-20260220181938762\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220181938762.png\" /></p>\n<p>å¯¼å‡ºè¿™è¾¹é€‰æ‹©makefile</p>\n<p><img alt=\"image-20260220182046638\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220182046638.png\" /></p>\n<h2 id=\"äºŒä¸‹è½½vscodeä»¥åŠæ’ä»¶\">äºŒã€ä¸‹è½½vscodeä»¥åŠæ’ä»¶</h2>\n<p>vscodeå®˜ç½‘ï¼š</p>\n<p><a href=\"https://www.st.com/en/development-tools/stm32cubemx.html#get-software\" rel=\"noopener nofollow\" target=\"_blank\">https://www.st.com/en/development-tools/stm32cubemx.html#get-software</a></p>\n<p>éœ€è¦å®‰è£…çš„vscdoeæ’ä»¶ï¼š</p>\n<p>ç‚¹å‡»vscodeå·¦ä¾§çš„è¿™ä¸ªå›¾æ ‡</p>\n<p><img alt=\"image-20260220174816604\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174816604.png\" /></p>\n<h3 id=\"stm32-for-vscode\">stm32 for vscode</h3>\n<p><img alt=\"image-20260220160002646\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220160002646.png\" /></p>\n<p><img alt=\"image-20260220155925565\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220155925565.png\" /></p>\n<p>ç‚¹å‡»install build tools</p>\n<p><img alt=\"image-20260220175156853\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175156853.png\" /></p>\n<p>å‡ºçŽ°å¦‚ä¸Šé¡µé¢å³ä»£è¡¨å®‰è£…æˆåŠŸï¼ˆå¤§çº¦5~15åˆ†é’Ÿï¼‰</p>\n<p>å¦‚æžœç½‘ç»œä¸å¥½å£è¯­åˆ‡æ¢æ‰‹æœºçƒ­ç‚¹å†æ¬¡å°è¯•</p>\n<p>è¿˜ä¸è¡Œå°±ç›´æŽ¥ä½¿ç”¨æˆ‘çš„ç™¾åº¦ç½‘ç›˜åˆ†äº«çš„zipåŽ‹ç¼©åŒ…ï¼Œå»ºè®®æ”¾åˆ°dç›˜ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰</p>\n<h3 id=\"makefiel\">makefiel</h3>\n<p><img alt=\"image-20260220155854381\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220155854381.png\" /></p>\n<h2 id=\"ä¸‰stlinké©±åŠ¨å®‰è£…\">ä¸‰ã€stlinké©±åŠ¨å®‰è£…</h2>\n<p>å¦‚æžœä½ ä¹‹å‰æ²¡æœ‰ä½¿ç”¨è¿‡stlinkï¼Œè¯·æ ¹æ®å¦‚ä¸‹é“¾æŽ¥å®Œæˆstlinké©±åŠ¨çš„å®‰è£…</p>\n<p><a href=\"https://www.st.com.cn/zh/development-tools/stsw-link009.html\" rel=\"noopener nofollow\" target=\"_blank\">STSW-LINK009 | Software - æ„æ³•åŠå¯¼ä½“</a><br />\næ ¹æ®è‡ªå·±çš„ç”µè„‘é…ç½®åŒå‡»ä»¥ä¸‹ä¸¤ä¸ªexeä¸­çš„ä¸€ä¸ª</p>\n<p><img alt=\"image-20260220184946316\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184946316.png\" /></p>\n<h2 id=\"å››-é…ç½®å¼€å‘çŽ¯å¢ƒ\">å››ã€ é…ç½®å¼€å‘çŽ¯å¢ƒ</h2>\n<h3 id=\"é…ç½®çŽ¯å¢ƒå˜é‡\">é…ç½®çŽ¯å¢ƒå˜é‡</h3>\n<ol>\n<li>\n<p>åœ¨vscodeæ‰¾åˆ°æœ€å·¦è¾¹çš„å››ä¸ªæ–¹å—å›¾æ ‡ï¼Œè¿™é‡Œæ˜¯æˆ‘ä»¬å®‰è£…æ‹“å±•çš„åœ°æ–¹</p>\n<p>ç‚¹å‡»ä¹‹åŽæ‰¾åˆ°stm32 for vscode</p>\n<p><img alt=\"image-20260220174706404\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174706404.png\" /></p>\n</li>\n<li>\n<p>æ‰“å¼€è¯¦æƒ…é¡µé¢--&gt;ç‚¹å‡»å³ä¸‹è§’è“è‰²çš„ç¼“å­˜æ–‡å­—ï¼Œæ‰“å¼€ç¼“å­˜æ–‡ä»¶å¤¹</p>\n<p><img alt=\"image-20260220175025884\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175025884.png\" /></p>\n<p>ç¼“å­˜æ–‡ä»¶å¤¹å¦‚ä¸‹</p>\n<p><img alt=\"image-20260220175310991\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175310991.png\" /></p>\n</li>\n<li>\n<p>è¿›å…¥@å¼€å¤´çš„æ–‡ä»¶å¤¹,å¦‚ä¸‹ï¼Œæˆ‘ä»¬ä¸ºäº†æ–¹ä¾¿ï¼ŒæŠŠè¯¥æ–‡ä»¶å¤¹ä¸‹é¢æ‰€æœ‰çš„ä¸œè¥¿è¿ç§»åˆ°Dç›˜ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰ï¼Œåœ¨Dç›˜ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹å«stm32toolsï¼ŒæŠŠæ–‡ä»¶å…¨éƒ¨æ”¾è¿›åŽ»</p>\n<p><img alt=\"image-20260220175354956\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175354956.png\" /></p>\n<p>è¿ç§»è·¯å¾„å¦‚ä¸‹å›¾ï¼ˆå› ä¸ºè¿™ä¸ªæ¼”ç¤ºçš„æœºå™¨æ²¡æœ‰åˆ†dç›˜ï¼Œæˆ‘å°±æ”¾åˆ°cç›˜äº†ï¼‰</p>\n<p><img alt=\"image-20260220175533984\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220175533984.png\" /></p>\n</li>\n<li>\n<p>æŽ¥ä¸‹æ¥æŒ‰ä¸‹winé”®ï¼Œåœ¨æœç´¢æ æœç´¢çŽ¯å¢ƒ</p>\n<p>ç‚¹å‡»ç¼–è¾‘ç³»ç»ŸçŽ¯å¢ƒå˜é‡</p>\n<p><img alt=\"\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174138545.png\" /></p>\n<p>ç‚¹å‡»æœ€ä¸‹é¢çš„çŽ¯å¢ƒå˜é‡ï¼ˆNï¼‰</p>\n<p><img alt=\"image-20260220174230783\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174230783.png\" /></p>\n<p>åŒå‡»path</p>\n<p><img alt=\"image-20260220174323481\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174323481.png\" /></p>\n<p>ç‚¹å‡»å³è¾¹çš„æ–°å»ºå³å¯æ–°å»ºå˜é‡ï¼Œctrl+vç²˜è´´ä¸‰ä¸ªbinçš„è·¯å¾„ï¼ˆå¦‚ä¸‹å›¾ï¼Œæ ¹æ®è‡ªå·±çš„æ–‡ä»¶ä½ç½®æ¥</p>\n<p><img alt=\"image-20260220174405199\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220174405199.png\" /></p>\n</li>\n</ol>\n<p>é…ç½®å®Œæˆä¹‹åŽwin + r</p>\n<p>åœ¨å¼¹å‡ºçš„çª—å£è¾“å…¥cmdï¼Œå›žè½¦</p>\n<p>ç²˜è´´å¦‚ä¸‹æŒ‡ä»¤è¿è¡Œ</p>\n<pre><code class=\"language-cmd\">arm-none-eabi-gcc -v\n</code></pre>\n<p>å¦‚æžœå‡ºçŽ°ç±»ä¼¼ä¸‹å›¾è¾“å‡ºï¼Œå°±ä»£è¡¨æˆåŠŸ</p>\n<p><img alt=\"image-20260220180204385\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220180204385.png\" /></p>\n<ol start=\"5\">\n<li>\n<p>æ‰“å¼€vscode è¿›å…¥åˆ°é¡¹ç›®æ–‡ä»¶å¤¹ï¼ˆå‰é¢åˆ›å»ºçš„cubemxé¡¹ç›®æ–‡ä»¶å¤¹ï¼‰</p>\n</li>\n<li>\n<p>ctrl + ï¼Œæ‰“å¼€è®¾ç½®ï¼Œæœç´¢stm32 for vscode<br />\n<img alt=\"image-20260220184204803\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184204803.png\" /><br />\nç‚¹å‡»åœ¨settings.jsonä¸­ç¼–è¾‘,å®Œå–„å¦‚ä¸‹è·¯å¾„</p>\n<p><img alt=\"image-20260220184315477\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184315477.png\" /><br />\nsettings.json(æ ¹æ®è‡ªå·±çš„è·¯å¾„é…ç½®)</p>\n<pre><code class=\"language-json\">{\n    \"stm32-for-vscode.openOCDPath\": \"C:\\\\stm32tools\\\\openocd\\\\0.12.0-7.1\\\\.content\\\\bin\\\\openocd.EXE\",\n    \"stm32-for-vscode.makePath\": \"C:\\\\stm32tools\\\\windows-build-tools\\\\4.4.1-3.1\\\\.content\\\\bin\\\\make.EXE\",\n    \"stm32-for-vscode.armToolchainPath\": \"C:\\\\stm32tools\\\\arm-none-eabi-gcc\\\\14.2.1-1.1.1\\\\.content\\\\bin\",\n    \"makefile.configureOnOpen\": true,\n    \"cortex-debug.stm32cubeprogrammer\": \"\",\n    \"cortex-debug.openocdPath\": \"C:\\\\stm32tools\\\\openocd\\\\0.12.0-7.1\\\\.content\\\\bin\\\\openocd.EXE\",\n    \"cortex-debug.armToolchainPath\": \"C:\\\\stm32tools\\\\arm-none-eabi-gcc\\\\14.2.1-1.1.1\\\\.content\\\\bin\",\n}\n</code></pre>\n</li>\n<li>\n<p>ctrl + ~</p>\n<p>åœ¨ç»ˆç«¯è¾“å…¥make -j12 æµ‹è¯•çœ‹çœ‹èƒ½å¦æˆåŠŸç¼–è¯‘,å¦‚ä¸‹å›¾å³ä»£è¡¨æˆåŠŸç¼–è¯‘</p>\n<p><img alt=\"image-20260220182335492\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220182335492.png\" /></p>\n</li>\n</ol>\n<h3 id=\"å…³äºŽlaunchjsonæ–‡ä»¶\">å…³äºŽlaunch.jsonæ–‡ä»¶</h3>\n<p>åœ¨å·¦è¾¹æ æ‰¾åˆ°è¿™ä¸ªå›¾æ ‡</p>\n<p><img alt=\"\" /></p>\n<p>ç‚¹å‡»ä¸€ä¸‹é‡Œé¢çš„åˆ›å»ºlaunchæ–‡ä»¶</p>\n<p>å°±å¯ä»¥åœ¨ç›®å½•çš„.vscodeæ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°</p>\n<p><img alt=\"image-20260220160146084\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220160146084.png\" /></p>\n<p>æˆ‘ä»¬ç›´æŽ¥å¤åˆ¶ä¸‹é¢æˆ‘ä¿®æ”¹å¥½çš„stlinkçš„ä»£ç ï¼ˆdaplinkã€jlinkæ¹–å¤§å¼€æºçš„giteeä»“åº“å·²ç»æä¾›ï¼‰</p>\n<pre><code class=\"language-json\">{\n    // å¯åŠ¨è°ƒè¯•çš„å¿«æ·é”®æ˜¯F5\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        // ä½¿ç”¨dap-link(å¦‚æ— çº¿è°ƒè¯•å™¨æ—¶çš„å‚è€ƒé…ç½®)\n        {\n            \"name\": \"STlink\",\n            \"cwd\": \"${workspaceRoot}\",\n            \"executable\": \"${workspaceRoot}\\\\build\\\\first.elf\", // è¦ä¸‹è½½åˆ°è°ƒè¯•å™¨çš„æ–‡ä»¶,èŠ±æ‹¬å·ä¸­çš„æ˜¯vscodeä¸¤ä¸ªé¢„å®šä¹‰çš„å‚æ•°\n            \"request\": \"launch\",\n            \"type\": \"cortex-debug\",\n            //ä½¿ç”¨J-link GDB Serveræ—¶å¿…é¡»;å…¶ä»–GBD Serveræ—¶å¯é€‰ï¼ˆæœ‰å¯èƒ½å¸®åŠ©è‡ªåŠ¨é€‰æ‹©SVDæ–‡ä»¶ï¼‰\n            //æ”¯æŒçš„è®¾å¤‡è§ https://www.segger.com/downloads/supported-devices.php\n            //svdæ–‡ä»¶ï¼Œæœ‰è¿™ä¸ªæ–‡ä»¶æ‰èƒ½æŸ¥çœ‹å¯„å­˜å™¨çš„å€¼ï¼Œæ¯ä¸ªå•ç‰‡æœºéƒ½ä¸åŒã€‚å¯ä»¥åœ¨ä»¥ä¸‹åœ°å€æ‰¾åˆ°https://github.com/modm-io/cmsis-svd-stm32 \n            //è¯¥é¡¹ç›®çš„æ ¹ç›®å½•å·²ç»æä¾›äº†Cåž‹å¼€å‘æ¿ä½¿ç”¨çš„å¤–è®¾svdæ–‡ä»¶\n            \"svdFile\": \"./STM32F103.svd\",\n            \"servertype\": \"openocd\", //ä½¿ç”¨çš„GDB Server\n            \"configFiles\": [\n                \"openocd_stlink.cfg\", // é…ç½®æ–‡ä»¶å·²ç»åœ¨æ ¹ç›®å½•æä¾›,è‹¥è¦ä¿®æ”¹ä»¥æ­¤ç±»æŽ¨,openocdçš„è·¯å¾„ä¸‹çš„share/scriptsä¸­æœ‰å„ç§å†™å¥½çš„é…ç½®æ–‡ä»¶\n            ],\n            \"runToEntryPoint\": \"main\", // è°ƒè¯•æ—¶åœ¨mainå‡½æ•°å…¥å£åœä¸‹\n            \"preLaunchTask\": \"build task\",//å…ˆè¿è¡ŒBuildä»»åŠ¡ç¼–è¯‘é¡¹ç›®,å–æ¶ˆæ³¨é‡Šå³å¯ä½¿ç”¨\n            \"liveWatch\": {\n                \"enabled\": true,\n                \"samplesPerSecond\": 4\n            }\n        },\n      \n    ],\n}\n</code></pre>\n<p>é…ç½®å®Œæˆä¹‹åŽåœ¨vscodeçš„å·¦ä¾§debugå›¾æ ‡å³å¯çœ‹åˆ°æ›´æ”¹é…ç½®çš„stlinkçš„é…ç½®<br />\n<img alt=\"image-20260220184555431\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184555431.png\" /></p>\n<h3 id=\"å…³äºŽtasksjsonæ–‡ä»¶\">å…³äºŽtasks.jsonæ–‡ä»¶</h3>\n<p>ä½ç½®ä¸Žlaunchæ–‡ä»¶ä¸€æ ·ï¼Œæ²¡æœ‰å°±æ–°å»ºä¸€ä¸ª</p>\n<pre><code class=\"language-json\">{\n    // See https://go.microsoft.com/fwlink/?LinkId=733558\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"build task\",         // ä»»åŠ¡æ ‡ç­¾\n            \"type\": \"shell\",               // ä»»åŠ¡ç±»åž‹,å› ä¸ºè¦è°ƒç”¨mingw32-make,æ˜¯åœ¨ç»ˆç«¯(CMD)é‡Œè¿è¡Œçš„,æ‰€ä»¥æ˜¯shellä»»åŠ¡\n            \"command\": \"make -j24\",// ä»»åŠ¡å‘½ä»¤,çº¿ç¨‹æ•°å¯ä»¥æ ¹æ®è‡ªå·±çš„ç”µè„‘ä¿®æ”¹,å»ºè®®ä¸Žcpuæ ¸æ•°ç›¸åŒ\n            \"problemMatcher\": [],          \n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        },\n        {\n            \"label\": \"download dap\",\n            \"type\": \"shell\",               // å¦‚æžœå¸Œæœ›åœ¨ä¸‹è½½å‰ç¼–è¯‘,å¯ä»¥æŠŠcommandæ¢æˆä¸‹é¢çš„å‘½ä»¤\n            \"command\":\"make -j24 ; make download_dap\", // \"mingw32-make -j24 ; mingw32-make download_dap\",\n            \"group\": {                     // å¦‚æžœæ²¡æœ‰ä¿®æ”¹ä»£ç ,ç¼–è¯‘ä»»åŠ¡ä¸ä¼šæ¶ˆè€—æ—¶é—´,å› æ­¤æŽ¨èä½¿ç”¨ä¸Šé¢çš„æ›¿æ¢.\n                \"kind\": \"build\",\n                \"isDefault\": false,\n            },\n        },\n        {\n            \"label\": \"download jlink\", // è¦ä½¿ç”¨æ­¤ä»»åŠ¡,éœ€æ·»åŠ jlinkçš„çŽ¯å¢ƒå˜é‡\n            \"type\": \"shell\",\n            \"command\":\"make -j24 ; make download_jlink\", // \"mingw32-make -j24 ; mingw32-make download_jlink\"\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": false,\n            }\n        },\n        {\n            \"label\": \"log\",\n            \"type\": \"shell\",\n            \"command\":\"JlinkRTTClient\",\n            \"args\": [],\n            \"problemMatcher\": [],\n            // \"dependsOn\":[\n            //     \"build task\", // å¯ä»¥æ·»åŠ å¤šä¸ª.\n            // ]\n            // è‹¥ä½¿ç”¨daplink,åˆ™å°†logä»»åŠ¡è®¾ç½®ä¸ºä¾èµ–äºŽjlink launchä»»åŠ¡,ä¿è¯jlink launchä»»åŠ¡å…ˆäºŽlogä»»åŠ¡æ‰§è¡Œ\n        }\n    ]\n}\n</code></pre>\n<h2 id=\"å¼€å§‹è°ƒè¯•\">å¼€å§‹è°ƒè¯•</h2>\n<p>åˆ°æ­¤é…ç½®åº”å½“å·²ç»å®Œæˆäº†ï¼ŒæŽ¥å¥½stlinkï¼Œè¿žæŽ¥å¥½stm32åŽå°±å¯ä»¥æ„‰å¿«çš„è°ƒè¯•å•¦ï¼Œç‚¹å‡»ç»¿è‰²çš„ä¸‰è§’å½¢å¼€å§‹ç¼–è¯‘å¹¶çƒ§å½•åˆ°å•ç‰‡æœº<br />\n<img alt=\"image-20260220184555431\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220184555431.png\" /></p>\n<p>ç­‰å¾…ä¸€ä¼šåŽï¼Œå°±ä¼šå‡ºçŽ°ä¸‹å›¾æ‰€ç¤ºçš„è°ƒè¯•ç•Œé¢<br />\n<img alt=\"image-20260220185452486\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185452486.png\" /><br />\nåœ¨å·¦ä¾§å°±æ˜¯è°ƒè¯•å¸¸ç”¨çš„ä¸€äº›å·¥å…·<br />\n<img alt=\"image-20260220185552784\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185552784.png\" /></p>\n<p>cortex live watchå¯ä»¥å®žæ—¶æŸ¥çœ‹å…¨å±€å˜é‡çš„å€¼ï¼Œåªéœ€è¦ç‚¹å‡»åŠ å·<br />\n<img alt=\"image-20260220185701085\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185701085.png\" /></p>\n<p>ç²˜è´´éœ€è¦æŸ¥çœ‹çš„å˜é‡åç§°</p>\n<p><img alt=\"image-20260220185726335\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185726335.png\" /></p>\n<p>å°±å¯ä»¥å®žæ—¶æŸ¥çœ‹åˆ°å˜é‡çš„å€¼å•¦</p>\n<p><img alt=\"image-20260220185758953\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185758953.png\" /></p>\n<p>ä»Žå·¦åˆ°å³ ç¬¬ä¸€ä¸ªæ˜¯é‡ç½®resetï¼Œæš‚åœï¼Œé€è¿‡ç¨‹ï¼Œå•æ­¥ï¼Œå•æ­¥è·³å‡ºï¼Œé‡æ–°å¼€å§‹è°ƒè¯•ï¼Œé€€å‡º</p>\n<p><img alt=\"image-20260220185836594\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220185836594.png\" /></p>\n<p>XPERIPHERALSå¿…é¡»é…ç½®ä¸Šé¢çš„svdæ–‡ä»¶æ‰èƒ½å¤Ÿçœ‹åˆ°å¯„å­˜å™¨å†…éƒ¨çš„å€¼</p>\n<p><img alt=\"image-20260220190044929\" src=\"http://tuchuang-cyy.oss-cn-beijing.aliyuncs.com/img/image-20260220190044929.png\" /></p>\n<p>ä½ ä¹Ÿå¯ä»¥ä¼˜é›…çš„ä½¿ç”¨copilotå·¥å…·æ›´å¿«é€Ÿçš„å¼€å‘stm32å•¦</p>\n<h3 id=\"stm32-svdæ–‡ä»¶\">stm32 svdæ–‡ä»¶</h3>\n<p>stmç³»åˆ—svdä»“åº“ï¼š</p>\n<p><a href=\"https://github.com/modm-io/cmsis-svd-stm32\" rel=\"noopener nofollow\" target=\"_blank\">modm-io/cmsis-svd-stm32: CMSIS SVD files for all STM32 devices</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-20 19:31</span>&nbsp;\n<a href=\"https://www.cnblogs.com/chenyouyuan\">ChenYY~</a>&nbsp;\né˜…è¯»(<span id=\"post_view_count\">42</span>)&nbsp;\nè¯„è®º(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">æ”¶è—</a>&nbsp;\n<a href=\"\">ä¸¾æŠ¥</a>\n</div>"
    }
  ]
}