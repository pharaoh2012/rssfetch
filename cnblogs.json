{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "AI开发-python-langchain框架（1-11 返回枚举-格式解析器）",
      "link": "https://www.cnblogs.com/yclh/p/19578042",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yclh/p/19578042\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 10:56\">\n    <span>AI开发-python-langchain框架（1-11 返回枚举-格式解析器）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>跟上一篇内容一样，这次我们来看如何限定大模型返回的结果值是枚举类型的。</p>\n<p>先看代码：</p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\"># 导入必要的模块\nfrom langchain.prompts import PromptTemplate          # 用于创建和管理提示模板\nfrom langchain_openai import ChatOpenAI               # 用于调用OpenAI兼容的聊天模型（如DeepSeek）\nfrom langchain.output_parsers.enum import EnumOutputParser  # 用于将LLM输出解析为枚举类型\nfrom enum import Enum                                 # Python标准库，用于定义枚举类型\nimport os                                             # 用于读取环境变量\n\n# 定义颜色枚举类，限定LLM输出必须为以下五种颜色之一\nclass Colors(Enum):\n    RED = \"红色\"\n    BROWN = \"棕色\"\n    BLACK = \"黑色\"\n    WHITE = \"白色\"\n    YELLOW = \"黄色\"\n\n# 创建枚举输出解析器，强制LLM输出必须匹配Colors枚举中的值\noutput_parser = EnumOutputParser(enum=Colors)\n\n# 获取格式化指令，告诉LLM如何正确格式化输出（例如：\"输出必须是：红色、棕色...\"）\nformat_instructions = output_parser.get_format_instructions()\nprint(format_instructions)  # 打印格式要求，用于调试或提示用户\nprint('###########')         # 分隔线\n\n# 创建提示模板：包含两个占位符 {person}（人物）和 {instructions}（输出格式要求）\npromptTemplate = PromptTemplate.from_template(\n    \"\"\"{person}的皮肤主要是什么颜色？\n{instructions}\"\"\"\n)\n\n# 固定instructions部分的内容，避免每次调用时重复传入\ninstructions = \"响应的结果请选择以下选项之一：红色、棕色、黑色、白色、黄色。\"\nprompt = promptTemplate.partial(instructions=instructions)  # partial用于预填充模板中的部分变量\n\n# 输出完整提示词示例（以\"亚洲人\"为例），用于调试查看实际发送给LLM的内容\nprint(prompt.invoke({\"person\": \"亚洲人\"}).text)\nprint('--------------')\n\n# 初始化聊天模型（使用DeepSeek API）\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),            # 从环境变量读取API密钥\n    base_url=os.getenv(\"BASE_URL\"),                   # 从环境变量读取API基础URL（如 https://api.deepseek.com）\n    model=\"deepseek-v3:671b\",                         # 指定使用的模型版本\n    temperature=0.7,                                  # 生成随机性控制：0.7 适中创造性\n    max_tokens=1024                                   # 单次响应最大token数\n)\n\n# 构建处理链：提示模板 → 大语言模型 → 枚举解析器\n# 实现端到端流程：生成提示 → 调用LLM → 强制输出为枚举类型\nchain = prompt | llm | output_parser\n\n# 调用链，传入\"亚洲人\"作为输入\nresult = chain.invoke({\"person\": \"亚洲人\"})\n\n# 输出解析后的结果（Enum类型）\nprint(result)        # 打印枚举对象（如：Colors.YELLOW）\nprint(result.name)   # 打印枚举成员名称（如：\"YELLOW\"）\nprint(result.value)  # 打印枚举成员值（如：\"黄色\"）\n</pre>\n</div>\n<p>&nbsp;返回值：</p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\">Select one of the following options: 红色, 棕色, 黑色, 白色, 黄色\n###########\n亚洲人的皮肤主要是什么颜色？\n响应的结果请选择以下选项之一：红色、棕色、黑色、白色、黄色。\n--------------\nColors.YELLOW\nYELLOW\n黄色\n</pre>\n</div>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 18pt;\"><strong>重点说明：</strong></span></p>\n<div class=\"response-message-content t2t phase-answer\">\n<div class=\"custom-qwen-markdown\">\n<div class=\"qwen-markdown\">\n<div class=\"qwen-markdown-paragraph\"><strong class=\"qwen-markdown-strong\"><span class=\"qwen-markdown-text\">精准控制大模型输出范围</span></strong><br /><span class=\"qwen-markdown-text\">本方案的核心目标是强制大语言模型返回预定义的枚举类型值，彻底解决自由文本输出的不确定性问题。通过结构化约束机制，确保模型响应严格限定在业务允许的选项集合内（如仅返回“红色、棕色、黑色、白色、黄色”），从源头杜绝“浅黄”“米白”等非标准值，显著提升系统可靠性与数据一致性。</span></div>\n<div class=\"qwen-markdown-space\">&nbsp;</div>\n<div class=\"qwen-markdown-paragraph\"><strong class=\"qwen-markdown-strong\"><span class=\"qwen-markdown-text\">双重约束保障输出合规性</span></strong><br /><span class=\"qwen-markdown-text\">枚举输出解析器（EnumOutputParser）构建前后端双重防护：前端通过<code class=\"qwen-markdown-codespan\" style=\"cursor: pointer;\">get_format_instructions()</code><span class=\"qwen-markdown-text\">自动生成格式指令并注入提示词，明确引导模型“仅可选择以下选项之一”；后端在解析阶段对返回结果进行强校验，任何超出枚举范围的值将立即抛出<code class=\"qwen-markdown-codespan\" style=\"cursor: pointer;\">OutputParserException</code><span class=\"qwen-markdown-text\">异常，形成从生成到解析的全链路约束。</span></span></span></div>\n<div class=\"qwen-markdown-space\">&nbsp;</div>\n<div class=\"qwen-markdown-paragraph\"><strong class=\"qwen-markdown-strong\"><span class=\"qwen-markdown-text\">枚举类型定义数据契约</span></strong><br /><span class=\"qwen-markdown-text\">通过Python的Enum类预先声明合法值集合（如<code class=\"qwen-markdown-codespan\" style=\"cursor: pointer;\">Colors</code><span class=\"qwen-markdown-text\">枚举），建立系统与模型之间的标准化数据契约。该设计不仅明确业务规则边界，更使模型输出直接转换为类型安全的枚举对象，开发者可直接通过<code class=\"qwen-markdown-codespan\" style=\"cursor: pointer;\">.name</code><span class=\"qwen-markdown-text\">（如\"YELLOW\"）和<code class=\"qwen-markdown-codespan\" style=\"cursor: pointer;\">.value</code><span class=\"qwen-markdown-text\">（如\"黄色\"）属性获取结构化结果，彻底规避字符串清洗与匹配的繁琐处理。</span></span></span></span></div>\n&nbsp;\n<div class=\"qwen-markdown-paragraph\"><strong class=\"qwen-markdown-strong\"><span class=\"qwen-markdown-text\">典型应用场景与业务价值</span></strong><br /><span class=\"qwen-markdown-text\">该方案特别适用于需严格输出控制的场景：情感分析限定{正面/中性/负面}、审批状态约束{待审/通过/拒绝}、颜色识别规范标准色系等。相比传统依赖正则表达式或关键词匹配的后处理方案，枚举控制从设计层面根除脏数据风险，降低90%以上的数据清洗成本，为关键业务系统提供确定性保障。</span></div>\n<div class=\"qwen-markdown-space\">&nbsp;</div>\n<div class=\"qwen-markdown-paragraph\"><strong class=\"qwen-markdown-strong\"><span class=\"qwen-markdown-text\">增强鲁棒性的实践建议</span></strong><br /><span class=\"qwen-markdown-text\">实际部署时建议结合重试机制提升容错能力：当模型首次输出不符合枚举要求时，自动触发2-3次重试并强化格式提示，成功率可达99%以上。对于金融、医疗等关键场景，可设置异常兜底策略——连续解析失败时自动转交人工审核，形成“自动约束+人工兜底”的完整质量保障闭环。</span></div>\n\n</div>\n\n</div>\n\n</div>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 10:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yclh\">万笑佛</a>&nbsp;\n阅读(<span id=\"post_view_count\">11</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "LVM动态扩容完全指南｜小白也能上手，零停机扩展磁盘空间（5种方法）",
      "link": "https://www.cnblogs.com/liuziyi1/p/19577932",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/liuziyi1/p/19577932\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 10:42\">\n    <span>LVM动态扩容完全指南｜小白也能上手，零停机扩展磁盘空间（5种方法）</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>做运维、搞服务器的小伙伴，肯定遇到过这种崩溃场景：</p>\n<p>半夜被告警惊醒，提示磁盘空间满了，MySQL、日志服务直接卡壳；想扩容，却发现传统磁盘分区一旦创建就固定大小，改起来又麻烦又容易丢数据……</p>\n<p>别慌！今天给大家带来 <strong>LVM动态扩容完全指南</strong>，从基础理论到实操步骤，全程通俗拆解，小白也能跟着一步步做，轻松实现「零停机扩容」，再也不用怕磁盘告警。</p>\n<p>先一句话搞懂LVM：它就像一个「磁盘魔术盒」，能把多块物理硬盘（或云盘）整合起来，变成一个统一的「存储水池」，后续扩容、缩容不用动底层硬盘，也不用停业务，灵活又安全。</p>\n<h1 id=\"一先搞懂lvm是什么为什么要用它\">一、先搞懂：LVM是什么？为什么要用它？</h1>\n<h2 id=\"11-核心背景小白必看\">1.1 核心背景（小白必看）</h2>\n<p>传统磁盘分区（比如/dev/sda1），创建时多大，后续就只能用多大，想扩容就得重新分区、格式化，不仅麻烦，还容易丢失数据，尤其生产环境根本不敢动。</p>\n<p>LVM（逻辑卷管理器）的出现，就是为了解决这个痛点——它在物理硬盘和文件系统之间加了一层「中间层」，把多块硬盘整合为一个「存储池」，空间可以自由分配、随时扩容，不用关心底层硬盘的边界。</p>\n<p>重点优势：<strong>零停机扩容</strong>，业务完全无感知；多硬盘整合，打破单盘容量限制；支持快照备份，数据更安全。</p>\n<h2 id=\"12-小白能懂的核心术语必记3个\">1.2 小白能懂的核心术语（必记3个）</h2>\n<p>LVM就像「水池系统」，记住这3个术语，后续操作不迷路：</p>\n<ul>\n<li>\n<p><strong>PV（物理卷）</strong>：最底层的「水源」，就是我们的物理硬盘（比如/dev/sdb）、云盘，是LVM管理的最小物理单元。</p>\n</li>\n<li>\n<p><strong>VG（卷组）</strong>：把多个PV整合起来的「大水池」，相当于把多块小硬盘合并成一个大存储池，统一管理空间。</p>\n</li>\n<li>\n<p><strong>LV（逻辑卷）</strong>：从VG「大水池」里分出来的「小水盆」，我们实际使用的磁盘空间（比如挂载到/var/lib/mysql的分区），就是LV。</p>\n</li>\n</ul>\n<p>简单类比：PV=多个小水桶，VG=把小水桶都倒进一个大水池，LV=从大水池里舀出的一碗水（我们实际用的）。扩容，就是给大水池加水（加PV），或者把碗变大（扩LV）。</p>\n<h2 id=\"13-适用场景看看你有没有需求\">1.3 适用场景（看看你有没有需求）</h2>\n<ul>\n<li>\n<p>数据库服务器（MySQL、PostgreSQL）：数据越存越多，需要在线扩容，不能停库。</p>\n</li>\n<li>\n<p>虚拟机/容器（KVM、K8s）：虚拟机磁盘不够用，容器持久化存储不足，需要灵活扩容。</p>\n</li>\n<li>\n<p>日志服务器（ELK）：日志量突增，磁盘很快满，需要快速扩容。</p>\n</li>\n<li>\n<p>普通服务器：多块小硬盘，想合并成一块大空间使用，后续方便扩容。</p>\n</li>\n</ul>\n<h2 id=\"14-环境要求提前准备避免踩坑\">1.4 环境要求（提前准备，避免踩坑）</h2>\n<p>不用记太复杂，满足这几个基础条件即可：</p>\n<ul>\n<li>\n<p>操作系统：CentOS 8+/Ubuntu 20.04+/Debian 11+（主流版本都支持）。</p>\n</li>\n<li>\n<p>安装LVM工具：系统一般默认安装，没有的话，下文有安装命令。</p>\n</li>\n<li>\n<p>磁盘：至少有1块未使用的硬盘/分区（或已扩容的云盘），用于扩容。</p>\n</li>\n</ul>\n<h1 id=\"二实操准备3步搞定前置工作必做\">二、实操准备：3步搞定前置工作（必做）</h1>\n<p>开始扩容前，先做好这3步，避免操作出错，小白也能轻松完成。</p>\n<h2 id=\"21-检查系统环境确认支持lvm\">2.1 检查系统环境（确认支持LVM）</h2>\n<p>复制下面的命令，依次执行，查看系统是否支持LVM（不用懂命令含义，执行就行）：</p>\n<pre><code class=\"language-bash\"># 检查操作系统版本\ncat /etc/os-release | grep -E \"^(NAME|VERSION)=\"\n\n# 检查LVM版本（有输出就是已安装）\nlvm version 2&gt;&amp;1 | head -5\n\n# 检查内核模块（确保LVM能正常工作）\nlsmod | grep -E \"^dm_\"\n\n# 若没有输出（模块未加载），执行下面2行命令加载\nmodprobe dm-mod\nmodprobe dm-snapshot\n</code></pre>\n<h2 id=\"22-安装lvm工具未安装则执行\">2.2 安装LVM工具（未安装则执行）</h2>\n<pre><code class=\"language-bash\"># CentOS/Rocky Linux（红帽系）\ndnf install -y lvm2 device-mapper-persistent-data\n\n# Ubuntu/Debian（debian系）\napt update &amp;&amp; apt install -y lvm2 thin-provisioning-tools\n\n# 验证安装（有输出就是安装成功）\npvs --version\n</code></pre>\n<h2 id=\"23-检查磁盘状态关键避免误操作\">2.3 检查磁盘状态（关键！避免误操作）</h2>\n<p>执行命令，查看当前磁盘情况，确认有未使用的磁盘（比如/dev/sdb，没有挂载点，没有文件系统）：</p>\n<pre><code class=\"language-bash\"># 列出所有磁盘，重点看「MOUNTPOINT」列（空的就是未使用）\nlsblk -o NAME,SIZE,TYPE,FSTYPE,MOUNTPOINT\n</code></pre>\n<p>输出示例（重点看sdb，未挂载、无文件系统，可用于扩容）：</p>\n<p>NAME SIZE TYPE FSTYPE MOUNTPOINT sda 50G disk ├─sda1 1G part xfs /boot └─sda2 49G part LVM2_member sdb 100G disk （未使用，可做PV）</p>\n<p>⚠️ 警告：一定要确认磁盘无数据、未挂载，否则操作会丢失数据！</p>\n<h1 id=\"三核心实操5种lvm扩容方法小白优先看前3种\">三、核心实操：5种LVM扩容方法（小白优先看前3种）</h1>\n<p>以下5种方法，覆盖不同场景，小白优先掌握「方法一、二、三」（最常用、最简单），方法四、五适合特定场景（虚拟化、备份存储）。</p>\n<p>所有命令都可以直接复制执行，重点看「步骤+注释」，不用死记命令含义。</p>\n<h2 id=\"方法一添加新磁盘最常用-新增硬盘云盘扩展vg再扩lv\">方法一：添加新磁盘（最常用）—— 新增硬盘/云盘，扩展VG再扩LV</h2>\n<p>场景：服务器新增物理硬盘，或云主机挂载新云盘（比如阿里云、腾讯云新增云盘），最通用的扩容方式。</p>\n<p>步骤（4步搞定，全程在线，不用停业务）：</p>\n<h3 id=\"步骤1创建pv把新磁盘变成水源\">步骤1：创建PV（把新磁盘变成「水源」）</h3>\n<pre><code class=\"language-bash\"># 把新磁盘（/dev/sdb）初始化为PV（替换成你的磁盘路径，比如/dev/sdc）\npvcreate /dev/sdb\n\n# 验证PV创建成功（有输出就是成功）\npvdisplay /dev/sdb\n</code></pre>\n<h3 id=\"步骤2扩展vg给大水池加水\">步骤2：扩展VG（给「大水池」加水）</h3>\n<pre><code class=\"language-bash\"># 把新创建的PV（/dev/sdb）加入现有的VG（替换成你的VG名称，比如vg_data）\n# 不知道VG名称？执行vgs命令查看\nvgextend vg_data /dev/sdb\n\n# 验证VG扩展成功（查看VG剩余空间，有新增空间就是成功）\nvgdisplay vg_data | grep -E \"(VG Size|Free)\"\n</code></pre>\n<h3 id=\"步骤3扩展lv把小水盆变大\">步骤3：扩展LV（把「小水盆」变大）</h3>\n<pre><code class=\"language-bash\"># 3种方式，选一种即可（替换成你的LV路径，比如/dev/vg_data/lv_mysql）\n# 方式1：扩展指定大小（比如新增50G）\nlvextend -L +50G /dev/vg_data/lv_mysql\n\n# 方式2：扩展到指定大小（比如扩展到150G）\nlvextend -L 150G /dev/vg_data/lv_mysql\n\n# 方式3：使用VG所有剩余空间（推荐，直接用满新增的空间）\nlvextend -l +100%FREE /dev/vg_data/lv_mysql\n\n# 验证LV扩展成功（查看LV大小，变大就是成功）\nlvdisplay /dev/vg_data/lv_mysql | grep \"LV Size\"\n</code></pre>\n<h3 id=\"步骤4扩展文件系统关键让系统识别新增空间\">步骤4：扩展文件系统（关键！让系统识别新增空间）</h3>\n<p>LV扩展后，系统还识别不到新增空间，需要执行下面的命令，根据你的文件系统类型选择（常见ext4、XFS）：</p>\n<pre><code class=\"language-bash\"># 情况1：文件系统是ext4（执行这个）\nresize2fs /dev/vg_data/lv_mysql\n\n# 情况2：文件系统是XFS（执行这个，替换成LV的挂载点，比如/data/mysql）\nxfs_growfs /data/mysql\n\n# 验证成功（查看挂载点空间，变大就是成功）\ndf -hT /data/mysql\n</code></pre>\n<p>✅ 完成：全程不用停业务，磁盘空间已经扩容成功！</p>\n<h2 id=\"方法二扩展现有磁盘云盘常用-云盘扩容后扩展现有pv\">方法二：扩展现有磁盘（云盘常用）—— 云盘扩容后，扩展现有PV</h2>\n<p>场景：云主机（阿里云、腾讯云）在控制台扩容了云盘（比如把50G云盘扩到100G），但系统里看不到新增空间，需要把新增空间纳入LVM管理。</p>\n<p>步骤（4步，不用加新磁盘，直接扩现有空间）：</p>\n<h3 id=\"步骤1确认云盘已扩容让系统识别新容量\">步骤1：确认云盘已扩容（让系统识别新容量）</h3>\n<pre><code class=\"language-bash\"># 重新扫描磁盘（云盘热扩容后必执行，让系统识别新容量）\necho 1 &gt; /sys/class/block/sdb/device/rescan\n\n# 确认磁盘新容量（查看磁盘大小，已经变成扩容后的大小就是成功）\nlsblk /dev/sdb\nfdisk -l /dev/sdb\n</code></pre>\n<h3 id=\"步骤2扩展磁盘分区让分区占用新增空间\">步骤2：扩展磁盘分区（让分区占用新增空间）</h3>\n<pre><code class=\"language-bash\"># 安装扩展工具（红帽系、debian系二选一）\ndnf install -y cloud-utils-growpart  # CentOS/Rocky Linux\napt install -y cloud-guest-utils     # Ubuntu/Debian\n\n# 扩展分区（替换成你的磁盘和分区，比如/dev/sdb的第1个分区）\ngrowpart /dev/sdb 1\n</code></pre>\n<h3 id=\"步骤3扩展pv让lvm识别分区的新增空间\">步骤3：扩展PV（让LVM识别分区的新增空间）</h3>\n<pre><code class=\"language-bash\"># 调整PV大小（替换成你的分区路径，比如/dev/sdb1）\npvresize /dev/sdb1\n\n# 验证成功（查看PV剩余空间，有新增空间就是成功）\npvdisplay /dev/sdb1 | grep -E \"(PV Size|Free PE)\"\n</code></pre>\n<h3 id=\"步骤4一键扩展lv和文件系统简化操作\">步骤4：一键扩展LV和文件系统（简化操作）</h3>\n<pre><code class=\"language-bash\"># 一条命令搞定：扩展LV，同时自动扩展文件系统（不用单独执行resize2fs/xfs_growfs）\nlvextend -r -l +100%FREE /dev/vg_data/lv_mysql\n</code></pre>\n<p>✅ 完成：云盘扩容后的空间，已经成功纳入LVM管理，业务无感知。</p>\n<h2 id=\"方法三一键扩容最简单-lvextend--r-一键搞定\">方法三：一键扩容（最简单）—— lvextend -r 一键搞定</h2>\n<p>场景：VG有剩余空间（比如之前加过PV，还有未分配空间），想快速扩容LV，不用分步执行。</p>\n<p>核心：利用LVM的「-r」参数，自动扩展LV+文件系统，一步到位。</p>\n<pre><code class=\"language-bash\"># 3种一键扩容方式，选一种即可（替换成你的LV路径）\n# 方式1：新增20G空间，自动扩展文件系统\nlvextend -r -L +20G /dev/vg_data/lv_mysql\n\n# 方式2：使用VG剩余空间的50%\nlvextend -r -l +50%FREE /dev/vg_data/lv_mysql\n\n# 方式3：使用VG所有剩余空间（推荐）\nlvextend -r -l +100%FREE /dev/vg_data/lv_mysql\n</code></pre>\n<p>✅ 完成：最简单的扩容方式，小白首选，避免分步操作出错。</p>\n<h2 id=\"方法四精简配置扩容虚拟化常用-thin-provisioning\">方法四：精简配置扩容（虚拟化常用）—— Thin Provisioning</h2>\n<p>场景：虚拟化环境（KVM、Proxmox）、容器存储，需要「超分配空间」（比如实际只有100G物理空间，却能创建200G的LV），按需分配实际空间，节省存储成本。</p>\n<p>步骤（简化版，小白了解即可，实操按需参考）：</p>\n<pre><code class=\"language-bash\"># 1. 创建精简池（thin pool，替换成你的VG名称）\nlvcreate -L 80G -T vg_data/thin_pool\n\n# 2. 创建精简卷（虚拟200G，实际按需分配）\nlvcreate -V 200G -T vg_data/thin_pool -n lv_vm_disk1\n\n# 3. 扩容精简池（当池空间不足时）\nlvextend -L +50G vg_data/thin_pool\n\n# 4. 扩容精简卷和文件系统\nlvextend -L +100G /dev/vg_data/lv_vm_disk1\nxfs_growfs /mnt/vm_disk1\n</code></pre>\n<h2 id=\"方法五vdo压缩扩容2026新特性-压缩去重节省空间\">方法五：VDO压缩扩容（2026新特性）—— 压缩去重，节省空间</h2>\n<p>场景：备份存储、虚拟机镜像（重复数据多的场景），利用LVM2 2.03.x新特性，实现数据压缩+去重，比如100G物理空间，可存储300G数据（3:1压缩比）。</p>\n<p>步骤（简化版，需LVM2 2.03.x以上版本）：</p>\n<pre><code class=\"language-bash\"># 1. 创建VDO池（100G物理空间，虚拟300G逻辑空间）\nlvcreate --type vdo -L 100G -V 300G -n vdo_pool vg_data\n\n# 2. 扩容VDO物理空间（新增50G）\nlvextend -L +50G vg_data/vdo_pool_vpool\n\n# 3. 扩容VDO逻辑空间（新增100G）\nlvextend -L +100G vg_data/vdo_pool\n\n# 4. 扩展文件系统\nxfs_growfs /mnt/vdo_storage\n</code></pre>\n<h1 id=\"四实战案例mysql数据库零停机扩容小白必看\">四、实战案例：MySQL数据库零停机扩容（小白必看）</h1>\n<p>结合方法一，实战演示「MySQL数据库在线扩容」，模拟生产环境最常见场景，跟着做就能搞定。</p>\n<h2 id=\"场景描述\">场景描述</h2>\n<p>生产环境MySQL服务器，数据目录/var/lib/mysql（挂载在/dev/vg_data/lv_mysql，100G，XFS文件系统），使用率达到85%，需要新增50G空间，不停止MySQL服务。</p>\n<p>环境：CentOS 9，MySQL 8.0，新增磁盘/dev/sdc（100G）。</p>\n<h2 id=\"实操步骤直接复制执行\">实操步骤（直接复制执行）</h2>\n<pre><code class=\"language-bash\"># 1. 确认当前磁盘使用率（查看是否真的满了）\ndf -hT /var/lib/mysql\n\n# 2. 确认MySQL服务正常运行（扩容不影响服务）\nsystemctl status mysqld\nmysql -e \"SHOW STATUS LIKE 'Uptime';\"\n\n# 3. 创建PV（新增磁盘/dev/sdc）\npvcreate /dev/sdc\n\n# 4. 扩展VG（加入现有vg_data）\nvgextend vg_data /dev/sdc\n\n# 5. 一键扩容LV+文件系统（新增50G）\nlvextend -r -L +50G /dev/vg_data/lv_mysql\n\n# 6. 验证扩容成功\ndf -hT /var/lib/mysql\n\n# 7. 确认MySQL服务正常（无中断）\nmysql -e \"SHOW STATUS LIKE 'Uptime';\"\n</code></pre>\n<p>✅ 结果：MySQL服务全程未中断，磁盘空间从100G扩展到150G，使用率从85%降到57%，完美解决磁盘告警。</p>\n<h1 id=\"五小白必看注意事项避坑指南重中之重\">五、小白必看：注意事项+避坑指南（重中之重）</h1>\n<p>LVM操作涉及底层存储，一步错可能丢数据，以下注意事项，一定要看完再操作！</p>\n<h2 id=\"51-核心警告必看\">5.1 核心警告（必看）</h2>\n<ul>\n<li>\n<p>⚠️ 所有操作前，<strong>务必备份数据</strong>！哪怕是在线扩容，也有极小概率出错，备份是最后保障（比如备份MySQL数据、重要文件）。</p>\n</li>\n<li>\n<p>⚠️ XFS文件系统「只能扩容，不能缩容」！规划LV大小时，尽量预留一定空间，避免后续想缩容却无法操作。</p>\n</li>\n<li>\n<p>⚠️ 不要误操作正在使用的磁盘！执行lsblk命令，确认磁盘未挂载、无数据，再进行PV创建。</p>\n</li>\n</ul>\n<h2 id=\"52-常见避坑点\">5.2 常见避坑点</h2>\n<ul>\n<li>\n<p>坑1：LV扩展后，df命令看不到新增空间 → 忘记扩展文件系统，执行resize2fs（ext4）或xfs_growfs（XFS）即可。</p>\n</li>\n<li>\n<p>坑2：云盘扩容后，系统看不到新容量 → 忘记执行磁盘扫描命令（echo 1 &gt; /sys/class/block/sdb/device/rescan）。</p>\n</li>\n<li>\n<p>坑3：vgextend命令失败 → 确认PV创建成功（pvdisplay查看），且VG名称正确（vgs命令查看）。</p>\n</li>\n</ul>\n<h2 id=\"53-最佳实践小白参考\">5.3 最佳实践（小白参考）</h2>\n<ul>\n<li>\n<p>创建VG时，指定PE大小为16MB或32MB（大容量存储更高效）：vgcreate -s 16M vg_data /dev/sdb。</p>\n</li>\n<li>\n<p>定期备份LVM元数据：vgcfgbackup vg_data（避免VG损坏，无法恢复）。</p>\n</li>\n<li>\n<p>监控VG剩余空间，当剩余空间低于10%时，提前扩容，避免磁盘满导致业务中断。</p>\n</li>\n</ul>\n<h1 id=\"六结尾总结命令速查表\">六、结尾总结+命令速查表</h1>\n<h2 id=\"61-核心总结\">6.1 核心总结</h2>\n<p>LVM动态扩容的核心逻辑：<strong>扩PV → 扩VG → 扩LV → 扩文件系统</strong>（一键扩容可跳过部分步骤）。</p>\n<p>小白重点掌握前3种方法（添加新磁盘、扩展现有磁盘、一键扩容），就能应对90%以上的扩容场景，全程零停机，业务无感知。</p>\n<h2 id=\"62-常用命令速查表小白收藏备用\">6.2 常用命令速查表（小白收藏，备用）</h2>\n<pre><code class=\"language-bash\"># PV操作（物理卷）\npvcreate /dev/sdb    # 创建PV\npvdisplay /dev/sdb   # 查看PV详情\npvs                  # 列出所有PV\n\n# VG操作（卷组）\nvgcreate vg_data /dev/sdb  # 创建VG\nvgextend vg_data /dev/sdc  # 扩展VG\nvgdisplay vg_data          # 查看VG详情\nvgs                        # 列出所有VG\n\n# LV操作（逻辑卷）\nlvcreate -L 50G -n lv_data vg_data  # 创建LV\nlvextend -r -L +20G /dev/vg_data/lv_data  # 一键扩容LV\nlvdisplay /dev/vg_data/lv_data            # 查看LV详情\nlvs                                       # 列出所有LV\n\n# 文件系统扩展\nresize2fs /dev/vg_data/lv_data  # ext4扩容\nxfs_growfs /data/mysql          # XFS扩容\n</code></pre>\n<p>💡 最后提醒：实操时，一定要替换成自己的磁盘路径（/dev/sdb）、VG名称（vg_data）、LV路径，避免复制错误！</p>\n<p>如果操作中遇到问题，评论区留言，我会一一解答，帮助大家避坑，轻松搞定LVM扩容～</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-02-05 10:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/liuziyi1\">刘子毅</a>&nbsp;\n阅读(<span id=\"post_view_count\">10</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "扣子Coze实战：混剪视频工作流，日产50条爆款，单月变现6位数（喂饭教程）",
      "link": "https://www.cnblogs.com/tangshiye/p/19577857",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tangshiye/p/19577857\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 10:30\">\n    <span>扣子Coze实战：混剪视频工作流，日产50条爆款，单月变现6位数（喂饭教程）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家好，我是汤师爷，专注AI智能体分享，致力于帮助100W人用智能体创富~</p>\n<p>混剪视频作为一种将多种素材拼接组合的创作形式，在抖音、视频号、小红书等平台上广受欢迎。</p>\n<p>传统的混剪制作需要耗费大量时间和精力：寻找素材、剪辑片段、添加特效、配音配乐……每一步都考验着创作者的耐心和技术。</p>\n<p>然而，AI技术的革新正在彻底改变这一切。</p>\n<p>你只需输入一个简单的主题，智能体就能自动为你生成一段混剪短视频，配上精美图片和匹配的音乐，一键完成从创意到成品的全过程。</p>\n<h2 id=\"1-什么是混剪视频\">1 什么是混剪视频</h2>\n<p>混剪视频是指将多个视频片段、图片或音频素材进行剪辑组合，创造出新的视频内容。</p>\n<p>随着Coze上线联动剪映功能，混剪视频制作正在进入自动化时代，为创作者带来巨大便利。</p>\n<p>图中展示了混剪视频的部分案例，它们呈现了AI自动化的特点：</p>\n<ol>\n<li>高效自动化处理：AI可以自动完成琐碎的剪辑工作，让创作者省下大量时间专注于项目策划和创意。</li>\n<li>批量素材产出：特别适用于抖音、小红书和视频号等平台上的养生、科普、心理、疗愈等垂直领域，可以自动化批量生产图片和视频素材。</li>\n<li>数据表现优异：通过AI辅助生成的混剪视频内容，往往能获得良好的点赞和收藏数据，具有较高的用户互动价值。</li>\n</ol>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>自动化混剪视频不仅提高了内容生产效率，还为创作者开辟了多种变现渠道：</p>\n<ol>\n<li>引流获客：通过优质内容吸引目标受众</li>\n<li>知识变现：通过教学传授技术</li>\n<li>工具变现：将搭建好的工作流作为产品销售</li>\n</ol>\n<p>混剪视频的自动化制作，正在重塑内容创作领域的生产方式，为创作者提供了更高效的工具和更广阔的商业可能。</p>\n<p>无论是个人创作者还是内容团队，都能借助这一技术降低制作成本，提升内容质量，在激烈的内容竞争中脱颖而出。</p>\n<h2 id=\"2-治愈老奶奶智能体\">2 治愈老奶奶智能体</h2>\n<p>在当今高压社会中，超过88%的年轻人长期承受压力。</p>\n<p>治愈系短视频作为一种\"电子安慰剂\"，正好满足了年轻人的心理需求，自然成为吸引流量的内容。</p>\n<p>这类视频之所以受欢迎，是因为它们能快速激活观众体内的多巴胺和血清素，带来即时的心理放松感。</p>\n<p>传统短视频制作过程繁琐费时，而现在借助AI技术，视频文案可以一键智能生成。</p>\n<p>我们可以创建一个治愈系老奶奶智能体，用于批量生成治愈系短视频。</p>\n<p>通过精心设计提示词和工作流，AI能自动生成符合治愈气质的文案、配音和分镜脚本。</p>\n<p>搭建治愈老奶奶智能体主要分为两个步骤：搭建工作流和设置智能体。</p>\n<h3 id=\"21-搭建工作流\"><strong>2.1 搭建工作流</strong></h3>\n<p>治愈老奶奶工作流的整体预览。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>工作流的整体执行流程如下：</p>\n<ol>\n<li>通过大模型生成高质量的语录文案</li>\n<li>将文案精确切分为简短句子，并清除所有空字符串</li>\n<li>使用大模型为每段文案创建匹配的配图描述</li>\n<li>利用AI图像生成技术，制作富有治愈感的老奶奶配图</li>\n<li>自动生成符合剪映格式的完整视频文件</li>\n</ol>\n<h3 id=\"22-设置智能体\">2.2 设置智能体</h3>\n<ol>\n<li>配置人设与交互逻辑：设置治愈老奶奶智能体的性格特点、回复风格和决策流程</li>\n<li>设置快捷指令：将工作流与智能体关联，实现特定任务的自动执行</li>\n<li>测试与发布：执行全面功能测试，确认各项功能正常后将智能体正式发布上线</li>\n</ol>\n<h2 id=\"3-搭建工作流\">3 搭建工作流</h2>\n<p>登录Coze官网，在“资源库-工作流”里新建一个空白工作流，取名“zhiyu_laonainai”。</p>\n<h3 id=\"31-配置开始节点\">3.1 配置开始节点</h3>\n<p>这里用于定义工作流启动时所需的输入参数。</p>\n<ul>\n<li>输入：\n<ul>\n<li>topic：治愈短视频主题</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"32-配置输出语录文案大模型节点\">3.2 配置“输出语录文案”大模型节点</h3>\n<p>我们通过大模型节点，输出语录文案。</p>\n<ul>\n<li>模型：豆包·1.5·Pro·32k</li>\n<li>输入：\n<ul>\n<li>input：选择开始节点的topic</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>系统提示词：</li>\n</ul>\n<pre><code class=\"language-markdown\">你是一位知心老奶奶，根据用户提出的话题，生成1段简短的感悟语录，极简风格，句子简短、治愈、有内涵。\n\n## 格式\n整句之前使用句号间隔，字数限制50字。\n\n## 限制\n直接输出语录文案。\n</code></pre>\n<p>接下来，配置用户提示词与输出变量。</p>\n<ul>\n<li>用户提示词：</li>\n</ul>\n<pre><code class=\"language-markdown\">主题：{{input}}\n</code></pre>\n<ul>\n<li>输出：\n<ul>\n<li>output：语录文案</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"33-配置文本处理节点\">3.3 配置“文本处理”节点</h3>\n<p>接下来，我们需要将语录文案精确切分为简短句子，我们添加“文本处理”节点。</p>\n<ul>\n<li>输入：\n<ul>\n<li>String：从“输出语录文案”大模型节点的输出中，选择output</li>\n<li>分隔符：选择句号、逗号、分号、感叹号、问号。</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"34-配置移除空字符串代码节点\">3.4 配置“移除空字符串”代码节点</h3>\n<p>将语录文案切分成短句后，我们需要通过代码节点移除空字符串，我们添加“代码”节点。如图所示。</p>\n<ul>\n<li>输入：\n<ul>\n<li>texts：从“文本处理”节点的输出中，选择output</li>\n</ul>\n</li>\n<li>输出：\n<ul>\n<li>textList：处理后的短句数组，类型为Array</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>处理文本的Python代码如下，它会清除数组中的空字符串并去除文本前后的空格：</p>\n<pre><code class=\"language-python\">async def main(args: Args) -&gt; Output:\n    params = args.params\n    texts = params.get('texts',\"\")\n    # 移除数组中可能存在的空字符串元素\n    texts = [t.strip() for t in texts if t.strip()]\n    ret: Output = {\n        \"textList\": texts\n    }\n    return ret\n</code></pre>\n<h3 id=\"35-配置配图文案大模型节点\">3.5 配置“配图文案”大模型节点</h3>\n<p>接下来，我们需要通过大模型节点生成配图文案。</p>\n<p>这个节点会将我们之前处理好的短句转化为详细的图像描述提示词，为下一步的图像生成做准备。</p>\n<p>在这一步，我们将使用批处理功能来高效地处理短句数组。如图所示。</p>\n<ul>\n<li>选择“批处理”标签</li>\n<li>模型：豆包·1.5·Pro·32k</li>\n<li>批处理：\n<ul>\n<li>text：从“移除空字符串”代码节点的输出中，选择textList变量</li>\n</ul>\n</li>\n<li>输入：\n<ul>\n<li>input：从“大模型配图文案”大模型节点的中，选择text变量</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>系统提示词：</li>\n</ul>\n<pre><code class=\"language-markdown\"># 角色\n你是一位经验丰富且亲切温暖的老奶奶语录视频剪映草稿生成专家，以老奶奶的身份，结合一只的猫咪，根据用户提供的文案和语境，创作出适合用于制作老奶奶语录视频剪映草稿的温馨绘画提示词。绘画提示词需呈现不同情景，输出内容限定为人物、动作和物品。\n\n## 技能\n### 技能 1: 生成绘画提示词\n1. 仔细分析用户提供的文案和语境。\n2. 基于分析结果，构思不同的温馨场景。\n3. 按照要求输出人物、动作和物品，形成绘画提示词。\n    - 示例：老奶奶坐在摇椅上，猫咪躺在脚边的毛毯上。\n    - 示例：老奶奶站在窗边，猫咪在窗台上蹭着她的手。\n    - 示例：老奶奶坐在暖暖的阳光下，手里拿着一本旧书，猫咪蜷在她膝盖上打盹儿\n    - 示例：老奶奶坐在暖暖的阳光下，手里拿着一本旧书，猫咪蜷在她膝盖上打盹儿\n    - 示例：老奶奶坐在打理花园，给花浇水\n4.每次只需要输出一条提示词。\n\n## 限制:\n- 仅围绕生成符合要求的绘画提示词进行回复，不回答其他无关问题。\n- 输出内容必须简洁呈现人物、动作和物品。\n</code></pre>\n<p>接下来，配置用户提示词与输出变量。</p>\n<ul>\n<li>用户提示词：</li>\n</ul>\n<pre><code class=\"language-markdown\">用户提供文案：{{input}}\n</code></pre>\n<ul>\n<li>输出：\n<ul>\n<li>output：配图文案</li>\n<li>outputList：配图文案数组</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"36-配置批处理节点\">3.6 配置“批处理”节点</h3>\n<p>接下来，我们使用批处理节点，批量生成治愈老奶奶图片。</p>\n<ul>\n<li>循环设置\n<ul>\n<li>并行运行数量：2</li>\n<li>批处理次数上线：100</li>\n</ul>\n</li>\n<li>输入：\n<ul>\n<li>promptList：从“大模型配图文案”大模型节点的输出中，选择outputList</li>\n<li>textList：从“移除空字符串”代码节点的输出中，选择textList变量</li>\n</ul>\n</li>\n<li>输出：\n<ul>\n<li>imageList：从“图像生成”节点的输出中，选择data，类型为Array<img />（需要先配置批处理体中的“图像生成”节点）</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"37-配置批处理体的图像生成节点\">3.7 配置批处理体的“图像生成”节点</h3>\n<p>接下来，我们配置批处理体的“图像生成”节点，新建“图像生成”节点。</p>\n<ul>\n<li>模型：通用-Pro</li>\n<li>比例\n<ul>\n<li>4:3(1024*768)</li>\n<li>宽1024；高768</li>\n</ul>\n</li>\n<li>输入：\n<ul>\n<li>prompt：从“批处理”节点的输出中，选择output</li>\n<li>text：从“批处理”节点的输出中，选择text</li>\n</ul>\n</li>\n<li>正向提示词：</li>\n</ul>\n<pre><code class=\"language-markdown\">纯色背景，上方留白，一位头发灰白、脸颊圆润的老奶奶，头顶写着“{{text}}”的文字内容，{{prompt}}，脸颊泛红、嘴角上扬露出愉悦笑容，整体画面色彩柔和温暖、线条简洁流畅，有着可爱温馨的卡通风格，简笔画，彩铅手绘，治愈系插画，富有童趣，笔触简单，有线条感。\n</code></pre>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"38-配置处理图片与音频代码节点\">3.8 配置“<strong>处理图片与音频</strong>”代码节点</h3>\n<p>接下来，我们需要添加一个\"代码\"节点来处理图片与音频，这是整个流程中的关键步骤。</p>\n<p>该节点将执行两项主要任务：首先，将批量生成的老奶奶图片整理为剪映可识别的数据结构；其次，配置背景音乐信息，确保视频有良好的听觉体验。</p>\n<ul>\n<li>输入：\n<ul>\n<li>imageList：从“批处理”节点的输出中，选择imageList</li>\n</ul>\n</li>\n<li>输出：\n<ul>\n<li>imgs：处理后的图片json数据结构，类型为String</li>\n<li>audio_infos：背景音乐的json数据结构，类型为String</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>处理文本的Python代码如下：</p>\n<pre><code class=\"language-python\">import json\nasync def main(args: Args) -&gt; Output:\n    params = args.params\n    # 构建输出对象\n    img_list = params.get(\"imageList\", [])\n    imgs = []\n\n    # 构建治愈老奶奶的图片输出结构\n    img_start = 0\n    for element in img_list:\n        start = img_start\n        end = img_start + 3000000  # 3秒\n        imgs.append({\n            \"image_url\": element,\n            \"width\": 1024,\n            \"height\": 768,\n            \"start\": start,\n            \"end\": end,\n            \"transition\": \"翻页\",\n            \"transition_duration\": 1000000  # 1秒\n        })\n        img_start = end\n\n    # 构建背景音乐的输出结构\n    total_duration = len(img_list) * 3000000\n    audio = [\n        {\n            \"audio_url\": params.get(\"audio_url\",\"https://vtang.oss-cn-hangzhou.aliyuncs.com/2025-10-06-lnn.mp3\"),\n            \"duration\": total_duration,\n            \"start\": 0,\n            \"end\": total_duration\n        }\n    ]\n\n    # 构建输出对象\n    ret = {\n        \"imgs\": json.dumps(imgs),\n        \"audio_infos\": json.dumps(audio) \n    }\n\n    return ret\n</code></pre>\n<h3 id=\"39-配置create_draft节点\">3.9 配置“create_draft”节点</h3>\n<p>我们使用“视频合成_剪映小助手”的create_draft工具，创建一个剪映草稿。</p>\n<ul>\n<li>输入：\n<ul>\n<li>height：草稿高度768</li>\n<li>width：草稿宽度1024</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"310-配置add_images节点\">3.10 配置“add_images”节点</h3>\n<p>我们使用\"视频合成_剪映小助手\"的add_images工具，为剪映草稿批量添加图片。</p>\n<ul>\n<li>输入：\n<ul>\n<li>draft_url：从“create_draft”节点的输出中，选择draft_url</li>\n<li>image_infos：从“处理图片与音频”节点的输出中，选择imgs</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"311-配置add_images节点\">3.11 配置“add_images”节点</h3>\n<p>我们使用\"视频合成_剪映小助手\"的add_images工具，为剪映草稿批量添加图片。</p>\n<ul>\n<li>输入：\n<ul>\n<li>draft_url：从“create_draft”节点的输出中，选择draft_url</li>\n<li>audio_infos：从“处理图片与音频”节点的输出中，选择audio_infos</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"312-配置add_audios节点\">3.12 配置“add_audios”节点</h3>\n<p>我们使用\"视频合成_剪映小助手\"的add_audios工具，为剪映草稿批量添加音频。</p>\n<ul>\n<li>输入：\n<ul>\n<li>draft_url：从“create_draft”节点的输出中，选择draft_url</li>\n<li>audio_infos：从“处理图片与音频”节点的输出中，选择audio_infos</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"313-配置save_draft节点\">3.13 配置“save_draft”节点</h3>\n<p>我们使用\"视频合成_剪映小助手\"的save_draft工具，保存剪映草稿。</p>\n<ul>\n<li>输入：\n<ul>\n<li>draft_url：从“create_draft”节点的输出中，选择draft_url</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"314-配置gen_video节点\">3.14 配置“gen_video”节点</h3>\n<p>我们使用\"视频合成_剪映小助手\"的gen_video工具，在云端渲染视频。</p>\n<ul>\n<li>输入：\n<ul>\n<li>api_token：API秘钥</li>\n<li>draft_url：从“create_draft”节点的输出中，选择draft_url</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"315-配置结束节点\">3.15 配置结束节点</h3>\n<p>最后，配置结束节点，输出剪映草稿、视频渲染地址。</p>\n<ul>\n<li>输出：\n<ul>\n<li>video_url：从“gen_video”节点的输出变量中，选择video_url</li>\n<li>draft_url：从“create_draft”节点的输出中，选择draft_url</li>\n<li>回答内容：</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"language-markdown\">剪映草稿：\n{{draft_url}}\n\n视频渲染地址：\n{{video_url}}\n</code></pre>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h2 id=\"4-设置智能体\">4 设置智能体</h2>\n<p>经过上述步骤的配置，我们已经完成了治愈老奶奶智能体的工作流设计。</p>\n<p>在本节中，我们将把这个工作流正式部署为一个可用的智能体。</p>\n<h3 id=\"41-新建智能体\">4.1 新建智能体</h3>\n<p>在Coze平台创建一个新的智能体，命名“视频数据复盘智能体”。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"41-设置人设与逻辑\">4.1 设置人设与逻辑</h3>\n<p>在人设与逻辑窗口中，配置智能体的处理逻辑。</p>\n<pre><code>当用户发送短视频主题后，使用{{zhiyu_laonainai}}工作流，生成治愈老奶奶短视频。\n</code></pre>\n<h3 id=\"41-绑定工作流\">4.1 绑定工作流</h3>\n<p>把“zhiyu_laonainai”工作流加进来，让智能体在合适的时机自动调用它。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"53-测试并发布\">5.3 测试并发布</h3>\n<p>最后，我们需要测试智能体是否能一键生成短视频。</p>\n<p>我们向智能体输入\"总是焦虑怎么办\"这个短视频主题，请求它生成一段治愈短视频。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>智能体处理完成后，会返回两个链接地址。我们只需复制视频渲染地址，在浏览器中打开，即可看到成功生成的短视频。确认正常后将智能体正式发布到生产环境。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<blockquote>\n<p>对了，我整理了一份开源的智能体学习手册，爆肝 10 万字，价值 999 元。限时开放领取👉：<a href=\"https://tangshiye.cn\" rel=\"noopener nofollow\" target=\"_blank\">tangshiye.cn</a></p>\n</blockquote>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/tangshiye/\" target=\"_blank\">AI架构师汤师爷</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/tangshiye/p/19577857\" target=\"_blank\">https://www.cnblogs.com/tangshiye/p/19577857</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 10:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tangshiye\">AI架构师汤师爷</a>&nbsp;\n阅读(<span id=\"post_view_count\">86</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "FastAPI生命周期管理实战：从启动到关闭，如何优雅地管好你的“资源家当”",
      "link": "https://www.cnblogs.com/ymtianyu/p/19577804",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19577804\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 10:23\">\n    <span>FastAPI生命周期管理实战：从启动到关闭，如何优雅地管好你的“资源家当”</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文深入讲解了FastAPI的Lifespan生命周期管理机制，详细分析了其工作原理，并提供了使用@asynccontextmanager的完整实战代码示例。重点总结了资源初始化、优雅关闭的实现方法，以及在实际使用中常见的四个“坑点”与解决方案，旨在帮助开发者构建更稳定、专业的FastAPI应用。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h2>FastAPI实战：你以为的启动与关闭，远不止开始和结束</h2>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">摘要：</strong>本文详细探讨了FastAPI的Lifespan（生命周期）管理，从为什么需要它、它的核心工作原理，到使用<span style=\"color: rgba(186, 55, 42, 1);\"><code>@asynccontextmanager</code></span>的最佳实践、常见“坑点”及解决方案。通过一个完整的实战示例，你将学会如何优雅地管理数据库连接池、配置加载等资源，确保应用稳定可控。</p>\n<hr />\n<p>有没有在部署FastAPI应用后，遇到过这些状况？👇</p>\n<p>→ 服务一重启，前几个请求总是失败，日志里飘着“数据库连接错误”。</p>\n<p>→ 想优雅地关闭，给下游服务发个通知，却发现请求直接被掐断，资源清理了个寂寞。</p>\n<p>→ 依赖项（比如配置、外部客户端）的初始化代码，散落在路由和中间件里，维护起来头大。</p>\n<p>这些都是用 <code style=\"color: rgba(186, 55, 42, 1);\">@app.on_event(\"startup\")</code> 和 <code style=\"color: rgba(186, 55, 42, 1);\">\"shutdown\"</code> 踩坑踩出来的经验（和眼泪）。今天，咱们就来聊聊它的正统接班人——<strong><span style=\"color: rgba(186, 55, 42, 1);\"><code>Lifespan</code></span></strong>，以及怎么用它写出更健壮、更专业的FastAPI应用。</p>\n<h2>🎯 第一部分：问题出在哪？从“餐厅”的混乱开业说起</h2>\n<p>想象一下你开了一家数字餐厅（你的FastAPI应用）。</p>\n<p>🙅 <strong>老做法（on_event）：</strong> 早上开业时间到了，厨师（数据库连接池）、服务员（配置）、采购员（HTTP客户端）才慌慌张张地各自开始准备。客人（请求）已经进门点菜了，厨师可能连锅都还没热。晚上打烊时，一声令下直接拉闸，采购员手里还在进行的订单、厨师没洗的锅，全都戛然而止。</p>\n<p>这，就是早期启动/关闭事件的异步问题，以及缺乏对“准备”和“清理”阶段的精细控制。</p>\n<p>FastAPI在较新的版本中，引入了<code style=\"color: rgba(186, 55, 42, 1);\">lifespan</code>参数，它是一个异步上下文管理器。它的核心思想是：<strong style=\"color: rgba(186, 55, 42, 1);\">在应用正式处理请求前，把所有“家当”都准备好；在应用退出前，有条不紊地收拾好所有“家当”。</strong></p>\n<p>这确保了在应用生命周期内，资源状态是确定的。</p>\n<h2>🧠 第二部分：核心原理与步骤，一个 yield 搞定所有</h2>\n<p><code style=\"color: rgba(186, 55, 42, 1);\">lifespan</code> 的原理，其实就是Python异步上下文管理器的经典模式：<code style=\"color: rgba(186, 55, 42, 1);\">__aenter__</code> 和 <code style=\"color: rgba(186, 55, 42, 1);\">__aexit__</code>。在FastAPI里，我们用一个<code style=\"color: rgba(186, 55, 42, 1);\">@asynccontextmanager</code>装饰器就能优雅实现。</p>\n<p>它的工作流超级清晰：</p>\n<div>\n<p> 1️⃣ <code style=\"color: rgba(186, 55, 42, 1);\">yield</code> 之前：启动逻辑。在这里连接数据库、加载配置、创建各种客户端。</p>\n<p> 2️⃣ <code style=\"color: rgba(186, 55, 42, 1);\">yield</code> 那一刻：应用进入“运行就绪”状态。此时所有资源都已初始化完毕，可以安全接收请求。</p>\n<p> 3️⃣ <code style=\"color: rgba(186, 55, 42, 1);\">yield</code> 之后：关闭逻辑。在这里关闭连接池、清理临时文件、发送关闭通知。</p>\n</div>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">重点：</strong> 所有在<code style=\"color: rgba(186, 55, 42, 1);\">yield</code>前初始化的对象，都可以通过<code style=\"color: rgba(186, 55, 42, 1);\">request.app.state</code>在整个应用范围内共享。这是依赖注入的“后勤总部”！</p>\n<h2>💻 第三部分：实战演示，手把手搭一个稳如老狗的应用</h2>\n<p>光说不练假把式，来看一个集成了Redis连接池和配置管理的实战例子。你完全可以直接复制，改改就能用。</p>\n<pre class=\"language-python highlighter-hljs\"><code>from contextlib import asynccontextmanager\nfrom fastapi import FastAPI, Depends, Request\nimport redis.asyncio as redis\n\n# 假装从环境或文件加载的配置\nAPP_CONFIG = {\"redis_url\": \"redis://localhost\", \"max_connections\": 10}\n\n# 这里是核心！定义 lifespan\n@asynccontextmanager\nasync def app_lifespan(app: FastAPI):\n    \"\"\"\n    应用生命周期管理\n    1. 启动：创建Redis连接池\n    2. 运行：保持\n    3. 关闭：清理连接池\n    \"\"\"\n    print(\"🚀 应用启动中...正在初始化资源\")\n    # --- 启动阶段 ---\n    # 初始化Redis连接池\n    try:\n        redis_pool = redis.ConnectionPool.from_url(\n            APP_CONFIG[\"redis_url\"],\n            max_connections=APP_CONFIG[\"max_connections\"],\n            decode_responses=True\n        )\n        app.state.redis_pool = redis_pool\n        app.state.config = APP_CONFIG  # 配置也存进去\n        print(\"✅ Redis连接池和配置初始化完成！\")\n    except Exception as e:\n        print(f\"❌ 资源初始化失败: {e}\")\n        # 这里一定要失败，不要让应用带着问题启动\n        raise\n\n    #  yield 标志着应用正式启动完成，开始接收请求\n    yield\n\n    # --- 关闭阶段 ---\n    print(\"\\n🛑 应用关闭中...正在清理资源\")\n    # 关闭Redis连接池\n    if hasattr(app.state, 'redis_pool'):\n        await app.state.redis_pool.disconnect()\n        print(\"✅ Redis连接池已关闭。\")\n    print(\"👋 资源清理完毕，应用安全退出。\")\n\n# 创建App，注入lifespan\napp = FastAPI(title=\"Lifespan Demo\", lifespan=app_lifespan)\n\n# 一个依赖项，用于在路由中方便地获取Redis连接\nasync def get_redis(request: Request):\n    # 直接从app.state获取连接池，并创建临时连接\n    async with redis.Redis(connection_pool=request.app.state.redis_pool) as client:\n        yield client\n\n# 示例路由\n@app.get(\"/cache/{key}\")\nasync def get_cache(key: str, redis = Depends(get_redis)):\n    value = await redis.get(key)\n    return {\"key\": key, \"value\": value}\n\n@app.post(\"/cache/{key}\")\nasync def set_cache(key: str, value: str, redis = Depends(get_redis)):\n    await redis.set(key, value, ex=60)  # 60秒过期\n    return {\"msg\": \"OK\"}\n\n@app.get(\"/config\")\nasync def show_config(request: Request):\n    # 直接访问全局配置\n    return request.app.state.config\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n    </code></pre>\n<p>跑起来之后，你会看到控制台先打印启动日志，Uvicorn工人就位后，应用才开始监听请求。用<code style=\"color: rgba(186, 55, 42, 1);\">Ctrl+C</code>关闭时，关闭逻辑也会被执行。</p>\n<h2>🚨 第四部分：常见坑点 &amp; 我的血泪经验</h2>\n<p>好了，代码跑通了，但下面这些才是保证你不上生产环境“演砸”的关键。</p>\n<div>\n<p><strong>🔥 坑点一：启动失败处理不当</strong></p>\n<p> - <strong>问题：</strong> 如果在<code style=\"color: rgba(186, 55, 42, 1);\">yield</code>之前初始化数据库失败了，你该怎么办？</p>\n<p> - <strong>我的教训：</strong> 千万别吞异常！就像上面代码里做的，必须<code style=\"color: rgba(186, 55, 42, 1);\">raise</code>出去，让应用启动失败。一个连不上数据库的应用，不如不启动。可以通过日志和监控系统及时告警。</p>\n</div>\n<div>\n<p><strong>🔥 坑点二：在lifespan里写“慢”逻辑</strong></p>\n<p> - <strong>问题：</strong> Lifespan的启动阶段会阻塞应用启动。如果你在这里跑一个耗时10分钟的数据同步任务，你的服务就10分钟不可用。</p>\n<p> - <strong>我的建议：</strong> 对于非核心、耗时的初始化（如预加载大数据模型），考虑在<code style=\"color: rgba(186, 55, 42, 1);\">yield</code>后，用后台任务异步执行。或者，设计成懒加载模式，在第一次请求时初始化。</p>\n</div>\n<div>\n<p><strong>🔥 坑点三：忽略异步上下文管理</strong></p>\n<p> - <strong>问题：</strong> 像数据库连接池、HTTP客户端这类资源，它们自己往往也需要<code style=\"color: rgba(186, 55, 42, 1);\">async with</code>来管理生命周期。</p>\n<p> - <strong>正确做法：</strong> 仔细阅读你用的客户端库文档。像上面redis的<code style=\"color: rgba(186, 55, 42, 1);\">ConnectionPool.disconnect()</code>，它就是异步的，必须<code style=\"color: rgba(186, 55, 42, 1);\">await</code>。同步客户端则通常在<code style=\"color: rgba(186, 55, 42, 1);\">.close()</code>。</p>\n</div>\n<div>\n<p><strong>🔥 坑点四：State滥用</strong></p>\n<p> - <strong>问题：</strong> <code style=\"color: rgba(186, 55, 42, 1);\">app.state</code>不是万能的储物间，它适合放<strong>全局、只读或线程/协程安全</strong>的对象。</p>\n<p> - <strong>警告：</strong> 别往里塞请求级别的数据，也别放频繁修改的全局变量，这会在多worker环境下让你怀疑人生。共享配置、连接池、初始化好的客户端实例，是它的最佳拍档。</p>\n</div>\n<h2>💎 最后啰嗦一句</h2>\n<p>使用<code style=\"color: rgba(186, 55, 42, 1);\">lifespan</code>，本质上是一种<strong style=\"color: rgba(186, 55, 42, 1);\">“契约编程”</strong>。你向框架承诺：“我会管好我带来的资源”；框架向你保证：“我会在正确的时间点给你执行管理的权利”。</p>\n<p>它让我们的应用从“能跑”进化到“跑得稳、关得优雅”。尤其是在云原生和容器化环境下，优雅启停是保证服务高可用的基础一环。</p>\n<p>希望这篇融合了我不少“坑”的文章，能帮你把FastAPI用得更加得心应手。如果你有更妙的用法或者也踩过有趣的坑，欢迎来聊聊！</p>\n<hr />\n<p style=\"text-align: center; color: rgba(127, 140, 141, 1); font-size: 0.9em;\">觉得有用就赶紧收藏吧，这种实战细节，下次配置新项目时翻出来看一眼，能省下不少查文档和Debug的时间。我是一名程序媛，我们下次见！👩💻</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 10:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Redis 事务的“原子性”迷思：为什么我们最终选择了 Lua 脚本",
      "link": "https://www.cnblogs.com/xzqcsj/p/19577555",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzqcsj/p/19577555\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 09:49\">\n    <span>Redis 事务的“原子性”迷思：为什么我们最终选择了 Lua 脚本</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"Redis 事务的“原子性”迷思：为什么我们最终选择了 Lua 脚本\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3703499/202602/3703499-20260205094823688-1305507315.png\" />\n        作为一个长期和关系型数据库（RDBMS）打交道的开发者，初次查阅 Redis 文档时，看到 MULTI、EXEC、DISCARD 这些指令，心中难免涌起一股由于熟悉而带来的安全感。\n我们的大脑会自动建立映射：MULTI 就是 BEGIN，EXEC 就是 COMMIT，DISCARD 就是 ROLLBACK。这套组合拳打下来，所有的业务逻辑似乎都应该具备了“不成功便成仁”的原子性保障。\n但这恰恰是 Redis 给我上的第一课：相似的命名背后，往往藏着截然不同的灵魂。 当你把 MySQL 的事务观生搬硬套到 Redis 身上时，错付就已经开始了。\n这篇文章将带你剥开 Redis 事务的外衣，从“原子性”的定义偏差说起，聊聊为什么在现代开发中，我们越来越倾向于用 Lua 脚本来替代它。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>写在前面的话</strong></p>\n<p>作为一个长期和关系型数据库（RDBMS）打交道的开发者，初次查阅 Redis 文档时，看到 <code>MULTI</code>、<code>EXEC</code>、<code>DISCARD</code> 这些指令，心中难免涌起一股由于熟悉而带来的安全感。</p>\n<p>我们的大脑会自动建立映射：<code>MULTI</code> 就是 <code>BEGIN</code>，<code>EXEC</code> 就是 <code>COMMIT</code>，<code>DISCARD</code> 就是 <code>ROLLBACK</code>。这套组合拳打下来，所有的业务逻辑似乎都应该具备了“不成功便成仁”的原子性保障。</p>\n<p>但这恰恰是 Redis 给我上的第一课：<strong>相似的命名背后，往往藏着截然不同的灵魂。</strong> 当你把 MySQL 的事务观生搬硬套到 Redis 身上时，错付就已经开始了。</p>\n<p>这篇文章将带你剥开 <strong>Redis 事务</strong>的外衣，从“原子性”的定义偏差说起，聊聊为什么在现代开发中，我们越来越倾向于<strong>用 Lua 脚本来替代它。</strong></p>\n</blockquote>\n<hr />\n<h2 id=\"一先把误会解开redis-事务不是-acid\">一、先把误会解开：Redis 事务不是 ACID</h2>\n<p><strong>在关系型数据库的世界里，“事务”二字重若千钧</strong>，它几乎等同于 <strong>ACID</strong>（原子性、一致性、隔离性、持久性）。我们习惯了“要么全有，要么全无”的安全感。</p>\n<p>而在 Redis 的世界里，<code>MULTI</code> 和 <code>EXEC</code> 更像是一个<strong>批处理信号</strong>：</p>\n<blockquote>\n<p><strong>把一堆命令先放进队列里排队，等到 <code>EXEC</code> 时，一次性、按顺序地执行它们。</strong></p>\n</blockquote>\n<p>这里有一个巨大的认知偏差。当我们谈论 Redis 的“原子性”时，Redis 指的其实是 <strong>隔离性（Isolation）</strong>，而不是 <strong>回滚（Rollback）</strong>。</p>\n<ul>\n<li><strong>它保证的是</strong>：<strong>我执行这段命令的时候，别人不能插队（独占执行）。</strong></li>\n<li><strong>它不保证的是</strong>：<strong>如果我执行到一半报错了，我会帮你把前面的操作撤销（失败回滚）。</strong></li>\n</ul>\n<p>为了更直观地理解，我们可以对比一下 Redis 事务和标准 ACID 事务的区别：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">关系型数据库 (MySQL)</th>\n<th style=\"text-align: left;\">Redis 事务</th>\n<th style=\"text-align: left;\">差异解读</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>原子性 (Atomicity)</strong></td>\n<td style=\"text-align: left;\"><strong>All or Nothing</strong> <br /> 失败即回滚，如同未发生过</td>\n<td style=\"text-align: left;\"><strong>All or Partial</strong> <br /> 没得商量，错了就错了，剩下的接着干</td>\n<td style=\"text-align: left;\">Redis 不支持 Rollback，部分成功是常态</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>一致性 (Consistency)</strong></td>\n<td style=\"text-align: left;\">强一致性 <br /> 约束必须满足</td>\n<td style=\"text-align: left;\">弱一致性 <br /> 依赖业务代码保障</td>\n<td style=\"text-align: left;\">Redis 不会校验业务约束（如外键、非空等）</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>隔离性 (Isolation)</strong></td>\n<td style=\"text-align: left;\">有多种隔离级别 (RC/RR/Serializable)</td>\n<td style=\"text-align: left;\"><strong>串行化执行</strong> <br /> 执行期间不可被打断</td>\n<td style=\"text-align: left;\">得益于单线程模型，<code>EXEC</code> 期间天然隔离</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>持久性 (Durability)</strong></td>\n<td style=\"text-align: left;\">WAL 日志保障 <br /> 掉电不丢失</td>\n<td style=\"text-align: left;\">取决于 AOF/RDB 配置</td>\n<td style=\"text-align: left;\">默认配置下通常有数据丢失风险</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p><strong>一句话总结：</strong><br />\n<strong>Redis 事务是“命令队列 + 独占执行”，绝不是“失败回滚 + 强一致”。</strong></p>\n</blockquote>\n<hr />\n<h2 id=\"二残酷的真相它真的不包回滚\">二、残酷的真相：它真的不包回滚</h2>\n<p>为了把这个概念刻进 DNA，我们看两种真实的错误场景。</p>\n<h3 id=\"1-入队时的低级错误全员连坐\">1. 入队时的“低级错误”（全员连坐）</h3>\n<p>如果你在<strong>命令入队阶段</strong>就犯了语法错误（比如参数写少了），Redis 还是讲道理的，它会直接拒绝整个事务。</p>\n<pre><code class=\"language-bash\">127.0.0.1:6379&gt; MULTI\nOK\n127.0.0.1:6379&gt; SET key1 value1\nQUEUED\n127.0.0.1:6379&gt; SET key2      # &lt;--- 语法错误：少了参数\n(error) ERR wrong number of arguments for 'set' command\n127.0.0.1:6379&gt; EXEC\n(error) EXECABORT Transaction discarded because of previous errors.\n</code></pre>\n<p>这时候，<strong>所有命令都不会执行</strong>。这符合我们对“事务”的预期。</p>\n<h3 id=\"2-执行时的运行时错误虽死犹进\">2. 执行时的“运行时错误”（虽死犹进）</h3>\n<p>这才是真正的坑。假设语法没问题，但在<strong>执行期间</strong>，某条命令因为数据类型不匹配报错了：</p>\n<pre><code class=\"language-bash\">127.0.0.1:6379&gt; MULTI\nOK\n127.0.0.1:6379&gt; SET user:A:points 100\nQUEUED\n127.0.0.1:6379&gt; LPUSH user:A:points \"error_data\"  # &lt;--- 对 String 类型做 List 操作，注定运行报错\nQUEUED\n127.0.0.1:6379&gt; INCR user:A:points                 # &lt;--- 后续命令\nQUEUED\n\n127.0.0.1:6379&gt; EXEC\n1) OK\n2) (error) WRONGTYPE Operation against a key holding the wrong kind of value  &lt;--- 报错！\n3) (integer) 101                                                              &lt;--- 依然成功了！\n</code></pre>\n<p><strong>目瞪口呆了吗？</strong><br />\n第二条命令报错了，但第三条命令依然欢快地执行了。数据出现了中间态：即所谓的“不一致”。</p>\n<p>Redis 官方对此的解释非常“直男”：</p>\n<blockquote>\n<p>“只有语法错误才会被拦截，运行时错误属于程序员的逻辑 Bug（比如把 String 当 List 用）。<strong>数据库不应该为了程序员的 Bug 买单，去搞复杂的回滚机制。</strong>”</p>\n</blockquote>\n<hr />\n<h2 id=\"三进阶之路从原生批量到-lua-脚本\">三、进阶之路：从原生批量到 Lua 脚本</h2>\n<blockquote>\n<p><strong>💡 预备知识：RTT 是性能杀手</strong></p>\n<p>一个 Redis 命令的执行可以简化为 4 步：<strong>发送命令 → 命令排队 → 命令执行 → 返回结果</strong>。</p>\n<p>其中，第 1 步和第 4 步的时间之和称为 <strong>RTT (往返时间)</strong>。如果我有 100 个命令，一个个发就需要 100 次 RTT，大部分时间都浪费在网络传输上。<br />\n<strong>批量操作的核心意义，就是把 100 次 RTT 压缩成 1 次。</strong></p>\n</blockquote>\n<p>既然 <code>MULTI/EXEC</code> 这么“头铁”，那我们在实际开发中到底该怎么选？我们可以把 Redis 的批量操作能力分为几个段位。</p>\n<h3 id=\"lv1-原生批量命令-mset--mget\">Lv1. 原生批量命令 (MSET / MGET)</h3>\n<p>这是最简单、最快的方式。</p>\n<ul>\n<li><strong>特点</strong>：原生的原子性。<code>MSET key1 val1 key2 val2</code> 是一个原子操作，<strong>要么都成功，要么都失败</strong>（在 Redis 层面）。</li>\n<li><strong>示例</strong>：<pre><code class=\"language-bash\">MSET key1 \"Hello\" key2 \"World\"\n</code></pre>\n</li>\n<li><strong>局限</strong>：只能处理同一种命令，逻辑死板。</li>\n</ul>\n<h3 id=\"lv2-管道-pipeline\">Lv2. 管道 (Pipeline)</h3>\n<p>当你需要批量执行几十个不同的命令，且不需要它们之间有逻辑依赖时，Pipeline 是首选。</p>\n<ul>\n<li><strong>特点</strong>：<strong>唯快不破</strong>。它把几十个命令打包，一次网络请求（RTT）发给服务器，服务器执行完再一次性返回。</li>\n<li><strong>形象理解</strong>：<strong>下 100 个单 -&gt; 一次性收 100 个快递 (1 次 RTT)</strong>。</li>\n<li><strong>与事务的区别</strong>：\n<ul>\n<li><strong>非原子性</strong>：Pipeline 只是打包发送，Redis 可能会在处理 Pipeline 中间穿插执行其他客户端的命令（交错执行）。</li>\n<li><strong>效率更高</strong>：不需要像事务那样每个命令都发一次，只需要发送一次。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"lv3-事务-multi--exec\">Lv3. 事务 (MULTI / EXEC)</h3>\n<p>比 Pipeline 多了一层保障：<strong>独占执行</strong>。</p>\n<ul>\n<li><strong>特点</strong>：<strong>原子操作（隔离性）</strong>。\n<ul>\n<li><strong>两个不同的事务不会同时运行</strong>。在 <code>EXEC</code> 执行期间，Redis 会“以此为尊”，保证没有其他客户端能插队。</li>\n</ul>\n</li>\n<li><strong>缺点</strong>：\n<ul>\n<li><strong>RTT 开销大</strong>：事务中 <strong>每个命令都需要单独发送</strong> 到服务端入队，请求次数并没有减少。</li>\n<li><strong>不支持回滚</strong>，不支持在事务中间做逻辑判断。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"lv31-事务--watch-乐观锁\">Lv3.1 事务 + WATCH (乐观锁)</h3>\n<p>单纯的 <code>MULTI/EXEC</code> 往往比较鸡肋，因为它无法感知中间状态。<strong>但这套机制唯一的“王牌”组合是配合 <code>WATCH</code> 命令，实现乐观锁 (CAS)。</strong></p>\n<ul>\n<li>\n<p><strong>场景</strong>：秒杀扣减库存。</p>\n<ul>\n<li>在 <code>MULTI</code> 之前 <code>WATCH stock</code>。</li>\n<li>如果在 <code>EXEC</code> 执行前 <code>stock</code> 被别人改了，整个事务原地取消（返回 nil）。</li>\n</ul>\n</li>\n<li>\n<p><strong>代码示例</strong>：</p>\n<pre><code class=\"language-bash\">WATCH stock:001                # 1. 监视库存\nGET stock:001                  # 2. 读库存，发现是 10\nMULTI                          # 3. 开启事务 (开始排队)\nDECR stock:001                 # 4. 减库存\nEXEC                           # 5. 执行\n# 如果在步骤 1-5 之间，别人改了 stock:001，这里会返回 (nil)，事务回滚。\n</code></pre>\n</li>\n<li>\n<p><strong>致命弱点</strong>：<strong>高并发下性能极差</strong>。</p>\n<ul>\n<li>就像一群人抢一个麦克风，一个人抢到了，其他人的 <code>CAS</code> 全部失败，只能客户端重试（自旋）。</li>\n<li><strong>竞争越激烈，重试越频繁，CPU 空转越严重。</strong></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"lv4-最终兵器--lua-脚本\">Lv4. 最终兵器 —— Lua 脚本</h3>\n<p>从 Redis 2.6 开始，Lua 脚本成为了解决复杂原子性问题的核心方案，它完美替代了 <code>WATCH</code> 事务。</p>\n<p><strong>为什么它比事务强？</strong></p>\n<ol>\n<li><strong>逻辑原子性</strong>：一段 Lua 脚本被视作一条命令。Redis 保证脚本执行期间，<strong>不会有任何其他脚本或命令插入</strong>。</li>\n<li><strong>效率更高</strong>：不需要像 <code>WATCH</code> 那样反复重试。脚本在服务器端执行，只有一次 RTT。</li>\n</ol>\n<p><strong>示例：安全的“先查后改”</strong></p>\n<pre><code class=\"language-lua\">-- 判断 key 是否等于预期值，如果是则删除\nif redis.call(\"GET\", KEYS[1]) == ARGV[1] then\n    return redis.call(\"DEL\", KEYS[1])\nelse\n    return 0\nend\n</code></pre>\n<p><strong>⚠️ 必须警惕的缺陷：Lua 也不回滚！</strong><br />\n虽然 Lua 脚本被称为“原子操作”，但请注意：它的原子性依然指的是<strong>不被打扰</strong>，而不是<strong>失败回滚</strong>。</p>\n<blockquote>\n<p><strong>如果 Lua 脚本运行到中途出错（比如调用了不存在的命令，或显式报错退出），脚本会停止执行，但之前已经执行过的写操作，是不会被撤销的！</strong></p>\n</blockquote>\n<p>这意味着，即使是 Lua，也不能给你带来 RDBMS 那种“回滚一切”的安全感。你依然需要在代码层面保证逻辑的严密性。</p>\n<hr />\n<h2 id=\"四总结选型决策表\">四、总结：选型决策表</h2>\n<p>为了让你在实际业务中不再纠结，我整理了一份简单的决策表：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">需求场景</th>\n<th style=\"text-align: left;\">推荐方案</th>\n<th style=\"text-align: left;\">核心理由</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>简单批量读写 (KV)</strong></td>\n<td style=\"text-align: left;\"><strong>MSET / MGET</strong></td>\n<td style=\"text-align: left;\">原生命令，最快，最省心。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>大量离散命令 (无关联)</strong></td>\n<td style=\"text-align: left;\"><strong>Pipeline</strong></td>\n<td style=\"text-align: left;\">网络开销最低，吞吐量最高。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>需要 CAS (低并发)</strong></td>\n<td style=\"text-align: left;\"><strong>WATCH + MULTI</strong></td>\n<td style=\"text-align: left;\"><strong>事务唯一的用武之地。</strong> 适合低频竞争，实现简单。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>复杂逻辑 / 高并发</strong></td>\n<td style=\"text-align: left;\"><strong>Lua 脚本</strong></td>\n<td style=\"text-align: left;\"><strong>行业标准。</strong> 避免了 CAS 自旋的性能开销，原子性强。</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>即使报错也要回滚</strong></td>\n<td style=\"text-align: left;\"><strong>MySQL / RDBMS</strong></td>\n<td style=\"text-align: left;\"><strong>别为难 Redis。</strong> 它没有 Undo Log，做不到真正的回滚。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"写在最后\">写在最后</h2>\n<p>回头看，<strong>Redis 事务这套机制，就像是一个“如果不仔细读说明书一定会用错”的半成品。</strong></p>\n<p>但正是这个“半成品”，折射出了 Redis 最底层的价值观：<strong>为了性能，可以牺牲一切“看起来很美”的抽象</strong>。它拒绝了沉重的 Undo Log，拒绝了复杂的隔离级别，只留下了一个最简单的“排队执行”逻辑。</p>\n<p>所以，当我们下次再写下 <code>MULTI</code> 的时候，心里要清楚：</p>\n<ul>\n<li>如果只是为了快，<strong>Pipeline</strong> 才是那个不讲武德的“加速器”。</li>\n<li>如果只是为了防插队，<strong>Transaction</strong> 够用了，但在高并发下，它脆弱得像个易碎品。</li>\n<li>如果要处理真正的复杂逻辑，请毫不犹豫地拥抱 <strong>Lua</strong> —— 虽然它也不会回滚，但至少在“执行原子性”上，它是我们手里最稳的那张牌。</li>\n</ul>\n<p>真正的技术成熟，不是背诵八股文里的 ACID 定义，而是懂得在<strong>由于物理限制而满是遗憾的真实世界里</strong>，做出那个最不坏的选择。</p>\n<hr />\n<blockquote>\n<p>文章的最后，想和你多聊两句。</p>\n<p>技术之路，常常是热闹与孤独并存。那些深夜的调试、灵光一闪的方案、还有踩坑爬起后的顿悟，如果能有人一起聊聊，该多好。</p>\n<p>为此，我建了一个小花园——我的微信公众号「<strong>[努力的小郑]</strong>」。</p>\n<p>这里没有高深莫测的理论堆砌，只有我对后端开发、系统设计和工程实践的持续思考与沉淀。它更像我的<strong>数字笔记本</strong>，记录着那些值得被记住的解决方案和思维火花。</p>\n<p>如果你觉得今天的文章还有一点启发，或者单纯想找一个同行者偶尔聊聊技术、谈谈思考，那么，欢迎你来坐坐。<br />\n<img alt=\"85f114bceb12e933bb817ec5fecdfef7\" class=\"lazyload\" /></p>\n<p>愿你前行路上，总有代码可写，有梦可追，也有灯火可亲。</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 09:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzqcsj\">一旅人</a>&nbsp;\n阅读(<span id=\"post_view_count\">107</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从Prompt工程到Skill工程：Agent Skills开放标准彻底改变了AI协作方式",
      "link": "https://www.cnblogs.com/zlt2000/p/19577443",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/zlt2000/p/19577443\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 09:20\">\n    <span>从Prompt工程到Skill工程：Agent Skills开放标准彻底改变了AI协作方式</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><img alt=\"0-封面\" class=\"lazyload\" /></p>\n<h2 id=\"一为什么-agent-skill-突然火了\">一、为什么 Agent Skill 突然火了？</h2>\n<p>你是不是也有过这样的崩溃时刻？</p>\n<ul>\n<li>每次让 <code>Claude</code> 写代码，都要重复粘贴 <strong>请使用我们的代码规范：驼峰命名、2空格缩进、必须写单元测试</strong> ——像极了每天入职新公司；</li>\n<li>好不容易调教好的 <code>Prompt</code> 换个项目就完全失效，之前的调教经验归零；</li>\n<li>团队里每个人给 AI 的指令不一样，导致输出的内容一会儿像资深架构师，一会儿像刚毕业的新手。</li>\n</ul>\n<p>这些问题的根源，其实是 <code>AI</code> 的 <strong>专业能力无法沉淀</strong>。直到 2025 年 10 月 <code>Anthropic</code> 推出 <code>Agent Skill</code>（又名 Claude Code Skill）正是为解决这些问题而生。这不仅是 <code>Claude</code> 的新功能，更是一个 <strong>开放的跨平台标准</strong>，目前已被 <code>OpenAI</code>、<code>Cursor</code>、<code>Trae</code> 等主流工具跟进支持。</p>\n<p>本文将带你从 <strong>是什么</strong> 到 <strong>怎么用在实际工作中</strong>，彻底掌握这个比 <code>Prompt</code> 更高级、比 <code>MCP</code> 更易用的 <code>AI</code> 编程神器。</p>\n<p>&nbsp;</p>\n<h2 id=\"二到底什么是-agent-skill\">二、到底什么是 Agent Skill？</h2>\n<p>用最通俗的比喻：<code>Agent Skill</code> 是 <code>AI</code> 的 <strong>入职手册 + 工具箱</strong>。</p>\n<p>想象你招了一位天才实习生 <code>Claude</code> 他智商极高但不懂你们公司的业务。传统的做法是每次布置任务都口头交代一遍 <code>Prompt</code> 而 <code>Agent Skill</code> 则是给他一本完整的标准作业程序 <code>SOP</code>：</p>\n<ul>\n<li>📋 入职手册（SKILL.md）：包含岗位描述、工作流程、注意事项</li>\n<li>🧰 工具箱（Scripts）：处理特定任务的脚本和代码</li>\n<li>📚 参考资料（References）：行业规范、模板素材、API文档</li>\n</ul>\n<p>技术本质：<code>Agent Skill</code> 是一个标准化的文件夹结构，核心必须包含 <code>SKILL.md</code> 文件（YAML元数据 + Markdown说明），可选包含脚本、模板等资源文件。</p>\n<pre><code>my-skill/            # 技能包根目录\n├── SKILL.md         # 📄 核心文件：元数据 + 工作流指令（必须）\n├── scripts/         # 🔧 可选：自动化脚本（Python/Bash）\n├── references/      # 📖 可选：专业文档、API手册、FAQ\n└── assets/          # 🎨 可选：模板、示例、静态资源\n</code></pre>\n<p>当 <code>AI</code> 检测到相关任务时，会自动 <strong>翻开</strong> 对应的手册，严格按照既定流程执行，无需你每次都重复交代。</p>\n<p>&nbsp;</p>\n<h2 id=\"三skill工作原理\">三、Skill工作原理</h2>\n<p><code>Skill</code> 最精妙的设计，是它的 <strong>渐进式加载机制</strong> —— 就像你查字典，先看目录，再翻对应章节，最后查附录，不会一上来就把整本书塞进脑子里。</p>\n<h3 id=\"31-三层加载用最少的-token-做最多的事\">3.1. 三层加载：用最少的 Token 做最多的事</h3>\n<p><img alt=\"1-核心机制\" class=\"lazyload\" /></p>\n<table>\n<thead>\n<tr>\n<th>加载层级</th>\n<th>内容类型</th>\n<th>加载时机</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>L1</td>\n<td>元数据（名片）</td>\n<td>Agent 启动时自动加载</td>\n<td>让AI知道“有什么技能可用”</td>\n</tr>\n<tr>\n<td>L2</td>\n<td>说明文档（正文）</td>\n<td>匹配用户需求时加载</td>\n<td>教AI“具体怎么做”</td>\n</tr>\n<tr>\n<td>L3</td>\n<td>资源文件（脚本 / 模板）</td>\n<td>执行中按需加载</td>\n<td>提供“工具/素材支持”</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"32-四步执行流程\">3.2. 四步执行流程</h3>\n<p><img alt=\"2-执行流程\" class=\"lazyload\" /></p>\n<ol>\n<li>🎯 意图匹配：AI 扫描所有 Skill 的元数据，找到最匹配当前任务的技能</li>\n<li>📖 读取指南：加载对应 SKILL.md，掌握执行步骤、检查点、输出规范</li>\n<li>🔧 按需执行：调用 scripts/ 中的脚本，查询 references/ 中的资料</li>\n<li>✅ 反馈结果：按模板输出成果，或询问缺失信息</li>\n</ol>\n<p>&nbsp;</p>\n<h2 id=\"四现有技术的对比\">四、现有技术的对比</h2>\n<h3 id=\"41-agent-skill-vs-prompt\">4.1. Agent Skill vs Prompt</h3>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>普通 Prompt</th>\n<th>Agent Skill</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>性质</strong></td>\n<td>临时指令，用完即走</td>\n<td>标准化流程，永久复用</td>\n</tr>\n<tr>\n<td><strong>加载方式</strong></td>\n<td>每次全量输入</td>\n<td>按需渐进加载</td>\n</tr>\n<tr>\n<td><strong>稳定性</strong></td>\n<td>依赖模型\"记忆\"，易漂移</td>\n<td>固化检查点，强制执行</td>\n</tr>\n<tr>\n<td><strong>管理</strong></td>\n<td>分散在聊天记录里</td>\n<td>文件化、版本可控</td>\n</tr>\n<tr>\n<td><strong>共享</strong></td>\n<td>复制粘贴，易丢失格式</td>\n<td>整包分享，开箱即用</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>一句话总结：Prompt 是 <strong>口头交代</strong>，Skills 是<strong>书面 SOP + 工具箱</strong>。</p>\n</blockquote>\n<h3 id=\"42-agent-skill-vs-多-agent-架构\">4.2. Agent Skill vs 多 Agent 架构</h3>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>多 Agent 架构</th>\n<th>Agent Skill</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>复杂度</strong></td>\n<td>重量级，需要架构设计</td>\n<td>轻量级，单个文件夹即可</td>\n</tr>\n<tr>\n<td><strong>适用场景</strong></td>\n<td>复杂并行任务（如研究+写作+审核同时进行）</td>\n<td>单领域深度任务（如专业代码审查）</td>\n</tr>\n<tr>\n<td><strong>资源消耗</strong></td>\n<td>高，需调度多个 Agent 实例</td>\n<td>低，单 Agent 内能力切换</td>\n</tr>\n<tr>\n<td><strong>启动成本</strong></td>\n<td>需要搭建 Agent 框架</td>\n<td>零成本，复制文件夹即可</td>\n</tr>\n<tr>\n<td><strong>关系</strong></td>\n<td>体系级解决方案</td>\n<td>单元级能力模块，可被多 Agent 调用</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"43-agent-skill-vs-mcp\">4.3. Agent Skill vs MCP</h3>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>MCP</th>\n<th>Agent Skill</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>定位</strong></td>\n<td>连接协议：AI 与外部系统的\"USB 接口\"</td>\n<td>执行标准：AI 做事的\"操作手册\"</td>\n</tr>\n<tr>\n<td><strong>解决的问题</strong></td>\n<td><strong>能不能连</strong>（访问数据库、API、文件系统）</td>\n<td><strong>怎么做</strong>（流程、规范、最佳实践）</td>\n</tr>\n<tr>\n<td><strong>技术形态</strong></td>\n<td>需要运行 MCP Server（TypeScript/Python）</td>\n<td>静态文件夹（Markdown + 脚本）</td>\n</tr>\n<tr>\n<td><strong>加载时机</strong></td>\n<td>启动时建立连接</td>\n<td>按需渐进加载</td>\n</tr>\n<tr>\n<td><strong>关系</strong></td>\n<td><strong>互补</strong>：MCP 提供“工具”</td>\n<td>Skills 提供“使用指南”</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>MCP 让 AI 能连上数据库，Skill 教 AI 怎么按你们公司的规范查数据、生成报表、处理异常。两者配合，AI 才能真正成为\"懂行的专家\"。</p>\n</blockquote>\n<p>&nbsp;</p>\n<h2 id=\"五创建你的第一个-agent-skill\">五、创建你的第一个 Agent Skill</h2>\n<p>下面用 <code>会议纪要整理助手</code> 为例，从零创建一个 Skill</p>\n<p><strong>场景</strong>：开会录音转文字后，需要整理成结构化会议纪要。不同会议类型（周会/项目复盘/客户沟通）需要不同的整理模板。</p>\n<h3 id=\"51-创建-skill-文件夹结构\">5.1. 创建 Skill 文件夹结构</h3>\n<p>新建一个名为 <code>meeting-minutes</code> 的文件夹，总体的文件结构如下：</p>\n<pre><code>/meeting-minutes/\n├── SKILL.md                    # L1：技能元数据，L2：内容\n├── references/                 # L3：按会议类型按需加载\n│   ├── weekly-rule.md          # 周会模板\n│   ├── retro-rule.md           # 复盘模板\n│   └── client-rule.md          # 客户沟通模板\n</code></pre>\n<h3 id=\"52-skillmd核心文件\">5.2. SKILL.md（核心文件）</h3>\n<h4 id=\"521-元数据\">5.2.1. 元数据</h4>\n<p>在 <code>SKILL.md</code> 文件最开头以上下两个 <code>---</code> 作为元数据标识</p>\n<pre><code class=\"language-markdown\">---\nname: meeting-minutes\ndescription: 办公室通用会议纪要整理助手，支持周会/项目复盘会/客户沟通会三类场景，自动识别会议类型，按需加载对应会议规则，智能提取关键信息，输出结构化纪要。\n---\n</code></pre>\n<h4 id=\"522-skill内容\">5.2.2. SKILL内容</h4>\n<p><img alt=\"3-编写SKILL\" class=\"lazyload\" /></p>\n<h3 id=\"53-编写模块化配置references\">5.3. 编写模块化配置references</h3>\n<p><img alt=\"4-编写模块化配置references\" class=\"lazyload\" /></p>\n<blockquote>\n<p>通过文件分离，AI每次只读取当前任务所需的规则，避免 Context 污染</p>\n</blockquote>\n<h3 id=\"54-测试你的-skill以-trae-为例\">5.4. 测试你的 Skill（以 Trae 为例）</h3>\n<p><code>Trae</code> 作为国内的 <code>AI IDE</code> 已原生支持 <code>Agent Skills</code></p>\n<ul>\n<li>\n<p>官网：<code>https://www.trae.cn/</code></p>\n</li>\n<li>\n<p>下载并安装 <code>TRAE IDE</code></p>\n</li>\n</ul>\n<h4 id=\"541-导入skill\">5.4.1. 导入Skill</h4>\n<ol>\n<li>创建一个文件夹，例如 <code>my_skills</code></li>\n<li>使用 <code>TRAE IDE</code> 打开这个文件夹</li>\n<li>将 <code>meeting-minutes</code> 文件夹复制到 my_skills/.trae/skills/ 目录下</li>\n</ol>\n<h4 id=\"542-输入提示词\">5.4.2. 输入提示词</h4>\n<p>需要切换为 <code>SOLO</code> 模式，然后在对话框输入以下提示词：</p>\n<pre><code class=\"language-bash\">帮我生成周会会议纪要\n\n原始文本：\n小明：用户模块我搞完了，已经提测。\n小红：接口文档我还没弄，我负责写，周五前给出来。\n张三：测试环境那个问题搞不定，需要运维老陈帮忙看看。\n李四：下周我打算开始订单模块，周三前出个技术方案看看。\n王五：数据库设计谁review一下？\n小明：我来吧，不过得明天才有空。\n</code></pre>\n<h4 id=\"543-执行skill\">5.4.3. 执行Skill</h4>\n<p><img alt=\"5-trae执行过程\" class=\"lazyload\" /></p>\n<h4 id=\"544-最终输出以下内容\">5.4.4. 最终输出以下内容</h4>\n<p><img alt=\"6-执行效果\" class=\"lazyload\" /></p>\n<p>&nbsp;</p>\n<h2 id=\"六本文skill下载地址\">六、本文Skill下载地址</h2>\n<p>本文案例 <code>会议纪要整理助手</code> Skill 的下载地址如下：</p>\n<ul>\n<li>Gitee地址：</li>\n</ul>\n<p><a href=\"https://gitee.com/zlt2000/my-agent-skill/tree/master/meeting-minutes\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/zlt2000/my-agent-skill/tree/master/meeting-minutes</a></p>\n<ul>\n<li>Github地址：</li>\n</ul>\n<p><a href=\"https://github.com/zlt2000/my-agent-skill/tree/master/meeting-minutes\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/zlt2000/my-agent-skill/tree/master/meeting-minutes</a></p>\n<blockquote>\n<p>在实际使用过程中本文 Skill 还可以进行以下迭代优化：</p>\n<ol>\n<li>在 <code>references</code> 里扩展更多的 <strong>会议类型</strong> 模板；</li>\n<li>在 <code>script</code> 文件夹写 <code>Python</code> 脚本，实现输出内容 <strong>导出word文档</strong> 或者 <strong>同步给飞书</strong>。</li>\n</ol>\n</blockquote>\n<p>&nbsp;</p>\n<h2 id=\"七总结\">七、总结</h2>\n<p><code>Agent Skills</code> 的正式发布，标志着 AI 协作从 <strong>提示词工程</strong> 正式迈入 <strong>技能工程</strong> 的全新范式。它将人类专家的经验、标准化流程与行业最佳实践，封装成 <code>AI</code> 可理解、可执行、可复用的数字资产。</p>\n<p>核心价值优势：</p>\n<ol>\n<li><strong>降本增效：</strong> 通过渐进式披露、按需加载机制，大幅减少 Token 消耗，同时让 AI 聚焦核心任务，推理效率与执行稳定性同步提升；</li>\n<li><strong>跨平台互通：</strong> 作为开放标准，实现 “一次构建、多端复用”，Skill 可无缝适配 Claude、Cursor、Trae、Copilot 等主流平台，打破工具壁垒；</li>\n<li><strong>Skill 市场：</strong> 构建起类似 VS Code 插件市场的 Skill 生态，官方与社区共同打造技能商店，让专业能力可分享、可迭代、可规模化应用。</li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 09:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/zlt2000\">zlt2000</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Obsidian × Claudian × Skills：打造真正会“思考”的个人知识库",
      "link": "https://www.cnblogs.com/bugshare/p/19577439",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/bugshare/p/19577439\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 09:19\">\n    <span>Obsidian × Claudian × Skills：打造真正会“思考”的个人知识库</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在上一篇文章 <strong>《Obsidian 使用指南：从零开始搭建你的个人知识库》</strong> 中，我们介绍了 Obsidian 的基础使用方式：<br />\n如何用 Markdown 记录知识、用双链组织思路、逐步搭建属于自己的知识体系。</p>\n<p>但问题也随之而来：</p>\n<blockquote>\n<p><strong>当笔记越来越多，它们真的“活”起来了吗？</strong></p>\n</blockquote>\n<p>最近一段时间，<strong>Claude Code + Skills</strong> 在开发者圈子里非常火🔥<br />\n它不仅是一个 AI 聊天工具，而是一个<strong>可以理解上下文、执行技能、参与协作的 AI 编程与思考助手</strong>。</p>\n<p>那么问题来了：</p>\n<blockquote>\n<p><strong>Obsidian 能不能接入 Claude Code？<br />\n让 AI 不只是“帮你写”，而是真正参与“思考”和“整理知识”？</strong></p>\n</blockquote>\n<p>答案是：<strong>可以，而且体验非常好。</strong></p>\n<p>本文将带你一步步完成：</p>\n<ul>\n<li>在 Obsidian 中接入 <strong>Claude Code</strong></li>\n<li>通过 <strong>Claudian 插件</strong>，把 Claude 变成你的<strong>AI 协作助手</strong></li>\n<li>利用 <strong>Skills</strong>，让 AI 直接参与笔记编辑、重构与思考</li>\n</ul>\n<hr />\n<h1 id=\"为什么要把-claude-接入-obsidian\">为什么要把 Claude 接入 Obsidian？</h1>\n<p>在开始之前，先说清楚<strong>这套组合解决什么问题</strong>。</p>\n<p>传统 AI + 笔记的方式，通常是：</p>\n<ul>\n<li>复制一段内容</li>\n<li>打开网页 / Chat 客户端</li>\n<li>让 AI 帮你改写 / 总结</li>\n<li>再粘贴回来</li>\n</ul>\n<p>而 <strong>Obsidian × Claude Code × Skills</strong> 的核心价值在于：</p>\n<h2 id=\"-ai-就在你的知识库里工作\">✅ AI 就在你的知识库里工作</h2>\n<ul>\n<li>不需要来回切换窗口</li>\n<li>直接理解你当前笔记内容</li>\n<li>在<strong>原地进行内联编辑</strong></li>\n</ul>\n<h2 id=\"-claude-code--skills--普通聊天\">✅ Claude Code + Skills ≠ 普通聊天</h2>\n<ul>\n<li>能调用 <strong>Skill（技能）</strong></li>\n<li>能执行复杂指令（重写、拆解、结构化、补充）</li>\n<li>更像一个「<strong>协作伙伴</strong>」，而不是问答机器人</li>\n</ul>\n<h2 id=\"-非侵入式完全本地友好\">✅ 非侵入式、完全本地友好</h2>\n<ul>\n<li>Obsidian 仍然是你的本地 Markdown</li>\n<li>Claude 只是“参与编辑”，不劫持你的数据结构</li>\n</ul>\n<hr />\n<h1 id=\"claudian-插件介绍\">Claudian 插件介绍</h1>\n<p>实现这一切的关键，就是 <strong>Claudian 插件</strong>。</p>\n<blockquote>\n<p>GitHub：<br />\n<a href=\"https://github.com/YishenTu/claudian\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/YishenTu/claudian</a></p>\n</blockquote>\n<p><strong>Claudian 是什么？</strong></p>\n<ul>\n<li>一个 Obsidian 桌面端插件</li>\n<li>用于连接 <strong>Claude Code CLI</strong></li>\n<li>支持 <strong>Claude Code 的 Skills 体系</strong></li>\n<li>可在 Obsidian 内直接与 Claude 交互、编辑文本</li>\n</ul>\n<p>一句话总结：</p>\n<blockquote>\n<p><strong>Claudian = 把 Claude Code 搬进 Obsidian。</strong></p>\n</blockquote>\n<hr />\n<h1 id=\"使用前的要求\">使用前的要求</h1>\n<p>在安装前，请确保你的环境满足以下条件：</p>\n<ul>\n<li>\n<p>✅ 已安装 <a href=\"https://code.claude.com/docs/en/overview\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code CLI</a><br />\n👉 <strong>强烈建议使用 Native Install</strong></p>\n</li>\n<li>\n<p>✅ Obsidian <strong>v1.8.9+</strong></p>\n</li>\n<li>\n<p>✅ 拥有支持 <strong>Anthropic API 格式</strong> 的 Claude 订阅 / API Key<br />\n或使用以下兼容平台之一：</p>\n<ul>\n<li><a href=\"https://openrouter.ai/docs/guides/guides/claude-code-integration\" rel=\"noopener nofollow\" target=\"_blank\">OpenRouter</a></li>\n<li><a href=\"https://platform.moonshot.ai/docs/guide/agent-support\" rel=\"noopener nofollow\" target=\"_blank\">Kimi（月之暗面）</a></li>\n<li><a href=\"https://docs.z.ai/devpack/tool/claude\" rel=\"noopener nofollow\" target=\"_blank\">GLM（智谱 BigModel）</a></li>\n<li><a href=\"https://api-docs.deepseek.com/guides/anthropic_api\" rel=\"noopener nofollow\" target=\"_blank\">DeepSeek</a></li>\n</ul>\n</li>\n<li>\n<p>✅ <strong>仅支持桌面端</strong>（macOS / Linux / Windows）</p>\n</li>\n</ul>\n<blockquote>\n<p>如果你对 Claude Code、Skills、或智谱模型的接入还不熟悉，可以先参考我之前的两篇文章：</p>\n<ul>\n<li>《Claude Code × 智谱 BigModel 实战集成指南》</li>\n<li>《Claude Code 支持重磅扩展 Skills》</li>\n</ul>\n</blockquote>\n<hr />\n<h1 id=\"claudian-插件安装手动\">Claudian 插件安装（手动）</h1>\n<p>目前 Claudian <strong>尚未上架 Obsidian 社区市场</strong>，需要手动安装。</p>\n<h2 id=\"1️⃣-下载插件文件\">1️⃣ 下载插件文件</h2>\n<p>前往 GitHub Releases 页面，下载最新版本：</p>\n<p>👉 <a href=\"https://github.com/YishenTu/claudian/releases/latest\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/YishenTu/claudian/releases/latest</a></p>\n<p>需要以下三个文件：</p>\n<ul>\n<li><code>main.js</code></li>\n<li><code>manifest.json</code></li>\n<li><code>styles.css</code></li>\n</ul>\n<hr />\n<h2 id=\"2️⃣-创建插件目录\">2️⃣ 创建插件目录</h2>\n<p>在你的 Obsidian Vault 中，创建插件目录：</p>\n<pre><code class=\"language-text\">/path/to/vault/.obsidian/plugins/claudian/\n</code></pre>\n<hr />\n<h2 id=\"3️⃣-拷贝文件\">3️⃣ 拷贝文件</h2>\n<p>将下载的三个文件复制到 <code>claudian</code> 文件夹中。</p>\n<hr />\n<h2 id=\"4️⃣-在-obsidian-中启用插件\">4️⃣ 在 Obsidian 中启用插件</h2>\n<p>路径如下：</p>\n<ul>\n<li><strong>设置 → 社区插件</strong></li>\n<li>启用 <strong>Claudian</strong></li>\n</ul>\n<p><img alt=\"PixPin_2026-02-01_18-40-08.png\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"启用-claudian-插件\">启用 Claudian 插件</h1>\n<p>如果插件没有立刻显示，可以：</p>\n<ul>\n<li>设置 → 第三方插件</li>\n<li>点击 <strong>刷新</strong></li>\n<li>启用 <strong>Claudian</strong></li>\n</ul>\n<p><img alt=\"PixPin_2026-02-01_18-41-08.png\" class=\"lazyload\" /></p>\n<hr />\n<h1 id=\"配置-claude--模型环境\">配置 Claude / 模型环境</h1>\n<p>进入插件设置：</p>\n<p><strong>设置 → Claudian → Environment（环境）</strong></p>\n<p>这里可以配置 Claude API，也可以配置你在前文中使用过的 <strong>智谱 BigModel（GLM）</strong>。</p>\n<p>示例配置如下：</p>\n<pre><code class=\"language-conf\">ANTHROPIC_API_KEY=your api key\nANTHROPIC_BASE_URL=https://open.bigmodel.cn/api/anthropic\nANTHROPIC_MODEL=glm-4.7\n</code></pre>\n<p><img alt=\"PixPin_2026-02-01_19-14-11.png\" class=\"lazyload\" /></p>\n<blockquote>\n<p>💡 Claudian 的优势之一就在于：<br />\n<strong>它不限定官方 Claude，只要兼容 Anthropic API 即可。</strong></p>\n</blockquote>\n<hr />\n<h1 id=\"在-obsidian-中使用-claude\">在 Obsidian 中使用 Claude</h1>\n<p>完成配置后，就可以正式开始使用了。</p>\n<h2 id=\"基础使用方式\">基础使用方式</h2>\n<ol>\n<li>点击 Obsidian 左侧功能区的 🤖 机器人图标<br />\n或使用 <strong>命令面板</strong> 打开 Claude 聊天窗口</li>\n<li>在笔记中 <strong>选中一段文本</strong></li>\n<li>使用快捷键，让 Claude <strong>直接进行内联编辑</strong></li>\n</ol>\n<p><img alt=\"PixPin_2026-02-01_19-18-15.png\" class=\"lazyload\" /></p>\n<p>这一步的体验非常关键：</p>\n<blockquote>\n<p><strong>AI 不再是“给你建议”，而是“直接帮你改文档”。</strong></p>\n</blockquote>\n<hr />\n<h1 id=\"skills让-claude-真正会干活\">Skills：让 Claude 真正“会干活”</h1>\n<p>Claudian 最大的亮点之一，就是 <strong>完整支持 Claude Code 的 Skills</strong>。</p>\n<p>在输入框中输入 <code>/</code>，即可弹出：</p>\n<ul>\n<li>可用命令</li>\n<li>已注册的 Skills</li>\n</ul>\n<p><img alt=\"PixPin_2026-02-01_19-28-15.png\" class=\"lazyload\" /></p>\n<p>这意味着什么？</p>\n<p>你可以在 Obsidian 里直接让 Claude：</p>\n<ul>\n<li>重构一篇技术文章</li>\n<li>拆解复杂概念</li>\n<li>生成大纲 / TODO / 知识卡片</li>\n<li>统一文档风格</li>\n<li>把“零散笔记”整理成“系统知识”</li>\n</ul>\n<p><strong>这已经不是简单的 AI 辅助写作，而是 AI 协作编辑。</strong></p>\n<hr />\n<h1 id=\"写在最后\">写在最后</h1>\n<p>如果说：</p>\n<ul>\n<li><strong>Obsidian</strong> 解决的是「<strong>知识如何存储与连接</strong>」</li>\n<li>那么 <strong>Claude Code + Skills</strong> 解决的就是「<strong>知识如何被持续加工与进化</strong>」</li>\n</ul>\n<p>而 <strong>Claudian 插件</strong>，正好把这两件事无缝连接在一起。</p>\n<blockquote>\n<p>从此你的 Obsidian 不只是笔记库，而是一个<br />\n<strong>可以被 AI 参与思考、不断演化的个人知识系统。</strong></p>\n</blockquote>\n<p>如果你觉得这篇文章有帮助，欢迎 <strong>点赞 / 转发 / 收藏</strong>。<br />\n我们下篇见。 👋</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 09:19</span>&nbsp;\n<a href=\"https://www.cnblogs.com/bugshare\">BugShare</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "基于 Starlight 文档站点接入 Microsoft Clarity 的完整实践指南",
      "link": "https://www.cnblogs.com/newbe36524/p/19577415",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19577415\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 09:13\">\n    <span>基于 Starlight 文档站点接入 Microsoft Clarity 的完整实践指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"从数据洞察到用户增长hagicode-博客接入-clarity-analytics-的完整指南\">从数据洞察到用户增长：HagiCode 博客接入 Clarity Analytics 的完整指南</h1>\n<blockquote>\n<p>本文将分享如何在 Starlight 文档站点中优雅地接入 Microsoft Clarity，不仅能看清用户行为，还能确保隐私合规。这套方案是我们在 HagiCode 项目中实践总结出来的，希望能给同样在折腾数据统计的你一点参考。</p>\n</blockquote>\n\n<h2 id=\"背景为什么我们需要-clarity\">背景：为什么我们需要 Clarity？</h2>\n<p>以下代码展示了如何在 Astro 集成中根据环境变量动态注入 Microsoft Clarity 脚本，仅在生效时进行生产环境加载。</p>\n\n<pre><code class=\"language-markdown\">105 | interface Props {\n106 |   // 未来可扩展: 允许手动覆盖 Project ID\n107 |   projectId?: string;\n108 | }\n109 | \n110 | const {\n111 |   projectId = import.meta.env.CLARITY_PROJECT_ID,\n112 | } = Astro.props;\n113 | \n114 | const isProduction = import.meta.env.PROD;\n115 | ---\n116 | \n117 | {isProduction &amp;&amp; projectId &amp;&amp; (\n118 |   &lt;script is:inline define:vars={{projectId}}&gt;\n119 |     (function(c,l,a,r,i,t,y){\n</code></pre>\n<p><em>文件：<code>openspec/changes/archive/2026-01-30-microsoft-clarity-integration/design.md</code></em></p>\n<p>在运营 <strong>HagiCode</strong> 的过程中，我们一直面临一个\"盲盒\"问题：我们产出内容，但不清楚用户是如何阅读的。虽然 GitHub 能看到 Star 数，但这太滞后了。我们需要知道：</p>\n<ul>\n<li>用户到底有没有看完我们的教程？</li>\n<li>那些复杂的配置文档，是在哪一步劝退了用户的？</li>\n<li>我们的 SEO 优化是否真的带来了有效流量？</li>\n</ul>\n<p>市面上有很多分析工具，比如 Google Analytics（GA）和 Microsoft Clarity。GA 功能强大但配置复杂，且受到隐私法规（如 GDPR）的严格限制。而 Clarity 作为微软推出的免费热力图工具，不仅功能直观，而且在隐私合规上相对宽松，非常适合技术文档站点。</p>\n<p><strong>我们的目标很明确</strong>：在 <strong>HagiCode</strong> 的文档站点中无缝集成 Clarity，既要在所有页面生效，又要给用户留有\"退出\"的权利（隐私合规）。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<p>HagiCode 主题初始化逻辑：优先读取本地存储，回退至系统偏好，默认暗色。</p>\n\n<pre><code class=\"language-markdown\">67 | function getInitialTheme(): Theme {\n68 |   // 1. 检查 localStorage\n69 |   const stored = localStorage.getItem('hagicode-theme');\n70 |   if (stored) return stored as Theme;\n71 | \n72 |   // 2. 检测系统偏好\n73 |   const systemDark = window.matchMedia('(prefers-color-scheme: dark)').matches;\n74 |   if (systemDark) return 'dark';\n75 | \n76 |   // 3. 默认暗色\n77 |   return 'dark';\n78 | }\n79 | ```\n80 | \n81 | ### 决策 3：主题应用方式\n82 | \n83 | **选择**：在 `&lt;html&gt;` 根元素设置 `data-theme` 属性\n84 | \n85 | **对比方案**：\n86 | \n</code></pre>\n<p><em>文件：<code>openspec/changes/archive/2026-01-29-theme-toggle-implementation/design.md</code></em></p>\n<p>本文分享的方案来自我们在 <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">HagiCode</a> 项目中的实践经验。HagiCode 是一个基于 AI 的代码辅助工具，在开发过程中，我们需要维护大量的技术文档和博客。为了更好地理解用户需求，我们探索并实施了这套数据接入方案。</p>\n<h2 id=\"技术选型与探索\">技术选型与探索</h2>\n<p>起初，我们在 Proposal 阶段讨论了多种集成方式。既然我们使用的是 Starlight（基于 Astro 的文档框架），最直观的想法是利用 Astro 的 Hooks。</p>\n<p>我们首先尝试了修改 <code>astro.config.mjs</code>，计划在构建时注入 Clarity 脚本。虽然这种方式能保证全局覆盖，但缺乏灵活性——我们无法根据用户的偏好动态加载或卸载脚本。</p>\n<p>考虑到用户体验和隐私控制，我们最终决定采用 <strong>组件覆盖</strong> 的方案。Starlight 允许开发者覆盖其内部组件，这意味着我们可以接管 <code>&lt;footer&gt;</code> 或 <code>&lt;head&gt;</code> 的渲染逻辑，从而精细控制 Clarity 的加载时机。</p>\n<p>这里有一个小插曲：原本我们想创建一个名为 <code>StarlightWrapper.astro</code> 的布局包装器。但在实际调试中发现，Starlight 的路由机制并不会自动调用这个自定义 Wrapper，这导致脚本在部分页面失效。这算是一个典型的\"想当然\"踩坑经历，提醒我们<strong>必须深入理解框架的渲染流程，而不是盲目套用通用框架模式</strong>。</p>\n<h2 id=\"核心方案footer-组件覆盖\">核心方案：Footer 组件覆盖</h2>\n<p>为了确保 Clarity 脚本在所有页面（包括文档和博客）加载，并且不破坏原有的页面结构，我们选择了覆盖 Starlight 的 <code>Footer</code> 组件。</p>\n<h3 id=\"为什么是-footer\">为什么是 Footer？</h3>\n<ol>\n<li><strong>全局性</strong>：Footer 几乎在所有标准页面都会出现。</li>\n<li><strong>非侵入性</strong>：将脚本放在 Footer 区域（实际渲染在 body 底部）不会阻塞页面的关键渲染路径（LCP），对性能影响最小。</li>\n<li><strong>逻辑集中</strong>：可以在组件内部统一处理 Cookie 同意逻辑。</li>\n</ol>\n<h3 id=\"实施步骤\">实施步骤</h3>\n<h4 id=\"1-准备-clarity-项目\">1. 准备 Clarity 项目</h4>\n<p>首先，你需要在 <a href=\"https://clarity.microsoft.com/\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft Clarity</a> 注册并创建一个新项目。获取你的 Project ID（类似 <code>k8z2ab3xxx</code> 这样的字符串）。</p>\n<h4 id=\"2-环境变量配置\">2. 环境变量配置</h4>\n<p>下面通过环境变量配置与日期判断代码，实现新年期间的逻辑控制，请参考具体实现。</p>\n\n<pre><code class=\"language-text\">46 |         function isLunarNewYearPeriod() {\n47 |           const now = new Date();\n48 |           const year = now.getFullYear();\n49 |           const month = now.getMonth() + 1; // 1-12\n50 |           const day = now.getDate();\n51 | \n52 |           // 2025年蛇年新年期间 (1月29日 - 2月12日)\n53 |           if (year === 2025) {\n54 |             if (month === 1 &amp;&amp; day &gt;= 29) return true;\n55 |             if (month === 2 &amp;&amp; day &lt;= 12) return true;\n56 |           }\n57 |           // 2026年马年新年期间 (2月17日 - 3月3日)\n58 |           if (year === 2026) {\n59 |             if (month === 2 &amp;&amp; day &gt;= 17) return true;\n60 |             if (month === 3 &amp;&amp; day &lt;= 3) return true;\n61 |           }\n62 |           return false;\n63 |         }\n64 | \n65 |         const stored = localStorage.getItem('starlight-theme');\n</code></pre>\n<p><em>文件：<code>src/pages/index.astro</code></em></p>\n<p>为了安全起见，不要硬编码 ID。建议将 ID 存入环境变量。</p>\n<p>在项目根目录创建 <code>.env</code> 文件：</p>\n<pre><code class=\"language-bash\"># Microsoft Clarity ID\nPUBLIC_CLARITY_ID=\"你的_Clarity_ID\"\n</code></pre>\n<h4 id=\"3-创建覆盖组件\">3. 创建覆盖组件</h4>\n<p>以下是监听系统主题变化的实现代码，展示了如何仅在未手动设置时跟随系统切换主题。</p>\n\n<pre><code class=\"language-markdown\">445 |     const handleChange = (e: MediaQueryListEvent) =&gt; {\n446 |       // 仅在用户未手动设置时跟随系统\n447 |       if (!localStorage.getItem(THEME_KEY)) {\n448 |         setThemeState(e.matches ? 'dark' : 'light');\n449 |       }\n450 |     };\n451 | \n452 |     mediaQuery.addEventListener('change', handleChange);\n453 |     return () =&gt; mediaQuery.removeEventListener('change', handleChange);\n454 |   }, []);\n455 | \n456 |   return { theme, toggleTheme, setTheme: manuallySetTheme };\n457 | }\n458 | ```\n459 | \n460 | #### 3. `src/components/ThemeButton.tsx` - 按钮组件\n461 | \n462 | **职责**：渲染主题切换按钮，处理用户交互\n463 | \n464 | **组件接口**：\n</code></pre>\n<p><em>文件：<code>openspec/changes/archive/2026-01-29-theme-toggle-implementation/design.md</code></em></p>\n<p>在 <code>src/components/</code> 目录下创建文件 <code>StarlightFooter.astro</code>。Starlight 会自动识别这个文件并覆盖默认的 Footer。</p>\n<p>核心代码逻辑如下：</p>\n<pre><code class=\"language-astro\">---\n// src/components/StarlightFooter.astro\n// 1. 引入原始组件以保留其默认功能\nimport DefaultFooter from '@astrojs/starlight/components/StarlightFooter.astro';\n\n// 2. 获取环境变量\nconst clarityId = import.meta.env.PUBLIC_CLARITY_ID;\n\n// 3. 定义简单的注入脚本（内联方式）\n// 注意：生产环境建议将此逻辑抽离到单独的 .js 文件中以利用缓存\nconst initScript = `\n(function(c,l,a,r,i,t,y){\n    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};\n    t=l.createElement(r);t.async=1;t.src=\"https://www.clarity.ms/tag/\"+i;\n    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);\n})(window, document, \"clarity\", \"script\", \"${clarityId}\");\n`;\n---\n\n&lt;DefaultFooter {...Astro.props} /&gt;\n\n{/* 仅在生产环境且 ID 存在时注入脚本 */}\n{import.meta.env.PROD &amp;&amp; clarityId &amp;&amp; (\n  &lt;script is:inline define:vars={{ clarityId }}&gt;\n    {initScript}\n  &lt;/script&gt;\n)}\n</code></pre>\n<p><strong>关键点解析</strong>：</p>\n<ul>\n<li><code>is:inline</code>：告诉 Astro 不要处理这个 script 标签内的内容，直接输出到 HTML。这对第三方统计脚本至关重要，否则 Astro 的打包优化可能会导致脚本失效。</li>\n<li><code>define:vars</code>：这是 Astro 3+ 的特性，允许在作用域内安全地注入变量。</li>\n<li><code>import.meta.env.PROD</code>：确保在本地开发时（除非为了调试）不产生无效统计，保持数据纯净。</li>\n</ul>\n<h3 id=\"进阶隐私合规与-cookie-控制\">进阶：隐私合规与 Cookie 控制</h3>\n<p>仅仅加上代码是不够的，特别是在 GDPR 管辖区域。我们需要尊重用户的选择。</p>\n<p>HagiCode 的做法是提供一个简单的开关。虽然这不是全功能的 Cookie Banner，但对于纯展示的技术文档站点来说，通常属于\"必要\"或\"统计\"类 Cookie，可以通过隐私声明告知并默认开启，或者在 Footer 链接到隐私设置页面。</p>\n<p>如果需要更严谨的控制，你可以结合 <code>localStorage</code> 来记录用户的选择：</p>\n<p>本文将介绍用于主题切换与持久化的 TypeScript 工具函数，通过类型安全与环境检测实现严谨控制。</p>\n\n<pre><code class=\"language-markdown\">367 | export function getInitialTheme(): Theme;\n368 | export function getSystemTheme(): Theme;\n369 | export function setTheme(theme: Theme): void;\n370 | export function applyTheme(theme: Theme): void;\n371 | ```\n372 | \n373 | **设计原则**：\n374 | - **纯函数**：无副作用（除了 `setTheme` 和 `applyTheme`）\n375 | - **类型安全**：完整的 TypeScript 类型推导\n376 | - **环境检测**：SSR 安全（`typeof window` 检查）\n377 | - **单一职责**：每个函数只做一件事\n378 | \n379 | **关键实现**：\n380 | ```typescript\n381 | export function getInitialTheme(): Theme {\n382 |   if (typeof window === 'undefined') return 'dark';\n383 | \n384 |   const stored = localStorage.getItem(THEME_KEY);\n385 |   if (stored === 'light' || stored === 'dark') return stored;\n386 | \n</code></pre>\n<p><em>文件：<code>openspec/changes/archive/2026-01-29-theme-toggle-implementation/design.md</code></em></p>\n<pre><code class=\"language-javascript\">// 简单示例：检查用户是否拒绝统计\nconst consent = localStorage.getItem('clarity_consent');\nif (consent !== 'denied') {\n    // 执行上面的 Clarity 初始化代码\n    window.clarity('start', clarityId);\n}\n</code></pre>\n<h2 id=\"经验总结与坑点\">经验总结与坑点</h2>\n<p>在将这套方案落地到 HagiCode 的过程中，我们总结了几个容易被忽视的细节：</p>\n<ol>\n<li>\n<p><strong><code>StarlightWrapper.astro</code> 是个陷阱</strong>：<br />\n如前所述，不要试图去创建一个全局 Wrapper 来注入脚本，这在 Starlight 中行不通。老老实实覆盖特定组件（如 <code>StarlightFooter.astro</code> 或 <code>StarlightHead.astro</code>）才是正解。</p>\n</li>\n<li>\n<p><strong>脚本位置的性能考量</strong>：<br />\n虽然 Clarity 建议放在 <code>&lt;head&gt;</code> 中以确保数据准确性，但对于文档站点，首屏加载速度（LCP）直接影响了 SEO 和用户留存。我们选择了放在 Footer（Body 底部），这会轻微丢失极少量\"秒退\"用户的数据，但换来了更快的页面加载体验，这是一个值得的权衡。</p>\n</li>\n<li>\n<p><strong>开发环境的干扰</strong>：<br />\n一定要加上 <code>import.meta.env.PROD</code> 判断。在开发模式下，你会频繁刷新页面，这会产生大量无意义的测试数据，污染你的 Clarity 仪表盘。</p>\n</li>\n</ol>\n<h2 id=\"效果验证\">效果验证</h2>\n<p>部署完成后，你可以在 Clarity 控制台查看实时数据。通常在几分钟内，你就能看到用户的heatmap（热力图）和 recordings（录屏）。</p>\n<p>对于 HagiCode 来说，通过这些数据我们发现：</p>\n<ul>\n<li>很多用户会反复查看\"快速开始\"章节，说明我们的安装指引可能还不够直观。</li>\n<li>\"API 参考\"页面的停留时间最长，证实了我们核心用户群体的需求。</li>\n</ul>\n<h2 id=\"总结\">总结</h2>\n<p>接入 Microsoft Clarity 并不需要复杂的服务端改造，也不需要引入沉重的 SDK。</p>\n<p>利用 Starlight 的组件覆盖机制，我们仅通过一个轻量级的 <code>StarlightFooter.astro</code> 组件，就实现了全局数据统计。这种\"微集成\"的方式，既保证了代码的整洁，又赋予了我们洞察用户行为的能力。</p>\n<p>如果你也在运营技术类项目，特别是像 <strong>HagiCode</strong> 这样需要不断迭代文档的项目，强烈建议尝试接入 Clarity。数据会告诉你，用户真正的痛点在哪里。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">HagiCode GitHub 仓库</a> - 查看我们在实际项目中的配置文件</li>\n<li><a href=\"https://learn.microsoft.com/en-us/clarity/\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft Clarity 官方文档</a></li>\n<li><a href=\"https://starlight.astro.build/guides/overriding-components/\" rel=\"noopener nofollow\" target=\"_blank\">Starlight 组件覆盖指南</a></li>\n</ul>\n<hr />\n<p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p>\n<p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p>\n<ul>\n<li><strong>本文作者:</strong> <a href=\"https://www.newbe.pro\" rel=\"noopener nofollow\" target=\"_blank\">newbe36524</a></li>\n<li><strong>本文链接:</strong> <a href=\"https://hagicode-org.github.io/site/blog/2026-02-04-starlight-docs-integration-microsoft-clarity/\" rel=\"noopener nofollow\" target=\"_blank\">https://hagicode-org.github.io/site/blog/2026-02-04-starlight-docs-integration-microsoft-clarity/</a></li>\n<li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 09:13</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "基于Ai Coding,20天完成一个基于大模型的医学分析系统：Ai体征分析助手",
      "link": "https://www.cnblogs.com/lsjwq/p/19577341",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lsjwq/p/19577341\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 08:52\">\n    <span>基于Ai Coding,20天完成一个基于大模型的医学分析系统：Ai体征分析助手</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        我是一名长期使用C#开发后台服务与数据库的开发者，在短短20天内，独立完成一个跨前后端、贴合医疗健康场景分析的完整系统（Ai体征分析助手）是未曾想过的。得益于AI Coding工具的深度实践与应用和医疗领域大模型的应用，让我对AI时代的软件开发有了全新的认知。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>目录</p>\n<p><strong>1.Ai Copilot</strong><strong>实践与应用</strong>... 1</p>\n<p><strong>2.Ai Coding</strong><strong>带来的好处与挑战</strong>... 1</p>\n<p><strong>2.1 </strong><strong>带来的好处</strong>... 2</p>\n<p><strong>2.2 </strong><strong>面临的挑战</strong>... 2</p>\n<p><strong>3.Ai</strong><strong>体征分析助手项目介绍</strong>... 2</p>\n<p><strong>3.1</strong><strong>业务介绍</strong>... 2</p>\n<p><strong>3.2</strong><strong>技术体系</strong>... 7</p>\n<p><strong>4.</strong><strong>总结</strong>... 8</p>\n<hr />\n<p style=\"text-align: center;\">&nbsp;<strong>基于</strong><strong>Ai Coding</strong><strong>，</strong><strong>20</strong><strong>天完成一个基于大模型的医学分析系统：</strong><strong>Ai</strong><strong>体征分析助手</strong>&nbsp;</p>\n<p><span style=\"font-size: 16px;\">　　我是一名长期使用C#开发后台服务与数据库的开发者，在短短20天内，独立完成一个跨前后端、贴合医疗健康场景分析的完整系统（<a href=\"https://www.aineuos.net/\" rel=\"noopener nofollow\">Ai体征分析助手</a>）是未曾想过的。得益于AI Coding工具的深度实践与应用和医疗领域大模型的应用，让我对AI时代的软件开发有了全新的认知。</span></p>\n<p><span style=\"font-size: 16px;\"><img alt=\"Snipaste_2026-02-04_14-30-34\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085311503-166624795.jpg\" /></span></p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 18px;\"><strong>1.Ai Copilot</strong><strong>实践与应用</strong></span></p>\n<p><span style=\"font-size: 16px;\">　　在本次Ai体征分析助手的开发过程中，我全程以VSCode+AI Copilot为核心开发工具，前期自己写了一个简单的想法和需求，但是需求变更很大。AI Copilot全程参与了其他环节：界面生成、代码开发、前后端测试、合理化建议等，需要开发者与工具形成高效配合。有三个实践感悟：</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　首先，</strong><strong>AI Copilot</strong><strong>的付费模式性价比高</strong>，我只是个人付费版本，不是专业版本，相较于聘请专业的前后端开发人员，付费工具的成本几乎可以忽略不计，无需担心沟通成本、时间协调等问题，一般干到晚上10点，有时候早上5点起来接着干。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　其次，</strong><strong>AI Copilot</strong><strong>能够实现前后端代码的协同生成</strong>，大幅缩短开发周期。以往前端、后端分开编写代码，花费大量时间。本次开发中，我只需明确需求（例如“开发一个医学影像上传接口，对接后端PostgreSQL数据库”、“开发前端影像上传组件，适配电脑端和手机端浏览器”等），AI Copilot就能生成对应的后端Flask接口代码、前端Vue组件代码，甚至自动生成接口调用示例和调试代码。当然，还有其他代码提示、合理化建议等方面的优势 。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　最后，</strong><strong>AI</strong><strong>生成代码逻辑需要开发者亲自</strong><strong>review</strong><strong>验证</strong>。AI Copilot虽然能快速生成代码，但是无法完全理解项目的整体架构逻辑和业务细节，偶尔会出现代码逻辑不严谨、参数缺失、安全漏洞（例如用户认证逻辑不完善、支付接口签名错误）等问题。因此，结合项目需求调整逻辑、补充细节、修复漏洞等。</span></p>\n<p><span style=\"font-size: 18px;\"><strong>2.Ai Coding</strong><strong>带来的好处与挑战</strong></span></p>\n<p><span style=\"font-size: 16px;\">　　20天的开发历程，从全新的医疗场景需求，到可正常运行的跨端系统，AI Coding给我带来的不仅是开发效率的提升，更有对职业发展、工作生活方式的深刻影响。</span></p>\n<p><span style=\"font-size: 18px;\"><strong>2.1 </strong><strong>带来的好处</strong></span></p>\n<p><span style=\"font-size: 16px;\">　　（1）<strong>大幅提升开发效率，降低小团体与个人创业的门槛</strong>。我原本只擅长C#后端开发，对Python、Vue、TypeScript等技术并不熟悉，但是借助AI Coding，顺利完成接口开发、前端页面、跨端适配等，20天开发周期，相较于传统开发模式大幅缩减开发周期，全程无需依赖其他开发者，让个人创业的门槛大幅降低。</span></p>\n<p><span style=\"font-size: 16px;\">　　（2）<strong>改变工作与生活的模式，让零碎时间发挥更大价值</strong>。以往开发一个完整的项目，往往需要集中大量的整块时间。这种开发模式无需集中整块时间，既能兼顾全职工作，又能利用零碎时间做自己喜欢的事情。但是，在“高效利用时间”的同时，也会促使人更加有压迫感，所以需要个人来调节状态。</span></p>\n<p><span style=\"font-size: 16px;\">　　（3）<strong>打破技术壁垒，为跨界开发提供了更大可能</strong>。跨界开发需要花费大量时间学习新的技术栈，我原本专注于C#后端服务与数据库开发，但在本次项目开发中，短短20天，打破技术边界，一个人使用AI Coding完成python、vue、数据库、大模型等整合。</span></p>\n<p><span style=\"font-size: 18px;\"><strong>2.2 </strong><strong>面临的挑战</strong></span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（</strong><strong>1</strong><strong>）普通工程师面临失业风险，技术门槛重新定义</strong>。AI Coding能够快速生成基础代码、完成重复性开发工作，这对于从事基础代码编写的普通工程师而言，未来面临很大失业风险。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（</strong><strong>2</strong><strong>）行业对创新与设计人才的需求大幅提升</strong>。AI Coding解决“怎么写代码”的问题，但无法解决“写什么代码”“为什么要这么写”的问题，这意味着，不再是会写代码就能立足，更需要具备需求梳理、架构设计、产品创新能力的人。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（</strong><strong>3</strong><strong>）</strong><strong>AI Coding</strong><strong>并非</strong><strong>“</strong><strong>零门槛</strong><strong>”</strong><strong>，不懂编程的人难以独立完成工程项目</strong>。AI Coding的核心价值是“辅助”，而非“替代”——它需要开发者具备基本的编程知识、逻辑思维能力，能够明确需求、梳理逻辑、review代码等。AI Coding降低了软件开发“技术门槛”，但并未消除门槛，它更适合有一定编程基础、能够与AI高效配合的开发者，而非完全不懂编程的“小白”。</span></p>\n<p><span style=\"font-size: 18px;\"><strong>3.Ai</strong><strong>体征分析助手项目介绍</strong></span></p>\n<p><span style=\"font-size: 18px;\"><strong>3.1</strong><strong>业务</strong><strong>介绍</strong></span></p>\n<p><span style=\"font-size: 16px;\">　　Ai体征分析助手的口号：“<strong>让医疗更智慧，让健康更普惠</strong>”。</span></p>\n<p><span style=\"font-size: 16px;\">　　Ai体征分析助手依托先进的人工智能专业模型，能够精准解读和分析各类医学影像与健康数据，全面覆盖普通大众的基础健康筛查需求。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　- **</strong><strong>医学影像</strong><strong>**</strong><strong>：</strong><strong>CT</strong><strong>扫描、核磁共振</strong><strong>(MRI)</strong><strong>影像、组织病理成像等</strong></span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　- **</strong><strong>临床影像</strong><strong>**</strong><strong>：胸部</strong><strong>X</strong><strong>光片、皮肤科图像、眼科图像等</strong></span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　- **</strong><strong>医疗数据</strong><strong>**</strong><strong>：医生诊断病历、电子健康记录</strong><strong>(EHR)</strong><strong>、解剖特征数据</strong></span></p>\n<p><span style=\"font-size: 16px;\">　　后台人工智能医学模型，已经在多项临床相关基准评估中展现出稳定、可靠的基础性能，能够为分析结果提供有力的技术保障，确保分析建议的科学性、参考性。</span></p>\n<p><span style=\"font-size: 16px;\">　　Ai体征分析助手有<strong>四大核心优势</strong>，能够切实解决大家在健康筛查、就医过程中遇到的痛点问题：</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（1）居家提早筛查</strong>：在家即可完成初步健康筛查，主动预防疾病，守护普通大众的健康。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（2）高效便捷</strong>：快速分析影像与病历，缩短就医等待时间，缓解就医焦虑。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（3）打破地域和资源壁垒</strong>：让优质医疗AI资源跨越地域，特别是让偏远地区的普通大众也能享受到优质的AI医疗服务。</span></p>\n<p><span style=\"font-size: 16px;\"><strong>　　（4）经济实惠</strong>：辅助分析验证信息，有效降低医疗成本，让普惠医疗真正落地。</span></p>\n<p><span style=\"font-size: 16px;\">　　Ai体征分析助手的核心目标，让人工智能走进千家万户，让普通大众在家就能完成初步健康筛查，不用再为了简单的健康咨询奔波往返医院，轻松实现疾病早发现、早预防，大大提升大家疾病预防的主动性。</span></p>\n<p><span style=\"font-size: 16px;\">　　特别提醒大家：<strong>AI</strong><strong>体征分析助手仅为人工智能模型分析得出的参考结果，不能替代正规医院的专业诊断，若有健康疑虑，请务必咨询专业医疗机构和医生</strong>。</span></p>\n<p><span style=\"font-size: 16px;\">　　（1）&nbsp;&nbsp;&nbsp; <strong>电脑端浏览器应用</strong>：医学分析、历史分析、邀请记录、赞助记录、提现记录、我的信息、邀请好友等。</span></p>\n<p><span style=\"font-size: 16px;\"><img alt=\"1\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085043467-1636338170.jpg\" /></span></p>\n<p><img alt=\"2\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085055078-1972974666.jpg\" /></p>\n<p><img alt=\"3\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085101120-1634808551.jpg\" /></p>\n<p><img alt=\"4\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085109946-801721347.jpg\" /></p>\n<p><img alt=\"5\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085115893-1478473000.jpg\" /></p>\n<p><img alt=\"6\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085122155-1181622956.jpg\" /></p>\n<p><img alt=\"7\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085127663-613759521.jpg\" /></p>\n<p><span style=\"font-size: 16px;\">　　</span><span style=\"font-size: 16px;\">（2）&nbsp;&nbsp;&nbsp; </span><strong style=\"font-size: 16px;\">手机端浏览器应用</strong><span style=\"font-size: 16px;\">：医学分析、历史分析、邀请记录、赞助记录、提现记录、我的信息、邀请好友等。</span></p>\n<p><span style=\"font-size: 16px;\"><img alt=\"全部\" src=\"https://img2024.cnblogs.com/blog/279374/202602/279374-20260205085141446-1921050907.png\" /></span></p>\n<p><strong style=\"font-size: 18px;\">3.2</strong><strong style=\"font-size: 18px;\">技术体系</strong></p>\n<p>&nbsp;</p>\n<p><span style=\"font-size: 16px;\"><strong>## 后端技术栈</strong></span></p>\n<p><span style=\"font-size: 16px;\">- **框架**：Flask 3.x</span></p>\n<p><span style=\"font-size: 16px;\">- **数据库**：PostgreSQL + SQLAlchemy ORM</span></p>\n<p><span style=\"font-size: 16px;\">- **鉴权**：JWT Token</span></p>\n<p><span style=\"font-size: 16px;\">- **支付**：微信支付 V3（Native/JSAPI）</span></p>\n<p><span style=\"font-size: 16px;\">- **短信**：阿里云短信</span></p>\n<p><span style=\"font-size: 16px;\">- **模型**：PyTorch + Transformers（医学诊断模型）</span></p>\n<p><span style=\"font-size: 16px;\">- **API**：RESTful API设计</span></p>\n<p><span style=\"font-size: 16px;\"><strong>## 前端技术栈</strong></span></p>\n<p><span style=\"font-size: 16px;\">- **框架**：Vue 3 + TypeScript</span></p>\n<p><span style=\"font-size: 16px;\">- **构建工具**：Vite</span></p>\n<p><span style=\"font-size: 16px;\">- **路由**：Vue Router</span></p>\n<p><span style=\"font-size: 16px;\">- **样式**：Scoped CSS</span></p>\n<p><span style=\"font-size: 16px;\">- **文档渲染**：@kangc/v-md-editor / Marked</span></p>\n<p><span style=\"font-size: 16px;\">- **导出**：HTML2Canvas + HTML2PDF</span></p>\n<p><span style=\"font-size: 16px;\">- **其他**：QRCode</span></p>\n<p><span style=\"font-size: 16px;\"><strong>## 核心模块</strong></span></p>\n<p><span style=\"font-size: 16px;\">| 模块 | 功能 | 说明 |</span></p>\n<p><span style=\"font-size: 16px;\">|------|------|------|</span></p>\n<p><span style=\"font-size: 16px;\">| 用户认证 | 注册、登录、信息管理 | 安全的身份验证 |</span></p>\n<p><span style=\"font-size: 16px;\">| 医学诊断 | 影像上传、分析、结果展示 | AI诊断核心模块 |</span></p>\n<p><span style=\"font-size: 16px;\">| 分析历史 | 记录查询、删除、PDF下载 | 完整的数据管理 |</span></p>\n<p><span style=\"font-size: 16px;\">| 个人中心 | 用户信息修改、密码修改 | 用户自助管理 |</span></p>\n<p><span style=\"font-size: 16px;\">| 支付与提现 | 微信支付、提现、支付记录、提现记录 | 资金相关能力 |</span></p>\n<p><span style=\"font-size: 16px;\">| 邀请好友 | 邀请码生成、邀请记录 | 用户增长与奖励 |</span></p>\n<p><span style=\"font-size: 16px;\"><strong>## 使用说明</strong></span></p>\n<p><span style=\"font-size: 16px;\">1. **注册登录** - 创建账户或使用现有账户登录</span></p>\n<p><span style=\"font-size: 16px;\">2. **提交诊断** - 上传医学影像和必要的医学描述</span></p>\n<p><span style=\"font-size: 16px;\">3. **等待分析** - 系统进行AI分析（显示分析状态）</span></p>\n<p><span style=\"font-size: 16px;\">4. **查看结果** - 查看详细的分析结果和建议</span></p>\n<p><span style=\"font-size: 16px;\">5. **管理记录** - 查看历史记录、下载报告、删除数据</span></p>\n<p><span style=\"font-size: 18px;\"><strong>4.</strong><strong>总结</strong></span></p>\n<p><span style=\"font-size: 16px;\">　　从需求梳理到代码落地，从功能调试到最终上线，20天的开发历程，这是碳基生命+硅基生命的完美协作，让我对软件开发的未来有了全新的认知。AI不会替代开发者，但会淘汰不懂得利用AI、不懂得提升自己的开发者。让我们利用AI技术做一些更有意义的事。</span></p>\n<p><span style=\"font-size: 16px;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Github</strong>: <a href=\"https://github.com/wxzz/\" rel=\"noopener nofollow\">https://github.com/wxzz/</a>。</span></p>\n<p><span style=\"font-size: 16px;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>博客</strong>：<a href=\"https://www.cnblogs.com/lsjwq\">https://www.cnblogs.com/lsjwq</a>。</span></p>\n<p><span style=\"font-size: 16px;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Ai</strong><strong>体征分析助手试用</strong>：<a href=\"https://www.aineuos.net/\" rel=\"noopener nofollow\">https://www.aineuos.net/</a>。</span></p>\n<hr />\n<p>物联网&amp;大数据技术 QQ群：54256083</p>\n<p>物联网&amp;大数据项目 QQ群：727664080</p>\n<p>QQ：504547114</p>\n<p><img alt=\"image\" height=\"121\" src=\"https://img2024.cnblogs.com/blog/279374/202509/279374-20250924180005285-1427975355.png\" width=\"243\" /></p>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 08:52</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lsjwq\">iNeuOS工业互联网系统</a>&nbsp;\n阅读(<span id=\"post_view_count\">66</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[开源分享] ChatGPT 浏览器效率插件：对话可视化为图谱及时间线，快速定位消息，把握对话脉络",
      "link": "https://www.cnblogs.com/roberick/p/19577242",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/roberick/p/19577242\" id=\"cb_post_title_url\" title=\"发布于 2026-02-05 08:28\">\n    <span>[开源分享] ChatGPT 浏览器效率插件：对话可视化为图谱及时间线，快速定位消息，把握对话脉络</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"[开源分享] ChatGPT 浏览器效率插件：对话可视化为图谱及时间线，快速定位消息，把握对话脉络\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2733976/202602/2733976-20260205082744246-958830395.png\" />\n        将 ChatGPT 转化为可导航的知识图谱。利用图谱视图可视化复杂分支，通过 Git 风格的时间线树管理历史记录，并将不断实现丰富的实用功能。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<div align=\"center\">\n<img alt=\"ChatGPT Graph\" class=\"lazyload\" width=\"128\" />\n<h1>ChatGPT Graph Navigator</h1>\n<table>\n<tbody><tr>\n<td align=\"center\" width=\"200\">\n<img alt=\"Graph View Icon\" class=\"lazyload\" height=\"45\" width=\"45\" />\n</td>\n<td align=\"center\" width=\"200\">\n<img alt=\"Timeline Tree Icon\" class=\"lazyload\" height=\"45\" width=\"45\" />\n</td>\n<td align=\"center\" width=\"200\">\n<img alt=\"Workflow Utils Icon\" class=\"lazyload\" height=\"45\" width=\"45\" />\n</td>\n</tr>\n<tr>\n<td align=\"center\">\n<strong>图谱视图</strong>\n</td>\n<td align=\"center\">\n<strong>时间线树</strong>\n</td>\n<td align=\"center\">\n<strong>实用工具</strong>\n</td>\n</tr>\n<tr>\n<td align=\"center\">\n<sub>空间可视化<br />逻辑全景概览</sub>\n</td>\n<td align=\"center\">\n<sub>分支快速导航<br />Git 风格历史记录</sub>\n</td>\n<td align=\"center\">\n<sub>消息折叠<br />及未来更多功能</sub>\n</td>\n</tr>\n</tbody></table>\n<h4>\n✨ 将聊天记录转化为交互式树状图。<br />\n专为 ChatGPT 对话打造的高效思维导图UI。\n</h4></div>\n\n<hr />\n<div align=\"center\">\n仓库链接：<a href=\"https://github.com/Robbings/chatgpt-graph-navigator\" rel=\"noopener nofollow\" style=\"display: inline-block; padding: 10px 20px; background-color: rgba(36, 41, 46, 1); color: rgba(255, 255, 255, 1); text-decoration: none; border-radius: 6px; font-weight: bold;\" target=\"_blank\"> https://github.com/Robbings/chatgpt-graph-navigator </a>\n</div>\n<hr />\n<h2 id=\"一为什么我们需要非线性对话\">一、为什么我们需要非线性对话？</h2>\n<p>相比于Gemini，ChatGPT支持通过修改提问或者回答，产生新的对话分支，并且每一个分支都可以被保存和重新访问。</p>\n<p><img alt=\"intro1\" class=\"lazyload\" /></p>\n<p>我个人非常喜欢这个功能。因为<strong>复杂问题的解决包含了不断地假设，试错和分支探索</strong> ，而这个功能让多分支的图谱式对话成为可能。</p>\n<p>举个栗子，比如搞科研或者开发一个项目的时候让GPT生成方案，它会提供多个选择，针对每一个方案我需要并行地讨论，然后确认如何选择。如果纯线性对话，一方面后续很难定位和复盘，另一方面，假设我最终选定一套方案，其他方案的大量对话就会变成无用的上下文，干扰模型思考和后续的复盘。而方案开始实施后我也会遇到很多问题需要处理，这些问题有些彼此相关，有些彼此无关，这时我也会使用分支功能，每个分支解决一个独立的问题。</p>\n<p>所以在进行复杂对话的时候，如果采用线性对话，会有诸多弊端，比如：</p>\n<ul>\n<li><strong>📉 “上下文污染”问题：</strong>  当你在同一个对话流中按顺序尝试不同方案时，无关的上下文和失败的尝试会不断堆积。这种“噪音”不仅消耗 Token 配额，还会干扰模型的注意力，使其难以针对你当前的策略提供最精准的分析。</li>\n<li><strong>🔀 “并行探索”的刚需：</strong>  为了获取最佳结果，你往往需要对对话进行“分叉”——通过修改 Prompt 或重新生成回复来测试不同的路径。在线性界面中，管理这些“平行宇宙”简直是一场灾难。你很容易忘记思路是在哪里分岔的，也记不清哪个分支产出了最佳结果。</li>\n<li><strong>🧠 逻辑混乱，定位困难：</strong>  试图在脑海中复盘 20 分钟前的 Prompt 与刚刚写好的新变体之间的逻辑关系，是一件极度消耗精力的事情。</li>\n</ul>\n<p><strong>ChatGPT Graph Navigator 专为解决此问题而生。</strong>  我们将你的分支可视化，帮助你<strong>隔离上下文</strong>以获取更纯净的模型输出，同时让你原本复杂的推理结构变得井井有条。</p>\n<h2 id=\"二功能介绍\">二、功能介绍</h2>\n<p><img alt=\"main_feature\" class=\"lazyload\" /></p>\n<h3 id=\"核心能力一览\">核心能力一览：</h3>\n<ul>\n<li><strong>🎨 两种界面：</strong> 选择 <strong>侧边栏 (Sidebar)</strong> 享受常驻的沉浸式工作流，或使用 <strong>悬浮窗 (Floating Window)</strong> 进行随叫随到的轻量化查看。</li>\n<li><strong>👁️ 两个可视化视图：</strong></li>\n<li><strong>图谱视图 (Graph View)：</strong> 采用思维导图结构，助你一眼掌握对话“全局”与逻辑脉络。</li>\n<li><strong>时间线树 (Timeline Tree)：</strong> 采用 Git 风格的垂直树状图，精准追踪每一次细微的修改与分支。</li>\n<li><strong>⚡ 导航：</strong> 点击任意节点即可 <strong>直接跳转</strong> 至对应分支的具体消息，瞬间还原历史上下文。</li>\n<li><strong>🔍 搜索：</strong> 在整个对话树中快速定位特定的 Prompt 或 AI 回复，不再迷失在长对话中。</li>\n<li><strong>🛠️ 实用工具：</strong> 内置长消息自动折叠功能，并计划持续集成更多效率工具（如导出、格式化等）。</li>\n</ul>\n<h3 id=\"更多功能展示\">更多功能展示</h3>\n<h4 id=\"1-侧边栏\">1. 侧边栏</h4>\n<p><img alt=\"sidepanel\" class=\"lazyload\" /></p>\n<p>侧边栏专为提升效率而生，提供两种模式以契合您的工作流：</p>\n<h4 id=\"a-图谱模式-graph-mode\">a. 图谱模式 (Graph Mode)</h4>\n<p><em>掌控结构与上下文跳转的最佳选择。</em></p>\n<ul>\n<li><strong>空间掌控：</strong> 支持自由缩放与平移，瞬间掌握对话主题的完整拓扑结构。</li>\n<li><strong>一键跳转：</strong> 点击图谱中的任意消息节点，即可 <strong>瞬间跳转</strong> 到任意分支的任意对话，并立即恢复当时的上下文环境。</li>\n</ul>\n<h4 id=\"b-时间线模式-timeline-mode\">b. 时间线模式 (Timeline Mode)</h4>\n<p><em>精准定位与内容检索的利器。</em></p>\n<ul>\n<li><strong>专注筛选：</strong> 信息噪音太多？切换过滤器以显示 <strong>全部问答</strong>、<strong>仅问题 (Prompts)</strong> 或 **仅回答 **。非常适合快速回顾您的 Prompt 迭代历史。同时也支持点击跳转。</li>\n<li><strong>即时搜索：</strong> 使用内置搜索栏快速定位关键词，快速定位消息，回车直接跳转。</li>\n</ul>\n<h4 id=\"2-悬浮窗\">2. 悬浮窗</h4>\n<p><img alt=\"float_main\" class=\"lazyload\" /></p>\n<ul>\n<li>🚀 <strong>拖拽与缩放：</strong> 在屏幕任意位置访问完整的图谱/时间线视图。</li>\n<li>👻 <strong>穿透模式：</strong> 点击穿透按钮，直接与悬浮窗背后的页面进行交互，互不干扰。</li>\n<li>📌 <strong>固定与融合：</strong> 支持窗口 <strong>置顶</strong> 并自由调节 <strong>透明度</strong>。</li>\n</ul>\n<h4 id=\"3-长消息折叠\">3. 长消息折叠</h4>\n<p><img alt=\"fold\" class=\"lazyload\" /></p>\n<ul>\n<li><strong>📂 消息自动折叠</strong>：长回复/代码块可自动或手动折叠，界面更清爽。</li>\n<li>支持自定义折叠提问或回答，可以设置折叠阈值，也可以手动折叠。</li>\n</ul>\n<h2 id=\"三后续计划\">三、后续计划</h2>\n<p>现在插件还在快速开发迭代的阶段，后续的计划主要包括：</p>\n<ol>\n<li>节点和分支的高亮，收藏，分类等功能。</li>\n<li>更多工具的集成，目前计划添加：对话或者消息级别的导出，其他功能如果需要欢迎issue。</li>\n<li><strong>图谱编辑：</strong> 删除不需要的分支或节点，以及手动编辑图谱结构，比如删除，添加节点间的连线，从而令图谱不再局限于消息结构，让逻辑更加清晰。</li>\n<li><strong>全局知识图谱：</strong> 实现针对项目或者自定义跨对话的更复杂的知识图谱构建和管理。</li>\n<li><strong>个人知识库的管理：</strong> 基于图谱构建个人的知识库，并支持知识库的管理，检索，导出，在对话中导入等功能。</li>\n</ol>\n<h3 id=\"四写在最后\">四、写在最后</h3>\n<p>最后的最后，非常欢迎感兴趣的朋友们试用本插件！ 目前项目还处于早期阶段，还有诸多 Bug 和不足，非常欢迎大家在 Issues 里反馈。如果觉得这个小工具对你有帮助，<strong>十分希望能得到您的一个 Star</strong>，这对我是莫大的鼓励。</p>\n<p>如果您有新的想法非常欢迎Fork我们的项目，并提交PR！</p>\n<p>最后最后的最后，再贴一下项目中文README的链接，项目和完整的介绍请参见：<a href=\"https://github.com/Robbings/chatgpt-graph-navigator/blob/master/README_ZH.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/Robbings/chatgpt-graph-navigator/blob/master/README_ZH.md</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-05 08:28</span>&nbsp;\n<a href=\"https://www.cnblogs.com/roberick\">Roberick</a>&nbsp;\n阅读(<span id=\"post_view_count\">42</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}