{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "CLAUDE.md 全方位指南：构建高效 AI 开发上下文",
      "link": "https://www.cnblogs.com/didispace/p/19489098",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/didispace/p/19489098\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 20:09\">\n    <span>CLAUDE.md 全方位指南：构建高效 AI 开发上下文</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>如果你是 Claude 的日常用户，你一定熟悉这个场景：每次开启一个新的对话，都必须不厌其烦地重复设置项目背景、编码规范和特定的指令。这不仅耗时，也容易出错。当你忘记提醒某个关键细节时，就不得不花更多时间去修复那些不符合规范的代码。</p>\n<p>CLAUDE.md 文件正是解决这一痛点的关键。它就像 Claude 的项目专属记忆，让 AI 在每次对话开始前自动加载并记住你的所有偏好。这是一个简单而强大的功能，但大多数用户仅仅停留在基础层面。</p>\n<p>事实上，要真正释放 CLAUDE.md 的威力，需要掌握一些更深刻、甚至有些违反直觉的技巧。本文将为你揭示其中最关键的五个，帮助你将这个简单的配置文件，转变为一个能够持续进化的项目知识库。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h2 id=\"1-你的-claudemd-应该是一个活的文档而不是一次性配置\">1. 你的 CLAUDE.md 应该是一个“活的文档”，而不是“一次性配置”</h2>\n<p>许多人认为 CLAUDE.md 文件只需在项目开始时配置一次，然后就可以置之不理。这是一个巨大的误区。最有效的 CLAUDE.md 应该随着项目的演进而持续更新和优化。</p>\n<p>最佳的维护方式是在日常工作中“有机地”构建它。例如，当 Claude 做出了一个需要纠正的假设——比如它建议使用 console.log 进行调试，而你的团队规范是使用特定的日志库——不要只是临时修正。直接告诉 Claude：“将‘总是使用日志库而不是 console.log’这条规则添加到我的 CLAUDE.md 文件中。” 这样，你的修正就会沉淀下来，在未来的所有会话中生效。值得注意的是，早期版本的 Claude 有一个 # 快捷键来添加指令，但在 2.0.70 版本后已被移除。目前，直接请求 Claude 进行修改是官方推荐的最佳实践。</p>\n<p>这种做法的价值在于，它能实时捕捉并固化工作流程中的隐性知识。正如一个精妙的比喻所说：</p>\n<p>这就像在会议中做笔记，不同的是，这些笔记真的会被使用。</p>\n<p>更高级的维护方法是将其与团队协作流程结合。在代码审查（Code Review）中发现的未被文档化的规范，正是更新 CLAUDE.md 的绝佳时机。一个由 Boris Cherny 分享的高效工作流是：通过 GitHub Action，你甚至可以直接在 PR 评论中 @claude，让它将新规范添加到 CLAUDE.md 文件中。这创建了一个强大的反馈循环，将团队的集体智慧源源不断地沉淀到这个核心文件中。</p>\n<h2 id=\"2-少即是多上下文是宝贵资源精简至上\">2. 少即是多：上下文是宝贵资源，精简至上</h2>\n<p>人们普遍认为，提供给 AI 的上下文越多，结果就越好。然而在使用 CLAUDE.md 时，这个直觉可能是错误的。</p>\n<p>核心论点是：“上下文是宝贵的（Context is precious）”。CLAUDE.md 中的每一行内容，都在与你当前的工作指令竞争 AI 的注意力。一个臃肿、充满冗余信息的文件，反而可能稀释掉最关键的指令，导致 AI 抓不住重点。<br />\n因此，精简至上。一个很好的起点是使用 /init 命令，它会根据你的项目结构和技术栈生成一个初始文件。我的建议是，以此为基础，然后删除所有你不需要的内容。从现有内容中删除比从零开始创建要容易得多。</p>\n<p>一般建议将文件长度保持在 300 行以下。当然，这并非硬性规定。对于一些具有复杂约定或非寻常模式的 codebase，一个更长的 CLAUDE.md 反而能通过预先加载足够的上下文，有效防止 Claude 做出错误假设。关键在于，文件中的每一行都应该有其明确的价值。毫不留情地删除那些显而易见的废话（例如“请编写高质量代码”）或没有实际指导意义的“填充”信息。</p>\n<p>精简的 CLAUDE.md 迫使你仔细思考并只保留最重要的指令。这不仅能节省宝贵的上下文空间，更能确保 AI 在处理你的请求时，能够更准确地聚焦于核心要求，而不是在大量无关信息中迷失方向。</p>\n<h2 id=\"3-超越单个文件用模块化结构管理复杂性\">3. 超越单个文件：用模块化结构管理复杂性</h2>\n<p>许多用户只知道在项目根目录下创建一个 CLAUDE.md 文件。这对于小型项目来说足够了，但对于大型或结构复杂的项目，存在着更优雅、更强大的模块化管理方式。</p>\n<ul>\n<li>@imports 语法 你可以使用 @path/to/file 语法，从主 CLAUDE.md 文件中引用其他文件的内容。这能让主文件保持简洁，同时将详细的规范拆分到独立的文档中。例如，你可以将复杂的 API 设计模式放在 docs/api-patterns.md 中，然后在主文件里用 @docs/api-patterns.md 引用它。</li>\n<li>.claude/rules/ 目录 这是一个非常适合大型团队的结构。所有放在 .claude/rules/ 目录下的 .md 文件都会被 Claude 自动加载，无需手动 @import。这使得不同领域的团队可以独立维护各自的规则文件，例如，前端团队维护 code-style.md，安全团队维护 security.md。大家各司其职，有效避免了在单个大文件中频繁产生合并冲突。</li>\n<li>子目录中的 CLAUDE.md 对于 Monorepo（单一代码库）项目，这是一个绝佳的解决方案。你可以在项目的特定子目录（例如 api/ 或 packages/ui/）中放置 CLAUDE.md 文件。这些文件非常特殊：它们并不会在会话启动时加载，而只在 Claude 主动处理该特定子目录中的内容时才会被包含进来。这使得你可以为项目的不同模块定义截然不同的规范，实现真正精细化的上下文管理。<br />\n• 个人配置 CLAUDE.local.md 还有一个关键文件：CLAUDE.local.md。它用于存放那些不应提交到版本控制中的个人偏好，例如你习惯的编辑器 quirks 或偏好的代码冗余度。由于这是个人专属的，请务必将其添加到 .gitignore 文件中，以避免将个人配置泄露给整个团队。</li>\n</ul>\n<h2 id=\"4-魔鬼在细节中文件名是区分大小写的\">4. 魔鬼在细节中：文件名是区分大小写的</h2>\n<p>这是一个极其微小但至关重要的技术细节，也是最容易被忽略的陷阱之一：CLAUDE.md 这个文件名是区分大小写的。</p>\n<p>正确的文件名必须是“CLAUDE.md”——CLAUDE 部分为大写，.md 扩展名为小写。如果你将其命名为 claude.md、Claude.md 或其他任何变体，Claude 的系统将无法识别并加载它。</p>\n<p>这个细节之所以重要，是因为它是一个典型的“陷阱”（gotcha）。有趣的是，这一点在官方文档中并未明确说明。我是通过询问官方文档的 AI 助手才最终确认了这一规则。一旦出错，你可能会花费大量时间排查为什么自己精心编写的指令完全没有生效，最终才发现问题出在一个简单的大小写错误上。这个看似微不足道的细节，恰恰体现了与 AI 高效协作时，精确配置的重要性。</p>\n<h2 id=\"5-让-ai-优化-ai定期请-claude-审查自己的说明书\">5. 让 AI 优化 AI：定期请 Claude 审查自己的“说明书”</h2>\n<p>这是一个非常巧妙的“元认知”技巧：定期让 Claude 自己来审查和优化它的“说明书”——CLAUDE.md 文件。</p>\n<p>随着时间的推移，CLAUDE.md 中不可避免地会积累一些过时、冗余甚至相互冲突的指令。通过一个简单的提示，例如“请审查这个 CLAUDE.md 文件，并提出改进建议以使其更清晰、更高效”，你可以利用 Claude 自身的能力来发现这些问题。它可能会建议你合并重复的规则，或澄清模糊的表述。</p>\n<p>对于那些绝对不能违反的关键规则，你可以使用强调词来引起 Claude 的注意，比如 IMPORTANT: 或 YOU MUST。这能提高 Claude 遵循这些指令的概率，但请务必谨慎使用。正如一句古老的建议所说：如果所有东西都被标记为重要，那就没有什么是重要的了。</p>\n<p>诚然，这需要一些维护成本，但其回报是巨大的。正如源文所说：<br />\n这听起来像是维护开销。确实是。但它比在每个会话中重复自己的话，或修复那些忽略了你的规范的代码要省事得多。</p>\n<p>这不仅仅是一种文件维护策略，更是一种与 AI 协作的新范式。我们不再仅仅是 AI 的使用者，更是其成长过程中的引导者，让工具本身参与到自我完善的流程中，形成一个持续改进的良性循环。</p>\n<h2 id=\"结论\">结论</h2>\n<p>CLAUDE.md 远不止一个简单的配置文件。通过本文分享的五个高级技巧——将其视为活文档、保持精简、模块化管理、注意大小写，以及让 AI 自我优化——你可以将其从一个静态的指令列表，转变为一个强大的、与项目共同成长的动态知识库。</p>\n<p>这些策略代表了一种更深层次的思维方式：将你的 AI 上下文本身视为一个“代码库”。它也需要像代码一样被重构、被审查、被持续改进。你的 CLAUDE.md 值得你如此对待。现在，不妨思考一下：你的 CLAUDE.md 中沉淀了多少团队智慧？或许，现在就是开始构建它的最佳时机。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 20:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/didispace\">程序猿DD</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。",
      "link": "https://www.cnblogs.com/xiaohui666/p/19489060",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaohui666/p/19489060\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 19:56\">\n    <span>使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>使用vue3. + vite 开发，打开控制台卡顿，关闭控制台流畅。打开控制台时，鼠标在页面上移动。此时浏览器进程的cpu利用率也有上升。</p>\n<p>&nbsp;</p>\n<p>打开任务管理器查看到 刚启动就 300M 左右，此时页面还正常流畅使用</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115192758334-1287855783.png\" /></p>\n<p>&nbsp;</p>\n<p>当打开浏览器F12控制台时 ，页面卡顿，内存占用直接到达惊人的1547M ,百思不得其解</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193120944-1363009300.png\" /></p>\n<p>&nbsp;</p>\n<p>打开内存面板，查找原因，此时用了706M</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193422895-368120997.png\" /></p>\n<p>&nbsp;</p>\n<p>筛选一下，发现是样式导入重复</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193617511-1308370927.png\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;查看代码有三处地方引用</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193908039-480362363.png\" /></p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193912528-202535441.png\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115193917151-2133524706.png\" /></p>\n<p>&nbsp;</p>\n<p>&nbsp;先注释&nbsp;vite.config.ts 里的</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115194950450-306480391.png\" /></p>\n<p>&nbsp;</p>\n<p>发现内存明显下降，问题解决</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115195104234-699812157.png\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1692424/202601/1692424-20260115195120872-371187655.png\" /></p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 19:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaohui666\">小辉。</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘",
      "link": "https://www.cnblogs.com/chengzp/p/19488966/stock-dashboard",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/chengzp/p/19488966/stock-dashboard\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 19:06\">\n    <span>我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"我用 stock-sdk 构建了一个个人专属的 A 股行情仪表盘\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1265396/202601/1265396-20260115190434191-202601803.png\" />\n        这篇博客介绍了我用 stock-sdk 搭建的 A 股股票看板 stock-dashboard：基于 React + TypeScript + Vite 的纯前端项目，不依赖后端或定时脚本，直接在页面侧拉取行情并完成展示与筛选。文章从数据层封装（SDK 单例、重试、TTL 缓存、服务层统一出口）讲起，再按功能拆解搜索、Dashboard、热力图、板块/个股详情、自选、信号扫描与设置等模块。最后重点分享“一日持股法（尾盘选股）”的全市场扫描思路：先批量拉取 5000+ 行情做基础过滤，再分批拉分时计算强度指标并排序输出候选。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"这是个啥\">这是个啥</h2>\n<p>背景故事很简单：作为一个日常关注行情的“韭菜”，我有一个不太高效的习惯——同时打开无数个看盘软件和网页，在混乱的窗口切换中迷失自我，最终收获的往往只有焦虑，外加浏览器那令人窒息的标签页堆叠。为了彻底治愈这种低效，我决定动手打造一个专属工具：<strong>在一个页面内集成所有高频功能，涵盖实时行情、板块动态、分时走势、K 线分析、资金流向以及筛选器</strong>。</p>\n<p>这就诞生了 <code>stock-dashboard</code>：一个完全基于 React + TypeScript + Vite 技术栈的前端大屏。所有数据直接由 <a href=\"https://stock-sdk.linkdiary.cn/\" rel=\"noopener nofollow\" target=\"_blank\">stock-sdk</a> 驱动，这意味着项目完全摒弃了后端服务，不需要运行任何 Python 定时任务，也不依赖什么“神秘朋友的高端服务器”。纯前端直连数据源，所见即所得，一切都安排得井井有条。</p>\n<p>直接上在线演示链接：<a href=\"https://chengzuopeng.github.io/stock-dashboard/\" rel=\"noopener nofollow\" target=\"_blank\">stock-dashboard</a> （友情提示：摸鱼期间请谨慎使用，建议配合小窗口模式）。<br />\n<img alt=\"stock-overview\" class=\"lazyload\" /></p>\n<h2 id=\"核心解密数据层架构设计\">核心解密：数据层架构设计</h2>\n<p>为了保持代码整洁，我将所有针对 <code>stock-sdk</code> 的调用逻辑都封装在了 <code>src/services/sdk.ts</code> 中。</p>\n<p>这里主要实施了三个既实用又不矫情的工程化策略：</p>\n<ol>\n<li>\n<p><strong>全局单例与自动重试机制</strong><br />\n通过 <code>new StockSDK({ timeout, retry })</code> 初始化实例。面对网络波动或接口偶尔抽风的情况，SDK 内置的自动重试机制（支持最大 3 次重试及指数退避算法）能完美兜底。</p>\n</li>\n<li>\n<p><strong>智能内存缓存（TTL 策略）</strong><br />\n对于行业或概念列表这类变动频率极低的数据（毕竟它们不会在几秒内发生剧变），直接上缓存减少无效请求；而对于实时行情，则设置了 2~3 秒的生存期（TTL），既保证了数据的时效性，又避免了无意义的高频请求轰炸接口。</p>\n</li>\n<li>\n<p><strong>分层隔离：页面仅对接服务层</strong><br />\n翻阅 <code>src/pages/**</code> 下的代码，你几乎找不到 <code>new StockSDK()</code> 的身影。UI 层只负责调用诸如 <code>getFullQuotes / getTodayTimeline / getKlineWithIndicators</code> 等经过二次封装的业务方法，而类型定义则直接复用 <code>stock-sdk</code> 的导出。</p>\n</li>\n</ol>\n<p>顺便展示两段核心代码骨架，后续的所有功能模块皆构建于此基础之上：</p>\n<pre><code class=\"language-ts\">// src/services/sdk.ts\nexport const sdk = new StockSDK({ timeout: 30000, retry: { maxRetries: 3, baseDelay: 1000, maxDelay: 10000, backoffMultiplier: 2 } });\n\nexport async function getFullQuotes(codes: string[], useCache = true) {\n  const key = getCacheKey('getFullQuotes', codes);\n  if (useCache) {\n    return withCache(key, DEFAULT_TTL.quotes, () =&gt; sdk.getFullQuotes(codes));\n  }\n  return sdk.getFullQuotes(codes);\n}\n</code></pre>\n<pre><code class=\"language-ts\">// src/services/sdk.ts\nexport async function getAllAShareQuotes(options?: { batchSize?: number; concurrency?: number; onProgress?: (completed: number, total: number) =&gt; void }) {\n  return sdk.getAllAShareQuotes(options);\n}\n</code></pre>\n<hr />\n<h2 id=\"功能拆解各模块如何玩转-stock-sdk-数据\">功能拆解：各模块如何玩转 stock-sdk 数据？</h2>\n<p>路由配置位于 <code>src/router/index.tsx</code>，而各个功能页面则模块化地分布在 <code>src/pages/*</code> 目录下。接下也就是大家最关心的——按“用户交互路径”来逐一复盘。</p>\n<h3 id=\"1-全局搜索告别手动翻代码的痛苦\">1) 全局搜索：告别手动翻代码的痛苦</h3>\n<p>搜索栏组件位于 <code>src/components/layout/Header.tsx</code>，其背后的魔法仅需一行代码：</p>\n<ul>\n<li><code>search(keyword)</code> 映射到 <code>stock-sdk</code> 的 <code>sdk.search(keyword)</code></li>\n</ul>\n<p>为了优化体验，我添加了 300ms 的输入防抖处理。搜索结果完美支持个股与板块的混合查询，点击即达：</p>\n<ul>\n<li>行业板块跳转至：<code>/boards/industry/:code</code></li>\n<li>概念板块跳转至：<code>/boards/concept/:code</code></li>\n<li>个股详情跳转至：<code>/s/:code</code></li>\n</ul>\n<p>顺手还利用 localStorage 实现了一个简单的历史记录功能（<code>src/services/storage.ts</code>），毕竟很多时候，我们寻找的不是新标的，而是昨天没看完的那个它。</p>\n<hr />\n<h3 id=\"2-仪表盘-dashboard行情概览与自选速览\">2) 仪表盘 Dashboard：行情概览与自选速览</h3>\n<p>对应页面文件：<code>src/pages/Dashboard/Dashboard.tsx</code>。</p>\n<p>数据获取逻辑非常直白粗暴：</p>\n<ul>\n<li>指数行情：调用 <code>getFullQuotes(MAIN_INDICES)</code> 一次性获取上证、深成指、科创 50 等关键指数。</li>\n<li>板块概况：并行调用 <code>getIndustryList()</code> 和 <code>getConceptList()</code>。</li>\n<li>自选股预览：先从存储服务 <code>src/services/storage.ts</code> 读取自选列表，再通过 <code>getFullQuotes(watchlistCodes.slice(0, 50))</code> 批量获取前 50 只行情的快照。</li>\n</ul>\n<p>为了保证数据的鲜活度，配合 <code>usePolling</code> Hook（<code>src/hooks/usePolling.ts</code>）实现了每 5 秒自动轮询。贴心的是，当页面处于后台不可见状态时，轮询会自动挂起，绝不浪费你的浏览器资源。</p>\n<p>额外提一句：目前 Dashboard 上的“榜单”主要展示板块数据。如果想做全市场的个股排名，技术路径完全可以参考后面提到的“一日持股法”，也就是直接利用 <code>getAllAShareQuotes</code> 接口。</p>\n<hr />\n<h3 id=\"3-市场热力图-heatmap一图看懂资金流向\">3) 市场热力图 Heatmap：一图看懂资金流向</h3>\n<p><img alt=\"stock-heatmap\" class=\"lazyload\" /></p>\n<p>实现文件位于 <code>src/pages/Heatmap/Heatmap.tsx</code>，底层依赖 ECharts 的矩形树图（Treemap）。</p>\n<p>根据观察视角的不同，数据源也各异：</p>\n<ul>\n<li>行业视角：直接用 <code>getIndustryList()</code>，因为返回的数据中已经包含了涨跌幅、换手率及领涨股信息。</li>\n<li>概念视角：同理，调用 <code>getConceptList()</code>。</li>\n<li>自选视角：获取所有自选代码 <code>getAllWatchlistCodes()</code> 后，通过 <code>getAllQuotesByCodes(codes.slice(0, topK))</code> 批量拉取。</li>\n</ul>\n<p>至于“全市场个股”热力图（代码预留了接口，暂未开启），实现逻辑也不复杂：</p>\n<ol>\n<li>通过 <code>getIndustryConstituents(industryCode)</code> 获取特定板块成分股。</li>\n<li>用 <code>getAllQuotesByCodes(stockCodes)</code> 把行情数据补齐。</li>\n<li>最后组装数据喂给 Treemap 组件。</li>\n</ol>\n<p>热力图最大的魅力在于：<strong>告别枯燥的数字列表，红绿相间的色块让你瞬间洞察市场强弱结构。</strong></p>\n<hr />\n<h3 id=\"4-龙虎榜-rankings观察市场风向标\">4) 龙虎榜 Rankings：观察市场风向标</h3>\n<p><img alt=\"stock-leaderboard\" class=\"lazyload\" /></p>\n<p>页面路径：<code>src/pages/Rankings/Rankings.tsx</code>。</p>\n<p>实现方式属于“简单粗暴且有效”：</p>\n<ul>\n<li>并行获取 <code>getIndustryList()</code> 和 <code>getConceptList()</code>。</li>\n<li>前端直接根据 <code>changePercent</code>（涨跌幅）或 <code>turnoverRate</code>（换手率）进行排序，截取 Top 50。</li>\n</ul>\n<p>目前的榜单本质上是“板块排行榜”。如果未来要扩展到全市场个股排行，技术方案与后文的“选股器”一致。</p>\n<hr />\n<h3 id=\"5-板块透视追踪领涨先锋\">5) 板块透视：追踪领涨先锋</h3>\n<p>板块列表页位于 <code>src/pages/Boards/Boards.tsx</code>：</p>\n<ul>\n<li><code>getIndustryList()</code> 与 <code>getConceptList()</code> 一把梭。</li>\n<li>所谓的 Tab 切换，仅仅是前端对不同数据源数组的渲染切换。</li>\n<li>当然也支持按板块名称或领涨股进行检索。</li>\n</ul>\n<p>详情页见 <code>src/pages/Boards/BoardDetail.tsx</code>，这里展示了 API 的组合拳能力（按行业/概念分流）：</p>\n<ul>\n<li>基础信息：直接复用列表数据，减少一次网络请求。</li>\n<li>成分股列表：调用 <code>getIndustryConstituents(code)</code> 或 <code>getConceptConstituents(code)</code>。</li>\n<li>板块走势：拉取 <code>getIndustryKline</code> 或 <code>getConceptKline</code>。</li>\n<li>盘口快照：通过 <code>getIndustrySpot</code> 或 <code>getConceptSpot</code> 获取。</li>\n</ul>\n<p>为了保证流畅度，板块 K 线图目前只截取了最近 60 根数据，防止缩放图表时浏览器渲染压力过大。</p>\n<hr />\n<h3 id=\"6-自选监控-watchlist只看我在意的\">6) 自选监控 Watchlist：只看我在意的</h3>\n<p>核心页面：<code>src/pages/Watchlist/Watchlist.tsx</code>。所有的增删改查逻辑都封装在 <code>src/services/storage.ts</code> 中。</p>\n<p>行情刷新主要依赖：</p>\n<ul>\n<li><code>getAllQuotesByCodes(normalizedActiveCodes)</code></li>\n</ul>\n<p>特别提一下这里的细节处理：在请求前我会先通过 <code>normalizeStockCode</code>（位于 <code>src/utils/format.ts</code>）对代码进行标准化格式化，有效防止了 <code>SZ000001</code>、<code>sz000001</code> 和 <code>000001</code> 这种“一码多式”造成的去重失败或数据请求异常。</p>\n<hr />\n<h3 id=\"7-个股深度分析-stockdetail全维数据一览无余\">7) 个股深度分析 StockDetail：全维数据一览无余</h3>\n<p><img alt=\"stock-detail\" class=\"lazyload\" /></p>\n<p>页面位置：<code>src/pages/StockDetail/StockDetail.tsx</code>。这是整个项目中承载信息量最大的页面，因为它聚合了极高密度的信息。</p>\n<p>它聚合了多维度的 API 数据：</p>\n<ul>\n<li>实时报价：<code>getFullQuotes([code])</code></li>\n<li>当日分时图（1分钟级）：<code>getTodayTimeline(code)</code></li>\n<li>分钟级 K 线（5/15/30/60）：<code>getMinuteKline(code, { period })</code></li>\n<li>历史 K 线（日/周/月）及复权：<code>getKlineWithIndicators(code, { period, adjust: 'qfq', indicators })</code></li>\n<li>资金流向监测：<code>getFundFlow([code])</code></li>\n<li>盘口大单监控：<code>getPanelLargeOrder([code])</code></li>\n</ul>\n<p>我个人非常推崇 <code>getKlineWithIndicators</code> 这个接口：只需传入你想要的指标参数（如 MA, MACD, KDJ, RSI, BOLL等），SDK 就能把计算好的指标数据连同 K 线一起返回。前端只需负责绘图，彻底告别了在前端手写复杂技术指标计算逻辑的噩梦（少写代码 = 少出 Bug = 长命百岁）。</p>\n<p>在这里，轮询策略也做了精细化分层：</p>\n<ul>\n<li>基础行情：2 秒/次</li>\n<li>分时图：3 秒/次</li>\n<li>资金流向：10 秒/次</li>\n</ul>\n<hr />\n<h3 id=\"8-策略扫描器-scanner量化交易的初体验\">8) 策略扫描器 Scanner：量化交易的初体验</h3>\n<p>页面：<code>src/pages/Scanner/Scanner.tsx</code>。</p>\n<p>扫描逻辑简述如下：</p>\n<ol>\n<li><strong>确定股票池</strong>：\n<ul>\n<li>既可以是你的“自选股列表”。</li>\n<li>也可以是某个板块的成分股，例如调用 <code>getIndustryConstituents('BK0475')</code>。</li>\n</ul>\n</li>\n<li><strong>批量分析</strong>：\n<ul>\n<li>遍历每只股票，调用 <code>getKlineWithIndicators</code> 获取带指标的 K 线数据。</li>\n</ul>\n</li>\n<li><strong>信号匹配</strong>：\n<ul>\n<li>前端逻辑判断最近两根 K 线是否满足预设形态（如均线金叉、MACD 金叉、RSI 超买超卖等）。</li>\n</ul>\n</li>\n</ol>\n<p>虽然这个功能带有一定的“心里安慰”属性，但它确确实实把模糊的“看涨感觉”转化为了可执行的“触发条件”。</p>\n<hr />\n<h3 id=\"9-个性化设置-settings打造顺手的工具\">9) 个性化设置 Settings：打造顺手的工具</h3>\n<p><img alt=\"stock-settings\" class=\"lazyload\" /></p>\n<p>页面：<code>src/pages/Settings/Settings.tsx</code>。</p>\n<p>这个页面并没有调用任何 <code>stock-sdk</code> 接口，它的使命是将你的使用偏好（刷新频率、红涨绿跌配色、各类指标的默认参数等）持久化保存到 localStorage。这样，无论何时打开页面，它都还是那个你最熟悉的样子。</p>\n<hr />\n<h2 id=\"重头戏一日持股策略尾盘选股前端实现的全市场扫描\">重头戏：一日持股策略（尾盘选股）——前端实现的全市场扫描</h2>\n<p><img alt=\"stock-last\" class=\"lazyload\" /></p>\n<p>该功能位于 <code>src/pages/EndOfDayPicker/EndOfDayPicker.tsx</code>。我在这个页面实现了一套经典的“三步走”选股漏斗，其核心动力源自强大的 <strong><code>getAllAShareQuotes</code></strong> 接口。</p>\n<h3 id=\"第一阶段全量-a-股行情抓取\">第一阶段：全量 A 股行情抓取</h3>\n<pre><code class=\"language-ts\">// src/pages/EndOfDayPicker/EndOfDayPicker.tsx\nconst quotes = await getAllAShareQuotes({\n  batchSize: 500,\n  concurrency: 5,\n  onProgress: (completed, total) =&gt; setLoadingProgress({ completed, total, stage: '数据加载中...' }),\n});\n</code></pre>\n<p>这一步调用的是 SDK 的重磅接口：</p>\n<ul>\n<li><code>sdk.getAllAShareQuotes(options?: GetAllAShareQuotesOptions): Promise&lt;FullQuote[]&gt;</code></li>\n<li>参数 <code>batchSize</code> 控制单次批大小（默认 500），<code>concurrency</code> 控制并发数（默认 7）。</li>\n</ul>\n<p>我采取了相对稳健的策略（并发设为 5），兼顾了浏览器的性能负载和网络稳定性。配合 <code>onProgress</code> 回调，用户能看到实时的进度条反馈，体验流畅不卡顿，不会误以为网页卡死。</p>\n<h3 id=\"第二阶段基础指标粗筛\">第二阶段：基础指标粗筛</h3>\n<p>拿到全市场 5000+ 只股票的 <code>FullQuote</code> 数据后，我们先进行一轮粗筛（字段直接取自 <code>FullQuote</code>）：</p>\n<ul>\n<li>流通市值 (<code>circulatingMarketCap</code>)</li>\n<li>量比 (<code>volumeRatio</code>)</li>\n<li>涨跌幅 (<code>changePercent</code>)</li>\n<li>换手率 (<code>turnoverRate</code>)</li>\n<li>ST/风险股过滤</li>\n</ul>\n<p>这一步逻辑封装在 <code>filterStocksBasic()</code> 中，通常能把目标池从 5000+ 缩减到几百甚至几十只，如果不筛这一刀，后续拉取分时数据会直接把浏览器送走。</p>\n<h3 id=\"第三阶段分时图形态精选\">第三阶段：分时图形态精选</h3>\n<p>对于粗筛剩下的候选股，我们再进行更细致的分时图分析：</p>\n<ul>\n<li>调用 <code>getTodayTimeline(fullCode)</code> 拉取分时数据（注意拼接 sh/sz/bj 前缀）。</li>\n<li>计算核心强度指标：<code>timelineAboveAvgRatio</code>（即：现价高于均价的时间占比，由 <code>price</code> 和 <code>avgPrice</code> 对比得出）。</li>\n</ul>\n<p>为了防止浏览器崩溃，<code>filterWithTimeline()</code> 中手动控制了分时数据请求的并发量（batchSize = 5）。<br />\n最终结果按 <code>timelineAboveAvgRatio</code> 降序排列，并在列表中展示迷你的分时走势图。这样一来，尾盘选股的效率直接起飞。</p>\n<hr />\n<h2 id=\"写在最后谁需要这个工具\">写在最后：谁需要这个工具？</h2>\n<p>如果你渴望拥有一个“既能看盘、又能筛股、还能顺便管理自选”的轻量级看板，同时极其排斥维护后端服务或编写复杂的 Python 脚本，那么这个纯前端方案绝对是你的不二之选。<strong>核心思路就是利用 <code>stock-sdk</code> 将强大的数据能力引入前端，剩下的就是单纯的 UI 组装与逻辑编排</strong>。</p>\n<p>本地启动非常简单：</p>\n<pre><code class=\"language-bash\">yarn install\nyarn dev\n</code></pre>\n<p>最后不得不俗套地提醒一句：页面底部的 disclaimer “仅供学习参考，不构成投资建议”并非摆设。代码虽可自信敲，投资仍需谨慎行。</p>\n<hr />\n<h2 id=\"传送门\">传送门</h2>\n<ul>\n<li>在线看板： <a href=\"https://chengzuopeng.github.io/stock-dashboard/\" rel=\"noopener nofollow\" target=\"_blank\">https://chengzuopeng.github.io/stock-dashboard/</a></li>\n<li>SDK 文档： <a href=\"https://stock-sdk.linkdiary.cn/\" rel=\"noopener nofollow\" target=\"_blank\">https://stock-sdk.linkdiary.cn/</a></li>\n<li>SDK 演练场： <a href=\"https://stock-sdk.linkdiary.cn/playground/\" rel=\"noopener nofollow\" target=\"_blank\">https://stock-sdk.linkdiary.cn/playground/</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 19:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/chengzp\">程序猿的程</a>&nbsp;\n阅读(<span id=\"post_view_count\">11</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI → JSON → UI",
      "link": "https://www.cnblogs.com/guangzan/p/19487446",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/guangzan/p/19487446\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 15:23\">\n    <span>AI → JSON → UI</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"背景\">背景</h2>\n<p>过去两年，AI 生成 UI 的实践基本集中在两种路径上。第一种是直接让模型生成 JSX、HTML 或 CSS。这条路线的优势在于自由度极高，模型几乎不受约束，看起来“什么都能写”。但在真实工程环境中，这种方式几乎不可控：输出结构不稳定，无法保证组件边界，难以做权限与审计控制，生成的代码经常无法编译或违背工程约定，更重要的是，它与实际业务中的组件体系和设计系统严重脱节。</p>\n<p>另一条路线是低代码或 schema 驱动 UI，例如基于 JSON Schema 或表单 schema 的方案。这类方案在工程上是可控的，结构稳定、可校验、可复用，但它们本质上是为“人编写配置”设计的，而不是为“模型生成结构”设计的。schema 表达能力有限，扩展成本高，并且与自然语言之间的映射并不自然，Prompt 往往需要大量人工约束。</p>\n<p>Vercel 刚刚开源了 json-render，json-render 的出现，本质上是对这两条路线的重新切分与组合。它并没有试图让 AI 写前端代码，也没有把 AI 限制在传统低代码 schema 中，而是引入了一个中间层：<strong>JSON UI AST</strong>。AI 只能生成这种 AST，而 AST 的能力边界完全由开发者定义。渲染、状态、行为解释全部留在业务侧完成。开发者因此可以安全地让用户通过自然语言生成仪表盘、小部件或数据视图，而不需要把执行权交给模型。</p>\n<p><img alt=\"iShot_2026-01-15_15.25.26\" src=\"https://img2024.cnblogs.com/blog/1501373/202601/1501373-20260115152759556-1171653435.gif\" /></p>\n<h2 id=\"整体架构json-render-是一个-dsl-解释系统\">整体架构：json-render 是一个 DSL 解释系统</h2>\n<p>从架构视角看，json-render 并不是一个 UI 框架，而是一个 DSL 执行系统。系统由三层构成：最底层是 Catalog，用来声明“系统允许 AI 使用哪些 UI 能力”；中间层是 JSON UI Tree，这是 AI 的唯一输出形式；最上层是 Renderer，由业务侧实现，用于解释 JSON 并渲染真实 UI。</p>\n<p>它们之间的关系可以用下面这张结构图来理解：</p>\n<pre><code>┌────────────┐\n│   Prompt   │\n└─────┬──────┘\n      │\n      ▼\n┌──────────────────┐\n│  LLM / AI Model  │\n└─────┬────────────┘\n      │  JSON UI AST（受 Catalog 严格约束）\n      ▼\n┌──────────────────┐\n│     Catalog      │  ← 能力白名单 / Schema / Grammar\n└─────┬────────────┘\n      │ 校验 + 解析\n      ▼\n┌──────────────────┐\n│    Renderer      │  ← React / Vue / Native\n└─────┬────────────┘\n      │\n      ▼\n┌──────────────────┐\n│   Real UI View   │\n└──────────────────┘\n</code></pre>\n<p>在这个模型中，AI 只参与“结构生成”，不参与“执行”。这也是 json-render 在工程上成立的根本原因。</p>\n<h2 id=\"从-catalog-到-ui\">从 Catalog 到 UI</h2>\n<h3 id=\"1-catalog系统的能力边界定义\">1. Catalog：系统的能力边界定义</h3>\n<p>下面这段代码是整个系统中最重要的入口，它定义了 AI 能使用的全部 UI 能力。</p>\n<pre><code class=\"language-ts\">import { createCatalog } from '@json-render/core'\nimport { z } from 'zod'\n\nexport const catalog = createCatalog({\n  components: {\n    Card: {\n      props: z.object({\n        title: z.string()\n      }),\n      hasChildren: true\n    },\n    Metric: {\n      props: z.object({\n        label: z.string(),\n        valuePath: z.string(),\n        format: z.enum(['number', 'currency', 'percent']).optional()\n      })\n    }\n  },\n  actions: {\n    refresh: {\n      params: z.object({})\n    }\n  }\n})\n</code></pre>\n<p>这里没有任何 UI 代码，只有能力声明。props 使用 Zod 定义，这意味着它不仅是类型提示，还包含运行时校验规则。如果你对 Zod 没有了解，可以看看这篇博文，<a href=\"https://www.cnblogs.com/guangzan/p/19350726\" target=\"_blank\">Zod：TypeScript 类型守卫与数据验证</a>。action 并不是函数实现，而是一个“意图声明”，它只描述“可以发生什么”，不描述“怎么发生”。</p>\n<p>Catalog 在系统中的地位，相当于一门语言的语法定义文件。AI 后续生成的所有 JSON，本质上都必须符合这套 grammar。</p>\n<h3 id=\"2-ai-输出的-json-ui-ast\">2. AI 输出的 JSON UI AST</h3>\n<p>当用户输入类似“生成一个收入仪表盘”的提示时，模型生成的结果不是 JSX，而是下面这样的 JSON：</p>\n<pre><code class=\"language-json\">{\n  \"type\": \"Card\",\n  \"props\": { \"title\": \"Revenue Overview\" },\n  \"children\": [\n    {\n      \"type\": \"Metric\",\n      \"props\": {\n        \"label\": \"Total Revenue\",\n        \"valuePath\": \"/metrics/revenue\",\n        \"format\": \"currency\"\n      }\n    }\n  ]\n}\n</code></pre>\n<p>这个 JSON 有几个非常关键的特征。它不包含任何函数、不包含条件表达式、不包含样式或状态逻辑。它只是结构化地描述“使用哪个组件，用什么参数，组件之间如何嵌套”。所有能力完全来源于 Catalog，因此这个 JSON 是可校验、可存储、可 diff、可审计、可回放的。</p>\n<h3 id=\"3-rendererjson-的解释执行\">3. Renderer：JSON 的解释执行</h3>\n<p>在 React 侧，Renderer 扮演的是解释器的角色。</p>\n<pre><code class=\"language-tsx\">import { Renderer } from '@json-render/react'\nimport { catalog } from './catalog'\n\nfunction App() {\n  return (\n    &lt;Renderer\n      catalog={catalog}\n      components={{\n        Card: ({ title, children }) =&gt; (\n          &lt;div className=\"card\"&gt;\n            &lt;h2&gt;{title}&lt;/h2&gt;\n            {children}\n          &lt;/div&gt;\n        ),\n        Metric: ({ label, value }) =&gt; (\n          &lt;div&gt;\n            {label}: {value}\n          &lt;/div&gt;\n        )\n      }}\n      data={{\n        metrics: { revenue: 120000 }\n      }}\n    /&gt;\n  )\n}\n</code></pre>\n<p>Renderer 并不关心 UI 长什么样，它只做三件事：根据 type 找到对应组件定义，根据 Catalog 校验 props 和 children，根据 valuePath 等规则完成数据注入。</p>\n<h2 id=\"为什么-json-render-是可控的\">为什么 json-render 是“可控的”</h2>\n<p>下面的借助 AI 能力分析基于 <code>vercel-labs/json-render</code> 主仓库。如果你对此不感兴趣，跳过这部分内容。</p>\n<h3 id=\"1-createcatalog能力被冻结的起点\">1. createCatalog：能力被冻结的起点</h3>\n<p>文件路径位于 <code>packages/core/src/create-catalog.ts</code>。这个函数的核心作用不是“注册组件”，而是“冻结能力边界”。</p>\n<p>简化后的核心逻辑可以理解为：</p>\n<pre><code class=\"language-ts\">export function createCatalog(definition) {\n  return {\n    components: definition.components,\n    actions: definition.actions,\n    validateNode(node) {\n      // 校验 type 是否存在\n      // 校验 props 是否符合 Zod schema\n      // 校验 children 是否被允许\n    }\n  }\n}\n</code></pre>\n<p>每一行代码都在服务一个目标：让 Catalog 成为一个不可突破的白名单。Renderer 和 AI 都无法绕过它。这也是为什么 json-render 把 Catalog 放在 core 包中，而不是 React 包中。</p>\n<h3 id=\"2-schema-校验ai-输出必须先编译再执行\">2. Schema 校验：AI 输出必须“先编译再执行”</h3>\n<p>在 JSON Tree 进入 Renderer 之前，系统会逐节点校验。type 是否在 Catalog 中声明，props 是否通过 Zod 校验，children 是否符合 hasChildren 约束，action 是否存在于白名单。这一过程本质上就是一次 AST 校验。</p>\n<p>这意味着 AI 的输出不是“运行时报错”，而是“不通过即拒绝执行”。在 AI UI 系统中，这是一个极其关键但经常被忽视的工程点。</p>\n<h3 id=\"3-renderer真正的解释器模型\">3. Renderer：真正的解释器模型</h3>\n<p>React Renderer 的内部逻辑并不是简单的 switch-case，而是一个递归解释过程。它根据节点的 type 查 Catalog，构造 props，解析 valuePath 注入数据，绑定 action handler，然后递归渲染 children。</p>\n<p>从架构角度看，它更接近一个 JSON AST Interpreter，而不是模板引擎。这也是 json-render 可以跨 React、Vue、Native 复用核心思想的原因。</p>\n<h3 id=\"4-valuepath刻意避免-ai-参与状态逻辑\">4. valuePath：刻意避免 AI 参与状态逻辑</h3>\n<p>valuePath 使用字符串路径描述数据依赖，例如：</p>\n<pre><code class=\"language-json\">\"valuePath\": \"/metrics/revenue\"\n</code></pre>\n<p>这样设计的直接结果是，AI 不需要理解状态结构，也不需要写任何状态逻辑。Renderer 统一负责解析路径、读取数据、触发更新。这在架构上刻意切断了“AI 直接操作状态”的可能性。</p>\n<p>下面是仅包含新增内容的补充章节，重点放在可落到源码层面的机制，避免概念化描述。示例代码与解释均基于 <code>vercel-labs/json-render</code> 当前仓库结构与实现思路。</p>\n<h2 id=\"prompt-与-catalog-的自动对齐\">Prompt 与 Catalog 的自动对齐</h2>\n<p>Prompt 与 Catalog 的自动对齐：不是“调 Prompt”，而是“导出 Grammar”。json-render 中，Prompt 与 Catalog 的对齐并不是通过人肉 Prompt Engineering 完成的，而是通过从 Catalog 派生一份机器可理解的能力描述，并将其注入到模型上下文中。这一点在 <code>packages/core</code> 中的设计非常关键。</p>\n<p>在 core 层，Catalog 本身并不是一个简单的对象，它包含了完整的组件定义、props schema 以及 action 描述。这些信息会被转换为一种“描述性结构”，用于告诉模型当前系统支持的 UI grammar。</p>\n<p>类似这样的逻辑：</p>\n<pre><code class=\"language-ts\">export function catalogToPrompt(catalog) {\n  return `\nYou can generate a JSON UI tree.\nAvailable components:\n${Object.entries(catalog.components).map(([name, def]) =&gt; `\n- ${name}\n  props: ${describeSchema(def.props)}\n  hasChildren: ${def.hasChildren}\n`).join('\\n')}\n\nAvailable actions:\n${Object.keys(catalog.actions).join(', ')}\n\nRules:\n- Output must be valid JSON\n- Only use listed components\n- Follow prop schemas strictly\n`\n}\n</code></pre>\n<p>这里的关键点不在于字符串本身，而在于信息来源完全来自 Catalog。换句话说，Catalog 是 single source of truth，Prompt 只是它的一种序列化视图。当开发者新增或修改组件定义时，Prompt 中允许模型使用的能力会自动发生变化，不存在“代码和 Prompt 不一致”的问题。这也是 json-render 能够避免大量“Prompt 腐化”的根本原因。</p>\n<p>从模型视角看，它面对的不是一段模糊的自然语言说明，而是一套接近 BNF 的 UI grammar 描述。模型生成 JSON UI Tree 的过程，本质上类似于在给定语法约束下生成 AST。这也是为什么 json-render 要使用 Zod 而不是仅靠 TypeScript 类型。Zod schema 可以被同时用于运行时校验和 Prompt 语义描述，形成闭环。</p>\n<h2 id=\"streaming-ui-的实现细节\">Streaming UI 的实现细节</h2>\n<p>流式构建 AST，而不是流式拼字符串。json-render 的 Streaming UI 能力，核心并不在“模型支持流式输出”，而在于 UI 的中间表示是可增量合并的 JSON AST。这一点在 React 包中的实现非常清晰。</p>\n<p>在 <code>packages/react</code> 中，可以看到类似 <code>useUIStream</code> 的 hook，其核心职责是：<br />\n维护一棵当前 UI Tree，并在模型流式输出时不断向这棵树中合并新节点。</p>\n<p>简化后的内部结构大致如下：</p>\n<pre><code class=\"language-ts\">// packages/react/src/use-ui-stream.ts（概念结构）\nexport function useUIStream() {\n  const [tree, setTree] = useState&lt;UITree | null&gt;(null)\n\n  function onChunk(chunk: string) {\n    const partialNode = parseChunkToNode(chunk)\n    if (!partialNode) return\n\n    setTree(prevTree =&gt; {\n      return mergeTree(prevTree, partialNode)\n    })\n  }\n\n  return { tree, onChunk }\n}\n</code></pre>\n<p>这里有两个非常关键但容易被忽略的点。</p>\n<p><code>parseChunkToNode</code> 并不是简单的 <code>JSON.parse</code>。模型在 streaming 模式下输出的通常是不完整 JSON，因此 json-render 采用的是逐段解析、延迟成型的策略。只有当一个节点在结构上是完整且通过 Catalog 校验时，才会被提升为“可合并节点”。<code>mergeTree</code> 是一个纯函数。它不依赖外部状态，只根据已有 UI Tree 和新节点生成下一棵 Tree。这使得每一次更新都是确定性的，也天然适合 React 的状态模型。</p>\n<p>在 Renderer 层，这棵 Tree 会被直接用于递归渲染：</p>\n<pre><code class=\"language-tsx\">function RenderNode({ node }) {\n  const Component = components[node.type]\n\n  const resolvedProps = resolveProps(node.props)\n  const children = node.children?.map(child =&gt;\n    &lt;RenderNode key={child.id} node={child} /&gt;\n  )\n\n  return &lt;Component {...resolvedProps}&gt;{children}&lt;/Component&gt;\n}\n</code></pre>\n<p>由于 Tree 始终是“已校验的合法结构”，Renderer 不需要关心节点是否完整，只需要关心“当前有哪些节点已经存在”。这也是 Streaming UI 能在生成未完成时就安全渲染的根本原因。</p>\n<h2 id=\"streaming-与-catalog-校验如何协同工作\">Streaming 与 Catalog 校验如何协同工作</h2>\n<p>Streaming UI 并不是绕过校验机制的捷径，恰恰相反，它依赖校验机制才能成立。在实际流程中，每一个候选节点在被合并进 UI Tree 之前，都会经过 Catalog 的校验逻辑：</p>\n<pre><code class=\"language-ts\">// packages/core/src/validate-node.ts（概念结构）\nexport function validateNode(node, catalog) {\n  const def = catalog.components[node.type]\n  if (!def) throw new Error('Unknown component')\n\n  def.props.parse(node.props)\n\n  if (node.children &amp;&amp; !def.hasChildren) {\n    throw new Error('Children not allowed')\n  }\n}\n</code></pre>\n<p>Streaming 模式下，这个校验发生得更频繁，但粒度更小。系统宁可“暂时不渲染”，也不会把一个非法节点交给 Renderer。这保证了 UI 在任何时刻都是一个合法子集，而不是半成品垃圾状态。</p>\n<p>Prompt 与 Catalog 的自动对齐，确保模型“不会幻想不存在的能力”；Streaming UI 的 AST 级增量构建，确保 UI“可以在不完整时仍然正确运行”。两者结合，使 json-render 的执行模型更接近编译器与解释器，而不是模板生成器。从工程视角看，这意味着一个重要转变：<strong>UI 生成不再是一次性结果，而是一个可观察、可中断、可回滚的过程。</strong>这也是 json-render 能够真正进入生产系统，而不仅停留在 Demo 层面的根本原因。</p>\n<h2 id=\"json-render-真正解决了什么\">json-render 真正解决了什么</h2>\n<p>json-render 本身并不是一种全新的技术范式。<strong>“用受限结构描述 UI，再由运行时解释执行”这一思想，在前端工程中早已反复出现过。</strong>早期的 JSON Schema Form、react-jsonschema-form、Formily、本质上都是用结构化数据描述界面，再由渲染器生成真实 UI。低代码平台、搭建系统、配置化后台，几乎全部建立在同一逻辑之上。即便在 AI 出现之前，这种模式也已经非常成熟：工程师通过 schema 描述组件、属性和布局，运行时负责校验与渲染，业务侧只操作结构而不直接触碰代码。json-render 并没有发明这种模式，它继承的正是这一整条技术脉络。</p>\n<p>json-render 的不同之处在于，它首次把“模型生成”作为一等公民纳入设计前提。传统 schema UI 假设配置由人编写，因此更强调完整性、可读性和编辑体验；而 json-render 假设结构由模型生成，因此更强调语法边界清晰、失败可恢复、部分结果可执行，以及与 Prompt 的自动对齐能力。从这个角度看，json-render 更像是“为 AI 重新设计的一代 schema UI 执行模型”。它真正解决的问题并不是“怎么用 JSON 渲染 UI”，而是当结构来源变成不可靠的模型时，工程边界应该在哪里。它给出的答案非常明确：AI 只负责生成结构化意图，工程师负责能力定义、执行与渲染，JSON 作为唯一中介和约束层。这使得 AI UI 不再是一次性 Demo，而是可以进入生产系统的工程能力。在当前阶段，这是少数真正站在工程立场思考 AI UI 的方案之一。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://json-render.dev/\" rel=\"noopener nofollow\" target=\"_blank\">json-render.dev</a></li>\n<li><a href=\"https://github.com/vercel-labs/json-render\" rel=\"noopener nofollow\" target=\"_blank\">github.com/vercel-labs/json-render</a></li>\n<li><a href=\"https://vercel.com/blog\" rel=\"noopener nofollow\" target=\"_blank\">vercel.com/blog</a></li>\n<li><a href=\"https://www.cnblogs.com/guangzan/p/19350726\" target=\"_blank\">Zod：TypeScript 类型守卫与数据验证</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 15:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/guangzan\">guangzan</a>&nbsp;\n阅读(<span id=\"post_view_count\">270</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "SeaTunnel(2.3.12)的高级用法（四）：多个source、多个sink",
      "link": "https://www.cnblogs.com/kakarotto-chen/p/19487270",
      "published": "",
      "description": "<h2>\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kakarotto-chen/p/19487270\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 15:08\">\n    <span>SeaTunnel(2.3.12)的高级用法（四）：多个source、多个sink</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"postbody\">\n            <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前置知识seatunnel配置中有数据流data-flow转的概念\">前置知识：seatunnel配置中有数据流（Data Flow）转的概念</h2>\n<p>见：<a href=\"https://www.cnblogs.com/kakarotto-chen/p/19487384\" target=\"_blank\">https://www.cnblogs.com/kakarotto-chen/p/19487384</a></p>\n<h2 id=\"demo1两个source汇聚到一个sink\">demo1：两个source汇聚到一个sink</h2>\n<ul>\n<li>\n<p>关键配置：sink的：plugin_input = [\"source_data1\", \"source_data2\"]</p>\n</li>\n<li>\n<p>对应模型</p>\n</li>\n</ul>\n<pre><code>┌──────────┐\n│ Source A │──┐\n└──────────┘  │\n              ├──▶  Sink\n┌──────────┐  │\n│ Source B │──┘\n└──────────┘\n</code></pre>\n<ul>\n<li>执行语句</li>\n</ul>\n<pre><code># ds-st-demo10-2-mysql2pgsql.conf\nsh /data/tools/seatunnel/seatunnel-2.3.12/bin/seatunnel.sh --config /data/tools/seatunnel/myconf/ds-st-demo10-2-mysql2pgsql.conf -i -DJvmOption=\"-Xms2G -Xmx2G\" -m local\n</code></pre>\n<ul>\n<li>建表</li>\n</ul>\n<pre><code>-- ds-st-demo10-2-mysql2pgsql.conf\nCREATE TABLE \"public\".\"t_8_100w_imp_st_ds_demo10\" (\n  id BIGINT PRIMARY KEY,\n  user_name VARCHAR(2000),\n  sex VARCHAR(20),\n  decimal_f NUMERIC(32, 6),\n  phone_number VARCHAR(20),\n  age INT,\n  create_time TIMESTAMP,\n  description TEXT,\n  address VARCHAR(2000) DEFAULT '未知',\n  my_status INT\n);\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"id\" IS '主键';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"user_name\" IS '名字';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"sex\" IS '性别：男；女';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"decimal_f\" IS '大数字';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"phone_number\" IS '电话';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"age\" IS '字符串年龄转数字';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"create_time\" IS '新增时间';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"description\" IS '大文本';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"address\" IS '空地址转默认值：未知';\nCOMMENT ON COLUMN \"public\".\"t_8_100w_imp_st_ds_demo10\".\"my_status\" IS '状态';\n\n</code></pre>\n<ul>\n<li>conf配置</li>\n</ul>\n<pre><code>env {\n  # 任务名字：业务中可以弄表id\n  job.name = \"ds-st-demo10.conf\"\n  # 最大批线程数：并行度（线程数）\n  parallelism = 5\n  # 任务模式：BATCH:批处理模式；STREAMING:流处理模式\n  job.mode = \"BATCH\"\n}\n\nsource {\n  # 第一个数据集\n  jdbc {\n    # 给这个数据集起个名字\n    plugin_output = \"source_data1\"\n  \n    url = \"jdbc:mysql://ip:port/cs1\"\n    driver = \"com.mysql.cj.jdbc.Driver\"\n    user = \"root\"\n    password = \"***\"\n    # sql\n    query = \"select id,name as user_name,sex,decimal_f,phone_number,CAST(age AS SIGNED) as age,create_time,description,address from t_8_100w where id &lt; 10\"\n    \n    # 并行读取配置\n    # 分片的字段：支持：String、Number(int, bigint, decimal, ...)、Date\n    partition_column = \"id\"\n    # 表的分割大小（行数）：每个分片的数据行（默认8096行）。最后分片数=表的总行数 / split.size\n    split.size = 50000\n    # 分片数，匹配并行度parallelism（2.3.12已不推荐配置了，用split.size来代替）\n    # partition_num = 5\n    # 最大批处理数:查询的行提取大小(指定当前任务每次执行时读取数据条数,该值(默认1000)受运行内存影响,若该值较大或单条数据量较大，需适当调整运行内存大小。)\n    fetch_size = 10000\n    \n    # 连接参数\n    # 连接超时时间300ms\n    connection_check_timeout_sec = 300\n    # 其他jdbc的参数\n    properties = {\n      useUnicode = true\n      characterEncoding = \"utf8\"\n      # 时区，不同数据库参数不一样\n      serverTimezone = \"Asia/Shanghai\"\n      # 使用游标提高大结果集性能\n      useCursorFetch = \"true\"\n      # 每次获取行数\n      defaultFetchSize = \"10000\"\n    }\n  }\n  \n  # 第二个数据集\n  jdbc {\n    # 给这个数据集起个名字\n    plugin_output = \"source_data2\"\n  \n    url = \"jdbc:mysql://ip:port/cs1\"\n    driver = \"com.mysql.cj.jdbc.Driver\"\n    user = \"root\"\n    password = \"***\"\n    # \n    query = \"select id,name as user_name,sex,decimal_f,phone_number,CAST(age AS SIGNED) as age,create_time,description,address from t_8_100w where id &gt; 10 and id &lt; 20\"\n    \n    # 并行读取配置\n    # 分片的字段：支持：String、Number(int, bigint, decimal, ...)、Date\n    partition_column = \"id\"\n    # 表的分割大小（行数）：每个分片的数据行（默认8096行）。最后分片数=表的总行数 / split.size\n    split.size = 50000\n    # 分片数，匹配并行度parallelism（2.3.12已不推荐配置了，用split.size来代替）\n    # partition_num = 5\n    # 最大批处理数:查询的行提取大小(指定当前任务每次执行时读取数据条数,该值(默认1000)受运行内存影响,若该值较大或单条数据量较大，需适当调整运行内存大小。)\n    fetch_size = 10000\n    \n    # 连接参数\n    # 连接超时时间300ms\n    connection_check_timeout_sec = 300\n    # 其他jdbc的参数\n    properties = {\n      useUnicode = true\n      characterEncoding = \"utf8\"\n      # 时区，不同数据库参数不一样\n      serverTimezone = \"Asia/Shanghai\"\n      # 使用游标提高大结果集性能\n      useCursorFetch = \"true\"\n      # 每次获取行数\n      defaultFetchSize = \"10000\"\n    }\n  }\n}\n\n# 清洗转换（简单的清洗转换，直接在source的query的sql中处理了就行）\ntransform {\n  # 1. 字段映射：sql中做了，实际生成中不在这里处理。直接在source的query的sql中处理了就行\n  # 还可以用：FieldMapper 插件，来映射字段\n  \n  # 转换age为数字类型（pgsql必须转）\n  \n  # 2. 手机号脱敏：13812341234 -&gt; 138****1234\n  \n  # 3. 年龄转换：字符串转整数（实际生产中，不用转换，也没有内置的转换插件，可以直接保存成功）\n\n  # 4. 性别转换：1-&gt;男，2-&gt;女\n  \n  # 5. 数据过滤：只保留 age &gt; 25 的记录。\n  \n  # 6. 地址默认值：空地址设为'未知'\n}\n\nsink {\n  jdbc {\n    # 接收的最终数据集（汇聚到一个结果中）\n    plugin_input = [\"source_data1\", \"source_data2\"]\n    \n    url = \"jdbc:postgresql://ip:5432/source_db\"\n    driver = \"org.postgresql.Driver\"\n    user = \"postgres\"\n    password = \"123456\"\n    # \n    # query = \"\"\n    \n    # 自动生成sql的配置，和query参数互斥\n    # 生成自动插入sql。如果目标库没有表，也会自动建表\n    generate_sink_sql = true\n    # database必须要，因为generate_sink_sql=true。\n    database = source_db\n    # 自动生成sql时，table必须要。\n    table = \"public.t_8_100w_imp_st_ds_demo10\"\n    # 生成类似：INSERT INTO …… ON CONFLICT (\"主键\") DO UPDATE SET …… 的sql\n    # enable_upsert = true\n    # 判断值唯一的健：此选项用于支持在自动生成 SQL 时进行 insert，delete 和 update 操作。\n    # primary_keys = [\"id\"]\n\n    # 表结构处理策略：表不存在时报错（任务失败），一般用：CREATE_SCHEMA_WHEN_NOT_EXIST（表不存在时创建表；表存在时跳过操作（保留数据））\n    schema_save_mode = \"ERROR_WHEN_SCHEMA_NOT_EXIST\"\n    # 插入数据的处理策略\n    # APPEND_DATA：保留表结构和数据，追加新数据（不删除现有数据）(一般用这个)\n    # DROP_DATA：保留表结构，删除表中所有数据（清空表）——实现清空重灌\n    # CUSTOM_PROCESSING :用户定义处理。需要配合：custom_sql使用\n    data_save_mode = \"DROP_DATA\"\n    # 当 data_save_mode 选择 CUSTOM_PROCESSING 时，您应该填写 CUSTOM_SQL 参数。此参数通常填入可执行的 SQL。SQL 将在同步任务之前执行。\n    #可以实现：同步删除（执行前置update、truncate的sql等）\n    #这个sql未执行，不知道为啥。\n    #这个sql已经执行。原因：因为generate_sink_sql=true的原因。才会执行custom_sql。（只有自动生成sql的时候，这个才会执行）\n    custom_sql = \"\"\"update \"source_db\".\"public\".\"t_8_100w_imp_st_ds_demo10\" set \"my_status\" = 23\"\"\"\n    \n    # 批量写入条数\n    batch_size = 10000\n    # 批次提交间隔\n    batch_interval_ms = 500\n    # 重试次数\n    max_retries = 3\n    \n    # 连接参数\n    # 连接超时时间300ms\n    connection_check_timeout_sec = 300\n    # 其他jdbc的参数\n    properties = {\n      # PostgreSQL专用参数\n      # PostgreSQL的批量优化（注意大小写）\n      reWriteBatchedInserts = \"true\"  \n      # 如果需要时区设置\n      options = \"-c timezone=Asia/Shanghai\"\n    }\n  }\n}\n</code></pre>\n<ul>\n<li>结果(汇聚了19条数据)</li>\n</ul>\n<pre><code>2026-01-15 14:28:15,952 INFO  [s.c.s.s.c.ClientExecuteCommand] [main] - \n***********************************************\n           Job Statistic Information\n***********************************************\nStart Time                : 2026-01-15 14:28:11\nEnd Time                  : 2026-01-15 14:28:15\nTotal Time(s)             :                   4\nTotal Read Count          :                  19\nTotal Write Count         :                  19\nTotal Failed Count        :                   0\n***********************************************\n</code></pre>\n<h2 id=\"demo2一个source分发到两个sink\">demo2：一个source分发到两个sink</h2>\n<p>……………………未完待续</p>\n\n</div>\n<div class=\"clear\"></div>\n\n        </div>\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-01-15 15:08</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kakarotto-chen\">C_C_菜园</a>&nbsp;\n阅读(<span id=\"post_view_count\">20</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "如何通过 C# 将 PPT 文档转换为 PDF 格式",
      "link": "https://www.cnblogs.com/jazz-z/p/19486170",
      "published": "",
      "description": "<div class=\"postcontent\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在日常开发和办公场景中，将 PowerPoint（PPT/PPTX） 转换为 PDF 格式是高频需求。PDF 格式具有跨平台兼容性强、格式固定不易篡改、便于分发归档等优势。本文将介绍如何使用一款 .NET PowerPoint 组件通过 C# 实现 PPT 转 PDF，并提供完整代码示例。</p>\n<h2 id=\"1-安装-net-库\">1. 安装 .NET 库</h2>\n<p>Spire.Presentation 是一款专门用于处理 PowerPoint 文档的 .NET 组件，无需依赖 Microsoft Office 或 PowerPoint 客户端即可完成 PPT 文档的读取、编辑和格式转换。推荐通过 NuGet 包管理器安装，步骤如下：</p>\n<ol>\n<li>打开 Visual Studio，创建任意 C# 项目（如Console App）；</li>\n<li>右键项目→“管理NuGet程序包”；</li>\n<li>搜索“Spire.Presentation”，选择对应版本安装；</li>\n<li>也可通过NuGet命令行安装：</li>\n</ol>\n<pre><code class=\"language-bash\">Install-Package Spire.Presentation\n</code></pre>\n<h2 id=\"2-基础示例单个-powerpoint-文件转-pdf\">2. 基础示例：单个 PowerPoint 文件转 PDF</h2>\n<p>这是最常用的场景，支持 PPT/PPTX 格式输入，直接通过 <code>SaveToFile</code> 方法输出为 PDF 文件：</p>\n<pre><code class=\"language-csharp\">using System;\nusing Spire.Presentation;\n\nnamespace PptToPdfDemo\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            try\n            {\n                // 1. 定义文件路径\n                string pptFilePath = @\"D:\\Demo\\source.pptx\"; // 输入PPT路径\n                string pdfFilePath = @\"D:\\Demo\\output.pdf\";   // 输出PDF路径\n\n                // 2. 加载PPT文档\n                Presentation presentation = new Presentation();\n                presentation.LoadFromFile(pptFilePath);\n\n                // 3. 转换为PDF并保存\n                // 可选参数：PDF导出选项（如压缩、权限等），此处使用默认配置\n                presentation.SaveToFile(pdfFilePath, FileFormat.PDF);\n\n                // 4. 释放资源（关键，避免内存泄漏）\n                presentation.Dispose();\n\n                Console.WriteLine(\"PPT转PDF成功！\");\n            }\n            catch (Exception ex)\n            {\n                // 异常处理：捕获文件不存在、格式不支持、权限不足等问题\n                Console.WriteLine($\"转换失败：{ex.Message}\");\n            }\n        }\n    }\n}\n</code></pre>\n<h3 id=\"3-批量转换转换多个-powerpoint-文件为-pdf\">3. 批量转换：转换多个 PowerPoint 文件为 PDF</h3>\n<p>通过遍历文件夹实现批量转换，适合处理大量 PPT 文件：</p>\n<pre><code class=\"language-csharp\">using System;\nusing System.IO;\nusing Spire.Presentation;\n\nnamespace BatchPptToPdf\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            // 源PPT文件夹路径\n            string pptFolderPath = @\"D:\\Demo\\PptFiles\";\n            // 输出PDF文件夹路径\n            string pdfFolderPath = @\"D:\\Demo\\PdfFiles\";\n\n            // 确保输出文件夹存在\n            if (!Directory.Exists(pdfFolderPath))\n            {\n                Directory.CreateDirectory(pdfFolderPath);\n            }\n\n            // 遍历文件夹中的PPT/PPTX文件\n            string[] pptFiles = Directory.GetFiles(pptFolderPath, \"*\", SearchOption.TopDirectoryOnly)\n                .Where(file =&gt; file.EndsWith(\".ppt\", StringComparison.OrdinalIgnoreCase) \n                             || file.EndsWith(\".pptx\", StringComparison.OrdinalIgnoreCase))\n                .ToArray();\n\n            foreach (string pptFile in pptFiles)\n            {\n                try\n                {\n                    // 获取文件名（不含扩展名），用于生成PDF文件名\n                    string fileName = Path.GetFileNameWithoutExtension(pptFile);\n                    string pdfFile = Path.Combine(pdfFolderPath, $\"{fileName}.pdf\");\n\n                    // 加载并转换\n                    using (Presentation presentation = new Presentation())\n                    {\n                        presentation.LoadFromFile(pptFile);\n                        presentation.SaveToFile(pdfFile, FileFormat.PDF);\n                    }\n\n                    Console.WriteLine($\"已转换：{pptFile} → {pdfFile}\");\n                }\n                catch (Exception ex)\n                {\n                    Console.WriteLine($\"转换失败 {pptFile}：{ex.Message}\");\n                }\n            }\n\n            Console.WriteLine(\"批量转换完成！\");\n        }\n    }\n}\n</code></pre>\n<h3 id=\"4-进阶示例将-powerpoint-转换为加密的-pdf\">4. 进阶示例：将 PowerPoint 转换为加密的 PDF</h3>\n<p>还可以在转换时直接加密保护 PDF 文件，并为 PDF 设置权限：</p>\n<pre><code class=\"language-csharp\">using Spire.Presentation;\nusing Spire.Presentation.External.Pdf;\n\nnamespace ConvertToEncryptedPdf\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            // 定义明确的文件路径（建议替换为你的实际路径）\n            string inputPptPath = @\"C:\\Users\\Administrator\\Desktop\\Input.pptx\";\n            string outputPdfPath = @\"C:\\Users\\Administrator\\Desktop\\ToEncryptedPdf.pdf\";\n            \n            // 使用using语句自动释放Presentation资源（优于手动Dispose）\n            try\n            {\n                using (Presentation presentation = new Presentation())\n                {\n                    // 加载PPT文件\n                    presentation.LoadFromFile(inputPptPath);\n\n                    // 获取PDF保存选项\n                    SaveToPdfOption option = presentation.SaveToPdfOption;\n                    \n                    // 设置PDF密码和权限\n                    // 参数说明：\n                    // 1. 用户密码（打开PDF需要输入的密码）：abc-123\n                    // 2. 所有者密码（用于修改PDF权限的密码）：owner-456（可自定义）\n                    // 3. PDF权限：允许打印 + 允许填写表单\n                    // 4. 加密级别：默认128位（高安全性）\n                  option.PdfSecurity.Encrypt(\"abc-123\", \"owner-456\", \n                        PdfPermissionsFlags.Print | PdfPermissionsFlags.FillFields, \n                        PdfEncryptionKeySize.Key128Bit);\n\n                    // 保存为加密PDF\n                    presentation.SaveToFile(outputPdfPath, FileFormat.PDF, pdfOptions);\n\n                    Console.WriteLine(\"PPT已成功转换为加密PDF！\");\n                    Console.WriteLine($\"输出路径：{outputPdfPath}\");\n                }\n            }\n            catch (Exception ex)\n            {\n                // 捕获所有可能的异常并提示\n                Console.WriteLine($\"转换失败：{ex.Message}\");\n            }\n\n            // 暂停控制台，便于查看结果\n            Console.ReadLine();\n        }\n    }\n}\n</code></pre>\n<h2 id=\"5-关键注意事项\">5. 关键注意事项</h2>\n<ol>\n<li>\n<p><strong>格式兼容性</strong>：</p>\n<ul>\n<li>支持输入格式：PPT、PPTX、PPS、PPSX 等；</li>\n<li>复杂PPT元素（如3D图表、自定义动画、嵌入式视频）转换后可能丢失或显示异常（。</li>\n</ul>\n</li>\n<li>\n<p><strong>资源释放</strong>：</p>\n<ul>\n<li>必须通过 <code>Dispose()</code> 方法释放 <code>Presentation</code> 对象，或使用 <code>using</code> 语句（推荐），否则易导致内存泄漏，尤其批量转换时需注意。</li>\n</ul>\n</li>\n<li>\n<p><strong>权限问题</strong>：</p>\n<ul>\n<li>确保程序对输入/输出路径有读写权限，否则会抛出 <code>UnauthorizedAccessException</code>。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"6-替代方案参考\">6. 替代方案参考</h2>\n<ol>\n<li><strong>LibreOffice SDK</strong>：免费开源，需部署 LibreOffice 服务，API 较复杂；</li>\n<li><strong>OpenXML SDK + iTextSharp</strong>：仅支持 PPTX（OpenXML 格式），需自行处理布局转换，开发成本高；</li>\n<li><strong>GroupDocs.Conversion</strong>：有免费额度，云原生支持，但依赖网络。</li>\n</ol>\n<hr />\n<p>本文提供了可靠的 C# PowerPoint 转 PDF 解决方案，特别适合在服务器环境或无需安装 Microsoft Office 的场景中使用。其优点包括部署简单、API 设计清晰、支持多种输出选项等。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"itemdesc\">\n                发表于 \n<span id=\"post-date\">2026-01-15 10:37</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jazz-z\">LAYONTHEGROUND</a>&nbsp;\n阅读(<span id=\"post_view_count\">133</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n            </div>"
    },
    {
      "title": "不服跑个分？.NET 10 大整数计算对阵 Java，结果令人意外",
      "link": "https://www.cnblogs.com/sdcb/p/19484525/20261113-big-integer-dotnet-10-vs-java",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sdcb/p/19484525/20261113-big-integer-dotnet-10-vs-java\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 08:50\">\n    <span>不服跑个分？.NET 10 大整数计算对阵 Java，结果令人意外</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"引言从经验值到无限大\">引言：从“经验值”到无限大</h2>\n<p>我对数值计算的执念，来自初中时代烟雾缭绕的网吧。那时玩《伝奇》，最让我着迷的不是打怪爆装备，而是角色面板里那条长长的<strong>经验值</strong>。看着数字不断跳动、累积，最终“叮”一声升级，那种简单的数值驱动整个世界运转的感觉，实在太奇妙了。</p>\n<p>当时自学编程，从 G-BASIC 里只有 16 位的 <code>INTEGER</code>，到第一次发现 QBASIC <code>LONG</code> 能存下“20亿”时的兴奋，再到如今成为一名 .NET 程序员，手握理论上“无限大”的 <code>System.Numerics.BigInteger</code>。我对大数的迷恋从未改变，只是疑惑随之而来：</p>\n<blockquote>\n<p><strong>作为 .NET 开发者，我手里的 <code>BigInteger</code> 到底够不够快？特别是和隔壁 Java 的 <code>BigInteger</code> 相比，究竟谁更胜一筹？</strong></p>\n</blockquote>\n<p>尤其是涉及高精度计算、密码学等关键领域时，这不仅是好奇，更是关乎性能的严肃拷问。今天，我就通过一次详尽的对比测试（含 .NET 10、Java 21以及Java 8），来为大家揭晓答案。结果可能出乎意料，请务必看到最后，文末还有一个高性能的“彩蛋”。</p>\n<hr />\n<h2 id=\"实验目标与范围\">实验目标与范围</h2>\n<p>我们对比这三套实现：</p>\n<ul>\n<li><strong>.NET</strong>：<code>System.Numerics.BigInteger</code>（基于 .NET 10）</li>\n<li><strong>Java</strong>：<code>java.math.BigInteger</code>\n<ul>\n<li><strong>Java 21（最新LTS）</strong>：代表未来趋势</li>\n<li><strong>Java 8（国内存量最大）</strong>：代表庞大的现状</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"测试操作3类覆盖常见大数热点\">测试操作（3类，覆盖常见大数热点）</h3>\n<ol>\n<li><strong>ADD_MOD</strong>：<code>(a + b) mod m</code>（加法 + 取模）</li>\n<li><strong>MUL_MOD</strong>：<code>(a * b) mod m</code>（乘法 + 取模）</li>\n<li><strong>MODPOW</strong>：<code>a^e mod m</code>（模幂，密码学等场景的性能热点）</li>\n</ol>\n<h3 id=\"位宽3档\">位宽（3档）</h3>\n<ul>\n<li>256 / 1024 / 4096 bits</li>\n</ul>\n<h3 id=\"计时口径尽量抑制噪声\">计时口径（尽量抑制噪声）</h3>\n<ul>\n<li><strong>热身</strong>：预热 5 次，让 JIT（即时编译器）充分发挥。</li>\n<li><strong>测量</strong>：正式跑 11 次，取中位数，避免单次抖动干扰。</li>\n<li><strong>指标</strong>：<code>nsPerOp</code>（每次操作耗时多少纳秒），这个值<strong>越小越好</strong>。</li>\n<li><strong>防作弊</strong>：用 <code>XOR</code> 聚合每次计算结果，防止聪明的编译器把整个循环优化掉。</li>\n</ul>\n<hr />\n<h2 id=\"测试环境\">测试环境</h2>\n<blockquote>\n<p>说明：以下是在同一 Linux 容器内完成。容器有资源限制，因此“看到的 CPU 核数/内存”与宿主机不完全一致。</p>\n</blockquote>\n<ul>\n<li><strong>OS</strong>：Ubuntu 24.04.3 LTS</li>\n<li><strong>CPU（宿主机型号）</strong>：AMD EPYC 7763 64-Core Processor<br />\n<strong>容器可用核心数</strong>：2 核（受容器限制）</li>\n<li><strong>内存</strong>：2GB（容器限制）</li>\n<li><strong>.NET</strong>\n<ul>\n<li>SDK：10.0.101</li>\n<li>Runtime：10.0.1</li>\n<li>环境变量：<code>DOTNET_GCServer=1</code></li>\n</ul>\n</li>\n<li><strong>Java</strong>\n<ul>\n<li>Java 21：OpenJDK 21.0.9（LTS）</li>\n<li>Java 8：Temurin(OpenJDK) 1.8.0_472-b08（广泛使用的 8u 系列）</li>\n<li>JVM 参数（两版本一致）：\n<ul>\n<li><code>-Xms1g -Xmx1g</code>（把 Java 堆固定为 1GB，避免堆动态扩张干扰）</li>\n<li><code>-XX:+UseG1GC</code></li>\n<li><code>-XX:+AlwaysPreTouch</code>（尽量减少运行中页分配扰动）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>一致性约束</strong>\n<ul>\n<li>Java 8/Java 21 使用<strong>同一份源码</strong>（仅使用 Java 8 语法），并且 <strong>用 Java 8 的 <code>javac</code> 编译</strong>（classfile=52.0）后分别在 Java 8 / Java 21 上运行，从而尽量把差异归因到运行时/JIT/库实现，而不是编译器生成差异。</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"赛前插曲net-biginteger-真的不公平吗\">赛前插曲：.NET BigInteger 真的“不公平”吗？</h2>\n<p>有人可能想问：</p>\n<blockquote>\n<p>“.NET BigInteger 每次运算都会创建新的对象（不可变），不公平。”</p>\n</blockquote>\n<p>这句话在“大数场景”里基本成立，但<strong>Java BigInteger 同样是不可变类型</strong>：<code>add/multiply/mod/xor/modPow</code> 都会返回新值，业务代码层面你并没有公开的 in-place API 可以复用内部缓冲。</p>\n<p>因此，在本文的“主对比”（.NET vs Java）里，双方都在不可变范式下运行，这点是公平的。</p>\n<hr />\n<h2 id=\"实验一net-biginteger-vs-java-21-biginteger\">实验一：.NET BigInteger vs Java 21 BigInteger</h2>\n<h3 id=\"31-完整源代码\">3.1 完整源代码</h3>\n<h4 id=\"java-源码bigintbenchjava\">Java 源码：<code>BigIntBench.java</code></h4>\n<blockquote>\n<p>兼容 Java 8 语法；同一份代码在 Java 21 下运行。</p>\n</blockquote>\n<pre><code class=\"language-java\">import java.math.BigInteger;\nimport java.util.*;\n\npublic class BigIntBench {\n    // SplitMix64 RNG (deterministic, fast)\n    static final class SplitMix64 {\n        private long x;\n        SplitMix64(long seed) { this.x = seed; }\n        long nextLong() {\n            long z = (x += 0x9E3779B97F4A7C15L);\n            z = (z ^ (z &gt;&gt;&gt; 30)) * 0xBF58476D1CE4E5B9L;\n            z = (z ^ (z &gt;&gt;&gt; 27)) * 0x94D049BB133111EBL;\n            return z ^ (z &gt;&gt;&gt; 31);\n        }\n        void nextBytes(byte[] dst) {\n            int i = 0;\n            while (i &lt; dst.length) {\n                long v = nextLong();\n                for (int k = 0; k &lt; 8 &amp;&amp; i &lt; dst.length; k++) {\n                    dst[i++] = (byte)(v &gt;&gt;&gt; (56 - 8*k)); // big-endian stream\n                }\n            }\n        }\n    }\n\n    static BigInteger[] genBigInts(int bitSize, int count, long seed) {\n        SplitMix64 rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        BigInteger[] arr = new BigInteger[count];\n        byte[] buf = new byte[byteLen];\n        int topBit = (bitSize - 1) % 8;\n        int keepBits = topBit + 1;\n        int firstMask = (keepBits == 8) ? 0xFF : ((1 &lt;&lt; keepBits) - 1);\n        byte topMask = (byte)(1 &lt;&lt; topBit);\n        for (int i = 0; i &lt; count; i++) {\n            rng.nextBytes(buf);\n            // Ensure exact bit length:\n            // - mask away unused top bits when bitSize is not byte-aligned\n            // - set the top bit so the number has the requested bit length\n            buf[0] &amp;= (byte)firstMask;\n            buf[0] |= topMask;\n            arr[i] = new BigInteger(1, buf);\n        }\n        return arr;\n    }\n\n    static BigInteger genModulus(int bitSize, long seed) {\n        SplitMix64 rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        byte[] buf = new byte[byteLen];\n        rng.nextBytes(buf);\n        int topBit = (bitSize - 1) % 8;\n        int keepBits = topBit + 1;\n        int firstMask = (keepBits == 8) ? 0xFF : ((1 &lt;&lt; keepBits) - 1);\n        buf[0] &amp;= (byte)firstMask;\n        buf[0] |= (byte)(1 &lt;&lt; topBit);\n        buf[buf.length - 1] |= 1; // odd\n        return new BigInteger(1, buf);\n    }\n\n    enum Op { ADD_MOD, MUL_MOD, MODPOW }\n\n    static final class Result {\n        final String lang;\n        final int bits;\n        final Op op;\n        final long ops;\n        final double nsPerOp;\n        final long checksum;\n        Result(String lang, int bits, Op op, long ops, double nsPerOp, long checksum) {\n            this.lang = lang; this.bits = bits; this.op = op; this.ops = ops; this.nsPerOp = nsPerOp; this.checksum = checksum;\n        }\n        String toJson() {\n            return String.format(Locale.ROOT,\n                    \"{\\\"lang\\\":\\\"%s\\\",\\\"bits\\\":%d,\\\"op\\\":\\\"%s\\\",\\\"ops\\\":%d,\\\"nsPerOp\\\":%.3f,\\\"checksum\\\":%d}\",\n                    lang, bits, op.name(), ops, nsPerOp, checksum);\n        }\n    }\n\n    static long runOnce(Op op, BigInteger[] a, BigInteger[] b, BigInteger[] e, BigInteger mod, int outer) {\n        BigInteger acc = BigInteger.ZERO;\n        int n = a.length;\n        switch (op) {\n            case ADD_MOD:\n                for (int o = 0; o &lt; outer; o++) {\n                    for (int i = 0; i &lt; n; i++) {\n                        BigInteger r = a[i].add(b[i]).mod(mod);\n                        acc = acc.xor(r);\n                    }\n                }\n                break;\n\n            case MUL_MOD:\n                for (int o = 0; o &lt; outer; o++) {\n                    for (int i = 0; i &lt; n; i++) {\n                        BigInteger r = a[i].multiply(b[i]).mod(mod);\n                        acc = acc.xor(r);\n                    }\n                }\n                break;\n\n            case MODPOW:\n                // here we use a.length as n; e can be same length\n                for (int o = 0; o &lt; outer; o++) {\n                    for (int i = 0; i &lt; n; i++) {\n                        BigInteger r = a[i].modPow(e[i], mod);\n                        acc = acc.xor(r);\n                    }\n                }\n                break;\n\n            default:\n                throw new IllegalArgumentException(\"Unknown op: \" + op);\n        }\n        return acc.longValue();\n    }\n\n    static Result bench(String lang, int bits, Op op, BigInteger[] a, BigInteger[] b, BigInteger[] e, BigInteger mod, long targetOps, int warmups, int measures) {\n        int n = a.length;\n        int outer = (int)Math.max(1, targetOps / n);\n        long actualOps = (long)n * outer;\n\n        // warmup\n        long ck = 0;\n        for (int i = 0; i &lt; warmups; i++) {\n            ck ^= runOnce(op, a, b, e, mod, outer);\n        }\n\n        long[] times = new long[measures];\n        for (int i = 0; i &lt; measures; i++) {\n            long t0 = System.nanoTime();\n            long c = runOnce(op, a, b, e, mod, outer);\n            long t1 = System.nanoTime();\n            ck ^= c;\n            times[i] = (t1 - t0);\n        }\n        Arrays.sort(times);\n        long median = times[times.length / 2];\n        double nsPerOp = (double)median / (double)actualOps;\n        return new Result(lang, bits, op, actualOps, nsPerOp, ck);\n    }\n\n    static void printHuman(List&lt;Result&gt; results) {\n        System.out.println(\"Java BigInteger benchmark\");\n        System.out.println(\"java.version=\" + System.getProperty(\"java.version\"));\n        System.out.println(\"java.vm.name=\" + System.getProperty(\"java.vm.name\"));\n        System.out.println();\n        System.out.printf(Locale.ROOT, \"%-6s %-9s %-12s %-12s\\n\", \"Bits\", \"Op\", \"ns/op(med)\", \"ops/run\");\n        for (Result r : results) {\n            System.out.printf(Locale.ROOT, \"%-6d %-9s %-12.3f %-12d\\n\", r.bits, r.op.name(), r.nsPerOp, r.ops);\n        }\n        System.out.println();\n        System.out.println(\"checksum=\" + results.stream().mapToLong(x -&gt; x.checksum).reduce(0L, (x,y)-&gt;x^y));\n    }\n\n    public static void main(String[] args) {\n        boolean json = false;\n        for (String a : args) if (a.equals(\"--json\")) json = true;\n\n        int warmups = 5;\n        int measures = 11;\n\n        int[] bitSizes = new int[]{256, 1024, 4096};\n        List&lt;Result&gt; results = new ArrayList&lt;&gt;();\n\n        for (int bits : bitSizes) {\n            BigInteger mod = genModulus(bits, 0xA1B2C3D4E5F60708L ^ bits);\n\n            // add/mul datasets\n            int nAddMul = 1024;\n            BigInteger[] a = genBigInts(bits, nAddMul, 0x1111222233334444L ^ bits);\n            BigInteger[] b = genBigInts(bits, nAddMul, 0x9999AAAABBBBCCCCL ^ bits);\n\n            // modpow datasets (smaller)\n            int nPow = 256;\n            BigInteger[] ap = genBigInts(bits, nPow, 0x13579BDF2468ACE0L ^ bits);\n            BigInteger[] ep = genBigInts(Math.min(bits, 512), nPow, 0x0FEDCBA987654321L ^ bits);\n\n            long addOps;\n            long mulOps;\n            long powOps;\n            if (bits == 256) {\n                addOps = 2_000_000L;\n                mulOps = 500_000L;\n                powOps = 8_000L;\n            } else if (bits == 1024) {\n                addOps = 1_000_000L;\n                mulOps = 120_000L;\n                powOps = 1_500L;\n            } else {\n                addOps = 200_000L;\n                mulOps = 20_000L;\n                powOps = 250L;\n            }\n\n            results.add(bench(\"java\", bits, Op.ADD_MOD, a, b, null, mod, addOps, warmups, measures));\n            results.add(bench(\"java\", bits, Op.MUL_MOD, a, b, null, mod, mulOps, warmups, measures));\n            results.add(bench(\"java\", bits, Op.MODPOW, ap, null, ep, mod, powOps, warmups, measures));\n        }\n\n        if (json) {\n            for (Result r : results) System.out.println(r.toJson());\n        } else {\n            printHuman(results);\n        }\n    }\n}\n</code></pre>\n<h4 id=\"net-源码programcsbiginteger-部分\">.NET 源码：<code>Program.cs</code>（BigInteger 部分）</h4>\n<blockquote>\n<p>这是“主对比”用的 .NET 基准程序。</p>\n</blockquote>\n<pre><code class=\"language-csharp\">using System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Globalization;\nusing System.Linq;\nusing System.Numerics;\n\nsealed class SplitMix64\n{\n    private ulong _x;\n    public SplitMix64(ulong seed) =&gt; _x = seed;\n\n    public ulong NextUInt64()\n    {\n        ulong z = (_x += 0x9E3779B97F4A7C15UL);\n        z = (z ^ (z &gt;&gt; 30)) * 0xBF58476D1CE4E5B9UL;\n        z = (z ^ (z &gt;&gt; 27)) * 0x94D049BB133111EBUL;\n        return z ^ (z &gt;&gt; 31);\n    }\n\n    public void NextBytes(byte[] dst)\n    {\n        int i = 0;\n        while (i &lt; dst.Length)\n        {\n            ulong v = NextUInt64();\n            for (int k = 0; k &lt; 8 &amp;&amp; i &lt; dst.Length; k++)\n            {\n                dst[i++] = (byte)(v &gt;&gt; (56 - 8 * k)); // big-endian stream\n            }\n        }\n    }\n}\n\nenum Op { ADD_MOD, MUL_MOD, MODPOW }\n\nrecord Result(string Lang, int Bits, Op Op, long Ops, double NsPerOp, long Checksum)\n{\n    public string ToJson() =&gt; string.Create(CultureInfo.InvariantCulture,\n        $\"{{\\\"lang\\\":\\\"{Lang}\\\",\\\"bits\\\":{Bits},\\\"op\\\":\\\"{Op}\\\",\\\"ops\\\":{Ops},\\\"nsPerOp\\\":{NsPerOp:F3},\\\"checksum\\\":{Checksum}}}\");\n}\n\nstatic class BigIntBench\n{\n    static BigInteger[] GenBigInts(int bitSize, int count, ulong seed)\n    {\n        var rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        var arr = new BigInteger[count];\n        var buf = new byte[byteLen];\n        int topBit = (bitSize - 1) % 8;\n        byte topMask = (byte)(1 &lt;&lt; topBit);\n\n        for (int i = 0; i &lt; count; i++)\n        {\n            rng.NextBytes(buf);\n            buf[0] |= topMask;\n            // unsigned + big-endian prevents negative\n            arr[i] = new BigInteger(buf, isUnsigned: true, isBigEndian: true);\n        }\n        return arr;\n    }\n\n    static BigInteger GenModulus(int bitSize, ulong seed)\n    {\n        var rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        var buf = new byte[byteLen];\n        rng.NextBytes(buf);\n        int topBit = (bitSize - 1) % 8;\n        buf[0] |= (byte)(1 &lt;&lt; topBit);\n        buf[^1] |= 1; // odd\n        return new BigInteger(buf, isUnsigned: true, isBigEndian: true);\n    }\n\n    static long RunOnce(Op op, BigInteger[] a, BigInteger[] b, BigInteger[] e, BigInteger mod, int outer)\n    {\n        BigInteger acc = BigInteger.Zero;\n        int n = a.Length;\n\n        switch (op)\n        {\n            case Op.ADD_MOD:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                    {\n                        var r = (a[i] + b[i]) % mod;\n                        acc ^= r;\n                    }\n                break;\n\n            case Op.MUL_MOD:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                    {\n                        var r = (a[i] * b[i]) % mod;\n                        acc ^= r;\n                    }\n                break;\n\n            case Op.MODPOW:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                    {\n                        var r = BigInteger.ModPow(a[i], e[i], mod);\n                        acc ^= r;\n                    }\n                break;\n        }\n\n        return (long)(acc &amp; long.MaxValue); // stable checksum\n    }\n\n    static Result Bench(string lang, int bits, Op op, BigInteger[] a, BigInteger[] b, BigInteger[] e, BigInteger mod, long targetOps, int warmups, int measures)\n    {\n        int n = a.Length;\n        int outer = (int)Math.Max(1, targetOps / n);\n        long actualOps = (long)n * outer;\n\n        long ck = 0;\n        for (int i = 0; i &lt; warmups; i++)\n            ck ^= RunOnce(op, a, b, e, mod, outer);\n\n        long[] timesNs = new long[measures];\n        for (int i = 0; i &lt; measures; i++)\n        {\n            var sw = Stopwatch.StartNew();\n            long c = RunOnce(op, a, b, e, mod, outer);\n            sw.Stop();\n            ck ^= c;\n            // Stopwatch ticks to ns\n            timesNs[i] = (long)(sw.ElapsedTicks * (1_000_000_000.0 / Stopwatch.Frequency));\n        }\n\n        Array.Sort(timesNs);\n        long median = timesNs[timesNs.Length / 2];\n        double nsPerOp = (double)median / actualOps;\n        return new Result(lang, bits, op, actualOps, nsPerOp, ck);\n    }\n\n    static void PrintHuman(List&lt;Result&gt; results)\n    {\n        Console.WriteLine(\"C# BigInteger benchmark\");\n        Console.WriteLine($\"dotnet.version={Environment.Version}\");\n        Console.WriteLine($\"os={System.Runtime.InteropServices.RuntimeInformation.OSDescription}\");\n        Console.WriteLine($\"arch={System.Runtime.InteropServices.RuntimeInformation.OSArchitecture}\");\n        Console.WriteLine();\n        Console.WriteLine($\"{ \"Bits\",-6} {\"Op\",-9} {\"ns/op(med)\",-12} {\"ops/run\",-12}\");\n        foreach (var r in results)\n            Console.WriteLine(string.Create(CultureInfo.InvariantCulture, $\"{r.Bits,-6} {r.Op,-9} {r.NsPerOp,-12:F3} {r.Ops,-12}\"));\n        Console.WriteLine();\n        long checksum = 0;\n        foreach (var r in results) checksum ^= r.Checksum;\n        Console.WriteLine($\"checksum={checksum}\");\n    }\n\n    public static int Main(string[] args)\n    {\n        bool json = args.Any(a =&gt; a == \"--json\");\n\n        int warmups = 5;\n        int measures = 11;\n        int[] bitSizes = [256, 1024, 4096];\n\n        var results = new List&lt;Result&gt;();\n\n        foreach (int bits in bitSizes)\n        {\n            var mod = GenModulus(bits, 0xA1B2C3D4E5F60708UL ^ (uint)bits);\n\n            int nAddMul = 1024;\n            var a = GenBigInts(bits, nAddMul, 0x1111222233334444UL ^ (uint)bits);\n            var b = GenBigInts(bits, nAddMul, 0x9999AAAABBBBCCCCUL ^ (uint)bits);\n\n            int nPow = 256;\n            var ap = GenBigInts(bits, nPow, 0x13579BDF2468ACE0UL ^ (uint)bits);\n            var ep = GenBigInts(Math.Min(bits, 512), nPow, 0x0FEDCBA987654321UL ^ (uint)bits);\n\n            long addOps = bits switch { 256 =&gt; 2_000_000L, 1024 =&gt; 1_000_000L, _ =&gt; 200_000L };\n            long mulOps = bits switch { 256 =&gt; 500_000L, 1024 =&gt; 120_000L, _ =&gt; 20_000L };\n            long powOps = bits switch { 256 =&gt; 8_000L, 1024 =&gt; 1_500L, _ =&gt; 250L };\n\n            results.Add(Bench(\"csharp\", bits, Op.ADD_MOD, a, b, null!, mod, addOps, warmups, measures));\n            results.Add(Bench(\"csharp\", bits, Op.MUL_MOD, a, b, null!, mod, mulOps, warmups, measures));\n            results.Add(Bench(\"csharp\", bits, Op.MODPOW, ap, null!, ep, mod, powOps, warmups, measures));\n        }\n\n        if (json)\n        {\n            foreach (var r in results) Console.WriteLine(r.ToJson());\n        }\n        else\n        {\n            PrintHuman(results);\n        }\n\n        return 0;\n    }\n}\n</code></pre>\n<h3 id=\"32-运行方式可复现命令\">3.2 运行方式（可复现命令）</h3>\n<pre><code class=\"language-bash\"># Java 21\ncd /app/bigintbench/java\njavac BigIntBench.java\njava -Xms1g -Xmx1g -XX:+UseG1GC -XX:+AlwaysPreTouch BigIntBench --json\n\n# .NET 10\ncd /app/bigintbench/csharp\ndotnet build -c Release\nDOTNET_GCServer=1 dotnet run -c Release -- --json\n</code></pre>\n<h3 id=\"33-实验一原始输出jsonl\">3.3 实验一原始输出（JSONL）</h3>\n<h4 id=\"java-21results_java21jsonl\">Java 21：<code>results_java21.jsonl</code></h4>\n<pre><code class=\"language-jsonl\">{\"lang\":\"java\",\"bits\":256,\"op\":\"ADD_MOD\",\"ops\":1999872,\"nsPerOp\":139.589,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":256,\"op\":\"MUL_MOD\",\"ops\":499712,\"nsPerOp\":387.031,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":256,\"op\":\"MODPOW\",\"ops\":7936,\"nsPerOp\":17764.884,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":1024,\"op\":\"ADD_MOD\",\"ops\":999424,\"nsPerOp\":284.672,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":1024,\"op\":\"MUL_MOD\",\"ops\":119808,\"nsPerOp\":3094.540,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":1024,\"op\":\"MODPOW\",\"ops\":1280,\"nsPerOp\":264577.852,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":4096,\"op\":\"ADD_MOD\",\"ops\":199680,\"nsPerOp\":900.735,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":4096,\"op\":\"MUL_MOD\",\"ops\":19456,\"nsPerOp\":32062.554,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":4096,\"op\":\"MODPOW\",\"ops\":256,\"nsPerOp\":3422756.113,\"checksum\":0}\n</code></pre>\n<h4 id=\"net-10results_csharpjsonl\">.NET 10：<code>results_csharp.jsonl</code></h4>\n<pre><code class=\"language-jsonl\">{\"lang\":\"csharp\",\"bits\":256,\"op\":\"ADD_MOD\",\"ops\":1999872,\"nsPerOp\":146.261,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":256,\"op\":\"MUL_MOD\",\"ops\":499712,\"nsPerOp\":560.246,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":256,\"op\":\"MODPOW\",\"ops\":7936,\"nsPerOp\":169713.608,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":1024,\"op\":\"ADD_MOD\",\"ops\":999424,\"nsPerOp\":297.335,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":1024,\"op\":\"MUL_MOD\",\"ops\":119808,\"nsPerOp\":4792.760,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":1024,\"op\":\"MODPOW\",\"ops\":1280,\"nsPerOp\":1938407.720,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":4096,\"op\":\"ADD_MOD\",\"ops\":199680,\"nsPerOp\":1280.760,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":4096,\"op\":\"MUL_MOD\",\"ops\":19456,\"nsPerOp\":36894.568,\"checksum\":0}\n{\"lang\":\"csharp\",\"bits\":4096,\"op\":\"MODPOW\",\"ops\":256,\"nsPerOp\":20617970.004,\"checksum\":0}\n</code></pre>\n<hr />\n<h2 id=\"实验二加入-java-8-看现状主流处于什么位置\">实验二：加入 Java 8 ——看“现状主流”处于什么位置</h2>\n<p>这一组的关键点是：<strong>同一份 Java 源码用 Java 8 编译</strong>，分别在 Java 8 与 Java 21 上运行，尽量避免“编译器产物差异”。</p>\n<h3 id=\"41-运行方式\">4.1 运行方式</h3>\n<pre><code class=\"language-bash\"># 编译（Java 8）\n/path/to/jdk8/bin/javac BigIntBench.java\n\n# 运行（Java 8）\n/path/to/jdk8/bin/java -Xms1g -Xmx1g -XX:+UseG1GC -XX:+AlwaysPreTouch BigIntBench --json\n\n# 运行（Java 21）\njava -Xms1g -Xmx1g -XX:+UseG1GC -XX:+AlwaysPreTouch BigIntBench --json\n</code></pre>\n<h3 id=\"42-实验二原始输出jsonl\">4.2 实验二原始输出（JSONL）</h3>\n<h4 id=\"java-8results_java8jsonl\">Java 8：<code>results_java8.jsonl</code></h4>\n<pre><code class=\"language-jsonl\">{\"lang\":\"java\",\"bits\":256,\"op\":\"ADD_MOD\",\"ops\":1999872,\"nsPerOp\":207.335,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":256,\"op\":\"MUL_MOD\",\"ops\":499712,\"nsPerOp\":468.248,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":256,\"op\":\"MODPOW\",\"ops\":7936,\"nsPerOp\":17697.113,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":1024,\"op\":\"ADD_MOD\",\"ops\":999424,\"nsPerOp\":390.906,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":1024,\"op\":\"MUL_MOD\",\"ops\":119808,\"nsPerOp\":3089.474,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":1024,\"op\":\"MODPOW\",\"ops\":1280,\"nsPerOp\":277395.652,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":4096,\"op\":\"ADD_MOD\",\"ops\":199680,\"nsPerOp\":990.708,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":4096,\"op\":\"MUL_MOD\",\"ops\":19456,\"nsPerOp\":30692.214,\"checksum\":0}\n{\"lang\":\"java\",\"bits\":4096,\"op\":\"MODPOW\",\"ops\":256,\"nsPerOp\":3468269.539,\"checksum\":0}\n</code></pre>\n<hr />\n<h2 id=\"可视化与总结\">可视化与总结</h2>\n<p>从一个 .NET 程序员的视角来看，这次的测试结果可以说既在情理之中，又有些出乎意料。</p>\n<ol>\n<li><strong>ADD_MOD (加法+取模)</strong>: 在这个项目上，.NET 和 Java 21 几乎打了个平手，差距微乎其微。可以说，在基础的加法运算上，.NET 表现得相当不错。<br />\n<img alt=\"bar_csharp_baseline_add_mod\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260114225530983-1114904260.png\" /></li>\n<li><strong>MUL_MOD (乘法+取模)</strong>: 从这里开始，差距出现了。.NET 明显慢于 Java，性能鸿沟开始变得“肉眼可见”。<br />\n<img alt=\"bar_csharp_baseline_mul_mod\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260114225554833-1748112213.png\" /></li>\n<li><strong>MODPOW (模幂)</strong>: 这是差距最大的地方。.NET 在这项测试中被 Java 21 拉开了 <strong>6到9倍</strong> 的差距。对于从事密码学或需要大量大数运算的开发者来说，这是一个非常刺眼的信号。<br />\n<img alt=\"bar_csharp_baseline_modpow\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260114225547260-463566788.png\" /></li>\n<li><strong>Java 8 vs Java 21</strong>: 毫无疑问，Java 21 在绝大多数情况下都比老迈的 Java 8 要快。不过有趣的是，在 <code>MUL_MOD</code> 的 1024 和 4096 位测试中，Java 8 居然出现了“反超”的现象。这可能是由于 JIT 策略、算法选择的阈值差异，或是单纯的测量误差。虽然这不影响“Java 21更快”的总体结论，但也提醒我们性能测试的复杂性。</li>\n</ol>\n<p>总而言之，这次对决让我们清楚地看到，在复杂的大数运算上，.NET 的 <code>BigInteger</code> 确实还有很长的路要走。</p>\n<hr />\n<h2 id=\"one-more-thing当外援登场\">One More Thing：当“外援”登场</h2>\n<p>在寻找 .NET 大数性能优化方案的过程中，我们自然能想到了业界标杆 GMP ——它是 GNU Multi-Precision Arithmetic Library，很多数学软件/密码学实现都会用它做高性能大整数运算。</p>\n<p>我碰巧也为它做了一个 .NET 封装：<a href=\"https://github.com/sdcb/Sdcb.Arithmetic\" rel=\"noopener nofollow\" target=\"_blank\">Sdcb.Arithmetic</a>。</p>\n<p>但必须提前声明：<strong>让 GMP 作为“外援”加入这场对比，是“不公平”的</strong>。原因很简单：</p>\n<ul>\n<li><strong>语言优势</strong>：GMP 是原生 C/汇编，而 .NET 和 Java 是在虚拟机上运行的托管语言。</li>\n<li><strong>内存策略</strong>：GMP 鼓励使用 <strong>in-place API</strong>，可以直接在原地修改数值，大大减少了内存分配和 GC 压力。而 .NET 和 Java 的 <code>BigInteger</code> 则是不可变对象。</li>\n</ul>\n<p>所以，这部分的结果更像是一个“彩蛋”，展示的是：<strong>如果你愿意引入原生依赖，并改变编码风格，.NET 的大数性能可以达到怎样的高度。</strong></p>\n<h3 id=\"71-客串实验完整源代码net-biginteger--gmpinteger-同场\">7.1 客串实验完整源代码（.NET BigInteger + GmpInteger 同场）</h3>\n<blockquote>\n<p>下面代码会同时输出两套结果：<code>csharp_bigint</code> 与 <code>csharp_gmp_inplace</code>（仍是 JSONL）。</p>\n</blockquote>\n<p><strong><code>Program.cs</code>（客串版，完整）</strong></p>\n<pre><code class=\"language-csharp\">using System;\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing System.Globalization;\nusing System.Linq;\nusing System.Numerics;\nusing Sdcb.Arithmetic.Gmp;\n\nsealed class SplitMix64\n{\n    private ulong _x;\n    public SplitMix64(ulong seed) =&gt; _x = seed;\n\n    public ulong NextUInt64()\n    {\n        ulong z = (_x += 0x9E3779B97F4A7C15UL);\n        z = (z ^ (z &gt;&gt; 30)) * 0xBF58476D1CE4E5B9UL;\n        z = (z ^ (z &gt;&gt; 27)) * 0x94D049BB133111EBUL;\n        return z ^ (z &gt;&gt; 31);\n    }\n\n    public void NextBytes(byte[] dst)\n    {\n        int i = 0;\n        while (i &lt; dst.Length)\n        {\n            ulong v = NextUInt64();\n            for (int k = 0; k &lt; 8 &amp;&amp; i &lt; dst.Length; k++)\n                dst[i++] = (byte)(v &gt;&gt; (56 - 8 * k));\n        }\n    }\n}\n\nenum Op { ADD_MOD, MUL_MOD, MODPOW }\n\nrecord Result(string Impl, int Bits, Op Op, long Ops, double NsPerOp, long Checksum)\n{\n    public string ToJson() =&gt; string.Create(CultureInfo.InvariantCulture,\n        $\"{{\\\"lang\\\":\\\"{Impl}\\\",\\\"bits\\\":{Bits},\\\"op\\\":\\\"{Op}\\\",\\\"ops\\\":{Ops},\\\"nsPerOp\\\":{NsPerOp:F3},\\\"checksum\\\":{Checksum}}}\");\n}\n\nstatic class BenchUtil\n{\n    public static void MaskToBitSize(byte[] buf, int bitSize)\n    {\n        int topBit = (bitSize - 1) % 8;\n        int keepBits = topBit + 1;\n        int firstMask = keepBits == 8 ? 0xFF : ((1 &lt;&lt; keepBits) - 1);\n        buf[0] &amp;= (byte)firstMask;\n        buf[0] |= (byte)(1 &lt;&lt; topBit);\n    }\n\n    public static string ToHex(byte[] bytes) =&gt; Convert.ToHexString(bytes);\n}\n\nstatic class BigIntegerBench\n{\n    public static BigInteger[] Gen(int bitSize, int count, ulong seed)\n    {\n        var rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        var arr = new BigInteger[count];\n        var buf = new byte[byteLen];\n\n        for (int i = 0; i &lt; count; i++)\n        {\n            rng.NextBytes(buf);\n            BenchUtil.MaskToBitSize(buf, bitSize);\n            arr[i] = new BigInteger(buf, isUnsigned: true, isBigEndian: true);\n        }\n        return arr;\n    }\n\n    public static BigInteger GenModulus(int bitSize, ulong seed)\n    {\n        var rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        var buf = new byte[byteLen];\n        rng.NextBytes(buf);\n        BenchUtil.MaskToBitSize(buf, bitSize);\n        buf[^1] |= 1;\n        return new BigInteger(buf, isUnsigned: true, isBigEndian: true);\n    }\n\n    public static long RunOnce(Op op, BigInteger[] a, BigInteger[] b, BigInteger[] e, BigInteger mod, int outer)\n    {\n        BigInteger acc = BigInteger.Zero;\n        int n = a.Length;\n\n        switch (op)\n        {\n            case Op.ADD_MOD:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                        acc ^= (a[i] + b[i]) % mod;\n                break;\n\n            case Op.MUL_MOD:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                        acc ^= (a[i] * b[i]) % mod;\n                break;\n\n            case Op.MODPOW:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                        acc ^= BigInteger.ModPow(a[i], e[i], mod);\n                break;\n        }\n\n        return (long)(acc &amp; long.MaxValue);\n    }\n}\n\nstatic class GmpIntegerBench\n{\n    public static GmpInteger[] Gen(int bitSize, int count, ulong seed)\n    {\n        var rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        var arr = new GmpInteger[count];\n        var buf = new byte[byteLen];\n\n        for (int i = 0; i &lt; count; i++)\n        {\n            rng.NextBytes(buf);\n            BenchUtil.MaskToBitSize(buf, bitSize);\n            arr[i] = GmpInteger.Parse(BenchUtil.ToHex(buf), 16);\n        }\n        return arr;\n    }\n\n    public static GmpInteger GenModulus(int bitSize, ulong seed)\n    {\n        var rng = new SplitMix64(seed);\n        int byteLen = (bitSize + 7) / 8;\n        var buf = new byte[byteLen];\n        rng.NextBytes(buf);\n        BenchUtil.MaskToBitSize(buf, bitSize);\n        buf[^1] |= 1;\n        return GmpInteger.Parse(BenchUtil.ToHex(buf), 16);\n    }\n\n    public static long RunOnce(Op op, GmpInteger[] a, GmpInteger[] b, GmpInteger[] e, GmpInteger mod, int outer)\n    {\n        using var acc = GmpInteger.From(0);\n        using var tmp = GmpInteger.From(0);\n\n        int n = a.Length;\n        switch (op)\n        {\n            case Op.ADD_MOD:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                    {\n                        GmpInteger.AddInplace(tmp, a[i], b[i]);\n                        GmpInteger.ModInplace(tmp, tmp, mod);\n                        GmpInteger.BitwiseXorInplace(acc, acc, tmp);\n                    }\n                break;\n\n            case Op.MUL_MOD:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                    {\n                        GmpInteger.MultiplyInplace(tmp, a[i], b[i]);\n                        GmpInteger.ModInplace(tmp, tmp, mod);\n                        GmpInteger.BitwiseXorInplace(acc, acc, tmp);\n                    }\n                break;\n\n            case Op.MODPOW:\n                for (int o = 0; o &lt; outer; o++)\n                    for (int i = 0; i &lt; n; i++)\n                    {\n                        GmpInteger.PowerModInplace(tmp, a[i], e[i], mod);\n                        GmpInteger.BitwiseXorInplace(acc, acc, tmp);\n                    }\n                break;\n        }\n\n        return acc.GetHashCode();\n    }\n\n    public static void DisposeAll(GmpInteger[] xs)\n    {\n        foreach (var x in xs) x.Dispose();\n    }\n}\n\nstatic class Runner\n{\n    static Result BenchBigInteger(int bits, Op op, BigInteger[] a, BigInteger[] b, BigInteger[] e, BigInteger mod, long targetOps, int warmups, int measures)\n    {\n        int n = a.Length;\n        int outer = (int)Math.Max(1, targetOps / n);\n        long actualOps = (long)n * outer;\n\n        long ck = 0;\n        for (int i = 0; i &lt; warmups; i++) ck ^= BigIntegerBench.RunOnce(op, a, b, e, mod, outer);\n\n        long[] timesNs = new long[measures];\n        for (int i = 0; i &lt; measures; i++)\n        {\n            var sw = Stopwatch.StartNew();\n            long c = BigIntegerBench.RunOnce(op, a, b, e, mod, outer);\n            sw.Stop();\n            ck ^= c;\n            timesNs[i] = (long)(sw.ElapsedTicks * (1_000_000_000.0 / Stopwatch.Frequency));\n        }\n        Array.Sort(timesNs);\n        long median = timesNs[timesNs.Length / 2];\n        return new Result(\"csharp_bigint\", bits, op, actualOps, (double)median / actualOps, ck);\n    }\n\n    static Result BenchGmpInteger(int bits, Op op, GmpInteger[] a, GmpInteger[] b, GmpInteger[] e, GmpInteger mod, long targetOps, int warmups, int measures)\n    {\n        int n = a.Length;\n        int outer = (int)Math.Max(1, targetOps / n);\n        long actualOps = (long)n * outer;\n\n        long ck = 0;\n        for (int i = 0; i &lt; warmups; i++) ck ^= GmpIntegerBench.RunOnce(op, a, b, e, mod, outer);\n\n        long[] timesNs = new long[measures];\n        for (int i = 0; i &lt; measures; i++)\n        {\n            var sw = Stopwatch.StartNew();\n            long c = GmpIntegerBench.RunOnce(op, a, b, e, mod, outer);\n            sw.Stop();\n            ck ^= c;\n            timesNs[i] = (long)(sw.ElapsedTicks * (1_000_000_000.0 / Stopwatch.Frequency));\n        }\n        Array.Sort(timesNs);\n        long median = timesNs[timesNs.Length / 2];\n        return new Result(\"csharp_gmp_inplace\", bits, op, actualOps, (double)median / actualOps, ck);\n    }\n\n    public static int Run(string[] args)\n    {\n        bool json = args.Any(a =&gt; a == \"--json\");\n\n        int warmups = 5;\n        int measures = 11;\n        int[] bitSizes = [256, 1024, 4096];\n\n        var results = new List&lt;Result&gt;();\n\n        foreach (int bits in bitSizes)\n        {\n            long addOps = bits switch { 256 =&gt; 2_000_000L, 1024 =&gt; 1_000_000L, _ =&gt; 200_000L };\n            long mulOps = bits switch { 256 =&gt; 500_000L, 1024 =&gt; 120_000L, _ =&gt; 20_000L };\n            long powOps = bits switch { 256 =&gt; 8_000L, 1024 =&gt; 1_500L, _ =&gt; 250L };\n\n            // BigInteger data\n            var modB = BigIntegerBench.GenModulus(bits, 0xA1B2C3D4E5F60708UL ^ (uint)bits);\n            var aB = BigIntegerBench.Gen(bits, 1024, 0x1111222233334444UL ^ (uint)bits);\n            var bB = BigIntegerBench.Gen(bits, 1024, 0x9999AAAABBBBCCCCUL ^ (uint)bits);\n            var apB = BigIntegerBench.Gen(bits, 256, 0x13579BDF2468ACE0UL ^ (uint)bits);\n            var epB = BigIntegerBench.Gen(Math.Min(bits, 512), 256, 0x0FEDCBA987654321UL ^ (uint)bits);\n\n            // GmpInteger data (same seeds/bit sizes)\n            using var modG = GmpIntegerBench.GenModulus(bits, 0xA1B2C3D4E5F60708UL ^ (uint)bits);\n            var aG = GmpIntegerBench.Gen(bits, 1024, 0x1111222233334444UL ^ (uint)bits);\n            var bG = GmpIntegerBench.Gen(bits, 1024, 0x9999AAAABBBBCCCCUL ^ (uint)bits);\n            var apG = GmpIntegerBench.Gen(bits, 256, 0x13579BDF2468ACE0UL ^ (uint)bits);\n            var epG = GmpIntegerBench.Gen(Math.Min(bits, 512), 256, 0x0FEDCBA987654321UL ^ (uint)bits);\n\n            try\n            {\n                results.Add(BenchBigInteger(bits, Op.ADD_MOD, aB, bB, null!, modB, addOps, warmups, measures));\n                results.Add(BenchBigInteger(bits, Op.MUL_MOD, aB, bB, null!, modB, mulOps, warmups, measures));\n                results.Add(BenchBigInteger(bits, Op.MODPOW, apB, null!, epB, modB, powOps, warmups, measures));\n\n                results.Add(BenchGmpInteger(bits, Op.ADD_MOD, aG, bG, null!, modG, addOps, warmups, measures));\n                results.Add(BenchGmpInteger(bits, Op.MUL_MOD, aG, bG, null!, modG, mulOps, warmups, measures));\n                results.Add(BenchGmpInteger(bits, Op.MODPOW, apG, null!, epG, modG, powOps, warmups, measures));\n            }\n            finally\n            {\n                GmpIntegerBench.DisposeAll(aG);\n                GmpIntegerBench.DisposeAll(bG);\n                GmpIntegerBench.DisposeAll(apG);\n                GmpIntegerBench.DisposeAll(epG);\n            }\n        }\n\n        if (json)\n        {\n            foreach (var r in results) Console.WriteLine(r.ToJson());\n        }\n\n        return 0;\n    }\n}\n\npublic static class Program\n{\n    public static int Main(string[] args) =&gt; Runner.Run(args);\n}\n</code></pre>\n<p><strong><code>gmpbench.csproj</code>（客串版项目文件）</strong></p>\n<pre><code class=\"language-xml\">&lt;Project Sdk=\"Microsoft.NET.Sdk\"&gt;\n  &lt;PropertyGroup&gt;\n    &lt;OutputType&gt;Exe&lt;/OutputType&gt;\n    &lt;TargetFramework&gt;net10.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Sdcb.Arithmetic.Gmp\" Version=\"*\" /&gt;\n    &lt;PackageReference Include=\"Sdcb.Arithmetic.Gmp.runtime.linux-x64\" Version=\"*\" /&gt;\n  &lt;/ItemGroup&gt;\n&lt;/Project&gt;\n</code></pre>\n<h3 id=\"72-客串实验原始输出jsonl\">7.2 客串实验原始输出（JSONL）</h3>\n<pre><code class=\"language-jsonl\">{\"lang\":\"csharp_bigint\",\"bits\":256,\"op\":\"ADD_MOD\",\"ops\":1999872,\"nsPerOp\":146.261,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":256,\"op\":\"MUL_MOD\",\"ops\":499712,\"nsPerOp\":560.246,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":256,\"op\":\"MODPOW\",\"ops\":7936,\"nsPerOp\":169713.608,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":256,\"op\":\"ADD_MOD\",\"ops\":1999872,\"nsPerOp\":76.644,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":256,\"op\":\"MUL_MOD\",\"ops\":499712,\"nsPerOp\":114.690,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":256,\"op\":\"MODPOW\",\"ops\":7936,\"nsPerOp\":13931.914,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":1024,\"op\":\"ADD_MOD\",\"ops\":999424,\"nsPerOp\":297.335,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":1024,\"op\":\"MUL_MOD\",\"ops\":119808,\"nsPerOp\":4792.760,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":1024,\"op\":\"MODPOW\",\"ops\":1280,\"nsPerOp\":1938407.720,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":1024,\"op\":\"ADD_MOD\",\"ops\":999424,\"nsPerOp\":97.260,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":1024,\"op\":\"MUL_MOD\",\"ops\":119808,\"nsPerOp\":562.235,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":1024,\"op\":\"MODPOW\",\"ops\":1280,\"nsPerOp\":218715.147,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":4096,\"op\":\"ADD_MOD\",\"ops\":199680,\"nsPerOp\":1280.760,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":4096,\"op\":\"MUL_MOD\",\"ops\":19456,\"nsPerOp\":36894.568,\"checksum\":0}\n{\"lang\":\"csharp_bigint\",\"bits\":4096,\"op\":\"MODPOW\",\"ops\":256,\"nsPerOp\":20617970.004,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":4096,\"op\":\"ADD_MOD\",\"ops\":199680,\"nsPerOp\":179.720,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":4096,\"op\":\"MUL_MOD\",\"ops\":19456,\"nsPerOp\":5431.441,\"checksum\":0}\n{\"lang\":\"csharp_gmp_inplace\",\"bits\":4096,\"op\":\"MODPOW\",\"ops\":256,\"nsPerOp\":2662198.492,\"checksum\":0}\n</code></pre>\n<h3 id=\"73-客串可视化以gmp为基准\">7.3 客串可视化（以GMP为基准）</h3>\n<p><img alt=\"bar_gmp_baseline_add_mod\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260114225617406-1423853952.png\" /><br />\n<img alt=\"bar_gmp_baseline_mul_mod\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260114225622152-863625745.png\" /><br />\n<img alt=\"bar_gmp_baseline_modpow\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260114225625327-2119127781.png\" /></p>\n<hr />\n<h2 id=\"总结与展望\">总结与展望</h2>\n<p>从这次“硬碰硬”的对决中，我们可以清晰地看到：在基础加法上，.NET <code>BigInteger</code> 与 Java 不分伯仲；但在乘法，尤其是<strong>模幂运算</strong>（对密码学等场景极其重要）上，.NET 目前确实存在明显的短板，大幅落后于 Java。</p>\n<p>承认不足是改进的开始。对于绝大多数业务场景，内置的 <code>BigInteger</code> 依然够用且方便。但如果你的应用处于性能敏感区（如加密算法、科学计算），那么也许是时候考虑一些“重武器”了。</p>\n<p>这也正是我开发并维护 <strong><a href=\"https://github.com/sdcb/Sdcb.Arithmetic\" rel=\"noopener nofollow\" target=\"_blank\">Sdcb.Arithmetic</a></strong> 的初衷。它通过封装 GMP 等高性能原生库，为 .NET 带来了<strong>原地修改（in-place）</strong>以及高达数倍的性能提升（如文中实验所示）。如果你对性能有极致追求，或者想看看 .NET 在大数计算上的极限，欢迎去 GitHub 点个 Star ⭐，试一试这个库。</p>\n<p>感谢阅读！如果你觉得这两个语言的对比分析有意思，或者对 .NET 高性能编程感兴趣，欢迎在评论区留言交流，也欢迎加入我的 <strong>.NET骚操作 QQ群：495782587</strong>，我们一起探索更多技术硬核玩法。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 08:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sdcb\">.NET骚操作</a>&nbsp;\n阅读(<span id=\"post_view_count\">1162</span>)&nbsp;\n评论(<span id=\"post_comment_count\">11</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Gemini3现在能做这种地图轨迹动画了，免费就能体验！",
      "link": "https://www.cnblogs.com/xuanyuan/p/19488441",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xuanyuan/p/19488441\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 17:25\">\n    <span>Gemini3现在能做这种地图轨迹动画了，免费就能体验！</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家好，我是轩辕。</p>\n<p>有段时间刷短视频经常刷到各种历史人物一生的足迹图：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/89a1652b-adb3-46fd-a49e-fc47d1e097ef.jpg\" /></p>\n<p>有一天我在想：这种动画能不能让AI给我做呢？</p>\n<p>于是我打开各种AI工具，尝试了一番。</p>\n<p>这是最新的ChatGPT 5.2做的：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/8ff53f02-80c6-4fdb-b00e-e47f0fb6e85d.gif\" /></p>\n<p>这是Gemini3 Pro做的：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/bf3bf856-b06c-4d68-a49b-aab5bfd58bf8.gif\" /></p>\n<p>都一言难尽没法看，连最强大的Gemini3 Pro都只能做成这样，有些失望。</p>\n<p>直到前几天洗碗的时候突然灵光一闪，想到了一个好的办法，通过这个办法指导AI可以做出最开始那样的动画效果。</p>\n<p>很快，我就把这套办法进行了验证并最终开发融入到了我的SVG动画网站里面去，给大家看看这是我用一句话做出来的刘备一生的足迹动画：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/81d74a93-66e7-4a7a-94be-21900f97e309.gif\" /></p>\n<p>这是我用一句话做出来的太平天国运动轨迹动画：</p>\n<p>效果比起直接让AI做好了太多了！</p>\n<p>现在，如果你也想做这样类似的动画，只需要在动画右下角点击<strong>【制作相同风格动画】</strong> 按钮就能轻松完成了：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/4487cb24-8fb3-4c08-9cf3-12f048dbcd39.jpg\" /></p>\n<p>除了这样的地图动画，我想到可能还有很多种不同的风格，大家在制作的时候心里有个大概的想法，但是要让你用提示词描述清楚却并不容易。</p>\n<p>于是我在此基础之上，进一步扩展，为我的动画制作网站引入了参考风格模板的功能。</p>\n<p>在动画创作页面可以看到比以前多了一个“<strong>参考风格</strong>”的选项：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/78b9e59d-934c-4296-b06e-1efd9bfaafd0.png\" /></p>\n<p>点击这个面板就可以看到系统内置的八种风格，几十种参考模板了：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/7c819565-e357-4832-a8c5-832107e60eeb.png\" /></p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/b8e4b4eb-0beb-4e96-b42f-b31272a0de03.png\" /></p>\n<p>这里涵盖了幻灯片风格、课程讲解、数据可视化、品牌展示、产品演示、创意特效、动态交互、地图标记等多种风格。</p>\n<p>选择你喜欢的风格，就可以让AI参考这个风格来生成你要的动画内容了。</p>\n<p>比如这里有一个奈飞风格的动画：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/e125e0fc-3022-48dd-9c5f-e37dad147b5c.gif\" /></p>\n<p>选择它之后，我基于这个风格创建一个SvgAnimate的动画：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/cac04db5-4de4-41af-81d8-a523cf4b9315.gif\" /></p>\n<p>怎么样，是不是有点内味儿了？</p>\n<p>前面提到的地图类的动画就在最后这个地图标记里面，这里我目前内置了中国地图、美国地图、世界地图和人物轨迹图四个模板，大家可以来发挥自己的想象力利用这些地图做一些好玩的动画。</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/bbd09da1-9e92-41de-b2ce-9b28d03c2a3d.jpg\" /></p>\n<p>后续我还会不断完善这里面的风格和模板库，集成更多更优质的内容在这里，帮助大家轻松制作出精彩的动画内容。</p>\n<p>如果现阶段你在这里面找不到喜欢的风格模板，你也可以浏览案例库：</p>\n<p><img alt=\"\" src=\"https://files.mdnice.com/user/3643/0cbf8d72-d2a7-4aaa-9254-328d918f15ae.jpg\" /></p>\n<p>这里面已经有上千个用户公开的动画，里面不乏精品，在这里面挑选到任意你感兴趣的，都可以点击<strong>【制作相同风格动画】</strong> 按钮作为参考模板来使用。</p>\n<p>我的动画网站上线一个月了，吸引了三千多位注册用户，其中有很多都是老师、医生、工程师，很多用户都在微信上给我发来好评，还有用户让我一定要坚持做下去，工作中已经离不开了。</p>\n<p>每当看到这些留言，我都非常有成就感，也让我更有动力把这个网站持续做深做好。</p>\n<p>也欢迎所有看到这篇文章的朋友来免费试用我的动画网站，网站地址就是：<a href=\"https://svganimate.ai\" rel=\"noopener nofollow\" target=\"_blank\">svganimate.ai</a>。</p>\n<p>路过的朋友欢迎点个关注，后续有新的更新也会第一时间在这里发布。</p>\n<h2 id=\"往期推荐\">往期推荐</h2>\n<ul>\n<li><a href=\"https://mp.weixin.qq.com/s/SvJjliEhFP90Yv97qyN-wA\" rel=\"noopener nofollow\" target=\"_blank\">一句话让AI生成科普动画，做动画视频太简单了！</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/m5JnHiLkNEQiG15KW5KZIQ\" rel=\"noopener nofollow\" target=\"_blank\">我开发了一个轻量又好用的抓包软件，基于Wireshark内核，只有20MB！</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/_Zrrk84vAjMidNH5FsaHfQ\" rel=\"noopener nofollow\" target=\"_blank\">一个神奇的网站：在线版“Wireshark”！</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/XrqnzIJVoXUprWWsJBObjA\" rel=\"noopener nofollow\" target=\"_blank\">我用Claude Code开发了一个个人网站！</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/Fp2ijjGH_qpuClQFOnVzGg\" rel=\"noopener nofollow\" target=\"_blank\">如何学习操作系统？</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/WDW1lceGhFBhY6bfAmZfoQ\" rel=\"noopener nofollow\" target=\"_blank\">如何学习计算机网络？</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/Kpn6i3PuZdcygfo4WAEHdg\" rel=\"noopener nofollow\" target=\"_blank\">如何学习C/C++编程？</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/6Tb361l8ADqtqFrOWZVIBg\" rel=\"noopener nofollow\" target=\"_blank\">如何学习网络安全？</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/o9i5pfQdfnhdyi-APuw06A\" rel=\"noopener nofollow\" target=\"_blank\">程序员赛道太卷，逆向工程师怎么样？</a></li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 17:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xuanyuan\">轩辕之风</a>&nbsp;\n阅读(<span id=\"post_view_count\">58</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从 Chat 到 Agent：Solon AI 带你进入“行动派”大模型时代",
      "link": "https://www.cnblogs.com/noear/p/19488385",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19488385\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 17:13\">\n    <span>从 Chat 到 Agent：Solon AI 带你进入“行动派”大模型时代</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Solon AI Agent 正式发布，推动大模型从 聊天机器人 向 智能执行体 进化。该框架提供三种智能体解决方案：SimpleAgent实现精准任务执行，ReActAgent支持复杂推理与行动，TeamAgent支持多智能体协作。Solon AI具有启动快、工具即方法、类型安全等优势，通过生命周期拦截可实时监控智能体运行过程。该框架旨在打破Chat与业务系统之间的屏障，让大模型真正转化为生产力，为Java应用赋予智能业务处理能力。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在过去的一年里，我们已经习惯了与 AI “聊天”。但当你试图让大模型帮你在数据库查数据、给客户发邮件、或者自动排查系统日志时，你会发现：<strong>只会“说”的对话框，无法直接解决复杂的业务逻辑。</strong></p>\n<p>大模型使用需要从“聊天机器人”进化为“智能执行体（Agent）”。</p>\n<p>作为高性能 Java AI 应用开发框架 Solon AI 增强版，<strong>Solon AI Agent</strong> 现已正式发布，旨在打破 Chat 与业务系统之间的屏障，开启智能体的“行动”元年。</p>\n<h2 id=\"1-现状chat-很美但离业务很远\">1. 现状：Chat 很美，但离业务很远</h2>\n<p>大多数开发者在使用 AI 时，还停留在简单的 API 调用层面：</p>\n<ul>\n<li><strong>上下文难管理</strong>：多轮对话的 Token 消耗和状态保存令人头疼。</li>\n<li><strong>能力有边界</strong>：模型无法感知你的数据库、无法调用你的微服务。</li>\n<li><strong>逻辑不闭环</strong>：模型给出了建议，但最后一步的操作还得靠人工手动完成。</li>\n</ul>\n<p><strong>智能体（Agent）的出现，改变了这一切。</strong> 它不再仅仅是“回答问题”，而是通过思考、规划、调用工具、团队协作（多智能体系统），最终“交付结果”。</p>\n<h2 id=\"2-跨越solon-ai-的智能体哲学\">2. 跨越：Solon AI 的智能体哲学</h2>\n<p>Solon AI Agent 提供了从极简到复杂的全栈智能体解决方案，让你的 AI 应用从“会说话”变成“会办事”。</p>\n<h3 id=\"极简派simpleagent--任务的精准执行\">极简派：SimpleAgent —— 任务的精准执行</h3>\n<p>如果你只需要一个能听懂指令、按格式输出、且具备短期记忆的小助手，<code>SimpleAgent</code> 是你的首选。它内置了自动重试、历史窗口管理和 JSON Schema 强约束。</p>\n<pre><code class=\"language-java\">// 1. 定义智能体\nSimpleAgent agent = SimpleAgent.of(chatModel)\n        .name(\"Translator\")\n        .systemPrompt(SimpleSystemPrompt.builder()\n                .role(\"你是一个中英文翻译助手\")\n                .instruction(\"请直接输出翻译结果，不要输出任何解释。\")\n                .build())\n        .build();\n\n// 2. 发起对话\nString result = agent.prompt(\"请把：'Life is short, use Python' 翻译成中文\").call().getContent();\nSystem.out.println(result); // 人生苦短，我用 Python\n                               \n</code></pre>\n<h3 id=\"思考派reactagent--像人一样推理与行动\">思考派：ReActAgent —— 像人一样推理与行动</h3>\n<p>面对复杂问题，ReActAgent 开启了“思考-行动-观察”的闭环。它能根据实时情况自主决定下一步该做什么。</p>\n<pre><code class=\"language-java\">// 1. 定义业务工具：给 Java 方法加上注解，AI 就能学会使用它\npublic class OrderService {\n    @ToolMapping(description = \"根据订单号查询快递状态\")\n    public String getOrderStatus(String orderNo) {\n        return \"订单 \" + orderNo + \" 正在派送中\";\n    }\n}\n\n// 2. 构建 ReAct 智能体\nReActAgent orderAgent = ReActAgent.of(chatModel)\n        .name(\"order_assistant\")\n        .systemPrompt(ReActSystemPrompt.builder()\n                        .role(\"你是一个专业的订单处理助手\")\n                        .instruction(\"请根据用户提供的信息处理订单\")\n                        .build())\n        .toolAdd(new MethodToolProvider(new OrderService())) \n        .build();\n\n// 3. 执行：AI 会自主思考 -&gt; 发现需查单 -&gt; 调用接口 -&gt; 组织语言反馈\nString answer = orderAgent.prompt(\"我的订单 SN9527 到哪了？能退钱吗？\").call().getContent();\n</code></pre>\n<h3 id=\"协作派teamagent--打造你的数字部门\">协作派：TeamAgent —— 打造你的数字部门</h3>\n<p>一个人的力量有限，TeamAgent 支持将多个 Agent 组织成团队。你可以配置“点到点模式（A2A）”让主管分发任务，也可以使用“顺序模式（Sequential）”构建生产线。</p>\n<pre><code class=\"language-java\">// 构建一个技术支持团队：包含“查单专家”和“日志专家”\nTeamAgent supportTeam = TeamAgent.of(chatModel)\n        .name(\"tech_support_team\")\n        .addAgent(orderAgent, logAgent)   \n        .protocol(TeamProtocols.HIERARCHICAL) // 主管负责分派任务\n        .build();\n\nsupportTeam.call(\"用户反馈订单查不到，帮我排查是数据库还是日志报错了。\");\n</code></pre>\n<h2 id=\"3-为何选择-solon-ai\">3. 为何选择 Solon AI？</h2>\n<ul>\n<li>天生快：延续 Solon 极简风格，启动快、内存省，适合微服务部署。</li>\n<li>工具即方法：无需复杂的 DSL，普通的 Java 方法即可直接作为工具。</li>\n<li>类型安全：借助 outputSchema，彻底告别 LLM 乱吐字符串导致的解析崩溃。</li>\n<li>生命周期拦截：通过拦截器，实时监控 Agent 的“内心独白”（Thought）和“动作执行”（Action）。</li>\n</ul>\n<pre><code class=\"language-java\">// 调试示例：实时打印 Agent 的思考过程\nagent.defaultInterceptorAdd(new ReActInterceptor() {\n    @Override\n    public void onThought(ReActTrace trace, String thought) {\n        System.out.println(\"🤔 思考中: \" + thought);\n    }\n});\n</code></pre>\n<h2 id=\"4-就在今天赋予你的应用灵魂\">4. 就在今天，赋予你的应用“灵魂”</h2>\n<p>从 Chat 进入 Agent，不仅是技术的迁移，更是思维的升级。未来每一个 Java 应用，都应该内置一个懂业务、会操作、能进化的智能体。</p>\n<p><strong>Solon AI，让大模型真正走进你的代码，转化为实际生产力。</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 17:13</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">21</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "进阶技巧：在Dash应用中直接使用原生React组件",
      "link": "https://www.cnblogs.com/feffery/p/19486989",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/feffery/p/19486989\" id=\"cb_post_title_url\" title=\"发布于 2026-01-15 13:56\">\n    <span>进阶技巧：在Dash应用中直接使用原生React组件</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<center style=\"font-size: 18px; font-weight: bold; padding-top: 40px;\">更多Dash应用开发干货知识、案例，欢迎关注“玩转Dash”微信公众号👇</center>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1344061/202507/1344061-20250703190053776-1837084116.png\" /></p>\n<h1 id=\"1-简介\">1 简介</h1>\n<p>大家好我是费老师。作为一个<code>Python</code>框架，我们日常在使用<code>Dash</code>构建各种应用的过程中，主流常见的功能可以利用<code>Dash</code>生态中丰富的<em>组件库</em>、<em>工具库</em>等资源，通过编写<code>Python</code>代码实现<em>全栈应用开发</em>，也可以额外配合<code>Dash</code>中的<em>浏览器端回调</em>，在<code>Dash</code>中很方便的调用<code>Echarts</code>等<em>原生JavaScript</em>库实现各种<em>特殊功能拓展</em>。</p>\n<p>除了这些常用形式以外，我们还可以基于今天文章中要给大家介绍的<code>Dash</code>插件<code>dash-vite-plugin</code>，实现将非原生<code>JavaScript</code>库譬如<code>React</code>等传统前端框架相关的功能逻辑，轻松整合到我们的<code>Dash</code>应用中，进一步提升<code>Dash</code>应用功能开发的上限🚀~</p>\n<center><img src=\"https://img2024.cnblogs.com/blog/1344061/202601/1344061-20260115134532456-1814849130.jpg\" /></center>\n<h1 id=\"2-dash-vite-plugin插件的使用\">2 dash-vite-plugin插件的使用</h1>\n<p><code>dash-vite-plugin</code>项目地址，欢迎⭐支持我们：</p>\n<ul>\n<li>Github仓库：<a href=\"https://github.com/HogaStack/dash-vite-plugin\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/HogaStack/dash-vite-plugin</a></li>\n<li>Gitee镜像同步仓库：<a href=\"https://gitee.com/insistence2022/dash-vite-plugin\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/insistence2022/dash-vite-plugin</a></li>\n</ul>\n<p>作为<code>Dash</code>应用的插件，我们可以直接通过<code>pip</code>对<code>dash-vite-plugin</code>进行安装：</p>\n<pre><code class=\"language-bash\">pip install dash-vite-plugin -U\n</code></pre>\n<p>完成安装后，我们直接来看几个实际应用案例，它们对应的完整源码你可以在👆上面提到的项目仓库中的<code>examples</code>目录下找到：</p>\n<h2 id=\"示例应用1shinytext特效\">示例应用1：ShinyText特效</h2>\n<p>这个例子基于非常流行的<code>React</code>动画效果库<code>react-bits</code>中的<code>ShinyText</code>组件（ <a href=\"https://reactbits.dev/text-animations/shiny-text\" rel=\"noopener nofollow\" target=\"_blank\">https://reactbits.dev/text-animations/shiny-text</a> ）。</p>\n<p>对应<code>dash-vite-plugin</code>源码仓库中的<code>examples/react-bits-shiny-text-demo</code>项目，<code>python app.py</code>启动后，初始执行需要稍等一会，等待终端提示相关构建完成后，访问本机<code>http://127.0.0.1:8050</code>就可以看到如下效果，完美还原了<code>react-bits</code>中的文字扫光特效组件功能：</p>\n<center><img src=\"https://img2024.cnblogs.com/blog/1344061/202601/1344061-20260115135151996-1596881536.gif\" /></center>\n<h2 id=\"示例应用2lightning特效\">示例应用2：Lightning特效</h2>\n<p>这个例子基于<code>react-bits</code>中的<code>Lightning</code>组件（ <a href=\"https://reactbits.dev/backgrounds/lightning\" rel=\"noopener nofollow\" target=\"_blank\">https://reactbits.dev/backgrounds/lightning</a> ）。</p>\n<p>对应<code>dash-vite-plugin</code>源码仓库中的<code>examples/react-bits-lightning-demo</code>项目，完美还原了<code>react-bits</code>中的雷电动态背景组件效果：</p>\n<center><img src=\"https://img2024.cnblogs.com/blog/1344061/202601/1344061-20260115135155979-1022491345.gif\" /></center>\n<h2 id=\"示例应用3gridscan特效\">示例应用3：GridScan特效</h2>\n<p>这个例子基于<code>react-bits</code>中的<code>GridScan</code>组件（ <a href=\"https://reactbits.dev/backgrounds/grid-scan\" rel=\"noopener nofollow\" target=\"_blank\">https://reactbits.dev/backgrounds/grid-scan</a> ）。</p>\n<p>对应<code>dash-vite-plugin</code>源码仓库中的<code>examples/react-bits-grid-scan-demo</code>项目，完美还原了<code>react-bits</code>中颇具赛博朋克风格的网格扫光背景组件效果：</p>\n<center><img src=\"https://img2024.cnblogs.com/blog/1344061/202601/1344061-20260115135159305-223594499.gif\" /></center>\n<hr />\n<p>有关<code>dash-vite-plugin</code>的使用说明详见项目仓库文档：</p>\n<ul>\n<li>Github仓库：<a href=\"https://github.com/HogaStack/dash-vite-plugin\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/HogaStack/dash-vite-plugin</a></li>\n<li>Gitee镜像同步仓库：<a href=\"https://gitee.com/insistence2022/dash-vite-plugin\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/insistence2022/dash-vite-plugin</a></li>\n</ul>\n<p>更多<code>Dash</code>应用开发可用插件列表详见：</p>\n<ul>\n<li><a href=\"https://github.com/HogaStack/awesome-dash-hooks\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/HogaStack/awesome-dash-hooks</a></li>\n</ul>\n<hr />\n<p>更多有关<code>Dash</code>应用开发的干货内容，欢迎持续关注我们❤️</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-15 13:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/feffery\">费弗里</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}