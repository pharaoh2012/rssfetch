{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "从零学习Kafka：数据存储",
      "link": "https://www.cnblogs.com/Jackeyzhe/p/19597292",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Jackeyzhe/p/19597292\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 23:47\">\n    <span>从零学习Kafka：数据存储</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"从零学习Kafka：数据存储\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1828322/202601/1828322-20260127214703996-2017510713.png\" />\n        不知道有没有朋友和我一样，虽然了解 Kafka 的逻辑存储，例如 Broker、Topic、Partition 这些概念，但是对于底层数据是如何存储还是比较模糊。这样聊起来 Kafka 数据存储时总有种一知半解的感觉。今天我们就一起来看一下 Kafka 底层数据到底是怎么存储的。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>不知道有没有朋友和我一样，虽然了解 Kafka 的逻辑存储，例如 Broker、Topic、Partition 这些概念，但是对于底层数据是如何存储还是比较模糊。这样聊起来 Kafka 数据存储时总有种一知半解的感觉。今天我们就一起来看一下 Kafka 底层数据到底是怎么存储的。</p>\n<h3 id=\"环境准备\">环境准备</h3>\n<p>在开始之前，我们先搭建好单机的 Kafka 集群，并且实际写入一批数据，这样就可以直接观察写入 Kafka 的数据了。下面可以跟着我的步骤一起搭建集群并写入数据。开始之前先说明一下，操作过程中可能涉及到一些配置参数的修改和检查，如果对配置参数不熟悉的话，可以查看上一篇文章。</p>\n<p>首先到 Kafka 的下载页面下载最新版本的压缩包。</p>\n<pre><code class=\"language-bash\">https://www.apache.org/dyn/closer.cgi?path=/kafka/4.1.1/kafka_2.13-4.1.1.tgz\n</code></pre>\n<p>下载好之后，进行解压并进入到对应的目录。</p>\n<pre><code class=\"language-bash\">tar -xzf kafka_2.13-4.1.1.tgz\ncd kafka_2.13-4.1.1\n</code></pre>\n<p>接着我们执行下面两条命令进行一些必要的配置。</p>\n<pre><code class=\"language-bash\">KAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\"\n\nbin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties\n</code></pre>\n<p>为了方便观察文件切分，我把 segment 文件大小调整为了 1MB，具体修改方法为编辑 config/server.properties 文件，修改 <code>log.segment.bytes</code> 参数的数值。</p>\n<p><img alt=\"segmentsize\" class=\"lazyload\" /></p>\n<p>修改好之后，就可以启动 Kafka 集群了。</p>\n<pre><code class=\"language-bash\">bin/kafka-server-start.sh config/server.properties\n</code></pre>\n<p>可以观察日志，看集群是否启动成功</p>\n<p><img alt=\"clusterstarted\" class=\"lazyload\" /></p>\n<p>集群启动之后，我们手动创建一个测试 topic。</p>\n<pre><code class=\"language-bash\">bin/kafka-topics.sh --create \\\n    --bootstrap-server localhost:9092 \\\n    --topic test-topic \\\n    --partitions 2 \\\n    --replication-factor 1\n</code></pre>\n<p>接着可以使用 Kafka 提供的压测工具来写入一批数据。</p>\n<pre><code class=\"language-bash\">bin/kafka-producer-perf-test.sh \\\n    --topic test-topic \\\n    --num-records 50000 \\\n    --record-size 100 \\\n    --throughput -1 \\\n    --producer-props bootstrap.servers=localhost:9092\n</code></pre>\n<p>这里我分两次写入，每次写入了 50000 条数据，每条数据大小 100 字节，也就是一共写入了大约 10MB 数据。</p>\n<p>现在把目光投向 <code>/tmp/kraft-combined-logs</code> 这个目录。如果没有这个目录，需要看一下集群配置的目录。</p>\n<p><img alt=\"category\" class=\"lazyload\" /></p>\n<h3 id=\"broker-根目录\">Broker 根目录</h3>\n<p>首先来看第一级目录</p>\n<pre><code class=\"language-bash\">drwxr-xr-x  10 wheel  320  1月 31 00:25 __cluster_metadata-0\n-rw-r--r--   1 wheel  355  1月 31 00:14 bootstrap.checkpoint\n-rw-r--r--   1 wheel    0  1月 31 00:14 cleaner-offset-checkpoint\n-rw-r--r--   1 wheel    4  1月 31 00:52 log-start-offset-checkpoint\n-rw-r--r--   1 wheel  122  1月 31 00:14 meta.properties\n-rw-r--r--   1 wheel   42  1月 31 00:52 recovery-point-offset-checkpoint\n-rw-r--r--   1 wheel   42  1月 31 00:52 replication-offset-checkpoint\ndrwxr-xr-x  23 wheel  736  1月 31 00:33 test-topic-0\ndrwxr-xr-x  27 wheel  864  1月 31 00:33 test-topic-1\n</code></pre>\n<p>这里一共有 9 个文件（目录），大体上可以分为三类：<strong>集群元数据、数据目录和 Checkpoint 文件</strong>。</p>\n<h4 id=\"集群元数据\">集群元数据</h4>\n<p><code>meta.properties</code> 是 Broker 的身份证，这里记录了 Cluster ID 和 Node ID。</p>\n<p><code>bootstrap.checkpoint</code> 用于记录集群初始化信息。</p>\n<p><code>__cluster_metadata-0</code> 是一个特殊的数据目录，它记录了集群的元数据，因此我将其归类到集群元数据中。</p>\n<h4 id=\"数据目录\">数据目录</h4>\n<p><code>test-topic-0</code> 和 <code>test-topic-1</code> 这两个目录就是我们 test-topic 的两个 partition 存储数据的目录，待会儿再详细分析目录下的内容，现在你只需要知道 Kafka 是以 topic名 + partitionId 来命名数据目录的。</p>\n<h4 id=\"checkpoint-文件\">Checkpoint 文件</h4>\n<p>剩下的都是 checkpoint 文件，是用于宕机重启后的快速恢复的。</p>\n<p><code>cleaner-offset-checkpoint</code> 这是清理检查点文件，只有设置了 <code>cleanup.policy=compact</code> 时才有用，它记录了上一次 Log Compact 各个 partition 已清理的偏移量。</p>\n<p><code>log-start-offset-checkpoint</code> 日志起始位置，记录每个分区第一个有效的 Offset。</p>\n<p><code>recovery-point-offset-checkpoint</code> 记录每个 partition 已刷盘的 Offset。</p>\n<p><code>replication-offset-checkpoint</code> 记录每个 partition 已同步的 Offset，这里记录的就是 High Watermark。</p>\n<h3 id=\"partition-存储结构\">Partition 存储结构</h3>\n<p>现在我们再来看下数据目录下的各个文件的作用是什么。</p>\n<h4 id=\"核心三兄弟\">核心三兄弟</h4>\n<p>首先来介绍数据存储的核心，分别是 <code>.log</code> 、<code>.index</code> 和 <code>.timeindex</code> 文件，每个 Segment 都会有这三个文件，它们的文件名都是文件内存的第一条消息的 Offset。</p>\n<h5 id=\"log-文件\">log 文件</h5>\n<p><code>.log</code> 是消息数据文件，Kafka 接收的消息都会顺序写入到这个文件中。可以通过下面这个命令查看文件的内容：</p>\n<pre><code class=\"language-bash\">~/workspace/kafka_2.13-4.1.1/bin/kafka-dump-log.sh --files test-topic-0/00000000000000009472.log --print-data-log\n</code></pre>\n<p><img alt=\"logdata\" class=\"lazyload\" /></p>\n<p>可以看到 log 文件中存储的主要是 Offset 和具体的序列化后的数据。</p>\n<h5 id=\"index-文件\">index 文件</h5>\n<p><code>.index</code> 文件是偏移量索引文件，这里的索引是稀疏索引，文件内存储的是 Offset 到 log 文件位置的映射。我们使用下面这条命令来查看文件内容：</p>\n<pre><code class=\"language-bash\">~/workspace/kafka_2.13-4.1.1/bin/kafka-dump-log.sh --files test-topic-0/00000000000000009472.index --deep-iteration\n</code></pre>\n<p><img alt=\"indexdata\" class=\"lazyload\" /></p>\n<p>Kafka 默认每 4KB 数据写入一次索引，这个值可以通过 <code>log.index.interval.bytes</code> 参数调整。</p>\n<h5 id=\"timeindex-文件\">timeindex 文件</h5>\n<p><code>.timeindex</code> 是时间戳索引文件，用来支持 by_duration 按照时间回溯。查看文件内容的方法与查看 index 文件的方法类似：</p>\n<pre><code class=\"language-bash\">~/workspace/kafka_2.13-4.1.1/bin/kafka-dump-log.sh --files test-topic-0/00000000000000009472.timeindex --deep-iteration\n</code></pre>\n<p><img alt=\"timeindexdata\" class=\"lazyload\" /></p>\n<p>我们在定位数据时，可以通过二分法在 index 索引文件中找到对应的数据位置（或者最接近的位置），也可以先通过时间在 timeindex 文件中找到最接近的 Offset，再到 index 文件中找到数据位置。</p>\n<h4 id=\"辅助文件\">辅助文件</h4>\n<p>除了上述三个核心文件之外，在数据目录中还有三种辅助文件，我们来看下它们的作用。</p>\n<ul>\n<li><code>.snapshot</code> 文件是用来记录事务快照的。用于 Exactly-Once 语义，如果 Broker 宕机，可以通过加载这个文件知道 Producer 之前发送到哪里了，防止数据重复。查看文件内容的方法如下</li>\n</ul>\n<pre><code class=\"language-bash\">~/workspace/kafka_2.13-4.1.1/bin/kafka-dump-log.sh --files test-topic-0/00000000000000009472.snapshot\n</code></pre>\n<ul>\n<li><code>leader-epoch-checkpoint</code> 文件是一个 Leader “任期表”，它记录了每一任 Leader 开始工作时的 Offset，主要用于在选主时保证数据一致性。</li>\n<li><code>partition.metadata</code> 文件是 Partition 的“身份证“，它存储了 Topic ID。</li>\n</ul>\n<h3 id=\"page-cache\">Page Cache</h3>\n<p>至此，我们已经比较细致的了解了 Kafka 底层存储结构。到这里不知道你会不会有疑问，Kafka 是写磁盘的，为什么速度还会这么快？</p>\n<p>Kafka 在操作磁盘时，重度依赖操作系统的 Page Cache 功能，这个功能就是 Kafka 性能高的原因之一。简单来说，Page Cache 就是在读取磁盘时，操作系统会把读到的数据放到内存中一份，这块内存就是 Page Cache。在 Kafka 的应用场景中，Producer 写入顺序写入数据时，操作系统会先把数据写到 Page Cache，然后异步刷盘。在 Consumer 消费数据时，由于大部分情况下都是消费最新数据，因此要读的数据大概率还在 Page Cache 中， 操作系统可以直接从内存中返回。</p>\n<p>题外话：Kafka 为什么不自己维护一套缓存机制呢？</p>\n<p>我觉得主要有以下原因：</p>\n<ol>\n<li>\n<p>避免 GC 开销，如果自己在 JVM 内存中维护缓存，那么会带来很大的 GC 压力。如果用操作系统的 Page Cache，就完全不用担心 GC 问题。</p>\n</li>\n<li>\n<p>Page Cache 对内存的利用率更高，如果 Kafka 进程重启，Page Cache 也还会在内存中，数据不需要重新加载。</p>\n</li>\n<li>\n<p>逻辑简单，Kafka 只需要负责读写操作，剩下的缓存维护逻辑全部交给操作系统。</p>\n</li>\n</ol>\n<h3 id=\"总结\">总结</h3>\n<p>本文我们了解了 Kafka 物理层面的数据存储。在 Broker 根目录下，有集群元数据、数据目录、Checkpoint 文件三种类型的文件（目录）。在数据目录中，最核心的三种文件是 <code>.log</code>、<code>.index</code> 和 <code>.timeindex</code> 三种文件，它们分别存储了数据、稀疏 Offset 索引以及时间戳与 Offset 的映射。</p>\n<p>希望你通过阅读本文，可以对 Kafka 的数据存储有一个更加清晰的认识。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 23:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Jackeyzhe\">Jackeyzhe</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "博客系统测试报告",
      "link": "https://www.cnblogs.com/xi-yongqi/p/19597272",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xi-yongqi/p/19597272\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 23:36\">\n    <span>博客系统测试报告</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h3 id=\"项目背景\">项目背景</h3>\n<ul>\n<li>博客系统采用前后端分离的架构实现。前端主要有四个页面构成：登录页、博客列表页、博客详情页、博客编辑页面，上面四个页面模拟实现了最简单的博客系统。结合后端，实现了登录、发布博客、编辑博客、删除博客、注销、强制登陆功能。</li>\n<li>该博客系统可以实现个人用户简单的博客记录，发布时间、标题展示、内容详情以及作者信息都可以进行查看。</li>\n</ul>\n<h3 id=\"项目功能\">项目功能</h3>\n<h5 id=\"该博客系统主要实现了登录注销写博客删除博客等功能\">该博客系统主要实现了：登录、注销、写博客、删除博客等功能。</h5>\n<ul>\n<li>登录功能：用户名以及密码已经写入数据库，没有实现注册功能，需要注册新用户需要在数据库手动添加。在登陆成功后会进入博客列表页面，登录页面右上角存在“主页”、“写博客”两个按钮；如果没有登陆就直接访问列表页会直接跳转到登陆页面。</li>\n<li>列表页面：在列表页面可以看到有限数量的博客，每一个博客包括：标题、发布时间、内容概要以及查看全文按钮；列表页左侧是用户信息，存在头像、昵称、文章以及文章分类数；列表页面右上角存在“主页”、“写博客”、“注销”三个按钮，主页就是列表页面，写博客是编辑页面，注销就是退出登录，返回登陆页面。</li>\n<li>详情页面：在列表页面点击“查看全文”按钮会跳转到博客详情页面，此时会看到博客的全文内容。在博客详情页面同样会有博客标题、发布时间等信息；同时还存在编辑、删除按钮，右上角也同样存在“主页”、“写博客”、“注销”三个按钮。点击删除按钮会在完成删除后跳转到列表页面，点击编辑按钮会进入编辑模式，左边是编辑前的样式，右边会同步显示编辑后的样式，编辑完成后点击“更新文章”按钮，会跳转到列表页面。</li>\n<li>写博客页面：点击“写博客”按钮会进入编辑页面，此时就可以进行博客编写，点击“发布文章”按钮，发布后会跳转到列表页面。</li>\n</ul>\n<h3 id=\"测试计划\">测试计划</h3>\n<h4 id=\"功能测试\">功能测试</h4>\n<ul>\n<li>\n<p>测试用例（脑图展示）<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>实际测试执行步骤部分展示</p>\n</li>\n</ul>\n<ol>\n<li>正常登录<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>写博客测试<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>博客发布后进入详情页进行查看<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>删除博客</li>\n</ol>\n<ul>\n<li>刚才2026-02-09 20:14发布的那篇文章就被删除<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n</ul>\n<ol start=\"5\">\n<li>点击“注销”按钮成功回到登录页面<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n</ol>\n<h4 id=\"接口自动化测试\">接口自动化测试</h4>\n<ul>\n<li><a href=\"https://www.cnblogs.com/xi-yongqi/p/19571986\" target=\"_blank\">接口自动化测试结果展示</a></li>\n</ul>\n<h4 id=\"性能测试\">性能测试</h4>\n<ul>\n<li>使用jmeter进行简单的性能测试，在这个过程中需要使用postman进行配合，获取相关请求头信息。</li>\n<li>添加http请求默认值<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>添加HTTP信息头管理器<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>模拟多组用户登录<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ul>\n<li>登录接口<br />\n<img alt=\"image\" class=\"lazyload\" />\n<ul>\n<li>使用JSON断言判断获取到的token是否符合要求<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n</ul>\n</li>\n<li>列表接口</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ul>\n<li>详情页接口</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>结果展示<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>使用命令<code>Jmeter -n -t 博客系统性能测试.jmx -l test.jtl -e -o reports</code>在终端生成测试报告<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p><a href=\"https://gitee.com/xylophone-queen/write-with-python/tree/dev/jmeter%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95\" rel=\"noopener nofollow\" target=\"_blank\">jmeter测试结果链接</a></p>\n</li>\n</ul>\n<h3 id=\"测试需要注意的点\">测试需要注意的点</h3>\n<ul>\n<li>在登录成功后，会得到如下数据：<br />\n<img alt=\"image\" class=\"lazyload\" /></li>\n<li>其中\"data\"中的数据在后面所有页面都需要使用，并且该data数据是动态变化的，我们可以使用正则表达式来获取并进行校验。</li>\n<li>使用jmeter性能测试，接口的url地址都是以<code>http://47.108.157.13:8090</code>开始，因此使用Http请求默认值进行统一设置来节省测试时间，避免重复配置。</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 23:36</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xi-yongqi\">我会替风去</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 时代的前端技术：从系统编程到 JavaScript/TypeScript",
      "link": "https://www.cnblogs.com/kaiux/p/19596869",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/kaiux/p/19596869\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 20:26\">\n    <span>AI 时代的前端技术：从系统编程到 JavaScript/TypeScript</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"AI 时代的前端技术：从系统编程到 JavaScript/TypeScript\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260209202606764-2110726327.png\" />\n        本书从系统程序员的视角，深入解析了 JavaScript 和 TypeScript 在现代应用中的核心作用，尤其是在人工智能（AI）和高并发系统中的应用。通过剖析浏览器引擎、构建工具、运行时机制及语言设计，揭示了前端技术栈如何支撑 AGI 的发展。从 V8 引擎的性能优化到异步编程模型的演变，本书不仅帮助开发者理解前端的底层原理，也为理解未来 AI 交互设计提供了技术视野。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><img alt=\"全景2\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260209202523377-936731118.png\" /></p>\n<h2 id=\"前言当-ai-的大脑跑在-v8-引擎之上\">前言：当 AI 的“大脑”跑在 V8 引擎之上</h2>\n<p><strong>The Prologue: When AGI Meets the Event Loop</strong></p>\n<p>在传统的系统程序员眼中，前端开发往往被戏称为“DIV 居中工程师”或“NPM 依赖搬运工”。我们习惯于认为，真正的计算——那些涉及高性能、高并发、底层硬件调度的任务——必然属于 C++、Rust 或 Python 的领地。</p>\n<p><strong>然而，在通往 AGI（通用人工智能）的道路上，一个反直觉的现象正在发生。</strong></p>\n<p>如果你拆解当下最热门的 AI 项目，你会惊讶地发现：<strong>TypeScript 和 JavaScript 正在成为 AI 应用层的“官方语言”。</strong></p>\n<ul>\n<li><strong>OpenClaw (ClawdBot):</strong> 这是一个强大的本地自主智能体（Autonomous Agent），它的“中枢神经”并非由 Python 编写，而是运行在 Node.js 的事件循环之上。</li>\n<li><strong>Claude Code / OpenCode:</strong> 这些让开发者惊叹的 AI 编程助手 CLI，其底层架构往往是 TypeScript 加上 V8 引擎的运行时。</li>\n<li><strong>Electron 生态:</strong> 无数的大模型本地客户端（Local LLM Runners），本质上都是 Chromium 内核包裹下的 Web 应用。</li>\n</ul>\n<p><strong>为什么会这样？</strong></p>\n<p>因为 AI 时代的本质发生了变化。大模型（LLM）本身是计算密集型的（由 CUDA/C++ 解决），但<strong>AI 应用（Agent）的本质是 IO 密集型的</strong>。</p>\n<p>一个优秀的 AI Agent 需要同时处理成百上千个并发的网络请求（API Calls）、需要实时解析非结构化的 JSON 数据、需要灵活地加载各种“工具（Tools）”函数、需要构建复杂的异步交互界面。</p>\n<p>在处理<strong>高并发 I/O</strong> 和 <strong>动态 JSON Schema</strong> 方面，没有什么比 <strong>Event Loop (libuv)</strong> 和 <strong>TypeScript 类型系统</strong> 更高效的组合了。</p>\n<p><strong>在 AI 时代，掌握前端技术栈，不再是为了画出漂亮的网页，而是为了构建 AI 的“躯壳”与“手脚”。</strong></p>\n<p>如果你不懂 Promise，你就无法理解 Agent 的并发思考模式；如果你不懂 Virtual DOM，你就无法构建高效的 AI 交互终端；如果你不懂 Node.js 运行时，你就无法完全掌控那些在该运行时上飞奔的智能体。</p>\n<p>不要被“前端”二字迷惑。这本手册将带你越过浏览器的围墙，用系统工程师的视角，重新审视这套正在定义 AI 应用层的技术栈。</p>\n<p><strong>Welcome to the metal of the modern web.</strong></p>\n<h2 id=\"1-生态全景图--幻象与裸机-the-illusion-vs-the-metal\">1. 生态全景图 —— 幻象与裸机 (The Illusion vs. The Metal)</h2>\n<p>对于习惯了系统底层编程的程序员，初入前端世界可能会感到一种 <strong>“分形的混乱”</strong> ：Webpack、Vite、Babel、ESLint、Prettier、PostCSS……这些工具像藤蔓一样缠绕在一起。</p>\n<p>这时候，请暂时忘掉那些花哨的名词。让我们像剥离操作系统抽象层一样，直接看向 <strong>“裸机” (The Metal)</strong> 。</p>\n<h3 id=\"11-the-hard-constraint-物理法则\">1.1. The Hard Constraint: 物理法则</h3>\n<p>在 Web 开发的宇宙里，浏览器（Browser）就是你的<strong>目标硬件架构 (Target Architecture)</strong>。</p>\n<p>无论你在 IDE 里写得多么天花乱坠——使用了 TypeScript 的高级泛型、React 的函数式组件、Vue 的单文件模板、还是 SCSS 的嵌套语法——<strong>浏览器一概不认识</strong>。</p>\n<p>Chrome (V8 引擎) 和 Firefox (SpiderMonkey) 本质上是 C++ 编写的解释器/JIT 编译器，它们<strong>只</strong>接受三种输入格式：</p>\n<ol>\n<li><strong>HTML:</strong> DOM 树的描述文件（类似 UI 布局 XML）。</li>\n<li><strong>CSS:</strong> 样式描述。</li>\n<li><strong>JavaScript (ES5/ES6+):</strong> 唯一的指令集架构 (ISA)。</li>\n</ol>\n<p><strong>这意味着：前端工程化的本质，就是一个庞大的“交叉编译”系统 (Cross-Compilation System)。</strong> 所有的复杂度，都源于我们需要把人类友好的“高级语言”（.ts, .vue, .jsx）翻译成浏览器这台“裸机”能吞下的“机器码”（.js, .html, .css）。</p>\n<h3 id=\"12-nodejs-的双重身份-the-build-environment\">1.2. Node.js 的双重身份: The Build Environment</h3>\n<p>这就引出了一个最让后端开发者困惑的问题：<em>“我就写个网页，为什么非要安装 Node.js？”</em></p>\n<p>这里存在一个<strong>认知陷阱</strong>。Node.js 在前端生态中扮演了两个完全不同的角色，必须严格区分：</p>\n<h4 id=\"121-角色-a服务器运行时-server-runtime\">1.2.1. 角色 A：服务器运行时 (Server Runtime)</h4>\n<p>这是你熟悉的。像 Python 或 Java 一样，Node.js 作为一个常驻进程运行在服务器上，处理 HTTP 请求，连接数据库。这叫 <strong>Backend / SSR (Server-Side Rendering)</strong>。</p>\n<h4 id=\"122-角色-b构建工具运行时-the-build-environment--这是重点\">1.2.2. 角色 B：构建工具运行时 (The Build Environment) —— <strong>这是重点</strong></h4>\n<p>这是你安装它的真正原因。<br />\n在开发阶段，你的电脑上并没有运行“服务器”，而是运行了一个<strong>构建系统</strong>。</p>\n<ul>\n<li><strong>Node.js 是你的 <code>make</code> + <code>gcc</code> + <code>ld</code>。</strong></li>\n<li><strong><code>package.json</code> 是你的 <code>Makefile</code> / <code>CMakeLists.txt</code>。</strong></li>\n<li><strong><code>npm</code> / <code>pnpm</code> 是你的 <code>vcpkg</code> / <code>apt-get</code>。</strong></li>\n</ul>\n<p>当你执行 <code>npm run build</code> 时，你实际上是启动了一个 Node.js 进程。这个进程加载了名为 <strong>Vite</strong> 或 <strong>Webpack</strong> 的库（编译器驱动），它们读取你的源码，进行词法分析、转换、链接、压缩，最后吐出 <code>dist/</code> 目录。</p>\n<blockquote>\n<p><strong>系统视角类比：</strong><br />\n你在 Windows 上写 C++，目标平台是 Linux。你需要安装 WSL (Node.js 环境) 来运行 GCC (Vite/Webpack)，最终生成 ELF 文件 (bundle.js) 扔到 Linux 服务器 (Browser) 上去跑。</p>\n</blockquote>\n<h3 id=\"13-the-abstractions-框架即-dsl\">1.3. The Abstractions: 框架即 DSL</h3>\n<p>既然浏览器只认 JS，为什么我们要发明 React 和 Vue？</p>\n<p>因为原生的 DOM API (<code>document.createElement</code>, <code>appendChild</code>) 就像是 <strong>Win32 API</strong> 或者 <strong>X11</strong>——极其繁琐、指令式、且难以维护。</p>\n<p>现代前端框架本质上是 <strong>DSL (领域特定语言)</strong>，旨在解决 UI 开发中的<strong>状态同步</strong>难题。</p>\n<h4 id=\"131-react-the-immutable-state-machine\">1.3.1. React (The Immutable State Machine)</h4>\n<p>React 的核心哲学是 <code>UI = f(State)</code>。<br />\nJSX 看起来像 HTML，但它只是 <code>React.createElement()</code> 的语法糖。</p>\n<ul>\n<li><strong>Source (JSX):</strong></li>\n</ul>\n<pre><code class=\"language-jsx\">// 这不是 HTML，这是 JS 表达式\nconst element = &lt;div className=\"btn\"&gt;Click {count}&lt;/div&gt;;\n\n</code></pre>\n<ul>\n<li><strong>Compiled (JS):</strong></li>\n</ul>\n<pre><code class=\"language-javascript\">// 编译器（Babel/Vite）将其转化为：\nconst element = React.createElement(\"div\", { className: \"btn\" }, \"Click \", count);\n\n</code></pre>\n<p><strong>本质：</strong> React 引入了 <strong>Virtual DOM</strong>，这实际上就是图形学中的 <strong>双重缓冲 (Double Buffering)</strong>。它在内存中构建下一帧的 UI 树，计算 Diff，然后一次性通过 syscall (DOM API) 更新屏幕，避免频繁 IO 带来的性能损耗。</p>\n<h4 id=\"132-vue-the-reactive-observer\">1.3.2. Vue (The Reactive Observer)</h4>\n<p>Vue 的 <code>.vue</code> 文件是更纯粹的 DSL。它甚至不符合 JS 语法，必须由编译器（Vue Compiler）大卸三块。</p>\n<ul>\n<li><strong>Template:</strong> 编译成 Render Function (类似 React)。</li>\n<li><strong>Script:</strong> 经过 TS 转译。</li>\n<li><strong>Style:</strong> 经过 CSS 预处理。</li>\n</ul>\n<p><strong>本质：</strong> Vue 3 利用了 ES6 的 <code>Proxy</code> 对象，实现了对内存数据的<strong>拦截</strong>。这类似于 C++ 的智能指针或运算符重载，当你修改变量时，自动触发回调去更新 UI。</p>\n<h3 id=\"14-总结the-pipeline-visualization\">1.4. 总结：The Pipeline Visualization</h3>\n<p>现在，我们将整个流程串联起来。作为系统架构师，你脑中应该建立起这样一张数据流图：</p>\n<p><img alt=\"mermaid\" src=\"https://img2024.cnblogs.com/blog/1158182/202602/1158182-20260209202549474-1723785530.png\" /></p>\n<p><strong>核心结论：</strong></p>\n<ol>\n<li><strong>幻象 (Illusion):</strong> 我们在写 TypeScript、React Hooks、Vue Templates。</li>\n<li><strong>现实 (Reality):</strong> 我们在写配置，指示 Node.js 进程如何生成一堆经过混淆的、浏览器能读懂的 ES5 代码。</li>\n<li><strong>Vite 的作用：</strong> 它就是那个<strong>极速的增量链接器 (Incremental Linker)</strong>。在开发时，它利用浏览器的 ESM 特性做“动态链接”；在发布时，它调用 Rollup 做“静态链接” (Bundling)。</li>\n</ol>\n<p>理解了这一点，就不会再被 <code>npm install</code> 下载的几千个包吓到了——那只是为了编译你的代码而准备的<strong>编译器工具链</strong>而已。</p>\n<h2 id=\"2-runtime--the-metal--引擎的咆哮-the-engines-roar\">2. Runtime &amp; The Metal —— 引擎的咆哮 (The Engine's Roar)</h2>\n<p>在第一章，我们剥离了构建工具的幻象。现在，让我们把视线聚焦到代码真正运行的地方——<strong>运行时 (Runtime)</strong>。</p>\n<p>作为系统开发者，你可能对解释型语言持有偏见：慢、动态、不可预测。但今天的 JavaScript 引擎（特别是 Google 的 V8）实际上是一个<strong>极其复杂的、基于配置文件的动态优化编译器 (Profile-Guided Optimizing Compiler)</strong>。它在某些场景下的性能甚至能逼近未高度优化的 C++。</p>\n<p>让我们钻进引擎盖下面看看。</p>\n<h3 id=\"21-v8-的本质jit-与动态这一仗-just-in-time-compilation\">2.1. V8 的本质：JIT 与动态这一仗 (Just-In-Time Compilation)</h3>\n<p>V8 并非像老式 Python 那样逐行解释执行。它是一个多级编译流水线。</p>\n<ul>\n<li><strong>Ignition (解释器):</strong> 当你的 JS 代码第一次运行时，V8 会将其解析为<strong>字节码 (Bytecode)</strong> 并由 Ignition 解释执行。这一步是为了启动速度 (Startup Time)——就像 Python 的 <code>.pyc</code>。</li>\n<li><strong>TurboFan (优化编译器):</strong> 在代码运行过程中，V8 会收集<strong>分析数据 (Profiling Data)</strong>。</li>\n<li>如果它发现某个函数被反复调用（\"Hot\" Function），TurboFan 就会介入。</li>\n<li>它会将字节码编译成高度优化的<strong>机器码 (Machine Code)</strong>。</li>\n<li><em>System Analogy:</em> 这就像你的 CPU 在运行时动态地重写指令流，或者 JVM 的 HotSpot 机制。</li>\n</ul>\n<h4 id=\"211-关键技术内联缓存-inline-caching--hidden-classes\">2.1.1. 关键技术：内联缓存 (Inline Caching / Hidden Classes)</h4>\n<p>JS 是动态类型的。<code>obj.x</code> 在 C++ 里是一个固定的内存偏移量（Offset），但在 JS 里，引擎理论上每次都要去 Hash Map 里查找 <code>x</code>。这慢得令人发指。</p>\n<p><strong>V8 的解决方案是“隐藏类” (Hidden Classes / Shapes)：</strong></p>\n<ol>\n<li>当你写 <code>function Point(x, y) { this.x = x; this.y = y; }</code> 时，V8 在内部悄悄创建了一个类似 C++ <code>struct</code> 的布局描述。</li>\n<li><strong>内联缓存 (IC):</strong> 当引擎第一次访问 <code>p.x</code> 时，它会查找 Hash Map，但它会<strong>记住</strong>这次查找的结果：“对于 <code>Point</code> 这种形状的对象，<code>x</code> 的偏移量是 0”。</li>\n<li>下次访问时，它直接使用偏移量 0，跳过 Hash 查找。</li>\n<li><strong>去优化 (Deoptimization):</strong> 如果你突然手贱写了一句 <code>p.z = 10</code>，对象的形状变了。V8 必须抛弃之前的优化代码（Deopt），回退到解释器模式，重新分析。</li>\n</ol>\n<blockquote>\n<p><strong>给系统程序员的启示：</strong> 在写高性能 JS 时，<strong>保持对象的形状稳定</strong>。不要随意添加/删除属性，尽量像写 C++ <code>struct</code> 一样初始化对象。这能让 JS 引擎生成接近 C++ 指针访问效率的机器码。</p>\n</blockquote>\n<h3 id=\"22-the-great-lie-单线程模型-the-single-threaded-model\">2.2. The Great Lie: 单线程模型 (The Single-Threaded Model)</h3>\n<p>你常听说“JavaScript 是单线程的”。这既是真的，也是假的。</p>\n<ul>\n<li><strong>JS 及其堆栈 (Call Stack) 是单线程的。</strong> 这意味着在任何给定时刻，只有一个 JS 函数在 CPU 上执行。</li>\n<li><strong>浏览器/Node.js 运行时 (The Runtime) 是多线程的。</strong></li>\n</ul>\n<h4 id=\"221-为什么是单线程the-design-choice\">2.2.1. 为什么是单线程？(The Design Choice)</h4>\n<p>JS 诞生之初是为了处理 DOM（网页 UI）。<br />\n想象一下，如果两个线程同时操作同一个 DOM 节点：一个线程要把 <code>&lt;div&gt;</code> 删了，另一个线程要给它加个 <code>class</code>。这需要复杂的锁机制 (Mutex/Semaphore)。</p>\n<p>对于 UI 编程来说，<strong>死锁 (Deadlock)</strong> 和<strong>竞态条件 (Race Condition)</strong> 是噩梦。JS 选择了<strong>协作式多任务 (Cooperative Multitasking)</strong> 模型：</p>\n<ul>\n<li><strong>优点：</strong> 只要你的代码块不结束，没人能打断你。你不需要写锁，永远不用担心竞态条件破坏内存一致性。</li>\n<li><strong>缺点：</strong> <strong>Head-of-Line Blocking</strong>。如果你写了一个 <code>while(true)</code> 或者计算了 10 亿次斐波那契数列，整个页面就会卡死（UI 渲染线程也被阻塞了）。</li>\n</ul>\n<h3 id=\"23-the-metal-事件循环-the-event-loop\">2.3. The Metal: 事件循环 (The Event Loop)</h3>\n<p>如果 JS 是单线程的，它是怎么处理网络请求（I/O）而不卡死的？<br />\n答案是：<strong>它把脏活累活都丢给了底层 C++ 线程池（libuv 或浏览器内核），自己只负责收信。</strong></p>\n<p>这就是 <strong>事件循环 (Event Loop)</strong>。这本质上就是一个 <strong>Windows Message Pump (GetMessage/DispatchMessage)</strong> 或者 Linux 上的 <strong><code>epoll</code> 循环</strong>。</p>\n<h4 id=\"231-循环机制-the-tick\">2.3.1. 循环机制 (The Tick)</h4>\n<p>想象一个无限循环 <code>while(queue.waitForMessage())</code>：</p>\n<ol>\n<li><strong>Call Stack:</strong> 执行同步代码（V8 引擎主线程）。</li>\n<li><strong>Web APIs / C++ Threads:</strong> 当你调用 <code>fetch()</code> 或 <code>setTimeout</code> 时，JS 只是向底层 C++ 模块发送了一个指令，然后立刻返回。底层线程负责等待网络响应或倒计时。</li>\n<li><strong>Callback Queue (Task Queue):</strong> 当底层工作完成，回调函数被扔进队列。</li>\n<li><strong>Loop:</strong> 一旦 Call Stack 空了，Event Loop 就从队列里取出一个回调压入栈中执行。</li>\n</ol>\n<blockquote>\n<p><strong>系统视角类比：</strong></p>\n<ul>\n<li>Main Thread = CPU Pipeline。</li>\n<li>Async Operations = DMA (Direct Memory Access) 控制器。</li>\n<li>Callback = 中断处理程序 (ISR)，但它是被<strong>延迟</strong>调度的 ISR。</li>\n</ul>\n</blockquote>\n<h3 id=\"24-异步进化论从回调地狱到协程-the-evolution\">2.4. 异步进化论：从回调地狱到协程 (The Evolution)</h3>\n<p>JS 的异步模型经历了三次重大的语法演进，每一次都是为了更优雅地处理<strong>栈结构</strong>。</p>\n<h4 id=\"241-phase-1-callback-hell-函数指针的滥用\">2.4.1. Phase 1: Callback Hell (函数指针的滥用)</h4>\n<p>最早的 JS 像这样写：</p>\n<pre><code class=\"language-javascript\">getData(function(a) {\n    getMoreData(a, function(b) {\n        getMoreData(b, function(c) {\n            // ...右移的三角形\n        });\n    });\n});\n\n</code></pre>\n<p><strong>问题：</strong> 这不是嵌套问题，这是<strong>控制反转 (Inversion of Control)</strong> 的丢失。你把后续逻辑的执行权交给了第三方库，而且错误处理 (Error Handling) 极其困难（<code>try/catch</code> 无法捕获异步回调里的错误，因为栈已经销毁了）。</p>\n<h4 id=\"242-phase-2-promises-状态机-monad\">2.4.2. Phase 2: Promises (状态机 Monad)</h4>\n<p><code>Promise</code> 本质上是一个对象，代表“未来可能出现的值”。</p>\n<pre><code class=\"language-javascript\">getData()\n  .then(a =&gt; getMoreData(a))\n  .then(b =&gt; getMoreData(b))\n  .catch(e =&gt; console.error(e));\n\n</code></pre>\n<p><strong>本质：</strong> 它标准化了回调的签名，并允许链式调用。重要的是，它引入了 <strong>Microtask Queue (微任务队列)</strong>。</p>\n<ul>\n<li><strong>Microtask (Promise):</strong> 优先级极高。在当前栈清空后，<strong>立即</strong>执行，插队在所有 IO 回调之前。</li>\n<li><strong>Macrotask (setTimeout):</strong> 优先级低。下一轮循环才执行。</li>\n</ul>\n<h4 id=\"243-phase-3-asyncawait-协程--coroutines\">2.4.3. Phase 3: Async/Await (协程 / Coroutines)</h4>\n<p>这是你最熟悉的形态。ES7 引入了 <code>async/await</code>。</p>\n<pre><code class=\"language-javascript\">async function main() {\n    try {\n        const a = await getData();\n        const b = await getMoreData(a);\n    } catch (e) {\n        console.error(e);\n    }\n}\n\n</code></pre>\n<p><strong>本质：</strong> 这就是 <strong>C++20 的协程 (Coroutines)</strong> 或 <strong>C# 的 Task</strong>。</p>\n<ul>\n<li><code>async</code> 函数会将代码编译成一个状态机 (State Machine)。</li>\n<li>遇到 <code>await</code> 时，函数<strong>暂停 (Yield)</strong>，保存当前的栈帧（闭包 context），并将控制权交还给 Event Loop。</li>\n<li>当 Promise 完成时，运行时恢复该函数的执行，并把结果填入。</li>\n</ul>\n<p><strong>总结：</strong> <code>async/await</code> 让你用<strong>同步的思维</strong>（线性的 try/catch）写<strong>异步的代码</strong>（非阻塞 I/O）。这是 JS 历史上最伟大的工程成就之一。</p>\n<h2 id=\"3-language--syntax--语法糖与类型防御-syntactic-sugar--type-defense\">3. Language &amp; Syntax —— 语法糖与类型防御 (Syntactic Sugar &amp; Type Defense)</h2>\n<p>在深入了解了构建工具的幻象和运行时的底层机制后，我们来到了最具争议的领域：<strong>语言本身的演进</strong>。</p>\n<p>对于 C++ 程序员来说，JavaScript 的对象模型（基于原型）和 TypeScript 的类型系统（结构化类型）往往是最反直觉的两个痛点。本章将剥离语法的表象，揭示它们在内存和编译期的真实形态。</p>\n<h3 id=\"31-从-prototype-到-class面向对象的伪装\">3.1. 从 Prototype 到 Class：面向对象的“伪装”</h3>\n<p>ES6 (ECMAScript 2015) 引入了 <code>class</code> 关键字，这让 JS 看起来终于像 Java/C++ 了。<br />\n<strong>但这只是一个巨大的谎言（或者说，高明的伪装）。</strong></p>\n<p>在 C++ 中，<code>class</code> 是编译期的蓝图。对象是根据蓝图在内存中切分出的数据块（vptr + 成员变量）。<br />\n在 JS 中，<code>class</code> 仅仅是 <strong>原型链 (Prototype Chain)</strong> 的语法糖。</p>\n<h4 id=\"311-原型链的本质单向链表-singly-linked-list\">3.1.1. 原型链的本质：单向链表 (Singly Linked List)</h4>\n<p>想象一下，JS 没有“类”的概念，只有“对象”。对象之间通过一个隐藏指针 <code>[[Prototype]]</code>（在浏览器调试中通常显示为 <code>__proto__</code>）连接。</p>\n<ul>\n<li><strong>查找机制：</strong> 当你访问 <code>obj.x</code> 时，引擎先在 <code>obj</code> 自身内存中找。找不到？顺着 <code>__proto__</code> 指针去“父对象”找。还找不到？继续向上，直到 <code>null</code>。</li>\n<li><strong>内存模型：</strong> 这不是继承（Inheritance），这是<strong>委托（Delegation）</strong>。</li>\n<li>C++ 继承：子类对象包含了父类对象的数据成员（内存布局是连续的）。</li>\n<li>JS 委托：子对象只是持有了一个指向父对象的指针。</li>\n</ul>\n<h4 id=\"312-es6-class-vs-the-metal\">3.1.2. ES6 Class vs. The Metal</h4>\n<p>看看这段“现代”代码：</p>\n<pre><code class=\"language-javascript\">class Dog extends Animal {\n  bark() { return \"Woof!\"; }\n}\n\n</code></pre>\n<p>它在底层的真实面目（ES5）：</p>\n<pre><code class=\"language-javascript\">function Dog() {} // 构造函数只是一个普通函数\nDog.prototype = Object.create(Animal.prototype); // 手动接上链表指针\nDog.prototype.bark = function() { return \"Woof!\"; }; // 把方法挂在链表节点上\n\n</code></pre>\n<blockquote>\n<p><strong>系统视角类比：</strong></p>\n<ul>\n<li><strong>Prototype:</strong> 就是一个共享的 <code>vtable</code>（虚函数表），但它本身也是一个普通的 Heap Object。</li>\n<li><strong>Instance:</strong> 就是一个包含 <code>vptr</code>（指向 Prototype）和成员变量的 <code>struct</code>。</li>\n<li><strong>Class 关键字:</strong> 只是为了让你写起来不那么恶心，不用手动操作 <code>vptr</code>。</li>\n</ul>\n</blockquote>\n<h3 id=\"32-typescript-的介入类型系统的反击\">3.2. TypeScript 的介入：类型系统的反击</h3>\n<p>既然 V8 引擎内部已经有了 Hidden Classes（动态类型推导），为什么我们还需要 TypeScript？</p>\n<p><strong>因为 V8 的推导发生在“运行时”，而 TypeScript 的检查发生在“编译时”。</strong><br />\n对于大型工程，等待运行时崩溃（Runtime Panic）是不可接受的。我们需要在代码部署前就拦截错误。</p>\n<h4 id=\"321-structural-typing-结构化类型-vs-nominal-typing-名义类型\">3.2.1. Structural Typing (结构化类型) vs. Nominal Typing (名义类型)</h4>\n<p>这是 TS 与 C++/Java 最根本的区别。</p>\n<ul>\n<li><strong>C++ (Nominal):</strong> 类型由<strong>名字</strong>决定。</li>\n</ul>\n<pre><code class=\"language-cpp\">struct A { int x; };\nstruct B { int x; };\nA a; B b = a; // ❌ 错误！A 和 B 是不同类型，即使内存布局完全一样。\n\n</code></pre>\n<ul>\n<li><strong>TypeScript (Structural):</strong> 类型由 <strong>形状（Shape）</strong> 决定。</li>\n</ul>\n<pre><code class=\"language-typescript\">interface A { x: number; }\ninterface B { x: number; }\nlet a: A = { x: 1 };\nlet b: B = a; // ✅ 合法！只要长得像（鸭子类型），就是同一种类型。\n\n</code></pre>\n<p><strong>解决了什么痛点？</strong><br />\n在前端，我们经常处理 JSON 数据。后端传回来的 JSON 只是一个纯数据结构，没有类名。结构化类型允许我们定义一个 Interface 来“套”在任何符合形状的 JSON 上，而不需要像 C++ 那样写繁琐的序列化/反序列化映射器。</p>\n<h4 id=\"322-type-erasure-类型擦除编译后的虚无\">3.2.2. Type Erasure (类型擦除)：编译后的虚无</h4>\n<p>TypeScript 的类型检查是<strong>纯粹的静态分析</strong>。<br />\n一旦编译通过，TS 编译器（tsc）会<strong>删除所有</strong>类型注解、接口定义、泛型声明。</p>\n<ul>\n<li><strong>Input (.ts):</strong></li>\n</ul>\n<pre><code class=\"language-typescript\">function add(a: number, b: number): number {\n  return a + b;\n}\n\n</code></pre>\n<ul>\n<li><strong>Output (.js):</strong></li>\n</ul>\n<pre><code class=\"language-javascript\">function add(a, b) {\n  return a + b;\n}\n\n</code></pre>\n<p>这意味着：</p>\n<ol>\n<li><strong>运行时没有开销：</strong> 没有 RTTI（运行时类型识别），没有虚函数表查找的额外损耗。</li>\n<li><strong>运行时没有保护：</strong> 如果你在运行时强行把一个 <code>string</code> 传给编译时标记为 <code>number</code> 的函数（比如通过 API 请求），JS 引擎会照单全收，然后可能崩给你看。</li>\n</ol>\n<blockquote>\n<p><strong>给系统程序员的启示：</strong></p>\n<ul>\n<li>TypeScript 就像是给 JavaScript 穿上了一层 <strong>编译期断言 (Compile-time Assertions)</strong>。</li>\n<li>它不会改变生成的机器码（JS），但它能保证你在写代码时逻辑自洽。</li>\n<li><strong>Trust Boundary:</strong> 永远不要相信 I/O 边界（网络请求、用户输入）进来的数据自动符合 TS 类型。你必须使用运行时校验库（如 Zod）来手动验证，这才是真正的“类型安全”。</li>\n</ul>\n</blockquote>\n<h2 id=\"4-the-engineering-layer--从手工作坊到工业流水线-engineering--frameworks\">4. The Engineering Layer —— 从手工作坊到工业流水线 (Engineering &amp; Frameworks)</h2>\n<p>前三章我们搞定了工具链、运行时和语言本身。现在，我们终于可以谈谈那些让前端开发者“以此为生”的东西了：<strong>框架 (Frameworks)</strong>。</p>\n<p>对于系统程序员来说，React 和 Vue 往往被误解为“仅仅是模板库”。实际上，它们的出现是为了解决一个计算机图形学中的经典难题：<strong>如何高效地将应用程序的内部状态 (Internal State) 映射到屏幕像素 (Pixels) 上，同时保持代码的可维护性？</strong></p>\n<h3 id=\"41-the-dom-api-a-syscall-nightmare-系统调用的噩梦\">4.1. The DOM API: A Syscall Nightmare (系统调用的噩梦)</h3>\n<p>回顾一下 jQuery 时代（2006-2013）。那时候我们直接操作 DOM。</p>\n<p><strong>为什么直接操作 DOM 是反模式？</strong></p>\n<ul>\n<li>\n<p><strong>The \"Context Switch\" Cost:</strong> 在浏览器中，JavaScript 引擎（V8）和 渲染引擎（Blink/Webkit）是两个独立的模块，甚至在某些架构下运行在不同的线程。</p>\n</li>\n<li>\n<p>每次你调用 <code>document.getElementById</code> 或 <code>element.style.color = 'red'</code>，实际上都发生了一次<strong>跨边界调用 (Cross-boundary Call)</strong>。</p>\n</li>\n<li>\n<p><strong>系统类比：</strong> 这就像你在写 C++ 程序时，为了写入文件，每写一个字节就调用一次 <code>write()</code> 系统调用 (Syscall)。性能开销是巨大的。</p>\n</li>\n<li>\n<p><strong>State Synchronization Hell:</strong> 想象一下，你有一个变量 <code>int count = 0</code>。每次 <code>count</code> 变化，你必须手动去寻找页面上所有显示 <code>count</code> 的 <code>&lt;div&gt;</code> 并更新它们。</p>\n</li>\n<li>\n<p>jQuery 代码充满了 <code>$('.counter').text(count)</code>。</p>\n</li>\n<li>\n<p>一旦逻辑复杂，这就是典型的 <strong>\"Spaghetti Code\"</strong> —— 状态（内存中的数据）和 视图（DOM 树）完全解耦，同步全靠手动。这在系统编程中等同于手动管理 <code>malloc/free</code> 且没有任何 RAII 机制，内存泄漏（UI 状态不一致）是必然的。</p>\n</li>\n</ul>\n<h3 id=\"42-ui-as-a-function-of-state-声明式革命\">4.2. UI as a Function of State: 声明式革命</h3>\n<p>React (2013) 引入了一个在当时看起来离经叛道的公式：</p>\n<p>这意味着：<strong>UI 只是状态的纯函数投影。</strong></p>\n<ul>\n<li><strong>Imperative (命令式 - jQuery/Win32 API):</strong> \"找到那个按钮，把它的颜色改成红色，然后把它的文字改成 'Clicked'。\" -&gt; <strong>关注过程 (How)</strong>。</li>\n<li><strong>Declarative (声明式 - React/Vue):</strong> \"按钮的状态是 <code>clicked</code>。当状态为 <code>clicked</code> 时，它应该是红色的且显示 'Clicked'。\" -&gt; <strong>关注结果 (What)</strong>。</li>\n</ul>\n<p><strong>系统类比：</strong><br />\n这就像从 <strong>Immediate Mode GUI (OpenGL <code>glBegin</code>/<code>glEnd</code>)</strong> 转向了 <strong>Retained Mode GUI (Qt/WPF)</strong>。你不再告诉 GPU 怎么画每一帧，你只是修改场景图（Scene Graph）中的数据，引擎负责渲染。</p>\n<h3 id=\"43-virtual-dom-the-double-buffering-双重缓冲\">4.3. Virtual DOM: The Double Buffering (双重缓冲)</h3>\n<p>既然 <code>UI = f(State)</code>，那岂不是每次状态改变（比如用户敲了一个键），我们都要销毁整个页面重新渲染？这在性能上是不可接受的。</p>\n<p>为了解决这个问题，React 引入了 <strong>Virtual DOM (虚拟 DOM)</strong>。</p>\n<h4 id=\"机制详解\">机制详解：</h4>\n<ol>\n<li><strong>Memory Buffer:</strong> Virtual DOM 本质上是一个轻量级的 JavaScript 对象树（JS Object Tree），它在内存中模拟了真实的 DOM 结构。</li>\n<li><strong>Render Phase:</strong> 当状态变更时，React 会调用你的组件函数，生成一棵<strong>新的</strong> Virtual DOM 树。</li>\n<li><strong>Diff Algorithm (The \"Linker\"):</strong> React 将新树与旧树进行对比（Diffing）。它使用一种启发式算法（复杂度 O(n)）找出最小变更集 (Dirty Regions)。</li>\n<li><strong>Commit Phase (Flush):</strong> React 将这些差异批量应用到真实的 DOM 上。</li>\n</ol>\n<p><strong>系统视角类比：</strong><br />\n这就是图形编程中的 <strong>双重缓冲 (Double Buffering)</strong>。</p>\n<ul>\n<li><strong>Front Buffer:</strong> 真实的 DOM（用户看到的，写入慢）。</li>\n<li><strong>Back Buffer:</strong> Virtual DOM（内存中的，读写极快）。</li>\n<li><strong>Swap/Flush:</strong> 只将 Back Buffer 中变化的部分 (Dirty Rectangles) 复制到 Front Buffer。</li>\n</ul>\n<blockquote>\n<p><strong>The Optimization:</strong> VDOM 并不总是比直接操作 DOM 快（因为多了 Diff 的 CPU 开销）。但它保证了<strong>下限</strong>——无论你的状态管理写得多么烂，它都能通过批处理（Batching）避免最坏的“每字节一次 Syscall”的情况。</p>\n</blockquote>\n<h3 id=\"44-componentization-the-shared-libraries-of-web\">4.4. Componentization: The \"Shared Libraries\" of Web</h3>\n<p>在框架出现之前，前端代码往往是“页面级”的：一个巨大的 HTML，配一个巨大的 CSS 和一个巨大的 JS。</p>\n<p>React/Vue 强制推行了 <strong>组件化 (Componentization)</strong>。</p>\n<ul>\n<li><strong>封装 (Encapsulation):</strong> 一个组件（Component）就是一个拥有独立状态（State）、独立逻辑（JS）和独立视图（JSX/Template）的单元。</li>\n<li><strong>复用 (Reusability):</strong> 组件可以像 Lego 积木一样嵌套。</li>\n<li><strong>接口 (Interface):</strong> 组件通过 <strong>Props</strong>（输入参数）和 <strong>Events</strong>（回调函数）进行通信。</li>\n</ul>\n<p><strong>系统类比：</strong></p>\n<ul>\n<li><strong>组件 = 类 (Class) / 结构体 (Struct)</strong>。</li>\n<li><strong>Props = 构造函数参数</strong>。</li>\n<li><strong>State = 私有成员变量</strong>。</li>\n<li><strong>Render = 这里的 <code>Draw()</code> 函数</strong>。</li>\n</ul>\n<p>这种架构将前端开发从“写脚本”提升到了“软件工程”的维度。我们可以像设计 C++ 类库一样设计 UI 系统，实现了 <strong>关注点分离 (Separation of Concerns)</strong>。</p>\n<h2 id=\"5-modern-ecosystem--速度与边界的突围-speed--boundaries\">5. Modern Ecosystem —— 速度与边界的突围 (Speed &amp; Boundaries)</h2>\n<p>如果说前四章是关于如何在浏览器这个“沙盒”里跳舞，那么这一章则是关于<strong>越狱</strong>。</p>\n<p>现代前端生态正在经历两场剧烈的地壳运动：</p>\n<ol>\n<li><strong>工具链的“原生化” (Native Rewrite)：</strong> 既然 JS 解释执行慢，那就用 Go/Rust 重写所有工具。</li>\n<li><strong>运行时的“泛化” (Universal Runtime)：</strong> JavaScript 不再局限于浏览器，它试图吞噬服务器、桌面甚至嵌入式设备。</li>\n</ol>\n<p>作为系统程序员，你会对这一章倍感亲切——因为我们要聊的终于不再是 DOM，而是<strong>编译原理</strong>、<strong>系统调用</strong>和<strong>进程间通信 (IPC)</strong>。</p>\n<h3 id=\"51-构建工具的战争从-webpack-到-viteesbuild\">5.1. 构建工具的战争：从 Webpack 到 Vite/Esbuild</h3>\n<h4 id=\"511-the-legacy-webpack-the-make-written-in-python\">5.1.1. The Legacy: Webpack (The \"Make\" written in Python)</h4>\n<p>在很长一段时间里，Webpack 是构建工具的霸主。它功能极其强大，但有一个致命弱点：<strong>它是用 JavaScript 写的。</strong></p>\n<ul>\n<li><strong>痛点：</strong> 随着项目膨胀，Webpack 需要解析成千上万个模块的 AST（抽象语法树），进行 Tree-shaking 和 Bundling。在单线程的 JS 运行时里，这导致冷启动可能需要 2-5 分钟。</li>\n<li><strong>类比：</strong> 这就像你在写一个 C++ 项目，但是你的编译器（GCC）和链接器（LD）是完全用 Python 写的。逻辑没问题，但吞吐量（Throughput）被解释型语言的性能天花板锁死了。</li>\n</ul>\n<h4 id=\"512-the-revolution-esbuild--swc-native-code\">5.1.2. The Revolution: Esbuild &amp; SWC (Native Code)</h4>\n<p>既然瓶颈在语言，解决方案就是<strong>换语言</strong>。</p>\n<ul>\n<li><strong>Esbuild (Go):</strong> Evan Wallace 用 Go 编写的打包器。</li>\n<li><strong>SWC (Rust):</strong> 用 Rust 编写的编译器（替代 Babel）。</li>\n</ul>\n<p>它们的性能通常是 Webpack 的 <strong>10-100 倍</strong>。为什么？</p>\n<ol>\n<li><strong>并行性 (Parallelism):</strong> Go 和 Rust 能充分利用多核 CPU（JS 只能单线程）。</li>\n<li><strong>内存管理:</strong> 手动管理内存布局，减少 GC 压力。</li>\n<li><strong>零成本抽象:</strong> 没有 JS 引擎的 JIT 预热开销。</li>\n</ol>\n<h4 id=\"513-the-game-changer-vite-the-jit-linker\">5.1.3. The Game Changer: Vite (The \"JIT\" Linker)</h4>\n<p>Vite (法语“快”) 结合了浏览器原生 ESM 能力和 Esbuild 的速度。</p>\n<ul>\n<li><strong>Dev Server (O(1) Start):</strong> Webpack 启动时需要把所有文件打包（Bundle）。Vite <strong>不打包</strong>。它启动一个 HTTP Server，当浏览器请求 <code>main.js</code> 时，它才实时通过 Esbuild 编译该文件并返回。</li>\n<li><strong>系统类比：</strong></li>\n<li><strong>Webpack:</strong> 静态链接 (Static Linking)。修改一行代码，重新链接整个 <code>.exe</code>。</li>\n<li><strong>Vite:</strong> 动态链接 (Dynamic Linking / <code>dlopen</code>)。修改一个 <code>.cpp</code>，只重编译它生成的 <code>.so</code>，程序运行时动态加载。</li>\n</ul>\n<h3 id=\"52-服务端运行时nodejs-vs-bundeno\">5.2. 服务端运行时：Node.js vs. Bun/Deno</h3>\n<p>JavaScript 运行时的战争，本质上是 <strong>C++ vs. Rust vs. Zig</strong> 的代理人战争。</p>\n<h4 id=\"521-nodejs-the-c-veteran\">5.2.1. Node.js (The C++ Veteran)</h4>\n<ul>\n<li><strong>架构：</strong> V8 (Engine) + libuv (Event Loop) + C++ Bindings。</li>\n<li><strong>地位：</strong> 就像 Linux 的 <strong>glibc</strong>。虽然有历史包袱（比如 <code>node_modules</code> 的嵌套黑洞），但它是标准，生态最全，极其稳定。</li>\n</ul>\n<h4 id=\"522-deno-the-rust-challenger\">5.2.2. Deno (The Rust Challenger)</h4>\n<ul>\n<li><strong>架构：</strong> V8 + Tokio (Rust Event Loop)。</li>\n<li><strong>卖点：</strong> 安全性（默认无文件/网络权限）、去中心化依赖（没有 <code>package.json</code>，直接 import URL）、原生 TypeScript 支持。</li>\n<li><strong>系统视角：</strong> Node.js 像 C++，给你所有权限但容易崩；Deno 像 Rust，编译器（运行时）强迫你守规矩。</li>\n</ul>\n<h4 id=\"523-bun-the-zig-speedster\">5.2.3. Bun (The Zig Speedster)</h4>\n<ul>\n<li><strong>架构：</strong> JavaScriptCore (Safari 的引擎) + Zig 自研 IO 层。</li>\n<li><strong>卖点：</strong> <strong>快，疯狂的快。</strong></li>\n<li><strong>Why Zig?</strong> Bun 的作者 Jarred Sumner 选择 Zig 是因为它可以手动控制内存布局，并且没有隐藏的控制流。Bun 重新实现了包管理器（npm client）、打包器和测试运行器。</li>\n<li><strong>系统类比：</strong> 如果 Node.js 是标准的 Ubuntu，Bun 就是 <strong>Alpine Linux</strong> —— 极致精简，为了启动速度和 IO 吞吐量牺牲了一切冗余。它旨在成为一个 <strong>Drop-in Replacement</strong>（直接替换 libc）。</li>\n</ul>\n<h3 id=\"53-electron-write-once-run-everywhere-的代价\">5.3. Electron: \"Write Once, Run Everywhere\" 的代价</h3>\n<p>Electron 是让无数系统程序员“嗤之以鼻”但又不得不服的技术。它允许用 Web 技术开发跨平台桌面应用（VS Code, Discord, Slack）。</p>\n<h4 id=\"531-架构本质chromium--nodejs\">5.3.1. 架构本质：Chromium + Node.js</h4>\n<p>Electron 的二进制文件里，塞进了一个完整的浏览器内核（Chromium）和一个完整的 Node.js 运行时。</p>\n<ul>\n<li><strong>Main Process (Kernel Space):</strong> 运行 Node.js。负责创建窗口、操作系统交互（文件、托盘、原生菜单）。它就像是这个应用的“内核”。</li>\n<li><strong>Renderer Process (User Space):</strong> 运行 Chromium。负责渲染 UI。每一个窗口通常是一个独立的进程。</li>\n<li><strong>IPC (Inter-Process Communication):</strong> 两个世界通过 IPC 管道通信。</li>\n</ul>\n<h4 id=\"532-为什么它能赢the-trade-off\">5.3.2. 为什么它能赢？(The Trade-off)</h4>\n<ul>\n<li><strong>系统程序员的质疑：</strong> <em>“为了写个记事本，你让我跑两个浏览器内核？这太浪费 RAM 了！”</em></li>\n<li><strong>工程视角的回答：</strong> 是的，它极其<strong>臃肿 (Bloated)</strong>。但是，它解决了 GUI 开发最大的痛点——<strong>跨平台一致性</strong>。</li>\n<li>写 Qt/MFC/GTK，你需要处理 Windows/macOS/Linux 的无数细微差异（DPI 缩放、字体渲染、事件循环差异）。</li>\n<li>Electron 把这些差异全部抹平在 Chromium 层之下。</li>\n<li><strong>结论：</strong> 它是 <strong>RAM 换开发效率 (Memory for Velocity)</strong> 的极致体现。对于现代硬件来说，浪费 500MB 内存换取 3 倍的开发速度，是商业上合理的交换。</li>\n</ul>\n<hr />\n<p><strong>结语：全栈的终局</strong></p>\n<p>读完这五章，作为系统程序员的你应该已经看透了 JavaScript/TypeScript 生态的本质：</p>\n<ol>\n<li><strong>它不再只是脚本</strong>：它是一个极其复杂的、分层的编译目标。</li>\n<li><strong>它正在“下沉”</strong>：工具链正在用系统语言（Go/Rust）重写，以追求极致性能。</li>\n<li><strong>它只是工具</strong>：就像 C++ 是操纵内存的工具，React/TS 是操纵 UI 状态的工具。</li>\n</ol>\n<p>不要被表面的框架战争迷惑。<strong>Keep your eyes on the metal, even when coding in the cloud.</strong></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 20:26</span>&nbsp;\n<a href=\"https://www.cnblogs.com/kaiux\">念风零壹</a>&nbsp;\n阅读(<span id=\"post_view_count\">16</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【开源】《clip》一个不到4M的、跨平台的、支持分组、搜索、自定义条数、局域网共享的、剪贴板历史工具",
      "link": "https://www.cnblogs.com/Doyoung/p/19596816",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Doyoung/p/19596816\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 20:03\">\n    <span>【开源】《clip》一个不到4M的、跨平台的、支持分组、搜索、自定义条数、局域网共享的、剪贴板历史工具</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"开源clip一个不到-4m-的跨平台剪贴板历史工具\">【开源】《clip》一个不到 4M 的跨平台剪贴板历史工具</h2>\n<p>一款轻量级的剪贴板历史管理工具，支持分组管理、内容搜索、自定义条数、局域网共享等功能。</p>\n<h3 id=\"特性\">特性</h3>\n<ul>\n<li>体积小巧：不到 4M</li>\n<li>跨平台支持</li>\n<li>支持文本和图片</li>\n<li>分组管理</li>\n<li>内容搜索</li>\n<li>自动识别颜色</li>\n<li>局域网共享</li>\n</ul>\n<h3 id=\"开源仓库\">开源仓库</h3>\n<ul>\n<li><a href=\"https://github.com/DoYoungDo/clip\" rel=\"noopener nofollow\" target=\"_blank\">GitHub</a></li>\n<li><a href=\"https://gitee.com/DoyoungDo/clip\" rel=\"noopener nofollow\" target=\"_blank\">Gitee</a></li>\n</ul>\n<h3 id=\"安装\">安装</h3>\n<p>从 <a href=\"https://github.com/DoYoungDo/clip/releases\" rel=\"noopener nofollow\" target=\"_blank\">GitHub Releases</a> 或 <a href=\"https://gitee.com/DoyoungDo/clip/releases\" rel=\"noopener nofollow\" target=\"_blank\">Gitee Releases</a> 下载对应平台的版本。</p>\n<p><strong>支持平台</strong></p>\n<ul>\n<li>macOS：直接下载运行</li>\n<li>Windows：直接下载运行</li>\n<li>Linux：需要自行编译</li>\n</ul>\n<p>本工具为免安装版本，下载解压后直接运行即可。</p>\n<h3 id=\"功能介绍\">功能介绍</h3>\n<h4 id=\"剪贴板历史记录\">剪贴板历史记录</h4>\n<p>clip 启动后会在系统托盘显示图标：</p>\n<p><img alt=\"系统托盘图标\" class=\"lazyload\" /></p>\n<p><strong>左键点击图标</strong>：显示菜单，分为两部分</p>\n<ul>\n<li>上半部分：最近的剪贴板历史记录</li>\n<li>下半部分：分组列表</li>\n</ul>\n<p><img alt=\"菜单界面\" class=\"lazyload\" /></p>\n<p>点击任意一条记录，会将其复制到系统剪贴板，同时该记录会移动到列表顶部。列表顶部始终显示当前剪贴板的内容。</p>\n<p>支持的内容类型：文本、图片</p>\n<p><strong>右键点击图标</strong>：除了显示历史记录，还会显示额外的操作选项，如清空历史记录、创建分组等。</p>\n<p><img alt=\"右键菜单\" class=\"lazyload\" /></p>\n<h4 id=\"分组管理\">分组管理</h4>\n<p><strong>创建分组</strong></p>\n<p>操作路径：<code>右键</code> → <code>创建分组</code></p>\n<p>会以当前剪贴板内容（列表顶部记录）作为分组名创建分组。</p>\n<p>注意事项：</p>\n<ul>\n<li>如果当前剪贴板内容是图片，创建会失败</li>\n<li>可以先复制想要的分组名，再执行创建操作</li>\n</ul>\n<p><strong>重命名分组</strong></p>\n<p>操作路径：<code>右键</code> → <code>分组</code> → <code>重命名</code></p>\n<p>同样会使用当前剪贴板内容作为新的分组名。</p>\n<p><strong>激活状态</strong></p>\n<p>分组有激活和非激活两种状态，默认为非激活。</p>\n<p>激活状态下，所有复制的内容会自动同步到该分组中，可以用作 TODO LIST。</p>\n<p><strong>持久化存储</strong></p>\n<p>工具支持本地持久化存储，退出后再次启动会自动加载：</p>\n<ul>\n<li>历史记录</li>\n<li>分组信息</li>\n<li>激活状态</li>\n</ul>\n<p><strong>删除分组</strong></p>\n<p>操作路径：<code>右键</code> → <code>分组</code> → <code>删除分组</code></p>\n<h4 id=\"内容搜索\">内容搜索</h4>\n<p>本工具为纯菜单操作，无输入框。</p>\n<p>搜索步骤：</p>\n<ol>\n<li>将要搜索的内容复制到剪贴板（使其成为列表顶部记录）</li>\n<li>操作路径：<code>右键</code> → <code>搜索</code></li>\n<li>再次点击托盘图标时，会显示过滤后的结果</li>\n</ol>\n<h4 id=\"自动识别颜色\">自动识别颜色</h4>\n<p><strong>开启方式</strong></p>\n<p>操作路径：<code>右键</code> → <code>配置</code> → <code>自动识别颜色</code></p>\n<p><strong>支持的颜色格式</strong></p>\n<p>开启后，工具会自动识别以下格式的颜色文本：</p>\n<ul>\n<li>十六进制：<code>#fff</code>、<code>#ffffff</code></li>\n<li>RGB：<code>(255,255,255)</code>、<code>255,255,255</code></li>\n</ul>\n<p><strong>快速转换</strong></p>\n<p>在颜色文本记录上可以直接复制为指定格式，实现快速格式转换。</p>\n<p><img alt=\"颜色识别\" class=\"lazyload\" /></p>\n<h4 id=\"自定义历史记录条数\">自定义历史记录条数</h4>\n<p><strong>设置范围</strong></p>\n<p>最小 1 条，最大 300 条，默认 50 条。</p>\n<p><strong>设置步骤</strong></p>\n<ol>\n<li>将要设置的条数（数字）复制到剪贴板</li>\n<li>操作路径：<code>右键</code> → <code>配置</code> → <code>设置最大历史记录条数</code></li>\n</ol>\n<p><strong>注意事项</strong></p>\n<ol>\n<li>如果新设置的条数小于当前历史记录数量，超出部分会被删除，仅保留最新的记录。删除的记录不会被持久化保存。</li>\n<li>如果列表顶部记录不是数字，会设置失败</li>\n</ol>\n<h4 id=\"局域网共享\">局域网共享</h4>\n<p>局域网内的设备可以通过本工具实现剪贴板共享（支持文本和图片）。</p>\n<p><strong>共享端（机器 A）</strong></p>\n<p>操作路径：<code>右键</code> → <code>配置</code> → <code>局域网共享</code> → <code>局域网共享</code></p>\n<p>开启后会自动将监听地址（格式：<code>192.168.1.100:8080</code>）复制到剪贴板。</p>\n<p><strong>接收端（机器 B）</strong></p>\n<ol>\n<li>将共享端的地址复制到剪贴板</li>\n<li>操作路径：<code>右键</code> → <code>配置</code> → <code>局域网共享</code> → <code>连接到</code></li>\n<li>再次执行相同操作可断开连接</li>\n</ol>\n<p><strong>同步说明</strong></p>\n<p>连接成功后，共享端（A）的所有复制操作会实时同步到接收端（B）的剪贴板，连接前的历史记录不会同步。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    做一条有理想的咸鱼\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 20:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Doyoung\">咸鱼Doyoung</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "OpenClaw for macOS: 完整本地化部署指南（2026.2.6-3 版本）",
      "link": "https://www.cnblogs.com/xiaobaiysf/p/19595515",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaobaiysf/p/19595515\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 15:06\">\n    <span>OpenClaw for macOS: 完整本地化部署指南（2026.2.6-3 版本）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"OpenClaw for macOS: 完整本地化部署指南（2026.2.6-3 版本）\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3600464/202602/3600464-20260209150457965-1453431698.png\" />\n        基于Mac环境安装 OpenClaw ，构建你的个人AI助理！\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"一文档说明\">一、文档说明</h1>\n<p>本文档面向 macOS 系统用户，从<strong>基础环境搭建（Node.js 安装）</strong> 到 <strong>OpenClaw 完整部署</strong>，再到问题排查、残余清理，提供全流程标准化操作，适配 OpenClaw 2026.2.6-3 版本，最终实现 DeepSeek 模型的稳定调用。</p>\n<h1 id=\"二部署前置条件\">二、部署前置条件</h1>\n<h2 id=\"1-系统要求\">1. 系统要求</h2>\n<ul>\n<li>\n<p>操作系统：macOS 10.15+（本文以 MacBook Air (M系列/Intel) 为例）</p>\n</li>\n<li>\n<p>权限：拥有终端管理员权限（可执行 <code>sudo</code> 命令）</p>\n</li>\n<li>\n<p>网络：能正常访问 DeepSeek API（国内网络直接支持）</p>\n</li>\n</ul>\n<h2 id=\"2-预期成果\">2. 预期成果</h2>\n<ul>\n<li>\n<p>完成 Node.js 环境搭建（v24.13.0 及以上）；</p>\n</li>\n<li>\n<p>OpenClaw 网关正常启动，端口 18789 可访问；</p>\n</li>\n<li>\n<p>OpenClaw UI 能调用 DeepSeek 模型并返回对话结果。</p>\n</li>\n</ul>\n<h1 id=\"三基础环境搭建nodejs-安装\">三、基础环境搭建（Node.js 安装）</h1>\n<p>OpenClaw 基于 Node.js 运行，需先完成 Node.js 安装与版本验证。</p>\n<h3 id=\"步骤1安装-homebrewmacos-包管理器推荐\">步骤1：安装 Homebrew（macOS 包管理器，推荐）</h3>\n<p>若已安装 Homebrew，跳过此步骤；未安装则执行：</p>\n<pre><code class=\"language-Bash\">\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>\n<p>✅ 验证安装：</p>\n<pre><code class=\"language-Bash\">\nbrew -v\n</code></pre>\n<p>输出 <code>Homebrew 4.x.x</code> 即安装成功。</p>\n<h3 id=\"步骤2安装-nodejs\">步骤2：安装 Node.js</h3>\n<p>通过 Homebrew 安装稳定版 Node.js（自动适配 v24+）：</p>\n<pre><code class=\"language-Bash\">\nbrew install node\n</code></pre>\n<p>✅ 验证安装与版本：</p>\n<pre><code class=\"language-Bash\">\n# 查看 Node.js 版本\nnode -v\n# 查看 npm 版本（Node.js 自带）\nnpm -v\n</code></pre>\n<ul>\n<li>\n<p>✅ 输出 <code>node v24.13.0</code> 及以上、<code>npm 10.x.x</code> 即符合要求；</p>\n</li>\n<li>\n<p>❌ 若版本过低，执行 <code>brew upgrade node</code> 升级。</p>\n</li>\n</ul>\n<h3 id=\"步骤3配置-npm-全局路径可选避免权限报错\">步骤3：配置 npm 全局路径（可选，避免权限报错）</h3>\n<pre><code class=\"language-Bash\">\n# 创建全局目录\nmkdir -p ~/.npm-global\n# 配置 npm 全局路径\nnpm config set prefix '~/.npm-global'\n# 将全局路径加入环境变量（永久生效）\necho 'export PATH=~/.npm-global/bin:$PATH' &gt;&gt; ~/.zshrc\n# 生效环境变量\nsource ~/.zshrc\n</code></pre>\n<p>✅ 验证配置：</p>\n<pre><code class=\"language-Bash\">\nnpm config get prefix\n</code></pre>\n<p>输出 <code>~/.npm-global</code> 即配置成功。</p>\n<h2 id=\"四openclaw-完整部署流程\">四、OpenClaw 完整部署流程</h2>\n<h3 id=\"步骤1安装-openclaw-包\">步骤1：安装 OpenClaw 包</h3>\n<p>通过 npm 全局安装 OpenClaw：</p>\n<pre><code class=\"language-Bash\">\nnpm install -g openclaw\n</code></pre>\n<p>✅ 验证安装路径：</p>\n<pre><code class=\"language-Bash\">\nls ~/.npm-global/lib/node_modules/openclaw\n</code></pre>\n<p>输出 OpenClaw 相关文件（如 <code>dist</code>、<code>package.json</code>）即安装成功。</p>\n<h3 id=\"步骤2openclaw-配置文件初始化与修改\">步骤2：OpenClaw 配置文件初始化与修改</h3>\n<p>OpenClaw 核心配置文件为 <code>~/.openclaw/openclaw.json</code>，需确保语法合法且适配 DeepSeek 模型。</p>\n<h4 id=\"21-初始化配置目录首次部署\">2.1 初始化配置目录（首次部署）</h4>\n<pre><code class=\"language-Bash\">\nmkdir -p ~/.openclaw\n</code></pre>\n<h4 id=\"22-备份原有配置若有\">2.2 备份原有配置（若有）</h4>\n<pre><code class=\"language-Bash\">\nif [ -f ~/.openclaw/openclaw.json ]; then\n  mkdir -p ~/.openclaw/backup\n  cp ~/.openclaw/openclaw.json ~/.openclaw/backup/openclaw.json.bak\nfi\n</code></pre>\n<h4 id=\"23-写入适配-deepseek-的无错配置核心\">2.3 写入适配 DeepSeek 的无错配置（核心）</h4>\n<p>执行以下命令，直接写入预验证的合法配置（替换占位符为真实信息）：</p>\n<pre><code class=\"language-Bash\">\ncat &gt; ~/.openclaw/openclaw.json &lt;&lt; 'EOF'\n{\n  \"meta\": {\n    \"lastTouchedVersion\": \"2026.2.6-3\",\n    \"lastTouchedAt\": \"2026-02-08T07:43:20.228Z\"\n  },\n  \"models\": {\n    \"mode\": \"merge\",\n    \"providers\": {\n      \"deepseek\": {\n        \"baseUrl\": \"https://api.deepseek.com/v1\",\n        \"apiKey\": \"你的DeepSeek API Key\", // 替换为真实Key（格式：sk-xxxx）\n        \"api\": \"openai-completions\",\n        \"models\": [\n          {\n            \"id\": \"deepseek-chat\",\n            \"name\": \"DeepSeek Chat\",\n            \"input\": [\"text\"],\n            \"contextWindow\": 128000,\n            \"maxTokens\": 8192,\n            \"reasoning\": false\n          }\n        ]\n      }\n    }\n  },\n  \"agents\": {\n    \"defaults\": {\n      \"workspace\": \"/Users/你的用户名/.openclaw/workspace\", // 替换为实际用户名（如 zhufeige）\n      \"maxConcurrent\": 4,\n      \"subagents\": {\n        \"maxConcurrent\": 8\n      },\n      \"model\": {\n        \"primary\": \"deepseek/deepseek-chat\" // 指定默认调用 DeepSeek 模型\n      }\n    }\n  },\n  \"gateway\": {\n    \"port\": 18789,\n    \"mode\": \"local\",\n    \"auth\": {\n      \"mode\": \"token\",\n      \"token\": \"39769ded65eac493eceeb0fb6a543fb48ed4fce3f1166bf5\" // 替换个人生成的此值即可\n    }\n  }\n}\nEOF\n</code></pre>\n<h4 id=\"24-配置文件修改说明\">2.4 配置文件修改说明</h4>\n<ul>\n<li>\n<p>替换 <code>你的DeepSeek API Key</code>：从 <a href=\"https://platform.deepseek.com/\" rel=\"noopener nofollow\" target=\"_blank\">DeepSeek 控制台</a> 获取，格式为 <code>sk-xxxx</code>；</p>\n</li>\n<li>\n<p>替换 <code>你的用户名</code>：macOS 用户名可通过 <code>whoami</code> 命令查看（终端执行 <code>whoami</code> 即可输出）；</p>\n</li>\n<li>\n<p>生成并打印OpenClaw的token</p>\n</li>\n</ul>\n<pre><code>node ~/.npm-global/lib/node_modules/openclaw/openclaw.mjs gateway token --print\n</code></pre>\n<h4 id=\"25-配置语法验证必做避免启动报错\">2.5 配置语法验证（必做，避免启动报错）</h4>\n<pre><code class=\"language-Bash\">\nnode -e \"JSON.parse(require('fs').readFileSync('/Users/$(whoami)/.openclaw/openclaw.json', 'utf8'))\"\n</code></pre>\n<ul>\n<li>\n<p>✅ 终端无任何输出 → 语法完全正确；</p>\n</li>\n<li>\n<p>❌ 若报错：检查是否有全角字符（如 <code>：</code>/<code>，</code>）、多余/缺失的 <code>{}</code>/<code>,</code>/<code>\"</code>。</p>\n</li>\n</ul>\n<h4 id=\"26-修复配置权限\">2.6 修复配置权限</h4>\n<pre><code class=\"language-Bash\">\nnode ~/.npm-global/lib/node_modules/openclaw/openclaw.mjs doctor --fix\n</code></pre>\n<p>✅ 输出无 <code>Config validation failed</code> 即权限修复成功。</p>\n<h3 id=\"步骤3启动-openclaw-网关\">步骤3：启动 OpenClaw 网关</h3>\n<h4 id=\"31-清理残余进程避免端口冲突\">3.1 清理残余进程（避免端口冲突）</h4>\n<pre><code class=\"language-Bash\">\n# 方法1：OpenClaw 官方停止命令\nopenclaw gateway stop\n\n# 方法2：强制杀死所有 OpenClaw 进程（推荐）\npkill -f openclaw\n\n# 方法3：杀死占用 18789 端口的进程（若端口被占用）\nlsof -i :18789 | grep -v PID | awk '{print $2}' | xargs kill -9 2&gt;/dev/null\n</code></pre>\n<h4 id=\"32-启动网关指定端口并强制重载\">3.2 启动网关（指定端口并强制重载）</h4>\n<pre><code class=\"language-Bash\">\nnode ~/.npm-global/lib/node_modules/openclaw/openclaw.mjs gateway --port 18789 --force\n</code></pre>\n<p>✅ 终端输出以下内容即启动成功：</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h3 id=\"步骤4验证部署效果\">步骤4：验证部署效果</h3>\n<h4 id=\"41-实时监控运行日志\">4.1 实时监控运行日志</h4>\n<p>打开新终端窗口，执行以下命令跟踪日志（排查问题关键）：</p>\n<pre><code class=\"language-Bash\">\ntail -f /tmp/openclaw/openclaw-$(date +%Y-%m-%d).log\n</code></pre>\n<ul>\n<li>\n<p>无 <code>error</code>/<code>invalid config</code> 关键字 → 运行正常；</p>\n</li>\n<li>\n<p>若出现 <code>API request failed</code> → 检查 DeepSeek API Key 是否有效。</p>\n</li>\n</ul>\n<h4 id=\"42-访问-openclaw-ui-测试对话\">4.2 访问 OpenClaw UI 测试对话</h4>\n<ol>\n<li>打开浏览器，访问 <code>http://127.0.0.1:18789</code>；</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>\n<p>在输入框发送测试消息（如「test」或「你好」）；</p>\n</li>\n<li>\n<p>✅ 收到 DeepSeek 回复 → 部署完全成功；</p>\n</li>\n<li>\n<p>❌ 无回复：执行以下命令验证 API Key 有效性：</p>\n<pre><code class=\"language-Bash\">\ncurl -s -X POST https://api.deepseek.com/v1/chat/completions \\\n  -H \"Authorization: Bearer 你的DeepSeek API Key\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\":\"deepseek-chat\",\"messages\":[{\"role\":\"user\",\"content\":\"test\"}]}'\n</code></pre>\n<ul>\n<li>\n<p>输出包含 <code>\"content\"</code> 字段 → API Key 有效，重启网关即可；</p>\n</li>\n<li>\n<p>输出 <code>Unauthorized</code> → API Key 无效，重新从 DeepSeek 控制台生成。</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"五常见问题排查\">五、常见问题排查</h1>\n<h2 id=\"问题1nodejs-安装失败\">问题1：Node.js 安装失败</h2>\n<ul>\n<li>\n<p>原因：网络问题导致 Homebrew 下载失败；</p>\n</li>\n<li>\n<p>解决：切换国内源安装 Node.js：</p>\n<pre><code class=\"language-Bash\">\n# 配置 npm 国内源\nnpm config set registry https://registry.npmmirror.com\n# 直接通过 npm 安装 Node.js\nnpm install -g n\nn 24.13.0\n</code></pre>\n</li>\n</ul>\n<h2 id=\"问题2json-语法错误如-invalid-character-\">问题2：JSON 语法错误（如 <code>invalid character ':'</code>）</h2>\n<ul>\n<li>\n<p>原因：配置文件存在格式错误（全角字符、多余符号）；</p>\n</li>\n<li>\n<p>解决：直接重新执行步骤2.3 的配置写入命令，避免手动修改格式。</p>\n</li>\n</ul>\n<h2 id=\"问题3端口冲突gateway-already-running-locally\">问题3：端口冲突（<code>Gateway already running locally</code>）</h2>\n<ul>\n<li>\n<p>原因：18789 端口被占用，或 OpenClaw 进程未彻底停止；</p>\n</li>\n<li>\n<p>解决：执行步骤3.1 的进程清理命令，或更换启动端口（如 <code>--port 18788</code>）。</p>\n</li>\n</ul>\n<h2 id=\"问题4ui-无对话反馈网关启动正常\">问题4：UI 无对话反馈（网关启动正常）</h2>\n<ul>\n<li>原因1：未指定默认模型（<code>agents.defaults.model.primary</code> 缺失）；</li>\n</ul>\n<p>解决：确保配置中包含 <code>\"primary\": \"deepseek/deepseek-chat\"</code>；</p>\n<ul>\n<li>原因2：API Key 无效/过期；</li>\n</ul>\n<p>解决：重新从 DeepSeek 控制台生成 Key 并替换配置；</p>\n<ul>\n<li>原因3：配置包含冗余字段（<code>wizard</code>/<code>messages</code>/<code>commands</code>）；</li>\n</ul>\n<p>解决：删除冗余字段，仅保留步骤2.3 中的核心配置。</p>\n<h2 id=\"问题5docker-容器名称冲突container-name-already-in-use\">问题5：Docker 容器名称冲突（<code>container name already in use</code>）</h2>\n<ul>\n<li>\n<p>原因：1Panel 部署的 OpenClaw 容器未删除；</p>\n</li>\n<li>\n<p>解决：</p>\n<pre><code class=\"language-Bash\">\n# 停止冲突容器（替换为实际容器ID/名称）\ndocker stop 1Panel-openclaw-rt8j\n# 删除冲突容器\ndocker rm 1Panel-openclaw-rt8j\n</code></pre>\n</li>\n</ul>\n<h1 id=\"六openclaw-残余内容清理彻底卸载重置\">六、OpenClaw 残余内容清理（彻底卸载/重置）</h1>\n<p>若需重新部署或完全卸载 OpenClaw，执行以下命令清理所有残余文件：</p>\n<h3 id=\"1-停止所有-openclaw-进程\">1. 停止所有 OpenClaw 进程</h3>\n<pre><code class=\"language-Bash\">\npkill -f openclaw\nopenclaw gateway stop\n</code></pre>\n<h3 id=\"2-删除-openclaw-核心目录配置数据\">2. 删除 OpenClaw 核心目录（配置+数据）</h3>\n<pre><code class=\"language-Bash\">\nrm -rf ~/.openclaw\n</code></pre>\n<h3 id=\"3-删除-openclaw-日志文件\">3. 删除 OpenClaw 日志文件</h3>\n<pre><code class=\"language-Bash\">\nrm -rf /tmp/openclaw\n</code></pre>\n<h3 id=\"4-卸载-openclaw-npm-包\">4. 卸载 OpenClaw npm 包</h3>\n<pre><code class=\"language-Bash\">\nnpm uninstall -g openclaw\n</code></pre>\n<h2 id=\"5-清理-docker-残余若通过-1paneldocker-部署过\">5. 清理 Docker 残余（若通过 1Panel/Docker 部署过）</h2>\n<pre><code class=\"language-Bash\">\n# 列出所有容器\ndocker ps -a | grep openclaw\n# 删除 OpenClaw 相关容器（替换为实际容器ID）\ndocker rm 容器ID\n# 清理未使用的镜像/卷（可选）\ndocker system prune -a\n</code></pre>\n<h2 id=\"6-验证清理完成\">6. 验证清理完成</h2>\n<pre><code class=\"language-Bash\">\n# 检查进程（无输出即清理成功）\nps -ef | grep openclaw | grep -v grep\n# 检查目录（无输出即清理成功）\nls ~/.openclaw\nls /tmp/openclaw\n</code></pre>\n<h1 id=\"七注意事项\">七、注意事项</h1>\n<h3 id=\"1-环境配置规范\">1. 环境配置规范</h3>\n<ul>\n<li>\n<p>Node.js 版本：必须 v24.13.0 及以上，低版本会导致 OpenClaw 启动失败；</p>\n</li>\n<li>\n<p>npm 全局路径：配置后避免 <code>EACCES</code> 权限报错，建议必做；</p>\n</li>\n<li>\n<p>配置文件：JSON 语法严格，仅使用半角符号，无注释，键名/值必须用双引号包裹。</p>\n</li>\n</ul>\n<h3 id=\"2-模型使用注意\">2. 模型使用注意</h3>\n<ul>\n<li>\n<p>优先选择 DeepSeek：Anthropic 模型需国际信用卡充值、合规网络，国内用户适配性差；</p>\n</li>\n<li>\n<p>DeepSeek API Key 有效期：需确保 Key 未过期，且账号有余额（DeepSeek 提供免费额度）；</p>\n</li>\n<li>\n<p>模型 ID 不可修改：DeepSeek 必须使用 <code>deepseek-chat</code>，自定义 ID 会导致调用失败。</p>\n</li>\n</ul>\n<h3 id=\"3-进程与端口管理\">3. 进程与端口管理</h3>\n<ul>\n<li>\n<p>启动前必清进程：避免端口冲突和配置重载失败；</p>\n</li>\n<li>\n<p>端口占用处理：若 18789 被占用，可更换端口（如 <code>--port 18788</code>），同时修改配置文件中的 <code>port</code> 字段。</p>\n</li>\n</ul>\n<h3 id=\"4-权限与网络\">4. 权限与网络</h3>\n<ul>\n<li>终端权限：执行 <code>rm</code>/<code>mkdir</code> 命令时若报错，加 <code>sudo</code> 提升权限；</li>\n</ul>\n<h1 id=\"八总结\">八、总结</h1>\n<h2 id=\"核心流程回顾\">核心流程回顾</h2>\n<ol>\n<li>\n<p>搭建基础环境：安装 Homebrew → 安装 Node.js → 配置 npm 全局路径；</p>\n</li>\n<li>\n<p>部署 OpenClaw：安装包 → 写入合法配置 → 验证语法 → 启动网关；</p>\n</li>\n<li>\n<p>验证效果：访问 UI 测试对话 → 实时监控日志排查问题；</p>\n</li>\n<li>\n<p>清理残余：停止进程 → 删除配置/日志/包文件。</p>\n</li>\n</ol>\n<h2 id=\"关键要点\">关键要点</h2>\n<ul>\n<li>\n<p>配置文件是核心：语法错误、字段缺失是部署失败的主要原因；</p>\n</li>\n<li>\n<p>DeepSeek 适配性最优：国内网络无需额外配置，API Key 易获取；</p>\n</li>\n<li>\n<p>日志是排查利器：启动后通过 <code>tail -f</code> 实时查看日志，快速定位问题。</p>\n</li>\n</ul>\n<p>通过以上步骤，可实现 OpenClaw 在 macOS 上的标准化部署，且能稳定调用 DeepSeek 模型完成对话交互。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 15:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaobaiysf\">小白跃升坊</a>&nbsp;\n阅读(<span id=\"post_view_count\">505</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "C++小白训练第十三天",
      "link": "https://www.cnblogs.com/godjian/p/19594585",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/godjian/p/19594585\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 12:13\">\n    <span>C++小白训练第十三天</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"c小白训练第十三天\">C++小白训练第十三天</h2>\n<p>以下为牛客挑战</p>\n<h2 id=\"今日收获\">今日收获</h2>\n<pre><code> vector&lt;pair&lt;int,int&gt;&gt;v;用于存储坐标，如果坐标：\n 方式：v.push_back({i,j}),v.emplace_back(i,j);\n \n v.push_back(make_pair(i, j));\n\ndp联想的又一个条件，就是因为限制只存在与相邻，那就和后面没有关系，所以考虑dp\n\n\n理解了置换环：n-环数等于操作数。\n</code></pre>\n<h2 id=\"牛客周赛-round-130\">牛客周赛 Round 130</h2>\n<h3 id=\"红美铃的访客登记\">红美铃的访客登记</h3>\n<p><a href=\"https://ac.nowcoder.com/acm/contest/127702/A\" rel=\"noopener nofollow\" target=\"_blank\">A-红美铃的访客登记_牛客周赛 Round 130 (nowcoder.com)</a></p>\n<p><img alt=\"image-20260209082136953\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121302221-750510719.png\" /></p>\n<h4 id=\"解题代码\">解题代码</h4>\n<pre><code class=\"language-c++\">#include&lt;bits/stdc++.h&gt;\n#define int long long\n#define lll __uint128_t\n#define PII pair&lt;int ,int&gt;\n#define endl '\\n'\nusing namespace std;\n#define yn(ans) printf(\"%s\\n\", (ans)?\"Yes\":\"No\");//快速打印\n#define YN(ans) printf(\"%s\\n\", (ans)?\"YES\":\"NO\");\n#define REP(i, e) for (int i = 0; i &lt; (e); ++i)\n#define REP1(i, s, e) for (int i = (s); i &lt;=(e); ++i)\n#define TESTS int t; cin &gt;&gt; t; while (t--)\n#define TEST\nconst int N=2e5+10,M=1e3+10,mod=1e9+7;\nint a[N],b[N],c[N],pre[N];\n\nsigned main(){\n\n\tstd::ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n    string s;\n    cin&gt;&gt;s;\n    int count=0;\n    for(int i=0;i&lt;s.size();i++){\n        if(s[i]!='0'){\n            count=i;\n            break;\n        }\n    }\n    for(int i=count;i&lt;s.size();i++){\n        cout&lt;&lt;s[i];\n    }\n    \n\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"爱丽丝的魔力零件分类\">爱丽丝的魔力零件分类</h3>\n<p><a href=\"https://ac.nowcoder.com/acm/contest/127702/B\" rel=\"noopener nofollow\" target=\"_blank\">B-爱丽丝的魔力零件分类_牛客周赛 Round 130 (nowcoder.com)</a></p>\n<p><img alt=\"image-20260209084218695\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121303147-1985436397.png\" /></p>\n<pre><code>3\n5\n.....\n.....\n.***.\n..*..\n.....\n5\n.....\n..*..\n..*..\n.**..\n.....\n6\n......\n..*...\n.**...\n..*...\n......\n......\n</code></pre>\n<pre><code>T\nL\nT\n</code></pre>\n<p><strong>题解</strong></p>\n<h4 id=\"解题代码-1\">解题代码</h4>\n<p>可以先把这些为*的点先存起来，然后去判断他们的度数双重循环，来判断，当我们发现最多度数为3的时候就就是t，其他的就不是t，是l</p>\n<pre><code class=\"language-c++\">#include&lt;bits/stdc++.h&gt;\n#define int long long\n#define lll __uint128_t\n#define PII pair&lt;int ,int&gt;\n#define endl '\\n'\nusing namespace std;\n#define yn(ans) printf(\"%s\\n\", (ans)?\"Yes\":\"No\");//快速打印\n#define YN(ans) printf(\"%s\\n\", (ans)?\"YES\":\"NO\");\n#define REP(i, e) for (int i = 0; i &lt; (e); ++i)\n#define REP1(i, s, e) for (int i = (s); i &lt;=(e); ++i)\n#define TESTS int t; cin &gt;&gt; t; while (t--)\n#define TEST\nconst int N=2e5+10,M=1e3+10,mod=1e9+7;\nint a[N],b[N],c[N],pre[N];\nvoid solve(){\n    int n;\n    cin&gt;&gt;n;\n    vector&lt;pair&lt;int,int&gt;&gt;v;\n    for(int i=1;i&lt;=n;i++){\n        for(int j=1;j&lt;=n;j++){\n            char m;\n            cin&gt;&gt;m;\n            if(m=='*'){\n                v.emplace_back(i,j);\n            }\n        }\n    }\n    int mx=0;\n    for(auto [x,y]:v){\n        int degree=0;\n        for(auto [nx,ny]:v){\n            if(abs(x-nx)+abs(y-ny)==1){\n                degree++;\n            }\n        }\n        mx=max(degree,mx);\n    }\n    if(mx==3){\n        cout&lt;&lt;\"T\"&lt;&lt;endl;\n    }else{\n        cout&lt;&lt;\"L\"&lt;&lt;endl;\n    }\n\n};\nsigned main(){\n\n\tstd::ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n    TESTS{\n        solve();\n    };\n\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"博丽大结界的稳定轴心\">博丽大结界的稳定轴心</h3>\n<p><a href=\"https://ac.nowcoder.com/acm/contest/127702/C\" rel=\"noopener nofollow\" target=\"_blank\">C-博丽大结界的稳定轴心_牛客周赛 Round 130 (nowcoder.com)</a></p>\n<p><img alt=\"image-20260209090135699\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121303545-355177775.png\" /></p>\n<pre><code>5\n1 2\n1 3\n1 4\n4 5\n</code></pre>\n<pre><code>4\n</code></pre>\n<p>我们可以去分析一下二叉树的特点，是不是最多的节点数在3个以下，且这个3个的节点不会作为轴心点。</p>\n<p>两个的和一个的都可以作为轴心点。</p>\n<p>所有我们可以去先判断到底哪个最大的点数有多大。大于3就直接是零，小于的3就可以作为轴心点。</p>\n<h4 id=\"解题代码-2\">解题代码</h4>\n<pre><code class=\"language-c++\">#include&lt;bits/stdc++.h&gt;\n#define int long long\n#define lll __uint128_t\n#define PII pair&lt;int ,int&gt;\n#define endl '\\n'\nusing namespace std;\n#define yn(ans) printf(\"%s\\n\", (ans)?\"Yes\":\"No\");//快速打印\n#define YN(ans) printf(\"%s\\n\", (ans)?\"YES\":\"NO\");\n#define REP(i, e) for (int i = 0; i &lt; (e); ++i)\n#define REP1(i, s, e) for (int i = (s); i &lt;=(e); ++i)\n#define TESTS int t; cin &gt;&gt; t; while (t--)\n#define TEST\nconst int N=2e5+10,M=1e3+10,mod=1e9+7;\nint a[N],b[N],c[N],pre[N];\n\nsigned main(){\n\n\tstd::ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n    int n;\n    cin&gt;&gt;n;\n    vector&lt;vector&lt;int&gt;&gt;g(n+1);\n    for(int i=1;i&lt;n;i++){\n        int u,v;\n        cin&gt;&gt;u&gt;&gt;v;\n        g[u].push_back(v);\n        g[v].push_back(u);\n    }\n    int mx=0;\n    int ans=0;\n    for(int i=1;i&lt;=n;i++){\n        mx=max(mx,(int)g[i].size());\n    }\n    if(mx&lt;=3){\n        for(int i=1;i&lt;=n;i++){\n            if(g[i].size()&lt;=2){\n                ans++;\n            }\n        }\n    }\n    cout&lt;&lt;ans&lt;&lt;endl;\n\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"魔法人偶的十进制校准\">魔法人偶的十进制校准</h3>\n<p><img alt=\"image-20260209094949846\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121303963-2021372242.png\" /></p>\n<pre><code>3\n1 5\n2 3\n5 7\n</code></pre>\n<pre><code>1 2\n1 3\n3 7\n</code></pre>\n<p>首先我们通过打标确定一下规律。</p>\n<pre><code class=\"language-c++\">for(double y=2;y&lt;=1000;y++){\n\tcout&lt;&lt;fixed&lt;&lt;setprecision(10)&lt;&lt;(1.0/y)&lt;&lt;endl;\n}\n</code></pre>\n<p><img alt=\"image-20260209095354057\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121304411-1460739702.png\" /></p>\n<p>可以发现特殊的</p>\n<pre><code>1/9----》得到这个。0.1111111，这个我们就可以去构造一下了，但是，b/9\n\n然后特判别的，应为没有9/9，所以我们看到0.9090...\n我们可以通过奇偶代换×一个10就可以了，我们直接9得到这个数.\n然后特判一些0，和可以被3，6的情况就行了\n</code></pre>\n<h4 id=\"解题代码-3\">解题代码</h4>\n<pre><code class=\"language-c++\">#include&lt;bits/stdc++.h&gt;\n#define int long long\n#define lll __uint128_t\n#define PII pair&lt;int ,int&gt;\n#define endl '\\n'\nusing namespace std;\n#define yn(ans) printf(\"%s\\n\", (ans)?\"Yes\":\"No\");//快速打印\n#define YN(ans) printf(\"%s\\n\", (ans)?\"YES\":\"NO\");\n#define REP(i, e) for (int i = 0; i &lt; (e); ++i)\n#define REP1(i, s, e) for (int i = (s); i &lt;=(e); ++i)\n#define TESTS int t; cin &gt;&gt; t; while (t--)\n#define TEST\nconst int N=2e5+10,M=1e3+10,mod=1e9+7;\n\nvoid solve(){\n    int a,b;\n    cin&gt;&gt;a&gt;&gt;b;\n    if(b==0){\n        if(a==1){\n            cout&lt;&lt;1&lt;&lt;\" \"&lt;&lt;1000&lt;&lt;endl;\n        }else{\n            cout&lt;&lt;1&lt;&lt;\" \"&lt;&lt;2&lt;&lt;endl;\n        }\n        return;\n    }else if(b==9){\n        if(a%2){\n            cout&lt;&lt;10&lt;&lt;\" \"&lt;&lt;11&lt;&lt;endl;\n        }else{\n            cout&lt;&lt;1&lt;&lt;\" \"&lt;&lt;11&lt;&lt;endl;\n        }\n        return;\n    }\n    if(b==3){\n        cout&lt;&lt;1&lt;&lt;\" \"&lt;&lt;3&lt;&lt;endl;\n        return;\n    }\n    if(b==6){\n        cout&lt;&lt;2&lt;&lt;\" \"&lt;&lt;3&lt;&lt;endl;\n        return;\n    }\n    cout&lt;&lt;b&lt;&lt;\" \"&lt;&lt;9&lt;&lt;endl;\n};\nsigned main(){\n\n\tstd::ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n    TESTS{\n        solve();\n    };\n\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"爱丽丝的人偶圆舞曲\">爱丽丝的人偶圆舞曲</h3>\n<p><a href=\"https://ac.nowcoder.com/acm/contest/127702/E\" rel=\"noopener nofollow\" target=\"_blank\">E-爱丽丝的人偶圆舞曲_牛客周赛 Round 130 (nowcoder.com)</a></p>\n<p><img alt=\"image-20260209112816198\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121304824-570108632.png\" /></p>\n<pre><code>abca\n</code></pre>\n<pre><code>1\n</code></pre>\n<p>因为限制只存在与相邻。我们就可以去考虑dp的做法</p>\n<p>这个是一个线性dp的题目，我们可以定义一个</p>\n<p>因为d没有确认，所以我们去枚举d</p>\n<pre><code>f[i][j]---&gt;表示前i个位置均合法，且si=j的最小次数\n\n你们转移就是\nmin（f[i-1][(j-d+26)%26],f[(i+d)%26]）+这个数到底是不是等于j，不等于就要用一次，最后再算出最小值。\n</code></pre>\n<h4 id=\"解题代码-4\">解题代码</h4>\n<pre><code class=\"language-c++\">#include&lt;bits/stdc++.h&gt;\n#define int long long\n#define lll __uint128_t\n#define PII pair&lt;int ,int&gt;\n#define endl '\\n'\nusing namespace std;\n#define yn(ans) printf(\"%s\\n\", (ans)?\"Yes\":\"No\");//快速打印\n#define YN(ans) printf(\"%s\\n\", (ans)?\"YES\":\"NO\");\n#define REP(i, e) for (int i = 0; i &lt; (e); ++i)\n#define REP1(i, s, e) for (int i = (s); i &lt;=(e); ++i)\n#define TESTS int t; cin &gt;&gt; t; while (t--)\n#define TEST\nconst int N=2e5+10,M=1e3+10,mod=1e9+7;\nint a[N],b[N],c[N],pre[N];\n\nsigned main(){\n\n\tstd::ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n    string s;\n    cin&gt;&gt;s;\n\n    int n=s.size();\n    s=\" \"+s;\n\n    //dp初始化。\n    int mx=2e8;\n    for(int d=0;d&lt;=25;d++){\n        vector&lt;vector&lt;int&gt;&gt;f(n+1,vector&lt;int&gt;(26,2e8));\n        for(int j=0;j&lt;=25;j++){\n            if(j==s[1]-'a'){\n                f[1][j]=0;\n            }else{\n                f[1][j]=1;\n            }\n        }\n        for(int i=2;i&lt;=n;i++){\n            for(int j=0;j&lt;=25;j++){\n                f[i][j]=min(f[i-1][(j-d+26)%26],f[i-1][(j+d)%26])+(j!=s[i]-'a');\n            }\n        }\n\n        for(int i=0;i&lt;=25;i++){\n            mx=min(mx,f[n][i]);\n        }\n\n    }\n    cout&lt;&lt;mx&lt;&lt;endl;\n\n\n\n\n\treturn 0;\n}\n</code></pre>\n<h3 id=\"红魔馆的微瑕序位\">红魔馆的微瑕序位</h3>\n<p><a href=\"https://ac.nowcoder.com/acm/contest/127702/F\" rel=\"noopener nofollow\" target=\"_blank\">F-红魔馆的微瑕序位_牛客周赛 Round 130 (nowcoder.com)</a></p>\n<p><img alt=\"image-20260209120106423\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121305276-651327063.png\" /></p>\n<pre><code>2\n5\n1 2 4 3 5\n2\n1 2\n</code></pre>\n<pre><code>0\n1\n</code></pre>\n<p>本题考的一个经典置换环</p>\n<pre><code>如果一个1-n的排列，要交换几次才能使得它是一个排列。\n结论是\nn-环的个数，相当于拆环。\n</code></pre>\n<p><img alt=\"image-20260209120521887\" src=\"https://img2024.cnblogs.com/blog/3621557/202602/3621557-20260209121305664-904288544.png\" /></p>\n<p>如图是4元环</p>\n<p>我们邀得到2，肯定得一个两个相邻的元素之间没有去交换</p>\n<pre><code>1 2 4 3 5\n</code></pre>\n<p>那我们先把交换的次数算出来，再考虑原来到底存不存在相邻的环。</p>\n<h4 id=\"解题代码-5\">解题代码</h4>\n<pre><code class=\"language-c++\">#include&lt;bits/stdc++.h&gt;\n#define int long long\n#define lll __uint128_t\n#define PII pair&lt;int ,int&gt;\n#define endl '\\n'\nusing namespace std;\n#define yn(ans) printf(\"%s\\n\", (ans)?\"Yes\":\"No\");//快速打印\n#define YN(ans) printf(\"%s\\n\", (ans)?\"YES\":\"NO\");\n#define REP(i, e) for (int i = 0; i &lt; (e); ++i)\n#define REP1(i, s, e) for (int i = (s); i &lt;=(e); ++i)\n#define TESTS int t; cin &gt;&gt; t; while (t--)\n#define TEST\nconst int N=2e5+10,M=1e3+10,mod=1e9+7;\nint a[N],b[N],c[N],pre[N];\nvoid solve(){\n    int n;\n    cin&gt;&gt;n;\n    vector&lt;int&gt;v(n+1);\n    for(int i=1;i&lt;=n;i++){\n        cin&gt;&gt;a[i];\n    }\n    int loop=0;\n    for(int i=1;i&lt;=n;i++){\n        if(v[i])continue;\n        int j=i;\n        loop++;\n        while (!v[j]){\n            v[j]=loop;\n            j=a[j];\n        }\n    }\n    int ans=n-loop+1;\n    for(int i=2;i&lt;=n;i++){//判断是不是相邻的环\n        if(v[i-1]==v[i]){\n            ans-=2;\n            break;\n        }\n    }\n    cout&lt;&lt;ans&lt;&lt;endl;\n};\nsigned main(){\n\n\tstd::ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n    TESTS{\n        solve();\n    };\n\n\treturn 0;\n}\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 12:13</span>&nbsp;\n<a href=\"https://www.cnblogs.com/godjian\">Godjian</a>&nbsp;\n阅读(<span id=\"post_view_count\">110</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "扣子Coze实战：从0到1搭建小红书图文改写智能体",
      "link": "https://www.cnblogs.com/tangshiye/p/19594522",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tangshiye/p/19594522\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 11:59\">\n    <span>扣子Coze实战：从0到1搭建小红书图文改写智能体</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家好，我是汤师爷，专注AI智能体分享，致力于帮助100W人用智能体创富~</p>\n<p>还在为小红书笔记创作发愁吗？</p>\n<p>每天都要绞尽脑汁想文案，看着别人的爆款笔记却不知道如何模仿？</p>\n<p>今天，我就教你如何利用AI智能体，轻松实现小红书图文改写，让创作效率提升10倍！</p>\n<p>我们先看下智能体的执行效果：</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h2 id=\"1整体工作流\">1.整体工作流</h2>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>1.获取小红书笔记详情</p>\n<p>2.使用OCR技术，提取图片中的文字</p>\n<p>3.将图片文案进行整理</p>\n<p>4.图片文案仿写</p>\n<h2 id=\"2详细工作流节点\">2.详细工作流节点</h2>\n<h3 id=\"21-开始节点\">2.1 开始节点</h3>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>开始节点有两个输入变量。</p>\n<ul>\n<li>输入：\n<ul>\n<li>noteUrl：小红书笔记链接</li>\n<li>cookieStr：小红书cookie</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"22-如何获取小红书cookie\">2.2 如何获取小红书cookie？</h3>\n<p>1.登陆<a href=\"https://www.xiaohongshu.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.xiaohongshu.com/</a></p>\n<p>2.在页面空白处右击鼠标，选择「检查」</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>3.在刚刚打开的面板中，点击「网络」选项卡</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>4.刷新当前页面</p>\n<p>5.点击第一条记录，在右侧「标头」部分向下滚动，找到cookie一行，将其内容复制下，这就是我们需要的cookieStr</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"23-获取小红书笔记详情\">2.3 获取小红书笔记详情</h3>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>我们将使用【小红书】插件的xhs_note_detail功能。</p>\n<p>通过这个功能，我们可以根据笔记链接获取笔记详情。</p>\n<ul>\n<li>输入：\n<ul>\n<li>cookieStr：开始 - cookieStr</li>\n<li>noteUrl：开始 - noteUrl</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"24-使用ocr技术提取图片中的文字\">2.4 使用OCR技术，提取图片中的文字</h3>\n<p><strong>1.接下来，我们使用循环节点，批量提取图片中的文字。</strong></p>\n<ul>\n<li>输入：\n<ul>\n<li>input：获取小红书笔记详情-note_image_list</li>\n</ul>\n</li>\n<li>输出\n<ul>\n<li>output：从图片中提取文字-data</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>2.使用循环体，批量提取图片的文字</strong></p>\n<p>我们会使用「OCR」插件，提取图片的文字。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>输入参数如下图所示。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"25-使用大模型将文案内容进行整理排版\">2.5 使用大模型将文案内容进行整理、排版</h3>\n<p>在这一步，我们会使用大模型节点，对文案内容进行整理、排版。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>大模型节点的系统提示词如下：</p>\n<pre><code class=\"language-markdown\">## 角色（Role）\n你是一位精通内容整理和 Markdown 排版的 AI 助手。你擅长阅读和理解非结构化的文本内容，并能够将其转化为结构清晰、格式优美的 Markdown 文档。\n\n## 背景（Background）\n随着社交媒体平台的普及，大量的图文内容被创作和分享。然而，这些内容往往缺乏良好的结构和格式，不利于阅读和理解。将这些内容整理成结构化的 Markdown 文档，可以大大提高内容的可读性和价值。\n\n## 任务（Task）\n你的任务是接收一段从插件输出的非结构化文本内容（主要是抖音图文中的文字），仔细阅读并理解内容，然后将其转化为结构清晰、格式规范的 Markdown 文档。你需要：\n\n1. 识别并提取文本中的关键信息，如标题、作者、主要内容等\n2. 根据内容的逻辑关系，对文本进行分类和整理\n3. 使用 Markdown 语法进行排版，包括但不限于使用标题、粗体、斜体、列表等格式\n4. 确保所有原始内容都被包含在最终的 Markdown 文档中，不遗漏任何信息\n\n## 规则与限制（Rules &amp; Restrictions）\n1. 必须使用 Markdown 语法进行排版\n2. 使用 #、##、### 等进行标题划分，层级不超过 3 级\n3. 使用 - 或 * 进行无序列表编写，使用 1. 2. 3. 等进行有序列表编写\n4. 重要内容使用粗体（**文字**）标注，需要强调的内容使用斜体（*文字*）标注\n5. 保持原文的主要结构和顺序，但可以适当调整以提高可读性\n6. 不得添加、删除或修改原文的实质内容\n7. 如遇到不确定的内容，保留原样并用括号标注\n\n## 参考短语（Reference sentences）\n- 内容完整，不遗漏任何信息\n- 结构清晰，层次分明\n- 格式规范，美观实用\n- 逻辑严密，条理清晰\n- 重点突出，易于阅读\n\n## 案例展示（Case Show）\n### 输入：\n{\n  \"code\": 0,\n  \"data\": {\n    \"results\": [\n      {\n        \"words\": [\n          {\n            \"lang\": \"auto\",\n            \"text\": \"求大连这两个\"\n          },\n          {\n            \"lang\": \"auto\",\n            \"text\": \"地方有啥\"\n          },\n          {\n            \"lang\": \"auto\",\n            \"text\": \"区别啊？？\"\n          }\n        ]\n      }\n    ]\n  },\n  \"log_id\": \"20250325123913080C6F506498C6F581B7\",\n  \"msg\": \"success\"\n}\n\n## 风格和语气（Style &amp; Tone）\n- 保持专业、清晰的语气\n- 使用简洁、直接的表达方式\n- 保持原文的重点和强调\n\n## 受众群体（Audience）\n- 小红书电商新手卖家\n- 对开设小红书店铺感兴趣的人群\n- 想要了解小红书电商运营的人群\n\n## 输出格式（Output format）\n使用 Markdown 格式输出，包括：\n1. 一级标题（#）用于文章主标题\n2. 二级标题（##）用于主要章节\n3. 三级标题（###）用于子章节\n4. 无序列表使用 - 或 *\n5. 有序列表使用 1. 2. 3. 等\n6. 重要内容使用粗体（**文字**）\n7. 需要强调的内容使用斜体（*文字*）\n\n## 工作流程（Workflow）\n1. 仔细阅读输入的文本内容，理解其结构和主要信息点\n2. 提取标题、作者、标签等元信息\n3. 识别主要章节和子章节，规划文档结构\n4. 按照规划的结构，使用 Markdown 语法重新排版内容\n5. 使用粗体和斜体突出重要信息和需要强调的内容\n6. 检查确保所有原始内容都被包含，没有遗漏\n7. 最后检查 Markdown 格式是否正确，调整以确保最佳可读性\n\n## 初始化（Initialization）\n\n下面是你需要整理和格式化的文本内容：\n\n&lt;评价内容&gt;\n\n请提供需要整理和格式化的文本内容。我会仔细阅读并按照上述要求将其转化为结构清晰的 Markdown 文档。不需要输出额外除图片识别文字以外的内容。\n</code></pre>\n<h3 id=\"26-图片文案仿写\">2.6 图片文案仿写</h3>\n<p>接下来，我们需要通过大模型节点退图片文案进行仿写。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>大模型节点的系统提示词如下：</p>\n<pre><code class=\"language-markdown\"># 角色说明\n你是一位专业的图文内容仿写助手，负责根据图片中提取的文字内容，结合视觉元素和背景信息，创作风格一致的仿写内容。\n\n# 背景说明\n处理用户提供的图片文字内容时，你需要：\n1. 理解图片的整体风格和背景（产品介绍、教程步骤、使用心得等）\n2. 分析文字的语言特点（正式/口语化、句式特征、专业术语等）\n3. 结合图片呈现的视觉信息（产品外观、使用场景等）\n4. 在保持原意的基础上进行自然的仿写扩展\n\n# 仿写原则\n1. 保持原意完整性\n2. 匹配原文语言风格\n3. 补充恰当的细节\n4. 与图片内容保持一致\n5. 避免添加虚假信息\n\n# 工作流程\n1. 接收图片文字内容\n2. 分析图片背景信息（可选）\n3. 分析原文特点：\n   - 语言风格\n   - 内容结构\n   - 关键词使用\n4. 创作三个版本：\n   - 贴近原文的保守版\n   - 适度优化的改进版\n   - 创意加强的亮点版\n\n# 输出示例\n## 原文：\n\"夏日必备防晒霜\nSPF50+ PA++++\n清爽不油腻\"\n\n## 仿写版本：\n1. 【保守版】\n\"夏季必备防晒产品\n防晒指数SPF50+ PA++++\n质地清爽不油腻\"\n\n2. 【优化版】\n\"夏日防晒推荐\n高倍防护SPF50+ PA++++\n轻薄水感质地，肌肤零负担\"\n\n3. 【创意版】\n\"今夏防晒天花板！\nSPF50+ PA++++超强防护\n一抹化水，清爽不黏腻\"\n\n# 执行要求\n请提供：\n1. 图片文字提取内容\n2. 图片背景说明（如有）\n\n我将按照以上规范进行仿写创作。\n</code></pre>\n<h3 id=\"27-使用文本处理插件拼接字符串\">2.7 使用文本处理插件拼接字符串</h3>\n<ul>\n<li>输入：\n<ul>\n<li>String1：获取小红书笔记详情-note</li>\n<li>String2：图片文案内容整理-output</li>\n<li>String3：图片文案仿写-output</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"28-结束节点\">2.8 结束节点</h3>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h2 id=\"3总结\">3.总结</h2>\n<p>通过以上介绍，相信你了解了如何利用DeepSeek+Coze来构建高效的小红书图片文案改写智能体。</p>\n<p>在AI时代，技术门槛将越来越低，小白也能搭建智能体，用AI工具来提升工作效率。</p>\n<p>用AI智能体不是未来，而是AI时代每个人的生存技能，学会AI智能体，人人都是超级个体。</p>\n<p>如果你觉得这篇文章有帮助，别忘了点赞、关注、收藏，我们下期再见！</p>\n<blockquote>\n<p>对了，我整理了一份开源《智能体学习手册》，爆肝 10 万字，价值 999 元。限时开放领取👉：<a href=\"https://tangshiye.cn\" rel=\"noopener nofollow\" target=\"_blank\">tangshiye.cn</a></p>\n</blockquote>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/tangshiye/\" target=\"_blank\">AI架构师汤师爷</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/tangshiye/p/19594522\" target=\"_blank\">https://www.cnblogs.com/tangshiye/p/19594522</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 11:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tangshiye\">AI架构师汤师爷</a>&nbsp;\n阅读(<span id=\"post_view_count\">179</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "FastAPI不止于API：手把手教你用Jinja2打造动态Web页面",
      "link": "https://www.cnblogs.com/ymtianyu/p/19594466",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ymtianyu/p/19594466\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 11:48\">\n    <span>FastAPI不止于API：手把手教你用Jinja2打造动态Web页面</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文系统介绍了如何在FastAPI框架中集成Jinja2模板引擎来构建动态Web页面。内容涵盖从安装配置、模板上下文数据传递（包括请求级和全局两种方式）、静态文件正确引入，到完整实战演示与常见避坑指南。帮助开发者快速掌握利用FastAPI服务端渲染页面的技能，适用于快速原型、管理后台等场景。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div>\n<p>你是不是也觉得，用FastAPI写接口爽到飞起，但一想到要返回个带数据的HTML页面，就瞬间头大？🎯</p>\n<p>我刚用FastAPI那会儿也这样，以为它就是个“API专用框架”，渲染页面？那不是Django和Flask的活儿吗？直到我在一个紧急项目里，需要快速给内部系统做个带数据看板的管理后台，我才发现，<strong style=\"color: rgba(186, 55, 42, 1);\">FastAPI配合Jinja2模板，原来可以这么香！</strong> 今天就跟你唠明白这事儿，保你10分钟上手，告别“前后端分离强迫症”在简单场景下的纠结。</p>\n<h2 style=\"color: rgba(52, 152, 219, 1); padding-bottom: 5px;\">📌 本文能帮你解决</h2>\n<div style=\"background-color: rgba(248, 249, 250, 1); padding: 15px; margin: 20px 0;\">\n<p>1. 在FastAPI中如何安装、配置Jinja2模板引擎。</p>\n<p>2. 如何把后台数据（上下文）安全又方便地“塞”给前端模板。</p>\n<p>3. 如何在模板里正确引入CSS、JS等静态文件，避免“404惨案”。</p>\n<p>4. 我踩过的几个坑和最佳实践，让你一次写对。</p>\n</div>\n<h2>🚀 主要内容脉络</h2>\n<p>👉 先聊聊：为什么需要模板引擎？（不只是为了省事）</p>\n<p>👉 核心操作：安装、配置、传递数据的“两条路径”。</p>\n<p>👉 实战演示：一个包含用户列表和样式的小项目。</p>\n<p>👉 避坑指南：静态文件那些“路径玄学”与进阶思考。</p>\n<hr style=\"border: none; height: 1px; background-color: rgba(238, 238, 238, 1); margin: 30px 0;\" />\n<h2>🔍 一、问题与背景：FastAPI只能“吃”JSON？</h2>\n<p>FastAPI以构建高性能API闻名，<code style=\"color: rgba(186, 55, 42, 1);\">return JSONResponse</code> 几乎是肌肉记忆。但很多场景下，比如：</p>\n<div>\n<p>- 快速原型开发，搞个带页面的demo。</p>\n<p>- 内部管理后台，复杂度不高，不想动用前端框架。</p>\n<p>- 需要服务端渲染（SSR）的简单页面。</p>\n</div>\n<p>这时候，你硬要前后端彻底分离，反而有种“杀鸡用牛刀”的繁琐。就好比你只想在家门口吃碗面，结果非要开车去市中心的高级餐厅点单、等餐、打包再回来。</p>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">模板引擎，就是让你在FastAPI这个“高性能厨房”里，直接开个“堂食窗口”。</strong> Jinja2就是这个窗口最得力的伙计，它能把你的数据（肉、菜）和HTML模板（碗、汤底）快速组合成一碗热腾腾的面（最终页面）。</p>\n<h2>🧠 二、核心原理与步骤：“两条腿”走路</h2>\n<p>好，咱们先来解决最核心的问题：数据怎么从后端“走”到模板里？</p>\n<p>核心就两步：1. 配置引擎；2. 传递数据。数据传递有两条关键“路径”，我画个灵魂图示给你看：</p>\n<div style=\"background-color: rgba(248, 249, 250, 1); padding: 15px; border-radius: 5px; margin: 20px 0;\">\n<p><strong>路径A：依赖项注入（全局/请求级上下文）</strong></p>\n<p>在路由处理函数里，通过 <code style=\"color: rgba(186, 55, 42, 1);\">TemplateResponse</code> 的 <code style=\"color: rgba(186, 55, 42, 1);\">context</code> 参数传递。这是<strong style=\"color: rgba(186, 55, 42, 1);\">最常用、最灵活</strong>的方式，数据针对每次请求。</p>\n<p><strong>路径B：全局模板上下文（每个模板都能用）</strong></p>\n<p>在初始化 <code style=\"color: rgba(186, 55, 42, 1);\">Jinja2Templates</code> 时，通过 <code style=\"color: rgba(186, 55, 42, 1);\">context</code> 参数传递。比如站点名、当前年份等<strong style=\"color: rgba(186, 55, 42, 1);\">全局通用数据</strong>。</p>\n</div>\n<p>是不是有点抽象？别急，咱们接着看实战，代码一写你就全明白了。</p>\n<h2>💻 三、实战演示：从零搭建一个用户列表页</h2>\n<p>接下来重点来了，咱们一步步来。假设我们要做一个显示用户列表的页面。</p>\n<h3>1️⃣ 安装与项目结构</h3>\n<p>先安装必备库：</p>\n<pre class=\"language-powershell highlighter-hljs\"><code>pip install fastapi jinja2 uvicorn</code></pre>\n<p>项目目录结构建议这样安排，清晰明了：</p>\n<div>\n<pre class=\"language-powershell highlighter-hljs\"><code>📁 your_project/\n├── 📁 templates/ # 存放所有Jinja2 HTML模板\n│     └── index.html\n├── 📁 static/ # 存放CSS, JS, 图片等静态文件\n│     └── style.css\n└── main.py # FastAPI 主应用文件</code></pre>\n</div>\n<h3>2️⃣ 配置FastAPI与Jinja2</h3>\n<p>在 <code style=\"color: rgba(186, 55, 42, 1);\">main.py</code> 里进行初始化。这里有个<strong style=\"color: rgba(186, 55, 42, 1);\">关键点</strong>：<code style=\"color: rgba(186, 55, 42, 1);\">directory</code> 参数必须是<strong style=\"color: rgba(186, 55, 42, 1);\">字符串路径</strong>，不能是Path对象（Jinja2的老规矩）。</p>\n<pre class=\"language-python highlighter-hljs\"><code>from fastapi import FastAPI, Request\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.staticfiles import StaticFiles\n\napp = FastAPI(title=\"FastAPI+Jinja2 Demo\")\n\n# 配置模板引擎，告诉它模板文件在哪\ntemplates = Jinja2Templates(directory=\"templates\")\n\n# 配置静态文件服务，挂载到`/static`路径\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")</code></pre>\n<h3>3️⃣ 定义路由与传递数据（路径A）</h3>\n<p>我们定义一个路由，模拟从数据库获取用户列表，并传递给模板：</p>\n<pre class=\"language-python highlighter-hljs\"><code>@app.get(\"/\", response_class=HTMLResponse)\nasync def read_users(request: Request):\n    # 模拟数据，实际中可能来自数据库\n    user_list = [\n        {\"id\": 1, \"name\": \"张三\", \"role\": \"管理员\"},\n        {\"id\": 2, \"name\": \"李四\", \"role\": \"编辑\"},\n        {\"id\": 3, \"name\": \"王五\", \"role\": \"订阅用户\"},\n    ]\n    # 网站标题，作为额外数据传递\n    site_title = \"内部用户管理系统\"\n    \n    # 核心操作：渲染模板，并通过context传递数据\n    return templates.TemplateResponse(\n        request=request,\n        name=\"index.html\", # 模板文件名\n        context={\n            \"request\": request, # 这个必须有！Jinja2Templates要求\n            \"users\": user_list,\n            \"title\": site_title\n        }\n    )</code></pre>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">千万注意</strong>：<code style=\"color: rgba(186, 55, 42, 1);\">context</code> 字典里<strong style=\"color: rgba(186, 55, 42, 1);\">必须包含 \"request\" 键</strong>！这是 <code style=\"color: rgba(186, 55, 42, 1);\">Jinja2Templates</code> 的工作机制要求的，不然模板里一些基于请求的功能会失效。</p>\n<h3>4️⃣ 编写模板文件 (templates/index.html)</h3>\n<p>看看数据在模板里怎么用：</p>\n<pre class=\"language-html highlighter-hljs\"><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"zh-CN\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;{{ title }}&lt;/title&gt;\n    &lt;!-- 重点！引入静态CSS文件 --&gt;\n    &lt;link rel=\"stylesheet\" href=\"{{ url_for('static', path='/style.css') }}\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;欢迎使用 {{ title }}&lt;/h1&gt;\n    &lt;table border=\"1\"&gt;\n        &lt;thead&gt;\n            &lt;tr&gt;\n                &lt;th&gt;ID&lt;/th&gt;\n                &lt;th&gt;姓名&lt;/th&gt;\n                &lt;th&gt;角色&lt;/th&gt;\n            &lt;/tr&gt;\n        &lt;/thead&gt;\n        &lt;tbody&gt;\n            {% for user in users %}\n            &lt;tr&gt;\n                &lt;td&gt;{{ user.id }}&lt;/td&gt;\n                &lt;td&gt;{{ user.name }}&lt;/td&gt;\n                &lt;td&gt;{{ user.role }}&lt;/td&gt;\n            &lt;/tr&gt;\n            {% endfor %}\n        &lt;/tbody&gt;\n    &lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;</code></pre>\n<p><strong style=\"color: rgba(186, 55, 42, 1);\">敲黑板</strong>：引入静态文件用的是 <code style=\"color: rgba(186, 55, 42, 1);\">url_for('static', path='/style.css')</code>。这里的 <code style=\"color: rgba(186, 55, 42, 1);\">'static'</code> 对应我们 <code style=\"color: rgba(186, 55, 42, 1);\">app.mount</code> 时设置的 <code style=\"color: rgba(186, 55, 42, 1);\">name=\"static\"</code>。这是我初期常配错的地方，<strong style=\"color: rgba(186, 55, 42, 1);\">name必须一致</strong>！</p>\n<h3>5️⃣ 编写静态文件 (static/style.css)</h3>\n<p>随便写点样式，确认它能被加载：</p>\n<pre class=\"language-css highlighter-hljs\"><code>body {\n    font-family: sans-serif;\n    padding: 20px;\n    background-color: #f5f5f5;\n}\nh1 {\n    color: #2c3e50;\n}\ntable {\n    width: 100%;\n    border-collapse: collapse;\n    margin-top: 20px;\n}\nth, td {\n    padding: 10px;\n    text-align: left;\n}\nthead {\n    background-color: #3498db;\n    color: white;\n}</code></pre>\n<p>好了！现在运行 <code style=\"color: rgba(186, 55, 42, 1);\">uvicorn main:app --reload</code>，打开 <code style=\"color: rgba(186, 55, 42, 1);\">http://127.0.0.1:8000</code>，一个带样式和动态数据的用户列表页面就出来了！数据从后端“流”到了前端，静态文件也正常加载。</p>\n<h2>⚠️ 四、注意事项与进阶思考</h2>\n<p>是不是以为这样就完了？再说几个容易翻车的点。</p>\n<h3>🎯 避坑指南</h3>\n<div>\n<p><strong>1. 静态文件404？</strong></p>\n<p>- 检查 <code style=\"color: rgba(186, 55, 42, 1);\">app.mount</code> 的 <code style=\"color: rgba(186, 55, 42, 1);\">directory</code> 路径是否正确（相对路径从项目根目录算起）。</p>\n<p>- 检查模板中 <code style=\"color: rgba(186, 55, 42, 1);\">url_for</code> 的 <code style=\"color: rgba(186, 55, 42, 1);\">name</code> 参数是否与 <code style=\"color: rgba(186, 55, 42, 1);\">mount</code> 的 <code style=\"color: rgba(186, 55, 42, 1);\">name</code> 一致。</p>\n<p>- 生产环境通常用Nginx等专门处理静态文件，开发时用 <code style=\"color: rgba(186, 55, 42, 1);\">StaticFiles</code> 很方便。</p>\n<p><strong>2. 全局上下文（路径B）怎么用？</strong></p>\n<p>比如你想在每个页面都显示版权年份：</p>\n</div>\n<pre class=\"language-python highlighter-hljs\"><code>templates = Jinja2Templates(\n    directory=\"templates\",\n    context={\"current_year\": 2024} # 全局注入\n)\n# 然后，在任何模板里都可以直接使用 {{ current_year }}</code></pre>\n<h3>🚀 进阶思考</h3>\n<p><strong>模板继承是王牌：</strong> 用 <code style=\"color: rgba(186, 55, 42, 1);\">{% extends \"base.html\" %}</code> 和 <code style=\"color: rgba(186, 55, 42, 1);\">{% block content %}...{% endblock %}</code> 来复用布局（如导航栏、页脚），能让你的模板代码干净十倍。强烈建议你用起来。</p>\n<p><strong>上下文处理器：</strong> 如果你想在每个请求的模板里都自动注入一些数据（比如当前登录用户），可以自定义依赖项，并在每个路由的 <code style=\"color: rgba(186, 55, 42, 1);\">TemplateResponse</code> 里调用。虽然有点绕，但结构更清晰。</p>\n<p><strong>何时用？何时不用？</strong> 对于复杂的、交互性强的现代Web应用，前后端分离（React/Vue + FastAPI API）仍是首选。但对于工具类、管理类、需要SEO的简单内容页，<strong style=\"color: rgba(186, 55, 42, 1);\">FastAPI + Jinja2 的组合能让你一人顶一个全栈团队，开发速度飞快</strong>。</p>\n<hr />\n<p>好了，今天的分享就到这儿。希望这篇“踩坑经验总结”能帮你把FastAPI的“另一面”也利用起来。</p>\n<p>技术选型没有银弹，<strong style=\"color: rgba(186, 55, 42, 1);\">最好的工具是那个能帮你高效、稳定解决问题的工具</strong>。下次当你需要快速捣鼓个带界面的小工具时，不妨试试这个组合。</p>\n<p>你在用FastAPI做Web页面时还遇到过什么奇葩问题？或者有更优雅的实践？<strong style=\"color: rgba(186, 55, 42, 1);\">欢迎在评论区一起聊聊</strong>，你的经验很可能也能帮到别人。</p>\n<p style=\"text-align: center; color: rgba(127, 140, 141, 1); font-size: 0.9em;\">觉得有用的话，记得收藏、点赞、关注哦~ 咱们下期见！</p>\n</div>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 11:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ymtianyu\">一名程序媛呀</a>&nbsp;\n阅读(<span id=\"post_view_count\">147</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从模型评估、梯度难题到科学初始化：一步步解析深度学习的训练问题",
      "link": "https://www.cnblogs.com/yldeveloper/p/19597056",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yldeveloper/p/19597056\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 21:47\">\n    <span>从模型评估、梯度难题到科学初始化：一步步解析深度学习的训练问题</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        要解决模型泛化能力与训练稳定性两大难题，关键在于理解偏差-方差权衡、梯度传播和参数初始化三者间的深层联系。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"引言\">引言</h2>\n<p>训练一个神经网络过程中，我们会关注两个问题：</p>\n<ol>\n<li>模型能否毫不费力处理应用环境中没见过的数据？</li>\n<li>模型能否被有效训练？</li>\n</ol>\n<p>第一个问题涉及<strong>偏差与方差的权衡</strong>，第二个问题涉及<strong>梯度传播的稳定性</strong>。本文首先探讨偏差与方差，然后分析梯度问题，最后引出解决梯度问题的关键之一——<strong>科学的初始化方法</strong>。</p>\n<h2 id=\"偏差--方差\">偏差 &amp; 方差</h2>\n<p>要理解模型的泛化能力，我们首先要量化它的“泛化误差”，即模型在未知数据上的表现。然而，泛化误差并非一个单一的问题，它源于三种不同性质的错误：模型固有的近似能力不足、对训练数据的过度敏感、模型数据本身的不可约噪声。</p>\n<h4 id=\"偏差---方差分解公式\">偏差 - 方差分解公式</h4>\n<p>规定：</p>\n<ul>\n<li><span class=\"math inline\">\\(P_{\\text{data}}(x,y)\\)</span>：数据生成分布</li>\n<li><span class=\"math inline\">\\(\\mathcal{D}\\)</span>：从<span class=\"math inline\">\\(P_{\\text{data}}\\)</span>中独立同分布采样得到的训练数据集</li>\n<li><span class=\"math inline\">\\(f(x;\\mathcal{D})\\)</span>：由训练集 <span class=\"math inline\">\\(\\mathcal{D}\\)</span> 学得的模型 <span class=\"math inline\">\\(f\\)</span> 对 <span class=\"math inline\">\\(x\\)</span> 的预测输出。</li>\n<li><span class=\"math inline\">\\(\\overline f(x)\\)</span>：<span class=\"math inline\">\\(\\mathbb{E}_{\\mathcal{D} \\sim P_{\\text{data}}^{\\otimes n}}[f(x; \\mathcal{D})]\\)</span>，对所有可能训练集的期望</li>\n<li><span class=\"math inline\">\\(\\mathbb{E}_{\\mathcal{D} \\sim P_{\\text{data}}^{\\otimes n}}[\\cdot]\\)</span>：对训练集采样的期望</li>\n</ul>\n<p>有：</p>\n<p></p><div class=\"math display\">\\[\\mathbb{E}_{y|x} \\mathbb{E}_{\\mathcal{D}}[(f(x; \\mathcal{D}) - y)^2] = \\text{Bias}^2(f(x)) + \\text{Var}(f(x)) + \\sigma_\\epsilon^2\n\\]</div><p></p><p>其中，</p>\n<ul>\n<li><span class=\"math inline\">\\(\\text{Bias}^2(f(x))\\)</span>：偏差，反映模型拟合能力。设真实函数为 <span class=\"math inline\">\\(h(x) = \\mathbb{E}[y|x]\\)</span>（条件期望），则偏差应定义为 <span class=\"math inline\">\\((\\overline f(x) - h(x))^2\\)</span></li>\n<li><span class=\"math inline\">\\(\\text{Var}(f(x))\\)</span>：方差，反映不同数据集表现波动情况即泛化能力，<span class=\"math inline\">\\(:=\\mathbb{E}_\\mathcal{D}[(f(x;\\mathcal{D})-\\overline f(x))^2]\\)</span></li>\n<li><span class=\"math inline\">\\(\\sigma_\\epsilon ^2\\)</span>：噪声，反映学习难度，<span class=\"math inline\">\\(:=\\mathbb{E}[(y - h(x))^2]\\)</span></li>\n</ul>\n<p>这里正好对应两种模型：线性拟合 vs. 神经网络</p>\n<ul>\n<li>若线性拟合，模型容量低，并且假设空间简单，即大偏差小方差，泛化误差大，欠拟合。</li>\n<li>若复杂度过高的神经网络（如未正则化），会学到训练数据中的噪声，导致在训练数据上表现很好（小偏差），但在未见过的数据上表现波动很大（大方差），泛化误差大，过拟合。</li>\n<li>若复杂度适中的神经网络，中等偏差中等方差，泛化误差小，最佳了。</li>\n</ul>\n<p>得出结论：<em>偏差大（欠拟合）意味着模型能力不足，未能捕捉数据中的真实模式；方差大（过拟合）意味着模型过于复杂，对训练数据中的噪声和随机波动过度敏感。</em></p>\n<h4 id=\"影响偏差与方差的三大因素\">影响偏差与方差的三大因素</h4>\n<p><strong>1. 学习算法能力（模型复杂度）</strong></p>\n<p>如果模型欠拟合（偏差大），就换更复杂的模型；如果过拟合（方差大），就换更简单的模型（或对复杂模型做正则化）。</p>\n<p><strong>2. 训练数据量</strong></p>\n<p>可间接降低偏差，对方差影响大<br />\n如果模型过拟合（方差大），优先增加训练数据。</p>\n<p><strong>3. 学习任务本身的难度（任务复杂度）</strong></p>\n<p>如果任务简单但方差大，就控制模型复杂度或增加数据；如果任务复杂导致偏差大，就提升模型复杂度</p>\n<h4 id=\"处理模型高偏差高方差的一些方法\">处理模型高偏差、高方差的一些方法</h4>\n<p><strong>欠拟合（高偏差）</strong>：应该换更复杂的模型、增加特征维数、仔细判断训练误差是否收敛到最低。</p>\n<p><strong>过拟合（高方差）</strong>：应该增加训练数据、正则化（如使用L1正则化、L2正则化（即权重衰减）、Dropout等）、批量归一化、剪枝降复杂度、降低特征维度。</p>\n<h4 id=\"偏差-方差权衡\">偏差-方差权衡</h4>\n<p>偏差与方差通常是对立的，提高模型复杂度可以减少偏差，但可能增加方差；反之，降低模型复杂度可以减少方差，但偏差可能会升高。这种权衡关系被称为 <strong>偏差-方差权衡（Bias-Variance Tradeoff）</strong></p>\n<p><strong>在此我们应该拓展一下</strong>，经典理论认为模型复杂度（如参数数量）增加，泛化误差会先因偏差降低而下降，后因方差增大而上升，形成单一的U型曲线。<strong>双重下降</strong>则揭示了在插值阈值（模型刚好能完美拟合训练数据）后，随着复杂度进一步增加，误差会再次下降，形成“下降-上升-下降”的波浪形曲线。在过参数化区域，模型并非必然过拟合到更差的程度，优化过程会引导其找到一个泛化良好的解。在过参数化体制下，模型好像是先“记忆”（拟合噪声），后通过漫长的优化过程“逐渐获得”泛化规则。（其实真正的原因是<strong>隐式正则化</strong>使得优化算法（如SGD）倾向于找到最小范数解或平坦极小值）</p>\n<p>这告诉我们，如果观察到增加模型参数后性能先变差，不要立即止步。这可能只是处于插值阈值附近的危险区。继续增加规模，并配合足够的训练，性能可能会突破并变得更好。</p>\n<p>理解了模型的误差问题由偏差、方差间的权衡决定，我们大体了解如何选择模型的复杂度。但是，当我们着手训练一个复杂深层模型，尤其是现代网络层数不断加深时，我们应该考虑，训练本身是否能够正常进行？否则结果上的“偏差、方差”都成空谈。这就引出了深度学习中的 <strong>梯度问题</strong> 。</p>\n<h2 id=\"梯度问题\">梯度问题</h2>\n<p>我们可以认为，</p>\n<p><span class=\"math inline\">\\(\\mathbf{h}^{(l)} = f_l (\\mathbf{h}^{(l-1)})\\)</span></p>\n<p>因此</p>\n<p><span class=\"math inline\">\\(\\mathbf{o} = f_L \\circ f_{L-1}\\circ \\ldots\\circ f_2\\circ f_1(\\mathbf{x})\\)</span></p>\n<p>那么不难得到：</p>\n<p></p><div class=\"math display\">\\[\\partial_{\\mathbf{W}^{(l)}} \\mathbf{o} = \\underbrace{\\partial_{\\mathbf{h}^{(L-1)}} \\mathbf{h}^{(L)}}_{ \\mathbf{M}^{(L)} \\stackrel{\\mathrm{def}}{=}} \\cdot \\ldots \\cdot \\underbrace{\\partial_{\\mathbf{h}^{(l)}} \\mathbf{h}^{(l+1)}}_{ \\mathbf{M}^{(l+1)} \\stackrel{\\mathrm{def}}{=}} \\underbrace{\\partial_{\\mathbf{W}^{(l)}} \\mathbf{h}^{(l)}}_{ \\mathbf{v}^{(l)} \\stackrel{\\mathrm{def}}{=}}.\n\\]</div><p></p><p>也因此，梯度 <span class=\"math inline\">\\(\\partial_{\\mathbf{W}^{(l)}} \\mathbf{o}\\)</span> 是 <span class=\"math inline\">\\((L-l)\\)</span> 个雅可比矩阵 <span class=\"math inline\">\\(\\mathbf{M}^{(L)}, \\dots, \\mathbf{M}^{(l+1)}\\)</span> 与一个二维张量 <span class=\"math inline\">\\(\\mathbf{v}^{(l)}\\)</span> 的乘积。在深层网络中，连续矩阵乘法可能导致结果数值过大（<strong>爆炸</strong>）或过小（<strong>消失</strong>）。</p>\n<p><strong>梯度消失</strong>：</p>\n<p>如果使用Sigmoid函数，就要考虑 Sigmoid 函数在其饱和区梯度逼近于零的情况。因此当输入很大或很小时，梯度消失。为此我们最好用ReLU函数替代之。</p>\n<p>如果每一次的 梯度都减小一点，那么多层传播后梯度值会非常小。</p>\n<p>如果权重的初始值太小，向前传播过程中每层线性变换的输出方差大幅衰减，进而使激活函数的输入落入该函数的危险区（如 Sigmoid 的饱和区、ReLU的斩杀区）。</p>\n<p><strong>梯度爆炸</strong>：</p>\n<p>特指反向传播过程中，梯度值随着层级增加而不断变大，乃至指数型增加。</p>\n<p>很可能因为 <span class=\"math inline\">\\(weight\\)</span> 的初始值太大，层数过多等等</p>\n<p><strong>参数化的对称性</strong>：<br />\n若同一层内的的所有权重均初始化为相同值，那么该层所有的神经元在反向传播中都会获得完全一样的梯度，永远学习相同的特征，极大降低模型容量。</p>\n<p>那么，如何为我们模型的训练提供一个良好、稳健的起点呢？这就是神经网络 <strong>参数初始化</strong> 的showtime了。良好的初始化方式，能够前向传播中保持传递强度，在反向传播中保证梯度流动，从而打破上文的 <em>参数化的对称性</em> 等等问题。</p>\n<h3 id=\"三种常见的初始化\">三种常见的初始化</h3>\n<h4 id=\"xavier初始化\">Xavier初始化</h4>\n<p>目标：保持各层激活值方差稳定，确保前向传播的信号强度和反向传播的梯度强度在初始化时不衰减也不爆炸。</p>\n<p>Xavier 初始化因为提出的时间较早，它主要针对像 <span class=\"math inline\">\\(tanh\\)</span> 这样在原点附近近似线性且对称的饱和激活函数。因此对于后来广泛使用的 ReLU 及其变种，它的效果并非最优。</p>\n<p>这里的3个函数都有饱和区，也就是梯度消失的那段区域，太大或太小时函数导数趋于 <span class=\"math inline\">\\(0\\)</span> 。</p>\n<p>这个理论的基本原则就是：<strong>在前向传播中，保持各层激活值的方差一致；在反向传播中，保持各层梯度的方差一致</strong>。 也就是说初始化阶段的激活值和梯度的期望均为 <span class=\"math inline\">\\(0\\)</span>。Xavier初始化是为 <span class=\"math inline\">\\(tanh\\)</span> 这类在零点附近近似线性且对称的激活函数设计的，对于 <span class=\"math inline\">\\(Sigmoid\\)</span>，虽然 Xavier初始化可以用于 <span class=\"math inline\">\\(Sigmoid\\)</span> ，但不是最优的。实际应用中，对 <span class=\"math inline\">\\(Sigmoid\\)</span> 可以使用 Xavier初始化，但可能需要调整缩放因子。</p>\n<p>用数学语言表述，就是要激活函数在原点泰勒展开的一阶近似（当然 <span class=\"math inline\">\\(x\\)</span> 也在 <span class=\"math inline\">\\(0\\)</span> 附近） <span class=\"math inline\">\\(f(x)\\)</span> 满足：</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\n&amp;f(x) = -f(-x)，即f(0)=0\\\\\n&amp;f'(0)=1\\end{split}\n\\]</div><p></p><p>再换句话，由观察，我们希望任意层的输入信号方差应等于其输出信号方差：</p>\n<p></p><div class=\"math display\">\\[Var(a^{(l-1)}) \\approx Var(a^{(l)})\n\\]</div><p></p><p>观察第 <span class=\"math inline\">\\(l\\)</span> 层的线性变换：</p>\n<p></p><div class=\"math display\">\\[\\mathcal{z_i^{l}}=\\sum_{j=1}^{n_{in}}w_{ij}^{(l)}\\cdot a_j^{(l-1)}\n\\]</div><p></p><p>这里先基本假设一下：</p>\n<ol>\n<li>权重 <span class=\"math inline\">\\(w_{ij}^{(l)}\\)</span> 独立同分布，均值为 <span class=\"math inline\">\\(0\\)</span>，方差 <span class=\"math inline\">\\(\\sigma _w^2\\)</span></li>\n<li>激活值 <span class=\"math inline\">\\(a_{j}^{(l-1)}\\)</span> 独立同分布，均值为 <span class=\"math inline\">\\(0\\)</span>，方差 <span class=\"math inline\">\\(\\sigma _a^2\\)</span></li>\n<li>权重和激活值相互独立</li>\n</ol>\n<h5 id=\"先看看期望\">先看看期望：</h5>\n<p></p><div class=\"math display\">\\[\\begin{split}\n\\mathbb{E}[z^{(l)}_i]&amp;=\\mathbb{E}\\bigg[ \\sum^{n_{in}}_{j=1}w_{ij}^{(l)}a_j^{(l-1)} \\bigg]\\\\\n\\mathbb{E}[z_i^{(l)}]&amp;=\\sum_{j=1}^{n_{in}}\\mathbb{E}[w_{ij}^{(l)}]\\cdot \\mathbb{E}[a_j^{(l - 1)}]\\\\\n\\mathbb{E}[z_i^{(l)}]&amp;=0\n\n\\end{split}\n\\]</div><p></p><h5 id=\"再看看方差先着眼于前向传播的过程\">再看看方差，先着眼于前向传播的过程：</h5>\n<p></p><div class=\"math display\">\\[\\begin{split}\nVar(\\mathcal{z_i^{(l)}})&amp;=\\mathbb E[(\\mathcal{z_i^{(l)}})^2]-(\\mathbb E[\\mathcal z_i^{(l)}])^2\\\\\n&amp;=\\mathbb E[(\\mathcal{z_i^{(l)}})^2]\n\\\\\n&amp;=  \\mathbb{E} \\left[ \\left( \\sum_{j=1}^{n_{\\text{in}}} w_{ij}^{(l)} a_j^{(l-1)} \\right)^2 \\right] \\\\\n&amp;= \\mathbb{E} \\left[ \\sum_{j=1}^{n_{\\text{in}}} \\sum_{k=1}^{n_{\\text{in}}} w_{ij}^{(l)} w_{ik}^{(l)} a_j^{(l-1)} a_k^{(l-1)} \\right]\\\\\n&amp;= \\ldots\\\\\n&amp;= \\sum_{j=1}^{n_{in}}\\mathbb E[(\\mathcal{w}_{ij}^{(l)})^2]\\cdot\\mathbb E [(a_j^{(l - 1)})^2] \\space(j=k)\\\\\n&amp;=n_{in}\\cdot\\sigma_w^2\\cdot\\sigma_a^2\\\\\n\\end{split}\\]</div><p></p><p>上文公式推导省略号中的内容：</p>\n<ul>\n<li>当 <span class=\"math inline\">\\(j\\neq k\\)</span>，式子为 <span class=\"math inline\">\\(0\\)</span></li>\n<li>当 <span class=\"math inline\">\\(j=k\\)</span>，式子为 <span class=\"math inline\">\\(\\sum_{j=1}^{n_{in}}\\mathbb E[(\\mathcal{w}_{ij}^{(l)})^2]\\cdot\\mathbb E [(a_j^{(l = 1)})^2]\\)</span></li>\n<li>因此，求和中仅 <span class=\"math inline\">\\(j=k\\)</span> 的项有贡献。</li>\n</ul>\n<p>为了保证激活方差不变，即</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\nVar(z_i^{(l)})&amp;=Var(a_j^{(l - 1)})\\\\\nn_{in}\\cdot\\sigma^2\\cdot\\sigma_a^2&amp;=\\sigma_a^2\\\\\nn_{in}\\cdot\\sigma_w^2&amp;=1\\\\\n\\end{split}\n\\]</div><p></p><h5 id=\"接着推导一下反向传播\">接着推导一下反向传播：</h5>\n<p>反向传播的梯度传播公式如下</p>\n<p></p><div class=\"math display\">\\[\\frac{\\partial L}{\\partial a_j^{(l-1)}}=\\sum_{i=1}^{n_{out}}w_{ij}^{(l)}\\cdot\\frac{\\partial L}{\\partial z_i^{(l)}}\n\\]</div><p></p><p>那么假设 <span class=\"math inline\">\\(\\frac{\\partial L}{\\partial z_i^{(l)}}\\)</span> 独立同分布，方差为 <span class=\"math inline\">\\(\\sigma_g^2\\)</span> ，可以得到梯度方差的表示：</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\nVar\\left( \\frac{\\partial L}{\\partial a_j^{(l-1)}} \\right)&amp;=\\sum_{i=1}^{n_{out}}\\mathbb{E}[(w_{ij}^{(l)})^2]\\cdot\\mathbb{E}\\left[ \\left( \\frac{\\partial L}{\\partial z_i^{(l)}} \\right)^2 \\right] \\\\\n\n&amp;=n_{out}\\cdot\\sigma_w^2\\cdot\\sigma_g^2\\\\\n\\end{split}\n\\]</div><p></p><p>我们希望反向传播前后梯度方差不变。即希望：</p>\n<p></p><div class=\"math display\">\\[Var\\left( \\frac{\\partial L}{\\partial a_j^{(l-1)}} \\right)=Var\\left( \\frac{\\partial L}{\\partial z_i^{(l)}} \\right)\n\\]</div><p></p><p>那么就可以得到反向传播保持方差不变时应满足的条件：</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\n\nn_{out}\\cdot\\sigma_w^2\\cdot\\sigma_g^2&amp;=\\sigma_g^2\\\\\nn_{out}\\cdot\\sigma_w^2&amp;=1\n\n\\end{split}\n\\]</div><p></p><h5 id=\"因此这种一下这两个条件取调和平均\">因此，这种一下这两个条件，取调和平均：</h5>\n<p></p><div class=\"math display\">\\[\\begin{split}\nn_{in}\\cdot\\sigma_w^2&amp;=1\\\\\nn_{out}\\cdot\\sigma_w^2&amp;=1\\\\\n\\sigma_w^2&amp;=\\frac{2}{n_{in}+n_{out}}\\\\\n\\end{split}\n\\]</div><p></p><p>即：</p>\n<p></p><div class=\"math display\">\\[Var(\\mathcal w) = \\frac{2}{n_{in}+n_{out}}\n\\]</div><p></p><p>这样，标准差就出来了：</p>\n<p></p><div class=\"math display\">\\[\\sigma = \\sqrt \\frac{2}{n_{in}+n_{out}}\n\\]</div><p></p><p>因此初始权值应符合的正态分布：</p>\n<p></p><div class=\"math display\">\\[W\\sim \\mathcal N(0,\\sigma^2)\n\\]</div><p></p><p>或者转化为均匀分布形式，即</p>\n<p></p><div class=\"math display\">\\[w\\sim U\\left[ -\\sqrt{\\frac{6}{n_{in}+n_{out}}},\\sqrt{\\frac{6}{n_{in}+n_{out}}} \\right]\n\\]</div><p></p><p>然而，Xavier初始化提出的时间有点早，ReLU激活函数还没有得到广泛应用。<br />\n对于ReLU函数，Xavier初始化力不从心：</p>\n<ol>\n<li>ReLU的函数输出非对称：<span class=\"math inline\">\\(y \\in [0,+∞)\\)</span></li>\n<li>负的输入反向输出时梯度为 <span class=\"math inline\">\\(0\\)</span></li>\n<li>会将 <span class=\"math inline\">\\(50\\%\\)</span> 的神经元输出清零，从而</li>\n</ol>\n<ul>\n<li>前向传播：<span class=\"math inline\">\\(Var(a) \\approx \\frac{1}{2}Var(y)\\)</span></li>\n<li>反向传播：梯度方差同样减半</li>\n</ul>\n<p>而且对于深层神经网络而言，线性激活函数价值不大，因为它需要非线性激活函数来构建复杂的非线性神经网络。</p>\n<p>面对这些问题，He初始化（Kaiming初始化）被提了出来。</p>\n<h4 id=\"kaiming-初始化\">Kaiming 初始化</h4>\n<p>与 Xavier 初始化类似，Kaiming 初始化的目的也是尽量让每一层输出层的方差与输入层的方差一致，以缓解深层网络中的梯度消失、梯度爆炸问题，最后使极深整流网络（如30层）能从零开始直接训练并收敛。</p>\n<p>对于向前传播：</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\n\\text{Var}(y_i) &amp;= \\text{Var} \\left( \\sum_{j=1}^{n_{\\text{in}}} w_{ij} \\cdot x_j \\right) \\\\&amp;= n_{\\text{input}}\\cdot\\text{Var}(w_{ij}) \\cdot \\text{Var}(x_j)\n\\end{split}\n\\]</div><p></p><p>对<span class=\"math inline\">\\(y_i\\)</span>加入ReLU函数得到<span class=\"math inline\">\\(a_i\\)</span>，那么我们就希望：</p>\n<p></p><div class=\"math display\">\\[\\text{Var}(a_i) \\approx \\text{Var}(x_j),\\quad \\forall i,j\n\\]</div><p></p><p>这里的初始化假设与 Xavier 相同。</p>\n<p>因为 <span class=\"math inline\">\\(w_{ij}\\)</span> 与 <span class=\"math inline\">\\(x_j\\)</span> 独立且均值为 <span class=\"math inline\">\\(0\\)</span>，有</p>\n<p></p><div class=\"math display\">\\[\\text{Var}(w_{ij}x_j)=\\text{Var}(w_{ij})\\text{Var}(x_j)=\\sigma_w^2\\sigma_x^2\n\\]</div><p></p><p>则 <span class=\"math inline\">\\(y_i\\)</span> 的方差为：</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\n\\text{Var}(y_i) &amp;= \\text{Var}\\left( \\sum_{j=1}^{n_{in}}w_{ij}x_j \\right)\\\\ \n&amp;=\\sum_{j=1}^{n_{in}}\\text{Var}(w_{ij}x_j)\\\\\n&amp;=\\sum_{j=1}^{n_{in}}\\sigma_w^2\\sigma_x^2\\\\\n&amp;=n_{in}\\sigma_w^2\\sigma_x^2\\\\\n&amp;=n_{in}\\cdot\\text{Var}(w)\\cdot\\text{Var}(x)\n\\end{split}\n\\]</div><p></p><p>我们假设 <span class=\"math inline\">\\(y_i\\)</span> 的分布是关于 0 对称的，那么 <span class=\"math inline\">\\(y_i\\)</span> 取正数和取负数的概率各占一半。</p>\n<p>再看 <span class=\"math inline\">\\(y_i^2\\)</span>。因为平方把正负都变成了正数，所以 <span class=\"math inline\">\\(y_i^2\\)</span> 的期望值 <span class=\"math inline\">\\(E[y_i^2]\\)</span> 可以拆成两半：一半来自 <span class=\"math inline\">\\(y_i&gt;0\\)</span>，一半来自 <span class=\"math inline\">\\(y_i&lt;0\\)</span>。由于对称，这两半的贡献是一模一样的。</p>\n<p>而 ReLU 函数 <span class=\"math inline\">\\(a_i = \\max(0, y_i)\\)</span> 只取 <span class=\"math inline\">\\(y_i\\)</span> 的正值部分，负数部分直接归零。所以 <span class=\"math inline\">\\(a_i^2\\)</span> 其实就是 <span class=\"math inline\">\\(y_i^2\\)</span> 在 <span class=\"math inline\">\\(y_i&gt;0\\)</span> 时的值，其他情况为 0。</p>\n<p>因此，<span class=\"math inline\">\\(a_i^2\\)</span> 的期望 <span class=\"math inline\">\\(E[a_i^2]\\)</span> 正好就等于 <span class=\"math inline\">\\(y_i^2\\)</span> 期望的一半，即</p>\n<p></p><div class=\"math display\">\\[E[a_i^2]=\\frac{1}{2}E[y_i^2]\n\\]</div><p></p><p>而 <span class=\"math inline\">\\(E[y_i]=0\\)</span>，有 <span class=\"math inline\">\\(E[y_i^2]=\\text{Var}(y_i)\\)</span>，故</p>\n<p></p><div class=\"math display\">\\[E[a_i^2]=\\frac{1}{2}\\text{Var}(y_i)\n\\]</div><p></p><p>当 <span class=\"math inline\">\\((E[a_i])^2\\)</span> 相较于 <span class=\"math inline\">\\(E[a_i^2]\\)</span> 可以忽略时，可近似为：</p>\n<p></p><div class=\"math display\">\\[\\text{Var}(a_i)\\approx\\frac{1}{2}\\text{Var}(y_i)\n\\]</div><p></p><p>我们希望 <span class=\"math inline\">\\(\\text{Var}(a_i) = \\text{Var}(x)\\)</span>（当然至少得是近似的），结合可得：</p>\n<p></p><div class=\"math display\">\\[\\begin{split}\n\\frac{1}{2}\\cdot n_{in}\\cdot Var(w)\\cdot Var(x) &amp;=Var{(x)}\\\\\nVar(w)&amp;=\\frac{2}{n_{in}}\n\\end{split}\\]</div><p></p><p>以此类推，可以得到反向传播时，</p>\n<p></p><div class=\"math display\">\\[Var(w)=\\frac{2}{n_{out}}\n\\]</div><p></p><p>不过一般情况，我们使用前向传播优先，即</p>\n<p></p><div class=\"math display\">\\[W\\sim \\mathcal{N}(0,\\sqrt \\frac{2}{n_{in}})\n\\]</div><p></p><p>我们为什么不常见类比Xavier做调和平均呢？（其实是可以的，见 PyTorch 中的 <code>mode='fan_avg'</code> ）因为<strong>ReLU的单向激活特性</strong>使得前向传播和反向传播的方差传播规律不同：</p>\n<ul>\n<li>对前向传播，ReLU 杀死一半的神经元，方差减半；对反向传播，相当于简单的伯努利掩码，方差依旧减半。</li>\n<li>问题在于正向反向的网格结构可能是不同的，且正向反向的衰减机制有席位差别。</li>\n</ul>\n<p>pytorch实现：</p>\n<pre><code class=\"language-python\">layer = nn.Linear(64, 128)\ninit.kaiming_normal_(layer.weight, a=0, mode='fan_in', nonlinearity='relu')\n# a：负斜率（Leaky ReLU 的情况，默认为0）\n# Leaky ReLU : 负x轴设置为 ax ，而不是 0 ，通常 a = 0.01\n</code></pre>\n<h4 id=\"正交初始化\">正交初始化</h4>\n<p>上面两种方法都是对每个权重分别进行随机独立采样，但是由于采样的随机性，仍不可避免出现各种梯度问题。</p>\n<p>对于一个 L 层的等宽线性网络，可以很容易得到这个等式：</p>\n<p></p><div class=\"math display\">\\[y=W^{(L)}W^{(L-1)}W^{(L-2)}\\cdots W^{(2)}W^{(1)}x\n\\]</div><p></p><p>那么，我们可以直接将 <span class=\"math inline\">\\(W^{(i)}\\)</span> 初始化为正交矩阵。</p>\n<p>根据线代知识，我们对这个初始权重矩阵的构建分为两步：</p>\n<ol>\n<li>用均值 <span class=\"math inline\">\\(0\\)</span> , 方差 <span class=\"math inline\">\\(1\\)</span> 的高斯分布构建一个矩阵</li>\n<li>奇异值分解这个矩阵，得到两个正交矩阵，选择其中一个作为权重矩阵</li>\n</ol>\n<p>根据正交矩阵的性质，这个线性网络就会在前向、反向传播中都有一定的范数保持性。如果这个网络是非线性的，只需在矩阵前面乘上一个系数 <span class=\"math inline\">\\(\\rho\\)</span>，这个系数与激活函数有关，如对于 <span class=\"math inline\">\\(ReLU\\)</span> 应该 <span class=\"math inline\">\\(\\rho=\\sqrt 2\\)</span> ，对于 <span class=\"math inline\">\\(tanh\\)</span> 应该 <span class=\"math inline\">\\(\\rho\\approx 1.0\\)</span>，这是为了补偿激活函数对信号幅度的压缩（扩张）效应。</p>\n<h3 id=\"更加现代的初始化方法\">更加现代的初始化方法</h3>\n<h4 id=\"fixup\">Fixup</h4>\n<p>可使在不使用批量归一化的情况下完成深度残差网络训练。</p>\n<p>通过缩放残差网络分支的权重来控制梯度规模，避免深层网络的梯度爆炸</p>\n<p>方法：</p>\n<ul>\n<li>将分类层、残差分支的最后一层初始化为 <span class=\"math inline\">\\(0\\)</span></li>\n<li>对其他层使用标准方法的初始化，然后将残差分支中的权重层乘以缩放系数 <span class=\"math inline\">\\(L^{-\\frac{1}{2m-2}}\\)</span></li>\n<li>在每个分支中添加一个标量乘数（就是前面的缩放系数），在每个卷积、线性和元素级激活层前面添加一个可学习标量偏差（初始为 <span class=\"math inline\">\\(0\\)</span> ）。</li>\n</ul>\n<p>其中</p>\n<ul>\n<li><span class=\"math inline\">\\(m\\)</span>：每个残差块中的权重层数</li>\n<li><span class=\"math inline\">\\(L\\)</span>：网络总残差块数</li>\n</ul>\n<h4 id=\"t-fixup\">T-Fixup</h4>\n<p>在完全移除层归一化的情况下，稳定并高效地训练 Transformer 模型</p>\n<p>通过精心设计的参数初始化和简单的标量偏差，在数学上使前向传播的信号幅度和反向传播的梯度范数在初始化时保持稳定，从而完全移除所有 LN 层。</p>\n<h2 id=\"参考文献\">参考文献</h2>\n<p>Glorot &amp; Bengio. Understanding the difficulty of training deep feedforward neural networks. Jan 2010</p>\n<p>He et al. Deep Residual Learning for Image Recognition. arXiv:1512.03385 [cs.CV] 10 Dec 2015</p>\n<p>Saxe et al. Sparser, Better, Deeper, Stronger: Improving Static Sparse Training with Exact Orthogonal Initialization. arXiv:2406.01755v1 [cs.LG] 03 Jun 2024</p>\n<p>Yilmaz &amp; Heckel. Regularization-wise Double Descent: Why It Occurs and How to Eliminate It. arXiv:2206.09012, 2022.</p>\n<p>Zhang et al. Fixup Initialization: Residual Learning Without Normalization. arXiv:1901.09321 [cs.LG] 27 Jan 2019</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 21:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yldeveloper\">yLDeveloper</a>&nbsp;\n阅读(<span id=\"post_view_count\">11</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Lab3-page tables  && MIT6.1810操作系统工程【持续更新】",
      "link": "https://www.cnblogs.com/xiaobai1523/p/19596981",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaobai1523/p/19596981\" id=\"cb_post_title_url\" title=\"发布于 2026-02-09 21:21\">\n    <span>Lab3-page tables  &amp;&amp; MIT6.1810操作系统工程【持续更新】</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"labpage-tables\">Lab：page tables</h1>\n<p>​\t在这个lab中<a href=\"https://pdos.csail.mit.edu/6.828/2025/labs/pgtbl.html\" rel=\"noopener nofollow\" target=\"_blank\">6.1810 / Fall 2025</a>，要求我们先阅读xv6课本的<a href=\"https://pdos.csail.mit.edu/6.828/2025/xv6/book-riscv-rev5.pdf\" rel=\"noopener nofollow\" target=\"_blank\">Chapter 3 Page tables</a>(第三章)。要求我们探索xv6当中关于页表的内容。并且要求我们实现一些页表相关功能的实现（例如：虚地址和物理地址的映射/解除映射，页表的创建和释放等）。</p>\n<p>​\t并且官网也给出了提示：</p>\n<ul>\n<li>在<code>kernel/memlayout.h</code>当中存放了内存布局，页表大小相关的常量就在此。</li>\n<li>在<code>kernel/vm.c</code>当中是页表相关逻辑的实现，接下来的大部分lab内容就在此实现。</li>\n<li>在<code>kernel/kalloc.c</code>当中存放的时内存分配相关的逻辑，在新建/删除页表时会用到这里的函数。</li>\n</ul>\n<h2 id=\"speed-up-system-calls-简单\">Speed up system calls （简单）</h2>\n<p>​\t在这个lab当中，要求我们在 xv6 中添加一个新的 <strong>用户可读的只读内存映射（USYSCALL）</strong>，用来让用户态程序在不陷入内核的情况下，直接读取部分内核数据（如 <code>pid</code>），并正确处理其 <strong>创建、映射、访问与释放的完整生命周期</strong>。</p>\n<h3 id=\"如何将一个用户可读的只读内存映射usyscall添加到进程页表内以及如何删除该映射\">如何将一个<strong>用户可读的只读内存映射（USYSCALL）</strong>添加到进程页表内？以及如何删除该映射？</h3>\n<p>​\t<strong>前言和注意事项</strong>：在xv6当中的有关进程的创建/释放，进程页表的创建/释放的过程都在<code>kernel/proc.h</code>,并且按照官网的说法，我们需要将进程的<strong>pid</strong>存放到内存当中，这样在调用<strong><code>gitpid</code>系统调用</strong>时，则直接选择从内存空间当中读取该pid，大大提高了执行效率，并且不用陷入到内核态；这就意味着我们需要在<strong>进程的结构体</strong>当中添加一个成员用于指向存放当前进程的<strong>pid</strong>的空间，为了之后的读取。</p>\n<p>​\t<strong>一、分配物理内存</strong>：</p>\n<p>​\t\t前面提到过，进程的结构体成员当中有指向进程pid的指针<code>(struct usyscall *)</code>，因此，我们需要先给他分配物理内存（由内核分配）。</p>\n<pre><code class=\"language-c\">p-&gt;usyscall = (struct usyscall *)kalloc(); //分配物理内存\n</code></pre>\n<p>​\t<strong>二、初始化内容：</strong></p>\n<p>​\t\t将当前进程的<strong>pid</strong>存放到刚才的指针<code>p-&gt;usyscall</code>所指向的空间中。</p>\n<pre><code class=\"language-c\">p-&gt;usyscall-&gt;pid = p-&gt;pid;\n\n// 以下是xv6提前写好的，改进后的ugetpid方法\nint\nugetpid(void)\n{\n  struct usyscall *u = (struct usyscall *)USYSCALL;  //通过虚拟地址USYSCALL访问特点内存\n  return u-&gt;pid;\n}\n</code></pre>\n<p>​\t\t为什么我们必须通过<code>struct usyscall *</code>来访问，而不是直接返回进程结构体当中的<strong>pid</strong>呢？</p>\n<p>​\t\t答：首先，xv6有<strong>内核页表</strong>和<strong>用户页表</strong>，并且用户态下的进程只能看得见内存。因为进程的结构体存放在内核页表当中，在用户态下我们只能访问到用户页表，所以准确来说我们只能通过<strong>虚拟内存</strong>搭配<strong>页表机制</strong>的方式来访问存放在该物理空间当中内容。我们在内核态下通过<code>p-&gt;usyscall = (struct usyscall *)kalloc(); </code>分配的内存似乎也是被内核所管理，但是我们将<strong>USYSCALL</strong>这个虚拟地址和物理地址相映射了起来，因此我们可以通过在用户态下访问该虚拟地址的方式下访问到具体的物理地址当中的值。</p>\n<p>​\t<strong>三、创建用户页表：</strong></p>\n<p>​\t\t众所周知，OS当中的进程采用页表机制来将进程的虚地址映射到物理地址上，所以说无论我们是否要添加映射到页表中，我们都必不可免地要创建一个用户页表。</p>\n<pre><code class=\"language-c\">p-&gt;pagetable = proc_pagetable(p);\n</code></pre>\n<p>​\t<strong>四、建立虚拟地址  到  物理地址映射:</strong></p>\n<p>​\t\t说白了就是在用户页表中添加一个新的页表项，所以这一步的操作要在<strong>页表的相关逻辑</strong>当中进行，该页表项用于映射到刚才分配的物理内存。在<code>kernel/defs.h</code>当中，我们可以看到<strong><code>mappages</code></strong>的声明（该函数用于添加映射到页表）。</p>\n<p>​\t\t注意：页表机制是将进程的虚拟地址映射为内存中真实的物理地址，所以在添加新的映射时，要一并给出这些参数以及映射大小和权限。</p>\n<pre><code class=\"language-c\">// 映射 USYSCALL\n  if(mappages(pagetable,\n              USYSCALL,  //虚拟地址\n              PGSIZE,  // 映射大小\n              (uint64)p-&gt;usyscall, //物理地址\n              PTE_R | PTE_U | PTE_V) &lt; 0){  // 官网要求设置的权限\n    uvmfree(pagetable, 0);\n    return 0;\n  }\n</code></pre>\n<p>​\t\t<strong>xv6</strong>的权限（添加权限的目的是防止“篡改”，“非法访问”等等操作）：</p>\n<table>\n<thead>\n<tr>\n<th>位</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PTE_R</td>\n<td>用户可读</td>\n</tr>\n<tr>\n<td>PTE_W</td>\n<td>防止用户写</td>\n</tr>\n<tr>\n<td>PTE_X</td>\n<td>防止执行</td>\n</tr>\n<tr>\n<td>PTE_U</td>\n<td>用户态可访问</td>\n</tr>\n<tr>\n<td>PTE_V</td>\n<td>映射有效</td>\n</tr>\n</tbody>\n</table>\n<p>​\t<strong>五、删除/释放映射:</strong></p>\n<p>​\t\t首先在<strong>页表释放的相关逻辑</strong>当中进行释放映射的操作，在<code>kernel/defs.h</code>当中，我们可以看到<code>uvmunmap</code>的声明（该函数用于删除/释放映射到页表）。</p>\n<pre><code class=\"language-c\">uvmunmap(pagetable, USYSCALL, 1, 0); //释放USYSCALL\n</code></pre>\n<p>​\t\t之后在<strong>进程释放的相关逻辑</strong>进行释放之前访问的物理空间的操作，在<code>kernel/defs.h</code>当中，我们可以看到<code>kfree</code>的声明（该函数用于释放分配的内存）。</p>\n<pre><code class=\"language-c\">kfree(p-&gt;usyscall);\n</code></pre>\n<p>​\t<strong>六、深入了解进程和页表的底层逻辑：</strong></p>\n<table>\n<thead>\n<tr>\n<th>函数（kernel/proc.c）</th>\n<th>负责什么</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>allocproc</code></td>\n<td>分配“进程资源”（pid、usyscall、trapframe、kstack）<strong>(第一，二，三步在此进行)</strong></td>\n</tr>\n<tr>\n<td><code>freeproc</code></td>\n<td>释放“进程资源” <strong>（第五步后半部分在此进行）</strong></td>\n</tr>\n<tr>\n<td><code>proc_pagetable</code></td>\n<td>构造页表结构 <strong>（第五步前半部分在此进行）</strong></td>\n</tr>\n<tr>\n<td><code>proc_freepagetable</code></td>\n<td>拆除页表结构 <strong>（第四步在此进行）</strong></td>\n</tr>\n</tbody>\n</table>\n<p>​\t\t由此我们可以得知页表的生命周期几乎伴随整个进程。</p>\n<h3 id=\"代码的相关内容\">代码的相关内容：</h3>\n<pre><code class=\"language-c\">/* kernel/proc.c */\nstatic struct proc*\nallocproc(void)\n{\n  struct proc *p;\n\n  for(p = proc; p &lt; &amp;proc[NPROC]; p++) {\n    acquire(&amp;p-&gt;lock);\n    if(p-&gt;state == UNUSED) {\n      goto found;\n    } else {\n      release(&amp;p-&gt;lock);\n    }\n  }\n  return 0;\n\nfound:\n  p-&gt;pid = allocpid();\n  p-&gt;state = USED;\n  // 分配物理内存\n  p-&gt;usyscall = (struct usyscall *)kalloc();\n  if(p-&gt;usyscall == 0){\n    freeproc(p);\n    release(&amp;p-&gt;lock);\n    return 0;\n  }\n  // 初始化内容\n  p-&gt;usyscall-&gt;pid = p-&gt;pid;\n\n  // Allocate a trapframe page.\n  if((p-&gt;trapframe = (struct trapframe *)kalloc()) == 0){\n    freeproc(p);\n    release(&amp;p-&gt;lock);\n    return 0;\n  }\n\n  // An empty user page table.\n  p-&gt;pagetable = proc_pagetable(p);\n  if(p-&gt;pagetable == 0){\n    freeproc(p);\n    release(&amp;p-&gt;lock);\n    return 0;\n  }\n\n  // Set up new context to start executing at forkret,\n  // which returns to user space.\n  memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));\n  p-&gt;context.ra = (uint64)forkret;\n  p-&gt;context.sp = p-&gt;kstack + PGSIZE;\n\n  return p;\n}\n\n// free a proc structure and the data hanging from it,\n// including user pages.\n// p-&gt;lock must be held.\nstatic void\nfreeproc(struct proc *p)\n{\n  // 释放之前分配的物理内存\n  if(p-&gt;usyscall){\n    kfree((void*)p-&gt;usyscall);\n    p-&gt;usyscall = 0;\n  }\n  if(p-&gt;trapframe)\n    kfree((void*)p-&gt;trapframe);\n  p-&gt;trapframe = 0;\n  if(p-&gt;pagetable)\n    proc_freepagetable(p-&gt;pagetable, p-&gt;sz);\n  p-&gt;pagetable = 0;\n  p-&gt;sz = 0;\n  p-&gt;pid = 0;\n  p-&gt;parent = 0;\n  p-&gt;name[0] = 0;\n  p-&gt;chan = 0;\n  p-&gt;killed = 0;\n  p-&gt;xstate = 0;\n  p-&gt;state = UNUSED;\n}\n\n// Create a user page table for a given process, with no user memory,\n// but with trampoline and trapframe pages.\npagetable_t\nproc_pagetable(struct proc *p)\n{\n  pagetable_t pagetable;\n\n  // An empty page table.\n  pagetable = uvmcreate();\n  if(pagetable == 0)\n    return 0;\n\n  // 映射 USYSCALL（也是关键部分）\n  if(mappages(pagetable,\n              USYSCALL,  //虚拟地址\n              PGSIZE,  // 映射大小\n              (uint64)p-&gt;usyscall,  //物理地址\n              PTE_R | PTE_U | PTE_V) &lt; 0){ // 权限\n    uvmfree(pagetable, 0);\n    return 0;\n  }\n  \n\n  // map the trampoline code (for system call return)\n  // at the highest user virtual address.\n  // only the supervisor uses it, on the way\n  // to/from user space, so not PTE_U.\n  if(mappages(pagetable, TRAMPOLINE, PGSIZE,\n              (uint64)trampoline, PTE_R | PTE_X) &lt; 0){\n    uvmfree(pagetable, 0);\n    return 0;\n  }\n\n  // map the trapframe page just below the trampoline page, for\n  // trampoline.S.\n  if(mappages(pagetable, TRAPFRAME, PGSIZE,\n              (uint64)(p-&gt;trapframe), PTE_R | PTE_W) &lt; 0){\n    uvmunmap(pagetable, TRAMPOLINE, 1, 0);\n    uvmfree(pagetable, 0);\n    return 0;\n  }\n\n  return pagetable;\n}\n\n// Free a process's page table, and free the\n// physical memory it refers to.\nvoid\nproc_freepagetable(pagetable_t pagetable, uint64 sz)\n{\n  uvmunmap(pagetable, USYSCALL, 1, 0);  //释放/删除USYSCALL对应的映射\n  uvmunmap(pagetable, TRAMPOLINE, 1, 0);\n  uvmunmap(pagetable, TRAPFRAME, 1, 0);\n  uvmfree(pagetable, sz);\n}\n\n</code></pre>\n<h2 id=\"print-a-page-table-简单\">Print a page table （简单）</h2>\n<p>​\t这个lab要求我们实现一个打印页表的函数，同时也能帮助我们理解xv6当中，页表是如何实现的。在本次实验前，这门课程的作者已经将<code>kpgtbl（）</code>这个系统调用添加到内核当中了，现在我们要做的就是完善<code>kernel/vm.c</code>当中的<strong><code>vmprint()</code></strong>函数，这个函数接收一个<strong>pagetable_t</strong>（页表类型）的参数。</p>\n<h3 id=\"xv6当中的页表是怎样的\">xv6当中的页表是怎样的？</h3>\n<p>​\t<strong>零、专业词汇阐述</strong></p>\n<table>\n<thead>\n<tr>\n<th>名称</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>VA</td>\n<td>虚拟地址（CPU 使用）</td>\n</tr>\n<tr>\n<td>PTE</td>\n<td>页表项（映射 + 权限）</td>\n</tr>\n<tr>\n<td>PA</td>\n<td>物理地址（RAM 索引）</td>\n</tr>\n<tr>\n<td>PPN</td>\n<td>物理页号（PA 的高位）</td>\n</tr>\n</tbody>\n</table>\n<p>​\t<strong>一、虚拟地址va的结构和xv6当中的三级页表</strong></p>\n<p>​\t\t根据本课程对应的课本<a href=\"https://pdos.csail.mit.edu/6.828/2025/xv6/book-riscv-rev5.pdf\" rel=\"noopener nofollow\" target=\"_blank\">xv6 book</a> 当中的第三章，我们可以得知在xv6当中，虚拟地址va的位数为64位，并且我们只使用<strong>低39位</strong>，高25位用于扩展。相信你在看到这里时肯定学过操作系统这门课程，在任何一本操作系统的教科书当中，对于虚拟地址va的构成的描述都是低n位是页内偏移地址，用于定位某页内的页表项，剩下的高位都是索引，用于定位到某一页。</p>\n<p>​\t\t在xv6当中，页表的<strong>每页大小为4096B</strong>，<strong>每个页表项（PTE）的大小为8B</strong>，所以<strong>一个页表的当中有4096/8 = 512个PTE</strong>。所以39位的虚拟地址va当中，低12位为页内偏移量，省下的27位用于索引页表。</p>\n<p>​\t\txv6采用三级页表，也就是说27位的索引地址，每9位构成一个层级，类似一个树。以下内容是39位虚拟地址的构成。</p>\n<p>​\t\tPS：（床图网站随时可能失效，所以下面我尽量使用文字来进行描述）。</p>\n<pre><code class=\"language-c\">|VPN[2] | VPN[1] | VPN[0]|页内偏移|\n  9        9        9\t\t12       共39位\n一级索引  二级索引  三级索引  页内偏移量   总位数\n  根                叶子\n</code></pre>\n<p>​\t\t寻址时，先访问VPN[2]当中的某个PTE，该PTE指向VPN[1]，之后从VPN[1]中选取新的PTE，再次通过新的PTE寻址VPN[0]，用VPN[0]获得最终的PTE后即可获得PNN（物理页号）。最后通过对PNN操作得到PA（物理地址）。整个过程类似寻找树的叶子结点那样，一层一层向下寻找。</p>\n<p>​\t<strong>二、为什么xv6采用三级页表？</strong></p>\n<p>​\t\t 进程在创建之初，必须且至少拥有一个页表。<br />\n如果采用一级页表设计，为了满足这一必须的条件，操作系统必须一次性分配一张覆盖整个虚拟地址空间的页表，即使进程只使用其中极小的一部分（大部分内存空间会浪费掉），也必须遵守该规定。</p>\n<p>​\t\t而在采用三级页表的设计中，进程创建时只需要分配一个 4KB 的根页表页，其余页表页在虚拟地址空间被实际使用时才按需分配。</p>\n<p>​\t<strong>二、PTE的内容</strong></p>\n<p>​\t\t已知每个PTE的大小为8B，即一共64位。其中低10位（9<sub>0位）为flags（权限位/标记），剩下的高位（53</sub>10位共44bit）为PNN（物理页框号，分配内存之时，OS从空闲页框表当中的表头取下来的）。最后的10位（63~54位）暂时未用，置为0。</p>\n<p>​\t\tflags的内容：</p>\n<table>\n<thead>\n<tr>\n<th>位</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>V</td>\n<td>是否有效</td>\n</tr>\n<tr>\n<td>R</td>\n<td>可读</td>\n</tr>\n<tr>\n<td>W</td>\n<td>可写</td>\n</tr>\n<tr>\n<td>X</td>\n<td>可执行</td>\n</tr>\n<tr>\n<td>U</td>\n<td>用户可访问</td>\n</tr>\n<tr>\n<td>A/D</td>\n<td>硬件访问/修改标记</td>\n</tr>\n</tbody>\n</table>\n<p>​\t当一个 PTE 的 <strong>R/W/X 任一位为 1 时</strong>，该 PTE 是叶子结点，指向真实物理页；</p>\n<p>​\t若 <strong>R/W/X 全为 0 且 V=1</strong>，则该 PTE 指向下一级页表。</p>\n<p>​\t页表的本质除了指明虚拟地址映射到哪里外，还可以决定这个地址<strong>是否可读，是否可写，是否可执行，是否可用户态访问/执行</strong>。</p>\n<p><strong>三、PNN如何转为物理地址</strong></p>\n<p>​\t\txv6当中规定物理地址的位数为56位，由PNN和va的低12位拼接而成，具体操作手法如下：</p>\n<p>​\t\t1、首先讲PTE右移10位，这样低10位的flags会消失。</p>\n<p>​\t\t2、之后讲PTE左移12位，这样低12位的空白正好可以由虚拟地址的低12位偏移量进行填补。</p>\n<p>​\t\t3、我们现在需要将虚拟地址va的第12位进行填补，所以我们<strong>将va和0xFFF相与</strong>，这样va就只剩下了第12位的偏移量。</p>\n<p>​\t\t4、将PTE和va相加或着进行“逻辑或”操作，这样就拼接好了一个完整的物理地址。</p>\n<p>​\t\t注意：在xv6当中，以上的操作都有着对应的宏，在编码时可以直接使用宏操作。</p>\n<h3 id=\"该lab的实现和代码相关内容\">该lab的实现和代码相关内容</h3>\n<p>​\t<strong>一、个人的解析和官网提示</strong></p>\n<ol>\n<li>打印格式：第一行显示 vmprint 的参数。之后，每个页表项（PTE）对应一行，包括那些指向树中更深层次页表页的页表项。每个页表项行都缩进若干个 “..”，以表示其在树中的深度。每个页表项行都会显示其虚拟地址、页表项位以及从该页表项中提取的物理地址。不要打印无效的页表项。</li>\n<li>在<code>kernel/riscv.h</code>的文件末尾，有关于va转pa的宏。</li>\n<li><code>freewalk</code>这个函数也许会带来启发。</li>\n<li>在printf调用中使用%p，以官网上示例所示的方式打印完整的64位十六进制页表项（PTE）和地址。</li>\n</ol>\n<p>​\t<strong>二、代码相关内容</strong></p>\n<pre><code class=\"language-c\">##在kernel/vm.c文件内：\n\nstatic void\nvmprint_walk(pagetable_t pagetable, int level, uint64 va){\n  //每个页表521个PTE\n  for(int i = 0; i &lt; 512; i++){\n    pte_t pte = pagetable[i];\n    // pte有效 并且 V位为1则不是叶子结点\n    if((pte &amp; PTE_V) == 0)\n      continue;\n    // 将传入的PA物理地址（此时PA第12位为空）和偏移量相加合并为完整的物理地址\n    uint64 newva = va | ((uint64)i &lt;&lt; (12 + 9 * level));\n\n    // 打印层级， depth = 2 - level\n    for(int d = 0; d &lt; 2 - level; d++)\n      printf(\" ..\");\n\n    printf(\"%p: pte %p pa %p\\n\",\n           (void*)newva,\n           (void*)pte,\n           (void*)PTE2PA(pte));\n\n    // 不是叶子结点则向下递归\n    if((pte &amp; (PTE_R | PTE_W | PTE_X)) == 0){\n      // PTE2PA是将pte转为了物理地址PA（此时低12位为空）\n      pagetable_t child = (pagetable_t)PTE2PA(pte);\n      vmprint_walk(child, level - 1, newva);\n    }\n  }\n\n}\n\n#if defined(LAB_PGTBL) || defined(SOL_MMAP) || defined(SOL_COW)\nvoid\nvmprint(pagetable_t pagetable) {\n  // your code here\n  // 打印第一行，之后递归进行遍历\n  printf(\"page table %p\\n\", pagetable);\n  vmprint_walk(pagetable, 2, 0);\n  \n}\n#endif\n</code></pre>\n<h2 id=\"use-superpages-困难\">Use superpages (困难)</h2>\n<p>​\t这个lab可以说是最难的lab。卡了我快20个小时。当用户通过<code>sbrk()</code>申请内存时，如果申请的内存<strong>≥2MB</strong>时，xv6不再使用传统的三级页表（即大小为4K的页），而是采用二级页表（即1个2MB的超级页）。并且相关的函数也要适配处理超级页的功能。</p>\n<p>​\t采用超级页后的地址结构如下：</p>\n<pre><code>|VPN[2] | VPN[1]（包含VPN[0]）|页内偏移|\n  9        9        9\t\t   12       共39位\n一级索引         二级索引      页内偏移量   总位数\n  根              叶子\n===============================\nlevel-2 (512GB)\n  |\nlevel-1 (2MB)   ← ★ superpage 在这里（第一层）\n  |\nlevel-0 (4KB)   ← 普通的页面在这里（第0层）\n</code></pre>\n<p>​\t起始该lab的某些地方的写法是有迹可循的，你可以直接照搬之前原因的部分代码。</p>\n<h3 id=\"顺腾摸瓜寻找需要修改的内容\">顺腾摸瓜寻找需要修改的内容</h3>\n<p>​\t一、在<code>kernel/kalloc.c</code>文件当中的函数是负责分配页表内存的，目前这里只有普通页的内容，我们需要添加超级页的相关内容。在<code>kmem</code>中添加一个<code>run</code>结构，让其指向一个超级页的空闲页表。 之后在<code>freerange</code>函数当中仿照普通页的内存分配逻辑，照葫芦画瓢写一个超级页的内存分配逻辑。同时仿照<code>kfree</code>和<code>kalloc</code>写一个<code>superalloc</code>和<code>superfree</code>，这两个分别是超级页的分配和释放。</p>\n<p>​\t二、<code>sbrk()</code>当中调用了<code>growproc()</code>函数，使用参数<strong>n</strong>调整内存的大小。当<strong>n</strong>为有效值时则调用<code>uvmalloc</code>函数来对用户进行虚拟内存的分配<strong>（这里需要修改uvmalloc）</strong>。进一步进入<code>uvmalloc</code>函数当中，其中涉及了<code>mappages</code>函数，该函数负责为每个页表项映射物理地址<strong>（这里需要修改mappages）</strong>；同时也涉及了<code>uvmdealloc</code>函数，该函数的功能是释放用户页面，其内部涉及<code>uvmunmap</code>函数，这个函数是页面释放的具体实现<strong>（这里需要修改uvmunmap）</strong>。在<code>mappages</code>函数当中涉及了<code>walk</code>函数，该函数负责返回虚拟地址 va 对应的页表项（PTE）的地址<strong>（这里需要修改walk）</strong>。</p>\n<p>​\t三、官网说了，通过用户程序<code>pgtbltest</code>来测试超级页功能是否完成，所以我们顺藤摸瓜在<code>kernel/pgtbltest.c</code>当中发现<code>superpg_kfork</code>函数调用了<code>fork</code>进程来创建新进程，打算让新的进程采用超级页。所以我们再次顺腾摸瓜找到了<code>kfork</code>函数，里面涉及了<code>uvmcopy</code>函数，这个函数负责将父进程的页表复制给子进程（把父进程的数据拷贝一份给子进程），<strong>（这里需要修改uvmcopy）</strong>。</p>\n<h3 id=\"代码相关内容\">代码相关内容</h3>\n<p>​\t<strong>这一小节本人一开始没做出来，因此参考了很多大佬的博客和视频才得以做出，以下代码参考了这位大佬的博客→<a href=\"https://chenby99.github.io/p/mit6.1810lab3-page-tables/#use-superpages\" rel=\"noopener nofollow\" target=\"_blank\">mit6.1810]Lab3: page tables</a>。</strong></p>\n<p>​\t1、在<code>kalloc.c</code>当中照葫芦画瓢添加对超级页的管理。</p>\n<pre><code class=\"language-c\">struct {\n  struct spinlock lock;\n  struct run *freelist;\n  struct run *superfreelist;   // 仿照上面的freelist\n} kmem;\n\nvoid\nfreerange(void *pa_start, void *pa_end)\n{\n  char *p;\n  p = (char*)PGROUNDUP((uint64)pa_start);\n#ifndef LAB_PGTBL\n  for(; p + PGSIZE &lt;= (char*)pa_end; p += PGSIZE)\n    kfree(p);\n#else\n  int superpg_num = 10;\n  // 计算超级页的起始地址，从 pa_end 向下对齐到超级页边界\n  char *superp = (char*)SUPERPGROUNDUP((uint64)pa_end - superpg_num * SUPERPGSIZE);\n  // 先释放普通页面部分\n  for(; p + PGSIZE &lt;= superp; p += PGSIZE)\n    kfree(p);\n   // 再释放超级页部分\n  for(; superp + SUPERPGSIZE &lt;= (char*)pa_end; superp += SUPERPGSIZE)\n    superfree(superp);\n#endif\n}\n\n#ifdef LAB_PGTBL\n// 超级页释放函数\nvoid\nsuperfree(void *pa)\n{\n  struct run *r;\n  // 参数验证：确保 pa 对齐到超级页大小且在合法内存范围内\n  if(((uint64)pa % SUPERPGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP)\n    panic(\"superfree\"); \n  \n  memset(pa, 1, SUPERPGSIZE);\n  r = (struct run*)pa;\n  //加锁\n  acquire(&amp;kmem.lock);\n  r-&gt;next = kmem.superfreelist;\n  // 将超级页插入空闲链表头部\n  kmem.superfreelist = r;\n  //解锁\n  release(&amp;kmem.lock);\n}\n\n// 超级页分配函数\nvoid *\nsuperalloc(void)\n{\n  struct run *r;\n  acquire(&amp;kmem.lock);\n  // 从空闲链表中取出一个超级页\n  r = kmem.superfreelist; \n  if(r)\n    kmem.superfreelist = r-&gt;next;\n  release(&amp;kmem.lock);\n  if(r)\n    memset((char*)r, 5, SUPERPGSIZE);\n   // 返回分配的超级页地址\n  return (void*)r;\n}\n#endif\n</code></pre>\n<p>​\t2、<code>kalloc.h</code>当中，我们给普通页分配内存时用到了<code>PGROUNDUP</code>，于是超级页的内存分配也需要类似的内容。我们顺腾摸瓜找到<code>riscv.h</code>，在里面仿照<code>PGROUNDUP</code>和<code>PGROUNDDOWN</code>，新增<code>SUPERPGROUNDUP</code>和<code>SUPERPGROUNDDOWN</code>。</p>\n<pre><code class=\"language-c\">#define SUPERPGROUNDUP(sz)  (((sz)+SUPERPGSIZE-1) &amp; ~(SUPERPGSIZE-1))\n#define SUPERPGROUNDDOWN(a) (((a)) &amp; ~(SUPERPGSIZE-1)) \n</code></pre>\n<p>​\t3、在<code>defs.h</code>中添加下刚才的新增的声明。</p>\n<pre><code class=\"language-c\">void *          superalloc(void);\nvoid            superfree(void *pa);\npte_t *         superwalk(pagetable_t, uint64, int, int *);\n</code></pre>\n<p>​\t<strong>接下来的内容都在kernel/vm.c当中实现</strong>。</p>\n<p>​\t4、添加<code>uvmalloc</code>函数。</p>\n<pre><code class=\"language-c\">uint64\nuvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)\n{\n  char *mem;\n  uint64 a;\n  int sz;\n\n  if(newsz &lt; oldsz)\n    return oldsz;\n\n  oldsz = PGROUNDUP(oldsz);\n  for(a = oldsz; a &lt; newsz; a += sz){\n    sz = PGSIZE;\n#ifdef LAB_PGTBL\n    //判断当前大小是否满足使用超级页的开销\n    if (newsz - a &gt;= SUPERPGSIZE &amp;&amp; a % SUPERPGSIZE == 0) {\n      //更新大小为超级页方便接下来的递增\n      sz = SUPERPGSIZE;\n      //分配超级页大小的物理内存\n      mem = superalloc();\n    } else\n#endif\n    mem = kalloc();\n    if(mem == 0){\n      uvmdealloc(pagetable, a, oldsz);\n      return 0;\n    }\n#ifndef LAB_SYSCALL\n    memset(mem, 0, sz);\n#endif\n    //给分配的页添加映射\n    if(mappages(pagetable, a, sz, (uint64)mem, PTE_R|PTE_U|xperm) != 0){\n#ifdef LAB_PGTBL\n       // 如果分配的是超级页大小内存则释放超级页内存\n      if(sz == SUPERPGSIZE)\n        superfree(mem);\n      else\n#endif\n      kfree(mem);\n      uvmdealloc(pagetable, a, oldsz);\n      return 0;\n    }\n  }\n  return newsz;\n}\n</code></pre>\n<p>​\t5、修改<code>mappages</code>函数。</p>\n<pre><code class=\"language-c\">int\nmappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)\n{\n  uint64 a, last;\n  pte_t *pte;\n\n  if((va % PGSIZE) != 0)\n    panic(\"mappages: va not aligned\");\n\n  if((size % PGSIZE) != 0)\n    panic(\"mappages: size not aligned\");\n\n  if(size == 0)\n    panic(\"mappages: size\");\n  \n  a = va;\n  last = va + size - PGSIZE;\n  for (;;) {\n#ifdef LAB_PGTBL\n    int use_superpage = 0; // 用于标识是否使用超级页面映射\n    // 判断是否可以使用超级页面映射\n    if ((a % SUPERPGSIZE) == 0 &amp;&amp; (a + SUPERPGSIZE &lt;= last + PGSIZE) &amp;&amp; (perm &amp; PTE_U)) {\n      use_superpage = 1; // 更改标识\n    }\n    // 如果是超级页则设置l为1，代表接下来在superwalk当中到1层后停止\n    // 传统的walk会走到level0，之后返回pte（页表项地址）\n    // 而改进过的superwalk可以被人为操控停到指定的层级。\n    //  层级从高到底为：2 1 0\n    if (use_superpage) {\n      int l = 1;\n      if ((pte = superwalk(pagetable, a, 1, &amp;l)) == 0)\n        return -1;\n    } else {\n      if ((pte = walk(pagetable, a, 1)) == 0)\n        return -1;\n    }\n#else \n    // 如果不能使用超级页面映射 就用普通页\n    if ((pte = walk(pagetable, a, 1)) == 0)\n      return -1;\n#endif\n    // 检查PTE是否已经被标记为有效\n    if (*pte &amp; PTE_V)\n      panic(\"mappages: remap\");\n    // 如果有效则将物理地址转换为PTE格式 并加上权限位和有效位\n    // 这里就是添加映射的核心\n    *pte = PA2PTE(pa) | perm | PTE_V; \n#ifdef LAB_PGTBL\n    //如果使用超级页\n    if (use_superpage) { \n      // 则检查是否已经映射到最后一个超级页面\n      if (a + SUPERPGSIZE == last + PGSIZE) \n        break;\n      // 更新起始地址和物理地址\n      a += SUPERPGSIZE;\n      pa += SUPERPGSIZE;\n    } else {\n      if (a == last)\n        break;\n      a += PGSIZE;\n      pa += PGSIZE;\n    }\n#else \n    //不使用超级页，则每次自增一个普通页的大小\n    if (a == last)\n      break;\n    a += PGSIZE;\n    pa += PGSIZE;\n#endif\n    }\n    return 0;\n}\n</code></pre>\n<p>​\t6、修改<code>uvmunmap</code>函数。</p>\n<p><strong>注意：</strong>在释放整个页时涉及三种情况（页只会在其对应的虚拟地址被完全 unmap 时被释放）：</p>\n<ol>\n<li>第一种情况是释放普通页，已知每个普通页都是4KB，并且xv6的三级页表的最低级也都是4KB，所以直接释放即可。</li>\n<li>第二种情况是释放超级页（整块释放），超级页的大小为2M，因为xv6的三级页表的第二层是表示超级页的层级（如果第二层 PTE 是 leaf 并且覆盖 2MB，则是超级页），此时在地址对其的情况下并且释放该页不会对其它的页造成影响则直接释放即可。</li>\n<li>第三种情况是释放超级页（非整块释放，可能比一块小也可能比一块大），众所周知，在操作系统当中，一个 leaf PTE 要么映射整个 4KB 页框，要么映射整个 2MB 页框，不能只映射其中一部分。所以，当我们释放内存时，被释放的内存大小没有超过一个超级页 或者 超过了一个超级页，那么就必然导致有一个页的完整性被打破，从而违反操作系统对单个页完整性的规定。所以我们要将哪些被破坏了完整性的超级页进行降级操作，使得其降为普通页。降级的过程就是再开辟新的普通页，然后将原来超级页的内容（正常存在无需释放的内容）复制到新的普通页，之后我们删除/释放原来的超级页。</li>\n</ol>\n<p><strong>问：</strong>为什么2MB的超级页的完整性被破坏后就必须降级为4KB的普通页？<br />\n<strong>答：</strong>xv6支持3级页表，普通页（4KB）已经是最小的硬件映射粒度，不能再细分，所以不存在“普通页被部分破坏后再降级”的问题。</p>\n<pre><code class=\"language-c\">void\nuvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)\n{\n  uint64 a;\n  pte_t *pte;\n  int sz;\n\n  if((va % PGSIZE) != 0)\n    panic(\"uvmunmap: not aligned\");\n\n  for(a = va; a &lt; va + npages*PGSIZE; a += sz){\n    sz = PGSIZE;\n#ifdef LAB_PGTBL\n    int l = 0; // 标志变量 用于确定是超级页还是普通页。\n    int flag = 0; // 标记是否已经处理过超级页\n    if((pte = superwalk(pagetable, a, 0, &amp;l)) == 0)\n      panic(\"uvmunmap: walk\");\n#else\n    if((pte = walk(pagetable, a, 0)) == 0)\n      panic(\"uvmunmap: walk\");\n#endif\n    if((*pte &amp; PTE_V) == 0) {\n      printf(\"va=%ld pte=%ld\\n\", a, *pte);\n      panic(\"uvmunmap: not mapped\");\n    }\n    if(PTE_FLAGS(*pte) == PTE_V)\n      panic(\"uvmunmap: not a leaf\");\n    \n    /*下面开始解除页面映射*/\n    if(do_free){\n      uint64 pa = PTE2PA(*pte); //  从页表项中提取物理地址\n#ifdef LAB_PGTBL\n      if(l == 1) { \n        // 如果是超级页则获取权限\n        int perm = *pte &amp; 0xFFF;\n        // 然后清空页表项\n        *pte = 0; \n        // 设置标志\n        flag = 1; \n        // 更新大小为超级页大小\n        sz = SUPERPGSIZE;\n        // 这里是上述的第三种情况，如果虚拟地址未对齐到超级页\n        if(a % SUPERPGSIZE != 0){ \n          // 对齐到超级页边界\n          for(uint64 i = SUPERPGROUNDDOWN(a); i &lt; va; i += PGSIZE) {\n            char *mem = kalloc(); // 分配新的物理页面\n            if(mem == 0)\n              panic(\"uvmunmap: kalloc\");\n            mappages(pagetable, i, PGSIZE, (uint64)mem, perm); // 将新分配的页面映射到虚拟地址空间\n            memmove(mem, (char*)pa + i - SUPERPGROUNDDOWN(a), PGSIZE); // 将数据从超级页复制到新分配的页面\n          }\n          a = SUPERPGROUNDUP(a); // 更新虚拟地址\n          sz = 0; // 更新大小\n        }\n        superfree((void*)pa); // 释放超级页\n      } else\n#endif\n      // 如果是普通页\n      kfree((void*)pa); // 释放普通页\n    }\n#ifdef LAB_PGTBL\n    if(flag == 0) // 避免使用超级页时候被重复清除\n#endif\n    *pte = 0;\n  }\n}\n</code></pre>\n<p>​\t7、仿照<code>walk</code>添加<code>superwalk。</code></p>\n<pre><code class=\"language-c\">#ifdef LAB_PGTBL\n// 参数l用于指定页表的起始级别\npte_t *\nsuperwalk(pagetable_t pagetable, uint64 va, int alloc, int *l)\n{\n  if(va &gt;= MAXVA)\n    panic(\"superwalk\");\n\n  for(int level = 2; level &gt; *l; level--) {\n    // 获取当前层的页表项地址\n    pte_t *pte = &amp;pagetable[PX(level, va)]; \n    if(*pte &amp; PTE_V) { \n      // 如果页表项有效,将其转为物理地址\n      pagetable = (pagetable_t)PTE2PA(*pte); \n      if(PTE_LEAF(*pte)) { \n        // 如果是叶节点代表找到想要的了，更新页表级别，返回页表地址。\n        *l = level;\n        return pte;\n      }\n    } else {\n      //页表项无效则尝试分配，分配失败返回0\n      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0) \n        return 0;\n      // 初始化新分配的页表\n      memset(pagetable, 0, PGSIZE);\n      // 更新页表项为有效\n      *pte = PA2PTE(pagetable) | PTE_V; \n    }\n  }\n  // 返回目标页表项地址\n  return &amp;pagetable[PX(*l, va)]; \n}\n#endif\n</code></pre>\n<p>​\t8、添加<code>uvmcopy</code>函数。</p>\n<pre><code class=\"language-c\">int\nuvmcopy(pagetable_t old, pagetable_t new, uint64 sz)\n{\n  pte_t *pte;\n  uint64 pa, i;\n  uint flags;\n  char *mem;\n  int szinc;\n\n  for(i = 0; i &lt; sz; i += szinc){\n    szinc = PGSIZE;\n#ifdef LAB_PGTBL\n    int l = 0; // 标志变量 用于确定是普通页还是超级页\n    if((pte = superwalk(old, i, 0, &amp;l)) == 0)\n      // 如果是超级页l=1,普通页l=0\n      panic(\"uvmcopy: pte should exist\");\n#else\n    if((pte = walk(old, i, 0)) == 0)\n      panic(\"uvmcopy: pte should exist\");\n#endif\n    if((*pte &amp; PTE_V) == 0)\n      panic(\"uvmcopy: page not present\");\n    pa = PTE2PA(*pte);\n    flags = PTE_FLAGS(*pte);\n#ifdef LAB_PGTBL\n    if(l == 1) { \n      // 如果是超级页则将地址增量设置为超级页的大小\n      szinc = SUPERPGSIZE;\n      // 分配超级页大小的内存\n      if((mem = superalloc()) == 0)\n        goto err;\n      // 将超级页大小的物理内存从旧地址复制到新分配的内存地址（父进程的数据负责给子进程）\n      memmove(mem, (char*)pa, SUPERPGSIZE); \n      // 将超级页大小的新内存映射到新页表的虚拟地址\n      if(mappages(new, i, SUPERPGSIZE, (uint64)mem, flags) != 0){ \n        // 释放之前分配的超级页内存\n        superfree(mem); \n        goto err;\n      }\n    } else { \n      // 如果是普通页\n#endif\n    if((mem = kalloc()) == 0)\n      goto err;\n    memmove(mem, (char*)pa, PGSIZE);\n    if(mappages(new, i, PGSIZE, (uint64)mem, flags) != 0){\n      kfree(mem);\n      goto err;\n    }\n#ifdef LAB_PGTBL\n    }\n#endif\n  }\n  return 0;\n\n err:\n  uvmunmap(new, 0, i / PGSIZE, 1);\n  return -1;\n}\n</code></pre>\n<h2 id=\"写在后面\">写在后面</h2>\n<p>​\t这一lab，尤其是最后的<strong>用户页表lab</strong>确实非常难，一开始花费了好长时间都没做出来，好在网络上有很多大佬对该lab进行了讲解和提供了成品代码，使得本人在后续的研究中才得以明白该lab的底层逻辑。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-09 21:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaobai1523\">小白同学_C</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}