{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "两天烧掉200美元！我AI大模型网关终于支持了Claude模型",
      "link": "https://www.cnblogs.com/sdcb/p/19508169/20260120-chats-190",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sdcb/p/19508169/20260120-chats-190\" id=\"cb_post_title_url\" title=\"发布于 2026-01-21 08:45\">\n    <span>两天烧掉200美元！我AI大模型网关终于支持了Claude模型</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这是一个关于“真金白银”的开发故事。</p>\n<p>Chats 1.9.0 发布于 2025 年 11 月 27 日，距离上一个版本发布仅过去了不到一个月。但对 Chats 来说，这却是一个里程碑式的版本：<strong>我们不仅全面支持了 Anthropic（Claude）模型，还顺带把 .NET 10 给升了，甚至还搞出了一套能在 Chats 里“借壳”跑 Claude Code 的 API 兼容层。</strong></p>\n<p>而在这一切的背后，是一张让我“肉痛”的 Azure 账单。</p>\n<hr />\n<h2 id=\"一切源于微软与-anthropic-联手\">一切源于“微软与 Anthropic 联手”</h2>\n<p>事情要从 2025 年 11 月 19 日说起。那天，微软与 Anthropic 达成合作，宣布将在 Azure 平台上提供 Anthropic 的 Claude 大模型服务。这意味着开发者和企业用户可以通过 Azure 云服务访问 Claude 模型。</p>\n<p>作为一名微软 MVP，我本以为 Claude 模型对 MVP 额度来说是可以使用的，因为根据以往的经验，如果没有资格使用某项服务，通常会直接在控制台里提示“无权限”或“无法启用”，而不是直接允许使用然后产生高额费用，但我大意了。</p>\n<p>因此我第一时间就想到了将 Claude 模型集成到我自己的项目中——<strong>Sdcb Chats</strong>。</p>\n<p>当时为了确保 Anthropic Messages API 工作正常且稳定，我做了大量的测试。为了验证兼容性，我甚至还“站起来蹬”，直接接入了 Anthropic 官方的命令行工具 <code>Claude Code</code> 来跑 Opus 模型。</p>\n<p>结果……短短 2 天时间，我在 Azure 上跑 Claude 模型的 API 调用费用就高达 <strong>192.95 美元</strong>！</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120172700464-1622754976.png\" /></p>\n<p>当时看到账单整个人都是蒙的。不过好在“氪金”没有白费，最终我成功将 Claude 模型完美集成到了 Sdcb Chats 中。现在，大家可以在 Chats 中愉快地使用 Claude 模型了！</p>\n<hr />\n<h2 id=\"190-的核心anthropic-全面落地\">1.9.0 的核心：Anthropic 全面落地</h2>\n<p>在 1.9.0 之前，Chats 对 Claude 的支持只能说是“能用”，因为并没有原生支持 Anthropic Messages API，需要通过 OpenAI 兼容接口转译——而 OpenAI Chat Completions 兼容接口并不支持 Extended Thinking。但这一次，我是<strong>原生支持</strong>。</p>\n<h3 id=\"原生-httpclient-实现与-thinking-支持\">原生 HttpClient 实现与 Thinking 支持</h3>\n<p>为了追求极致的性能和可控性，我重写了 Chats 的底层调用逻辑。</p>\n<p>原本 Anthropic 提供了<a href=\"https://github.com/anthropics/anthropic-sdk-csharp\" rel=\"noopener nofollow\" target=\"_blank\">Anthropic C# API Library</a>，我一开始使用了这个 SDK，但发现里面的验证逻辑有点太过分了，连模型名称都要验证（报错说：<code>AnthropicInvalidDataException: Data did not match any variant of RawMessageStreamEvent</code>）。在我开发的时候，Opus 模型还没发布 4.5 版本，我使用这个 SDK 连自家的 Claude 4.5 Opus 都报错，笑死！更不要提用这个 SDK 连接国产的 MiniMax/GLM/DeepSeek v3.2 了，这种操作非常“Anthropic”（这个问题直到 <strong>2026-01-14</strong> 发布的 <code>12.2.0</code> 版本中才解决！）。</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120214334386-1499186789.png\" /></p>\n<p>因此我的 <code>Git</code> 提交记录里可以看到，我一开始是准备走 SDK 做 Anthropic 支持的，但最终又放弃了，转而在代码中用原生 <code>HttpClient</code> 手撸了一个近 1000 行的 <code>AnthropicChatService</code>。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120172700992-1302091122.png\" /></p>\n<p>这意味着什么？</p>\n<ol>\n<li>\n<p><strong>完整支持 Thinking（思维链）</strong>：Claude 模型的 Thinking 可以像在官方网页版那样展示，支持流式输出，“思考”与“回答”分离。为此我在数据库中专门新增了 <code>StepContentThink</code> 表，用于独立存储思维内容。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120172701332-89257932.png\" /></p>\n</li>\n<li>\n<p><strong>Signature（签名）验证</strong>：Chats 现在能正确处理和存储 Claude 的思维签名（Signature），确保证据链完整。</p>\n</li>\n<li>\n<p><strong>Vision Link 优化</strong>：默认使用 URL 而非 Base64 传图，大幅节省带宽和 Token。</p>\n</li>\n</ol>\n<p>同时，我还引入了 <code>MaxThinkingBudget</code>（模型级）和 <code>ThinkingBudget</code>（会话级）配置，防止你的 Token 再像我一样“不知不觉”地烧完。</p>\n<hr />\n<h2 id=\"借壳上位anthropic-messages-api-兼容\">“借壳上位”：Anthropic Messages API 兼容</h2>\n<p>这一条可能比原生支持更硬核。</p>\n<p>Chats 1.9.0 <strong>反向实现</strong>了 Anthropic 的官方 API 协议（<code>/v1/messages</code>）。我在 <code>src/BE/web/Controllers/Api/AnthropicCompatible/AnthropicMessagesController.cs</code> 中完整复刻了 Anthropic 的接口规范。这意味着 Chats 不仅是一个客户端，它本身也变成了一个<strong>标准的 Anthropic API 服务端</strong>。</p>\n<p><strong>为什么要这么做？</strong></p>\n<p>因为现在有很多优秀的工具（比如 Cursor、Claude Code、各种 AI 插件）只支持 Anthropic 原生协议。为了支持官方的 <code>claude-code</code> 命令行工具（如动图，后台可以实时追踪 Claude Code 的使用信息）：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120172701746-1289382319.avif\" /></p>\n<p>我甚至专门修复了 System Prompt 的解析逻辑，同时，我还引入了 <code>MaxThinkingBudget</code>（模型级）和 <code>ThinkingBudget</code>（会话级）配置，以及 <strong>Prompt Cache Token</strong> 的计费支持（Commit <code>85a1c2a6</code>），防止你的 Token 再像我一样“不知不觉”地烧完。</p>\n<p>既然 Chats 已经变成了一个强大的 API 网关，那么配套的开发者体验必须跟上。</p>\n<p>1.9.0 新增了 <strong>Build</strong> 模块，包含三个核心页面：</p>\n<ul>\n<li><strong>API Keys</strong>：更安全的密钥管理，支持过期时间、备注，还能看到密钥掩码。</li>\n<li><strong>Docs</strong>：一站式文档，列出了所有兼容 OpenAI 和 Anthropic 的 API 端点（支持一键复制）。</li>\n<li><strong>Usage</strong>：按 API Key 维度的用量统计，谁用了多少 Token，一目了然。</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120172702273-280531674.png\" /></p>\n<hr />\n<h2 id=\"视觉生产力openai-图像-api-与-net-10\">视觉生产力：OpenAI 图像 API 与 .NET 10</h2>\n<p>除了大语言模型，1.9.0 还补齐了视觉能力：</p>\n<ul>\n<li>实现了标准的 OpenAI 图像生成（<code>/v1/images/generations</code>）和编辑（<code>/v1/images/edits</code>）API。</li>\n<li>配合前端的 <strong>ChatInput 动画优化</strong>，现在的图片生成体验更加流畅。</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260120172702911-1941831639.png\" /></p>\n<p>最后，作为一个 .NET 信仰粉，Chats 1.9.0 已经<strong>全线升级到了 .NET 10</strong>。虽然用户感知不强，但这带来了更好的性能和更现代的底层设施，为未来的长远发展打下了基础。</p>\n<hr />\n<h2 id=\"结语为了更自由的-ai-网关\">结语：为了更自由的 AI 网关</h2>\n<p>从 1.7 的 MCP 落地，到 1.9 的 Anthropic 原生支持与 API 兼容，Chats 正在一步步从一个“聊天网页”进化成一个<strong>真正通用的 AI 基础设施</strong>。</p>\n<p>那个 200 美元的账单虽然让人心痛，但它换来了 Chats 对 Claude 的完美支持，以及那段“为了测试而疯狂调用”的激情时光，我觉得——值了！</p>\n<p>另外相信我，我做了一切努力尝试联系微软和 Anthropic，争取把那 200 美元的费用给要回来，但他们互相推诿，也没说是用户自己的行为或者平台责任，只是互相说这是对方（微软/Anthropic）的责任，所以最后也就不了了之了。</p>\n<p>感谢阅读！喜欢的朋友请给我的 GitHub 项目一个 star：<a href=\"https://github.com/sdcb/chats\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats</a></p>\n<p>这是完整的更新日志：<a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md</a></p>\n<p>有什么想法也欢迎在评论区留言交流，也欢迎加入我的新创建的微信群：</p>\n<p><img alt=\"\" src=\"https://io.starworks.cc:88/cv-public/2026/chats-wxg-qr.png\" /></p>\n<p>如果你更习惯用 QQ 的话，也可以加入 Chats QQ 群：498452653，我们一起探索更多 AI 技术硬核玩法。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-21 08:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sdcb\">.NET骚操作</a>&nbsp;\n阅读(<span id=\"post_view_count\">86</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "为什么 IO 流通常只能被读取一次",
      "link": "https://www.cnblogs.com/yanshajiuzhou/p/19508716",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yanshajiuzhou/p/19508716\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 20:22\">\n    <span>为什么 IO 流通常只能被读取一次</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        IO 流只能读取一次，是 精心设计的，贴合操作系统文件 / 网络 IO 的 \"顺序消费\"&nbsp;特性，保持和底层系统的一致性。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>今天我们来一起探讨下&nbsp;为什么<strong> IO 流</strong>通常只能被读取一次？</p>\n<p>我为什么会发出这个疑问呢？是因为我研究Web开发中的一个问题时，HTTP请求体在 <strong>Filter（过滤器）</strong>处被读取了之后，在 Controller（控制层）就读不到值了，使用 @RequestBody 的时候。</p>\n<p>无论是字节流（InputStream / OutputStream）还是字符流（Reader / Writer），所有基于流的读取操作都会维护一个 <strong>\"位置指针\"</strong>。</p>\n<ul>\n<li>初始状态下，指针指向流的起始位置<strong>（position = 0）</strong>；</li>\n<li>每次调用 <strong>read() / read(byte[]) / read(char[])</strong> 等读取方法时，指针会向后移动对应字节数；</li>\n<li>当指针移动到流的末尾（没有更多数据），read() 方法会返回 <strong>-1</strong>，表示流读取完毕；</li>\n<li>指针移动后不会自动回退，也无法反向移动（除非流显式支持重置），因此再次读取只能得到 <strong>-1</strong>。</li>\n</ul>\n<p><strong>类比</strong>：<strong>IO 流</strong>的读取过程，就像用 <strong>磁带播放器听磁带</strong> —— 磁头（对应流的位置指针）从磁带开头（指针 0）开始移动，每读一个字节 / 字符，磁头就往后走一步；当磁头走到磁带末尾，再继续播放（读取）就只能听到 \"沙沙声\"（流返回 <strong>-1</strong>），并且磁头不会自动回到开头。</p>\n<p>当然，<strong>不是所有流都只能读一次</strong>，<strong>基于内存的流</strong>（如 <strong>ByteArrayInputStream / CharArrayReader</strong>）支持重置指针，因为它们的数据源是内存中的数组（<strong>数据不会消失</strong>），可以通过 <strong>mark()</strong> 和 <strong>reset()&nbsp;</strong>方法将指针 <strong>恢复</strong> 到标记位置。</p>\n<p>需要注意：</p>\n<ul>\n<li>调用 <strong>reset()&nbsp;</strong>前必须先调用 <strong>mark(int readlimit)</strong>；</li>\n<li>不是所有流都支持 <strong>mark() / reset()</strong>，可以通过 <strong>inputStream.markSupported()</strong> 来进行判断。</li>\n</ul>\n<p><strong>使用 mark() 和 reset() 方法：</strong></p>\n<pre class=\"language-java highlighter-hljs\"><code>// 仅适用于支持mark的流\npublic void processWithMark(InputStream input) throws IOException {\n    if (!input.markSupported()) {\n        throw new IOException(\"Mark not supported\");\n    }\n    \n    // 标记当前位置，参数100表示最多可回退100字节\n    input.mark(100);\n    \n    // 第一次读取\n    byte[] firstRead = new byte[50];\n    input.read(firstRead);\n    System.out.println(\"First read: \" + new String(firstRead));\n    \n    // 重置到标记位置\n    input.reset();\n    \n    // 第二次读取（相同内容）\n    byte[] secondRead = new byte[50];\n    input.read(secondRead);\n    System.out.println(\"Second read: \" + new String(secondRead));\n}</code></pre>\n<p>使用 <strong>包装类</strong> 解决上文我们提到的&nbsp;<strong>HTTP请求体多次读取 </strong>的问题：</p>\n<pre class=\"language-java highlighter-hljs\"><code>public class MyRequestWrapper extends HttpServletRequestWrapper {\n    private final byte[] body; // 缓存请求体的字节数组\n\n    public MyRequestWrapper(HttpServletRequest request) throws IOException {\n        super(request);\n        // 关键步骤：在构造时一次性读取并存储原始请求流\n        body = StreamUtils.copyToByteArray(request.getInputStream());\n    }\n\n    // 提供一个便捷方法，用于在过滤器中获取请求体内容（例如记录日志）\n    // 使用时，直接调用 getBodyString() 即可\n    public String getBodyString() throws UnsupportedEncodingException {\n        return new String(body, this.getCharacterEncoding());\n    }\n\n    @Override\n    public ServletInputStream getInputStream() throws IOException {\n        // 每次调用都返回一个基于缓存数据的新流\n        ByteArrayInputStream bais = new ByteArrayInputStream(body);\n        return new ServletInputStream() {\n            @Override\n            public int read() {\n                return bais.read();\n            }\n\n            @Override\n            public boolean isFinished() {\n                return bais.available() == 0;\n            }\n\n            @Override\n            public boolean isReady() {\n                return true;\n            }\n\n            @Override\n            public void setReadListener(ReadListener readListener) {\n                // 无需实现\n            }\n        };\n    }\n\n    @Override\n    public BufferedReader getReader() throws IOException {\n        return new BufferedReader(new InputStreamReader(this.getInputStream(), this.getCharacterEncoding()));\n    }\n}</code></pre>\n<p>然后在 <strong>过滤器</strong> 处包装请求：</p>\n<pre class=\"language-java highlighter-hljs\"><code>@Slf4j\n@Configuration\npublic class RequestCachingFilterConfig {\n\n    @Bean\n    public FilterRegistrationBean requestCachingFilter() {\n        FilterRegistrationBean registrationBean = new FilterRegistrationBean();\n\n        // 核心：创建过滤器，包装请求为 ContentCachingRequestWrapper\n        registrationBean.setFilter(new OncePerRequestFilter() {\n            @Override\n            protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain)\n                    throws ServletException, IOException {\n                // 1. 仅包装 HTTP 请求（排除 WebSocket 等）\n                if (request instanceof HttpServletRequest &amp;&amp; !(request instanceof ContentCachingRequestWrapper)) {\n                    log.info(\"==========进入requestCachingFilter========\");\n                    // 2. 包装请求（自动缓存请求体）\n                    MyRequestWrapper wrappedRequest = new MyRequestWrapper(request);\n                    filterChain.doFilter(wrappedRequest, response); // 传递包装后的请求\n                } else {\n                    filterChain.doFilter(request, response); // 无需包装，直接放行\n                }\n            }\n        });\n\n        // 3. 配置拦截所有请求（可根据需求调整 URL 模式）\n        registrationBean.addUrlPatterns(\"/*\");\n        registrationBean.setOrder(1); // 优先级最高，确保先于其他过滤器执行\n        registrationBean.setName(\"requestCachingFilter\");\n        return registrationBean;\n    }\n}</code></pre>\n<p><strong>IO 流</strong>只能读取一次，是 <strong>精心设计的</strong>，贴合操作系统文件 / 网络 IO 的 <strong>\"顺序消费\"</strong>&nbsp;特性，保持和底层系统的一致性。</p>\n<p style=\"text-align: right;\"><span style=\"color: rgba(53, 152, 219, 1);\">外在形式越简单的东西，智慧含量越高，因为它已经不再依赖形式，必须依靠智慧。-- 烟沙九洲</span></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 20:22</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yanshajiuzhou\">烟沙九洲</a>&nbsp;\n阅读(<span id=\"post_view_count\">51</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "告别 throw exception！为什么 Result<T> 才是业务逻辑的正确选择",
      "link": "https://www.cnblogs.com/diamondhusky/p/19508626",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/diamondhusky/p/19508626\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 19:40\">\n    <span>告别 throw exception！为什么 Result&lt;T&gt; 才是业务逻辑的正确选择</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p></p><div class=\"toc\"><div class=\"toc-container-header\">目录</div><ul><li><a href=\"#引言一个普遍存在的坏味道\" rel=\"noopener nofollow\">引言：一个普遍存在的“坏味道”</a></li><li><a href=\"#一异常的原罪--我们一直在滥用它\" rel=\"noopener nofollow\">一、异常的“原罪” —— 我们一直在滥用它</a><ul><li><a href=\"#11-异常的本质是什么\" rel=\"noopener nofollow\">1.1 异常的本质是什么？</a></li><li><a href=\"#12-业务逻辑--异常情况\" rel=\"noopener nofollow\">1.2 业务逻辑 ≠ 异常情况</a></li></ul></li><li><a href=\"#二result业务逻辑的优雅降级\" rel=\"noopener nofollow\">二、Result——业务逻辑的\"优雅降级\"</a><ul><li><a href=\"#21-什么是result\" rel=\"noopener nofollow\">2.1 什么是Result？</a></li><li><a href=\"#22-如何正确使用result\" rel=\"noopener nofollow\">2.2 如何正确使用Result？</a></li></ul></li><li><a href=\"#三性能对决--几近碾压的性能差距\" rel=\"noopener nofollow\">三、性能对决 —— 几近碾压的性能差距</a><ul><li><a href=\"#31-部分测试代码\" rel=\"noopener nofollow\">3.1 部分测试代码</a></li><li><a href=\"#32-测试结果触目惊心\" rel=\"noopener nofollow\">3.2 测试结果：触目惊心</a></li><li><a href=\"#33-并发场景下性能差距依旧不忍直视\" rel=\"noopener nofollow\">3.3 并发场景下：性能差距依旧不忍直视</a></li></ul></li><li><a href=\"#四为什么异常在业务场景下如此昂贵\" rel=\"noopener nofollow\">四、为什么异常在业务场景下如此\"昂贵\"？</a><ul><li><a href=\"#41-clr异常机制的底层原理\" rel=\"noopener nofollow\">4.1 CLR异常机制的底层原理</a><ul><li><a href=\"#411-异常对象的构造过程\" rel=\"noopener nofollow\">4.1.1 异常对象的构造过程</a></li><li><a href=\"#412-堆栈跟踪的真实代价\" rel=\"noopener nofollow\">4.1.2 堆栈跟踪的真实代价</a></li><li><a href=\"#413-jit和aot编译对异常的影响\" rel=\"noopener nofollow\">4.1.3 JIT和AOT编译对异常的影响</a></li></ul></li><li><a href=\"#42-异常处理的内存分配细节\" rel=\"noopener nofollow\">4.2 异常处理的内存分配细节</a><ul><li><a href=\"#421-异常对象的内存布局\" rel=\"noopener nofollow\">4.2.1 异常对象的内存布局</a></li><li><a href=\"#422-gc的影响\" rel=\"noopener nofollow\">4.2.2 GC的影响</a></li></ul></li><li><a href=\"#43-cpu级别的性能影响\" rel=\"noopener nofollow\">4.3 CPU级别的性能影响</a><ul><li><a href=\"#431-现代cpu的异常处理开销\" rel=\"noopener nofollow\">4.3.1 现代CPU的异常处理开销</a></li><li><a href=\"#432-对比正常返回和异常返回\" rel=\"noopener nofollow\">4.3.2 对比正常返回和异常返回</a></li></ul></li><li><a href=\"#44-对比其他编程语言\" rel=\"noopener nofollow\">4.4 对比其他编程语言</a><ul><li><a href=\"#441-java的异常机制\" rel=\"noopener nofollow\">4.4.1 Java的异常机制</a></li><li><a href=\"#442-go的错误处理哲学\" rel=\"noopener nofollow\">4.4.2 Go的错误处理哲学</a></li><li><a href=\"#443-rust的result类型\" rel=\"noopener nofollow\">4.4.3 Rust的Result类型</a></li><li><a href=\"#444-c的错误处理\" rel=\"noopener nofollow\">4.4.4 C++的错误处理</a></li></ul></li><li><a href=\"#45-net-core的改进和局限\" rel=\"noopener nofollow\">4.5 .NET Core的改进和局限</a></li></ul></li><li><a href=\"#五result的进阶优势\" rel=\"noopener nofollow\">五、Result的进阶优势</a><ul><li><a href=\"#51-丰富的错误信息\" rel=\"noopener nofollow\">5.1 丰富的错误信息</a></li><li><a href=\"#52-函数式编程支持\" rel=\"noopener nofollow\">5.2 函数式编程支持</a></li><li><a href=\"#53-更好的api设计\" rel=\"noopener nofollow\">5.3 更好的API设计</a></li></ul></li><li><a href=\"#六-result模式的一些弊端\" rel=\"noopener nofollow\">六、 Result模式的一些弊端</a><ul><li><a href=\"#61-if地狱问题条件判断泛滥\" rel=\"noopener nofollow\">6.1 \"if地狱\"问题（条件判断泛滥）</a></li><li><a href=\"#62-值类型structvs-引用类型class的两难选择\" rel=\"noopener nofollow\">6.2 值类型（struct）vs 引用类型（class）的两难选择</a></li><li><a href=\"#63-异步编程的复杂性\" rel=\"noopener nofollow\">6.3 异步编程的复杂性</a></li><li><a href=\"#64-类型系统冗长\" rel=\"noopener nofollow\">6.4 类型系统冗长</a></li><li><a href=\"#65-其他问题\" rel=\"noopener nofollow\">6.5 其他问题</a></li></ul></li><li><a href=\"#七常见问题与答疑\" rel=\"noopener nofollow\">七、常见问题与答疑</a></li><li><a href=\"#八总结\" rel=\"noopener nofollow\">八、总结</a></li></ul></div><p></p>\n<h1 id=\"引言一个普遍存在的坏味道\">引言：一个普遍存在的“坏味道”</h1>\n<p>如果你在C#项目中看到这样的代码，一定不会感到陌生：</p>\n<pre><code class=\"language-csharp\">public User Login(string username, string password)\n{\n    var user = FindUser(username);\n    if (user == null)\n        throw new Exception(\"用户不存在\");  // ❌ 熟悉的模式\n    \n    if (!VerifyPassword(user, password))\n        throw new Exception(\"密码错误\");    // ❌ 另一个熟悉的模式\n    \n    return user;\n}\n</code></pre>\n<p>这种使用异常来处理业务逻辑的做法，几乎成了C#开发的“标准范式”。<br />\n可是，<strong>从来如此，便是对的么？</strong></p>\n<h1 id=\"一异常的原罪--我们一直在滥用它\">一、异常的“原罪” —— 我们一直在滥用它</h1>\n<h2 id=\"11-异常的本质是什么\">1.1 异常的本质是什么？</h2>\n<p>首先，我们要明白C#语言里的异常（Exception）的设计初衷：</p>\n<pre><code class=\"language-csharp\">// 这些才是异常真正的使用场景：\npublic void ReadFile(string path)\n{\n    if (string.IsNullOrEmpty(path))\n        throw new ArgumentNullException(nameof(path));  // ✅ 参数检查\n    \n    if (!File.Exists(path))\n        throw new FileNotFoundException($\"文件不存在: {path}\");  // ✅ 系统错误\n    \n    // 尝试读取文件，可能抛出IOException等\n    var content = File.ReadAllText(path);\n}\n</code></pre>\n<p>异常是为真正的\"异常情况\"设计的，比如：</p>\n<ul>\n<li>系统资源不可用（文件不存在、数据库连接失败）</li>\n<li>程序状态异常（空指针、数组越界）</li>\n<li>参数验证失败（前置条件不满足）</li>\n</ul>\n<h2 id=\"12-业务逻辑--异常情况\">1.2 业务逻辑 ≠ 异常情况</h2>\n<p>业务错误（用户不存在、密码错误、余额不足）是<strong>可预见的正常业务流程</strong>，而不是异常情况。<br />\n把业务错误用异常处理，就像：</p>\n<ul>\n<li>用\"地震警报\"来处理\"家里没米了\"</li>\n<li>用\"消防车\"来运送\"快递包裹\"</li>\n<li>用\"手术室\"来处理\"感冒发烧\"</li>\n</ul>\n<p>这是对异常机制的严重滥用！</p>\n<h1 id=\"二result业务逻辑的优雅降级\">二、Result——业务逻辑的\"优雅降级\"</h1>\n<h2 id=\"21-什么是result\">2.1 什么是Result？</h2>\n<p>一个简单，具备基本功能的Result类如下：</p>\n<pre><code class=\"language-csharp\">public class Result&lt;T&gt;\n{\n    public bool Success { get; }\n    public T? Value { get; }\n    public string? Error { get; }\n    \n    private Result(T value) { Success = true; Value = value; Error = null; }\n    private Result(string error) { Success = false; Value = default; Error = error; }\n    \n    public static Result&lt;T&gt; Ok(T value) =&gt; new(value);\n    public static Result&lt;T&gt; Fail(string error) =&gt; new(error);\n}\n</code></pre>\n<h2 id=\"22-如何正确使用result\">2.2 如何正确使用Result？</h2>\n<pre><code class=\"language-csharp\">public Result&lt;User&gt; Login(string username, string password)\n{\n    if (string.IsNullOrEmpty(username))\n        return Result&lt;User&gt;.Fail(\"用户名不能为空\");  // ✅ 明确返回业务错误\n    \n    if (string.IsNullOrEmpty(password))\n        return Result&lt;User&gt;.Fail(\"密码不能为空\");    // ✅ 明确返回业务错误\n    \n    var user = FindUser(username);\n    if (user == null)\n        return Result&lt;User&gt;.Fail(\"用户不存在\");      // ✅ 明确返回业务错误\n    \n    if (!VerifyPassword(user, password))\n        return Result&lt;User&gt;.Fail(\"密码错误\");        // ✅ 明确返回业务错误\n    \n    return Result&lt;User&gt;.Ok(user);                   // ✅ 明确返回成功\n}\n</code></pre>\n<h1 id=\"三性能对决--几近碾压的性能差距\">三、性能对决 —— 几近碾压的性能差距</h1>\n<h2 id=\"31-部分测试代码\">3.1 部分测试代码</h2>\n<p>项目环境：</p>\n<pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk\"&gt;\n\t&lt;PropertyGroup&gt;\n\t\t&lt;OutputType&gt;Exe&lt;/OutputType&gt;\n\t\t&lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n\t\t&lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n\t\t&lt;Nullable&gt;enable&lt;/Nullable&gt;\n\t\t&lt;LangVersion&gt;latest&lt;/LangVersion&gt;\n\t&lt;/PropertyGroup&gt;\n&lt;/Project&gt;\n</code></pre>\n<p>部分测试代码：</p>\n<pre><code class=\"language-csharp\"> public class LoginService\n {\n     private readonly Dictionary&lt;string, User&gt; _users = new()\n     {\n         [\"valid_user\"] = new User { Id = 1, Username = \"valid_user\" }\n     };\n\n    \n     public User LoginWithException(string username, string password)\n     {\n         if (!_users.TryGetValue(username, out var user))\n             throw new BusinessException(\"用户不存在\");\n\n         if (password != \"correct_password\")\n             throw new BusinessException(\"密码错误\");\n\n         return user;\n     }\n\n    \n     public Result&lt;User&gt; LoginWithResult(string username, string password)\n     {\n         if (!_users.TryGetValue(username, out var user))\n             return Result&lt;User&gt;.Fail(\"用户不存在\");\n\n         if (password != \"correct_password\")\n             return Result&lt;User&gt;.Fail(\"密码错误\");\n\n         return Result&lt;User&gt;.Ok(user);\n     }\n }\n</code></pre>\n<pre><code class=\"language-csharp\">public class PerformanceTester\n{\n    private readonly LoginService _service = new();\n    private readonly Random _random = new(42);\n\n    public void RunAllTests(int iterations = 1000000)\n    {\n        Console.WriteLine($\"性能对比测试 - 迭代次数: {iterations:N0}\");\n        Console.WriteLine(\"=\".PadRight(60, '='));\n\n        // 测试1：成功路径（正常情况）\n        TestSuccessPath(iterations);\n\n        // 测试2：失败路径（错误情况）\n        TestErrorPath(iterations);\n\n        // 测试3：混合路径（30%成功率）\n        TestMixedPath(iterations, 0.3);\n    }\n\n    private void TestSuccessPath(int iterations)\n    {\n        Console.WriteLine(\"\\n测试1：成功路径（100%成功）\");\n\n        // 异常方式\n        var exceptionTime = Measure(() =&gt;\n        {\n            try\n            {\n                _service.LoginWithException(\"valid_user\", \"correct_password\");\n            }\n            catch\n            {\n                // 不应该发生\n            }\n        }, iterations, \"异常方式\");\n\n        // Result方式\n        var resultTime = Measure(() =&gt;\n        {\n            var result = _service.LoginWithResult(\"valid_user\", \"correct_password\");\n            if (!result.Success)\n            {\n                // 不应该发生\n            }\n        }, iterations, \"Result方式\");\n\n        PrintComparison(exceptionTime, resultTime);\n    }\n\n    private void TestErrorPath(int iterations)\n    {\n        Console.WriteLine(\"\\n测试2：失败路径（100%失败）\");\n\n        // 异常方式\n        var exceptionTime = Measure(() =&gt;\n        {\n            try\n            {\n                _service.LoginWithException(\"invalid_user\", \"wrong_password\");\n            }\n            catch (BusinessException)\n            {\n                // 预期异常\n            }\n        }, iterations, \"异常方式\");\n\n        // Result方式\n        var resultTime = Measure(() =&gt;\n        {\n            var result = _service.LoginWithResult(\"invalid_user\", \"wrong_password\");\n            if (result.Success)\n            {\n                // 不应该发生\n            }\n        }, iterations, \"Result方式\");\n\n        PrintComparison(exceptionTime, resultTime);\n    }\n\n    private void TestMixedPath(int iterations, double successRate)\n    {\n        Console.WriteLine($\"\\n测试3：混合路径（{successRate:P0}成功率）\");\n\n        // 准备测试数据\n        var testData = new (string user, string pwd, bool shouldSucceed)[iterations];\n        for (int i = 0; i &lt; iterations; i++)\n        {\n            testData[i] = _random.NextDouble() &lt; successRate\n                ? (\"valid_user\", \"correct_password\", true)   // 成功\n                : (\"invalid_user\", \"wrong_password\", false); // 失败\n        }\n\n        // 异常方式\n        var exceptionTime = MeasureMixed(testData, true, \"异常方式\");\n\n        // Result方式\n        var resultTime = MeasureMixed(testData, false, \"Result方式\");\n\n        PrintComparison(exceptionTime, resultTime);\n    }\n\n    private static long Measure(Action action, int iterations, string testName)\n    {\n        // 预热\n        for (int i = 0; i &lt; 1000; i++) action();\n\n        GC.Collect();\n        GC.WaitForPendingFinalizers();\n        GC.Collect();\n\n        var sw = Stopwatch.StartNew();\n        for (int i = 0; i &lt; iterations; i++)\n        {\n            action();\n        }\n        sw.Stop();\n\n        var opsPerSecond = iterations / (sw.ElapsedMilliseconds / 1000.0);\n        Console.WriteLine($\"  {testName}: {sw.ElapsedMilliseconds,8}ms ({opsPerSecond,12:N0} ops/s)\");\n\n        return sw.ElapsedMilliseconds;\n    }\n\n    private long MeasureMixed(\n        (string user, string pwd, bool shouldSucceed)[] testData,\n        bool useException,\n        string testName)\n    {\n        // 预热\n        for (int i = 0; i &lt; Math.Min(1000, testData.Length); i++)\n        {\n            var (user, pwd, _) = testData[i];\n            if (useException)\n            {\n                try\n                {\n                    _service.LoginWithException(user, pwd);\n                }\n                catch { }\n            }\n            else\n            {\n                _service.LoginWithResult(user, pwd);\n            }\n        }\n\n        GC.Collect();\n        GC.WaitForPendingFinalizers();\n        GC.Collect();\n\n        var sw = Stopwatch.StartNew();\n\n        if (useException)\n        {\n            for (int i = 0; i &lt; testData.Length; i++)\n            {\n                var (user, pwd, _) = testData[i];\n                try\n                {\n                    _service.LoginWithException(user, pwd);\n                }\n                catch { }\n            }\n        }\n        else\n        {\n            for (int i = 0; i &lt; testData.Length; i++)\n            {\n                var (user, pwd, _) = testData[i];\n                _service.LoginWithResult(user, pwd);\n            }\n        }\n\n        sw.Stop();\n\n        var opsPerSecond = testData.Length / (sw.ElapsedMilliseconds / 1000.0);\n        Console.WriteLine($\"  {testName}: {sw.ElapsedMilliseconds,8}ms ({opsPerSecond,12:N0} ops/s)\");\n\n        return sw.ElapsedMilliseconds;\n    }\n\n    private static void PrintComparison(long exceptionTime, long resultTime)\n    {\n        var speedup = exceptionTime / (double)resultTime;\n        var improvement = (exceptionTime - resultTime) * 100.0 / exceptionTime;\n\n        if (speedup &gt; 1)\n        {\n            Console.WriteLine($\"Result比Exception快 {speedup:F1}x，性能提升 {improvement:F1}%\");\n        }\n        else\n        {\n            Console.WriteLine($\"差异不大: {speedup:F2}x\");\n        }\n    }\n}\n</code></pre>\n<h2 id=\"32-测试结果触目惊心\">3.2 测试结果：触目惊心</h2>\n<p>先上图，看测试结果(<strong>基于RELEASE模式编译</strong>)：</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h2 id=\"33-并发场景下性能差距依旧不忍直视\">3.3 并发场景下：性能差距依旧不忍直视</h2>\n<p>并发测试核心代码：</p>\n<pre><code class=\"language-csharp\">/// &lt;summary&gt;\n/// // 并发测试结果类\n/// &lt;/summary&gt;\npublic class ConcurrentTestResult\n{\n    public int Concurrency { get; set; }\n    public long ExceptionTime { get; set; }\n    public long ResultTime { get; set; }\n    public double ExceptionOpsPerSecond { get; set; }\n    public double ResultOpsPerSecond { get; set; }\n}\n\n\n/// &lt;summary&gt;\n/// 并发测试器\n/// &lt;/summary&gt;\npublic class ConcurrentPerformanceTester\n{\n    private readonly LoginService _service = new();\n    private readonly Random _random = new(42);\n\n    private readonly double _errorRate = 0.3;\n\n\n    public async Task RunConcurrentTests(int totalIterations = 1000000)\n    {\n        Console.WriteLine(\"\\n并发性能测试 - 总迭代次数: {0:N0} - 错误率：{1:P0}\", totalIterations, _errorRate);\n        Console.WriteLine(\"=\".PadRight(60, '='));\n\n        var concurrencyLevels = new[] { 4, 8, 16, 32, 64, 128, 256 };\n\n        foreach (var concurrency in concurrencyLevels)\n        {\n            Console.WriteLine($\"\\n并发数: {concurrency}\");\n\n            // 预热\n            await Warmup(concurrency);\n\n            // 异常方式并发测试（30%错误率模拟真实场景）\n            var exceptionTime = await RunConcurrentExceptionTest(\n                concurrency,\n                totalIterations,\n                errorRate: _errorRate\n            );\n\n            // Result方式并发测试\n            var resultTime = await RunConcurrentResultTest(\n                concurrency,\n                totalIterations,\n                errorRate: _errorRate\n            );\n\n            var exceptionOps = totalIterations / (exceptionTime / 1000.0);\n            var resultOps = totalIterations / (resultTime / 1000.0);\n            var speedup = exceptionTime / (double)resultTime;\n\n            Console.WriteLine($\"  异常: {exceptionTime,5}ms ({exceptionOps,8:N0} ops/s)\");\n            Console.WriteLine($\"  Result: {resultTime,5}ms ({resultOps,8:N0} ops/s)\");\n            Console.WriteLine($\"  Result快 {speedup:F1}x\");\n        }\n    }\n\n    /// &lt;summary&gt;\n    /// 并发异常测试\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"concurrency\"&gt;&lt;/param&gt;\n    /// &lt;param name=\"totalIterations\"&gt;&lt;/param&gt;\n    /// &lt;param name=\"errorRate\"&gt;&lt;/param&gt;\n    /// &lt;returns&gt;&lt;/returns&gt;\n    private async Task&lt;long&gt; RunConcurrentExceptionTest(\n        int concurrency,\n        int totalIterations,\n        double errorRate)\n    {\n        var iterationsPerTask = totalIterations / concurrency;\n        var tasks = new Task[concurrency];\n\n        var sw = Stopwatch.StartNew();\n\n        for (int i = 0; i &lt; concurrency; i++)\n        {\n            // 每个任务使用自己的随机实例，避免竞争\n            var taskRandom = new Random(_random.Next());\n            tasks[i] = Task.Run(() =&gt;\n            {\n                for (int j = 0; j &lt; iterationsPerTask; j++)\n                {\n                    // 为每次迭代生成测试数据，避免索引问题\n                    var (user, pwd) = GenerateTestDataForIteration(taskRandom, errorRate);\n                    try\n                    {\n                        _service.LoginWithException(user, pwd);\n                    }\n                    catch (BusinessException)\n                    {\n                        // 预期异常\n                    }\n                }\n            });\n        }\n\n        await Task.WhenAll(tasks);\n        sw.Stop();\n\n        return sw.ElapsedMilliseconds;\n    }\n\n    /// &lt;summary&gt;\n    /// 并发Result测试\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"concurrency\"&gt;&lt;/param&gt;\n    /// &lt;param name=\"totalIterations\"&gt;&lt;/param&gt;\n    /// &lt;param name=\"errorRate\"&gt;&lt;/param&gt;\n    /// &lt;returns&gt;&lt;/returns&gt;\n    private async Task&lt;long&gt; RunConcurrentResultTest(\n        int concurrency,\n        int totalIterations,\n        double errorRate)\n    {\n        var iterationsPerTask = totalIterations / concurrency;\n        var tasks = new Task[concurrency];\n\n        var sw = Stopwatch.StartNew();\n\n        for (int i = 0; i &lt; concurrency; i++)\n        {\n            var taskRandom = new Random(_random.Next());\n            tasks[i] = Task.Run(() =&gt;\n            {\n                for (int j = 0; j &lt; iterationsPerTask; j++)\n                {\n                    var (user, pwd) = GenerateTestDataForIteration(taskRandom, errorRate);\n                    var result = _service.LoginWithResult(user, pwd);\n                    // 不需要额外处理，Result已经包含了成功/失败状态\n                }\n            });\n        }\n\n        await Task.WhenAll(tasks);\n        sw.Stop();\n\n        return sw.ElapsedMilliseconds;\n    }\n\n    /// &lt;summary&gt;\n    /// 为单次迭代生成测试数据\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"random\"&gt;&lt;/param&gt;\n    /// &lt;param name=\"errorRate\"&gt;&lt;/param&gt;\n    /// &lt;returns&gt;&lt;/returns&gt;\n    private static (string user, string pwd) GenerateTestDataForIteration(Random random, double errorRate)\n    {\n        if (random.NextDouble() &gt; errorRate)\n        {\n            // 成功案例\n            return (\"valid_user\", \"correct_password\");\n        }\n        else\n        {\n            // 失败案例 - 随机选择失败类型\n            if (random.Next(2) == 0)\n                return (\"invalid_user\", \"any_password\");  // 用户不存在\n            else\n                return (\"valid_user\", \"wrong_password\");   // 密码错误\n        }\n    }\n\n    /// &lt;summary&gt;\n    /// 预热\n    /// &lt;/summary&gt;\n    /// &lt;param name=\"concurrency\"&gt;&lt;/param&gt;\n    /// &lt;param name=\"errorRate\"&gt;&lt;/param&gt;\n    /// &lt;returns&gt;&lt;/returns&gt;\n    private async Task Warmup(int concurrency, double errorRate = 0.3)\n    {\n        var warmupTasks = new Task[Math.Min(concurrency, 4)];\n\n        for (int i = 0; i &lt; warmupTasks.Length; i++)\n        {\n            warmupTasks[i] = Task.Run(() =&gt;\n            {\n                var taskRandom = new Random(_random.Next());\n                for (int j = 0; j &lt; 100; j++)\n                {\n                    var (user, pwd) = GenerateTestDataForIteration(taskRandom, errorRate);\n                    try\n                    {\n                        _service.LoginWithException(user, pwd);\n                    }\n                    catch { }\n\n                    _service.LoginWithResult(user, pwd);\n                }\n            });\n        }\n\n        await Task.WhenAll(warmupTasks);\n        GC.Collect();\n        GC.WaitForPendingFinalizers();\n        GC.Collect();\n    }\n}\n</code></pre>\n<p>并发测试结果：<br />\n<img alt=\"image\" class=\"lazyload\" /></p>\n<p>上述测试可能并不严谨和权威，但是暴露出来的问题还是非常明显的：</p>\n<ul>\n<li>在100%失败场景下，Result比Exception快了差不多200倍</li>\n<li>接近实际业务场景的30%错误率情况下，Result比Exception也快了160多倍</li>\n<li>并发场景下，性能差距也有接近百倍</li>\n</ul>\n<h1 id=\"四为什么异常在业务场景下如此昂贵\">四、为什么异常在业务场景下如此\"昂贵\"？</h1>\n<h2 id=\"41-clr异常机制的底层原理\">4.1 CLR异常机制的底层原理</h2>\n<h3 id=\"411-异常对象的构造过程\">4.1.1 异常对象的构造过程</h3>\n<p>当我们在C#中抛出异常时，看似简单的一行代码，背后却发生了大量复杂的操作：</p>\n<pre><code class=\"language-csharp\">throw new BusinessException(\"用户不存在\");\n</code></pre>\n<p>这个操作的实际执行流程如下：</p>\n<pre><code class=\"language-csharp\">// 伪代码展示异常构造的实际开销\npublic static Exception CreateException(string message)\n{\n    // 1. 堆分配：异常对象本身（至少40-64字节）\n    var exception = RuntimeHelpers.AllocateException(typeof(BusinessException));\n    \n    // 2. 字段初始化（调用构造函数链）\n    exception._message = message;  // 字符串分配\n    exception._stackTrace = null;\n    exception._innerException = null;\n    exception._helpURL = null;\n    exception._source = null;\n    \n    // 3. 捕获调用堆栈（最昂贵的部分！）\n    exception.CaptureStackTrace();\n    \n    return exception;\n}\n\nprivate void CaptureStackTrace()\n{\n    // 4. 获取当前线程的调用堆栈\n    var frames = new StackFrame[64];  // 分配数组\n    var frameCount = StackTraceHelper.CaptureStackTrace(\n        frames, 0,  // 起始位置\n        false,      // 是否需要文件信息\n        null);      // 异常对象本身\n    \n    // 5. 格式化成字符串（可能涉及大量字符串操作）\n    this._stackTrace = FormatStackTrace(frames, frameCount);\n}\n</code></pre>\n<h3 id=\"412-堆栈跟踪的真实代价\">4.1.2 堆栈跟踪的真实代价</h3>\n<p>让我们深入看看<code>CaptureStackTrace</code>到底做了什么：</p>\n<pre><code class=\"language-csharp\">// Windows上的实际实现（简化）\ninternal static unsafe int CaptureStackTrace(\n    StackFrame[] frames, \n    int startIndex,\n    bool needFileInfo,\n    Exception exception)\n{\n    // 1. 调用系统API获取当前线程的上下文\n    CONTEXT context;\n    RtlCaptureContext(&amp;context);\n    \n    // 2. 遍历调用堆栈（性能杀手！）\n    STACKFRAME64 stackFrame = new STACKFRAME64();\n    while (StackWalk64(\n        IMAGE_FILE_MACHINE_AMD64,\n        GetCurrentProcess(),\n        GetCurrentThread(),\n        &amp;stackFrame,\n        &amp;context,\n        null,\n        SymFunctionTableAccess64,\n        SymGetModuleBase64,\n        null))\n    {\n        // 3. 解析每个栈帧的信息\n        frames[frameCount++] = new StackFrame(\n            stackFrame.AddrPC.Offset,\n            needFileInfo ? GetSourceInfo(stackFrame) : null);\n        \n        if (frameCount &gt;= frames.Length) break;\n    }\n    \n    return frameCount;\n}\n</code></pre>\n<p>关键点：</p>\n<ul>\n<li>每个throw操作都要遍历整个调用堆栈</li>\n<li>堆栈遍历涉及多个系统调用和内存访问</li>\n<li>需要将内存地址解析为方法名、文件名、行号等</li>\n<li>在Release模式下，JIT优化可能会影响堆栈信息</li>\n</ul>\n<h3 id=\"413-jit和aot编译对异常的影响\">4.1.3 JIT和AOT编译对异常的影响</h3>\n<pre><code class=\"language-csharp\">// 考虑以下代码\npublic int Process(int value)\n{\n    try\n    {\n        return ProcessValue(value);  // 可能抛出异常\n    }\n    catch (Exception)\n    {\n        return -1;\n    }\n}\n\n// JIT编译器需要生成：\n// 1. 正常执行路径的代码\n// 2. 异常处理表（EH表）\n// 3. 堆栈展开代码\n// 4. finally块执行逻辑（如果有）\n</code></pre>\n<p>EH表的结构：</p>\n<pre><code>Method Exception Handling Table:\nStart   Length  Handler Type    Class           Filter\n0x0000  0x0020  0x0030  CLAUSE  Exception       null\n</code></pre>\n<p>每个try-catch块都会在方法的元数据中添加EH表条目，增加方法大小和加载时间。</p>\n<h2 id=\"42-异常处理的内存分配细节\">4.2 异常处理的内存分配细节</h2>\n<h3 id=\"421-异常对象的内存布局\">4.2.1 异常对象的内存布局</h3>\n<pre><code class=\"language-csharp\">// Exception类的简化内存布局\nclass Exception\n{\n    // 对象头（8-16字节）\n    MethodTable* _methodTable;  // 8字节\n    // 同步块索引（可选）\n    \n    // 实例字段\n    string _message;           // 8字节（引用）\n    IDictionary _data;         // 8字节（通常为null）\n    Exception _innerException; // 8字节\n    string _helpURL;          // 8字节\n    string _source;           // 8字节\n    string _stackTrace;       // 8字节（字符串，实际分配更大）\n    object _stackTraceString; // 8字节（可能不同格式）\n    object _remoteStackTrace; // 8字节\n    int _remoteStackIndex;    // 4字节\n    int _HResult;             // 4字节\n    \n    // 总共：至少80字节（64位系统）\n    // 加上字符串内容：可能数百到数千字节\n}\n</code></pre>\n<h3 id=\"422-gc的影响\">4.2.2 GC的影响</h3>\n<pre><code class=\"language-csharp\">// 高频抛出异常会显著影响GC\npublic void TestExceptionGC()\n{\n    var list = new List&lt;Exception&gt;();\n    \n    for (int i = 0; i &lt; 10000; i++)\n    {\n        try\n        {\n            throw new Exception($\"Error {i}\");\n        }\n        catch (Exception ex)\n        {\n            list.Add(ex);  // 大量对象进入第0代堆\n        }\n    }\n}\n\n</code></pre>\n<p>上述代码会导致:</p>\n<ul>\n<li>触发频繁的Gen0 GC</li>\n<li>如果ex被长时间引用，可能进入Gen1/Gen2</li>\n<li>增加GC暂停时间</li>\n<li>降低缓存局部性</li>\n</ul>\n<h2 id=\"43-cpu级别的性能影响\">4.3 CPU级别的性能影响</h2>\n<h3 id=\"431-现代cpu的异常处理开销\">4.3.1 现代CPU的异常处理开销</h3>\n<pre><code class=\"language-assembly\">; x64汇编层面的异常处理\n; 正常路径：\nprocess_value:\n    mov eax, [rcx]      ; 加载值\n    add eax, 100        ; 计算\n    ret                 ; 返回\n    \n; 异常路径：\nthrow_exception:\n    ; 1. 保存所有寄存器到堆栈\n    push rbx\n    push rbp\n    push r12\n    push r13\n    push r14\n    push r15\n    sub rsp, 28h        ; 分配堆栈空间\n    \n    ; 2. 调用异常构造函数\n    call Exception..ctor\n    \n    ; 3. 设置SEH（结构化异常处理）\n    mov [rsp+20h], rcx  ; 保存异常对象\n    call __CxxThrowException@8\n    \n    ; 4. 清理堆栈\n    add rsp, 28h\n    pop r15\n    pop r14\n    pop r13\n    pop r12\n    pop rbp\n    pop rbx\n</code></pre>\n<p>CPU层面的问题:</p>\n<ul>\n<li><strong>分支预测失败</strong>：异常路径很少执行，CPU分支预测器难以优化</li>\n<li><strong>缓存失效</strong>：异常处理代码通常不在指令缓存中</li>\n<li><strong>流水线停顿</strong>：异常处理需要保存/恢复大量寄存器状态</li>\n<li><strong>内存访问模式差</strong>：EH表查找导致随机内存访问</li>\n</ul>\n<h3 id=\"432-对比正常返回和异常返回\">4.3.2 对比正常返回和异常返回</h3>\n<pre><code class=\"language-csharp\">// Result&lt;T&gt;的正常返回路径\nreturn Result&lt;User&gt;.Fail(\"用户不存在\");\n// 汇编：\n; 1. 构造Result对象（可能在栈上）\n; 2. 设置Success=false\n; 3. 设置Error字段\n; 4. 返回（普通ret指令）\n\n// 异常返回路径\nthrow new BusinessException(\"用户不存在\");\n// 汇编：\n; 1. 堆分配异常对象\n; 2. 捕获堆栈跟踪\n; 3. 设置SEH帧\n; 4. 调用kernel32!RaiseException\n; 5. 堆栈展开\n; 6. 查找catch块\n; 7. 执行catch块代码\n</code></pre>\n<h2 id=\"44-对比其他编程语言\">4.4 对比其他编程语言</h2>\n<h3 id=\"441-java的异常机制\">4.4.1 Java的异常机制</h3>\n<pre><code class=\"language-java\">// Java的异常使用看起来和C#相似\npublic User login(String username, String password) \n    throws UserNotFoundException, InvalidPasswordException\n{\n    User user = findUser(username);\n    if (user == null) {\n        throw new UserNotFoundException(\"用户不存在\");\n    }\n    if (!verifyPassword(user, password)) {\n        throw new InvalidPasswordException(\"密码错误\");\n    }\n    return user;\n}\n</code></pre>\n<p>Java异常的特点：<br />\n1.检查型异常（Checked Exception）：强制处理或声明<br />\n2.性能开销与C#类似：同样需要捕获堆栈跟踪<br />\n3.JVM的优化：HotSpot JVM有更成熟的异常优化:</p>\n<ul>\n<li>内联缓存（Inline Cache）</li>\n<li>栈上替换（On-Stack Replacement）</li>\n<li>但业务异常仍然昂贵</li>\n</ul>\n<p><strong>重要区别：</strong></p>\n<pre><code class=\"language-java\">// Java 14+引入了Records，但异常开销依旧\npublic record Result&lt;T&gt;(T value, String error) {\n    public boolean isSuccess() { return error == null; }\n}\n\n// Java社区也在转向Result模式，特别是响应式编程\npublic Mono&lt;User&gt; login(String username, String password) {\n    return Mono.fromCallable(() -&gt; findUser(username))\n        .switchIfEmpty(Mono.error(new UserNotFoundException()))\n        .filter(user -&gt; verifyPassword(user, password))\n        .switchIfEmpty(Mono.error(new InvalidPasswordException()));\n}\n</code></pre>\n<h3 id=\"442-go的错误处理哲学\">4.4.2 Go的错误处理哲学</h3>\n<pre><code class=\"language-go\">// Go的错误处理：显式返回错误\nfunc Login(username, password string) (*User, error) {\n    user, err := findUser(username)\n    if err != nil {\n        return nil, fmt.Errorf(\"查找用户失败: %w\", err)\n    }\n    \n    if !verifyPassword(user, password) {\n        return nil, errors.New(\"密码错误\")\n    }\n    \n    return user, nil\n}\n\n// 调用方必须显式处理错误\nuser, err := Login(\"test\", \"123\")\nif err != nil {\n    // 处理错误\n    switch {\n    case strings.Contains(err.Error(), \"密码错误\"):\n        // 特定处理\n    default:\n        // 通用处理\n    }\n}\n</code></pre>\n<p>Go的设计选择：</p>\n<ul>\n<li><strong>没有异常机制</strong>：只有错误返回值</li>\n<li><strong>错误是值（errors are values）</strong>：可以像普通值一样传递</li>\n<li><strong>强制显式处理</strong>：无法忽略错误（除非使用_）</li>\n<li><strong>零成本抽象</strong>：错误处理几乎没有运行时开销</li>\n</ul>\n<p>Go的错误性能优势:</p>\n<pre><code class=\"language-go\">// Go的errors.New实际上很简单\nfunc New(text string) error {\n    return &amp;errorString{text}\n}\n\ntype errorString struct {\n    s string\n}\n\nfunc (e *errorString) Error() string {\n    return e.s\n}\n\n// 没有堆栈跟踪，没有复杂构造\n// 只是一个包含字符串的结构体\n</code></pre>\n<h3 id=\"443-rust的result类型\">4.4.3 Rust的Result类型</h3>\n<pre><code class=\"language-rust\">// Rust的错误处理：基于枚举的Result\nfn login(username: &amp;str, password: &amp;str) -&gt; Result&lt;User, LoginError&gt; {\n    let user = find_user(username)?;  // ?操作符自动传播错误\n    \n    if !verify_password(&amp;user, password) {\n        return Err(LoginError::InvalidPassword);\n    }\n    \n    Ok(user)\n}\n\n// 错误类型定义\n#[derive(Debug)]\nenum LoginError {\n    UserNotFound,\n    InvalidPassword,\n    DatabaseError(DbError),\n}\n\n// 使用match处理\nmatch login(\"test\", \"123\") {\n    Ok(user) =&gt; println!(\"欢迎 {}\", user.name),\n    Err(LoginError::UserNotFound) =&gt; println!(\"用户不存在\"),\n    Err(LoginError::InvalidPassword) =&gt; println!(\"密码错误\"),\n    Err(e) =&gt; println!(\"其他错误: {:?}\", e),\n}\n</code></pre>\n<p>Rust的设计特点:</p>\n<ul>\n<li>零成本抽象：Result在运行时通常是普通枚举</li>\n<li>模式匹配：编译器确保所有情况都被处理</li>\n<li>错误传播运算符（?）：简化错误传播</li>\n<li>丰富的错误库：anyhow、thiserror等</li>\n</ul>\n<p>Rust的性能优势：</p>\n<pre><code>编译后的Result通常优化为：\n1.成功：存储User\n2.失败：存储错误码（通常是整数）\n3.没有堆分配，没有虚函数调用\n</code></pre>\n<h3 id=\"444-c的错误处理\">4.4.4 C++的错误处理</h3>\n<pre><code class=\"language-cpp\">// C++的多种错误处理方式\n\n// 1. 异常（类似C#/Java）\nUser login(const std::string&amp; username, const std::string&amp; password) {\n    auto user = find_user(username);\n    if (!user) {\n        throw UserNotFoundException(\"用户不存在\");\n    }\n    if (!verify_password(*user, password)) {\n        throw InvalidPasswordException(\"密码错误\");\n    }\n    return *user;\n}\n\n// 2. 错误码（传统方式）\nint login(const std::string&amp; username, \n          const std::string&amp; password,\n          User&amp; out_user) {\n    User user;\n    int err = find_user(username, user);\n    if (err != 0) return err;\n    \n    if (!verify_password(user, password)) {\n        return ERROR_INVALID_PASSWORD;\n    }\n    \n    out_user = user;\n    return 0;  // 成功\n}\n\n// 3. std::expected（C++23）\nstd::expected&lt;User, Error&gt; login(const std::string&amp; username,\n                                 const std::string&amp; password) {\n    auto user = find_user(username);\n    if (!user) {\n        return std::unexpected(Error::UserNotFound);\n    }\n    if (!verify_password(*user, password)) {\n        return std::unexpected(Error::InvalidPassword);\n    }\n    return *user;\n}\n</code></pre>\n<p>C++的选择：</p>\n<ul>\n<li>游戏和嵌入式：通常禁用异常，使用错误码</li>\n<li>性能敏感应用：避免异常，因为零开销原则</li>\n<li>现代C++：倾向于std::expected等类型安全方案</li>\n</ul>\n<h2 id=\"45-net-core的改进和局限\">4.5 .NET Core的改进和局限</h2>\n<p>.Net 8.0版本，官方团队针对异常处理这块进行了大幅的优化，包括预分配异常对象（PREallocated Exception）、延迟堆栈跟踪生成（Lazy Stack Trace）、堆栈跟踪缓存和复用、新的堆栈跟踪算法等多种手段，同时也对JIT和RunTime进行了针对性优化。但是目前来看，依旧还有很大的提升空间。<br />\n详情请见官方团队的博客：<a href=\"https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#exception-handling\" rel=\"noopener nofollow\" target=\"_blank\">https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-8/#exception-handling</a></p>\n<pre><code class=\"language-csharp\">// .NET 8.0 对参数异常的特殊优化\npublic void ValidateUser(string username, int age)\n{\n    // 这些调用在 .NET 8.0 中非常高效\n    ArgumentNullException.ThrowIfNull(username);\n    ArgumentOutOfRangeException.ThrowIfNegative(age);\n    ArgumentException.ThrowIfNullOrEmpty(username);\n    \n    // 但注意：业务异常不在此优化范围内！\n    if (!IsValidUsername(username))\n        throw new BusinessException(\"无效用户名\"); // 代价仍然昂贵\n}\n</code></pre>\n<h1 id=\"五result的进阶优势\">五、Result的进阶优势</h1>\n<h2 id=\"51-丰富的错误信息\">5.1 丰富的错误信息</h2>\n<pre><code class=\"language-csharp\">public class Result&lt;T&gt;\n{\n    public bool Success { get; }\n    public T? Value { get; }\n    public string ErrorCode { get; }    // 错误代码\n    public string ErrorMessage { get; } // 错误消息\n    public Dictionary&lt;string, object&gt; Metadata { get; } // 附加信息\n}\n\n// 使用：\nvar result = Login(\"test\", \"wrong\");\nif (!result.Success)\n{\n    switch (result.ErrorCode)\n    {\n        case \"USER_NOT_FOUND\":\n            // 用户不存在，跳转注册页面\n            break;\n        case \"INVALID_PASSWORD\":\n            // 密码错误，显示提示\n            break;\n        case \"ACCOUNT_LOCKED\":\n            // 账户锁定，显示锁定时间\n            var lockTime = result.Metadata[\"LockUntil\"];\n            break;\n    }\n}\n</code></pre>\n<h2 id=\"52-函数式编程支持\">5.2 函数式编程支持</h2>\n<pre><code class=\"language-csharp\">// Map - 转换成功的值\nvar userResult = GetUser(123);\nvar userName = userResult.Map(user =&gt; user.Name.ToUpper());\n\n// Bind - 链式操作\nvar orderResult = GetUser(123)\n    .Bind(user =&gt; GetOrder(user.CurrentOrderId))\n    .Bind(order =&gt; ValidateOrder(order));\n\n// Match - 模式匹配\nvar message = loginResult.Match(\n    success: user =&gt; $\"欢迎回来，{user.Name}!\",\n    failure: error =&gt; $\"登录失败: {error.Message}\"\n);\n</code></pre>\n<h2 id=\"53-更好的api设计\">5.3 更好的API设计</h2>\n<pre><code class=\"language-csharp\">// Web API中的使用\n[HttpPost(\"login\")]\npublic IActionResult Login([FromBody] LoginRequest request)\n{\n    var result = _authService.Login(request);\n    \n    return result.Match&lt;IActionResult&gt;(\n        success: user =&gt; Ok(new { success = true, user }),\n        failure: error =&gt; BadRequest(new { \n            success = false, \n            errorCode = error.Code,\n            message = error.Message \n        })\n    );\n}\n\n// 客户端获得清晰的响应：\n// 成功: { success: true, user: { ... } }\n// 失败: { success: false, errorCode: \"INVALID_PASSWORD\", message: \"密码错误\" }\n</code></pre>\n<h1 id=\"六-result模式的一些弊端\">六、 Result模式的一些弊端</h1>\n<h2 id=\"61-if地狱问题条件判断泛滥\">6.1 \"if地狱\"问题（条件判断泛滥）</h2>\n<p>最常被诟病的问题，就是代码中充斥大量的 if (!result.Success) 检查。</p>\n<pre><code class=\"language-csharp\">// \"if地狱\"的典型例子\npublic Result&lt;Order&gt; ProcessOrder(int userId, OrderRequest request)\n{\n    var userResult = GetUser(userId);\n    if (!userResult.Success)\n        return Result&lt;Order&gt;.Fail(userResult.Error);\n    \n    var validationResult = ValidateOrder(request);\n    if (!validationResult.Success)\n        return Result&lt;Order&gt;.Fail(validationResult.Error);\n    \n    var inventoryResult = CheckInventory(request.Items);\n    if (!inventoryResult.Success)  \n        return Result&lt;Order&gt;.Fail(inventoryResult.Error);\n    \n    var paymentResult = ProcessPayment(userResult.Value, request);\n    if (!paymentResult.Success)\n        return Result&lt;Order&gt;.Fail(paymentResult.Error);\n    \n    // ... 更多检查\n}\n</code></pre>\n<p>这个问题，使用函数式编程思想可以巧妙解决，这一块JAVA做的真心挺不错的。</p>\n<pre><code class=\"language-csharp\">// 使用 Railway-Oriented Programming\npublic Result&lt;Order&gt; ProcessOrder(int userId, OrderRequest request)\n{\n    return GetUser(userId)\n        .Bind(user =&gt; ValidateOrder(request)\n            .Bind(validated =&gt; CheckInventory(request.Items)\n                .Bind(inventory =&gt; ProcessPayment(user, request)\n                    .Map(payment =&gt; CreateOrder(user, validated, payment)))));\n}\n\n// 或者使用扩展方法\npublic Result&lt;Order&gt; ProcessOrder(int userId, OrderRequest request)\n{\n    return GetUser(userId)\n        .Then(user =&gt; ValidateOrder(request))\n        .Then(validated =&gt; CheckInventory(request.Items))\n        .Then(inventory =&gt; ProcessPayment(user, request))\n        .Map(payment =&gt; CreateOrder(user, validated, payment));\n}\n</code></pre>\n<h2 id=\"62-值类型structvs-引用类型class的两难选择\">6.2 值类型（struct）vs 引用类型（class）的两难选择</h2>\n<pre><code class=\"language-csharp\">public readonly struct Result&lt;T&gt;  // 值类型\n{\n    private readonly T? _value;\n    private readonly string? _error;\n    \n    // 问题1：T是引用类型时，struct存储的是引用\n    // 问题2：struct复制开销（如果T是大对象）\n    // 问题3：装箱/拆箱开销\n    // 问题4：不能为null，需要额外状态标记\n}\n\npublic class Result&lt;T&gt;  // 引用类型\n{\n    // 问题：每个Result都是堆分配，增加GC压力\n    // 即使成功情况也要分配对象\n}\n\n</code></pre>\n<p>折中方案：针对值类型和引用类型分别优化，针对通用的Result对象进行缓存和复用。</p>\n<pre><code class=\"language-csharp\">/// &lt;summary&gt;\n/// 结果基类\n/// &lt;/summary&gt;\n/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\npublic abstract class Result&lt;T&gt;\n{\n    /// &lt;summary&gt;\n    /// 是否成功\n    /// &lt;/summary&gt;\n    public abstract bool IsSuccess { get; }\n    /// &lt;summary&gt;\n    /// 具体返回值（成功时有效）\n    /// &lt;/summary&gt;\n    public abstract T? Value { get; }\n    /// &lt;summary&gt;\n    /// 错误码\n    /// &lt;/summary&gt;\n    public abstract string? ErrorCode { get; }\n    /// &lt;summary&gt;\n    /// 错误信息\n    /// &lt;/summary&gt;\n    public abstract string? ErrorMessage { get; }\n  \n    // 缓存单例成功（仅针对 default(T)）\n    private static readonly ConcurrentDictionary&lt;Type, Result&lt;T&gt;&gt; _successCache = new();\n    //只按 errorCode 缓存（避免按 message 无限增长）\n    private static readonly ConcurrentDictionary&lt;string, Result&lt;T&gt;&gt; _errorCache = new();  \n} \n\n/// &lt;summary&gt;\n/// 仅用于性能关键路径，不存储大对象\n/// &lt;/summary&gt;\n/// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\npublic readonly ref struct ValueResult&lt;T&gt; where T : struct\n{\n  //省略\n}\n\n /// &lt;summary&gt;\n /// 引用类型结果，仅用于性能关键路径\n /// &lt;/summary&gt;\n /// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n public readonly ref struct RefResult&lt;T&gt; where T : class\n{\n //省略\n}\n</code></pre>\n<h2 id=\"63-异步编程的复杂性\">6.3 异步编程的复杂性</h2>\n<p>在异步编程中，可能每个异步操作都需要处理Result，这也大大增加了代码复杂度，其实也属于上面说的“if 地狱”范畴。</p>\n<pre><code class=\"language-csharp\">public async Task&lt;Result&lt;User&gt;&gt; LoginAsync(string username, string password)\n{\n    // 每个异步操作都需要处理Result\n    var userResult = await FindUserAsync(username);\n    if (!userResult.Success)\n        return Result&lt;User&gt;.Fail(userResult.Error);\n    \n    var validationResult = await ValidatePasswordAsync(userResult.Value, password);\n    if (!validationResult.Success)\n        return Result&lt;User&gt;.Fail(validationResult.Error);\n    \n    return Result&lt;User&gt;.Ok(userResult.Value);\n}\n\n// 对比异常版本：\npublic async Task&lt;User&gt; LoginAsync(string username, string password)\n{\n    var user = await FindUserAsync(username);  // 抛异常则直接中断后续逻辑\n    await ValidatePasswordAsync(user, password); // 抛异常则直接中断后续逻辑\n    return user;\n}\n</code></pre>\n<h2 id=\"64-类型系统冗长\">6.4 类型系统冗长</h2>\n<p>每一个接口方法都要包裹Result,再加上异步的Task,分页请求结果模型PagedResult，再加上点其他东西，就会出现令人头皮发麻的泛型参数爆炸&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;。<br />\n下面的代码，是项目里面的真实代码</p>\n<pre><code class=\"language-csharp\">     /// &lt;summary&gt;\n    /// 员工业务服务接口\n    /// &lt;/summary&gt;\n    public interface IEmployeeService\n    {\n        Task&lt;Result&lt;long&gt;&gt; CreateAsync(CreateEmployeeDto dto);\n        Task&lt;Result&lt;EmployeeDto&gt;&gt; GetByIdAsync(long id);\n        Task&lt;Result&gt; UpdateAsync(UpdateEmployeeDto dto);\n        Task&lt;Result&gt; DeleteAsync(long id);\n        Task&lt;Result&lt;PagedResult&lt;EmployeeDto&gt;&gt;&gt; GetPageListAsync(EmployeePageListDto dto);\n        Task&lt;Result&lt;List&lt;EmployeeDto&gt;&gt;&gt; GetListAsync(string? keyword = null);\n        Task&lt;Result&lt;Dictionary&lt;string,long&gt;&gt;&gt; GetEmployeeAliases(List&lt;long&gt;? employeeIds = null, bool includeShowName = true);\n    }\n</code></pre>\n<h2 id=\"65-其他问题\">6.5 其他问题</h2>\n<p>当然，这种模式还有一些其他的问题，比如团队成员的接受度，团队学习成本，与现有代码/生态的兼容性，与第三方包的兼容性等，这里就不一一说明了。</p>\n<h1 id=\"七常见问题与答疑\">七、常见问题与答疑</h1>\n<p><strong>Q：异常不是更方便吗？一行代码就能中断流程</strong><br />\nA：方便不等于正确。goto语句也很\"方便\"，但现代编程中我们避免使用它。异常在业务逻辑中就是\"远程goto\"，破坏了代码的可读性和可维护性。</p>\n<p><strong>Q：Result需要更多的if判断，代码更冗长</strong></p>\n<pre><code class=\"language-csharp\">// 简洁的处理方式\nvar result = Login(\"test\", \"123\");\nif (!result.Success) return result;\n\n// 或者使用模式匹配\nvar message = result switch\n{\n    { Success: true, Value: var user } =&gt; $\"欢迎 {user.Name}\",\n    { Error: var error } =&gt; $\"错误: {error}\",\n    _ =&gt; \"未知状态\"\n};\n</code></pre>\n<p><strong>Q：我们的项目很小，性能影响不大</strong><br />\nA:即使不考虑性能，从代码质量和维护性角度，Result也是更好的选择。好的习惯应该从项目初期就开始培养。</p>\n<h1 id=\"八总结\">八、总结</h1>\n<p>Result 不是银弹，它有它适用的场景，也有相应的一些弊端。选择的关键不在于哪个\"更好\"，而在于哪个\"更适合\"当前的场景和约束。明智的工程师会根据具体情况做出平衡的选择。<br />\n适合使用 Result 的场景：</p>\n<ul>\n<li>高频失败的校验逻辑（表单验证、业务规则检查）</li>\n<li>需要明确错误分类的业务流程</li>\n<li>API边界（需要结构化错误响应）</li>\n<li>与外部系统交互（需要处理各种失败模式）</li>\n<li>需要组合的复杂业务逻辑</li>\n</ul>\n<p>仍然适合使用异常的场景：</p>\n<ul>\n<li>真正的系统故障（内存不足、数据库崩溃）</li>\n<li>程序状态异常（空引用、索引越界）</li>\n<li>不满足前置条件（无效参数）</li>\n<li>开发阶段的断言检查</li>\n<li>极低失败率的操作</li>\n</ul>\n<p>关键建议：</p>\n<ul>\n<li>不要全盘替换：Result和异常各有适用场景</li>\n<li>分层设计：不同架构层使用不同策略</li>\n<li>团队共识：建立明确的规范和边界</li>\n<li>渐进采用：从核心业务开始，逐步扩展</li>\n<li>监控反馈：通过日志和监控验证选择</li>\n</ul>\n<p>最终原则：</p>\n<ul>\n<li>异常：用于\"不应该发生\"的事情</li>\n<li>Result：用于\"可能发生但需要处理\"的事情</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 19:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/diamondhusky\">呆萌哈士奇</a>&nbsp;\n阅读(<span id=\"post_view_count\">156</span>)&nbsp;\n评论(<span id=\"post_comment_count\">4</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "干货满满：Redis 分布式锁必避的 8 大问题及解决方案",
      "link": "https://www.cnblogs.com/sun-10387834/p/19493006",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sun-10387834/p/19493006\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 19:23\">\n    <span>干货满满：Redis 分布式锁必避的 8 大问题及解决方案</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在分布式系统中，Redis 分布式锁虽能高效解决跨服务并发冲突，但实际落地时稍不注意就会踩坑——小到数据不一致，大到服务雪崩，这些问题多源于对 Redis 特性、分布式场景复杂性的考虑不周。之前开发电商库存和订单系统时，就因忽视了锁过期、脑裂等问题，先后出现过超卖、锁失效等故障。今天结合生产实战经验，梳理 Redis 实现分布式锁时最易遇到的 8 大问题，逐一拆解成因、表现及根治方案，帮大家避开这些“隐形炸弹”。</p>\n<p>先明确前提：分布式锁的核心是“互斥性”，但在分布式环境下，网络延迟、服务宕机、Redis 集群同步延迟等因素，都会破坏锁的稳定性。所有问题的本质，要么是“原子性缺失”，要么是“高可用考虑不足”，要么是“业务与锁机制不匹配”。</p>\n<h2 id=\"一核心问题及解决方案按踩坑频率排序\">一、核心问题及解决方案（按踩坑频率排序）</h2>\n<h3 id=\"问题-1误删他人持有锁最基础也最易犯的漏洞\">问题 1：误删他人持有锁——最基础也最易犯的漏洞</h3>\n<p><strong>成因</strong>：释放锁时未做身份校验，直接执行 DEL 命令删除键。典型场景：服务 A 持有锁后，业务逻辑耗时超过锁过期时间，锁被自动释放；服务 B 趁机加锁成功，此时服务 A 执行完业务，直接 DEL 锁就会误删服务 B 持有的锁，导致互斥性失效。</p>\n<p><strong>表现</strong>：多个服务实例同时持有同一把锁，操作同一资源，出现数据不一致（如超卖、重复订单）。</p>\n<p><strong>解决方案</strong>：加锁时存入全局唯一的随机值（如 UUID+线程 ID）作为 value，释放锁前先验证 value 是否与自身持有一致，一致才释放。关键是用 Lua 脚本保证“验证+删除”的原子性，避免验证后锁过期被他人持有。</p>\n<pre><code class=\"language-lua\">-- 安全释放锁的 Lua 脚本\nif redis.call('get', KEYS[1]) == ARGV[1] then\n    return redis.call('del', KEYS[1])\nelse\n    return 0\nend\n</code></pre>\n<p>注意：严禁拆分“验证”和“删除”为两步操作，否则仍存在并发漏洞。</p>\n<h3 id=\"问题-2锁过期提前释放业务未做完锁已失效\">问题 2：锁过期提前释放——业务未做完锁已失效</h3>\n<p><strong>成因</strong>：锁的过期时间设置过短，而业务逻辑执行耗时过长，导致锁在业务完成前就自动过期释放，其他服务可趁机加锁，引发并发冲突。比如锁设为 30 秒过期，但数据库复杂查询、第三方接口调用耗时 40 秒，就会出现锁提前失效。</p>\n<p><strong>表现</strong>：业务执行中锁被释放，多个服务同时操作资源，出现数据错误，且问题具有随机性（取决于业务耗时是否超过过期时间）。</p>\n<p><strong>解决方案</strong>：引入“锁续约（Watch Dog）”机制。服务成功加锁后，启动后台守护线程，每隔锁过期时间的 1/3 （如 10 秒）检查锁是否仍被自身持有，若持有则延长锁的过期时间（重置为 30 秒），直到业务完成主动释放锁。</p>\n<p>实际开发中无需手动实现，Redisson 框架内置 Watch Dog 机制，加锁后自动续约，彻底解决锁提前释放问题。</p>\n<h3 id=\"问题-3redis-单点故障锁服务整体不可用\">问题 3：Redis 单点故障——锁服务整体不可用</h3>\n<p><strong>成因</strong>：Redis 采用单点部署，当 Redis 服务宕机（如进程崩溃、服务器断电），所有分布式锁的加锁、释放操作都会失败，导致分布式系统的并发控制机制崩溃，无法正常处理资源竞争。</p>\n<p><strong>表现</strong>：所有依赖分布式锁的业务接口报错，无法执行（如库存扣减、订单创建接口），甚至引发服务雪崩。</p>\n<p><strong>解决方案</strong>：采用 Redis 高可用集群部署，两种主流方案按需选择：</p>\n<ol>\n<li>\n<p><strong>主从复制 + 哨兵模式</strong>：部署 1 主多从 Redis 集群，哨兵实时监控主节点状态，主节点宕机时自动将从节点切换为主节点，保证 Redis 服务连续性。缺点是存在“脑裂”风险（主从数据同步延迟导致锁丢失），适合对一致性要求一般的场景。</p>\n</li>\n<li>\n<p><strong>Redlock 算法</strong>：向至少 3 个独立的 Redis 主节点发起加锁请求，仅当超过半数节点加锁成功，且总耗时不超过超时时间，才算加锁成功。即使部分节点宕机，只要多数节点正常，锁服务就可用，彻底避免单点故障和脑裂问题，适合高一致性场景。Redisson 已内置 Redlock 实现，开箱即用，以下是完整实战配置与代码：</p>\n</li>\n</ol>\n<h4 id=\"1-多组独立-redis-节点配置yml\">1. 多组独立 Redis 节点配置（YML）</h4>\n<p>Redlock 要求节点物理独立（避免同一机房故障牵连多组节点），每组节点可单独部署主从+哨兵提升可用性，3 组节点完整配置如下：</p>\n<pre><code class=\"language-yaml\">spring:\n  redis:\n    # Redlock 专用多组独立节点配置\n    redlock:\n      # 第一组节点（可部署主从+哨兵）\n      node1:\n        host: 192.168.1.101\n        port: 6379\n        password: 123456\n        database: 0\n        timeout: 5000  # 连接超时时间（毫秒）\n      # 第二组节点（独立服务器，与第一组无关联）\n      node2:\n        host: 192.168.1.102\n        port: 6379\n        password: 123456\n        database: 0\n        timeout: 5000\n      # 第三组节点（独立服务器，建议跨机房）\n      node3:\n        host: 192.168.1.103\n        port: 6379\n        password: 123456\n        database: 0\n        timeout: 5000\n</code></pre>\n<h4 id=\"2-redisson-客户端配置多节点实例化\">2. Redisson 客户端配置（多节点实例化）</h4>\n<p>通过配置类读取 YML 信息，创建对应 RedissonClient 实例，保证每组节点独立连接：</p>\n<pre><code class=\"language-java\">@Configuration\npublic class RedissonRedlockConfig {\n\n    // 第一组 Redlock 节点客户端\n    @Bean(name = \"redlockClient1\")\n    public RedissonClient redlockClient1(\n            @Value(\"${spring.redis.redlock.node1.host}\") String host,\n            @Value(\"${spring.redis.redlock.node1.port}\") int port,\n            @Value(\"${spring.redis.redlock.node1.password}\") String password,\n            @Value(\"${spring.redis.redlock.node1.database}\") int database,\n            @Value(\"${spring.redis.redlock.node1.timeout}\") int timeout) {\n        Config config = new Config();\n        // 单节点模式（若为集群，可改用 useSentinelServers 配置哨兵）\n        config.useSingleServer()\n                .setAddress(\"redis://\" + host + \":\" + port)\n                .setPassword(password)\n                .setDatabase(database)\n                .setTimeout(timeout);\n        return Redisson.create(config);\n    }\n\n    // 第二组 Redlock 节点客户端\n    @Bean(name = \"redlockClient2\")\n    public RedissonClient redlockClient2(\n            @Value(\"${spring.redis.redlock.node2.host}\") String host,\n            @Value(\"${spring.redis.redlock.node2.port}\") int port,\n            @Value(\"${spring.redis.redlock.node2.password}\") String password,\n            @Value(\"${spring.redis.redlock.node2.database}\") int database,\n            @Value(\"${spring.redis.redlock.node2.timeout}\") int timeout) {\n        Config config = new Config();\n        config.useSingleServer()\n                .setAddress(\"redis://\" + host + \":\" + port)\n                .setPassword(password)\n                .setDatabase(database)\n                .setTimeout(timeout);\n        return Redisson.create(config);\n    }\n\n    // 第三组 Redlock 节点客户端\n    @Bean(name = \"redlockClient3\")\n    public RedissonClient redlockClient3(\n            @Value(\"${spring.redis.redlock.node3.host}\") String host,\n            @Value(\"${spring.redis.redlock.node3.port}\") int port,\n            @Value(\"${spring.redis.redlock.node3.password}\") String password,\n            @Value(\"${spring.redis.redlock.node3.database}\") int database,\n            @Value(\"${spring.redis.redlock.node3.timeout}\") int timeout) {\n        Config config = new Config();\n        config.useSingleServer()\n                .setAddress(\"redis://\" + host + \":\" + port)\n                .setPassword(password)\n                .setDatabase(database)\n                .setTimeout(timeout);\n        return Redisson.create(config);\n    }\n}\n</code></pre>\n<h4 id=\"3-redlock-加锁释放锁业务代码\">3. Redlock 加锁/释放锁业务代码</h4>\n<p>通过 RedissonRedLock 组合多节点锁，自动触发投票逻辑，兼容普通锁用法，内置 Watch Dog 续约：</p>\n<pre><code class=\"language-java\">@Service\npublic class StockService {\n\n    @Autowired\n    @Qualifier(\"redlockClient1\")\n    private RedissonClient redlockClient1;\n\n    @Autowired\n    @Qualifier(\"redlockClient2\")\n    private RedissonClient redlockClient2;\n\n    @Autowired\n    @Qualifier(\"redlockClient3\")\n    private RedissonClient redlockClient3;\n\n    @Autowired\n    private StockMapper stockMapper;\n\n    public void deductStock(Long productId) {\n        // 1. 生成统一锁Key，获取多节点锁对象\n        String lockKey = \"lock:stock:\" + productId;\n        RLock lock1 = redlockClient1.getLock(lockKey);\n        RLock lock2 = redlockClient2.getLock(lockKey);\n        RLock lock3 = redlockClient3.getLock(lockKey);\n\n        // 2. 组合为Redlock锁，触发多节点投票\n        RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3);\n\n        try {\n            // 3. 加锁：1秒内等待节点响应，锁过期时间30秒（内置续约）\n            boolean locked = redLock.tryLock(1000, 30000, TimeUnit.MILLISECONDS);\n            if (locked) {\n                // 4. 核心业务：库存扣减（仅保留锁内必要操作）\n                Stock stock = stockMapper.selectById(productId);\n                if (stock != null &amp;&amp; stock.getCount() &gt; 0) {\n                    stock.setCount(stock.getCount() - 1);\n                    stockMapper.updateById(stock);\n                }\n            } else {\n                // 加锁失败兜底\n                throw new RuntimeException(\"系统繁忙，请稍后再试\");\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(\"操作被中断，请重试\");\n        } finally {\n            // 5. 安全释放锁：仅当前线程持有锁时执行\n            if (redLock.isHeldByCurrentThread()) {\n                redLock.unlock();\n            }\n        }\n    }\n}\n</code></pre>\n<p>关键说明：① 多组节点需物理隔离，跨机房部署可提升容错；② 3 组节点最多允许 1 组故障，超过半数节点加锁成功即生效；③ 释放锁时自动同步清理所有节点锁数据，无需手动协调。</p>\n<h3 id=\"问题-4锁无法重入嵌套业务死锁\">问题 4：锁无法重入——嵌套业务死锁</h3>\n<p><strong>成因</strong>：基础实现的锁不支持重入，即同一服务的同一线程在持有锁的情况下，再次请求加同一把锁会失败。典型场景：服务 A 加锁后，执行的方法中又调用了另一个需要加同一把锁的方法，第二次加锁失败，导致线程阻塞，引发死锁。</p>\n<p><strong>表现</strong>：业务线程阻塞，接口超时无响应，排查后发现是同一线程重复加锁被拒。</p>\n<p><strong>解决方案</strong>：实现可重入锁机制。锁的 value 存储“唯一标识 + 重入次数”，第一次加锁时存入标识和次数 1；同一线程再次加锁时，验证标识一致，将次数加 1；释放锁时，次数减 1，直到次数为 0 才删除键彻底释放锁。</p>\n<p>手动实现逻辑复杂，推荐使用 Redisson 的 RLock 接口，天然支持可重入，用法与本地 synchronized 锁一致，无需额外开发。</p>\n<h3 id=\"问题-5主从切换锁丢失脑裂集群环境下的隐形坑\">问题 5：主从切换锁丢失（脑裂）——集群环境下的隐形坑</h3>\n<p><strong>成因</strong>：Redis 主从集群中，主节点存储锁数据后，尚未同步到从节点就宕机；哨兵将从节点切换为主节点，新主节点无该锁数据，其他服务可重新加锁，导致原锁失效，出现多个服务持有锁的情况。这是主从 + 哨兵模式的固有风险。</p>\n<p><strong>表现</strong>：主从切换后，原持有锁的服务仍在执行业务，新服务却能加锁成功，引发数据冲突，且问题难以复现（仅发生在主从切换瞬间）。</p>\n<p><strong>解决方案</strong>：</p>\n<ul>\n<li>\n<p>低一致性场景：开启 Redis 主从同步的“持久化 + 等待同步确认”，主节点写入锁数据后，等待至少 1 个从节点同步完成再返回加锁成功，降低锁丢失概率（仍无法完全避免）。</p>\n</li>\n<li>\n<p>高一致性场景：放弃主从 + 哨兵模式，改用 Redlock 算法，通过多主节点投票机制，从根源上解决脑裂导致的锁丢失问题。</p>\n</li>\n</ul>\n<h3 id=\"问题-6加锁失败无重试策略业务偶发失败\">问题 6：加锁失败无重试策略——业务偶发失败</h3>\n<p><strong>成因</strong>：加锁时仅尝试一次，若因网络波动、Redis 临时繁忙导致加锁失败，直接抛出异常，导致业务执行失败。分布式环境中，网络抖动、Redis 瞬时压力大是常见情况，无重试策略会放大这类问题的影响。</p>\n<p><strong>表现</strong>：部分用户操作失败（如提交订单提示“系统繁忙”），重试后可成功，问题具有随机性。</p>\n<p><strong>解决方案</strong>：实现带限制的重试机制，加锁失败后，间隔一定时间（如 100ms）重试，同时设置最大重试次数（如 3 次）和总超时时间（如 1 秒），避免无限重试导致 Redis 压力过大，也能提升加锁成功率。</p>\n<pre><code class=\"language-java\">// 带重试的加锁逻辑（Spring Data Redis 示例）\npublic boolean lockWithRetry(String key, String value, long expireMs, int maxRetry, long retryIntervalMs) {\n    for (int i = 0; i &lt; maxRetry; i++) {\n        Boolean result = redisTemplate.opsForValue().setIfAbsent(key, value, expireMs, TimeUnit.MILLISECONDS);\n        if (Boolean.TRUE.equals(result)) {\n            return true;\n        }\n        try {\n            Thread.sleep(retryIntervalMs);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            return false;\n        }\n    }\n    return false;\n}\n</code></pre>\n<h3 id=\"问题-7长时间持有锁系统并发量骤降\">问题 7：长时间持有锁——系统并发量骤降</h3>\n<p><strong>成因</strong>：在锁的范围内执行耗时操作（如复杂数据库查询、第三方接口调用、大量数据处理），导致锁持有时间过长，其他服务请求该锁时被长时间阻塞，系统吞吐量大幅下降。</p>\n<p><strong>表现</strong>：依赖该锁的接口响应时间变长，并发量上不去，监控显示大量线程阻塞在加锁环节。</p>\n<p><strong>解决方案</strong>：</p>\n<ul>\n<li>\n<p>精简锁内业务：仅将“资源竞争核心逻辑”（如库存扣减、订单状态修改）放入锁内，非核心逻辑（如日志记录、消息推送）移至锁外执行。</p>\n</li>\n<li>\n<p>异步化处理：若锁内必须执行耗时操作，将其异步化（如用线程池、消息队列），缩短锁持有时间。</p>\n</li>\n<li>\n<p>设置锁持有超时预警：通过监控工具统计锁持有时间，超过阈值（如 20 秒）时告警，及时排查耗时业务。</p>\n</li>\n</ul>\n<h3 id=\"问题-8锁-key-设计不当锁粒度问题引发并发瓶颈\">问题 8：锁 key 设计不当——锁粒度问题引发并发瓶颈</h3>\n<p><strong>成因</strong>：锁 key 粒度太粗（如用“lock:stock”作为所有商品的库存锁），导致所有商品的库存操作都互斥，即使操作不同商品，也需排队等待锁释放，彻底丧失分布式系统的并发优势。</p>\n<p><strong>表现</strong>：系统并发量极低，不同商品的库存扣减请求串行执行，接口吞吐量远低于预期。</p>\n<p><strong>解决方案</strong>：精细化设计锁 key，按具体资源标识拆分锁。比如库存锁，用“lock:stock:1001”（1001 为商品 ID）作为锁 key，仅对同一商品的库存操作互斥，不同商品可并行处理，大幅提升并发量。</p>\n<p>延伸：高并发场景下，可进一步用“分段锁”拆分资源（如将商品 ID 哈希到 10 个分段，锁 key 为“lock:stock:segment:1”），同一分段互斥，不同分段并行，进一步提升并发能力。</p>\n<h3 id=\"问题-9网络分区导致锁状态不一致极端场景下的隐患\">问题 9：网络分区导致锁状态不一致——极端场景下的隐患</h3>\n<p><strong>成因</strong>：分布式环境中出现网络分区，持有锁的服务与 Redis 集群隔离，无法主动释放锁，也无法接收锁续约信号；锁过期后，其他服务加锁成功；网络恢复后，原持有锁的服务误以为锁仍有效，继续操作资源，导致数据冲突。</p>\n<p><strong>表现</strong>：极端网络异常后，出现数据不一致，且问题难以排查（与网络分区时间、锁过期时间强相关）。</p>\n<p><strong>解决方案</strong>：</p>\n<ul>\n<li>\n<p>引入业务校验机制：操作资源前，再次校验资源状态（如扣减库存前，检查库存是否与预期一致），避免基于过期锁的无效操作。</p>\n</li>\n<li>\n<p>缩短锁过期时间：结合 Watch Dog 机制，将基础过期时间设短（如 10 秒），减少网络分区导致的锁状态不一致窗口。</p>\n</li>\n<li>\n<p>使用 Redlock 算法：多主节点投票机制，可降低网络分区对锁状态的影响，提升一致性。</p>\n</li>\n</ul>\n<h2 id=\"二生产避坑总结\">二、生产避坑总结</h2>\n<p>Redis 分布式锁的问题，大多不是 Redis 本身的缺陷，而是对分布式场景的复杂性考虑不足。结合实战经验，总结 3 个核心避坑原则：</p>\n<ol>\n<li>\n<p>优先使用成熟框架：放弃手动实现分布式锁，Redisson 已封装解决上述所有问题，开箱即用，稳定性远高于自定义实现。</p>\n</li>\n<li>\n<p>匹配业务场景选型：高一致性、高可用场景用 Redlock 算法；一般场景用主从 + 哨兵模式；根据并发量设计锁粒度（精细化/分段锁）。</p>\n</li>\n<li>\n<p>完善监控与兜底：监控锁持有时间、加锁成功率、Redis 集群状态，设置告警阈值；加锁失败、锁过期等场景，需有业务兜底策略（重试、返回友好提示、队列缓存）。</p>\n</li>\n</ol>\n<p>总之，Redis 分布式锁的核心是“兼顾互斥性与高可用”，避开上述问题后，才能真正成为分布式系统解决并发冲突的利器，而非系统的新瓶颈。</p>\n\n</div>\n<div id=\"MySignature\">\n    \n<p>❤️ 如果你喜欢这篇文章，请点赞支持！ 👍 同时欢迎关注我的博客，获取更多精彩内容！</p>\n\n<p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/sun-10387834/\" target=\"_blank\">佛祖让我来巡山</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/sun-10387834/p/19493006\" target=\"_blank\">https://www.cnblogs.com/sun-10387834/p/19493006</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 19:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sun-10387834\">佛祖让我来巡山</a>&nbsp;\n阅读(<span id=\"post_view_count\">33</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "华为云发布CodeArts Doer代码智能体个人版：一键开启你的编码自动驾驶模式",
      "link": "https://www.cnblogs.com/huaweiyun/p/19508288",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/huaweiyun/p/19508288\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 18:34\">\n    <span>华为云发布CodeArts Doer代码智能体个人版：一键开启你的编码自动驾驶模式</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<div align=\"center\" style=\"text-align: left;\">2026年1月16日，华为云正式发布CodeArts Doer代码智能体。这款深度融合AI原生能力的智能编码产品，集成了AI IDE、Code Agent、Codebase代码仓深度理解等核心能力，更懂研发需求、精通编码、善用百器，为开发者带来焕新研发体验。</div>\n<div style=\"text-align: left;\">&nbsp;<img alt=\"\" class=\"lazyload\" /></div>\n<p>本次发布的三大新品特性： AI IDE、Code Agent、Codebase</p>\n<p><strong>AI IDE</strong><strong>：原生智能，焕新开发体验</strong></p>\n<p>AI IDE以AI原生为起点，将编码能力与智能体深度融合，为开发者带来更自然的开发工作流：从需求描述到任务拆解，从接口设计到代码落地，在IDE内即可完成闭环。同时，AI IDE内置专家技能与精选工具，形成“人+AI+工具”的协同开发平台：开发者专注业务判断与关键决策，AI IDE负责高频、重复、易遗漏的工程化工作，让体验从“多开窗口找工具”升级为“在一个工作台里完成交付”。</p>\n<p>&nbsp;<img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>Code Agent</strong><strong>：左手编码自由，右手规范高效</strong></p>\n<p>CodeArts Doer代码智能体提供两种面向不同阶段与诉求的开发模式：</p>\n<p>探索模式：更强调人机协同与创造力。你可以用自然语言描述需求目标，让CodeArts Doer代码智能体为你规划并分解项目任务，生成项目级代码、进行Agent知识增强、代码续写，并在多轮对话中持续迭代，把“想法”快速推进到“可运行”。</p>\n<p>规范模式：更强调质量、安全与一致性。规范驱动开发，让代码遵从标准流程生成。在生成与修改代码过程中对齐规范，提升代码的可读性、可维护性，同时在关键点进行安全与质量校验，帮助团队把“快”建立在“稳”的基础上。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>Codebase</strong><strong>：代码仓深度理解，最懂你的AI编码专家</strong></p>\n<p>真正适用于生产环境的AI编码，关键在于“理解你的项目”。Codebase支持百万行级代码索引、知识图谱构建、文档生成与演化历史知识沉淀，准确理解代码仓结构、依赖关系与业务边界，化身成一位专属的代码知识专家，帮助新成员快速上手、老成员快速定位。同时，准确检索能力让AI更快找到你真正需要的函数、接口与实现细节，减少“看似正确、实则不适配”的生成内容，让每一次建议都更贴近项目现实。</p>\n<p>&nbsp;<img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>多种用户场景：让研发从“人力主导”走向“人机共创”</strong></p>\n<p>CodeArts Doer代码智能体已在项目级代码生成、Agent知识增强、代码续写、研发知识问答、单元测试生成等场景实现开发者效率提升，同时也支持丰富工具生态，助力高效开发与个性化定制。</p>\n<p>目前，CodeArts Doer代码智能体个人版已经正式发布，面向广大开发者开放免费体验。让AI真正走进工程、走进流程、走进交付——从今天起，开启你的编码自动驾驶模式。</p>\n<p>体验CodeArts Doer代码智能体：<a href=\"https://developer.huaweicloud.com/signup/78745481cafb4d79bf62096f6770c72e?channelCode=hcdg\" rel=\"noopener nofollow\" target=\"_blank\">https://developer.huaweicloud.com/signup/78745481cafb4d79bf62096f6770c72e?channelCode=hcdg</a></p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 18:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/huaweiyun\">华为云开发者联盟</a>&nbsp;\n阅读(<span id=\"post_view_count\">59</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "进阶指南：BrowserUse + Agentrun Sandbox 最佳实践指南",
      "link": "https://www.cnblogs.com/Serverless/p/19507367",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Serverless/p/19507367\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 16:12\">\n    <span>进阶指南：BrowserUse + Agentrun Sandbox 最佳实践指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>提示</strong>: 本文是AgentRun Browser Sandbox 快速上手实践指南的姊妹篇,专注于高级集成方案、生产环境的最佳实践、性能优化和部署策略。如果您还没有完成基础学习,请先阅读<a href=\"https://mp.weixin.qq.com/s/2LjN6LxymuZNlWUR-nhrEg\" rel=\"noopener nofollow\" target=\"_blank\">《快速上手：LangChain + AgentRun 浏览器沙箱极简集成指南》</a>。</p>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>在完成了 Browser Sandbox 的基础集成之后，本文将介绍高级集成方案（如 BrowserUse 框架）以及生产环境部署需要考虑的因素：如何管理 Sandbox 生命周期？如何优化性能和成本？如何保证系统的安全性和可观测性？本文将为您提供全面的高级应用和生产环境最佳实践指南。</p>\n<h2 id=\"基于-browseruse-集成-browser-sandbox\">基于 BrowserUse 集成 Browser Sandbox</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>&lt;效果截图&gt;</p>\n<p>BrowserUse 是一个专门为 AI Agent 设计的浏览器自动化框架,支持视觉理解和智能决策。通过 AgentRun Browser Sandbox，您可以让 BrowserUse 在云端运行,享受 Serverless 架构的优势。</p>\n<h3 id=\"browseruse-架构概览\">BrowserUse 架构概览</h3>\n<p>下图展示了 BrowserUse 与 Browser Sandbox 的集成架构：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>架构特点：</strong></p>\n<ol>\n<li><strong>智能决策循环</strong>：Agent 通过 LLM 分析页面截图,基于视觉理解生成操作指令，执行操作后继续循环，直到任务完成</li>\n<li><strong>无头浏览器控制</strong>：通过 CDP 协议远程控制云端浏览器，Playwright 作为底层驱动，所有操作在云端执行</li>\n<li><strong>实时可视化</strong>：VNC 提供实时画面监控,方便调试和验证 Agent 行为</li>\n</ol>\n<h3 id=\"快速开始\">快速开始</h3>\n<h4 id=\"安装依赖\">安装依赖</h4>\n<pre><code class=\"language-bash\">pip install browser-use python-dotenv agentrun-sdk[playwright,server]\n</code></pre>\n<p>主要依赖说明：</p>\n<ul>\n<li><code>browser-use</code>: BrowserUse 核心库,支持多模态 LLM</li>\n<li><code>agentrun-sdk[playwright,server]</code>: AgentRun SDK，用于创建 Sandbox</li>\n<li><code>python-dotenv</code>: 环境变量管理</li>\n</ul>\n<h4 id=\"配置环境变量\">配置环境变量</h4>\n<p>创建 <code>.env</code> 文件：</p>\n<pre><code class=\"language-bash\"># DashScope API Key（用于 Qwen 模型）\nDASHSCOPE_API_KEY=sk-your-dashscope-api-key\n\n# AgentRun 认证信息\nAGENTRUN_ACCOUNT_ID=your-account-id\nALIBABA_CLOUD_ACCESS_KEY_ID=your-access-key-id\nALIBABA_CLOUD_ACCESS_KEY_SECRET=your-access-key-secret\n\n# Browser Sandbox 模板名称\nBROWSER_TEMPLATE_NAME=sandbox-browser-demo\n</code></pre>\n<h4 id=\"创建-sandbox-并使用-browseruse\">创建 Sandbox 并使用 BrowserUse</h4>\n<pre><code class=\"language-python\">import asyncio\nimport os\nfrom agentrun.sandbox import Sandbox, TemplateType\nfrom browser_use import Agent, BrowserSession, ChatOpenAI\nfrom browser_use.browser import BrowserProfile\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nasync def main():\n    # 创建 Browser Sandbox\n    sandbox = Sandbox.create(\n        template_type=TemplateType.BROWSER,\n        template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n        sandbox_idle_timeout_seconds=3000\n    )\n    \n    # 配置 Qwen 多模态模型\n    llm = ChatOpenAI(\n        model='qwen-vl-max',\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n    \n    # 创建浏览器会话\n    browser_session = BrowserSession(\n        cdp_url=sandbox.get_cdp_url(),\n        browser_profile=BrowserProfile(\n            headless=False,\n            timeout=3000000,\n            keep_alive=True\n        )\n    )\n    \n    # 创建 Agent 并执行任务\n    agent = Agent(\n        task=\"访问阿里云官网并总结主要产品分类\",\n        llm=llm,\n        browser_session=browser_session,\n        use_vision=True\n    )\n    \n    result = await agent.run()\n    \n    print(f\"任务结果: {result.final_result()}\")\n    \n    # 清理资源\n    await browser_session.stop()\n    sandbox.delete()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>\n<h3 id=\"browseruse-高级配置\">BrowserUse 高级配置</h3>\n<h4 id=\"自定义浏览器行为\">自定义浏览器行为</h4>\n<pre><code class=\"language-python\">browser_profile = BrowserProfile(\n    timeout=3000000,             # 超时时间（毫秒）\n    keep_alive=True,             # 保持会话活跃\n)\n</code></pre>\n<h4 id=\"多步骤任务编排\">多步骤任务编排</h4>\n<pre><code class=\"language-python\">async def complex_task():\n    \"\"\"复杂的多步骤任务\"\"\"\n    sandbox = Sandbox.create(\n        template_type=TemplateType.BROWSER,\n        template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n        sandbox_idle_timeout_seconds=3000\n    )\n    \n    llm = ChatOpenAI(\n        model='qwen-vl-max',\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n    \n    browser_session = BrowserSession(\n        cdp_url=sandbox.cdp_url,\n        browser_profile=BrowserProfile(keep_alive=True)\n    )\n    \n    # 任务 1：信息收集\n    agent1 = Agent(\n        task=\"访问阿里云官网，收集产品分类信息\",\n        llm=llm,\n        browser_session=browser_session,\n        use_vision=True\n    )\n    result1 = await agent1.run()\n    \n    # 任务 2：基于第一步结果继续操作\n    agent2 = Agent(\n        task=f\"基于以下信息：{result1.final_result()}，访问每个产品分类并提取关键特性\",\n        llm=llm,\n        browser_session=browser_session,\n        use_vision=True\n    )\n    result2 = await agent2.run()\n    \n    # 清理资源\n    await browser_session.stop()\n    sandbox.delete()\n    \n    return result2.final_result()\n</code></pre>\n<h4 id=\"集成-vnc-实时监控\">集成 VNC 实时监控</h4>\n<pre><code class=\"language-python\">import webbrowser\nimport urllib.parse\n\nasync def run_with_vnc_monitoring():\n    \"\"\"运行 BrowserUse 并启用 VNC 监控\"\"\"\n    sandbox = Sandbox.create(\n        template_type=TemplateType.BROWSER,\n        template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n        sandbox_idle_timeout_seconds=3000\n    )\n    \n    # 获取 VNC URL 并打开查看器\n    vnc_url = sandbox.get_vnc_url(),\n    if vnc_url:\n        # 修复 VNC URL 路径\n        if vnc_url.endswith('/vnc'):\n            vnc_url = vnc_url[:-4] + '/ws/livestream'\n        \n        # 在浏览器中打开 VNC 查看器\n        encoded_url = urllib.parse.quote(vnc_url, safe='')\n        viewer_url = f\"file://path/to/vnc-viewer.html?url={encoded_url}\"\n        webbrowser.open(viewer_url)\n        print(f\"VNC 查看器已打开，可实时监控浏览器操作\")\n    \n    # 创建并运行 Agent\n    llm = ChatOpenAI(\n        model='qwen-vl-max',\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n    \n    browser_session = BrowserSession(\n        cdp_url=sandbox.get_cdp_url(),\n        browser_profile=BrowserProfile(headless=False, keep_alive=True)\n    )\n    \n    agent = Agent(\n        task=\"访问淘宝首页并搜索商品\",\n        llm=llm,\n        browser_session=browser_session,\n        use_vision=True\n    )\n    \n    result = await agent.run()\n    \n    # 清理资源\n    await browser_session.stop()\n    sandbox.delete()\n    \n    return result.final_result()\n</code></pre>\n<h3 id=\"browseruse-最佳实践\">BrowserUse 最佳实践</h3>\n<ol>\n<li><strong>启用视觉理解</strong>：对于复杂页面，使用 <code>use_vision=True</code> 让 LLM 分析页面截图</li>\n<li><strong>保持会话活跃</strong>：使用 <code>keep_alive=True</code> 避免频繁重建连接</li>\n<li><strong>合理设置超时</strong>：根据任务复杂度调整 <code>timeout</code> 参数</li>\n<li><strong>复用 BrowserSession</strong>：对于多步骤任务，复用同一个 BrowserSession 提高效率</li>\n<li><strong>结合 VNC 调试</strong>：开发阶段启用 VNC 实时查看 Agent 行为</li>\n</ol>\n<h3 id=\"获取完整示例代码\">获取完整示例代码</h3>\n<p>本文中的所有示例代码都可以在以下仓库中找到：</p>\n<pre><code class=\"language-bash\"># 克隆示例代码仓库\ngit clone https://github.com/devsapp/agentrun-sandbox-demos.git\n\n# 进入项目目录\ncd agentrun-browseruse-wth-sandbox-demo\n\n# 安装依赖（注意需要安装 server 扩展）\npip install -r requirements.txt\n</code></pre>\n<h4 id=\"配置环境变量-1\">配置环境变量</h4>\n<pre><code class=\"language-bash\"># 复制环境变量模板\ncp env.example .env\n\n# 编辑 .env 文件，填入您的配置信息\n# 必需配置项：\n# - DASHSCOPE_API_KEY: DashScope API Key（用于 Qwen 模型）\n# - AGENTRUN_ACCOUNT_ID: AgentRun 账号 ID\n# - ALIBABA_CLOUD_ACCESS_KEY_ID: 阿里云访问密钥 ID\n# - ALIBABA_CLOUD_ACCESS_KEY_SECRET: 阿里云访问密钥 Secret\n# - BROWSER_TEMPLATE_NAME: Browser Sandbox 模板名称\n</code></pre>\n<h4 id=\"运行示例两步运行设计\">运行示例（两步运行设计）</h4>\n<p>本项目采用<strong>服务器-客户端</strong>的架构设计，需要分两步运行：</p>\n<p><strong>第一步：启动 VNC 查看器服务</strong></p>\n<pre><code class=\"language-bash\"># 在终端 1 中启动 VNC Web 服务器\npython main.py\n\n# 服务启动后会显示：\n# VNC 查看器服务已启动: http://localhost:8000\n# 访问 http://localhost:8000 可以实时查看浏览器操作\n</code></pre>\n<p><code>main.py</code> 的作用：</p>\n<ul>\n<li>启动本地 Web 服务器，提供 VNC 实时查看界面</li>\n<li>提供 WebSocket 代理，连接 AgentRun Sandbox 的 VNC 服务</li>\n<li>允许您在浏览器中实时监控 Agent 的操作过程</li>\n</ul>\n<p><strong>第二步：运行 BrowserUse 示例</strong></p>\n<pre><code class=\"language-bash\"># 在终端 2 中运行示例代码\npython examples/01_browseruse_basic.py\n\n# 运行高级示例\npython examples/02_browseruse_advanced.py\n</code></pre>\n<p><strong>为什么需要两步运行？</strong></p>\n<ol>\n<li><strong>实时监控</strong>：main.py 提供 VNC 查看器，可以实时看到 Agent 在浏览器中的操作</li>\n<li><strong>调试友好</strong>：通过可视化界面，更容易理解 Agent 的决策过程和行为</li>\n<li><strong>服务解耦</strong>：VNC 服务和业务逻辑分离，可以同时运行多个示例而共用同一个查看器</li>\n</ol>\n<p><strong>运行流程图：</strong></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>仓库内容包括：</strong></p>\n<ul>\n<li><code>main.py</code>: VNC Web 服务器，用于实时监控</li>\n<li><code>examples/01_browseruse_basic.py</code>: 基础集成示例</li>\n<li><code>examples/02_browseruse_advanced.py</code>: 高级配置示例</li>\n<li><code>examples/sandbox_manager.py</code>: Sandbox 生命周期管理</li>\n<li><code>vncviewer/</code>: VNC 查看器前端和后端代码</li>\n<li>完整的环境配置和最佳实践代码</li>\n</ul>\n<hr />\n<h2 id=\"sandbox-生命周期管理最佳实践\">Sandbox 生命周期管理最佳实践</h2>\n<h3 id=\"三种管理模式\">三种管理模式</h3>\n<p>根据不同的应用场景,我们推荐三种 Sandbox 管理模式：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>方案对比：</strong></p>\n<table>\n<thead>\n<tr>\n<th>管理模式</th>\n<th>优点</th>\n<th>缺点</th>\n<th>适用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>单例模式</strong></td>\n<td>• 资源复用   • 响应快   • 简单易用</td>\n<td>• 状态污染风险   • 不适合并发</td>\n<td>开发调试   多轮对话   个人应用</td>\n</tr>\n<tr>\n<td><strong>请求级别</strong></td>\n<td>• 环境隔离   • 状态独立   • 安全性高</td>\n<td>• 创建开销大   • 成本较高</td>\n<td>一次性任务   高安全需求   无状态服务</td>\n</tr>\n<tr>\n<td><strong>连接池</strong></td>\n<td>• 并发能力强   • 资源利用率高   • 性能稳定</td>\n<td>• 实现复杂   • 需要监控</td>\n<td>生产环境   高并发服务   企业应用</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"单例模式实现\">单例模式实现</h3>\n<p>适合开发调试和多轮对话场景：</p>\n<pre><code class=\"language-python\">class SandboxManager:\n    \"\"\"单例模式 Sandbox 管理器\"\"\"\n    _instance = None\n    _sandbox = None\n    \n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n    \n    def get_or_create(self):\n        \"\"\"获取或创建 Sandbox\"\"\"\n        if self._sandbox is None:\n            self._sandbox = Sandbox.create(\n                template_type=TemplateType.BROWSER,\n                template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n                sandbox_idle_timeout_seconds=3000\n            )\n        return self._sandbox\n    \n    def destroy(self):\n        \"\"\"销毁 Sandbox\"\"\"\n        if self._sandbox:\n            self._sandbox.delete()\n            self._sandbox = None\n\n# 使用\nmanager = SandboxManager()\nsandbox = manager.get_or_create()  # 首次创建\nsandbox = manager.get_or_create()  # 复用现有实例\n</code></pre>\n<h3 id=\"连接池模式实现\">连接池模式实现</h3>\n<p>适合高并发生产环境：</p>\n<pre><code class=\"language-python\">from queue import Queue\nfrom threading import Lock\n\nclass SandboxPool:\n    \"\"\"Sandbox 连接池\"\"\"\n    \n    def __init__(self, pool_size=5, max_idle_time=300):\n        self.pool_size = pool_size\n        self.max_idle_time = max_idle_time\n        self.pool = Queue(maxsize=pool_size)\n        self.lock = Lock()\n        self._initialize_pool()\n    \n    def _initialize_pool(self):\n        \"\"\"初始化连接池\"\"\"\n        for _ in range(self.pool_size):\n            sandbox = self._create_sandbox()\n            self.pool.put(sandbox)\n    \n    def _create_sandbox(self):\n        \"\"\"创建 Sandbox 实例\"\"\"\n        return Sandbox.create(\n            template_type=TemplateType.BROWSER,\n            template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n            sandbox_idle_timeout_seconds=self.max_idle_time\n        )\n    \n    def acquire(self, timeout=30):\n        \"\"\"获取 Sandbox 实例\"\"\"\n        try:\n            sandbox = self.pool.get(timeout=timeout)\n            if not self._is_alive(sandbox):\n                sandbox = self._create_sandbox()\n            return sandbox\n        except:\n            raise RuntimeError(\"获取 Sandbox 超时\")\n    \n    def release(self, sandbox):\n        \"\"\"归还 Sandbox 实例\"\"\"\n        if self._is_alive(sandbox):\n            self.pool.put(sandbox)\n        else:\n            new_sandbox = self._create_sandbox()\n            self.pool.put(new_sandbox)\n    \n    def _is_alive(self, sandbox):\n        \"\"\"检查 Sandbox 是否存活\"\"\"\n        try:\n            return hasattr(sandbox, 'sandbox_id')\n        except:\n            return False\n\n# 使用\npool = SandboxPool(pool_size=5)\n\nsandbox = pool.acquire()\ntry:\n    # 使用 sandbox 执行任务\n    pass\nfinally:\n    pool.release(sandbox)\n</code></pre>\n<h3 id=\"会话状态管理\">会话状态管理</h3>\n<p>支持多用户多会话场景：</p>\n<pre><code class=\"language-python\">import time\n\nclass SessionManager:\n    \"\"\"会话状态管理\"\"\"\n    \n    def __init__(self):\n        self.sessions = {}  # session_id -&gt; sandbox\n    \n    def create_session(self, session_id: str):\n        \"\"\"创建会话\"\"\"\n        if session_id not in self.sessions:\n            sandbox = Sandbox.create(\n                template_type=TemplateType.BROWSER,\n                template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n                sandbox_idle_timeout_seconds=1800\n            )\n            self.sessions[session_id] = {\n                'sandbox': sandbox,\n                'created_at': time.time(),\n                'last_used': time.time()\n            }\n        return self.sessions[session_id]['sandbox']\n    \n    def get_session(self, session_id: str):\n        \"\"\"获取会话\"\"\"\n        if session_id in self.sessions:\n            session = self.sessions[session_id]\n            session['last_used'] = time.time()\n            return session['sandbox']\n        return None\n    \n    def cleanup_expired_sessions(self, max_idle_time=1800):\n        \"\"\"清理过期会话\"\"\"\n        current_time = time.time()\n        expired_sessions = []\n        \n        for session_id, session in self.sessions.items():\n            if current_time - session['last_used'] &gt; max_idle_time:\n                expired_sessions.append(session_id)\n        \n        for session_id in expired_sessions:\n            self.destroy_session(session_id)\n    \n    def destroy_session(self, session_id: str):\n        \"\"\"销毁会话\"\"\"\n        if session_id in self.sessions:\n            self.sessions[session_id]['sandbox'].delete()\n            del self.sessions[session_id]\n</code></pre>\n<h2 id=\"性能优化\">性能优化</h2>\n<h3 id=\"超时时间配置\">超时时间配置</h3>\n<p>合理设置超时时间是平衡性能和成本的关键：</p>\n<pre><code class=\"language-python\"># 开发环境（调试用）\nsandbox = Sandbox.create(\n    template_name=\"dev-template\",\n    sandbox_idle_timeout_seconds=7200  # 2 小时\n)\n\n# 生产环境（单次任务）\nsandbox = Sandbox.create(\n    template_name=\"prod-template\",\n    sandbox_idle_timeout_seconds=300  # 5 分钟\n)\n\n# 长时间任务\nsandbox = Sandbox.create(\n    template_name=\"long-task-template\",\n    sandbox_idle_timeout_seconds=10800  # 3 小时\n)\n</code></pre>\n<p><strong>超时策略推荐：</strong></p>\n<table>\n<thead>\n<tr>\n<th>场景</th>\n<th>推荐超时</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>开发调试</td>\n<td>1-2 小时</td>\n<td>方便调试,避免频繁重建</td>\n</tr>\n<tr>\n<td>简单任务</td>\n<td>5-10 分钟</td>\n<td>单页操作,快速完成</td>\n</tr>\n<tr>\n<td>复杂任务</td>\n<td>30-60 分钟</td>\n<td>多步骤流程,需要时间</td>\n</tr>\n<tr>\n<td>后台服务</td>\n<td>2-4 小时</td>\n<td>长期运行,定期刷新</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"sandbox-复用策略\">Sandbox 复用策略</h3>\n<pre><code class=\"language-python\">class SmartSandboxManager:\n    \"\"\"智能 Sandbox 复用管理器\"\"\"\n    \n    def __init__(self):\n        self.sandboxes = {}  # key -&gt; sandbox\n        self.usage_count = {}  # key -&gt; count\n    \n    def get_sandbox(self, user_id: str, session_id: str):\n        \"\"\"获取或创建 Sandbox（支持复用）\"\"\"\n        key = f\"{user_id}:{session_id}\"\n        \n        if key not in self.sandboxes:\n            self.sandboxes[key] = Sandbox.create(\n                template_type=TemplateType.BROWSER,\n                template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n                sandbox_idle_timeout_seconds=1800\n            )\n            self.usage_count[key] = 0\n        \n        self.usage_count[key] += 1\n        return self.sandboxes[key]\n    \n    def should_recreate(self, key: str, max_reuse=50):\n        \"\"\"判断是否需要重建（防止状态累积）\"\"\"\n        return self.usage_count.get(key, 0) &gt;= max_reuse\n    \n    def recreate_if_needed(self, key: str):\n        \"\"\"按需重建 Sandbox\"\"\"\n        if self.should_recreate(key):\n            if key in self.sandboxes:\n                self.sandboxes[key].delete()\n                del self.sandboxes[key]\n                self.usage_count[key] = 0\n</code></pre>\n<h3 id=\"错误处理和重试机制\">错误处理和重试机制</h3>\n<p>使用 tenacity 库实现智能重试：</p>\n<pre><code class=\"language-python\">from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n\nclass SandboxError(Exception):\n    \"\"\"Sandbox 操作异常\"\"\"\n    pass\n\n@retry(\n    retry=retry_if_exception_type(SandboxError),\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10)\n)\ndef execute_with_retry(sandbox, operation):\n    \"\"\"带重试的操作执行\"\"\"\n    try:\n        return operation(sandbox)\n    except ConnectionError:\n        raise SandboxError(\"连接失败\")\n    except TimeoutError:\n        raise SandboxError(\"操作超时\")\n    except Exception as e:\n        print(f\"操作失败: {e}\")\n        raise SandboxError(f\"操作失败: {e}\")\n\n# 使用示例\ndef navigate_page(sandbox):\n    with sync_playwright() as p:\n        browser = p.chromium.connect_over_cdp(sandbox.cdp_url)\n        page = browser.contexts[0].pages[0]\n        page.goto(\"https://example.com\", timeout=30000)\n        return page.title()\n\nresult = execute_with_retry(sandbox, navigate_page)\n</code></pre>\n<h2 id=\"安全性最佳实践\">安全性最佳实践</h2>\n<h3 id=\"环境变量保护\">环境变量保护</h3>\n<pre><code class=\"language-python\">import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# 验证必需的环境变量\nrequired_vars = [\"DASHSCOPE_API_KEY\", \"AGENTRUN_ACCOUNT_ID\"]\nmissing_vars = [var for var in required_vars if not os.getenv(var)]\nif missing_vars:\n    raise ValueError(f\"缺少必需的环境变量: {', '.join(missing_vars)}\")\n\n# 敏感信息不要硬编码\nAPI_KEY = os.getenv(\"DASHSCOPE_API_KEY\")\nACCESS_KEY_ID = os.getenv(\"ALIBABA_CLOUD_ACCESS_KEY_ID\")\nACCESS_KEY_SECRET = os.getenv(\"ALIBABA_CLOUD_ACCESS_KEY_SECRET\")\n</code></pre>\n<h3 id=\"url-白名单\">URL 白名单</h3>\n<pre><code class=\"language-python\">ALLOWED_DOMAINS = [\n    'example.com',\n    'aliyun.com',\n    'alibaba.com'\n]\n\ndef is_url_allowed(url: str) -&gt; bool:\n    \"\"\"检查 URL 是否在白名单中\"\"\"\n    from urllib.parse import urlparse\n    domain = urlparse(url).netloc\n    return any(allowed in domain for allowed in ALLOWED_DOMAINS)\n\ndef safe_navigate(page, url: str):\n    \"\"\"安全导航\"\"\"\n    if not is_url_allowed(url):\n        raise ValueError(f\"URL 不在白名单中: {url}\")\n    page.goto(url)\n</code></pre>\n<h3 id=\"日志脱敏\">日志脱敏</h3>\n<pre><code class=\"language-python\">import re\n\ndef sanitize_log(log_text: str) -&gt; str:\n    \"\"\"日志脱敏\"\"\"\n    # 脱敏 API Key\n    log_text = re.sub(r'sk-[a-zA-Z0-9]{20,}', 'sk-***', log_text)\n    # 脱敏 Access Key\n    log_text = re.sub(r'LTAI[a-zA-Z0-9]{12,}', 'LTAI***', log_text)\n    # 脱敏密码\n    log_text = re.sub(r'password[\"\\s:=]+[^\"\\s,}]+', 'password: ***', log_text, flags=re.IGNORECASE)\n    return log_text\n\n# 使用\nprint(sanitize_log(f\"使用 API Key: {API_KEY}\"))\n</code></pre>\n<h2 id=\"可观测性与监控\">可观测性与监控</h2>\n<h3 id=\"日志记录最佳实践\">日志记录最佳实践</h3>\n<pre><code class=\"language-python\">import logging\nfrom datetime import datetime\n\n# 配置日志\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(f'sandbox_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger(__name__)\n\nclass MonitoredSandboxManager:\n    \"\"\"带监控的 Sandbox 管理器\"\"\"\n    \n    def create_sandbox(self, **kwargs):\n        \"\"\"创建 Sandbox（带日志）\"\"\"\n        start_time = time.time()\n        logger.info(f\"开始创建 Sandbox: {kwargs}\")\n        \n        try:\n            sandbox = Sandbox.create(**kwargs)\n            duration = time.time() - start_time\n            logger.info(f\"Sandbox 创建成功: {sandbox.sandbox_id}, 耗时: {duration:.2f}s\")\n            return sandbox\n        except Exception as e:\n            duration = time.time() - start_time\n            logger.error(f\"Sandbox 创建失败: {e}, 耗时: {duration:.2f}s\")\n            raise\n    \n    def execute_task(self, sandbox, task_name: str, operation):\n        \"\"\"执行任务（带日志）\"\"\"\n        start_time = time.time()\n        logger.info(f\"开始执行任务: {task_name}, Sandbox: {sandbox.sandbox_id}\")\n        \n        try:\n            result = operation(sandbox)\n            duration = time.time() - start_time\n            logger.info(f\"任务执行成功: {task_name}, 耗时: {duration:.2f}s\")\n            return result\n        except Exception as e:\n            duration = time.time() - start_time\n            logger.error(f\"任务执行失败: {task_name}, 错误: {e}, 耗时: {duration:.2f}s\")\n            raise\n</code></pre>\n<h3 id=\"指标收集\">指标收集</h3>\n<pre><code class=\"language-python\">from dataclasses import dataclass\nfrom typing import Dict, List\nimport json\n\n@dataclass\nclass SandboxMetrics:\n    \"\"\"Sandbox 指标\"\"\"\n    sandbox_id: str\n    create_time: float\n    destroy_time: float = None\n    total_requests: int = 0\n    failed_requests: int = 0\n    total_duration: float = 0.0\n\nclass MetricsCollector:\n    \"\"\"指标收集器\"\"\"\n    \n    def __init__(self):\n        self.metrics: Dict[str, SandboxMetrics] = {}\n    \n    def record_creation(self, sandbox_id: str):\n        \"\"\"记录创建\"\"\"\n        self.metrics[sandbox_id] = SandboxMetrics(\n            sandbox_id=sandbox_id,\n            create_time=time.time()\n        )\n    \n    def record_request(self, sandbox_id: str, duration: float, success: bool):\n        \"\"\"记录请求\"\"\"\n        if sandbox_id in self.metrics:\n            metric = self.metrics[sandbox_id]\n            metric.total_requests += 1\n            metric.total_duration += duration\n            if not success:\n                metric.failed_requests += 1\n    \n    def record_destruction(self, sandbox_id: str):\n        \"\"\"记录销毁\"\"\"\n        if sandbox_id in self.metrics:\n            self.metrics[sandbox_id].destroy_time = time.time()\n    \n    def export_metrics(self, filepath: str):\n        \"\"\"导出指标\"\"\"\n        metrics_data = [\n            {\n                'sandbox_id': m.sandbox_id,\n                'create_time': m.create_time,\n                'destroy_time': m.destroy_time,\n                'total_requests': m.total_requests,\n                'failed_requests': m.failed_requests,\n                'success_rate': (m.total_requests - m.failed_requests) / m.total_requests if m.total_requests &gt; 0 else 0,\n                'avg_duration': m.total_duration / m.total_requests if m.total_requests &gt; 0 else 0,\n                'lifetime': m.destroy_time - m.create_time if m.destroy_time else time.time() - m.create_time\n            }\n            for m in self.metrics.values()\n        ]\n        \n        with open(filepath, 'w') as f:\n            json.dump(metrics_data, f, indent=2)\n\n# 使用\ncollector = MetricsCollector()\ncollector.record_creation(sandbox.sandbox_id)\n# ... 执行任务 ...\ncollector.export_metrics('metrics.json')\n</code></pre>\n<h2 id=\"成本优化\">成本优化</h2>\n<h3 id=\"按需创建与销毁\">按需创建与销毁</h3>\n<pre><code class=\"language-python\">class CostOptimizedManager:\n    \"\"\"成本优化的管理器\"\"\"\n    \n    def __init__(self, idle_threshold=300):\n        self.idle_threshold = idle_threshold\n        self.sandboxes = {}\n        self.last_used = {}\n    \n    def get_sandbox(self, key: str):\n        \"\"\"获取 Sandbox（懒加载）\"\"\"\n        if key not in self.sandboxes:\n            self.sandboxes[key] = Sandbox.create(\n                template_type=TemplateType.BROWSER,\n                template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\"),\n                sandbox_idle_timeout_seconds=self.idle_threshold\n            )\n        \n        self.last_used[key] = time.time()\n        return self.sandboxes[key]\n    \n    def cleanup_idle(self):\n        \"\"\"清理闲置 Sandbox\"\"\"\n        current_time = time.time()\n        to_remove = []\n        \n        for key, last_time in self.last_used.items():\n            if current_time - last_time &gt; self.idle_threshold:\n                to_remove.append(key)\n        \n        for key in to_remove:\n            if key in self.sandboxes:\n                self.sandboxes[key].delete()\n                del self.sandboxes[key]\n                del self.last_used[key]\n                logger.info(f\"清理闲置 Sandbox: {key}\")\n</code></pre>\n<h3 id=\"批量任务处理\">批量任务处理</h3>\n<pre><code class=\"language-python\">async def batch_process_tasks(tasks: List[str], pool_size: int = 5):\n    \"\"\"批量处理任务（复用 Sandbox）\"\"\"\n    pool = SandboxPool(pool_size=pool_size)\n    results = []\n    \n    for task in tasks:\n        sandbox = pool.acquire()\n        try:\n            # 处理任务\n            result = await process_task(sandbox, task)\n            results.append(result)\n        finally:\n            pool.release(sandbox)\n    \n    return results\n</code></pre>\n<h2 id=\"生产环境部署\">生产环境部署</h2>\n<h3 id=\"环境配置\">环境配置</h3>\n<p><strong>开发环境 (.env.dev)</strong>：</p>\n<pre><code class=\"language-bash\"># 开发环境配置\nBROWSER_TEMPLATE_NAME=dev-browser-template\nSANDBOX_IDLE_TIMEOUT=7200\nPOOL_SIZE=2\nLOG_LEVEL=DEBUG\n</code></pre>\n<p><strong>生产环境 (.env.prod)</strong>：</p>\n<pre><code class=\"language-bash\"># 生产环境配置\nBROWSER_TEMPLATE_NAME=prod-browser-template\nSANDBOX_IDLE_TIMEOUT=300\nPOOL_SIZE=10\nLOG_LEVEL=INFO\nENABLE_METRICS=true\nMETRICS_EXPORT_INTERVAL=300\n</code></pre>\n<h3 id=\"高可用架构\">高可用架构</h3>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<h3 id=\"健康检查\">健康检查</h3>\n<pre><code class=\"language-python\">from flask import Flask, jsonify\n\napp = Flask(__name__)\nmanager = SandboxManager()\n\n@app.route('/health')\ndef health_check():\n    \"\"\"健康检查端点\"\"\"\n    try:\n        # 检查 Sandbox 是否可用\n        sandbox = manager.get_or_create()\n        \n        # 简单的健康检查\n        is_healthy = hasattr(sandbox, 'sandbox_id')\n        \n        if is_healthy:\n            return jsonify({\n                'status': 'healthy',\n                'sandbox_id': sandbox.sandbox_id,\n                'timestamp': time.time()\n            }), 200\n        else:\n            return jsonify({\n                'status': 'unhealthy',\n                'error': 'Sandbox not available'\n            }), 503\n    except Exception as e:\n        return jsonify({\n            'status': 'unhealthy',\n            'error': str(e)\n        }), 503\n\n@app.route('/metrics')\ndef metrics():\n    \"\"\"指标端点\"\"\"\n    collector = MetricsCollector()\n    # 返回当前指标\n    return jsonify({\n        'total_sandboxes': len(collector.metrics),\n        'timestamp': time.time()\n    })\n</code></pre>\n<h2 id=\"故障排查与常见问题\">故障排查与常见问题</h2>\n<h3 id=\"连接问题\">连接问题</h3>\n<p><strong>问题</strong>：无法连接到 Sandbox</p>\n<p><strong>排查步骤</strong>：</p>\n<pre><code class=\"language-python\">def diagnose_connection(sandbox):\n    \"\"\"诊断连接问题\"\"\"\n    print(f\"1. 检查 Sandbox ID: {sandbox.sandbox_id}\")\n    print(f\"2. 检查 CDP URL: {sandbox.cdp_url}\")\n    \n    # 测试 CDP 连接\n    try:\n        with sync_playwright() as p:\n            browser = p.chromium.connect_over_cdp(sandbox.cdp_url)\n            print(\"✓ CDP 连接成功\")\n            browser.close()\n    except Exception as e:\n        print(f\"✗ CDP 连接失败: {e}\")\n    \n    # 测试 VNC 连接\n    print(f\"3. VNC URL: {sandbox.vnc_url}\")\n    print(\"提示: 可以在浏览器中打开 VNC URL 测试连接\")\n</code></pre>\n<h3 id=\"超时问题\">超时问题</h3>\n<p><strong>问题</strong>：任务执行超时</p>\n<p><strong>解决方案</strong>：</p>\n<pre><code class=\"language-python\">def handle_timeout(sandbox, operation, max_retries=3):\n    \"\"\"处理超时（带重试）\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return operation(sandbox, timeout=30000)\n        except TimeoutError:\n            logger.warning(f\"任务超时（尝试 {attempt + 1}/{max_retries}）\")\n            if attempt == max_retries - 1:\n                # 最后一次尝试失败，重建 Sandbox\n                logger.error(\"多次超时，重建 Sandbox\")\n                sandbox.delete()\n                sandbox = Sandbox.create(\n                    template_type=TemplateType.BROWSER,\n                    template_name=os.getenv(\"BROWSER_TEMPLATE_NAME\")\n                )\n                return operation(sandbox, timeout=60000)\n</code></pre>\n<h3 id=\"性能问题\">性能问题</h3>\n<p><strong>问题</strong>：响应速度慢</p>\n<p><strong>优化建议</strong>：</p>\n<ol>\n<li><strong>使用连接池</strong>：预先创建多个 Sandbox 实例</li>\n<li><strong>启用 keep_alive</strong>：保持浏览器会话，避免重复建立连接</li>\n<li><strong>合理设置超时</strong>：根据任务复杂度调整超时时间</li>\n<li><strong>并发控制</strong>：限制并发请求数，避免资源竞争</li>\n</ol>\n<pre><code class=\"language-python\"># 性能优化配置示例\nbrowser_session = BrowserSession(\n    cdp_url=sandbox.cdp_url,\n    browser_profile=BrowserProfile(\n        timeout=30000,          # 30秒超时\n        keep_alive=True,        # 保持连接\n        disable_security=False  # 保持安全检查\n    )\n)\n</code></pre>\n<h3 id=\"错误码参考\">错误码参考</h3>\n<table>\n<thead>\n<tr>\n<th>错误码</th>\n<th>说明</th>\n<th>解决方案</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>ConnectionError</code></td>\n<td>连接失败</td>\n<td>检查网络连接，验证 CDP URL</td>\n</tr>\n<tr>\n<td><code>TimeoutError</code></td>\n<td>操作超时</td>\n<td>增加超时时间，检查任务复杂度</td>\n</tr>\n<tr>\n<td><code>AuthenticationError</code></td>\n<td>认证失败</td>\n<td>验证 API Key 和访问密钥</td>\n</tr>\n<tr>\n<td><code>ResourceExhausted</code></td>\n<td>资源不足</td>\n<td>减少并发数，增加资源配额</td>\n</tr>\n<tr>\n<td><code>InvalidArgument</code></td>\n<td>参数错误</td>\n<td>检查参数格式和有效性</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"总结\">总结</h2>\n<p>通过本指南，您已经掌握了：</p>\n<ol>\n<li><strong>BrowserUse 集成</strong>：如何使用 BrowserUse 框架实现智能浏览器自动化</li>\n<li><strong>生命周期管理</strong>：三种 Sandbox 管理模式的选择和实现</li>\n<li><strong>性能优化</strong>：超时配置、复用策略、错误重试机制</li>\n<li><strong>安全实践</strong>：环境变量保护、URL 白名单、日志脱敏</li>\n<li><strong>可观测性</strong>：日志记录、指标收集、监控告警</li>\n<li><strong>成本优化</strong>：按需创建、闲置清理、批量处理</li>\n<li><strong>生产部署</strong>：高可用架构、健康检查、故障排查</li>\n</ol>\n<h2 id=\"立即体验函数计算-agentrun\">立即体验函数计算 AgentRun</h2>\n<p>函数计算 AgentRun 的无代码到高代码演进能力，现已开放体验：</p>\n<ol>\n<li><strong>快速创建</strong>：访问控制台（<a href=\"https://functionai.console.aliyun.com/cn-hangzhou/agent/explore\" rel=\"noopener nofollow\" target=\"_blank\">https://functionai.console.aliyun.com/cn-hangzhou/agent/explore</a>），60秒创建你的第一个 Agent</li>\n<li><strong>深度定制</strong>：当需要更复杂功能时，一键转换为高代码</li>\n<li><strong>持续演进</strong>：利用函数计算 AgentRun 的基础设施能力，持续优化你的 Agent</li>\n</ol>\n<p>从想法到上线，从原型到生产，函数计算 AgentRun 始终是你最好的伙伴。<strong>欢迎加入“函数计算 AgentRun 客户群”，钉钉群号：<em>134570017218</em>。</strong></p>\n<h2 id=\"快速了解函数计算-agentrun\">快速了解函数计算 AgentRun</h2>\n<p><strong>一句话介绍：</strong><a href=\"https://www.aliyun.com/product/fc/agentrun\" rel=\"noopener nofollow\" target=\"_blank\">函数计算 AgentRun</a> 是一个以高代码为核心的一站式 Agentic AI 基础设施平台。秉持生态开放和灵活组装的理念，为企业级 Agent 应用提供从开发、部署到运维的全生命周期管理。</p>\n\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>函数计算 AgentRun 架构图</p>\n<p>AgentRun 运行时基于阿里云函数计算 FC 构建，继承了 Serverless 计算极致弹性、按量付费、零运维的核心优势。通过深度集成 AgentScope、LangChain、RAGFlow、Mem0 等主流开源生态。函数计算 AgentRun 将 Serverless 的极致弹性、零运维和按量付费的特性与 AI 原生应用场景深度融合，助力企业实现成本与效率的极致优化，<strong>平均 TCO 降低 60%</strong>。</p>\n<p><strong>让开发者只需专注于 Agent 的业务逻辑创新，无需关心底层基础设施，让 Agentic AI 真正进入企业生产环境。</strong></p>\n<p><strong>推荐阅读：</strong></p>\n<ul>\n<li>阅读<a href=\"https://yuque.alibaba-inc.com/agentrun/dxnn5p/rcpbigg7gthpa2u4\" rel=\"noopener nofollow\" target=\"_blank\">《快速上手：LangChain + AgentRun 浏览器沙箱极简集成指南》</a>复习基础集成和 LangChain 集成</li>\n<li>查看<a href=\"https://docs.agent.run\" rel=\"noopener nofollow\" target=\"_blank\">官方文档</a>了解更多 AgentRun 功能</li>\n<li>访问<a href=\"https://github.com/devsapp/agentrun-sandbox-demos\" rel=\"noopener nofollow\" target=\"_blank\">示例代码仓库</a> 获取参考代码</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 16:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Serverless\">Serverless社区</a>&nbsp;\n阅读(<span id=\"post_view_count\">75</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "基于springboot系统，如何跟踪会话过期，浏览器会话标识是否收到正常响应，存储，并在后续请求保持携带",
      "link": "https://www.cnblogs.com/liuyangjava/p/19507022",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/liuyangjava/p/19507022\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 15:22\">\n    <span>基于springboot系统，如何跟踪会话过期，浏览器会话标识是否收到正常响应，存储，并在后续请求保持携带</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>今天我们分享一个项目开发中的出现操作某个业务时候，<span style=\"color: rgba(224, 62, 45, 1); font-size: 18px;\"><strong>出现闪退</strong></span>的经典问题，针对老旧的Spring MVC系统，要系统性地跟踪会话（Session）生命周期和Cookie的携带情况，我们需要一套清晰的、从浏览器到服务器的排查方案。以下是详细的跟踪步骤和方法。</p>\n<p>当然这个排查步骤和方法，也适合基本SpringBoot开发的系统，但是服务端的排查需要大家根据实际情况修改后端排查日志、拦截器等方法</p>\n<h3>整体排查思路</h3>\n<p>我们的目标是验证以下三个环节是否正常：</p>\n<ol class=\"ybc-ol-component ybc-ol-component_1\">\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>登录成功时</strong>：服务器是否正确生成了Session并返回了包含正确 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code>的Cookie给浏览器。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>浏览器端</strong>：浏览器是否成功接收并存储了该Cookie。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>后续请求</strong>：浏览器在执行查询等操作时，是否始终在请求头中携带了这个Cookie。</p>\n</li>\n</ol>\n<h3>第一步：浏览器端跟踪（客户端验证）</h3>\n<p>这是最直接、最容易操作的第一步，可以由开发或运维人员在问题电脑上进行。</p>\n<p>一、跟踪会话标识（Cookie）的接收与存储</p>\n<ol class=\"ybc-ol-component ybc-ol-component_1\">\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>开启浏览器开发者工具</strong>：使用出现问题的浏览器（如奇安信、Chrome），按 <code class=\"hyc-common-markdown__code__inline\">F12</code>打开开发者工具。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>切换到Network/网络面板</strong>：勾选 <strong><code class=\"hyc-common-markdown__code__inline\">Preserve log</code>(保留日志)</strong>​ 复选框，防止页面跳转时日志被清空。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>清空Cookie（可选，为了纯净的测试）</strong>：在开发者工具的 <code class=\"hyc-common-markdown__code__inline\">Application</code>（应用）或 <code class=\"hyc-common-markdown__code__inline\">Storage</code>（存储）标签页下，找到 <code class=\"hyc-common-markdown__code__inline\">Cookies</code>，选中当前系统地址的Cookie，将其删除。这可以模拟一次全新的登录。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>执行登录</strong>：</p>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>在地址栏输入系统单节点地址（如 <code class=\"hyc-common-markdown__code__inline\">http://10.15.9.106/...</code>）进行登录。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>在Network面板中，找到登录请求（通常是 <code class=\"hyc-common-markdown__code__inline\">login</code>或 <code class=\"hyc-common-markdown__code__inline\">j_spring_security_check</code>之类的POST请求）。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>重点查看登录请求的响应</strong>：</p>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>点击这个登录请求，查看 <code class=\"hyc-common-markdown__code__inline\">Response Headers</code>（响应头）。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>你应该能看到一个 <code class=\"hyc-common-markdown__code__inline\">Set-Cookie</code>头，内容类似于 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID=ABCD1234...; Path=/; HttpOnly</code>。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>记录下这个 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code>的值</strong>。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>验证Cookie存储</strong>：</p>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>切换到 <code class=\"hyc-common-markdown__code__inline\">Application/应用</code>标签页。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>在左侧找到 <code class=\"hyc-common-markdown__code__inline\">Cookies</code>-&gt; <code class=\"hyc-common-markdown__code__inline\">http://10.15.9.106</code>。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>检查是否存在一个名为 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code>的Cookie，其值是否与刚才在响应头中看到的一致。</p>\n</li>\n</ul>\n</li>\n</ol>\n<p><strong>至此，我们验证了环节1和2。<span style=\"color: rgba(224, 62, 45, 1);\">如果这里就出问题，那么根源在服务器响应或浏览器安全策略上</span>。</strong></p>\n<p>二、跟踪后续请求的Cookie携带情况</p>\n<ol class=\"ybc-ol-component ybc-ol-component_1\">\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>进行正常操作</strong>：登录成功后，在系统内进行一些不会触发闪退的简单操作，比如点击菜单。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>观察请求</strong>：在Network面板中，观察这些操作触发的Ajax或页面请求。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>检查请求头</strong>：随机点击几个后续请求，查看它们的 <code class=\"hyc-common-markdown__code__inline\">Request Headers</code>（请求头）。</p>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>必须找到一个 <code class=\"hyc-common-markdown__code__inline\">Cookie:</code>头，其内容应包含 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID=ABCD1234...</code>（即登录时设置的那个值）。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>确保每个请求都携带了这个Cookie</strong>。</p>\n</li>\n</ul>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ol\">\n<p><strong>触发闪退（关键步骤）</strong>：</p>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p>进行那个<strong>已知会引发闪退的查询操作</strong>。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>密切观察Network面板</strong>，在点击“查询”按钮后，瞬间发出的请求。</p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>重点检查触发闪退的那个特定查询请求</strong>：</p>\n<ul class=\"ybc-ul-component\">\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>情况A（正常）</strong>：该请求的 <code class=\"hyc-common-markdown__code__inline\">Request Headers</code>里正常携带了 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code>，但服务器返回了一个 <code class=\"hyc-common-markdown__code__inline\">302 Found</code>状态码，Location指向登录页，或者直接返回了登录页的HTML（状态码200）。<strong>这说明问题出在服务器端，服务器主动废弃了会话。</strong></p>\n</li>\n<li class=\"ybc-li-component ybc-li-component_ul\">\n<p><strong>情况B（异常）</strong>：该请求的 <code class=\"hyc-common-markdown__code__inline\">Request Headers</code>里<strong>没有</strong>​ <code class=\"hyc-common-markdown__code__inline\">Cookie</code>头，或者 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code>的值变成了空、错误或一个新的值。<strong>这说明问题出在浏览器端，Cookie在发送前丢失了。</strong></p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p><span style=\"font-size: 16px;\"><strong>第二步：服务器端跟踪（代码与日志层面）</strong></span></p>\n<p>如果浏览器端跟踪指向了“情况A”（Cookie携带正常，但服务器返回登录页），那么问题根因在服务器内部。</p>\n<p>一、启用详细日志记录（最有效的方法）</p>\n<p>如果这个老系统可能日志不全，我们需要临时增加会话跟踪日志。</p>\n<p><strong>1.在<code class=\"hyc-common-markdown__code__inline\">web.xml</code>中配置Session监听器</strong>：</p>\n<p>创建一个类，实现 <code class=\"hyc-common-markdown__code__inline\">HttpSessionListener</code>和 <code class=\"hyc-common-markdown__code__inline\">HttpSessionAttributeListener</code>接口，并部署到生产环境。这个类可以记录Session的创建、销毁和属性变化。</p>\n<pre class=\"language-java highlighter-hljs\"><code>import javax.servlet.http.HttpSessionEvent;\nimport javax.servlet.http.HttpSessionAttributeListener;\nimport javax.servlet.http.HttpSessionBindingEvent;\nimport java.util.logging.Logger; // 或使用Log4j、Slf4j\n\npublic class SessionDebugListener implements HttpSessionListener, HttpSessionAttributeListener {\n\n    private static final Logger logger = Logger.getLogger(SessionDebugListener.class.getName());\n\n    @Override\n    public void sessionCreated(HttpSessionEvent se) {\n        logger.info(\"！！！ Session被创建: ID=\" + se.getSession().getId() + \"， 时间=\" + new java.util.Date());\n    }\n\n    @Override\n    public void sessionDestroyed(HttpSessionEvent se) {\n        // 这是最关键的信息！会话何时、为何被销毁？\n        logger.info(\"！！！ Session被销毁: ID=\" + se.getSession().getId() + \"， 时间=\" + new java.util.Date() + \"。 最后访问时间: \" + new java.util.Date(se.getSession().getLastAccessedTime()));\n        // 可以在这里打印堆栈信息，看是哪个线程触发了销毁\n        Thread.dumpStack();\n    }\n\n    @Override\n    public void attributeAdded(HttpSessionBindingEvent event) {\n        if (\"user\".equals(event.getName())) { // 监听用户登录属性\n            logger.info(\"！！！ 用户登录成功，User对象被存入Session。 SessionID=\" + event.getSession().getId() + \", User=\" + event.getValue());\n        }\n    }\n\n    @Override\n    public void attributeRemoved(HttpSessionBindingEvent event) {\n        if (\"user\".equals(event.getName())) { // 监听用户登出属性\n            logger.info(\"！！！ 用户登出，User对象从Session移除。 SessionID=\" + event.getSession().getId());\n        }\n    }\n}</code></pre>\n<p>在 <code class=\"hyc-common-markdown__code__inline\">web.xml</code>中注册：</p>\n<pre class=\"language-xml highlighter-hljs\"><code>&lt;listener&gt;\n    &lt;listener-class&gt;com.yourcompany.SessionDebugListener&lt;/listener-class&gt;\n&lt;/listener&gt;</code></pre>\n<p><strong>2.在过滤器中记录请求</strong>：</p>\n<p>在一个全局的Filter中（如果已有，则修改它），记录每个请求的Session状态。</p>\n<pre class=\"language-java highlighter-hljs\"><code>public class SessionTrackingFilter implements Filter {\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n        HttpServletRequest req = (HttpServletRequest) request;\n        HttpServletResponse res = (HttpServletResponse) response;\n\n        String sessionId = req.getRequestedSessionId();\n        boolean sessionValid = req.isRequestedSessionIdValid();\n\n        logger.info(\"请求进入: URI=\" + req.getRequestURI() + \n                   \", SessionID=\" + sessionId + \n                   \", Session是否有效=\" + sessionValid);\n\n        chain.doFilter(request, response);\n\n        // 请求处理后，再次检查Session状态\n        sessionValid = req.isRequestedSessionIdValid();\n        logger.info(\"请求离开: URI=\" + req.getRequestURI() + \n                   \", Session是否有效=\" + sessionValid);\n    }\n}</code></pre>\n<p>部署这些监听器和过滤器后，重现闪退问题。然后立即查看服务器日志，寻找 <code class=\"hyc-common-markdown__code__inline\">！！！ Session被销毁</code>这条关键日志。它会告诉你Session被销毁的精确时间，结合堆栈信息，就能定位到是哪个代码路径或配置触发了销毁。</p>\n<p>二、分析服务器线程栈</p>\n<p>如果怀疑是<strong>会话锁超时</strong>，需要在闪退发生时，立刻获取服务器的线程堆栈快照（<code class=\"hyc-common-markdown__code__inline\">jstack &lt;pid&gt;</code>）。分析快照，看是否有线程长时间持有Session锁（状态为 <code class=\"hyc-common-markdown__code__inline\">RUNNABLE</code>且正在执行查询SQL），而其他线程在等待这个锁（状态为 <code class=\"hyc-common-markdown__code__inline\">BLOCKED</code>）。</p>\n<h3>总结：跟踪流程一览表</h3>\n<div class=\"hyc-common-markdown__table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>\n<p>步骤</p>\n</th>\n<th>\n<p>跟踪点</p>\n</th>\n<th>\n<p>方法</p>\n</th>\n<th>\n<p>期望结果</p>\n</th>\n<th>\n<p>异常结果与含义</p>\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n<p><strong>1</strong>​</p>\n</td>\n<td>\n<p><strong>浏览器接收Cookie</strong>​</p>\n</td>\n<td>\n<p>F12 -&gt; Network -&gt; 查看登录请求的 <code class=\"hyc-common-markdown__code__inline\">Set-Cookie</code>响应头</p>\n</td>\n<td>\n<p>收到正确的 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code></p>\n</td>\n<td>\n<p>未收到：服务器响应问题</p>\n</td>\n</tr>\n<tr>\n<td>\n<p><strong>2</strong>​</p>\n</td>\n<td>\n<p><strong>浏览器存储Cookie</strong>​</p>\n</td>\n<td>\n<p>F12 -&gt; Application -&gt; Cookies</p>\n</td>\n<td>\n<p>存储了正确的 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code></p>\n</td>\n<td>\n<p>未存储：浏览器安全策略阻止</p>\n</td>\n</tr>\n<tr>\n<td>\n<p><strong>3</strong>​</p>\n</td>\n<td>\n<p><strong>后续请求携带Cookie</strong>​</p>\n</td>\n<td>\n<p>F12 -&gt; Network -&gt; 查看查询请求的 <code class=\"hyc-common-markdown__code__inline\">Cookie</code>请求头</p>\n</td>\n<td>\n<p>携带了登录时的 <code class=\"hyc-common-markdown__code__inline\">JSESSIONID</code></p>\n</td>\n<td>\n<p>未携带/值错误：浏览器端Cookie丢失</p>\n</td>\n</tr>\n<tr>\n<td>\n<p><strong>4</strong>​</p>\n</td>\n<td>\n<p><strong>服务器处理请求</strong>​</p>\n</td>\n<td>\n<p>查看服务器日志/监听器日志</p>\n</td>\n<td>\n<p>Session有效，请求正常处理</p>\n</td>\n<td>\n<p>日志显示Session被销毁：服务器端主动废弃会话</p>\n</td>\n</tr>\n<tr>\n<td>\n<p><strong>5</strong>​</p>\n</td>\n<td>\n<p><strong>服务器并发情况</strong>​</p>\n</td>\n<td>\n<p>分析线程堆栈快照 (<code class=\"hyc-common-markdown__code__inline\">jstack</code>)</p>\n</td>\n<td>\n<p>无长时间锁等待</p>\n</td>\n<td>\n<p>有线程因等待Session锁而阻塞：会话锁超时问题</p>\n</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>请按照这个流程进行操作，很大概率能直接定位到问题发生的具体环节。先从<strong>浏览器端跟踪</strong>开始，这通常能给出最直接的线索。</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 15:22</span>&nbsp;\n<a href=\"https://www.cnblogs.com/liuyangjava\">子墨老师</a>&nbsp;\n阅读(<span id=\"post_view_count\">123</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Docker 升级后 VS Code 本地调试 AWS Lambda 报「Running AWS SAM projects locally requires Docker」的那些坑与排查思路",
      "link": "https://www.cnblogs.com/wanghaiwei/p/19505845",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wanghaiwei/p/19505845\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 11:48\">\n    <span>Docker 升级后 VS Code 本地调试 AWS Lambda 报「Running AWS SAM projects locally requires Docker」的那些坑与排查思路</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"一问题场景描述\">一、问题场景描述</h2>\n<ul>\n<li>\n<p>在 VS Code 中使用 AWS Toolkit 本地调试 Lambda（基于 AWS SAM 项目）时，点击本地运行/调试，出现提示：<br />\n“Running AWS SAM projects locally requires Docker. Have you got it installed and running?”</p>\n</li>\n<li>\n<p>实际情况是：本地已经安装并运行 Docker Desktop，使用命令行执行&nbsp;<code>docker ps</code>、<code>docker info</code>&nbsp;等都正常，容器环境可用。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n<li>\n<p>换句话说：<strong>Docker 明明在跑，但 VS Code + SAM CLI 坚持说“找不到 Docker”</strong>。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n</ul>\n<hr />\n<h2 id=\"二最终确认的根因你这次遇到的\">二、最终确认的根因（你这次遇到的）</h2>\n<ul>\n<li>\n<p>你找到的最终原因是：<strong>在升级 Docker Desktop 之后，本地的 AWS SAM CLI 以及关系紧密的 AWS 工具链（如 VS Code 插件）版本没有同步升级，导致与新 Docker 版本的 API/行为不兼容</strong>。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n<li>\n<p>升级 AWS SAM CLI 和 AWS 相关插件到最新版本后，错误提示消失，本地调试恢复正常。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]</p>\n</li>\n<li>\n<p>升级方法：跟着官方文档重新下载安装包，会自动升级：<a href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html#install-sam-cli-instructions%E2%80%8B\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html#install-sam-cli-instructions​</a></p>\n</li>\n</ul>\n<p>这一点可以作为你分享里的“主线故事”——“隐形的版本兼容问题”。</p>\n<hr />\n<h2 id=\"三可能的原因总览可用作分享中的-checklist\">三、可能的原因总览（可用作分享中的 checklist）</h2>\n<p>你可以按“从最基础到偏高级”的顺序介绍，帮助听众形成排查思路。</p>\n<h3 id=\"31-docker-本身真的没装--没启动\">3.1 Docker 本身真的没装 / 没启动</h3>\n<p>虽然看起来很基础，但在团队里经常是最真实的情况，可以简要提一下。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n<ul>\n<li>\n<p>未安装 Docker Desktop 或其他 Docker 引擎。</p>\n</li>\n<li>\n<p>Docker Desktop 已安装，但当前没有启动（托盘图标还在 starting / 未 running 状态）。</p>\n</li>\n<li>\n<p>在 VS Code 集成终端中运行&nbsp;<code>docker ps</code>&nbsp;报“Cannot connect to the Docker daemon”等错误。</p>\n</li>\n</ul>\n<p><strong>定位方式</strong></p>\n<ul>\n<li>\n<p>打开 VS Code 集成终端，执行&nbsp;<code>docker ps</code>、<code>docker info</code>。</p>\n</li>\n<li>\n<p>如果这里都失败，基本优先检查 Docker 安装和启动状态。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n</ul>\n<hr />\n<h3 id=\"32-vs-code-所在环境与-docker-不在同一个世界\">3.2 VS Code 所在环境与 Docker 不在同一个“世界”</h3>\n<p>这是第二类很常见的问题：<strong>你在 A 终端里能用 Docker，但 VS Code 使用的是 B 环境</strong>。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n<p>典型情形：</p>\n<ul>\n<li>\n<p>在 Windows 上用 WSL 打开工程，而 Docker Desktop 只在 Windows 环境可见；VS Code 的调试在 WSL 里跑，WSL 内没有可用的 Docker socket。</p>\n</li>\n<li>\n<p>使用 Dev Container / Remote-SSH / Remote-WSL 等远程开发模式，但容器/远程环境内部没有 Docker 或没有映射 Docker socket。</p>\n</li>\n<li>\n<p>手动开终端时用的是一个 shell profile，设置了一些变量或 alias，而 VS Code 集成终端没有加载同样的配置。</p>\n</li>\n</ul>\n<p><strong>定位方式</strong></p>\n<ul>\n<li>\n<p>一律在 VS Code 集成终端中执行：<code>docker ps</code>、<code>sam local invoke</code>，看输出和普通终端是否一致。</p>\n</li>\n<li>\n<p>如果普通终端 OK，VS Code 里失败，就可以讲：<br />\n“问题在于 VS Code 运行 SAM CLI 的环境，与我平时用的终端环境不一样。”[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n</ul>\n<hr />\n<h3 id=\"33-docker_host--docker-context-配置把-sam-带偏\">3.3 DOCKER_HOST / Docker context 配置把 SAM “带偏”</h3>\n<p>当使用过远程 Docker、Colima、Rancher Desktop 等工具时，很容易留下旧的&nbsp;<code>DOCKER_HOST</code>&nbsp;环境变量或非默认 Docker context。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n<p><strong>典型问题</strong></p>\n<ul>\n<li>\n<p><code>DOCKER_HOST</code>&nbsp;指向一个已经不存在或不可达的远程 Docker。</p>\n</li>\n<li>\n<p>当前 Docker context 是某个远程/实验环境，而不是本地 Desktop。</p>\n</li>\n<li>\n<p>用&nbsp;<code>docker ps</code>&nbsp;可能还显示得正常，但实际连的是某个奇怪的 host。</p>\n</li>\n</ul>\n<p><strong>排查与修复</strong></p>\n<ul>\n<li>\n<p>在 VS Code 集成终端中查看环境变量：</p>\n<ul>\n<li>\n<p>Linux/macOS:&nbsp;<code>env | grep DOCKER_HOST</code></p>\n</li>\n<li>\n<p>PowerShell:&nbsp;<code>Get-ChildItem Env:DOCKER_HOST</code></p>\n</li>\n</ul>\n</li>\n<li>\n<p>如果有值，可以尝试临时&nbsp;<code>unset</code>&nbsp;/&nbsp;<code>Remove-Item Env:DOCKER_HOST</code>，再试一次本地调试。</p>\n</li>\n<li>\n<p>查看 Docker context：<code>docker context ls</code>，确认当前 active 的 context 是否是预期的本地环境。</p>\n</li>\n<li>\n<p>若问题解决，可以在分享中强调：<br />\n“遇到 Docker 明明在跑却被认为‘不可用’时，记得检查 DOCKER_HOST 和 docker context。”[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n</ul>\n<hr />\n<h3 id=\"34-docker-版本升级后sam-cli--工具链版本太旧你的实际案例\">3.4 Docker 版本升级后，SAM CLI / 工具链版本太旧（你的实际案例）</h3>\n<p>这是你这次遇到的核心原因，也非常适合重点讲解。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n<p><strong>现象</strong></p>\n<ul>\n<li>\n<p>Docker Desktop 升级到新版本之后，<code>docker ps</code>&nbsp;等命令都正常。</p>\n</li>\n<li>\n<p>但通过 VS Code（AWS Toolkit）点击本地运行 Lambda，提示仍然是 “Running AWS SAM projects locally requires Docker…”。</p>\n</li>\n<li>\n<p>手动在终端执行&nbsp;<code>sam local invoke</code>&nbsp;或&nbsp;<code>sam local start-api</code>&nbsp;可能也会报类似“Docker 不可达”或 API 相关的错误。</p>\n</li>\n</ul>\n<p><strong>原因</strong></p>\n<ul>\n<li>\n<p>老版本的 AWS SAM CLI 内部依赖的 Docker 客户端库，对新 Docker API 或某些行为不兼容。</p>\n</li>\n<li>\n<p>VS Code 的 AWS Toolkit 也有对 SAM CLI 或 Docker 的版本要求，如果太旧，检测逻辑会失败。</p>\n</li>\n<li>\n<p>结果就是：<strong>Docker 实际可用，但健康检查阶段就“挂了”，于是前端统一抛出“需要安装 Docker”这种误导性的错误信息</strong>。[<a href=\"https://stackoverflow.com/questions/50791354/running-aws-sam-projects-locally-get-error\" rel=\"noopener nofollow\" target=\"_blank\">stackoverflow</a>]​</p>\n</li>\n</ul>\n<p><strong>解决方式</strong></p>\n<ul>\n<li>\n<p>升级 AWS SAM CLI 到最新稳定版本。</p>\n</li>\n<li>\n<p>升级 VS Code 中的 AWS Toolkit（以及如有需要的 AWS CLI 等依赖）。</p>\n</li>\n<li>\n<p>升级后再次尝试本地运行 Lambda，问题消失。</p>\n</li>\n</ul>\n<p>这一段可以作为你分享里“真正踩坑”的部分，强调“Docker 升级后别忘了升级 SAM / 工具链”。</p>\n<hr />\n<h2 id=\"四推荐的排查顺序可以直接投屏的一张-slide\">四、推荐的排查顺序（可以直接投屏的一张 slide）</h2>\n<p>你可以整理成一个“故障排查流程”：</p>\n<ol>\n<li>\n<p><strong>确认 Docker 真的在 VS Code 环境里可用</strong></p>\n<ul>\n<li>在 VS Code 集成终端执行&nbsp;<code>docker ps</code>、<code>docker info</code>。</li>\n</ul>\n</li>\n<li>\n<p><strong>检查环境是否一致</strong></p>\n<ul>\n<li>\n<p>是否在 WSL / Dev Container / 远程环境中？</p>\n</li>\n<li>\n<p>这些环境里是否也安装/映射了 Docker？</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>检查 DOCKER_HOST 和 Docker context</strong></p>\n<ul>\n<li>移除可疑的&nbsp;<code>DOCKER_HOST</code>；确认当前 context 正确。</li>\n</ul>\n</li>\n<li>\n<p><strong>检查版本兼容</strong></p>\n<ul>\n<li>\n<p>Docker Desktop 是否刚升级？</p>\n</li>\n<li>\n<p><code>sam --version</code>&nbsp;是否很老？</p>\n</li>\n<li>\n<p>升级 AWS SAM CLI、AWS Toolkit 等工具到最新版本。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>再次从 VS Code 中发起本地调试</strong></p>\n<ul>\n<li>验证问题是否解决。</li>\n</ul>\n</li>\n</ol>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 11:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wanghaiwei\">游学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">89</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "APEX实战第10篇：手把手教你给APEX打补丁",
      "link": "https://www.cnblogs.com/jyzhao/p/19508942/apex-shi-zhan-di10pian-shou-ba-shou-jiao-ni-geiape",
      "published": "",
      "description": "<a name=\"top\"></a>\n    <h2><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jyzhao/p/19508942/apex-shi-zhan-di10pian-shou-ba-shou-jiao-ni-geiape\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 22:15\">\n    <span>APEX实战第10篇：手把手教你给APEX打补丁</span>\n    \n\n</a>\n</h2>\n    <small>\n<span id=\"post-date\">2026-01-20 22:15</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jyzhao\">AlfredZhao</a>&nbsp;\n阅读(<span id=\"post_view_count\">11</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</small>\n    <div class=\"entry\">\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>这一期技术上没什么难度，但却很重要，因为任何企业级软件，定期应用补丁是很必要的，可以有效规避很多已知bug。</p>\n<p>下面我们就以 <code>APEX 24.2</code> 版本为例，使用MOS可以直接搜到最新的补丁集信息，这是一个月前才发布的bundle包，其中已经包含了目前最新的 <code>24.2.12</code> 补丁集：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260120221500169-644256984.jpg\" /></p>\n<p>点击 <code>Download</code>，下载，只有2.6M大小。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260120221500138-290754377.jpg\" /></p>\n<p>然后严格按照README说明进行操作即可。这里按照笔者的Linux环境，实际执行步骤如下：</p>\n<h2 id=\"1下载的补丁介质上传到apex环境的任意目录下\">1.下载的补丁介质上传到APEX环境的任意目录下</h2>\n<ul>\n<li>p37366599_242_GENERIC.zip</li>\n</ul>\n<h2 id=\"2解压补丁介质\">2.解压补丁介质</h2>\n<ul>\n<li>unzip p37366599_242_GENERIC.zip</li>\n</ul>\n<h2 id=\"3关闭ords服务\">3.关闭ORDS服务</h2>\n<p>安装时要求关闭ORDS以阻止对ORDS和APEX的访问：</p>\n<blockquote>\n<ol start=\"3\">\n<li>\n<p>Preventing Access to Oracle REST Data Services</p>\n<p>It is important that no developers or end users access Oracle APEX while you are applying the patch. This section describes how to prevent access to Oracle APEX.</p>\n<p>Stopping Oracle REST Data Services:</p>\n<p>To learn more about stopping the Oracle REST Data Services server, see Oracle REST Data Services Installation and Configuration Guide:</p>\n<p><a href=\"https://docs.oracle.com/en/database/oracle/oracle-rest-data-services/index.html\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.oracle.com/en/database/oracle/oracle-rest-data-services/index.html</a></p>\n</li>\n</ol>\n</blockquote>\n<h2 id=\"4切换到37366599目录下\">4.切换到37366599目录下</h2>\n<ul>\n<li>cd 37366599</li>\n</ul>\n<h2 id=\"5设置nls_lang环境变量\">5.设置NLS_LANG环境变量</h2>\n<ul>\n<li>NLS_LANG=American_America.AL32UTF8</li>\n<li>export NLS_LANG</li>\n</ul>\n<h2 id=\"6sys用户执行脚本\">6.sys用户执行脚本</h2>\n<p>官方安装说明详细的给出了几种不同情况，对应笔者实际情况，只是在某一个PDB下安装了APEX，<br />\n因此这里只在安装了APEX的PDB下执行这个脚本即可：</p>\n<ul>\n<li>@catpatch.sql</li>\n</ul>\n<p>执行完成，确认没有报错，再查询下APEX组件状态OK：</p>\n<pre><code class=\"language-SQL\">SELECT comp_id, comp_name, version, status \nFROM dba_registry \nWHERE comp_id = 'APEX';\n</code></pre>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260120221500130-878148293.jpg\" /></p>\n<h2 id=\"7-针对images目录的更新\">7. 针对images目录的更新</h2>\n<blockquote>\n<p>Install the Patch Set Exception's changes in the images directory</p>\n<p>cp -rf /tmp/images ORACLE_APEX_HOME/apex</p>\n</blockquote>\n<p>笔者注：特别需要注意下这个拷贝，最好先使用命令 <code>ords config list</code> 查询确认下，自己的配置是否相同，比如笔者这里路径就不是默认的images：</p>\n<blockquote>\n<p>standalone.static.path                   /u02/app/apex/apex_images              Global</p>\n</blockquote>\n<p>这是因为笔者之前安装是把原本的images复制了一份apex_images，所以这里应该把新的images下面的文件拷贝到apex_images这个目录下才对，如果你没有这样的情况，就直接复制命令即可。</p>\n<h2 id=\"8启动ords登录apex验证\">8.启动ORDS，登录APEX验证</h2>\n<p>一切正常，APEX主页这里 <code>Available Updates</code> 显示系统已是最新状态：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260120221500019-1301140551.jpg\" /></p>\n<p>APEX界面的右下角还可以看到具体版本号，就是我们本次安装的 <code>Oracle APEX 24.2.12</code>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/635610/202601/635610-20260120221459988-1096283148.jpg\" /></p>\n<p>至此，已完成给APEX打补丁的全部工作。</p>\n\n</div>\n<div id=\"MySignature\">\n    <a href=\"https://www.cnblogs.com/jyzhao/\" target=\"_blank\">AlfredZhao</a>©版权所有「从Oracle起航，领略精彩的IT技术。」<br />\n转载请注明原文链接：<a href=\"https://www.cnblogs.com/jyzhao/p/19508942/apex-shi-zhan-di10pian-shou-ba-shou-jiao-ni-geiape\" target=\"_blank\">https://www.cnblogs.com/jyzhao/p/19508942/apex-shi-zhan-di10pian-shou-ba-shou-jiao-ni-geiape</a>\n<hr />\n<div style=\"text-align: center; margin-top: 30px;\">\n  <p style=\"font-size: 14px; color: #555;\">\n    👋 感谢阅读，欢迎关注我的公众号 <b>「赵靖宇」</b>\n  </p>\n  <img src=\"https://images.cnblogs.com/cnblogs_com/jyzhao/824234/o_250208075013_qrcode-zjy.jpg\" style=\"border: 1px solid #ddd; border-radius: 8px;\" width=\"160\" />\n</div>\n</div>\n<div class=\"clear\"></div>\n\n        <div class=\"clear\"></div>\n        \n</div>\n    <ul class=\"postmetadata\">\n        \n    </ul>"
    },
    {
      "title": "Flink源码阅读：Kafka Connector",
      "link": "https://www.cnblogs.com/Jackeyzhe/p/19508927",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Jackeyzhe/p/19508927\" id=\"cb_post_title_url\" title=\"发布于 2026-01-20 22:03\">\n    <span>Flink源码阅读：Kafka Connector</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"Flink源码阅读：Kafka Connector\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1828322/202601/1828322-20260120220247061-350106518.png\" />\n        本文我们来梳理 Kafka Connector 相关的源码。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>本文我们来梳理 Kafka Connector 相关的源码。</p>\n<h3 id=\"自定义-source-和-sink\">自定义 Source 和 Sink</h3>\n<p>在介绍 Kafka Connector 之前，我们先来看一下在 Flink 中是如何支持自定义 Source 和 Sink 的。我们来看一张 Flink 官方文档提供的图。</p>\n<p><img alt=\"tableconnector\" class=\"lazyload\" /></p>\n<p>这张图展示了 Connector 的基本体系结构，三层架构也非常清晰。</p>\n<h4 id=\"metadata\">Metadata</h4>\n<p>首先是最上层的 MetaData，CREATE TABLE 会更新 Catalog，然后被转换为 TableAPI 的 CatalogTable，CatalogTable 实例用于表示动态表（Source 或 Sink 表）的元信息。</p>\n<h4 id=\"planning\">Planning</h4>\n<p>在解析和优化程序时，会将 CatalogTable 转换为 DynamicTableSource 和 DynamicTableSink，分别用于查询和插入数据，这两个实例的创建都需要对应的工厂类，工厂类的完整路径需要放到这个配置文件中。</p>\n<pre><code class=\"language-bash\">META-INF/services/org.apache.flink.table.factories.Factory\n</code></pre>\n<p>如果有需要的话，我们还可以在解析过程中配置编码和解码方法。</p>\n<p>在 Source 端，通过三个接口支持不同的查询能力。</p>\n<ul>\n<li>\n<p>ScanTableSource：用于消费 changelog 流，扫描的数据支持 insert、updata、delete 三种类型。ScanTableSource 还支持很多其他的功能， 都是通过接口提供的。具体可以看参考这个连接</p>\n<pre><code class=\"language-bash\">https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/dev/table/sourcessinks/#source-abilities\n</code></pre>\n</li>\n<li>\n<p>LookupTableSource：LookupTableSource 不会全量读取表的数据，它在需要时会发送请求，懒加载数据。目前只支持 insert-only 变更模式。</p>\n</li>\n<li>\n<p>VectorSearchTableSource：使用一个输入向量来搜索数据，并返回最相似的 Top-K 行数据。</p>\n</li>\n</ul>\n<p>在 Sink 端，通过 DynamicTableSink 来实现具体的写入逻辑，这里也提供了一些用于扩展能力的接口。具体参考</p>\n<pre><code class=\"language-bash\">https://nightlies.apache.org/flink/flink-docs-release-2.2/docs/dev/table/sourcessinks/#sink-abilities\n</code></pre>\n<h4 id=\"runtime\">Runtime</h4>\n<p>逻辑解析完成后，会到 Runtime 层。这里就是定义几个 Provider，在 Provider 中实现和连接器具体的交互逻辑。</p>\n<h4 id=\"小结\">小结</h4>\n<p>当我们需要创建一个自定义的 Source 和 Sink 时，就可以通过以下步骤实现。</p>\n<ol>\n<li>\n<p>定义 Flink SQL 的 DDL，需要定义相应的 Options。</p>\n</li>\n<li>\n<p>实现 DynamicTableSourceFactory 和 DynamicTableSinkFactory，并把实现类的具体路径写到配置文件中。</p>\n</li>\n<li>\n<p>实现 DynamicTableSource 和 DynamicTableSink，这里需要处理 SQL 层的元数据。</p>\n</li>\n<li>\n<p>提供 Provider，将逻辑层与底层 DataStream 关联起来。</p>\n</li>\n<li>\n<p>编写底层算子，实现 Source 和 Sink 接口。</p>\n</li>\n</ol>\n<h3 id=\"kafka-connector-的实现\">Kafka Connector 的实现</h3>\n<p>带着这些知识，我们一起来看一下 Kafka Connector 相关的源码。</p>\n<p>Kafka Connector 代码目前已经是一个独立的项目了。项目地址是</p>\n<pre><code class=\"language-bash\">https://github.com/apache/flink-connector-kafka\n</code></pre>\n<h4 id=\"factory\">Factory</h4>\n<p>我们首先找到定义的工厂类</p>\n<pre><code class=\"language-java\">org.apache.flink.streaming.connectors.kafka.table.KafkaDynamicTableFactory\norg.apache.flink.streaming.connectors.kafka.table.UpsertKafkaDynamicTableFactory\n</code></pre>\n<p>以 KafkaDynamicTableFactory 为例，它同时实现了 DynamicTableSourceFactory 和 DynamicTableSinkFactory 两个接口。</p>\n<p>KafkaDynamicTableFactory 包含以下几个方法。</p>\n<p><img alt=\"KafkaDynamicTableFactory\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>factoryIdentifier：返回一个唯一标识符，对应 Flink SQL 中 connector='xxx' 这个配置。</p>\n</li>\n<li>\n<p>requiredOptions：必填配置集合。</p>\n</li>\n<li>\n<p>optionalOptions：选填配置集合。</p>\n</li>\n<li>\n<p>forwardOptions：直接传递到 Runtime 层的配置集合。</p>\n</li>\n<li>\n<p>createDynamicTableSource：创建 DynamicTableSource。</p>\n</li>\n<li>\n<p>createDynamicTableSink：创建 DynamicTableSink。</p>\n</li>\n</ul>\n<h4 id=\"source-端\">Source 端</h4>\n<p>工厂类的 createDynamicTableSource 方法创建了 DynamicTableSource，我们来看一下创建的逻辑。</p>\n<pre><code class=\"language-java\">public DynamicTableSource createDynamicTableSource(Context context) {\n    final TableFactoryHelper helper = FactoryUtil.createTableFactoryHelper(this, context);\n\n    final Optional&lt;DecodingFormat&lt;DeserializationSchema&lt;RowData&gt;&gt;&gt; keyDecodingFormat =\n            getKeyDecodingFormat(helper);\n\n    final DecodingFormat&lt;DeserializationSchema&lt;RowData&gt;&gt; valueDecodingFormat =\n            getValueDecodingFormat(helper);\n\n    helper.validateExcept(PROPERTIES_PREFIX);\n\n    final ReadableConfig tableOptions = helper.getOptions();\n\n    validateTableSourceOptions(tableOptions);\n\n    validatePKConstraints(\n            context.getObjectIdentifier(),\n            context.getPrimaryKeyIndexes(),\n            context.getCatalogTable().getOptions(),\n            valueDecodingFormat);\n\n    final StartupOptions startupOptions = getStartupOptions(tableOptions);\n\n    final BoundedOptions boundedOptions = getBoundedOptions(tableOptions);\n\n    final Properties properties = getKafkaProperties(context.getCatalogTable().getOptions());\n\n    // add topic-partition discovery\n    final Duration partitionDiscoveryInterval =\n            tableOptions.get(SCAN_TOPIC_PARTITION_DISCOVERY);\n    properties.setProperty(\n            KafkaSourceOptions.PARTITION_DISCOVERY_INTERVAL_MS.key(),\n            Long.toString(partitionDiscoveryInterval.toMillis()));\n\n    final DataType physicalDataType = context.getPhysicalRowDataType();\n\n    final int[] keyProjection = createKeyFormatProjection(tableOptions, physicalDataType);\n\n    final int[] valueProjection = createValueFormatProjection(tableOptions, physicalDataType);\n\n    final String keyPrefix = tableOptions.getOptional(KEY_FIELDS_PREFIX).orElse(null);\n\n    final Integer parallelism = tableOptions.getOptional(SCAN_PARALLELISM).orElse(null);\n\n    return createKafkaTableSource(\n            physicalDataType,\n            keyDecodingFormat.orElse(null),\n            valueDecodingFormat,\n            keyProjection,\n            valueProjection,\n            keyPrefix,\n            getTopics(tableOptions),\n            getTopicPattern(tableOptions),\n            properties,\n            startupOptions.startupMode,\n            startupOptions.specificOffsets,\n            startupOptions.startupTimestampMillis,\n            boundedOptions.boundedMode,\n            boundedOptions.specificOffsets,\n            boundedOptions.boundedTimestampMillis,\n            context.getObjectIdentifier().asSummaryString(),\n            parallelism);\n}\n</code></pre>\n<p>在这个方法中，首先要获取到 key 和 value 的解码格式。接着是各种参数校验和获取必要的属性。最后创建 KafkaDynamicSource 实例。</p>\n<p>获取解码格式需要用到 DeserializationFormatFactory 工厂，DeserializationFormatFactory 有多个实现类，对应了多种格式的反序列化方法。</p>\n<p><img alt=\"DeserializationFormatFactory\" class=\"lazyload\" /></p>\n<p>我们来看比较常见的 Json 格式的工厂 JsonFormatFactory。</p>\n<pre><code class=\"language-java\">public DecodingFormat&lt;DeserializationSchema&lt;RowData&gt;&gt; createDecodingFormat(\n        DynamicTableFactory.Context context, ReadableConfig formatOptions) {\n    FactoryUtil.validateFactoryOptions(this, formatOptions);\n    JsonFormatOptionsUtil.validateDecodingFormatOptions(formatOptions);\n\n    final boolean failOnMissingField = formatOptions.get(FAIL_ON_MISSING_FIELD);\n    final boolean ignoreParseErrors = formatOptions.get(IGNORE_PARSE_ERRORS);\n    final boolean jsonParserEnabled = formatOptions.get(DECODE_JSON_PARSER_ENABLED);\n    TimestampFormat timestampOption = JsonFormatOptionsUtil.getTimestampFormat(formatOptions);\n\n    return new ProjectableDecodingFormat&lt;DeserializationSchema&lt;RowData&gt;&gt;() {\n        @Override\n        public DeserializationSchema&lt;RowData&gt; createRuntimeDecoder(\n                DynamicTableSource.Context context,\n                DataType physicalDataType,\n                int[][] projections) {\n            final DataType producedDataType =\n                    Projection.of(projections).project(physicalDataType);\n            final RowType rowType = (RowType) producedDataType.getLogicalType();\n            final TypeInformation&lt;RowData&gt; rowDataTypeInfo =\n                    context.createTypeInformation(producedDataType);\n            if (jsonParserEnabled) {\n                return new JsonParserRowDataDeserializationSchema(\n                        rowType,\n                        rowDataTypeInfo,\n                        failOnMissingField,\n                        ignoreParseErrors,\n                        timestampOption,\n                        toProjectedNames(\n                                (RowType) physicalDataType.getLogicalType(), projections));\n            } else {\n                return new JsonRowDataDeserializationSchema(\n                        rowType,\n                        rowDataTypeInfo,\n                        failOnMissingField,\n                        ignoreParseErrors,\n                        timestampOption);\n            }\n        }\n\n        @Override\n        public ChangelogMode getChangelogMode() {\n            return ChangelogMode.insertOnly();\n        }\n\n        @Override\n        public boolean supportsNestedProjection() {\n            return jsonParserEnabled;\n        }\n    };\n}\n</code></pre>\n<p>在创建解码格式时，最重要的是创建运行时的解码器，也就是 DeserializationSchema，在 JsonFormatFactory 中，有 JsonParserRowDataDeserializationSchema 和 JsonRowDataDeserializationSchema 两种实现，分别是用于将 JsonParser 和 JsonNode 转换成为 RowData，具体的逻辑都在 createNotNullConverter 方法中。</p>\n<p>了解完解码格式后，我们把视角拉回到 KafkaDynamicSource，它实现了三个接口 ScanTableSource、SupportsReadingMetadata、SupportsWatermarkPushDown。分别用于消费数据，读取元数据和生成水印。</p>\n<pre><code class=\"language-java\">public ScanRuntimeProvider getScanRuntimeProvider(ScanContext context) {\n    final DeserializationSchema&lt;RowData&gt; keyDeserialization =\n            createDeserialization(context, keyDecodingFormat, keyProjection, keyPrefix);\n\n    final DeserializationSchema&lt;RowData&gt; valueDeserialization =\n            createDeserialization(context, valueDecodingFormat, valueProjection, null);\n\n    final TypeInformation&lt;RowData&gt; producedTypeInfo =\n            context.createTypeInformation(producedDataType);\n\n    final KafkaSource&lt;RowData&gt; kafkaSource =\n            createKafkaSource(keyDeserialization, valueDeserialization, producedTypeInfo);\n\n    return new DataStreamScanProvider() {\n        @Override\n        public DataStream&lt;RowData&gt; produceDataStream(\n                ProviderContext providerContext, StreamExecutionEnvironment execEnv) {\n            if (watermarkStrategy == null) {\n                watermarkStrategy = WatermarkStrategy.noWatermarks();\n            }\n            DataStreamSource&lt;RowData&gt; sourceStream =\n                    execEnv.fromSource(\n                            kafkaSource, watermarkStrategy, \"KafkaSource-\" + tableIdentifier);\n            providerContext.generateUid(KAFKA_TRANSFORMATION).ifPresent(sourceStream::uid);\n            return sourceStream;\n        }\n\n        @Override\n        public boolean isBounded() {\n            return kafkaSource.getBoundedness() == Boundedness.BOUNDED;\n        }\n\n        @Override\n        public Optional&lt;Integer&gt; getParallelism() {\n            return Optional.ofNullable(parallelism);\n        }\n    };\n}\n</code></pre>\n<p>在 ScanRuntimeProvider 的逻辑中，先获取到反序列化器，也就是刚刚我们提到的 DeserializationSchema。</p>\n<p><img alt=\"KafkaSource\" class=\"lazyload\" /></p>\n<p>然后开始创建 KafkaSource 实例，它是 Source 的实现类，也就是执行引擎层了，这个过程会依次创建图中这些类。</p>\n<p>KafkaSource 中主要是创建 KafkaSourceReader 和 KafkaSourceEnumerator，KafkaSourceEnumerator 是负责和分片相关的逻辑，包括分片分配和分片发现等。</p>\n<p>KafkaSourceReader 中主要是和 State 相关的逻辑，包括触发快照和完成 Checkpoint 通知的方法。当做 Snapshot 时，会记录活跃 split 的 offset，同时将 split 作为状态提交。当 Checkpoint 完成时，会调用 <code>KafkaSourceFetcherManager.commitOffsets</code> 提交 offset。</p>\n<pre><code class=\"language-java\">public List&lt;KafkaPartitionSplit&gt; snapshotState(long checkpointId) {\n    List&lt;KafkaPartitionSplit&gt; splits = super.snapshotState(checkpointId);\n    if (!commitOffsetsOnCheckpoint) {\n        return splits;\n    }\n\n    if (splits.isEmpty() &amp;&amp; offsetsOfFinishedSplits.isEmpty()) {\n        offsetsToCommit.put(checkpointId, Collections.emptyMap());\n    } else {\n        Map&lt;TopicPartition, OffsetAndMetadata&gt; offsetsMap =\n                offsetsToCommit.computeIfAbsent(checkpointId, id -&gt; new HashMap&lt;&gt;());\n        // Put the offsets of the active splits.\n        for (KafkaPartitionSplit split : splits) {\n            // If the checkpoint is triggered before the partition starting offsets\n            // is retrieved, do not commit the offsets for those partitions.\n            if (split.getStartingOffset() &gt;= 0) {\n                offsetsMap.put(\n                        split.getTopicPartition(),\n                        new OffsetAndMetadata(split.getStartingOffset()));\n            }\n        }\n        // Put offsets of all the finished splits.\n        offsetsMap.putAll(offsetsOfFinishedSplits);\n    }\n    return splits;\n}\n\n\npublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n    LOG.debug(\"Committing offsets for checkpoint {}\", checkpointId);\n    ...\n\n    ((KafkaSourceFetcherManager) splitFetcherManager)\n            .commitOffsets(\n                    committedPartitions,\n                    (ignored, e) -&gt; {...});\n}\n</code></pre>\n<p>KafkaSourceFetcherManager 负责管理 fetcher 线程，提交 Offset。</p>\n<p>KafkaPartitionSplitReader 的 fetch 方法用来消费 Kafka 的数据。</p>\n<pre><code class=\"language-java\">public RecordsWithSplitIds&lt;ConsumerRecord&lt;byte[], byte[]&gt;&gt; fetch() throws IOException {\n    ConsumerRecords&lt;byte[], byte[]&gt; consumerRecords;\n    try {\n        consumerRecords = consumer.poll(Duration.ofMillis(POLL_TIMEOUT));\n    } catch (WakeupException | IllegalStateException e) {\n        // IllegalStateException will be thrown if the consumer is not assigned any partitions.\n        // This happens if all assigned partitions are invalid or empty (starting offset &gt;=\n        // stopping offset). We just mark empty partitions as finished and return an empty\n        // record container, and this consumer will be closed by SplitFetcherManager.\n        KafkaPartitionSplitRecords recordsBySplits =\n                new KafkaPartitionSplitRecords(\n                        ConsumerRecords.empty(), kafkaSourceReaderMetrics);\n        markEmptySplitsAsFinished(recordsBySplits);\n        return recordsBySplits;\n    }\n    KafkaPartitionSplitRecords recordsBySplits =\n            new KafkaPartitionSplitRecords(consumerRecords, kafkaSourceReaderMetrics);\n    List&lt;TopicPartition&gt; finishedPartitions = new ArrayList&lt;&gt;();\n    for (TopicPartition tp : consumer.assignment()) {\n        long stoppingOffset = getStoppingOffset(tp);\n        long consumerPosition = getConsumerPosition(tp, \"retrieving consumer position\");\n        // Stop fetching when the consumer's position reaches the stoppingOffset.\n        // Control messages may follow the last record; therefore, using the last record's\n        // offset as a stopping condition could result in indefinite blocking.\n        if (consumerPosition &gt;= stoppingOffset) {\n            LOG.debug(\n                    \"Position of {}: {}, has reached stopping offset: {}\",\n                    tp,\n                    consumerPosition,\n                    stoppingOffset);\n            recordsBySplits.setPartitionStoppingOffset(tp, stoppingOffset);\n            finishSplitAtRecord(\n                    tp, stoppingOffset, consumerPosition, finishedPartitions, recordsBySplits);\n        }\n    }\n\n    // Only track non-empty partition's record lag if it never appears before\n    consumerRecords\n            .partitions()\n            .forEach(\n                    trackTp -&gt; {\n                        kafkaSourceReaderMetrics.maybeAddRecordsLagMetric(consumer, trackTp);\n                    });\n\n    markEmptySplitsAsFinished(recordsBySplits);\n\n    // Unassign the partitions that has finished.\n    if (!finishedPartitions.isEmpty()) {\n        finishedPartitions.forEach(kafkaSourceReaderMetrics::removeRecordsLagMetric);\n        unassignPartitions(finishedPartitions);\n    }\n\n    // Update numBytesIn\n    kafkaSourceReaderMetrics.updateNumBytesInCounter();\n\n    return recordsBySplits;\n}\n</code></pre>\n<p>至此，Source 端相关的源码我们就梳理完了。接下来我们再看 Sink 端的代码。</p>\n<h4 id=\"sink-端\">Sink 端</h4>\n<p>我们从工厂类中的 createDynamicTableSink 方法开始。</p>\n<pre><code class=\"language-java\">public DynamicTableSink createDynamicTableSink(Context context) {\n    final TableFactoryHelper helper =\n            FactoryUtil.createTableFactoryHelper(\n                    this, autoCompleteSchemaRegistrySubject(context));\n\n    final Optional&lt;EncodingFormat&lt;SerializationSchema&lt;RowData&gt;&gt;&gt; keyEncodingFormat =\n            getKeyEncodingFormat(helper);\n\n    final EncodingFormat&lt;SerializationSchema&lt;RowData&gt;&gt; valueEncodingFormat =\n            getValueEncodingFormat(helper);\n\n    helper.validateExcept(PROPERTIES_PREFIX);\n\n    final ReadableConfig tableOptions = helper.getOptions();\n\n    final DeliveryGuarantee deliveryGuarantee = validateDeprecatedSemantic(tableOptions);\n    validateTableSinkOptions(tableOptions);\n\n    KafkaConnectorOptionsUtil.validateDeliveryGuarantee(tableOptions);\n\n    validatePKConstraints(\n            context.getObjectIdentifier(),\n            context.getPrimaryKeyIndexes(),\n            context.getCatalogTable().getOptions(),\n            valueEncodingFormat);\n\n    final DataType physicalDataType = context.getPhysicalRowDataType();\n\n    final int[] keyProjection = createKeyFormatProjection(tableOptions, physicalDataType);\n\n    final int[] valueProjection = createValueFormatProjection(tableOptions, physicalDataType);\n\n    final String keyPrefix = tableOptions.getOptional(KEY_FIELDS_PREFIX).orElse(null);\n\n    final Integer parallelism = tableOptions.getOptional(SINK_PARALLELISM).orElse(null);\n\n    return createKafkaTableSink(\n            physicalDataType,\n            keyEncodingFormat.orElse(null),\n            valueEncodingFormat,\n            keyProjection,\n            valueProjection,\n            keyPrefix,\n            getTopics(tableOptions),\n            getTopicPattern(tableOptions),\n            getKafkaProperties(context.getCatalogTable().getOptions()),\n            getFlinkKafkaPartitioner(tableOptions, context.getClassLoader()).orElse(null),\n            deliveryGuarantee,\n            parallelism,\n            tableOptions.get(TRANSACTIONAL_ID_PREFIX),\n            tableOptions.get(TRANSACTION_NAMING_STRATEGY));\n}\n</code></pre>\n<p>和 Source 的流程很相似，这里首先是获取 key 和 value 的编码格式，然后做了很多校验，最后是创建 KafkaDynamicSink 实例。</p>\n<p>获取编码格式用到的工厂类是 SerializationFormatFactory，我们前面介绍的 JsonFormatFactory 也实现了 SerializationFormatFactory，因此它既提供了解码格式，又提供了编码格式。编码格式用到的编码器是 JsonRowDataSerializationSchema，通过 RowDataToJsonConverters 将 RowData 转换成 JsonNode。</p>\n<p>在 KafkaDynamicSink 的 getSinkRuntimeProvider 方法中，主要就是创建 KafkaSink 实例。</p>\n<p><img alt=\"KafkaSink\" class=\"lazyload\" /></p>\n<p>KafkaSink 类实现了 TwoPhaseCommittingStatefulSink 接口，即支持两阶段提交。它创建了 KafkaWrter 和 KafkaCommiter。</p>\n<p>创建 KafkaWriter 时，如果配置的是 ExactlyOnce 模式，则会创建出 ExactlyOnceKafkaWriter，否则创建 KafkaWriter。Writer 真正实现两阶段提交的是 ExactlyOnceKafkaWriter。它在启动时，会调用 <code>producer.beginTransaction</code> 开启一个事务。数据写入时会调用 <code>KafkaWriter.write</code> 方法，此操作会被标记为事务内的操作。当 Sink 收到 Barrier 时，会先调用 flush 方法，将缓冲区的数据都发送到 Kafka Broker，然后调用 prepareCommit 方法预提交。预提交方法中记录 epoch 和 transactionalId 返回给框架层。</p>\n<pre><code class=\"language-java\">public Collection&lt;KafkaCommittable&gt; prepareCommit() {\n    // only return a KafkaCommittable if the current transaction has been written some data\n    if (currentProducer.hasRecordsInTransaction()) {\n        KafkaCommittable committable = KafkaCommittable.of(currentProducer);\n        LOG.debug(\"Prepare {}.\", committable);\n        currentProducer.precommitTransaction();\n        return Collections.singletonList(committable);\n    }\n\n    // otherwise, we recycle the producer (the pool will reset the transaction state)\n    producerPool.recycle(currentProducer);\n    return Collections.emptyList();\n}\n</code></pre>\n<p>状态保存时，会将预提交的 transactionalId 存到状态中。</p>\n<pre><code class=\"language-java\">public List&lt;KafkaWriterState&gt; snapshotState(long checkpointId) throws IOException {\n    // recycle committed producers\n    TransactionFinished finishedTransaction;\n    while ((finishedTransaction = backchannel.poll()) != null) {\n        producerPool.recycleByTransactionId(\n                finishedTransaction.getTransactionId(), finishedTransaction.isSuccess());\n    }\n    // persist the ongoing transactions into the state; these will not be aborted on restart\n    Collection&lt;CheckpointTransaction&gt; ongoingTransactions =\n            producerPool.getOngoingTransactions();\n    currentProducer = startTransaction(checkpointId + 1);\n    return createSnapshots(ongoingTransactions);\n}\n\nprivate List&lt;KafkaWriterState&gt; createSnapshots(\n        Collection&lt;CheckpointTransaction&gt; ongoingTransactions) {\n    List&lt;KafkaWriterState&gt; states = new ArrayList&lt;&gt;();\n    int[] subtaskIds = this.ownedSubtaskIds;\n    for (int index = 0; index &lt; subtaskIds.length; index++) {\n        int ownedSubtask = subtaskIds[index];\n        states.add(\n                new KafkaWriterState(\n                        transactionalIdPrefix,\n                        ownedSubtask,\n                        totalNumberOfOwnedSubtasks,\n                        transactionNamingStrategy.getOwnership(),\n                        // new transactions are only created with the first owned subtask id\n                        index == 0 ? ongoingTransactions : List.of()));\n    }\n    LOG.debug(\"Snapshotting state {}\", states);\n    return states;\n}\n</code></pre>\n<p>当 Checkpoint 完成时，会调用 <code>KafkaCommitter.commit</code> 方法。在 commit 方法中会调用 <code>producer.commitTransaction</code> 正式提交事务。</p>\n<p>FlinkKafkaInternalProducer 是 Flink 内部封装的与 Kafka 生产者的交互类，所有与 Kafka 生产者的交互都通过它执行。</p>\n<p>关于 Kafka Connector 的 Sink 端的源码我们就梳理到这里。</p>\n<h3 id=\"总结\">总结</h3>\n<p>最后还是总结一下。本文我们先了解了 Flink 中自定义 Source 和 Sink 的流程。按照这个流程，我们梳理了 Kafka Connector 的源码。在 Source 端，Flink Kafka 封装了对消费者 Offset 的提交逻辑。在 Sink 端结合了 Kafka 提供的事务支持实现了两阶段提交的逻辑。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-20 22:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Jackeyzhe\">Jackeyzhe</a>&nbsp;\n阅读(<span id=\"post_view_count\">4</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}