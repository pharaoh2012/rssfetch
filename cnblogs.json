{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "开源一个自己的作品浏览器插件ChaTab，一键提交Prompt到多个AI应用",
      "link": "https://www.cnblogs.com/jqbird/p/19531428/chatab",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jqbird/p/19531428/chatab\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 09:06\">\n    <span>开源一个自己的作品浏览器插件ChaTab，一键提交Prompt到多个AI应用</span>\n    \n\n</a>\n\n\t\t</h1>\n\t\t<div class=\"clear\"></div>\n\t\t<div class=\"postBody\">\n\t\t\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"chatab-简介\">ChaTab 简介</h1>\n<p>好看也好用的chrome浏览器首页插件，已经在谷歌浏览器商店上架4个月了，代码调整到基本稳定状态了，所以打算把它开源出来。<br />\n每天在用各种AI工具，不同平台切换，非常烦人，所以就自己做了一个这样的工具给自己用，挺好用，所以分享给有类似痛点的用户。</p>\n<h1 id=\"开发工具\">开发工具</h1>\n<p>cursor + claude code</p>\n<p>现在软件开发的成本极大降低，再也不是手工业时代的一针一线的编码了，只要基础架构设计好，AI基本可以完成 90%的设计和编码工作，</p>\n<h1 id=\"插件功能说明\">插件功能说明</h1>\n<ol>\n<li>批量Prompt提交，一键快速批量发送提示词至 ChatGPT、DeepSeek 等多个 AI 应用，提升效率。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>智能背景切换 ， 随机更换 Chrome 启动页背景，让每次开启浏览器都有新鲜感。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>3.应用导航，下拉的时候点击icon快速链接到应用地址。</p>\n<p><img alt=\"2\" class=\"lazyload\" /></p>\n<ol start=\"4\">\n<li>左侧历史记录，点击可以快速填充历史记录到tab里的输入框中。</li>\n</ol>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<h1 id=\"使用说明\">使用说明</h1>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>1、谷歌浏览器商店搜索 \"chatab\"，或者复制链接地址安装：</p>\n<p><a href=\"https://chromewebstore.google.com/detail/chatab/gcbcmnekbambjebgfjnbgopmgcgcealn?hl=zh-CN&amp;utm_source=ext_sidebar\" rel=\"noopener nofollow\" target=\"_blank\">https://chromewebstore.google.com/detail/chatab/gcbcmnekbambjebgfjnbgopmgcgcealn?hl=zh-CN&amp;utm_source=ext_sidebar</a></p>\n<p>2、使用前请先在浏览器中登录 ChatGPT、DeepSeek 等相关平台。插件将为您提供一键提交、多平台切换的便捷体验。</p>\n<p>注意：这个插件会修改浏览器首页。</p>\n<h1 id=\"开源地址\">开源地址</h1>\n<ul>\n<li><a href=\"https://github.com/robotbird/chatab\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/robotbird/chatab</a></li>\n</ul>\n<h1 id=\"关于作者\">关于作者</h1>\n<p>产品经理，热爱哲学，个人博客 <a href=\"http://www.jqpress.com\" rel=\"noopener nofollow\" target=\"_blank\">jqpress.com</a>，微信公众号：产品经理随想曲</p>\n<p><img alt=\"产品经理随想曲\" class=\"lazyload\" /></p>\n\n</div>\n<div class=\"clear\"></div>\n\n\t\t</div>\n\t\t<div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 09:06</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jqbird\">叶鹏</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "HagiCode 实践：如何利用 GitHub Actions 实现 Docusaurus 自动部署",
      "link": "https://www.cnblogs.com/newbe36524/p/19531383",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/newbe36524/p/19531383\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 08:56\">\n    <span>HagiCode 实践：如何利用 GitHub Actions 实现 Docusaurus 自动部署</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"为-hagicode-添加-github-pages-自动部署支持\">为 HagiCode 添加 GitHub Pages 自动部署支持</h1>\n<blockquote>\n<p>本项目早期代号为 PCode，现已正式更名为 HagiCode。本文记录了如何为项目引入自动化静态站点部署能力，让内容发布像喝水一样简单。</p>\n</blockquote>\n\n<h2 id=\"背景引言\">背景/引言</h2>\n<p>在 HagiCode 的开发过程中，我们遇到了一个很现实的问题：随着文档和提案越来越多，如何高效地管理和展示这些内容成了当务之急。我们决定引入 GitHub Pages 来托管我们的静态站点，但是手动构建和部署实在是太麻烦了——每次改动都要本地构建、打包，然后手动推送到 <code>gh-pages</code> 分支。这不仅效率低下，还容易出错。</p>\n<p>为了解决这个问题（主要是为了偷懒），我们需要一套自动化的部署流程。本文将详细记录如何为 HagiCode 项目添加 GitHub Actions 自动部署支持，让我们只需专注于内容创作，剩下的交给自动化流程。</p>\n<h2 id=\"关于-hagicode\">关于 HagiCode</h2>\n<blockquote>\n<p>嘿，介绍一下我们正在做的东西</p>\n</blockquote>\n<p>我们正在开发 <strong>HagiCode</strong>——一款 AI 驱动的代码智能助手，让开发体验变得更智能、更便捷、更有趣。</p>\n<p><strong>智能</strong>——AI 全程辅助，从想法到代码，让编码效率提升数倍。<strong>便捷</strong>——多线程并发操作，充分利用资源，开发流程顺畅无阻。<strong>有趣</strong>——游戏化机制和成就系统，让编码不再枯燥，充满成就感。</p>\n<p>项目正在快速迭代中，如果你对技术写作、知识管理或者 AI 辅助开发感兴趣，欢迎来 <a href=\"https://github.com/HagiCode-org/site\" rel=\"noopener nofollow\" target=\"_blank\">GitHub</a> 看看～</p>\n<h2 id=\"目标分析\">目标分析</h2>\n<p>在动手之前，我们得先明确这次任务到底要干啥。毕竟磨刀不误砍柴工嘛。</p>\n<h3 id=\"核心需求\">核心需求</h3>\n<ol>\n<li><strong>自动化构建</strong>：当代码推送到 <code>main</code> 分支时，自动触发构建流程。</li>\n<li><strong>自动部署</strong>：构建成功后，自动将生成的静态文件部署到 GitHub Pages。</li>\n<li><strong>环境一致性</strong>：确保 CI 环境和本地构建环境一致，避免\"本地能跑，线上报错\"的尴尬。</li>\n</ol>\n<h3 id=\"技术选型\">技术选型</h3>\n<p>考虑到 HagiCode 是基于 Docusaurus 构建的（一种非常流行的 React 静态站点生成器），我们可以利用 GitHub Actions 来实现这一目标。</p>\n<h2 id=\"配置-github-actions-工作流\">配置 GitHub Actions 工作流</h2>\n<p>GitHub Actions 是 GitHub 提供的 CI/CD 服务。通过在代码仓库中定义 YAML 格式的工作流文件，我们可以定制各种自动化任务。</p>\n<h3 id=\"创建工作流文件\">创建工作流文件</h3>\n<p>我们需要在项目根目录下的 <code>.github/workflows</code> 文件夹中创建一个新的配置文件，比如叫 <code>deploy.yml</code>。如果文件夹不存在，记得先手动创建一下。</p>\n<p>这个配置文件的核心逻辑如下：</p>\n<ol>\n<li><strong>触发条件</strong>：监听 <code>main</code> 分支的 <code>push</code> 事件。</li>\n<li><strong>运行环境</strong>：最新版的 Ubuntu。</li>\n<li><strong>构建步骤</strong>：\n<ul>\n<li>检出代码</li>\n<li>安装 Node.js</li>\n<li>安装依赖 (<code>npm install</code>)</li>\n<li>构建静态文件 (<code>npm run build</code>)</li>\n</ul>\n</li>\n<li><strong>部署步骤</strong>：使用官方提供的 <code>action-gh-pages</code> 将构建产物推送到 <code>gh-pages</code> 分支。</li>\n</ol>\n<h3 id=\"关键配置代码\">关键配置代码</h3>\n<p>以下是我们最终采用的配置模板：</p>\n<pre><code class=\"language-yaml\">name: Deploy to GitHub Pages\n\n# 触发条件：当推送到 main 分支时\non:\n  push:\n    branches:\n      - main\n    # 可以根据需要添加路径过滤，比如只有文档变动才构建\n    # paths:\n    #   - 'docs/**'\n    #   - 'package.json'\n\n# 设置权限，这对于部署到 GitHub Pages 很重要\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# 并发控制：取消同一分支的旧构建\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        # 注意：必须设置 fetch-depth: 0，否则可能导致构建版本号不准确\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20 # 建议与本地开发环境保持一致\n          cache: 'npm'     # 启用缓存可以加速构建过程\n\n      - name: Install dependencies\n        run: npm ci\n        # 使用 npm ci 而不是 npm install，因为它更快、更严格，适合 CI 环境\n\n      - name: Build website\n        run: npm run build\n        env:\n          # 如果你的站点构建需要环境变量，在这里配置\n          # NODE_ENV: production\n          # PUBLIC_URL: /your-repo-name\n          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./build # Docusaurus 默认输出目录\n\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n</code></pre>\n<h2 id=\"实施过程中的坑点\">实施过程中的坑点</h2>\n<p>在实际操作中，我们遇到了一些问题，这里分享出来希望大家能避开（或者提前准备好解决方案）。</p>\n<h3 id=\"1-github-token-权限问题\">1. GitHub Token 权限问题</h3>\n<p>最开始配置的时候，部署总是报错 403 (Forbidden)。查了好久才发现，是因为 GitHub 默认的 <code>GITHUB_TOKEN</code> 并没有写入 Pages 的权限。</p>\n<p><strong>解决方案</strong>：在仓库的 <code>Settings</code> -&gt; <code>Actions</code> -&gt; <code>General</code> -&gt; <code>Workflow permissions</code> 中，务必选择 <strong>\"Read and write permissions\"</strong>。</p>\n<h3 id=\"2-构建目录路径错误\">2. 构建目录路径错误</h3>\n<p>Docusaurus 默认把构建好的静态文件放在 <code>build</code> 目录。但是有些项目（比如 Create React App 默认是 <code>build</code>，Vite 默认是 <code>dist</code>）可能配置不一样。如果在 Actions 中报错找不到文件，记得去 <code>docusaurus.config.js</code> 里检查一下输出路径配置。</p>\n<h3 id=\"3-子路径问题\">3. 子路径问题</h3>\n<p>如果你的仓库不是用户主页（即不是 <code>username.github.io</code>），而是项目主页（比如 <code>username.github.io/project-name</code>），你需要配置 <code>baseUrl</code>。</p>\n<p>在 <code>docusaurus.config.js</code> 中：</p>\n<pre><code class=\"language-javascript\">module.exports = {\n  // ...\n  url: 'https://HagiCode-org.github.io', // 你的 GitHub URL\n  baseUrl: '/site/', // 如果你的仓库叫 site，这里就填 /site/\n  // ...\n};\n</code></pre>\n<p>这一点很容易被忽略，配置不对会导致页面打开全是白屏，因为资源路径加载不到。</p>\n<h2 id=\"验证成果\">验证成果</h2>\n<p>配置完所有东西并推送代码后，我们就可以去 GitHub 仓库的 <strong>Actions</strong> 标签页看戏了。</p>\n<p>你会看到黄色的圆圈（工作流正在运行），变绿就代表成功啦！如果变红了，点击进去查看日志，通常都能排查出问题（大部分时候是拼写错误或者路径配置不对）。</p>\n<p>构建成功后，访问 <code>https://&lt;你的用户名&gt;.github.io/&lt;仓库名&gt;/</code> 就能看到崭新的站点了。</p>\n<h2 id=\"总结\">总结</h2>\n<p>通过引入 GitHub Actions，我们成功实现了 HagiCode 文档站的自动化部署。这不仅节省了手动操作的时间，更重要的是保证了发布流程的标准化。现在不管是哪位小伙伴更新了文档，只要合并到 <code>main</code> 分支，几分钟后就能在线上看到最新的内容。</p>\n<p><strong>核心收益</strong>：</p>\n<ul>\n<li><strong>效率提升</strong>：从\"手动打包、手动上传\"变成\"代码即发布\"。</li>\n<li><strong>降低错误</strong>：消除了人为操作失误的可能性。</li>\n<li><strong>体验优化</strong>：让开发者更专注于内容质量，而不是被繁琐的部署流程困扰。</li>\n</ul>\n<p>虽然配置 CI/CD 刚开始有点麻烦（尤其是各种权限和路径问题），但这是一次性投入，长期回报巨大的工作。强烈建议所有静态站点项目都接入类似的自动化流程。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://docs.github.com/en/actions\" rel=\"noopener nofollow\" target=\"_blank\">GitHub Actions 官方文档</a></li>\n<li><a href=\"https://docusaurus.io/docs/deployment\" rel=\"noopener nofollow\" target=\"_blank\">Docusaurus 部署指南</a></li>\n<li>[actions-gh-pages Action 使用说明](<a href=\"https://github.com\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com</a> peaceiris/actions-gh-pages)</li>\n</ul>\n<hr />\n<p>感谢您的阅读,如果您觉得本文有用,快点击下方点赞按钮👍,让更多的人看到本文。</p>\n<p>本内容采用人工智能辅助协作,经本人审核,符合本人观点与立场。</p>\n<h2 id=\"元信息\">元信息</h2>\n<ul>\n<li><strong>本文作者:</strong> <a href=\"https://www.newbe.pro\" rel=\"noopener nofollow\" target=\"_blank\">newbe36524</a></li>\n<li><strong>本文链接:</strong> <a href=\"https://hagicode-org.github.io/site/blog/2026/01/25/docusaurus-auto-deployment-with-github-actions\" rel=\"noopener nofollow\" target=\"_blank\">https://hagicode-org.github.io/site/blog/2026/01/25/docusaurus-auto-deployment-with-github-actions</a></li>\n<li><strong>版权声明:</strong> 本博客所有文章除特别声明外,均采用 BY-NC-SA 许可协议。转载请注明出处!</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 08:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/newbe36524\">Newbe36524</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "复刻 ChatGPT 高级数据分析！Sdcb Chats 1.10 重磅发布：能分析Excel、做PPT",
      "link": "https://www.cnblogs.com/sdcb/p/19528764/chats-1-10",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sdcb/p/19528764/chats-1-10\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 08:45\">\n    <span>复刻 ChatGPT 高级数据分析！Sdcb Chats 1.10 重磅发布：能分析Excel、做PPT</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Chats 1.10.0 发布了！这是一个我个人非常喜欢，也期待已久的版本。</p>\n<p>距离 1.9.0 发布（2025 年 11 月 27 日）已经过去了近两个月。这期间，我并不是在摸鱼，而是在憋一个“大招”——<strong>内置代码执行器（Code Interpreter）</strong>。</p>\n<blockquote>\n<p>如果你还不了解 <strong>Sdcb Chats</strong>：简单说，这是一个支持多家主流模型服务商的 AI 网关。它不只能让你在一个统一界面里聚合管理所有模型，同时也兼容标准 API 协议，支持 Docker 一键部署与多数据库支持。</p>\n</blockquote>\n<h2 id=\"为什么是代码执行器\">为什么是代码执行器？</h2>\n<p>Sdcb Chats 1.9发布之后，很多人好奇我下一步准备怎么走，我当时想的两个方向：</p>\n<p><strong>方向一：Dify 模式（Dify化）</strong><br />\n一种是支持发布成 App 的功能，比如通过一定的系统提示词、工具集选择、模型参数设置（如温度等），可以将这样的东西打包发布成一个像 App 一样的网页，或者是一个 js 入口。用户可以通过这个网页直接使用 Chats 的预定功能和 AI 大模型聊天、完成指定任务。打包成的 js 甚至可以嵌入用户（通常是企业用户）的网页中，这样一来用户就可以直接在自己的网站上使用定制化的 AI 助手了。这个方向很有商业潜力，很多客户都在问。</p>\n<p><strong>方向二：Code Interpreter 模式（ADA）</strong><br />\n另外一个方向就是实现内置的基于 Docker 的沙箱功能。因为我经常看到 ChatGPT 网站（或者像 Manus 一样）中可以执行一段 Python 脚本——或者经过一系列多步骤的过程，然后生成一张图片或者一个图表、Excel、PPT。这个功能之前 ChatGPT 叫作 Code Interpreter（代码执行器），后来为了显得更专业，改名叫“高级数据分析”（Advanced Data Analysis，ADA）。</p>\n<p>这个功能的核心在于：<strong>它可以让 AI 模型直接操作文件、生成各种格式的输出，而不需要用户手动去处理数据和文件。</strong></p>\n<p>我发现，目前市面上除了 OpenAI 提供了完整体验外，像 Gemini、Grok、Qwen（基于OpenWebUI）等都没有提供类似的功能支持。</p>\n<p><strong>我的选择</strong><br />\n从 Chats 的商业化角度来说，Dify 方向肯定更有“钱”景。但我个人对 ADA 方向更感兴趣一些，因为我觉得这个功能更“硬核”，也更能体现 AI 模型的能力和潜力。</p>\n<p>所以我最终选择了 ADA 方向作为 1.10 版本发布的核心功能。经过几周的努力，1.10 版本终于完成了内置 Docker Code Interpreter 的功能！现在用户可以在 Chats 中直接请 AI 创建一个 Docker 会话，上传文件，让 AI 模型执行代码、分析数据、生成 PPT 等，非常方便实用。</p>\n<h2 id=\"强大的-docker-沙箱不只是-python\">强大的 Docker 沙箱：不只是 Python</h2>\n<p>为了实现这个功能，我不仅仅是加了几个 API 那么简单。</p>\n<p>这个功能的 PoC 其实早在去年 11 月我就完成了，之后我陆续打磨，直到 2026 年元旦的时候我和 AI 做了多轮的设计，最终定稿并创建了 7 个内置工具：</p>\n<ul>\n<li><code>create_docker_session</code>：创建环境</li>\n<li><code>run_command</code>：执行命令</li>\n<li><code>read_file</code> / <code>write_file</code> / <code>patch_file</code>：文件操作</li>\n<li><code>download_chat_files</code>：文件流转</li>\n<li><code>destroy_session</code>：资源回收</li>\n</ul>\n<p>我还内置了一套 <strong>Artifact（工件）文件夹跟踪机制</strong>。简单来说，如果大模型操作命令行工具或者其它什么脚本将文件放到了指定的 artifact 文件夹，Chats 系统就会自动帮用户保存下来，用户在聊天界面可以直接点击下载。</p>\n<h3 id=\"专属镜像sdcbcode-interpreter\">专属镜像：sdcb/code-interpreter</h3>\n<p>为了让体验达到极致，我不想让大家每次都去拉取巨大的通用镜像，也不想让大家费劲去配置环境。因此，我专门构建了一个 docke 镜像：<code>sdcb/code-interpreter</code>。</p>\n<p>和 OpenAI 的 ADA 功能类似，这个镜像里预装了常用的工具链和依赖库：</p>\n<ul>\n<li><strong>语言环境</strong>：Python, .NET (Dotnet), Node.js, GCC</li>\n<li><strong>数据处理</strong>：SQLite3, Pandas, Numpy</li>\n<li><strong>文档办公</strong>：LibreOffice, Pandoc</li>\n<li><strong>多媒体</strong>：FFmpeg, ImageMagick</li>\n<li><strong>Web自动化</strong>：Playwright Chromium</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102326917-629370352.png\" /></p>\n<p>大模型在使用这个镜像时，会自动加载 <code>/app/skills.md</code> 这个文件，里面列出了镜像中预装的工具和库：</p>\n<pre><code class=\"language-md\">This environment is pre-configured with the following tools and libraries:\n* utilities: git, LibreOffice, Pandoc, Poppler (`pdftotext`, `pdfinfo`), sqlite3, file, FFmpeg {ffmpegVersion}, git, imagemagick, playwright[chromium]\n* dotnet {dotnetVersion}, commands: `dotnet build`, `dotnet run single-file.cs`, `dotnet add package`, pre-cached NuGet packages in `/opt/nuget-local`\n* python {pythonVersion}, commands: `python3 - &lt;&lt;'PY' ...`, `pip install --break-system-packages package-name`, IMPORTANT: Many packages are pre-installed, Always check with `pip list` BEFORE installing to avoid unnecessary waits.\n* C/C++ Toolchain (gcc {gccVersion}), tools: `gcc`, `g++`, `make`, `cmake`\n* node.js {nodeVersion}, commands: `node`, `npm`, IMPORTANT: Many packages are pre-installed globally. Always check with `npm -g ls` BEFORE installing.\n</code></pre>\n<p>大模型可以直接调用这些工具，非常方便。</p>\n<p>值得一提的是，作为一名 .NET 爱好者，这个镜像我是基于 .NET 做的（Base Image），因此碰巧你像我一样使用 .NET/C# 来验证一些东西的话，让大模型直接使用这个镜像就行了！</p>\n<h2 id=\"场景演示它能做什么\">场景演示：它能做什么？</h2>\n<p>光说不练假把式，我们来看看它在实际场景中的威力。</p>\n<h3 id=\"场景一分析-excel-并生成图表\">场景一：分析 Excel 并生成图表</h3>\n<p>以前我们让 AI 分析 Excel，通常是将数据格式发给AI，然后让它帮忙写代码，用户再自己运行代码生成图表。现在可以直接让 AI 在沙箱中操作 Excel 文件，生成图表。</p>\n<p>比如你有一个这样的excel：<a href=\"https://cv-public.sdcb.pub/2026/changsha_weather_2025.xlsx\" rel=\"noopener nofollow\" target=\"_blank\">https://cv-public.sdcb.pub/2026/changsha_weather_2025.xlsx</a><br />\n里面的数据是长沙 2025 年的每日天气记录：<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102327825-611206051.png\" /></p>\n<blockquote>\n<p><strong>用户</strong>：请帮我分析这个 Excel 文件，生成一个包含每月平均气温和降水量的报告，并附上图表。</p>\n</blockquote>\n<p>AI 会直接在 Docker 沙箱中运行 Python 代码，使用 Pandas 和 Matplotlib 生成图表，然后把结果打包成报告发给你（视频有加速）。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102328487-114968639.avif\" /></p>\n<h3 id=\"场景二一句话生成-ppt\">场景二：一句话生成 PPT</h3>\n<p>这是我最爱的功能之一。</p>\n<blockquote>\n<p><strong>用户</strong>：请根据上面的天气分析，帮我生成一份以“2025年长沙天气分析报告”为主题的PPT，包含封面、目录、数据分析、图表展示和结论五个部分。</p>\n</blockquote>\n<p>AI 会调用 <code>python-pptx</code> 库，在沙箱中生成 <code>.pptx</code> 文件，然后给你一个下载链接。你下载下来直接就可以去汇报了（当然最好还是微调一下）。</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102329000-1999082053.png\" /></p>\n<p>这是原始 PPT 的下载链接，有兴趣的可以看看感受一下效果：<a href=\"https://cv-public.sdcb.pub/2026/changsha_weather_report_2025.pptx\" rel=\"noopener nofollow\" target=\"_blank\">https://cv-public.sdcb.pub/2026/changsha_weather_report_2025.pptx</a></p>\n<h3 id=\"场景三做实验\">场景三：做实验</h3>\n<p>这其实也是我最喜欢的一个场景。比如我想测试一个新的算法，或者验证一个代码片段，我可以直接让 AI 在沙箱中帮我跑代码。</p>\n<p>比如之前我写过两篇博客：</p>\n<ul>\n<li>《不服跑个分？.NET 10 大整数计算对阵 Java，结果令人意外》（博客园链接：<a href=\"https://www.cnblogs.com/sdcb/p/19484525/20261113-big-integer-dotnet-10-vs-java%EF%BC%89\" target=\"_blank\">https://www.cnblogs.com/sdcb/p/19484525/20261113-big-integer-dotnet-10-vs-java）</a></li>\n<li>《.NET 10了，HttpClient还是不能用using吗？我做了一个实验》（博客园链接：<a href=\"https://www.cnblogs.com/sdcb/p/19500792/20260119-using-httpclient%EF%BC%89\" target=\"_blank\">https://www.cnblogs.com/sdcb/p/19500792/20260119-using-httpclient）</a></li>\n</ul>\n<p>这里面有大量的代码、实验数据和图表，我可以直接让 AI 在沙箱中帮我跑这些代码，生成数据，然后帮我分析结果、生成图表，极大地提高了我的写作效率：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102329414-26338747.png\" /></p>\n<h2 id=\"其它重磅更新\">其它重磅更新</h2>\n<p>除了代码执行器，1.10 还有很多硬核更新：</p>\n<h3 id=\"1-交错思考改进\">1. 交错思考改进</h3>\n<p>在 1.9 版本中，我引入了交错思考（Interleaved Thinking）的概念，允许大模型在回答问题时分多步思考和行动。但只支持 Minimax-M2、Anthropic Claude等模型支持交错思考。</p>\n<p>在 1.10 版本中，我扩展了对更多模型的支持，包括 OpenAI Responses API、DeepSeek V3.2模型。</p>\n<p>比如你看下面的使用量统计（来自 Chats 的截图）：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102329774-510845930.png\" /></p>\n<p>我当时使用的模型是 OpenAI 的 gpt-5.2，它通过 Response API 的交错思考将思考信息回传，在总结 201K Tokens 的对话中，有 189K 触发了请求缓存，节省了大量的计算资源和费用，还提升了模型能力，这都依赖于交错思考的功能。</p>\n<p>到此，Sdcb Chats中已经有这些模型提供商确认支持完整的交错思考功能：</p>\n<table>\n<thead>\n<tr>\n<th>Id</th>\n<th>Name</th>\n<th>加入时间</th>\n<th>交错思考</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>Azure AI Foundry</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>2</td>\n<td>腾讯混元</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>3</td>\n<td>零一万物</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td></td>\n</tr>\n<tr>\n<td>4</td>\n<td>月之暗面</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>5</td>\n<td>OpenAI</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>6</td>\n<td>百度千帆</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>阿里百炼</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>8</td>\n<td>讯飞星火</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td></td>\n</tr>\n<tr>\n<td>9</td>\n<td>智谱AI</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/3b3918af\" rel=\"noopener nofollow\" target=\"_blank\">2024-09-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>10</td>\n<td>DeepSeek</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/30db0079\" rel=\"noopener nofollow\" target=\"_blank\">2024-12-06</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>11</td>\n<td>x.ai</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/0d1cab20\" rel=\"noopener nofollow\" target=\"_blank\">2024-12-11</a></td>\n<td></td>\n</tr>\n<tr>\n<td>12</td>\n<td>Github Models</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/0d1cab20\" rel=\"noopener nofollow\" target=\"_blank\">2024-12-11</a></td>\n<td></td>\n</tr>\n<tr>\n<td>13</td>\n<td>谷歌AI</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/a4effc1b\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-10</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>14</td>\n<td>Ollama</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/6a5288e7\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-20</a></td>\n<td></td>\n</tr>\n<tr>\n<td>15</td>\n<td>MiniMax</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/6a5288e7\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-20</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>16</td>\n<td>火山方舟</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/843510ff\" rel=\"noopener nofollow\" target=\"_blank\">2025-01-24</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>17</td>\n<td>硅基流动</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/889144cf\" rel=\"noopener nofollow\" target=\"_blank\">2025-02-08</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>18</td>\n<td>OpenRouter</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/15adedfe\" rel=\"noopener nofollow\" target=\"_blank\">2025-03-05</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>19</td>\n<td>小马算力</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/32e4a0d5\" rel=\"noopener nofollow\" target=\"_blank\">2025-11-07</a></td>\n<td>❓</td>\n</tr>\n<tr>\n<td>20</td>\n<td>Anthropic</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/22ebef98\" rel=\"noopener nofollow\" target=\"_blank\">2025-11-24</a></td>\n<td>✅</td>\n</tr>\n<tr>\n<td>21</td>\n<td>小米Mimo</td>\n<td><a href=\"https://github.com/sdcb/chats/commit/026f1a4e\" rel=\"noopener nofollow\" target=\"_blank\">2025-12-17</a></td>\n<td>✅</td>\n</tr>\n</tbody>\n</table>\n<p>注：</p>\n<ul>\n<li>❓代表模型提供商使用了基于 Anthropic Messages API 的实现，按协议推断应该支持，但由于未做过端到端测试，因此不确定是否能实现完整的交错思考能力——我相当肯定不能简单地说“支持”，因为有些模型在实现上可能会有差异化。</li>\n<li>还有一些模型提供商基于 OpenAI Responses API 实现的，比如文心千帆，理论上只要支持 Responses API 也能实现交错思考，但我还没有做过测试，因此暂时不列入表格。</li>\n</ul>\n<h3 id=\"2-用户体验大升级\">2. 用户体验大升级</h3>\n<ul>\n<li>\n<p><strong>工具调用展示</strong>：为了配合 Code Interpreter，我重写了工具调用的 UI（<code>ToolCallBlock</code>）。现在可以看到实时的控制台输出流（Log Stream），体验就像自己在看终端一样爽。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102330184-33469646.avif\" /></p>\n</li>\n<li>\n<p><strong>拖拽上传</strong>：支持直接 Ctrl+V 粘贴文件，或者拖拽文件到输入框。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/233608/202601/233608-20260125102330573-196654545.png\" /></p>\n</li>\n<li>\n<p><strong>生成信息统计</strong>：现在气泡上会显示 Step 数量、平均耗时等极客信息（如上已经有截图示例）。</p>\n</li>\n</ul>\n<h2 id=\"幕后花絮\">幕后花絮</h2>\n<h3 id=\"那个让人头秃的-ef-core-bug\">那个让人头秃的 EF Core Bug</h3>\n<p>开发后期有一个很烦人的 EF Core 问题，表现是会话追踪的数据有时候会莫名其妙地状态不对。当时我把日志丢给 AI 大模型，让它帮我分析了好久都没解决，给出的建议都在“隔靴搔痒”。</p>\n<p>后来没办法，我只能拿出传统的“调试器大法”，一步一步地断点调试，才发现是 EF Core 在处理并发更新时的状态跟踪（Change Tracking）导致了数据污染。果然，关键时刻还是得靠人类工程师的直觉和经验啊！😅</p>\n<h3 id=\"为什么迟到了\">为什么迟到了？</h3>\n<p>1.10 其实早在 <strong>2026-01-14</strong> 就发布了，为什么今天是 26 号我才发文章宣传？</p>\n<p>一方面是我自己在进行高强度的“狗粮测试”（Dogfooding），确保在这个 Docker 沙箱里跑 rm -rf / 不会把我的宿主机炸了（开玩笑的，有安全限制）。</p>\n<p>另一方面，我补了大量的文档。新功能的配置参数比较多，为了让大家能顺利部署，我花了几天时间重新梳理了 <a href=\"https://github.com/sdcb/chats/blob/main/README.md\" rel=\"noopener nofollow\" target=\"_blank\">README</a> 和 <a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/1.10.0.md\" rel=\"noopener nofollow\" target=\"_blank\">Release Note</a>，大家部署前一定要去看看。</p>\n<hr />\n<h2 id=\"结语\">结语</h2>\n<p>Chats 1.10 是一个里程碑，它让 Chats 从一个单纯的“聊天窗口”进化成了一个“生产力工场”。我非常期待看到大家用这个功能玩出什么花样！</p>\n<p>喜欢的朋友请给我的 GitHub 项目一个 star：<br />\n🌟 <strong><a href=\"https://github.com/sdcb/chats\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats</a></strong></p>\n<p>这是完整的更新日志：<br />\n<a href=\"https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/sdcb/chats/blob/main/doc/zh-CN/release-notes/README.md</a></p>\n<p>有什么想法也欢迎在评论区留言交流，也欢迎加入我的新创建的微信群：</p>\n<p><img alt=\"微信群\" src=\"https://io.starworks.cc:88/cv-public/2026/chats-wxg-qr.png\" /></p>\n<p>如果你更习惯用 QQ 群或者上面的微信群链接失效的话，也可以加入 Chats QQ 群：<strong>498452653</strong>，我们一起探索更多 AI 技术硬核玩法。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 08:45</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sdcb\">.NET骚操作</a>&nbsp;\n阅读(<span id=\"post_view_count\">73</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "上周热点回顾（1.19-1.25）",
      "link": "https://www.cnblogs.com/cmt/p/19531319",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/cmt/p/19531319\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 08:34\">\n    <span>上周热点回顾（1.19-1.25）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>热点随笔：</p>\n<p>· <a href=\"https://www.cnblogs.com/HaiJun-Aion/archive/2026/01/23/19521040.html\" rel=\"noopener\" target=\"_blank\">32岁程序员猝死背后，我的一些真实感受</a> (<a href=\"https://www.cnblogs.com/HaiJun-Aion/\" rel=\"noopener\" target=\"_blank\">程序员海军</a>) <br />· <a href=\"https://www.cnblogs.com/sdcb/archive/2026/01/23/20260119-using-httpclient.html\" rel=\"noopener\" target=\"_blank\">.NET 10了，HttpClient还是不能用using吗？我做了一个实验</a> (<a href=\"https://www.cnblogs.com/sdcb/\" rel=\"noopener\" target=\"_blank\">.NET骚操作</a>) <br />· <a href=\"https://www.cnblogs.com/sdcb/archive/2026/01/21/20260120-chats-190.html\" rel=\"noopener\" target=\"_blank\">两天烧掉200美元！我AI大模型网关终于支持了Claude模型</a> (<a href=\"https://www.cnblogs.com/sdcb/\" rel=\"noopener\" target=\"_blank\">.NET骚操作</a>) <br />· <a href=\"https://www.cnblogs.com/yupi/archive/2026/01/20/19505500.html\" rel=\"noopener\" target=\"_blank\">20 个神级 AI 编程扩展，爽爆了！</a> (<a href=\"https://www.cnblogs.com/yupi/\" rel=\"noopener\" target=\"_blank\">程序员鱼皮</a>) <br />· <a href=\"https://www.cnblogs.com/xdesigner/archive/2026/01/19/19501590.html\" rel=\"noopener\" target=\"_blank\">MWGA - 为了复活1000亿行C#代码</a> (<a href=\"https://www.cnblogs.com/xdesigner/\" rel=\"noopener\" target=\"_blank\">袁永福 电子病历，医疗信息化</a>) <br />· <a href=\"https://www.cnblogs.com/haibindev/archive/2026/01/19/19503791.html\" rel=\"noopener\" target=\"_blank\">国内四大AI编程IDE对比（一）：直观印象与模型能力</a> (<a href=\"https://www.cnblogs.com/haibindev/\" rel=\"noopener\" target=\"_blank\">haibindev</a>) <br />· <a href=\"https://www.cnblogs.com/xzqcsj/archive/2026/01/22/19510445.html\" rel=\"noopener\" target=\"_blank\">一个月搞定100+表迁移：我的“偷师”Navicat实战复盘</a> (<a href=\"https://www.cnblogs.com/xzqcsj/\" rel=\"noopener\" target=\"_blank\">一旅人</a>) <br />· <a href=\"https://www.cnblogs.com/MeteorSeed/archive/2026/01/22/19505675.html\" rel=\"noopener\" target=\"_blank\">【译】Visual Studio 2026 来了：更快、更智能，深受老用户的喜爱</a> (<a href=\"https://www.cnblogs.com/MeteorSeed/\" rel=\"noopener\" target=\"_blank\">MeteorSeed</a>) <br />· <a href=\"https://www.cnblogs.com/sheng-jie/archive/2026/01/20/19508743.html\" rel=\"noopener\" target=\"_blank\">.NET+AI | Workflow | 核心概念速通（1）</a> (<a href=\"https://www.cnblogs.com/sheng-jie/\" rel=\"noopener\" target=\"_blank\">「圣杰」</a>) <br />· <a href=\"https://www.cnblogs.com/diamondhusky/archive/2026/01/20/19508626.html\" rel=\"noopener\" target=\"_blank\">告别 throw exception！为什么 Result&lt;T&gt; 才是业务逻辑的正确选择</a> (<a href=\"https://www.cnblogs.com/diamondhusky/\" rel=\"noopener\" target=\"_blank\">呆萌哈士奇</a>) <br />· <a href=\"https://www.cnblogs.com/powertoolsteam/archive/2026/01/21/19511415.html\" rel=\"noopener\" target=\"_blank\">如何提升 C# 应用中的性能</a> (<a href=\"https://www.cnblogs.com/powertoolsteam/\" rel=\"noopener\" target=\"_blank\">葡萄城技术团队</a>) <br />· <a href=\"https://www.cnblogs.com/cmt/archive/2026/01/19/19499970.html\" rel=\"noopener\" target=\"_blank\">上周热点回顾（1.12-1.18）</a> (<a href=\"https://www.cnblogs.com/cmt/\" rel=\"noopener\" target=\"_blank\">博客园团队</a>) </p>\n<p>热点新闻：</p>\n<p>· <a href=\"https://news.cnblogs.com/n/813132/\" rel=\"noopener\" target=\"_blank\">睡眠对寿命的影响仅次于吸烟！建议每晚至少睡7小时</a><br />· <a href=\"https://news.cnblogs.com/n/813264/\" rel=\"noopener\" target=\"_blank\">马斯克兑现承诺，开源X推荐算法！100% AI驱动，0人工规则</a><br />· <a href=\"https://news.cnblogs.com/n/813133/\" rel=\"noopener\" target=\"_blank\">每天多动5分钟、少坐30分钟，显著降低死亡风险</a><br />· <a href=\"https://news.cnblogs.com/n/813178/\" rel=\"noopener\" target=\"_blank\">国产第一、全球第四，巨亏400亿</a><br />· <a href=\"https://news.cnblogs.com/n/813193/\" rel=\"noopener\" target=\"_blank\">设计师开窍了！比亚迪海洋网「8 系双旗舰」亮相，纯电续航或超 1000 km</a><br />· <a href=\"https://news.cnblogs.com/n/813255/\" rel=\"noopener\" target=\"_blank\">Gemini准确率从21%飙到97%！谷歌只用了这一招：复制粘贴</a><br />· <a href=\"https://news.cnblogs.com/n/813323/\" rel=\"noopener\" target=\"_blank\">DeepSeek R1发布一年了，不卷功能、不融资、不着急，凭什么「硬控」硅谷</a><br />· <a href=\"https://news.cnblogs.com/n/813184/\" rel=\"noopener\" target=\"_blank\">罗永浩被禁言后现身B站颁奖典礼 获年度新人奖 并上台发表感言</a><br />· <a href=\"https://news.cnblogs.com/n/813260/\" rel=\"noopener\" target=\"_blank\">Cursor一夜翻车，AI 300万代码写浏览器被打假！全网群嘲「AI泔水」</a><br />· <a href=\"https://news.cnblogs.com/n/813326/\" rel=\"noopener\" target=\"_blank\">IPv4 和 IPv6 地址现状</a><br />· <a href=\"https://news.cnblogs.com/n/813348/\" rel=\"noopener\" target=\"_blank\">看了300期神秘园，我能挑战「鳌太线」了吗</a><br />· <a href=\"https://news.cnblogs.com/n/813242/\" rel=\"noopener\" target=\"_blank\">小米汽车回应两起火事件！</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 08:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/cmt\">博客园团队</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "收藏！LLM开发全链路：5大步骤+15大框架，从数据治理到RLHF一文通关",
      "link": "https://www.cnblogs.com/aifrontiers/p/19529366",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/aifrontiers/p/19529366\" id=\"cb_post_title_url\" title=\"发布于 2026-01-26 08:12\">\n    <span>收藏！LLM开发全链路：5大步骤+15大框架，从数据治理到RLHF一文通关</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>原文：<a href=\"https://mp.weixin.qq.com/s/oRUjkoUcHOrMtHfVHkr5Cw\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/oRUjkoUcHOrMtHfVHkr5Cw</a></p>\n<p><strong>LLM往期文章推荐</strong></p>\n<p><a href=\"https://mp.weixin.qq.com/s/cx3qY42Lp0L3RaSOgsH77A\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RL-PPO</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/nfN0dWT3ZfDuW7ZGfaG6dA\" rel=\"noopener nofollow\" target=\"_blank\">收藏！强化学习从入门到封神：5 本经典教材 + 8 大实战项目 + 7个免费视频，一站式搞定</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/4_6CBXMJhqmiYKSzsAXncg\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RLHF：基础篇</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/8O7W8--x14-b1d3M9IS_3w\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的RLHF-PPO：原理篇</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/9KT9LrMTXDGHSvGFrQhRkg\" rel=\"noopener nofollow\" target=\"_blank\">小白也能看懂的LLM-RL算法：PPO/DPO/GRPO/GSPO</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s/9f4mqYVGKNS-LhmHLl6CXw\" rel=\"noopener nofollow\" target=\"_blank\">收藏！LLM-RL训练框架：3大流派+6大框架，一文搞定</a></p>\n<p>在上一篇<a href=\"https://mp.weixin.qq.com/s/9f4mqYVGKNS-LhmHLl6CXw\" rel=\"noopener nofollow\" target=\"_blank\">收藏！LLM-RL训练框架：3大流派+6大框架，一文搞定</a>中，我们重点讨论了LLM训练技术的开源框架，并未涉及LLM训练的其他环节。在人工智能领域从模型中心化向数据中心化范式转移的背景下，LLM的成功不仅依赖于模型参数规模的爆炸式增长，更取决于全链路工程化的精细程度。</p>\n<p>这一链路涵盖了从海量异构数据的精炼、超大规模分布式环境下的模型训练、特定任务驱动的指令微调，到最终模型输出与人类价值观对齐的RLHF阶段。如近的开源生态系统已涌现出一批高性能、模块化且落地性强的代码框架，这些工具极大地降低了开发者训练、微调和部署私有化大模型的门槛。本篇将对这一全链路中的核心开源框架进行深度的技术解构，分析其底层机制、性能指标及行业应用场景。</p>\n<h1 id=\"1-分布式数据清洗与编排引擎\">1 分布式数据清洗与编排引擎</h1>\n<p>数据质量是LLM性能的生命线。当前工业界的共识是，高质量的合成数据和经过严苛清洗的NLP语料对提升模型逻辑推理能力至关重要。当数据规模达到PB级时，单机处理变得不可行。异构脏数据的处理流程需要复杂的任务编排和大规模分布式计算的支持。</p>\n<h2 id=\"11-data-juicer\">1.1 <strong>Data-Juicer</strong></h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>gitHub：<a href=\"https://github.com/datajuicer/data-juicer\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/datajuicer/data-juicer</a> 5.8k⭐</p>\n</li>\n<li>\n<p>说明文档：<a href=\"https://datajuicer.github.io/data-juicer/zh_CN/main/docs_index_ZH.html\" rel=\"noopener nofollow\" target=\"_blank\">https://datajuicer.github.io/data-juicer/zh_CN/main/docs_index_ZH.html</a></p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2501.14755v2\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2501.14755v2</a></p>\n</li>\n</ul>\n<h3 id=\"核心特点\"><strong>核心特点</strong></h3>\n<ul>\n<li>\n<p><strong>一站式与系统化</strong>：涵盖了数据分析、清洗、过滤、转换、去重及合成的完整链路。它不仅是一个工具包，更是一个完整的系统，提供了100多个核心算子。</p>\n</li>\n<li>\n<p><strong>多模态支持</strong>：除了基础的文本数据，Data-Juicer 2.0及后续版本深度支持图像、视频、音频等多种模态，能够处理复杂的交织多模态数据。</p>\n</li>\n<li>\n<p><strong>高效扩展</strong>：基于Ray和CUDA优化，支持单机到数千核集群的弹性扩展，性能经工业级验证。</p>\n</li>\n<li>\n<p><strong>数据-模型共开发（Sandbox）</strong>：提供沙盒机制，允许开发者在小规模数据上快速迭代实验，通过反馈循环和可视化工具快速验证数据改进对模型效果的影响。</p>\n</li>\n</ul>\n<h3 id=\"适用场景\">适用场景</h3>\n<ul>\n<li>\n<p><strong>预训练/微调加速</strong>：对海量网页数据去噪，或筛选高质量、高多样性的指令微调数据。</p>\n</li>\n<li>\n<p><strong>多模态生成训练</strong>：为类似Sora的视频生成或多模态大模型准备精细化标注与清洗后的语料。</p>\n</li>\n<li>\n<p><strong>自动化数据工程</strong>：利用AI算子自动生成、重写数据，或探索最优数据混合比例。</p>\n</li>\n</ul>\n<h3 id=\"优缺点\">优缺点</h3>\n<p><strong>优点</strong>：① 工业级成熟度：源自阿里巴巴通义实验室，经过大规模生产环境验证，算子丰富且性能优异；② 生态集成度高：与ModelScope（魔搭社区）、LLaMA-Factory、Ray等主流大模型生态深度打通，方便开发者集成到现有流水线；③ 灵活易用：对于新手，可以直接使用官方提供的最佳实践配置；对于高级用户，可以通过 Python 灵活自定义算子。</p>\n<p><strong>缺点</strong>：① 学习成本：算子库庞大，需一定时间摸索最佳参数组合；② 资源需求：部分高级算子（如模型打分）依赖计算资源，处理海量数据时成本较高。</p>\n<h2 id=\"12-datatrove\">1.2 Datatrove</h2>\n<ul>\n<li>github: <a href=\"https://github.com/huggingface/datatrove\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/huggingface/datatrove</a> 2.8k⭐</li>\n</ul>\n<h3 id=\"关键特性\">关键特<strong>性</strong></h3>\n<ul>\n<li>\n<p><strong>平台无关的流水线</strong>：代码在本地机器、Slurm集群或 Ray集群上运行时几乎不需要改动。它通过执行器机制抽象了底层算力。</p>\n</li>\n<li>\n<p><strong>低<strong><strong>内存</strong></strong>占用与流式处理</strong>：采用生成器模式，数据以流的形式通过处理模块，即便处理数百TB的数据，内存消耗也能控制在较低水平。</p>\n</li>\n<li>\n<p><strong>强大的去重功能</strong>：内置了工业级的去重算法，包括MinHash（模糊去重）和Exact Substring（精确子串去重），这是处理网页抓取数据的关键。</p>\n</li>\n<li>\n<p><strong>容错与断点续传</strong>：能够自动跟踪已完成的任务，如果作业在集群中崩溃，重启后会自动跳过已处理的部分。</p>\n</li>\n</ul>\n<h3 id=\"适用场景-1\">适用场景</h3>\n<ul>\n<li>\n<p><strong>LLM</strong> <strong>预训练清洗</strong>：处理Common Crawl等原始网页快照，提取纯净文本并剔除低质量内容。。</p>\n</li>\n<li>\n<p><strong>超大规模去重</strong>：在海量数据中精准剔除重复或高度相似的文档。</p>\n</li>\n<li>\n<p><strong>分布式数据工程</strong>：利用Slurm或Ray等集群环境快速处理万亿规模的数据集。</p>\n</li>\n</ul>\n<h3 id=\"优缺点-1\">优缺点</h3>\n<p><strong>优点</strong>：① 极致的扩展性：不是为了处理小样本设计的，而是为了处理万亿级Token设计的，在Slurm或Ray分布式环境下表现极佳；②简洁的API：Pythonic风格，模块化程度高，易于自定义扩展；③ 与生态深度集成：与Hugging Face Hub和fsspec深度整合，支持直接读写S3、Hugging Face数据仓库。</p>\n<p><strong>缺点</strong>：①主要侧重文本：理论上虽然可以处理其他数据，但目前其生态和预置算子主要集中在文本领域。在多模态（图像、视频）算子的丰富度上，目前弱于Data-Juicer；② 文档相对精简：相比一些商业化或历史悠久的框架，其详细文档和教程仍在完善中，更多依赖示例代码（Examples）。</p>\n<h1 id=\"2-分布式预训练与模型训练底层架构\">2 分布式预训练与模型训练底层架构</h1>\n<p>当数据准备就绪后，如何将其高效地输入到分布式计算集群中进行训练成为核心挑战。因单个GPU的显存（如H100的80GB）远不足以容纳100+B参数的模型、及其优化器状态和梯度，分布式并行策略成为了现代训练框架的基石。</p>\n<h2 id=\"21-megatron-lm\">2.1 Megatron-LM</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>Github : <a href=\"https://github.com/NVIDIA/Megatron-LM\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/NVIDIA/Megatron-LM</a> 15k⭐</p>\n</li>\n<li>\n<p>官方文档：<a href=\"https://docs.nvidia.com/megatron-core/index.html\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.nvidia.com/megatron-core/index.html</a></p>\n</li>\n<li>\n<p>论文1：<a href=\"https://arxiv.org/pdf/1909.08053\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/1909.08053</a></p>\n</li>\n<li>\n<p>论文2：<a href=\"https://arxiv.org/pdf/2104.04473\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2104.04473</a></p>\n</li>\n<li>\n<p>论文3：<a href=\"https://arxiv.org/pdf/2205.05198\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2205.05198</a></p>\n</li>\n</ul>\n<p>Megatron-LM作为由NVIDIA深度开发的分布式训练框架，核心贡献在于提出并完善了多维并行体系，特别是针对 Transformer 结构的深度优化，在大模型预训练领域占据着举足轻重的地位。其设计哲学始终围绕着如何榨干NVIDIA GPU的每一分性能，特别是利用高性能NVLink互联和CUDA内核融合技术。</p>\n<h3 id=\"关键特性与底层架构分析\">关键特性与底层架构分析</h3>\n<p>核心贡献在于提出并完善了多维并行体系，特别是针对 Transformer结构的深度优化。</p>\n<ul>\n<li>\n<p><strong>多维<strong><strong>并行计算</strong></strong>架构</strong>：将计算任务在三个维度进行解耦：层内计算（张量并行）、层间计算（流水线并行）以及批次数据（数据并行）。张量并行（Tensor Parallelism）是一种层内并行技术，将Transformer层的矩阵乘法操作沿列或行进行拆分。例如，在注意力机制的QKV投影层，通过将输出维度（列）切分到不同GPU，每个进程仅需存储和计算部分参数，最后通过All-Reduce操作聚合梯度。这种精细化的切分使得单卡无法容纳的大型层得以在节点内高效运行。</p>\n</li>\n<li>\n<p><strong>流水线<strong><strong>并行</strong></strong>的1F1B调度</strong>：为了解决跨层并行的负载均衡问题，Megatron-LM引入了1F1B（One-Forward-One-Backward）调度算法。通过将全局批次切分为多个微批次（Micro-batches），1F1B允许不同的流水线阶段在同一时间点并行处理不同的微批次，极大地压缩了流水线气泡（Pipeline Bubble）占用的时间比例，从而提升了集群的整体利用率。</p>\n</li>\n<li>\n<p><strong>序列<strong><strong>并行</strong></strong>与上下文并行</strong>：针对长文本训练需求，实现了序列并行（Sequence Parallelism），它将非张量并行部分（如LayerNorm和Dropout）沿序列维度进一步拆分，有效减少了冗余的显存占用。而在处理超长上下文（如 32K及以上tokens）时，上下文并行（Context Parallelism）则通过跨设备分配序列片段来应对激活值内存激增的挑战。</p>\n</li>\n<li>\n<p><strong>Megatron Core (MCore)</strong>：作为该框架的最新演进版本，MCore采用了模块化、组件化的设计理念。它通过Composable APIs允许用户灵活构建自定义训练流程，并集成了混合专家模型的先进支持，包括针对 DeepSeek-V3等架构的深度优化，支持 DeepEP、HybridEP等高效的Token调度算法，旨在实现异构数据中心规模下的高弹性能。</p>\n</li>\n</ul>\n<h3 id=\"适合场景与性能边界\">适合场景与性能边界</h3>\n<p>Megatron-LM专为拥有高性能计算集群（尤其是具备 NVLink 节点内互联的高端NVIDIA GPU环境）的团队设计。它是训练基础大模型（如Deepseek等级模型）的参考实现，特别是在需要追求极致的TFLOPS吞吐量时，其定制化的CUDA内核融合技术（能减少显存访问开销约 40%）展现出了巨大的技术优势。</p>\n<h3 id=\"优缺点-2\">优缺点</h3>\n<p><strong>优点</strong>：① 性能极致：通过高度优化的算子融合和硬件感知通信，实现业界最高的显存和算力效率 ；② 稳定性强：作为NVIDIA官方维护项目，对Hopper/Blackwell等新架构的支持最为迅速且深度；③ 工业标准：其提出的3D并行方案已成为大规模训练的事实标准。</p>\n<p><strong>缺点</strong>：① 开发难度高：代码侵入性强，对非Transformer架构的适配极其复杂，需要深厚的系统编程功底；② 灵活性受限：由于过度依赖NVLink和专有算子，在非同构网络或显存极度受限的异构环境下表现不如DeepSpeed。</p>\n<h2 id=\"22--deepspeed\">2.2  DeepSpeed</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>gitHub: <a href=\"https://github.com/deepspeedai/DeepSpeed\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/deepspeedai/DeepSpeed</a> 41.3k⭐</p>\n<ul>\n<li><a href=\"https://github.com/microsoft/DeepSpeedExamples\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/microsoft/DeepSpeedExamples</a> 6.8k⭐</li>\n</ul>\n</li>\n<li>\n<p>官方文档：<a href=\"https://deepspeed.readthedocs.io/en/stable/zero3.html\" rel=\"noopener nofollow\" target=\"_blank\">https://deepspeed.readthedocs.io/en/stable/zero3.html</a></p>\n</li>\n<li>\n<p>官网：<a href=\"https://www.deepspeed.ai/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.deepspeed.ai/</a></p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2308.01320\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2308.01320</a></p>\n</li>\n</ul>\n<p>DeepSpeed是微软在大模型训练领域推出的另一力作，其设计重心在于解决大模型训练中的显存瓶颈问题。通过零冗余优化器（ZeRO）系列技术，DeepSpeed极大地降低了训练超大规模模型的准入门槛。</p>\n<h3 id=\"关键技术深度解析\">关键技术深度解析</h3>\n<p>DeepSpeed的核心架构由ZeRO优化器及其衍生的异构存储技术构成。</p>\n<ul>\n<li>\n<p><strong>ZeRO<strong><strong>优化器</strong></strong>（ZeRO-1/2/3）</strong>：ZeRO技术的精髓在于消除模型状态的冗余存储。在传统数据并行中，每个GPU都保存完整的模型状态，而ZeRO则将这些状态进行分片（Sharding）。ZeRO-1仅对优化器状态进行分片；ZeRO-2进一步对梯度进行分片；ZeRO-3则实现了对参数、梯度和优化器状态的全量分片存储。这种策略使得显存消耗随设备数的增加而线性下降。</p>\n</li>\n<li>\n<p><strong>ZeRO-Offload与ZeRO-Infinity</strong>：针对显存严重短缺的场景，DeepSpeed提出了异构内存利用方案。ZeRO-Offload利用CPU内存存储并处理优化器状态更新，而ZeRO-Infinity则将这一思路推向极致，通过高效的Infinity Offload引擎同时利用GPU显存、CPU内存和NVMe SSD，支持在单个GPU上训练高达130亿参数的模型，或在集群上支持万亿参数规模。</p>\n</li>\n<li>\n<p><strong>DeepSpeed-Ulysses序列****并行</strong>：相比Megatron的序列并行，Ulysses采用了一种更通用的All-to-All通信机制。它在注意力计算前后重新分配数据，使得每个GPU能够完整地看到全局上下文，但仅负责计算部分注意力头，这在长序列训练中展现出了极佳的带宽效率。</p>\n</li>\n<li>\n<p><strong>混合3D<strong><strong>并行</strong></strong>集成</strong>：DeepSpeed通过与Megatron-LM的深度融合，将ZeRO技术与张量并行、流水线并行相结合，形成了一套完整的万亿级模型训练方案。其提供的TiledLinear模块进一步通过内存平铺技术减少了算子的峰值内存需求。</p>\n</li>\n</ul>\n<h3 id=\"适合场景\">适合场景</h3>\n<p>DeepSpeed是资源异构或受限环境下的不二之选。无论是需要在中小规模集群上微调百亿参数模型，还是在跨节点的非高速互联环境下进行预训练，其强大的显存管理能力都能确保持续运行。此外，由于其与 Hugging Face等开源生态结合紧密，它是研究人员和企业进行快速实验和模型私有化部署的首选框架。</p>\n<h3 id=\"优缺点-3\">优缺点</h3>\n<p><strong>优点</strong>：① 显存效率极高：ZeRO-3与Infinity技术极大地打破了内存墙，支持单机训练超大规模模型；② 易用性与兼容性：通过简单的JSON配置文件即可启用复杂功能，无需大规模重构PyTorch代码；③ 生态开放：支持包括AMD、Intel 在内的多种硬件平台，广泛集成于第三方库。</p>\n<p><strong>缺点</strong>：① 通信开销风险：在开启深度Offload模式下，由于受限于PCIe带宽，计算效率可能大幅下降；② 复杂系统集成：在将ZeRO与3D并行结合使用时，参数配置与负载均衡的调优极其繁琐。</p>\n<h2 id=\"23-colossal-ai\">2.3 Colossal-AI</h2>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/hpcaitech/ColossalAI\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/hpcaitech/ColossalAI</a> 41.3k⭐</p>\n</li>\n<li>\n<p>官网：<a href=\"https://colossalai.org/\" rel=\"noopener nofollow\" target=\"_blank\">https://colossalai.org/</a></p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2110.14883\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2110.14883</a></p>\n</li>\n</ul>\n<p>Colossal-AI由潞晨科技团队开发，致力于通过统一的并行接口和智能化的内存管理，将复杂的分布式训练大众化。其最大的特色在于对异构内存的精细化控制以及自动并行化搜索技术。</p>\n<h3 id=\"关键技术特性分析\">关键技术特性分析</h3>\n<p>Colossal-AI引入了一系列旨在提升资源利用率和开发效率的底层机制。</p>\n<ul>\n<li>\n<p><strong>Gemini动态异构<strong><strong>内存</strong></strong>管理器</strong>：Gemini是Colossal-AI的核心组件，其设计灵感源于PatrickStar。它采用块状内存管理策略，将参数、梯度及优化器状态组织成连续的内存块。Gemini的先进之处在于其Warmup机制：在训练的第一步，系统会实时监测非模型数据（如激活值）的内存波动，据此动态调整模型数据在GPU与CPU间的存放比例。这种自适应的逐出策略能有效减少内存碎片，并充分利用空闲的CPU显存空间。</p>\n</li>\n<li>\n<p><strong>自动并行化搜索</strong>：区别于其他框架的显著标志。通过ColoTracer静态图分析技术，系统可以将并行策略的制定转化为一个约束优化问题。它不仅能自动搜索张量并行的切分方案，还能结合激活值检查点的插入位置，找到比人类专家手动配置更优的执行计划。这极大降低了对系统架构师的依赖。</p>\n</li>\n<li>\n<p><strong>多维<strong><strong>张量并行</strong></strong>架构</strong>：除了传统的1D张量并行，Colossal-AI还实现了2D、2.5D和3D张量并行。利用复杂的分布式矩阵乘法算法，它能够在更大规模的集群中进一步减少通信量，实现超线性的并行加速比。</p>\n</li>\n<li>\n<p><strong>Booster与Shardformer生态</strong>：Colossal-AI提供了Booster插件系统，支持对开源社区（如Hugging Face, Timm）中的模型进行非侵入式的分布式包装。Shardformer可以在不改变原始模型定义的情况下，通过JIT编译和内核替换，自动注入并行算子、FlashAttention及FusedNorm等性能增强项。</p>\n</li>\n</ul>\n<h3 id=\"适合场景-1\">适合场景</h3>\n<p>Colossal-AI非常适合那些需要训练多样化模型结构、且希望减少手动调优工作量的团队。在视觉Transformer (ViT) 以及对显存利用率要求极高的长序列任务中，其动态管理机制表现卓越。此外，其作为PyTorch Lightning的合作伙伴，也吸引了大量追求开发效率的科研用户。</p>\n<h3 id=\"优缺点-4\">优缺点</h3>\n<p><strong>优点</strong>：① 极佳的显存容忍度：Chunk机制相比原生ZeRO能显著降低内存碎片，提升训练稳定性；② 自动化程度最高：一键式并行策略搜索极大地简化了从单机到集群的迁移过程；③ 多维并行方案丰富：针对不同集群拓扑提供了更灵活的算法选择。</p>\n<p><strong>缺点</strong>：① 稳定性尚需打磨：部分前沿特性（如某些自动并行模式）在复杂异构环境下的健壮性仍有提升空间；② 维护复杂性：底层集成的各种优化插件较多，对初学者的排错能力有一定要求。</p>\n<h2 id=\"24-torchtitan\">2.4 torchtitan</h2>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/pytorch/torchtitan\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/pytorch/torchtitan</a> 5k⭐</p>\n</li>\n<li>\n<p>论文：<a href=\"https://openreview.net/pdf?id=WuQtmIkiUL\" rel=\"noopener nofollow\" target=\"_blank\">https://openreview.net/pdf?id=WuQtmIkiUL</a></p>\n</li>\n</ul>\n<p>torchtitan是PyTorch官方团队近期推出的原生分布式预训练参考框架。它的出现标志着PyTorch正致力于在核心库层面统一各种分布式并行原语，从而提供一个轻量级、模块化且高度可组合的标杆实现。</p>\n<h3 id=\"架构设计哲学与关键原语\">架构设计哲学与关键原语</h3>\n<p>torchtitan的核心优势在于其完全基于PyTorch原生组件，如DTensor、DeviceMesh和FSDP2，而非依赖繁重的外部封装。</p>\n<ul>\n<li>\n<p><strong>DTensor与DeviceMesh 抽象</strong>：这是torchtitan的基石。DeviceMesh将集群中的计算节点抽象为一个多维逻辑网格，管理底层的进程组通信。DTensor（Distributed Tensor）则允许开发者以单设备语义编写代码，通过在DTensor上定义分片、复制或部分聚合等状态，系统会自动推导并执行必要的重分布通信操作。这种设计极大地简化了多维并行的逻辑复杂性。</p>\n</li>\n<li>\n<p><strong>FSDP2 (Fully Sharded Data Parallel 2)</strong>：torchtitan率先集成了FSDP2。相比于第一代FSDP 的FlatParameter设计，FSDP2采用了基于参数维度的DTensor分片，具有更强的组合性，并能与torch.compile实现深度融合。实验数据显示，FSDP2在吞吐量上提升了约1.5%，且内存占用降低了7%。</p>\n</li>\n<li>\n<p><strong>硬件软件协同设计与可组合4D并行</strong>：框架原生支持数据并行、张量并行、流水线并行及上下文并行的叠加（即4D并行）。torchtitan引入了Float8混合精度训练、SymmetricMemory共享内存通信优化以及异步检查点保存。其设计的精妙之处在于模块的解耦，模型定义保持算法中立，而并行策略作为独立的层进行包装。</p>\n</li>\n<li>\n<p><strong>编译器驱动的内核融合</strong>：深度集成torch.compile，支持区域级编译优化。通过将Transformer Block作为一个整体进行编译，框架能自动实现算子融合与显存复用，减少了对昂贵的手写CUDA内核的依赖，同时也提升了跨硬件平台的迁移能力。</p>\n</li>\n</ul>\n<h3 id=\"适合场景-2\">适合场景</h3>\n<p>torchtitan适用于希望紧随PyTorch技术栈、进行最前沿架构实验或追求代码长期可维护性的团队。它是训练Llama 3.1等尖端开源模型的官方推荐参考系统。由于其代码量极简且遵循标准的PyTorch编程模式，它也非常适合用于教学和分布式系统原理的研究。</p>\n<h3 id=\"优缺点-5\">优缺点</h3>\n<p><strong>优点</strong>：① 极致的原生性：与PyTorch核心深度绑定，无第三方框架带来的兼容性包袱；② 模块化与可组合性：4D并行的实现逻辑清晰，便于研究人员自定义并行策略；③ 先进的优化技术：率先集成Float8、torch.compile等官方最新成果，具备极高的扩展潜力。</p>\n<p><strong>缺点</strong>：① 成熟度稍欠：相比Megatron或DeepSpeed，其在万亿参数级的大规模工业化生产环境中，相关辅助工具（如监控、故障恢复）仍处于快速完善阶段；② 功能覆盖面：目前的重心主要集中在基础LLM训练，对MoE、多模态等复杂场景的开箱即用支持尚未达到DeeSpeed的丰富程度。</p>\n<h1 id=\"3-合成数据与问答对生成\">3 合成数据与问答对生成</h1>\n<p>AI领域从判别式模型向生成式大语言模型演进中，高质量指令数据成为决定模型性能、领域专业性与对齐效果的关键。传统监督微调高度依赖人类标注，不仅规模化生产成本高，且在深层逻辑推理、长链数学证明和垂直行业知识相关标注中，易因标注者能力局限导致质量波动。为突破该瓶颈，学界与工业界研发出多种自动化数据合成框架，依托教师模型的生成能力，将少量种子指令或原始文档转化为海量结构化问答对。</p>\n<h2 id=\"31-self-instruct\">3.1 Self-Instruct</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/yizhongw/self-instruct\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/yizhongw/self-instruct</a> 4.6k⭐</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2212.10560\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2212.10560</a></p>\n</li>\n</ul>\n<p>Self-Instruct框架是由华盛顿大学等机构在2022年底提出的，其核心贡献在于提出了一种几乎不需要人工干预的指令数据自增长路径。在LLM发展早期，该框架的出现极大地民主化了模型微调的过程，使得研究者能够以极低的成本将预训练模型转化为指令遵循模型。</p>\n<h3 id=\"迭代自引导的生成机制\">迭代自引导的生成机制</h3>\n<p>其底层逻辑是一种迭代的自引导算法。该过程始于一个包含175个由人类编写的种子任务的微型集合。每个任务由一条指令和相应的&lt;输入, 输出&gt;示例组成。框架通过利用LLM的上下文学习能力，从任务池中随机抽取少量示例作为提示词，引导模型生成新的指令、输入以及对应的输出。</p>\n<p>在具体的任务生成阶段，Self-Instruct展现了严密的逻辑分层。为了确保生成的实例具有高质量的格式，框架首先要求模型生成指令，随后对其进行任务类型识别。这种识别机制将任务分为“分类任务”与“非分类任务”两类，并针对性地应用不同的实例生成策略：</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>生成策略</strong></td>\n<td><strong>应用场景</strong></td>\n<td><strong>执行逻辑</strong></td>\n</tr>\n<tr>\n<td><strong>输入优先</strong></td>\n<td>非分类任务</td>\n<td>先引导模型根据指令生成输入背景，再根据指令和输入生成输出回复。</td>\n</tr>\n<tr>\n<td><strong>输出优先</strong></td>\n<td>分类任务</td>\n<td>先让模型列出所有可能的类别标签，再针对每个标签反向生成符合逻辑的输入内容，以避免模型倾向于生成单一标签的偏见。</td>\n</tr>\n</tbody>\n</table>\n<p>这种差异化的生成路径确保了在处理诸如情感分析等简单分类任务时，数据集的分布不会因模型的逻辑惯性而向某一类别倾斜。</p>\n<h3 id=\"启发式过滤与多样性保障\">启发式过滤与多样性保障</h3>\n<p>为了解决模型自生成过程中的<strong>幻觉</strong>与<strong>重复</strong>问题，框架采用两层筛选机制：</p>\n<ul>\n<li>\n<p><strong>相似度去重：</strong> 利用ROUGE-L指标，剔除与现有任务池相似度超过0.7的冗余指令。</p>\n</li>\n<li>\n<p><strong>针对性清洗：</strong></p>\n<ul>\n<li>\n<p><strong>长度过滤：</strong> 确保任务完整且重点突出。</p>\n</li>\n<li>\n<p><strong>依赖排除：</strong> 屏蔽包含图像、文件等模型无法处理的外部关键词。</p>\n</li>\n<li>\n<p><strong>格式规范：</strong> 移除无效标点开头或非英文的生成内容。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"实验成果与性能提升\">实验成果与性能提升</h3>\n<p>Self-Instruct成功从GPT-3中提取了5.2万条指令及8.2万个实例：</p>\n<ul>\n<li>\n<p><strong>性能飞跃：</strong> 在SuperNI基准测试中，GPT-3的指令遵循能力提升了33.1%。</p>\n</li>\n<li>\n<p><strong>对标结果：</strong> 仅依靠合成数据微调，其实际表现已接近InstructGPT-001的水平。</p>\n</li>\n</ul>\n<h2 id=\"32-wizardlm\">3.2 <strong>WizardLM</strong></h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/nlpxucan/WizardLM\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/nlpxucan/WizardLM</a> 9.5k⭐</p>\n</li>\n<li>\n<p>论文：<a href=\"https://proceedings.iclr.cc/paper_files/paper/2024/file/82eec786fdfbbfa53450c5feb7d1ac92-Paper-Conference.pdf\" rel=\"noopener nofollow\" target=\"_blank\">https://proceedings.iclr.cc/paper_files/paper/2024/file/82eec786fdfbbfa53450c5feb7d1ac92-Paper-Conference.pdf</a></p>\n</li>\n</ul>\n<p>如果说Self-Instruct解决了数据从无到有的问题，WizardL则专注于数据由简入繁的质变。</p>\n<h3 id=\"evol-instruct的进化逻辑与操作算子\">Evol-Instruct的进化逻辑与操作算子</h3>\n<p>Evol-Instruct是WizardLM的核心算法，它不再是从种子任务中水平扩张，而是通过垂直进化不断改写指令。该机制通过提示词引导LLM执行六种具体的进化操作：</p>\n<ul>\n<li>\n<p><strong>深度进化</strong>：</p>\n<ul>\n<li>\n<p><strong>添加约束</strong>：向原指令引入更多限制性条件。例如将\"写一个故事\"进化为\"写一个关于量子力学的悬疑故事，且不能使用‘科学’这个词\"。</p>\n</li>\n<li>\n<p><strong>深化</strong>：要求模型在更高、更抽象的认知层面上探讨原有的主题。</p>\n</li>\n<li>\n<p><strong>具体化</strong>：将泛化的概念指令转化为细节丰富的特定场景，增加处理实际问题的复杂性。</p>\n</li>\n<li>\n<p><strong>增加推理步骤</strong>：强制要求模型展示多步逻辑推导过程，而非直接给出答案。</p>\n</li>\n<li>\n<p><strong>复杂化输入</strong>：通过引入干扰信息、错误逻辑或极其复杂的上下文背景来测试模型的稳健性。</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>广度进化</strong>：</p>\n<ul>\n<li><strong>变异</strong>：基于原指令生成一条全新的、在主题或技能上更具挑战性的指令，旨在扩展数据集的领域覆盖范围和技能多样性</li>\n</ul>\n</li>\n</ul>\n<p>通过定制Prompt模板实现操作，模型按进化指令生成回复，经多轮迭代将简单种子指令转化为复杂推理任务。</p>\n<h3 id=\"指令消除器严苛的质量守门人\">指令消除器：严苛的质量守门人</h3>\n<p>在进化过程中，模型可能会生成逻辑不通、无法完成或毫无增量的指令。WizardLM引入了\"指令消除器\"作为过滤机制，将以下四类失败任务予以剔除：</p>\n<ul>\n<li>\n<p><strong>无信息增量</strong>: 进化的指令与原指令内容基本一致，没有实质性的复杂度提升，通常利用GPT-4进行自动判定。</p>\n</li>\n<li>\n<p><strong>执行失败</strong>: 模型生成的回复包含\"对不起/sorry\"等道歉词汇，且回复长度少于80字，表明任务已超出模型处理能力。</p>\n</li>\n<li>\n<p><strong>输出退化</strong>: 回复仅包含标点符号、停用词或生成过程中产生的无效字符。</p>\n</li>\n<li>\n<p><strong>模板泄露</strong>: 进化的指令中直接包含了进化 Prompt 中的引导性词汇，如\"#Rewritten Prompt#\"等。</p>\n</li>\n</ul>\n<p>这种基于\"进化-淘汰\"的物竞天择机制，确保了最终产生的数据集（如WizardLM-70k）在质量分布上向高难度区间倾斜。</p>\n<h3 id=\"专用领域的衍生应用\">专用领域的衍生应用</h3>\n<p>Evol-Instruct普适性强，可助力多垂直领域打造顶尖模型：WizardCoder针对编程任务进化，在代码生成领域超越更大参数量模型；WizardMath结合强化学习形成RLEIF机制，通过复杂数学推理链生成与步骤级评分，大幅提升模型逻辑严密性。</p>\n<h2 id=\"33-easy-dataset\">3.3 Easy Dataset</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/ConardLi/easy-dataset\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/ConardLi/easy-dataset</a> 12.9k⭐</p>\n</li>\n<li>\n<p>官网：<a href=\"https://docs.easy-dataset.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.easy-dataset.com/</a></p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/pdf/2507.04009v1\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2507.04009v1</a></p>\n</li>\n</ul>\n<p>与探索算法边界的Self-Instruct、WizardLM不同，Easy Dataset框架聚焦垂直领域模型训练的工程痛点。金融、医疗、法律等行业的高质量指令数据多隐藏在各类非结构化文档中，难以高效利用，而这款集成化GUI 数据工程套件，实现了从文档解析到模型评估的全链路闭环。</p>\n<h3 id=\"自适应文档处理与语义切分\">自适应文档处理与语义切分</h3>\n<p>Easy Dataset的首要核心功能是其\"自适应文档处理\"模块。针对传统文本切分工具容易导致语义断裂的问题，该框架集成了多种智能切分算法：</p>\n<ul>\n<li>\n<p><strong>Markdown结构感知切分</strong>：能够识别文档的分级标题结构，确保每一个切分出的文本块在逻辑上是完整的。</p>\n</li>\n<li>\n<p><strong>代码感知切分</strong>：针对技术文档，自动识别代码块并防止其在切分过程中被截断 。</p>\n</li>\n<li>\n<p><strong>混合切分策略</strong>：结合语义相似度与固定长度约束，产生既符合计算效率又具备语义连贯性的文本块。</p>\n</li>\n</ul>\n<h3 id=\"角色驱动的合成\">角色驱动的合成</h3>\n<p>为了提升合成数据的多样性和专业性，Easy Dataset引入了创新的\"角色驱动合成\"机制。系统会根据文档内容自动生成\"流派-受众对\"。例如，当处理一份复杂的法律合规文档时，系统会设定不同的提问与回答角色：</p>\n<ul>\n<li>\n<p><strong>角色A</strong>：法律专家（针对专业条文进行深度解析）。</p>\n</li>\n<li>\n<p><strong>角色B</strong>：初级法务（针对合规操作流程进行提问）。</p>\n</li>\n<li>\n<p><strong>角色C</strong>：企业高管（针对合规风险点进行总结性询问）。</p>\n</li>\n</ul>\n<p>这种角色驱动的Prompting策略，使得从同一段非结构化文本中可以延伸出多条视角迥异、风格多元的QA对，极大地模拟了真实世界中复杂的人机交互场景。</p>\n<h3 id=\"人机协作的视觉化管理\">人机协作的视觉化管理</h3>\n<p>Easy Dataset最大的工程优势在于其直观的图形用户界面，这使得非技术出身的行业专家也能深度参与数据建设过程。</p>\n<ul>\n<li>\n<p><strong>文档预处理</strong>：视觉化调节切分阈值，实时查看切分后的文本块，并支持全局标签树构建。</p>\n</li>\n<li>\n<p><strong>指令生成</strong>：批量构建基于文本块的任务，支持手动修改生成的指令，通过标签树管理知识点分布。</p>\n</li>\n<li>\n<p><strong>回复增强</strong>：利用LLM生成包含思维链的详细回答，并提供AI辅助纠偏和质量分级。</p>\n</li>\n<li>\n<p><strong>数据集导出</strong>：一键导出为Alpaca或ShareGPT格式，并自动生成 LLaMA Factory配置文件。</p>\n</li>\n</ul>\n<p>人机协作模式有效缓解纯合成数据的幻觉问题，用户可在界面一键优化逻辑、事实有误的回答，保障训练集的严谨性。</p>\n<h3 id=\"评估闭环与-arena-系统\">评估闭环与 Arena 系统</h3>\n<p>Easy Dataset v1.7.0进一步强化了其评估能力，引入了模型竞技场（Arena）、自动化评估模块。用户不仅可以合成训练数据，还可以同步合成包含判断、单选、多选、简答、开放式五大题型的测试集。教师模型量化评分并生成评估报告，形成生成 — 训练准备 — 评估反馈闭环，是工业界落地便捷的数据工程套件。</p>\n<h2 id=\"34-技术选型建议\">3.4 技术选型建议</h2>\n<ul>\n<li>\n<p><strong>通用对齐阶段</strong>：预训练基础模型先通过Self-Instruct构建广覆盖指令基座，掌握基础对话范式。</p>\n</li>\n<li>\n<p><strong>专业逻辑突破阶段</strong>：面向代码、数学、复杂咨询的模型，引入WizardLM算法，多轮进化打造人类标注难穷尽的逻辑难点。</p>\n</li>\n<li>\n<p><strong>行业模型落地阶段</strong>：特定行业模型采用Easy Dataset路径，以行业规档为底座，通过角色驱动合成专业贴合业务的问答数据集。</p>\n</li>\n</ul>\n<h1 id=\"4-有监督微调sft与参数高效适配框架\">4 有监督微调（SFT）与参数高效适配框架</h1>\n<p>预训练赋予了模型博学，而有监督微调（SFT）则赋予了模型听从指令的能力。随着模型规模的增长，全参数微调的成本变得难以承受，为了平衡模型性能与资源利用率，有监督微调（SFT）结合参数高效适配（PEFT）技术成为了行业主流方案。</p>\n<h2 id=\"41-llamafactory\">4.1 LlamaFactory</h2>\n<ul>\n<li>\n<p>gitHub: <a href=\"https://github.com/hiyouga/LlamaFactory\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/hiyouga/LlamaFactory</a> 66.1k⭐</p>\n</li>\n<li>\n<p>官方文档: <a href=\"https://docs.llamafactory.com.cn/docs/documents/introduct\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.llamafactory.com.cn/docs/documents/introduct</a></p>\n</li>\n</ul>\n<p>LlamaFactory以微调的民主化为核心理念，是易用、高效、高集成的LLM训练平台。它通过抽象底层逻辑，将复杂的分布式训练、数据格式转化、模型兼容等问题封装于统一接口，其特色的LLaMA Board可视化界面，支持用户无代码完成从数据准备、模型加载到微调启动、损失监控及权重合并的全流程操作。更多内容见<a href=\"https://mp.weixin.qq.com/s/9f4mqYVGKNS-LhmHLl6CXw\" rel=\"noopener nofollow\" target=\"_blank\">收藏！LLM-RL训练框架：3大流派+6大框架，一文搞定</a>。</p>\n<h3 id=\"关键技术特性与算法矩阵\">关键技术特性与算法矩阵</h3>\n<p>LlamaFactory展现了极强的Day 0支持能力，即在 Llama 3/4、Qwen 2.5/3、DeepSeek-R1 等前沿模型发布的第一时间提供适配。在算法层面，该框架集成了目前最广泛的PEFT算法矩阵。</p>\n<ul>\n<li>\n<p><strong>基础微调模式</strong>: 全量参数微调、冻结微调、LoRA、QLoRA (2/3/4/5/6/8-bit)</p>\n</li>\n<li>\n<p><strong>先进适配器算法</strong>: DoRA、LoRA+、rsLoRA、PiSSA、LoftQ、OFT</p>\n</li>\n<li>\n<p><strong>优化器与内存管理</strong>: GaLore、BAdam、Adam-mini、Muon、FlashAttention-2、Liger Kernel</p>\n</li>\n<li>\n<p><strong>对齐与强化学习</strong>: SFT、PPO、DPO、KTO、ORPO、SimPO</p>\n</li>\n</ul>\n<p>LlamaFactory在数据处理上支持主流数据集格式及多轮对话、多模态数据处理，内置Native DDP、DeepSpeed、FSDP等分布式训练策略，可在中大规模GPU集群运行，还深度适配昇腾NPU，覆盖驱动安装、CANN配置及加速算子集成。</p>\n<h3 id=\"适合场景-3\">适合场景</h3>\n<ul>\n<li>\n<p><strong>科研实验与原型验证</strong>：研究人员可以利用WebUI快速测试不同PEFT算法对特定任务的效果，无需在工程细节上浪费时间。</p>\n</li>\n<li>\n<p><strong>快速领域定制</strong>：中小企业或开发团队需要将通用模型转化为特定垂直领域的助手时，LlamaFactory提供了最快的落地路径。</p>\n</li>\n<li>\n<p><strong>国产化替代</strong>：在需要基于昇腾NPU进行自主可控的大模型微调时，LlamaFactory的NPU训练方案提供了详尽的工程参考。</p>\n</li>\n</ul>\n<h3 id=\"优缺点-6\">优缺点</h3>\n<p><strong>优点</strong>：① 交互极致友好：LLaMA Board可视化界面是目前开源社区中成熟度最高的GUI工具，极大降低了非工程背景用户的门槛；② 兼容性极其广泛：支持模型超过100种，涵盖了当前市场上绝大多数主流及小众架构；③ 算法跟进迅速：社区活跃度极高，新算法（如GaLore、DoRA）的集成速度处于行业领先水平。</p>\n<p><strong>缺点</strong>：①单卡极限优化不足：虽然集成了Unsloth的加速算子，但在纯粹的单卡极致效率上，仍略逊于原生Unsloth框架；② 工程复杂度较高：由于功能过于丰富，底层代码库较为庞大，对于希望进行深度二次开发的用户来说，代码的学习曲线可能较陡。</p>\n<h2 id=\"42-unsloth\">4.2 Unsloth</h2>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/unslothai/unsloth\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/unslothai/unsloth</a> 51.1k⭐</p>\n</li>\n<li>\n<p>说明文档：<a href=\"https://unsloth.ai/docs\" rel=\"noopener nofollow\" target=\"_blank\">https://unsloth.ai/docs</a></p>\n</li>\n</ul>\n<h3 id=\"核心机制triton内核与手动反向传播\">核心机制：Triton内核与手动反向传播</h3>\n<p>Unsloth颠覆了开发者对显存占用的认知，由Daniel Han和Michael Han兄弟开发，核心是极致性能优化与深度挖掘硬件潜力。该框架舍弃PyTorch默认算子实现，基于OpenAI的Triton语言手写线性层、RoPE位置嵌入等几乎所有关键计算内核。</p>\n<p>其核心价值在于消除冗余的中间张量存储：标准PyTorch流程中，反向传播需保留大量激活值，是显存消耗的主要来源。Unsloth通过手动编写反向传播逻辑，结合内核融合技术，让单次GPU调用完成多个计算步骤，大幅减少VRAM的读写次数。</p>\n<h3 id=\"性能表现与显存节省数据\">性能表现与显存节省数据</h3>\n<p>根据官方及社区的实测数据，Unsloth在微调任务中相比基准（HF+FA2）的优势。</p>\n<ul>\n<li>\n<p><strong>训练速度</strong>：提速 2x 至 5x，部分场景甚至达到 10x 以上</p>\n</li>\n<li>\n<p><strong>显存占用</strong>：减少70%至80%，极大地缓解了OOM问题</p>\n</li>\n<li>\n<p><strong>精度保持</strong>：0%精度损失，通过数学上的精确等价实现优化而非近似</p>\n</li>\n<li>\n<p><strong>上下文支持</strong>：在80GB显存下支持高达500K的上下文窗口训练</p>\n</li>\n</ul>\n<p>此外，Unsloth的动态4-bit量化技术优化自bitsandbytes，通过动态保护关键权重，以不足10%的显存开销提升4-bit模型微调精度，在MMLU等基准上表现更优。</p>\n<h3 id=\"适合场景-4\">适合场景</h3>\n<ul>\n<li>\n<p><strong>消费级<strong><strong>显卡</strong></strong>训练</strong>：在RTX 3060 (12GB) 或RTX 4090 (24GB) 上微调Llama 7B甚至20B规模的模型，这是传统框架难以完成的任务。</p>\n</li>\n<li>\n<p><strong>长文本任务训练</strong>：对于需要极长上下文（如法律文书、长篇小说分析）的微调，Unsloth的内存管理能力是核心优势。</p>\n</li>\n<li>\n<p><strong>高频迭代任务</strong>：在需要频繁调整参数、快速看到训练结果的场景下，2-5倍的速度提升意味着研发周期的指数级缩短。</p>\n</li>\n</ul>\n<h3 id=\"优缺点-7\">优缺点</h3>\n<p><strong>优点</strong>：① 效率断层领先：在单卡微调领域，Unsloth的速度和显存效率目前处于无敌地位；② 零部署痛苦：提供丰富的Google Colab和Kaggle笔记本模板，且支持一键导出至GGUF、vLLM等多种部署格式；③ RL支持卓越：针对GRPO算法进行了内存优化，使其成为当前复现DeepSeek-R1风格推理模型最经济的工具。</p>\n<p><strong>缺点</strong>：① 多卡支持较弱：长期以来其开源版本主要针对单卡优化，虽然可以通过一些非官方手段接入多卡，但成熟的分布式支持（Pro版）尚未全面开源；② 模型结构敏感：由于算子是手写的，当模型引入全新的算子或结构（如非Transformer架构）时，需要开发者手动更新内核，兼容性扩展相对滞后。</p>\n<h2 id=\"43-ms-swift\">4.3 ms-swift</h2>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>Github: <a href=\"https://github.com/modelscope/ms-swift\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/modelscope/ms-swift</a> 12.3k⭐</p>\n</li>\n<li>\n<p>论文：<a href=\"https://arxiv.org/abs/2408.05517\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2408.05517</a></p>\n</li>\n</ul>\n<p>ms-swift（Scalable lightWeight Infrastructure for Fine-Tuning)阿里是ModelScope社区推出的全能型大模型微调框架，区别于LlamaFactory的易用性和Unsloth的性能追求，其以工业级的深度与广度为设计目标。该框架深度融合ModelScope生态，支持600余种纯文本模型、300余种多模态模型，覆盖图像、视频、音频等全模态输入。</p>\n<p>ms-swift实现了辅助数据标注、微调训练、EvalScope评测、量化及vLLM/SGLang部署的全链路闭环，一站式工具链大幅降低企业生产环境中跨平台迁移的工程损耗。</p>\n<h3 id=\"核心技术megatron-扩展与国产硬件适配\">核心技术：Megatron 扩展与国产硬件适配</h3>\n<p>在处理超大规模模型时，ms-swift引入了Megatron并行技术，支持张量并行（TP）、流水线并行（PP）、上下文并行（CP）等复杂策略。通过Megatron-SWIFT模块，该框架在微调 MoE（专家混合）模型时的加速比可达10倍以上。</p>\n<p>ms-swift对国产化算力的支持最为彻底。它不仅支持 NVIDIA A100/H100，还针对昇腾NPU、寒武纪、寒武纪及国内主流算力平台进行了深度调优。其在昇腾NPU上支持基于CANN的底层加速，并能够配合DeepSpeed实现大规模分布式训练。</p>\n<ul>\n<li>\n<p><strong>模型支持</strong>：支持Qwen-VL, InternVL, GLM-4.5V, Ovis等300+多模态模型</p>\n</li>\n<li>\n<p><strong>多模态优化</strong>：引入多模态打包技术（Packing），训练速度提升100%+</p>\n</li>\n<li>\n<p><strong>强化学习族群</strong>：内置GRPO, DAPO, GSPO, RLOO, Reinforce++等全系列强化学习算法</p>\n</li>\n<li>\n<p><strong>部署后端</strong>: 集成vLLM, SGLang, LMDeploy，提供标准的OpenAI API接口</p>\n</li>\n</ul>\n<h3 id=\"适合场景-5\">适合场景</h3>\n<p>ms-swift是企业级项目及超大规模任务的首选：</p>\n<ul>\n<li>\n<p><strong>多模态模型微调</strong>：在处理包含视觉、语音、视频的跨模态对齐任务时，ms-swift提供了最成熟的模板与算子支持。</p>\n</li>\n<li>\n<p><strong>大规模集群训练</strong>：当微调任务需要跨越数十台甚至上百台服务器，并利用复杂的并行策略时，ms-swift的Megatron架构是核心保障。</p>\n</li>\n<li>\n<p><strong>国产化工业落地</strong>：对于必须部署在国产硬件环境（如金融、政务云）的AI项目，ms-swift提供了最完备的驱动与框架兼容性支持。</p>\n</li>\n</ul>\n<h3 id=\"优缺点-8\">优缺点</h3>\n<p><strong>优点</strong>：① 多模态支持之王：目前开源界对视觉、语音模型微调支持最全面、优化最深入的框架之一; ② 国产算力之友：在昇腾等国产芯片上的表现最为稳定，且有ModelScope社区的强大技术支持; ③并行策略完备：真正支持千亿级参数模型的并行训练与优化，具备极强的可扩展性。</p>\n<p><strong>缺点</strong>：① 学习难度最高：由于集成了Megatron和海量的工业级参数，其配置复杂度高于LlamaFactory，对开发者的工程水平有较高要求; ② 环境依赖较重：在安装分布式及国产硬件支持模块时，对系统库、编译器版本有较严苛的要求，初次部署可能耗时较长。</p>\n<h1 id=\"5-强化学习与人类偏好对齐rlhf\">5 强化学习与人类偏好对齐（RLHF）</h1>\n<p>RLHF是大模型通往智能的最后一步，通过与人类价值观的对齐，模型能够学会拒绝有害指令并在复杂任务中表现得更有逻辑。随着DPO（直接偏好优化）和 GRPO（组相对策略优化）等算法的普及，对齐框架正在向高性能生成和灵活策略切换方向演进。</p>\n<p>因前一篇<a href=\"https://mp.weixin.qq.com/s/9f4mqYVGKNS-LhmHLl6CXw\" rel=\"noopener nofollow\" target=\"_blank\">收藏！LLM-RL训练框架：3大流派+6大框架，一文搞定</a>做过介绍，这里不过多阐述，只给一个汇总表格。</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>框架名称</td>\n<td>核心技术方案</td>\n<td>适用场景</td>\n</tr>\n<tr>\n<td>OpenRLHF</td>\n<td>Ray + vLLM架构、分布式多模型分发</td>\n<td>大规模集群下的高吞吐 PPO/DPO/GRPO训练</td>\n</tr>\n<tr>\n<td>veRL</td>\n<td>3D-HybridEngine、训练与采样高效重塑</td>\n<td>超大规模MoE模型的高性能强化学习对齐</td>\n</tr>\n<tr>\n<td>TRL</td>\n<td>深度集成PEFT、Hugging Face原生支持</td>\n<td>使用HF生态进行轻量级对齐实验</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"6-选型建议\">6 选型建议</h1>\n<p>大模型全链路已形成高度协同的开源生态，数据制备环节可通过Easy-dataset将企业内部文档直接抽离为问答对，并搭配Data-Juicer完成质量清洗；模型微调环节针对处理好的数据集，可采用Llama-Factory调用生成的配置开展微调，若资源受限还能结合Unsloth实现加速；智能对齐环节则借助OpenRLHF进行强化学习对齐，让模型具备更优的逻辑推理能力与价值观对齐效果，其中逻辑推理可达到O1级思考水平。建议企业开发者优先尝试Easy-dataset与Llama-Factory的组合方案，该方案是目前上手最快、工程化程度最高的数据—微调闭环方案。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-26 08:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/aifrontiers\">AI-Frontiers</a>&nbsp;\n阅读(<span id=\"post_view_count\">10</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "深入浅出了解生成模型-8：生成加速策略概述",
      "link": "https://www.cnblogs.com/Big-Yellow/p/19530732",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Big-Yellow/p/19530732\" id=\"cb_post_title_url\" title=\"发布于 2026-01-25 23:16\">\n    <span>深入浅出了解生成模型-8：生成加速策略概述</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        扩散模型生成加速策略主要包括加速框架优化、Cache策略及量化技术。加速框架方面，可通过指定attention计算后端（如flash_attn）、torch.compile编译、torch.channels_last优化内存访问，或使用xFormers加速attention计算并降低显存，配合CPU卸载、设备分配等显存优化措施。Cache策略利用扩散过程时间冗余，如DeepCache缓存UNet高层特征、FORA复用DiT的Attn和MLP层特征，FBCache基于First Block L1误差判断是否复用残差，CacheDit结合前n层缓存与阈值判断实现加速。量化技术通过PTQ或QAT降低显存并加速，如Bitsandbytes的即时可逆int4/int8量化、SVDQuant分解权重吸收异常值后量化残差、GGUF格式的紧凑编码与多种PTQ量化级别。测试显示，结合channel优化、flash_attn及cache-dit等策略可有效缩短生图时间。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>原文：<a href=\"https://www.big-yellow-j.top/posts/2025/12/29/SDAcceralate.html\" rel=\"noopener nofollow\" target=\"_blank\">https://www.big-yellow-j.top/posts/2025/12/29/SDAcceralate.html</a></p>\n<h2 id=\"扩散模型生成加速策略\">扩散模型生成加速策略</h2>\n<p>Diffusion推理加速的方案，主要包括Cache、量化、分布式推理、采样器优化和蒸馏等。下面内容主要是去对Cache、计算加速框架以及量化技术进行介绍</p>\n<blockquote>\n<p>SD模型加速方式：<a href=\"https://github.com/xlite-dev/Awesome-DiT-Inference?tab=readme-ov-file#Quantization\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/xlite-dev/Awesome-DiT-Inference?tab=readme-ov-file#Quantization</a></p>\n</blockquote>\n<p>不过值得注意的是对于下面内容，首先介绍加速框架（这部分内容主要是介绍进行加速的一些小trick，主要是直接通过api去加速）、cache以及量化一般就会涉及到一些算法的基本原理。所有的测试代码：<a href=\"https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/df_acceralate.ipynb\" rel=\"noopener nofollow\" target=\"_blank\">df_acceralate.ipynb</a></p>\n<h3 id=\"一般加速框架以及显存优化措施\">一般加速框架以及显存优化措施</h3>\n<p>这部分内容的话比较杂（直接总结<a href=\"https://huggingface.co/docs/diffusers/optimization/fp16#scaled-dot-product-attention\" rel=\"noopener nofollow\" target=\"_blank\">huggingface</a>内容），1、<strong>直接使用attn计算加速后端</strong>，比如说一般就是直接使用比如说<code>flash_attn</code>进行attention计算加速，比如说：</p>\n<pre><code class=\"language-python\">pipeline.transformer.set_attention_backend(\"_flash_3_hub\") # 启用flash attn计算加速\npipeline.transformer.reset_attention_backend()             # 关闭flash attn计算加速\n</code></pre>\n<p>不过值得注意的是<code>_flash_3_hub</code> 只支持非hopper架构，因此可以直接就使用<code>set_attention_backend(\"flash\")</code>。2、<strong>直接使用</strong><code>torch.compile</code>进行加速，不过值得注意的是<strong>在开始使用过程中会比较慢</strong>，因为在执行时，它会将模型编译为优化的内核，所以相对会比较慢，但是如果对编译后模型进行批量测试在时间上就会有所提升比如说在代码<a href=\"https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/df_acceralate.ipynb\" rel=\"noopener nofollow\" target=\"_blank\">df_acceralate.ipynb</a>中测试结果使用compile在z-image上生成5张图片耗时：86.49s（<strong>平均生图时间</strong>4s）不使用compile：29.92（<strong>平均生图时间</strong>5s）；3、使用<code>torch.channels_last</code>去优化数据结构（<a href=\"https://docs.pytorch.org/tutorials/intermediate/memory_format_tutorial.html#performance-gains\" rel=\"noopener nofollow\" target=\"_blank\">torch文档</a>）：最主要的一点是通过channel_last让 GPU 在计算卷积 / attention 时，内存访问更连续，比如说一般数据的输入是NCHW那么在内存访问中格式是：<code>N0C0H0W0, N0C0H0W1, ..., N0C0H1W0, ...</code>这个里面通道C变化最慢，使用channel_list数据格式变为NHWC在内存中访问顺序是：<code>N0H0W0C0, N0H0W0C1, N0H0W0C2, ...</code>值得注意的是两部分数据在shape上是一致的只是strid不一致。使用方式也比较简单：</p>\n<pre><code class=\"language-python\"># 修改模型\nmodel = model.to(memory_format=torch.channels_last)\n# 修改输入\ninput = input.to(memory_format=torch.channels_last)\noutput = model(input)\n...\npipeline.unet.to(memory_format=torch.channels_last)\n</code></pre>\n<h4 id=\"1xformers加速\">1、xFormers加速</h4>\n<blockquote>\n<p>项目地址：<a href=\"https://github.com/facebookresearch/xformers\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/facebookresearch/xformers</a></p>\n</blockquote>\n<p>在SD模型中对于xformers基本使用方式如下所示：</p>\n<pre><code class=\"language-python\">import torch\nfrom diffusers import StableDiffusionXLPipeline\n\npipeline = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\",\n    torch_dtype=torch.float16,\n).to(\"cuda\")\n# 使用xformer加速\npipeline.enable_xformers_memory_efficient_attention()\n# 关闭xformer加速\npipeline.disable_xformers_memory_efficient_attention()\n</code></pre>\n<p>xformers作用在于<strong>加速attention计算并降低显存</strong>，除此之外还提供了多种注意力实现方式，如casual attention等。根据<a href=\"https://facebookresearch.github.io/xformers/components/ops.html#xformers.ops.fmha.cutlass.FwOp\" rel=\"noopener nofollow\" target=\"_blank\">官方文档</a>中的描述，对于对于<code>xformers.ops.memory_efficient_attention</code>在使用上参数主要是：1、输入数据也就是QKV的格式上必须满足为：<code>[B, M, H, K]</code>分别表示的是其中B 为batch size, N为序列长度, num_heads为多头注意力头的个数, dim_head则为每个头对应的embeding size；2、attn_bias实际上充当为在使用mask attention时的mask；3、p也就是dropout对应值；4、op为Tuple，用于指定优化self-attention计算所采用的算子。基本使用方式如下：</p>\n<pre><code class=\"language-python\">import xformers.ops as xops\ny = xops.memory_efficient_attention(q, k, v)\ny = xops.memory_efficient_attention(q, k, v, p=0.2) # 使用dropout\ny = xops.memory_efficient_attention(\n    q, k, v,\n    attn_bias=xops.LowerTriangularMask()\n)# 使用casual 注意力\n</code></pre>\n<p>值得着重了解的就是其中<code>attn_bias</code>参数，简单直观的理解：用于控制注意力可见性和结构的统一接口，<strong>既可以表示 mask，也可以表示稀疏/局部/因果等高级注意力模式</strong>，并且以高性能方式融入 attention 内核。比如说：<br />\n1、<code>xops.LowerTriangularMask()</code>：常规的causal注意力也就是下三角mask<br />\n2、<code>xops.LocalAttentionFromBottomRightMask</code>：局部注意力，每个token只能看最近的window_size个token</p>\n<h4 id=\"2显存优化\">2、显存优化</h4>\n<blockquote>\n<p>这部分内容直接总结：<a href=\"https://huggingface.co/docs/diffusers/en/optimization/memory?device-map=pipeline+level#reduce-memory-usage\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/docs/diffusers/en/optimization/memory?device-map=pipeline+level#reduce-memory-usage</a></p>\n</blockquote>\n<p>对于模型的显存过大可以考虑根据自身的设备进行分配，比如说将模型卸载到CPU或者将VAE等放到其它显卡上，在diffusers就提供了这些方法（这块内容直接问AI进行总结）：<br />\n<strong>1、CPU卸载</strong><br />\n它启用了一种极致级别的逐层（leaf-level / sequential）CPU offloading机制，核心思路是：把模型的计算图中<strong>最底层的参数（leaf modules，即最细粒度的子模块、层或权重块）默认放在 CPU 内存里存储</strong>。在前向传播（forward pass）过程中，只在真正需要计算某个具体层的时候，才把那一小块参数临时从 CPU 拷贝（onload）到 GPU。计算完这层之后，立刻把这块参数再 offload 回 CPU，释放 GPU 显存。然后再加载下一层，以此类推，一层一层顺序执行（sequential）。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602481-1040500181.webp\" /><br />\n<strong>2、设备分配</strong><br />\n这部分主要是将生成模型中不同模型结构如VAE、CLIP去分配到其它显卡上：</p>\n<pre><code class=\"language-python\">import torch\nfrom diffusers import AutoModel, StableDiffusionXLPipeline\npipeline = StableDiffusionXLPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-base-1.0\",\n    torch_dtype=torch.float16,\n    device_map=\"balanced\" # 使用balance就可以实现不同设备分配\n)\nprint(pipeline.hf_device_map)\n{'unet': 1, 'vae': 1, 'safety_checker': 0, 'text_encoder': 0}\n</code></pre>\n<p>亦或者直接自己定分配：</p>\n<pre><code class=\"language-python\">import torch\nfrom diffusers import AutoModel\ndevice_map = {\n    'pos_embed': 0, 'time_text_embed': 0, 'context_embedder': 0, 'x_embedder': 0, 'transformer_blocks': 0, 'single_transformer_blocks.0': 0, 'single_transformer_blocks.1': 0, 'single_transformer_blocks.2': 0, 'single_transformer_blocks.3': 0, 'single_transformer_blocks.4': 0, 'single_transformer_blocks.5': 0, 'single_transformer_blocks.6': 0, 'single_transformer_blocks.7': 0, 'single_transformer_blocks.8': 0, 'single_transformer_blocks.9': 0, 'single_transformer_blocks.10': 1, 'single_transformer_blocks.11': 1, 'single_transformer_blocks.12': 1, 'single_transformer_blocks.13': 1, 'single_transformer_blocks.14': 1, 'single_transformer_blocks.15': 1, 'single_transformer_blocks.16': 1, 'single_transformer_blocks.17': 1, 'single_transformer_blocks.18': 1, 'single_transformer_blocks.19': 1, 'single_transformer_blocks.20': 1, 'single_transformer_blocks.21': 'cpu', 'single_transformer_blocks.22': 'cpu', 'single_transformer_blocks.23': 'cpu', 'single_transformer_blocks.24': 'cpu', 'single_transformer_blocks.25': 'cpu', 'single_transformer_blocks.26': 'cpu', 'single_transformer_blocks.27': 'cpu', 'single_transformer_blocks.28': 'cpu', 'single_transformer_blocks.29': 'cpu', 'single_transformer_blocks.30': 'cpu', 'single_transformer_blocks.31': 'cpu', 'single_transformer_blocks.32': 'cpu', 'single_transformer_blocks.33': 'cpu', 'single_transformer_blocks.34': 'cpu', 'single_transformer_blocks.35': 'cpu', 'single_transformer_blocks.36': 'cpu', 'single_transformer_blocks.37': 'cpu', 'norm_out': 'cpu', 'proj_out': 'cpu'\n}\ntransformer = AutoModel.from_pretrained(\n    \"black-forest-labs/FLUX.1-dev\", \n    subfolder=\"transformer\",\n    device_map=device_map,\n    torch_dtype=torch.bfloat16\n)\n</code></pre>\n<h3 id=\"cache策略概述\">cache策略概述</h3>\n<p>cache指的是：<strong>缓存通过存储和重用不同层（例如注意力层和前馈层）的中间输出来加速推理，而不是在每个推理步骤执行整个计算</strong>。它以更多内存为代价显着提高了生成速度，并且不需要额外的训练。主要详细介绍两种：1、DeepCache；2、FORA。对于更加多的cache策略可以看<a href=\"https://zhuanlan.zhihu.com/p/711223667\" rel=\"noopener nofollow\" target=\"_blank\">知乎</a>，<strong>推荐直接使用</strong><a href=\"#cachedit\" rel=\"noopener nofollow\">CacheDit</a>来进行加速。</p>\n<h4 id=\"deepcache策略\">DeepCache策略</h4>\n<blockquote>\n<p>Paper:<a href=\"https://arxiv.org/pdf/2312.00858\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2312.00858</a><br />\nCode:<a href=\"https://link.zhihu.com/?target=https%3A//github.com/horseee/DeepCache\" rel=\"noopener nofollow\" target=\"_blank\">https://link.zhihu.com/?target=https%3A//github.com/horseee/DeepCache</a></p>\n</blockquote>\n<p><strong>主要针对UNet架构</strong>的Diffusion模型进行推理加速。DeepCache 是一种Training-free的扩散模型加速算法，核心思想是<strong>利用扩散模型序列去噪步骤中固有的时间冗余来减少计算开销</strong>。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231603400-1714104454.webp\" /><br />\n基于 U-Net 结构特性，发现相邻去噪步骤的高层特征具有显著时间一致性（Adjacent steps in the denoising process exhibit significant temporal similarity in high-level features.），比如说上图中作者在测试上采用block <span class=\"math inline\">\\(U_2\\)</span>的特征和其它所有的采样步之间相似性计算（图b），因此缓存这些高层特征并仅以低成本更新低层特征，从而避免重复计算。具体方法为：<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602316-18977204.webp\" /><br />\n比如说在官方的使用中有参数：<code>helper.set_params(cache_interval=3,cache_branch_id=0,)</code>表示是每3个时间步进行一次完成forward然后刷新cache，而其中参数cache_branch_id值得是一般而言在UNet中会定义<code>branch 0 → early / down blocks</code>等就是选择哪些层的输出。具体过程如下：t=1进行计算缓存，t=2,3都直接使用缓存，t=4完整计算得到缓存。</p>\n<h4 id=\"fora\">FORA</h4>\n<blockquote>\n<p>Paper: <a href=\"https://arxiv.org/pdf/2407.01425\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/pdf/2407.01425</a><br />\nCode: <a href=\"https://github.com/prathebaselva/FORA\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/prathebaselva/FORA</a></p>\n</blockquote>\n<p><strong>主要是争对Dit架构</strong>的Diffusion模型进行推理加速。利用 Diffusion Transformer 扩散过程的重复特性实现了可用于DiT的Training-free的Cache加速算法。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602779-569782593.webp\" /><br />\nFORA的核心在于发现Dit在去噪过程中，<strong>相邻时间步的Attn和MLP层特征存在显著重复性</strong>（如上图所示:在layer0、9、18、27这些层以及250步采样中，随后采样步约往后特征之间相似性也就越高。）。通过Caching特征，FORA 将这些重复计算的中间特征保存并在后续时间步直接复用，避免逐步重新计算。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231603384-1139937541.webp\" /><br />\n具体而言，模型以固定间隔 N 重新计算并缓存特征：当时间步 t 满足 t mod N=0 时，更新所有层的缓存；在后续 N-1 步中，直接检索cached的 Attn 和 MLP 特征，跳过重复计算。这种策略利用了 DiT 架构在邻近时间时间步的特征相似性，在不修改DiT模型结构的前提下实现加速。例如，在 250 步 DDIM 采样中，当 N=3 时，模型仅需在第 3、6、9... 步重新计算特征，其余步骤复用Cache，使计算量减少约 2/3。实验表明，FORA对后期去噪阶段的特征相似性利用更为高效，此时特征变化缓慢，缓存复用的性价比最高。</p>\n<h4 id=\"fbcache\">FBCache</h4>\n<blockquote>\n<p>项目地址：<a href=\"https://github.com/chengzeyi/ParaAttention/blob/main/doc/fastest_flux.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/chengzeyi/ParaAttention/blob/main/doc/fastest_flux.md</a></p>\n</blockquote>\n<p>通过缓存变换器模型中变换器块的输出，并在下一步推理中重新使用它们，可以降低计算成本，加快推理速度。然而，很难决定何时重新使用缓存以确保生成图像的质量。最近，TeaCache 提出，可以使用时间步嵌入来近似模型输出之间的差异。AdaCache 也表明，在多个图像和视频 DiT 基线中，<strong>缓存可以在不牺牲生成质量的情况下显著提高推理速度</strong>。不过，TeaCache 仍然有点复杂，因为它需要重新缩放策略来确保缓存的准确性。在 ParaAttention 中，<strong>发现可以直接使用第一个transformer输出的残差来近似模型输出之间的差异。当差值足够小时，我们可以重复使用之前推理步骤的残差</strong>，这意味着我们实际上跳过了去噪步骤。我们的实验证明了这一方法的有效性，我们可以在 FLUX.1-dev 推理上实现高达 1.5 倍的速度，而且质量非常好<sup class=\"footnote-ref\"><a href=\"#fn1\" id=\"fnref1\" rel=\"noopener nofollow\">[1]</a></sup>。<br />\n简单来说就是上面提到的DeepCache/FORA在使用上太粗糙直接通过固定时间步去cache缓存这样忽视输出差异的非均匀性，因此后续的TeaCache发现模型输入与输出的强相关性，通过Timestep Emebdding（输入）来估计输出差异。而后FBCache又做了新的改进：<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602704-899465973.webp\" /><br />\n利用residual cache实现了一个基于First Block L1误差的Cache方案，误差小于指定阈值，就跳过当前步计算，复用residual cache，对当前步的输出进行估计。</p>\n<h4 id=\"cachedit\">CacheDit</h4>\n<p><a href=\"https://github.com/vipshop/cache-dit\" rel=\"noopener nofollow\" target=\"_blank\">cache-dit</a>这个框架主要是适用于Dit结构的扩散模型使用，其具体<a href=\"https://cache-dit.readthedocs.io/en/latest/user_guide/DBCACHE_DESIGN/\" rel=\"noopener nofollow\" target=\"_blank\">模型框架</a>如下：<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231603414-1076713638.webp\" /><br />\n对于上述框架首先了解CacheDit中几个概念：1、<code>Fn</code>：表示需要计算前n层transformer block在时间步t并且详细解释一下CacheDit原理；2、<code>Bn</code>:表示进一步的融合后n层transformer block的信息去强化预测准确性。其中n=1时候就是FBCache。<br />\n因此对于CacheDit具体过程为：<strong>在t-1步时候</strong>，前n块block去计算他们的结果得到输出结果hidden state并且写入缓存中<span class=\"math inline\">\\(C_{t-1}\\)</span>，而后后几层进行完整结算。<strong>在t步时候</strong>，前n块block不完整计算，而是直接复用/近似 t-1 步的缓存<span class=\"math inline\">\\(C_{t-1}\\)</span>得到近似的结果，计算近似结果和缓存结果中差异（L1 范数），如果差异小于阈值直接复用缓存输入到后续的块中计算，反之就重新计算这n块结果。<br />\n其中具体使用如下：<a href=\"https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/df_acceralate.ipynb\" rel=\"noopener nofollow\" target=\"_blank\">df_acceralate.ipynb</a></p>\n<h3 id=\"量化技术概述\">量化技术概述</h3>\n<p><a href=\"https://www.big-yellow-j.top/posts/2025/10/11/Quantized.html\" rel=\"noopener nofollow\" target=\"_blank\">量化技术</a>是一种模型压缩的常见方法，将模型权重从高精度（如FP16或FP32）量化为低比特位（如INT8、INT4）去实现<strong>降低显存+生成加速</strong>。量化过程的基本范式，量化过程：<span class=\"math inline\">\\(Q=\\frac{W}{S}\\)</span>其中 <span class=\"math inline\">\\(S\\)</span>表示scale，反量化过程：<span class=\"math inline\">\\(\\hat{w}=QS\\)</span>，因此对于量化只需要保存：1、量化后权重；2、scale值（不同量化模型计算方式不同）。比如说（对称量化过程）对于：<code>1.21, -1.13, 0.22, 0.83, 2.11, -1.53, 0.79\t-0.54, 0.84</code>其中最大值为2.11那么可以计算出缩放系数为：<span class=\"math inline\">\\(\\frac{2.11}{127}=0.01661417\\)</span>（127代表int8数值范围-127，127）那么可以对数据缩放（量化）得到：<code>72, -69, 13, 49, 127, -93, 47, -33, 50</code>反量化可以得到：<code>1.19622024,....</code>（直接乘scale即可）具体计算数字之间差异，都是存在误差的。<br />\n常见的量化策略可以分为PTQ和QAT两大类。量化感知训练（Quantization-Aware Training）：在<strong>模型训练过程中进行量化</strong>，一般效果会更好一些，但需要额外训练数据和大量计算资源比如说qlora。后量化（PTQ）：在<strong>模型训练完成后，对模型进行量化</strong>，无需重新训练。对于线性量化下，浮点数与定点数之间的转换公式如下：<span class=\"math inline\">\\(Q=\\frac{R}{S}+Z;R=(Q-Z)*S\\)</span>，其中R 表示量化前的浮点数、Q 表示量化后的定点数、S（Scale）表示缩放因子的数值、Z（Zero）表示零点的数值。除此之外还会听到几个概念：<strong>1、对称量化</strong>：对称量化的核心思想是将浮点数量化为整数，且量化后的分布是关于零对称的；<strong>2、非对称量化</strong>：是一种用于将浮点数转换为整数表示的量化方法。与对称量化不同的是，这种方法在数据具有偏移（即非对称分布）时更有效，因为它可以减少量化误差。非对称量化会分别找出浮点数的最小值和最大值，分别量化到目标整数范围的最小值和最大值，充分利用量化后的整数范围。这可以使用一个缩放因子（scale）和偏移量（zero-point）来实现<sup class=\"footnote-ref\"><a href=\"#fn2\" id=\"fnref2\" rel=\"noopener nofollow\">[2]</a></sup>。<br />\n比如说在LLM中常用的两种<strong>后量化技术</strong>：1、<strong>GPTQ量化技术</strong>：通过量化——补偿——量化迭代方法，首先量化<span class=\"math inline\">\\(W_{:,j}\\)</span>，而后去计算误差并且补充到 <span class=\"math inline\">\\(W_{:,j:(i+B)}\\)</span>而后进行迭代实现所有参数的量化；2、<strong>AWQ量化技术</strong>：模型计算过程中只有关键参数起作用因此对于关键参数保持原来的精度(FP16)，对其他权重进行低比特量化，但是这样不同进度参数会导致硬件问题，因此在AWQ中<strong>对所有权重均进行低比特量化，但是，在量化时，对于显著权重乘以较大的scale，相当于降低其量化误差；同时，对于非显著权重，乘以较小的scale，相当于给予更少的关注。</strong></p>\n<blockquote>\n<p>补充一个小知识，一般量化看到比较多就是W4A4这个一般指的就是权重和激活的4bit量化，其中权重一般就是<strong>对应该层的模型权重</strong>，激活就是<strong>对应该层的输入</strong></p>\n</blockquote>\n<h4 id=\"bitsandbytes-量化\">Bitsandbytes 量化</h4>\n<p>通过使用bitsandbytes量化来实现8-bit（int8）或者4-bit（int4、Qlora中一般就会使用）量化，不过区别上面提到的AWQ以及GPTQ量化，bitsandbytes不需要对模型进行训练（AWQ、GPTQ可能需要输入数据然后计算误差进行量化），前者需要通过数据来保证量化精度（量化过程是离线、一次性过程），后者量化过程是即时的可逆的。其技术原理如下：<span class=\"math inline\">\\(w≈s q\\)</span>其中w表示原始的FP16权重，q代表int4/int8权重，s缩放因子，其量化过程为对每一个block权重计算：<span class=\"math inline\">\\(\\max(\\text{abs}(w))\\)</span>而后去计算scale：<span class=\"math inline\">\\(s=\\frac{amx(\\| w\\|)}{2^{b-1}-1}\\)</span>而后代入公式就可以得到量化后权重，推理过程中进行：反量化 + 矩阵乘法融合在一个 CUDA kernel 中完成：<span class=\"math inline\">\\(Y=X(sq)\\)</span>。因此对于其使用也很简单，比如说在代码中：<a href=\"https://github.com/shangxiaaabb/ProjectCode/blob/main/code/Python/DFModelCode/DF_acceralate/cache_acceralate.py\" rel=\"noopener nofollow\" target=\"_blank\">cache_acceralate.py</a></p>\n<pre><code class=\"language-python\"># 在ZImagePipeline中参数为：\nclass ZImagePipeline(DiffusionPipeline, ZImageLoraLoaderMixin, FromSingleFileMixin):\n    def __init__(,..,vae, text_encoder, tokenizr, transformer):\n        ...\n# 因此可以直接对里面的text_encoder使用量化处理\n\nfrom diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig\nquantization_config = DiffusersBitsAndBytesConfig(\n    load_in_4bit=True,# 在模型加载阶段，将权重以 4-bit 量化形式加载\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,# 指定 反量化后参与计算的 dtype\n    bnb_4bit_use_double_quant=True,#启用 Double Quantization（双重量化），也就是对block的scale在进行一次量化\n    llm_int8_skip_modules=[\"transformer_blocks.0.img_mod\"],# 指定 不参与 bitsandbytes 量化的模块\n)\ntransformer = AutoModel.from_pretrained(\n    model_name,\n    cache_dir=cache_dir,\n    subfolder=\"transformer\",\n    quantization_config=quantization_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    mirror='https://hf-mirror.com'\n)\n</code></pre>\n<p>去对你的<code>model_name</code>里面的transformer进行量化处理，除此之外还有使用例子就是进行优化器量化，比如说</p>\n<pre><code class=\"language-python\"># 和使用adamw方式一样，使用qlora使用一般带上这个优化器\nimport bitsandbytes as bnb\noptimizer_class = bnb.optim.AdamW8bit\n</code></pre>\n<h4 id=\"svdquant量化\">SVDQuant量化</h4>\n<blockquote>\n<p><a href=\"https://github.com/nunchaku-ai/nunchaku\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/nunchaku-ai/nunchaku</a></p>\n</blockquote>\n<p>在扩散模型中，权重（Weights）和激活（Activations）往往包含大量异常值（极端大或小的值），这些值在低位量化（如4-bit INT4）时会引起严重误差，导致生成的图像失真或噪声增多。<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231601731-775108244.webp\" /></p>\n<blockquote>\n<p>a：权重和激活值中都存在异常值，b：将激活值的异常值移动到权重中，c：将权重进行分解低秩的<span class=\"math inline\">\\(L_1L_2\\)</span>以及残差</p>\n</blockquote>\n<p>因此对于SVDQuant过程描述如下，对于权重和激活值：<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 以及 <span class=\"math inline\">\\(\\mathbf{X}\\)</span>，在最初这两部分值都是存在大量异常值，因此首先通过平滑操作将激活<span class=\"math inline\">\\(\\mathbf{X}\\)</span>中的异常值迁移到权重 <span class=\"math inline\">\\(\\mathbf{X}\\)</span>中得到更新后权重 <span class=\"math inline\">\\(\\hat{\\mathbf{W}}\\)</span>，这部分数据表述为：<span class=\"math inline\">\\(\\hat{\\mathbf{W}}=\\mathbf{W}\\odot S\\)</span>其中S是平滑因子，用于转移异常（⊙表示逐元素乘法）。这部分操作主要是因为：<strong>将异常值集中到权重侧，因为权重是静态的，更容易后续处理。激活侧的异常值减少后，量化难度降低</strong>。而后，进行SVD分解与低秩吸收，对更新后权重进行奇异值分解：$  \\hat{𝑾} = 𝑼 \\Sigma 𝑽^T  <span class=\"math inline\">\\(, 其中𝑼和𝑽是正交矩阵，\\)</span>\\Sigma<span class=\"math inline\">\\(是奇异值对角矩阵。保留前k个最大奇异值（低秩r，通常r &lt;&lt; min(m,n)，其中m,n是权重矩阵维度），形成低秩近似：\\)</span>  𝑳_1 𝑳_2 = 𝑼[:,:r] \\cdot \\Sigma[:r,:r] \\cdot 𝑽^T[:r,:]  <span class=\"math inline\">\\(。然后，计算残差：\\)</span>  𝑹 = \\hat{𝑾} - 𝑳_1 𝑳_2<span class=\"math inline\">\\(，其中只对残差\\)</span>𝑹<span class=\"math inline\">\\(进行量化（\\)</span>Q(𝑹)=\\text{round}(\\frac{𝑹}{S_𝑹})S_𝑹<span class=\"math inline\">\\(，其中\\)</span>S_𝑹<span class=\"math inline\">\\(为缩放因子）处理。低秩分支\\)</span>  𝑳_1 𝑳_2  $使用高精度（16-bit float）运行，专门“吸收”异常值和主要信息，而残差𝑹中的异常值和幅度显著减少，只需量化到4-bit。量化误差界限分析（从论文中）：量化误差上界可通过F范数和奇异值控制，证明低秩吸收后残差的量化难度降低（误差 ≤ $  \\frac{\\sqrt{\\log(\\text{size}(𝑹)\\pi)}}{q_{\\max}} \\mathbb{E}[|𝑹|_F]  $，其中q_max是量化最大值），<strong>最后的整体近似计算</strong>：</p>\n<p></p><div class=\"math display\">\\[\\hat{\\mathbf{X}}\\hat{\\mathbf{W}}=\\hat{\\mathbf{X}}(R+L_1L_2)≈\\hat{\\mathbf{X}}(L_1L_2)+Q(\\hat{\\mathbf{X}})Q(R)\n\\]</div><p></p><p>第一项是16-bit低秩分解，第二项为4-bit残差分支。整个过程对应：<br />\n<img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602130-1215683201.webp\" /></p>\n<h4 id=\"gguf\">GGUF</h4>\n<blockquote>\n<p>HF文档：<a href=\"https://huggingface.co/docs/hub/en/gguf\" rel=\"noopener nofollow\" target=\"_blank\">https://huggingface.co/docs/hub/en/gguf</a><br />\n<a href=\"https://unsloth.ai/docs/basics/inference-and-deployment/saving-to-gguf\" rel=\"noopener nofollow\" target=\"_blank\">https://unsloth.ai/docs/basics/inference-and-deployment/saving-to-gguf</a></p>\n</blockquote>\n<p>GGUF格式是用于存储大型模型预训练结果的，相较于Hugging Face和torch的bin文件，它采用了紧凑的二进制编码格式、优化的数据结构以及内存映射等技术，提供了更高效的数据存储和访问方式。GGUF 本身支持多种量化级别（Q2_K ~ Q8_0、IQ2 ~ IQ4 等），这些量化方式属于后训练量化（PTQ），和 AWQ、GPTQ、bitsandbytes 4bit 一样，都是在预训练模型上直接执行量化（不需要重新训练）。不过需要区别的是AWQ、GPTQ、SVDQuant都需要一小批数据而bitsandbytes以及GGUF不需要，在GGUF中可以实现量化方式有两类：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\"><strong>传统Q系列</strong>（按照权重逐层量化）</th>\n<th style=\"text-align: center;\"><strong>K-Quant系列</strong>（通过 block-wise + scale 优化）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602722-1391696036.webp\" /></td>\n<td style=\"text-align: center;\"><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602534-100439133.webp\" /></td>\n</tr>\n</tbody>\n</table>\n<p>其中<strong>传统Q系列</strong>主要是一整块权重共享一个 scale（缩放因子），每个权重用低 bit 整数表示，容易受到极端值的影响。 <strong>K-Quant系列</strong>一个 block 内，再分“子块”，每个子块有自己的 scale，其中S代表子块少、scale少；M代表子块多、scale多。</p>\n<h2 id=\"总结\">总结</h2>\n<p>本文主要是介绍一些在SD模型中加快生图的策略，1、直接使用加速框架进行优化，比如说指定attention计算后端方式、通过<code>torch.compile</code>进行编译、使用<code>torch.channels_last</code>去优化内存访问方式等；2、cache策略，发现在生成过程中在某些层/时间布之间图像的特征比较相似，因此就可以考虑将这些计算结果进行缓存在后续n步中直接加载缓存好的特征来实现生成加速，主要介绍框架是<code>cache-dit</code>；3、量化技术概述，<br />\n最后简单对比一下生成加速时间</p>\n<blockquote>\n<p>测试prompt: <code>超写实亚洲中年男性，年龄约45-55岁。面容坚毅、憔悴，带有生活阅历的痕迹（如眼角的细纹）。他穿着质感柔软的深灰色高领毛衣，外搭一件经典的卡其色风衣，站在寒风中周围是高楼大厦</code><br />\n从测试结果上图像的差异还是不大，时间的话从5.97--&gt;5.48（<strong>不一定严谨！</strong>）还是有效的</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">正常生图</th>\n<th style=\"text-align: center;\">+使用channel+ flash_attn</th>\n<th style=\"text-align: center;\">+使用cachedit</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\"><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602310-1840320611.webp\" /></td>\n<td style=\"text-align: center;\"><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602417-1468973015.webp\" /></td>\n<td style=\"text-align: center;\"><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/3395559/202601/3395559-20260125231602717-1497084798.webp\" /></td>\n</tr>\n<tr>\n<td style=\"text-align: center;\"><code>5.97</code></td>\n<td style=\"text-align: center;\"><code>5.67</code></td>\n<td style=\"text-align: center;\"><code>5.48</code></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"参考\">参考</h2>\n<hr class=\"footnotes-sep\" />\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li class=\"footnote-item\" id=\"fn1\"><p><a href=\"https://github.com/chengzeyi/ParaAttention/blob/main/doc/fastest_flux.md\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/chengzeyi/ParaAttention/blob/main/doc/fastest_flux.md</a> <a class=\"footnote-backref\" href=\"#fnref1\" rel=\"noopener nofollow\">↩︎</a></p>\n</li>\n<li class=\"footnote-item\" id=\"fn2\"><p><a href=\"https://juejin.cn/post/7436976221068148786\" rel=\"noopener nofollow\" target=\"_blank\">https://juejin.cn/post/7436976221068148786</a> <a class=\"footnote-backref\" href=\"#fnref2\" rel=\"noopener nofollow\">↩︎</a></p>\n</li>\n</ol>\n</section>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-25 23:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Big-Yellow\">Big-Yellow-J</a>&nbsp;\n阅读(<span id=\"post_view_count\">22</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MCP 进化：让静态 Tool 进化为具备“上下文感知”的远程 Skills",
      "link": "https://www.cnblogs.com/noear/p/19530698",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/noear/p/19530698\" id=\"cb_post_title_url\" title=\"发布于 2026-01-25 22:47\">\n    <span>MCP 进化：让静态 Tool 进化为具备“上下文感知”的远程 Skills</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        摘要： Solon AI 通过将 Model Context Protocol (MCP) 封装为动态感知的 Skill，解决了传统静态工具交互的三大痛点：上下文噪音、权限真空和行为失控。Skill 通过智能准入（isSupported）、指令注入（getInstruction）和三态路由（getToolsName）实现动态分发，使模型仅感知当前场景所需的工具。实战示例展示了客户端与服务端的协作，支持多租户隔离和权限控制。该方案适用于复杂业务场景，但需注意其非标准化特性及适用边界。最终，Skill 架构提升\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在 AI Agent 的工程实践中，Model Context Protocol (MCP) 已成为连接大模型与外部世界的标准桥梁。然而，随着应用场景从“个人助手”向“企业级复杂业务”迈进，传统的 MCP 交互模式开始显露其 <strong>“静态化”</strong> 的瓶颈。</p>\n<p>Solon AI 支持将 MCP 封装为 Skill，实现了从“冷冰冰的 API 集合”到“具备感知能力的智能技能”的跨越。</p>\n<h3 id=\"一静态-tools-的三大痛点\">一、静态 Tools 的三大痛点</h3>\n<p>传统的 MCP 交互类似于一个“无法关闭的工具箱”，无论场景如何，所有工具一涌而上：</p>\n<ul>\n<li><strong>上下文噪音（Context Noise）：</strong> 即使是一个简单的问候，模型也会被注入成百上千行的工具 Schema 定义，白白浪费 Token，更干扰模型的推理专注度。</li>\n<li><strong>权限真空（Security Risks）：</strong> 模型对工具的可见性是“全量”的。难以根据当前登录用户的角色（如普通用户 vs 管理员）动态隐藏敏感操作（如：删除订单）。</li>\n<li><strong>行为失控（Instruction Gap）：</strong> 工具只提供了“能做什么”，却无法告诉模型“在当前背景下该怎么做”。模型缺乏针对特定业务场景的即时指令约束。</li>\n</ul>\n<h3 id=\"二核心解决方式感知挂载与动态分发\">二、核心解决方式：感知、挂载与动态分发</h3>\n<p>Solon AI 通过引入 Skill（Solon AI Skills） 生命周期 来包裹 MCP 协议，实现以下机制解决上述痛点：</p>\n<h4 id=\"a-智能准入-issupported\">A. 智能准入 (isSupported)：</h4>\n<p>只有当 Prompt 上下文（意图、租户信息、环境变量）满足条件时，技能才会被激活。</p>\n<h4 id=\"b-指令注入-getinstruction\">B. 指令注入 (getInstruction)：</h4>\n<p>在技能挂载时，自动为模型注入针对当前上下文的“行为准则”（System Message）。</p>\n<h4 id=\"c-三态路由-gettoolsname\">C. 三态路由 (getToolsName)：</h4>\n<p>服务端根据 Prompt 属性，动态决定给模型展示哪些工具。支持三种形态的路由方式：</p>\n<ul>\n<li>全量使用：未定义过滤逻辑时，显示所有业务工具。</li>\n<li>精准授权：仅展示当前用户权限范围内的工具。</li>\n<li>完全拒绝：即便技能激活，也可能因安全策略在此时封锁所有工具调用。</li>\n</ul>\n<h3 id=\"三实战示例\">三、实战示例</h3>\n<h4 id=\"1-客户端像本地技能一样调用\">1. 客户端：像本地技能一样调用</h4>\n<p>开发者只需关注业务属性的注入，无需操心工具的过滤逻辑，一切由 MCP Skill 代理与远程服务端约定与协商。</p>\n<pre><code class=\"language-java\">import org.noear.solon.ai.chat.ChatModel;\nimport org.noear.solon.ai.chat.prompt.Prompt;\nimport org.noear.solon.ai.mcp.McpChannel;\nimport org.noear.solon.ai.mcp.client.McpClientProvider;\nimport org.noear.solon.ai.mcp.client.McpSkillClient;\n\n//构建 mcp 客户端\nMcpClientProvider mcpClient = McpClientProvider.builder()\n                .channel(McpChannel.STREAMABLE)\n                .url(\"http://localhost:8081//skill/order\")\n                .build();\n\n// 构建带有业务属性的提示词\nPrompt prompt = Prompt.of(\"帮我取消订单 A001\")\n                .attrPut(\"tenant_id\", \"solon_001\")\n                .attrPut(\"user_role\", \"ADMIN\"); // 模拟管理员身份\n\n// 注入技能，模型将只看到“管理员”权限下的工具\nchatModel.prompt(prompt)\n         .options(o -&gt; o.skillAdd(new McpSkillClient(mcpClient))) //将 mcp 客户端 包装为 Solon AI Skills\n         .call();\n</code></pre>\n<h4 id=\"2-服务端实现具备感知力的技能\">2. 服务端：实现具备“感知力”的技能</h4>\n<p>服务端不再是盲目响应，而是通过解析 Prompt 决定自己的表现。</p>\n<pre><code class=\"language-java\">import org.noear.solon.ai.annotation.ToolMapping;\nimport org.noear.solon.ai.chat.prompt.Prompt;\nimport org.noear.solon.ai.mcp.McpChannel;\nimport org.noear.solon.ai.mcp.server.McpSkillServer;\nimport org.noear.solon.ai.mcp.server.annotation.McpServerEndpoint;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\n@McpServerEndpoint(channel = McpChannel.STREAMABLE_STATELESS, mcpEndpoint = \"/skill/order\")\npublic class OrderSkillServer extends McpSkillServer {\n    \n    @Override\n    public boolean isSupported(Prompt prompt) {\n        // 感知意图：只有涉及“订单”且租户合规时才激活\n        return prompt.getUserContent().contains(\"订单\") \n               &amp;&amp; prompt.attr(\"tenant_id\") != null;\n    }\n\n    @Override\n    public String getInstruction(Prompt prompt) {\n        // 动态指令：注入租户特定的业务规则\n        return \"你现在是租户[\" + prompt.attr(\"tenant_id\") + \"]的订单助手。\";\n    }\n\n    @Override\n    public List&lt;String&gt; getToolsName(Prompt prompt) {\n        // 权限隔离：根据用户角色动态下发工具名\n        List&lt;String&gt; tools = new ArrayList&lt;&gt;();\n        tools.add(\"OrderQuery\"); // 基础权限\n\n        if (\"ADMIN\".equals(prompt.attr(\"user_role\"))) {\n            tools.add(\"OrderCancel\"); // 仅管理员可见\n        }\n        return tools;\n    }\n\n    @ToolMapping(description = \"查询订单\")\n    public String OrderQuery(String id) { ... }\n\n    @ToolMapping(description = \"取消订单\")\n    public String OrderCancel(String id) { ... }\n}\n</code></pre>\n<h3 id=\"四skills-架构反思与局限性补充\">四、Skills 架构反思与局限性补充</h3>\n<p>尽管将 MCP 进化为 Skills 带来了显著的工程优势，但开发者仍需理清其技术边界：</p>\n<ul>\n<li>非标准化的架构增强：</li>\n</ul>\n<p>LLM 的底层标准仅包含 Prompt 和 Tool-Call。Skills 并非模型原生标准，也不属于 MCP 的公共协议规范，而是一种 架构设计模式（模式，是通用的）。它通常由 AI 开发框架（如 Solon AI）在消费侧实现，用于解决复杂业务下的能力调度问题。</p>\n<ul>\n<li>消费侧驱动的定制：</li>\n</ul>\n<p>MCP 向 Skills 的进化本质上是“业务驱动”或“领域驱动”的。在设计远程 MCP Skill 时，必须参考消费侧（即 Agent 执行引擎）的具体规范进行深度定制。</p>\n<ul>\n<li>适用场景的选择：</li>\n</ul>\n<p>Tool：适用于原子化、无状态、全量公开的简单功能插件。</p>\n<p>Skill：适用于需要上下文感知、多租户隔离、动态指令约束的复杂业务逻辑块。</p>\n<h3 id=\"五-好处总结\">五、 好处总结</h3>\n<p>将 MCP 进化为 Skills 之后，您的 AI Agent 架构将获得：</p>\n<ul>\n<li>极致的上下文纯净度：</li>\n</ul>\n<p>模型只看到此时此刻该看的工具（通过 getToolsName 实现按需加载，或权限控制）。</p>\n<ul>\n<li>天然的权限安全：</li>\n</ul>\n<p>通过服务端感知的动态分发，实现真正的跨进程角色权限控制（RBAC for Tools）。</p>\n<ul>\n<li>低耦合的业务演进：</li>\n</ul>\n<p>业务逻辑和规则变更集中在服务端，客户端 “无需” 任何代码改动即可获得最新能力。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-25 22:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/noear\">带刺的坐椅</a>&nbsp;\n阅读(<span id=\"post_view_count\">27</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "MySQL升级8.0.44后登录报错-系统表不支持'MyISAM'存储引擎",
      "link": "https://www.cnblogs.com/ldocser/p/19530406",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ldocser/p/19530406\" id=\"cb_post_title_url\" title=\"发布于 2026-01-25 20:10\">\n    <span>MySQL升级8.0.44后登录报错-系统表不支持'MyISAM'存储引擎</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"一故障现象\">一、故障现象</h1>\n<p>近期我们公司内部网络安全排查中，发现其中一个业务系统使用的是mysql8.0.11，存在几个高风险漏洞，经评估决定对其升级到最新版本MySQL8.0.44。升级后出现数据库无法远程登录，即使输入正确的密码也提示连接拒绝，报错如下图；<br />\n<img alt=\"MySQL远程登录报错\" class=\"lazyload\" /></p>\n<h1 id=\"二排查处理过程\">二、排查处理过程</h1>\n<h2 id=\"第一步尝试修改用户密码\">第一步：尝试修改用户密码</h2>\n<p>开始我以为是数据库用户的密码错误了，就想着使用root用户进去修改下用户密码。执行修改用户密码的sql，结果发现执行sql报错，提示系统表不支持MyISAM存储引擎，提示如下图：<br />\n<img alt=\"修改数据库用户密码报错\" class=\"lazyload\" /></p>\n<h2 id=\"第二步通过日志确认原因\">第二步：通过日志确认原因</h2>\n<p>通过查看 MySQL 数据库运行日志，发现数据库在启动时就已经发出警告，</p>\n<pre><code class=\"language-bash\">[Warning] [MY-010929] [Server] Storage engine 'MyISAM' does not support system tables. [mysql.user].\n[Warning] [MY-010929] [Server] Storage engine 'MyISAM' does not support system tables. [mysql.db].\n</code></pre>\n<p><img alt=\"系统表不支持'MyISAM'存储引擎\" class=\"lazyload\" /></p>\n<h2 id=\"第三步尝试使用mysql_upgrade手动升级数据结构\">第三步：尝试使用mysql_upgrade手动升级数据结构</h2>\n<p>使用 mysql_upgrade 命令使用手动升级方式，重新升级数据库表数据。提示已经不支持使用该方式手动升级数据库数据文件。借助翻译工具翻译后的内容可以看到：新版本的MySQL数据库在启动时会自动升级，但是也提供了 <code>--upgrade</code> 参数用于控制升级动作。可以尝试使用该方式强制升级mysql数据库。</p>\n<p><img alt=\"mysql_upgrade\" class=\"lazyload\" /></p>\n<blockquote>\n<p><strong>提示内容翻译</strong><br />\n<code>mysql_upgrade</code>&nbsp;客户端现已弃用。原先由该升级客户端执行的操作，现在均由服务器自身完成。<br />\n要执行升级，请使用新的 MySQL 二进制程序启动旧的数据目录。用户表的修复将自动进行，升级后无需重启。<br />\n当使用新版本的 MySQL 二进制程序启动旧数据目录时，升级过程会自动开始。为避免意外触发升级，请在启动 MySQL 二进制程序时使用&nbsp;<code>--upgrade=NONE</code>&nbsp;选项。此外，也提供了&nbsp;<code>--upgrade=FORCE</code>&nbsp;选项，用于按需强制执行服务器升级流程。<br />\n升级过程可能因多种原因而失败。若发生失败，MySQL 服务器在下次启动时将再次尝试执行升级序列。如果服务器反复升级失败，可使用&nbsp;<code>--upgrade=MINIMAL</code>&nbsp;选项启动服务器，以跳过升级流程，从而允许用户手动排查并修复问题。</p>\n</blockquote>\n<h2 id=\"第四步使用upgrade参数强制升级数据库\">第四步：使用upgrade参数强制升级数据库</h2>\n<p>根据刚才的提示，可以使用upgrade参数控制数据库的升级行为，查看upgrade参数如何使用，</p>\n<pre><code class=\"language-bash\">mysqld --verbose --help | grep -A 10 -B 10 -i \"upgrade\"\n</code></pre>\n<p><img alt=\"upgrade参数\" class=\"lazyload\" /></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">参数值</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">NONE</td>\n<td>如果自动升级服务器，则中止启动</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">MINIMAL</td>\n<td>启动服务器，但跳过非绝对必要的升级步骤</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">AUTO（默认）</td>\n<td>在需要时自动升级服务器</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">FORCE</td>\n<td>强制执行服务器升级</td>\n</tr>\n</tbody>\n</table>\n<p>根据提示内容，<code>FORCE</code> 可以强制服务器启动的时候执行升级操作。</p>\n<pre><code class=\"language-bash\"> mysqld --user=mysql --datadir=/..../mysql/ --upgrade=FORCE\n</code></pre>\n<p><img alt=\"使用upgrade参数强制升级数据库\" class=\"lazyload\" /></p>\n<p>查看MySQL的运行日志可以看出，在数据库启动过程中执行了升级操作，而且完成了升级，也没有出现之前 <code>Storage engine 'MyISAM' does not support system tables</code> 的字样。</p>\n<h2 id=\"第五步-正常启动数据库尝试登陆\">第五步： 正常启动数据库，尝试登陆</h2>\n<p>使用常规参数启动数据库服务，查看日志确认没有在出现类似告警，尝试使用mysql命令行工具登录数据库，经过尝试可以正常登录。</p>\n<pre><code class=\"language-bash\">systemctl restart  mysqld\nmysql -u'user' -p -h192.168.170.195\n</code></pre>\n<p><img alt=\"尝试使用mysql命令登陆数据库\" class=\"lazyload\" /></p>\n<p>开始逐个启动服务，逐步恢复业务系统。<br />\n到此为止完成本次故障处理。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-25 20:10</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ldocser\">小白爱运维</a>&nbsp;\n阅读(<span id=\"post_view_count\">61</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET周刊【12月】",
      "link": "https://www.cnblogs.com/InCerry/p/-/dotnet_week_25_12",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/InCerry/p/-/dotnet_week_25_12\" id=\"cb_post_title_url\" title=\"发布于 2026-01-25 19:40\">\n    <span>.NET周刊【12月】</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"公告\">公告</h2>\n<p>此前国内 .NET 周刊的更新节奏一直参考 .NET 国际周刊。但由于国际周刊更新频率不稳定，导致国内周刊发布也不固定，内容常常滞后于主线进展。</p>\n<p>因此，2026 年起将调整为新的更新模式：不再等待国际周刊同步。若国际周刊当周未更新，国内周刊将按计划正常发布；若国际周刊当周更新，其内容将整合至下一期国内周刊一并发布。</p>\n<p>本文为 2025 年周刊的收官篇。</p>\n<h2 id=\"国内文章\">国内文章</h2>\n<h3 id=\"avalonia-源码解读grid网格控件\">Avalonia 源码解读：Grid（网格控件）</h3>\n<p><a href=\"https://www.cnblogs.com/BettaFish/p/19354900/avalonia-grid\" target=\"_blank\">https://www.cnblogs.com/BettaFish/p/19354900/avalonia-grid</a></p>\n<p>Grid 是一种灵活且常用的布局控件，用于创建复杂的用户界面。本文以 Avalonia 框架为例，讲解 Grid 控件的工作原理和测量流程。Grid 通过行和列定义组织界面元素，计算过程中存在不同的大小定义方式。测量遵循优先确定大小原则，Grid 将元素分为几组测量。具体算法包括初始化行列定义和分组处理。文中详细描述了不同类型项的测量机制，适用于各种 XAML UI 框架。整体结构清晰，信息量大。</p>\n<h3 id=\"2025-年-webtransport-生态深度研究javascript-客户端与net-10-signalr-的演进与融合\">2025 年 WebTransport 生态深度研究：JavaScript 客户端与.NET 10 SignalR 的演进与融合</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19355053\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19355053</a></p>\n<p>本文讨论了 WebTransport 协议在实时网络通信中的应用，特别是在 JavaScript 客户端和 ASP.NET Core SignalR 中的支持。至 2025 年，该协议标志着 TCP 向 UDP 和 QUIC 的转型。报告指出，Chrome 和 Firefox 已全面支持 WebTransport，Apple 的 WebKit 则存在障碍。在服务端，ASP.NET Core SignalR 已实现生产就绪。本文分析了 HTTP/3 和 QUIC 的优势，包括流独立性、可靠数据报和连接迁移等特性，为企业级架构师和开发者提供了实现指导。</p>\n<h3 id=\"精选-8-个-net-开发实用的类库效率提升利器\">精选 8 个 .NET 开发实用的类库，效率提升利器！</h3>\n<p><a href=\"https://www.cnblogs.com/Can-daydayup/p/19375857\" target=\"_blank\">https://www.cnblogs.com/Can-daydayup/p/19375857</a></p>\n<p>这篇文章介绍了一些开源的 .NET 技术库，包括 Mapster、FlaUI、QuestPDF、BouncyCastle、IdGenerator、CsvHelper、Moq 和 xUnit。这些库各具特色，提供对象映射、自动化测试、PDF 生成、密码学功能、ID 生成、CSV 操作、模拟测试等功能。它们均为 MIT 许可，支持 .NET 生态，提高开发效率，减少重复代码和错误。文中提供了每个库的开源地址和详细介绍链接，方便开发者进一步学习。</p>\n<h3 id=\"opencvsharp了解几种特征检测\">OpenCVSharp：了解几种特征检测</h3>\n<p><a href=\"https://www.cnblogs.com/mingupupu/p/19352075\" target=\"_blank\">https://www.cnblogs.com/mingupupu/p/19352075</a></p>\n<p>文章介绍了 OpenCVSharp 库中多种特征检测算法，重点阐述了 FAST 算法与 FREAK 算法。FAST 算法以高效的特征点检测闻名，利用像素强度差异识别角点，特别适合实时应用。文章展示了 FAST 算法的实现代码，包括图像读取、处理与特征点绘制。FREAK 算法则模仿人类视网膜结构，快速提取二进制特征描述符，具有高效性的特点，适用于实时图像匹配。整体内容清晰，技术性强，适合对计算机视觉有兴趣的读者。</p>\n<h3 id=\"newtonsoftjson-与-systemtextjson-多态反序列化的安全性差异解析\">Newtonsoft.Json 与 System.Text.Json 多态反序列化的安全性差异解析</h3>\n<p><a href=\"https://www.cnblogs.com/MeteorSeed/p/19366736\" target=\"_blank\">https://www.cnblogs.com/MeteorSeed/p/19366736</a></p>\n<p>多态反序列化涉及继承结构对象序列化，是一项常见需求。不同 JSON 序列化库存在明显的安全风险。微软 CA2326 规则提示避免使用不安全的 JsonSerializerSettings。本文对比了 Newtonsoft.Json 和 System.Text.Json 的实现差异，重点分析了安全性问题。Newtonsoft.Json 允许 TypeNameHandling 反序列化，但易受到攻击，可能实例化敏感类型。相比之下，System.Text.Json 强调安全设计，默认不支持多态，需显式声明允许的类型，从根本上降低风险。通过代码示例，可以验证各自的安全性表现及潜在问题。</p>\n<h3 id=\"aspire-13从net-编排工具到真正的多语言云原生应用平台\">Aspire 13：从.NET 编排工具到真正的多语言云原生应用平台</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19360467\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19360467</a></p>\n<p>Aspire 13 的发布标志着微软云原生开发工具箱的重大转变，去掉了“.NET”前缀，转向多语言支持，包括 Python 和 JavaScript。本文深入分析了 Aspire 13 的架构变化，探讨了新引入的统一 AppHost 模型和 Aspire.Hosting.Python 包的深度集成。Aspire 13 提供了标准化的服务协作，消除了跨语言监控的壁垒，同时简化了本地开发到生产部署的流程。本文还评估了该版本对 .NET 10 SDK 的依赖及其全新生命周期管理工具的影响，这一切标志着微软致力于构建多语言融合的开发平台。</p>\n<h3 id=\"用-net-最小化-api-构建高性能-api\">用 .NET 最小化 API 构建高性能 API</h3>\n<p><a href=\"https://www.cnblogs.com/powertoolsteam/p/19360421\" target=\"_blank\">https://www.cnblogs.com/powertoolsteam/p/19360421</a></p>\n<p>本文探讨了使用.NET 最小化 API 构建高性能 API 的方法。最小化 API 简化了开发流程，减少了模板代码，提升了启动性能。它摒弃了传统控制器结构，允许在 Program.cs 文件中直接定义路由。最小化 API 具备显著降低代码复杂度、提升内存使用效率和提高请求处理速度等优点。其设计原则包括保持端点简洁、使用类型化结果、支持依赖注入及输入验证等。通过支持异步编程和高效的数据访问策略，最小化 API 在高负载下表现突出，适合高并发应用场景。</p>\n<h3 id=\"openai-code-interpreter-coworker-架构审计与安全取证分析\">OpenAI Code Interpreter (\"Coworker\") 架构审计与安全取证分析</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19350418\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19350418</a></p>\n<p>2025 年发生的 OpenAI Code Interpreter 泄露事件揭示了先进大语言模型执行环境的真实架构。初步假设其仅为 Python 环境，但实则是多语言混合系统，核心依赖于.NET 9（C#）构建的 XML 解析引擎。该环境运行在 Google 特征的 Chrome 容器中，并通过 @oai/walnut 包实现高效文档处理。泄露信息显示，C#在性能与安全性上优于 Python，架构采用‘Roundtrip’流程，确保数据结构完整性。这次事件表明，LLM 的能力受到规则限制，通过规范化的 Protobuf 格式与系统交互。</p>\n<h3 id=\"cvisionmaster-学习笔记目录-目录\">C#+VisionMaster 学习笔记(目录)-目录</h3>\n<p><a href=\"https://www.cnblogs.com/qq2806933146xiaobai/p/19354654\" target=\"_blank\">https://www.cnblogs.com/qq2806933146xiaobai/p/19354654</a></p>\n<p>这篇文章探讨了 C#与 VisionMaster 联合开发的多个方面，包括操作方案、模块、全局变量和设备控制等。目录不仅包括基础使用教程，还涉及控件的配置与控制。文章旨在补充相关知识，尤其对现有示例的不足之处进行改进，推动 AI 与图像处理的结合。作者希望提供全面的学习资料，并逐步更新基础教程以增强理解，适合对 C#与 VisionMaster 感兴趣的开发者和学习者。</p>\n<h3 id=\"译初探-visual-studio-2026-全新的用户体验\">【译】初探 Visual Studio 2026 全新的用户体验</h3>\n<p><a href=\"https://www.cnblogs.com/MeteorSeed/p/19307311\" target=\"_blank\">https://www.cnblogs.com/MeteorSeed/p/19307311</a></p>\n<p>Visual Studio 2026 通过注重清晰度、可访问性和简洁设计，提升了用户体验。更新包括排版、图标和布局改进，以减少干扰。新设置界面现代化，便于用户发现和调整。推出 11 款彩色主题，增强无障碍功能。编辑器外观设置允许用户自定义代码编辑环境，提供高对比度选项，满足可读性需求。用户可以与当前版本共存，轻松探索新功能并提供反馈，进一步改善体验。</p>\n<h3 id=\"你的代码正在腐烂为什么我们都不敢碰那座屎山\">你的代码正在腐烂：为什么我们都不敢碰那座“屎山”？</h3>\n<p><a href=\"https://www.cnblogs.com/huizhudev/p/19368567\" target=\"_blank\">https://www.cnblogs.com/huizhudev/p/19368567</a></p>\n<p>本文探讨了软件工程中的代码脆弱性现象，强调了重构时的恐惧感和维护难度。作者指出，代码腐烂是自然规律，必须主动重构。提出了利用 AI 模型提供重构建议，从而提升代码的安全性和可维护性。AI 可以识别代码异味并确保每次修改的安全性。文中强调了资深架构师的角色，以及重构的具体方法和任务要求，旨在引导开发者进行有效的代码重构。</p>\n<h3 id=\"net10-new-feature-新增功能介绍-jit-编译器改进\">.NET10 New feature 新增功能介绍-JIT 编译器改进</h3>\n<p><a href=\"https://www.cnblogs.com/tianqing/p/19378803\" target=\"_blank\">https://www.cnblogs.com/tianqing/p/19378803</a></p>\n<p>.NET 10 是最新的 LTS 版本，微软支持三年，提供了重要的新功能，特别是在 JIT 编译器方面。改进的 JIT 编译器使“好代码”能更高效地运行，无需编写特殊代码或使用 unsafe 选项。通过优化结构参数，JIT 能直接在寄存器中处理数据，减少内存访问。循环反转的优化提高了代码布局，增强了循环的识别。JIT 去虚拟化数组接口方法的能力，使遍历数组的代码执行更快，降低了抽象开销。这些改进为开发者提供了显著的性能提升。</p>\n<h3 id=\"opencvsharp学习人脸检测例子\">OpenCVSharp：学习人脸检测例子</h3>\n<p><a href=\"https://www.cnblogs.com/mingupupu/p/19363129\" target=\"_blank\">https://www.cnblogs.com/mingupupu/p/19363129</a></p>\n<p>本文介绍了 OpenCVSharp 中的人脸检测方法，包括级联分类器和 DNN 模型。详细讲解了 Haar 和 Lbp 级联分类器，说明了 haarcascade_frontalface_default.xml 文件的作用与使用方法。通过示例代码，展示了如何加载分类器及通过多尺度检测人脸，同时展示检测到的人脸。文章提供了必要的文件下载链接，支持读者进行实践。</p>\n<h3 id=\"maf-快速入门7工作流的状态共享\">MAF 快速入门（7）工作流的状态共享</h3>\n<p><a href=\"https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper07\" target=\"_blank\">https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper07</a></p>\n<p>本文介绍了使用 MAF 实现工作流状态共享的技巧，通过经典案例演示了如何在 AI 工作流中共享上下文数据。文章阐述了 WorkflowContext 模型的功能，以及如何通过 API 实现状态的读取与设置。作者展示了一个文档统计工作流的实践，包括读取文件和统计单词数及段落数的 Executor。文中提供了必要的准备工作和配置示例，强调了并发协作的基础。整体内容简洁明了，适合希望深入学习.NET 与 AI 结合的开发者。</p>\n<h3 id=\"opencvsharphog-行人检测\">OpenCVSharp：HOG 行人检测</h3>\n<p><a href=\"https://www.cnblogs.com/mingupupu/p/19365183\" target=\"_blank\">https://www.cnblogs.com/mingupupu/p/19365183</a></p>\n<p>HOG 行人检测是一种基于方向梯度直方图特征的计算机视觉目标检测技术。该算法将图像细分为小区域，计算并生成梯度方向直方图。相邻细胞单元组合后归一化，形成特征向量。特征向量通过 SVM 分类器判断图像区域是否包含行人，依赖多尺度扫描策略实现目标检测和定位。文章提供了完整的 C#代码示例，包括读取图像、创建 HOG 描述符及目标检测过程，适合实际应用。</p>\n<h3 id=\"net-通过-efcore-和仓储模式实现统一数据权限管控并且相关权限配置动态生成\">.Net 通过 EFCore 和仓储模式实现统一数据权限管控并且相关权限配置动态生成</h3>\n<p><a href=\"https://www.cnblogs.com/net-kevin-li/p/19368351\" target=\"_blank\">https://www.cnblogs.com/net-kevin-li/p/19368351</a></p>\n<p>本文介绍了在.NET 应用中使用 EFCore 和仓储模式实现数据权限管控的设计方案。文章定义了数据权限的四个层级，并通过具体的代码示例展示了基础仓储接口的设计和数据过滤的实现。作者提供了项目地址，便于读者参考和使用。整体结构清晰，逻辑性强，适合开发人员理解和应用。</p>\n<h3 id=\"aspire-与-azure-functions-深度集成架构范式工程实践与运维\">Aspire 与 Azure Functions 深度集成：架构范式、工程实践与运维</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19376604\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19376604</a></p>\n<p>本文探讨了 Azure Functions 与 Aspire 的结合，强调其在云原生架构中的重要性。分布式应用开发面临的复杂性与传统微服务架构的运维难题被详细描述。Aspire 通过提供标准化的服务编排和依赖管理，改善了开发者体验。它将 Azure Functions 转变为主要资源，并依赖隔离工作进程模型，以实现生命周期管理和功能编排。AppHost 作为基础设施表示，简化了本地环境配置，提升了开发效率。</p>\n<h3 id=\"maui-库推荐二mpowerkit\">MAUI 库推荐二：MPowerKit</h3>\n<p><a href=\"https://www.cnblogs.com/sesametech-dotnet/p/19376927\" target=\"_blank\">https://www.cnblogs.com/sesametech-dotnet/p/19376927</a></p>\n<p>MPowerKit 是.NET MAUI 的导航框架，支持多种导航方式，灵感来源于 Prism。该框架提供与 Prism 相同的导航原则，但实现方式不同，性能稍有提升。其核心库包括多个接口，如 IInitializeAware、IDestructible 等，允许开发者控制页面初始化和销毁时的行为。使用时，只需在项目中引用相应的 NuGet 包，并在 MauiProgram 中添加配置代码即可启动和注册相关服务。MPowerKit 还支持 MVVM 设计模式，简化了应用程序的构建。</p>\n<h3 id=\"acp让-ai-编程工具配置从此告别碎片化--一款开源的-ai-配置管理平台\">ACP：让 AI 编程工具配置从此告别碎片化 —— 一款开源的 AI 配置管理平台</h3>\n<p><a href=\"https://www.cnblogs.com/fanshaoO/p/19351155\" target=\"_blank\">https://www.cnblogs.com/fanshaoO/p/19351155</a></p>\n<p>ACP（AI-Config-Plaza）是一个开源平台，旨在简化 AI 编程工具的配置管理。它通过统一管理和社区共享，解决了开发者在使用多个 AI 工具时的重复配置问题。ACP 提供了一站式管理，包括多种类型的参数配置和解决方案的组合。其命令行工具支持本地同步，极大地降低切换成本。开发者可分享优质配置，促进资源互用。项目采用全栈架构，支持多语言，欢迎开发者参与。ACP 旨在提高开发效率，积极推动社区合作。</p>\n<h3 id=\"用-net-maui-10--vs-copilot-从-0-开发一个签到-app四和-copilot-一起创建签到历史页面\">用 .NET MAUI 10 + VS Copilot 从 0 开发一个签到 App（四）和 Copilot 一起创建「签到历史页面」</h3>\n<p><a href=\"https://www.cnblogs.com/densen2014/p/19379931\" target=\"_blank\">https://www.cnblogs.com/densen2014/p/19379931</a></p>\n<p>本文介绍如何使用 .NET MAUI 和 VS Copilot 从零开发签到 App 的签到历史页面。前文完成了基本的签到页面，本篇重点在于展示用户的签到记录。文章首先明确目标，即实现签到历史页面，并列出实现步骤。Copilot 生成了签到历史页面的 XAML 代码，设计简洁，使用了 CollectionView，展示签到时间信息。同时，页面逻辑由 Copilot 自动生成，展示了良好的工程实践。整体内容围绕真实业务需求展开，实用性强。</p>\n<h3 id=\"未来已来--写给-net-开发者的-2025-年度总结\">未来已来 | 写给 .NET 开发者的 2025 年度总结</h3>\n<p><a href=\"https://www.cnblogs.com/sheng-jie/p/19402252/goodbye-2025-welcome-2026\" target=\"_blank\">https://www.cnblogs.com/sheng-jie/p/19402252/goodbye-2025-welcome-2026</a></p>\n<p>本文为.NET 开发者总结了 2025 年的技术趋势，重点讨论了 AI 与.NET 的融合和发展。指出了 AI 模型的快速进步及其对开发者的影响，包括更强的代码生成和自动化能力。强调了 AI 从助手向代理的进化，具备规划、推理、工具调用和记忆等核心能力。同时回顾了.NET 生态的重要里程碑，如.NET 10 发布和 C#在 TIOBE 榜单上的上升，展望未来的挑战与机遇。</p>\n<h3 id=\"从-mcp-到-agent-skillsai-ready-的-net-10-正当时\">从 MCP 到 Agent Skills，AI Ready 的 .NET 10 正当时</h3>\n<p><a href=\"https://www.cnblogs.com/sheng-jie/p/19381647\" target=\"_blank\">https://www.cnblogs.com/sheng-jie/p/19381647</a></p>\n<p>本文介绍了如何使用 .NET File-Based Apps 编写高效的 Agent Skills 脚本。Agent Skills 是一种轻量级的格式，旨在扩展 AI Agent 的能力，支持包括 Python 和 JavaScript 在内的多种语言。文章讲解了 Agent Skills 的核心概念、应用场景及其目录结构，强调了 .NET 在脚本开发中的类型安全和性能优势。作者指出，Agent Skills 使专业知识封装、按需加载和可执行能力成为可能，能够优化工作流和跨工具互操作性。整体上，文章为开发者提供了实践指导。</p>\n<h3 id=\"问世间exe-是何物直教-ai-沉默web-寡言1\">问世间，exe 是何物？直教 AI 沉默、Web 寡言（1）</h3>\n<p><a href=\"https://www.cnblogs.com/sunhui/p/19391507\" target=\"_blank\">https://www.cnblogs.com/sunhui/p/19391507</a></p>\n<p>这篇文章以爱丽丝的视角探讨了 WinForms 应用开发的奇妙世界。作者利用隐喻表达了. exe 文件的内在复杂性与潜力，强调了现代技术对传统编程的影响。爱丽丝从对浏览器的惊叹，到对 AI 和编程的探索，展现了技术演变带来的可能。文章对编译后软件灵魂的思考呼应了数字时代的变革。整体叙述充满幻想与启发，引发读者对编程与软件生命的深度思索。</p>\n<h3 id=\"所有-64-位-winform-应用都是-chromium-浏览器\">所有 64 位 WinForm 应用都是 Chromium 浏览器</h3>\n<p><a href=\"https://www.cnblogs.com/sunhui/p/19395609\" target=\"_blank\">https://www.cnblogs.com/sunhui/p/19395609</a></p>\n<p>文章讨论了 64 位 WinForm/MFC/WPF 应用与现代浏览器之间的关系，强调这类桌面应用其实可以被视为浏览器。作者结合个人经历和与 AI 的对话，提出桌面应用应融入 Web 生态，以便充分利用 AI 和 Web 技术，从而提升应用价值。虽然技术上可能面临一些挑战，但最终用户的需求可能推动开发者接受这种转变。文章观点新颖，挑战传统认知，有助于引发对未来软件开发趋势的思考。</p>\n<h3 id=\"wpf-使用-rendertransform-实现高性能平滑滚动的-scrollviewer\">WPF 使用 RenderTransform 实现高性能平滑滚动的 ScrollViewer</h3>\n<p><a href=\"https://www.cnblogs.com/TwilightLemon/p/19383555\" target=\"_blank\">https://www.cnblogs.com/TwilightLemon/p/19383555</a></p>\n<p>本文探讨了 WPF 中实现平滑滚动的三种方案，重点介绍了第三版设计（v3），将视觉层与逻辑层分离。v3 方案通过使用 TranslateTransform 降低频繁布局计算，提升性能，同时以较低频率更新逻辑位置，保证滚动体验流畅。文中详细描述了视觉与逻辑层的处理方式，以及物理模型的设计思路，特别是动态速度因子与物理衰减模型的应用，使得滚动体验更接近真实物理效果。整体思路清晰，有助于开发者理解和实现高效的滚动功能。</p>\n<h3 id=\"hellogithub第-117-期\">《HelloGitHub》第 117 期</h3>\n<p><a href=\"https://www.cnblogs.com/xueweihan/p/19400116\" target=\"_blank\">https://www.cnblogs.com/xueweihan/p/19400116</a></p>\n<p>HelloGitHub 是一个分享开源项目的平台，鼓励用户探索开源的魅力。它提供多种编程语言的入门项目和实战教程，包括 C、C#、C++、Go 等。该平台每月更新内容，涵盖多款工具，如用于 Linux 的手势启动器 Hexecute，以及流行的 C# 工具 BetterLyrics 和 LiteMonitor。通过简单易用的界面，这些工具提升了用户的开发体验。HelloGitHub 适合新手和有经验的开发者，促进了开源文化的传播。</p>\n<h3 id=\"基于莱布尼茨公式的编程语言计算性能基准测试\">基于莱布尼茨公式的编程语言计算性能基准测试</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19408361\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19408361</a></p>\n<p>本文探讨了莱布尼茨公式计算圆周率的算法及其在性能基准测试中的应用。尽管收敛速度慢，莱布尼茨级数在浮点运算、循环逻辑和 ALU 压力测试中显示出不错的效用。文章分析了 62 种编程语言的性能，包括 C#和 C++，并探讨了 SIMD 技术和编译器优化在性能差异中的作用。C#在基准测试中表现优异，几乎与 C++ 平起平坐，挑战了托管语言性能的刻板印象。通过评估编译器的效率，文章揭示了现代语言在算法实现中的深度和复杂性。</p>\n<h3 id=\"net10-new-feature-新增功能介绍-类库新增功能\">.NET10 New feature 新增功能介绍-类库新增功能</h3>\n<p><a href=\"https://www.cnblogs.com/tianqing/p/19380073\" target=\"_blank\">https://www.cnblogs.com/tianqing/p/19380073</a></p>\n<p>本文介绍了.NET 10 类库的新增功能，包括 ISOWeek 对 DateOnly 类型的支持、数值字符串比较的新方法、单参数 TimeSpan.FromMilliseconds 重载、OrderedDictionary 的 TryAdd 和 TryGetValue 重载等。这些功能提高了代码的灵活性和可读性，方便了开发者在实际应用中的使用，反映了.NET 技术的持续演进和实用性。</p>\n<h3 id=\"ef-core将一个实体映射到多个表的正确方法\">【EF Core】将一个实体映射到多个表的正确方法</h3>\n<p><a href=\"https://www.cnblogs.com/tcjiaan/p/19394178\" target=\"_blank\">https://www.cnblogs.com/tcjiaan/p/19394178</a></p>\n<p>此文探讨实体拆分，即将一个实体映射到多个数据库表。通过举例说明，一个学生实体可以拆分为基础信息、补充信息和联系方式三个表，并强调这三个表行的对应关系。文章指出，设计中主键与外键可以设为同一列，确保数据一致性。最后，给出实体类的代码示例，计划将宠物映射到三个表，示范基本信息、特征和额外信息的拆分。这种处理方式提升了数据结构的清晰度与合理性。</p>\n<h3 id=\"通过-c-为-pdf-文档添加电子签名\">通过 C# 为 PDF 文档添加电子签名</h3>\n<p><a href=\"https://www.cnblogs.com/jazz-z/p/19396484\" target=\"_blank\">https://www.cnblogs.com/jazz-z/p/19396484</a></p>\n<p>电子签名在文档合规性中重要。基于 C# 的 Spire.PDF 库可以实现 PDF 电子签名，用户无需依赖第三方软件。文章详细阐述了库的使用方法，包括安装 .NET 库、核心依赖（.pfx 格式证书）和实现逻辑。介绍了加载 PDF 文档、解析证书、初始化签名器、执行签名以及保存文档的步骤。示例代码清晰易懂，适合需要电子签名的场景。文章内容具体、技术性强且具实用性。使用案例涵盖基础电子签名及可见签名等功能。</p>\n<h3 id=\"企业级多智能体系统mas架构深度研究c-与-python-生态系统的全面对比与战略评估\">企业级多智能体系统（MAS）架构深度研究：C# 与 Python 生态系统的全面对比与战略评估</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19380471\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19380471</a></p>\n<p>这篇文章探讨了 C#与 Python 在企业级多智能体系统中的适用性。随着生成式人工智能的发展，企业软件架构面临转变。作者分析了 C#和 Python 的核心框架及产品，指出尽管 Python 在 AI 开发中占主导，但在多智能体的工程化实现中，C#展现出更强的性能和安全性。C#的任务并行库和静态类型系统减少了重构风险，同时.NET 的 Native AOT 技术降低了冷启动延迟。文章建议，对于复杂的企业级系统，C#是更稳健的选择，而 Python 则适用于快速原型和特定数据科学任务。</p>\n<h3 id=\"一款轻量级-winform-开源控件库让老界面秒变高颜值\">一款轻量级 WinForm 开源控件库，让老界面秒变高颜值</h3>\n<p><a href=\"https://www.cnblogs.com/1312mn/p/19201142\" target=\"_blank\">https://www.cnblogs.com/1312mn/p/19201142</a></p>\n<p>本文介绍了一款基于 WinForm 的自绘控件库，旨在提升用户界面的视觉效果和交互体验。该库通过自定义绘制技术，实现了丰富、灵活的控件设计，具备高度可定制性和动画效果，包括按钮、面板和文本框等。PPFlodPanel 控件突出其动画特性，为用户提供流畅的展开与折叠体验。作者通过重写控件的 OnPaint 方法，运用 GDI+ 图形库进行绘制，同时引入定时器机制来控制动画效果。这种方法有效地改善了 WinForm 应用的视觉呈现，具有较高的实用价值和技术深度。</p>\n<h3 id=\"一个-net-开源免费功能强大的-ui-自动化库\">一个 .NET 开源免费、功能强大的 UI 自动化库</h3>\n<p><a href=\"https://www.cnblogs.com/Can-daydayup/p/19395009\" target=\"_blank\">https://www.cnblogs.com/Can-daydayup/p/19395009</a></p>\n<p>FlaUI 是一个开源的.NET UI 自动化库，专为 Windows 桌面应用的自动化测试设计。它基于 Microsoft 的 UI Automation 库构建，提供灵活的 API，便于开发者编写测试脚本。该库适用于功能测试、回归测试和 UI 验证等场景。文章包含创建项目的步骤以及具体代码示例，展示如何操作记事本。读者可以通过提供的 GitHub 链接获取项目源码，并关注相关优质项目和框架以提升开发效率。</p>\n<h3 id=\"net-数据摄取与向量化架构构建企业级检索增强生成rag管道\">.NET 数据摄取与向量化架构：构建企业级检索增强生成（RAG）管道</h3>\n<p><a href=\"https://www.cnblogs.com/shanyou/p/19408104\" target=\"_blank\">https://www.cnblogs.com/shanyou/p/19408104</a></p>\n<p>本文探讨了生成式人工智能在企业级应用开发中的应用，介绍了微软的 Microsoft.Extensions.DataIngestion 和 Microsoft.Extensions.VectorData 库。这些库标志着从实验性到标准化 AI 数据管道的转变。文章分析了如何通过统一文档表示解决非结构化数据处理的挑战，并探讨了数据摄取流程的标准化。模块化和解耦设计提高了灵活性，使开发者可以便捷地调整底层架构。此外，文中还阐述了选择 Markdown 作为中间格式的优势，增强了对大语言模型的兼容性。这些技术展现了现代 AI 应用的未来方向。</p>\n<h3 id=\"全栈开发实战wpfffmpeggis打造工业级雷达探测终端\">全栈开发实战：WPF+FFmpeg+GIS，打造工业级雷达探测终端</h3>\n<p><a href=\"https://www.cnblogs.com/yuanchenhui/p/19387990/radar-client\" target=\"_blank\">https://www.cnblogs.com/yuanchenhui/p/19387990/radar-client</a></p>\n<p>在工业软件的国产化和智能升级中，开发者需将技术转化为实用方案。本文介绍一款工业级雷达探测终端的开发过程，涵盖架构设计、编码和功能实现，融合 WPF、多协议通信、GIS 可视化等技术，确保高精度和易用性。系统采用模块化设计，保障稳定性并预留扩展空间。核心技术包括 GPU 加速可视化、高效数据处理和智能预警，能够精准监测、实时展示和报警满足个性化需求，实现多设备联动和历史数据回溯。整体设计注重用户体验，通过灵活的控制选项和直观的界面提升操作效率。</p>\n<h3 id=\"问世间exe-是何物直教-ai-沉默web-寡言4\">问世间，exe 是何物？直教 AI 沉默、Web 寡言（4）</h3>\n<p><a href=\"https://www.cnblogs.com/sunhui/p/19399320\" target=\"_blank\">https://www.cnblogs.com/sunhui/p/19399320</a></p>\n<p>这篇文章探讨了桌面应用程序的深层意义，认为编译后的 exe 文件并非简单工具，而是拥有自身生命的复杂系统。作者通过比喻和哲学思考，指出每个应用都是潜在的浏览器，强调开发者应意识到程序的无限可能性。文章在编程背后传达了关于选择和意图的重要理念，鼓励开发者拥抱新技术，发现隐藏在代码中的创新潜力。</p>\n<h3 id=\"译在-visual-studio-2026-中减少升级时间增加编码时间\">【译】在 Visual Studio 2026 中，减少升级时间，增加编码时间</h3>\n<p><a href=\"https://www.cnblogs.com/MeteorSeed/p/19403351\" target=\"_blank\">https://www.cnblogs.com/MeteorSeed/p/19403351</a></p>\n<p>Visual Studio 2026 提供更简便的安装体验，自动复制 Visual Studio 2022 的配置，节省配置时间。它支持多种工具集和 SDK，允许独立更新 IDE 而保持兼容性。设置助手可以快速重定向项目到最新版本，并轻松安装缺失的依赖项。内置的 GitHub Copilot 应用现代化功能，能帮助用户将项目迁移至 Azure。发布更新的速度加快，用户可通过“Update on Close”功能轻松保持最新版本。整体体验更加高效和便捷。</p>\n<h3 id=\"maf-快速入门8条件路由工作流\">MAF 快速入门（8）条件路由工作流</h3>\n<p><a href=\"https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper08\" target=\"_blank\">https://www.cnblogs.com/edisontalk/p/-/quick-start-on-maf-chatper08</a></p>\n<p>本文介绍了在 MAF 中如何实现条件路由，特别是在企业内部邮件检测的工作流中应用。条件路由可以根据邮件是否为垃圾邮件来决定后续处理步骤。使用 Conditional Edge 实现 if-else 决策，案例展示了如何通过 LLM 判断邮件，并将其转交给相应的节点。设置.NET 控制台应用程序，读取 LLM API 信息并定义数据模型。本文提供了实用的技术方案，适合开发者学习与应用。</p>\n<h3 id=\"cnetnet-core-技术前沿周刊--第-64-期2025-年-121-1221\">C#/.NET/.NET Core 技术前沿周刊 | 第 64 期（2025 年 12.1-12.21）</h3>\n<p><a href=\"https://www.cnblogs.com/Can-daydayup/p/19384367\" target=\"_blank\">https://www.cnblogs.com/Can-daydayup/p/19384367</a></p>\n<p>这篇文章介绍了 C#/.NET/.NET Core 技术的最新动态，包括实用类库、Visual Studio 2026 的下载和安装教程、UI 自动化库 FlaUI、多态反序列化的安全性分析、.NET 和.NET Framework 的服务更新、如何用.NET MAUI 构建 iOS 小部件以及.NET 10 的网络改进。这些内容提供了最新的技术指南和实用工具，帮助开发者提升编程效率和简化开发流程。</p>\n<h3 id=\"基于-blazor-实现的样品扫码比对管理系统\">基于 Blazor 实现的样品扫码比对管理系统</h3>\n<p><a href=\"https://www.cnblogs.com/known/p/19399622\" target=\"_blank\">https://www.cnblogs.com/known/p/19399622</a></p>\n<p>样品扫码比对管理系统集成 PDA 和 PC 端，采用 C#+Blazor 框架开发。PC 端可录入样品信息、统计比对记录，PDA 端支持扫码登录和比对操作。系统共用网址，使用 PWA 技术，数据库为 MySQL，并部署于阿里云 ECS，安全措施包括 HTTPS 和 RBAC 权限控制。功能模块涵盖样品信息管理、比对记录查询和系统设置。技术难点在于实现 PDA 按键扫码和避免弹出软键盘，依赖 JS 模拟键盘输入。系统实现了效率和安全性。</p>\n<h3 id=\"bi-报表及可视化分析类工具使用经验总结上\">BI 报表及可视化分析类工具使用经验总结（上）</h3>\n<p><a href=\"https://www.cnblogs.com/davablog/p/19205294\" target=\"_blank\">https://www.cnblogs.com/davablog/p/19205294</a></p>\n<p>这篇文章总结了作者作为数据工程师使用的各种 BI 报表和可视化工具，包括微软 SSRS、Oracle BIEE、帆软 FineReport、网易有数 BI 等。作者分享了每种工具的特点和适用场景，指出了它们的优缺点和功能。文章还探讨了工具的部署架构，包括 C/S 和 B/S 架构的区别及具体应用。通过多年的实践经验，作者提供了对数据工程师在工作中如何选择和使用这些工具的指导，强调了工具在分析和展示数据中的重要性。</p>\n<h3 id=\"rabbitmq-发布订阅模式多实例消费者防止重复消费实现方式\">RabbitMQ 发布订阅模式多实例消费者防止重复消费实现方式</h3>\n<p><a href=\"https://www.cnblogs.com/zhaorong/p/19392986\" target=\"_blank\">https://www.cnblogs.com/zhaorong/p/19392986</a></p>\n<p>本文讨论了 RabbitMQ 在 C#中的应用，介绍了如何通过实现发布订阅模式来防止消息重复消费。文章提供了详细的环境搭建步骤，包括 Docker 上部署 RabbitMQ 及添加相关包，重点在于配置和代码示例，以便读者能够快速上手。针对 RabbitMQ.Client 的依赖管理，文中指出了版本更新后的异步处理变化，确保读者可顺利使用最新特性。整体内容通过实例引导读者实现基本功能，具有实用性和指导性。</p>\n<h3 id=\"maui-库推荐三syncfusionmauitoolkit\">MAUI 库推荐三：Syncfusion.Maui.Toolkit</h3>\n<p><a href=\"https://www.cnblogs.com/sesametech-dotnet/p/19401006\" target=\"_blank\">https://www.cnblogs.com/sesametech-dotnet/p/19401006</a></p>\n<p>Syncfusion Toolkit for .NET MAUI 是一个高质量的用户界面控件工具包，支持开发跨平台的高性能应用程序。它帮助开发者在短时间内创建美观且功能丰富的应用。该工具包支持多种控件，包括数据可视化、日历、编辑控件、导航和按钮等，适用于 iOS、Android、macOS 和 Windows。通过 NuGet 轻松安装，并且有详细的文档支持。项目地址为 <a href=\"https://github.com/syncfusion/maui-toolkit\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/syncfusion/maui-toolkit</a>，采用 MIT 授权，方便开发者使用。</p>\n<h3 id=\"译azure-mcp-服务器现已内置到-visual-studio-2026-中智能体工作流的新时代\">【译】Azure MCP 服务器现已内置到 Visual Studio 2026 中：智能体工作流的新时代</h3>\n<p><a href=\"https://www.cnblogs.com/MeteorSeed/p/19381988\" target=\"_blank\">https://www.cnblogs.com/MeteorSeed/p/19381988</a></p>\n<p>Azure MCP 服务器工具已在 Visual Studio 2026 中集成，使云资源管理更高效。开发人员可以利用自然语言生成代码，查询管理 Azure 资源。此工具简化了开发流程，减少上下文切换，提高了工作效率。Visual Studio 2026 提供了自动化 CI/CD 设置和 Azure CLI 命令生成等功能，进一步增强开发体验。通过此技术，开发者能够专注于构建创新、安全的应用程序，提升工作效果。</p>\n<h3 id=\"opencvsharp使用霍夫变换检测直线\">OpenCVSharp：使用霍夫变换检测直线</h3>\n<p><a href=\"https://www.cnblogs.com/mingupupu/p/19390228\" target=\"_blank\">https://www.cnblogs.com/mingupupu/p/19390228</a></p>\n<p>霍夫变换是一种计算机视觉技术，用于图像中几何形状的检测。它将图像点映射到参数空间，以识别直线等形状。该技术在图像噪声和部分遮挡中表现出鲁棒性，广泛应用于道路检测和文档分析。实践中，使用 Canny 边缘检测进行预处理，随后运行标准和概率霍夫变换，以提取和绘制检测到的线条。此过程提供了关于性能的耗时记录，确保了实用性和效率。</p>\n<h3 id=\"重试死信与补偿策略失败处置流水线的设计防雪崩的节流思路\">重试、死信与补偿策略——失败处置流水线的设计，防雪崩的节流思路</h3>\n<p><a href=\"https://www.cnblogs.com/shiyuelp/p/19401138\" target=\"_blank\">https://www.cnblogs.com/shiyuelp/p/19401138</a></p>\n<p>本文讨论如何在分布式系统中构建弹性消息系统，重点关注失败处理机制。通过精心设计的重试策略，文章强调了指数退避算法的重要性，以避免瞬时故障造成的资源浪费。内容涉及同步和异步重试的适用场景，以及基于异常类型的差异化重试策略，旨在确保系统在异常情况下的稳定性和可靠性。</p>\n<h3 id=\"aspnet-core-依赖注入的三种服务生命周期\">ASP.NET Core 依赖注入的三种服务生命周期</h3>\n<p><a href=\"https://www.cnblogs.com/Can-daydayup/p/19401414\" target=\"_blank\">https://www.cnblogs.com/Can-daydayup/p/19401414</a></p>\n<p>依赖注入是实现控制反转的设计模式，用于构建松耦合应用。ASP.NET Core 内置强大的 DI 容器，支持瞬态、作用域和单例三种服务生命周期。瞬态服务在每次请求时创建新实例，适用于轻量级无状态服务。作用域服务在同一 HTTP 请求内共享实例，适合需要状态共享的场景，如数据库上下文。单例服务在应用生命周期内共享一个实例，适用于无状态的全局服务。文章详细解析了这三种生命周期的特点与适用场景，帮助开发者合理选择。参考资料来自官方文档。</p>\n<h3 id=\"net-如何优雅的实现发送邮件服务\">Net 如何优雅的实现发送邮件服务</h3>\n<p><a href=\"https://www.cnblogs.com/net-kevin-li/p/19403699\" target=\"_blank\">https://www.cnblogs.com/net-kevin-li/p/19403699</a></p>\n<p>本文介绍了如何使用.NET 中的 SmtpClient 类发送邮件，并提及了相关的企业级 SaaS 智能应用架构。作者强调前后端分离的设计，描述了所采用的技术如 Vue3 和 SignalR 等，且提供了项目的 GitHub 和 Gitee 地址。具体实现部分展示了 EmailService 类的代码，涵盖了邮件服务的初始化、配置 SMTP 客户端及发送邮件的基本方法，这些内容具有良好的技术深度和实用性。</p>\n<h3 id=\"分库分表数据源-shardingspheredatasource-的-connection-元数据误用问题分析\">分库分表数据源 ShardingSphereDataSource 的 Connection 元数据误用问题分析</h3>\n<p><a href=\"https://www.cnblogs.com/wuyuegb2312/p/19405814\" target=\"_blank\">https://www.cnblogs.com/wuyuegb2312/p/19405814</a></p>\n<p>本文讨论了使用 ShardingSphere 进行分库分表的应用及遇到的问题。作者分享了在直接操作数据库元数据时的一个具体案例，强调了逻辑库名与物理库名的区别。提供了代码示例，展示了如何查询以特定前缀命名的表，并对其进行结构变更。文章同样指出了代码中存在的潜在错误，确保对两种库名的正确使用至关重要。总结了调试过程中的经验教训，旨在帮助开发者更高效地处理类似问题。</p>\n<h2 id=\"今日人物\">今日人物</h2>\n<p><strong>埃德加·弗兰克·科德</strong>（英语：Edgar Frank Codd， 1923 年 8 月 23 日—2003 年 4 月 18 日），小名泰德·科德（Ted Codd），生于<a href=\"https://zh.wikipedia.org/wiki/%E8%8B%B1%E5%9B%BD\" rel=\"noopener nofollow\" target=\"_blank\">英国</a><a href=\"https://zh.wikipedia.org/wiki/%E8%8B%B1%E6%A0%BC%E5%85%B0\" rel=\"noopener nofollow\" target=\"_blank\">英格兰</a><a href=\"https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%A1%9E%E7%89%B9%E9%83%A1\" rel=\"noopener nofollow\" target=\"_blank\">多塞特郡</a>的<a href=\"https://zh.wikipedia.org/w/index.php?title=%E6%B3%A2%E7%89%B9%E5%85%B0_(%E5%A4%9A%E5%A1%9E%E7%89%B9%E9%83%A1)&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">波特兰</a>，<a href=\"https://zh.wikipedia.org/wiki/%E7%94%B5%E5%AD%90%E8%AE%A1%E7%AE%97%E6%9C%BA\" rel=\"noopener nofollow\" target=\"_blank\">计算机</a><a href=\"https://zh.wikipedia.org/wiki/%E7%A7%91%E5%AD%A6%E5%AE%B6\" rel=\"noopener nofollow\" target=\"_blank\">科学家</a>。他为<a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93\" rel=\"noopener nofollow\" target=\"_blank\">关系型数据库</a><a href=\"https://zh.wikipedia.org/wiki/%E7%90%86%E8%AE%BA\" rel=\"noopener nofollow\" target=\"_blank\">理论</a>做出了奠基性的贡献。他在<a href=\"https://zh.wikipedia.org/wiki/IBM\" rel=\"noopener nofollow\" target=\"_blank\">IBM</a>工作期间，首创了<a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%9E%8B\" rel=\"noopener nofollow\" target=\"_blank\">关系模型</a>理论。他一生中为<a href=\"https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6\" rel=\"noopener nofollow\" target=\"_blank\">计算机科学</a>做出了很多有价值的贡献，而<a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%9E%8B\" rel=\"noopener nofollow\" target=\"_blank\">关系模型</a>，作为一个在<a href=\"https://zh.wikipedia.org/w/index.php?title=%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">数据库管理</a>方面非常具有影响力的<a href=\"https://zh.wikipedia.org/w/index.php?title=%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">基础理论</a>，仍然被认为是他最引人瞩目的成就。</p>\n<p>埃德加·弗兰克·科德生于英格兰的<a href=\"https://zh.wikipedia.org/wiki/%E6%B3%A2%E7%89%B9%E5%85%B0%E5%B2%9B_(%E8%8B%B1%E5%9B%BD)\" rel=\"noopener nofollow\" target=\"_blank\">波特兰岛</a>。在<a href=\"https://zh.wikipedia.org/wiki/%E7%89%9B%E6%B4%A5%E5%A4%A7%E5%AD%A6%E5%9F%83%E5%85%8B%E5%A1%9E%E7%89%B9%E5%AD%A6%E9%99%A2\" rel=\"noopener nofollow\" target=\"_blank\">牛津大学埃克塞特学院</a>主修<a href=\"https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%A6\" rel=\"noopener nofollow\" target=\"_blank\">数学</a>与<a href=\"https://zh.wikipedia.org/wiki/%E5%8C%96%E5%AD%A6\" rel=\"noopener nofollow\" target=\"_blank\">化学</a>，<a href=\"https://zh.wikipedia.org/wiki/%E7%AC%AC%E4%BA%8C%E6%AC%A1%E4%B8%96%E7%95%8C%E5%A4%A7%E6%88%98\" rel=\"noopener nofollow\" target=\"_blank\">第二次世界大战</a>期间，成为<a href=\"https://zh.wikipedia.org/wiki/%E8%8B%B1%E5%9C%8B%E7%9A%87%E5%AE%B6%E7%A9%BA%E8%BB%8D\" rel=\"noopener nofollow\" target=\"_blank\">英国皇家空军</a>的<a href=\"https://zh.wikipedia.org/wiki/%E9%A3%9E%E8%A1%8C%E5%91%98\" rel=\"noopener nofollow\" target=\"_blank\">飞行员</a>参战。</p>\n<p>1948 年，他来到<a href=\"https://zh.wikipedia.org/wiki/%E7%BA%BD%E7%BA%A6\" rel=\"noopener nofollow\" target=\"_blank\">纽约</a>，加入了<a href=\"https://zh.wikipedia.org/wiki/IBM\" rel=\"noopener nofollow\" target=\"_blank\">IBM</a>公司，成为一名<a href=\"https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%A6\" rel=\"noopener nofollow\" target=\"_blank\">数学</a><a href=\"https://zh.wikipedia.org/wiki/%E7%A8%8B%E5%BA%8F%E5%91%98\" rel=\"noopener nofollow\" target=\"_blank\">程序员</a>。</p>\n<p>1953 年，出于对<a href=\"https://zh.wikipedia.org/wiki/%E5%8F%83%E8%AD%B0%E5%93%A1\" rel=\"noopener nofollow\" target=\"_blank\">参议员</a><a href=\"https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%91%9F%E5%A4%AB%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1\" rel=\"noopener nofollow\" target=\"_blank\">约瑟夫·麦卡锡</a>的不满，他迁往<a href=\"https://zh.wikipedia.org/wiki/%E5%8A%A0%E6%8B%BF%E5%A4%A7\" rel=\"noopener nofollow\" target=\"_blank\">加拿大</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B8%A5%E5%A4%AA%E5%8D%8E\" rel=\"noopener nofollow\" target=\"_blank\">渥太华</a>，居住了十年。</p>\n<p>之后他回到<a href=\"https://zh.wikipedia.org/wiki/%E5%AF%86%E6%AD%87%E6%A0%B9%E5%A4%A7%E5%AD%A6\" rel=\"noopener nofollow\" target=\"_blank\">密歇根大学</a>并取得了<a href=\"https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6\" rel=\"noopener nofollow\" target=\"_blank\">计算机科学</a><a href=\"https://zh.wikipedia.org/wiki/%E5%8D%9A%E5%A3%AB\" rel=\"noopener nofollow\" target=\"_blank\">博士</a>学位。两年后，科德去往<a href=\"https://zh.wikipedia.org/wiki/IBM\" rel=\"noopener nofollow\" target=\"_blank\">IBM</a>公司位于<a href=\"https://zh.wikipedia.org/wiki/%E8%81%96%E8%8D%B7%E8%A5%BF_(%E5%8A%A0%E5%88%A9%E7%A6%8F%E5%B0%BC%E4%BA%9E%E5%B7%9E)\" rel=\"noopener nofollow\" target=\"_blank\">圣何塞</a>的<a href=\"https://zh.wikipedia.org/w/index.php?title=%E9%98%BF%E5%B0%94%E9%A9%AC%E7%99%BB%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">阿尔马登研究中心</a>工作。</p>\n<p>1968 年，针对“<a href=\"https://zh.wikipedia.org/wiki/%E7%B4%B0%E8%83%9E%E8%87%AA%E5%8B%95%E6%A9%9F\" rel=\"noopener nofollow\" target=\"_blank\">细胞自动机</a>”提出自己的“<a href=\"https://zh.wikipedia.org/w/index.php?title=%E7%A7%91%E5%BE%B7%E7%B4%B0%E8%83%9E%E8%87%AA%E5%8B%95%E6%A9%9F&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">科德细胞自动机</a>”（以<a href=\"https://zh.wikipedia.org/wiki/%E7%8E%8B%E6%B5%A9_(%E6%95%B0%E5%AD%A6%E5%AE%B6)\" rel=\"noopener nofollow\" target=\"_blank\">王浩</a>的“<a href=\"https://zh.wikipedia.org/w/index.php?title=Wang_B-machine&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">Wang B-machine</a>”为基础）论点，以探讨“<a href=\"https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%94%9F%E5%91%BD\" rel=\"noopener nofollow\" target=\"_blank\">人工生命</a>”议题。</p>\n<p>1981 年，科德因在<a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93\" rel=\"noopener nofollow\" target=\"_blank\">关系型数据库</a>方面的贡献获得了<a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E5%A5%96\" rel=\"noopener nofollow\" target=\"_blank\">图灵奖</a>。</p>\n<p>2003 年 4 月 18 日，科德因<a href=\"https://zh.wikipedia.org/wiki/%E5%BF%83%E8%84%8F%E7%97%85\" rel=\"noopener nofollow\" target=\"_blank\">心脏病</a>在<a href=\"https://zh.wikipedia.org/wiki/%E4%BD%9B%E7%BD%97%E9%87%8C%E8%BE%BE\" rel=\"noopener nofollow\" target=\"_blank\">佛罗里达</a><a href=\"https://zh.wikipedia.org/w/index.php?title=%E5%A8%81%E5%BB%89%E5%A7%86%E6%96%AF%E5%B2%9B&amp;action=edit&amp;redlink=1\" rel=\"noopener nofollow\" target=\"_blank\">威廉姆斯岛</a>的家中去世，享年 79 岁。<img alt=\"img-1\" src=\"https://img2024.cnblogs.com/blog/997046/202601/997046-20260125193726518-2140612999.jpg\" /></p>\n<h2 id=\"c-net-交流群\">C# .NET 交流群</h2>\n<p>相信大家在开发中经常会遇到一些性能问题，苦于没有有效的工具去发现性能瓶颈，或者是发现瓶颈以后不知道该如何优化。之前一直有读者朋友询问有没有技术交流群，但是由于各种原因一直都没创建，现在很高兴的在这里宣布，我创建了一个专门交流.NET 性能优化经验的群组，主题包括但不限于：</p>\n<ul>\n<li>如何找到.NET 性能瓶颈，如使用 APM、dotnet tools 等工具</li>\n<li>.NET 框架底层原理的实现，如垃圾回收器、JIT 等等</li>\n<li>如何编写高性能的.NET 代码，哪些地方存在性能陷阱</li>\n</ul>\n<p>希望能有更多志同道合朋友加入，分享一些工作中遇到的.NET 问题和宝贵的分析优化经验。<strong>目前一群已满，现在开放二群。</strong>可以加我 vx，我拉你进群: <strong>ls1075</strong> 另外也创建了 <strong>QQ Group</strong>: 687779078，欢迎大家加入。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-25 19:40</span>&nbsp;\n<a href=\"https://www.cnblogs.com/InCerry\">InCerry</a>&nbsp;\n阅读(<span id=\"post_view_count\">150</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【EF Core】实体状态与变更追踪",
      "link": "https://www.cnblogs.com/tcjiaan/p/19528796",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tcjiaan/p/19528796\" id=\"cb_post_title_url\" title=\"发布于 2026-01-25 18:41\">\n    <span>【EF Core】实体状态与变更追踪</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>好长时间没有水文章了，请容老周解释一下。因为最近老周进了两个厂，第一个厂子呆了八天左右，第二个厂子还在调试。管理很严格，带的电子设备都要登记、办手续。当初觉得雷神笔记本的屏幕大，在车间调试代码方便，所以登记了这个型号。但这个游戏本功耗大，而且充电只能充到 83% 就充不进去了。只能白天在车间调试时用，其他时间玩手机。手机是那个 23800 mAH 的坦克3，所以电量多得是，充一次随便玩。在厂里很无聊，老周还另带了一台某宝买的开源掌机……扯远了。</p>\n<p>第二个厂子的项目很诡异，老周甚至怀疑有人故意捣乱。他们工人自己测试的时候，总是报莫名其妙的错；但是，只要老周过去和他们一起测，就一切正常。反正现在是测不出到底啥问题。从日志中记录的异常看，都是 Modbus TCP 连接超时。把 time out 改为 50 分钟，也照样在无限连接中。老周觉得是人为拨了网线的可能性更大。反正只要老周在现场就没问题，所以耗了近一个月也没结果。所以老周就请了四天假玩玩，不管他们同不同意，四天后老周准时回去报到。</p>\n<p>--------------------------------------------------------------------------------------------------------------------------------------------------------------------</p>\n<p>记得上一篇水文中，老周说了把一个实体映射到多个表的话题。注意，一实体一数据表的原则是不变的，这种特殊情况可以用在你这几个表可以组成一个整体，并且经常一起使用的，这样你在查询时就不用联合了，一般是一对一关系的。</p>\n<p>熟悉老周的人都知道，老周分享的都是纯知识和纯技术的东西。至于实际开发中怎么用，那是你的事。实际应用是没办法写教程的，你得看具体情况，灵活运用，不存在一个教程包万能的道理。做项目我从小周做成了老周，虽然没做过什么大项目，但小 Case 是不少的（吹吹牛皮）。你别小看那些杂七杂八的项目，哪个不是要六边形战士，哪个不是软硬结合，哪个不是既485又CAN又PLC又单片机的。别看它小，WinForms、Web、STM32（珠海极海的 APM32 也遇到过）、串口、Esp8266 全用上都是常见的事。这年头，不学点 C 语言连小项目都搞不起，哪像那些互联网巨头那么爽，天天盯着 HTML + CSS 玩。</p>\n<p>老周一直觉得，经验其实不重要的，跟一两周的项目你都有经验了，关键还得是基础扎实、技术过硬，这样才能来什么活接什么活。至于说基础问题，干活的家伙，实战更重要，理论的东西其实知道是啥就好，咱们又不用写论文评职称。你理论知识说得一套一套的，真用的时候不会用，那有啥用？不要排斥实用主义，实用主义其实是正确的，技术学了就是拿来用的，不用就没意义了。学习是分两种的：一种是内修——比如琴棋书画，这是文化底蕴，个人气质。这种你不必学了就要用（但也可以用），更重要的是养心养神，自我调整；另一种就是工作干活用的，叫技能，属于外修。从小老师都教我们要内外兼修。</p>\n<p>好了，不扯了。在开始今天的主题前，咱们补一个内容：既然实体能分布到多个表中，那反过来呢？能把多个实体映射到一个表中吗？当然可以了，官方称作“表拆分”。同样的道理，一般也是一对一的关系。</p>\n<p>光说不练，惨过失恋。咱们直接用实例来说明。假设下面有两个实体。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Person\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> PsID { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span> Name { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span>; } = <span style=\"color: rgba(0, 0, 255, 1);\">null</span>!<span style=\"color: rgba(0, 0, 0, 1);\">;\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> Age {  <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 导航属性</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">public</span> PersonInfo OtherInfo { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span>; } = <span style=\"color: rgba(0, 0, 255, 1);\">null</span>!<span style=\"color: rgba(0, 0, 0, 1);\">;\n}\n\n</span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> PersonInfo\n{\n    </span><strong><span style=\"background-color: rgba(255, 255, 0, 1);\"><span style=\"color: rgba(0, 0, 255, 1);\">private</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> InfoID {  <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span>; }</span></strong>        <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 既做主键也做外键</span>\n    <span style=\"color: rgba(128, 128, 128, 1);\">///</span> <span style=\"color: rgba(128, 128, 128, 1);\">&lt;summary&gt;</span>\n    <span style=\"color: rgba(128, 128, 128, 1);\">///</span><span style=\"color: rgba(0, 128, 0, 1);\"> 体重\n    </span><span style=\"color: rgba(128, 128, 128, 1);\">///</span> <span style=\"color: rgba(128, 128, 128, 1);\">&lt;/summary&gt;</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">float</span> Weight { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(128, 128, 128, 1);\">///</span> <span style=\"color: rgba(128, 128, 128, 1);\">&lt;summary&gt;</span>\n    <span style=\"color: rgba(128, 128, 128, 1);\">///</span><span style=\"color: rgba(0, 128, 0, 1);\"> 身高\n    </span><span style=\"color: rgba(128, 128, 128, 1);\">///</span> <span style=\"color: rgba(128, 128, 128, 1);\">&lt;/summary&gt;</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">float</span> Height {  <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(128, 128, 128, 1);\">///</span> <span style=\"color: rgba(128, 128, 128, 1);\">&lt;summary&gt;</span>\n    <span style=\"color: rgba(128, 128, 128, 1);\">///</span><span style=\"color: rgba(0, 128, 0, 1);\"> 民族\n    </span><span style=\"color: rgba(128, 128, 128, 1);\">///</span> <span style=\"color: rgba(128, 128, 128, 1);\">&lt;/summary&gt;</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span>? Ethnicity {  <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n}</span></pre>\n</div>\n<p>待会儿咱们要做的是把这两个实体映射到一个表中，所以为了安全，你可以让 PersonInfo 实体的&nbsp;InfoID 属性变成私有成员，这可以防止三只手的人意外修改主键值。因为这个实体的 ID 值必须始终与 Person 的 ID 一致。</p>\n<p>下面代码是数据库上下文类。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> DemoDbContext : DbContext\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> DbSet&lt;Person&gt; People { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> DbSet&lt;PersonInfo&gt; PersonInfos { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">protected</span> <span style=\"color: rgba(0, 0, 255, 1);\">override</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> OnConfiguring(DbContextOptionsBuilder optionsBuilder)\n    {\n        optionsBuilder.UseSqlite(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">data source=恭喜发财.db</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n                                .LogTo(\n                                    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 输出日志的委托</span>\n                                    action: msg =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> Console.WriteLine(msg),\n                                    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 过滤器，只显示即将执行的命令日志，可以看到SQL语句</span>\n                                    filter: (eventId, _) =&gt; eventId.Id ==<span style=\"color: rgba(0, 0, 0, 1);\"> RelationalEventId.CommandExecuting\n                                );\n    }\n\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">protected</span> <span style=\"color: rgba(0, 0, 255, 1);\">override</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> OnModelCreating(ModelBuilder modelBuilder)\n    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 配置实体</span>\n        modelBuilder.Entity&lt;Person&gt;(pse =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n        {\n            pse.<strong><span style=\"background-color: rgba(255, 255, 0, 1);\">Property(e </span></strong></span><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">=&gt; e.PsID).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_id</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span></span></strong><span style=\"color: rgba(0, 0, 0, 1);\"><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">)</span></strong>;\n            pse.Property(b </span>=&gt; b.Name).HasMaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">16</span>).IsRequired().HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_name</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            pse.Property(d </span>=&gt; d.Age).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_age</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 主键</span>\n            pse.HasKey(w =&gt; w.PsID).<strong><span style=\"background-color: rgba(255, 255, 0, 1);\">HasName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">PK_Person</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span></span></strong><span style=\"color: rgba(0, 0, 0, 1);\"><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">)</span></strong>;\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 表名</span>\n            pse.<strong><span style=\"background-color: rgba(255, 255, 0, 1);\">ToTable(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">tb_people</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span></span></strong><span style=\"color: rgba(0, 0, 0, 1);\"><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">)</span></strong>;\n        });\n        modelBuilder.Entity</span>&lt;PersonInfo&gt;(pie =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n        {\n            pie.<strong><span style=\"background-color: rgba(255, 255, 0, 1);\">Property(</span></strong></span><strong><span style=\"background-color: rgba(255, 255, 0, 1);\"><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">InfoID</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_id</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span></span></strong><span style=\"color: rgba(0, 0, 0, 1);\"><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">).ValueGeneratedNever()</span></strong>;\n            pie.Property(r </span>=&gt; r.Height).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">info_height</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            pie.Property(i </span>=&gt; i.Weight).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">info_weight</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            pie.Property(k </span>=&gt; k.Ethnicity).HasMaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">10</span>).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">info_ethnic</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 主键</span>\n            pie.HasKey(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">InfoID</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).<strong><span style=\"background-color: rgba(255, 255, 0, 1);\">HasName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">PK_Person</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span></span></strong><span style=\"color: rgba(0, 0, 0, 1);\"><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">)</span></strong>;\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 同一个表名</span>\n            pie.<strong><span style=\"background-color: rgba(255, 255, 0, 1);\">ToTable(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">tb_people</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span></span></strong><span style=\"color: rgba(0, 0, 0, 1);\"><strong><span style=\"background-color: rgba(255, 255, 0, 1);\">)</span></strong>;\n        });\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 两实体的关系</span>\n        modelBuilder.Entity&lt;Person&gt;().HasOne(n =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> n.OtherInfo)\n                                                          .WithOne()\n                                                          </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> info --&gt; person</span>\n                                                          .HasForeignKey&lt;PersonInfo&gt;(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">InfoID</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).HasConstraintName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">FK_PersonInfo</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n                                                          </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> person --&gt; info</span>\n                                                          .HasPrincipalKey&lt;Person&gt;(p =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> p.PsID);\n    }\n}</span></pre>\n</div>\n<p>基本代码相信各位能看懂的。和配置一般实体区别不大，但要注意几点：</p>\n<p>1、两个实体所映射的表名要相同。这是F话了，都说映射到同一个表了，表名能不一样的？</p>\n<p>2、两个实体中作为主键的属性名可以不同，但类型要相同（可以减少翻车事故）；更重要的是：<span style=\"text-decoration: underline; font-size: 16px;\"><span style=\"color: rgba(255, 0, 0, 1); text-decoration: underline;\"><strong>一定要映射到同一个列名</strong></span></span>。因为映射后，两个实体作为主键的属性会合并；再者，<span style=\"text-decoration: underline;\"><span style=\"color: rgba(255, 0, 0, 1);\"><strong><span style=\"font-size: 16px;\">主键的约束名称也要相同</span></strong></span></span>，不解释了，一样的道理。</p>\n<div class=\"cnblogs_code\">\n<pre>modelBuilder.Entity&lt;Person&gt;(pse =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    pse.Property(e </span>=&gt; e.PsID).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">person_id</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    ……\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 主键</span>\n    pse.HasKey(w =&gt; w.PsID).HasName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">PK_Person</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 表名</span>\n    pse.ToTable(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">tb_people</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n});\nmodelBuilder.Entity</span>&lt;PersonInfo&gt;(pie =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    pie.Property(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">InfoID</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).HasColumnName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">person_id</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">).ValueGeneratedNever();\n    ……\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 主键</span>\n    pie.HasKey(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">InfoID</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>).HasName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">PK_Person</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 同一个表名</span>\n    pie.ToTable(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">tb_people</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n});</span></pre>\n</div>\n<p>对于第二个实体，ValueGeneratedNever 方法可以不调用，EF 会自动感知到不需要自动生成列值。</p>\n<p>3、两个实体配置为一对一关系，这个和常规实体操作一样。</p>\n<p>然后在 Main 方法中测试一下。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span> Main(<span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">[] args)\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">using</span> <span style=\"color: rgba(0, 0, 255, 1);\">var</span> context = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> DemoDbContext();\n    context.Database.EnsureDeleted();\n    context.Database.EnsureCreated();\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 打印数据库模型</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    Console.WriteLine(context.Model.ToDebugString());\n}</span></pre>\n</div>\n<p>运行结果：</p>\n<div class=\"cnblogs_code\">\n<pre>      Executing DbCommand [Parameters=[], CommandType=<span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">Text</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>, CommandTimeout=<span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">30</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">]\n      CREATE TABLE </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">tb_people</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> (\n          </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_id</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> INTEGER NOT NULL CONSTRAINT <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">PK_Person</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> PRIMARY KEY AUTOINCREMENT,\n          </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_name</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> TEXT NOT NULL,\n          </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">person_age</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> INTEGER NOT NULL,\n          </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">info_weight</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> REAL NOT NULL,\n          </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">info_height</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> REAL NOT NULL,\n          </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">info_ethnic</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> TEXT NULL\n      );\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 以下是数据库模型</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">Model:\n  EntityType: Person\n    Properties:\n      PsID (</span><span style=\"color: rgba(0, 0, 255, 1);\">int</span><span style=\"color: rgba(0, 0, 0, 1);\">) Required PK AfterSave:Throw ValueGenerated.OnAdd\n      Age (</span><span style=\"color: rgba(0, 0, 255, 1);\">int</span><span style=\"color: rgba(0, 0, 0, 1);\">) Required\n      Name (</span><span style=\"color: rgba(0, 0, 255, 1);\">string</span>) Required MaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">16</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n    Navigations:\n      OtherInfo (PersonInfo) Required ToDependent PersonInfo\n    Keys:\n      PsID PK\n  EntityType: PersonInfo\n    Properties:\n      InfoID (</span><span style=\"color: rgba(0, 0, 255, 1);\">int</span><span style=\"color: rgba(0, 0, 0, 1);\">) Required PK FK AfterSave:Throw\n      Ethnicity (</span><span style=\"color: rgba(0, 0, 255, 1);\">string</span>) MaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">10</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n      Height (</span><span style=\"color: rgba(0, 0, 255, 1);\">float</span><span style=\"color: rgba(0, 0, 0, 1);\">) Required\n      Weight (</span><span style=\"color: rgba(0, 0, 255, 1);\">float</span><span style=\"color: rgba(0, 0, 0, 1);\">) Required\n    Keys:\n      InfoID PK\n    Foreign keys:\n      PersonInfo {</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">InfoID</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>} -&gt; Person {<span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">PsID</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>} Unique Required RequiredDependent Cascade ToDependent: OtherInfo</pre>\n</div>\n<p>--------------------------------------------------------------------------------------------------------------------------------------</p>\n<p>下面正片开始。今天咱们说说 EF Core 中几大主要功能模块之一——追踪（叫跟踪也行）。正常情况下，EF Core 从实体被查询出来的时候开始跟踪。跟踪前会为实体的各个属性/字段的值创建一个快照（就备份一下，不是拷贝对象，而是用一个字典来存放）。然后在特定条件下，会触发比较，即比较实体引用当前各属性的值与当初快照中的值，从而确定实体的状态。</p>\n<p>为了方便访问，DbContext 类会公开&nbsp;ChangeTracker 属性，通过它你能访问到由 EF Core 创建的&nbsp;ChangeTracker 实例（在Microsoft.EntityFrameworkCore.ChangeTracking 命名空间）。该类包含与实体追踪有关的信息。调用&nbsp;DetectChanges 方法会触发实体的追踪扫描，方法只负责触发状态检查，不返回任何结果，调用后实体的状态自动更新。实体的状态由&nbsp;EntityState 枚举表示。</p>\n<p>1、Unchanged：实体从数据库中查询出来后就是这个状态，前提是这个实体是从数据库中查出来的，也就是说它已经在数据库中了。</p>\n<p>2、Added：当你用 DbContext.Add 或 DbSet.Add 方法添加新实体后，实体就处在这个状态。实体只存在 EF Core 中，还没保存到数据库。提交时生成 INSERT 语句。</p>\n<p>3、Modified：已修改。实体自从数据库中查询出来到目前为止，它的某些属性或全部属性被修改过。提交时生成 UPDATE 语句。</p>\n<p>4、Deleted：已删除。实体已从 DbSet 中删除（还在数据库中）就是这个状态，提交后生成 DELETE 语句。</p>\n<p>5、Detached：失踪人口，EF Core 未追踪其状态。</p>\n<p>EF Core 内部有个名为&nbsp;IStateManager 的服务接口，默认实现类是&nbsp;StateManager。该类可以修改实体的状态，也可以控制开始/停止追踪实体的状态。咱们在写代码时不需要直接访问它，DbContext 以及 DbContext.ChangeTracker、DbSet 已经封装了相关访问入口。</p>\n<p>对 DbSet 对象来说，你调用 Add、Remove、Update 等方法只是更改了实体的状态，并没有真正更新到数据库，除非你调用 SaveChanges 方法。SaveChanges 方法内部会先调用&nbsp;DetectChanges 方法触发状态变更扫描，然后再根据实体的最新状态生成相应的 SQL 语句，再发送到数据库中执行。</p>\n<p>下面以插入新实体为例，演示一下。本示例在插入新实体前、后，以及提交到数据库后都打印一次实体的状态。</p>\n<p>先定义实体类。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Pet\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> Id { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span> Name { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span>; } = <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">.Empty;\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span>? Description { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span>? Category {  <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n}</span></pre>\n</div>\n<p>正规流程，写数据库上下文类。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> TestDbContext : DbContext\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">protected</span> <span style=\"color: rgba(0, 0, 255, 1);\">override</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> OnConfiguring(DbContextOptionsBuilder optionsBuilder)\n    {\n        optionsBuilder.UseSqlite(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">data source=天宫赐福.db</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    }\n\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">protected</span> <span style=\"color: rgba(0, 0, 255, 1);\">override</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span><span style=\"color: rgba(0, 0, 0, 1);\"> OnModelCreating(ModelBuilder modelBuilder)\n    {\n        modelBuilder.Entity</span>&lt;Pet&gt;(et =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n        {\n            et.ToTable(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">tb_pets</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            et.Property(g </span>=&gt; g.Name).HasMaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">20</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            et.Property(k </span>=&gt; k.Description).HasMaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">200</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            et.Property(q </span>=&gt; q.Category).HasMaxLength(<span style=\"color: rgba(128, 0, 128, 1);\">15</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            et.HasKey(m </span>=&gt; m.Id).HasName(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">PK_PetID</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n        });\n    }\n}</span></pre>\n</div>\n<p>好，现在进入测试环节。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span> Main(<span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">[] args)\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">using</span> <span style=\"color: rgba(0, 0, 255, 1);\">var</span> context = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> TestDbContext();\n    context.Database.EnsureCreated();\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 添加一个实体</span>\n    Pet p = <span style=\"color: rgba(0, 0, 255, 1);\">new</span>() { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Jack</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Description = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">不会游泳的巴西龟</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Category = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">爬行动物</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> };\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 打印一下状态</span>\n    Console.WriteLine(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">----------- 添加前 -------------</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    Console.WriteLine(context.ChangeTracker.DebugView.LongView);\n    context.Add(p);\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 再打印一下状态</span>\n    Console.WriteLine(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">\\n---------- 添加后 ------------</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    Console.WriteLine(context.ChangeTracker.DebugView.LongView);\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 提交</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    context.SaveChanges();\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 再打印状态</span>\n    Console.WriteLine(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">\\n---------- 提交后 ------------</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    Console.WriteLine(context.ChangeTracker.DebugView.LongView);\n}</span></pre>\n</div>\n<p>和 Model 类似，ChangeTracker 对象也有个 DebugView，用于获取调试用的信息。这个能打印出实体以及它的各个属性的状态。</p>\n<p>运行一遍，结果如下：</p>\n<div class=\"cnblogs_code\">\n<pre>----------- 添加前 -------------\n\n\n---------- 添加后 ------------<span style=\"color: rgba(0, 0, 0, 1);\">\nPet {Id: </span>-<span style=\"color: rgba(128, 0, 128, 1);\">2147482647</span><span style=\"color: rgba(0, 0, 0, 1);\">} Added\n    Id: </span>-<span style=\"color: rgba(128, 0, 128, 1);\">2147482647</span><span style=\"color: rgba(0, 0, 0, 1);\"> PK Temporary\n    Category: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">爬行动物</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Description: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">不会游泳的巴西龟</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Name: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">Jack</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>\n\n\n---------- 提交后 ------------<span style=\"color: rgba(0, 0, 0, 1);\">\nPet {Id: </span><span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\">} Unchanged\n    Id: </span><span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\"> PK\n    Category: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">爬行动物</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Description: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">不会游泳的巴西龟</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Name: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">Jack</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span></pre>\n</div>\n<p>新实体被 Add 之前，它是没有被追踪的，所以打印状态信息空白。调用 Add 方法后，它的状态就变成 Added 了。此时，你不需要调用&nbsp;DetectChanges 方法，因为 Add 方法本身就会修改实体的状态。新实体还未存入数据库，所以主键 ID 赋了个负值，且是临时的。当调用 SaveChanges 方法后，提交数据库保存，并取回数据库生成的ID值，故此时 ID 的值是 1。而且，实体的状态被改回 Unchanged。这是合理的，现在新的实体已经在数据库了，而且自从插入后没有修改过，状态应当是 Unchaged。</p>\n<p>如果你有其他想法，希望在 SaveChanges 之后实体的状态不变回 Unchaged，可以这样调用 SaveChanges 方法。</p>\n<div class=\"cnblogs_code\">\n<pre>context.SaveChanges(acceptAllChangesOnSuccess: <span style=\"color: rgba(0, 0, 255, 1);\">false</span>);</pre>\n</div>\n<p>acceptAllChangesOnSuccess 参数设置为 false 后，数据库执行成功后不会改变实体的当前状态。于是，数据库中插入新记录后，实体状态还是 Added。</p>\n<div class=\"cnblogs_code\">\n<pre>---------- 添加后 ------------<span style=\"color: rgba(0, 0, 0, 1);\">\nPet {Id: </span>-<span style=\"color: rgba(128, 0, 128, 1);\">2147482647</span><span style=\"color: rgba(0, 0, 0, 1);\">} Added\n    Id: </span>-<span style=\"color: rgba(128, 0, 128, 1);\">2147482647</span><span style=\"color: rgba(0, 0, 0, 1);\"> PK Temporary\n    Category: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">爬行动物</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Description: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">不会游泳的巴西龟</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Name: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">Jack</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>\n\n\n---------- 提交后 ------------<span style=\"color: rgba(0, 0, 0, 1);\">\nPet {Id: </span><span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\">} <strong><span style=\"background-color: rgba(255, 255, 0, 1);\">Added</span></strong>\n    Id: </span><span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\"> PK\n    Category: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">爬行动物</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Description: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">不会游泳的巴西龟</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(0, 0, 0, 1);\">\n    Name: </span><span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">Jack</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span></pre>\n</div>\n<p>这样做可能会导致逻辑错误，除非你有特殊用途，比如这样用。</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span> <span style=\"color: rgba(0, 0, 255, 1);\">var</span> context = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> TestDbContext();\ncontext.Database.EnsureDeleted();\ncontext.Database.EnsureCreated();\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 处理事件</span>\ncontext.ChangeTracker.Tracked += (_, e) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> backupcolor =<span style=\"color: rgba(0, 0, 0, 1);\"> Console.ForegroundColor;\n    Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> ConsoleColor.Green;\n    Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">实体被追踪：\\n{e.Entry.DebugView.LongView}\\n</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> backupcolor;\n};\ncontext.ChangeTracker.StateChanged </span>+= (_, e) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> bkColor =<span style=\"color: rgba(0, 0, 0, 1);\"> Console.ForegroundColor;\n    Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> ConsoleColor.Blue;\n    Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">实体（ID={e.Entry.Property(nameof(Pet.Id)).CurrentValue}）状态改变：{e.OldState} --&gt; {e.NewState}\\n</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> bkColor;\n};\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 新实体</span>\nPet p = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> Pet { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Tom</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Description = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">会游泳的鸟</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Category = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">猛禽</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> };\ncontext.Add(p);\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 保存，但状态不改变</span>\n<span style=\"background-color: rgba(255, 255, 0, 1);\">context.SaveChanges(<span style=\"color: rgba(0, 0, 255, 1);\">false</span></span><span style=\"color: rgba(0, 0, 0, 1);\"><span style=\"background-color: rgba(255, 255, 0, 1);\">)</span>;\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 因为是 Added 状态，所以还可以继续insert</span>\np.Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Simum</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">;\np.Description </span>= <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">三手青蛙</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">;\np.Category </span>= <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">两栖动物</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 保存，状态改变</span>\n<span style=\"color: rgba(0, 0, 0, 1); background-color: rgba(255, 255, 0, 1);\">context.SaveChanges();\n\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 把它们查询出来看看</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> <span style=\"color: rgba(0, 0, 255, 1);\">set</span> = context.Set&lt;Pet&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\nConsole.WriteLine(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">\\n数据库中的记录：</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n</span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span>(<span style=\"color: rgba(0, 0, 255, 1);\">var</span> pp <span style=\"color: rgba(0, 0, 255, 1);\">in</span> <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n{\n    Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">{pp.Id}  {pp.Name}  {pp.Description}  {pp.Category}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n}</span></pre>\n</div>\n<p>上面代码中，侦听了两个事件：Tracked——当 EF Core 开始跟踪某个实体时发生；当有实体的状态改变之后发生。其实还有一个&nbsp;StateChanging 事件，是在实体状态即将改变时发生。总结来说就是：状态改变之前发生&nbsp;StateChanging 事件，改变之后发生&nbsp;StateChanged 事件。要注意，StateChanged 和&nbsp;StateChanging 事件在 EF Core 首次追踪实体时不会引发。比如，刚开始追踪时状态为 Unchanged，不会引发事件，而之后状态变为 Added，就会引发事件（最开始那个状态不会触发事件）。</p>\n<p>上面代码处理 Tracked 事件，当开始追踪某实体时，打印一下调试信息，记录某状态；处理 StateChanged 事件，在开始追踪状态后，状态发生改变之后打印变化前后的状态。</p>\n<p>代码运行结果如下：</p>\n<p><img alt=\"image\" height=\"266\" src=\"https://img2024.cnblogs.com/blog/367389/202601/367389-20260125181401722-693660532.png\" width=\"288\" /></p>\n<p>首先，new 了一个 Pet 对象，赋值，再调用 Add 方法添加到数据集合中，此时状态会被改为 Added。Tracked 事件输出第一块绿色字体，表示实体开始追踪的状态为 Added，ID 值是随机分配的负值，并说明是临时主键值。</p>\n<p>然后调用 SaveChanges 方法并传递 false 给acceptAllChangesOnSuccess&nbsp;参数，表明 INSERT 进数据库后，状态不改变，还是 Added。</p>\n<p>然后，还是用那个实体实例，改变一下属性值，由于它的状态依旧是 Added，调用&nbsp;SaveChanges() 方法时未传参数，它会调用&nbsp;SaveChanges(acceptAllChangesOnSuccess: true)，结果是这次实体的状态变成了 Unchanged。就是输出结果中蓝色字体那一行。此时实体的 ID=2，记住这个值，待会儿用到。</p>\n<p>再往后，咱们 foreach 语句给 DbSet 会触发 EF Core 去查询数据库，于是，我们看到，控制台在“数据库中的记录：”一行之后又发生了 Tracked 事件，有一个 ID=1 的实体被追踪了，它刚从数据库中查询出来，就是第二块绿色字体那里。</p>\n<p>这时候你是不是迷乎了？不是从数据库查出两条记录吗，为什么只有 ID=1 的被追踪了，ID=2 呢？其实，ID = 2 已经被追踪了。忘了吗？它前面不是从 Added 状态变为 Unchanged 状态吗。这是因为咱们这一连串操作都在同一个 DbContext 实例的生命周期进行的，EF Core 对实体的追踪不会断开。</p>\n<p>如果你把上面的代码改成这样，那就明白了。</p>\n<div class=\"cnblogs_code\">\n<pre>    <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span> Main(<span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">[] args)\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">using</span> (<span style=\"color: rgba(0, 0, 255, 1);\">var</span> context = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> TestDbContext())\n        {\n            context.Database.EnsureDeleted();\n            context.Database.EnsureCreated();\n\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 处理事件</span>\n            <span style=\"background-color: rgba(255, 255, 0, 1);\">context.ChangeTracker.Tracked +=</span><span style=\"color: rgba(0, 0, 0, 1);\"><span style=\"background-color: rgba(255, 255, 0, 1);\"> OnTracked;</span>\n            <span style=\"background-color: rgba(255, 255, 0, 1);\">context.ChangeTracker.StateChanged </span></span><span style=\"background-color: rgba(255, 255, 0, 1);\">+=<span style=\"color: rgba(0, 0, 0, 1);\"> OnStateChanged;\n\n</span></span>            <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 新实体</span>\n            Pet p = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> Pet { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Tom</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Description = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">会游泳的鸟</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Category = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">猛禽</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> };\n            context.Add(p);\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 保存，但状态不改变</span>\n            context.SaveChanges(<span style=\"color: rgba(0, 0, 255, 1);\">false</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 因为是 Added 状态，所以还可以继续insert</span>\n            p.Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Simum</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n            p.Description </span>= <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">三手青蛙</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n            p.Category </span>= <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">两栖动物</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">;\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 保存，状态改变</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">            context.SaveChanges();\n        }\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 把它们查询出来看看</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">using</span>(<span style=\"color: rgba(0, 0, 255, 1);\">var</span> context2 = <span style=\"color: rgba(0, 0, 255, 1);\">new</span><span style=\"color: rgba(0, 0, 0, 1);\"> TestDbContext())\n        {\n            </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 依旧要处理事件</span>\n            <span style=\"background-color: rgba(255, 255, 0, 1);\">context2.ChangeTracker.Tracked +=</span><span style=\"color: rgba(0, 0, 0, 1);\"><span style=\"background-color: rgba(255, 255, 0, 1);\"> OnTracked;</span>\n            <span style=\"background-color: rgba(255, 255, 0, 1);\">context2.ChangeTracker.StateChanged </span></span><span style=\"background-color: rgba(255, 255, 0, 1);\">+=<span style=\"color: rgba(0, 0, 0, 1);\"> OnStateChanged;\n\n</span></span>            <span style=\"color: rgba(0, 0, 255, 1);\">var</span> <span style=\"color: rgba(0, 0, 255, 1);\">set</span> = context2.Set&lt;Pet&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n            Console.WriteLine(</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">\\n数据库中的记录：</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            </span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (<span style=\"color: rgba(0, 0, 255, 1);\">var</span> pp <span style=\"color: rgba(0, 0, 255, 1);\">in</span> <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">)\n            {\n                Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">{pp.Id}  {pp.Name}  {pp.Description}  {pp.Category}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n            }\n        }\n    }\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 下面两个方法处理事件</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span> OnTracked(<span style=\"color: rgba(0, 0, 255, 1);\">object</span>?<span style=\"color: rgba(0, 0, 0, 1);\"> _,  EntityTrackedEventArgs e)\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> backupcolor =<span style=\"color: rgba(0, 0, 0, 1);\"> Console.ForegroundColor;\n        Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> ConsoleColor.Green;\n        Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">实体被追踪：\\n{e.Entry.DebugView.LongView}\\n</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n        Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> backupcolor;\n    }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">void</span> OnStateChanged(<span style=\"color: rgba(0, 0, 255, 1);\">object</span>?<span style=\"color: rgba(0, 0, 0, 1);\"> _,  EntityStateChangedEventArgs e)\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> bkColor =<span style=\"color: rgba(0, 0, 0, 1);\"> Console.ForegroundColor;\n        Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> ConsoleColor.Blue;\n        Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">实体（ID={e.Entry.Property(nameof(Pet.Id)).CurrentValue}）状态改变：{e.OldState} --&gt; {e.NewState}\\n</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n        Console.ForegroundColor </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> bkColor;\n    }</span></pre>\n</div>\n<p>现在再次运行，看看结果是不是符合你当初的期望。</p>\n<p><img alt=\"image\" height=\"378\" src=\"https://img2024.cnblogs.com/blog/367389/202601/367389-20260125183707220-446191187.png\" width=\"373\" /></p>\n<p>现在的情况是：向数据库插入记录是第一个 DbContext 实例，完事后就释放了，实体追踪器自然就挂了；随后创建了第二个 DbContext 实例，这时候从数据库中查询出两条记录都是没有被追踪的，所以要启动追踪，自然就能引发两次 Tracked 事件了。</p>\n<p>好了，各位，今天咱们就粗浅地聊到这里。后面老周还会继续讨论实体追踪的话题，本文主要是让大伙伴们了解一下实体的状态变化。</p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-25 18:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tcjiaan\">东邪独孤</a>&nbsp;\n阅读(<span id=\"post_view_count\">44</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}