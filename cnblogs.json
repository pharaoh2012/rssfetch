{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "2025年终总结——在奔跑中前行",
      "link": "https://www.cnblogs.com/lucky_hu/p/19430418",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lucky_hu/p/19430418\" id=\"cb_post_title_url\" title=\"发布于 2026-01-01 17:27\">\n    <span>2025年终总结——在奔跑中前行</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h3 id=\"导航\">导航</h3>\n<ul>\n<li>前言</li>\n<li>职场人的核心竞争力是什么</li>\n<li>拥抱AI，拥抱大模型</li>\n<li>尝试自媒体</li>\n<li>读毛选</li>\n<li>写过的文章</li>\n<li>结语</li>\n<li>参考</li>\n</ul>\n<br />\n<section>\n    <a href=\"https://img.zhikestreet.com/2026-01-01_165557_428.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" rel=\"noopener nofollow\"><img alt=\"\" src=\"https://img.zhikestreet.com/2026-01-01_165557_428.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n<h3 id=\"前言\">前言</h3>\n<blockquote>\n<p>不是先学好了再干，而是干起来再学习，干就是学习。——《毛选》</p>\n</blockquote>\n<p>2025年，对于笔者而言，是极不平凡的一年。</p>\n<p>这一年，有快乐、有焦虑、有遗憾、有成长。</p>\n<p><strong>忙碌了一整年，回顾了这一年的经历，笔者对主要工作做了梳理和总结，同时要有一些自己的感悟,或许能与您产生共鸣。</strong></p>\n<h3 id=\"职场人的核心竞争力是什么\">职场人的核心竞争力是什么</h3>\n<blockquote>\n<p>对大部分企业而言，增长才是的核心竞争力,技术不是。</p>\n</blockquote>\n<p>在很多年的技术职业生涯中，笔者曾坚定地认为把产品做好，技术方案做好，兢兢业业，持续迭代，就一定能赢得公司的认可。(请参考<a href=\"https://www.52interview.com/solutions/31\" rel=\"noopener nofollow\" target=\"_blank\">《技术更迭，一往无前》</a>)</p>\n<p>然而,随着工作年限的增长,发现很多企业并不这么认为。他们更看重的是业绩的增长,技术只是实现增长的手段之一。</p>\n<p><strong>结论：让业绩增长才是职场人的核心竞争力。</strong></p>\n<h3 id=\"拥抱ai拥抱大模型\">拥抱AI，拥抱大模型</h3>\n<blockquote>\n<p>一定不能让自己被AI列车甩下，无论是玩还是工作，一定要经常使用它们。</p>\n</blockquote>\n<p>2025年的年初，deepseek-r1的强势发布，让AI大模型在业界引起了轩然大波，各个行业开始纷纷拥抱AI大模型。</p>\n<p>2025年的年末，Manus被Meta收购，在科技界十分轰动。</p>\n<p>过去，我们认为AI只是个玩具，离自己很远。</p>\n<p>而现在，它已经能够做具体的工作了。</p>\n<h3 id=\"尝试自媒体\">尝试自媒体</h3>\n<blockquote>\n<p>转型，不一定非的转行。</p>\n</blockquote>\n<p>2025年的国庆节后，笔者开始做视频号。</p>\n<p>主要基于两点考虑：</p>\n<ul>\n<li>希望能够突破自我，拓宽自己的视野。</li>\n<li>培养兴趣、爱好，丰富自己的生活。</li>\n</ul>\n<p>干技术工作十几年了，如果只是沉浸在技术领域,那未免有些枯燥。<br />\n何况，生活不止是工作，还有诗和远方。</p>\n<br />\n<section>\n    <a href=\"https://img.zhikestreet.com/2026-01-01_160015_444-min.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" rel=\"noopener nofollow\"><img alt=\"\" src=\"https://img.zhikestreet.com/2026-01-01_160015_444-min.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n<br />\n<section>\n    <a href=\"https://img.zhikestreet.com/2026-01-01_160113_397.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" rel=\"noopener nofollow\"><img alt=\"\" src=\"https://img.zhikestreet.com/2026-01-01_160113_397.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n<p>做视频很花心思，也很有挑战性，也没啥收益。<br />\n每次期待有粉丝关注，也算是一种成就感。</p>\n<h3 id=\"读毛选\">读毛选</h3>\n<blockquote>\n<p>内心强大才是真正的强大。</p>\n</blockquote>\n<p>2025年，职场遭遇困境，几乎快要到了面临抉择的时候，笔者开始阅读《毛选》。<br />\n就这样，深一脚，浅一脚挺了过来。</p>\n<p>不管是企业还是个人，都有遇到困难的时候。</p>\n<p>有时候，逃避问题很容易，直面问题需要莫大的勇气。</p>\n<p>\"贵人成全你，小人成就你。\"，经历过风雨的人，深有感受。</p>\n<section>\n    <a href=\"https://img.zhikestreet.com/20260101162415_666_2-min.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" rel=\"noopener nofollow\"><img alt=\"\" src=\"https://img.zhikestreet.com/20260101162415_666_2-min.png?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n<section>\n    <a href=\"https://img.zhikestreet.com/1767255242289-min.jpg?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" rel=\"noopener nofollow\"><img alt=\"\" src=\"https://img.zhikestreet.com/1767255242289-min.jpg?imageView2/0/q/75|watermark/2/text/NTJJbnRlcnZpZXc=/font/5a6L5L2T/fontsize/240/fill/IzBFMDkwNQ==/dissolve/100/gravity/SouthEast/dx/10/dy/10\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n<h3 id=\"写过的文章\">写过的文章</h3>\n<blockquote>\n<p>经验创造价值，分享成就未来。</p>\n</blockquote>\n<ul>\n<li><a href=\"https://www.cnblogs.com/lucky_hu/collections/29080\" target=\"_blank\">《AI工作流实战》</a></li>\n</ul>\n<br />\n<section>\n    <a href=\"https://www.52interview.com/book/100\" rel=\"noopener nofollow\"><img alt=\"\" src=\"https://img.zhikestreet.com/2026-01-01_164320_875.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n<h3 id=\"结语\">结语</h3>\n<blockquote>\n<p>我们都在奔跑,但是短暂地停下来思考,是为了更好地再出发。</p>\n</blockquote>\n<p>过去的一年，为了\"柴米油盐、三餐四季\"忙碌奔波。</p>\n<p>新的一年，希望可以多一点战略思考，发掘更多个人的潜力和强项，突破发展瓶颈，找到属于自己的赛道。</p>\n<p>以上只是笔者个人的一点点浅见,有理解不对的地方，请大家多多包含和指正。</p>\n<h3 id=\"致谢\">致谢</h3>\n<p>最后，分享一首《踏莎行·元旦》，祝您在新的一年里，一路向阳，温暖前行，万事无忧。</p>\n<blockquote>\n<p>爆竹庭前，树桃门右。香汤浴罢，五更后。高烧银烛，瑞烟喷金兽。萱堂次第了，相为寿。<br />\n改岁宜新、应时纳祐。从今诸事愿、胜如旧。人生强健，喜一年入手。休辞最后饮，酴酥酒。</p>\n</blockquote>\n<br />\n<section>\n <a href=\"https://www.52interview.com/\" rel=\"noopener nofollow\" target=\"_blank\"><img alt=\"\" src=\"https://img.zhikestreet.com/20210522-22216942.jpg\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></a>\n</section> \n<br />\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-01 17:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lucky_hu\">楠木大叔</a>&nbsp;\n阅读(<span id=\"post_view_count\">75</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "实用程序：解放双手！Python 打造 PDF 手写模拟器，轻松搞定手写作业",
      "link": "https://www.cnblogs.com/ChenAI-TGF/p/19430267",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/ChenAI-TGF/p/19430267\" id=\"cb_post_title_url\" title=\"发布于 2026-01-01 15:59\">\n    <span>实用程序：解放双手！Python 打造 PDF 手写模拟器，轻松搞定手写作业</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文介绍了一款基于Python开发的PDF手写模拟工具，可自动将电子文本转换为逼真手写效果并填充至PDF指定区域。该工具支持中英文独立配置字体、大小、颜色等参数，通过随机扰动算法模拟真实手写的行倾斜、字符偏移等不规则特性。用户可通过可视化界面框选填写区域、实时预览效果并保存配置模板。技术实现采用PyMuPDF处理PDF核心操作，结合tkinter构建GUI界面，Pillow实现图像渲染。开源项目地址已提供，可帮助学生高效完成手写作业需求，显著提升工作效率。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>作为学生，想必大家都有过被海量手写实验报告、课程作业支配的痛苦。要花费大量时间一笔一划地抄写到纸质文档中再进行扫描成pdf提交，不仅耗时耗力，手写的字迹还可能参差不齐，影响作业美观度。</p>\n<p>为了偷懒，博主开发了一款基于python的PDF手写模拟器，它能够模拟真实手写笔迹，将电脑上的文字批量填充到 PDF 指定区域，支持中文/英文分开配置、手写扰动效果自定义、配置模版复用等功能，生成的效果高度贴近真实手写，帮你彻底告别手动抄写的烦恼。首先来个界面以及效果预览：</p>\n<p><strong>代码已经开源在Github：<a href=\"https://github.com/ChenAI-TGF/PDF_HandWrite\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/ChenAI-TGF/PDF_HandWrite</a><br />\n欢迎大家下载，如果觉得有用的话可以给我点个Star，万分感谢！！<br />\n如果登不上Github的话也欢迎直接私信博主要代码</strong></p>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h2 id=\"流程思路总览\">流程思路总览</h2>\n<p>这款 PDF 手写模拟器的整体运作流程可以分为「用户操作流程」和「技术实现流程」两层，清晰易懂：</p>\n<h2 id=\"1--用户操作流程简单易上手\">1.  用户操作流程（简单易上手）</h2>\n<ol>\n<li>\n<p>打开目标 PDF：选择需要填写的实验报告、作业等 PDF 文件；<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>框选填写区域：在 PDF 预览界面拖动鼠标，框选出需要插入文字的区域（红色矩形标记）；<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>配置手写参数：分别在中文、英文/数字选项卡中调整字体、大小、颜色、扰动效果等参数；<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>输入并预览文字：在右侧文本框输入需要填写的内容，开启「实时预览」查看手写效果；<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /><br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>不满意可实时调整参数<br />\n<img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n</li>\n<li>\n<p>确认并保存：效果满意后确认应用笔迹，支持撤销、擦除错误内容，也可保存当前配置为模版，最后导出填写完成的 PDF。</p>\n</li>\n</ol>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h3 id=\"2--技术实现流程分层协作\">2.  技术实现流程（分层协作）</h3>\n<ol>\n<li>UI 交互层：基于 tkinter 搭建可视化界面，提供按钮、选项卡、文本框等交互组件，接收用户操作；</li>\n<li>参数配置层：管理中文/英文手写参数，支持配置保存（JSON）与加载，实现模版复用；</li>\n<li>PDF 操作层：基于 PyMuPDF 实现 PDF 的读取、页面渲染、文字插入、擦除、保存等核心操作；</li>\n<li>手写渲染层：核心逻辑层，实现文字排版、语言区分、手写扰动效果生成，最终将模拟手写文字插入 PDF。</li>\n</ol>\n<pre><code class=\"language-bash\">┌─────────────────────┐\n│  UI交互层（tkinter） │  # 可视化交互，接收操作\n└─────────────┬───────┘\n              ▼\n┌─────────────────────┐\n│  参数配置层（JSON）  │  # 参数管理，模版复用\n└─────────────┬───────┘\n              ▼\n┌─────────────────────┐\n│ PDF操作层（PyMuPDF） │  # PDF核心操作（读写/保存等）\n└─────────────┬───────┘\n              ▼\n┌─────────────────────┐\n│  手写渲染层（核心）  │  # 手写效果生成，文字插入\n└─────────────────────┘\n</code></pre>\n<h1 id=\"涉及的具体技术\">涉及的具体技术</h1>\n<p>这款工具基于 Python 生态的常用库开发，技术栈轻量化且实用性强，核心涉及以下技术：</p>\n<ol>\n<li><strong>tkinter</strong>：Python 内置 GUI 库，无需额外安装，负责搭建整个应用的可视化界面，实现按钮点击、参数调整、文本输入、PDF 预览等交互功能；</li>\n<li><strong>PyMuPDF（fitz）</strong>：核心 PDF 处理库，提供高效的 PDF 读取、写入、页面渲染、文字插入、红act标注（擦除功能）等接口，是实现 PDF 编辑的核心依赖；</li>\n<li><strong>Pillow（PIL）</strong>：图像处理库，将 PyMuPDF 渲染出的 PDF 页面像素数据，转换成 tkinter 画布可显示的图像格式，实现 PDF 页面的可视化预览；</li>\n<li><strong>JSON</strong>：轻量级数据格式，用于保存用户配置的手写参数模版（字体、大小、扰动值等），方便后续直接复用，无需重复调整；</li>\n<li><strong>Python 随机数与数学计算</strong>：实现手写效果的「不规则扰动」，模拟真实手写的位置偏移、大小波动、行倾斜等特性；</li>\n<li><strong>TTF 字体支持</strong>：读取自定义 TrueType 字体文件，支持切换不同手写风格字体，适配不同用户的手写习惯。</li>\n</ol>\n<h1 id=\"最终效果演示\">最终效果演示</h1>\n<p><img alt=\"在这里插入图片描述\" class=\"lazyload\" /></p>\n<h1 id=\"代码原理简单讲解手写字体生成--扰动效果\">代码原理简单讲解（手写字体生成 + 扰动效果）</h1>\n<p>我们重点讲解核心功能 —— 手写字体生成与扰动效果的实现，忽略 UI 搭建等辅助代码，聚焦核心逻辑：</p>\n<h2 id=\"一-手写字体生成文字插入-pdf-核心\">一、 手写字体生成（文字插入 PDF 核心）</h2>\n<p>这部分的核心是将文字按规则排版后，插入到 PDF 指定区域，关键步骤如下：</p>\n<ol>\n<li>\n<p><strong>文字与区域预处理</strong><br />\n首先获取文本框中的输入文字，按换行符 <code>\\n</code> 分割成多行，同时将用户框选的预览区域坐标（带缩放比例）转换为 PDF 实际坐标（除以缩放系数 <code>self.zoom</code>），得到真实的填写范围 <code>(x1, y1, x2, y2)</code>。</p>\n<pre><code class=\"language-python\"># 读取输入文字并分割行\ntext = self.text_editor.get(\"1.0\", tk.END).strip(\"\\n\")\nlines = text.split('\\n')\n# 转换为 PDF 实际坐标（去除预览缩放影响）\nx1, y1 = min(self.start_x, self.end_x)/self.zoom, min(self.start_y, self.end_y)/self.zoom\nx2, y2 = max(self.start_x, self.end_x)/self.zoom, max(self.start_y, self.end_y)/self.zoom\n</code></pre>\n</li>\n<li>\n<p><strong>语言区分与参数匹配</strong><br />\n通过 <code>is_chinese</code> 函数判断单个字符是中文还是英文/数字，分别匹配对应的配置参数（中文/英文独立的字体、大小、字距等），确保不同语言的手写效果适配合理。</p>\n<pre><code class=\"language-python\"># 判断是否为中文（含中文标点）\ndef is_chinese(self, char):\n    if '\\u4e00' &lt;= char &lt;= '\\u9fff': return True\n    if char in \"。，、？！：；“”‘’（）《》【】\": return True\n    return False\n\n# 遍历字符时匹配对应语言参数\nlang = 'zh' if self.is_chinese(char) else 'en'\np = self.params[lang]  # 获取对应语言的配置参数\n</code></pre>\n</li>\n<li>\n<p><strong>PDF 文字插入核心 API</strong><br />\n使用 PyMuPDF 的 <code>page.insert_text</code> 方法实现文字插入，这是手写字体生成的关键，核心参数说明如下：</p>\n<ul>\n<li><code>fitz.Point(final_x, final_y)</code>：文字的实际插入坐标（经排版和扰动调整后）；</li>\n<li><code>char</code>：要插入的单个字符（逐字符插入实现精细排版）；</li>\n<li><code>fontsize</code>：字符的实际大小（带大小抖动）；</li>\n<li><code>fontfile</code>：TTF 手写字体文件路径，决定字体风格；</li>\n<li><code>color</code>：文字颜色（默认纯黑，支持用户自定义）；</li>\n<li><code>morph</code>：变换矩阵，实现字符旋转效果（叠加行倾斜与字符旋转抖动）。</li>\n</ul>\n</li>\n<li>\n<p><strong>行与字符排版</strong><br />\n按行遍历文字，逐字符计算插入坐标，处理空格（单独预留间距），当字符横坐标超出框选区域右侧时自动换行，同时根据「行距参数」调整下一行的纵坐标，确保文字排版规整且不超出框选范围。</p>\n</li>\n</ol>\n<h2 id=\"二-扰动效果实现模拟真实手写不规则性\">二、 扰动效果实现（模拟真实手写不规则性）</h2>\n<p>这是工具的灵魂所在，通过「行级扰动」和「字符级扰动」两层效果，彻底摆脱打印体的规整感，贴近真实手写，对应代码中的配置参数：</p>\n<ol>\n<li>\n<p><strong>行级扰动（整行不规则性）</strong><br />\n针对每一行文字，添加整体的偏移和倾斜，模拟手写时「行不直、略有偏移」的特点，对应三个参数：</p>\n<ul>\n<li>行左右平移（<code>line_jitter_x</code>）：随机生成 <code>-line_jitter_x ~ line_jitter_x</code> 范围内的偏移量 <code>line_dx</code>，使每行文字左右轻微晃动；</li>\n<li>行上下平移（<code>line_jitter_y</code>）：随机生成 <code>-line_jitter_y ~ line_jitter_y</code> 范围内的偏移量 <code>line_dy</code>，使行与行之间的间距略有差异；</li>\n<li>行整行倾斜（<code>line_tilt</code>）：随机生成倾斜角度 <code>line_angle_deg</code>，转换为弧度后，通过 <code>tilt_y_offset = (curr_x - line_start_x) * math.tan(line_angle_rad)</code> 计算每个字符的Y轴偏移，实现整行轻微倾斜。</li>\n</ul>\n<pre><code class=\"language-python\"># 行级扰动参数计算\nline_dx = random.uniform(-p_line['line_jitter_x'].get(), p_line['line_jitter_x'].get())\nline_dy = random.uniform(-p_line['line_jitter_y'].get(), p_line['line_jitter_y'].get())\nline_angle_deg = random.uniform(-p_line['line_tilt'].get(), p_line['line_tilt'].get())\nline_angle_rad = math.radians(line_angle_deg)\n</code></pre>\n</li>\n<li>\n<p><strong>字符级扰动（单个字符不规则性）</strong><br />\n针对每个字符，添加位置、大小、旋转的细微差异，模拟手写时「每个字大小不一、略有晃动」的特点，对应三个参数：</p>\n<ul>\n<li>字位置抖动（<code>jitter_pos</code>）：随机生成 <code>(-jitter_pos ~ jitter_pos)</code> 的X、Y偏移量，使字符脱离严格的水平对齐；</li>\n<li>字大小抖动（<code>jitter_size</code>）：在基础字体大小上，随机增减 <code>(-jitter_size ~ jitter_size)</code> 的数值，生成 <code>char_jitter_fs</code>，使字符大小略有差异；</li>\n<li>字旋转抖动（<code>jitter_rot</code>）：随机生成 <code>(-jitter_rot ~ jitter_rot)</code> 的旋转角度，叠加行倾斜角度后，通过 <code>morph</code> 参数实现字符轻微旋转。</li>\n</ul>\n<pre><code class=\"language-python\"># 字符级扰动参数计算\nchar_jitter_x = random.uniform(-p['jitter_pos'].get(), p['jitter_pos'].get())\nchar_jitter_y = random.uniform(-p['jitter_pos'].get(), p['jitter_pos'].get())\nchar_jitter_rot = random.uniform(-p['jitter_rot'].get(), p['jitter_rot'].get())\nchar_jitter_fs = f_size + random.uniform(-p['jitter_size'].get(), p['jitter_size'].get())\n</code></pre>\n</li>\n<li>\n<p><strong>随机数控制（预览稳定 + 实际随机）</strong><br />\n为了保证实时预览时效果稳定可调整，设置随机数种子 <code>random.seed(42)</code> 固定扰动效果；实际应用笔迹时，不设置种子 <code>random.seed()</code>，生成随机的扰动效果，让每次生成的手写风格略有差异，更贴近真实场景。</p>\n<pre><code class=\"language-python\">if is_preview: random.seed(42)  # 预览模式：固定随机数，效果稳定\nelse: random.seed()  # 实际生成：随机种子，效果更真实\n</code></pre>\n</li>\n</ol>\n<h1 id=\"总结\">总结</h1>\n<p>这款 PDF 手写模拟器完美解决了手写作业、实验报告的痛点，兼具「实用性」和「灵活性」：</p>\n<ol>\n<li><strong>实用性拉满</strong>：无需手动抄写，一键生成手写风格 PDF，节省大量时间和精力，生成效果高度贴近真实手写；</li>\n<li><strong>自定义性强</strong>：中文/英文独立配置，支持字体、颜色、大小、字距行距调整，多层扰动参数可精细调控手写风格；</li>\n<li><strong>操作便捷</strong>：可视化界面友好，支持实时预览、撤销、擦除、模版复用，零基础用户也能快速上手；</li>\n<li><strong>技术轻量化</strong>：基于 Python 常用库开发，无需复杂环境配置，代码可灵活修改扩展。</li>\n</ol>\n<p>当然，这款工具还有优化空间，比如支持连笔效果、笔迹粗细变化、批量处理多个 PDF 等。如果大家有类似需求，可以基于这份代码进行二次开发，适配自己的使用场景。希望这款工具能帮大家解放双手，把更多时间投入到核心学习和研究中！</p>\n<p><strong>代码已经开源在Github：<a href=\"https://github.com/ChenAI-TGF/PDF_HandWrite\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/ChenAI-TGF/PDF_HandWrite</a><br />\n欢迎大家下载，如果觉得有用的话可以给我点个Star，万分感谢！！<br />\n如果登不上Github的话也欢迎直接私信博主要代码</strong></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-01 15:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/ChenAI-TGF\">TTGF</a>&nbsp;\n阅读(<span id=\"post_view_count\">78</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Perigon.CLI 10.0 重磅发布【AspNetCore开发模板和辅助工具】",
      "link": "https://www.cnblogs.com/msdeveloper/p/19430150/perigon-10-announce",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/msdeveloper/p/19430150/perigon-10-announce\" id=\"cb_post_title_url\" title=\"发布于 2026-01-01 15:18\">\n    <span>Perigon.CLI 10.0 重磅发布【AspNetCore开发模板和辅助工具】</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"-perigoncli-100-重磅发布\">🎉 Perigon.CLI 10.0 重磅发布</h1>\n<p><img alt=\"perigon_logo320\" src=\"https://img2024.cnblogs.com/blog/1074783/202601/1074783-20260101151334306-54452182.png\" /></p>\n<p>我们很高兴地宣布，Perigon.CLI 10.0 现已正式发布！此次更新带来了众多令人兴奋的新功能和改进，旨在提升开发者的生产力和开发体验。</p>\n<p>简而言之，Perigon是围绕<code>Aspire/AspNetCore/EF Core</code>等相关技术栈的开发辅助工具，帮助你快速构建可维护的项目，它主要提供：</p>\n<ul>\n<li><strong>项目脚手架</strong>：通过解决方案模板(Perigon.templates)，快速创建符合最佳实践的项目结构。</li>\n<li><strong>代码生成器</strong>：提供WebUI界面，用来通过实体来生成对应的增删改查代码，以及客户端请求服务的生成，极大减少重复劳动；同时提供自定义模板功能，满足不同项目需求。</li>\n<li><strong>MCP</strong>: 提供MCP支持，以与现有IDE中的AI集成。</li>\n<li><strong>命令行工具</strong>：用来创建解决方案/启动WebUI/生成客户端请求服务等。</li>\n</ul>\n<h2 id=\"由来\">由来</h2>\n<p>最初，它只是我个人在开发前后端项目时，为了减少重复劳动而开发的简单的项目分层脚手架和代码生成工具。当时(2020年)它叫<code>GT.CLI</code>和<code>GT.Framework.Web</code>。</p>\n<p>2021年，重构了结构，并开始在团队项目中使用，模板改名为<code>ater.web.templates</code>，CLI工具也经过两次大改，分别为<code>ater.droplet.cli</code>和<code>ater.dry</code>，它加入了一些公司内项目需求的功能，如提供更多开箱即用的模块。</p>\n<blockquote>\n<p>[!TIP]<br />\n以上工具可在<code>nuget</code>中找到，但都不再维护。</p>\n</blockquote>\n<h2 id=\"-现在\">✨ 现在</h2>\n<p>2025年.NET10发布，在年初，我开始计划进行全面的重构和优化，提供一个全新的版本，完全基于.NET10，不再兼容之前的版本，经过数月的开发和测试，最终发布了<code>Perigon.CLI</code>和<code>Perigon.templates</code>，该版本主要的特点包括：</p>\n<ul>\n<li>\n<p>操作界面从<code>Angular</code>改为<code>Blazer server</code>，使用<code>fluent-ui</code>组件库，从技术到视觉上都更贴近<code>NET</code>生态。</p>\n</li>\n<li>\n<p>在项目结构上，去复杂化，更加通用。去除了以下设计</p>\n<ul>\n<li><code>仓储模式</code></li>\n<li>默认使用<code>QueryDbContext</code>和<code>CommandDbContext</code>的设计，需要多一层DataAccess来抽象。</li>\n<li>默认生成业务接口类</li>\n<li><code>[Module]</code>特性，直接使用目录结构来区分模块</li>\n<li>其他不必要的抽象和复杂设计</li>\n</ul>\n</li>\n<li>\n<p>重构项目结构，并添加了更多通用和实用的功能</p>\n<ul>\n<li>引入Aspire：解决开发环境基础设施和多服务支持问题</li>\n<li>多服务支持：结合单体和微服务，一个解决方案都搞定</li>\n<li>多租户支持：通过配置在单租户和多租户间切换</li>\n<li>多数据库支持：通过工厂模式支持多种数据库</li>\n<li>多语言支持：内置多语言支持，方便国际化</li>\n<li>MCP支持：直接在IDE中调用工具生成代码</li>\n<li>源代码生成器支持(多语言和自动注入Manager)</li>\n</ul>\n</li>\n</ul>\n<p>更为重要的是，新版本确定了一些核心设计原则：</p>\n<ul>\n<li>通用且开放：不依托于特定设计模式或架构，优先使用通用且成熟的技术栈</li>\n<li>简单易用：不引入新的设计模式或理论，降低学习成本和心智负担</li>\n<li>以开发者为中心：提高开发效率和使用体验是主要目标</li>\n</ul>\n<p>现在，你可以通过我们的📚<a href=\"https://dusi.dev/docs/Perigon.html\" rel=\"noopener nofollow\" target=\"_blank\">官方文档</a>，了解如何安装和使用<code>Perigon.CLI</code>，并开始你的高效开发之旅！</p>\n<h2 id=\"未来\">🚀未来</h2>\n<p>未来将在三个方面持续改进：</p>\n<ul>\n<li>生产力。如今我们通过IDE和代码生成器避免重复性的工作。而今年使用code agent编程已经是非常平常的事情，其能力和效果无需多言，虽然还有些局限性，但其能力还在不断提升。我们会将更多AI编程的实践经验融入到工具中，进一步提升开发效率和开发体验。</li>\n<li>性能。在保持模板框架稳定的基础上，尽可能的提升性能，完善性能方面的最佳实践(文档说明)。</li>\n<li>生态。我们将基于<code>perigon</code>构建更多的内容，如身份验证系统，AIAgent系统等，也就是在基础框架的基础上，提供更多面向特定场景的解决方案。此外，还将尝试对模块进行打包和分发，进一步提高复用性和可维护性。</li>\n</ul>\n<h3 id=\"版本计划\">版本计划</h3>\n<p>对于<code>Perigon.CLI</code>，它将跟随<code>.NET</code>的版本迭代进行更新，计划每年发布一个大版本，单数版本会同时支持上一个LTS版本，偶数版本只支持当前LTS版本。</p>\n<p>对于``Perigon.templates<code>，它从</code>1.0.0`开始，由于它影响整个项目的结构和技术选型，未来主要专注于问题修复和性能提升。新的功能特性尽可能在不改变现有结构的前提下进行添加。</p>\n<h2 id=\"️️社区参与\">🏃‍♂️‍➡️社区参与</h2>\n<p>如果你对.NET开发有兴趣，并希望参与到Perigon.CLI的建设中来，欢迎访问我们的<a href=\"https://github.com/AterDev/Perigon.CLI\" rel=\"noopener nofollow\" target=\"_blank\">GitHub仓库</a>，提交你的想法、建议或贡献代码。我们期待与你一起打造更好的开发工具！</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-01 15:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/msdeveloper\">TypingLearn</a>&nbsp;\n阅读(<span id=\"post_view_count\">81</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2025年度总结",
      "link": "https://www.cnblogs.com/SilverGo/p/19428614",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/SilverGo/p/19428614\" id=\"cb_post_title_url\" title=\"发布于 2025-12-31 22:47\">\n    <span>2025年度总结</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"table-of-contents\">Table of Contents</h1>\n<ol>\n<li><a href=\"#org936be25\" rel=\"noopener nofollow\">2025年度总结</a></li>\n<li><a href=\"#org07aceb4\" rel=\"noopener nofollow\">关于Ctorch</a></li>\n<li><a href=\"#orgc1859ea\" rel=\"noopener nofollow\">关于CSP-J</a></li>\n<li><a href=\"#org1d85aae\" rel=\"noopener nofollow\">关于lambda演算、UTM（通用图灵机）、Coq</a></li>\n<li><a href=\"#org9a42a9e\" rel=\"noopener nofollow\">关于汇编</a></li>\n<li><a href=\"#orgabafce1\" rel=\"noopener nofollow\">一些感想</a></li>\n<li><a href=\"#org89cb23b\" rel=\"noopener nofollow\">资料</a></li>\n<li><a href=\"#org3319ea0\" rel=\"noopener nofollow\">结语</a></li>\n</ol>\n<p>Powered by GhostFace's Emacs.</p>\n<p><a id=\"org936be25\"></a></p>\n<h1 id=\"2025年度总结\">2025年度总结</h1>\n<p><a id=\"org07aceb4\"></a></p>\n<h2 id=\"关于ctorch\">关于Ctorch</h2>\n<p><strong>Ctorch 诞生的第166天。</strong><br />\n没想到，ct都这么大了，<strong>从一个单人项目到现在4人的小团队，从一个模糊的想法到如今近万行的代码，总计5个月13天。</strong></p>\n<p>不得不说，这段时间，学到了很多。</p>\n<p><strong>从来没有用过git的人，commit了近160次；<br />\n从来没有接触过汇编的人，为了极限优化、搞懂编译器行为，学了2个月的汇编；<br />\n曾经连类都没写过的人，写了5个几千行的类；<br />\n曾经连朴素矩阵乘都不会写的菜鸡，手搓了一个Strassen+分块的并行矩阵乘</strong>；<br />\n诸如此类，不再列举。</p>\n<p><a id=\"orgc1859ea\"></a></p>\n<h2 id=\"关于csp-j\">关于CSP-J</h2>\n<p>本蒟蒻已经很长时间没有更新过日志了，可能的原因是比较忙。</p>\n<p><strong>最近几个月，本人一直在忙CSP-J的准备、Ctorch的开发、Coq的学习与lambda演算上。<br />\n先在暑假发起了「挑战3个月达省一」的挑战（当然，挑战成功了）</strong>；</p>\n<p>这一段时间，刷的题比我之前一年刷的都多；</p>\n<p>20多天，我学习了：<strong>dp、图论、并查集、加权并查集、模拟退火等算法，之前一年也只学了排序；</strong></p>\n<p><strong>怎么说呢，之前一直没搞清楚的搜索算法，现在看来也不过如此。</strong></p>\n<p><a id=\"org1d85aae\"></a></p>\n<h2 id=\"关于lambda演算utm通用图灵机coq\">关于lambda演算、UTM（通用图灵机）、Coq</h2>\n<p>随后，先是因为知道了C++有个叫lambda表达式的东西，随后在洛谷上搜索，<strong>意外看到了一篇讲lambda演算的文章</strong>；</p>\n<p>抱着在学校上课无聊的心态，学习了lambda演算，结果一发不可收拾。</p>\n<p>学完之后，我得知<strong>lambda演算图灵完备，于是乎，我想起了一个好玩的东西：用无类型lambda演算手搓UTM（通用图灵机），这当然理论可行</strong>。</p>\n<p>反正我平时能够思考的时间很多，在问过AI后，得知这是一次非常困难但是收获极大的挑战，我便开始了我的构建。</p>\n<p><strong>一支笔，一个本，一个脑子，不看论文，不搜索，只思考。<br />\n每天上放学的路上，走着需要35min左右，这段时间，我就会不停地思考关于UTM的问题。<br />\n这个过程很爽，因为我在构建一个完整的世界，理论上，这台「仅仅依靠代入完成计算」的“计算机”可以完成任何工作，只要你想，甚至可以跑一个仿真的Windows.</strong></p>\n<p>写了快几十张纸，我才明白，AI说的那句：<strong>「lambda演算可以练习思维」</strong>，突然有一天，我看待调用、递归的感觉完全变了，我看函数的感觉也变了。</p>\n<p><strong>我们都觉得，是先有了数字，才有了函数;</strong><br />\n但是，Church数字告诉我们，<strong>数字也是函数</strong>。</p>\n<p>（这个名为LUTM的UTM仍在设计，不过，由于Ctorch对我的优先级更高，目前暂时停工，等2月16日发布Ctorch RC 1之后再继续）</p>\n<p><strong>学习完lambda演算后，我接触到了Coq。<br />\nCoq证明「加法左零律」的思路让我感觉无比震惊，这完全颠覆了我对数学归纳法的认知</strong>。</p>\n<p><strong>而且，Coq中对自然数的定义和lambda演算的列表出奇的一致。<br />\n怎么说呢，可能这就是「万变不离其宗」吧.</strong><br />\n但是仍然是为了Ctorch的开发，我暂停了Coq的学习。</p>\n<p><a id=\"org9a42a9e\"></a></p>\n<h2 id=\"关于汇编\">关于汇编</h2>\n<p>在这之后，我学习了Arm64汇编。<br />\n仅仅是写出一个Hello World，我就花了2天（当然，我在学校每天只有10min能用电脑，20min可以和AI对话）.<br />\n但仅此一次，我就明白了，C++中递归、调用是如何做的，本质其实就是将x29,x30寄存器的值修改；<br />\n我也明白了，什么是「栈溢出」，什么是「调用栈」。<br />\n几行的C++换成汇编就可能需要数十行，这让我写代码时会思考着汇编的样子。<br />\n不得不说，这确实是一次很好的历练。</p>\n<p><a id=\"orgabafce1\"></a></p>\n<h2 id=\"一些感想\">一些感想</h2>\n<p>回首这几个月我所经历的，可能比我之前一年学的都要多，都要杂；</p>\n<p><strong>这些知识无疑带给了我很强的塑造作用：<br />\n设计LUTM，锻炼了我进行2小时以上的深度思考的能力；<br />\n学习汇编，让我对底层有了掌控；<br />\n学习lambda演算，让我对函数有了更彻底的认识；<br />\n可以说，对一个初中生而言，这条路径独一无二。<br />\n我结识了一群志同道合的朋友，有了自己的团队、组织；<br />\n曾经那个被嘲笑“写这些有什么用”、“连个奖都拿不到”的人，如今竟成为一个开源项目的开发者、CSP-J的省一。</strong><br />\n<strong>毫无疑问，这是无比有价值的半年；</strong></p>\n<p><a id=\"org89cb23b\"></a></p>\n<h1 id=\"资料\">资料</h1>\n<p>下面放一点资料</p>\n<p>1.设计LUTM时与Deepseek的对话：<a href=\"https://chat.deepseek.com/share/wednovjlp5sa013j4q\" rel=\"noopener nofollow\" target=\"_blank\">https://chat.deepseek.com/share/wednovjlp5sa013j4q</a><br />\n2.文章：《恭喜自己，挑战成功》————CSP-J省一获奖感言：<a href=\"https://www.cnblogs.com/SilverGo/p/19223328\" target=\"_blank\">https://www.cnblogs.com/SilverGo/p/19223328</a><br />\n3.文章：《逆袭导论·初中生的宝书》：<a href=\"https://www.cnblogs.com/SilverGo/p/19284999\" target=\"_blank\">https://www.cnblogs.com/SilverGo/p/19284999</a><br />\n4.文章：《矩阵乘法优化》：<a href=\"https://www.cnblogs.com/SilverGo/p/19019364\" target=\"_blank\">https://www.cnblogs.com/SilverGo/p/19019364</a><br />\n5.Ctorch的github：<a href=\"https://github.com/ShengFlow/CTorch/tree/feature-nn.Module?tab=contributing-ov-file\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/ShengFlow/CTorch/tree/feature-nn.Module?tab=contributing-ov-file</a><br />\n6.以下是图片：<br />\n<img alt=\"截屏2025-12-28 10.22.19\" height=\"982\" src=\"https://img2024.cnblogs.com/blog/3357339/202512/3357339-20251231224442471-111964913.png\" width=\"1512\" /><br />\n<img alt=\"截屏2025-12-18 06.31.21\" height=\"982\" src=\"https://img2024.cnblogs.com/blog/3357339/202512/3357339-20251231224520016-1653169643.png\" width=\"1512\" /><br />\n<img alt=\"截屏2025-10-04 16.25.21\" height=\"982\" src=\"https://img2024.cnblogs.com/blog/3357339/202512/3357339-20251231224619686-610660255.png\" width=\"1512\" /></p>\n<p><a id=\"org3319ea0\"></a></p>\n<h1 id=\"结语\">结语</h1>\n<blockquote>\n<p>“Put yourself in places that are gonna cause you to stretch<br />\n让自己置身于能促使自己突破的境地<br /><br />\nA fighter isn't someone that never fails<br />\n真正的勇士并非永不失败<br /><br />\nA fighter is someone who never quits<br />\n而是永不言弃<br /><br />\nYou are more to me than you could never now<br />\n你对我而言远比自己想象的更重要<br /><br />\nAnd I know I've got a full room of fighters in here right<br />\n此刻我深知这满座皆是勇者”<br /></p>\n</blockquote>\n<blockquote>\n<p>“I see ,I like ,I go ,I get.<br />\n目之所及，心之所向，踏上征程，志在必得！”<br /></p>\n</blockquote>\n<blockquote>\n<p>“为天地立心，<br /><br />\n为生民立命，<br /><br />\n为往圣继绝学，<br /><br />\n为万世开太平”————宋·张载《横渠四句》<br /></p>\n</blockquote>\n<blockquote>\n<p>“身处低谷不自弃，我命由我不由天。<br /><br />\n无人扶我青云志，我自踏雪至山巅。<br /><br />\n若是命中无此运，亦可孤身登昆仑。<br /><br />\n红尘赠我三尺剑，酒换瘦马一世街。<br /><br />\n世人朝路乃绝涧，独见众生止步前。<br /><br />\n海到尽头天作岸，山登绝顶我为峰。<br /><br />\n如若东山能再起，大鹏展翅九万里。<br /><br />\n一入红尘梦易真，一朝悟透心境名。<br /><br />\n一朝悟道见真我，昔日枷锁皆云烟。<br /><br />\n天门将至百运开，拂尘轻笑问仙来。<br /><br />\n何须扶我青云志，我自凌云至山巅！”————徐霞客《青云志》<br /></p>\n</blockquote>\n<p><strong>2025，对我而言，注定是难忘的一年.</strong><br />\n<strong>诸位，新年快乐！</strong></p>\n<p><strong>预告：我们预计在2026.2.16（除夕）发布Ctorch RC v1.0，敬请期待，欢迎联系：QQ 1113109729，参与内测，感激不尽！</strong></p>\n<p>GhostFace<br />\n2025.12.31</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2025-12-31 22:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/SilverGo\">Ghost-Face</a>&nbsp;\n阅读(<span id=\"post_view_count\">131</span>)&nbsp;\n评论(<span id=\"post_comment_count\">2</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[微服务进阶场景实战] - 数据一致性",
      "link": "https://www.cnblogs.com/yhup/p/19427692",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yhup/p/19427692\" id=\"cb_post_title_url\" title=\"发布于 2025-12-31 17:21\">\n    <span>[微服务进阶场景实战] - 数据一致性</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"[微服务进阶场景实战] - 数据一致性\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/2428649/202512/2428649-20251231172110600-959933332.png\" />\n        本文探讨了微服务架构中的数据一致性问题及解决方案。针对最终一致性场景，提出基于消息队列的异步补偿方案，通过消息持久化和重试机制确保数据最终一致；对于强一致性需求，对比分析了TCC模式与Seata AT模式，重点推荐Seata AT方案，其通过自动生成回滚日志实现低侵入式分布式事务管理。实践表明，这两种方案能有效解决数据不一致问题，且不会显著增加开发负担，为微服务架构提供了可靠的数据一致性保障。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面我们梳理了微服务的九大痛点，其中一部分目前尚无完美解决方案，另一部分则已有可行对策。从本章起，我们将逐一探讨那些“有解”的痛点。首当其冲的，就是数据一致性问题——让我们从一个实际业务场景切入。</p>\n<h1 id=\"1-业务场景下游服务失败后上游服务如何独善其身\">1 业务场景：下游服务失败后上游服务如何独善其身</h1>\n<p>在微服务架构中，一个业务请求常常需要跨多个服务更新多个数据库，示意图如下：</p>\n<p><img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202512/2428649-20251231172011750-1090431586.png\" /></p>\n<p>理想情况下，业务顺利完成时，三个服务的数据应依次更新为 a2、b2、c2，此时数据处于一致状态。然而，现实往往充满意外：网络抖动、服务过载、数据库响应缓慢等都可能导致调用链中途失败。例如，若在步骤 2 失败，数据会停留在 a2、b1、c1；若在步骤 3 失败，则变成 a2、b2、c1——数据不一致就这样产生了。</p>\n<p>在本项目启动前，由于早期改造工期紧张，开发团队无暇顾及数据一致性问题，导致线上陆续出现错误数据。业务部门通过工单反馈后，IT 团队排查发现，根源正是分布式更新过程中的不一致。</p>\n<p>事已至此，团队不得不专门腾出精力，为数据一致性问题设计可靠方案。经过讨论，他们将问题归纳为两类：</p>\n<p><strong>第一类：可接受短期不一致，但必须保证最终一致性</strong><br />\n以零售下单为例（简化版）：订单需依次在商品服务扣库存、订单服务生成订单、交易服务生成交易单。假设生成交易单失败，就会出现库存已扣、订单已生、但交易单缺失的状态。此时只要系统能最终补全交易单，业务即可接受——这就是最终一致性。</p>\n<p><strong>第二类：必须保证实时一致性</strong><br />\n以积分兑换折扣券为例：需要先扣积分，再发折扣券。若采用最终一致性，用户可能看到积分已扣但券未到账，进而立刻投诉。此时更好的做法是：一旦后续步骤失败，立即回滚前面所有操作，并提示用户“操作失败，请重试”。这就是实时一致性。</p>\n<p>那么，针对这两类情况，具体如何实现呢？下面我们分别展开。</p>\n<h1 id=\"2-最终一致性方案\">2 最终一致性方案</h1>\n<p>对对于接受最终一致性的场景，核心思路是借助消息队列（MQ）实现跨服务的数据更新“接力”。具体流程如下：</p>\n<ol>\n<li>每个服务完成本地操作后，向 MQ 发送一条消息，触发下一个服务的处理。</li>\n<li>下游服务消费消息，完成自身操作后，继续发送消息给更下游的服务。</li>\n<li>若消费失败，消息应保留在 MQ 中，等待后续重试。</li>\n</ol>\n<p>整个调用流程如图所示：<br />\n<img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202512/2428649-20251231172011700-764051171.png\" /></p>\n<p><strong>详细步骤与异常处理如下：</strong></p>\n<table>\n<thead>\n<tr>\n<th>步骤</th>\n<th>执行内容</th>\n<th>失败应对策略</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>调用端调用 Service A</td>\n<td>直接返回失败，用户数据无影响</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Service A 将 a1 改为 a2</td>\n<td>本地事务回滚，数据恢复</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Service A 向 MQ 发送 Step2 消息</td>\n<td>发送失败则触发本地回滚</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Service A 返回成功响应给调用端</td>\n<td>无需额外处理</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Service B 消费 Step2 消息</td>\n<td>MQ 自带重试机制，无需担心</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Service B 将 b1 改为 b2</td>\n<td>本地事务回滚，消息重新投递(重新回到步骤5)</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Service B 向 MQ 发送 Step3 消息</td>\n<td>依赖 MQ 生产端重试机制</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Service B 确认消费 Step2</td>\n<td>若失败，MQ 会重新投递给其他消费者(重新回到步骤5)</td>\n</tr>\n<tr>\n<td>9</td>\n<td>Service C 消费 Step3 消息</td>\n<td>同步骤 5</td>\n</tr>\n<tr>\n<td>10</td>\n<td>Service C 将 c1 改为 c2</td>\n<td>同步骤 6</td>\n</tr>\n<tr>\n<td>11</td>\n<td>Service C 确认消费 Step3</td>\n<td>同步骤 8</td>\n</tr>\n</tbody>\n</table>\n<p>该方案本质上是利用 MQ 的消息持久化、重试和确认机制，将分布式更新拆解为多个本地事务，通过异步消息串联起来。但还需要注意两个常见问题：</p>\n<p><strong>1. 幂等性必须保证</strong><br />\n由于 MQ 的重试机制，步骤 6 和步骤 10 可能被重复执行。因此，下游服务在更新数据时，必须实现<strong>业务幂等</strong>——即同一消息多次消费，结果应与一次消费相同。</p>\n<p><strong>2. 代码复用与封装</strong><br />\n如果每个业务流程都手动实现上述逻辑，开发量会很大。实际上，MQ 相关的发送、消费、确认逻辑可以抽象为公共组件。本项目最终将这些重复代码封装成通用模块，供各业务服务调用。具体封装方法较为直接，此处不再展开。</p>\n<h1 id=\"3-实时一致性方案\">3 实时一致性方案</h1>\n<p>实时一致性其实就是常说的分布式事务。</p>\n<p>MySQL其实有一个两阶段提交的分布式事务方案MySQL XA，但是该方案存在严重的性能问题。比如，一个数据库的事务与多个数据库间的XA事务性能可能相差10倍。</p>\n<p>另外，XA的事务处理过程会长期占用锁资源，所以项目组一开始就没有考虑这个方案。而当时比较流行的方案是使用TCC模式，下面简单介绍一下。</p>\n<h1 id=\"4-tcc模式一分为三的补偿型事务\">4 TCC模式：一分为三的补偿型事务</h1>\n<p>TCC（Try-Confirm-Cancel）是一种补偿型事务方案。它将一个完整的业务接口逻辑拆解为三个独立的操作阶段：</p>\n<ol>\n<li><strong>Try</strong>：尝试执行。负责完成所有业务检查，并<strong>预留</strong>必要的资源（例如冻结积分、锁定库存）。</li>\n<li><strong>Confirm</strong>：确认执行。真正执行业务操作，使用Try阶段预留的资源，通常<strong>保证成功</strong>。</li>\n<li><strong>Cancel</strong>：取消执行。用于<strong>释放</strong>Try阶段预留的资源，进行业务回滚。</li>\n</ol>\n<p>以“积分兑换折扣券”为例，涉及“账户服务扣积分”和“营销服务发折扣券”两个操作。那么，仅“扣积分”这一个接口，就需要拆分为以下三个方法：</p>\n<pre><code class=\"language-java\">public boolean prepareMinus (BusinessActionContext businessActionContext,\n                             final String accountNo,\n                             final double amount){\n    //[校验] 账户积分余额\n    //[冻结] 积分金额\n}\npublic boolean Confirm(BusinessActionContext businessActionContext){\n    //[扣除] 账户积分余额\n    //[释放] 账户，冻结积分金额\n}\npublic boolean Cancel(BusinessActionContext businessActionContext){\n    //[回滚] 所有数据变更\n}\n</code></pre>\n<p>理，“发折扣券”接口也需要编写对应的三个方法。其成功调用的流程示意如图所示。<br />\n<img alt=\"在这里插入图片描述\" src=\"https://img2024.cnblogs.com/blog/2428649/202512/2428649-20251231172011621-1381075228.png\" /></p>\n<p>该流程中，除Cancel路径外，代表成功调用链。一旦任何环节出错，事务管理器将协调调用所有已执行服务的Cancel方法进行回滚。</p>\n<p>TCC模式将一段业务逻辑拆成三部分，实施复杂度显著增加，并需谨慎处理以下问题：</p>\n<ol>\n<li><strong>空提交</strong>：需保证Try成功，Confirm必定成功。</li>\n<li><strong>空回滚</strong>：需处理Try未执行却收到Cancel调用的情况，实现正确回滚。</li>\n<li><strong>防悬挂</strong>：需防止因网络拥堵，Cancel先于Try到达导致资源被永久锁定。</li>\n<li><strong>幂等性</strong>：所有Try、Confirm、Cancel操作都必须支持重复调用。</li>\n<li><strong>数据隔离</strong>：事务期间数据处于中间状态（如“冻结”），需设计得当，避免对其他业务逻辑造成干扰。</li>\n</ol>\n<p>可见，TCC模式实现<strong>相当繁琐</strong>，不仅业务代码量激增，还需精心处理上述各类边缘情况，开发和维护成本高，易出错。幸运的是，存在更优的替代方案，例如Seata框架提供的<strong>AT模式</strong>。</p>\n<h1 id=\"5-seata-at模式基于sql反向补偿的自动回滚\">5 Seata AT模式：基于SQL反向补偿的自动回滚</h1>\n<p>AT（Automatic Transaction）模式，即自动（分支）事务模式。其最大优点是<strong>对业务侵入极低</strong>。</p>\n<p>开发者只需做两件事：</p>\n<ul>\n<li>在全局事务的<strong>发起方</strong>方法上添加 <code>@GlobalTransactional</code> 注解。</li>\n<li>在各个参与服务的本地方法上，继续使用普通的 <code>@Transactional</code> 注解。</li>\n</ul>\n<p>Seata官网对这块介绍的非常详细，有兴趣的朋友可以看一下：<a href=\"https://seata.apache.org/zh-cn/docs/dev/mode/at-mode\" rel=\"noopener nofollow\" target=\"_blank\">Apache Seata</a>。在这里简要概括一下，其核心机制在于，Seata会<strong>自动拦截并解析</strong>业务SQL，通过生成并管理反向回滚日志，实现分布式事务的自动协调。整个过程可简要概括为三个阶段：</p>\n<p><strong>第一阶段：执行与日志记录</strong></p>\n<ol>\n<li><strong>解析SQL</strong>：拦截业务SQL，解析其操作类型、表、条件等。</li>\n<li><strong>保存前置镜像</strong>：根据解析条件查询数据，保存更新前的状态（Before Image）。</li>\n<li><strong>执行业务SQL</strong>：执行用户定义的更新操作。</li>\n<li><strong>保存后置镜像</strong>：查询更新后的数据状态（After Image）。</li>\n<li><strong>插入回滚日志</strong>：将前后镜像数据及SQL信息组成回滚日志，存入 <code>UNDO_LOG</code> 表。</li>\n<li><strong>注册与锁</strong>：向事务协调器（TC）注册分支事务，并获取相关数据的<strong>全局锁</strong>。</li>\n<li><strong>本地提交</strong>：提交业务数据更新和 <code>UNDO_LOG</code>。</li>\n<li><strong>上报结果</strong>：将本地事务提交结果<strong>上报</strong>给TC。</li>\n</ol>\n<p><strong>第二阶段：回滚（如需要）</strong><br />\n若收到TC发出的回滚指令，则：</p>\n<ol>\n<li>开启本地事务，查找对应的 <code>UNDO_LOG</code> 记录。</li>\n<li><strong>数据校验</strong>：对比 <code>UNDO_LOG</code> 中的后镜像与当前数据。若不一致（说明数据被其他事务修改），需根据策略处理。</li>\n<li><strong>生成并执行回滚SQL</strong>：根据前镜像数据，生成反向SQL执行，恢复数据。</li>\n<li><strong>提交并上报</strong>：提交本地事务，删除 <code>UNDO_LOG</code>，并向TC上报回滚结果。</li>\n</ol>\n<p><strong>第三阶段：异步清理</strong><br />\n收到TC的提交指令后，异步、批量地删除对应的 <code>UNDO_LOG</code> 记录，完成资源清理。</p>\n<h3 id=\"6-为何选择seata一个务实的工程决策\">6 为何选择Seata：一个务实的工程决策</h3>\n<p>当时，Seata虽未发布正式版，但我们项目组仍决定采用，主要基于两点现实考量：</p>\n<ol>\n<li><strong>场景可控</strong>：需要强实时一致性的业务场景<strong>占比少、频率低</strong>，影响范围有限。对于高频、高并发的场景，我们会优先与业务方沟通，采用<strong>最终一致性</strong>方案，从而规避性能风险。</li>\n<li><strong>投入产出比高</strong>：相较于TCC模式需要将每个业务逻辑“一拆三”并处理各种异常，AT模式<strong>仅需增加一个</strong><code>@GlobalTransactional</code><strong>注解</strong>，开发工作量天差地别。这种显著的效率提升，使得尝试新技术带来的风险变得可以接受。这或许也是Seata能迅速流行的原因之一。</li>\n</ol>\n<p>尽管AT模式存在一些小缺陷（如全局锁对性能的细微影响），但<strong>瑕不掩瑜</strong>，其易用性优势在大多数场景下非常突出。</p>\n<h3 id=\"7-小结缓解痛点轻装前行\">7 小结：缓解痛点，轻装前行</h3>\n<p>通过为“最终一致性”和“实时一致性”场景分别设计并落地了基于MQ的异步补偿方案与基于Seata AT模式的自动补偿方案，我们成功解决了数据不一致的核心痛点。<br />\n<strong>关键成果在于</strong>：这些方案<strong>并未给业务开发带来显著负担</strong>，也未影响项目正常推进，却极大降低了数据错误的发生概率。</p>\n<p>至此，数据一致性的痛点已得到有效缓解。接下来，我们将面对微服务架构中的另一个常见难题：<strong>服务间数据依赖复杂，导致需要编写大量冗余数据获取与组装逻辑</strong>。这个问题又该如何破解？</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2025-12-31 17:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yhup\">yihuiComeOn</a>&nbsp;\n阅读(<span id=\"post_view_count\">91</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2025 年终总结｜30岁",
      "link": "https://www.cnblogs.com/liyq666/p/19427476",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/liyq666/p/19427476\" id=\"cb_post_title_url\" title=\"发布于 2025-12-31 16:47\">\n    <span>2025 年终总结｜30岁</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        今天是2025最后一天，回顾这一年，感到的只有对未来的迷茫，我是一名前端开发，在AI的冲击以及大环境的影响下，离开了上一家公司，Gap到现在，写下这篇年终总结，算是对自己的2025年有个交代吧\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"前言\">前言</h1>\n<p>今天是2025最后一天，回顾这一年，感到的只有对未来的迷茫，我是一名前端开发，在25年之前可以说是一名很纯粹的前端，在AI的冲击以及大环境的影响下，离开了上一家公司，然后就是Gap到现在，坐在上海出租屋的电脑前，写下这篇年终总结，算是对自己的2025年有个交代吧。</p>\n<h2 id=\"回顾来时路\">回顾来时路</h2>\n<p>我出生于河南的一个农村家庭，大学学的计算机，18年毕业入行前端，在郑州拿到了第一份工作3.5K，待了大概10个月，算是起点吧，在这里接触并学习了React，很感激第一家公司，确实为我之后的工作打下了基础；</p>\n<p>第二份工作6k好像，待了8个月，然后倒闭了，无奈换到了郑州的第三家公司，在这个公司待了1年2个月，薪资是9k不到，正准备一展宏图，然后公司又倒闭了，还拖欠了差不多4个月💰，欠了我3w多的薪资，至今未拿到手。随着钱包逐渐干瘪，我知道不能在公司继续耗下去，于是拿了离职证明破釜沉舟直接来了大都市上海打拼。</p>\n<p>在郑州待了差不多三年，主要技术栈是React + Vue，做的都是C端的一些产品，做过App，wx小程序，wx公众号，web网页等，申请过软著，上架过应用商店，上架过小程序，对接过商城的支付，一路摸着石头过河，好在走过来了。</p>\n<p>20年来了上海，入职了上一家公司，薪资是14K，有奖金包，这边企业主要是做B端的产品，基本相当于从0开始了。</p>\n<p>入职后，感叹大城市的繁华，我在10号线航中路附近租了一个“蛋壳公寓🏠”房子，说是押一付一，实际是微众银行的贷款，然后20年“蛋壳”暴雷😂，当时的我面临🏠住不了，押金💰退不了，还要背上一年贷款，经历过那段的人应该知道，当时网络上各种，有的🔥房子，有的跳楼，有的拿🔪威胁不搬走。直到那时候我才发现，刚到上海就踩了一个“坑”，多亏了各路英雄的的群策群力，以及网络舆论的影响，还有政府的居中协调，最终我的结果就是贷款不用还了，但押金，只能吃哑巴亏咽了。</p>\n<p>从20年入职直到25年初，共4年7个多月，之前郑州三年我基本是不与客户直接打交道的，来到上海这边，做B端企业产品，就得跟客户打交道，在这期间，真的很感谢🙏我的领导，从最初的青涩到逐渐自然，我确实成长了很多，下面举一些面对客户的例子：</p>\n<ol>\n<li>首先态度要有，（面对反馈要及时响应）实际做是后面的事；</li>\n<li>需求变更问题，（不要怕争吵）态度也是要有，不要啥都接受；</li>\n</ol>\n<p>多的就不再多言。这份工作主要是企业定制化开发，修修补补是常态，也有从0-1的项目，算是进一步沉淀了技术吧。时间来到24年，有一个项目需要出差，出差山东，刚开始说是3个月，没想到一直出差了一整年，直到离职，项目也还没结束。</p>\n<h2 id=\"被裁\">被裁</h2>\n<p>3月份，还在山东出差加班的我，收到了公司HR的消息，沟通组织架构调整事宜，我只能选择接受，于是3月底，离开出差一年的潍坊，回到了上海，拿了离职证明，离开了我工作近5年的公司，由于之前一年都是做的修修补补，对于吃饭的技能感觉有点生疏，于是我选择沉淀一段时间，正好也休息一下长期加班疲惫的身体。</p>\n<h2 id=\"找工作\">找工作</h2>\n<p>4-5月眨眼过去，从6月份，我开始逐渐的整简历，投简历，邀面试，这时才发现，市场好像变化了，不再问大量的“八股文”，而是转而问场景题，从项目整体思维出发面试。</p>\n<p>记得当时有一位面试官问我，工作7年，你最拿得出手的项目是什么，有从0-1搭建过项目吗？我挑了最近几年的项目中一个做了回答，因为还是B端的企业内部系统，技术上没有C端那些更亮眼的技术，也没有所谓的高并发什么的，最后当然挂了。</p>\n<p>之前都是用Umi，Dva、react-create-app、Vue-cli、Antd、Element Ui等现成的脚手架及库搭建项目，B端项目讲究敏捷开发，重业务，轻页面，说句不好听的就是“能用就行、好用就行”，于是结束面试后我开始萌生一个想法，从0-1去搭建一个项目。</p>\n<p>6月份Boss上沟通了几百个，投了几十简历，面试了几个，比例几乎是10:1:1，结果很扎心，于是我一边投简历，一边写代码，不能让自己闲下来，不然容易乱想，就这样靠着这份信念，我从0-1搭建了一个项目，完善了搭建的历程<br />\n<a href=\"https://juejin.cn/post/7519864446069489704\" rel=\"noopener nofollow\" target=\"_blank\"># 从零搭建 react 模板 【React 18 + Webpack 5 + Antd 5 + React-Router 6 】</a>，</p>\n<p>7-8月份我拿着这份从0-1搭建的项目去面试，比之6月份好像好了点，但又好的有限，期间又完善了权限控制<br />\n<a href=\"https://juejin.cn/post/7525733315133341706\" rel=\"noopener nofollow\" target=\"_blank\"># React 18 全局错误捕获 + React-router 6 动态权限路由</a>，又遇到一个面试官，点评我的项目，纯静态的，没错，就是纯静态页面，模拟数据做的，最后还是挂了。于是我想着是不是可以加上后端，正好之前也接触过NodeJs，于是又是框框学，最后选了Express，打算做一个全栈管理系统，因为我对这种系统很熟悉，包括布局、页面、业务都熟悉。</p>\n<p>来到金九银十了，继续更新简历，继续投，发现岗位确实多了一些，面试也确实多了一些，但还是没有结果，我开始思考哪里的原因，可能是大专毕业，学历低，外加Gap5个多月了，也有可能是我要求高了点，因为上一家5年前入职时14k，离职也是14k，算上奖金💰一年大概有20w，新工作想找个20k以上的，因为即将临近30，后面更难，程序员30岁，35岁都是一个坎，随着一直找不到💼，开始有点否定自己，我发觉不能这样下去了，于是就继续搭建后端Node系统，好不让自己闲下来。</p>\n<p>十一回老家，装作没事人一样，在家陪了父母七八天，家里人都不知道我失业了，父母都是60多的年纪，老爸是做建筑工的，60多还爬高上低，老妈身体不好，在家串那个几厘💰一串的手串，不让她干还不愿意，说是给我攒老婆本，我三番五次拿不结婚不找对象来威胁她好让她放弃一坐低头几个小时的手工劳作，她总是美其名曰，这是我的一份“工作”。我又怎么忍心告诉他们，我失业了呢，难道让他们跟着我一起着急，一起焦虑吗，我做不到，我想大多数人都跟我一样做不到，本来就是在外地工作的“游子”，报喜不报忧已是最基本的了，于是假期结束我毅然返回上海，像“没事人”一样。</p>\n<p>10月底，我终于做出了第一版开源<a href=\"https://wladmin.cn\" rel=\"noopener nofollow\" target=\"_blank\">全栈管理系统</a>，包含前端后端，登录，权限控制，发布在了<a href=\"https://gitee.com/lyqjob/project-root\" rel=\"noopener nofollow\" target=\"_blank\">Gitee仓库</a>，这个系统参考了好几个开源管理系统，借鉴他们的页面，参考他们的实现架构，既然做出来了这个系统，就要有个名字。</p>\n<p>我给他起名叫<a href=\"https://www.wladmin.cn\" rel=\"noopener nofollow\" target=\"_blank\">WlAdmin</a>，译名“未来”不是碰瓷“蔚来”,是我对其抱有期待，期待我的“未来”，这是一个全栈管理系统，采用React + Antd + NodeJs + MySQL + Redis构建。</p>\n<p>11月，这个月应该是我最累的的一个月，随着系统初版的上线，要真正达到开源可用的企业级管理系统的功能，还有很长一段路要走，在10月底我接触到了<strong>AI编程</strong>，说实话真的很强大，赶上了字节的“Trae CN末班车”，当时还能免费用Claude Code，我想要更快的完善这个系统，于是开始在AI的帮助下，慢慢完善系统，没想到刚好用几天，突然AI变得很“笨”，网上一查才知道，国外禁止Claude Code在国内使用了，于是又下载了Cursor，免费14天，于是开始框框改造，借助AI和网上的一些架构知识，管理系统逐渐完善，作为一个前端，去学习了解后端，才发现从整体架构一个系统，真的挺不容易的，最开始我引以为豪的就是逻辑思维，知道真正从0-1搭建起来<a href=\"https://juejin.cn/post/7573912365910442026\" rel=\"noopener nofollow\" target=\"_blank\">全栈管理系统：Node.js + Express + MySQL + React + Antd</a>，才发现后端真🐮🍺。</p>\n<p>随着投简历，这个项目也算推广出去了，是有一定的人访问的，为了不影响第二天的“面试官”访问，所以线上网站不能出大的问题，本地开发好好的，部署到服务器上就是各种出问题，于是经常性的搞到一两点，搞得心力交瘁。在群里推广时有人问我“<strong>你做这个项目盈利吗，有价值吗？当今AI盛行，还用Express这种老掉牙的东西</strong>”，我竟无法反驳。11月简历投的都较其他月少了很多，当然依然是没有结果，当时一度想放弃，最后才发现，投入几个月的时间精力静下来做一个系统，一坐一整天那种，投入这么大的成本，就这么放弃有点可惜。</p>\n<p>12月，随着Gap9个月的⏰继续往前走，11月简历也都石沉大海，虽然有的进了“二面”，但依然没有结果，这个时候说不焦虑是假的，每个月上海的租金是1800，算上吃喝一个月的成本💰大概3000，也确实有点扛不动了。</p>\n<p>继续完善系统，加上了Docker部署，Docker用起来才发现真的很香，本地构建，服务器部署，当时是用了两个docker-compose.yml，一个用来启动MySQL和Redis，一个用来启动后端服务（这导致经常性一重启就无法连接数据库，之前搞到凌晨的罪魁祸首绝对有它，前几天改为了只有一个docker-compose.yml）。当时掘金网站里有很多推Monorepo架构的文章，仔细阅读发现这个确实是好东西，于是12月初就全面重构了整个系统，改为Monorepo + Turbo架构的全栈管理系统，启动、构建确实比之前快了很多，项目体积我确实没仔细看，因为这时只有两个应用，前端React，以及后端Node，后面我又采用<strong>React Native + Expo + TypeScript</strong> 构建扩展了<a href=\"https://expo.dev/accounts/liyq/projects/app-rn-ts/builds/baa8d23c-208e-4af9-8bff-6123d872cf63\" rel=\"noopener nofollow\" target=\"_blank\">App</a>以及使用<strong>Next.js + Tailwind + TypeScript</strong>构建了支持SSR以及SEO优化的<a href=\"https://www.wladmin.cn\" rel=\"noopener nofollow\" target=\"_blank\">WlAdmin｜Doc</a>，进一步扩展了知识面，而不只是停留在简历上的熟悉***，现在可惜12月份简历全都石沉大海</p>\n<h2 id=\"30岁\">30岁</h2>\n<p>上周迎来了30岁生日🎂，都说“<strong>三十而立</strong>”，可我没车没房没对象，新时代的“三无”人员😑。20年刚到上海时，Boss上都是消息，虽然大多都是“<strong>外包</strong>”，现如今，简历不是已读不回，就是没有下文，大环境愈发低迷，虽然花费几个月做出来了这个<a href=\"https://wladmin.cn/\" rel=\"noopener nofollow\" target=\"_blank\">企业级全栈管理系统</a>，但好像正如之前群里说的，“没什么太大的价值”，也就简历能添一笔。<strong>AI</strong>已经能完成80%的工作，作为一个前端，实际使用过AI，才发现AI真的已经把前端拍进了泥土里。这一年，说句不好听的，一事无成🤣，也挺失败的。系统已经完善的差不多，<strong>Web端</strong>、<strong>服务端</strong>、<strong>App端</strong>、<strong>Doc网站</strong>，差不多可以停下来思考一下未来的路了。</p>\n<h2 id=\"未来\">未来</h2>\n<p>马上2026就要到了，希望新的一年，能够迎来一份“未来“，也祝愿看到这里的朋友新的一年能收获丰硕的果实</p>\n<h2 id=\"-致谢\">🙏 致谢</h2>\n<p>感谢阅读到这里的朋友🙏，在这里厚着脸皮希望大家能够去访问一下我的<a href=\"https://wladmin.cn\" rel=\"noopener nofollow\" target=\"_blank\">开源管理系统</a>，可以去<a href=\"https://gitee.com/lyqjob/project-root\" rel=\"noopener nofollow\" target=\"_blank\">仓库</a>克隆下来耍耍，欢迎👏各位大佬提出<a href=\"https://gitee.com/lyqjob/project-root/issues\" rel=\"noopener nofollow\" target=\"_blank\">意见</a>，有问题也可以发我邮箱📮<a href=\"mailto:lyqjob@yeah.net\" rel=\"noopener nofollow\" target=\"_blank\">lyqjob@yeah.net</a>，再次感谢</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2025-12-31 16:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/liyq666\">香煎藕饼</a>&nbsp;\n阅读(<span id=\"post_view_count\">1150</span>)&nbsp;\n评论(<span id=\"post_comment_count\">33</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "论文解读：One-shot Entropy Minimization",
      "link": "https://www.cnblogs.com/qizhou/p/19426973",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/qizhou/p/19426973\" id=\"cb_post_title_url\" title=\"发布于 2025-12-31 15:36\">\n    <span>论文解读：One-shot Entropy Minimization</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>一篇还未发表的论文，但做了大量实验对熵最小化技巧提升模型推理能力进行了探索。本文训练了13440个大型语言模型，发现熵最小化（EM）只需要一个未标记的数据和10步优化，性能提升就比<strong>RL</strong>还强。基于两个直接而简单的假设：</p>\n<ul>\n<li>\n<p>生成大型语言模型的采样过程本质上是随机的。</p>\n</li>\n<li>\n<p>正确答案的熵通常低于错误答案。</p>\n</li>\n</ul>\n<p>EM和RL有<strong>共同目标</strong>：在不添加新知识的情况下释放预训练模型的潜在潜力，都依赖于所谓“token重评级”。</p>\n<p>原文网址：<a href=\"https://arxiv.org/abs/2505.20282v4\" rel=\"noopener nofollow\" target=\"_blank\">https://arxiv.org/abs/2505.20282v4</a></p>\n<h1>方法</h1>\n<p>给定prompt <span class=\"math\">$x$</span>，生成序列<span class=\"math\">$y$</span>，最小化生成序列token级别的预测熵：</p>\n<p style=\"text-align: center;\"><span class=\"math\">$\\displaystyle L_{\\mathrm{EM}} = \\frac{1}{|y|} \\sum_{t = 1}^{|y|} H_t&nbsp;&nbsp;$</span></p>\n<p style=\"text-align: center;\"><span class=\"math\">$\\displaystyle H_t = -\\sum_{v \\in V} p_\\theta(v \\mid y_{&lt;t}, x)\\,\\log p_\\theta(v \\mid y_{&lt;t}, x)$</span></p>\n<p>训练对单个样本进行，从未标注数据中筛选（2.2节）：模型在多次采样下表现出较高的 pass@k 方差，从而对“熵”更敏感，提供更强的<strong>熵梯度</strong>信号。所谓pass@k 方差就是大模型针对同一个数据生成<span class=\"math\">$k$</span>段内容，计算<span class=\"math\">$k$</span>个内容正确与否的方差。</p>\n<h1>实验</h1>\n<p><strong>训练设置：</strong>针对特定样本，每次生成64段推理内容（即训练批量为64），用以上最小熵损失微调大模型10次。预测温度设置为0.5，学习率固定为<span class=\"math\">$2\\times 10^{-5}$</span>。</p>\n<p>表1：各种推理模型与EM的对比。</p>\n<p>图1：用了EM之后，模型生成token 的概率分布。EM使分布更右偏。</p>\n<p>图2：EM损失和评估分数随着训练的变化曲线。</p>\n<p>图3/4：不同温度对性能的影响。</p>\n<p>图5：EM和RL先后执行，性能随迭代的变化。发现RL之后应用EM会导致性能下降，而EM之后RL性能会提升。这表明EM加剧了RL引入的分配扭曲，强化了RL的“对齐税”。</p>\n<p>表2：多样本的EM与单样本的EM对比，看出多样本也没有多大优势。</p>\n<p>图6：不同学习率对推理性能的影响。</p>\n<h1>讨论与见解</h1>\n<p>单次EM增益的上限由基础模型的内在推理能力决定。在相对较弱的LLaMA-3.1-8B上，单次EM的平均准确率仅提高到24.3%，勉强超过23.6%的基线。这表明，当底层模型缺乏足够的推理能力时，最小EM优化无法完全弥补其不足。</p>\n<p>RL根据外部真实奖励调整令牌概率。这通常会促进以前低概率（尾部）代币的相对排名。即使在重新排序后，这些代币也往往占据概率分布的中间位置，需要在采样过程中选择更高的温度。因此，RL训练的模型表现出相反的趋势：性能随着采样温度的升高而提高，如图4所示。</p>\n<p>在大多数场景中，尤其是在SFT和训练最少的RL环境中，EM显著地修剪了冗余的决策路径，稳定了关键预测，验证了其作为最小但强大的优化策略的有效性和通用性。</p>\n<p>&nbsp;</p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2025-12-31 15:36</span>&nbsp;\n<a href=\"https://www.cnblogs.com/qizhou\">颀周</a>&nbsp;\n阅读(<span id=\"post_view_count\">89</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "2025再见，码农当自强，47岁尚能饭否",
      "link": "https://www.cnblogs.com/datacool/p/19430534",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/datacool/p/19430534\" id=\"cb_post_title_url\" title=\"发布于 2026-01-01 19:22\">\n    <span>2025再见，码农当自强，47岁尚能饭否</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        2025年度总结，令我啼笑皆非的2025结束了。\n    </div>\n<div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong><span style=\"font-size: 18px;\">2025注定是难忘的一年。2025年1月1号，是我结束飘洋过海的生活从太平洋岛国萨摩亚回国的第一天。我以为迎接的将是全新的人生。打开公众号文章劈头盖脸的都是负面的新闻，还有各种平台都有人在吐槽，诉苦。我明白了最难的2025它来了。</span></strong></p>\n<p>&nbsp;</p>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/124467/202601/124467-20260101175023459-602426282.png\" /></p>\n<p>&nbsp;</p>\n<p>好在坚强的我，迎来了2026。没想到以前看到一位博主说的：<span style=\"font-size: 18px;\"><strong>宠辱不惊，闲看庭前花开花落；去留无意，漫随天外云卷云舒</strong></span>。这看来一辈子都难做到了。</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n</blockquote>\n<h1>正文&nbsp;&nbsp;</h1>\n<p><span>我想总结是要做的。</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>《啼笑姻缘》</span><br /><span>演唱：陈小春</span><br /><span>作曲：陶昌廷</span><br /><span>填词：黄伟文</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>苦恋三千年 分手皆一念</span><br /><span>匆匆只在半生间</span><br /><span>谁管烽火连天 嫣红姹紫</span><br /><span>只想一贯真心 相见</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>纵使不相见 鲜血比水更甜</span><br /><span>一生不配做情人</span><br /><span>你生来这么美 只看一眼十万个心碎</span><br /><span>宁愿不爱 我自劳不获</span><br /><span>憎相知 晚一点</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>却怕一天 一切不再重要</span><br /><span>那时追悔 可算迟</span><br /><span>和你凄风苦雨 和你披星戴月</span><br /><span>任你呼天抢地 我也不退</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>爱似黄金 恨似钨丝</span><br /><span>就恨情难尽 爱可熔掉恨</span><br /><span>我本心上 无情的人</span><br /><span>却变成了 伤心的人</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>为你假意当真 为你献上灵魂</span><br /><span>但最伤心的人 还笑说不要紧</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>赐我祝福的壮举 请你不用担忧我会不争气</span><br /><span>没有心 痛便要别离 很珍惜我的骨气</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>纵使不相见 鲜血比水更甜</span><br /><span>一生不配做情人</span><br /><span>你生来这么美 只看一眼十万个心碎</span><br /><span>宁愿不爱 我自劳不获</span><br /><span>憎相知 晚一点</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>却怕一天 一切不再重要</span><br /><span>那时追悔 可算迟</span><br /><span>和你凄风苦雨 和你披星戴月</span><br /><span>任你呼天抢地 我也不退</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>爱似黄金 恨似钨丝</span><br /><span>就恨情难尽 爱可熔掉恨</span><br /><span>我本心上 无情的人</span><br /><span>却变成了 伤心的人</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>为你假意当真 为你献上灵魂</span><br /><span>但最伤心的人 还笑说不要紧</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>赐我祝福的壮举 请你不用担忧我会不争气</span><br /><span>没有心 痛便要别离 很珍惜我的骨气</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>相恋 苦恋 依恋 姻缘</span><br /><span>若注定这就叫缘</span><br /><span>这循环 何时能完</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>和你凄风苦雨 和你披星戴月</span><br /><span>任你呼天抢地 我也不退</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>爱似黄金 恨似钨丝</span><br /><span>就恨情难尽 爱可熔掉恨</span><br /><span>我本心上 无情的人</span><br /><span>却变成了 伤心的人</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>为你假意当真 为你献上灵魂</span><br /><span>但最伤心的人 还笑说不要紧</span></p>\n<p>&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span>赐我祝福的壮举 请你不用担忧我会不争气</span><br /><span>没有心 痛便要别离 很珍惜我的骨气</span></p>\n<p class=\"ds-markdown-paragraph\">&nbsp;</p>\n<p class=\"ds-markdown-paragraph\"><span><span style=\"font-size: 18px;\">我的程序人生让我啼笑皆非；47岁大龄还不能躺平，2个孩子在读初中，家里房贷还没还完。2025-03-07结束了在成都近3个月的外包，做的是一个涉密的项目，不知道客户是谁，用户场景是什么。理解需求比较难，所以就做不久了。刚开始任务还很多，狂做了2个月，慢慢变得没什么任务，主动要任务也没有，经常要找别的同事蹭任务。当时正是金3银4的季节。于是想自降身价回重庆主城找个工作。没想到我这个决定害得我经历了半年多的失业。意向中的工作没搞定，新工作一直没找到。这期间4月份去了嘉兴一个做工厂的公司同时也有上位机业务的，做了3天，一看不签合同，除了入职那天录了个指纹之外，其他啥手续都没有。所以就跑了。5月初找以前同事介绍一个去扬州驻场开发的工作，也是去了9天，把自己的第一个业务作顺的时候，上线了还不提签合同的事，于是心又慌了。因为多年不见，也对前同事不够信任，然后一朋友打电话说要合作开发一套洗浴软件，他运营我开发，他资助我2年每月提供基本的生活费；做起来就继续。做不好就转。然后吭哧吭哧苦干了3个月。来说说6月的事，boss上一个上海的韩总，说可以和我谈谈居家远程工作的细节。他说给6K，如果去上海每天补助300，提供租房。我先在柳州的中车的中控项目做了2个星期，然后6月初去了上海。公司给租了房，我每天乘坐轮渡从黄浦江对面的塘桥去外滩的久事大厦上班。做的是JAVA开发，阿里投资的人力窝项目，微服务，JAVA并不是很精通，心里又慌了。结果上了9天班，甲方提出换人。所以我又一次提桶跑路回家。时间来到9月，那个洗浴软件只完成了一大半。这时鸡血的剧情来了，我那个合作伙伴迎来了至暗时刻：他感情受挫，被小3骗光了钱，陷入了低谷，没钱继续了。久久没有稳定下来，我一下更慌了。时间来到9月底，又有外包公司联系我，说有个数据迁移的工作机会。这一干就是3个月，前几天甲方说明年人员要裁剪。</span>前几天我发了个朋友圈，打算失业了这次就转身做独立开发者。你看：<img alt=\"微信图片_20251230102937_59_8\" src=\"https://img2024.cnblogs.com/blog/124467/202601/124467-20260101191417734-591032732.png\" /></span></p>\n<p>&nbsp;</p>\n<p><img alt=\"微信图片_20260101185504_64_8\" src=\"https://img2024.cnblogs.com/blog/124467/202601/124467-20260101191457746-1335682248.jpg\" /></p>\n<p>&nbsp;</p>\n<p><img alt=\"微信图片_20260101185505_65_8\" src=\"https://img2024.cnblogs.com/blog/124467/202601/124467-20260101191520009-1689318354.jpg\" /></p>\n<p>&nbsp;</p>\n<p>还有个gif不知道怎么传不上来。反正是一种思考。<span style=\"font-size: 18px;\">现在结果下来了明年继续干甲方的活。今天听了一个广播说是阿Q才是人间清醒的。我想也是的，现实很骨感，那我就精神上胜利。好吧，总结完毕，祝大家越来越好。</span></p>\n<p class=\"ds-markdown-paragraph\">&nbsp;</p>\n<p class=\"ds-markdown-paragraph\">&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n<div id=\"MySignature\">\n    <div>\n    <p>作者：<a href=\"https://www.cnblogs.com/datacool/\" target=\"_blank\">数据酷软件</a></p>\n    <p>出处：<a href=\"https://www.cnblogs.com/datacool/p/19430534\" target=\"_blank\">https://www.cnblogs.com/datacool/p/19430534</a></p>\n    <p>关于作者：20年编程从业经验，持续关注工业自动化</p>\n    <p>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明。</p>\n    <p>联系方式: qq:71008973;wx:6857740733</p>\n    <p>基于人脸识别的考勤系统 地址: https://gitee.com/afeng124/viewface_attendance_ext </p>\n    <p>自己开发安卓应用框架 地址: https://gitee.com/afeng124/android-app-frame</p>\n    <p>WPOS(warehouse+pos) 后台演示地址: http://47.239.106.75:8080/</p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-01 19:22</span>&nbsp;\n<a href=\"https://www.cnblogs.com/datacool\">数据酷软件</a>&nbsp;\n阅读(<span id=\"post_view_count\">39</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Ruoyi框架 | 扩展部门数据权限实现",
      "link": "https://www.cnblogs.com/echohye/p/19430439",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/echohye/p/19430439\" id=\"cb_post_title_url\" title=\"发布于 2026-01-01 17:51\">\n    <span>Ruoyi框架 | 扩展部门数据权限实现</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"一背景与目标\">一、背景与目标</h2>\n<p>在若依框架原有 <code>DataScope</code> 的基础上，实现一套<strong>独立的、基于部门层级的数据权限过滤机制</strong>，用于按组织结构灵活控制数据可见范围。</p>\n<h3 id=\"设计目标\">设计目标</h3>\n<ul>\n<li>\n<p>不依赖角色、不判断是否管理员</p>\n</li>\n<li>\n<p>通过注解参数动态控制数据范围</p>\n</li>\n<li>\n<p>支持：</p>\n<ul>\n<li>是否包含本部门</li>\n<li>向上查询 N 级部门</li>\n<li>向下查询 N 级部门 / 所有子部门</li>\n</ul>\n</li>\n<li>\n<p>与若依原有 <code>BaseEntity + params + MyBatis XML</code> 机制完全兼容</p>\n</li>\n</ul>\n<hr />\n<h2 id=\"二核心设计思路\">二、核心设计思路</h2>\n<h3 id=\"1-技术方案\">1. 技术方案</h3>\n<ul>\n<li>\n<p>使用 <strong>AOP + 自定义注解</strong> 拦截查询方法</p>\n</li>\n<li>\n<p>在方法执行前：</p>\n<ul>\n<li>根据当前用户部门 ID</li>\n<li>动态拼接部门过滤 SQL</li>\n<li>注入到 <code>BaseEntity.params.dataScope</code></li>\n</ul>\n</li>\n<li>\n<p>Mapper XML 中通过 <code>${params.dataScope}</code> 拼接 WHERE 条件</p>\n</li>\n</ul>\n<h3 id=\"2-依赖表结构sys_dept\">2. 依赖表结构（sys_dept）</h3>\n<pre><code class=\"language-text\">dept_id     部门ID\nparent_id   父部门ID\nancestors   祖先路径，如：0,1,3,10\n</code></pre>\n<hr />\n<h2 id=\"三自定义注解extendeddatascope\">三、自定义注解：ExtendedDataScope</h2>\n<pre><code class=\"language-java\">@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface ExtendedDataScope {\n\n    // 部门表别名（必填）\n    String deptAlias() default \"\";\n\n    // 用户表别名（预留扩展）\n    String userAlias() default \"\";\n\n    // 权限类型（当前主要使用 dept）\n    String type() default \"dept\";\n\n    // 向上级部门层数（0 = 不包含）\n    int upLevel() default 0;\n\n    // 向下级部门层数（0 = 不包含，999 = 所有子级）\n    int downLevel() default 0;\n\n    // 是否包含本部门\n    boolean includeSelf() default true;\n}\n</code></pre>\n<hr />\n<h2 id=\"四aop-实现要点\">四、AOP 实现要点</h2>\n<h3 id=\"1-切面职责\">1. 切面职责</h3>\n<ul>\n<li>拦截所有标注 <code>@ExtendedDataScope</code> 的方法</li>\n<li>清空历史 dataScope，防止 SQL 注入</li>\n<li>生成部门层级 SQL</li>\n<li>写入 <code>BaseEntity.params.dataScope</code></li>\n</ul>\n<h3 id=\"2-核心处理流程\">2. 核心处理流程</h3>\n<pre><code class=\"language-text\">@Before\n  ├─ clearDataScope()\n  ├─ 获取当前用户\n  ├─ 读取注解参数\n  ├─ 构建部门范围 SQL\n  └─ 写入 params.dataScope\n</code></pre>\n<details>\n点击查看代码\n<pre><code>@Aspect\n@Component\npublic class ExtendedDataScopeAspect {\n\n    @Autowired\n    private SysDeptMapper deptMapper;\n\n    /**\n     * 参数 key（和若依一致）\n     */\n    public static final String DATA_SCOPE = \"dataScope\";\n\n    @Before(\"@annotation(dataScope)\")\n    public void doBefore(JoinPoint joinPoint, ExtendedDataScope dataScope) {\n        clearDataScope(joinPoint);\n        handleDataScope(joinPoint, dataScope);\n    }\n\n    private void handleDataScope(JoinPoint joinPoint, ExtendedDataScope dataScope) {\n        LoginUser loginUser = SecurityUtils.getLoginUser();\n        if (loginUser == null) {\n            return;\n        }\n\n        String deptAlias = dataScope.deptAlias();\n        if (StringUtils.isBlank(deptAlias)) {\n            return;\n        }\n\n        String sql = buildDeptScopeSql(loginUser.getDeptId(), deptAlias, dataScope);\n        if (StringUtils.isBlank(sql)) {\n            return;\n        }\n\n        Object params = joinPoint.getArgs()[0];\n        if (params instanceof BaseEntity) {\n            BaseEntity baseEntity = (BaseEntity) params;\n            baseEntity.getParams().put(DATA_SCOPE, \" AND (\" + sql + \")\");\n        }\n    }\n\n    /**\n     * 构建部门层级 SQL\n     */\n    private String buildDeptScopeSql(Long deptId, String deptAlias, ExtendedDataScope scope) {\n        List&lt;String&gt; conditions = new ArrayList&lt;&gt;();\n\n        /* ========== 本部门 ========== */\n        if (scope.includeSelf()) {\n            conditions.add(deptAlias + \".dept_id = \" + deptId);\n        }\n\n        /* ========== 向上 ========== */\n        if (scope.upLevel() &gt; 0) {\n            // ancestors 形如：0,1,3,10\n            // 向上 N 级：取 ancestors 中倒数 N 位\n            SysDept sysDept = deptMapper.selectDeptById(deptId);\n            String ancestors = sysDept.getAncestors();\n            if (ancestors != null) {\n                conditions.add(buildUpDeptSql(deptAlias, ancestors, scope.upLevel()));\n            }\n\n        }\n\n        /* ========== 向下 ========== */\n        if (scope.downLevel() &gt; 0) {\n            if (scope.downLevel() &gt;= 999) {\n                // 所有子级\n                conditions.add(\n                        deptAlias + \".dept_id IN (\" +\n                                \"SELECT dept_id FROM sys_dept \" +\n                                \"WHERE find_in_set(\" + deptId + \", ancestors)\" +\n                                \")\"\n                );\n            } else {\n                conditions.add(buildDownDeptSql(deptAlias, deptId, scope.downLevel()));\n            }\n        }\n\n        return String.join(\" OR \", conditions);\n    }\n\n    /**\n     * 向上 N 级部门\n     */\n    private String buildUpDeptSql(String deptAlias, String ancestors, int upLevel) {\n        // 使用子查询，取 ancestors 中的上级\n        return \"find_in_set(\" + deptAlias + \".dept_id,\" +\n                \" SUBSTRING_INDEX('\" + ancestors + \"', ',', -\" + upLevel + \") \" +\n                \")\";\n    }\n\n    /**\n     * 向下 N 级部门\n     */\n    private String buildDownDeptSql(String deptAlias, Long deptId, int downLevel) {\n        // ancestors 深度控制（当前 depth + N）\n        return deptAlias + \".dept_id IN (\" +\n                \" SELECT d.dept_id FROM sys_dept d \" +\n                \" WHERE find_in_set(\" + deptId + \", d.ancestors) \" +\n                \" AND (LENGTH(d.ancestors) - LENGTH(REPLACE(d.ancestors, ',', ''))) &lt;= \" +\n                \"     ( \" +\n                \"       SELECT (LENGTH(ancestors) - LENGTH(REPLACE(ancestors, ',', ''))) + \" + downLevel +\n                \"       FROM sys_dept WHERE dept_id = \" + deptId +\n                \"     )\" +\n                \")\";\n    }\n\n    /**\n     * 清空 dataScope，防止 SQL 注入\n     */\n    private void clearDataScope(JoinPoint joinPoint) {\n        Object params = joinPoint.getArgs()[0];\n        if (params instanceof BaseEntity) {\n            ((BaseEntity) params).getParams().put(DATA_SCOPE, \"\");\n        }\n    }\n}\n\n</code></pre>\n</details>\n<hr />\n<h2 id=\"五部门层级-sql-构建规则\">五、部门层级 SQL 构建规则</h2>\n<h3 id=\"1-本部门\">1. 本部门</h3>\n<pre><code class=\"language-sql\">d.dept_id = {currentDeptId}\n</code></pre>\n<p>由 <code>includeSelf = true</code> 控制</p>\n<hr />\n<h3 id=\"2-向上-n-级部门uplevel\">2. 向上 N 级部门（upLevel）</h3>\n<p>原理：</p>\n<ul>\n<li>利用 <code>ancestors</code> 字段</li>\n<li>从 ancestors 中向前截取 N 个父级</li>\n</ul>\n<p>示意 SQL：</p>\n<pre><code class=\"language-sql\">d.dept_id IN (\n  SELECT SUBSTRING_INDEX(\n    SUBSTRING_INDEX(ancestors, ',', -(N + 1)), ',', 1\n  )\n  FROM sys_dept\n  WHERE dept_id = 当前部门ID\n)\n</code></pre>\n<hr />\n<h3 id=\"3-向下-n-级部门downlevel\">3. 向下 N 级部门（downLevel）</h3>\n<h4 id=\"31-所有子级downlevel--999\">3.1 所有子级（downLevel = 999）</h4>\n<pre><code class=\"language-sql\">d.dept_id IN (\n  SELECT dept_id FROM sys_dept\n  WHERE find_in_set(当前部门ID, ancestors)\n)\n</code></pre>\n<h4 id=\"32-限定层级子部门\">3.2 限定层级子部门</h4>\n<p>思路：</p>\n<ul>\n<li>计算 ancestors 的层级深度（逗号个数）</li>\n<li>控制最大深度 = 当前深度 + N</li>\n</ul>\n<pre><code class=\"language-sql\">d.dept_id IN (\n  SELECT d.dept_id\n  FROM sys_dept d\n  WHERE find_in_set(当前部门ID, d.ancestors)\n    AND 层级深度(d) &lt;= 当前层级 + N\n)\n</code></pre>\n<hr />\n<h2 id=\"六mapper-xml-使用方式\">六、Mapper XML 使用方式</h2>\n<pre><code class=\"language-xml\">&lt;select id=\"selectList\" resultType=\"xxx\"&gt;\n  SELECT *\n  FROM biz_table t\n  LEFT JOIN sys_dept d ON t.dept_id = d.dept_id\n  &lt;where&gt;\n    1 = 1\n    ${params.dataScope}\n  &lt;/where&gt;\n&lt;/select&gt;\n</code></pre>\n<p>说明：</p>\n<ul>\n<li><code>${params.dataScope}</code> 必须保留</li>\n<li>AOP 动态注入 <code>AND ( ... )</code></li>\n</ul>\n<hr />\n<h2 id=\"七使用示例\">七、使用示例</h2>\n<pre><code class=\"language-java\">@ExtendedDataScope(\n    deptAlias = \"d\",\n    includeSelf = true,\n    upLevel = 1,\n    downLevel = 2\n)\npublic List&lt;SysDept&gt; selectDeptList(SysDept dept)\n{\n    return deptMapper.selectDeptList(dept);\n}\n</code></pre>\n<h3 id=\"含义说明\">含义说明</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>includeSelf</td>\n<td>包含本部门</td>\n</tr>\n<tr>\n<td>upLevel=1</td>\n<td>包含上一级部门</td>\n</tr>\n<tr>\n<td>downLevel=2</td>\n<td>包含下两级部门</td>\n</tr>\n<tr>\n<td>downLevel=999</td>\n<td>包含所有子部门</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"八方案特点总结\">八、方案特点总结</h2>\n<ul>\n<li>✅ 与若依原生 DataScope 解耦</li>\n<li>✅ 仅依赖部门层级，不依赖角色权限</li>\n<li>✅ 控制粒度细，适合复杂组织结构</li>\n<li>✅ 非侵入式，Mapper 无需改动</li>\n<li>✅ 特别适合安全监管 / GIS / 组织树场景</li>\n</ul>\n<hr />\n<h2 id=\"九可扩展方向后续优化\">九、可扩展方向（后续优化）</h2>\n<ul>\n<li>使用 MySQL 8 / PostgreSQL 的 <code>WITH RECURSIVE</code> 优化层级查询</li>\n<li>部门层级缓存（Redis）减少子查询</li>\n<li>扩展到：部门 + 用户混合数据权限</li>\n<li>支持多部门归属（兼职部门）</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-01 17:51</span>&nbsp;\n<a href=\"https://www.cnblogs.com/echohye\">槑孒</a>&nbsp;\n阅读(<span id=\"post_view_count\">76</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "吴恩达深度学习课程四：计算机视觉 第四周：卷积网络应用 课后习题和代码实践",
      "link": "https://www.cnblogs.com/Goblinscholar/p/19430429",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Goblinscholar/p/19430429\" id=\"cb_post_title_url\" title=\"发布于 2026-01-01 17:41\">\n    <span>吴恩达深度学习课程四：计算机视觉 第四周：卷积网络应用 课后习题和代码实践</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>此分类用于记录吴恩达深度学习课程的学习笔记。<br />\n课程相关信息链接如下：</p>\n<ol>\n<li>原课程视频链接：<a href=\"https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&amp;from_spmid=playlist.playlist-detail.0.0&amp;is_story_h5=false&amp;mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1713085655&amp;unique_k=DfBgvFW&amp;up_id=8654113&amp;vd_source=e035e9878d32f414b4354b839a4c31a4\" rel=\"noopener nofollow\" target=\"_blank\">[双语字幕]吴恩达深度学习deeplearning.ai</a></li>\n<li>github课程资料，含课件与笔记:<a href=\"https://github.com/robbertliu/deeplearning.ai-andrewNG\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习教学资料</a></li>\n<li>课程配套练习（中英）与答案：<a href=\"https://blog.csdn.net/u013733326/article/details/79827273\" rel=\"noopener nofollow\" target=\"_blank\">吴恩达深度学习课后习题与答案</a></li>\n</ol>\n<p>本篇为第四课第四周的课后习题和代码实践部分。</p>\n<hr />\n<h1 id=\"1-理论习题\">1. 理论习题</h1>\n<p><a href=\"https://blog.csdn.net/u013733326/article/details/80736992\" rel=\"noopener nofollow\" target=\"_blank\">【中英】【吴恩达课后测验】Course 4 -卷积神经网络 - 第四周测验</a><br />\n还是比较简单，我们就不展开了。</p>\n<h1 id=\"2代码实践\">2.代码实践</h1>\n<p><a href=\"https://blog.csdn.net/u013733326/article/details/80767079\" rel=\"noopener nofollow\" target=\"_blank\">【中英】【吴恩达课后编程作业】Course 4 -卷积神经网络 - 第四周作业</a><br />\n再次提醒 Keras 的导库问题。<br />\n老样子，我们还是使用现有的成熟框架来分别实现本周介绍的人脸识别和图像风格转换模型。</p>\n<h2 id=\"21-人脸识别\">2.1 人脸识别</h2>\n<p>实际上，在如今的实验和实际部署中，人脸识别的整套逻辑已经远比我们在<a href=\"https://www.cnblogs.com/Goblinscholar/p/19418306\" target=\"_blank\">理论部分</a>所介绍的要<strong>复杂和完善的多</strong>，我们依旧分点来进行介绍。</p>\n<h3 id=\"1python-库insightface\">（1）python 库：InsightFace</h3>\n<p>作为一个应用中生活中方方面面的技术，就像我们之前介绍的目标检测有<a href=\"https://www.cnblogs.com/Goblinscholar/p/19401196\" target=\"_blank\">ultralytics</a>，人脸识别也有将成熟算法体系工程化、模块化的工具库：<strong>InsightFace</strong></p>\n<p>InsightFace 是基于 <strong>ArcFace</strong> 等先进算法构建的人脸分析库，功能涵盖：</p>\n<ol>\n<li><strong>人脸检测</strong>：支持单人或多人图像检测，返回人脸框和关键点；</li>\n<li><strong>人脸对齐</strong>：通过关键点实现旋转、缩放等对齐操作，提高识别精度；</li>\n<li><strong>人脸识别/验证</strong>：提取 embedding，进行相似度计算或一对多搜索；</li>\n<li><strong>性别、年龄、姿态估计</strong>：内置轻量化预测模型；</li>\n<li><strong>模块化、可扩展</strong>：你可以直接使用预训练模型，也可以替换为自己训练的模型。</li>\n</ol>\n<p>使用 InsightFace，我们几乎不需要从零实现算法逻辑，只需调用接口即可完成人脸识别的实验和演示。<br />\n同样，我们可以通过 pip 安装 InsightFace 相关依赖：</p>\n<pre><code class=\"language-bash\">pip install insightface onnxruntime\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><strong>CPU 版本</strong>：默认安装即可，无需额外配置。</li>\n<li><strong>GPU 版本</strong>：如果希望使用 GPU 加速，则需要安装 GPU 版本 ONNX Runtime：</li>\n</ul>\n<pre><code class=\"language-bash\">pip install onnxruntime-gpu\n</code></pre>\n<p>有一些<strong>注意事项</strong>，如果不进行相关配置会导致报错：</p>\n<ol>\n<li>ONNX Runtime GPU 需要 <strong>CUDA 和 cuDNN</strong> 与当前版本兼容</li>\n<li>在 Windows 上，部分组件需要 <strong>Microsoft C++ Build Tools</strong>，用于编译部分 C++/Cython 扩展：\n<ul>\n<li>安装 <a href=\"https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/\" rel=\"noopener nofollow\" target=\"_blank\">Visual Studio Installer</a></li>\n<li>勾选 <strong>“使用 C++ 的桌面开发”</strong></li>\n<li>即可保证 <code>insightface</code> 或其他依赖（如 <code>face3d</code>）可以正确编译。</li>\n</ul>\n</li>\n</ol>\n<p>在成功安装 InsightFace 后，我们来看看如何使用这个框架。</p>\n<h3 id=\"2insightface-预训练模型\">（2）InsightFace 预训练模型</h3>\n<p>我们对预训练模型的使用也早就不陌生了，InsightFace 同样内置了一系列从轻量级到重量级的预训练模型，我们可以通过接口实现下载并调用。<br />\n来简单看一段代码：</p>\n<pre><code class=\"language-python\">from insightface.app import FaceAnalysis\napp = FaceAnalysis(name='buffalo_l')  # 会自动下载预训练模型，这是一种轻量级模型\n</code></pre>\n<p>当你运行时，<strong>模型会缓存到用户目录下</strong>，自动下载并解压，无需手动配置：</p>\n<pre><code>C:\\Users\\&lt;用户名&gt;\\.insightface\\models\\\n</code></pre>\n<p>需要特别说明的是，<code>buffalo_l</code> 模型不仅仅是单一的识别模型，它实际上<strong>集成了人脸识别任务中的多个环节</strong>，包括：</p>\n<ol>\n<li><strong>人脸检测</strong> ：在输入图像中快速找到人脸区域。</li>\n<li><strong>关键点定位</strong>：在检测到的人脸上标出关键点（如眼睛、嘴角、鼻尖等）。</li>\n<li><strong>3D 人脸建模（可选，部分模型）</strong>：预测人脸的三维结构信息。</li>\n<li><strong>人脸特征提取</strong>：将每张人脸映射到一个高维向量空间，就是我们之前说的<strong>编码</strong>。</li>\n<li><strong>性别与年龄预测（部分模型）</strong>：预测人脸的性别和年龄区间。</li>\n</ol>\n<p>了解了它的功能后，现在我们就来演示一下：</p>\n<h3 id=\"3示例使用人脸检测\">（3）示例使用：人脸检测</h3>\n<p>我们用这样一段代码来进行初始化和人脸检测：</p>\n<pre><code class=\"language-python\">from insightface.app import FaceAnalysis  \nimport cv2 # 用来读取图像  \n  \napp = FaceAnalysis(name='buffalo_l')  # 轻量级预训练模型  \napp.prepare(ctx_id=0, det_size=(640, 640))  # ctx_id=-1 使用 CPU  \nimg = cv2.imread(\"images4.jpg\") # 读取图片  \nfaces = app.get(img) # 传入模型进行处理  \n  \nif faces:  \n    print(\"检测到人脸数量:\", len(faces))  \n    print(\"第一张人脸 embedding:\", faces[0].embedding[:20]) # 只显示前 20 维  \n    print(\"第二张人脸 embedding:\", faces[1].embedding[:20])\n</code></pre>\n<p>来看看运行后的效果：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260101173840687-1529887582.png\" /><br />\n这样，就完成了对图像的编码。</p>\n<h3 id=\"4示例使用关键点定位\">（4）示例使用：关键点定位</h3>\n<p>同样，只要所选用的预训练模型支持，<code>app.get(img)</code>的同样可以实现关键点定位：</p>\n<pre><code class=\"language-python\">from insightface.app import FaceAnalysis  \nimport cv2  \n  \napp = FaceAnalysis(name='buffalo_l')  \napp.prepare(ctx_id=0, det_size=(640, 640))  \nimg = cv2.imread(\"images4.jpg\")  \nfaces = app.get(img)  \n  \nif faces:  \n    # 画定位图  \n    vis = img.copy()  \n    for face in faces:  \n        bbox = face.bbox.astype(int)  \n        cv2.rectangle(vis, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)  \n        if 'landmark_2d_106' in face:  \n            landmarks_2d = face['landmark_2d_106'].astype(int)  \n            for (x, y) in landmarks_2d:  \n                cv2.circle(vis, (x, y), 2, (0, 0, 255), -1)  \n    # 保存结果  \n    cv2.imwrite(\"output.jpg\", vis)  \n    print(\"结果已保存到 output.jpg\")\n</code></pre>\n<p>来看结果：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260101173840103-664111316.png\" /><br />\n同样可以较为成功的定位到人脸的各个部位。</p>\n<h3 id=\"5通过相似度学习实现人脸识别\">（5）通过相似度学习实现人脸识别</h3>\n<p>演示了一些基本功能后，我们回到正题，再回顾一下原理：<strong>人脸识别并非要训练“你是谁”的网络，而是“你更像谁”的网络。即学习相似度而非分类，以此来实现具有较高部署价值的系统。</strong><br />\n因此，我们可以把两幅图像输入预训练模型，通过二者的编码来计算它们的相似度，代码如下：</p>\n<pre><code class=\"language-python\">import cv2  \nimport numpy as np  \nfrom insightface.app import FaceAnalysis  \n  \n# 1. 初始化 \nInsightFaceapp = FaceAnalysis(name='buffalo_l')  \napp.prepare(ctx_id=-1, det_size=(640, 640))  # ctx_id=-1 用 CPU  \n# 2. 读取图片  \nimg1 = cv2.imread(\"images1.jpg\")  \nimg2 = cv2.imread(\"images2.jpg\")  \n  \n# 3. 检测并提取人脸 embedding\nfaces1 = app.get(img1)  \nfaces2 = app.get(img2)  \nemb1 = faces1[0].embedding  \nemb2 = faces2[0].embedding  \n  \n# 4. 另一种更常用的相似度计算：余弦相似度  \ndef cosine_similarity(a, b):  \n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))  \nsim = cosine_similarity(emb1, emb2)  \nprint(f\"Cosine similarity: {sim:.4f}\")  \n  \n# 5.阈值决策  \nif sim &gt; 0.60:  \n    print(\"很可能是同一个人\")  \nelse:  \n    print(\"很可能不是同一个人\")\n</code></pre>\n<p>来看结果：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260101173840005-440514446.png\" /><br />\n这样，我们就通过学习相似度，避免了因人数增加而导致的结构和训练问题，实现了人脸识别。<br />\n而在实际应用中，我们便可以<strong>将所有识别目标预先输入模型得到编码并存储，与刷脸时截取的图像输入模型得到的编码依次计算相似度，根据结果进行下一步操作。</strong><br />\n同时，如果希望得到指标更高的结果，我们可以下载更重量级的模型。</p>\n<p>现在还有一个问题：<strong>如果我们想自己训练模型呢？</strong><br />\n由于 InsightFace 本身主要是 <strong>提供预训练模型和推理/应用接口</strong>，所以它并没有像 Pytorch 或 TF 一样完全封装一套“开箱即用、端到端训练你自己数据集”的完整训练流水线。<br />\n因此，我们虽然可以调用 InsightFace 定义的网络结构，但仍需要借助 Pytorch 或 TF 来编码数据输入、训练和梯度下降等逻辑。<br />\n但为了实现二者的兼容使用，我们就又要进行很多设置，一个更常见的思路是<strong>完全使用Pytorch 或 TF 来搭建自己的人脸识别网络</strong>，但这又涉及一些我们还没介绍过的网络结构。<br />\n因此在这里就不再展开了，在相关理论补充完成后，我们再来进行这部分内容。</p>\n<p>下面来看另一部分：图像风格转换。</p>\n<h2 id=\"22-图像风格转换\">2.2 图像风格转换</h2>\n<p>同样先回顾一下<a href=\"https://www.cnblogs.com/Goblinscholar/p/19423276\" target=\"_blank\">图像风格转换</a>的核心思想：在<strong>固定预训练卷积神经网络参数</strong>的前提下，利用网络中间层特征，将图像的内容结构与风格统计进行显式分离，并通过在特征空间中最小化相应的代价函数，直接对输入图像进行优化，从而重构出一幅同时匹配内容与风格约束的图像。</p>\n<p>因此，要实现一个图像风格转换网络，我们首先要选择一个<strong>经过预训练，可以合理提取图像特征的网络</strong>作为工具。<br />\n在这里，我选择使用 VGG16 作为<strong>预训练模型</strong>：</p>\n<pre><code class=\"language-python\">vgg = models.vgg16(pretrained=True).features.to(device).eval() # 选择评估模式 \nfor param in vgg.parameters():  # 冻结所有网络参数\n    param.requires_grad = False\n</code></pre>\n<p>开始编码，首先，我们需要对风格图和内容图两幅<strong>图像进行处理</strong>：</p>\n<pre><code class=\"language-python\"># 读取并预处理输入图像：统一尺寸、转换为张量并送入指定设备，网络输入要求\ndef load_image(path, size=(512, 256)):  \n    image = Image.open(path).convert(\"RGB\")  \n    transform = transforms.Compose([  \n        transforms.Resize(size),  \n        transforms.ToTensor()  \n    ])  \n    return transform(image).unsqueeze(0).to(device)  \n  \ncontent = load_image(\"content.jpg\")  \nstyle = load_image(\"style.jpg\")  \n</code></pre>\n<p>此外，我们还需要一些<strong>工具方法</strong>：</p>\n<pre><code class=\"language-python\"># 将模型输出的张量形式图像后处理为 PIL 图像，用于结果可视化与保存  \ndef tensor_to_pil(tensor):  \n    image = tensor.cpu().clone().squeeze(0)  \n    image = transforms.ToPILImage()(image.clamp(0,1))  \n    return image  \n    \n# 提取输出特征图用于计算代价\ndef get_features(x, model, layers):  \n    features = {}  \n    for name, layer in model._modules.items():  \n        x = layer(x)  \n        if name in layers:  \n            features[name] = x  \n    return features      \n     \n# 计算 Gram 矩阵用于计算风格代价  \ndef gram_matrix(features):  \n    b, ch, h, w = features.size()  \n    features = features.view(b, ch, h*w)  \n    gram = torch.bmm(features, features.transpose(1,2))  \n    return gram / (ch*h*w)\n</code></pre>\n<p>最后，再进行传播前的<strong>超参数设置</strong>：</p>\n<pre><code class=\"language-python\"># 指定用于内容表示的 VGG 网络层（通常选用较深层，保留语义信息）\ncontent_layers = ['15']\n# 指定用于风格表示的 VGG 网络层（从浅到深，捕捉不同尺度的纹理与统计特征）\nstyle_layers   = ['0', '5', '10', '15']\n# 以内容图像为初始值创建可优化的输出图像张量，并开启梯度计算\noutput = content.clone().requires_grad_(True).to(device)\n# 使用 L-BFGS 优化器对输出图像进行优化（风格迁移中常用）\noptimizer = optim.LBFGS([output])\n# 风格损失的权重，控制生成结果中风格特征的强度\nstyle_weight = 1e6\n# 内容损失的权重，控制生成结果与原内容图像的相似程度\ncontent_weight = 1\n# 提前计算内容图像在指定内容层上的特征表示\ncontent_features = get_features(content, vgg, content_layers)\n# 提前计算风格图像在指定风格层上的特征表示\nstyle_features = get_features(style, vgg, style_layers)\n# 提前对风格图像的各层特征计算 Gram 矩阵，用于表示风格的统计特性\nstyle_grams = {layer: gram_matrix(style_features[layer]) for layer in style_layers}\n# 设置优化的总迭代次数\nnum_steps = 400\n# 设置每隔多少步保存或显示一次中间结果\ndisplay_step = 50\n# 用于存储每隔 display_step 生成的输出图像，便于可视化训练过程\noutput_images = []\n</code></pre>\n<p>由此，我们终于可以进行训练了：</p>\n<pre><code class=\"language-python\">run = [0]  \nwhile run[0] &lt;= num_steps:  \n    def closure():  \n        optimizer.zero_grad()  \n        output_features = get_features(output, vgg, content_layers + style_layers) \n  \n        # 内容损失  \n        content_loss = 0  \n        for layer in content_layers:  \n            content_loss += torch.mean((output_features[layer] - content_features[layer])**2)  \n  \n        # 风格损失  \n        style_loss = 0  \n        for layer in style_layers:  \n            G = gram_matrix(output_features[layer])  \n            style_loss += torch.mean((G - style_grams[layer])**2)  \n  \n        total_loss = content_weight * content_loss + style_weight * style_loss  \n        total_loss.backward()  \n  \n        # 保存中间输出  \n        if run[0] % display_step == 0:  \n            print(f\"Step {run[0]}: Total Loss: {total_loss.item():.2f}\")  \n            output_images.append(tensor_to_pil(output.clone()))  \n        run[0] += 1  \n        return total_loss  \n  \n    optimizer.step(closure)\n</code></pre>\n<p>现在，来看看结果吧：<br />\n<img alt=\"image.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260101173839136-1949214051.png\" /></p>\n<p><img alt=\"myplot21312.png\" src=\"https://img2024.cnblogs.com/blog/3708248/202601/3708248-20260101173839578-1423866898.png\" /><br />\n这样，我们就完成了图像的风格转换，你也可以更换为自己的图像来试试效果。</p>\n<h1 id=\"3-附录\">3. 附录</h1>\n<h2 id=\"31-图像风格转换代码-pytorch版\">3.1 图像风格转换代码 Pytorch版</h2>\n<pre><code class=\"language-python\">import torch  \nimport torch.optim as optim  \nfrom torchvision import transforms, models  \nfrom PIL import Image  \nimport matplotlib.pyplot as plt  \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \nprint(\"Using device:\", device)  \n# 读取并预处理输入图像：统一尺寸、转换为张量并送入指定设备，网络输入要求  \ndef load_image(path, size=(256, 512)):  \n    image = Image.open(path).convert(\"RGB\")  \n    transform = transforms.Compose([  \n        transforms.Resize(size),  \n        transforms.ToTensor()  \n    ])  \n    return transform(image).unsqueeze(0).to(device)  \n  \ncontent = load_image(\"content.jpg\")  \nstyle = load_image(\"style.jpg\")  \n# 将模型输出的张量形式图像后处理为 PIL 图像，用于结果可视化与保存  \ndef tensor_to_pil(tensor):  \n    image = tensor.cpu().clone().squeeze(0)  \n    image = transforms.ToPILImage()(image.clamp(0,1))  \n    return image  \n# 计算 Gram 矩阵用于计算风格代价  \ndef gram_matrix(features):  \n    b, ch, h, w = features.size()  \n    features = features.view(b, ch, h*w)  \n    gram = torch.bmm(features, features.transpose(1,2))  \n    return gram / (ch*h*w)  \n  \nvgg = models.vgg16(pretrained=True).features.to(device).eval()  \nfor param in vgg.parameters():  \n    param.requires_grad = False  \n  \ncontent_layers = ['15']  \nstyle_layers   = ['0','5','10','15']  \n  \ndef get_features(x, model, layers):  \n    features = {}  \n    for name, layer in model._modules.items():  \n        x = layer(x)  \n        if name in layers:  \n            features[name] = x  \n    return features  \n  \noutput = content.clone().requires_grad_(True).to(device)  \noptimizer = optim.LBFGS([output])  \n  \nstyle_weight = 1e6  \ncontent_weight = 1  \n  \ncontent_features = get_features(content, vgg, content_layers)  \nstyle_features = get_features(style, vgg, style_layers)  \nstyle_grams = {layer: gram_matrix(style_features[layer]) for layer in style_layers}  \n  \nnum_steps = 400  \ndisplay_step = 50  \n  \n# 用于存储每隔 display_step 的输出  \noutput_images = []  \n  \nprint(\"开始优化...\")  \nrun = [0]  \nwhile run[0] &lt;= num_steps:  \n    def closure():  \n        optimizer.zero_grad()  \n        output_features = get_features(output, vgg, content_layers + style_layers)  \n  \n        # 内容损失  \n        content_loss = 0  \n        for layer in content_layers:  \n            content_loss += torch.mean((output_features[layer] - content_features[layer])**2)  \n  \n        # 风格损失  \n        style_loss = 0  \n        for layer in style_layers:  \n            G = gram_matrix(output_features[layer])  \n            style_loss += torch.mean((G - style_grams[layer])**2)  \n  \n        total_loss = content_weight * content_loss + style_weight * style_loss  \n        total_loss.backward()  \n  \n        # 保存中间输出  \n        if run[0] % display_step == 0:  \n            print(f\"Step {run[0]}: Total Loss: {total_loss.item():.2f}\")  \n            output_images.append(tensor_to_pil(output.clone()))  \n        run[0] += 1  \n        return total_loss  \n  \n    optimizer.step(closure)  \n  \n  \nnum_imgs = len(output_images)  \ncols = 3  \nrows = (num_imgs + cols - 1) // cols  \nplt.figure(figsize=(5*cols, 5*rows))  \nfor i, img in enumerate(output_images):  \n    plt.subplot(rows, cols, i+1)  \n    plt.imshow(img)  \n    plt.axis('off')  \n    plt.title(f\"Step {i*display_step}\")  \nplt.tight_layout()  \nplt.show()\n</code></pre>\n<h2 id=\"32-图像风格转换代码-tf版\">3.2 图像风格转换代码 TF版</h2>\n<pre><code class=\"language-python\">import tensorflow as tf  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \n  \nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input  \nfrom tensorflow.keras.models import Model  \nfrom tensorflow.keras.preprocessing import image  \n  \ndef load_and_process_img(path, target_size=None, max_size=512):  \n    img = image.load_img(path)  \n    if max(img.size) &gt; max_size:  \n        scale = max_size / max(img.size)  \n        img = img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))  \n    if target_size is not None:  \n        img = img.resize(target_size)  \n    img = image.img_to_array(img)  \n    img = np.expand_dims(img, axis=0)  \n    img = preprocess_input(img)  \n    return tf.convert_to_tensor(img, dtype=tf.float32)  \n  \ndevice = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"  \nprint(\"Using device:\", device)  \ncontent_path = \"content.jpg\"  \nstyle_path = \"style.jpg\"  \nmax_size = 512  \ncontent_weight = 1.0  \nstyle_weight = 1e6  \nnum_steps = 400  \ndisplay_step = 50  \n  \ncontent_pil = image.load_img(content_path)  \nif max(content_pil.size) &gt; max_size:  \n    scale = max_size / max(content_pil.size)  \n    final_size = (int(content_pil.size[0] * scale), int(content_pil.size[1] * scale))  \nelse:  \n    final_size = content_pil.size  \n  \nprint(f\"最终统一图像尺寸: {final_size}\")  \n  \n  \ncontent_img = load_and_process_img(content_path, max_size=max_size)  \nstyle_img = load_and_process_img(style_path, target_size=final_size, max_size=max_size)  \nvgg = VGG16(include_top=False, weights='imagenet')  \nvgg.trainable = False  \n  \ncontent_layers = ['block4_conv2']  \nstyle_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1']  \n  \noutputs = [vgg.get_layer(name).output for name in (style_layers + content_layers)]  \nmodel = Model(vgg.input, outputs)  \n  \n  \ndef gram_matrix(tensor):  \n    x = tf.transpose(tensor, [0, 3, 1, 2])    \n    b, c, h, w = tf.shape(x)  \n    features = tf.reshape(x, (b, c, h * w))  \n    gram = tf.matmul(features, features, transpose_b=True)  \n    return gram / tf.cast(c * h * w, tf.float32)  \n  \ndef get_features(x):  \n    outs = model(x)  \n    style_outs = outs[:len(style_layers)]  \n    content_outs = outs[len(style_layers):]  \n    return style_outs, content_outs  \n  \n  \nstyle_features, content_features = get_features(style_img)  \nstyle_grams = [gram_matrix(f) for f in style_features]  \nnoise = tf.random.uniform(tf.shape(content_img), -20., 20.)  \noutput_img = tf.Variable(content_img + noise)    \n  \noptimizer = tf.optimizers.Adam(learning_rate=5.0)  \ndef deprocess_img(x):  \n    x = x.numpy()[0]  \n    x[:, :, 0] += 103.939  \n    x[:, :, 1] += 116.779  \n    x[:, :, 2] += 123.68  \n    x = x[:, :, ::-1]  # BGR -&gt; RGB  \n    x = np.clip(x, 0, 255).astype('uint8')  \n    return x  \noutput_images = []  \n  \nfor step in range(num_steps):  \n    with tf.GradientTape() as tape:  \n        style_out, content_out = get_features(output_img)  \n        # 内容损失  \n        content_loss = tf.add_n([tf.reduce_mean((a - b) ** 2)  \n                                 for a, b in zip(content_out, content_features)])  \n        # 风格损失  \n        style_loss = tf.add_n([tf.reduce_mean((gram_matrix(a) - g) ** 2)  \n                               for a, g in zip(style_out, style_grams)])  \n  \n        total_loss = content_weight * content_loss + style_weight * style_loss  \n  \n    grads = tape.gradient(total_loss, output_img)  \n    optimizer.apply_gradients([(grads, output_img)])  \n  \n    if step % display_step == 0:  \n        print(f\"Step {step}, Total loss: {total_loss:.2f}\")  \n        output_images.append(deprocess_img(output_img))  \n  \nnum_imgs = len(output_images)  \ncols = 3  \nrows = (num_imgs + cols - 1) // cols  \n  \nplt.figure(figsize=(5 * cols, 5 * rows))  \nfor i, img in enumerate(output_images):  \n    plt.subplot(rows, cols, i + 1)  \n    plt.imshow(img)  \n    plt.title(f\"Step {i * display_step}\")  \n    plt.axis('off')  \nplt.tight_layout()  \nplt.show()\n</code></pre>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-01 17:41</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Goblinscholar\">哥布林学者</a>&nbsp;\n阅读(<span id=\"post_view_count\">33</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}