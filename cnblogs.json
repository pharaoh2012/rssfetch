{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "智能体时代的语言复兴：从 TIOBE 2025 年度语言到 2026 年 C# 智能体生态的全面崛起",
      "link": "https://www.cnblogs.com/shanyou/p/19441004",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shanyou/p/19441004\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 09:21\">\n    <span>智能体时代的语言复兴：从 TIOBE 2025 年度语言到 2026 年 C# 智能体生态的全面崛起</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><font face=\"微软雅黑 Light\" size=\"3\">2026 年 1 月，随着 TIOBE 指数正式宣布 C# 为 2025 年度编程语言，全球软件工程领域迎来了一个决定性的转折点 [1]。这一荣誉不仅是对 C# 过去一年在搜索热度和开发者活跃度上取得最大增幅的认可，更是一个滞后指标，揭示了底层技术范式的深刻变迁。如果说过去十年是 Python 依靠数据科学和模型训练确立霸权的时代，那么 2025 年的数据表明，行业重心正在从“模型构建”向“系统编排”转移。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">随着人工智能从生成式内容（Generative AI）向智能体系统（Agentic AI）演进，企业对开发语言的需求发生了根本性变化。智能体系统要求具备长周期的状态管理、复杂的并发处理能力、确定性的类型安全以及企业级的可观测性——这些正是 C# 和.NET 生态系统的传统强项。</font></p><h1><font face=\"微软雅黑 Light\"><font size=\"3\">一、</font><font size=\"3\">TIOBE 2025 判决：开发者情绪的结构性转变</font></font></h1><font size=\"3\"></font><font size=\"3\"></font><h5><font size=\"3\"><font face=\"微软雅黑 Light\" style=\"font-weight: normal;\">1.1 胜利的解剖学：C# 的二次加冕</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">2026 年初，TIOBE 指数公布了 2025 年的年度编程语言得主——C# [1]。这是 C# 在三年内第二次获此殊荣（上一次是在 2023 年），标志着其从一种被视为“传统企业级语言”的角色，成功转型为现代云原生和 AI 应用的核心力量 。TIOBE 的评选标准并非基于绝对市场份额，而是基于年度增长率，这使其成为捕捉开发者兴趣迁移的最佳风向标。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">数据显示，尽管 Python 依然凭借其在数据科学和初级编程教学中的绝对优势占据总榜首位，但其增长曲线已在 2025 年出现明显的平台期 。相比之下，C# 展现出了强劲的“长尾效应”，不仅稳固了其在游戏开发（Unity）和企业后端（ASP.NET Core）的基本盘，更在 AI 工程化领域实现了爆发式增长 。TIOBE CEO Paul Jansen 指出，C# 正在以前所未有的速度蚕食 Java 的市场份额，两者在 2025 年底的差距已缩小至不足 1 个百分点 。这种此消彼长的态势，实际上反映了工业界对于构建大规模、高性能 AI 应用系统的务实选择。</font></p><p></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">1.2 超越语法的驱动力：为何是 2025？</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">C# 的复兴并非偶然，而是三大宏观趋势在 2025 年交汇的结果：</font></p><ol><li><p><font face=\"微软雅黑 Light\" size=\"3\">对“脆弱性”的厌倦（Fatigue with Fragility）： 在 AI 原型设计阶段，Python 的动态特性和脚本化的灵活性是巨大的优势。然而，随着 AI 项目从实验室走向生产环境（Production），从简单的 RAG（检索增强生成）演进为复杂的智能体工作流，Python 代码库的可维护性问题日益凸显 。大型企业开始寻求一种既能提供类似于 Python 的开发效率，又能保证 C++/Java 级别稳健性的语言。C# 凭借其强大的类型系统（Type System）和编译器检查，成为了解决这一“工程化鸿沟”的最佳候选者 。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">全栈生态的统一（Unified Ecosystems）： 微软在 2025 年完成了其开发技术栈的深度整合。从 Azure 云基础设施，到 Visual Studio 开发环境，再到 Azure AI Foundry 模型服务，C# 开发者首次能够在同一个生态系统中无缝完成从模型微调、应用编排到云端部署的全流程 。这种“单一栈”（Single Stack）优势极大地降低了上下文切换的成本，吸引了大量原本因 AI 开发而转向 Python 的.NET 开发者回归。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">算力经济学的压力（Performance Criticality）： 随着大模型推理成本的居高不下，应用层的运行时效率重新成为关注焦点。2025 年发布的.NET 10 在张量处理（Tensor Primitives）和内存管理上的突破性改进，使得 C# 在执行轻量级推理和向量运算时的性能足以媲美甚至超越传统的 Python 数据栈，从而为企业节省了可观的计算资源成本 。</font></p></li></ol><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">1.3 Python 的平台期与 C# 的进击</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">2025 年的故事并非 Python 的衰落，而是工具链的分化。Python 依然是 AI 研究 和 训练 的通用语，把持着 PyTorch 和 TensorFlow 等核心库 。但在 AI 应用 和 编排层——即如何将大模型的能力转化为具体业务流程的领域——C# 正在重新夺回领地。TIOBE 的数据暗示，随着“AI 工程”（AI Engineering）逐渐从“数据科学”（Data Science）中剥离出来成为独立学科，工具链正在发生分裂：Python 负责炼制模型，而 C# 负责管理和指挥这些模型。这种分工将在 2026 年随着智能体系统的普及而变得更加清晰。</font></p><p></p><h1>二、智能体革命：从对话到编排</h1><p><font face=\"微软雅黑 Light\" size=\"3\">要理解 C# 为何能在 2026 年迎来爆发，必须首先理解 AI 发展的核心趋势：从生成式 AI 向智能体 AI 的跃迁。</font></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">2.1 智能体（Agentic AI）的定义与挑战</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">智能体 AI 不仅仅是能够回答问题的聊天机器人，它们是能够感知环境、进行推理规划、调用工具并执行多步任务的自主系统 。与传统的命令式程序不同，智能体系统的执行路径往往是非确定性的，依赖于大模型（LLM）的实时决策。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">这种范式转移给软件架构带来了前所未有的挑战：</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">状态管理的复杂性： 一个复杂的智能体任务（如“审核一笔贷款”）可能持续数天，期间涉及多次人机交互和外部 API 调用。系统必须能够持久化保存智能体的记忆（Memory）和执行状态（State），并在故障后恢复 。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">多智能体协作（Multi-Agent Orchestration）： 复杂的任务往往需要多个专职智能体（如“研究员”、“程序员”、“审核员”）协同工作。如何定义它们之间的通讯协议、仲裁机制和交接流程，是一个极其复杂的分布式系统问题。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">确定性与非确定性的融合： 企业应用需要结果是可预测且合规的，但 LLM 本质上是概率性的。如何在代码层面为不可靠的 LLM 加上“护栏”，是工程实施的关键。</font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">2.2 编排层的崛起：C# 的天然战场</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">正是这些挑战，让 C# 的优势得以充分发挥。</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">强类型系统的安全网： 在 Python 中，智能体之间传递的消息往往是松散的字典（Dictionary），极易在运行时导致类型错误。C# 允许开发者定义严格的接口（Interface）和数据契约（Data Contract），确保智能体之间的交互在编译期就经过验证。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">并发与异步处理： 智能体系统是高度 I/O 密集型的（等待 LLM 响应、等待 API 返回）。C# 的 async/await 模式和任务并行库（TPL）提供了比 Python asyncio 更成熟、更高性能的并发模型，能够轻松支撑成千上万个并发智能体实例 。</font></p></li></ul><p><font face=\"微软雅黑 Light\" size=\"3\">企业级持久化基因：.NET 生态拥有 Orleans、Durable Functions 等成熟的分布式运行时技术。微软智能体框架直接继承了这些基因，使得 C# 智能体天生具备“永生”的能力——即在进程重启或服务器故障后，依然能从断点无缝继续执行</font> 。</p><p></p><h1>三、 微软智能体框架（Microsoft Agent Framework）：统一的新引擎</h1><p><font face=\"微软雅黑 Light\" size=\"3\">2025 年 10 月，微软正式推出了 Microsoft Agent Framework（以下简称 MAF），这不仅是一个新的 SDK，更是 C# 在智能体领域确立地位的基石 。</font></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">3.1 历史性的统一：Semantic Kernel 与 AutoGen 的融合</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">在 MAF 诞生之前，微软的 AI 开发生态存在分裂：</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">Semantic Kernel (SK)： 作为一个企业级 SDK，SK 擅长将 LLM 集成到现有的应用中，提供插件（Plugin）和记忆（Memory）的抽象，但在多智能体复杂编排上略显乏力 。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">AutoGen： 作为一个源自微软研究院的 Python 项目，AutoGen 开创了多智能体对话（Group Chat）的先河，极其灵活但缺乏生产环境所需的类型安全和可观测性 。</font></p></li></ul><p><font face=\"微软雅黑 Light\" size=\"3\">MAF 的推出宣告了这种分裂的结束。它将 AutoGen 的创新编排模式（Orchestration Patterns）重构在 Semantic Kernel 坚实的企业级地基之上 。对于 C# 开发者而言，这意味着他们首次拥有了一个既具备前沿研究能力，又符合企业合规要求的原生框架。MAF 将于 2026 年第一季度正式商用（GA），这被视为 C# 智能体应用爆发的起跑线。</font></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">3.2 核心架构解析</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">MAF 引入了一套全新的、基于图（Graph-based）的架构体系，取代了早期松散的事件驱动模型。</font></p><h6><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">3.2.1 工作流引擎（Workflow Engine）</font></font></h6><p><font face=\"微软雅黑 Light\" size=\"3\">MAF 的核心是工作流引擎，它将智能体的交互建模为由 执行器（Executors） 和 边（Edges） 组成的有向图 12。</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">确定性编排： 开发者可以使用 C# 代码显式定义流程的流转逻辑。例如，只有当“风险评估智能体”输出的置信度低于 0.8 时，流程才会流转到“人工审核节点”。这种逻辑在 C# 中是强类型的，编译器会检查每一条边的输入输出类型是否匹配 12。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">状态管理（State Management）： MAF 引入了 AgentThread 的概念，用于持久化保存对话历史和上下文。与 Python 中常见的内存存储不同，C# 版的 MAF 可以通过依赖注入（DI）轻松集成 Cosmos DB 或 SQL Server 作为持久化后端，确保企业数据的安全性 12。</font></p></li></ul><h6><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">3.2.2 编排模式（Orchestration Patterns）</font></font></h6><p><font face=\"微软雅黑 Light\" size=\"3\">MAF 原生支持多种复杂的协作模式，使 C# 开发者能够像搭积木一样构建系统：</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">Magentic 编排： 受到 Magentic-One 研究的启发，这种模式包含一个主控的“经理智能体”（Manager）和多个“工智能体”（Worker）。经理维护一个动态的任务账本（Task Ledger），根据任务进展动态指派工智能体（如 WebSurfer、Coder）去执行具体操作。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">群聊模式（Group Chat）： 允许多个智能体在一个共享的上下文中轮流发言。C# 开发者可以通过实现 ITerminationStrategy 接口来精确控制群聊何时结束（例如：当达成共识或尝试次数耗尽时），而不是依赖脆弱的提示词指令。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">人在回路（Human-in-the-Loop）： MAF 将人工干预视为一种标准的工作流状态。系统可以在关键节点挂起，序列化当前状态，等待人类用户通过 UI 批准后，再反序列化并继续执行。这种机制对于金融和法律等高风险领域的应用至关重要。</font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">3.3 开发的“金三角”：DevUI, AG-UI, OpenTelemetry</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">为了解决 AI 系统“黑盒”难以调试的痛点，MAF 引入了被称为“金三角”的配套工具，极大地提升了 C# 开发者的体验：</font></p><ol><li><p><font face=\"微软雅黑 Light\" size=\"3\">DevUI（调试层）： 这是一个内环开发工具，提供可视化的界面来展示智能体的“思维链”（Chain of Thought）。开发者可以像查看 X 光片一样，清晰地看到智能体在每一步是如何进行推理、调用了哪个工具、以及为什么做出了某个决策。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">AG-UI（交互层）： 这是一个标准化的代理-用户交互协议。它解耦了后端智能体逻辑与前端展示。C# 后端可以通过该协议向前端流式传输结构化数据（如 JSON 表格、图表配置），而前端（无论是 React 还是 Blazor）只需实现标准渲染器即可。这使得全栈开发变得异常高效 。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">OpenTelemetry（可观测层）： MAF 与.NET 的 OpenTelemetry 深度集成。在 Azure Monitor 或 Aspire Dashboard 中，开发者可以看到完整的分布式追踪（Trace），监控 Token 消耗、延迟以及外部 API 的故障率。这对于 2026 年企业大规模部署 AI 智能体后的运维监控是必不可少的 18。</font></p></li></ol><h4><font face=\"微软雅黑 Light\" size=\"3\"><hr /><font style=\"font-weight: normal;\"> </font></font></h4><h1>四、技术深潜：.NET 10 与 C# 14 的底层革新</h1><p><font face=\"微软雅黑 Light\" size=\"3\">2026 年 C# 在智能体领域的竞争力，不仅仅来自于上层的框架，更来自于底层的硬核性能提升。.NET 10 和 C# 14 的发布，系统性地消除了 C# 在 AI 开发中相对于 Python 的最后几块短板。</font></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">4.1 System.Numerics.Tensors：终结 NumPy 依赖</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">长期以来，Python 在 AI 界的统治力很大程度上归功于 NumPy 及其背后的 C/C++ 优化库。.NET 10 通过重构 System.Numerics.Tensors 库，向这一壁垒发起了正面挑战 。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\"><a href=\"https://img2024.cnblogs.com/blog/510/202601/510-20260105092037994-1794180972.png\"><img alt=\"image\" border=\"0\" height=\"752\" src=\"https://img2024.cnblogs.com/blog/510/202601/510-20260105092038972-1464504355.png\" style=\"display: inline; background-image: none;\" title=\"image\" width=\"1747\" /></a></font></p><p><font face=\"微软雅黑 Light\" size=\"3\"></font></p><p><font face=\"微软雅黑 Light\" size=\"3\">.NET 10 引入了 Tensor&lt;T&gt;、TensorSpan&lt;T&gt; 和 ReadOnlyTensorSpan&lt;T&gt; 等高性能类型 。这些类型允许 C# 代码直接在内存中操作多维数组，利用 CPU 的 SIMD（单指令多数据）指令集进行加速。基准测试显示，在轻量级推理和向量运算（如 RAG 系统中的余弦相似度计算）场景下，C# 的性能可以媲美甚至在某些情况下超越 NumPy，且无需跨越 Python 与 C 之间的互操作边界（Marshalling Overhead）。这对于构建低延迟的实时智能体系统至关重要。</font></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">4.2 AVX-512 与推理优化</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">随着 AI 推理从云端向边缘侧和通用服务器迁移，CPU 推理的重要性日益提升。.NET 10 对 Intel AVX-512 指令集的原生支持（包括 VNNI - 向量神经网络指令），使得 C# 应用能够充分挖掘现代服务器 CPU（如 Intel Xeon Scalable）的 AI 加速能力 。这意味着企业可以在现有的.NET 服务器集群上高效运行量化后的大模型（如 Phi-3&nbsp; 的量化版本），而无需为每个简单的智能体任务都配备昂贵的 GPU 资源 。这种“CPU 推理友好”的特性，大大降低了企业部署大规模智能体集群的门槛。</font></p><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">4.3 C# 14：语义表达力的进化</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">C# 14 的语言特性更新，致力于减少定义智能体和数据结构时的样板代码，使其在表达力上更加接近 Python 的简洁性，同时保持静态类型的安全性 。</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">field 关键字： 这一特性简化了属性（Property）的定义，允许开发者在属性访问器中直接访问隐式生成的后备字段。这在定义智能体的内部状态模型时非常有用，使得代码更加紧凑易读。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">扩展成员（Extension Members）： C# 14 允许向接口添加扩展属性和静态方法。这对于扩展 AI SDK 的能力至关重要。例如，开发者可以为标准的 IChatClient 接口添加特定领域的扩展方法，而无需修改原始库代码或创建复杂的包装类。这极大地增强了多智能体系统的可组合性（Composability）。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">隐式 Span 转换： 这一特性简化了不同内存表示形式之间的转换，使得在向量数据库、LLM 输入和应用逻辑之间传递数据变得更加流畅和高效 。</font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\"><font style=\"font-weight: normal;\">4.4 TypeChat 与结构化输出</font></font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">在智能体开发中，最头疼的问题之一是如何让 LLM 稳定地输出程序可读的 JSON 数据。微软推出的 TypeChat 库与 C# 的强类型系统简直是天作之合 。</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">原理： 开发者只需定义 C# 的类（Class）或接口（Interface）来描述期望的数据结构。TypeChat 会自动根据这些类型定义生成 Prompt，并在 LLM 返回结果后，利用 C# 编译器进行反序列化和验证。如果验证失败，它甚至会自动构建修复提示词让 LLM 重试。</font></p></li></ul><p><font face=\"微软雅黑 Light\" size=\"3\">价值： 这种机制将 LLM 的非确定性输出被约束在确定的 C# 类型系统中，为构建可靠的业务智能体提供了坚实的保障。在.NET 10 中，这种能力被进一步集成进 MAF，成为标准的开发范式 。</font></p><p><br /></p><p><font face=\"微软雅黑 Light\" size=\"3\"></font></p><h1>五、展望 2026：智能体网格与 IDE 的进化</h1><h5><font face=\"微软雅黑 Light\" size=\"3\" style=\"font-weight: normal;\">5.1 Visual Studio 2026：智能体原生 IDE</font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">2025 年底发布的 Visual Studio 2026 成为首个“智能体原生”（Agent-Native）的 IDE 。</font></p><ul><li><p><font face=\"微软雅黑 Light\" size=\"3\">智能体调试器： 开发者将不再只是调试代码行，而是调试智能体的“思维”。VS 2026 将支持在智能体推理循环中设置断点，查看当前的上下文窗口、工具调用堆栈和 Token 使用情况 。</font></p></li><li><p><font face=\"微软雅黑 Light\" size=\"3\">Aspire 集成：.NET Aspire 将成为智能体编排的标准容器化方案，提供开箱即用的服务发现、配置管理和遥测集成，让多智能体系统的本地开发体验像单体应用一样简单 。</font></p></li></ul><h5><font face=\"微软雅黑 Light\" size=\"3\" style=\"font-weight: normal;\">5.2 智能体服务网格（Agentic Service Mesh）</font></h5><p><font face=\"微软雅黑 Light\" size=\"3\">随着智能体数量的激增，企业内部将涌现出“智能体注册表”和“智能体互联协议”（A2A）的需求 。未来的企业软件架构，将出现大量是由 C# 编写的、成百上千个专职智能体组成的庞大协作网络。</font></p><h1>结语</h1><p><font face=\"微软雅黑 Light\" size=\"3\">C# 荣膺 TIOBE 2025 年度编程语言，绝非旧时代的余晖，而是新时代的曙光。在人工智能从“生成”迈向“行动”的关键节点，行业对软件工程的严谨性、性能和可维护性提出了更高要求。通过.NET 10 的底层重构和微软智能体框架的顶层设计，C# 成功地重塑了自己，从 Python 手中接过了 AI 应用编排的接力棒。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">2026 年，对于 C# 开发者而言，将是黄金时代。他们手中的工具不再仅仅是构建 Web 页面或 CRUD 接口的铲子，而是指挥数字劳动力、编排智能体网络的权杖。在这个智能体驱动的新世界里，C# 不仅是参与者，更是定义者。</font></p><p><font face=\"微软雅黑 Light\" size=\"3\"><br /></font></p><p><font face=\"微软雅黑 Light\" size=\"3\">相关链接：</font></p><p><font face=\"微软雅黑 Light\" size=\"3\">[1] <b>TIOBE Index: <a href=\"https://www.tiobe.com/tiobe-index/\" rel=\"noopener nofollow\">https://www.tiobe.com/tiobe-index/</a></b></font></p><p><br /></p><p><font face=\"微软雅黑 Light\" size=\"3\"></font></p><p><font face=\"微软雅黑 Light\" size=\"3\"></font></p>\n</div>\n<div id=\"MySignature\">\n    <p>欢迎大家扫描下面二维码成为我的客户，扶你上云</p>\n<img src=\"https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg\" width=\"170\" />\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 09:21</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shanyou\">张善友</a>&nbsp;\n阅读(<span id=\"post_view_count\">358</span>)&nbsp;\n评论(<span id=\"post_comment_count\">4</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "前注意加工：让你的图表抓住读者的眼球",
      "link": "https://www.cnblogs.com/wang_yb/p/19440010",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wang_yb/p/19440010\" id=\"cb_post_title_url\" title=\"发布于 2026-01-04 23:10\">\n    <span>前注意加工：让你的图表抓住读者的眼球</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>想象一下，你走进一个挤满人的房间，朋友向你招手--你几乎立刻就能看到他。</p>\n<p>这是因为“招手”这个动作在你的大脑进行深入思考之前，就已经被注意到了。</p>\n<p>再比如当你走在熙熙攘攘的大街上，如果所有人穿的都是黑灰色的大衣，而此时有一个人穿着鲜红色的风衣，你会看哪里？</p>\n<p>毫无疑问，你的目光会瞬间被那抹红色吸引。</p>\n<p>这就是<strong>前注意加工</strong>：我们的大脑能在极短时间内（约200-250毫秒）自动检测到某些视觉特征，而无需我们有意识地去寻找。</p>\n<p>在数据可视化中，<strong>前注意加工</strong>就是我们用来引导读者注意力的“视觉魔术”。</p>\n<p>通过巧妙地改变颜色、大小、形状等视觉属性，我们可以让图表中的关键信息（如最大值、最小值、异常值）像朋友招手一样“跳出来”，第一时间抓住读者的眼球。</p>\n<h1 id=\"1-前注意加工的实用技巧\">1. 前注意加工的实用技巧</h1>\n<ol>\n<li><strong>少即是多</strong>：不要过度使用突出效果，否则会失去焦点</li>\n<li><strong>一致性原则</strong>：在整个报告或仪表板中使用相同的突出颜色编码</li>\n<li><strong>考虑色盲用户</strong>：避免仅依靠颜色区分，可结合形状、纹理等</li>\n<li><strong>上下文相关</strong>：根据数据特点和观众背景选择合适的突出方式</li>\n<li><strong>测试效果</strong>：让其他人查看你的图表，确认突出效果是否达到预期</li>\n</ol>\n<h1 id=\"2-前注意加工实例\">2. 前注意加工实例</h1>\n<p>概念介绍完了，下面直接看代码，看看实际情况下如何使用<strong>前注意加工</strong>来提高我们的可视化效果。</p>\n<h2 id=\"21-突出最大值和最小值\">2.1. 突出最大值和最小值</h2>\n<pre><code class=\"language-python\"># 示例1：突出最大值和最小值\n# 创建数据\nnp.random.seed(42)\ncategories = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\nvalues = np.random.randint(10, 100, size=8)\n\n# 找出最大值和最小值的索引\nmax_idx = np.argmax(values)\nmin_idx = np.argmin(values)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# 左图：没有前注意加工\nbars1 = ax1.bar(categories, values, color='lightblue', edgecolor='black')\n\n# 右图：有前注意加工（突出最大最小值）\ncolors = ['lightblue'] * len(values)\ncolors[max_idx] = '#FF6B6B'  # 红色突出最大值\ncolors[min_idx] = '#4ECDC4'  # 青色突出最小值\n\nbars2 = ax2.bar(categories, values, color=colors, edgecolor='black')\n\n# 在最大值和最小值上添加标签\nax2.text(max_idx, values[max_idx] + 2, f'最大: {values[max_idx]}',\n         ha='center', fontweight='bold', color='#FF6B6B')\nax2.text(min_idx, values[min_idx] + 2, f'最小: {values[min_idx]}',\n         ha='center', fontweight='bold', color='#4ECDC4')\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260104230912188-646033135.png\" /></p>\n<p>左图中，所有柱子都是相同的蓝色，读者需要逐个比较才能找出最大值和最小值。</p>\n<p>右图中，最大值用醒目的红色标出，最小值用青色标出，读者一眼就能看到关键数据点。</p>\n<p><strong>前注意加工的好处</strong>：就像在人群中为重要人物戴上特别的帽子，读者无需费力寻找就能立即识别关键数据点。</p>\n<h2 id=\"22-突出异常值\">2.2. 突出异常值</h2>\n<pre><code class=\"language-python\"># 示例2：突出异常值\n# 创建包含异常值的数据\nnp.random.seed(42)\ndata_normal = np.random.normal(50, 10, 100)\ndata_outliers = np.array([5, 125, 130])  # 异常值\nall_data = np.concatenate([data_normal, data_outliers])\n\n# 识别异常值（简单方法：超出平均值±2倍标准差）\nmean_val = np.mean(all_data)\nstd_val = np.std(all_data)\noutlier_indices = np.where((all_data &lt; mean_val - 2*std_val) | (all_data &gt; mean_val + 2*std_val))[0]\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# 左图：没有前注意加工\nscatter1 = ax1.scatter(range(len(all_data)), all_data, alpha=0.7, c='gray', s=50)\nax1.axhline(y=mean_val, color='black', linestyle='--', alpha=0.5, label=f'平均值: {mean_val:.1f}')\nax1.axhline(y=mean_val + 2*std_val, color='red', linestyle=':', alpha=0.5, label='±2标准差')\nax1.axhline(y=mean_val - 2*std_val, color='red', linestyle=':', alpha=0.5)\n\n# 右图：有前注意加工（突出异常值）\ncolors = ['gray'] * len(all_data)\nsizes = [50] * len(all_data)\n\n# 突出异常值\nfor idx in outlier_indices:\n    colors[idx] = '#FF6B6B'  # 红色\n    sizes[idx] = 150  # 更大\n\nscatter2 = ax2.scatter(range(len(all_data)), all_data, alpha=0.7, c=colors, s=sizes)\nax2.axhline(y=mean_val, color='black', linestyle='--', alpha=0.5, label=f'平均值: {mean_val:.1f}')\nax2.axhline(y=mean_val + 2*std_val, color='red', linestyle=':', alpha=0.5, label='±2标准差')\nax2.axhline(y=mean_val - 2*std_val, color='red', linestyle=':', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260104230912194-1976550473.png\" /></p>\n<p>左图中，异常值混在普通数据点中，难以立即识别。</p>\n<p>右图中，异常值用更大的红色点突出显示，即使数据量很大，读者也能立即注意到这些特殊点。</p>\n<p><strong>前注意加工的好处</strong>：就像在平静湖面上标记出涟漪的起源，异常值不再隐藏在数据海洋中，而是成为分析的重点。</p>\n<h2 id=\"23-突出趋势变化点\">2.3. 突出趋势变化点</h2>\n<pre><code class=\"language-python\"># 示例3：突出趋势变化点\n# 创建包含趋势变化的时间序列数据\nnp.random.seed(42)\ntime_points = np.arange(0, 100)\ntrend_change_point = 45\n\n# 分段创建趋势数据\ntrend1 = 30 + 0.5 * np.arange(0, trend_change_point) + np.random.normal(0, 2, trend_change_point)\ntrend2 = trend1[-1] - 0.8 * np.arange(0, 100 - trend_change_point) + np.random.normal(0, 2, 100 - trend_change_point)\ndata = np.concatenate([trend1, trend2])\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# 左图：没有前注意加工\nline1 = ax1.plot(time_points, data, color='gray', alpha=0.8, linewidth=2)\n\n# 右图：有前注意加工（突出趋势变化点）\nline2 = ax2.plot(time_points, data, color='gray', alpha=0.6, linewidth=2)\n\n# 突出趋势变化区域\nax2.axvspan(trend_change_point-5, trend_change_point+5, alpha=0.3, color='#FF6B6B', label='趋势变化区域')\nax2.scatter(trend_change_point, data[trend_change_point], color='#FF6B6B', s=200, zorder=5, label='变化点')\nax2.plot(time_points[:trend_change_point+1], data[:trend_change_point+1], color='#4ECDC4', linewidth=3, alpha=0.8, label='上升趋势')\nax2.plot(time_points[trend_change_point:], data[trend_change_point:], color='#45B7D1', linewidth=3, alpha=0.8, label='下降趋势')\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260104230912195-715553153.png\" /></p>\n<p>左图展示了一个完整的趋势线，但变化点不明显。</p>\n<p>右图使用不同颜色区分趋势段，并用阴影区域和突出点标记变化区域，使趋势转折一目了然。</p>\n<p><strong>前注意加工的好处</strong>：就像在道路地图上标记出转弯处，读者能立即看到趋势变化的关键时刻。</p>\n<h2 id=\"24-突出特定类别\">2.4. 突出特定类别</h2>\n<pre><code class=\"language-python\"># 示例4：突出特定类别\n# 创建饼图数据\ncategories = [\"电子产品\", \"服装\", \"食品\", \"家居\", \"书籍\", \"其他\"]\nvalues = [25, 18, 22, 15, 10, 10]\nhighlight_category = \"食品\"  # 要突出的类别\nhighlight_idx = categories.index(highlight_category)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# 左图：没有前注意加工\ncolors1 = [\"#FF9AA2\", \"#FFB7B2\", \"#FFDAC1\", \"#E2F0CB\", \"#B5EAD7\", \"#C7CEEA\"]\nwedges1, texts1, autotexts1 = ax1.pie(\n    values, labels=categories, autopct=\"%1.1f%%\", colors=colors1, startangle=90\n)\n\n# 右图：有前注意加工（突出特定类别）\n# 将突出类别的颜色改为醒目的颜色，其他类别用灰度\ncolors2 = [\"lightgray\"] * len(categories)\ncolors2[highlight_idx] = \"#FF6B6B\"  # 突出类别用红色\n\n# 突出显示：将特定类别\"拉出\"\nexplode = [0] * len(categories)\nexplode[highlight_idx] = 0.1\n\nwedges2, texts2, autotexts2 = ax2.pie(\n    values,\n    labels=categories,\n    autopct=\"%1.1f%%\",\n    colors=colors2,\n    explode=explode,\n    startangle=90,\n)\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260104230912185-501416555.png\" /></p>\n<p>左图中，所有类别视觉权重相同，读者需要阅读标签或百分比才能找到特定类别。</p>\n<p>右图中，目标类别被\"拉出\"并用醒目的红色显示，其他类别则用灰色淡化，读者一眼就能看到重点。</p>\n<p><strong>前注意加工的好处</strong>：就像在合唱团中为独唱者打上聚光灯，特定类别立即成为视觉焦点。</p>\n<p>同样，在绘制<strong>多条折线图</strong>（也就是俗称的“面条图”）时，如果每条线都用高饱和度的颜色，画面会非常混乱，读者不知道该看哪一条。</p>\n<p>也可以用上面饼图类似的思路，降低非重点数据的<strong>不透明度</strong>（<code>Alpha</code>）和<strong>线宽</strong>（<code>Linewidth</code>），只保留重点数据的鲜明样式。</p>\n<p>这就像舞台上的聚光灯，灯光打在哪里，观众就看哪里。</p>\n<pre><code class=\"language-python\"># 模拟时间序列数据\nx = np.linspace(0, 10, 100)\n# 生成5条干扰线\nlines = [np.sin(x + i) * (1 + i/10) for i in range(5)]\n# 生成1条重点线（比如这是我们公司的产品）\nmain_line = np.sin(x) * 2.5 + 1\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# --- 图1：没有前注意加工 ---\n# 典型的面条图，所有线都在争夺注意力\nfor i, line in enumerate(lines):\n    ax1.plot(x, line, label=f'Competitor {i}')\nax1.plot(x, main_line, label='Our Product')\n\n# --- 图2：有前注意加工 ---\n# 策略：弱化背景，突出前景\nfor line in lines:\n    ax1.plot(x, line) # 左图逻辑\n    # 右图逻辑：灰色、细线、半透明\n    ax2.plot(x, line, color='lightgray', linewidth=1, alpha=0.6)\n\n# 重点线：深青色、加粗、不透明\nax2.plot(x, main_line, color='teal', linewidth=3, label='Our Product')\n\nplt.tight_layout()\nplt.show()\n</code></pre>\n\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/83005/202601/83005-20260104230912198-1217895469.png\" /></p>\n<h1 id=\"3-总结\">3. 总结</h1>\n<p><strong>前注意加工</strong>是数据可视化中的\"视觉语法\"，它通过预认知的视觉特征引导读者的注意力。</p>\n<p>就像熟练的导游会指出风景中的亮点，有效的数据可视化应该引导读者立即看到数据故事中<strong>最关键</strong>的部分。</p>\n<p>数据可视化不仅仅是把数据画出来，更是一场<strong>注意力的管理艺术</strong>。</p>\n<ul>\n<li><strong>不要让读者的眼睛去“工作”</strong>：如果他们需要花好几秒钟去找最大值，那是我们设计者的失职。</li>\n<li><strong>利用对比</strong>：颜色（亮/暗）、大小（大/小）、位置（前/后），这些物理属性的对比能瞬间触发大脑的“系统1”（直觉系统）。</li>\n</ul>\n<p>下次使用 <code>Matplotlib</code> 绘图时，在 <code>plt.show()</code> 之前，请停下来问自己一个问题：“<strong>我这张图里，最想让读者第一眼看到的是什么？</strong>”</p>\n<p>一旦确定了答案，就请大胆地使用上述技巧，把它“推”到读者眼前吧！</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-04 23:10</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wang_yb\">wang_yb</a>&nbsp;\n阅读(<span id=\"post_view_count\">101</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "如何用 AI + OpenSpec 驱动团队迭代开发",
      "link": "https://www.cnblogs.com/zh94/p/19439980",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/zh94/p/19439980\" id=\"cb_post_title_url\" title=\"发布于 2026-01-04 22:49\">\n    <span>如何用 AI + OpenSpec 驱动团队迭代开发</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>从混乱到有序，从口口相传到知识沉淀，我们用一次实践探索了 AI 辅助团队开发的完整架构</p>\n<h2 id=\"一个真实的痛点\">一个真实的痛点</h2>\n<p>你是否遇到过这样的场景：</p>\n<ol>\n<li>写个正则表达式？AI 秒杀我。</li>\n<li>写个独立脚本？AI 真香。</li>\n<li>写个炫酷网页？AI 真牛 X！</li>\n</ol>\n<p>但是一旦将 AI 扔进一个庞大的微服务项目里，它似乎立刻降智为了“新手小白”？</p>\n<p>由于 AI 无法理解三年前写下的那段“奇葩代码”究竟为何，导致每次对话都像“开盲盒”，Review AI 生成代码的时间，比自己重写一遍还要长。</p>\n<p>这些问题的本质其实是：<strong>缺乏一个结构化的、AI 可理解的知识管理体系</strong>。</p>\n<p>最近，我们在一个复杂的微服务项目中，探索并实践了一套 <strong>“人机协同迭代开发”的完整架构</strong>。整个过程没有额外编写一行工具代码，仅通过对话和现有工具链，就让 AI 从“项目小白”成长为“熟悉业务的开发伙伴”。</p>\n<p>本文将完整还原这一过程，并总结出可复制的方法论。</p>\n<h2 id=\"第一步建立-ai-可理解的项目大脑\">第一步：建立 AI 可理解的“项目大脑”</h2>\n<p>大多数团队的文档是写给人看的，而非 AI：</p>\n<ul>\n<li>❌ 飞书/Confluence/Wiki 里的设计文档太多，太杂。</li>\n<li>❌ 散落在各处的 README → AI 抓不住重点。</li>\n<li>❌ 资深员工脑中的隐性知识 → AI 永远学不会。</li>\n</ul>\n<p>我们的解法是引入 <strong>OpenSpec</strong> 规范，并基于它构建一整套“知识迭代体系”。</p>\n<p>OpenSpec 核心理念极其简单：让 AI 明确知道“知识在哪、如何用、以及为什么这样做”。</p>\n<h3 id=\"11-搭建知识骨架\">1.1 搭建“知识骨架”</h3>\n<p>无论是新项目还是历史项目，第一步都是通过命令行初始化一个标准的知识目录结构：</p>\n<pre><code class=\"language-bash\">cd /path/to/your-project\nopenspec init\n</code></pre>\n<p>生成的目录结构，便是项目的“知识骨架”：</p>\n<pre><code>openspec/\n ├── AGENTS.md       # 【大脑指令】AI 工作指南（开发规范、测试策略、错误码设计等）\n ├── project.md      # 【长期记忆】项目上下文（目标、核心术语、文档索引）\n ├── specs/          # 【技能树】已实现能力的规范（做了什么）\n ├── changes/        # 【短期记忆】待处理的变更提案（要做什么）\n └── docs/           # 【知识库】详细文档（为什么这样做）\n</code></pre>\n<p>此举的核心在于为 AI 提供一个明确的结构化索引，而非一股脑地塞入所有文档。</p>\n<p>其中 <code>docs</code> 并非OpenSpec规范，而是自行创建的目录，后续用作详细索引时使用，需要手动创建。</p>\n<h3 id=\"12-让-ai-认识你的项目\">1.2 让 AI “认识”你的项目</h3>\n<p>对于已有项目，AI 起初面对一片空白。我们采用 <strong>“索引层 + 明细层”</strong> 的双层结构来填充知识。</p>\n<p><strong>索引层（<code>AGENTS.md</code> &amp; <code>project.md</code>）</strong></p>\n<p>这里不写长篇大论，只提供“地图”。</p>\n<ul>\n<li><code>AGENTS.md</code>：定义 AI 的核心开发规范（如命名、错误码、测试策略）。</li>\n<li><code>project.md</code>：阐述业务共性知识（如项目目标、核心术语、需求概要），并指明各项详细文档在 <code>docs/</code> 中的位置索引。</li>\n</ul>\n<p><strong>明细层（<code>openspec/docs/</code>）</strong>：这里存放真正的“干货”：详细的架构设计、复杂的需求文档、业务逻辑说明。</p>\n<p>工作流形成闭环：当 AI 接到任务 → 先读 <code>AGENTS.md</code>（获取规范）→ 再读 <code>project.md</code>（获取业务背景）→ 根据索引定位到 <code>docs/</code> 下的具体文档 → 深刻理解上下文后开始工作。</p>\n<p>最棒的是：你无需手动编写这些索引。只需发起一个 OpenSpec 提案，通过对话引导 AI 自己去梳理项目架构和业务，它便能自动生成初始的 <code>project.md</code> 内容。</p>\n<blockquote>\n<p><strong>知识迭代提示</strong>：后续在 docs/ 下维护新知识时，需引导 AI 基于更新后的知识库，重新总结生成新的 project.md。为此，我们可以定义一个《文档管理指南》作为准则，确保 AI 每次迭代时都能遵循，从而保障业务知识的持续有效性和一致性。</p>\n</blockquote>\n<h2 id=\"第二步协作机制像管理代码一样管理知识\">第二步：协作机制——像管理代码一样管理“知识”</h2>\n<p>建立了初始知识库，还需让知识随着项目迭代而更新。我们引入了一套 <strong>Change-Driven（变更驱动）</strong> 的协作流程，并将其作为团队核心准则严格执行。</p>\n<p>所有新的需求或变更，都必须严格通过 OpenSpec 发起提案：</p>\n<ol>\n<li><strong>需求变更 → 发起 OpenSpec 提案</strong>\n<ul>\n<li>开发新需求时，必须通过 OpenSpec 创建提案（<code>changes/proposal-xxx.md</code>）。</li>\n<li>人工审查重点：核对 AI 生成的提案中 <strong>Why（背景）、What（目标）、Impact（影响）</strong> 是否清晰一致，确保人与 AI 的理解对齐。</li>\n</ul>\n</li>\n<li><strong>AI 辅助实现</strong>\n<ul>\n<li>AI 读取已通过的提案，结合 <code>specs/</code> 中已有的能力规范，生成或修改代码及测试用例。</li>\n<li>人工进行 Code Review。</li>\n</ul>\n</li>\n<li><strong>知识沉淀（归档）</strong>\n<ul>\n<li>运行 <code>openspec archive</code> 命令。</li>\n<li>AI 将自动把本次变更所涉及的新知识、新规范，更新到 <code>specs/</code> 和 <code>docs/</code> 中，完成知识入库。</li>\n</ul>\n</li>\n</ol>\n<p>通过这个流程，每一次需求迭代及其产生的代码，都完整地闭环并沉淀到 OpenSpec 体系里。AI 在处理后续需求时，便有了可追溯和借鉴的“历史经验”。</p>\n<h2 id=\"实践建议与场景考量\">实践建议与场景考量</h2>\n<p>在实际操作中，你还会遇到一些具体问题，例如：</p>\n<p><strong>Q：微服务项目下子服务众多，应该每个服务初始化一套 OpenSpec，还是整个项目共用一套？</strong></p>\n<p>我们的经验则是：<strong>基于知识独立性进行判断</strong>。</p>\n<ul>\n<li>如果某个模块（如用户中心）的业务知识与其他模块重合度很低（例如&lt;30%），独立初始化一个 OpenSpec 目录是更清晰的选择。</li>\n<li>如果多个服务共享大量共性业务知识（重合度&gt;70%），共用一套OpenSpec 更能保证知识的一致性和 AI 的理解效率。</li>\n</ul>\n<p>不同的业务架构需要灵活采用不同的策略。</p>\n<h2 id=\"走向人--ai的团队协作\">走向“人 + AI”的团队协作</h2>\n<p>当这套以知识为核心的迭代体系稳固运行后，你会发现：</p>\n<ul>\n<li>隐性知识被彻底显性化。</li>\n<li>新成员（包括 AI） 学习成本大幅降低。</li>\n<li>在后续编写接口文档、架构迭代或代码重构时，AI 的效能将被成倍放大。</li>\n</ul>\n<p>未来的高效团队协作，是 <strong>“人 + AI”</strong> 的深度融合。让 AI 成为团队忠实的“知识伙伴”而不仅仅是临时的“代码助手”，这，才是 AI 时代团队开发的正确打开方式。</p>\n<hr />\n<p><strong>欢迎日常交流</strong></p>\n<p>AI 驱动团队开发是这个时代的新命题，欢迎大家加微信互相交流心得。</p>\n<p>👉 想要进群的朋友，扫码时备注 “AI实验群”，看到消息后会第一时间拉你进群。</p>\n<p>群定位：AI工具提效/实战经验互助<br />\n群规则：不水群、不广告、干货优先</p>\n<p>欢迎访问该链接获取群信息：<a href=\"https://zhaozhihao.com/archives/KRMxDLo4\" rel=\"noopener nofollow\" target=\"_blank\">https://zhaozhihao.com/archives/KRMxDLo4</a></p>\n<hr />\n<p><strong>好文章值得被更多人看见！既然看到这里了，随手点个赞👍和关注，并转发给更多的朋友吧！感谢。</strong></p>\n<blockquote>\n<p>作者：数字生命贾克斯、微信：x_h886688</p>\n</blockquote>\n<p>公众号原文地址：<a href=\"https://mp.weixin.qq.com/s/CJPCsYoQOo5Ib1Q8f0IZBA\" rel=\"noopener nofollow\" target=\"_blank\">如何用 AI + OpenSpec 驱动团队迭代开发</a><br />\n个人网站原文地址：<a href=\"https://zhaozhihao.com/archives/rGL0TwgK\" rel=\"noopener nofollow\" target=\"_blank\">如何用 AI + OpenSpec 驱动团队迭代开发</a></p>\n\n</div>\n<div id=\"MySignature\">\n    <br />\n<fieldset style=\"padding: 10px; margin: 10px; background-color: #fff; width: 850px; border: 1px solid black; font-size: blod;\">\n<p><span style=\"color: black;\">版权声明</span></p>\n<hr style=\"color: black;\" />\n<p><span style=\"color: black;\">作者：陈咬金</span></p>\n<p><span style=\"color: black;\">出处：</span><a href=\"https://www.cnblogs.com/zh94/\" style=\"color: black;\" target=\"_blank\">陈咬金的技术博客--https://www.cnblogs.com/zh94/</a></p>\n<p><span style=\"color: black;\">您的支持是对博主最大的鼓励，感谢您的认真阅读。</span></p>\n<p><span style=\"color: black;\">本文版权归作者所有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留任何追究法律责任的权利。</span></p>\n</fieldset>\n\n<div style=\"padding: 10px; margin: 10px; background-color: #fff; width: 850px; border: 0px solid black; font-size: blod;\">\n     <img src=\"https://images.cnblogs.com/cnblogs_com/zh94/1586631/o_211225012748_weixin_saoma.png\" />&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://images.cnblogs.com/cnblogs_com/zh94/1586631/o_211225012748_weixin_saoma.png\" />\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-04 22:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/zh94\">陈咬金</a>&nbsp;\n阅读(<span id=\"post_view_count\">39</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Flink源码阅读：Watermark机制",
      "link": "https://www.cnblogs.com/Jackeyzhe/p/19439749",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/Jackeyzhe/p/19439749\" id=\"cb_post_title_url\" title=\"发布于 2026-01-04 20:59\">\n    <span>Flink源码阅读：Watermark机制</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"Flink源码阅读：Watermark机制\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/1828322/202601/1828322-20260104205855506-262249653.png\" />\n        前面我们已经梳理了 Flink 状态和 Checkpoint 相关的源码。从本文开始，我们再来关注另外几个核心概念，即时间、Watermark 和窗口。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面我们已经梳理了 Flink 状态和 Checkpoint 相关的源码。从本文开始，我们再来关注另外几个核心概念，即时间、Watermark 和窗口。</p>\n<h3 id=\"写在前面\">写在前面</h3>\n<p>在 Flink 中 Watermark 是用来解决数据乱序问题的，它也是窗口关闭的触发条件。对于 Watermark 的概念和用法还不熟悉的同学可以先阅读<a href=\"https://jackeyzhe.github.io/2025/06/30/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%97%B6%E9%97%B4%E4%B8%8EWatermark/\" rel=\"noopener nofollow\" target=\"_blank\">Flink学习笔记：时间与Watermark</a>一文。下面我们进入正题，开始梳理 Watermark 相关的源码。</p>\n<h3 id=\"watermark-定义\">Watermark 定义</h3>\n<p>Watermark 的定义非常简单，它继承了 <code>StreamElement</code> 类，内部只有一个 timestamp 变量。</p>\n<pre><code class=\"language-java\">@PublicEvolving\npublic class Watermark extends StreamElement {\n\n    /** The watermark that signifies end-of-event-time. */\n    public static final Watermark MAX_WATERMARK = new Watermark(Long.MAX_VALUE);\n\n    /** The watermark that signifies is used before any actual watermark has been generated. */\n    public static final Watermark UNINITIALIZED = new Watermark(Long.MIN_VALUE);\n\n    // ------------------------------------------------------------------------\n\n    /** The timestamp of the watermark in milliseconds. */\n    protected final long timestamp;\n\n    /** Creates a new watermark with the given timestamp in milliseconds. */\n    public Watermark(long timestamp) {\n        this.timestamp = timestamp;\n    }\n\n    /** Returns the timestamp associated with this {@link Watermark} in milliseconds. */\n    public long getTimestamp() {\n        return timestamp;\n    }\n\n    // ------------------------------------------------------------------------\n\n    @Override\n    public boolean equals(Object o) {\n        return this == o\n                || o != null\n                        &amp;&amp; o.getClass() == this.getClass()\n                        &amp;&amp; ((Watermark) o).timestamp == timestamp;\n    }\n\n    @Override\n    public int hashCode() {\n        return (int) (timestamp ^ (timestamp &gt;&gt;&gt; 32));\n    }\n\n    @Override\n    public String toString() {\n        return \"Watermark @ \" + timestamp;\n    }\n}\n</code></pre>\n<h3 id=\"watermark-处理过程\">Watermark 处理过程</h3>\n<p>我们先来回顾一下 Watermark 的生成方法。</p>\n<pre><code class=\"language-java\">SingleOutputStreamOperator&lt;Event&gt; withTimestampsAndWatermarks = source\n        .assignTimestampsAndWatermarks(\n                WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(20))\n        );\n</code></pre>\n<h4 id=\"初始化\">初始化</h4>\n<p>在定义 Watermark 的时候，我们调用 assignTimestampsAndWatermarks 方法。</p>\n<pre><code class=\"language-java\">public SingleOutputStreamOperator&lt;T&gt; assignTimestampsAndWatermarks(\n        WatermarkStrategy&lt;T&gt; watermarkStrategy) {\n    final WatermarkStrategy&lt;T&gt; cleanedStrategy = clean(watermarkStrategy);\n    // match parallelism to input, to have a 1:1 source -&gt; timestamps/watermarks relationship\n    // and chain\n    final int inputParallelism = getTransformation().getParallelism();\n    final TimestampsAndWatermarksTransformation&lt;T&gt; transformation =\n            new TimestampsAndWatermarksTransformation&lt;&gt;(\n                    \"Timestamps/Watermarks\",\n                    inputParallelism,\n                    getTransformation(),\n                    cleanedStrategy,\n                    false);\n    getExecutionEnvironment().addOperator(transformation);\n    return new SingleOutputStreamOperator&lt;&gt;(getExecutionEnvironment(), transformation);\n}\n</code></pre>\n<p>这个方法接收了一个 WatermarkStrategy 参数，把它封装到 TimestampsAndWatermarksTransformation 中之后，就添加到 transformations 列表中了。在生成 StreamGraph 的过程中，会调用每个 transformation 的 transform 方法。</p>\n<p><img alt=\"transform\" class=\"lazyload\" /></p>\n<p>通过这个调用链路，创建出了 TimestampsAndWatermarksOperatorFactory，在初始化 StreamTask 时，会调用 <code>TimestampsAndWatermarksOperatorFactory.createStreamOperator</code> 方法来创建 TimestampsAndWatermarksOperator，并调用它的 open 方法。</p>\n<p>在这个 open 方法中，主要是生成 timestampAssigner 和 watermarkGenerator。timestampAssigner 是用于提取时间戳，watermarkGenerator 是用于生成 Watermark。</p>\n<p>生成完成之后注册了一个定时器，到指定时间后会调用 onProcessingTime 方法。</p>\n<pre><code class=\"language-java\">public void onProcessingTime(long timestamp) throws Exception {\n    watermarkGenerator.onPeriodicEmit(wmOutput);\n\n    final long now = getProcessingTimeService().getCurrentProcessingTime();\n    getProcessingTimeService().registerTimer(now + watermarkInterval, this);\n}\n</code></pre>\n<p>这个方法的逻辑也很简单，先发送创建并发送 Watermark，然后再注册一个定时器。</p>\n<h4 id=\"发送-watermark\">发送 Watermark</h4>\n<p><img alt=\"emitWatermark\" class=\"lazyload\" /></p>\n<p>我们以 BoundedOutOfOrdernessWatermarks 为例，它向下游发送了一个 Watermark，时间戳为 maxTimestamp - outOfOrdernessMillis - 1（maxTimestamp 是当前最大的事件时间戳，outOfOrdernessMillis 是我们定义的周期时间毫秒值）。随后在 WatermarkEmitter.emitWatermark 方法中，更新了当前 Watermark 的值。最后 RecordWriterOutput.emitWatermark 则是向下游广播当前的 Watermark。</p>\n<h4 id=\"下游处理\">下游处理</h4>\n<p>下游处理方法我们从 <code>StreamOneInputProcessor.processInput</code> 入手，先来看具体的调用链路。</p>\n<p><img alt=\"processWatermark\" class=\"lazyload\" /></p>\n<p>在 inputWatermark 方法中，先是对 alignedSubpartitionStatuses 进行调整，alignedSubpartitionStatuses 这个变量主要是用来获取最小的 Watermark。最后调用了 <code>findAndOutputNewMinWatermarkAcrossAlignedSubpartitions</code> 方法。这个方法中，会获取到所有上游最小的 Watermark，如果它大于最近发送的一个 Watermark，就会向下游发送。</p>\n<pre><code class=\"language-java\">public void emitWatermark(Watermark watermark) throws Exception {\n    watermarkGauge.setCurrentWatermark(watermark.getTimestamp());\n    operator.processWatermark(watermark);\n}\n</code></pre>\n<p>这个发送方法中，调用了 <code>operator.processWatermark</code>，我们接着看这个处理方法。</p>\n<p><img alt=\"advanceWatermark\" class=\"lazyload\" /></p>\n<p>在 tryAdvanceWatermark 方法中如果 Watermark 的时间大于 eventTimeTimersQueue 队列中头节点的时间，那么对 eventTimeTimersQueue 这个队列进行出队操作，这个操作意味着触发了窗口计算。</p>\n<pre><code class=\"language-java\">public boolean tryAdvanceWatermark(\n        long time, InternalTimeServiceManager.ShouldStopAdvancingFn shouldStopAdvancingFn)\n        throws Exception {\n    currentWatermark = time;\n    InternalTimer&lt;K, N&gt; timer;\n    boolean interrupted = false;\n    while ((timer = eventTimeTimersQueue.peek()) != null\n            &amp;&amp; timer.getTimestamp() &lt;= time\n            &amp;&amp; !cancellationContext.isCancelled()\n            &amp;&amp; !interrupted) {\n        keyContext.setCurrentKey(timer.getKey());\n        eventTimeTimersQueue.poll();\n        triggerTarget.onEventTime(timer);\n        taskIOMetricGroup.getNumFiredTimers().inc();\n        // Check if we should stop advancing after at least one iteration to guarantee progress\n        // and prevent a potential starvation.\n        interrupted = shouldStopAdvancingFn.test();\n    }\n    return !interrupted;\n}\n</code></pre>\n<p>之后 Watermark 就随着数据流一直到 sink 节点，在 StreamSink 中，支持用户自己实现方法向 sink 中写入 Watermark，除此之外什么也不做。</p>\n<h3 id=\"总结\">总结</h3>\n<p>本文我们一起梳理了 Watermark 相关的源码，从 Watermark 的定义，到 Watermark 的处理过程。处理过程分成了初始化、上游发送和下游处理三部分。在下游处理部分，关于触发窗口计算的部分我们简单带过了，后面会再详细介绍这部分。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-04 20:59</span>&nbsp;\n<a href=\"https://www.cnblogs.com/Jackeyzhe\">Jackeyzhe</a>&nbsp;\n阅读(<span id=\"post_view_count\">40</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "【Azure Web App】Github Action部署Jar包到App Service报400错误",
      "link": "https://www.cnblogs.com/lulight/p/19439653",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/lulight/p/19439653\" id=\"cb_post_title_url\" title=\"发布于 2026-01-04 20:07\">\n    <span>【Azure Web App】Github Action部署Jar包到App Service报400错误</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h1>问题描述</h1>\n<p>通过github aciton部署azure app service服务的时候，遇见400报错。</p>\n<p>报错信息非常简单：</p>\n<blockquote>\n<p>Starting deployment for web app...<br />Package deployment using OneDeploy initiated.<br />Error: Failed to deploy web package to App Service.<br /><span style=\"color: rgba(255, 0, 0, 1);\"><strong>Error: Deployment Failed, Error: Failed to deploy web package using OneDeploy to App Service.</strong></span><br />Bad Request (CODE: 400)</p>\n</blockquote>\n<p> 这个问题应该如何调查呢？</p>\n<p>&nbsp;</p>\n<h1>问题解答</h1>\n<p>在Github Aciton中，使用 Azure WebApp(azure/webapps-deploy@v3)来部署App Service的应用, 这次部署的是一个jar包。</p>\n<p>Github Action  脚本:</p>\n<blockquote>\n<p>- name: Azure WebApp<br />uses: azure/webapps-deploy@v3<br />with:<br />app-name: '&lt;app service name&gt;'<br />package: ${{ github.workspace }}/target/*.jar<br /> </p>\n</blockquote>\n<p>查看Azure文档，介绍部署java应用时，使用az cli命令，github action和maven 插件都是使用的Kudu OneDeploy接口( https://&lt;your web app&gt;.scm.chinacloudsites.cn/api/publish?type=jar )</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"235\" width=\"666\" /></p>\n<p>(文档链接：<a href=\"https://docs.azure.cn/zh-cn/app-service/configure-language-java-deploy-run?tabs=linux&amp;pivots=java-tomcat#deploying-your-app\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.azure.cn/zh-cn/app-service/configure-language-java-deploy-run?tabs=linux&amp;pivots=java-tomcat#deploying-your-app</a>)</p>\n<p>&nbsp;</p>\n<p>根据以上信息，就尝试使用az webapp deploy命令直接部署jar包应用，发现多了一句错误提示信息：</p>\n<blockquote>\n<p><span style=\"color: rgba(255, 0, 255, 1);\">&gt; <strong>az webapp deploy --resource-group &lt;your resource group name&gt; --name &lt;your app service name&gt; --src-path myjava.jar --type jar</strong></span></p>\n<p>Initiating deployment<br />Deploying from local path: myjava.jar<br />An error occurred during deployment. Status Code: 400, </p>\n<p><strong><span style=\"color: rgba(255, 0, 0, 1);\">Details: \"Artifact type = 'Jar' cannot be deployed to stack = 'TOMCAT'. Site should be configured to run with stack = JAVA\", </span></strong></p>\n<p>Please visit https://XXXXXXXXX.scm.chinacloudsites.cn/api/deployments/latest to get more information about your deployment</p>\n</blockquote>\n<p>这句错误消息非常关键(Artifact type = 'Jar' cannot be deployed to stack = 'TOMCAT'. Site should be configured to run with stack = JAVA\")。</p>\n<p>在查看App Service的配置信息后，Stack果然设置为Tomcat。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"465\" width=\"666\" /></p>\n<p>因为这里只有两种选项( Tomcat 和Java SE )。于是，修改为Java SE后，再次部署jar包。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"194\" width=\"666\" /></p>\n<p>成功。</p>\n<p>&nbsp;</p>\n<p>当问题解决后，想进一步验证是否是one deploy接口对jar包的强制限制。</p>\n<p>恰好kudu也是开源项目，所以，进入github kudu 仓库 (源码：<a href=\"https://github.com/projectkudu/kudu/tree/master\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/projectkudu/kudu/tree/master</a> )，使用错误消息关键字整库搜索“cannot be deployed to stack”，最终，定位到 PushDeploymentController.cs 中，有如下的验证条件：</p>\n<ul>\n<li>当部署的文件为Jar时，需要判断目标App Service的Stack只能是JavaSE。如果不是，返回400的状态码</li>\n</ul>\n<p><img alt=\"image\" class=\"lazyload\" height=\"110\" width=\"666\" /></p>\n<p>&nbsp;</p>\n<h2>附录一：使用 curl 命令直接调用接口也可以复现问题，效果和az webapp deploy命令相同</h2>\n<div class=\"cnblogs_code\">\n<pre><span style=\"background-color: rgba(255, 255, 0, 1);\">curl -<span style=\"color: rgba(0, 0, 0, 1);\">X POST \\\n\n     </span>-<span style=\"color: rgba(0, 0, 0, 1);\">u user:password \\\n\n     </span>-T <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">/Users/Downloads/xxxxx-0.0.1-SNAPSHOT.jar</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> \\\n\n     </span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">https://xxxxx.scm.chinacloudsites.cn/api/publish?type=jar</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\"> \\\n\n     </span>-<span style=\"color: rgba(0, 0, 0, 1);\">v\n\n\n\n</span></span>* Host xxxxx.scm.chinacloudsites.cn:<span style=\"color: rgba(128, 0, 128, 1);\">443</span><span style=\"color: rgba(0, 0, 0, 1);\"> was resolved.\n\n</span>*<span style=\"color: rgba(0, 0, 0, 1);\"> IPv6: (none)\n\n</span>* IPv4: <span style=\"color: rgba(128, 0, 128, 1);\">159.27</span>.<span style=\"color: rgba(128, 0, 128, 1);\">20.0</span>\n\n*   Trying <span style=\"color: rgba(128, 0, 128, 1);\">159.27</span>.<span style=\"color: rgba(128, 0, 128, 1);\">20.0</span>:<span style=\"color: rgba(128, 0, 128, 1);\">443</span><span style=\"color: rgba(0, 0, 0, 1);\">...\n\n</span>* Connected to xxxxx.scm.chinacloudsites.cn (<span style=\"color: rgba(128, 0, 128, 1);\">159.27</span>.<span style=\"color: rgba(128, 0, 128, 1);\">20.0</span>) port <span style=\"color: rgba(128, 0, 128, 1);\">443</span>\n\n* ALPN: curl offers h2,http/<span style=\"color: rgba(128, 0, 128, 1);\">1.1</span>\n\n* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (OUT), TLS handshake, Client hello (<span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>*  CAfile: /etc/ssl/<span style=\"color: rgba(0, 0, 0, 1);\">cert.pem\n\n</span>*<span style=\"color: rgba(0, 0, 0, 1);\">  CApath: none\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (IN), TLS handshake, Server hello (<span style=\"color: rgba(128, 0, 128, 1);\">2</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (OUT), TLS handshake, Client hello (<span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (IN), TLS handshake, Server hello (<span style=\"color: rgba(128, 0, 128, 1);\">2</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (IN), TLS handshake, Unknown (<span style=\"color: rgba(128, 0, 128, 1);\">8</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (IN), TLS handshake, Certificate (<span style=\"color: rgba(128, 0, 128, 1);\">11</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (IN), TLS handshake, CERT verify (<span style=\"color: rgba(128, 0, 128, 1);\">15</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (IN), TLS handshake, Finished (<span style=\"color: rgba(128, 0, 128, 1);\">20</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* (<span style=\"color: rgba(128, 0, 128, 1);\">304</span>) (OUT), TLS handshake, Finished (<span style=\"color: rgba(128, 0, 128, 1);\">20</span><span style=\"color: rgba(0, 0, 0, 1);\">):\n\n</span>* SSL connection <span style=\"color: rgba(0, 0, 255, 1);\">using</span> TLSv1.<span style=\"color: rgba(128, 0, 128, 1);\">3</span> / AEAD-AES256-GCM-SHA384 / [blank] /<span style=\"color: rgba(0, 0, 0, 1);\"> UNDEF\n\n</span>* ALPN: server accepted http/<span style=\"color: rgba(128, 0, 128, 1);\">1.1</span>\n\n*<span style=\"color: rgba(0, 0, 0, 1);\"> Server certificate:\n\n</span>*  subject: C=CN; ST=Shanghai; O=Shanghai Blue Cloud Technology Co., Ltd.; CN=*<span style=\"color: rgba(0, 0, 0, 1);\">.chinacloudsites.cn\n\n</span>*  start date: Dec <span style=\"color: rgba(128, 0, 128, 1);\">19</span> <span style=\"color: rgba(128, 0, 128, 1);\">00</span>:<span style=\"color: rgba(128, 0, 128, 1);\">00</span>:<span style=\"color: rgba(128, 0, 128, 1);\">00</span> <span style=\"color: rgba(128, 0, 128, 1);\">2025</span><span style=\"color: rgba(0, 0, 0, 1);\"> GMT\n\n</span>*  expire date: Jun <span style=\"color: rgba(128, 0, 128, 1);\">17</span> <span style=\"color: rgba(128, 0, 128, 1);\">23</span>:<span style=\"color: rgba(128, 0, 128, 1);\">59</span>:<span style=\"color: rgba(128, 0, 128, 1);\">59</span> <span style=\"color: rgba(128, 0, 128, 1);\">2026</span><span style=\"color: rgba(0, 0, 0, 1);\"> GMT\n\n</span>*  subjectAltName: host <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">xxxxx.scm.chinacloudsites.cn</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span> matched cert<span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">s \"*.scm.chinacloudsites.cn\"</span>\n\n*  issuer: C=US; O=DigiCert Inc; CN=<span style=\"color: rgba(0, 0, 0, 1);\">DigiCert Basic RSA CN CA G2\n\n</span>*<span style=\"color: rgba(0, 0, 0, 1);\">  SSL certificate verify ok.\n\n</span>* <span style=\"color: rgba(0, 0, 255, 1);\">using</span> HTTP/<span style=\"color: rgba(128, 0, 128, 1);\">1</span><span style=\"color: rgba(0, 0, 0, 1);\">.x\n\n</span>* Server auth <span style=\"color: rgba(0, 0, 255, 1);\">using</span> Basic with user <span style=\"color: rgba(128, 0, 0, 1);\">'</span><span style=\"color: rgba(128, 0, 0, 1);\">deploypoc</span><span style=\"color: rgba(128, 0, 0, 1);\">'</span>\n\n&gt; POST /api/publish?type=jar HTTP/<span style=\"color: rgba(128, 0, 128, 1);\">1.1</span>\n\n&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> Host: xxxxx.scm.chinacloudsites.cn\n\n</span>&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> Authorization: Basic xxxxxxxxxxxxxxxx\n\n</span>&gt; User-Agent: curl/<span style=\"color: rgba(128, 0, 128, 1);\">8.7</span>.<span style=\"color: rgba(128, 0, 128, 1);\">1</span>\n\n&gt; Accept: *<span style=\"color: rgba(0, 128, 0, 1);\">/*</span><span style=\"color: rgba(0, 128, 0, 1);\">\n\n&gt; Content-Length: 25578166\n\n&gt; Expect: 100-continue\n\n&gt; \n\n* Done waiting for 100-continue\n\n&lt; HTTP/1.1 400 Bad Request\n\n&lt; Content-Type: text/plain; charset=utf-8\n\n&lt; Date: Wed, 31 Dec 2025 03:42:36 GMT\n\n&lt; Server: Kestrel\n\n&lt; Set-Cookie: ARRAffinity=xxxx;Path=/;HttpOnly;Secure;Domain=xxxxx.scm.chinacloudsites.cn\n\n&lt; Set-Cookie: ARRAffinitySameSite=xxxxx;Path=/;HttpOnly;SameSite=None;Secure;Domain=xxxxx.scm.chinacloudsites.cn\n\n&lt; Transfer-Encoding: chunked\n\n&lt; \n\n* HTTP error before end of send, stop sending\n\n* abort upload after having sent 589824 bytes\n\n* Closing connection\n\n<span style=\"background-color: rgba(255, 255, 0, 1);\">Artifact type = 'Jar' cannot be deployed to stack = 'TOMCAT'. Site should be configured to run with stack = JAVA%   </span> </span></pre>\n</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h1>参考资料</h1>\n<p>App Service部署Java应用：<a href=\"https://docs.azure.cn/zh-cn/app-service/configure-language-java-deploy-run?tabs=linux&amp;pivots=java-tomcat#deploying-your-app\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.azure.cn/zh-cn/app-service/configure-language-java-deploy-run?tabs=linux&amp;pivots=java-tomcat#deploying-your-app</a></p>\n<p>Kudu One Deploy Source Code ： <a href=\"https://github.com/projectkudu/kudu/blob/master/Kudu.Services/Deployment/PushDeploymentController.cs#L304\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/projectkudu/kudu/blob/master/Kudu.Services/Deployment/PushDeploymentController.cs#L304</a></p>\n<p>&nbsp;</p>\n</div>\n<div id=\"MySignature\">\n    <div style=\"background: #1c5f55; height: 36px; width: 618px; padding: 14px 5px 0px 3px;\">\n  <p style=\"font-weight: bold; color: white;\">当在复杂的环境中面临问题，格物之道需：浊而静之徐清，安以动之徐生。 云中，恰是如此!</p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-04 20:07</span>&nbsp;\n<a href=\"https://www.cnblogs.com/lulight\">路边两盏灯</a>&nbsp;\n阅读(<span id=\"post_view_count\">32</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "让WinForms再次伟大",
      "link": "https://www.cnblogs.com/xdesigner/p/19438384/Make_WinForms_Great_Again",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xdesigner/p/19438384/Make_WinForms_Great_Again\" id=\"cb_post_title_url\" title=\"发布于 2026-01-04 15:49\">\n    <span>让WinForms再次伟大</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"postText\">    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本项目就是专门帮助将WinForms 应用程序迁移到 Blazor WASM平台上，即使这些程序使用GDI+功能，我们也预期将对这些程序源码的修改量不超过10%。这极大的降低WinForms软件现代化的成本和风险。\n我们的长期目标是能将全球1000亿行经过市场验证的C#代码能重获新生，在现代Web前端平台上继续发挥价值。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"让-winforms-再次伟大-httpsgithubcomdcsoft-yyfmwga\">让 WinForms 再次伟大 <a href=\"https://github.com/dcsoft-yyf/MWGA\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/dcsoft-yyf/MWGA</a></h1>\n<h2 id=\"更新日志\">更新日志</h2>\n<ul>\n<li>2026-1-4 :第一滴血 <a href=\"https://dcsoft-yyf.github.io/MWGA/WinFormCalculator.html\" rel=\"noopener nofollow\" target=\"_blank\">https://dcsoft-yyf.github.io/MWGA/WinFormCalculator.html</a></li>\n</ul>\n<h2 id=\"全球-winforms-现代化现状\">全球 WinForms 现代化现状</h2>\n<p>全球范围内，估计WinForms开发者约有300万至500万人，占.NET开发者总数的40%至50%。生产环境中运行着1000万至1500万个WinForms应用程序。在这些应用中，60%至80%有现代化改造需求，其中40%至60%优先选择Web化迁移，涉及的C#代码可能有<code>数千亿行</code>。核心驱动因素包括网页端访问、界面现代化、跨平台支持、云集成和安全合规。由于可复用C#代码且具备基于浏览器的跨平台能力，Blazor WebAssembly成为热门选择。</p>\n<p>但是有大量的WinForms使用了<code>System.Drawing</code>模块调用<code>GDI+</code>进行复杂的自定义绘图和交互，这些部分难以通过简单的控件映射迁移，通常需要重写或大幅修改。为此，市场上对低改动、可复用业务逻辑和绘图代码的现代化迁移解决方案需求强烈。但长期以来一直缺乏有效工具和方法，导致许多企业面临高昂的重写成本和风险。</p>\n<h2 id=\"项目简介\">项目简介</h2>\n<p>本项目就是专门帮助将WinForms 应用程序迁移到 Blazor WASM平台上，即使这些程序使用GDI+功能，我们也预期将对这些程序源码的修改量不超过<code>10%</code>。这极大的降低WinForms软件现代化的成本和风险。</p>\n<p>我们的长期目标是能将全球<code>1000亿</code>行经过市场验证的C#代码能重获新生，在现代Web前端平台上继续发挥价值。</p>\n<h2 id=\"全球待迁移-winforms-应用市场规模估算美元\">全球待迁移 WinForms 应用市场规模估算（美元）</h2>\n<p>假设需要迁移的 WinForms 应用约 50 万 – 200 万 个；应用复杂度分布：简单 60%、中等 30%、复杂 10%。</p>\n<ul>\n<li>按示例单应用迁移成本中位数估算（美元）：加权均价约 5.5 万美元/应用。</li>\n<li>TAM（总可寻址市场）估算：约 275 亿 – 1,100 亿 美元（50 万 – 200 万 应用 × 5.5 万美元）。</li>\n<li>工具/许可模式可寻址市场（5 千 – 2 万 美元/应用）：约 25 亿 – 400 亿 美元。</li>\n<li>复杂应用（10%）市场：约 5 万 – 20 万 个，按每例 15 万美元计约 75 亿 – 300 亿 美元。</li>\n</ul>\n\n</div>\n<div class=\"clear\"></div>\n</div>\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-01-04 15:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xdesigner\">袁永福 电子病历，医疗信息化</a>&nbsp;\n阅读(<span id=\"post_view_count\">1399</span>)&nbsp;\n评论(<span id=\"post_comment_count\">12</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "读写分离面临的问题及其解决方案",
      "link": "https://www.cnblogs.com/huang-changfan/p/19185323",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/huang-changfan/p/19185323\" id=\"cb_post_title_url\" title=\"发布于 2026-01-04 15:48\">\n    <span>读写分离面临的问题及其解决方案</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"1读写分离带来的问题及解决方法\">1.读写分离带来的问题及解决方法</h1>\n<h2 id=\"11-延时问题\">1.1 延时问题</h2>\n<p>主从复制，主库与从库之间由于网络，设备差异，负载情况等，必然存在延时，延时有大有小，只要延时保持再一个合理的范围内是可以接受的。</p>\n<p>1.1.1造成主从延时的参见原因</p>\n<ul>\n<li>主从设备差异：例如主库性能较好，从库性能较差，对于同样的写入或更新操作，主库能较快完成，从库花费时间较多，如果系统持续维持高频的写入更新，主库与从库之间的差异会被逐渐拉大。导致主从的延迟越来越大。对于这种情况，需要尽量保证主从服务器性能一致，使得两种处理相同量的数据花费的时间尽可能接近。这样一般情况而言主从延时可以保证在一个合理范围，不会出现很大的差异。</li>\n<li>从库上执行了过多任务：由于从库是只读的，加上相比于主库而言重要性没那么高，所以其他系统可能会从库进行大量的数据同步或分析业务，导致从库被占用过多资源，处理从主库同步过来的日志较慢，造成了延迟。此时需要注意从库的压力，考虑负载均衡或采用其他方式使得从库负载不要太高，造成较长延迟。</li>\n<li>大事务：如果主库执行一个要更新或删除大量数据的SQL，例如主库都需要执行20s.那么对于语句或数据（取决于binlog格式）复制到从库，从库也需要执行20s.这样主从之间就天然的存在一个延迟，这个延时由事务的执行时间决定。所以需要避免大事务，开发过程中就需要注意，同时需要添加监控，对于执行情况进行监控预警。</li>\n</ul>\n<p>提高从库复制性能的方法：从库的io线程通过读取主库的日志，然后sql线程将读取日志内容执行，如果执行sql的线程是单线程执行效率会偏低。主库写入时是可以并发写入的，如果从库执行采用多线程执行，可以提高从库的复制效率降低延迟。MySQL会判断可以并发执行的部分语句使用多个线程并发执行。</p>\n<h2 id=\"12--读写分离的挑战读一致性\">1.2  读写分离的挑战：读一致性</h2>\n<p>主从的延迟总会存在，那么一个操作写入主库，此时从从库读取数据，可能读到可能读不到，这取决于从库的延迟以及读取的时机。如果主从延迟大于，写入主库与读取从库的间隔，那么读取的从库就不会存在这次写入操作。反之就可以读取到这次写入操作。这两种情况存在一定的随机成分，例如用户写入主库后，很快进行了读取，可能这次读取的从库没有当前的写入数据。如果用户隔了一段时间才读取，这次可能可以在从库中读取对于的操作。<br />\n由此引发了读一致的问题，有些操作可以接受一定程度的延迟，有些操作不能接收延迟，需要保证写后立即可见。</p>\n<h3 id=\"121-读之所写\">1.2.1 读之所写</h3>\n<p><img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202511/1435315-20251129211311701-1878061974.png\" /><br />\n例如用户编辑自己的主页信息，保存后刷新页面获取自己的主页信息。第一个操作是写操作，请求会被路由到主库，第二个操作是读操作会被路由到从库。<br />\n如果主库与从库之间存在延时，且第二次读取操作的从库还没有及时同步主库的数据，此时就会出现怪异的现象，用户编辑后执行保存，提示保存成功。但他刷新页面，发现页面还是修改前的信息。<br />\n这显然会对用户造成困扰，或者所一致性被破坏，记录提示了用户保存成功，那么刷新页面读取时应该读取到保存的数据，但实际情况确没有读取到。这种不一致性可能还会导致用户重复操作，造成损失，例如用户执行一个操作提示成功，然后用户查询，发现没有记录刚才的操作，他可能会再次执行这个操作，后续主从同步完毕后，他会查询到两次操作，可他的预期是只进行一次操作。<br />\n针对用户写入后，需要读取到自己写入的最新数据，这种读一致性称为读己所写。</p>\n<p>如何保证读己所写的隔离级别？</p>\n<ul>\n<li>读主库：简单粗暴直接读主库，如果当前的读操作对一致性要去较高，直接读主库，这次请求肯定保证读的一致性，对于同一个实例就不存在一致性问题了。但其缺点也很明显，读写分离是为了将读操作路由到从库，降低主库负载，使得系统提供更多的吞吐量。如果多数读请求最后还是被路由到了主库，扩展性降低了，大量操作都依赖主库，没有被剥离出来。</li>\n<li>判断主从点位，选择合适的从库<br />\n例如用户写入主库后，当前bindlog的点位是100.执行<code>show slave status;</code>获取从库同步主库的点位信息，如果当前从库的点位信息大于等于主库，那么主库之前的写操作在该从库是可见的。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202511/1435315-20251129213640521-349884627.png\" /><br />\n例如上图，如果主库写入的时的点位小于等于当前从库的点位，那么此次读取操作对之前的写入操作可见。<br />\n当然，如果主从延时比较大，例如30s.不可能等到从库同步好之后再查询从库，延时较大情况，指定时间内没有满足条件的从库需要触发降级逻辑，可直接查询主库。同时添加好监控，延时达到上限需要告警，同时统计好路由从库失败被转发到主库的操作，想办法优化对应问题。</li>\n</ul>\n<p>当然也不是所有的操作需要读己所写，还需要根据具体业务情况分析。以上例为例，对于用户编辑自己主页信息，对于用户本人来说肯定是需要读己所写的。当对于其他人来说则不需要读己所写，访问其他人的主页，由于自己不可能编辑他人的主页，所以主页的写操作对他人来说是不可见的，此时直接读取从库即可，等待从库同步好对应数据后，才读取最新数据也是可以接受的。这样看读取其他用户的主页似乎没有问题，何时同步好就何时读取最新数据，但是存在多个从库又会带来新的问题，这就是下一节的单调读问题。</p>\n<h3 id=\"122基于sharding-jdbc实现读之所写\">1.2.2基于sharding jdbc实现读之所写。</h3>\n<ul>\n<li>基本环境：一主两从基于jdbc。主库3310端口，从库3311，3312端口.</li>\n<li>实现思路：自定义从库选择算法，如果需要读己所写，将请求路由到合适的从库，如果没有从库符合条件，路由到主库。</li>\n<li>整体流程：\n<ol>\n<li>定时Job读取主库从库点位信息记录在Redis中。</li>\n<li>对于需要记录点位信息的写操作添加注解，写入后记录事务提交时的点位信息</li>\n<li>读请求添加注解，标识当前请求是否需要读之所写，记录在上下文中。</li>\n<li>根据当前用户写入操作时记录的点位，选择合适的从库，如果没有符合条件的，降级到主库。</li>\n</ol>\n</li>\n</ul>\n<pre><code>    /**  \n     * 1.定时Job读取主库从库点位信息记录在Redis中。\n     * 每500ms刷新主库与库点位信息\n     *\n     * @throws SQLException\n     */\n    @Scheduled(fixedRate = 5000) // 每500ms更新一次\n    public void refreshSlavePositon() throws SQLException {\n        log.info(\"zookeeper info ={}\", JSON.toJSONString(this.zookeeperCurrentVersionInfoHolder));\n        //写入从库点位\n        Map&lt;String, Connection&gt; slaveConnection = getSlaveConnection();\n        slaveConnection.forEach((slaveName, connection) -&gt; {\n            try {\n                log.info(\"slave={} url={}\", slaveName, connection.getMetaData().getURL());\n            } catch (SQLException e) {\n                throw new RuntimeException(e);\n            }\n            BinlogPosition binlogPosition = this.getSlaveBinLogPoint(connection);\n            redisTemplate.&lt;String, String&gt;opsForHash().put(slavesPositionInfoCachePreKey, slaveName, JSON.toJSONString(binlogPosition));\n        });\n\n        //写入主库点位\n        Connection masterConnection = getMasterConnection();\n        log.info(\"masterConnection url={}\", masterConnection.getMetaData().getURL());\n        BinlogPosition binlogPosition = this.getMasterBinLogPoint(masterConnection);\n        redisTemplate.&lt;String, String&gt;opsForHash().put(slavesPositionInfoCachePreKey, MASTER_DB_NAME, JSON.toJSONString(binlogPosition));\n    }\n</code></pre>\n<pre><code>/**\n * 2.对于需要记录点位信息的写操作添加注解，写入后记录事务提交时的点位信息\n */\n@Slf4j\n@Aspect\n@Component\npublic class CacheUserBinlogPositionAspect {\n\n    @Autowired\n    private BinlogPositionService binLogService;\n\n    @Pointcut(\"@annotation(com.example.annotation.CacheUserBinlogPosition)\")\n    public void cacheUserMasterPositionCut() {\n    }\n\n    @AfterReturning(pointcut = \"cacheUserMasterPositionCut()\", returning = \"result\")\n    public Object cacheMasterPosition(JoinPoint joinPoint, Object result) throws Throwable {\n        String uid = UserManager.getUid();\n\n        // 注册事务回调，由于执行到改切面时，事务的切面还没有提交，所以需要注册事务提交后执行获取点位方法，以确保获取提交后的点位信息\n        TransactionSynchronizationManager.registerSynchronization(\n                new TransactionSynchronization() {\n                    @Override\n                    public void afterCommit() {\n                        // 在事务提交后执行\n                        try {\n                            //获取主库点位\n                            BinlogPosition masterDBPosition = binLogService.getMasterBinLogPoint();\n                            //缓存当前用户主库点位\n                            binLogService.cacheUserBinlogPosition(uid, masterDBPosition);\n                        } catch (Exception e) {\n                            log.error(\"记录binlog点位失败\", e);\n                        }\n                    }\n                }\n        );\n\n        return result;\n    }\n}\n</code></pre>\n<pre><code>/**\n * 3. 读请求添加注解，标识当前请求是否需要读之所写，记录在上下文中。\n */\n@Slf4j\n@Aspect\n@Component\npublic class ReadConsistencyAspect {\n\n    @Pointcut(\"@annotation(com.example.annotation.ReadSelfWrite)\")\n    public void readSelfWritePointCut() {\n    }\n\n    @Before(value = \"readSelfWritePointCut()\")\n    public void readSelfWritePoint(JoinPoint joinPoint) throws Throwable {\n        //对于标注了读己所写的接口，上下文中设置对应属性\n        ReadConsistencyManager.setReadSelfWrite();\n    }\n}\n</code></pre>\n<pre><code>  /**\n   *4. 根据当前用户写入操作时记录的点位，选择合适的从库，如果没有符合条件的，降级到主库。\n  */\n  @Slf4j\npublic class BinlogAwareLoadBalanceAlgorithm implements ReadQueryLoadBalanceAlgorithm {\n\n    private Properties properties;\n\n    @Override\n    public Properties getProps() {\n        return this.properties;\n\n    }\n\n    @Override\n    public void init(Properties properties) {\n        this.properties = properties;\n    }\n\n    @Override\n    public String getType() {\n        return \"BINLOG_AWARE\";\n    }\n\n    /**\n     * read query load-balance algorithm.\n     * @param name read query logic data source name\n     * @param writeDataSourceName name of write data source\n     * @param readDataSourceNames names of read data sources\n     * @param context context\n     * @return\n     */\n    @Override\n    public String getDataSource(String name, String writeDataSourceName, List&lt;String&gt; readDataSourceNames, TransactionConnectionContext context) {\n        return this.getDataSource(name, writeDataSourceName, readDataSourceNames);\n    }\n\n    /**\n     * 选择数据源的核心方法\n     *\n     * @param name                read query logic data source name\n     * @param writeDataSourceName 主库名称\n     * @param readDataSourceNames 从库名称列表\n     * @return 选择的数据源名称\n     */\n    public String getDataSource(String name, String writeDataSourceName, List&lt;String&gt; readDataSourceNames) {\n        try {\n            if (ReadConsistencyManager.readSelfWrite()) {\n                //要求读之所写\n                return getDb(writeDataSourceName, readDataSourceNames);\n            } else {\n                //不要求读之所写\n                return loadBalance(readDataSourceNames);\n            }\n        } finally {\n            //清理Thread Local\n            ReadConsistencyManager.clear();\n        }\n    }\n\n    /**\n     * 获取大于等于用户当前存储点位信息的从库，如果没有从库满足条件，返回主库。存储的点位不不会过期情况下。\n     * @param writeDataSourceName\n     * @param readDataSourceNames\n     * @return\n     */\n    private String getDb(String writeDataSourceName, List&lt;String&gt; readDataSourceNames) {\n        //该类被SPI创建，无法通过spring容器注入，所以通过单例模式从容器中获取service\n        BinlogPositionService binlogPositionService = Singleton.getBinlogPositionServiceInstance();\n        //获取用户点位\n        BinlogPosition positionInfo = binlogPositionService.getUserPosition(UserManager.getUid());\n        //存在点位信息\n        if (positionInfo.isEffective()) {\n            //可以找到包含指定点位的从库，返回对于从库\n            List&lt;String&gt; containsSpecPositionSourceName = binlogPositionService.getContainSpecPositionSlave(positionInfo);\n            if (CollectionUtils.isNotEmpty(containsSpecPositionSourceName)) {\n                return loadBalance(containsSpecPositionSourceName);\n            }\n\n            //没有查询到满足条件的从库，查询主库\n            return writeDataSourceName;\n        } else {\n            //没有点位信息,用户没有执行过写操作\n            //此时，任选一个从库即可\n            return loadBalance(slaveNames);\n        }\n    }\n\n    /**\n     * 负载均衡策略随机选择\n     *\n     * @param readDataSourceNames\n     * @return\n     */\n    private String loadBalance(List&lt;String&gt; readDataSourceNames) {\n        return readDataSourceNames.get(ThreadLocalRandom.current().nextInt(readDataSourceNames.size()));\n    }\n</code></pre>\n<p>以上策略实在用户点位信息没有过期时间的基础上可保证读己所写。如果点位设置了过期时间，则需要调整逻辑。（如果保证点位信息不会过期，或者存储到用户侧始终会有点位信息，就不需要考入下列逻辑了）<br />\n如果点位设置了过期时间，没有获取到点位信息可能存在两种情况。<br />\n1.用户没有执行写操作。<br />\n2.用户执行了写操作，但当前时间已经超过点位的过期时间。<br />\n由于1.2在点位不存在的情况下，无法区分具体是哪一种情况。所以此时就需要判断主从同步延时，选取延迟时间小于等于过期时间的从库，满足条件的从库即可以读取到之前写入的数据。<br />\n证明过程如下：<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202511/1435315-20251130170958176-301806385.png\" /><br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202511/1435315-20251130171047342-618582452.png\" /><br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202511/1435315-20251130171106033-569878748.png\" /><br />\n延迟时间小于等于过期时间的从库，可以读取到之前的写入数据，但如果延时时间大于过期时间，实际存在两种情况，一种是可以读取到，一种是无法读取到。<br />\n此时由于点位已经过期，无法区分出来。所以统一走降级逻辑查主库。<br />\n从库包含写入的条件：Δt ≥ L。<br />\n延时时间(L)大于过期时间（6s）<br />\nΔt = 10秒, L = 8秒<br />\n条件：10 ≥ 8 ✅<br />\n结果：从库已包含写入，可以安全读取</p>\n<p>Δt = 7秒, L = 9秒<br />\n条件：7 ≥ 9 ❌<br />\n结果：从库还未同步写入，读取会得到旧数据<br />\n例如用户写入后，数据被同步到了所有从库，用户第二天发起查询请求，此时点位信息以及过期，且用户写入主库数据已经同步到所有从库。<br />\n用户此时需要判断主从延时，假设此时主从延时达到30s.但是用户昨天的数据早已写入，此时还是会被路由到主库。</p>\n<pre><code>/**\n     * 获取大于等于用户当前存储点位信息的从库，如果没有从库满足条件，返回主库。\n     * @param writeDataSourceName\n     * @param readDataSourceNames\n     * @return\n     */\n    private String getDb(String writeDataSourceName, List&lt;String&gt; readDataSourceNames) {\n        //该类被SPI创建，无法通过spring容器注入，所以直接从容器中获取service\n        BinlogPositionService binlogPositionService = Singleton.getBinlogPositionServiceInstance();\n        //获取用户点位\n        BinlogPosition positionInfo = binlogPositionService.getUserPosition(UserManager.getUid());\n        //存在有效的点位信息\n        if (positionInfo.isEffective()) {\n            //可以找到包含指定点位的从库，返回对于从库\n            List&lt;String&gt; containsSpecPositionSourceName = binlogPositionService.getContainSpecPositionSlave(positionInfo);\n            if (CollectionUtils.isNotEmpty(containsSpecPositionSourceName)) {\n                return loadBalance(containsSpecPositionSourceName);\n            }\n\n            //没有查询到满足条件的从库，查询主库\n            return writeDataSourceName;\n        } else {\n            //没有点位信息存在两种情况\n            //case1 用户没有执行过写操作\n            //此时，任选一个从库即可\n            //case2 用户执行写操作，但存储的用户点位信息已过期。\n            //可将用户点位信息过期时间，设置为主从延迟的三倍。用户点位过期是主从延迟的三倍，过期后一般情况下，从库都同步了对应点位数据。\n            //但也可能存在没有同步的情况，此时就需要判断主从同步延时，选取延迟时间小于等于过期时间的从库。\n            //或者，将点位信息不设置过期时间，这样始终可以通过点位比较，然后通过定时任务，判断存储的点位信息小于所有从库当前点位就将其清空。\n            Set&lt;String&gt; slaveNames = binlogPositionService.getReasonablyDelayedSlave();\n            if (CollectionUtils.isNotEmpty(slaveNames)) {\n                return loadBalance(slaveNames);\n            }\n\n            //没有符合条件的，降级主库。\n            return writeDataSourceName;\n        }\n    }\n</code></pre>\n<p>由于Shrding Jdbc的自定义查询负载均衡算法使用SPI加载的，所以还需要指定自定义算法SPI文件。<br />\n在<code>resource</code>目录下创建一个META-INF/services文件夹，添加一个名为org.apache.shardingsphere.readwritesplitting.spi.ReadQueryLoadBalanceAlgorithm的文件。<br />\n文件中添加自定义实现了ReadQueryLoadBalanceAlgorithm的具体类的路基。</p>\n<pre><code>#SPI load\ncom.example.config.BinlogAwareLoadBalanceAlgorithm\n</code></pre>\n<h3 id=\"123-单调读\">1.2.3 单调读</h3>\n<p>单调读如下图所示，如果用户A更新或插入了数据，这个行为对用户B不可见，用户B只需要查询从库即可，从库何时同步了对应数据，就何时读取即可。由于写入操作是用户A进行的，所以用户B无需读己所写的保证。但如果用户B第一次读取的从库，已经同步了用户A的写入或更新内容，此时用户B可以查看到A的写入或更新。但是用户B再次刷新页面，此时读请求被路由到另外一个从库，此从库因为网络问题改从库没有同步用户A的写入或更新。此时对用户B来说，第一次看到了内容，第二次又没有看到内容。用户首先从新鲜副本读取，然后从陈旧副本读取，时间似乎倒退了。为了防止这种异常，我们需要单调读。单调读提供的保证是，不会读取到比之前读取数据更旧的数据。也就说单调读读取的数据，保持单调递增，每一次读取的数据版本只会大于或等于前一次读取的数据。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202511/1435315-20251129215659292-1491477398.png\" /></p>\n<p>如何保证单调读隔离级别？</p>\n<ul>\n<li>同一个用户每个请求路由到固定的从库，就当个数据库而言，数据版本是递增的，读取单个实例，读取的数据版本只会大于或等于上一次读取的数据。</li>\n<li>记录第一次读取数据库的点位信息，保证后续请求只会被路由到比记录点位相等或更新的数据库。</li>\n</ul>\n<p>如果仅仅只是需要单调读的保证，将读操作根据用户uid hash后路由到固定从库是实现最简单的方式。但某些在单调读的基础上，需要保证读之所写的混合情况时，路由到固定从库这个方案就不行了，路由到固定从库只能满足单调读的一致性，但无法满足读己所写。下一节会说明单调读+读己所写的混合情况。</p>\n<h3 id=\"124-基于shrding-jdbc实现单调读\">1.2.4 基于Shrding Jdbc实现单调读</h3>\n<pre><code>/**\n *1. 读一致性切面添加单调读标识\n * 读一致性注解，用于标识当读请求的一致性级别\n */\n@Slf4j\n@Aspect\n@Component\npublic class ReadConsistencyAspect {\n    \n    //读己所写\n    @Pointcut(\"@annotation(com.example.annotation.ReadSelfWrite)\")\n    public void readSelfWritePointCut() {\n    }\n\n    @Before(value = \"readSelfWritePointCut()\")\n    public void readSelfWritePoint(JoinPoint joinPoint) throws Throwable {\n        //对于标注了读之所写的接口，上下文中设置对应属性\n        ReadConsistencyManager.setReadSelfWrite();\n    }\n\n    //单调读\n    @Pointcut(\"@annotation(com.example.annotation.MonotonicRead)\")\n    public void monotonicReadPointCut() {\n    }\n\n    @Before(value = \"monotonicReadPointCut()\")\n    public void monotonicReadPoint(JoinPoint joinPoint) throws Throwable {\n        //对于标注了读之所写的接口，上下文中设置对于属性\n        ReadConsistencyManager.setMonotonicRead();\n    }\n\n}\n</code></pre>\n<pre><code>/**\n     * 2.自定义算法中，单调读选择分区。\n     *\n     * @param name                read query logic data source name\n     * @param writeDataSourceName 主库名称\n     * @param readDataSourceNames 从库名称列表\n     * @return 选择的数据源名称\n     */\n    public String getDataSource(String name, String writeDataSourceName, List&lt;String&gt; readDataSourceNames) {\n        try {\n\n            if (ReadConsistencyManager.readSelfWrite()) {\n                //2.只要求读之所写\n                return getDb(writeDataSourceName, readDataSourceNames);\n            } else if (ReadConsistencyManager.monotonicRead()) {\n                //3.只要求单调读（根据唯一标识分区即可），此处使用uid hash后取余，将请求路由到指定分区。\n                //由于hashCode可能算出负数，所以将其与0x7ffffff按位相与，使其首位置0变为正数。\n                return readDataSourceNames.get((UserManager.getUid().hashCode() &amp; Integer.MAX_VALUE) % readDataSourceNames.size());\n            } else {\n                //4.不要求读之所写+单调读\n                return loadBalance(readDataSourceNames);\n            }\n        } finally {\n            //清理Thread Local\n            ReadConsistencyManager.clear();\n        }\n    }\n</code></pre>\n<h3 id=\"125-读己所写单调读\">1.2.5 读己所写+单调读</h3>\n<p>前面提到，读己所写和单调读，但这两个混合的情况呢。这两个读一致性是独立的，满足其中一个并不能意味着满足另外一个。但有时会需要当前的请求需要同时满足两个读一致性的要求。<br />\n例如当前用户编辑自己主页，后续读取自己主页要满足读己所写，此时在用户看来，编辑和读取自己的主页都没有问题，可以看到修改后的数据。但是读取别人主页呢，此时就没有任何保证了。<br />\n例如用户当前最新的更新已经同步到所有从库（S1,S2），当前读取满足读己所写，请求被路由到任一个从库即可，该从库有自己最新写入的数据，满足读己所写，同时当前从库S1有用户B的更新操作，但由于网络原因，用户B的最新数据没有被同步到从库S2,此时用户如果只保证读己所写，第一次被路由到S1满足读己所写，用户同时查看用户B的主页，第一次被路由到S1可以看到修改过后的内容，第二次被路由到S2又无法看到用户修改后的内容，S1，S2均满足读己所写，但写入操作是其他用户B写入的，对当前用户来说感知不到，但此时读取其他用户又存在单调读的问题。<br />\n或者是购物车场景，用户需要满足读己所写，即添加到购物车的内容需要添加后马上可见，同时多次读取自己购物车需要满足单调读，不能出现数据回退的现象。<br />\n两种读一致性需要根据具体场景具体满足对于一致性要求。</p>\n<p>既然要实现读己所写+单调读，如何保证这两种读一致性，本质上不一致问题都是读取的数据版本造成的，读取到比当前应该看见的数据版本更旧的版本导致的。无论时读己所写（读取数据版本 ≥ 自己最后写入版本），还是单调读（读取版本要 ≥ 最后一次读取的数据版本），所以只要保证了读取的数据版本 ≥ max(最后读取版本, 最后写入版本)，即可保证两种一致性。</p>\n<p>所以具体实现策略为，<strong>根据用户记录的点位，先保证读己所写，获取一个满足条件的数据版本，然后读取该数据版本，并且记录当前读取的版本，将其最为最新点位。</strong><br />\n后续读取操作必须大于等于当前点位，即不会出现回退现象。写入操作时写入主库，同时更新点位(写入操作是写入主库，点位保持单调递增)，即不会出现违背读己所写情况。<br />\n所以最后读取的数据版本 ≥ max(最后读取版本, 最后写入版本)，即可保证两种一致性。</p>\n<p>L​ = 当前已知最大版本点位<br />\nVᵣ​ = 读操作实际版本<br />\nV​ = 写操作产生版本<br />\n设写操作 w(x,v) 在 r(x) 之前：<br />\nw(x,v) 后：L ≥ v (写操作更新规则，记录写入点位)<br />\nr(x) 要求：Vᵣ ≥ L (读操作要求，即当前读取数据副本要大于等于记录的用户副本)<br />\n由传递性：Vᵣ ≥ L ≥ v，即当前读操作可以读取到自己最新写入的数据<br />\n即 Vᵣ ≥ v 满足读己所写。</p>\n<p>设 r₁(x) 在 r₂(x) 之前：<br />\nr₁(x) 后：L ≥ Vᵣ₁ (读操作更新规则，读取数据后记录当前读取点位，即L ≥ Vᵣ₁)<br />\nr₂(x) 要求：Vᵣ₂ ≥ L (读操作要求，读取要求读取数据必须大于等于记录点位)<br />\n由传递性：Vᵣ₂ ≥ L ≥ Vᵣ₁，即第二次读取的数据，必得大于等于第一次读取数据不会出现回退。<br />\n即 Vᵣ₂ ≥ Vᵣ₁ 满足单调读。</p>\n<h3 id=\"126-基于sahrding-jdbc实现读己所写单调读\">1.2.6 基于Sahrding Jdbc实现读己所写+单调读</h3>\n<pre><code>/**\n     * 选择数据源的核心方法\n     *\n     * @param name                read query logic data source name\n     * @param writeDataSourceName 主库名称\n     * @param readDataSourceNames 从库名称列表\n     * @return 选择的数据源名称\n     */\n    public String getDataSource(String name, String writeDataSourceName, List&lt;String&gt; readDataSourceNames) {\n        try {\n\n            if (ReadConsistencyManager.readSelfWrite() &amp;&amp; ReadConsistencyManager.monotonicRead()) {\n                //如果是读之所写+单调读\n                //先根据读之所写，获取能读取的库。\n                //此时有三种清空\n                //1. 存在点位信息，可以找到满足点位的从库，选择从库。\n                //2. 存在点位信息，无法找到满足点位的从库，选择主库。\n                String dbName = getDb(writeDataSourceName, readDataSourceNames);\n\n                //获取当前读取库的点位信息，并缓存\n                //后续请求必须大于等于存储的最新点位。\n                BinlogPositionService binlogPositionService = Singleton.getBinlogPositionServiceInstance();\n                BinlogPosition specDbPosition = binlogPositionService.getPositionFromCache(dbName);\n                binlogPositionService.cacheUserBinlogPosition(UserManager.getUid(), specDbPosition);\n\n                return dbName;\n            } else if (ReadConsistencyManager.readSelfWrite()) {\n                //2.只要求读之所写\n                return getDb(writeDataSourceName, readDataSourceNames);\n            } else if (ReadConsistencyManager.monotonicRead()) {\n                //3.只要求单调读（根据唯一标识分区即可）\n                return readDataSourceNames.get((UserManager.getUid().hashCode() &amp; Integer.MAX_VALUE) % readDataSourceNames.size());\n            } else {\n                //4.不要求读之所写+单调读\n                return loadBalance(readDataSourceNames);\n            }\n        } finally {\n            //清理Thread Local\n            ReadConsistencyManager.clear();\n        }\n    }\n\n</code></pre>\n<h2 id=\"13-高可用篇---故障切换\">1.3 高可用篇 - 故障切换</h2>\n<h3 id=\"131-切换的一致性问题\">1.3.1 切换的一致性问题</h3>\n<p>切换前，首先要讨论，主从数据一致性问题。如果是预期的切换，即主库没有宕机的情况下。这种情况一致性是很容易保证的。<br />\n具体切换流程如下。<br />\n1.判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；<br />\n2.把主库 A 改成只读状态，即把 readonly 设置为 true；<br />\n3.判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；<br />\n4.把备库 B 改成可读写状态，也就是把 readonly 设置为 false；<br />\n5.把业务请求切到备库 B。<br />\n切换后数据主从数据是一致的，且没有丢失。</p>\n<p>那如果是主库宕机呢？这时情况就比较复杂呢。<br />\n首先，我们主从复制的情况下，数据有两个大的约束。<br />\n约束1，客户端收到成功响应保证主库事务已提交并持久化。<br />\n约束2，从库读取主库binlog写入relay log成功，主库必定写入对应binlog。<br />\n约束1，由MySQL保证，约束2，也很容易看出，从库中继日志的内容就是主库的binlog内容，写入了从库中继日志，主库必定会存在对应日志内容。<br />\n那么主要场景如下：</p>\n<table>\n<thead>\n<tr>\n<th>场景编号</th>\n<th>客户端接收响应</th>\n<th>主库binlog写入状态</th>\n<th>从库ready blog状态</th>\n<th>最终切换后主从数据状态</th>\n<th>切换从库后客户端与从库一致性</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>✓ 成功</td>\n<td>✓ 已写入</td>\n<td>✓ 已写入</td>\n<td>一致</td>\n<td>一致</td>\n<td>普遍情况</td>\n</tr>\n<tr>\n<td>2</td>\n<td>✓ 成功</td>\n<td>✓ 已写入</td>\n<td>✗ 未写入</td>\n<td>数据丢失</td>\n<td>不一致，客户端接收到成功响应，切换后从库没有数据</td>\n<td>在正确配置半同步情况不会出现，如果出现降级则会出现这种情况。</td>\n</tr>\n<tr>\n<td>3</td>\n<td>✓ 成功</td>\n<td>✗ 未写入</td>\n<td>✓ 已写入</td>\n<td></td>\n<td></td>\n<td>不会出现，违反约束2</td>\n</tr>\n<tr>\n<td>4</td>\n<td>✓ 成功</td>\n<td>✗ 未写入</td>\n<td>✗ 未写入</td>\n<td></td>\n<td></td>\n<td>不会出现，违反约束1，约束2</td>\n</tr>\n<tr>\n<td>5</td>\n<td>✗ 失败</td>\n<td>✓ 已写入</td>\n<td>✓ 已写入</td>\n<td>一致</td>\n<td>不一致，客户端接收到失败响应，切换后从库已经完成操作</td>\n<td>可能出现，主从都写入binlog后，返回客户端失败，如网络故障。</td>\n</tr>\n<tr>\n<td>6</td>\n<td>✗ 失败</td>\n<td>✓ 已写入</td>\n<td>✗ 未写入</td>\n<td>数据丢失</td>\n<td>认知一致，客户端接收失败消息，从库也没有数据。</td>\n<td>可能出现，从库降级，写入主库成功，响应客户端前故障。在正确配置半同步情况不会出现，如果出现降级则会出现这种情况。</td>\n</tr>\n<tr>\n<td>7</td>\n<td>✗ 失败</td>\n<td>✗ 未写入</td>\n<td>✓ 已写入</td>\n<td></td>\n<td></td>\n<td>不会出现，违法约束2</td>\n</tr>\n<tr>\n<td>8</td>\n<td>✗ 失败</td>\n<td>✗ 未写入</td>\n<td>✗ 未写入</td>\n<td>一致</td>\n<td>认知一致，客户端接收失败，主从都没有写入。</td>\n<td>会出现，主库写入前直接挂了，或SQL语法错误，长度超长等主库就直接未执行。</td>\n</tr>\n<tr>\n<td>9</td>\n<td>▲ 超时未知</td>\n<td>✓ 已写入</td>\n<td>✓ 已写入</td>\n<td>一致</td>\n<td>未知，需要重试或查询。</td>\n<td>可能出现，超时了。</td>\n</tr>\n<tr>\n<td>10</td>\n<td>▲ 超时未知</td>\n<td>✓ 已写入</td>\n<td>✗ 未写入</td>\n<td>数据丢失</td>\n<td>未知，需要重试或查询。</td>\n<td>可能出现，超时了。同时从库由半同步降级为异步。</td>\n</tr>\n<tr>\n<td>11</td>\n<td>▲ 超时未知</td>\n<td>✗ 未写入</td>\n<td>✓ 已写入</td>\n<td></td>\n<td></td>\n<td>不会出现，违法约束2</td>\n</tr>\n<tr>\n<td>12</td>\n<td>▲ 超时未知</td>\n<td>✗ 未写入</td>\n<td>✗ 未写入</td>\n<td>一致</td>\n<td>未知，需要重试或查询。</td>\n<td>可能出现，网络故障。</td>\n</tr>\n</tbody>\n</table>\n<p>读写分离场景下，用户不关注主从数据是否一致，用户只关注客户端接收响应，与切换后从库数据状态。所以我们提取这两列。<br />\n去除不可能出现和前后一致的情况，保留不一致的情况如下:</p>\n<table>\n<thead>\n<tr>\n<th>场景编号</th>\n<th>客户端</th>\n<th>切换后从库</th>\n<th>客户端与从库数据一致性</th>\n<th>客户端与从库一致性</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>✓ 成功</td>\n<td>✗ 未写入</td>\n<td>丢失数据</td>\n<td>不一致，客户端接收成功，切换后从库没有数据</td>\n</tr>\n<tr>\n<td>2</td>\n<td>✗ 失败</td>\n<td>✓ 已写入</td>\n<td>幽灵数据</td>\n<td>不一致，客户端接收失败，切换后从库有数据</td>\n</tr>\n<tr>\n<td>3</td>\n<td>▲ 超时未知</td>\n<td>✓ 已写入</td>\n<td>未知，需要查询或重试</td>\n<td>一致，超时未知，需要重新查询。</td>\n</tr>\n<tr>\n<td>4</td>\n<td>▲ 超时未知</td>\n<td>✗ 未写入</td>\n<td>未知，需要查询或重试</td>\n<td>一致，超时未知，需要重新查询。</td>\n</tr>\n</tbody>\n</table>\n<p>场景1，明显数据丢失了，内部统还好，操作以事务为单位，即使数据丢失，整体数据状态也是一致的。预期是由一致性状态A转移到一致性状态B。即使没有转移到一致性状态B,但数据也保持了之前的一致性状态A，也是安全的。例如状态，A用户扣减100，B用户增加100.即使这个事务操作丢失，A用户钱也没有扣减，B用户钱也没增加还是一致的。但涉及第三方系统一致性既没有办法得到保证了，事务只能保证内部系统的一致性，例如是创建一个订单，后续根据这个订单调用第三方接口转账，然后更新订单状态。如果这个订单数据丢失，同时也调用了第三方接口完成了状态。那这个就需要对账去处理了。系统内当前有100笔订单，第三方系统有101笔，通过监控找出不一致性的数据，要么在第三方系统中退掉订单，或在内部系统恢复数据。<br />\n场景2，幽灵数据，客户接收响应失败，但数据写入了，这时用户可能重复操作，有些操作是覆盖的，重复操作以最后一次为准即可，例如修改个人主页。重复写入后面覆盖前面即可，多次操作是安全的。<br />\n但有些不允许出现重复数据的操作，就需要结合业务场景考虑幂等操作。<br />\n场景3，4，对于客户来说，接收的是超时。那么切换后，从库数据无论是存在还是丢失都是可以接受的，比较没有明确的返回成功或失败。针对这些返回，需要先查询一次，同时考虑重试或幂等去重即可。</p>\n<p>上述就是切换后的一致性问题，需要根据业务重要性去做相对于的兜底操作。对于不重要的业务数据，丢失或重复都是可接收的。<br />\n对于重要的数据就需要考虑好各种情况，能通过监控等手段，识别最终数据的一致性情况，加上做好预案，出现问题能快速修复即可。<br />\n毕竟，真正的不一致情况相对来说还是较少的，大多数情况都是正常情况，但也要考虑到最坏情况。</p>\n<h3 id=\"132-基于zookeeper的动态配置切换\">1.3.2 基于Zookeeper的动态配置切换</h3>\n<pre><code class=\"language-xml\">        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;\n            &lt;artifactId&gt;shardingsphere-cluster-mode-core&lt;/artifactId&gt;\n            &lt;version&gt;5.2.1&lt;/version&gt;\n\n            &lt;exclusions&gt;\n                &lt;exclusion&gt;\n                    &lt;groupId&gt;org.yaml&lt;/groupId&gt;\n                    &lt;artifactId&gt;snakeyaml&lt;/artifactId&gt;\n                &lt;/exclusion&gt;\n            &lt;/exclusions&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.yaml&lt;/groupId&gt;\n            &lt;artifactId&gt;snakeyaml&lt;/artifactId&gt;\n            &lt;version&gt;1.33&lt;/version&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;\n            &lt;artifactId&gt;shardingsphere-cluster-mode-repository-zookeeper&lt;/artifactId&gt;\n            &lt;version&gt;5.3.0&lt;/version&gt;\n        &lt;/dependency&gt;\n</code></pre>\n<pre><code class=\"language-yaml\">  # ShardingSphere读写分离配置：\n  shardingsphere:\n    mode:\n      type: Cluster\n      repository:\n        type: ZooKeeper\n        props:\n          namespace: governance_ds\n          server-lists: hcf.com:2181\n          retryIntervalMilliseconds: 500\n          timeToLiveSeconds: 60\n          maxRetries: 3\n          operationTimeoutMilliseconds: 5000\n      overwrite: false\n</code></pre>\n<p>应用启动，配置信息上传到zookeeper。后续直接修改zookeeper中的配置信息。shrding-jdbc会收到通知，修改对应配置，如分片规则，主从数据源等。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202601/1435315-20260103213755857-1418909837.png\" /></p>\n<p>主：3311，从1：3312，从2：3313<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202601/1435315-20260103212522657-533951894.png\" /></p>\n<p>修改zookeeper上的配置。假装主库宕机，3312变为新的主库，3313保持从库。<br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202601/1435315-20260103212539665-780073460.png\" /><br />\n<img alt=\"image\" src=\"https://img2024.cnblogs.com/blog/1435315/202601/1435315-20260103212657920-1583796145.png\" /><br />\n可以看到，zookeeper中versions下新增一个版本号为1的配置，在里面填写修改后配置，然后将active_version修改为1，后续项目中数据源也刷新了。主库变为3312，从库变为了3313.</p>\n<p><a href=\"https://github.com/GCMH/Read-Write-Separation\" rel=\"noopener nofollow\" target=\"_blank\">完整代码详见https://github.com/GCMH/Read-Write-Separation</a></p>\n<p>参考资料：<br />\n[1].《数据密集型应用系统设计》<br />\n[2].《MySQL45讲》<br />\n[3]. <a href=\"http://shardingsphere.apache.org/document/current/en/overview/\" rel=\"noopener nofollow\" target=\"_blank\">Shrding Jdbc</a></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-04 15:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/huang-changfan\">gcmh</a>&nbsp;\n阅读(<span id=\"post_view_count\">278</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": ".NET+AI | 基于 Microsoft Agent Framework 一步步集成 Agent Skills，让你的 AI Agent 更智能",
      "link": "https://www.cnblogs.com/sheng-jie/p/19442149",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/sheng-jie/p/19442149\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 11:50\">\n    <span>.NET+AI | 基于 Microsoft Agent Framework 一步步集成 Agent Skills，让你的 AI Agent 更智能</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"基于-microsoft-agent-framework-实现-agent-skills-集成\">基于 Microsoft Agent Framework 实现 Agent Skills 集成</h1>\n<h2 id=\"引言\">引言</h2>\n<p>随着 AI Agent 技术的快速发展，如何让 Agent 具备可复用、可扩展的专业能力成为一个重要课题。<a href=\"https://agentskills.io\" rel=\"noopener nofollow\" target=\"_blank\">Agent Skills</a> 规范提供了一种标准化的方式来定义和分发 Agent 技能，而 <a href=\"https://github.com/microsoft/ai-agents\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft Agent Framework (MAF)</a> 则提供了构建 AI Agent 的强大基础设施。</p>\n<p>本文将深入介绍如何基于 MAF 的上下文扩展（<code>AIContextProvider</code>）实现 Agent Skills 的集成，包括核心架构设计、关键组件实现以及实际应用示例。</p>\n<blockquote>\n<p>源码已上传至GitHub，文末扫码，<strong>加入「.NET+AI 社区群」，即可获取「.NET+AI 公开资料包」</strong>。</p>\n</blockquote>\n<hr />\n<h2 id=\"架构概述\">架构概述</h2>\n<h3 id=\"整体架构\">整体架构</h3>\n<p>Maf.AgentSkills 项目采用了 MAF 官方推荐的 <code>AIContextProviderFactory</code> 模式，实现了与 MAF 的无缝集成。整体架构如下：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837837-1484392163.png\" /></p>\n<h3 id=\"技术栈\">技术栈</h3>\n<ul>\n<li><strong>目标框架</strong>: .NET 10.0</li>\n<li><strong>核心依赖</strong>:\n<ul>\n<li><code>Microsoft.Agents.AI</code> - MAF 核心框架</li>\n<li><code>Microsoft.Extensions.AI</code> - AI 抽象层</li>\n<li><code>YamlDotNet</code> - YAML Frontmatter 解析</li>\n<li><code>Microsoft.Extensions.DependencyInjection</code> - 依赖注入支持</li>\n</ul>\n</li>\n</ul>\n<hr />\n<h2 id=\"核心设计理念\">核心设计理念</h2>\n<h3 id=\"1-渐进式披露-progressive-disclosure\">1. 渐进式披露 (Progressive Disclosure)</h3>\n<p>Agent Skills 的核心理念之一是<strong>渐进式披露</strong>：Agent 首先只获取技能的元数据（名称和描述），只有在真正需要使用某个技能时，才加载完整的指令内容。</p>\n<p>这种设计有几个重要优势：</p>\n<ol>\n<li><strong>减少 Token 消耗</strong>：系统提示只包含简短的技能列表，而不是所有技能的完整内容</li>\n<li><strong>提高效率</strong>：Agent 可以快速判断哪些技能与当前任务相关</li>\n<li><strong>按需加载</strong>：详细指令仅在需要时获取，避免信息过载</li>\n</ol>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837828-1786264926.png\" /></p>\n<p><strong>信息获取流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837954-307200857.png\" /></p>\n<h3 id=\"2-符合-maf-设计模式\">2. 符合 MAF 设计模式</h3>\n<p>项目严格遵循 MAF 的 <code>AIContextProviderFactory</code> 模式，这是 MAF 推荐的上下文注入方式：</p>\n<pre><code class=\"language-csharp\">// MAF 标准模式\nAIAgent agent = chatClient.CreateAIAgent(new ChatClientAgentOptions\n{\n    AIContextProviderFactory = ctx =&gt; new MyContextProvider(\n        chatClient,\n        ctx.SerializedState,\n        ctx.JsonSerializerOptions)\n});\n</code></pre>\n<p>通过实现 <code>AIContextProvider</code> 抽象类，我们可以：</p>\n<ul>\n<li>在每次 Agent 调用前注入技能信息</li>\n<li>动态提供 Instructions、Messages 和 Tools</li>\n<li>支持线程状态的序列化和反序列化</li>\n</ul>\n<h3 id=\"3-安全第一\">3. 安全第一</h3>\n<p>技能系统涉及文件读取和可能的脚本执行，因此安全性是首要考虑：</p>\n<ul>\n<li><strong>路径遍历防护</strong>：所有文件操作都经过路径安全验证</li>\n<li><strong>符号链接检测</strong>：防止通过符号链接逃逸</li>\n<li><strong>脚本执行默认禁用</strong>：需要显式启用并配置白名单</li>\n<li><strong>命令执行白名单</strong>：只允许预定义的命令</li>\n</ul>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114838100-771593506.png\" /></p>\n<hr />\n<h2 id=\"关键组件详解\">关键组件详解</h2>\n<h3 id=\"1-skillscontextprovider---技能上下文提供器\">1. SkillsContextProvider - 技能上下文提供器</h3>\n<p><code>SkillsContextProvider</code> 是整个系统的核心，它继承自 MAF 的 <code>AIContextProvider</code> 抽象类：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillsContextProvider : AIContextProvider\n{\n    private readonly IChatClient _chatClient;\n    private readonly SkillLoader _skillLoader;\n    private readonly SkillsOptions _options;\n    private SkillsState _state;\n\n    // 构造函数1：创建新实例\n    public SkillsContextProvider(IChatClient chatClient, SkillsOptions? options = null)\n    {\n        _chatClient = chatClient;\n        _options = options ?? new SkillsOptions();\n        \n        var settings = new SkillsSettings(_options.AgentName, _options.ProjectRoot);\n        _skillLoader = new SkillLoader();\n        _state = new SkillsState();\n\n        // 自动加载技能\n        LoadSkills(settings);\n    }\n\n    // 构造函数2：从序列化状态恢复（支持线程持久化）\n    public SkillsContextProvider(\n        IChatClient chatClient,\n        JsonElement serializedState,\n        JsonSerializerOptions? jsonSerializerOptions = null)\n    {\n        // 反序列化恢复状态...\n    }\n\n    // 在 Agent 调用前注入技能上下文\n    public override ValueTask&lt;AIContext&gt; InvokingAsync(\n        InvokingContext context,\n        CancellationToken cancellationToken = default)\n    {\n        // 生成技能系统提示\n        var instructions = GenerateSkillsPrompt(_state.AllSkills);\n        \n        // 创建技能工具\n        var tools = CreateSkillsTools(_state);\n\n        return ValueTask.FromResult(new AIContext\n        {\n            Instructions = instructions,\n            Tools = tools\n        });\n    }\n\n    // 序列化状态以支持线程持久化\n    public override JsonElement Serialize(JsonSerializerOptions? jsonSerializerOptions = null)\n    {\n        var state = new { Options = _options, State = _state };\n        return JsonSerializer.SerializeToElement(state, jsonSerializerOptions);\n    }\n}\n</code></pre>\n<p><strong>关键设计点</strong>：</p>\n<ol>\n<li><strong>双构造函数模式</strong>：一个用于创建新实例，一个用于从序列化状态恢复</li>\n<li><strong>InvokingAsync</strong>：在每次 Agent 调用前被调用，返回 <code>AIContext</code> 注入技能信息</li>\n<li><strong>Serialize</strong>：支持将技能状态序列化，用于线程持久化场景</li>\n</ol>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837897-1781124143.png\" /></p>\n<h3 id=\"2-skillloader---技能加载器\">2. SkillLoader - 技能加载器</h3>\n<p><code>SkillLoader</code> 负责从文件系统发现和加载技能：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillLoader\n{\n    private readonly SkillParser _parser;\n\n    /// &lt;summary&gt;\n    /// 从指定目录加载所有技能\n    /// &lt;/summary&gt;\n    public IEnumerable&lt;SkillMetadata&gt; LoadSkillsFromDirectory(\n        string skillsDirectory, \n        SkillSource source)\n    {\n        if (!Directory.Exists(skillsDirectory))\n            yield break;\n\n        foreach (var skillDir in Directory.GetDirectories(skillsDirectory))\n        {\n            var skill = TryLoadSkill(skillDir, source);\n            if (skill is not null)\n                yield return skill;\n        }\n    }\n\n    private SkillMetadata? TryLoadSkill(string skillDirectory, SkillSource source)\n    {\n        var skillFilePath = Path.Combine(skillDirectory, \"SKILL.md\");\n\n        if (!File.Exists(skillFilePath))\n            return null;\n\n        // 安全检查：验证符号链接\n        if (PathSecurity.IsSymbolicLink(skillFilePath))\n        {\n            var realPath = PathSecurity.GetRealPath(skillFilePath);\n            if (!PathSecurity.IsPathSafe(realPath, skillDirectory))\n                return null;\n        }\n\n        return _parser.Parse(skillFilePath, source);\n    }\n}\n</code></pre>\n<p><strong>技能目录结构</strong>：</p>\n<pre><code>~/.maf/{agent-name}/skills/     # 用户级技能\n{project-root}/.maf/skills/     # 项目级技能（优先级更高）\n</code></pre>\n<p>每个技能是一个独立的目录，包含 <code>SKILL.md</code> 文件：</p>\n<pre><code>skills/\n├── web-research/\n│   ├── SKILL.md\n│   ├── search.py\n│   └── templates/\n│       └── report.md\n├── code-review/\n│   ├── SKILL.md\n│   └── checklist.md\n└── pdf-tools/\n    ├── SKILL.md\n    ├── split_pdf.py\n    └── merge_pdf.py\n</code></pre>\n<p><strong>技能加载流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114838125-1683611629.png\" /></p>\n<h3 id=\"3-skillparser---技能解析器\">3. SkillParser - 技能解析器</h3>\n<p><code>SkillParser</code> 负责解析 SKILL.md 文件的 YAML Frontmatter：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillParser\n{\n    private const string FrontmatterDelimiter = \"---\";\n\n    public SkillMetadata Parse(string skillFilePath, SkillSource source)\n    {\n        var content = File.ReadAllText(skillFilePath);\n        var skillDirectory = Path.GetDirectoryName(skillFilePath)!;\n        var directoryName = Path.GetFileName(skillDirectory);\n\n        // 提取 YAML Frontmatter\n        var frontmatter = ExtractFrontmatter(content);\n        if (frontmatter is null)\n            throw new SkillParseException(skillFilePath, \n                \"SKILL.md must have YAML frontmatter delimited by '---'.\");\n\n        // 解析 YAML\n        var yamlData = _yamlDeserializer.Deserialize&lt;SkillFrontmatter&gt;(frontmatter);\n\n        // 验证必需字段\n        if (string.IsNullOrWhiteSpace(yamlData.Name))\n            throw new SkillParseException(skillFilePath, \"Skill 'name' is required.\");\n\n        if (string.IsNullOrWhiteSpace(yamlData.Description))\n            throw new SkillParseException(skillFilePath, \"Skill 'description' is required.\");\n\n        // 验证名称格式和目录匹配\n        SkillValidator.ValidateName(yamlData.Name);\n        SkillValidator.ValidateNameMatchesDirectory(yamlData.Name, directoryName);\n\n        return new SkillMetadata(\n            Name: yamlData.Name,\n            Description: yamlData.Description,\n            Path: skillDirectory,\n            Source: source,\n            License: yamlData.License,\n            AllowedTools: AllowedTool.Parse(yamlData.AllowedTools)\n        );\n    }\n}\n</code></pre>\n<p><strong>SKILL.md 格式示例</strong>：</p>\n<pre><code class=\"language-markdown\">---\nname: web-research\ndescription: A skill for conducting comprehensive web research\nlicense: MIT\nallowed-tools: web_search fetch_url\n---\n\n# Web Research Skill\n\n## When to Use\nUse this skill when researching topics online...\n\n## Instructions\n1. Clarify the research scope\n2. Search strategically\n3. Synthesize information\n...\n</code></pre>\n<h3 id=\"4-skillstoolfactory---工具工厂\">4. SkillsToolFactory - 工具工厂</h3>\n<p><code>SkillsToolFactory</code> 根据配置创建技能相关的工具：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillsToolFactory\n{\n    public IReadOnlyList&lt;AITool&gt; CreateTools()\n    {\n        var tools = new List&lt;AITool&gt;();\n\n        // 默认启用的安全工具\n        if (_options.EnableReadSkillTool)\n            tools.Add(new ReadSkillTool(_loader, _stateProvider).ToAIFunction());\n\n        if (_options.EnableReadFileTool)\n            tools.Add(new ReadFileTool(_stateProvider).ToAIFunction());\n\n        if (_options.EnableListDirectoryTool)\n            tools.Add(new ListDirectoryTool(_loader, _stateProvider).ToAIFunction());\n\n        // 需要显式启用的高危工具\n        if (_options.EnableExecuteScriptTool)\n            tools.Add(new ExecuteScriptTool(_stateProvider, _options).ToAIFunction());\n\n        if (_options.EnableRunCommandTool &amp;&amp; _options.AllowedCommands.Count &gt; 0)\n            tools.Add(new RunCommandTool(_stateProvider, _options).ToAIFunction());\n\n        return tools;\n    }\n}\n</code></pre>\n<p><strong>内置工具</strong>：</p>\n<table>\n<thead>\n<tr>\n<th>工具名</th>\n<th>功能</th>\n<th>默认状态</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>read_skill</code></td>\n<td>读取 SKILL.md 完整内容</td>\n<td>✅ 启用</td>\n</tr>\n<tr>\n<td><code>read_skill_file</code></td>\n<td>读取技能目录中的文件</td>\n<td>✅ 启用</td>\n</tr>\n<tr>\n<td><code>list_skill_directory</code></td>\n<td>列出技能目录内容</td>\n<td>✅ 启用</td>\n</tr>\n<tr>\n<td><code>execute_skill_script</code></td>\n<td>执行技能中的脚本</td>\n<td>❌ 禁用</td>\n</tr>\n<tr>\n<td><code>run_skill_command</code></td>\n<td>运行白名单命令</td>\n<td>❌ 禁用</td>\n</tr>\n</tbody>\n</table>\n<p><strong>工具创建决策流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114838189-800056356.png\" /></p>\n<h3 id=\"5-chatclientextensions---便捷扩展方法\">5. ChatClientExtensions - 便捷扩展方法</h3>\n<p>为了简化使用，项目提供了 <code>ChatClient</code> 的扩展方法：</p>\n<pre><code class=\"language-csharp\">public static class ChatClientExtensions\n{\n    public static AIAgent CreateSkillsAgent(\n        this IChatClient chatClient,\n        Action&lt;SkillsOptions&gt;? configureSkills = null,\n        Action&lt;ChatClientAgentOptions&gt;? configureAgent = null)\n    {\n        var skillsOptions = new SkillsOptions();\n        configureSkills?.Invoke(skillsOptions);\n\n        var agentOptions = new ChatClientAgentOptions\n        {\n            AIContextProviderFactory = ctx =&gt;\n            {\n                // 检查是否从序列化状态恢复\n                if (ctx.SerializedState.ValueKind != JsonValueKind.Undefined)\n                {\n                    return new SkillsContextProvider(\n                        chatClient,\n                        ctx.SerializedState,\n                        ctx.JsonSerializerOptions);\n                }\n\n                // 创建新实例\n                return new SkillsContextProvider(chatClient, skillsOptions);\n            }\n        };\n\n        configureAgent?.Invoke(agentOptions);\n        return chatClient.CreateAIAgent(agentOptions);\n    }\n}\n</code></pre>\n<hr />\n<h2 id=\"实现细节\">实现细节</h2>\n<h3 id=\"agent-调用完整流程\">Agent 调用完整流程</h3>\n<p>以下是 Agent 执行任务时的完整调用流程：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837850-1773548166.png\" /></p>\n<h3 id=\"1-技能系统提示生成\">1. 技能系统提示生成</h3>\n<p>技能信息通过系统提示注入到 Agent 中。系统提示采用渐进式披露的设计：</p>\n<pre><code class=\"language-csharp\">public static class SkillsPromptTemplates\n{\n    public const string SystemPromptTemplate = \"\"\"\n        ## Skills System\n\n        You have access to a skills library that provides specialized capabilities.\n\n        {skills_locations}\n\n        **Available Skills:**\n\n        {skills_list}\n\n        ---\n\n        ### How to Use Skills (Progressive Disclosure) - CRITICAL\n\n        Skills follow a **progressive disclosure** pattern - you know they exist \n        (name + description above), but you **MUST read the full instructions \n        before using them**.\n\n        **MANDATORY Workflow:**\n\n        1. **Recognize when a skill applies**: Check if the user's task matches \n           any skill's description above\n        2. **Read the skill's full instructions FIRST**: Use `read_skill` tool \n           to get the complete SKILL.md content\n        3. **Follow the skill's instructions precisely**: SKILL.md contains \n           step-by-step workflows and examples\n        4. **Execute scripts only after reading**: Use the exact script paths \n           and argument formats from SKILL.md\n\n        **IMPORTANT RULES:**\n\n        ⚠️ **NEVER call `execute_skill_script` without first reading the skill \n           with `read_skill`**\n        \n        ✅ **Correct Workflow Example:**\n        ```\n        User: \"Split this PDF into pages\"\n        1. Recognize: \"split-pdf\" skill matches this task\n        2. Call: read_skill(\"split-pdf\") → Get full instructions\n        3. Learn: SKILL.md shows the actual script path and argument format\n        4. Execute: Use the exact command format from SKILL.md\n        ```\n\n        Remember: **Read first, then execute.** This ensures you use skills correctly!\n        \"\"\";\n}\n</code></pre>\n<h3 id=\"2-技能状态管理\">2. 技能状态管理</h3>\n<p>技能状态通过 <code>SkillsState</code> 类管理，支持序列化：</p>\n<pre><code class=\"language-csharp\">public sealed class SkillsState\n{\n    public IReadOnlyList&lt;SkillMetadata&gt; UserSkills { get; init; } = [];\n    public IReadOnlyList&lt;SkillMetadata&gt; ProjectSkills { get; init; } = [];\n    public DateTimeOffset LastRefreshed { get; init; }\n\n    /// &lt;summary&gt;\n    /// 获取所有技能，项目级技能优先级更高\n    /// &lt;/summary&gt;\n    public IReadOnlyList&lt;SkillMetadata&gt; AllSkills\n    {\n        get\n        {\n            var projectSkillNames = ProjectSkills\n                .Select(s =&gt; s.Name)\n                .ToHashSet(StringComparer.OrdinalIgnoreCase);\n            \n            var userSkillsWithoutOverrides = UserSkills\n                .Where(s =&gt; !projectSkillNames.Contains(s.Name));\n            \n            return [.. ProjectSkills, .. userSkillsWithoutOverrides];\n        }\n    }\n\n    public SkillMetadata? GetSkill(string name)\n    {\n        return ProjectSkills.FirstOrDefault(s =&gt; \n                s.Name.Equals(name, StringComparison.OrdinalIgnoreCase))\n            ?? UserSkills.FirstOrDefault(s =&gt; \n                s.Name.Equals(name, StringComparison.OrdinalIgnoreCase));\n    }\n}\n</code></pre>\n<h3 id=\"3-路径安全验证\">3. 路径安全验证</h3>\n<p>所有文件操作都经过严格的路径安全验证：</p>\n<pre><code class=\"language-csharp\">public static class PathSecurity\n{\n    /// &lt;summary&gt;\n    /// 解析安全路径，防止路径遍历攻击\n    /// &lt;/summary&gt;\n    public static string? ResolveSafePath(string basePath, string relativePath)\n    {\n        var fullPath = Path.GetFullPath(Path.Combine(basePath, relativePath));\n        var normalizedBase = Path.GetFullPath(basePath);\n\n        // 确保解析后的路径仍在基础路径内\n        if (!fullPath.StartsWith(normalizedBase, StringComparison.OrdinalIgnoreCase))\n            return null;\n\n        return fullPath;\n    }\n\n    /// &lt;summary&gt;\n    /// 检查是否是符号链接\n    /// &lt;/summary&gt;\n    public static bool IsSymbolicLink(string path)\n    {\n        var fileInfo = new FileInfo(path);\n        return fileInfo.Attributes.HasFlag(FileAttributes.ReparsePoint);\n    }\n\n    /// &lt;summary&gt;\n    /// 验证路径是否安全\n    /// &lt;/summary&gt;\n    public static bool IsPathSafe(string targetPath, string allowedBasePath)\n    {\n        var normalizedTarget = Path.GetFullPath(targetPath);\n        var normalizedBase = Path.GetFullPath(allowedBasePath);\n        \n        return normalizedTarget.StartsWith(normalizedBase, StringComparison.OrdinalIgnoreCase);\n    }\n}\n</code></pre>\n<hr />\n<h2 id=\"使用方法\">使用方法</h2>\n<h3 id=\"基本用法\">基本用法</h3>\n<pre><code class=\"language-csharp\">using Maf.AgentSkills.Agent;\nusing OpenAI;\n\n// 创建 ChatClient\nvar chatClient = new OpenAIClient(apiKey)\n    .GetChatClient(\"gpt-4\")\n    .AsIChatClient();\n\n// 创建支持技能的 Agent\nvar agent = chatClient.CreateSkillsAgent(\n    configureSkills: options =&gt;\n    {\n        options.AgentName = \"my-assistant\";\n        options.ProjectRoot = Directory.GetCurrentDirectory();\n    },\n    configureAgent: options =&gt;\n    {\n        options.ChatOptions = new() \n        { \n            Instructions = \"You are a helpful assistant.\" \n        };\n    });\n\n// 使用 Agent\nvar thread = agent.GetNewThread();\nvar response = await agent.RunAsync(\"What skills do you have?\", thread);\nConsole.WriteLine(response.Text);\n</code></pre>\n<h3 id=\"线程序列化\">线程序列化</h3>\n<p>技能状态可以随线程一起序列化，支持持久化会话：</p>\n<pre><code class=\"language-csharp\">// 序列化线程\nvar serializedThread = thread.Serialize();\n\n// 保存到数据库或文件\nawait SaveThreadAsync(userId, serializedThread);\n\n// 稍后恢复并继续对话\nvar restoredThread = agent.DeserializeThread(serializedThread);\nvar response = await agent.RunAsync(\"Continue our chat\", restoredThread);\n</code></pre>\n<p><strong>序列化/反序列化流程</strong>：</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/577140/202601/577140-20260105114837994-620347996.png\" /></p>\n<h3 id=\"依赖注入集成\">依赖注入集成</h3>\n<pre><code class=\"language-csharp\">var builder = Host.CreateApplicationBuilder(args);\n\n// 注册 ChatClient\nbuilder.Services.AddChatClient(sp =&gt;\n{\n    return new OpenAIClient(apiKey)\n        .GetChatClient(\"gpt-4\")\n        .AsIChatClient();\n});\n\n// 注册技能 Agent\nbuilder.Services.AddSingleton&lt;AIAgent&gt;(sp =&gt;\n{\n    var chatClient = sp.GetRequiredService&lt;IChatClient&gt;();\n    \n    return chatClient.CreateSkillsAgent(\n        configureSkills: options =&gt;\n        {\n            options.AgentName = \"di-agent\";\n            options.ProjectRoot = Directory.GetCurrentDirectory();\n            \n            options.ToolsOptions.EnableReadSkillTool = true;\n            options.ToolsOptions.EnableReadFileTool = true;\n        });\n});\n\nvar host = builder.Build();\nvar agent = host.Services.GetRequiredService&lt;AIAgent&gt;();\n\nvar thread = agent.GetNewThread();\n\nvar path = \"E:\\\\GitHub\\\\My\\\\dotnet-agent-skills\\\\NET+AI：技术栈全景解密.pdf\";\nvar response = await agent.RunAsync($\"请将指定目录：{path}的文件拆分前3页\", thread);\n</code></pre>\n<h3 id=\"启用脚本执行\">启用脚本执行</h3>\n<pre><code class=\"language-csharp\">var agent = chatClient.CreateSkillsAgent(\n    configureSkills: options =&gt;\n    {\n        options.AgentName = \"power-assistant\";\n        options.ProjectRoot = Directory.GetCurrentDirectory();\n        \n        // 启用脚本执行（需要显式开启）\n        options.ToolsOptions.EnableExecuteScriptTool = true;\n        options.ToolsOptions.AllowedScriptExtensions = [\".py\", \".ps1\", \".cs\"];\n        options.ToolsOptions.ScriptTimeoutSeconds = 60;\n        \n        // 启用命令执行（白名单模式）\n        options.ToolsOptions.EnableRunCommandTool = true;\n        options.ToolsOptions.AllowedCommands = [\"git\", \"npm\", \"dotnet\"];\n    });\n</code></pre>\n<hr />\n<h2 id=\"安全考量\">安全考量</h2>\n<h3 id=\"1-默认安全\">1. 默认安全</h3>\n<p>项目遵循\"默认安全\"原则：</p>\n<ul>\n<li><strong>脚本执行默认禁用</strong>：<code>EnableExecuteScriptTool = false</code></li>\n<li><strong>命令执行默认禁用</strong>：<code>EnableRunCommandTool = false</code></li>\n<li><strong>只读工具默认启用</strong>：<code>ReadSkill</code>, <code>ReadFile</code>, <code>ListDirectory</code></li>\n</ul>\n<h3 id=\"2-路径遍历防护\">2. 路径遍历防护</h3>\n<p>所有文件操作都限制在技能目录内：</p>\n<pre><code class=\"language-csharp\">// 读取文件时验证路径\nvar safePath = PathSecurity.ResolveSafePath(skill.Path, relativePath);\nif (safePath is null)\n{\n    return JsonSerializer.Serialize(new\n    {\n        success = false,\n        error = \"Path traversal attempt detected\"\n    });\n}\n</code></pre>\n<h3 id=\"3-脚本执行白名单\">3. 脚本执行白名单</h3>\n<p>即使启用了脚本执行，也只允许特定扩展名：</p>\n<pre><code class=\"language-csharp\">public class SkillsToolsOptions\n{\n    public List&lt;string&gt; AllowedScriptExtensions { get; set; } = [\".py\", \".ps1\", \".sh\", \".cs\"];\n    public int ScriptTimeoutSeconds { get; set; } = 30;\n    public int MaxOutputSizeBytes { get; set; } = 50 * 1024; // 50KB\n}\n</code></pre>\n<h3 id=\"4-命令执行白名单\">4. 命令执行白名单</h3>\n<p>命令执行采用严格的白名单机制：</p>\n<pre><code class=\"language-csharp\">options.AllowedCommands = [\"git\", \"npm\", \"dotnet\"]; // 只允许这些命令\n</code></pre>\n<hr />\n<h2 id=\"最佳实践\">最佳实践</h2>\n<h3 id=\"1-技能设计原则\">1. 技能设计原则</h3>\n<ul>\n<li><strong>单一职责</strong>：每个技能专注于一个领域</li>\n<li><strong>清晰描述</strong>：description 字段要足够描述技能用途</li>\n<li><strong>详细指令</strong>：SKILL.md 正文要包含完整的使用说明</li>\n<li><strong>示例驱动</strong>：提供具体的使用示例</li>\n</ul>\n<h3 id=\"2-目录组织\">2. 目录组织</h3>\n<pre><code># 推荐的技能目录结构\nmy-skill/\n├── SKILL.md              # 必需：技能定义文件\n├── README.md             # 可选：详细文档\n├── scripts/              # 脚本文件\n│   ├── main.py\n│   └── utils.py\n├── templates/            # 模板文件\n│   └── output.md\n└── config/               # 配置文件\n    └── settings.json\n</code></pre>\n<h3 id=\"3-skillmd-编写规范\">3. SKILL.md 编写规范</h3>\n<pre><code class=\"language-markdown\">---\nname: my-skill\ndescription: Brief description under 1024 characters\nlicense: MIT\nallowed-tools: web_search file_write\n---\n\n# Skill Name\n\n## Overview\nClear explanation of what this skill does.\n\n## When to Use\n- Situation 1\n- Situation 2\n\n## Prerequisites\n- Required tools or dependencies\n\n## Instructions\nStep-by-step workflow:\n\n1. First step\n2. Second step\n3. Third step\n\n## Available Scripts\n\n### script.py\n- **Purpose**: What it does\n- **Arguments**: `--input &lt;file&gt; --output &lt;file&gt;`\n- **Example**: `python script.py --input data.csv --output result.json`\n\n## Examples\n\n### Example 1: Basic Usage\n...\n</code></pre>\n<h3 id=\"4-项目级-vs-用户级技能\">4. 项目级 vs 用户级技能</h3>\n<ul>\n<li><strong>用户级技能</strong> (<code>~/.maf/{agent}/skills/</code>)：通用技能，适用于多个项目</li>\n<li><strong>项目级技能</strong> (<code>{project}/.maf/skills/</code>)：项目特定技能，可覆盖同名用户级技能</li>\n</ul>\n<hr />\n<h2 id=\"总结\">总结</h2>\n<p>Maf.AgentSkills 项目展示了如何基于 Microsoft Agent Framework 实现 Agent Skills 集成。</p>\n<p><strong>核心设计要点</strong>：</p>\n<ol>\n<li><strong>遵循 MAF 模式</strong>：使用 <code>AIContextProviderFactory</code> 实现无侵入式集成</li>\n<li><strong>渐进式披露</strong>：通过三层结构（元数据 → 指令 → 资源）优化 Token 使用</li>\n<li><strong>安全第一</strong>：默认禁用危险操作，采用白名单机制</li>\n<li><strong>线程序列化</strong>：完整支持会话持久化</li>\n<li><strong>依赖注入友好</strong>：易于集成到现有应用</li>\n</ol>\n<p>通过这套实现，开发者可以轻松为 AI Agent 添加可复用的专业技能，使 Agent 能够完成更复杂的任务。</p>\n<hr />\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li><a href=\"https://agentskills.io\" rel=\"noopener nofollow\" target=\"_blank\">Agent Skills 规范</a></li>\n<li><a href=\"https://github.com/microsoft/agent-framework\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft Agent Framework</a></li>\n<li><a href=\"https://github.com/dotnet/extensions\" rel=\"noopener nofollow\" target=\"_blank\">Microsoft.Extensions.AI</a></li>\n</ul>\n<hr />\n\n</div>\n<div id=\"MySignature\">\n    <div style=\"display: block; border: 2px solid #6ecaa8; padding: 10px;\">  \n<img src=\"https://files.cnblogs.com/files/sheng-jie/maf-course-card-scan.bmp\" />\n<blockquote>\n<b>👆面向.NET开发者的AI Agent 开发课程【.NET+AI | 智能体开发进阶】已上线，欢迎扫码加入学习。👆</b>\n</blockquote>\n</div>\n\n<img src=\"https://files.cnblogs.com/files/sheng-jie/scan-follow.bmp\" />\n<blockquote>\n<b>\n关注我的公众号『向 AI 而行』，我们微信不见不散。\n<br />\n阅罢此文，如果您觉得本文不错并有所收获，请【打赏】或【推荐】，也可【评论】留下您的问题或建议与我交流。\n\n你的支持是我不断创作和分享的不竭动力！</b>\n</blockquote>\n\n<div id=\"AllanboltSignature\" style=\"display: block; border: 2px solid #6ecaa8; padding: 10px;\">    \n        <div>作者：<a href=\"http://www.jianshu.com/u/39ec0e6b1844\" target=\"_blank\">『圣杰』</a></div>\n        <div>出处：<a href=\"http://www.cnblogs.com/sheng-jie/\" target=\"_blank\">http://www.cnblogs.com/sheng-jie/</a></div>\n        <div>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文链接，否则保留追究法律责任的权利。</div>  \n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 11:50</span>&nbsp;\n<a href=\"https://www.cnblogs.com/sheng-jie\">「圣杰」</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "基于openspec-cn的SDD规范驱动开发实战",
      "link": "https://www.cnblogs.com/shiningrise/p/19441876",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/shiningrise/p/19441876\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 11:12\">\n    <span>基于openspec-cn的SDD规范驱动开发实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"规范驱动开发-简单介绍\">规范驱动开发 简单介绍</h2>\n<p>规范驱动开发（Specification Driven Development，简称 SDD 或 SpecDD）是一种以规范为核心的软件工程方法，既包含传统敏捷开发衍生出的混合型模式，也发展出适配 AI 时代的新型开发范式，核心是让规范成为开发全流程的核心指引与执行依据</p>\n<h1 id=\"新建项目二维码生成器英文名qrcodecreator\">新建项目：二维码生成器（英文名：QrcodeCreator）</h1>\n<h2 id=\"新建目录-qrcodecreator\">新建目录 QrcodeCreator</h2>\n<p>在QrcodeCreator目录打开cursor</p>\n<h2 id=\"步骤1全局安装cli\">步骤1：全局安装CLI</h2>\n<pre><code>npm install -g @studyzy/openspec-cn@latest\n</code></pre>\n<h2 id=\"步骤2在项目中初始化openspec\">步骤2：在项目中初始化OpenSpec</h2>\n<pre><code>openspec-cn init\n</code></pre>\n<p>选择cursor编辑器</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2025/20260105101011477.png\" /></p>\n<p>生成如下目录结构：</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105101532472.png\" /></p>\n<p>复制以下内容到cursor对话框</p>\n<pre><code>1. 填充您的项目上下文：\n   \"请阅读 openspec/project.md 并帮我填写\n    我的项目详情、技术栈和约定规范\"\n</code></pre>\n<p>修改：project.md</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105105705596.png\" /></p>\n<h2 id=\"新建提案\">新建提案</h2>\n<pre><code>AI对话框，我：我想创建一个规范提案:新增一张html页面,根据输入的网址生成二维码\n</code></pre>\n<p>生成如下文件</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105102929047.png\" /></p>\n<pre><code>修改提案：add-url-qrcode-generator  不使用python，仅使用html+javascript实现qrcode生成功能\n</code></pre>\n<h2 id=\"生成代码\">生成代码</h2>\n<pre><code>输入命令/openspec-apply 生成代码\n</code></pre>\n<h2 id=\"归档\">归档</h2>\n<pre><code>/openspec-archive add-url-qrcode-generator\n</code></pre>\n<h2 id=\"完成后的项目结构\">完成后的项目结构</h2>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105110141451.png\" /></p>\n<p>使用浏览器打开index.html</p>\n<p><img alt=\"\" src=\"https://wxy-blog.oss-cn-hangzhou.aliyuncs.com/wxy-blog/2026/20260105110229694.png\" /></p>\n<h1 id=\"openspec-cn项目网址\">openspec-cn项目网址</h1>\n<p><a href=\"https://github.com/studyzy/OpenSpec-cn\" rel=\"noopener nofollow\" target=\"_blank\">studyzy/OpenSpec-cn: OpenSpec汉化版</a></p>\n<p>项目完成展示网址：<br />\n<a href=\"https://qrcode.wxy.vip/\" rel=\"noopener nofollow\" target=\"_blank\">https://qrcode.wxy.vip/</a></p>\n\n</div>\n<div id=\"MySignature\">\n    欢迎光临:<font size=\"3\"><font size=\"3\"><a href=\"http://shiningrise.cnblogs.com/\" target=\"_blank\"><font size=\"3\"><font size=\"3\">http://shiningrise.cnblogs.com</font></font></a><br /><br /></font></font>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 11:12</span>&nbsp;\n<a href=\"https://www.cnblogs.com/shiningrise\">shiningrise</a>&nbsp;\n阅读(<span id=\"post_view_count\">10</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从手动到自动：基于 Mutating Admission Webhook 实现 Envoy Sidecar 自动注入",
      "link": "https://www.cnblogs.com/MrVolleyball/p/19441540",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/MrVolleyball/p/19441540\" id=\"cb_post_title_url\" title=\"发布于 2026-01-05 11:04\">\n    <span>从手动到自动：基于 Mutating Admission Webhook 实现 Envoy Sidecar 自动注入</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在微服务规模不断扩大的场景下，手动为每个 Pod 注入 Envoy Sidecar 已经难以维护。本文从实际工程问题出发，详细讲解如何利用 Kubernetes 的 Mutating Admission Webhook 机制，实现 Envoy Sidecar 的自动注入。内容涵盖证书生成、Webhook 配置、注入服务实现，以及基于 Namespace / Pod Label 的精细化注入控制\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>上一小节我们详细讨论了如何做流量劫持，并且使用initContainers来做自动劫持的配置。但是目前还有一个问题，如果我们的系统有好几百个微服务，那作为重要的代理envoy，是手动注入的，难道每个微服务都要手动编辑一次 ？这显然是不可承受的，所以这一节，我们来详细讨论一下自动注入的问题</p>\n<h2 id=\"环境准备\">环境准备</h2>\n<p>由于本节只讨论容器注入，所以只需要准备一个普通的deployment就行了</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: backend\n  template:\n    metadata:\n      labels:\n        app: backend\n    spec:\n      containers:\n      - image: backend-service:v1\n        imagePullPolicy: Never\n        name: backend\n        ports:\n        - containerPort: 10000\n          protocol: TCP\n        resources: {}\n      restartPolicy: Always\n</code></pre>\n<h2 id=\"mutating-admission-webhooks\">mutating admission webhooks</h2>\n<p><img alt=\"auto_injection_1\" class=\"lazyload\" /></p>\n<p>简单来说，就是当pod重启的时候，会发起一系列的过程，其中在mutating admission controller 这里，k8s提供了一个webhooks，可以回调到指定的地方去，所以我们需要创建一个server来处理该回调，添加一个容器进去，完成容器注入的工作</p>\n<h4 id=\"创建相关证书\">创建相关证书</h4>\n<pre><code>cd /etc/kubernetes/pki\n</code></pre>\n<p>创建openssl.cnf</p>\n<pre><code>[ req ]\ndistinguished_name = req_distinguished_name\nreq_extensions = v3_req\nprompt = no\n\n[ req_distinguished_name ]\nCN = sidecar-webhook.default.svc\n\n[ v3_req ]\nkeyUsage = keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[ alt_names ]\nDNS.1 = sidecar-webhook\nDNS.2 = sidecar-webhook.default\nDNS.3 = sidecar-webhook.default.svc\n\n</code></pre>\n<p>从k8s根证书中创建证书</p>\n<pre><code>sudo openssl req -x509 -newkey rsa:2048 \\\n  -keyout tls.key \\\n  -out tls.crt \\\n  -days 365 -nodes \\\n  -config openssl.cnf \\\n  -extensions v3_req\n</code></pre>\n<h4 id=\"创建mutatingwebhookconfiguration\">创建MutatingWebhookConfiguration</h4>\n<pre><code>mytls=`cat tls.crt | base64 | tr -d '\\n'`\n\necho 'apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: sidecar-injector\nwebhooks:\n- name: sidecar.demo.io\n  clientConfig:\n    service:\n      name: sidecar-webhook\n      namespace: default\n      path: /mutate\n    caBundle: '$mytls'\n  rules:\n  - apiGroups: [\"\"]\n    apiVersions: [\"v1\"]\n    operations: [\"CREATE\"]\n    resources: [\"pods\"]\n  admissionReviewVersions: [\"v1\"]\n  sideEffects: None' | kubectl apply -f -\n\n</code></pre>\n<h4 id=\"创建服务来接收webhook\">创建服务来接收webhook</h4>\n<p><a href=\"https://github.com/wilsonchai8/myblog/blob/main/micro_service/injection/inject.go\" rel=\"noopener nofollow\" target=\"_blank\">自动注入服务</a></p>\n<p>这没什么可说的，需要注意的就是注入pod的配置直接写在了代码里面，并且注入了2个部分，首先是sidecar container，其次是sidecar的volumes配置（pod级别的）</p>\n<pre><code>        patch := []map[string]interface{}{\n                {\n                        \"op\":   \"add\",\n                        \"path\": \"/spec/containers/-\",\n                        \"value\": map[string]interface{}{\n                                \"image\":           \"registry.cn-beijing.aliyuncs.com/wilsonchai/envoy:v1.32-latest\",\n                                \"imagePullPolicy\": \"IfNotPresent\",\n                                \"name\":            \"envoy\",\n                                \"args\":            []string{\"-c\", \"/etc/envoy/envoy.yaml\"},\n                                \"volumeMounts\": []map[string]interface{}{\n                                        {\n                                                \"mountPath\": \"/etc/envoy\",\n                                                \"name\":      \"envoy-config\",\n                                        },\n                                },\n                        },\n                },\n                {\n                        \"op\":   \"add\",\n                        \"path\": \"/spec/volumes/-\",\n                        \"value\": map[string]interface{}{\n                                \"configMap\": map[string]interface{}{\n                                        \"defaultMode\": 420,\n                                        \"name\":        \"envoy-config\",\n                                },\n                                \"name\": \"envoy-config\",\n                        },\n                },\n        }\n\n</code></pre>\n<pre><code>▶ go run inject.go\n2025/12/29 14:58:19 Webhook listening on :8443\n\n</code></pre>\n<p>打开8443端口以便接收请求</p>\n<h4 id=\"创建访问路径\">创建访问路径</h4>\n<p>我们的服务在集群外，所以创建一个endpoint指向集群之外</p>\n<pre><code>echo 'apiVersion: v1\nkind: Service\nmetadata:\n  name: sidecar-webhook\nspec:\n  ports:\n  - port: 443\n    targetPort: 8443\n    protocol: TCP\n  type: ClusterIP\n\n---\n\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: sidecar-webhook\n  namespace: default\nsubsets:\n- addresses:\n  - ip: 10.22.12.178\n  ports:\n  - port: 8443\n    protocol: TCP' | kubectl apply -f -\n</code></pre>\n<h4 id=\"验证\">验证</h4>\n<p>重启backend服务，<code>kubectl rollout restart deploy backend</code></p>\n<pre><code>cannot bind '0.0.0.0:10000': Address already in use\n\n</code></pre>\n<p>出现了报错，这应该是由于envoy是监听10000端口，backend服务监听的也是10000端口，现在它们在一个net namespace，就肯定要报错了，所以改一下envoy的配置，监听另外一个端口吧，10000改成10001</p>\n<pre><code>      listeners:\n        - name: ingress_listener\n          address:\n            socket_address:\n              address: 0.0.0.0\n              port_value: 10001\n</code></pre>\n<p>再次重启查看pod状态</p>\n<pre><code>▶ kubectl get pod -owide -l app=backend\nNAME                       READY   STATUS    RESTARTS   AGE    IP             NODE     NOMINATED NODE   READINESS GATES\nbackend-6bdf5d484b-5czgx   2/2     Running   0          100s   10.244.0.184   wilson   &lt;none&gt;           &lt;none&gt;\n\n</code></pre>\n<p>查看详情</p>\n<p><img alt=\"auto_injection_2\" class=\"lazyload\" /></p>\n<p>自动注入了envoy容器</p>\n<p>至此，架构图如下：</p>\n<p><img alt=\"auto_injection_3\" class=\"lazyload\" /></p>\n<h2 id=\"精细化注入\">精细化注入</h2>\n<p>按照目前的配置，只要有pod create，就立刻回调集群外的注入服务，如果k8s集群的服务很多，并且频繁的create/destroy，那就会对注入服务产生较大的压力。如果在这些服务中，只有一些服务是需要使用自动注入功能的，那 就需要更精细化的注入管理</p>\n<h4 id=\"namespace打标签\">namespace打标签</h4>\n<p>首先要调整一下MutatingWebhookConfiguration</p>\n<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: sidecar-injector\nwebhooks:\n- name: sidecar.demo.io\n  namespaceSelector:\n    matchLabels:\n      sidecar-inject: \"true\"\n...\n</code></pre>\n<p>加上标签 <code>sidecar-inject: \"true\"</code>，只有满足这个标签，才会回调到外部的注入服务，这样就可以大大减轻注入服务的压力了</p>\n<p>再给namespace打上标签</p>\n<pre><code>kubectl label ns default sidecar-inject=true\n</code></pre>\n<p>default namespace里面所有的pod，都会回调至外部注入服务</p>\n<h4 id=\"pod-打标签\">pod 打标签</h4>\n<p>这次不在namespace下，而是基于某个pod label</p>\n<pre><code>apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: sidecar-injector\nwebhooks:\n- name: sidecar.demo.io\n  objectSelector:\n    matchLabels:\n      sidecar-inject-pod: \"true\"\n...\n</code></pre>\n<p>然后再给deployment打标签，这里要注意打的是pod的标签</p>\n<pre><code>kubectl patch deployment backend \\\n  --type='merge' \\\n  -p '{\n    \"spec\": {\n      \"template\": {\n        \"metadata\": {\n          \"labels\": {\n            \"sidecar-inject-pod\": \"true\"\n          }\n        }\n      }\n    }\n  }'\n</code></pre>\n<h2 id=\"小结\">小结</h2>\n<p>本文详细描述了怎么做自动注入：k8s配置修改+外部注入服务。其中需要注入的pod是写死在注入服务的，这部分可以抽出来，将配置写成configmap，或者在其他的配置中心中，这样就不用频繁的修改注入服务了</p>\n<p>另外mutating webhooks可以拦截大部分k8s支持的资源，并且发送到所配置的外部服务中进行需要的配置，这就不单单是pod自动注入，而是资源拦截。比如我需要拦截configmap</p>\n<pre><code>echo 'apiVersion: admissionregistration.k8s.io/v1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: callback-configmap\nwebhooks:\n- name: sidecar.demo.io\n  clientConfig:\n    service:\n      name: sidecar-webhook\n      namespace: default\n      path: /mutate\n    caBundle: '$mytls'\n  rules:\n  - apiGroups: [\"\"]\n    apiVersions: [\"v1\"]\n    operations: [\"CREATE\", \"UPDATE\"]\n    resources: [\"configmaps\"]\n  admissionReviewVersions: [\"v1\"]\n  sideEffects: None' | kubectl apply -f -\n</code></pre>\n<p>resources变更为configmap之后，就可以直接回调到外部服务。本章由于篇幅有限，就不对这个话题展开了，这个以后有需要再来详细讨论</p>\n<h2 id=\"联系我\">联系我</h2>\n<ul>\n<li>联系我，做深入的交流</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" height=\"200\" width=\"500\" /></p>\n<hr />\n<p>至此，本文结束<br />\n在下才疏学浅，有撒汤漏水的，请各位不吝赐教...</p>\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/MrVolleyball/\" target=\"_blank\">it排球君</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/MrVolleyball/p/19441540\" target=\"_blank\">https://www.cnblogs.com/MrVolleyball/p/19441540</a></p>\n<div>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须在文章页面给出原文连接，否则保留追究法律责任的权利。 </div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-01-05 11:04</span>&nbsp;\n<a href=\"https://www.cnblogs.com/MrVolleyball\">it排球君</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}