{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "从零开始:C#单文件AOT打包前后端分离项目",
      "link": "https://www.cnblogs.com/luojin765/p/19607043",
      "published": "",
      "description": "<h2 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/luojin765/p/19607043\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 09:42\">\n    <span>从零开始:C#单文件AOT打包前后端分离项目</span>\n    \n\n</a>\n</h2>\n    <div class=\"postText\"><div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"一前言\">一、前言</h1>\n<p>在 .NET 生态里，官方早就给出过“前后端一把梭”的方案——Blazor Server、Blazor WebAssembly、ASP.NET Core 寄宿 IIS 等。但它们要么强依赖前端独立部署，要么运行时拖家带口，源码裸露、启动速度、跨域配置都是痛点。<br />\n反观 Go、Rust 社区，一个 app 文件就能跑完 HTTP 服务 + 静态站点，拷贝即用，编译完连源码影子都看不到。<br />\n其实 C# 也能做到。今天这篇，就把“单文件、AOT、前后端全打进 exe”的完整流程拆给你看。</p>\n<p><img alt=\"frontBackAot\" class=\"lazyload\" /></p>\n<h1 id=\"二项目准备3-分钟搞定\">二、项目准备（3 分钟搞定）</h1>\n<p>项目仍然是前后端分离架构，前端可以用Vue、React任意框架实现，然后在.Net中打包在一起（前端代码只是嵌入）。<br />\n整体流程非常简单，从零开始创建，以NET10为例：</p>\n<ul>\n<li><code>dotnet new webapi -n AotDocsify -aot</code>创建一个 <code>ASP.NET Core Web API(native AOT)</code> 项目。</li>\n<li>项目根目录建<code>wwwroot</code>文件夹</li>\n<li>把前端编译产物（或任何前端 dist）整包拖进 wwwroot（本例中用docsify项目（纯前端markdown文档库），将原nginx中html下的文件复制进来）</li>\n</ul>\n<h1 id=\"三把静态文件嵌进-exe\">三、把静态文件“嵌”进 exe</h1>\n<p>打开<code>.csproj</code>文件，手动增加一行配置，将<code>wwwroot</code>文件夹下所有文件全部设为嵌入的资源。<br />\n编译器会把所有文件写进 PE 资源段，AOT 后依旧可见，零反射、零动态生成，放心用。</p>\n<pre><code class=\"language-xml\">\t&lt;ItemGroup&gt;\n\t\t&lt;EmbeddedResource Include=\"wwwroot\\**\\*\" /&gt;\n\t&lt;/ItemGroup&gt;\n</code></pre>\n<h1 id=\"四让-webapplication-认识这些内嵌文件\">四、让 WebApplication 认识这些“内嵌”文件</h1>\n<p>原后端代码不变，新增静态文件，通过<code>EmbeddedFileProvider</code>将嵌入的资源配置为静态文件。<br />\n如果在EmbeddedResource不重新更改文件逻辑名的话，这里就需要填写完整的默认命名空间（程序集名），即\"AotDocsify.wwwroot\"。这样程序就能通过输入路径，返回相应嵌入文件。</p>\n<pre><code class=\"language-csharp\">  app.UseStaticFiles(new StaticFileOptions\n  {\n      FileProvider = new EmbeddedFileProvider(Assembly.GetExecutingAssembly(), \"AotDocsify.wwwroot\"),\n      \n      RequestPath = \"\"\n  });\n</code></pre>\n<p>划重点：<code>Assembly.GetExecutingAssembly().GetManifestResourceStream</code> 在 NativeAOT 里并不是“真正的反射”，它只是对 编译期就已知且被嵌入到 PE 的元数据表 做的一次 常量级查找；只要你在 .csproj 里把 index.html 标记成 EmbeddedResource，NativeAOT 编译器就会把该资源连同它的名字一起写进最终映像，并生成一段 无反射、无动态代码生成的存根代码。因此运行时既不会触发 “反射被裁剪” 的异常，也不会出现 “找不到资源” 的错误。因此本代码可直接编译。</p>\n<h1 id=\"五页面路由配置\">五、页面路由配置</h1>\n<p>根路径 / 和 SPA 的 404 兜底都要手动接：当输入服务器根地址时，比如<code>localhost:5000</code>，服务器还是会返回404。这是因为我们还未对服务器根目录路由进行配置。传统方法配置仅针对于物理文件路径，因此我们需要额外手动来创建一个根目录的路由。具体代码如下：</p>\n<pre><code class=\"language-csharp\"> using var stream = Assembly.GetExecutingAssembly()\n                           .GetManifestResourceStream(\"AotDocsify.wwwroot.index.html\");\n if (stream is null) throw new Exception(\"找不到嵌入的 index.html\");\n\n string indexHtml;\n using (var reader = new StreamReader(stream))\n     indexHtml = reader.ReadToEnd();\n\n app.MapGet(\"/\", () =&gt; Results.Content(indexHtml, \"text/html\"));\n\n app.MapFallback(() =&gt; Results.Content(indexHtml, \"text/html\"));\n\n</code></pre>\n<p>通过以下代码打印，我们就能看到嵌入挂载的文件及路径：</p>\n<pre><code class=\"language-csharp\"> var names = Assembly.GetExecutingAssembly().GetManifestResourceNames();\n Console.WriteLine(\"=== 嵌入资源列表 ===\");\n foreach (var n in names) Console.WriteLine(n);\n\n// === 嵌入资源列表 ===\n// AotDocsify.wwwroot..nojekyll\n// AotDocsify.wwwroot.about.contributing.md\n// AotDocsify.wwwroot.about.project.md\n// AotDocsify.wwwroot.advanced.i18n.md\n// AotDocsify.wwwroot.advanced.plugins.md\n// AotDocsify.wwwroot.advanced.theme.md\n// AotDocsify.wwwroot.examples.code-highlight.md\n// AotDocsify.wwwroot.examples.markdown.md\n// AotDocsify.wwwroot.examples.math.md\n// AotDocsify.wwwroot.features.cover.md\n// AotDocsify.wwwroot.features.multipage.md\n// AotDocsify.wwwroot.features.navbar.md\n// AotDocsify.wwwroot.features.sidebar.md\n// AotDocsify.wwwroot.guide.basic-usage.md\n// AotDocsify.wwwroot.guide.installation.md\n// AotDocsify.wwwroot.guide.quickstart.md\n// AotDocsify.wwwroot.README.md\n// AotDocsify.wwwroot._sidebar.md\n// AotDocsify.wwwroot.index.html\n</code></pre>\n<p>发布完后，删除除exe外的所有文件，包括<code>wwwroot</code>目录。因为此时所有前端文件均已嵌入打包，本例aot生成的最终exe大小约10mb，运行后，前端后端均可正常工作，且后端所有资源可供前端调用，不存在跨域问题。打开<code>http://localhost:5000</code>出页面，打开<code>http://localhost:5000/todos</code>出接口返回值。</p>\n<h1 id=\"六最后\">六、最后</h1>\n<p>本文主要介绍了用最少的代码量把“前端 dist + 后端 API” 压成了一个 AOT 可执行文件，部署只剩“复制 → 运行”两步。<br />\n如果你在阅读过程中有任何疑问，或者在实际操作中遇到了困难，欢迎随时与我们交流。我们非常期待听到你的反馈和建议，以便我们能够进一步完善内容，帮助更多开发者。请继续关注我们的公众号“萤火初芒”，我们将持续分享更多有趣且实用的技术内容，与大家一起学习交流，共同进步。</p>\n<p><img alt=\"QR\" class=\"lazyload\" /></p>\n\n\n</div>\n<div class=\"clear\"></div>\n</div>\n    <p class=\"postfoot\">posted on \n<span id=\"post-date\">2026-02-12 09:42</span>&nbsp;\n<a href=\"https://www.cnblogs.com/luojin765\">LdotJdot</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</p>"
    },
    {
      "title": "表格设计：结构与美感并重",
      "link": "https://www.cnblogs.com/wang_yb/p/19606960",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/wang_yb/p/19606960\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 09:18\">\n    <span>表格设计：结构与美感并重</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>提到数据可视化，大家脑海里往往浮现的是炫酷的动态图表或复杂的仪表板。</p>\n<p>但其实，在商业报告和学术研究中，<strong>表格</strong>（<code>Table</code>） 才是那个最默默无闻却最不可或缺的英雄。</p>\n<p>很多时候，一张设计糟糕的表格就像一堵密不透风的砖墙，让人望而生畏；而一张优秀的表格，应该像是一个精心整理的陈列柜，一眼就能看到最有价值的宝贝。</p>\n<p>今天，本文将总结一下表格的结构美学与设计智慧。</p>\n<h1 id=\"1-表格的结构\">1. 表格的结构</h1>\n<p>如果把表格比作一座建筑，那么它的每个结构部件都承担着特定功能。</p>\n<p>下面是一个完整的表格示例，展示了所有标准结构组件：</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769823999740-9f83f02d-038b-4c25-b6aa-fe3443ad5a32.png\" /></p>\n<p>表格结构图解：</p>\n<ol>\n<li><strong>标题与副标题</strong>：表格的\"名字\"和\"简介\"，告诉读者这是什么</li>\n<li><strong>表头</strong>：列标题，相当于数据列的\"姓名标签\"</li>\n<li><strong>跨列标题</strong>：横跨多列的标题，用于分组</li>\n<li><strong>单元格</strong>：数据的基本单位，行列交叉点</li>\n<li><strong>网格线</strong>：分隔单元格的线，像田字格的线</li>\n<li><strong>边框</strong>：整个表格的边界线（本例使用阴影替代粗边框）</li>\n<li><strong>边线</strong>：各部分之间的分隔线，如页脚上方的虚线</li>\n<li><strong>页脚</strong>：表格的\"总结陈词\"</li>\n<li><strong>来源和注释</strong>：数据的\"身份证\"和\"使用说明\"</li>\n</ol>\n<h1 id=\"2-表格的设计准则\">2. 表格的设计准则</h1>\n<p>设计表格的最高境界是“隐形”。好的设计应该让读者忽略表格本身，而直接看到数据。</p>\n<p>以下是十条黄金法则，每条都准备了<strong>“反面教材”</strong>和<strong>“正面示范”</strong>。</p>\n<h2 id=\"21-将表头字段与正文区分开\">2.1. 将表头字段与正文区分开</h2>\n<p>表头是路牌，正文是风景。如果路牌和风景混在一起，游客就迷路了。</p>\n<p>使用加粗、背景色或线条来区分。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825066577-3377e8e0-dec0-49da-bdea-09ab005df3f1.png\" /></p>\n<h2 id=\"22-使用淡而细的分隔线\">2.2. 使用淡而细的分隔线</h2>\n<p>不要把数据关进“监狱”里！粗黑的网格线会抢夺视线。</p>\n<p>现代设计倾向于只保留横向分割线，甚至完全用留白代替线条。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825086423-d4485a90-70e2-4ad0-b2cc-d973eb40c970.png\" /></p>\n<h2 id=\"23-数据和表头字段右对齐\">2.3. 数据和表头字段右对齐</h2>\n<p>这是新手最常犯的错误。</p>\n<p>数字一定要<strong>右对齐</strong>！因为我们比较数值大小时，是根据“位”来比的（个位对个位，十位对十位）。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825100185-1bd84382-8621-4c76-b2f0-6fbe7225c80a.png\" /></p>\n<h2 id=\"24-文本和标题左对齐\">2.4. 文本和标题左对齐</h2>\n<p>对于非数字的文本（如名字、地区、类别），左对齐符合我们的阅读习惯（从左到右）。</p>\n<p>居中对齐文本会让读者的眼球在锯齿状的边缘跳来跳去，非常累。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825113141-761532f1-d04a-4f78-bc7d-1af78f069010.png\" /></p>\n<h2 id=\"25-选择适当的精度级别\">2.5. 选择适当的精度级别</h2>\n<p>数据不是越精确越好，给高管看报表，$1,234,567.89 远不如 $1.23M 来得直观。</p>\n<p>多余的小数点是“数据噪音”。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825131209-bb733176-7f58-4fe8-b788-7694816b7041.png\" /></p>\n<h2 id=\"26-利用留白引导视线\">2.6. 利用留白引导视线</h2>\n<p>拥挤的表格让人窒息。给行与行、列与列之间留出“呼吸空间”（Padding）。</p>\n<p>留白本身就是最好的分割线。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825150546-db07e24d-f074-4b43-b817-8afe5b4d68d9.png\" /></p>\n<h2 id=\"27-删除重复的单位\">2.7. 删除重复的单位</h2>\n<p>不要让读者的眼睛一遍遍重复读同样的信息。把单位（$、kg、%）提到表头里去。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825172096-1787cad2-2267-4716-8cb7-39af8792724c.png\" /></p>\n<h2 id=\"28-突出显示异常值\">2.8. 突出显示异常值</h2>\n<p>表格不仅要陈列数据，还要发出警报。</p>\n<p>如果某个数据需要关注（如亏损、未达标），请用红色或加粗标出来，不要让读者自己去“找茬”。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825187223-10cecb69-3d7e-4cd4-9ce5-d9d1a8b140cc.png\" /></p>\n<h2 id=\"29-将相似数据分组并增加空白\">2.9. 将相似数据分组并增加空白</h2>\n<p>如果多行属于同一个类别，不要重复写类别名，也不要留空让人猜。</p>\n<p>更好的做法是分组显示，或者只显示一次类别名。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825199656-612b3e57-3bf3-446b-878e-b0eb2083e918.png\" /></p>\n<h2 id=\"210-适当添加可视化元素\">2.10. 适当添加可视化元素</h2>\n<p>表格和图表不是死对头。</p>\n<p>在表格里嵌入数据条（Data Bars）、迷你图（Sparklines） 或 热力色块，能让表格瞬间变成“可视化仪表板”。</p>\n\n<p><img alt=\"\" src=\"https://cdn.nlark.com/yuque/0/2026/png/2235414/1769825210326-7c50dc8f-2808-4b0b-90d9-f0481023f76a.png\" /></p>\n<h1 id=\"3-总结\">3. 总结</h1>\n<p><strong>表格</strong>不仅仅是存放数字的容器，它是沟通的桥梁。</p>\n<p>好的表格设计就像优秀的城市导览图：清晰的标识（表头）、合理的分区（分组）、直观的路径（对齐方式）、适度的装饰（可视化元素），以及最重要的——以用户（读者）为中心。</p>\n<p>表格不仅是数据的容器，更是沟通的工具。</p>\n<p>每个设计决策都应服务于一个目标：让读者更快、更准确地理解数据背后的故事。</p>\n<p>在数据可视化的大花园中，表格可能是最朴实无华的那一朵，但它的实用性和精确性永远无法被替代。</p>\n<p>掌握表格的设计艺术，你就能在最基础的媒介上，创造出最优雅的数据表达。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 09:18</span>&nbsp;\n<a href=\"https://www.cnblogs.com/wang_yb\">wang_yb</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI工具实践日记（一）：在树莓派上搭建OpenClaw，一个后端开发者的真实踩坑记录",
      "link": "https://www.cnblogs.com/rsls/p/19606304",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/rsls/p/19606304\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 08:53\">\n    <span>AI工具实践日记（一）：在树莓派上搭建OpenClaw，一个后端开发者的真实踩坑记录</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"AI工具实践日记（一）：在树莓派上搭建OpenClaw，一个后端开发者的真实踩坑记录\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/280247/202602/280247-20260212004610584-747709995.png\" />\n        真实记录我在树莓派上探索OpenClaw的过程——不美化、不炫技，只有真实的踩坑和惊喜。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>真实记录我在树莓派上探索OpenClaw的过程——不美化、不炫技，只有真实的踩坑和惊喜。</p>\n</blockquote>\n<hr />\n<h2 id=\"引言\">引言</h2>\n<p>作为一名后端开发者，我的技术栈从C#开始，逐渐学会了VUE，变成了全栈开发。后来也学习了Python，也用Java开发企业级应用。但是最近这几年，随着AI的发展，从ChatGPT到Kimi，从在VsCode中对话，到在Cursor中编程，从学会使用Claude Code开始，我已经变成了AI全栈开发者。最近OpenClaw也很火，而我也很羡慕钢铁侠中的贾维斯，于是我开始探索一个不同的方向：<strong>把AI助手部署在自己的树莓派上。</strong></p>\n<p>为什么是树莓派？</p>\n<ol>\n<li><strong>数据隐私</strong>：AI助手运行在自己的设备上，数据不出本地</li>\n<li><strong>硬件集成</strong>：树莓派支持GPIO、摄像头、蓝牙等硬件</li>\n<li><strong>7x24小时运行</strong>：低功耗，可以一直待命</li>\n<li><strong>多渠道集成</strong>：直接在钉钉、Discord等通讯工具中使用</li>\n<li><strong>自动化能力强</strong>：内置Cron调度器，各种定时任务</li>\n</ol>\n<p>听起来很完美，对吧？</p>\n<p>但实际在树莓派上安装和配置OpenClaw的过程中，我踩了不少坑。下面，我想记录真实的探索过程。</p>\n<hr />\n<h2 id=\"为什么选择在树莓派上部署openclaw\">为什么选择在树莓派上部署OpenClaw？</h2>\n<h3 id=\"我的树莓派配置\">我的树莓派配置</h3>\n<ul>\n<li><strong>型号</strong>：树莓派4B（4GB内存）</li>\n<li><strong>系统</strong>：Linux 6.12.62+rpt-rpi-v8（ARM64架构）</li>\n<li><strong>Python版本</strong>：3.8+</li>\n<li><strong>Node.js版本</strong>：v24.13.0</li>\n</ul>\n<h3 id=\"选择openclaw的原因\">选择OpenClaw的原因</h3>\n<ol>\n<li><strong>本地化部署</strong>：完全在树莓派上运行，数据更安全</li>\n<li><strong>硬件友好</strong>：支持摄像头、蓝牙等硬件设备</li>\n<li><strong>多渠道集成</strong>：支持钉钉、Discord等，直接在聊天中使用</li>\n<li><strong>技能扩展</strong>：可以自己写Python/Shell脚本扩展功能</li>\n<li><strong>定时任务</strong>：内置Cron调度器，自动化更方便</li>\n</ol>\n<hr />\n<h2 id=\"在树莓派上安装openclaw从一键安装到慢慢摸索\">在树莓派上安装OpenClaw：从\"一键安装\"到\"慢慢摸索\"</h2>\n<h3 id=\"第一步环境准备\">第一步：环境准备</h3>\n<p>树莓派的系统环境和普通的x86服务器不太一样，这点在安装时给了我不少惊喜。</p>\n<p><strong>坑1：Python版本不兼容</strong></p>\n<p>树莓派默认安装的是Python 3.7，但OpenClaw需要Python 3.8+。</p>\n<pre><code class=\"language-bash\"># 检查Python版本\npython3 --version\n# Python 3.7.3\n\n# 安装Python 3.8+\nsudo apt update\nsudo apt install python3.8 python3.8-venv python3-pip\n</code></pre>\n<p><strong>坑2：ARM64架构的Node.js安装</strong></p>\n<p>OpenClaw需要Node.js，但树莓派是ARM64架构，普通的x86版本不能用。</p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 下载ARM64版本的Node.js\nwget https://nodejs.org/dist/v24.13.0/node-v24.13.0-linux-arm64.tar.xz\n\n# 解压\ntar -xf node-v24.13.0-linux-arm64.tar.xz\n\n# 移动到系统目录\nsudo mv node-v24.13.0-linux-arm64 /usr/local/node\n\n# 配置环境变量\necho 'export PATH=/usr/local/node/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# 验证安装\nnode --version\n# v24.13.0\n</code></pre>\n<h3 id=\"第二步安装openclaw-cli\">第二步：安装OpenClaw CLI</h3>\n<p>官方文档说一行命令就能安装：</p>\n<pre><code class=\"language-bash\">npm install -g @openclaw/cli\n</code></pre>\n<p>但在树莓派上，遇到了几个问题。</p>\n<p><strong>坑3：npm权限问题</strong></p>\n<p>第一次安装时报错：<code>EACCES: permission denied</code></p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 配置npm全局目录\nmkdir ~/.npm-global\nnpm config set prefix '~/.npm-global'\necho 'export PATH=~/.npm-global/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nnpm install -g @openclaw/cli\n</code></pre>\n<p><strong>坑4：npm安装速度慢</strong></p>\n<p>树莓派的性能有限，npm安装速度很慢，甚至会超时。</p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 使用国内镜像\nnpm config set registry https://registry.npmmirror.com\n</code></pre>\n<h3 id=\"第三步初始化配置\">第三步：初始化配置</h3>\n<pre><code class=\"language-bash\">openclaw init\n</code></pre>\n<p>这步比较顺利，但有个小细节：</p>\n<p><strong>坑5：时区配置错误</strong></p>\n<p>一开始我没注意时区设置，结果定时任务总是比我预期的时间晚8小时（UTC vs 北京时间）。</p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 检查系统时区\ntimedatectl status\n# 显示：Time zone: UTC\n\n# 设置时区为Asia/Shanghai\nsudo timedatectl set-timezone Asia/Shanghai\n# 验证\ntimedatectl status\n# 显示：Time zone: Asia/Shanghai (CST, +0800)\n</code></pre>\n<h3 id=\"第四步安装dingtalk插件\">第四步：安装DingTalk插件</h3>\n<p>我想用钉钉作为主要通讯工具，所以安装了DingTalk插件：</p>\n<pre><code class=\"language-bash\">openclaw plugins install dingtalk\n</code></pre>\n<p><strong>坑6：插件配置复杂</strong></p>\n<p>安装后需要配置AppKey、AppSecret、企业ID等信息。我在钉钉开发者后台折腾了很久才搞清楚这些参数从哪里获取。</p>\n<p>解决：</p>\n<ol>\n<li>登录钉钉开放平台：<a href=\"https://open.dingtalk.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://open.dingtalk.com/</a></li>\n<li>创建应用（机器人应用）</li>\n<li>获取AppKey、AppSecret</li>\n<li>配置企业ID</li>\n<li>在 <code>~/.openclaw/openclaw.json</code>中填入这些信息</li>\n</ol>\n<p>配置文件示例：</p>\n<pre><code class=\"language-json\">{\n  \"channels\": {\n    \"dingtalk\": {\n      \"enabled\": true,\n      \"clientId\": \"你的AppKey\",\n      \"clientSecret\": \"你的AppSecret\",\n      \"robotCode\": \"你的机器人编码\",\n      \"corpId\": \"你的企业ID\",\n      \"dmPolicy\": \"open\",\n      \"groupPolicy\": \"open\",\n      \"messageType\": \"card\"\n    }\n  }\n}\n</code></pre>\n<h3 id=\"第五步启动gateway服务\">第五步：启动Gateway服务</h3>\n<pre><code class=\"language-bash\">openclaw gateway start\n</code></pre>\n<p><strong>坑7：端口冲突</strong></p>\n<p>第一次启动时报错：<code>Error: listen EADDRINUSE: address already in use :::18789</code></p>\n<p>检查发现是其他服务占用了端口。</p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 检查端口占用\nlsof -i :18789\n\n# 停止占用端口的进程\nsudo kill &lt;进程ID&gt;\n\n# 或者修改配置文件中的端口\n</code></pre>\n<p><strong>坑8：树莓派性能限制</strong></p>\n<p>启动Gateway后，树莓派的内存占用很高，系统变得卡顿。</p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 在~/.openclaw/openclaw.json中调整并发参数\n\"agents\": {\n  \"defaults\": {\n    \"maxConcurrent\": 2,  // 降低并发数\n    \"subagents\": {\n      \"maxConcurrent\": 4  // 降低子任务并发数\n    }\n  }\n}\n</code></pre>\n<hr />\n<h2 id=\"在树莓派上的实用场景\">在树莓派上的实用场景</h2>\n<h3 id=\"场景1蓝牙tts语音播放\">场景1：蓝牙TTS语音播放</h3>\n<p>我想让OpenClaw通过蓝牙音箱播放语音。这在树莓派上实现起来很有意思。</p>\n<p><strong>坑9：蓝牙音箱配对</strong></p>\n<p>树莓派的蓝牙配置和普通电脑不太一样。</p>\n<pre><code class=\"language-bash\"># 安装蓝牙工具\nsudo apt install bluez bluez-tools pulseaudio pulseaudio-module-bluetooth\n\n# 启动蓝牙服务\nsudo systemctl start bluetooth\n\n# 配置蓝牙\nsudo bluetoothctl\n# 进入交互模式\n[bluetooth]# power on\n[bluetooth]# agent on\n[bluetooth]# scan on\n# 找到设备后\n[bluetooth]# pair &lt;设备MAC地址&gt;\n[bluetooth]# connect &lt;设备MAC地址&gt;\n[bluetooth]# trust &lt;设备MAC地址&gt;\n[bluetooth]# exit\n</code></pre>\n<p>问题：配对成功了，但音频输出不到蓝牙音箱。</p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 检查音频输出设备\npactl list sinks short\n\n# 设置默认输出为蓝牙设备\npactl set-default-sink &lt;蓝牙设备名称&gt;\n\n# 测试音频播放\npaplay /usr/share/sounds/alsa/Front_Center.wav\n</code></pre>\n<p>现在，我可以对OpenClaw说：</p>\n<pre><code>请播放语音：\"现在是下午三点，记得休息一下\"\n</code></pre>\n<p>它就会通过蓝牙音箱播放出来。</p>\n<p><strong>树莓派上的特别之处：</strong></p>\n<ul>\n<li>蓝牙配置需要手动操作，不像PC那样图形界面方便</li>\n<li>脉冲音频（PulseAudio）的配置需要熟悉</li>\n<li>但一旦配置好，可以7x24小时待命，随时播报</li>\n</ul>\n<h3 id=\"场景2摄像头拍照和控制\">场景2：摄像头拍照和控制</h3>\n<p>我想让OpenClaw帮我拍照并发送到钉钉。树莓派上接USB摄像头很方便。</p>\n<p><strong>坑10：摄像头被占用</strong></p>\n<p>树莓派上有个监控服务 <code>motion</code>，它占用了摄像头设备 <code>/dev/video0</code>。</p>\n<p>第一次拍照时报错：<code>Could not open video device /dev/video0</code></p>\n<p>解决：</p>\n<pre><code class=\"language-bash\"># 停止motion服务\nsudo pkill motion\nsudo systemctl stop motion\n\n# 检查摄像头\nls /dev/video*\n# /dev/video0 /dev/video1\n\n# 拍照\nffmpeg -f v4l2 -video_size 640x480 -i /dev/video0 -frames:v 1 /tmp/photo.jpg -y\n\n# 拍照后重启motion（如果需要）\nsudo systemctl start motion\n</code></pre>\n<p><strong>坑11：摄像头分辨率限制</strong></p>\n<p>树莓派支持的摄像头格式和分辨率有限。</p>\n<pre><code class=\"language-bash\"># 查看摄像头支持的格式\nv4l2-ctl --list-formats\n\n# 查看支持的分辨率\nv4l2-ctl --list-formats-ext\n\n# 我的icspring camera最高只支持640x480，YUYV格式\n</code></pre>\n<p>拍摄命令需要指定正确的格式：</p>\n<pre><code class=\"language-bash\">ffmpeg -f v4l2 -video_size 640x480 -i /dev/video0 -pix_fmt yuyv422 -frames:v 1 /tmp/photo.jpg -y\n</code></pre>\n<p>现在，我可以对OpenClaw说：</p>\n<pre><code>请拍一张照片，并发送到钉钉\n</code></pre>\n<p>几秒后，我就能在钉钉聊天中看到刚刚拍的照片。</p>\n<p><strong>树莓派上的特别之处：</strong></p>\n<ul>\n<li>USB摄像头热插拔方便</li>\n<li>可以和监控服务motion配合使用</li>\n<li>树莓派体积小，可以放在任何需要监控的地方</li>\n</ul>\n<h3 id=\"场景3邮件发送功能\">场景3：邮件发送功能</h3>\n<p>我想让OpenClaw帮我发邮件。于是开发了一个email-sender技能。</p>\n<p><strong>坑12：SMTP配置陷阱</strong></p>\n<p>配置126邮箱的SMTP服务时，我一开始用的是邮箱密码，结果一直报认证错误。</p>\n<p>查了半天文档才发现，126邮箱需要用\"客户端授权码\"，而不是邮箱密码。</p>\n<p>解决：</p>\n<ol>\n<li>登录126邮箱网页版</li>\n<li>进入设置 → POP3/SMTP/IMAP</li>\n<li>开启SMTP服务</li>\n<li>获取授权码</li>\n<li>在配置文件中使用授权码</li>\n</ol>\n<p>配置文件（<code>/home/pi/.openclaw/workspace/config/email.conf</code>）：</p>\n<pre><code class=\"language-ini\">[SMTP]\nhost = smtp.126.com\nport = 465\nusername = ren8179@126.com\npassword = QHyjTYHm8w3QVpi6  # 客户端授权码，不是邮箱密码\n</code></pre>\n<p>Python发送脚本：</p>\n<pre><code class=\"language-python\">import smtplib\nfrom email.mime.text import MIMEText\nimport configparser\n\ndef send_email(to, subject, content):\n    config = configparser.ConfigParser()\n    config.read('/home/pi/.openclaw/workspace/config/email.conf')\n\n    smtp_host = config['SMTP']['host']\n    smtp_port = config['SMTP']['port']\n    username = config['SMTP']['username']\n    password = config['SMTP']['password']\n\n    msg = MIMEText(content)\n    msg['From'] = username\n    msg['To'] = to\n    msg['Subject'] = subject\n\n    with smtplib.SMTP_SSL(smtp_host, smtp_port) as server:\n        server.login(username, password)\n        server.send_message(msg)\n</code></pre>\n<p>现在，我可以对OpenClaw说：</p>\n<pre><code>请发送邮件到ren8179@126.com，主题是\"测试\"，内容是\"OpenClaw邮件发送功能测试\"\n</code></pre>\n<p>几秒后，邮件就发送成功了。</p>\n<p><strong>树莓派上的特别之处：</strong></p>\n<ul>\n<li>24小时在线，随时可以发送邮件</li>\n<li>可以配合定时任务，自动发送日报、周报</li>\n<li>邮件内容可以基于传感器数据（温度、湿度等）</li>\n</ul>\n<h3 id=\"场景4定时任务和自动化\">场景4：定时任务和自动化</h3>\n<p>这是OpenClaw最强大的功能之一。内置的Cron调度器让我可以设置各种自动化任务。</p>\n<p><strong>坑13：Cron表达式理解错误</strong></p>\n<p>一开始我不太理解Cron表达式的格式，导致任务执行时间和预期不符。</p>\n<p>比如，我想设置\"每天早上8点执行\"，我写成了：</p>\n<pre><code class=\"language-json\">\"expr\": \"0 8 * * *\"\n</code></pre>\n<p>结果发现是在UTC时间8点执行，不是北京时间8点。</p>\n<p>解决：<br />\n在配置文件中明确指定时区：</p>\n<pre><code class=\"language-json\">{\n  \"schedule\": {\n    \"kind\": \"cron\",\n    \"expr\": \"0 8 * * *\",\n    \"tz\": \"Asia/Shanghai\"  // 明确指定时区\n  }\n}\n</code></pre>\n<p>现在，我可以设置各种自动化任务：</p>\n<ul>\n<li>每天8点：发送早间简报到钉钉</li>\n<li>每小时整点：播报时间</li>\n<li>每天凌晨2点：执行数据备份</li>\n<li>工作日上午9点：发送工作提醒</li>\n</ul>\n<p><strong>早间简报示例：</strong></p>\n<pre><code class=\"language-json\">{\n  \"id\": \"morning-report\",\n  \"name\": \"早间简报\",\n  \"schedule\": {\n    \"kind\": \"cron\",\n    \"expr\": \"0 8 * * *\",\n    \"tz\": \"Asia/Shanghai\"\n  },\n  \"payload\": {\n    \"kind\": \"agentTurn\",\n    \"message\": \"请生成今天的早间简报，包括：\\n1. 昨夜完成的工作\\n2. 系统状态\\n3. 今日建议\\n\\n发送到钉钉\"\n  }\n}\n</code></pre>\n<p><strong>树莓派上的特别之处：</strong></p>\n<ul>\n<li>低功耗，24小时运行也不心疼电费</li>\n<li>系统稳定，长时间运行不重启</li>\n<li>可以和各种硬件定时器配合</li>\n</ul>\n<hr />\n<h2 id=\"树莓派性能优化经验\">树莓派性能优化经验</h2>\n<h3 id=\"挑战1内存占用高\">挑战1：内存占用高</h3>\n<p>OpenClaw运行在树莓派上，内存占用是个问题。</p>\n<p><strong>解决方案：</strong></p>\n<ol>\n<li>\n<p><strong>降低并发数</strong>：</p>\n<pre><code class=\"language-json\">\"agents\": {\n  \"defaults\": {\n    \"maxConcurrent\": 2,\n    \"subagents\": {\n      \"maxConcurrent\": 4\n    }\n  }\n}\n</code></pre>\n</li>\n<li>\n<p><strong>启用会话压缩</strong>：</p>\n<pre><code class=\"language-json\">\"agents\": {\n  \"defaults\": {\n    \"compaction\": {\n      \"mode\": \"safeguard\",\n      \"maxTokens\": 200000\n    }\n  }\n}\n</code></pre>\n</li>\n<li>\n<p><strong>定期清理旧会话</strong>：</p>\n<pre><code class=\"language-bash\">openclaw sessions cleanup --older-than 1d\n</code></pre>\n</li>\n</ol>\n<h3 id=\"挑战2磁盘空间不足\">挑战2：磁盘空间不足</h3>\n<p>OpenClaw会话日志会占用大量磁盘空间。</p>\n<p><strong>解决方案：</strong></p>\n<pre><code class=\"language-bash\"># 设置日志轮转\nsudo vim /etc/logrotate.d/openclaw\n\n/home/pi/.openclaw/agents/main/sessions/*.jsonl {\n    daily\n    rotate 7\n    compress\n    delaycompress\n    missingok\n    notifempty\n}\n</code></pre>\n<h3 id=\"挑战3树莓派散热\">挑战3：树莓派散热</h3>\n<p>OpenClaw持续运行会让树莓派发热，影响性能。</p>\n<p><strong>解决方案：</strong></p>\n<pre><code class=\"language-bash\"># 安装散热监控\nsudo apt install lm-sensors\n\n# 查看温度\nsensors\n\n# 安装散热风扇\n# 树莓派4B强烈建议安装主动散热\n\n# 配置CPU频率调节\necho 'performance' | sudo tee /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\n</code></pre>\n<hr />\n<h2 id=\"深入体验主动式ai助手的力量\">深入体验：主动式AI助手的力量</h2>\n<p>OpenClaw最让我惊喜的，是它的\"主动性\"。</p>\n<h3 id=\"传统的ai助手\">传统的AI助手</h3>\n<p>传统的AI助手，是\"被动式\"的：</p>\n<ul>\n<li>你问什么，它答什么</li>\n<li>你不问，它什么都不会做</li>\n<li>像一个随时待命的仆人</li>\n</ul>\n<h3 id=\"openclaw的主动性\">OpenClaw的主动性</h3>\n<p>OpenClaw的设计理念是\"主动式AI助手\"：</p>\n<ul>\n<li>它会主动检查系统状态</li>\n<li>它会主动发送早间简报</li>\n<li>它会主动执行定时任务</li>\n<li>像一个积极的队友</li>\n</ul>\n<h3 id=\"实际案例早间简报\">实际案例：早间简报</h3>\n<p>我设置了一个每日早间简报，每天早上8点自动发送到钉钉。内容包括：</p>\n<ul>\n<li>📝 内容创作进展</li>\n<li>🚀 工具优化和创新</li>\n<li>📚 学习进度</li>\n<li>🔍 行业动态</li>\n<li>💡 今日建议</li>\n</ul>\n<p>每天早上醒来，打开钉钉，就能看到AI助手已经帮我整理好了所有重要信息。这种感觉，真的像有一个\"私人助理\"在默默为我工作。</p>\n<p><strong>树莓派上的优势：</strong></p>\n<ul>\n<li>7x24小时在线，从不错过任何任务</li>\n<li>低功耗，一个月电费不到10元</li>\n<li>体积小，可以放在任何地方</li>\n</ul>\n<hr />\n<h2 id=\"我的思考树莓派ai助手的可能性\">我的思考：树莓派+AI助手的可能性</h2>\n<h3 id=\"以前的想法ai在云端\">以前的想法：AI在云端</h3>\n<p>以前我觉得AI必须在云端运行，因为：</p>\n<ul>\n<li>云端算力强</li>\n<li>云端模型大</li>\n<li>云端更新快</li>\n</ul>\n<h3 id=\"现在的想法ai也可以在边缘\">现在的想法：AI也可以在边缘</h3>\n<p>在树莓派上运行OpenClaw后，我的想法改变了：</p>\n<p><strong>AI不是只能在云端，也可以在边缘设备上运行。</strong></p>\n<p>优势：</p>\n<ol>\n<li><strong>数据隐私</strong>：所有数据在本地，更安全</li>\n<li><strong>网络独立</strong>：不依赖网络，离线也能用（部分功能）</li>\n<li><strong>硬件集成</strong>：可以直接控制摄像头、蓝牙、GPIO等</li>\n<li><strong>7x24小时</strong>：低功耗，可以一直待命</li>\n<li><strong>成本可控</strong>：一次性购买，没有订阅费用</li>\n</ol>\n<h3 id=\"应用场景\">应用场景</h3>\n<p>基于树莓派+OpenClaw，可以做很多事情：</p>\n<ol>\n<li><strong>智能家居控制中心</strong>：控制灯光、温度、安防</li>\n<li><strong>家庭监控</strong>：摄像头拍照、异常检测</li>\n<li><strong>语音助手</strong>：通过蓝牙音箱播报信息</li>\n<li><strong>自动化任务</strong>：定时发送邮件、提醒、备份</li>\n<li><strong>远程监控</strong>：通过钉钉随时查看状态</li>\n<li><strong>学习记录</strong>：记录学习进度、生成日报周报</li>\n</ol>\n<hr />\n<h2 id=\"写在最后\">写在最后</h2>\n<p>这篇文章，记录了我在树莓派上安装和配置OpenClaw的真实过程。</p>\n<p><strong>真实体验总结：</strong></p>\n<ol>\n<li><strong>安装不轻松</strong>：踩了不少坑，但都解决了</li>\n<li><strong>学习曲线陡</strong>：需要时间熟悉，但值得</li>\n<li><strong>功能很强大</strong>：超出了我的预期</li>\n<li><strong>主动性很强</strong>：像一个真正的\"队友\"</li>\n<li><strong>性能需要优化</strong>：树莓派性能有限，需要调整配置</li>\n<li><strong>硬件集成很有趣</strong>：摄像头、蓝牙等，探索空间很大</li>\n</ol>\n<p><strong>给想尝试的朋友的建议：</strong></p>\n<p>如果你也想在树莓派上玩AI助手，我的建议是：</p>\n<ol>\n<li><strong>选择合适的设备</strong>：树莓派4B（4GB或8GB内存）</li>\n<li><strong>耐心安装</strong>：会遇到各种问题，慢慢解决</li>\n<li><strong>关注性能</strong>：注意内存、CPU、磁盘使用情况</li>\n<li><strong>发挥硬件优势</strong>：摄像头、蓝牙、GPIO都试试</li>\n<li><strong>记录经验</strong>：把踩坑经验记录下来，既帮助自己，也能帮助别人</li>\n</ol>\n<p><strong>下一步计划：</strong></p>\n<ol>\n<li>继续探索OpenClaw的高级功能</li>\n<li>开发更多自定义技能</li>\n<li>尝试树莓派+AI的各种组合场景</li>\n<li>记录完整的智能家居项目</li>\n<li>分享更多树莓派+AI的实践经验</li>\n</ol>\n<hr />\n<h2 id=\"参考链接\">参考链接</h2>\n<ul>\n<li>OpenClaw 文档：<a href=\"https://docs.openclaw.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.openclaw.ai</a></li>\n<li>钉钉开放平台：<a href=\"https://open.dingtalk.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://open.dingtalk.com/</a></li>\n<li>树莓派官方文档：<a href=\"https://www.raspberrypi.org/documentation/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.raspberrypi.org/documentation/</a></li>\n<li>爱弥儿任务看板：<a href=\"https://github.com/ren8179/aimier-kanban\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/ren8179/aimier-kanban</a></li>\n</ul>\n<hr />\n<p><em>本文是真实的探索记录，没有美化，没有技术炫技。只是一个后端开发者在树莓派上探索AI助手的踩坑经历。</em></p>\n<hr />\n<p><strong>发布日期：</strong> 2026-02-07<br />\n<strong>作者：</strong> 任琪<br />\n<strong>标签：</strong> #AI工具 #OpenClaw #树莓派 #后端开发 #实践经验 #本地化部署 #智能家居</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 08:53</span>&nbsp;\n<a href=\"https://www.cnblogs.com/rsls\">五蕴非空</a>&nbsp;\n阅读(<span id=\"post_view_count\">45</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "我装了个插件，让两个 OpenClaw 开始 24/7 搞事情了",
      "link": "https://www.cnblogs.com/xueweihan/p/19605642",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xueweihan/p/19605642\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 08:27\">\n    <span>我装了个插件，让两个 OpenClaw 开始 24/7 搞事情了</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>最近爆火的开源项目 OpenClaw 是一个款能够运行在自己设备上的个人 AI 助手。你只需分配任务，它就会 7x24 干活——而不是简单的文字回复。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>目前，网上已经有很多详细的 OpenClaw 安装教程，这里就不再重复了。我平时用 OpenClaw 干活，比如：创意策划和执行落地这两个角色是需要分开的——前者需要天马行空，后者需要严谨细致。这个时候，不同的 AI 需要有不同的定位才能干好活。</p>\n<p>我就想，能不能让两个 OpenClaw 各干各的活，但又能无缝衔接&nbsp;24/7 搞事情？</p>\n<p>最近在 x 上也看到了 @huangserva 大佬的方案，给了我更多的灵感！如果跑通了，以后「一人公司」的未来不就是我带着自己的 OpenClaw A、B、C 一起 24/7 高效搞事儿？！</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>这时候我又看到了 MemOS 刚发的 OpenClaw 插件，用下来感觉还真行。</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<blockquote>\n<p>GitHub 地址：<a href=\"https://github.com/MemTensor/MemOS\" rel=\"noopener nofollow\" target=\"_blank\">github.com/MemTensor/MemOS</a></p>\n</blockquote>\n<p>下面就是我的实际操作记录：怎么部署的、怎么配置的以及最后跑通了的效果（多 OpenClaw 协作）。</p>\n<h2 id=\"一为什么需要两个-openclaw-协作\">一、为什么需要两个 OpenClaw 协作？</h2>\n<p>一开始我也觉得，一个 OpenClaw 不就够了吗？为什么要搞两个？</p>\n<p>用了一阵子发现，有些场景确实需要分工，其次是分工可以更高效的产出。</p>\n<p>比如：策划活动时，<strong>创意阶段需要发散思维、天马行空。执行阶段需要落地细节、风险把控</strong>。让同一个 Agent 既发散又严谨，很容易精神分裂。</p>\n<p>其次，一个 OpenClaw 装了设计工具、文案模板，专门干创意。另一个连接了项目管理系统、预算工具，专门干落地。各司其职，效率更高。</p>\n<p>我的需求就是第一种：策划一场技术沙龙。创意阶段让 OpenClaw A 产出活动主流程和招募文案，执行阶段让 OpenClaw B 接力产出物料清单、风险预案，最后再 double-check 一遍。</p>\n<p>这里的关键是：<strong>B 不需要我手动告诉它 A 做了什么，它应该自己从记忆里读到 A 的产出</strong>，然后无缝接力 24/7 搞事情。</p>\n<p>然后 MemOS 的 OpenClaw 插件帮助我更好的干了这个脏活。</p>\n<h2 id=\"二部署两个-openclaw--memos-插件\">二、部署两个 OpenClaw + MemOS 插件</h2>\n<p>整个部署过程不复杂，但有几个细节要注意。</p>\n<h3 id=\"21-获取-memos-api-key\">2.1 获取 MemOS API Key</h3>\n<p>首先去 MemOS 官方注册并获取 API Key 格式是 mpg-... 开头的字符串。</p>\n<p><img alt=\"\" class=\"lazyload\" height=\"308\" width=\"1363\" /></p>\n<p>这个 Key 是两个 OpenClaw 共享记忆的凭证。有了它，两个独立的 OpenClaw 实例就能访问同一个记忆池。</p>\n<h3 id=\"22-部署两个-openclaw-实例\">2.2 部署两个 OpenClaw 实例</h3>\n<p>我是在同一台机器上跑两个实例，用不同端口区分。你也可以分别部署在两台服务器上，效果一样。</p>\n<p><strong>OpenClaw A：创意策划</strong></p>\n<pre><code class=\"language-bash\"># 创建配置目录并写入 API Key\nmkdir -p ~/.openclaw &amp;&amp; echo \"MEMOS_API_KEY=mpg-your_key_here\" &gt; ~/.openclaw/.env\n\n# 安装 OpenClaw（如果还没装）\nnpm install -g openclaw@latest\n\n# 初始化配置\nopenclaw onboard\n</code></pre>\n<p>按提示配置完后，OpenClaw A 会跑在默认端口（通常是 3000）。</p>\n<p><strong>OpenClaw B：执行落地</strong></p>\n<p>这里有个坑：同一台机器跑两个实例，需要指定不同的工作目录和端口。</p>\n<pre><code class=\"language-bash\"># 创建 OpenClaw B 的独立工作目录\nmkdir -p ~/.openclaw-exec\n\n# 复制配置（用同一个 API Key）\ncp ~/.openclaw/.env ~/.openclaw-exec/.env\n\n# 用独立配置启动第二个实例\nOPENCLAW_HOME=~/.openclaw-exec openclaw onboard --port 3001\n</code></pre>\n<p>这样两个 OpenClaw 就跑起来了，一个在 3000 端口一个在 3001 端口。</p>\n<h3 id=\"23-安装-memos-插件\">2.3 安装 MemOS 插件</h3>\n<p>两个实例都要装 MemOS 插件。分别进入各自的终端执行：</p>\n<p><strong>OpenClaw A</strong></p>\n<pre><code>openclaw plugins install github:MemTensor/MemOS-Cloud-OpenClaw-Plugin\nopenclaw gateway restart\n</code></pre>\n<p><strong>OpenClaw B</strong></p>\n<pre><code>OPENCLAW_HOME=~/.openclaw-exec openclaw plugins install github:MemTensor/MemOS-Cloud-OpenClaw-Plugin\nOPENCLAW_HOME=~/.openclaw-exec openclaw gateway restart\n</code></pre>\n<p>装完后，检查插件是否启用：</p>\n<pre><code># OpenClaw A\ncat ~/.openclaw/openclaw.json | grep memos-cloud-openclaw-plugin\n\n# OpenClaw B\ncat ~/.openclaw-exec/openclaw.json | grep memos-cloud-openclaw-plugin\n</code></pre>\n<p>看到 <code>\"enabled\": true</code> 就说明插件已激活。</p>\n<h3 id=\"24-共享-user_id关键\">2.4 共享 user_id（关键）</h3>\n<p><code>user_id</code> 是实现让多个 OpenClaw 记忆共享的关键。</p>\n<p>MemOS 用 <code>user_id</code> 来区分不同的记忆空间。同一个 <code>user_id</code> 下的所有对话和产出，都存在同一个记忆池里。</p>\n<p>默认配置下 <code>MEMOS_USER_ID=openclaw-user</code>，两个 OpenClaw 实例用的是同一个 <code>.env</code> 文件（或者你手动复制了一份相同的），所以它们的 <code>user_id</code> 是一样的——这就实现了记忆共享。</p>\n<p>如果你想改成自定义的 <code>user_id</code>，可以在 <code>.env</code> 文件里加一行就搞定：</p>\n<pre><code>MEMOS_USER_ID=my-custom-user-id\n</code></pre>\n<p>两个龙虾（OpenClaw）都用这个配置，就能轻松共享记忆！</p>\n<h2 id=\"三测试两个-openclaw-协作策划技术沙龙\">三、测试两个 OpenClaw 协作策划技术沙龙</h2>\n<p>部署好后，开始测试协作流程。</p>\n<h3 id=\"31-任务分工\">3.1 任务分工</h3>\n<p>我给两个 OpenClaw 定了明确的分工和角色：</p>\n<p><strong>OpenClaw A 负责创意策划</strong></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><strong>OpenClaw B 则负责执行落地</strong></p>\n<ul>\n<li>基于 A 的方案，产出物料清单</li>\n<li>制定风险预案</li>\n<li>最后再 double-check 整体方案</li>\n</ul>\n<p>这么操作的目的是：<strong>B 不需要我告诉它 A 做了什么，自己就能从 MemOS 记忆里读到 A 的产出，并开始无缝接力干活</strong>。</p>\n<h3 id=\"32-第一步openclaw-a-产出创意方案\">3.2 第一步：OpenClaw A 产出创意方案</h3>\n<p>我打开 OpenClaw A 的界面，直接问：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>OpenClaw A 开始工作。几分钟后，它开始产出了：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>并且快速给我返回了结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>这些内容自动写入了 MemOS。我没做任何手动保存，插件已经把 A 的产出存进了记忆池。</p>\n<h3 id=\"33-第二步openclaw-b-无缝接力\">3.3 第二步：OpenClaw B 无缝接力</h3>\n<p>协作的关键点来啦！我切换到 OpenClaw B 的界面（<a href=\"http://localhost:3001\" rel=\"noopener nofollow\" target=\"_blank\">http://localhost:3001</a>），不告诉它任何背景信息，直接问：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>OpenClaw B 开始工作，可以明显看到它在“思考”——它先调用了 MemOS 的记忆检索，然后基于 A 的产出开始接力。几分钟后，B 也开始产出了：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>B 返回的结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>从返回的结果可以看出：</p>\n<ul>\n<li>B 没有问我什么活动</li>\n<li>B 直接基于 A 的方案做了后续的补充和延展</li>\n<li>B 的物料清单和 A 的议程完全对得上～</li>\n</ul>\n<p>这说明 MemOS 的记忆检索和注入机制是有效的！B 确实读到了 A 的产出，并且理解了完整上下文。</p>\n<h3 id=\"34-第三步openclaw-b-做-double-check\">3.4 第三步：OpenClaw B 做 Double-Check</h3>\n<p>为了验证 B 的质量把控能力，我又问了一句：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>B 很快给出了反馈：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>还不错，可以交付了！</p>\n<h2 id=\"四技术原理memos-如何实现跨龙虾共享\">四、技术原理：MemOS 如何实现跨龙虾共享？</h2>\n<p>整体两个 OpenClaw 的协作过程很顺畅，安装配置简单，而且背后的技术原理也不难理解。核心就是下面三点：</p>\n<ol>\n<li>记忆隔离机制</li>\n<li>召回机制</li>\n<li>写回机制</li>\n</ol>\n<p><strong>记忆隔离机制</strong></p>\n<p>MemOS 通过 <code>user_id</code> 区分不同的记忆空间。可以简单理解为：</p>\n<pre><code>user_id=\"openclaw-user\"（默认配置）\n  ├─ OpenClaw A 的对话记录和输出\n  ├─ OpenClaw B 的对话记录和输出\n  └─ 所有共享的上下文\n</code></pre>\n<p>两个 OpenClaw 用同一个 <code>user_id</code>，就能访问同一个共享记忆池。</p>\n<p><strong>召回机制</strong></p>\n<p>OpenClaw B 启动后，MemOS 就会开始默默工作。它会分析用户的问题意图，然后去共享记忆池里找。等它把 OpenClaw A 之前产出的那份方案扒出来后，会先做个精简，然后将这些记忆直接“喂”给 B 当作背景知识（上下文）。这样一来，<strong>B 就不再是每次都失忆的状态，而是基于 A 的工作成果继续干</strong>。</p>\n<p>这个过程实现了完全自动，不再需要人工干预或复制粘贴。</p>\n<p><strong>写回机制</strong></p>\n<p>OpenClaw A 和 B 的产出都会自动写回 MemOS，同时，根据 MemOS 官方文档说明：<strong>不需要手动保存、不需要指定存储格式自动分类和索引且支持后续检索</strong>。</p>\n<p>这就是为什么 B 能读到 A 的产出——因为 A 的每次对话都自动存进了 MemOS 的记忆池。</p>\n<h2 id=\"五最后\">五、最后</h2>\n<p>在跑通了两个 OpenClaw 自动协作后，我开始思考这套方案适合什么场景、有什么局限。</p>\n<p>从 OpenClaw 爆火后，可以看到一个趋势，就是未来更多的场景会变成了多个智能体/AI 协同，如何管理让它们更好地高效协作成为了这个阶段大家探讨最多的问题。</p>\n<p>我看到的很多场景都已经开始涌现了对应的需求：</p>\n<ol>\n<li><strong>多个 🦞 协作</strong>：创意 + 执行、前端 + 后端、技术 + 运营，需要分工但又要信息同步的场景。</li>\n<li><strong>异步工作流</strong>：A 今天产出方案，B 明天接力执行。不需要同时在线，记忆会持久化保存。</li>\n<li><strong>多人项目</strong>：我的 OpenClaw 负责一部分，同事的 OpenClaw 负责另一部分，通过同一个 <code>user_id</code> 共享上下文。</li>\n</ol>\n<p>结合这些场景，再看基于 MemOS 的方案，还是有一些改进空间：</p>\n<ol>\n<li>同一个账号（user_id）：目前不支持更灵活的权限控制，比如 A 可以读 B 的输出，但 B 不能修改 A 的记忆。</li>\n<li>记忆检索精度：B 能否准确读到 A 的产出，取决于 MemOS 的检索算法。我测试下来准确率还不错，但复杂场景可能需要调整检索参数。</li>\n<li>复用模板：支持将好用的案例提取成可复用的模板或 Skills，新项目自动继承最佳实践。</li>\n</ol>\n<p>写了这么多，也不知道 MemOS 官方能不能看到我提出的改进点😅。</p>\n<p>但总体来说这套基于 MemOS 的方案还是值得一试！部署简单几个命令就能跑起来，让多个 OpenClaw 相互协作 24/7 搞事儿。</p>\n<p>虽说还有提升空间但也算是一套快速极简的 OpenClaw 协作方案，我觉得还挺有意思的。</p>\n<ul>\n<li>MemOS 官网：<a href=\"https://memos.openmem.net/\" rel=\"noopener nofollow\" target=\"_blank\">memos.openmem.net</a></li>\n<li>GitHub：<a href=\"https://github.com/MemTensor/MemOS\" rel=\"noopener nofollow\" target=\"_blank\">github.com/MemTensor/MemOS</a></li>\n<li>MemOS 插件：<a href=\"https://github.com/MemTensor/MemOS-Cloud-OpenClaw-Plugin\" rel=\"noopener nofollow\" target=\"_blank\">github.com/MemTensor/MemOS-Cloud-OpenClaw-Plugin</a></li>\n<li>OpenClaw 文档：<a href=\"https://docs.openclaw.ai/\" rel=\"noopener nofollow\" target=\"_blank\">docs.openclaw.ai</a></li>\n</ul>\n<p>最后，开启春节假期模式，让 OpenClaw 帮你干活吧！</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <div>    \n    <p id=\"PSignature\">\n    <br />\n    作者：<a href=\"https://github.com/521xueweihan\" target=\"_blank\">削微寒</a>\n\n    <br />\n    <strong>扫描左侧的二维码可以联系到我</strong>\n    <br />\n\n    <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh\" rel=\"license\"><img alt=\"知识共享许可协议\" src=\"https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png\" style=\"border-width: 0;\" /></a><br />本作品采用<a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh\" rel=\"license\">署名-非商业性使用-禁止演绎 4.0 国际 </a>进行许可。\n    </p>\n</div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 08:27</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xueweihan\">削微寒</a>&nbsp;\n阅读(<span id=\"post_view_count\">115</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "秒杀活动时系统在干什么 PHP 高并发场景优化指南",
      "link": "https://www.cnblogs.com/catchadmin/p/19606652",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/catchadmin/p/19606652\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 07:44\">\n    <span>秒杀活动时系统在干什么 PHP 高并发场景优化指南</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"秒杀活动时系统在干什么-php-高并发场景优化指南\">秒杀活动时系统在干什么 PHP 高并发场景优化指南</h1>\n<p>秒杀活动是电商平台的关键战役，往往会带来流量和订单的剧烈飙升。秒杀期间，每一毫秒都很关键，后端需要同时扛住海量请求。对 PHP 应用来说，这尤其有挑战性，但只要优化到位，即使流量洪峰来了，用户体验也能稳住。</p>\n<p>这篇文章会拆解 PHP 后端在秒杀期间需要做哪些事情：从数据库查询优化，到缓存管理，再到应用扩容。</p>\n<h2 id=\"用负载均衡应对高并发\">用负载均衡应对高并发</h2>\n<p>秒杀期间，PHP 应用需要动态扩容来承接激增的流量。负载均衡是把请求分散到多台服务器的核心手段。</p>\n<h3 id=\"负载均衡--自动扩容\">负载均衡 + 自动扩容</h3>\n<p>流量暴涨时，PHP 应用应该部署在负载均衡器（比如 AWS ELB 或 NGINX）后面，由负载均衡器把请求均匀分发到多台应用服务器。</p>\n<p>工作原理：</p>\n<ul>\n<li><strong>PHP-FPM 工作进程</strong>：每台 PHP 服务器通过 PHP-FPM（FastCGI 进程管理器）处理请求。负载均衡器确保请求被分散到多台服务器，避免单台服务器被打垮。</li>\n<li><strong>自动扩容</strong>：流量上来后，AWS EC2 Auto Scaling 或 Google Cloud Compute Engine 等云服务会自动拉起更多 PHP 实例来承接负载。</li>\n</ul>\n<p><strong>配置自动扩容</strong>：当 CPU 使用率或请求量超过阈值时触发扩容。</p>\n<pre><code class=\"language-bash\">aws autoscaling create-auto-scaling-group \\\n  --auto-scaling-group-name php-flash-sale-group \\\n  --min-size 2 --max-size 50 --desired-capacity 10 \\\n  --vpc-zone-identifier subnet-xyz\n</code></pre>\n<p><strong>负载均衡器配置</strong>：确保请求被高效地分发到所有 PHP 服务器。</p>\n<pre><code class=\"language-nginx\">upstream php_backend {\n    server php-server-1;\n    server php-server-2;\n    server php-server-3;\n}\nserver {\n    location / {\n        proxy_pass http://php_backend;\n    }\n}\n</code></pre>\n<p>通过负载均衡加自动扩容，PHP 后端可以平滑地应对秒杀期间的流量洪峰。</p>\n<h2 id=\"缓存策略减轻数据库压力\">缓存策略：减轻数据库压力</h2>\n<p>秒杀期间最大的挑战之一，就是防止数据库因为大量读写操作变成瓶颈。最有效的手段是用缓存来分担数据库查询，同时提升响应速度。</p>\n<h3 id=\"缓存静态内容和数据库查询\">缓存静态内容和数据库查询</h3>\n<p><strong>CDN 缓存静态资源</strong></p>\n<p>图片、CSS、JavaScript 这类静态资源应该通过 CDN（比如 Cloudflare 或 AWS CloudFront）在边缘节点缓存，保证用户能快速加载。在 PHP 中设置合适的缓存控制头：</p>\n<pre><code class=\"language-php\">header(\"Cache-Control: public, max-age=3600\");  // Cache static assets for 1 hour\n</code></pre>\n<p><strong>内存缓存热点数据</strong></p>\n<p>用 Redis 或 Memcached 缓存频繁查询的数据，比如商品库存和价格，减少数据库压力。</p>\n<p>秒杀期间，把商品库存状态存到 Redis 里，每次查库存就不用打数据库了：</p>\n<pre><code class=\"language-php\">$redis = new Redis();\n$redis-&gt;connect('localhost', 6379);\n// Check if product availability is cached\n$productId = 123;\n$productAvailability = $redis-&gt;get(\"product:{$productId}:availability\");\nif (!$productAvailability) {\n    // Cache miss, fetch from database\n    $productAvailability = fetchProductAvailabilityFromDb($productId);\n    $redis-&gt;set(\"product:{$productId}:availability\", $productAvailability, 3600);  // Cache for 1 hour\n}\n</code></pre>\n<p>这样可以大幅减少秒杀期间的数据库查询次数，用户的响应速度也更快。</p>\n<h2 id=\"优化数据库性能\">优化数据库性能</h2>\n<p>数据库性能往往是秒杀场景的瓶颈所在，特别是大量请求同时读写数据库的时候。优化查询、确保 PHP 应用高效处理数据库操作至关重要。</p>\n<h3 id=\"分库分表\">分库分表</h3>\n<p>分库分表是把数据库拆分成更小、更易管理的部分，每个部分只处理一部分数据，从而把查询分散到多个数据库实例上。</p>\n<p>比如可以按用户地区分库（北美用户和欧洲用户各用一套数据库），以此均衡负载。</p>\n<h3 id=\"连接池\">连接池</h3>\n<p>每次请求都开关数据库连接会带来很大的开销。通过连接池复用数据库连接，可以显著降低这部分消耗。在 PHP 中，可以配置持久连接：</p>\n<pre><code class=\"language-php\">$mysqli = new mysqli(\"p:localhost\", \"username\", \"password\", \"database\");\n</code></pre>\n<h3 id=\"读写分离\">读写分离</h3>\n<p>如果用了数据库主从复制（比如 MySQL Replication），可以配置 PHP 应用把读查询发到从库，写查询发到主库：</p>\n<pre><code class=\"language-php\">$readDb = new mysqli('read-replica-host', 'username', 'password', 'database');\n$writeDb = new mysqli('primary-db-host', 'username', 'password', 'database');\n</code></pre>\n<h3 id=\"查询优化\">查询优化</h3>\n<p>秒杀期间要确保数据库查询经过优化：对高频查询字段（比如商品 ID、分类等）建好索引。在 PHP 中使用预处理语句可以提升查询执行效率：</p>\n<pre><code class=\"language-php\">$stmt = $mysqli-&gt;prepare(\"SELECT * FROM products WHERE id = ?\");\n$stmt-&gt;bind_param(\"i\", $productId);\n$stmt-&gt;execute();\n$result = $stmt-&gt;get_result();\n$product = $result-&gt;fetch_assoc();\n</code></pre>\n<p>通过分库分表、连接池、读写分离和查询优化，可以防止数据库成为瓶颈，保证 PHP 应用在秒杀这种高并发场景下依然跑得动。</p>\n<h2 id=\"会话管理和用户认证\">会话管理和用户认证</h2>\n<p>秒杀期间，用户能不能顺利加购、结账、登录，直接决定了转化率。会话管理必须针对高并发做优化。</p>\n<h3 id=\"用-redis-做会话持久化\">用 Redis 做会话持久化</h3>\n<p>用 Redis 存储会话数据，这样即使请求被负载均衡器分发到不同的 PHP 服务器上，会话也不会丢失：</p>\n<pre><code class=\"language-php\">// Store session data in Redis\nsession_set_save_handler(new RedisSessionHandler($redis), true);\nsession_start();\n</code></pre>\n<h3 id=\"用-jwt-做无状态认证\">用 JWT 做无状态认证</h3>\n<p>用户登录和认证环节，可以用 JWT（JSON Web Token）来减轻会话存储的压力，实现无状态认证：</p>\n<pre><code class=\"language-php\">// Example of generating JWT token\n$payload = ['user_id' =&gt; $userId, 'exp' =&gt; time() + 3600];  // Expires in 1 hour\n$jwt = JWT::encode($payload, $secretKey);\n</code></pre>\n<p>把会话数据交给 Redis，认证环节用 JWT，就能保证秒杀期间的登录和会话管理又快又稳。</p>\n<h2 id=\"实时库存管理\">实时库存管理</h2>\n<p>秒杀期间，库存必须随着商品售出实时更新。PHP 需要确保库存数据在多台服务器之间保持同步，一旦有人下单，库存立刻扣减。</p>\n<h3 id=\"事件驱动架构处理库存更新\">事件驱动架构处理库存更新</h3>\n<p>通过 Apache Kafka 或 RabbitMQ 实现事件驱动架构，实时处理库存变更：</p>\n<pre><code class=\"language-php\">// Kafka Producer: Send product purchase events\n$producer-&gt;produce('product-purchased-topic', 0, json_encode(['product_id' =&gt; 123, 'quantity' =&gt; 1]));\n</code></pre>\n<p>库存服务订阅这些事件，实时更新数据库中的商品库存。用户下单后，购买事件发送到 Kafka，库存服务收到事件后立即扣减库存，其他用户就不会再买到已经卖完的商品。</p>\n<h2 id=\"总结\">总结</h2>\n<p>秒杀期间保证 PHP 应用的性能，需要多管齐下：负载均衡、缓存、数据库优化、实时库存管理，缺一不可。通过自动扩容、Redis 内存缓存、高效的数据库查询和事件驱动架构，PHP 应用完全有能力扛住流量洪峰，给用户提供流畅的体验。</p>\n<p>把这些手段用好，你的电商平台就能顶住秒杀的压力，不宕机、不卡顿，把转化率拉到最高。</p>\n<p><a href=\"https://catchadmin.com/post/2026-02/php-problem-isnt-language\" rel=\"noopener nofollow\" target=\"_blank\">秒杀活动时系统在干什么 PHP 高并发场景优化指南</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 07:44</span>&nbsp;\n<a href=\"https://www.cnblogs.com/catchadmin\">JaguarJack</a>&nbsp;\n阅读(<span id=\"post_view_count\">22</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎] Channel——驱动Node执行的原力",
      "link": "https://www.cnblogs.com/jaydenai/p/19605973/channel-of-pregel",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19605973/channel-of-pregel\" id=\"cb_post_title_url\" title=\"发布于 2026-02-12 06:28\">\n    <span>[拆解LangChain执行引擎] Channel——驱动Node执行的原力</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        Pregel由Node和Channel这两个核心部件组成，Channel不仅维护了整个图的状态，还是驱动Node执行的 “原力” 。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>Pregel由Node和Channel这两个核心部件组成，Channel不仅维护了整个图的状态，还是驱动Node执行的 “原力” 。在前面演示的一系列实例中，我们已经使用了三种Channel类型，包括频繁使用的LastValue，能够将所有添加的值保留下来的BinaryOperatorAggregate，以及帮助我们轻松解决多Node依赖问题的NamedBarrierValue。为什么Channel有这么多类型，我们应该在何种场景中使用何种类型的Channel，要回答这个问题，就无法回避（BSP：Bulk Synchronous Parallel）这一个算法模式，毫不夸张地说，整个Pregel就是围绕BSP进行设计的。</p>\n<h2 id=\"1-bsp\">1. BSP</h2>\n<p>我们知道一个Agent利用作为决策者的LLM和一系列作为执行者的Tool协助完成指定的任务。LLM（这里主要指基于文本生成的GPT）由于其逐Token的生成机制，加上各种工具可能涉及到大数据的处理、IO读写、跨网络的交互等耗时操作，所以要确保Agent能够提供可接受的性能保障，并行计算是唯一的解决方案。考虑到对并行计算的 “钢需” ，那么Pregel为什么选择Actor模型来实现也就很容易理解了，因为高并发正式Actor模型最擅长的领域。BSP中的BP（Bulk Parallel）可以理解为Pregel多个Node在同一时段的并行执行，那么S（Synchronous）有作何理解呢？</p>\n<p>在很多典型的Actor模型里，Actor大多是有状态的，但是作为Pregel的Actor，其Node对象是完全无状态的。开始执行之前，他从注册的Channel读取数据，执行结果以最终输出到相应的Channel。我们知道高并发、低延时和数据一致性是三个永远不可能同时兼顾的指标，如果要兼顾其中两个，就不得不牺牲第三个。大部分系统的架构与设计都是在对三者作一个平衡，Pregel亦是如此。</p>\n<p>由于多个并行执行的Node会涉及针对同一份数据（Channel）的读写，如果要保证数据的完整性，就不得不施加相应的同步机制，比如各种不同类型的锁。不论多轻量级的锁，它们都是高并发最强的杀手，那么能否实现无锁的解决方案呢？BSP就是答案，而这其中又涉及一个名为Superstep（Super Step，由于这一个概念会频繁提及，后续内容直接将Superstep视为一个专有名词来指代这一个概念）的概念，我们可以将其视为整个图有条不紊向前推进的一个单步，是Pregel执行引擎的一个脉冲，是所有Node执行的“节拍”，每个Superstep具有一个自增的序号。</p>\n<p>在每个Superstep结束之后，每个Channel的状态被固定下来，引擎根据Node针对Channel的订阅和Channel在当前Superstep内的更新情况确定在下一Superstep需要执行的Node，并为它们创建创建相应的任务。这些任务在新的Superstep开始是并发执行，而且它们只能访问前一超步固化下来的值。这一策略确保输入的一致性，保证所有并发执行的Node所见的状态都是一样的；另一方面Channel在Superstep内保持只读状态就完全不用考虑并发脏读的问题了。</p>\n<p>并发执行的Node不允许对任何Channel实施写入，它只能将写入诉求提交给执行引擎，后者按照提交的顺序存储下来。让所有任务成功执行后，Superstep进入一个同步屏障，执行引擎将对收集到的Channel写入请求按照顺序统一应用，使所有Channel最终能准确地体现Superstep结束后的状态。然后再确定下一Superstep的任务，如此反复，周而复始。</p>\n<p>第一个Superstep的序号是从-1开始计数的，这个所谓的“创世超步”开始于针对Pregel兑现的常规调用，引擎利用这一Superstep将原始输入写入对应的Channel，并计算需要在Superstep 0中执行的任务，所以Node的首次执行是在Superstep 0中执行的。</p>\n<p>由于Agent可以涉及一个需要长时间执行的处理流程，而且这个过程还可能出现中断，此中断可能是由于系统故障，也可能是需要认为介入导致，所以Agent的状态不可能常驻内容。而且Agent还提供了 “时间旅行” 的功能，这一个功能使我们从过去的某个时间点开启一个新的分支来执行流程，这相当于开启一个 “平行世界” 。所有的这一切都离不开针对状态的持久化，这是整个Pregel最复杂的部分。</p>\n<p>我们将在后续内容详细介绍Pregel针对状态持久化的设计与实现，这里我们做一个概括性介绍。当Superstep进入同步屏障之后，持久化发生在 “解析待执行任务” 之后，此时引擎会针对当前Channel的状态创建一份名为Checkpoint快照并利用注册的Checkpointer记录下来。</p>\n<p>每个被记录的Checkpoint不仅具有一个唯一标识，还登记了当前的Superstep序号，还有一个能够精确描述当前Agent对应的图在整个执行图中的位置（多Agent应用中，一个Agent可作为 “子Agent” 被调用，对应的图就是整张执行图的 “子图” ）和调用顺序的 “命名空间” 。完整的标识体系的唯一左右就是，在Agent从某个点恢复执行的时候，相应的Checkpointer能够准确地提取对应的Checkpoint来 “恢复现场” 。下图基本反映了Pregel针对单一Superstep的执行流程。</p>\n<p><img alt=\"image\" class=\"lazyload\" /></p>\n<p>但是很多文档中你看到他们将Superstep划分为“计划”、“执行”、“更新”和“持久化”，看起来合理，但是和真正的执行流程是有出入的。计划阶段得到其实不是当前Superstep待执行的任务，而是下一Superstep待执行的任务，因为这有这样采用解释为什么针对Superstep -1的Checkpoint会包含任务列表，这些任务分明是在Superstep 0中才会被执行。实际上Checkpoint中的任务列表反映的都是下一Superstep待执行的操作，所以唯独最后一个Checkpoint才不会存在任务列表。表示状态快照的StateSnapshot将返回任务名称列表的字段命名为next，我想也应该是处于这个原因。</p>\n<h2 id=\"2-basechannel\">2. BaseChannel</h2>\n<p>所有的Channel类型都派生于如下这个名为BaseChannel的抽象类，它的泛型类型参数Value和Update分别表示存储类型、更新时提供的值类型，我们可以利用属性ValueType和UpdateType获取前两种类型。抽象方法get和update提供针对这两个类型的读写,update方法返回的布尔值表示是否具有实质性的更新，引擎由此判断Channel的值是否发生改变。另一个泛型类型参数Checkpoint与持久化有关，引擎在恢复执行时会从持久化的快照中提取对应的数据并将其转换成此对象，最终调用from_checkpoint方法恢复Channel的状态，在进行持久化时，引擎会调用checkpoint方法将自身的状态转换成该类型，并提交给Checkpointer实施持久化。</p>\n<pre><code class=\"language-python\">Value = TypeVar(\"Value\")\nUpdate = TypeVar(\"Update\")\nCheckpoint = TypeVar(\"Checkpoint\")\n\nclass BaseChannel(Generic[Value, Update, Checkpoint], ABC):\n    __slots__ = (\"key\", \"typ\")\n    def __init__(self, typ: Any, key: str = \"\") -&gt; None\n\n    @property\n    @abstractmethod\n    def ValueType(self) -&gt; Any\n    @property\n    @abstractmethod\ndef UpdateType(self) -&gt; Any\n    \n    @abstractmethod\ndef get(self) -&gt; Value\n    @abstractmethod\ndef update(self, values: Sequence[Update]) -&gt; bool\n\n    @abstractmethod\ndef from_checkpoint(self, checkpoint: Checkpoint | Any) -&gt; Self\ndef checkpoint(self) -&gt; Checkpoint | Any\n\n    def copy(self) -&gt; Self    \n    def consume(self) -&gt; bool\n    def finish(self) -&gt; bool\t\n    def is_available(self) -&gt; bool \n</code></pre>\n<p>除此之外，BaseChannel还定义了其他几个方法，其中copy方法会根据自身状态创建一个新Channel对象，默认实现会先调用checkpoint方法，然后将返回值作为参数调用from_checkpoint方法，后者调用的结果就是copy方法的返回值，所以这是一个深拷贝。在所有任务执行完成后，触发它们的所有Channel的consume方法会被执行，Channel可以利用这个机会做一些清除工作以防止相同的数据被重复消费。consume方法的返回值旨在告诉 引擎该通道的内部数据是否已经发生了实质性改变（被消费或者清空）。如果返回True，意味着Channel的状态已被更新，其版本会被提升。</p>\n<p>Channel的值并非在每个时间点都是可用的，比如对于某些Channel，在Superstep N中写入的值只能在Superstep N+1中可用，Channel的可用性由is_available方法决定。finish是一个“钩子（Hook）”方法，引擎会在每个Superstep完成时调用此方法，对应的Channel可用利用此方法做一些类似于“可用性控制”的操作。指的一体的是，只有在当前Superstep中被更新的且被Node订阅的Channel，它们的finish方法才会被调用。</p>\n<h2 id=\"3-channel\">3. Channel</h2>\n<p>Pregel提供了若干预定义的Channel类型，它们的读写行为以及可用性上都有差异，我们需要根据数据或者状态的特性选择适合的Channel类型。</p>\n<h2 id=\"31lastvalue\">3.1\tLastValue</h2>\n<p>LastValue只存储单值，并且采用后来居上的策略，存储最后一个提交更新的值。从如下提供的具体实现可用看出，LastValue的值类型、更新类型和Checkpoint类型三者合一，所以只通过字段value维护唯一的值。get、checkpoint和update方法实现了针对该字段的读写，如果没有对value字段显式赋值，is_available方法会返回False，get方法也会抛出异常。copy和from_checkpoint方法返回的都是一个新的LastValue对象，提供的值会为其value字段赋值。</p>\n<pre><code class=\"language-python\">class LastValue(Generic[Value], BaseChannel[Value, Value, Value]):\n    __slots__ = (\"value\",)\n    value: Value | Any\n\n    def __init__(self, typ: Any, key: str = \"\") -&gt; None:\n        super().__init__(typ, key)\n        self.value = MISSING\n\n    def __eq__(self, value: object) -&gt; bool:\n        return isinstance(value, LastValue)\n\n    @property\n    def ValueType(self) -&gt; type[Value]:\n        return self.typ\n\n    @property\n    def UpdateType(self) -&gt; type[Value]:\n        return self.typ\n\n    def copy(self) -&gt; Self:\n        empty = self.__class__(self.typ, self.key)\n        empty.value = self.value\n        return empty\n\n    def from_checkpoint(self, checkpoint: Value) -&gt; Self:\n        empty = self.__class__(self.typ, self.key)\n        if checkpoint is not MISSING:\n            empty.value = checkpoint\n        return empty\n\n    def update(self, values: Sequence[Value]) -&gt; bool:\n        if len(values) == 0:\n            return False\n        if len(values) != 1:\n            msg = create_error_message(\n                message=f\"At key '{self.key}': Can receive only one value per step. Use an Annotated key to handle multiple values.\",\n                error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n            )\n            raise InvalidUpdateError(msg)\n\n        self.value = values[-1]\n        return True\n\n    def get(self) -&gt; Value:\n        if self.value is MISSING:\n            raise EmptyChannelError()\n        return self.value\n\n    def is_available(self) -&gt; bool:\n        return self.value is not MISSING\n\n    def checkpoint(self) -&gt; Value:\n        return self.value\n\nMISSING = object()\n</code></pre>\n<p>我们说LastValue这个使用频率最高的Channel针对多个更新采用“后来居上”的策略，只存储最后一次更新的提供的值，但这里所谓的多次更新只得时跨越不同Superstep针对Channel得多次写入，因为它根本不支持在单个Superstep针对它得多次更新，update方法得实现已经体现了这一点。在如下这个演示程序中，我们让三个并行执行得Node在同一Superstep内更新命名为“output”的这个LastValue类型的Channel，给定的断言证实了update方法中抛出InvalidUpdateError异常的逻辑。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.errors import InvalidUpdateError\n\ndef build(node_name:str)-&gt;NodeBuilder:\n    return (NodeBuilder()\n            .subscribe_to(\"start\")\n            .do(lambda _:node_name)\n            .write_to(\"output\"))\n\napp = Pregel(\n    nodes={name: build(name) for name in [\"foo\", \"bar\", \"baz\"]},\n    channels={\n        \"start\": LastValue(None),\n        \"output\": LastValue(str),\n    },\n    input_channels=[\"start\"],\n    output_channels=[\"output\"],\n)\n\ntry:\n    app.invoke(input={\"start\": None})\n    assert False, \"Expected InvalidUpdateError\"\nexcept Exception as e:\n    assert isinstance(e, InvalidUpdateError)\n</code></pre>\n<h3 id=\"32anyvalue\">3.2\tAnyValue</h3>\n<p>AnyValue类型的Channel同样是用于存储单值，所以它的实现于LastValue在很多地方都类似。两者之间最大的不同在于，AnyValue支持同一个Superstep的多次更新，但是将所有的更新视为等效，所以它的update方法会使用最后一个更新提供的值。</p>\n<pre><code class=\"language-python\">class AnyValue(Generic[Value], BaseChannel[Value, Value, Value]):\n    __slots__ = (\"typ\", \"value\")\n\n    value: Value | Any\n    def __init__(self, typ: Any, key: str = \"\") -&gt; None:\n        super().__init__(typ, key)\n        self.value = MISSING\n    def update(self, values: Sequence[Value]) -&gt; bool:\n        if len(values) == 0:\n            if self.value is MISSING:\n                return False\n            else:\n                self.value = MISSING\n                return True\n\n        self.value = values[-1]\n        return True\n</code></pre>\n<p>虽然AnyValue针对同一Superstep内的多次更新会选择最后一次更新，但是这个更新的顺序是无法通过程序控制的，我们也不能对更新顺序作任何假设。如下的演示程序很清晰地说明了这一点，我们按照上一个例子相似的方式并行执行“foo” 、 “bar” 和 “baz” 三个Node，它们在完成执行后会更新 “output” 这个AnyValue类型的Channel。由于我们为“bar” 和 “baz” 的处理函数做了1秒的休眠，按照“常理”推断，“foo”提供的更新应该先被收集和应用，但事实却未必如此。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,AnyValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nimport time\nfrom typing import Any\nfrom functools import partial\n\nchanges: list[Any] = []\nclass ExtendedAnyValue(AnyValue):\n    def update(self, values: list[Any]) -&gt; bool:\n        global changes\n        changes = values\n        return super().update(values)\n    \ndef handle(node_name:str, args:dict[str,Any])-&gt;str:\n    if node_name != \"foo\":\n        time.sleep(1)  # Simulate some processing delay\n    return node_name\n\ndef build(node_name:str)-&gt;NodeBuilder:\n    return (NodeBuilder()\n            .subscribe_to(\"start\")\n            .do(partial(handle, node_name))\n            .write_to(\"output\"))\n\napp = Pregel(\n    nodes={name: build(name) for name in [\"foo\",\"bar\", \"baz\"]},\n    channels={\n        \"start\": LastValue(None),\n        \"output\": ExtendedAnyValue(str),\n    },\n    input_channels=[\"start\"],\n    output_channels=[\"output\"], \n)\n\nresult =  app.invoke(input={\"start\": None})\nprint(\"collected changes:\", changes)\nprint(\"channel value:\", result[\"output\"])\n</code></pre>\n<p>我们通过继承AnyValue定义了一个ExtendedAnyValue类型，重写的update方法在调用基类同名方法前，我们将values参数赋值给全局变量changes。“output” 现在盖用现在这个类型。在完成正常调用后，我们将changes变量承载的更新次序和Channel最终的值打印出来。从如下的输出结果可以看出，本应该最先完成的 “foo” 节点提供的更新反而放在最后，但是Channel最后的值确实是提取的最后一个。</p>\n<pre><code>collected changes: ['bar', 'baz', 'foo']\nchannel value: foo\n</code></pre>\n<h3 id=\"33lastvalueafterfinish\">3.3\tLastValueAfterFinish</h3>\n<p>LastValueAfterFinish类型的Channel弥补了LastValue在同一Superstep中不能多次更新的不足，它的update方法采用了与AnyValue类似的逻辑，总是会提取最后提交的更新。不过我们在前面已经说过，我们不应该对更新顺序作任何假设，所以它是选择第一个还是最后一个其实都没有什么不同。</p>\n<pre><code class=\"language-python\">class LastValueAfterFinish(\n    Generic[Value], BaseChannel[Value, Value, tuple[Value, bool]]):\n    value: Value | Any\n    finished: bool\t\n    def __init__(self, typ: Any, key: str = \"\") -&gt; None:\n        super().__init__(typ, key)\n        self.value = MISSING\n        self.finished = False   \n\n    def update(self, values: Sequence[Value | Any]) -&gt; bool:\n        if len(values) == 0:\n            return False\n\n        self.finished = False\n        self.value = values[-1]\n        return True\n\n    def consume(self) -&gt; bool:\n        if self.finished:\n            self.finished = False\n            self.value = MISSING\n            return True\n        return False\n\n    def finish(self) -&gt; bool:\n        if not self.finished and self.value is not MISSING:\n            self.finished = True\n            return True\n        else:\n            return False\n\n    def get(self) -&gt; Value:\n        if self.value is MISSING or not self.finished:\n            raise EmptyChannelError()\n        return self.value\n\n    def is_available(self) -&gt; bool:\n        return self.value is not MISSING and self.finished\n</code></pre>\n<p>LastValueAfterFinish最为典型的特性是针对它的更新只有在Superstep完成之后才会生效，所以在Superstep N中的更新只能等到Superstep N+1才能被读取。我们可以从LastValueAfterFinish的定义看出它利用finished字段判断Superstep是否完成，这个字段会在update和finish方法中分别被设置成False和True。is_available方法在做出可用性判断的时候会同时评估值是否存在和这个finished字段的值。</p>\n<p>赋予了LastValueAfterFinish “跨步延迟” 的可见性，我们可以从如下这个演示程序看出它和LastValue的不同之处。如代码片段所示，Pregel唯一的Node订阅了“foo”和“bar”这两个Channel，其类型分别为LastValue和LastValueAfterFinish。在Superstep -1提供的两个输入foo和bar，前者在Superstep -1可见，所以会在Superstep 0触发节点执行，此时后者是不可用的状态。等到Superstep 0结束，finish方法被调用之后，bar变得可用，其更新触发节点与Superstep 1中再次执行。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,LastValueAfterFinish\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Any\n\ninputs:list = []\ndef handle(args:dict[str,Any], config: RunnableConfig)-&gt;None:\n    step = config.get(\"metadata\", {}).get(\"langgraph_step\")\n    inputs.append((step, args.get(\"foo\"), args.get(\"bar\")))\n\nnode = (NodeBuilder()\n    .subscribe_to(\"foo\",\"bar\", read=True)\n    .do(handle))\n\napp =  Pregel(\n    nodes={\"body\": node},\n    channels={\n        \"foo\": LastValue(str), \n        \"bar\": LastValueAfterFinish(str),  \n    },\n    input_channels=[\"foo\", \"bar\"],\n    output_channels=[],\n)\napp.invoke(input={\"foo\": \"123\", \"bar\": \"456\",})\nassert len(inputs) == 2\nassert inputs[0] == (0, \"123\", None)\nassert inputs[1] == (1, \"123\", \"456\")\n</code></pre>\n<p>如下这种Node根据无法被触发执行的问题，也正是源于LastValueAfterFinish这种“跨步延迟” 的可见性造成的。由于作为输入Channel的类型为LastValueAfterFinish，所以在Superstep -1中处于不可用的状态，所以引擎任务下一步没有需要执行的节点，整个流程就直接结束了。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,LastValueAfterFinish\nfrom langgraph.pregel import Pregel, NodeBuilder\n\nnode = (NodeBuilder()\n        .subscribe_only(\"input\")\n        .do(lambda args:args)\n        .write_to(\"output\"))\napp =  Pregel(\n    nodes={\"body\": node},\n    channels={\n       \"input\": LastValueAfterFinish(str), \n       \"output\": LastValue(str),\n    },\n    input_channels=[\"input\"],\n    output_channels=[\"output\"],\n)\nresult = app.invoke(input={\"input\": \"foobar\"})\nassert result == None\n</code></pre>\n<p>从给出的定义我们还发现，LastValueAfterFinish还重写了consume，并将finished字段重置为False，并将值抹除。这个实现赋予了LastValueAfterFinish “阅后即焚” 的特性。</p>\n<h3 id=\"34ephemeralvalue\">3.4\tEphemeralValue</h3>\n<p>EphemeralValue是一种专门用于短寿命数据传递的Channel类型，因为它的核心特性就是 “更新数据邻步有效” 。EphemeralValue在默认情况下也像LastValue一样不支持通过Superstep中的多个更新，但是我们可用在构造函数中将guard参数设置为False来关闭这个限制。如果允许单个Superstep内的多次更新，它也只会选择最后一次更新提供的值。</p>\n<pre><code class=\"language-python\">class EphemeralValue(Generic[Value], BaseChannel[Value, Value, Value]):\n    __slots__ = (\"value\", \"guard\")\n    value: Value | Any\n    guard: bool\n\n    def __init__(self, typ: Any, guard: bool = True) -&gt; None:\n        super().__init__(typ)\n        self.guard = guard\n        self.value = MISSING    \n\n    def update(self, values: Sequence[Value]) -&gt; bool:\n        if len(values) == 0:\n            if self.value is not MISSING:\n                self.value = MISSING\n                return True\n            else:\n                return False\n        if len(values) != 1 and self.guard:\n            raise InvalidUpdateError(\n                f\"At key '{self.key}': EphemeralValue(guard=True) can receive only one value per step. Use guard=False if you want to store any one of multiple values.\"\n            )\n\n        self.value = values[-1]\n        return True\n</code></pre>\n<p>EphemeralValue所谓的 “邻步有效” 的更新有效性策略实现在它的update方法中。如上面的代码片段所示，如果当前Superstep内无更新，update方法的values参数为空，此时它会将之前设置的值清空。如下的演示程序充分体现了这一点：在Super step -1输入到 “bar” 这个EphemeralValue类型的Channel，它的值只能Superstep 0中执行的Node（ “node1” ）读取，在Superstep中的Node（ “node2” ）试试图读取时已被清空。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,EphemeralValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Any\n\ninputs:list = []\ndef handle(args:dict[str,Any], config: RunnableConfig)-&gt;None:\n    step = config.get(\"metadata\", {}).get(\"langgraph_step\")\n    inputs.append((step, args.get(\"foo\"), args.get(\"bar\")))\n\nnode1 = (NodeBuilder()\n    .subscribe_to(\"node1\", read=False)\n    .read_from(\"foo\", \"bar\")\n    .do(handle)\n    .write_to(node2= None))\n\nnode2 = (NodeBuilder()\n    .subscribe_to(\"node2\", read=False)\n    .read_from(\"foo\", \"bar\")\n    .do(handle))\n\napp =  Pregel(\n    nodes={\"node1\": node1, \"node2\": node2},\n    channels={\n        \"foo\": LastValue(str), \n        \"bar\": EphemeralValue(str),  \n        \"node1\": LastValue(None),\n        \"node2\": LastValue(None),\n    },\n    input_channels=[\"node1\",\"foo\", \"bar\"],\n    output_channels=[],\n)\n\napp.invoke(input={\"node1\": None,\"foo\": \"123\", \"bar\": \"456\",})\nassert len(inputs) == 2\nassert inputs[0] == (0, \"123\", \"456\")\nassert inputs[1] == (1, \"123\", None)\n</code></pre>\n<h3 id=\"35untrackedvalue\">3.5\tUntrackedValue</h3>\n<p>UntrackedValue是一种特殊的Channel类型，其核心特性在于它的 “非持久性” 和 “不可追踪性” 。写入UntrackedValue的值常驻内存，并会参与持久化。这一特性体现在的checkpoint和from_checkpoint方法上，前者为持久化提供一个空值，后者直接放弃从持久化存储加载的值。与EphemeralValue一样，UntrackedValue也通过构造函数的guard参数决定是否允许同一Superstep的多次写入。</p>\n<pre><code class=\"language-python\">class UntrackedValue(Generic[Value], BaseChannel[Value, Value, Value]):\n    def checkpoint(self) -&gt; Value | Any:\n        return MISSING\n    def from_checkpoint(self, checkpoint: Value) -&gt; Self:\n        empty = self.__class__(self.typ, self.guard)\n        empty.key = self.key\n        return empty\n    def update(self, values: Sequence[Value]) -&gt; bool:\n        if len(values) == 0:\n            return False\n        if len(values) != 1 and self.guard:\n            raise InvalidUpdateError(\n                f\"At key '{self.key}': UntrackedValue(guard=True) can receive only one value per step. Use guard=False if you want to store any one of multiple values.\"\n            )\n\n        self.value = values[-1]\n        return True\n</code></pre>\n<p>在复杂的智能体工作流中，并非所有数据都适合或需要持久化。使用UntrackedValue的主要原因包括：</p>\n<ul>\n<li>\n<p>安全性与隐私：某些敏感信息（如临时访问令牌、API Keys 或用户私密凭证）不应写入磁盘或持久化数据库的快照中。</p>\n</li>\n<li>\n<p>性能优化：如果某些数据量极大（如大型图像 Buffer、大型文件流或复杂的对象实例），且这些数据在系统崩溃后可以重新生成或不再需要，排除它们可以显著减小 Checkpoint 的体积，提升存储性能。</p>\n</li>\n<li>\n<p>对象非序列化兼容：有些 Python 对象（如打开的文件句柄、数据库连接、正在运行的线程或特定的第三方库对象）是无法被序列化的。将它们放入UntrackedValueChannel可以避免图在保存状态时报错。</p>\n</li>\n</ul>\n<p>UntrackedValueChannel不参与持久化的特性可用通过如下这个程序来验证。如代码片段所示，我们分别定义了一个组输入Channel（foo和bar）和输出Channel（baz和qux），每组中一个是常规的LastValue，另一个则是UntrackedValueChannel。我们为Pregel对象指定了Checkpointer, 并在调用时利用RunnableConfig指定了Thread ID，那么调用的历史将会被持久化下来。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,UntrackedValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langchain_core.runnables import RunnableConfig\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nnode = (NodeBuilder()\n    .subscribe_to(\"foo\",\"bar\")\n    .do(lambda args:args)\n    .write_to(baz=lambda r: r[\"foo\"], qux=lambda r: r[\"bar\"]))\napp =  Pregel(\n    nodes={\"body\": node},\n    channels={\n        \"foo\": LastValue(str), \n        \"bar\": UntrackedValue(str), \n        \"baz\": LastValue(str), \n        \"qux\": UntrackedValue(str),\n    },\n    input_channels=[\"foo\", \"bar\"],\n    output_channels=[\"baz\", \"qux\"],\n    checkpointer= InMemorySaver()\n)\nconfig:RunnableConfig = {\"configurable\":{\"thread_id\":\"123\"}}\napp.invoke(input={\"start\": None,\"foo\": \"123\", \"bar\": \"456\",}, config=config)\nfor state in app.get_state_history(config=config):\nprint(f\"step {state.metadata['step']}: {state.values}\")\n</code></pre>\n<p>我们调用Pregel的get_state_history方法提取持久化的历史，并输出每个Checkpoint中存储的Channel值。从如下的输出结果可用看出，被持久化的Checkpoint不会保留类型为UntrackedValueChannel的Channel状态，不论它是输入还是输出。</p>\n<pre><code>step 0: {'foo': '123', 'baz': '123'}\nstep -1: {'foo': '123'}\n</code></pre>\n<h3 id=\"36binaryoperatoraggregate\">3.6\tBinaryOperatorAggregate</h3>\n<p>BinaryOperatorAggregate是功能最强大的Channel类型。首先，它支持同一Superstep中针对它的多次写入；其次，我们可用利用它来存储不同类型的数据，可以是单值，也可以是列表、集合胡总和字典，因为最终存储的值是由我们提供的一个二元操作符决定的。这个操作符体现为一个Callable[[Value, Value], Value] 对象，两个输入参数分别表示现有的值和新写入的值，这个可执行对象的返回值最终写入Channel的值。</p>\n<pre><code class=\"language-python\">class BinaryOperatorAggregate(Generic[Value], BaseChannel[Value, Value, Value]):\n    __slots__ = (\"value\", \"operator\")\n\n    def __init__(self, typ: type[Value], operator: Callable[[Value, Value], Value]):\n        super().__init__(typ)\n        self.operator = operator\n        …\n    def update(self, values: Sequence[Value]) -&gt; bool:\n        if not values:\n            return False\n        if self.value is MISSING:\n            self.value = values[0]\n            values = values[1:]\n        seen_overwrite: bool = False\n        for value in values:\n            is_overwrite, overwrite_value = _get_overwrite(value)\n            if is_overwrite:\n                if seen_overwrite:\n                    msg = create_error_message(\n                        message=\"Can receive only one Overwrite value per super-step.\",\n                        error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n                    )\n                    raise InvalidUpdateError(msg)\n                self.value = overwrite_value\n                seen_overwrite = True\n                continue\n            if not seen_overwrite:\n                self.value = self.operator(self.value, value)\n        return True\n</code></pre>\n<p>BinaryOperatorAggregate的核心全部体现update方法上。在正常情况下，它会遍历每个待写入的值，并将value字段表示的当前值和待写入的值作为参数调用二元操作，最后将返回结果赋值给value字段。我们已经在前面的演示实例中多次使用过这个类型，比如我们通过如下的方式将所有写入的值全部保存下来。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,BinaryOperatorAggregate\nfrom langgraph.pregel import Pregel, NodeBuilder\nimport operator\n\ndef build_node(node_name:str)-&gt;NodeBuilder:\n    return (NodeBuilder()\n        .subscribe_to(\"start\", read=False)\n        .do(lambda _: [node_name])\n        .write_to(\"result\"))\n\napp = Pregel(\n    nodes={name: build_node(name) for name in [\"foo\", \"bar\", \"baz\"]},\n    channels={\n        \"start\": LastValue(None),\n        \"result\": BinaryOperatorAggregate(list, operator.add),\n    },\n    input_channels=[\"start\"],\n    output_channels=[\"result\"],\n)\n\nresult = app.invoke(input={\"start\": None})\nassert all(x in result[\"result\"] for x in [\"foo\", \"bar\", \"baz\"])\n</code></pre>\n<p>对于上面这个例子，由于我们Channel存储的数据类型是列表，而operator.add要求两个输入参数均为列表，所以我们不得不让Node将单值封装成列表。虽然BinaryOperatorAggregate以“泛型” 的形式定义，作为操作的可执行对象也定义Callable[[Value, Value], Value]类型，貌似要求存储类型和待更新数据类型一致，但我们知道泛型在运行时是没有约束力的，所以我们可以根据具体的需求自由发挥。比如如下这个例子用于构造BinaryOperatorAggregate是我们自定义的append函数，它及支持列表，也支持单值。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,BinaryOperatorAggregate\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom typing import Any\n\ndef build_node(node_name:str)-&gt;NodeBuilder:\n    return (NodeBuilder()\n        .subscribe_to(\"start\", read=False)\n        .do(lambda _: node_name)\n        .write_to(\"result\"))\n\ndef append(a:list,b:Any)-&gt;list:\n    if isinstance(b,list):\n        return a + b\n    else:\n        a.append(b)\n        return a\n\napp = Pregel(\n    nodes={name: build_node(name) for name in [\"foo\", \"bar\", \"baz\"]},\n    channels={\n        \"start\": LastValue(None),\n        \"result\": BinaryOperatorAggregate(list, append),\n    },\n    input_channels=[\"start\"],\n    output_channels=[\"result\"],\n)\n\nresult = app.invoke(input={\"start\": None})\nassert all(x in result[\"result\"] for x in [\"foo\", \"bar\", \"baz\"])\n</code></pre>\n<p>我们从BinaryOperatorAggregate的update方法的定义还发现了它执行“覆盖（override）”的功能。按照代码反映的逻辑，如果提供的是一个Overwrite对象，指定的二元操作将被忽略，update方法会直接使用该对象的value字段覆盖现有的值。</p>\n<pre><code class=\"language-python\">@dataclass(slots=True)\nclass Overwrite:\n    value: Any\n</code></pre>\n<p>比如下面的演示程序中，率先执行的节点foo将自己的名称添加到名为“output”的这个BinaryOperatorAggregate通道中，但是节点bar执行之后会将最终的值以覆盖的方式改写成[\"bar\"]。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,BinaryOperatorAggregate\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.types import Overwrite\n\nfoo = (NodeBuilder()\n    .subscribe_to(\"foo\", read=False)\n    .write_to(output = [\"foo\"], bar=None))\nbar = (NodeBuilder()\n    .subscribe_to(\"bar\", read=False)\n    .do(lambda _: Overwrite(value=[\"bar\"]))\n    .write_to(\"output\"))\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar\": bar},\n    channels={\n        \"foo\": LastValue(None),\n        \"bar\": LastValue(None),\n        \"output\": BinaryOperatorAggregate(list, lambda a,b: a + b),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[\"output\"],\n)\n\nresult = app.invoke(input={\"foo\": None}, interrupt_after= \"foo\")\nassert result == {\"output\": [\"foo\"]}\n\nresult = app.invoke(input={\"foo\": None})\nassert result == {\"output\": [\"bar\"]}\n</code></pre>\n<p>这种覆盖性质的写还可以按照如下的方写入一个特殊的字典来实现。这个字典只包含一个Key为 “<strong>overwrite</strong>” 的键值对，它的值将用于覆盖现有的值。值得一提的是，在一个Superstep中，这样的覆盖操作只能进行一次。如果多次提供这样的字典和Overwrite对象，update方法会抛出一个InvalidUpdateError异常。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,BinaryOperatorAggregate\nfrom langgraph.pregel import Pregel, NodeBuilder\n\nfoo = (NodeBuilder()\n    .subscribe_to(\"foo\", read=False)\n    .write_to(output = [\"foo\"], bar=None))\nbar = (NodeBuilder()\n    .subscribe_to(\"bar\", read=False)\n    .do(lambda _: {\"__overwrite__\": [\"bar\"]})\n    .write_to(\"output\"))\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar\": bar},\n    channels={\n        \"foo\": LastValue(None),\n        \"bar\": LastValue(None),\n        \"output\": BinaryOperatorAggregate(list, lambda a,b: a + b),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[\"output\"],\n)\n\nresult = app.invoke(input={\"foo\": None}, interrupt_after= \"foo\")\nassert result == {\"output\": [\"foo\"]}\n\nresult = app.invoke(input={\"foo\": None})\nassert result == {\"output\": [\"bar\"]}\n</code></pre>\n<h3 id=\"37namedbarriervalue\">3.7\tNamedBarrierValue</h3>\n<p>我们在前面的演示实例中利用NamedBarrierValue这个特殊的Channel解决了“多Node依赖”的问题，我们从中也能大致知道它的工作原理：它内部维护两个集合，一个是初始化指定的名称集合，另一个写入填充的集合，等两个集合一致的时候该Channel才变得可用。这两个集合对应NamedBarrierValue如下所示的names和seen集合。当update在应用更新的时候，如果提供的名称没有在names集合中，会直接抛出InvalidUpdateError异常。如果已经在seen集合中，它会直接忽略并返回False，否则才会将其添加到seen集合中，并返回True。</p>\n<pre><code class=\"language-python\">class NamedBarrierValue(Generic[Value], BaseChannel[Value, Value, set[Value]]):\n\n    names: set[Value]\n    seen: set[Value]\n\n    def __init__(self, typ: type[Value], names: set[Value]) -&gt; None:\n        super().__init__(typ)\n        self.names = names\n        self.seen: set[str] = set()\n\n    def checkpoint(self) -&gt; set[Value]:\n        return self.seen\n\n    def from_checkpoint(self, checkpoint: set[Value]) -&gt; Self:\n        empty = self.__class__(self.typ, self.names)\n        empty.key = self.key\n        if checkpoint is not MISSING:\n            empty.seen = checkpoint\n        return empty\n\n    def update(self, values: Sequence[Value]) -&gt; bool:\n        updated = False\n        for value in values:\n            if value in self.names:\n                if value not in self.seen:\n                    self.seen.add(value)\n                    updated = True\n            else:\n                raise InvalidUpdateError(\n                    f\"At key '{self.key}': Value {value} not in {self.names}\"\n                )\n        return updated\n\n    def get(self) -&gt; Value:\n        if self.seen != self.names:\n            raise EmptyChannelError()\n        return None\n\n    def is_available(self) -&gt; bool:\n        return self.seen == self.names\n\n    def consume(self) -&gt; bool:\n        if self.seen == self.names:\n            self.seen = set()\n            return True\n        return False\n</code></pre>\n<p>为了保留填充的名称，用于持久化的checkpoint方法会直接提供seen集合，而对应的from_checkpoint方法则将Checkpoint提供的内容赋值给seen集合。由于NamedBarrierValue的目的仅仅是在等到希望的名称被填满是对外发出信号，该条件体现在is_available方法上。如果此条件不满足，它的get方法会直接抛出EmptyChannelError异常。在条件满足后，get方法返回的值也不重要，所以它直接返回None。和LastValueAfterFinish一样，NamedBarrierValue同样在重写的consume方法中清空了seen集合，达到了 “阅后即焚” 的效果。</p>\n<h3 id=\"38namedbarriervalueafterfinish\">3.8\tNamedBarrierValueAfterFinish</h3>\n<p>NamedBarrierValueAfterFinish在NamedBarrierValue基础上添加了基于 “AfterFinish” 的可用性限制。即使names和seen集合导致一致状态，其生效的时机会延后致下一个Superstep。NamedBarrierValueAfterFinish会在内部维护一个finished状态，当seen被填充满时针对finish方法的调用会将此状态设置为True。在达到可用条件后针对consume方法的调用会将此状态设置为False。实现的逻辑基本上与和LastValueAfterFinish一致。</p>\n<h3 id=\"39topic\">3.9\tTopic</h3>\n<p>Topic类型的Channel就相当于一个消息队列，它会保留所有提供的数据。在默认情况下，在完成基于Superstep的更新应用之前，这个对象会被清空。如果在初始化的时候利用accumulate参数开启了 “累积” 模式，数据在跨越Superstep时会被保留。这个逻辑体现在如下所示的update方法上。</p>\n<pre><code class=\"language-python\">class Topic(\n    Generic[Value],\n    BaseChannel[Sequence[Value], Value | list[Value], list[Value]]):\n\n    __slots__ = (\"values\", \"accumulate\")\n    def __init__(self, typ: type[Value], accumulate: bool = False) -&gt; None:\n        super().__init__(typ)\n        self.accumulate = accumulate\n        self.values = list[Value]()\n\n    def update(self, values: Sequence[Value | list[Value]]) -&gt; bool:\n        updated = False\n        if not self.accumulate:\n            updated = bool(self.values)\n            self.values = list[Value]()\n        if flat_values := tuple(_flatten(values)):\n            updated = True\n            self.values.extend(flat_values)\n        return updated\n</code></pre>\n<p>如下的代码体现了是否开启“累积效应”之间的差异。如代码片段所示，我们由四个Node（node1、node2、node3和node4）构建了一个Pregel。四个Node分两个Superstep完成，其中node1和node2先执行，node3和node4后执行，具体实现借助了一个NamedBarrierValue类型的Channel（trigger）。这四个Node都会将自己的名称写入foo和bar两个Topic类型的通道，其中bar开启了累积模式。所有从最后的调用结果可用看出，通道foo只保留了最后Superstep写入的内容，而通道bar则把整个执行流程写入的数据都保留了下来。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue,NamedBarrierValue, Topic\nfrom langgraph.pregel import Pregel, NodeBuilder\n\nnode1 = (NodeBuilder()\n    .subscribe_to(\"start\", read=False)\n    .write_to(trigger=\"node1\", foo=\"node1\", bar=\"node1\"))\nnode2 = (NodeBuilder()\n    .subscribe_to(\"start\", read=False)\n    .write_to(trigger=\"node2\", foo=\"node2\", bar=\"node2\"))\n\nnode3 = (NodeBuilder()\n    .subscribe_to(\"trigger\", read=False)\n    .write_to(foo=\"node3\", bar=\"node3\"))\nnode4 = (NodeBuilder()\n    .subscribe_to(\"trigger\", read=False)\n    .write_to(foo=\"node4\", bar=\"node4\"))\n\napp = Pregel(\n    nodes={\"node1\": node1, \"node2\": node2, \"node3\": node3, \"node4\": node4},\n    channels={\n        \"start\": LastValue(None),\n        \"trigger\": NamedBarrierValue(list,names={\"node1\", \"node2\"}),\n        \"foo\": Topic(list),\n        \"bar\": Topic(list, accumulate=True),\n    },\n    input_channels=[\"start\"],\n    output_channels=[\"foo\", \"bar\"],\n)   \n\nresult = app.invoke(input={\"start\": None})\nassert set(result[\"foo\"]) == {\"node3\", \"node4\"}\nassert set(result[\"bar\"]) == {\"node1\", \"node2\", \"node3\", \"node4\"}\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-12 06:28</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">17</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "如何用SSH访问远程服务器上的内网服务（如：MySQL、Redis、Kafka）？",
      "link": "https://www.cnblogs.com/hackyle/p/19606177",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/hackyle/p/19606177\" id=\"cb_post_title_url\" title=\"发布于 2026-02-11 23:13\">\n    <span>如何用SSH访问远程服务器上的内网服务（如：MySQL、Redis、Kafka）？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><strong>你是否有遇到以下的需求场景：</strong></p>\n<ul>\n<li>场景1：你部署在个人的云服务器上的服务，出现了问题，想在本地的Navicat / DBeaver查一下线上MySQL，却发现连都连不上。</li>\n<li>场景2：线上 Redis 出问题了，你排查时发现无从下手。\n<ul>\n<li>如果有打印日志，你还可以结合代码逻辑和日志来分析</li>\n<li>但是对于某些业务场景下的缓存穿透，Key 被误删，排查起来就比较困难了</li>\n</ul>\n</li>\n<li>场景3：Kafka 有消息积压，但我连 Topic 都看不到\n<ul>\n<li>有消息积压，你想：看 topic 列表，看 consumer group 状态，尝试手动消费一条消息。但是，Kafka 端口 9092 / 9093 不开放公网，本地 Kafka 工具根本连不上。</li>\n<li>Kafka 本身就复杂，一出问题，你连“观察窗口”都没有，完全依赖运维、日志和平台，排查问题的复杂度飙升。</li>\n</ul>\n</li>\n</ul>\n<p><strong>以上问题的原因是什么？</strong></p>\n<ul>\n<li>MySQL、Redis、Kafka配置了只有本地127.0.0.1可以访问，不能通过其他IP访问</li>\n<li>防火墙没有对服务端口开放</li>\n<li>云服务器的安全策略也没有对端口打开</li>\n</ul>\n<p><strong>而我只想临时做几件事：</strong></p>\n<ul>\n<li>只想临时查看数据、验证问题</li>\n<li>不想改防火墙、安全策略组</li>\n<li>不想改代码、不想提需求、不想走审批</li>\n</ul>\n<p>我要临时访问内网服务，但是网络不通，不能随便改网络，有没有什么技术方法解决这个问题？答案是肯定的 —— <strong>SSH本地端口转发</strong>。</p>\n<p><strong>注意：这有个很重要的前提条件，你能通过SSH连接到远程服务器。</strong></p>\n<h1><strong><u>实现思路</u></strong></h1>\n<p><strong>一句话概括原理：</strong>利用 SSH 在本地和远程服务器之间建立一条加密通道，把远程内网端口“转发”到本地端口。</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"263\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"550\" /></p>\n<p>对本地工具来说：它以为自己连的是 localhost</p>\n<p>实际上流量通过 SSH：</p>\n<ol>\n<li>先到远程服务器</li>\n<li>再由远程服务器访问内网服务</li>\n<li>你不需要改网络、不需要开端口、不需要暴露服务。</li>\n</ol>\n<p><strong>语法：ssh -L [本地端口]:[目标主机]:[目标端口] [SSH服务器用户名]@[SSH服务器地址]</strong></p>\n<p><strong>对于开发人员来说，常用的两类应用场景：</strong></p>\n<ul>\n<li>远程服务器上的某些服务无法从公网访问</li>\n</ul>\n<ol>\n<li>线上环境里，数据库、中间件（MySQL / Redis / Kafka）几乎从不暴露公网端口，只能在内网访问。</li>\n<li>防火墙是关闭状态，暴露公网访问需要改动防火墙（易出错）</li>\n<li>云服务器的安全策略阻止访问，需要手动配置流入、流出的安全策略端口</li>\n</ol>\n<ul>\n<li>公司内网服务器上的服务无法从本机访问</li>\n</ul>\n<ol>\n<li>服务内网部署，不对开发人员开放</li>\n<li>权限管控严格</li>\n<li>想调试问题，但安全策略比问题还复杂，懒得去配置</li>\n<li>内网服务器上不允许随便安装其他第三方软件</li>\n<li>注意：此方式可能让你违规，谨慎使用</li>\n</ol>\n<p><strong>这种方式适合哪些场景？</strong></p>\n<ul>\n<li>非常适合\n<ul>\n<li>临时排查线上问题</li>\n<li>查看缓存数据</li>\n<li>不想改代码</li>\n<li>不想装客户端</li>\n<li>权限受限环境</li>\n</ul>\n</li>\n<li>不适合\n<ul>\n<li>长期运维通道</li>\n<li>高并发访问</li>\n</ul>\n</li>\n</ul>\n<h1><strong><u>执行步骤</u></strong></h1>\n<p>在了解了基本原理和实现思路后，开始梳理执行步骤，跟着我一步一步来实现吧。</p>\n<p><strong>执行步骤</strong></p>\n<ul>\n<li>第一步：能正常 SSH 登录到一台服务器，且允许端口转发</li>\n<li>第二步：明确你要连接的目标，开启本地端口转发</li>\n<li>第三步：验证 SSH 隧道是否生效</li>\n<li>第四步：远程访问目标服务</li>\n</ul>\n<p>假设我要连接远程服务器（8.145.45.70）的Redis服务，他们在远程服务器上分别使用6379端口。</p>\n<p>在本地选择一个没被占用、你自己记得住的端口，比如：16379。不要求和远端端口一致，只是为了好记。</p>\n<p><strong>如何检查SSH服务器是否允许端口转发？检查sshd_config中以下配置项的值</strong></p>\n<ul>\n<li>AllowTcpForwarding no &nbsp;#应该改为yes</li>\n<li>AllowAgentForwarding no &nbsp;#应该改为yes</li>\n<li>PermitTunnel no &nbsp;#应该改为yes</li>\n</ul>\n<h2><strong><u>开启本地端口转发</u></strong></h2>\n<p>在本地创建 SSH 隧道</p>\n<ul>\n<li>这一操作的目标是：让本地某个端口，指向远程内网服务端口</li>\n<li>流量流向：localhost:本地端口 --&gt; SSH 隧道 --&gt; 远程内网IP:服务端口</li>\n</ul>\n<p><strong>在终端执行命令：</strong>ssh -L 16379:127.0.0.1:6379 root@8.145.45.70</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"225\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"637\" /></p>\n<p><strong>验证本地端口是否生效：netstat -ano | findstr 16379</strong></p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"111\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"612\" /></p>\n<p>验证方式最简单，检查本地端口是否处于监听状态。如上图，本地的16379已经处于LISTENING状态。</p>\n<p>执行完成后：SSH 连接会保持，本地端口开始监听，所有访问都会被转发。此时你“看起来什么都没做”，但通道已经打通了。</p>\n<p>&nbsp;</p>\n<p>在上面的开启本地端口转发的图片中，你可能发现了这个SSH链接进入了交互式的Shell Terminal，要是我不想进入这种交互式的终端，应该怎么做呢？</p>\n<p><strong>不打开交互式对话：</strong>ssh -N -L 16379:127.0.0.1:6379 root@8.145.45.70</p>\n<ul>\n<li>-N：不执行远程命令（只做端口转发）</li>\n<li>更安全、更清晰</li>\n</ul>\n<p><strong>放到后台运行：</strong>ssh -f -N -L 16379:127.0.0.1:6379 user@server_ip</p>\n<ul>\n<li>-f：放到后台</li>\n<li>用完记得杀掉进程：tasklist + taskkill / ps + kill</li>\n</ul>\n<h2><strong><u>远程访问</u></strong></h2>\n<p>接下来是最“反直觉但最爽”的一步：</p>\n<ul>\n<li>不再使用内网 IP，也不再使用远程服务器 IP，而统一使用： 127.0.0.1 或 localhost</li>\n<li>端口使用你刚刚在本地绑定的端口</li>\n</ul>\n<p>&nbsp;</p>\n<p>本地使用已安装的&nbsp;redis-cli&nbsp;工具连接Redis：redis-cli -h 127.0.0.1 -p 16379</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"120\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"996\" /></p>\n<p>使用 GUI 客户端（Another Redis Desktop Manager）连接远程Redis</p>\n<p><img alt=\"image\" class=\"lazyload\" height=\"285\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"879\" /></p>\n<h2><strong><u>QA</u></strong></h2>\n<p><strong>报错：prohibited</strong></p>\n<p>channel X: open failed: administratively prohibited</p>\n<p>channel 3: open failed: administratively prohibited: open failed</p>\n<p>原因：管理员禁止了你使用端口转发</p>\n<p>解决：sshd_config 中禁用了端口转发</p>\n<ul>\n<li>AllowTcpForwarding no &nbsp;#应该改为yes</li>\n<li>AllowAgentForwarding no &nbsp;#应该改为yes</li>\n<li>PermitTunnel no &nbsp;#应该改为yes</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>报错：Connection timed out</strong></p>\n<p>原因：连接超时，网络问题</p>\n<p>解决：检查网络是否连通、防火墙是否开放</p>\n<p>&nbsp;</p>\n<p><strong>我有MySQL、redis、kafka都要进行本地端口转发，可以只有一个端口吗？</strong></p>\n<p>不行。</p>\n<p>SSH 本地端口转发是：一个本地端口 与 一个远程地址:端口 是一对一映射。</p>\n<p>一条命令同时开启转发：ssh user@server \\</p>\n<p>&nbsp;&nbsp;-L 13306:127.0.0.1:3306 \\</p>\n<p>&nbsp;&nbsp;-L 16379:127.0.0.1:6379 \\</p>\n<p>&nbsp;&nbsp;-L 19092:127.0.0.1:9092</p>\n<p>&nbsp;</p>\n<p><strong>连不上 Redis，但 SSH 没报错？</strong></p>\n<ul>\n<li>检查Redis 是否监听 127.0.0.1</li>\n<li>是否启用了密码</li>\n<li>是否限制 protected-mode</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>在使用过程中，是否</strong><strong>SSH 连接必须保持</strong><strong>？</strong></p>\n<ul>\n<li>是的</li>\n<li>SSH 断开 = 隧道失效，本地工具会立即连不上</li>\n<li>建议单独开一个终端，专门用于维护 SSH 隧道</li>\n<li>根据场景考虑是-N、-f参数</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>为什么有些公司的安全团队会关闭SSH的端口转发？</strong></p>\n<ul>\n<li>SSH 端口转发 = 隐形隧道</li>\n<li>可绕过防火墙 / 网关 / 审计</li>\n<li>本地流量进了内网，难以追踪</li>\n<li>容易被当成内网代理滥用</li>\n<li>场景配置：\n<ul>\n<li>AllowTcpForwarding no</li>\n<li>AllowAgentForwarding no</li>\n<li>PermitTunnel no</li>\n<li>X11Forwarding no #是否允许把“远程服务器上的图形界面程序”，转发到你本地屏幕上显示。</li>\n</ul>\n</li>\n</ul>\n<p><strong>额外提醒：</strong></p>\n<ul>\n<li>SSH隧道用完即关，本地端口立即释放，不留任何后门</li>\n<li>妥善保管SSH连接密码、私钥</li>\n</ul>\n<h1><strong><u>多级跳板</u></strong></h1>\n<p>企业服务器通常有以下特点：</p>\n<ul>\n<li>内网环境，不直接暴露公网</li>\n<li>安全要求高，必须对访问进行审计</li>\n<li>多人运维或开发团队共用服务器</li>\n<li>不允许直接暴露管理端口</li>\n</ul>\n<p>问题：如果你直接 SSH 登录内网服务器，就会导致</p>\n<ul>\n<li>没有日志记录</li>\n<li>难以审计操作</li>\n<li>可能导致安全风险</li>\n</ul>\n<p>解决方案就是：在公网部署一台或多台跳板机 (Bastion / JumpServer)，通过 SSH 间接访问目标服务器。接下来，我们一起探索如何在一台和多台跳板机上实现端口转发。</p>\n<h2><strong><u>一级跳板</u></strong></h2>\n<p>通过跳板机（Jump Host / Bastion Host），利用 SSH 作为中转，访问内网里的目标服务器。</p>\n<p><strong>一级跳板的网络结构：</strong></p>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"227\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"517\" /></strong></p>\n<p><strong>实现方式一：手动两次SSH逐步跳转</strong></p>\n<ul>\n<li>第一步：先登录跳板机：ssh jump_user@jump_host</li>\n<li>第二步：在跳板机上，再 SSH 到目标服务器：ssh target_user@target_host</li>\n</ul>\n<p><strong>实现方式二：</strong><strong>-J</strong><strong>语法实现</strong></p>\n<p>语法：ssh -J jump_user@jump_host target_user@target_host</p>\n<p>例如：ssh -NT -L 3306:127.0.0.1:3306 -J jump_user@jump_host target_user@target_host</p>\n<ul>\n<li>-L 3306:127.0.0.1:3306 &nbsp;本地 3306 → 目标3306</li>\n<li>-J jump_user@jump_host &nbsp;先跳到跳板机</li>\n<li>target_user@target_host 再连到目标机</li>\n<li>-N &nbsp;不执行远程命令</li>\n<li>-T &nbsp;不分配 TTY</li>\n<li>仅支持OpenSSH（7.3+）</li>\n</ul>\n<p><strong>实现方式三：</strong><strong>-o</strong><strong>语法实现</strong></p>\n<p>语法：ssh -o ProxyCommand=\"ssh jump_user@jump_host -W %h:%p\" target_user@target_host</p>\n<p>例如：ssh -NT -L 3306:127.0.0.1:3306 -o ProxyCommand=\"ssh jump_user@jump_host -W %h:%p\" target_user@target_host</p>\n<ul>\n<li>如果 SSH 版本 &lt; 7.3（没有 -J）</li>\n<li><strong>注意是小写的o</strong></li>\n</ul>\n<h2><strong><u>二级跳板</u></strong></h2>\n<p><strong>二级跳板的网络结构：</strong></p>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"214\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"533\" /></strong></p>\n<p><strong>实现方式一：</strong><strong>-J</strong><strong>语法实现</strong></p>\n<p>ssh -J user1@jump1,user2@jump2 user3@target</p>\n<p>例子：ssh -NT -L 3306:127.0.0.1:3306&nbsp;-J user1@jump1,user2@jump2 user3@target</p>\n<ul>\n<li>跳板机之间连续写，逗号分割</li>\n<li>注意：跳板机前后顺序非常重要，按网络进入方向写。</li>\n<li>-L 3306:127.0.0.1:3306 &nbsp;本地 3306 → 目标3306</li>\n<li>-N &nbsp;不执行远程命令</li>\n<li>-T &nbsp;不分配 TTY</li>\n<li>仅支持OpenSSH（7.3+）</li>\n</ul>\n<p><strong>实现方式二：</strong><strong>-o</strong><strong>语法实现</strong></p>\n<p>语法：ssh -o ProxyCommand=\"ssh user1@jump1 \\</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-o ProxyCommand='ssh user2@jump2 \\</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-o ProxyCommand=\\\"ssh user3@jump3 -W %h:%p\\\" -W %h:%p' \\</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;-W %h:%p\" \\</p>\n<p>&nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp;user4@target</p>\n<ul>\n<li>注意引号，最外层是双引号，内层是单引号，区分引号的边界</li>\n<li>命令太复杂了，维护起来很难</li>\n<li>不推荐使用</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>三级跳板？</strong></p>\n<p>语法：ssh -J jump1,jump2,jump3 target</p>\n<p><strong>注意点：-J后面跟跳板机，注意顺序</strong></p>\n<h1><strong><u>服务部署在Docker上</u></strong></h1>\n<p><strong>如果你的内网服务部署在Docker上，如何实现SSH的本地转发呢？</strong></p>\n<p>两种情况</p>\n<ul>\n<li>容器的端口映射到了宿主机</li>\n<li>容器的端口没有映射到了宿主机</li>\n</ul>\n<h2><strong><u>映射到了宿主机</u></strong></h2>\n<p><strong>Redis</strong><strong>容器的端口映射到了宿主机</strong></p>\n<ul>\n<li>在启动容器时指定了端口映射：docker run -d --name redis-server-16379 -p 16379:6379 redis:7</li>\n<li>SSH本地端口转发直接参考上文中的执行步骤。因为相当于宿主机的16379号端口上工作了Redis服务，对于我们来说，跟Redis直接运行于宿主机上没有区别。</li>\n</ul>\n<p><strong>执行步骤</strong></p>\n<ul>\n<li>环境准备\n<ul>\n<li>进入远程服务器，启动一个Redis Docker：docker run -d --name redis-server-16379 -p 16379:6379 redis:7</li>\n<li>进入容器:docker exec -it redis-server-16379 /bin/bash</li>\n<li>往容器中的Redis塞入一个键值对：set name hackyle</li>\n</ul>\n</li>\n</ul>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"369\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"713\" /></strong></p>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"199\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"881\" /></strong></p>\n<ul>\n<li>在本台机器上开启本地端口转发：ssh -NT -L 16379:127.0.0.1:16379 <a href=\"mailto:root@8.145.45.70\" rel=\"noopener nofollow\"><u>root@8.145.45.70</u></a></li>\n</ul>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"176\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"569\" /></strong></p>\n<ul>\n<li><strong>验证：在本台机器上连接16379端口，访问到远程Docker中的Redis</strong></li>\n</ul>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"246\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"671\" /></strong></p>\n<h2><strong><u>未映射到宿主机</u></strong></h2>\n<p><strong>MySQL容器的端口没有映射到了宿主机</strong></p>\n<ul>\n<li>先查看容器 IP：docker inspect mysql | grep IPAddress</li>\n<li>再SSH 本地端口转发，直接指向容器 IP：ssh -L 3306:172.17.0.3:6379user@remote-host</li>\n</ul>\n<p>&nbsp;</p>\n<p><strong>执行步骤</strong></p>\n<p>1.环境准备</p>\n<ul>\n<li>进入远程服务器，启动一个Redis Docker：docker run -d --name redis-server-26379 redis:7</li>\n<li>查看容器IP：docker inspect redis-server-26379 | grep IPAddress</li>\n<li>进入容器:docker exec -it redis-server-16379 /bin/bash</li>\n<li>往容器中的Redis塞入一个键值对：set name hackyleshawe</li>\n</ul>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"315\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"908\" /></strong></p>\n<p>2. 在本台机器上开启本地端口转发：ssh -NT -L 26379:172.17.0.3:6379 <a href=\"mailto:root@8.145.45.70\" rel=\"noopener nofollow\"><u>root@8.145.45.70</u></a></p>\n<ul>\n<li>本地端口使用26379，转发的目标是docker的IP</li>\n<li>docker redis运行的端口时6379，所以“-L 26379:172.17.0.3:6379”</li>\n</ul>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"200\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"820\" /></strong></p>\n<p><strong>3.验证：在本台机器上连接26379端口，访问到远程Docker中的Redis</strong></p>\n<p><strong><img alt=\"image\" class=\"lazyload\" height=\"329\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"826\" /></strong></p>\n<h1><strong><u>结尾</u></strong></h1>\n<p>本文主要阐述了用SSH访问远程服务器上的内网服务（如：Redis）的原理和操作步骤，同时对部署在Docker中的服务如何访问也做了解释说明。</p>\n<p>在文章最后，尝试对自己提问一下问题，来检验你是否真正了解到了本文的核心内容：</p>\n<ul>\n<li>什么是SSH的本地端口转发(Local Port Forwarding）？</li>\n<li>他能做什么？能帮你解决什么问题？</li>\n<li>怎么使用？语法是什么？</li>\n<li>内网服务部署在Docker和宿主机，使用端口转发访问时有什么区别？</li>\n</ul>\n<p>本文结束。</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-11 23:13</span>&nbsp;\n<a href=\"https://www.cnblogs.com/hackyle\">ALGO阿狗</a>&nbsp;\n阅读(<span id=\"post_view_count\">63</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从零开始实现一个简易json解析器",
      "link": "https://www.cnblogs.com/xiaoxiongcanguan/p/19605794",
      "published": "",
      "description": "<h1 class=\"postTitle\"><a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xiaoxiongcanguan/p/19605794\" id=\"cb_post_title_url\" title=\"发布于 2026-02-11 20:23\">\n    <span>从零开始实现一个简易json解析器</span>\n    \n\n</a>\n</h1>\n\t<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"从零开始实现一个简易json解析器\">从零开始实现一个简易json解析器</h1>\n<h2 id=\"1-mysimplejsonparser-介绍与整体设计\">1. MySimpleJsonParser 介绍与整体设计</h2>\n<p>最近在学习编译原理相关的知识。为了加深对词法分析、语法分析阶段中诸如<strong>有限自动机、自顶向下语法分析、AST</strong> 等概念的理解，我选择实现一个json解析器作为练手机会。</p>\n<h5 id=\"_\"></h5>\n<p>相比直接实现一门完整的编程语言，将json解析作为练手对象有几个明显优势：</p>\n<ol>\n<li><strong>几乎零额外学习成本</strong>：json作为一种轻量级的数据交换格式是日常开发中使用最频繁的数据格式之一。</li>\n<li><strong>文法足够简单</strong>：对于编译原理入门者来说，若选择的语言太复杂，很容易在词法/语法规则上被劝退；而json的词法和语法比较规整，语法分析时通常只需根据下一个token即可决定AST的构造方向。</li>\n<li><strong>无需运行时</strong>：json不是编程语言，其完全不需要后端的运行时。只要能把json文本转换成正确的AST就已经算完成任务，在此基础上实现一个基于AST的Pretty JSON输出，就能产生一定的成就感。</li>\n</ol>\n<h5 id=\"_-1\"></h5>\n<p>在本篇博客中，我们将基于<strong>java语言</strong>，不依赖任何第三方库，从零开始实现一个简单的json解析器：<strong>MySimpleJsonParser</strong>。其包括以下几个主要模块：</p>\n<ol>\n<li><strong><code>StaticJsonLexer</code></strong>：一次性解析出全部token的静态json词法分析器</li>\n<li><strong><code>StreamJsonLexer</code></strong>：按需惰性解析token的流式json词法分析器</li>\n<li><strong><code>RecursiveJsonParser</code></strong>：基于递归的json语法解析器</li>\n<li><strong><code>StackBaseJsonParser</code></strong>：基于显式堆栈的json语法解析器（非递归）</li>\n<li><strong><code>AST结构</code></strong>：JsonElement及其子类，并基于AST生成Pretty JSON字符串的工具方法</li>\n</ol>\n<h2 id=\"2-从文法到词法分析器手写-json-lexer\">2. 从文法到词法分析器：手写 json lexer</h2>\n<p>词法分析阶段的任务是：将原始的字符流，按照json的词法规则，转换为token流。之后的语法分析会在token流的基础上按文法规则构建AST。</p>\n<h3 id=\"21-json文法与基本结构\">2.1 json文法与基本结构</h3>\n<p>根据<a href=\"https://www.json.org/json-en.html\" rel=\"noopener nofollow\" target=\"_blank\"><strong>json官方文档</strong></a>，json中主要包含以下几类结构：</p>\n<ol>\n<li><strong>string</strong>：由双引号包住的Unicode字符串，可包含转义字符。一个字符（character）也可以是一个单独的字符串（character string）。</li>\n<li><strong>number</strong>：以<code>0</code>或<code>-</code>开头，可以是整数、小数、、负数或者是包含一个E/e符号的指数。</li>\n<li><strong>object</strong>：以“<code>{</code>” 开头，以“<code>}</code>”结尾。</li>\n<li><strong>array</strong>：以“<code>[</code>” 开头，以“<code>]</code>”结尾。</li>\n<li><strong>value</strong>：可以是string、number、<code>true</code>(关键字)、<code>false</code>(关键字)、<code>null</code>(关键字)、object或者array。</li>\n<li><strong>whitespace</strong>：由任意个space空格、linefeed换行符、carriage return回车符以及tab制表符组成，本身无意义，仅起到分割的作用。</li>\n</ol>\n<h5 id=\"_-2\"></h5>\n<ul>\n<li>仔细分析后，发现string结构、number结构和whitespace结构以及<code>{</code>、<code>}</code>、<code>[</code>、<code>]</code> 这类符号都是基本结构，是自身无法再嵌套其它结构的基本单元，因此其都是最终AST中的叶子节点，而object、array和value都是可以互相嵌套的复合结构，其都是AST中的非叶子节点。</li>\n<li>对于这些可嵌套的非AST叶子节点，必须在语法分析中才能完成解析；而string结构、number结构、false、true、null关键字以及“{”、“]”等特殊符号，则适合在词法分析中完成解析。<br />\n因为json语法中，无论原始的json字符串中一个number字面量有多复杂(比如-2.03214e+6605218)，在语法分析中都只需要当做一个完整的number类型的token来处理即可。</li>\n<li>词法分析专注于局部，将原始的字符流按照词法规则正确的转换为token流；而语法分析则专注于将token流按照语法规则转换为正确的AST树结构。<br />\n通过将整个分析流程，有机的分解为词法分析和语法分析等等不同步骤，每个步骤都依赖于前一个步骤的产出的分层设计，能够很好的控制解析器整体的复杂度，方便调试的同时性能上也有很大的提升。<br />\n因此，除了少数非常简单的语言外，几乎所有的编译器都会采用分层的架构来实现整体的功能。</li>\n</ul>\n<h3 id=\"22-token类型定义\">2.2 token类型定义</h3>\n<p>从文法角度，json中允许的token类型大致可分为三类：</p>\n<ol>\n<li>特殊符号：诸如“<code>{</code>”、“<code>}</code>”、“<code>[</code>”、“<code>]</code>”、“<code>,</code>”,“<code>:</code>”,“<code>\"</code>”等独立的字符是json中的特殊符号</li>\n<li>关键字：完整且独立的<code>true</code>、<code>false</code>、<code>null</code>被视为关键字</li>\n<li>字面量：number、string这两种复杂字符流字面量</li>\n</ol>\n<h5 id=\"_-3\"></h5>\n<p>因此我们可以先定义出json的token类型枚举。其中EOF类型是额外的，用于在完成整个字符流的词法分析后，追加到token流的最后，标志着token流的结束。</p>\n<pre><code class=\"language-java\">public enum JsonTokenTypeEnum {\n    LEFT_BRACE(\"{\"),\n    RIGHT_BRACE(\"}\"),\n\n    LEFT_BRACKET(\"[\"),\n    RIGHT_BRACKET(\"]\"),\n\n    COMMA(\",\"),\n    COLON(\":\"),\n\n    TRUE(\"true\"),\n    FALSE(\"false\"),\n    NULL(\"null\"),\n\n    STRING(\"string\"),\n    NUMBER(\"number\"),\n\n    EOF(\"EOF\"),\n    ;\n    private final String key;\n\n    JsonTokenTypeEnum(String key) {\n        this.key = key;\n    }\n\n    public String getKey() {\n        return key;\n    }\n}\n</code></pre>\n<h3 id=\"23-词法分析器整体框架与特殊字符的词法分析\">2.3 词法分析器整体框架与特殊字符的词法分析</h3>\n<p>现在我们已经知道诸如“{”、“]”等独立字符是json中的特殊符号，但是当我们在字符流中遇到了一个“{”字符时，并不能无脑的将其作为一个LEFT_BRACE类型的token来处理。因为如果其是被双引号包裹的，作为string类型token内容的一部分，那么就并不能将其直接当做独立的token来对待。<br />\n所以，词法分析中一般使用有限状态自动机来解决此类“同一字符在不同上下文含义不同”的问题，在判断如何处理字符流时并不仅仅取决于下一个字符是什么，而还要结合当前自动机的状态来决定行为。<br />\n以上述对“{”字符的处理为例，如果是在初始化状态下(已经完成了一个完整token的解析,准备开始解析下一个新token)，碰到“{”字符时可以确定的将其转化为LEFT_BRACE类型的token，但是当自动机处于string类型token的解析状态时，则需要将其作为string类型token内容的一部分。</p>\n<h5 id=\"json词法分析自动机总览图\">json词法分析自动机总览图</h5>\n<p>基于官方文档中的json文法规则，我们可以设计出一个如下图所示的json有限状态自动机来实现我们的词法分析。<br />\n<img alt=\"lexer_total\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195126490-433213565.png\" /></p>\n<h5 id=\"_-4\"></h5>\n<ul>\n<li>在json解析一开始，自动机位于状态0，随后便会基于字符流的下一个字符的类型进行状态转换，在读取到诸如“{”、“[”、“,”等独立符号时，便会直接接收该字符，推进字符流，同时生成对应类型的token。</li>\n<li>在完整的解析出一个完整token后，自动机便会重新回到状态0，准备尝试解析下一个新的token。状态0只能合法的接收有限种类的字符，对于不符合json文法的字符将认为当前字符流不是合法的json字符串而直接报错，退出解析。</li>\n<li>对于更复杂的string类型、number类型token的解析，我们放在后面的小节再展开，总览图中暂时省略。</li>\n</ul>\n<h5 id=\"静态的词法分析器实现\">静态的词法分析器实现</h5>\n<pre><code class=\"language-java\">public class StaticJsonLexer extends AbstractJsonLexer{\n\n    public StaticJsonLexer(String jsonString) {\n        super(jsonString);\n    }\n\n    /**\n     * 一次完整的扫描，非流式的处理\n     * */\n    public List&lt;JsonToken&gt; doLex(){\n        char[] chars = super.jsonStringArray;\n\n        // 相当于是状态0\n        while(doLexContext.currentIndex &lt; chars.length){\n            char ch = chars[doLexContext.currentIndex];\n\n            switch(ch){\n                case '{':\n                    doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.LEFT_BRACE));\n                    doLexContext.currentIndex++;\n                    break;\n                case '}':\n                    doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.RIGHT_BRACE));\n                    doLexContext.currentIndex++;\n                    break;\n                case '[':\n                    doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.LEFT_BRACKET));\n                    doLexContext.currentIndex++;\n                    break;\n                case ']':\n                    doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.RIGHT_BRACKET));\n                    doLexContext.currentIndex++;\n                    break;\n                case ',':\n                    doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.COMMA));\n                    doLexContext.currentIndex++;\n                    break;\n                case ':':\n                    doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.COLON));\n                    doLexContext.currentIndex++;\n                    break;\n                case '\"':\n                    doLexContext.tokenCollector.add(parseString(chars, doLexContext));\n                    break;\n                case 't':\n                    // 尝试解析true关键字\n                    doLexContext.tokenCollector.add(parseTrueKeyword(chars, doLexContext));\n                    break;\n                case 'f':\n                    // 尝试解析false关键字\n                    doLexContext.tokenCollector.add(parseFalseKeyword(chars, doLexContext));\n                    break;\n                case 'n':\n                    // 尝试解析null关键字\n                    doLexContext.tokenCollector.add(parseNullKeyword(chars, doLexContext));\n                    break;\n                default:\n                    // 其它case\n                    if(ch == '-' || CommonStringUtil.is0_9(ch)){\n                        // number解析\n                        JsonToken numberToken = parseNumber(chars, doLexContext);\n                        doLexContext.tokenCollector.add(numberToken);\n                        break;\n                    }else if(CommonStringUtil.isWhitespace(ch)){\n                        // whiteSpace 直接跳过\n                        doLexContext.currentIndex++;\n                        break;\n                    }else{\n                        throw new MuJsonParserException(\"unexpected character: \" + ch + \" at index \" + doLexContext.currentIndex);\n                    }\n            }\n        }\n\n        // 最后加上EOF\n        doLexContext.tokenCollector.add(new JsonToken(JsonTokenTypeEnum.EOF));\n        return doLexContext.tokenCollector;\n    }\n}\n</code></pre>\n<p>抽象父类<code>AbstractJsonLexer</code>封装了string/number/keyword等具体类型的公共解析逻辑：</p>\n<pre><code class=\"language-java\">public abstract class AbstractJsonLexer {\n\n    protected final char[] jsonStringArray;\n\n    protected final DoLexContext doLexContext;\n\n    public AbstractJsonLexer(String jsonString) {\n        this.jsonStringArray = jsonString.toCharArray();\n        this.doLexContext = new DoLexContext();\n    }\n\n    protected JsonToken parseNumber(char[] chars, DoLexContext doLexContext){\n        // number类型的内容\n        String numberStr = new NumberLexStatemachine().tryParse(chars,doLexContext);\n\n        return new JsonToken(JsonTokenTypeEnum.NUMBER, numberStr);\n    }\n\n    protected JsonToken parseString(char[] chars, DoLexContext doLexContext){\n        // string类型的内容\n        String stringStr = new StringLexStatemachine().tryParse(chars,doLexContext);\n\n        return new JsonToken(JsonTokenTypeEnum.STRING, stringStr);\n    }\n\n    protected JsonToken parseTrueKeyword(char[] chars, DoLexContext doLexContext){\n        // true关键字\n        String stringStr = new KeywordTrueLexStatementMachine().tryParse(chars,doLexContext);\n\n        return new JsonToken(JsonTokenTypeEnum.TRUE, stringStr);\n    }\n\n    protected JsonToken parseFalseKeyword(char[] chars, DoLexContext doLexContext){\n        // false关键字\n        String stringStr = new KeywordFalseLexStatementMachine().tryParse(chars,doLexContext);\n\n        return new JsonToken(JsonTokenTypeEnum.FALSE, stringStr);\n    }\n\n    protected JsonToken parseNullKeyword(char[] chars, DoLexContext doLexContext){\n        // null关键字\n        String stringStr = new KeywordNullLexStatementMachine().tryParse(chars,doLexContext);\n\n        return new JsonToken(JsonTokenTypeEnum.NULL, stringStr);\n    }\n}\n</code></pre>\n<h5 id=\"_-5\"></h5>\n<ul>\n<li>为了支持后续流式的词法分析器，静态的词法分析器StaticJsonLexer继承自AbstractJsonLexer类，构造方法中接收一个字符串，并通过方法doLex进行解析，返回一次性完整解析字符串后的token列表。</li>\n<li>doLex方法中是一个while循环，每一次循环开始都相当于是自动机位于状态0，在解析时会通过自增currentIndex不断地推进字符流，成功解析出完整的token后便会将新的token保存到上下文中的tokenCollector中。只有在解析报错或者成功完成了整个字符串的解析后才会退出循环。</li>\n<li>在正常退出while循环后，doLex方法返回前token集合的尾部会追加一个特殊的EOF类型的token，用于告知下一阶段的parser已经解析到了token流的末尾，该结束解析了。</li>\n</ul>\n<h3 id=\"24-number类型的词法分析\">2.4 number类型的词法分析</h3>\n<p>number的词法规则相对复杂，因为number类型作为json中表示数字的组件，其可以是整数，也可以是小数、负数，同时还可以是带符号e/E的指数形式。</p>\n<h5 id=\"json-number类型token的词法规则\">json number类型token的词法规则</h5>\n<pre><code>number\n    integer fraction exponent\n\ninteger\n    digit\n    onenine digits\n    '-' digit\n    '-' onenine digits\n\ndigits\n    digit\n    digit digits\n\ndigit\n    '0'\n    onenine\n\nonenine\n    '1' . '9'\n\nfraction\n    \"\"\n    '.' digits\n\nexponent\n    \"\"\n    'E' sign digits\n    'e' sign digits\n\nsign\n    \"\"\n    '+'\n    '-'\n</code></pre>\n<p><img alt=\"json_number_lex_rule\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195806369-790385529.png\" /></p>\n<h5 id=\"_-6\"></h5>\n<p>基于上述词法规则，我们可以构造出如下图所示的用于解析number类型token的状态自动机。</p>\n<h5 id=\"number类型解析的状态自动机示意图\">number类型解析的状态自动机示意图</h5>\n<p><img alt=\"json_number_lex_state_machine\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211201818452-99218238.png\" /></p>\n<h5 id=\"_-7\"></h5>\n<p>设计好上述的状态自动机后，就可以按照图中的状态转移关系手写一个简单的状态机来解析number类型的token了。</p>\n<h5 id=\"number类型解析状态机实现源码\">number类型解析状态机实现源码</h5>\n<pre><code class=\"language-java\">public class NumberLexStatemachine extends LexStatementMachine{\n\n    private static final Map&lt;Integer,Boolean&gt; staticFinalStateMap;\n    private static final LexStateHandler[] lexStateHandlers;\n\n    static{\n        staticFinalStateMap = new HashMap&lt;&gt;();\n        staticFinalStateMap.put(-1,true);\n        staticFinalStateMap.put(1,true);\n        staticFinalStateMap.put(2,false);\n        staticFinalStateMap.put(3,true);\n        staticFinalStateMap.put(4,true);\n        staticFinalStateMap.put(5,false);\n        staticFinalStateMap.put(6,true);\n        staticFinalStateMap.put(7,false);\n        staticFinalStateMap.put(8,false);\n        staticFinalStateMap.put(9,true);\n\n        lexStateHandlers = new LexStateHandler[]{\n            new State0Handler(), new State1Handler(), new State2Handler(), new State3Handler(), new State4Handler(),\n            new State5Handler(),new State6Handler(),new State7Handler(),new State8Handler(),new State9Handler()\n        };\n    }\n\n    public NumberLexStatemachine() {\n        this.stateHandlers = lexStateHandlers;\n        this.isFinalStateMap = staticFinalStateMap;\n    }\n\n    private static abstract class NumberLexStateHandler implements LexStateHandler {\n\n        @Override\n        public int processInState(char[] chars, DoLexContext doLexContext, LexStatementMachine lexStatementMachine, StringBuilder oneTokenAcceptResult) {\n            char currentChar = chars[doLexContext.currentIndex];\n\n            // whitespace符号以及number后合法的终结符\n            if(CommonStringUtil.isWhitespace(currentChar)\n                || currentChar == ']' || currentChar == '}' || currentChar == ',' || currentChar == ':'){\n                if(lexStatementMachine.currentStateIsFinal()){\n                    // 结束number的解析\n                    return -1;\n                }else{\n                    // 遇到了分隔符，但是当前number解析的状态不是终态，无法转换为一个合法的number类型的token，抛异常\n                    throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n                }\n            }\n\n            return doProcessInState(currentChar,doLexContext, oneTokenAcceptResult);\n        }\n\n        abstract int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult);\n    }\n\n    private static class State0Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '0'){\n                // accept\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                // 进入状态1\n                return 1;\n            }\n\n            if(currentChar == '-'){\n                // accept\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                // 进入状态2\n                return 2;\n            }\n\n            if(CommonStringUtil.is1_9(currentChar)){\n                // accept\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                // 进入状态3\n                return 3;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State1Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '.'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 5;\n            }\n\n            if(currentChar == 'e' || currentChar == 'E'){\n                accept(currentChar,doLexContext, oneTokenAcceptResult);\n                return 7;\n            }\n\n            throw new MuJsonParserException(\"unexpected char '\" + currentChar + \"', index=\" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State2Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '0'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 1;\n            }\n\n            if(CommonStringUtil.is1_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 3;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State3Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '.'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 5;\n            }\n\n            if(currentChar == 'e' || currentChar == 'E'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 7;\n            }\n\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 4;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State4Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext,StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '.'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 5;\n            }\n\n            if(currentChar == 'e' || currentChar == 'E'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 7;\n            }\n\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 4;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State5Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 6;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State6Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext,StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 6;\n            }\n\n            if(currentChar == 'e' || currentChar == 'E'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 7;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State7Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext,StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 9;\n            }\n\n            if(currentChar == '-' || currentChar == '+'){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 8;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State8Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 9;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State9Handler extends NumberLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.is0_9(currentChar)){\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 9;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n}\n\n</code></pre>\n<pre><code class=\"language-java\">public abstract class LexStatementMachine {\n\n    protected int currentState = 0;\n    protected StringBuilder oneTokenAcceptResult = new StringBuilder();\n\n    protected LexStateHandler[] stateHandlers;\n    protected Map&lt;Integer,Boolean&gt; isFinalStateMap;\n\n    public String tryParse(char[] chars, DoLexContext doLexContext){\n        doParse(chars,doLexContext);\n\n        boolean isFinalState = isFinalStateMap.get(currentState);\n        if(isFinalState){\n            return oneTokenAcceptResult.toString();\n        }else{\n            throw new MuJsonParserException(String.format(\"currentState is not finalState! acceptResult=%s, acceptResult=%s\",currentState, oneTokenAcceptResult));\n        }\n    }\n\n    public boolean currentStateIsFinal(){\n        return isFinalStateMap.get(currentState);\n    }\n\n    protected static void accept(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult){\n        oneTokenAcceptResult.append(currentChar);\n        doLexContext.currentIndex++;\n    }\n\n    private void doParse(char[] chars, DoLexContext doLexContext){\n        // 一进来是状态0\n        while(doLexContext.currentIndex &lt; chars.length){\n            if(currentState == -1){\n                // 遇到了合法的分隔符号，退出token解析\n                return;\n            }\n\n            if(currentState &gt;= stateHandlers.length){\n                // 有bug\n                throw new MuJsonParserException(String.format(\"unknown state! currentState=%s\",currentState));\n            }\n            LexStateHandler targetStateHandler = stateHandlers[currentState];\n            \n            currentState = targetStateHandler.processInState(chars,doLexContext,this,oneTokenAcceptResult);\n        }\n    }\n}\n</code></pre>\n<h5 id=\"_-8\"></h5>\n<ul>\n<li>NumberLexStatemachine继承自父类LexStatementMachine。在LexStatementMachine中与doLex方法类似，也是一个while循环来反复的处理每一次的状态跳转。</li>\n<li>子类NumberLexStatemachine定义了一系列的LexStateHandler状态处理器，每一个状态处理器都对应状态机示意图中的一个状态。</li>\n<li>每一个LexStateHandler中的功能都比较类似，即决定在当前状态下自己能够接收的字符类型，以及控制在合法接收字符流当前字符后应该跳转的下一个状态是什么。<br />\n在合法接收字符时，会修改上下文中的当前字符指针以推进字符流，同时将接受到的当前合法字符追加到oneTokenAcceptResult中。</li>\n<li>如果遇到了合法的结束分隔符，比如whitespace或者“}”、“]”之类的字符，且当前状态是属于number解析的终态，则NumberLexStateHandler会返回-1，终止当前token的解析。(比如{\"number\":-123.0}结束时的状态是6，6是终态，所以其是合法的json串)<br />\n如果状态处理器中遇到当前状态下不合法的字符，或者在退出解析时当前状态不属于number解析的终态，说明当前字符串不是合法的json串，则会直接抛出异常，退出词法解析。(比如{\"number\":-123.}结束时的状态是5,5不是终态，所以其是不合法的json串)</li>\n<li>NumberLexStatemachine状态机正常退出当前number类型token后，返回收集到的所有字符oneTokenAcceptResult，作为number类型的字面量返回。</li>\n</ul>\n<h3 id=\"25-string类型的词法分析\">2.5 string类型的词法分析</h3>\n<p>string类型的词法规则相比之下比较简单，要求以双引号开头，并以双引号结尾即可，但需要额外处理转义字符相关的逻辑。</p>\n<h5 id=\"json-string类型token的词法规则\">json string类型token的词法规则</h5>\n<pre><code>string\n    '\"' characters '\"'\n\ncharacters\n    \"\"\n    character characters\n\ncharacter\n    '0020' . '10FFFF' - '\"' - '\\'\n    '\\' escape\n\nescape\n    '\"'\n    '\\'\n    '/'\n    'b'\n    'f'\n    'n'\n    'r'\n    't'\n    'u' hex hex hex hex\n\nhex\n    digit\n    'A' . 'F'\n    'a' . 'f'\n</code></pre>\n<p><img alt=\"json_string_lex_rule\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195844242-1192651121.png\" /></p>\n<h5 id=\"_-9\"></h5>\n<p>基于上述词法规则，我们构造出如下图所示的用于解析string类型token的状态自动机。</p>\n<h5 id=\"string类型解析的状态自动机示意图\">string类型解析的状态自动机示意图</h5>\n<p><img alt=\"json_string_lex_state_machine\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195854133-180088812.png\" /></p>\n<h5 id=\"string类型解析状态机实现源码\">string类型解析状态机实现源码</h5>\n<pre><code class=\"language-java\">public class StringLexStatemachine extends LexStatementMachine{\n\n    private static final Map&lt;Integer,Boolean&gt; staticFinalStateMap;\n    private static final LexStateHandler[] lexStateHandlers;\n\n    static{\n        staticFinalStateMap = new HashMap&lt;&gt;();\n        staticFinalStateMap.put(-1,true);\n        staticFinalStateMap.put(1,false);\n        staticFinalStateMap.put(2,true);\n        staticFinalStateMap.put(3,false);\n        staticFinalStateMap.put(4,false);\n        staticFinalStateMap.put(5,false);\n        staticFinalStateMap.put(6,false);\n        staticFinalStateMap.put(7,false);\n\n        lexStateHandlers = new LexStateHandler[]{\n            new State0Handler(),new State1Handler(),new State2Handler(),new State3Handler(),new State4Handler(),\n            new State5Handler(),new State6Handler(),new State7Handler()};\n    }\n\n    public StringLexStatemachine() {\n        this.stateHandlers = lexStateHandlers;\n        this.isFinalStateMap = staticFinalStateMap;\n    }\n\n    private static abstract class StringLexStateHandler implements LexStateHandler {\n\n        @Override\n        public int processInState(char[] chars, DoLexContext doLexContext, LexStatementMachine lexStatementMachine, StringBuilder oneTokenAcceptResult) {\n            char currentChar = chars[doLexContext.currentIndex];\n\n            return doProcessInState(currentChar,doLexContext,oneTokenAcceptResult);\n        }\n\n        abstract int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult);\n    }\n\n    private static class State0Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '\"'){\n                // accept\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                // 进入状态1\n                return 1;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State1Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(currentChar == '\"'){\n                // accept\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                // 进入状态2\n                return 2;\n            }\n\n            if(currentChar == '\\\\'){\n                // accept\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                // 进入状态3\n                return 3;\n            }\n\n            // 控制字符是不合法的，不能出现在string中\n            if (currentChar &lt; 0x20) {\n                throw new MuJsonParserException(\"unexpected control char \" + currentChar + \" in string, \" + doLexContext.currentIndex);\n            }\n\n            // 除了[\"]和[\\]两个字符，别的都当做字符串的一部分接收\n            // accept\n            accept(currentChar,doLexContext,oneTokenAcceptResult);\n            return 1;\n        }\n    }\n\n    private static class State2Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            // 终态，完成一个string的解析，直接退出\n            return -1;\n        }\n    }\n\n    private static class State3Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            // 合法的转义字符\n            if(currentChar == '\"' || currentChar == '\\\\' || currentChar == '/' ||\n                currentChar == 'b' || currentChar == 'f' || currentChar == 'n' ||\n                currentChar == 'r' || currentChar == 't'){\n                // 接收，回到状态1\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 1;\n            }\n\n            if(currentChar == 'u'){\n                // 特殊case 要求后面连续4个hex字符 '\\\\u hex hex hex hex'\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 4;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State4Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.isHex(currentChar)){\n                // 接收，进入状态5\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 5;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State5Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.isHex(currentChar)){\n                // 接收，进入状态6\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 6;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State6Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.isHex(currentChar)){\n                // 接收，进入状态7\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 7;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n\n    private static class State7Handler extends StringLexStateHandler {\n        @Override\n        int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult) {\n            if(CommonStringUtil.isHex(currentChar)){\n                // 连续接收了4个hex字符，回到状态1\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return 1;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n}\n</code></pre>\n<h5 id=\"_-10\"></h5>\n<ul>\n<li>string类型token解析的状态机与number类型的工作模式类似，同样继承自LexStatementMachine，并且定义了一系列的对应状态机示意图中各个状态的LexStateHandler。</li>\n</ul>\n<h3 id=\"26-关键字的词法分析\">2.6 关键字的词法分析</h3>\n<p>最后，json的词法分析中还有关键字类型的token解析需要实现。所幸json的文法非常简单，只有true、false和null三个关键字，且这三个关键字的f(1)都不相同，也与其它类型的token的f(1)不相同。<br />\n因此，在词法解析时，我们可以很简单的根据第一个字符来决定要解析的关键字类型，在状态0时，如果碰到字符t就尝试解析true类型的token；碰到字符f就尝试解析false类型的token；碰到字符n就尝试解析null类型的token。<br />\n因此我们可以很简单的得到如下图所示的三个关键字的状态自动机。</p>\n<h5 id=\"关键字类型解析的状态自动机示意图\">关键字类型解析的状态自动机示意图</h5>\n<p><img alt=\"json_keyword_lex_state_machine\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195910810-282453956.png\" /></p>\n<h5 id=\"keyword类型解析状态机实现源码\">keyword类型解析状态机实现源码</h5>\n<pre><code class=\"language-java\">public abstract class KeywordLexStatementMachine extends LexStatementMachine{\n\n    protected final String keyword;\n\n    public KeywordLexStatementMachine(String keyword) {\n        this.keyword = keyword;\n    }\n\n    protected static Map&lt;Integer,Boolean&gt; buildIsFinalStateMap(String keyword){\n        Map&lt;Integer,Boolean&gt; isFinalStateMap = new HashMap&lt;&gt;(keyword.length() + 1);\n        isFinalStateMap.put(-1,true);\n\n        for(int i=0; i&lt;keyword.length(); i++) {\n            isFinalStateMap.put(i,false);\n        }\n\n        // 最后一个字符就是合理的终态\n        isFinalStateMap.put(keyword.length(),true);\n\n        return isFinalStateMap;\n    }\n\n    protected static LexStateHandler[] buildLexStateHandlers(String keyword){\n        LexStateHandler[] lexStateHandlers = new LexStateHandler[keyword.length() + 1];\n\n        for(int i=0; i&lt;keyword.length(); i++) {\n            char c = keyword.charAt(i);\n\n            lexStateHandlers[i] = new KeywordLexStateHandler(c,i+1);\n        }\n\n        // 最后一个状态，直接返回\n        lexStateHandlers[keyword.length()] = new KeywordLexStateHandler(' ',-1);\n\n        return lexStateHandlers;\n    }\n\n    private static class KeywordLexStateHandler implements LexStateHandler {\n\n        private final char targetCh;\n        private final int nextState;\n\n        public KeywordLexStateHandler(char targetCh, int nextState) {\n            this.targetCh = targetCh;\n            this.nextState = nextState;\n        }\n\n        @Override\n        public int processInState(char[] chars, DoLexContext doLexContext, LexStatementMachine lexStatementMachine, StringBuilder oneTokenAcceptResult) {\n            char currentChar = chars[doLexContext.currentIndex];\n\n            return doProcessInState(currentChar,doLexContext,oneTokenAcceptResult);\n        }\n\n        private int doProcessInState(char currentChar, DoLexContext doLexContext, StringBuilder oneTokenAcceptResult){\n            if(nextState == -1){\n                // -1是特殊的直接返回\n                return nextState;\n            }\n\n            if(currentChar == targetCh) {\n                // 接收，进入下一个状态\n                accept(currentChar,doLexContext,oneTokenAcceptResult);\n                return nextState;\n            }\n\n            throw new MuJsonParserException(\"unexpected char \" + currentChar + \" \" + doLexContext.currentIndex);\n        }\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">/**\n * 解析关键字true的状态自动机\n * */\npublic class KeywordTrueLexStatementMachine extends KeywordLexStatementMachine{\n\n    private static final String KEYWORD = JsonTokenTypeEnum.TRUE.getKey();\n    private static final Map&lt;Integer,Boolean&gt; staticIsFinalStateMap;\n    private static final LexStateHandler[] lexStateHandlers;\n\n    static {\n        staticIsFinalStateMap = buildIsFinalStateMap(KEYWORD);\n        lexStateHandlers = buildLexStateHandlers(KEYWORD);\n    }\n\n    public KeywordTrueLexStatementMachine() {\n        super(KEYWORD);\n\n        super.isFinalStateMap = staticIsFinalStateMap;\n        super.stateHandlers = lexStateHandlers;\n    }\n}\n</code></pre>\n<h5 id=\"_-11\"></h5>\n<ul>\n<li>由于关键字的解析都是最简单的单向状态转移，所以单独抽象出了KeywordLexStatementMachine类，其根据构造方法中传入的关键字字面量，自动生成对应数量的LexStateHandler集合和IsFinalStateMap。</li>\n<li>false和null关键字的词法解析与true基本一致，这里省略掉</li>\n</ul>\n<h5 id=\"27-jsontokenreader\">2.7 jsonTokenReader</h5>\n<p>至此，我们就已经实现了基本的json词法分析能力，能够将json字符串一次性的解析成token列表供下一阶段的语法分析使用。<br />\n但在语法解析阶段，parser更希望接收的是能够自己记忆当前所处理token的token流，而不是一个孤零零的List，所以这里简单的以迭代器的方式包装一下方便使用。</p>\n<pre><code class=\"language-java\">public interface JsonTokenReader {\n\n    boolean hasNextToken();\n\n    JsonToken nextToken();\n\n    JsonToken peek();\n\n    int currentIndex();\n}\n</code></pre>\n<p>静态词法分析器的实现：</p>\n<pre><code class=\"language-java\">public class StaticJsonTokenReader implements JsonTokenReader {\n\n    private int currentIndex;\n\n    private final List&lt;JsonToken&gt; tokens;\n\n    public StaticJsonTokenReader(String jsonString) {\n        this.currentIndex = 0;\n\n        StaticJsonLexer staticJsonLexer = new StaticJsonLexer(jsonString);\n        this.tokens = staticJsonLexer.doLex();\n    }\n\n    @Override\n    public boolean hasNextToken() {\n        return tokens.get(currentIndex).getType() != JsonTokenTypeEnum.EOF;\n    }\n\n    @Override\n    public JsonToken nextToken() {\n        JsonToken jsonToken = tokens.get(currentIndex);\n        currentIndex++;\n        return jsonToken;\n    }\n\n    @Override\n    public JsonToken peek() {\n        return tokens.get(currentIndex);\n    }\n\n    @Override\n    public int currentIndex() {\n        return this.currentIndex;\n    }\n}\n</code></pre>\n<p>简单demo：</p>\n<pre><code class=\"language-java\">    public static void main(String[] args) {\n        String json = \"{\\\"k1\\\":{\\\"abc\\\":123},\\\"k2\\\":true}\";\n\n        StaticJsonLexer staticJsonLexer = new StaticJsonLexer(json);\n        List&lt;JsonToken&gt; jsonTokenList = staticJsonLexer.doLex();\n        System.out.println(\"json=\" + json);\n        jsonTokenList.forEach(System.out::println);\n    }\n</code></pre>\n<p><img alt=\"static_json_lexer_demo_result\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195926464-23510035.png\" /></p>\n<h2 id=\"3-手写-json-语法分析器从-token-到-ast\">3. 手写 json 语法分析器：从 token 到 AST</h2>\n<p>语法分析阶段，接收词法分析阶段输出的token流，需要按照语法规则解析出正确的AST抽象语法树。<br />\n在json的AST中其实本质上只有三种类型的元素：</p>\n<ul>\n<li><code>JsonObject</code>：对象</li>\n<li><code>JsonArray</code>：数组</li>\n<li><code>JsonPrimitiveStr</code>：primitive基础类型（string/number/true/false/null）封装为字符串字面量</li>\n</ul>\n<h5 id=\"_-12\"></h5>\n<p>primitive基础类型是无法进行递归嵌套的类型，是AST中的叶节点，而object和array则是可以互相嵌套的(对象的一个属性可以是数组或者另一个对象，数组中的元素也可以是对象或者另一个数组)，其属于AST中的非叶子结点。</p>\n<h3 id=\"31-json-ast节点结构定义\">3.1 json AST节点结构定义</h3>\n<pre><code class=\"language-java\">public abstract class JsonElement {\n}\n</code></pre>\n<pre><code class=\"language-java\">/**\n * json AST的object类型节点\n * */\npublic class JsonObject extends JsonElement{\n\n    private final Map&lt;String,JsonElement&gt; objMap = new LinkedHashMap&lt;&gt;();\n\n    public void putKV(String key, JsonElement value) {\n        objMap.put(key, value);\n    }\n\n    public Map&lt;String, JsonElement&gt; getObjMap() {\n        return objMap;\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">/**\n * json AST的array类型节点\n * */\npublic class JsonArray extends JsonElement{\n\n    private List&lt;JsonElement&gt; array = new ArrayList&lt;&gt;();\n\n    public void addElement(JsonElement element) {\n        array.add(element);\n    }\n\n    public List&lt;JsonElement&gt; getArray() {\n        return array;\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">/**\n * json AST的primitive类型节点\n * */\npublic class JsonPrimitiveStr extends JsonElement{\n\n    /**\n     * 基础类型的字符串字面量\n     * */\n    private final String primitiveValueStr;\n\n    public JsonPrimitiveStr(String primitiveValueStr) {\n        this.primitiveValueStr = primitiveValueStr;\n    }\n\n    public String getPrimitiveValueStr() {\n        return primitiveValueStr;\n    }\n}\n</code></pre>\n<h5 id=\"_-13\"></h5>\n<ul>\n<li>jsonElement是所有AST节点的共同抽象父类</li>\n<li>json的object结构映射为java中是一个有序的k/v Map结构</li>\n<li>json的array结构映射为java中是一个List结构</li>\n<li>json的primitive结构映射为java中的一个简单字符串字面量</li>\n</ul>\n<h3 id=\"32-json根节点语法解析\">3.2 json根节点语法解析</h3>\n<pre><code>json\n    element\n    \nelement\n    ws value ws\n\nvalue\n    object\n    array\n    string\n    number\n    \"true\"\n    \"false\"\n    \"null\"\n\nobject\n    '{' ws '}'\n    '{' members '}'    \n\narray\n    '[' ws ']'\n    '[' elements ']'\n</code></pre>\n<h5 id=\"_-14\"></h5>\n<p>上述文法中，json是AST的根节点，其最终可以是object、array或者5种基本类型的一种。<br />\nobject类型的f(1)有且仅有'{'，而array类型的f(1)有且仅有'['，因此我们可以构造出一个简单的根节点解析的状态机来实现语法分析。</p>\n<ul>\n<li>若token流中的第一个 token 是 <code>{</code> → 解析为 <code>JsonObject</code>。</li>\n<li>若token流中的第一个 token 是 <code>[</code> → 解析为 <code>JsonArray</code>。</li>\n<li>若token流中的第一个 token 是基础类型 → 解析为 <code>JsonPrimitiveStr</code>。</li>\n<li>否则都是非法json。</li>\n</ul>\n<h5 id=\"json根节点语法解析状态自动机\">json根节点语法解析状态自动机</h5>\n<p><img alt=\"json_parser_root\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195937409-994915878.png\" /></p>\n<h5 id=\"json根节点解析状态自动机实现\">json根节点解析状态自动机实现</h5>\n<pre><code class=\"language-java\">/**\n * 基于递归实现的json解析器\n * */\npublic class RecursiveJsonParser extends JsonParser {\n\n    public RecursiveJsonParser(JsonTokenReader tokenReader) {\n        super(tokenReader);\n    }\n\n    @Override\n    public JsonElement doParse() {\n        JsonToken token = jsonTokenReader.peek();\n\n        if (token.getType() == JsonTokenTypeEnum.LEFT_BRACE) {\n            JsonObjectParseStatementMachine jsonObjectParseStatementMachine = new JsonObjectParseStatementMachine(jsonTokenReader);\n\n            return jsonObjectParseStatementMachine.parseJsonElement();\n        }\n\n        if (token.getType() == JsonTokenTypeEnum.LEFT_BRACKET) {\n            JsonArrayParseStatementMachine jsonArrayParseStatementMachine = new JsonArrayParseStatementMachine(jsonTokenReader);\n\n            return jsonArrayParseStatementMachine.parseJsonElement();\n        }\n\n        // 基础类型的value\n        if (token.getType().isPrimitiveValue()) {\n            return new JsonPrimitiveStr(token.getContent());\n        }\n\n        // 第一个token，不属于json规则的f(1)集合\n        throw new MuJsonParserException(\"unexpected start json token! token=\" + jsonTokenReader.currentIndex());\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">public enum JsonTokenTypeEnum {\n    // 省略了无关逻辑\n\n    /**\n     * 基础类型的value（string、number、true、false、null）\n     * */\n    public boolean isPrimitiveValue(){\n        return this == STRING || this == NUMBER || this == NULL ||this == TRUE || this == FALSE;\n    }\n}\n</code></pre>\n<h3 id=\"33-json-object对象结构解析\">3.3 json object对象结构解析</h3>\n<p>现在我们来研究json object对象的语法解析。object结构是以“{”开头，“}”结尾的结构，内部可以有0到N个kv键值对，其中key必须是string类型，而value则可以是嵌套的结构，key和value之间以冒号分隔，kv对之间以逗号分割。<br />\n因此，使用递归的方式来实现object对象的语法解析是很容易理解和实现的(尽管递归的实现效率不够高)。</p>\n<h5 id=\"json-object对象结构语法\">json object对象结构语法</h5>\n<pre><code>object\n    '{' ws '}'\n    '{' members '}'\n\nmembers\n    member\n    member ',' members\n\nmember\n    ws string ws ':' element\n\nelement\n    ws value ws    \n\nvalue\n    object\n    array\n    string\n    number\n    \"true\"\n    \"false\"\n    \"null\"\n</code></pre>\n<p><img alt=\"json_object_parser\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195946762-1722527366.png\" /></p>\n<h5 id=\"object结构解析状态自动机示意图\">object结构解析状态自动机示意图</h5>\n<p><img alt=\"json_object_state_machine\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211195955922-1227811677.png\" /></p>\n<h5 id=\"object结构解析状态自动机递归实现递归版本\">object结构解析状态自动机递归实现（递归版本）</h5>\n<p>语法分析与词法分析类似，也是使用状态自动机来实现的。实现的大致方式也是通过抽象出一个父类(AbstractJsonParseStatementMachine),在父类中通过持续不断的从token流中读取token来推进状态。在子类中定义相应的状态处理器来实现每个状态的处理</p>\n<pre><code class=\"language-java\">/**\n * 基于递归实现的 object类型语法解析状态自动机\n * */\npublic class JsonObjectParseStatementMachine extends AbstractJsonParseStatementMachine&lt;JsonObject&gt;{\n\n    public JsonObjectParseStatementMachine(JsonTokenReader jsonTokenReader) {\n        this.jsonTokenReader = jsonTokenReader;\n        this.targetJsonElement = new JsonObject();\n        this.recursiveDoParserContext = new RecursiveDoParserContext&lt;&gt;(this.targetJsonElement);\n        stateHandlers = new ParserStateHandler[]{\n            new ParserState0Handler(),new ParserState1Handler(),new ParserState2Handler(),new ParserState3Handler(),\n            new ParserState4Handler(),new ParserState5Handler(),new ParserState6Handler()\n        };\n    }\n\n    private static class ParserState0Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() != JsonTokenTypeEnum.LEFT_BRACE){\n                throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n            }\n\n            accept(jsonTokenReader);\n            return 1;\n        }\n    }\n\n    private static class ParserState1Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() == JsonTokenTypeEnum.RIGHT_BRACE){\n                accept(jsonTokenReader);\n                return 2;\n            }\n\n            if(token.getType() == JsonTokenTypeEnum.STRING){\n                // 把key先压入栈中，然后等构造kv对时弹出\n                recursiveDoParserContext.getTokenStack().push(token);\n                accept(jsonTokenReader);\n                return 3;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private static class ParserState2Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            // 终态，直接返回\n            return -1;\n        }\n    }\n\n    private static class ParserState3Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() == JsonTokenTypeEnum.COLON){\n                accept(jsonTokenReader);\n                return 4;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private static class ParserState4Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            JsonToken keyToken = recursiveDoParserContext.getTokenStack().pop();\n            Assert.assertTrue(keyToken != null &amp;&amp; keyToken.getType() == JsonTokenTypeEnum.STRING,\"parse object keyToken not match!\");\n\n            // 嵌套的jsonObject结构\n            if(token.getType() == JsonTokenTypeEnum.LEFT_BRACE){\n                JsonObjectParseStatementMachine jsonObjectParseStatementMachine = new JsonObjectParseStatementMachine(jsonTokenReader);\n\n                JsonObject subJsonObject = jsonObjectParseStatementMachine.parseJsonElement();\n\n                // 构造好了一个kv对（key : obj）\n                recursiveDoParserContext.getTargetJsonElement().putKV(keyToken.getContent(), subJsonObject);\n\n                return 5;\n            }\n\n            // 嵌套的jsonArray结构\n            if(token.getType() == JsonTokenTypeEnum.LEFT_BRACKET){\n                // jsonArray状态机\n                JsonArrayParseStatementMachine jsonArrayParseStatementMachine = new JsonArrayParseStatementMachine(jsonTokenReader);\n\n                JsonArray jsonArray = jsonArrayParseStatementMachine.parseJsonElement();\n                // 构造好了一个kv对 (key ：array)\n                recursiveDoParserContext.getTargetJsonElement().putKV(keyToken.getContent(), jsonArray);\n\n                return 5;\n            }\n\n            // 基础类型的value\n            if(token.getType().isPrimitiveValue()){\n                accept(jsonTokenReader);\n                recursiveDoParserContext.getTargetJsonElement().putKV(keyToken.getContent(), new JsonPrimitiveStr(token.getContent()));\n\n                return 5;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private static class ParserState5Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() == JsonTokenTypeEnum.RIGHT_BRACE){\n                accept(jsonTokenReader);\n                return 2;\n            }\n\n            if(token.getType() == JsonTokenTypeEnum.COMMA){\n                accept(jsonTokenReader);\n                return 6;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private static class ParserState6Handler implements ParserStateHandler&lt;JsonObject&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonObject&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() == JsonTokenTypeEnum.STRING){\n                // 把key先压入栈中，然后等构造kv对时弹出\n                recursiveDoParserContext.getTokenStack().push(token);\n                accept(jsonTokenReader);\n                return 3;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">public class AbstractJsonParseStatementMachine&lt;T extends JsonElement&gt; {\n\n    protected JsonTokenReader jsonTokenReader;\n\n    protected RecursiveDoParserContext&lt;T&gt; recursiveDoParserContext;\n\n    protected int currentState = 0;\n\n    protected T targetJsonElement;\n\n    protected ParserStateHandler[] stateHandlers;\n\n    public T parseJsonElement(){\n        while(jsonTokenReader.hasNextToken()){\n            if(currentState == -1){\n                // 遇到了合法的分隔符号，退出token解析\n                return targetJsonElement;\n            }\n\n            if(currentState &gt;= stateHandlers.length){\n                // 有bug\n                throw new MuJsonParserException(String.format(\"unknown state! currentState=%s\",currentState));\n            }\n            ParserStateHandler targetStateHandler = stateHandlers[currentState];\n            \n            currentState = targetStateHandler.processInState(jsonTokenReader, recursiveDoParserContext);\n        }\n\n        return targetJsonElement;\n    }\n\n    protected static void accept(JsonTokenReader jsonTokenReader){\n        jsonTokenReader.nextToken();\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">public class RecursiveDoParserContext&lt;T extends JsonElement&gt;  {\n\n    private Stack&lt;JsonToken&gt; tokenStack = new Stack&lt;&gt;();\n\n    private T targetJsonElement;\n\n    public RecursiveDoParserContext(T targetJsonElement) {\n        this.targetJsonElement = targetJsonElement;\n    }\n\n    public Stack&lt;JsonToken&gt; getTokenStack() {\n        return tokenStack;\n    }\n\n    public T getTargetJsonElement() {\n        return targetJsonElement;\n    }\n}\n</code></pre>\n<h5 id=\"_-15\"></h5>\n<ul>\n<li>在解析kv对时，需要先将string类型的key暂时缓存起来，等待后续的value类型结构(object、array或者primitive)也完成解析后，再一并的放入AST中(getTargetJsonElement().putKV)。</li>\n<li>解析kv对的value时，当前的实现是基于递归实现的。即当根据当前token的类型创建一个新的对应类型的状态机，去递归的解析更深一层的AST结构。<br />\n递归实现的好处是思路简单易懂，不用过多的考虑不同类型结构之间状态的互相转移，通过递归解析子AST的方式天然的屏蔽掉了大量的复杂度。<br />\n但缺点也同样明显，在解析层次非常深的json字符串时，递归的层次过深可能会导致当前线程栈溢出，解析失败。</li>\n</ul>\n<h3 id=\"34-json-array数组结构解析\">3.4 json array数组结构解析</h3>\n<p>array结构是以“[”开头，“]”结尾的结构，内部可以有0到N个value类型的元素,以逗号做分割，value同样是可以是嵌套的结构。与上面object结构的解析实现方式一样，同样是基于递归实现的。</p>\n<h5 id=\"json-array数组结构语法\">json array数组结构语法</h5>\n<pre><code>array\n    '[' ws ']'\n    '[' elements ']'\n\nelements\n    element\n    element ',' elements\n\nelement\n    ws value ws\n\nvalue\n    object\n    array\n    string\n    number\n    \"true\"\n    \"false\"\n    \"null\"\n</code></pre>\n<p><img alt=\"json_array_parser\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211200007327-1872691214.png\" /></p>\n<h5 id=\"array结构解析状态自动机示意图\">array结构解析状态自动机示意图</h5>\n<p><img alt=\"json_array_state_machine\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211200016319-1527985884.png\" /></p>\n<h5 id=\"array结构解析状态自动机递归实现递归版本\">array结构解析状态自动机递归实现（递归版本）</h5>\n<pre><code class=\"language-java\">/**\n * 基于递归实现的 array类型语法解析状态自动机\n * */\npublic class JsonArrayParseStatementMachine extends AbstractJsonParseStatementMachine&lt;JsonArray&gt; {\n\n    public JsonArrayParseStatementMachine(JsonTokenReader jsonTokenReader) {\n        this.jsonTokenReader = jsonTokenReader;\n        this.targetJsonElement = new JsonArray();\n        this.recursiveDoParserContext = new RecursiveDoParserContext&lt;&gt;(this.targetJsonElement);\n        stateHandlers = new ParserStateHandler[]{\n            new ParserState0Handler(),new ParserState1Handler(),new ParserState2Handler(),\n            new ParserState3Handler(), new ParserState4Handler()\n        };\n    }\n\n    private static class ParserState0Handler implements ParserStateHandler&lt;JsonArray&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonArray&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() != JsonTokenTypeEnum.LEFT_BRACKET){\n                throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n            }\n\n            accept(jsonTokenReader);\n            return 1;\n        }\n    }\n\n    private static class ParserState1Handler implements ParserStateHandler&lt;JsonArray&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonArray&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() == JsonTokenTypeEnum.RIGHT_BRACKET){\n                accept(jsonTokenReader);\n                return 2;\n            }\n\n            // 嵌套的jsonObject结构\n            if(token.getType() == JsonTokenTypeEnum.LEFT_BRACE){\n                JsonObjectParseStatementMachine jsonObjectParseStatementMachine = new JsonObjectParseStatementMachine(jsonTokenReader);\n\n                JsonObject subJsonObject = jsonObjectParseStatementMachine.parseJsonElement();\n\n                // add一个obj\n                recursiveDoParserContext.getTargetJsonElement().addElement(subJsonObject);\n\n                return 3;\n            }\n\n            // 嵌套的jsonArray结构\n            if(token.getType() == JsonTokenTypeEnum.LEFT_BRACKET){\n                // jsonArray状态机\n                JsonArrayParseStatementMachine jsonArrayParseStatementMachine = new JsonArrayParseStatementMachine(jsonTokenReader);\n\n                JsonArray jsonArray = jsonArrayParseStatementMachine.parseJsonElement();\n\n                // add一个array\n                recursiveDoParserContext.getTargetJsonElement().addElement(jsonArray);\n\n                return 3;\n            }\n\n            // 基础类型的value\n            if(token.getType().isPrimitiveValue()){\n                accept(jsonTokenReader);\n                recursiveDoParserContext.getTargetJsonElement().addElement(new JsonPrimitiveStr(token.getContent()));\n\n                return 3;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private static class ParserState2Handler implements ParserStateHandler&lt;JsonArray&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonArray&gt; recursiveDoParserContext) {\n            // 终态，直接返回\n            return -1;\n        }\n    }\n\n    private static class ParserState3Handler implements ParserStateHandler&lt;JsonArray&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonArray&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            if(token.getType() == JsonTokenTypeEnum.RIGHT_BRACKET){\n                accept(jsonTokenReader);\n                return 2;\n            }\n\n            if(token.getType() == JsonTokenTypeEnum.COMMA){\n                accept(jsonTokenReader);\n                return 4;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private static class ParserState4Handler implements ParserStateHandler&lt;JsonArray&gt;{\n\n        @Override\n        public int processInState(JsonTokenReader jsonTokenReader, RecursiveDoParserContext&lt;JsonArray&gt; recursiveDoParserContext) {\n            JsonToken token = jsonTokenReader.peek();\n\n            // 嵌套的jsonObject结构\n            if(token.getType() == JsonTokenTypeEnum.LEFT_BRACE){\n                JsonObjectParseStatementMachine jsonObjectParseStatementMachine = new JsonObjectParseStatementMachine(jsonTokenReader);\n\n                JsonObject subJsonObject = jsonObjectParseStatementMachine.parseJsonElement();\n\n                // add一个obj\n                recursiveDoParserContext.getTargetJsonElement().addElement(subJsonObject);\n\n                return 3;\n            }\n\n            // 嵌套的jsonArray结构\n            if(token.getType() == JsonTokenTypeEnum.LEFT_BRACKET){\n                // jsonArray状态机\n                JsonArrayParseStatementMachine jsonArrayParseStatementMachine = new JsonArrayParseStatementMachine(jsonTokenReader);\n\n                JsonArray jsonArray = jsonArrayParseStatementMachine.parseJsonElement();\n\n                // add一个array\n                recursiveDoParserContext.getTargetJsonElement().addElement(jsonArray);\n\n                return 3;\n            }\n\n            // 基础类型的value\n            if(token.getType().isPrimitiveValue()){\n                accept(jsonTokenReader);\n                recursiveDoParserContext.getTargetJsonElement().addElement(new JsonPrimitiveStr(token.getContent()));\n\n                return 3;\n            }\n\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n}\n</code></pre>\n<h5 id=\"_-16\"></h5>\n<ul>\n<li>相比object结构的状态自动机，array结构的状态自动机则显得比较简单。同样在遇到复杂类型的结构时，通过当前token的类型递归的创建一个新的状态机去构造出子AST(JsonElement)，然后加入到当前JsonArray中(getTargetJsonElement().addElement)。</li>\n</ul>\n<h2 id=\"4-基于ast生成beauty-json字符串\">4. 基于AST生成beauty json字符串</h2>\n<p>现在我们已经实现了json的词法解析和语法解析，可以将一个原始的合法的json字符串正确的转换成对应的AST了。<br />\n拿到AST之后理论上可以做很多事情，比如将json串反序列化为java对象。这里我们实现一个<strong>更简单也更直观的功能</strong>，即将原始的json字符串格式化成缩进良好，更美观，可读性更佳的beauty字符串。</p>\n<h5 id=\"生成格式化后的beauty-json字符串实现\">生成格式化后的beauty json字符串实现</h5>\n<pre><code class=\"language-java\">public abstract class JsonElement {\n\n    private static final String BEAUTY_INDENT = \"    \";  // 四个空格缩进\n    private static final String BEAUTY_KV_INDENT = \" \";  // kv多一个空格\n    private static final String BEAUTY_LINE_BREAK = \"\\n\"; // 换行分割\n\n    /**\n     * 生成美化后的beauty字符串\n     * */\n    public String buildBeautyJsonString(){\n        StringBuilder jsonStringBuilder = new StringBuilder();\n\n        buildJsonString(this,jsonStringBuilder,\"\",BEAUTY_LINE_BREAK,BEAUTY_INDENT,BEAUTY_KV_INDENT);\n\n        return jsonStringBuilder.toString();\n    }\n\n    private static void buildJsonString(JsonElement jsonElement, StringBuilder jsonStringBuilder, String currentIndent,\n                                        String lineBreak, String indent, String kvIndent){\n        if(jsonElement instanceof JsonPrimitiveStr){\n            jsonStringBuilder.append(jsonElement);\n            return;\n        }\n\n        if(jsonElement instanceof JsonArray){\n            JsonArray jsonArray  = (JsonArray) jsonElement;\n            jsonStringBuilder.append(\"[\").append(lineBreak);\n            List&lt;JsonElement&gt; jsonArrayList = jsonArray.getArray();\n            int i=0;\n            for(JsonElement arrayItem : jsonArrayList){\n                jsonStringBuilder.append(currentIndent).append(indent);\n                // 递归下去，currentIndent多缩进一层\n                buildJsonString(arrayItem,jsonStringBuilder,currentIndent + indent,lineBreak,indent,kvIndent);\n                if(i != jsonArrayList.size()-1){\n                    jsonStringBuilder.append(\",\");\n                }\n\n                jsonStringBuilder.append(lineBreak);\n                i++;\n            }\n\n            jsonStringBuilder.append(currentIndent).append(\"]\");\n        }\n\n        if(jsonElement instanceof JsonObject){\n            JsonObject jsonObject  = (JsonObject) jsonElement;\n            jsonStringBuilder.append(\"{\").append(lineBreak);\n\n            Map&lt;String, JsonElement&gt; objMap = jsonObject.getObjMap();\n\n            int i=0;\n            for(Map.Entry&lt;String, JsonElement&gt; entry : objMap.entrySet()){\n                String key = entry.getKey();\n                JsonElement value = entry.getValue();\n\n                // key是string类型的，字面量里自带双引号的\n                jsonStringBuilder.append(currentIndent).append(indent).append(key).append(kvIndent).append(\":\").append(kvIndent);\n                // 递归下去，currentIndent多缩进一层\n                buildJsonString(value,jsonStringBuilder,  currentIndent + indent, lineBreak,indent,kvIndent);\n\n                if(i != objMap.size()-1){\n                    jsonStringBuilder.append(\",\");\n                }\n\n                jsonStringBuilder.append(lineBreak);\n                i++;\n            }\n\n            jsonStringBuilder.append(currentIndent).append(\"}\");\n        }\n    }\n}\n</code></pre>\n<h5 id=\"_-17\"></h5>\n<ul>\n<li>从源码实现中可以看到，输出美化后的beauty字符串本质上就是一个针对AST树形结构的<strong>深度优先遍历</strong>，只需要注意随着递归深度动态调整缩进长度即可。</li>\n<li>格式化json的方式多种多样，像jackson这样成熟的json处理框架中提供了大量的配置参数允许用户以所想要的方式非常灵活的生成所需格式的json字符串。我们这里的实现不够灵活，性能也不够高效，仅仅是起到一个抛砖引玉的作用。</li>\n</ul>\n<h5 id=\"json-beauty示意图\">json beauty示意图</h5>\n<p><img alt=\"json_beauty_demo\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211200026283-104525624.png\" /></p>\n<h2 id=\"5-流式的json词法解析\">5. 流式的json词法解析</h2>\n<p>截止目前我们已经实现了json字符串的解析功能，但还存在两个严重的性能问题需要优化。</p>\n<ul>\n<li>首先是目前的词法分析器是一次性的解析出所有的token后，再交给语法分析去解析的。而这存在一个隐患，因为很多时候我们实际解析的并不总是一个合法的json字符串。<br />\n如果一个非常长的不合法的json字符串，在词法分析阶段看不出任何的问题(比如在合法的以<code>{</code>开头的 json字符串的前面误追加一个123)，而直到语法分析才发现存在语法错误，那么词法分析阶段花费的计算资源就统统浪费了。</li>\n<li>如果能够在完整的词法分析处理的过程中提前发现语法错误就能避免这个问题。但实现这个功能不需要将词法分析和语法分析的功能耦合在一起，而是将词法分析器改造成按需加载的流式解析即可。<br />\n流式的词法分析能够在语法解析器需要读取token时才触发词法分析，并且一次可以只按需的完整解析出一个完整的token交给parser。</li>\n<li>有了流式的词法分析，像上面举得例子，在合法的非常长的json字符串的前面误加一个123的场景，便能够很早的就发现语法错误，结束解析过程。</li>\n</ul>\n<h5 id=\"流式的词法分析解析实现\">流式的词法分析解析实现</h5>\n<pre><code class=\"language-java\">public class StreamJsonLexer extends AbstractJsonLexer{\n\n    public StreamJsonLexer(String jsonString) {\n        super(jsonString);\n    }\n\n    public JsonToken doLex(){\n        if(doLexContext.currentIndex &gt;= jsonStringArray.length){\n            return new JsonToken(JsonTokenTypeEnum.EOF);\n        }\n\n        while(true) {\n            char ch = jsonStringArray[doLexContext.currentIndex];\n\n            // 每一次尝试解析一个完整的token前，都是状态0\n            switch (ch) {\n                case '{':\n                    doLexContext.currentIndex++;\n                    return new JsonToken(JsonTokenTypeEnum.LEFT_BRACE);\n                case '}':\n                    doLexContext.currentIndex++;\n                    return new JsonToken(JsonTokenTypeEnum.RIGHT_BRACE);\n                case '[':\n                    doLexContext.currentIndex++;\n                    return new JsonToken(JsonTokenTypeEnum.LEFT_BRACKET);\n                case ']':\n                    doLexContext.currentIndex++;\n                    return new JsonToken(JsonTokenTypeEnum.RIGHT_BRACKET);\n                case ',':\n                    doLexContext.currentIndex++;\n                    return new JsonToken(JsonTokenTypeEnum.COMMA);\n                case ':':\n                    doLexContext.currentIndex++;\n                    return new JsonToken(JsonTokenTypeEnum.COLON);\n                case '\"':\n                    return parseString(jsonStringArray, doLexContext);\n                case 't':\n                    // 尝试解析true关键字\n                    return parseTrueKeyword(jsonStringArray, doLexContext);\n                case 'f':\n                    // 尝试解析false关键字\n                    return parseFalseKeyword(jsonStringArray, doLexContext);\n                case 'n':\n                    // 尝试解析null关键字\n                    return parseNullKeyword(jsonStringArray, doLexContext);\n                default:\n                    // 走其它case\n                    break;\n            }\n\n            // 其它case\n            if (CommonStringUtil.is0_9(ch) || ch == '-') {\n                // number解析\n                return parseNumber(jsonStringArray, doLexContext);\n            } else if (CommonStringUtil.isWhitespace(ch)) {\n                // whiteSpace 直接跳过\n                doLexContext.currentIndex++;\n            } else{\n                throw new MuJsonParserException(\"unexpected character: \" + ch + \",charIndex=\" + doLexContext.currentIndex);\n            }\n        }\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">public class StreamJsonTokenReader implements JsonTokenReader {\n\n    private int currentIndex;\n    private final StreamJsonLexer streamJsonLexer;\n\n    private JsonToken peekToken;\n    private boolean hasNextToken;\n\n    public StreamJsonTokenReader(String jsonString) {\n        this.currentIndex = 0;\n        this.hasNextToken = true;\n        this.streamJsonLexer = new StreamJsonLexer(jsonString);\n    }\n\n    @Override\n    public boolean hasNextToken() {\n        return hasNextToken;\n    }\n\n    @Override\n    public JsonToken nextToken() {\n        JsonToken nextToken = getNextToken();\n        if(nextToken.getType() == JsonTokenTypeEnum.EOF){\n            hasNextToken = false;\n        }\n\n        currentIndex++;\n        return nextToken;\n    }\n\n    private JsonToken getNextToken() {\n        if(peekToken != null){\n            JsonToken nextToken = peekToken;\n            this.peekToken = null;\n            return nextToken;\n        }\n\n        return streamJsonLexer.doLex();\n    }\n\n    @Override\n    public JsonToken peek() {\n        if(peekToken == null) {\n            peekToken = streamJsonLexer.doLex();\n        }\n\n        return peekToken;\n    }\n\n    @Override\n    public int currentIndex() {\n        return currentIndex;\n    }\n}\n</code></pre>\n<h5 id=\"_-18\"></h5>\n<ul>\n<li>流式的词法解析器StreamJsonLexer的核心工作原理与之前已经实现的静态的StaticJsonLexer别无二致，其底层依赖的代码都是相同的。<br />\n最大的区别在于解析出一个完整的token后，在维护当前字符流下标的同时提前终止了后续的词法分析。在StreamJsonTokenReader调用nextToken时，才会按需的惰性解析新的token并返回。</li>\n<li>流式的词法解析毫无疑问是性能更好的，主流的json解析器也都是流式的解析。但静态的词法解析更容易理解，也更容易调试，所以在一开始介绍词法分析原理时，我们先实现了静态的词法分析，将其作为基础，略微的改造后便实现了流式的词法解析。</li>\n</ul>\n<h2 id=\"6-基于堆栈实现的json语法解析\">6. 基于堆栈实现的json语法解析</h2>\n<p>第二个性能问题则是基于递归实现的json语法解析器受限于较小的线程栈空间，无法处理嵌套层级非常深的json串。</p>\n<ul>\n<li>我们知道，一个普通的java进程通常都含有大量的线程，因此给每个线程分配的线程栈通常都比较小，比如1m。而递归实现的语法解析器，在每深入一个层次的json子树时便会向栈上压入一些局部变量，当极端情况下要解析的json串层次过深时，则会出现StackOverflowError，导致解析失败。</li>\n<li>而内存的堆通常都是以GB为单位的，因此如果把递归中隐式压栈的解析逻辑转换为等价的显式基于内存堆的压栈，则可以很好的解决线程栈过小无法处理大深度json串的问题了。</li>\n</ul>\n<h5 id=\"基于堆栈的语法解析状态自动机示意图\">基于堆栈的语法解析状态自动机示意图</h5>\n<p><img alt=\"stack_base_json_parser_state_machine\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211200035364-62927704.png\" /></p>\n<ul>\n<li>为了尽可能的将状态转移与递归实现的逻辑保持一致，堆栈的状态自动机依然冗余了两个状态(obj-0和arr-0)。</li>\n<li>可以看到，基于堆栈的状态自动机会在array与object的解析状态中互相转移，相当于将之前递归实现的各个状态自动机的子状态图合并为了一个大而全的状态自动机。</li>\n<li>同时，由于还涉及了手动模拟的入栈与出栈处理(obj-2，obj-4，arr-1，arr-2)，因此整体的复杂度比起递归实现要高出一个量级。</li>\n</ul>\n<h5 id=\"json根节点解析状态自动机实现源码\">json根节点解析状态自动机实现源码</h5>\n<pre><code class=\"language-java\">/**\n * 基于堆栈的，非递归的json语法解析器\n * */\npublic class StackBaseJsonParser extends JsonParser {\n\n    private final JsonParseStack parseStack = new JsonParseStack();\n\n    private StackBaseJsonParserStatusEnum currentStatus;\n\n    public StackBaseJsonParser(JsonTokenReader tokenReader) {\n        super(tokenReader);\n\n        this.currentStatus = StackBaseJsonParserStatusEnum.START_PARSE;\n    }\n\n    private void accept(){\n        jsonTokenReader.nextToken();\n    }\n\n    @Override\n    public JsonElement doParse() {\n        while(jsonTokenReader.hasNextToken()){\n            JsonToken token = jsonTokenReader.peek();\n\n            if(currentStatus == StackBaseJsonParserStatusEnum.END_PARSE){\n                break;\n            }\n\n            switch (currentStatus){\n                case START_PARSE:\n                    processInStartParse(token);\n                    break;\n                case PARSE_OBJECT_0:\n                    processInParseObject0(token);\n                    break;\n                case PARSE_OBJECT_1:\n                    processInParseObject1(token);\n                    break;\n                case PARSE_OBJECT_2:\n                    processInParseObject2(token);\n                    break;\n                case PARSE_OBJECT_3:\n                    processInParseObject3(token);\n                    break;\n                case PARSE_OBJECT_4:\n                    processInParseObject4(token);\n                    break;\n                case PARSE_OBJECT_5:\n                    processInParseObject5(token);\n                    break;\n                case PARSE_OBJECT_6:\n                    processInParseObject6(token);\n                    break;\n                case PARSE_ARR_0:\n                    processInParseArr0(token);\n                    break;\n                case PARSE_ARR_1:\n                    processInParseArr1(token);\n                    break;\n                case PARSE_ARR_2:\n                    processInParseArr2(token);\n                    break;\n                case PARSE_ARR_3:\n                    processInParseArr3(token);\n                    break;\n                default:\n                    throw new MuJsonParserException(\"Unexpected currentStatus: \" + currentStatus);\n            }\n        }\n\n        // 如果json字符串是合法的，那么最后栈顶必然是有且唯一的一个JsonElement类型的对象\n        if(this.parseStack.size() != 1){\n            throw new MuJsonParserException(\"after parse，stack element size &gt; 1! stack=\" + this.parseStack);\n        }\n\n        JsonParseStackValue object = this.parseStack.pop();\n        return (JsonElement) object.getValue();\n    }\n\n    private void processInStartParse(JsonToken token){\n        if (token.getType() == JsonTokenTypeEnum.LEFT_BRACE) {\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_0;\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_OBJECT,new JsonObject()));\n            return;\n        }\n\n        if (token.getType() == JsonTokenTypeEnum.LEFT_BRACKET) {\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_0;\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_ARRAY,new JsonArray()));\n            return;\n        }\n\n        if (token.getType().isPrimitiveValue()) {\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.END_PARSE;\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_PRIMITIVE,new JsonPrimitiveStr(token.getContent())));\n            return;\n        }\n\n        // 第一个token，不属于json规则的f(1)集合\n        throw new MuJsonParserException(\"unexpected start json token! token=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseObject0(JsonToken token){\n        if(token.getType() != JsonTokenTypeEnum.LEFT_BRACE){\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n\n        accept();\n\n        this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_1;\n    }\n\n    private void processInParseObject1(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.RIGHT_BRACE){\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_2;\n            return;\n        }\n\n        if(token.getType() == JsonTokenTypeEnum.STRING){\n            // 把key先压入栈中，然后等构造kv对时弹出\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_KEY,token));\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_3;\n            return;\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseObject2(JsonToken token){\n        // 遇到'}'才会进来\n        if(token.getType() != JsonTokenTypeEnum.RIGHT_BRACE){\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }else{\n            accept();\n        }\n\n        // 当前栈顶必定是JsonObject，先将其弹出，然后看栈顶的元素类型判断\n        JsonParseStackValue currentJsonObjectStackValue = this.parseStack.popAndCheck(JsonParseStackValueTypeEnum.JSON_OBJECT);\n        if(this.parseStack.isEmpty()){\n            // 说明是root的JsonObject解析完了，再推回去直接返回\n            this.parseStack.push(currentJsonObjectStackValue);\n            this.currentStatus = StackBaseJsonParserStatusEnum.END_PARSE;\n            return;\n        }\n\n        JsonObject currentJsonObject = (JsonObject) currentJsonObjectStackValue.getValue();\n\n        JsonParseStackValueTypeEnum topObjType = this.parseStack.peekTopType();\n\n        if(topObjType == JsonParseStackValueTypeEnum.JSON_KEY){\n            // 如果是json_key，说明是当前jsonObject是父object的一个k/v项中的value。\n            JsonParseStackValue keyStackValue = this.parseStack.popAndCheck(JsonParseStackValueTypeEnum.JSON_KEY);\n            JsonToken keyJsonToken = (JsonToken) keyStackValue.getValue();\n            JsonParseStackValue parentObject = this.parseStack.peekAndCheck(JsonParseStackValueTypeEnum.JSON_OBJECT);\n\n            // 将当前k/v项附加在父object上\n            ((JsonObject)parentObject.getValue()).putKV(keyJsonToken.getContent(), currentJsonObject);\n\n            // 基于下一个token判断状态跳转\n            JsonToken nextJsonToken = this.jsonTokenReader.peek();\n            if(nextJsonToken.getType() == JsonTokenTypeEnum.COMMA){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_5;\n                return;\n            }else if (nextJsonToken.getType() == JsonTokenTypeEnum.RIGHT_BRACE){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_2;\n                return;\n            }else{\n                throw new MuJsonParserException(\"unexpected token! index=\" + (jsonTokenReader.currentIndex()+1));\n            }\n\n        }else if(topObjType == JsonParseStackValueTypeEnum.JSON_ARRAY){\n            // 说明当前jsonObject是jsonArray的一个元素\n\n            JsonParseStackValue parentArr = this.parseStack.peekAndCheck(JsonParseStackValueTypeEnum.JSON_ARRAY);\n            ((JsonArray)parentArr.getValue()).addElement(currentJsonObject);\n\n            // 基于下一个token判断状态跳转\n            JsonToken nextJsonToken = this.jsonTokenReader.peek();\n            if(nextJsonToken.getType() == JsonTokenTypeEnum.COMMA){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_3;\n                return;\n            }else if (nextJsonToken.getType() == JsonTokenTypeEnum.RIGHT_BRACKET){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_2;\n                return;\n            }else{\n                throw new MuJsonParserException(\"unexpected token! index=\" + (jsonTokenReader.currentIndex()+1));\n            }\n        }else{\n            // 别的情况都说明有问题，不是合法的json\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private void processInParseObject3(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.COLON){\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_4;\n            return;\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseObject4(JsonToken token){\n        // 嵌套的jsonObject结构\n        if(token.getType() == JsonTokenTypeEnum.LEFT_BRACE){\n            // 发现'{'，栈上推进一个JsonObject\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_OBJECT, new JsonObject()));\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_1;\n            return;\n        }\n\n        // 嵌套的jsonArray结构\n        if(token.getType() == JsonTokenTypeEnum.LEFT_BRACKET){\n            // 发现'['，栈上推进一个JsonArr\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_ARRAY, new JsonArray()));\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_1;\n            return;\n        }\n\n        // 基础类型的value\n        if(token.getType().isPrimitiveValue()){\n            JsonParseStackValue jsonKeyToken = this.parseStack.popAndCheck(JsonParseStackValueTypeEnum.JSON_KEY);\n\n            JsonToken keyToken  = (JsonToken) jsonKeyToken.getValue();\n            Assert.assertTrue(keyToken.getType() == JsonTokenTypeEnum.STRING,\"parse object keyToken not match!\");\n\n            // 获取栈顶的jsonObject对象，设置k/v\n            JsonParseStackValue topJsonObject = this.parseStack.peekAndCheck(JsonParseStackValueTypeEnum.JSON_OBJECT);\n\n            ((JsonObject) topJsonObject.getValue()).putKV(keyToken.getContent(), new JsonPrimitiveStr(token.getContent()));\n\n            accept();\n\n            // 基于下一个token判断状态跳转\n            JsonToken nextJsonToken = this.jsonTokenReader.peek();\n            if(nextJsonToken.getType() == JsonTokenTypeEnum.COMMA){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_5;\n                return;\n            }else if (nextJsonToken.getType() == JsonTokenTypeEnum.RIGHT_BRACE){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_2;\n                return;\n            }else{\n                throw new MuJsonParserException(\"unexpected token! index=\" + (jsonTokenReader.currentIndex()+1));\n            }\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseObject5(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.COMMA){\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_6;\n            return;\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseObject6(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.STRING){\n            // 把key先压入栈中，然后等构造kv对时弹出\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_KEY,token));\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_3;\n            return;\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseArr0(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.LEFT_BRACKET){\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_1;\n            return;\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseArr1(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.RIGHT_BRACKET){\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_2;\n            return;\n        }\n\n        // 嵌套的jsonObject结构\n        if(token.getType() == JsonTokenTypeEnum.LEFT_BRACE){\n            // 发现'{'，栈上推进一个JsonObject\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_OBJECT, new JsonObject()));\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_1;\n            return;\n        }\n\n        // 嵌套的jsonArray结构\n        if(token.getType() == JsonTokenTypeEnum.LEFT_BRACKET){\n            // 发现'['，栈上推进一个JsonArr\n            this.parseStack.push(new JsonParseStackValue(JsonParseStackValueTypeEnum.JSON_ARRAY, new JsonArray()));\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_1;\n            return;\n        }\n\n        // 基础类型的value\n        if(token.getType().isPrimitiveValue()){\n            // 获取栈顶的jsonArr对象，添加一个元素\n            JsonParseStackValue topJsonArr = this.parseStack.peekAndCheck(JsonParseStackValueTypeEnum.JSON_ARRAY);\n\n            ((JsonArray) topJsonArr.getValue()).addElement(new JsonPrimitiveStr(token.getContent()));\n\n            accept();\n\n            // 基于下一个token判断状态跳转\n            JsonToken nextJsonToken = this.jsonTokenReader.peek();\n            if(nextJsonToken.getType() == JsonTokenTypeEnum.COMMA){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_3;\n                return;\n            }else if (nextJsonToken.getType() == JsonTokenTypeEnum.RIGHT_BRACKET){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_2;\n                return;\n            }else{\n                throw new MuJsonParserException(\"unexpected token! index=\" + (jsonTokenReader.currentIndex()+1));\n            }\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n\n    private void processInParseArr2(JsonToken token){\n        // 遇到']'才会进来\n        if(token.getType() != JsonTokenTypeEnum.RIGHT_BRACKET){\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }else{\n            accept();\n        }\n\n        // 当前栈顶必定是JsonArray，先将其弹出，然后看栈顶的元素类型判断\n        JsonParseStackValue currentJsonObjectStackValue = this.parseStack.popAndCheck(JsonParseStackValueTypeEnum.JSON_ARRAY);\n        if(this.parseStack.isEmpty()){\n            // 说明是root的JsonArr解析完了，再推回去直接返回\n            this.parseStack.push(currentJsonObjectStackValue);\n            this.currentStatus = StackBaseJsonParserStatusEnum.END_PARSE;\n            return;\n        }\n\n        JsonArray jsonArray = (JsonArray) currentJsonObjectStackValue.getValue();\n\n        JsonParseStackValueTypeEnum topObjType = this.parseStack.peekTopType();\n\n        if(topObjType == JsonParseStackValueTypeEnum.JSON_KEY){\n            // 如果是json_key，说明是当前jsonArray是父object的一个k/v项中的value。\n            JsonParseStackValue keyStackValue = this.parseStack.popAndCheck(JsonParseStackValueTypeEnum.JSON_KEY);\n            JsonToken keyJsonToken = (JsonToken) keyStackValue.getValue();\n\n            JsonParseStackValue parentObject = this.parseStack.peekAndCheck(JsonParseStackValueTypeEnum.JSON_OBJECT);\n\n            // 将当前k/v项附加在父object上\n            ((JsonObject)parentObject.getValue()).putKV(keyJsonToken.getContent(), jsonArray);\n\n            // 基于下一个token判断状态跳转\n            JsonToken nextJsonToken = this.jsonTokenReader.peek();\n            if(nextJsonToken.getType() == JsonTokenTypeEnum.COMMA){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_5;\n                return;\n            }else if (nextJsonToken.getType() == JsonTokenTypeEnum.RIGHT_BRACE){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_OBJECT_2;\n                return;\n            }else{\n                throw new MuJsonParserException(\"unexpected token! index=\" + (jsonTokenReader.currentIndex()+1));\n            }\n\n        }else if(topObjType == JsonParseStackValueTypeEnum.JSON_ARRAY){\n            // 说明当前jsonObject是jsonArray的一个元素\n\n            JsonParseStackValue parentArr = this.parseStack.peekAndCheck(JsonParseStackValueTypeEnum.JSON_ARRAY);\n            ((JsonArray)parentArr.getValue()).addElement(jsonArray);\n\n            // 基于下一个token判断状态跳转\n            JsonToken nextJsonToken = this.jsonTokenReader.peek();\n            if(nextJsonToken.getType() == JsonTokenTypeEnum.COMMA){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_3;\n                return;\n            }else if (nextJsonToken.getType() == JsonTokenTypeEnum.RIGHT_BRACKET){\n                this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_2;\n                return;\n            }else{\n                throw new MuJsonParserException(\"unexpected token! index=\" + (jsonTokenReader.currentIndex()+1));\n            }\n        }else{\n            // 别的情况都说明有问题，不是合法的json\n            throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n        }\n    }\n\n    private void processInParseArr3(JsonToken token){\n        if(token.getType() == JsonTokenTypeEnum.COMMA){\n            accept();\n            this.currentStatus = StackBaseJsonParserStatusEnum.PARSE_ARR_1;\n            return;\n        }\n\n        throw new MuJsonParserException(\"unexpected token! index=\" + jsonTokenReader.currentIndex());\n    }\n}\n\n</code></pre>\n<h5 id=\"比较堆栈与递归实现性能差异的demo\">比较堆栈与递归实现性能差异的demo</h5>\n<p>我们可以很简单的构造出一个非常深嵌套层次的json串，即由连续N个“[”和连续N个“]”构成的json字符串。即根节点为数组，同时每个数组中都有且仅有一个子元素，子元素的类型依然是数组，依次类推。</p>\n<pre><code class=\"language-java\">public class TestHugeLevelJsonParse {\n\n    @Test\n    public void testHugeLevelJsonParse() {\n        int level = 3500;\n        String hugeLevelJson = TestUtil.buildHugeLevelJson(level);\n\n        // 3500层的深度，会StackOverflowError栈溢出\n        Error recursiveJsonParseEx = null;\n        try{\n            RecursiveJsonParser recursiveJsonParser = new RecursiveJsonParser(new StreamJsonTokenReader(hugeLevelJson));\n            JsonElement obj = recursiveJsonParser.doParse();\n        }catch (Error e){\n            recursiveJsonParseEx = e;\n        }\n\n        Assert.assertTrue(recursiveJsonParseEx instanceof StackOverflowError);\n        System.out.println(\"level = \" + level + \" recursiveJsonParseEx has StackOverflowError!\");\n\n        // jackson默认json深度为1000，超过了会报错\n        {\n            try {\n                Object obj = JackSonUtil.string2Obj(hugeLevelJson, Object.class);\n            }catch (Exception e){\n                // 会报错\n                System.out.println(\"jackson parse hugeLevelJson error!   \" + e.getCause().getMessage());\n            }\n        }\n\n        // 基于堆栈的能正确的解析出来，不会StackOverflowError栈溢出\n        {\n            StackBaseJsonParser stackBaseJsonParser = new StackBaseJsonParser(new StreamJsonTokenReader(hugeLevelJson));\n            JsonElement obj = stackBaseJsonParser.doParse();\n            int arrayLevel = TestUtil.getSpecialJsonArrayLevel(obj);\n            Assert.assertEquals(arrayLevel, level - 1);\n            System.out.println(\"stackBaseJsonParser parse，arrayLevel=\" + arrayLevel);\n        }\n    }\n}\n</code></pre>\n<p><img alt=\"test_huge_level_json_parse\" src=\"https://img2024.cnblogs.com/blog/1506329/202602/1506329-20260211200045678-964632399.png\" /></p>\n<h5 id=\"递归-vs-堆栈解析的取舍\">递归 vs 堆栈解析的取舍</h5>\n<ul>\n<li>基于递归的json语法解析器实现简单，思路更直观，但受限于线程栈大小，在极深层级下会出现StackOverflow。</li>\n<li>基于堆栈的json语法解析器状态机更庞大，实现起来更复杂，但将调用栈搬到堆上之后，能处理极深层级的json（只要堆内存足够）。</li>\n<li>Jackson等成熟的三方库即使同样基于堆栈实现，通常也会设置一个合理的深度上限，避免恶意或异常的json导致系统资源耗尽。</li>\n</ul>\n<h2 id=\"总结\">总结</h2>\n<p>到这里，我们已经如开头所说的那般，一步一步的从零开始实现了一个简单的json解析器。<br />\n虽然网络上已经有着大量关于json解析器实现原理的博客，甚至利用ai都能帮你实现的大差不差。但是纸上得来终觉浅，绝知此事要躬行，想要更好的学习编译原理，去理解乃至实现更复杂的编译器、解释器，通过自己动手去体会那些晦涩抽象的原理也许是一种效率较低但长远看受益无穷的学习方式。</p>\n<h5 id=\"_-19\"></h5>\n<p>博客中展示的完整代码在我的github上：<a href=\"https://github.com/1399852153/MySimpleJsonParser\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/1399852153/MySimpleJsonParser</a> (main分支)。<br />\n希望能够帮助到对json解析或是编译原理感兴趣的读者，内容如有错误，还请多多指教。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n\t<div class=\"postDesc\">posted on \n<span id=\"post-date\">2026-02-11 20:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xiaoxiongcanguan\">小熊餐馆</a>&nbsp;\n阅读(<span id=\"post_view_count\">97</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "类型擦除与部分异步编程",
      "link": "https://www.cnblogs.com/suiyuan129/p/19605836",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/suiyuan129/p/19605836\" id=\"cb_post_title_url\" title=\"发布于 2026-02-11 20:16\">\n    <span>类型擦除与部分异步编程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"类型擦除与部分异步编程-消除差别统一使用\">类型擦除与部分异步编程: 消除差别，统一使用</h1>\n<p>C++ 中类型擦除最典型的实现思路分为两类——模板（编译期擦除）与多态（运行时擦除），这两种方式大家都比较熟悉。而标准库为我们封装了更易用的类型擦除工具，核心包括 <code>std::function</code>、<code>std::any</code>、<code>std::span</code> 和 <code>std::variant</code>，它们在不同场景下帮我们“消除类型差别，实现统一使用”；同时，类型擦除也是异步编程的核心基础，<code>std::function</code> 搭配相关组件可实现任意异步任务的统一调度，这也是我们将两者结合讲解的核心原因。</p>\n<h2 id=\"1-stdfunction可调用对象的统一调用接口\">1. std::function：可调用对象的“统一调用接口”</h2>\n<p><code>std::function</code> 是针对<strong>可调用对象</strong>的类型擦除工具，其底层实现核心是「抽象基类 + 模板子类」的多态模式，也是运行时类型擦除的典型应用：</p>\n<ul>\n<li>抽象基类：定义了与“函数签名”完全匹配的纯虚调用接口（比如 <code>virtual Ret call(Args...) = 0</code>），作为统一调用的基准；</li>\n<li>模板子类：存储具体的可调用对象（函数、lambda、仿函数、<code>std::bind</code> 结果等），并重写抽象基类的 <code>call</code> 方法，适配具体对象的调用逻辑。</li>\n</ul>\n<p>正因为 <code>std::function</code> 是通过调用<strong>抽象基类的统一接口</strong>，间接呼叫存入模板子类中的具体函数，所以我们<strong>必须提前明确告知 <code>std::function</code> 完整的函数签名（返回值类型、参数类型、参数个数）</strong> —— 这是抽象基类定义统一调用接口的前提，只有签名一致，所有被擦除类型的可调用对象，才能通过抽象基类的接口被正确调用。也正因运行时的多态派发（通过抽象基类指针调用子类的 <code>call</code> 方法），<code>std::function</code> 会产生一定的运行时开销。</p>\n<h3 id=\"测试代码stdfunction-统一调用不同可调用对象\">测试代码：std::function 统一调用不同可调用对象</h3>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;functional&gt;\n#include &lt;string&gt;\n\n// 普通函数\nint add(int a, int b) { return a + b; }\n\n// 仿函数\nstruct Multiply {\n    int operator()(int a, int b) { return a * b; }\n};\n\nint main() {\n    // 定义函数签名：int(int, int)\n    std::function&lt;int(int, int)&gt; func;\n\n    // 存储普通函数\n    func = add;\n    std::cout &lt;&lt; \"add(3,4) = \" &lt;&lt; func(3, 4) &lt;&lt; std::endl; // 输出7\n\n    // 存储lambda表达式\n    func = [](int a, int b) { return a - b; };\n    std::cout &lt;&lt; \"sub(3,4) = \" &lt;&lt; func(3, 4) &lt;&lt; std::endl; // 输出-1\n\n    // 存储仿函数\n    func = Multiply{};\n    std::cout &lt;&lt; \"mul(3,4) = \" &lt;&lt; func(3, 4) &lt;&lt; std::endl; // 输出12\n\n    return 0;\n}\n</code></pre>\n<p>代码说明：无论存储的是普通函数、lambda还是仿函数，只要函数签名匹配 <code>int(int, int)</code>，就能通过 <code>std::function</code> 统一调用，体现了类型擦除“消除差别，统一使用”的核心。</p>\n<h2 id=\"2-stdany--stdvariant数据存储的类型擦除双雄\">2. std::any &amp; std::variant：数据存储的“类型擦除双雄”</h2>\n<p>两者均用于实现数据存储的类型擦除，但定位互补，<code>std::variant</code> 核心是弥补 <code>std::any</code> 的繁琐与低效问题。</p>\n<h3 id=\"stdany无约束的全类型擦除\">std::any：无约束的全类型擦除</h3>\n<p><code>std::any</code> 是经典的“全类型擦除”工具，它完全擦除编译期的类型信息，仅保留“数据本身 + 运行时类型ID（<code>std::type_info</code>）”，相当于一个“带类型标签的万能盒子”，能存储任意类型的数据。<br />\n和 <code>std::function</code> 类似，<code>std::any</code> 需在运行时通过类型ID识别内部数据类型，因此存在运行时开销；此外，<code>std::any</code> 对大类型会进行堆内存分配，进一步增加轻微的内存开销。其最大的特点是自由无约束，但这份自由也带来了操作繁琐的问题——使用时必须手动通过 <code>typeid</code> 检查类型，再用 <code>any_cast</code> 提取数据，且类型错误只能在运行时暴露（抛出 <code>std::bad_any_cast</code> 异常）。</p>\n<h3 id=\"stdvariant有限制的高效类型擦除\">std::variant：有限制的高效类型擦除</h3>\n<p><code>std::variant</code> 是为解决 <code>std::any</code> 的痛点而生，它通过<strong>编译期提前声明可存储的类型范围</strong>，实现了更高效、更安全的类型擦除，属于“有限类型擦除”：</p>\n<ul>\n<li>编译期兜底：写错类型（比如用 <code>std::get</code> 提取非活跃类型）会被编译器及时提醒，更早暴露问题，避免运行时异常难以调试；</li>\n<li>统一便捷处理：无需手写一堆 <code>if (typeid)</code> 判断分支，通过 <code>std::visit</code> 就能批量处理所有预定义类型，代码更简洁、不易漏分支；</li>\n<li>零堆开销：<code>std::variant</code> 的大小在编译期确定（等于所有预定义类型中最大类型的尺寸 + 类型标签尺寸），所有数据均存储在栈上，无堆分配开销；</li>\n<li>安全提取：提供 <code>std::holds_alternative</code>（判断是否为指定类型）、<code>std::get_if</code>（安全提取，不匹配返回 <code>nullptr</code>）等工具，无需捕获异常，类型检查和数据提取更直观、安全。</li>\n</ul>\n<p>简单来说，<code>std::any</code> 是“无拘无束但全靠手动”，<code>std::variant</code> 是“有限制但编译器帮你兜底”，这份限制恰恰是它简化操作、提升效率的核心。</p>\n<h3 id=\"测试代码stdany-与-stdvariant-对比\">测试代码：std::any 与 std::variant 对比</h3>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;any&gt;\n#include &lt;variant&gt;\n#include &lt;string&gt;\n#include &lt;typeinfo&gt;\n\n// 处理std::any\nvoid process_any(std::any val) {\n    if (val.type() == typeid(int)) {\n        std::cout &lt;&lt; \"any存储int：\" &lt;&lt; std::any_cast&lt;int&gt;(val) &lt;&lt; std::endl;\n    } else if (val.type() == typeid(std::string)) {\n        std::cout &lt;&lt; \"any存储string：\" &lt;&lt; std::any_cast&lt;std::string&gt;(val) &lt;&lt; std::endl;\n    } else if (val.type() == typeid(double)) {\n        std::cout &lt;&lt; \"any存储double：\" &lt;&lt; std::any_cast&lt;double&gt;(val) &lt;&lt; std::endl;\n    }\n}\n\n// 处理std::variant\nusing MyVariant = std::variant&lt;int, std::string, double&gt;;\nvoid process_variant(const MyVariant&amp; val) {\n    // 无需手写if(typeid)，std::visit批量处理\n    std::visit([](const auto&amp; v) {\n        using T = std::decay_t&lt;decltype(v)&gt;;\n        if constexpr (std::is_same_v&lt;T, int&gt;) {\n            std::cout &lt;&lt; \"variant存储int：\" &lt;&lt; v &lt;&lt; std::endl;\n        } else if constexpr (std::is_same_v&lt;T, std::string&gt;) {\n            std::cout &lt;&lt; \"variant存储string：\" &lt;&lt; v &lt;&lt; std::endl;\n        } else if constexpr (std::is_same_v&lt;T, double&gt;) {\n            std::cout &lt;&lt; \"variant存储double：\" &lt;&lt; v &lt;&lt; std::endl;\n        }\n    }, val);\n}\n\nint main() {\n    // std::any测试\n    std::any a = 10;\n    process_any(a); // 输出any存储int：10\n    a = std::string(\"hello any\");\n    process_any(a); // 输出any存储string：hello any\n    a = 3.14;\n    process_any(a); // 输出any存储double：3.14\n\n    // std::variant测试\n    MyVariant v = 20;\n    process_variant(v); // 输出variant存储int：20\n    v = std::string(\"hello variant\");\n    process_variant(v); // 输出variant存储string：hello variant\n    v = 6.28;\n    process_variant(v); // 输出variant存储double：6.28\n\n    // std::variant安全提取示例\n    if (std::holds_alternative&lt;double&gt;(v)) {\n        auto p = std::get_if&lt;double&gt;(&amp;v);\n        std::cout &lt;&lt; \"安全提取double：\" &lt;&lt; *p &lt;&lt; std::endl; // 输出6.28\n    }\n\n    return 0;\n}\n</code></pre>\n<p>代码说明：</p>\n<ul>\n<li><code>std::any</code> 需手动写 <code>if (typeid)</code> 分支，新增类型时需手动扩展；</li>\n<li><code>std::variant</code> 借助 <code>std::visit</code> 批量处理所有预定义类型，代码更简洁，且 <code>holds_alternative</code>/<code>get_if</code> 让类型检查/提取更安全。</li>\n</ul>\n<h2 id=\"3-stdspan连续容器的零开销类型擦除\">3. std::span：连续容器的“零开销类型擦除”</h2>\n<p><code>std::span</code> 是针对<strong>连续内存容器</strong>的“特制类型擦除工具”，专门用于消除不同连续容器的类型差异，实现统一访问：<br />\n它会擦除 <code>std::vector</code>、<code>std::array</code>、C风格数组等连续容器的具体类型，仅保留“起始指针 + 元素长度”两个核心特征，相当于给所有连续内存容器提供了一个统一的“视图”。<br />\n<code>std::span</code> 的核心优势是<strong>零运行时开销</strong>——类型擦除在编译期完成，无需运行时额外计算或内存分配；但也有明确限制：仅支持连续内存容器，无法处理 <code>std::list</code> 等非连续内存容器。</p>\n<h3 id=\"测试代码stdspan-统一访问不同连续容器\">测试代码：std::span 统一访问不同连续容器</h3>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;span&gt;\n#include &lt;vector&gt;\n#include &lt;array&gt;\n\n// 统一处理所有连续int容器\nvoid print_span(std::span&lt;int&gt; sp) {\n    std::cout &lt;&lt; \"容器长度：\" &lt;&lt; sp.size() &lt;&lt; \"，内容：\";\n    for (int val : sp) {\n        std::cout &lt;&lt; val &lt;&lt; \" \";\n    }\n    std::cout &lt;&lt; std::endl;\n}\n\nint main() {\n    // std::vector\n    std::vector&lt;int&gt; vec = {1, 2, 3};\n    print_span(vec); // 输出容器长度：3，内容：1 2 3\n\n    // std::array\n    std::array&lt;int, 4&gt; arr = {4, 5, 6, 7};\n    print_span(arr); // 输出容器长度：4，内容：4 5 6 7\n\n    // C风格数组\n    int c_arr[] = {8, 9, 10};\n    print_span(c_arr); // 输出容器长度：3，内容：8 9 10\n\n    // 切片访问（span的额外优势）\n    print_span(std::span(vec).subspan(1, 2)); // 输出容器长度：2，内容：2 3\n\n    return 0;\n}\n</code></pre>\n<p>代码说明：<code>print_span</code> 函数无需关心传入的是 <code>vector</code>、<code>array</code> 还是C数组，<code>std::span</code> 擦除了容器类型差异，实现统一访问，且无任何运行时开销。</p>\n<h2 id=\"4-类型擦除在异步编程中的核心应用\">4. 类型擦除在异步编程中的核心应用</h2>\n<p>为什么要将类型擦除与异步编程结合？因为 <code>std::function</code> 的类型擦除能力，是异步任务“统一管理”的核心，它常搭配 lambda 表达式、<code>std::packaged_task</code>、<code>std::bind</code> 实现任意异步任务的统一调度，核心逻辑是“擦除任务差异，统一管理，按需获取结果”：</p>\n<ol>\n<li>用 <code>std::bind</code> 将任务参数与可调用对象绑定，擦除不同任务的参数类型差异，让有参任务适配统一的调用形式；</li>\n<li>将绑定后的任务装入 <code>std::packaged_task</code>，通过 <code>std::packaged_task</code> 内置的 <code>std::promise</code>，获取 <code>std::future</code> 对象（用于后续接收异步任务的返回值）—— 此时任务的返回值类型未被擦除；</li>\n<li>通过 lambda 表达式封装 <code>std::packaged_task</code> 的执行逻辑，将“有返回值的任务”包装成无返回值的 <code>void()</code> 类型，从而擦除返回值差异；</li>\n<li>最终，所有异步任务均可统一装进 <code>std::function&lt;void()&gt;</code> 中进行管理，任务的返回值则在异步执行完成后，自动存入 <code>std::packaged_task</code> 内部的 <code>std::promise</code>，我们通过之前获取的 <code>std::future</code> 就能按需获取异步结果，实现“任务统一管理 + 结果按需获取”。</li>\n</ol>\n<h3 id=\"测试代码类型擦除实现异步任务统一管理\">测试代码：类型擦除实现异步任务统一管理</h3>\n<pre><code class=\"language-cpp\">#include &lt;iostream&gt;\n#include &lt;functional&gt;\n#include &lt;future&gt;\n#include &lt;thread&gt;\n#include &lt;queue&gt;\n#include &lt;mutex&gt;\n#include &lt;condition_variable&gt;\n#include &lt;string&gt;\n\n// 全局任务队列：存储统一的无返回值任务\nstd::queue&lt;std::function&lt;void()&gt;&gt; task_queue;\nstd::mutex mtx;\nstd::condition_variable cv;\nbool stop = false;\n\n// 工作线程：消费任务队列\nvoid worker() {\n    while (!stop) {\n        std::function&lt;void()&gt; task;\n        // 加锁取任务\n        {\n            std::unique_lock&lt;std::mutex&gt; lock(mtx);\n            cv.wait(lock, []() { return stop || !task_queue.empty(); });\n            if (stop &amp;&amp; task_queue.empty()) return;\n            task = std::move(task_queue.front());\n            task_queue.pop();\n        }\n        // 执行任务\n        task();\n    }\n}\n\n// 提交任务模板：擦除参数/返回值差异，统一存入队列\ntemplate&lt;typename F, typename... Args&gt;\nauto submit_task(F&amp;&amp; f, Args&amp;&amp;... args) -&gt; std::future&lt;decltype(f(args...))&gt; {\n    // 绑定参数，擦除参数差异\n    auto bound_task = std::bind(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...);\n    // 定义packaged_task，保留返回值类型\n    using RetType = decltype(f(args...));\n    std::packaged_task&lt;RetType()&gt; pt(std::move(bound_task));\n    // 获取future用于接收结果\n    std::future&lt;RetType&gt; fut = pt.get_future();\n    // 封装成void()任务，擦除返回值差异\n    std::function&lt;void()&gt; wrapper = [pt = std::move(pt)]() mutable {\n        pt(); // 执行packaged_task，结果存入promise\n    };\n    // 存入任务队列\n    {\n        std::lock_guard&lt;std::mutex&gt; lock(mtx);\n        task_queue.push(std::move(wrapper));\n    }\n    cv.notify_one(); // 唤醒工作线程\n    return fut;\n}\n\n// 测试任务1：有参有返回值（计算平方）\nint square(int x) {\n    std::this_thread::sleep_for(std::chrono::seconds(1));\n    return x * x;\n}\n\n// 测试任务2：有参有返回值（拼接字符串）\nstd::string concat(const std::string&amp; a, const std::string&amp; b) {\n    std::this_thread::sleep_for(std::chrono::seconds(1));\n    return a + b;\n}\n\nint main() {\n    // 启动工作线程\n    std::thread t(worker);\n\n    // 提交任务1：计算5的平方\n    auto fut1 = submit_task(square, 5);\n    // 提交任务2：拼接字符串\n    auto fut2 = submit_task(concat, \"hello \", \"async\");\n\n    // 主线程等待结果\n    std::cout &lt;&lt; \"等待异步任务结果...\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"5的平方：\" &lt;&lt; fut1.get() &lt;&lt; std::endl; // 输出25\n    std::cout &lt;&lt; \"字符串拼接：\" &lt;&lt; fut2.get() &lt;&lt; std::endl; // 输出hello async\n\n    // 停止工作线程\n    stop = true;\n    cv.notify_one();\n    t.join();\n\n    return 0;\n}\n</code></pre>\n<p>代码说明：</p>\n<ul>\n<li><code>square</code> 和 <code>concat</code> 是不同签名的任务（参数/返回值均不同）；</li>\n<li>通过 <code>std::bind</code> 擦除参数差异，<code>std::packaged_task</code> 保留返回值并绑定 <code>future</code>，lambda 封装成 <code>void()</code> 擦除返回值差异；</li>\n<li>最终所有任务都能存入 <code>std::function&lt;void()&gt;</code> 队列，实现统一管理，体现了类型擦除在异步编程中的核心价值。</li>\n</ul>\n<h2 id=\"整体总结\">整体总结</h2>\n<p>标准库中的四种类型擦除工具，虽定位不同，但核心目标一致——<strong>消除类型差别，实现统一使用</strong>：</p>\n<ol>\n<li><code>std::function</code>：针对可调用对象，统一调用接口，依赖函数签名和多态实现，有运行时开销；</li>\n<li><code>std::any</code>：针对任意数据，全类型擦除，自由但繁琐、有运行时和堆内存开销；</li>\n<li><code>std::variant</code>：针对有限范围数据，弥补 <code>std::any</code> 不足，编译期兜底、高效便捷、零堆开销；</li>\n<li><code>std::span</code>：针对连续容器，零开销类型擦除，统一连续内存访问接口，仅支持连续容器。</li>\n</ol>\n<p>而类型擦除与异步编程的结合，核心是借助 <code>std::function</code> 的统一管理能力，搭配 lambda、<code>std::packaged_task</code>、<code>std::bind</code> 等组件，擦除不同异步任务的参数和返回值差异，实现任意异步任务的统一调度，这也是类型擦除在实际开发中最常用的场景之一。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-11 20:16</span>&nbsp;\n<a href=\"https://www.cnblogs.com/suiyuan129\">suiyuan129</a>&nbsp;\n阅读(<span id=\"post_view_count\">22</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "简易的分布式kv设计",
      "link": "https://www.cnblogs.com/jackjavacpp/p/19605754",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jackjavacpp/p/19605754\" id=\"cb_post_title_url\" title=\"发布于 2026-02-11 19:47\">\n    <span>简易的分布式kv设计</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"简易的分布式kv设计--一\">简易的分布式kv设计--(一)</h1>\n<p><strong>这篇文章目前只设计到集群启动，然后自动选主的功能。</strong></p>\n<p>地址：<a href=\"https://github.com/Jack-txf/easy-kv\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/Jack-txf/easy-kv</a></p>\n<p><strong>TIPS</strong>：此文章对应的分支版本是<strong>version0211</strong></p>\n<p>raft基础知识：<a href=\"https://mp.weixin.qq.com/s/DHO2CK87kI-clf4O96t5Cw\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/DHO2CK87kI-clf4O96t5Cw</a></p>\n<h1 id=\"1-前言\">1. 前言</h1>\n<p>在 Raft KV 系统中，每个节点（Node）都是对等的。一个典型的请求流向是： <code>Client</code> -&gt; <code>Leader Node</code> -&gt; <code>Raft 日志同步</code> -&gt; <code>大多数节点确认</code> -&gt; <code>应用到状态机 (KV Store)</code> -&gt; <code>返回 Client</code>。</p>\n<h1 id=\"2-设计步骤\">2. 设计步骤</h1>\n<p>Raft 核心组件包括：一致性结点模块，RPC 通信，日志模块。</p>\n<h2 id=\"21-日志\">2.1 日志</h2>\n<pre><code class=\"language-txt\">写日志 → 复制日志 → commit → apply 【leader应用顺序】\n\n细分一下的话就如下：\nClient\n   ↓\nLeader\n   ↓ append log (本地)\n   ↓\n发送 AppendEntries\n   ↓\nFollowers append log\n   ↓\n多数成功\n   ↓\nLeader commit\n   ↓\nLeader apply\n   ↓\n返回客户端成功\n   ↓\nLeader 下次心跳带 commitIndex\n   ↓\nFollowers apply\n</code></pre>\n<p>首先看一下，客户端发送一个请求，涉及到的大致东西有哪些：</p>\n<img src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194613207-412932482.png\" />\n<p>从后往前看，我们需要设计的就是如何写入日志文件，以及日志文件的格式该如何设计呢？此处我们就弄简单一点儿就好了</p>\n<table>\n<thead>\n<tr>\n<th>totalLength （int）</th>\n<th>term（long）</th>\n<th>index（long）</th>\n<th>commandLength（int）</th>\n<th>command（byte[]）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>整条log entry 长度</td>\n<td>Raft term</td>\n<td>日志 index</td>\n<td>命令长度</td>\n<td>真正命令，这个肯定是变长的</td>\n</tr>\n</tbody>\n</table>\n<p>totalLength = 8 (term) + 8 (index) + 4 (commandLength) + commandLength</p>\n<pre><code class=\"language-java\">public class LogEntry {\n    private final long term;\n    private final long index;\n    private final String command;\n    ....\n}\n</code></pre>\n<p>日志存储与管理</p>\n<pre><code class=\"language-java\">/**\n * @Description: 日志存储与管理\n * @Author: txf\n * @Date: 2026/2/9\n */\npublic class LogManager {\n    // 日志文件路径\n    private static final String LOG_FILE_PATH = \"easy_kv_log.dat\";\n    // 内存映射的分段大小（128MB，可根据内存调整）,这里先调整为两兆\n    private static final int MAPPED_SIZE = 2 * 1024 * 1024;\n    // 文件打开模式：rw = 读写\n    private static final String FILE_MODE = \"rw\";\n\n    private final File logFile;\n    private RandomAccessFile raf;\n    private FileChannel fileChannel;\n    // 当前映射的内存缓冲区\n    private MappedByteBuffer currentMappedBuffer;\n    // 当前映射段的起始偏移（文件偏移）\n    private long currentMappedOffset = 0;\n    // 当前写入的位置（相对于文件的总偏移）\n    private long writePosition = 0;\n\n    public LogManager() {\n        this.logFile = new File(LOG_FILE_PATH);\n        initFileChannel();\n        initMappedBuffer();\n        // 初始化时定位到文件末尾（继续追加写）\n        try {\n            this.writePosition = fileChannel.size();\n        } catch (IOException e) {\n            throw new RuntimeException(\"获取文件大小失败\", e);\n        }\n    }\n\n    /**\n     * 追加写入单条日志（核心高性能写入）\n     * @param term Raft任期\n     * @param index 日志索引\n     * @param command KV操作命令（如\"PUT key value\"）\n     */\n    public void appendLogEntry(long term, long index, String command) {\n        // 1. 准备命令字节数组\n        byte[] commandBytes = command.getBytes(StandardCharsets.UTF_8);\n        int commandLength = commandBytes.length;\n        // 2. 计算总长度\n        int totalLength = 4 + 8 + 8 + 4 + commandLength;\n\n        // 3. 准备直接缓冲区（堆外内存，避免拷贝）\n        ByteBuffer directBuffer = ByteBuffer.allocateDirect(totalLength);\n        // 按格式写入缓冲区 -- 这里是写入二进制的，文件内容我们人类就读不懂了\n        directBuffer.putInt(totalLength);\n        directBuffer.putLong(term);\n        directBuffer.putLong(index);\n        directBuffer.putInt(commandLength);\n        directBuffer.put(commandBytes);\n\n        // 这里是写入字符串的\n        // directBuffer.put((term + index + command).getBytes(StandardCharsets.UTF_8));\n\n        // 翻转缓冲区（从写模式转为读模式）\n        directBuffer.flip();\n        // 4. 写入到内存映射缓冲区（核心：零拷贝）\n        writeToMappedBuffer(directBuffer);        // 5. 更新全局写入位置\n        writePosition += totalLength;\n    }\n\n    /**\n     * 将缓冲区数据写入内存映射区（自动扩容映射段）\n     */\n    private void writeToMappedBuffer(ByteBuffer buffer) {\n        while (buffer.hasRemaining()) {\n            // 检查当前映射缓冲区是否有足够剩余空间\n            if (currentMappedBuffer.remaining() &lt; buffer.remaining()) {\n                // 先写入当前映射区的剩余空间\n                int remaining = currentMappedBuffer.remaining();\n                byte[] temp = new byte[remaining];\n                buffer.get(temp);\n                currentMappedBuffer.put(temp);\n                // 强制刷盘（将映射内存的数据同步到磁盘，可选：批量刷盘可提升性能）\n                currentMappedBuffer.force();\n                // 扩容映射段\n                initMappedBuffer();\n            } else {\n                // 直接写入映射缓冲区\n                currentMappedBuffer.put(buffer);\n            }\n        }\n    }\n\n    /**\n     * 读取指定索引的日志条目（高性能读取）\n     */\n    public LogEntry readLogEntry(long index) {\n        try {\n            // 使用FileChannel + 直接缓冲区读取\n            ByteBuffer directBuffer = ByteBuffer.allocateDirect(1024 * 1024); // 1MB直接缓冲区\n            long fileOffset = 0;\n            long fileSize = fileChannel.size();\n\n            while (fileOffset &lt; fileSize) {\n                // 重置缓冲区\n                directBuffer.clear();\n                // 从文件指定偏移读取数据到缓冲区\n                int readBytes = fileChannel.read(directBuffer, fileOffset);\n                if (readBytes == -1) break;\n                directBuffer.flip();\n\n                // 解析缓冲区中的日志条目\n                while (directBuffer.hasRemaining()) {\n                    // 检查剩余字节是否足够读取固定头部（4+8+8+4=24字节）\n                    if (directBuffer.remaining() &lt; 24) break;\n                    // 读取固定字段\n                    int totalLength = directBuffer.getInt();\n                    long term = directBuffer.getLong();\n                    long currentIndex = directBuffer.getLong();\n                    int commandLength = directBuffer.getInt();\n                    // 检查剩余字节是否足够读取command\n                    if (directBuffer.remaining() &lt; commandLength) {\n                        // 回退缓冲区position，下次继续解析\n                        directBuffer.position(directBuffer.position() - 24);\n                        break;\n                    }\n                    // 读取command\n                    byte[] commandBytes = new byte[commandLength];\n                    directBuffer.get(commandBytes);\n                    String command = new String(commandBytes, StandardCharsets.UTF_8);\n                    // 校验总长度\n                    int actualLength = 4 + 8 + 8 + 4 + commandLength;\n                    if (totalLength != actualLength) {\n                        throw new RuntimeException(\"日志文件损坏：总长度不匹配\");\n                    }\n                    // 找到目标索引则返回\n                    if (currentIndex == index) {\n                        return new LogEntry(term, index, command);\n                    }\n                    // 更新文件偏移\n                    fileOffset += totalLength;\n                }\n            }\n        } catch (IOException e) {\n            throw new RuntimeException(\"读取日志条目失败 [index=\" + index + \"]\", e);\n        }\n        return null;\n    }\n\n    /**\n     * 加载所有日志条目（节点启动时恢复）\n     */\n    public List&lt;LogEntry&gt; loadAllLogEntries() {\n        List&lt;LogEntry&gt; logEntries = new ArrayList&lt;&gt;();\n        try {\n            ByteBuffer directBuffer = ByteBuffer.allocateDirect(1024 * 1024);\n            long fileOffset = 0;\n            long fileSize = fileChannel.size();\n\n            while (fileOffset &lt; fileSize) {\n                directBuffer.clear();\n                int readBytes = fileChannel.read(directBuffer, fileOffset);\n                if (readBytes == -1) break;\n                directBuffer.flip();\n\n                while (directBuffer.hasRemaining()) {\n                    if (directBuffer.remaining() &lt; 24) break;\n\n                    int totalLength = directBuffer.getInt();\n                    long term = directBuffer.getLong();\n                    long index = directBuffer.getLong();\n                    int commandLength = directBuffer.getInt();\n\n                    if (directBuffer.remaining() &lt; commandLength) {\n                        directBuffer.position(directBuffer.position() - 24);\n                        break;\n                    }\n\n                    byte[] commandBytes = new byte[commandLength];\n                    directBuffer.get(commandBytes);\n                    String command = new String(commandBytes, StandardCharsets.UTF_8);\n\n                    int actualLength = 4 + 8 + 8 + 4 + commandLength;\n                    if (totalLength != actualLength) {\n                        throw new RuntimeException(\"日志文件损坏：总长度不匹配\");\n                    }\n\n                    logEntries.add(new LogEntry(term, index, command));\n                    fileOffset += totalLength;\n                }\n            }\n        } catch (IOException e) {\n            throw new RuntimeException(\"加载所有日志条目失败\", e);\n        }\n        return logEntries;\n    }\n\n    /**\n     * 强制刷盘（将映射内存的数据同步到磁盘）\n     */\n    public void forceFlush() {\n        if (currentMappedBuffer != null) {\n            currentMappedBuffer.force(); // 同步映射内存到磁盘\n        }\n        try {\n            fileChannel.force(true); // 强制刷盘（包含元数据）\n        } catch (IOException e) {\n            throw new RuntimeException(\"刷盘失败\", e);\n        }\n    }\n\n    /**\n     * 关闭资源（必须调用，否则会导致文件句柄泄漏）\n     */\n    public void close() {\n        try {\n            forceFlush();\n            if (fileChannel != null) {\n                fileChannel.close();\n            }\n            if (raf != null) {\n                raf.close();\n            }\n        } catch (IOException e) {\n            throw new RuntimeException(\"关闭资源失败\", e);\n        }\n    }\n    /**\n     * 初始化/扩容内存映射缓冲区\n     */\n    private void initMappedBuffer() {\n        try {\n            // 计算需要映射的起始位置和大小\n            long fileSize = fileChannel.size();\n            // 如果当前映射段已写满，或首次初始化，创建新的映射\n            if (currentMappedBuffer == null || writePosition &gt;= currentMappedOffset + MAPPED_SIZE) {\n                currentMappedOffset = (writePosition / MAPPED_SIZE) * MAPPED_SIZE;\n                // 映射文件的指定区间到内存（FileChannel.MapMode.READ_WRITE：读写模式）\n                currentMappedBuffer = fileChannel.map(\n                        FileChannel.MapMode.READ_WRITE,\n                        currentMappedOffset,\n                        MAPPED_SIZE\n                );\n                // 将缓冲区的position定位到当前写入位置相对于映射段的偏移\n                currentMappedBuffer.position((int) (writePosition - currentMappedOffset));\n            }\n        } catch (IOException e) {\n            throw new RuntimeException(\"初始化内存映射缓冲区失败\", e);\n        }\n    }\n\n    /**\n     * 初始化FileChannel（核心高性能通道）\n     */\n    private void initFileChannel() {\n        try {\n            // 不存在则创建文件\n            if (!logFile.exists()) {\n                boolean newFile = logFile.createNewFile();\n                if (!newFile) {\n                    throw new RuntimeException(\"创建文件失败\");\n                }\n            }\n            this.raf = new RandomAccessFile(logFile, FILE_MODE);\n            this.fileChannel = raf.getChannel();\n        } catch (IOException e) {\n            throw new RuntimeException(\"初始化FileChannel失败\", e);\n        }\n    }\n}\n</code></pre>\n<h2 id=\"22-服务端设计\">2.2 服务端设计</h2>\n<h3 id=\"221-消息设计\">2.2.1 消息设计</h3>\n<p>日志设计好了之后，接下来看服务端如何设计。我们使用的是netty框架，要求有netty基础。然后序列化协议采用的是protobuf，读者可以参考这篇文章：<a href=\"https://mp.weixin.qq.com/s/kg_-AMHRn_DzFbfBnkK4VQ\" rel=\"noopener nofollow\" target=\"_blank\">https://mp.weixin.qq.com/s/kg_-AMHRn_DzFbfBnkK4VQ</a> 这篇文章大致讲解了一下该序列化协议，并且也是采用netty整合的。根据proto文件生成类的命令如下，也可以用idea的插件自动生成。</p>\n<pre><code class=\"language-proto\">protoc  --proto_path=xxxx目录  --java_out=xxx目录  具体的proto文件\n</code></pre>\n<p>消息模板如下：</p>\n<pre><code class=\"language-proto\">syntax = \"proto3\";\noption java_outer_classname = \"KvRaftProto\"; // 生成的外层类名\noption java_multiple_files = false; // 生成多个独立的Java类（而非内部类）\n\n// ===================== 1. 通用消息封装体（核心） =====================\n// Netty传输时只传这个消息，通过type识别具体消息类型\nmessage RaftKvMessage {\n  // 消息类型枚举（覆盖所有交互场景）\n  enum MessageType {\n    UNKNOWN = 0; // 未知类型（兜底）\n    // 客户端 ↔ 节点：KV操作\n    KV_REQUEST = 1;    // 客户端发起KV请求（PUT/GET/DELETE）\n    KV_RESPONSE = 2;   // 节点响应客户端KV请求\n    // 节点 ↔ 节点：Raft共识\n    VOTE_REQUEST = 3;  // 选举请求（Candidate→Follower）\n    VOTE_RESPONSE = 4; // 选举响应（Follower→Candidate）\n    APPEND_ENTRIES_REQUEST = 5;  // 日志追加/心跳（Leader→Follower）\n    APPEND_ENTRIES_RESPONSE = 6; // 日志追加响应（Follower→Leader）\n  }\n\n  MessageType type = 1; // 消息类型（必传）\n  string node_id = 2;   // 发送方节点ID（用于识别节点）\n\n  // 具体消息体（根据type选择其中一个）\n  KvRequest kv_request = 3;\n  KvResponse kv_response = 4;\n  VoteRequest vote_request = 5;\n  VoteResponse vote_response = 6;\n  AppendEntriesRequest append_entries_request = 7;\n  AppendEntriesResponse append_entries_response = 8;\n}\n\n// ===================== 2. 客户端KV操作相关 =====================\n// 客户端发起的KV请求（PUT/GET/DELETE）\nmessage KvRequest {\n  enum OpType {\n    PUT = 0;    // 写入/更新\n    GET = 1;    // 读取\n    DELETE = 2; // 删除\n  }\n  OpType op_type = 1; // 操作类型（必传）\n  string key = 2;     // KV的key（必传）\n  string value = 3;   // KV的value（仅PUT时传）\n  // 可选：请求ID，用于幂等性（防止重复请求）\n  string request_id = 4;\n}\n\n// 节点响应客户端的KV结果\nmessage KvResponse {\n  bool success = 1;    // 操作是否成功\n  string message = 2;  // 错误信息/提示（失败时必传）\n  string value = 3;    // 返回的value（仅GET成功时传）\n  string request_id = 4; // 对应请求的ID（幂等性）\n}\n\n// ===================== 3. Raft选举相关 =====================\n// Candidate向Follower发起的投票请求\nmessage VoteRequest {\n  int64 term = 1;                // Candidate的当前任期（必传）\n  string candidate_id = 2;       // Candidate的节点ID（必传）\n  int64 last_log_index = 3;      // Candidate最后一条日志的索引（用于日志一致性检查）\n  int64 last_log_term = 4;       // Candidate最后一条日志的任期（用于日志一致性检查）\n}\n\n// Follower响应Candidate的投票结果\nmessage VoteResponse {\n  int64 term = 1;                // Follower的当前任期（必传，用于更新Candidate的任期）\n  bool vote_granted = 2;         // 是否投赞成票（必传）\n}\n\n// ===================== 4. Raft日志追加/心跳相关 =====================\n// 日志条目（与你设计的日志格式对齐，序列化后可直接写入日志文件）\nmessage LogEntry {\n  int64 term = 1;        // Raft任期（对应你日志格式的term）\n  int64 index = 2;       // 日志索引（对应你日志格式的index）\n  string command = 3;    // KV操作命令（如\"PUT key1 value1\"，对应你日志格式的command）\n}\n\n// Leader向Follower发送的日志追加/心跳请求\nmessage AppendEntriesRequest {\n  int64 term = 1;                // Leader的当前任期（必传）\n  string leader_id = 2;          // Leader的节点ID（必传）\n  int64 prev_log_index = 3;      // 前一条日志的索引（用于日志一致性检查）\n  int64 prev_log_term = 4;       // 前一条日志的任期（用于日志一致性检查）\n  repeated LogEntry entries = 5; // 待追加的日志条目（心跳时为空）\n  int64 leader_commit = 6;       // Leader已提交的日志索引（Follower据此更新自己的提交索引）\n}\n\n// Follower响应Leader的日志追加结果\nmessage AppendEntriesResponse {\n  int64 term = 1;                // Follower的当前任期（必传，用于更新Leader的任期）\n  bool success = 2;              // 日志追加是否成功（必传）\n  int64 match_index = 3;         // Follower已匹配的日志索引（Leader据此更新nextIndex）\n}\n</code></pre>\n<p>上面是消息的大致格式。</p>\n<p>接下来看服务端的节点设计，我们从netty服务启动开始往下看：</p>\n<p>在kv-core的app包里面</p>\n<pre><code class=\"language-java\">public static void main(String[] args) {\n    int port = getPort(args);\n    RaftNettyServer raftNettyServer = new RaftNettyServer(port);\n    try {\n        raftNettyServer.start();\n    } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n    }\n}\n\nprivate static int getPort(String[] args) {\n    for (String arg : args) {\n        if (arg.startsWith(\"node.port=\")) {\n            return Integer.parseInt(arg.substring(10));\n        }\n    }\n    return 7777;\n}\n</code></pre>\n<p>从java程序启动的命令行读取结点的端口参数，我们可以用一台电脑开启多个应用，在idea中这样配置就可以了：如下图所示</p>\n<img src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194613557-847947640.png\" />\n<p>从上图中可以看到，配置了三个节点，然后本项目的jdk是采用的21这个版本。配置好了之后，在idea的services里面可以把这些配置一起加进去，然后就可以同时启动多个节点了。</p>\n<h3 id=\"222-连接设计\">2.2.2 连接设计</h3>\n<pre><code class=\"language-java\">RaftNettyServer raftNettyServer = new RaftNettyServer(port);\n...\nraftNettyServer.start();\n</code></pre>\n<p>从上一节的启动类看出来主要就是new了一个server对象，然后调用start方法。我们顺着这两个看就可以了。</p>\n<p>首先是构造方法：</p>\n<pre><code class=\"language-java\">public class RaftNettyServer {\n  \t....\n    private final int port;\n    private final RaftNode node;\n\n    public RaftNettyServer(int port) {\n        this.port = port;\n         // 这里创建了一个raft结点对象\n        this.node = new RaftNode(port);\n    }\n}\n\n// 这个是RaftNode类，\npublic RaftNode(int port) {\n    this.port = port;\n\n    // 从配置文件中找到自己\n    this.nodesConfig = new NodesConfig();\n    this.nodeId = nodesConfig.findSelf(port);\n\n    // 需要把自身结点\n    this.rpcPeers = nodesConfig.getNodeList().stream()\n        // node的格式是'ip:port'\n        .map(node -&gt; new RpcPeer(node, node.split(\":\")[0],\n                                 Integer.parseInt(node.split(\":\")[1]), this))\n        .toList();\n\n    this.logManager = new LogManager();\n    this.storage = new MemoryStorage();\n\n    // 把两个时间先初始化咯\n    this.electionTimeout = 8000 + ThreadLocalRandom.current().nextInt(4000);\n    this.lastHeartbeatTime = System.currentTimeMillis();\n    log.info(\"初始化选举超时：{}\", electionTimeout);\n\n    // 定时器\n    scheduler = Executors.newScheduledThreadPool(2);\n    scheduler.scheduleAtFixedRate(this::tick, 2, 2000, TimeUnit.MILLISECONDS);\n}\n</code></pre>\n<p>Raft类是最核心的一个类。上面的构造方法其实很简单。读者自行理解。需要说明一下的就是nodeId的格式：【ip:端口】</p>\n<pre><code class=\"language-java\">127.0.0.1:8888 // 就是这种字符串的格式\n</code></pre>\n<p>还有要说明的就是rpcPeers这个List的构建，可以看出来先是从配置文件读取到了集群节点列表，然后遍历这个列表创建了对象，这个具体是什么意思呢？</p>\n<p>首先看一下Netty的客户端发送请求到服务端，服务端处理后在返回给客户端，客户端根据响应结果进行逻辑处理。这样一个示意图：</p>\n<img src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194613912-363189595.png\" />\n<p>再看一下下面的连接示意图：</p>\n<img src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194614275-746707923.png\" />\n<p>NettyClient不仅仅是给客户用的，集群结点内部互相通信也要用到这个，rpcPeers就是集群节点内部通信使用的。如上图所示，每个节点都有一个NettyServer启动并监听着端口，同时Leader结点需要给所有的Follower结点发送心跳请求，此时这个Leader相当于其他两个Follower结点就相当于Client了，所以在结点一里面有client的部分，在项目归到了rpc的包下，也就是上面那个rpcPeers的由来了。</p>\n<p>在集群启动的时候，都是Follower结点，只有等到超时了才会开始选主，在此之前，每个节点都有成为Candidate的可能，也就是说每个节点都有向其他结点发送投票请求的可能（VoteRequest），那么每个节点里面都要有一套Netty Client及处理流程。就如下图所示：</p>\n<img src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194614720-1938302844.png\" />\n<p>这样就有一个问题了，三个节点，我就要六个tcp连接了，四个节点就要12个连接，十个节点呢，就要90个连接，这也太多了吧，那也确实是的。有一个思路是搞一个中间层叫做routeCenter，所有结点连向它，然后消息都经过这个路由中心来转发，这样连接数就会少很多了。</p>\n<p>还有一个思路，反正NettyClient + 一个NettyServer构建出一个Channel，理论上我只需要三个tcp连接就可以了啊。如下图所示：</p>\n<img src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194615069-208910434.png\" />\n<p>但是这样的话，节点间通信需要转发了，代码逻辑就太复杂了，况且还有一个问题，那就是如何确定这个tcp的连接顺序呢？这个可以按照nodeId的字典顺序来嘛。反正就是麻烦就完事儿了。。。</p>\n<p>综上所述，还是最开始的方案最简单直接了，反正这就是一个简易的案例，不要考虑太多了。如果有一些其他合适的思路，欢迎读者给出。</p>\n<p>节点之间的连接设计就是上面的样子了。</p>\n<p>接下来看RaftNode的设计。</p>\n<h3 id=\"223-raftnode设计\">2.2.3 RaftNode设计</h3>\n<p>那就从构造器开始看吧：</p>\n<pre><code class=\"language-java\">public RaftNode(int port) {\n    this.port = port;\n\n    // 从配置文件中找到自己\n    this.nodesConfig = new NodesConfig();\n    this.nodeId = nodesConfig.findSelf(port);\n\n    // 需要把自身结点\n    this.rpcPeers = nodesConfig.getNodeList().stream()\n        // node的格式是'ip:port'\n        .map(node -&gt; new RpcPeer(node, node.split(\":\")[0],\n                                 Integer.parseInt(node.split(\":\")[1]), this))\n        .toList();\n\n    this.logManager = new LogManager();\n    this.storage = new MemoryStorage();\n\n    // 把两个时间先初始化咯\n    this.electionTimeout = 8000 + ThreadLocalRandom.current().nextInt(4000);\n    this.lastHeartbeatTime = System.currentTimeMillis();\n    log.info(\"初始化选举超时：{}\", electionTimeout);\n\n    // 定时器\n    scheduler = Executors.newScheduledThreadPool(2);\n    scheduler.scheduleAtFixedRate(this::tick, 2, 2000, TimeUnit.MILLISECONDS);\n}\n</code></pre>\n<p>可以看到都是做一些初始化的工作，然后下面是开启了一个定时任务tick</p>\n<pre><code class=\"language-java\">private void tick() {\n    log.info(\"检查是否超时：{} 状态: {}\", nodeId, state);\n    try {\n        if (state != NodeState.LEADER &amp;&amp; isTimeout()) {\n            becomeCandidate();\n        } else if (state == NodeState.LEADER) {\n            // sendHeartbeats();\n        }\n    } catch ( Exception e ) {\n        log.error(\"{} 节点tick定时任务异常\", nodeId, e);\n    }\n}\nprivate void becomeCandidate() {\n    log.info(\"{} 选举超时，转为 Candidate，开始任期: {}\", nodeId, currentTerm.get() + 1);\n    state = NodeState.CANDIDATE;\n    currentTerm.getAndIncrement(); // 任期+1\n    votedFor = nodeId; // 给自己投一票\n    resetElectionTimeout();\n    // 集群发送投票请求\n    requestVotes();\n}\n private boolean isTimeout() {\n     return System.currentTimeMillis() - lastHeartbeatTime &gt; electionTimeout;\n }\nprivate void resetElectionTimeout() {\n    // 8000ms ~ 12000ms 随机超时，避免平票\n    this.electionTimeout = 8000 + ThreadLocalRandom.current().nextInt(4000);\n    log.info(\"重置 {} 节点选举时间，随机超时：{} ms\", nodeId, electionTimeout);\n    this.lastHeartbeatTime = System.currentTimeMillis();\n}\n</code></pre>\n<p>主要就是看becomeCandidate这个方法最后的向集群发送投票请求。</p>\n<pre><code class=\"language-java\">private void requestVotes() {\n    // 1. 初始化票数：自己的一票\n    AtomicInteger grantedVotes = new AtomicInteger(1);\n    long count = rpcPeers.stream().filter(peer -&gt; !peer.isSelf()).count(); // 不包含自己的结点数\n    int majority = (int) ((count + 1) / 2 + 1); // 总节点数(包含自己)的半数以上\n\n    // 2.构造投票消息\n    KvRaftProto.VoteRequest voteRequest = KvRaftProto.VoteRequest.newBuilder()\n        .setTerm(currentTerm.get())\n        .setCandidateId(nodeId)\n        .setLastLogIndex(logManager.getLastLogIndex())\n        .setLastLogTerm(logManager.getLastLogTerm())\n        .build();\n    // 3. 发送投票请求\n    // 构建一个对象，表示当前投票请求的状态\n    // String voteId = UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n    // 这里为什么可以用term？因为 Raft 规定，一个节点在一个 term 内只能投一张票。\n    // 所以，只要 term 匹配，这个响应就一定是针对你当前发起的这一轮选举的。\n    GlobalVoteManager.setVoteState(currentTerm.get(), new VoteState(nodeId, currentTerm.get(), majority));\n\n    int countSend = 0;\n    for (RpcPeer peer : rpcPeers) {\n        if (!peer.isSelf()) { // 不是自身结点，就发送投票请求\n            // send方法就很简单了，请读者自行查看\n            boolean send = peer.send(KvRaftProto.RaftKvMessage.newBuilder()\n                                     .setType(KvRaftProto.RaftKvMessage.MessageType.VOTE_REQUEST)\n                                     .setVoteRequest(voteRequest)\n                                     .build());\n            if ( send ) countSend++;\n        }\n    }\n    log.info(\"发送投票请求：{}，已发送给了 {} 个结点..\", voteRequest, countSend);\n}\n</code></pre>\n<p>这样投票请求就发送出去了，此时结点是作为客户端发送给其他节点的，接下来的逻辑就是其他节点接收到voteRequest请求然后做逻辑处理，所以就要在server包下面去查看具体逻辑。</p>\n<pre><code class=\"language-java\">// 在kv-core的server包下面的KvBusinessHandler.java\n// 1.如果是投票请求\nif ( raftKvMessage.getType() == KvRaftProto.RaftKvMessage.MessageType.VOTE_REQUEST) {\n    log.info(\"receive vote request.........\");\n    KvRaftProto.VoteRequest voteRequest = raftKvMessage.getVoteRequest();\n    // 可以看到交给了node去处理\n    KvRaftProto.VoteResponse voteResponse = node.tackleVoteRequest(voteRequest);\n    ctx.writeAndFlush(KvRaftProto.RaftKvMessage.newBuilder()\n                      .setType(KvRaftProto.RaftKvMessage.MessageType.VOTE_RESPONSE)\n                      .setVoteResponse(voteResponse)\n                      .build());\n}\n\n// 又回到了RaftNode类了\npublic KvRaftProto.VoteResponse tackleVoteRequest(KvRaftProto.VoteRequest voteRequest) {\n    // 比较任期\n    if (voteRequest.getTerm() &lt; currentTerm.get()) {\n        log.info(\"{} 投票请求任期太小，拒绝投票\", nodeId);\n        return buildVoteResponse(false, currentTerm.get());\n    }\n    if ( votedFor != null &amp;&amp; !voteRequest.getCandidateId().equals(votedFor) ) {\n        log.info(\"{}已投给其他人，拒绝该投票请求\", nodeId);\n        return buildVoteResponse(false, currentTerm.get());\n    }\n    // 再比较日志情况\n    if ( voteRequest.getLastLogIndex() &gt;= logManager.getLastLogIndex() &amp;&amp;\n        voteRequest.getLastLogTerm() &gt;= logManager.getLastLogTerm() ) {\n        log.info(\"{} 投票请求ok，赞成投票\", nodeId);\n        currentTerm.set(voteRequest.getTerm()); // 更新自己的任期\n        votedFor = voteRequest.getCandidateId(); // 投票给该节点\n        return buildVoteResponse(true, voteRequest.getTerm());\n    }\n    log.info(\"{} 投票请求日志太旧，拒绝该投票请求\", nodeId);\n    return buildVoteResponse(false, currentTerm.get());\n}\n</code></pre>\n<p>其他节点收到了拉票请求，会返回response给candidate结点，candidate结点是作为Client发送的拉票请求，收到的响应肯定是在客户端的处理器handler，接下来的逻辑就要在rpc包下面的RpcClientHandler去查看了：</p>\n<pre><code class=\"language-java\">@Override\nprotected void channelRead0(ChannelHandlerContext ctx, KvRaftProto.RaftKvMessage msg) {\n    // 2.VOTE_RESPONSE 投票请求回来的响应【投票请求是结点作为客户端发出的，应该在客户端的handler处理响应】\n    if (msg.getType() == KvRaftProto.RaftKvMessage.MessageType.VOTE_RESPONSE) {\n        log.info(\"receive vote response.........\");\n        KvRaftProto.VoteResponse voteResponse = msg.getVoteResponse();\n        raftNode.tackleVoteResponse(voteResponse); // 又回到了RaftNode\n    }\n}\n\n// RaftNode.java\n// 投票结果处理,【投票请求是结点作为客户端发出的，要在客户端的handler处理响应】\npublic synchronized void tackleVoteResponse(KvRaftProto.VoteResponse voteResponse) {\n    long term = voteResponse.getTerm();\n    // 2. 发现更高任期，立即降级并更新\n    // 1. 任期检查：对方比我大，我立即认输\n    if (term &gt; currentTerm.get()) {\n        stepDown(term);\n        return;\n    }\n    // 2. 状态检查：如果我已经不是 Candidate 了（比如已经超时重选或收到心跳），忽略\n    if (state != NodeState.CANDIDATE) return;\n\n    // 3. 任期匹配检查：确保这是对“当前这一轮”选举的回复\n    // 如果收到的响应任期比当前小，说明是之前过期的选举回复，直接丢弃\n    if (term &lt; currentTerm.get()) {\n        return;\n    }\n\n    // 4. 从全局管理器获取当前选举的投票状态\n    VoteState voteState = GlobalVoteManager.getVoteState(term);\n    if (voteState == null) {\n        log.error(\"未找到任期 {} 的投票记录状态\", term);\n        return;\n    }\n\n    // 5. 如果对方投了赞成票\n    if (voteResponse.getVoteGranted()) {\n        // 增加票数（这里 AtomicInteger 在 VoteState 内部保证了线程安全，\n        // 但由于本方法加了 synchronized，其实双重保险）\n        int currentVotes = voteState.addVote();\n        int majority = voteState.getMajority();\n        log.info(\"赞成票，当前票数: {}/{}\", currentVotes, nodesConfig.getNodeList().size());\n\n        // 6. 检查是否达到多数派\n        if (currentVotes &gt;= majority) {\n            log.info(\"节点 {} 获得过半选票 ({})，准备晋升为 Leader\", nodeId, currentVotes);\n            becomeLeader();\n        }\n    } else {\n        log.info(\"拒绝了我的投票请求\");\n    }\n}\nprivate synchronized void becomeLeader() {\n    if (state != NodeState.CANDIDATE) return;\n    if (state == NodeState.LEADER) return;\n\n    this.state = NodeState.LEADER;\n    log.info(\"Node {} 赢得选举，即将成为 Leader, Term: {}\", nodeId, currentTerm.get());\n    // 1. 清理上一任期的残留状态\n    this.votedFor = null;\n\n    // 2. 立即发送第一波心跳，宣示主权 (防止其他节点又超时)\n    sendHeartbeats();\n\n    // 3. 启动定时心跳任务 (比如每 2 秒一次)\n    if (heartbeatTask != null) heartbeatTask.cancel(true);\n    heartbeatTask = scheduler.scheduleAtFixedRate(this::sendHeartbeats,\n                                                  0, 1000, TimeUnit.MILLISECONDS);\n    log.info(\"&lt;&lt;&lt;&lt;&lt; 节点 {} 正式成为 Term {} 的 Leader &gt;&gt;&gt;&gt;&gt;\", nodeId, currentTerm.get());\n}\n</code></pre>\n<h1 id=\"3启动测试选主\">3.启动测试选主</h1>\n<p>把配置好的三个节点启动一下看看结果</p>\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194611564-1443963355.png\" /></p>\n<hr />\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194612379-843476723.png\" /></p>\n<hr />\n<p><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/2358057/202602/2358057-20260211194612841-1185877353.png\" /></p>\n<p>从上图可以看出，端口9999成为了Leader结点，然后向其他节点发送心跳数据了。</p>\n<p>接下来就是完善一下日志分发那些逻辑了。</p>\n<h1 id=\"end-参考\">end. 参考</h1>\n<ol>\n<li><a href=\"http://thinkinjava.cn/2019/01/12/2019/2019-01-12-lu-raft-kv/#%E4%BB%80%E4%B9%88%E6%98%AF-Java-%E7%89%88-Raft-%E5%88%86%E5%B8%83%E5%BC%8F-KV-%E5%AD%98%E5%82%A8\" rel=\"noopener nofollow\" target=\"_blank\">http://thinkinjava.cn/2019/01/12/2019/2019-01-12-lu-raft-kv/#什么是-Java-版-Raft-分布式-KV-存储</a></li>\n<li><a href=\"https://github.com/stateIs0/lu-raft-kv\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/stateIs0/lu-raft-kv</a></li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-11 19:47</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jackjavacpp\">别来无恙✲</a>&nbsp;\n阅读(<span id=\"post_view_count\">20</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}