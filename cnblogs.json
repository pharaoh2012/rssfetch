{
  "title": "主页 - 博客园",
  "link": "https://www.cnblogs.com/",
  "description": "主页 - 博客园 RSS",
  "entries": [
    {
      "title": ".NET 中如何快速实现 List 集合去重？",
      "link": "https://www.cnblogs.com/1312mn/p/18552496",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/1312mn/p/18552496\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 16:34\">\n    <span>.NET 中如何快速实现 List 集合去重？</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain md-expand\" style=\"font-size: 16px;\">前言</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">在数据处理中，去除集合中的重复元素是一个常见的需求。.NET 6 和 .NET 7 引入了 <span class=\"md-pair-s\"><code>DistinctBy</code><span class=\"md-plain\"> 方法，这是一个非常实用的新特性，可以方便地根据指定的键对集合进行去重。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">本文将详细介绍 <span class=\"md-pair-s\"><code>DistinctBy</code><span class=\"md-plain\"> 方法的使用，并通过具体的案例来展示其在实际开发中的应用。</span></span></span></p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\" style=\"font-size: 16px;\">正文</span></h2>\n<h3><strong>1、<code>DistinctBy</code> 方法</strong></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><code>DistinctBy</code><span class=\"md-plain\"> 方法允许我们在 LINQ 查询中根据某个键对集合中的元素进行去重。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">这个方法返回一个新的集合，其中只包含根据指定键唯一确定的元素。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s md-expand\" style=\"font-size: 16px;\"><strong>方法签名</strong></span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; DistinctBy&lt;TSource, TKey&gt;<span style=\"color: rgba(0, 0, 0, 1);\">(\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">this</span> IEnumerable&lt;TSource&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> source,\n    Func</span>&lt;TSource, TKey&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> keySelector\n);</span></pre>\n</div>\n<h3 class=\"md-end-block md-heading\"><strong><span class=\"md-plain\" style=\"font-size: 16px;\">2、基本用法</span></strong></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">最简单的用法是在 LINQ 查询中直接调用 <span class=\"md-pair-s\"><code>DistinctBy</code><span class=\"md-plain\"> 方法，然后处理去重后的集合。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><strong>说明</strong></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">假设我们有一个用户列表，我们想要根据用户名去除重复的用户。</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Linq;\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> User\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span> Name { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> Age { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n}\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> users = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> List&lt;User&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> User { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Alice</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Age = <span style=\"color: rgba(128, 0, 128, 1);\">25</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> User { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Bob</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Age = <span style=\"color: rgba(128, 0, 128, 1);\">32</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> User { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Alice</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Age = <span style=\"color: rgba(128, 0, 128, 1);\">28</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> User { Name = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">David</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Age = <span style=\"color: rgba(128, 0, 128, 1);\">35</span><span style=\"color: rgba(0, 0, 0, 1);\"> }\n};\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> distinctUsers = users.DistinctBy(user =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> user.Name);\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (<span style=\"color: rgba(0, 0, 255, 1);\">var</span> user <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> distinctUsers)\n{\n    Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Name: {user.Name}, Age: {user.Age}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n}</span></pre>\n</div>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">输出结果：</span></p>\n<div class=\"cnblogs_code\">\n<pre>Name: Alice, Age: <span style=\"color: rgba(128, 0, 128, 1);\">25</span><span style=\"color: rgba(0, 0, 0, 1);\">\nName: Bob, Age: </span><span style=\"color: rgba(128, 0, 128, 1);\">32</span><span style=\"color: rgba(0, 0, 0, 1);\">\nName: David, Age: </span><span style=\"color: rgba(128, 0, 128, 1);\">35</span></pre>\n</div>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">过滤前后元素还是保持原有的顺序，我们可以查看源码。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><strong>源码</strong></span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">private</span> <span style=\"color: rgba(0, 0, 255, 1);\">static</span> IEnumerable&lt;TSource&gt; DistinctByIterator&lt;TSource, TKey&gt;(IEnumerable&lt;TSource&gt; source, Func&lt;TSource, TKey&gt; keySelector, IEqualityComparer&lt;TKey&gt;?<span style=\"color: rgba(0, 0, 0, 1);\"> comparer)\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">using</span> IEnumerator&lt;TSource&gt; enumerator =<span style=\"color: rgba(0, 0, 0, 1);\"> source.GetEnumerator();\n​\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">if</span><span style=\"color: rgba(0, 0, 0, 1);\"> (enumerator.MoveNext())\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> <span style=\"color: rgba(0, 0, 255, 1);\">set</span> = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> HashSet&lt;TKey&gt;<span style=\"color: rgba(0, 0, 0, 1);\">(DefaultInternalSetCapacity, comparer);\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">do</span><span style=\"color: rgba(0, 0, 0, 1);\">\n        {\n            TSource element </span>=<span style=\"color: rgba(0, 0, 0, 1);\"> enumerator.Current;\n            </span><span style=\"color: rgba(0, 0, 255, 1);\">if</span> (<span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">.Add(keySelector(element)))\n            {\n                </span><span style=\"color: rgba(0, 0, 255, 1);\">yield</span> <span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> element;\n            }\n        }\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">while</span><span style=\"color: rgba(0, 0, 0, 1);\"> (enumerator.MoveNext());\n    }\n}</span></pre>\n</div>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">通过查看源码，可以看到是利用了 <span class=\"md-pair-s\"><code>HashSet</code><span class=\"md-plain\"> 去重，元素顺序并未被打乱。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">在处理集合时，我们经常需要去除重复的元素，同时保持原有的顺序。</span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">使用 <span class=\"md-pair-s\"><code>HashSet</code><span class=\"md-plain\"> 可以高效地实现这一目标。</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">首先将指定的键尝试添加到 <span class=\"md-pair-s\"><code>HashSet</code><span class=\"md-plain\"> 中，如果添加成功，说明该键没有重复；</span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">如果添加失败，说明已经存在相同的键，此元素将被过滤掉。</span></p>\n<h3 class=\"md-end-block md-heading\"><strong><span class=\"md-plain\" style=\"font-size: 16px;\">3、复杂用法</span></strong></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><code>DistinctBy</code><span class=\"md-plain\"> 方法可以用于更复杂的去重逻辑，例如根据多个属性进行去重。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \" style=\"font-size: 16px;\"><strong>说明</strong></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">假设我们有一个订单列表，我们想要根据客户名称和订单金额去除重复的订单。</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">class</span><span style=\"color: rgba(0, 0, 0, 1);\"> Order\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">int</span> OrderId { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">string</span> CustomerName { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">decimal</span> Amount { <span style=\"color: rgba(0, 0, 255, 1);\">get</span>; <span style=\"color: rgba(0, 0, 255, 1);\">set</span><span style=\"color: rgba(0, 0, 0, 1);\">; }\n}\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> orders = <span style=\"color: rgba(0, 0, 255, 1);\">new</span> List&lt;Order&gt;<span style=\"color: rgba(0, 0, 0, 1);\">\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> Order { OrderId = <span style=\"color: rgba(128, 0, 128, 1);\">1</span>, CustomerName = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Alice</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Amount = <span style=\"color: rgba(128, 0, 128, 1);\">100.0m</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> Order { OrderId = <span style=\"color: rgba(128, 0, 128, 1);\">2</span>, CustomerName = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Bob</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Amount = <span style=\"color: rgba(128, 0, 128, 1);\">150.0m</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> Order { OrderId = <span style=\"color: rgba(128, 0, 128, 1);\">3</span>, CustomerName = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Alice</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Amount = <span style=\"color: rgba(128, 0, 128, 1);\">100.0m</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> Order { OrderId = <span style=\"color: rgba(128, 0, 128, 1);\">4</span>, CustomerName = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Charlie</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Amount = <span style=\"color: rgba(128, 0, 128, 1);\">120.0m</span><span style=\"color: rgba(0, 0, 0, 1);\"> },\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">new</span> Order { OrderId = <span style=\"color: rgba(128, 0, 128, 1);\">5</span>, CustomerName = <span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Bob</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>, Amount = <span style=\"color: rgba(128, 0, 128, 1);\">150.0m</span><span style=\"color: rgba(0, 0, 0, 1);\"> }\n};\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> distinctOrders = orders.DistinctBy(order =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> (order.CustomerName, order.Amount));\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (<span style=\"color: rgba(0, 0, 255, 1);\">var</span> order <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> distinctOrders)\n{\n    Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Order ID: {order.OrderId}, Customer: {order.CustomerName}, Amount: {order.Amount}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n}</span></pre>\n</div>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">输出结果：</span></p>\n<div class=\"cnblogs_code\">\n<pre>Order ID: <span style=\"color: rgba(128, 0, 128, 1);\">1</span>, Customer: Alice, Amount: <span style=\"color: rgba(128, 0, 128, 1);\">100.0</span><span style=\"color: rgba(0, 0, 0, 1);\">\nOrder ID: </span><span style=\"color: rgba(128, 0, 128, 1);\">2</span>, Customer: Bob, Amount: <span style=\"color: rgba(128, 0, 128, 1);\">150.0</span><span style=\"color: rgba(0, 0, 0, 1);\">\nOrder ID: </span><span style=\"color: rgba(128, 0, 128, 1);\">4</span>, Customer: Charlie, Amount: <span style=\"color: rgba(128, 0, 128, 1);\">120.0</span></pre>\n</div>\n<h3 class=\"md-end-block md-heading\"><strong><span class=\"md-plain\" style=\"font-size: 16px;\">4、性能考虑</span></strong></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><code>DistinctBy</code><span class=\"md-plain\"> 方法在内部使用哈希表来跟踪已经出现的键，因此在大多数情况下性能非常好。但在处理非常大的数据集时，仍然需要注意内存使用情况。</span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><strong>说明</strong></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">假设我们有一个包含数百万条记录的大集合，我们需要根据某个键进行去重。</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">var</span> largeCollection = Enumerable.Range(<span style=\"color: rgba(128, 0, 128, 1);\">1</span>, <span style=\"color: rgba(128, 0, 128, 1);\">10000000</span>).Select(i =&gt; <span style=\"color: rgba(0, 0, 255, 1);\">new</span> { Id = i, Value = i % <span style=\"color: rgba(128, 0, 128, 1);\">1000</span><span style=\"color: rgba(0, 0, 0, 1);\"> });\n</span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> distinctLargeCollection = largeCollection.DistinctBy(item =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> item.Value);\nConsole.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Distinct count: {distinctLargeCollection.Count()}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span>);</pre>\n</div>\n<h3 class=\"md-end-block md-heading\"><strong><span class=\"md-plain\" style=\"font-size: 16px;\">5、异步 LINQ 查询中的使用</span></strong></h3>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><code>DistinctBy</code><span class=\"md-plain\"> 方法也可以在异步 LINQ 查询中使用，结合 <span class=\"md-pair-s\"><code>IAsyncEnumerable&lt;T&gt;</code><span class=\"md-plain\"> 类型，处理大量数据时更加高效。</span></span></span></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s \" style=\"font-size: 16px;\"><strong>说明</strong></span></p>\n<p class=\"md-end-block md-p\"><span class=\"md-plain\" style=\"font-size: 16px;\">假设我们有一个异步方法返回一个用户列表，我们想要根据用户名去除重复的用户。</span></p>\n<div class=\"cnblogs_code\">\n<pre><span style=\"color: rgba(0, 0, 255, 1);\">using</span><span style=\"color: rgba(0, 0, 0, 1);\"> System.Net.Http.Json;\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">public</span> <span style=\"color: rgba(0, 0, 255, 1);\">async</span> IAsyncEnumerable&lt;User&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> GetUsersAsync()\n{\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> response = <span style=\"color: rgba(0, 0, 255, 1);\">await</span> httpClient.GetAsync(<span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">https://api.example.com/users</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n    </span><span style=\"color: rgba(0, 0, 255, 1);\">var</span> usersJson = <span style=\"color: rgba(0, 0, 255, 1);\">await</span><span style=\"color: rgba(0, 0, 0, 1);\"> response.Content.ReadAsStringAsync();\n    \n    </span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 使用Json序列化工具解析用户列表</span>\n    <span style=\"color: rgba(0, 0, 255, 1);\">var</span> users = JsonSerializer.Deserialize&lt;List&lt;User&gt;&gt;<span style=\"color: rgba(0, 0, 0, 1);\">(usersJson);\n    \n    </span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (<span style=\"color: rgba(0, 0, 255, 1);\">var</span> user <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> users)\n    {\n        </span><span style=\"color: rgba(0, 0, 255, 1);\">yield</span> <span style=\"color: rgba(0, 0, 255, 1);\">return</span><span style=\"color: rgba(0, 0, 0, 1);\"> user;\n    }\n}\n​\n</span><span style=\"color: rgba(0, 128, 0, 1);\">//</span><span style=\"color: rgba(0, 128, 0, 1);\"> 使用异步LINQ查询</span>\n<span style=\"color: rgba(0, 0, 255, 1);\">var</span> distinctUsers = <span style=\"color: rgba(0, 0, 255, 1);\">await</span> GetUsersAsync().DistinctByAsync(user =&gt;<span style=\"color: rgba(0, 0, 0, 1);\"> user.Name).ToListAsync();\n​\n</span><span style=\"color: rgba(0, 0, 255, 1);\">foreach</span> (<span style=\"color: rgba(0, 0, 255, 1);\">var</span> user <span style=\"color: rgba(0, 0, 255, 1);\">in</span><span style=\"color: rgba(0, 0, 0, 1);\"> distinctUsers)\n{\n    Console.WriteLine($</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(128, 0, 0, 1);\">Name: {user.Name}, Age: {user.Age}</span><span style=\"color: rgba(128, 0, 0, 1);\">\"</span><span style=\"color: rgba(0, 0, 0, 1);\">);\n}</span></pre>\n</div>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\" style=\"font-size: 16px;\">总结</span></h2>\n<p class=\"md-end-block md-p\"><span class=\"md-pair-s\" style=\"font-size: 16px;\"><code>DistinctBy</code><span class=\"md-plain\"> 方法是 .NET 6 和 .NET 7 中 LINQ 的一个非常实用的新特性。我们在 LINQ 查询中根据指定的键对集合进行去重，简化了代码并提高了开发效率。</span></span></p>\n<p class=\"md-end-block md-p md-focus\"><span class=\"md-plain\" style=\"font-size: 16px;\">希望本文能帮助大家更好地理解和利用 .NET 6 和 .NET 7 中 LINQ 的 <span class=\"md-pair-s\"><code>DistinctBy</code><span class=\"md-plain md-expand\"> 方法，从而在项目中发挥更大的作用。</span></span></span></p>\n<h2 class=\"md-end-block md-heading\"><span class=\"md-plain\" style=\"font-size: 16px;\">最后</span></h2>\n<p><span class=\"md-plain\" style=\"font-size: 16px;\"><span class=\"md-plain md-expand\">如果你觉得这篇文章对你有帮助，不妨点个赞支持一下！你的支持是我继续分享知识的动力。如果有任何疑问或需要进一步的帮助，欢迎随时留言。也可以加入微信公众号&nbsp;<span class=\"md-pair-s \"><strong>[DotNet技术匠]</strong><span class=\"md-plain md-expand\">&nbsp;社区，与其他热爱技术的同行一起交流心得，共同成长！</span></span></span></span></p>\n<p><span class=\"md-plain\" style=\"font-size: 16px;\"><img alt=\"\" src=\"https://img2024.cnblogs.com/blog/576536/202408/576536-20240813102419584-1596250541.png\" style=\"display: block; margin-left: auto; margin-right: auto;\" /></span></p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 16:34</span>&nbsp;\n<a href=\"https://www.cnblogs.com/1312mn\">小码编匠</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "扣子Coze实战：从0到1打造抖音+小红书热点监控智能体",
      "link": "https://www.cnblogs.com/tangshiye/p/19575161",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tangshiye/p/19575161\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 16:30\">\n    <span>扣子Coze实战：从0到1打造抖音+小红书热点监控智能体</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>大家好，我是汤师爷，专注AI智能体分享，致力于帮助100W人用智能体创富~</p>\n<p>热点监控智能体是帮你自动发现爆款选题的利器。</p>\n<p>它能全天候扫描各大平台的热门内容，从海量信息中筛选出最有价值的话题和创意。</p>\n<p>你不需要再手动搜索，智能体会自动将热点内容整理成表格，让你清晰直观地掌握行业动态。</p>\n<h3 id=\"1-为什么要做热点监控\">1 为什么要做热点监控</h3>\n<p>热点监控是内容创作者和营销人员的必备工具，它帮助我们在信息爆炸时代精准把握用户关注点，提升内容效果和影响力。以下是进行热点监控的四大核心理由：</p>\n<p><strong>1. 把握用户兴趣，提高内容相关性</strong></p>\n<p>用户的注意力是稀缺资源。通过实时监控热点话题，我们能了解目标受众当下最关心的问题和兴趣点。热点本质上是用户兴趣的集中体现，基于热点创作的内容自然具有更高的用户匹配度，更容易获得关注和互动。</p>\n<p><strong>2. 节约选题时间，提高创作效率</strong></p>\n<p>没有热点监控系统时，创作者需要在各平台间不断切换，手动搜索和筛选信息，这个过程既耗时又低效。自动化热点监控能持续追踪多平台热门内容，将重复性工作交给智能体，让创作者能专注于内容创作本身。</p>\n<p><strong>3. 抓住时机，提高曝光机会</strong></p>\n<p>热点具有明显的时效性，越早参与讨论，获得的曝光机会就越多。自动化热点监控系统能在热点刚出现时就发出提醒，帮助创作者抢占先机。比起等热点完全爆发后再跟进，提前布局能获得更多流量红利和平台算法青睐。</p>\n<p><strong>4. 发现内容机会，避免同质化</strong></p>\n<p>热点监控不只是追踪已经爆发的话题，更重要的是发现潜在新兴热点。通过分析热点数据，创作者可以识别尚未被充分挖掘的内容机会，避开同质化竞争，找到差异化表达角度，从而在激烈的内容竞争中脱颖而出。</p>\n<h3 id=\"2-热点监控智能体搭建流程\">2 热点监控智能体搭建流程</h3>\n<p>智能体的搭建流程主要分为两个步骤：梳理工作流和设置智能体。</p>\n<p><strong>1、梳理工作流</strong></p>\n<p>热点监控工作流是一套自动化信息采集和处理系统，能将人工需要几小时甚至几天完成的工作压缩至几分钟内自动完成。这一工作流主要包含三大环节：</p>\n<p><strong>（1）根据关键词，批量获取热门视频</strong></p>\n<p>系统根据预设的关键词（如行业热词、产品名称、竞品信息等），自动从抖音、小红书等平台搜索相关视频。这一步骤替代了手动搜索和浏览结果的过程，大幅提高效率。</p>\n<p><strong>（2）批量获取视频详细信息</strong></p>\n<p>获取视频列表后，系统进一步抓取每个视频的详细数据，包括：</p>\n<ul>\n<li>基础信息：视频ID、标题、链接、发布时间、视频时长等</li>\n<li>互动数据：点赞数、评论数、收藏数、分享数等关键指标</li>\n<li>创作者信息：作者名称、用户ID、个人简介等</li>\n</ul>\n<p>这些数据是分析视频热度和受欢迎程度的关键指标，也是判断内容价值的重要依据。系统将这些零散数据整合成结构化信息，便于后续分析。</p>\n<p><strong>（3）将数据添加到多维表格</strong></p>\n<p>最后，系统将处理好的数据自动导入到预设的飞书多维表格中。</p>\n<p>通过这样的自动化处理，我们能建立一个实时更新的热点内容库，随时查看行业动态，发现爆款选题灵感。</p>\n<p>这种工作流显著减轻了运营人员的工作负担，让我们能将更多精力投入到内容创作和策略制定上。</p>\n<p><strong>2、设置智能体</strong></p>\n<p>完成工作流搭建后，我们需要创建一个热点监控智能体来执行这个工作流。智能体设置过程分为三个关键步骤：</p>\n<ol>\n<li>设置人设与逻辑：配置智能体的特征、回复风格和决策逻辑</li>\n<li>绑定工作流：将工作流与智能体关联，赋予它执行具体任务的能力</li>\n<li>测试并发布：进行全面功能测试，确认一切正常后将智能体正式发布到生产环境</li>\n</ol>\n<p>完成这三个步骤后，我们就成功搭建了一个热点监控智能体。</p>\n<h3 id=\"3-抖音热点监控工作流\">3 抖音热点监控工作流</h3>\n<p>前面我们详细介绍了热点监控的重要性和智能体搭建的基本流程，接下来我们将深入了解如何实际搭建一个抖音热点监控工作流。</p>\n<p>登录Coze官网，在“资源库-工作流”里新建一个空白工作流，取名“fetch_douyin_hot_videos”。</p>\n<p>工作流整体预览如图所示。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>1、开始节点</strong></p>\n<p>这里用于定义工作流启动时所需的输入参数。如图6-2所示。</p>\n<ul>\n<li>输入：\n<ul>\n<li>keywords：用于搜索热点的关键词，可以是产品名称、行业术语、竞品名称或热门话题，系统会自动搜索相关的热门内容</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>2、插件节点：根据关键词，批量获取热门视频</strong></p>\n<p>我们将使用\"视频搜索\"插件的\"douyin_search\"工具。通过这个功能，我们可以根据关键词批量获取热门视频。</p>\n<ul>\n<li>输入：\n<ul>\n<li>api_token：这里需要填入你的API密钥，可以从插件的官方平台获取，它是调用视频数据的重要凭证，相当于你的身份证明</li>\n<li>keyword：关键词，从开始节点获取</li>\n<li>page：获取第几页的内容</li>\n<li>publish_time：发布时间，可用值为_0(不限)、_1(一天之内)、_7(一周之内)、_180(半年之内)，这里我们选择_7</li>\n<li>sort_type：排序类型，可用值：_0(综合)、_1(最多点赞)、_2(最新发布)，这里我们选择_1</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>4、批处理节点：批量获取视频详细信息</strong></p>\n<p>批量获取视频详细信息是工作流中的核心节点，它负责将上一步骤中获取的视频列表进一步深入处理，获取每个视频的完整信息。</p>\n<ul>\n<li>输入：\n<ul>\n<li>并行运行数量：设置适当的并行数量可提高工作流执行效率，设置为1则按顺序串行执行</li>\n<li>批处理次数上限：批处理操作不会超过这个设定的最大次数</li>\n<li>aweme_list：从\"根据关键词，批量获取热门视频\"节点输出中，选择data，类型为Array</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>5、批处理体内插件节点：获取单个视频详细信息</strong></p>\n<p>接下来，我们需要添加批处理体内的节点。我们将使用\"视频搜索\"插件的douyin_data工具，通过这个功能可以根据抖音视频链接获取视频的详细信息。</p>\n<ul>\n<li>输入：\n<ul>\n<li>api_token：API密钥</li>\n<li>douyin_url：从\"批量获取视频详细信息\"节点的输出中，选择share_url</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>6、批处理体内代码节点：将视频详情整合进视频列表中</strong></p>\n<p>这一步将从抖音API获取的详细视频信息与之前收集的视频列表数据合并。</p>\n<p>通过这个过程，我们能掌握每个视频的完整信息，包括互动数据（点赞、评论、收藏数）、创作者信息和内容详情，从而为后续分析提供全面的数据基础。</p>\n<ul>\n<li>输入：\n<ul>\n<li>aweme_detail：从\"获取单个视频详细信息\"节点的输出中，选择aweme_detail</li>\n<li>aweme：从\"批量获取视频详细信息\"节点的输出中，选择item</li>\n</ul>\n</li>\n<li>输出：\n<ul>\n<li>aweme_list：变量类型设置为 Array 对象数组，表示处理后的视频列表</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>下面是处理数据的Python代码，它会将视频信息转换成我们需要的格式。</p>\n<pre><code class=\"language-python\">async def main(args: Args) -&gt; Output:\n    params = args.params\n    aweme_detail = params.get(\"aweme_detail\", {})\n    aweme = params.get(\"aweme\", {})\n    aweme[\"aweme_detail\"] = aweme_detail\n\n    ret: Output = {\n        \"aweme_list\": [aweme]\n    }\n    return ret\n</code></pre>\n<p><strong>7、批处理体内代码节点：将信息整理为飞书表格可以使用的数据</strong></p>\n<p>在这个环节中，我们会提取视频的核心信息（如标题、点赞数、评论数等），并将它们转换成飞书表格能够直接识别和处理的格式。</p>\n<ul>\n<li>输入：\n<ul>\n<li>aweme_list：从\"将视频详情整合进视频列表中\"节点的输出中，选择aweme_list</li>\n<li>keywords：从开始节点中，选择keywords</li>\n</ul>\n</li>\n<li>输出：\n<ul>\n<li>records：处理后的表格数据，选择Array类型</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>下面是处理数据的Python代码，这段代码非常重要，它负责将抖音API返回的原始数据转换成结构化的表格数据。</p>\n<pre><code class=\"language-python\">async def main(args: Args) -&gt; Output:\n    params = args.params\n    aweme_list = params.get(\"aweme_list\", [])\n\n    result = []\n\n    # 遍历 aweme_list，依次处理\n    for aweme in aweme_list:\n\n        # 获取 aweme_detail 并判空\n        aweme_detail = aweme.get(\"aweme_detail\") or {}\n        title = aweme_detail.get(\"desc\") or \"\"\n        link = aweme_detail.get(\"share_url\") or \"\"\n\n        # 安全获取 statistics\n        statistics = aweme_detail.get(\"statistics\") or {}\n\n        # 提取各字段信息，并在取值时加默认值\n        video_id = statistics.get(\"aweme_id\") or \"\"\n        digg_count = statistics.get(\"digg_count\") or 0\n        comment_count = statistics.get(\"comment_count\") or 0\n        collect_count = statistics.get(\"collect_count\") or 0\n        share_count = statistics.get(\"share_count\") or 0\n\n        # 获取作者信息\n        author_info = aweme_detail.get(\"author\") or {}\n        author_name = author_info.get(\"nickname\") or \"\"\n        signature = author_info.get(\"signature\") or \"\"\n        sec_uid = author_info.get(\"sec_uid\") or \"\"\n        raw_create_time = aweme_detail.get(\"create_time\", 0)\n        # 如果不是 int，就尝试转换，失败则为 0\n        try:\n            create_time = int(raw_create_time)\n        except (TypeError, ValueError):\n            create_time = 0\n\n        # 创建时间以毫秒计，避免 None 或非法值导致报错\n        create_time_ms = create_time * 1000\n\n        raw_duration = aweme_detail.get(\"duration\", 0)\n        # 如果不是数字，尝试转换为 float，失败则为 0\n        try:\n            duration = float(raw_duration)\n        except (TypeError, ValueError):\n            duration = 0.0\n        duration_sec = duration / 1000\n\n        # 组装返回数据\n        item_dict = {\n            \"fields\": {\n                \"视频ID\": video_id,\n                \"标题\": title.strip(),\n                \"关键词\": params.get(\"keywords\", \"\"),\n                \"链接\": {\n                    \"text\": \"查看视频\",\n                    \"link\": link.strip(),\n                },\n                \"点赞数\": digg_count,\n                \"评论数\": comment_count,\n                \"收藏数\": collect_count,\n                \"分享数\": share_count,\n                \"作者\": author_name,\n                \"用户简介\": signature,\n                \"用户ID\": sec_uid,\n                \"发布日期\": create_time_ms,  # 毫秒级时间戳\n                \"时长\": duration_sec        # 秒\n            }\n        }\n        result.append(item_dict)\n\n    return result\n</code></pre>\n<p><strong>8、批处理体内插件节点：将数据添加到多维表格</strong></p>\n<p>首先，我们需要创建一个多维表格并设置好表头字段，为后续数据采集做好准备。这个表格是存储和分析抖音热点视频数据的核心，因此表头设计至关重要。我们应包含视频ID、标题、点赞数、评论数等关键信息，便于后期分析和筛选。创建好的表格界面如下图所示。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>选择\"飞书表格\"插件节点的add_records工具，将数据添加到多维表格。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>输入：\n<ul>\n<li>app_token：提前创建一个多维表格，将多维表格的链接复制进去。</li>\n<li>records：从\"将信息整理为飞书表格可以使用的数据\"的输出变量中，选择records。</li>\n<li>table_id：多维表格数据表的唯一标识符，如图6-10所示。</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>9、结束节点</strong></p>\n<p>选择\"返回文本\"，并将回答内容设置为：\"获取关键词下的所有抖音视频【完成】\"。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"4抖音热点监控智能体设置\">4.抖音热点监控智能体设置</h3>\n<p>到目前为止，我们已经介绍了抖音热点监控工作流的搭建过程。接下来，我们将介绍抖音热点监控智能体的设置。这个环节将工作流与智能体绑定，只有完成这一步，我们才能真正实现抖音热点监控智能体的功能。</p>\n<p>接下来，我们将逐步指导你完成整个设置过程，包括创建智能体、配置基本参数、连接工作流以及进行测试，帮助你快速掌握这项实用技能。</p>\n<p><strong>1、新建智能体</strong></p>\n<p>在Coze平台创建一个新的智能体，将其命名为\"抖音热点监控智能体\"。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>2、设置人设与逻辑</strong></p>\n<p>设置人设与逻辑是创建智能体的关键步骤。在这一环节，我们需要明确智能体的行为模式和响应方式。</p>\n<p>对于抖音热点监控智能体，我们希望它能直接执行任务，无需过多交互。因此，我们设置简单明了的指令，让智能体在接收到关键词后立即执行视频采集工作。</p>\n<pre><code>直接执行`fetch_douyin_hot_videos`\n</code></pre>\n<p><strong>3、绑定工作流</strong></p>\n<p>把\"fetch_douyin_hot_videos\"工作流添加到智能体中。这个工作流是我们之前设计的抖音视频采集工作流，将它绑定到智能体后，用户只需输入关键词，智能体就会自动执行工作流，帮助我们高效地收集抖音热点视频。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>5、测试并发布</strong></p>\n<p>在预览与调试窗口中输入关键词，测试智能体采集热点抖音视频的功能。系统会自动执行工作流，并将结果添加到飞书表格中。</p>\n<p>使用不同关键词进行多次测试，确保智能体在各种情况下都能稳定运行。测试无误后，点击\"发布\"按钮将智能体正式发布到生产环境，供用户使用。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"5小红书热点监控工作流\">5.小红书热点监控工作流</h3>\n<p>接下来我们将深入了解如何实际搭建一个小红书热点监控工作流。</p>\n<p>这个工作流能帮你自动收集小红书平台上的热门内容，让你不用手动浏览就能掌握最新趋势。</p>\n<p>我们将使用简单易懂的步骤，带你从零开始构建这个强大的监控系统，即使你没有编程经验也能轻松上手。</p>\n<p>登录Coze官网，在“资源库-工作流”里新建一个空白工作流，取名“xhs_keywords”。工作流整体预览如图所示。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>1、开始节点</strong></p>\n<p>这里用于定义工作流启动时所需的输入参数。</p>\n<ul>\n<li>输入：\n<ul>\n<li>foldUrl：飞书表格链接，需要提前创建好一个飞书多维表格，并复制其链接。该表格将用于存储我们采集到的小红书热点视频</li>\n<li>cookie：小红书网站的cookie信息，这是访问小红书API的必要凭证，我们将在后面详细讲解如何获取</li>\n<li>keywords：用于搜索热点的关键词，可以是产品名称、行业术语、竞品名称或热门话题，系统会自动搜索相关的热门内容</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>2、如何获取小红书cookie</strong></p>\n<p>在Chrome浏览器中，登录小红书主页：<a href=\"https://www.xiaohongshu.com/\" rel=\"noopener nofollow\" target=\"_blank\">https://www.xiaohongshu.com/</a></p>\n<p>按F12键打开开发者工具面板，然后按照以下步骤操作：</p>\n<ul>\n<li>第一步：点击「网络」选项卡</li>\n<li>第二步：点击「文档」标签</li>\n<li>第三步：点击「explore」文档</li>\n<li>第四步：点击「标头」选项卡</li>\n<li>第五步：滚动页面找到Cookie字段，复制整段Cookie信息。</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>2、插件节点：根据关键词获取笔记</strong></p>\n<p>我们将使用“小红书”插件的xhs_search_note工具。通过这个功能，我们可以根据关键词，批量获取热门视频。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>输入：\n<ul>\n<li>cookieStr：开始节点的 cookie</li>\n<li>keywords：关键词，从开始节点获取</li>\n<li>notType：查询类型（0=全部，1=视频，2=图文），这里我们选择1 视频类型</li>\n<li>sort：排序（默认为综合，0=综合，1=最新，2=最热），这里我们选择2 最热</li>\n<li>totalNumber：查询总数，这里我们输入20</li>\n</ul>\n</li>\n</ul>\n<p><strong>3、循环节点：循环获取笔记详情</strong></p>\n<p>循环获取笔记详情是工作流中的关键环节，它使我们能够一次性处理多条小红书笔记。从搜索结果中获取笔记链接后，我们需要逐一获取每条笔记的详细信息，包括标题、内容、作者和点赞数等。</p>\n<ul>\n<li>输入：\n<ul>\n<li>input：从\"根据关键词获取笔记\"节点的输出中，选择 data</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>4、循环体内插件节点：获取笔记详情</strong></p>\n<p>我们将使用小红书插件的xhs_note_detail工具。该工具能获取每条笔记的完整信息，包括标题、内容、作者信息和互动数据等。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>输入\n<ul>\n<li>cookieStr：开始节点的 cookie</li>\n<li>noteUrl：从 “循环笔记详情” 节点的输出中，选择 noteUrl</li>\n</ul>\n</li>\n</ul>\n<p><strong>5、循环体内插件节点：提取视频文案</strong></p>\n<p>我们将使用\"字幕获取\"插件的generate_video_captions_sync工具。该工具能自动从视频中提取文字内容，将口述转换为文本，省去手动听写的麻烦。它能精准识别视频中的语音并生成文字记录，帮助我们快速理解视频的主题和关键信息。</p>\n<p>输入：</p>\n<ul>\n<li>url：从\"获取笔记详情\"节点的输出中，选择 video_h264_url，表示H264标准编码格式视频链接</li>\n<li>lang：视频语言，如汉语、英语等，不填时默认为汉语</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>6、循环体内代码节点：将笔记数据整理成飞书表格格式</strong></p>\n<p>这一步将采集到的视频信息转换为标准化数据结构，以便写入飞书表格。我们需要提取视频的标题、内容、作者和点赞数等关键信息，并按飞书表格要求进行格式化。这样不仅便于数据整理和筛选，还能帮助我们更直观地分析热门内容的特点。</p>\n<ul>\n<li>输入\n<ul>\n<li>input：从\"获取笔记详情\"节点的输出中，选择note</li>\n<li>data：从\"提取视频文案\"节点的输出中，选择data</li>\n</ul>\n</li>\n<li>输出\n<ul>\n<li>records：变量类型设置为 Array 对象数组，表示处理后的视频列表</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>下面是处理数据的Python代码，它将采集到的小红书视频信息转换为标准格式，便于存储和分析。</p>\n<p>代码提取视频的标题、内容、作者等关键信息，将其组织成飞书表格所需的格式，然后返回处理好的数据。这样我们能将所有热门视频整齐地存放在同一张表格中，方便后续分析：</p>\n<pre><code class=\"language-python\">async def main(args: Args) -&gt; Output:\n    input_data = args.params.get('input')  or {}\n    data = args.params.get('data') or {}\n\n    records = []  # 初始化 records 列表\n\n    # 提取 note 相关字段\n    title = input_data.get('note_display_title', '')  # 标题\n    desc = input_data.get('note_desc', '')  # 描述\n    url = input_data.get('note_url', '')  # 链接\n    nickname = input_data.get('auther_nick_name', '')  # 作者昵称\n    likedCount = input_data.get('note_liked_count', '0')  # 点赞数\n    videoUrl = input_data.get('video_h264_url', '')  # 视频地址\n    collectedCount = input_data.get('collected_count', '0')  # 收藏数\n    imageList = input_data.get('note_image_list', [])  # 图片列表\n\n    # 构建记录对象\n    record = {\n        \"fields\": {\n            \"笔记链接\": url,\n            \"标题\": title,\n            \"内容\": desc,\n            \"作者\": nickname,\n            \"点赞数\": likedCount,\n            \"链接\": {\n                \"link\": url,\n                \"text\": title\n            },\n            \"收藏数\": collectedCount,\n            \"图片地址\": '\\n'.join(imageList),  # 将图片列表拼接成字符串\n            \"视频地址\": videoUrl,\n            \"视频文案\": data.get(\"content\", \"\") \n        }\n    }\n    records.append(record)  # 将记录对象添加到 records 列表中\n\n    # 构建输出对象\n    ret: Output = {\n        \"records\": records\n    }\n    return ret\n</code></pre>\n<p><strong>7、循环体内插件节点：写入飞书表格</strong></p>\n<p>最后，我们将收集到的所有数据添加到飞书多维表格中。</p>\n<p>我们需要提前创建一个多维表格，并设置好对应的表头字段。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p>表头字段包括视频的所有关键信息：笔记链接、标题、内容、作者、点赞数、链接、收藏数、图片地址、视频地址和视频文案。</p>\n<p>接下来，选择\"飞书表格\"插件节点的add_records工具，将采集到的数据添加到多维表格中。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<ul>\n<li>输入：\n<ul>\n<li>app_token：提前创建一个多维表格，然后将多维表格的链接复制到此处。</li>\n<li>records：从\"将信息整理为飞书表格可以使用的数据\"节点的输出变量中，选择records。</li>\n<li>table_id：需填入多维表格数据表的唯一标识符。</li>\n</ul>\n</li>\n</ul>\n<p><strong>8、结束节点</strong></p>\n<p>最后添加结束节点，完成整个工作流程。如图6-25所示。</p>\n<ul>\n<li>输出：\n<ul>\n<li>output：开始节点的foldUrl，也就是飞书多维表格的链接</li>\n</ul>\n</li>\n</ul>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<h3 id=\"6小红书热点监控智能体设置\">6.小红书热点监控智能体设置</h3>\n<p>至此，我们已完成小红书热点监控工作流的搭建。接下来，我们将介绍如何设置小红书热点监控智能体。这个关键环节将工作流与智能体绑定在一起，只有完成这一步，才能真正实现小红书热点监控智能体的功能。</p>\n<p><strong>1、新建智能体</strong></p>\n<p>在Coze平台创建一个新的智能体，命名“小红书热点监控智能体”。如图6-26所示。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>2、设置人设与逻辑</strong></p>\n<p>设置人设与逻辑是创建智能体的关键步骤。在这一环节，我们需要明确智能体的行为模式和响应方式。</p>\n<p>对于小红书热点监控智能体，我们希望它能直接执行任务，无需过多交互。因此，我们设置简单明了的指令，让智能体在接收到关键词后立即执行视频采集工作。</p>\n<pre><code>直接执行`xhs_keywords`\n</code></pre>\n<p><strong>3、绑定工作流</strong></p>\n<p>把\"xhs_keywords\"工作流添加到智能体中。</p>\n<p><img alt=\"image.png\" class=\"lazyload\" /></p>\n<p><strong>4、测试并发布</strong></p>\n<p>在预览与调试窗口中输入关键词，测试智能体的小红书热点视频采集功能。系统会自动执行工作流，并将结果直接添加到飞书表格中。</p>\n<blockquote>\n<p>对了，我整理了一份开源的智能体学习手册，爆肝 10 万字，价值 999 元。限时开放领取👉：<a href=\"https://tangshiye.cn\" rel=\"noopener nofollow\" target=\"_blank\">tangshiye.cn</a></p>\n</blockquote>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/tangshiye/\" target=\"_blank\">AI架构师汤师爷</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/tangshiye/p/19575161\" target=\"_blank\">https://www.cnblogs.com/tangshiye/p/19575161</a></p>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 16:30</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tangshiye\">AI架构师汤师爷</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "浅谈数据访问层",
      "link": "https://www.cnblogs.com/legweifang/p/19575087",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/legweifang/p/19575087\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 16:23\">\n    <span>浅谈数据访问层</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p style=\"text-align: center;\">浅谈数据访问层</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp; 写下数据访问层这几个字，恐怕现在的程序员很少知道是什么意思的，他们可能知道数据实体，知道EF和SqlSugar，不知道数据访问层是咋回事。的确现在的ORM框架已经淡化了数据访问层的概念，现在只要会创建实体类，会调用EF就可以了，框架一切都是做好了，不用懂数据库，也不用关心是什么数据库，总之一套代码什么数据库都支持，还为这种开发模式起了名字叫CodeFirst（代码先行）。作为一名老程序员，我不知道软件开发模式为啥会演变到今天这个样子，搞的越来越复杂，越来越脱离根本。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp;我们那时候的程序员（大概范围是在2000年前后10年吧）要想学会软件开发，首先要学会使用数据库，要学会写sql，因为sql 是操作数据的根本，然后要学会存储过程，因为存储过程是性能优化的重要手段，还要学会视图，因为视图是数据关联的桥梁，还有触发器，是弥补功能缺陷的利器。而现在呢？这些全不被提倡了，这些传统的技术全成为了ORM 的绊脚石。在ORM框架里，数据库的组织和处理能力全部被实体类代替了，只剩下存储这一个功能了。</p>\n<p>&nbsp; &nbsp; &nbsp; &nbsp;现在的程序员不了解数据库，软件系统出了问题也不知道是什么原因，代码没问题，问题可能出在数据上。就好比现在的程序员也不懂硬件，甚至不会安装操作系统。我们那时候的程序员在很多人眼里就是修电脑的，其实主业是写代码，但人家不关心，也不了解，只知道会修电脑。现在呢，不是这样了，有人说这是行业的细分，专业的人就得做专业的事，但我觉得有些相关技能还是自己会比较好。</p>\n<p>&nbsp; &nbsp; &nbsp; 程序员必须要懂数据库，这是根本。</p>\n<p>&nbsp; &nbsp; &nbsp; 我遇到过一个程序员，他说他从来不会去写sql，用ORM框架多简单，不用ORM 就是一种落后，他很执着，我是没法反驳他的，因为这是当下流行的趋势，我只知道，要解决软件系统的问题，只了解程序代码是不够的，很多深层次的问题要查数据库，分析数据，这才能从本质上解决问题，否则很可能改了这个问题出来那个问题，按下葫芦起来瓢，永远改不完的问题。</p>\n<p>喜欢使用ORM框架的我总结了两个原因，第一、为了跨数据库，一套代码适合各种数据库；第二、不用学习sql语法、视图、存储过程、触发器，省去学习数据库的成本，其他我想不出更合适的理由。</p>\n<p>我不喜欢这种开发模式，ORM 把本该放在数据库上的精力，放在了程序上，那些拉姆达表达式比sql还难理解，我觉得这是本末倒置，认知上的倒退，道在迩而求诸远，事在易而求诸难。其实每种开发方式都有它的优缺点，没有对错，只有是否合适，适合你的，对你来说就是对的，不适合你的对你来说就是错的，不能一概而论。要解决问题，就用自己最擅长的方式。</p>\n<p>我提倡的方式是不用实体类，用传统的sql和DataTable，这是最简单最灵活的方式，也就是最传统的方式。这样既能熟悉了数据库又能灵活的编写代码。</p>\n<p>&nbsp; &nbsp; &nbsp; 我知道我写这篇文章很多人会反对，因为现在估计80%的人都在使用ORM框架开发，包括以前喜欢写sql的那批老程序员。这里呢我也不想争论，能解决问题就行。愿意用啥就用啥，但是要做到问题到我这里结束，不要说我不会这个，这个不管我的事，数据库我不会查，每个人要对自己选择的方式负责到底。</p>\n<p>&nbsp; &nbsp; &nbsp; 几年前，我比较看中程序代码的编写规范，我觉得代码应该看上去比较舒服，编码风格要一致，不仅仅是实现功能。有一位资深的程序员，不太认同，他说不管代码写的怎样，只要数据对就行，以数据库为准，现在我觉得他说的有一定道理，每个程序员的水平不一样，程序写的不好可以重写，但数据要对。产生数据的方式有很多，数据来源不止一个，有可能是手工录入的，有可能是接口推送的，有可能是导入的，不管是那种方式都要确保数据的准确性和完整性。</p>\n<p>&nbsp; &nbsp; &nbsp; 所以从本质上来说，数据访问层使用什么方式并不是最重要的。数据准确性和完整性才是最重要的。</p>\n<p>如果你赞同上面的分析，那么继续向下看如何设计简单实用的数据访问层，如果不赞同那就到次为止。因为后面的设计思想可能让你更加不屑。</p>\n<p>数据访问层的设计要解决一下几个问题：</p>\n<p>1、连接数据库。要支持连接多种类型的数据库，方式主要是通过官方提供的数据库访问类，例如SqlDataClient。</p>\n<p>2、基本的数据访问方法。执行新建insert、更新update、查询select，以及调用存储过程，这些基本就够了。再进一步归纳一下就是两个方法，ExecuteNonQuery 和ExecuteQuery。</p>\n<p>3、执行数据操作返回的数据对象。新增和更新返回的是影响的数据行数，存储过程返回的是执行是否成功（尽量避免使用存储过程的返回值），这些没什么好说的。需要说的是查询数据时返回数据对象。有两种对象，一种是DataTable ，一种是DataReader，DataTable 是比较传统的方式，也是最早被广泛使用的。DataReader 是后期才有的，可以看作是DataTable 的只读形式，目的是提高读取的性能，ORM 框架就是把DataReader 映射成实体类。这是目前被提倡的开发模式，但我们不用这种方式，而是继续用DataTable，因为我们不使用实体类。</p>\n<p>&nbsp; &nbsp; &nbsp; 下面我们对这三个问题展开说明，具体如何实现。</p>\n<p>&nbsp; &nbsp; &nbsp; 第一个问题，如何实现连接多种类型的数据库。</p>\n<p>&nbsp; &nbsp; &nbsp; 如在访问SqlServer 数据库的时候使用SqlDataClient(Net版本不同名字可能不一样)，访问MySql 数据库的时候使用MySql.DataClient。 最简单的办法就是使用接口类，定义一个接口类，把所有数据访问方法都定义出来，使用接口来调用方法，再创建访问SqlServer 的实现类和MySql 的实现类，都要实现该接口。然后最外层再做一个代理类Agent ，用来确定接口要调用哪个类。</p>\n<p>程序结构如下图：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162050993-867994170.png\" /></p>\n<p>接口的定义如下图（只显示主要的方法）：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162052693-107139067.png\" /></p>\n<p>代理类的定义如下图（只显示主要方法）：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162053367-1421368934.png\" /></p>\n<p>&nbsp; &nbsp; &nbsp; 第二个问题，操作数据库的基本方法，有人说基本方法是增删改查，这个没错，我觉得再进一步会归纳一下是执行和获取数据。就是两个方法ExecuteNonQuery和ExecuteQuery。其他所有的操作都是围绕这两个方法，也可以说都是调用这两个方法。要在每种类型的数据库访问类中实现这几个基本方法。</p>\n<p>以SqlServer 为例列出基本方法如下图（只显示主要的方法）：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162052434-912150011.png\" /></p>\n<p>&nbsp; &nbsp; &nbsp; 第三个问题，返回数据的对象。</p>\n<p>&nbsp; &nbsp; &nbsp; 前面说了我们用DataTable，而不用数据实体，主要是因为它灵活。这样设计是在项目中成本最低的方案。我曾经设想过使用数据实体的场景，那就是业务需求非常明确，调研充分，数据结构基本定型，字段数量类型都很确切，至少业务模型预演了几遍的，也就保证功能做出来不会经常修改。这种情况我见过，做过对日外包项目的都知道，简直是变态的设计要求，一个字段，一个输入框的尺寸，字数限制，验证提示都要在文档里写清楚，项目周期三个月的话文档要写两个半月。现实中这种情况太少了，很多情况我们拿到个大概的需求就动手了，一边做一边完善数据库字段，大方向不会错，增加个字段是常有的事。不要说这是违反软件开发规范的，严格遵守软件规范是很理想的事情，不知道大厂们是否能严格遵守软件开发规范？</p>\n<p>&nbsp; &nbsp; &nbsp; ExecuteQuery包括两个方法，一个是返回DataTable，一个是返回DataReader，严格来讲DataTable并不存在，在Net的Framework或NetCore框架中有两种方式返回DataTable，一种是通过DataAdapter对象的Fill方法填充DataTable，一种是使用DataReader填充DataTable，其实这已经足够用了。</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162053187-175167613.png\" /></p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162053774-1873792402.png\" /></p>\n<p>两种方法稍微有点差异，以后再慢慢说，真正使用的时候就知道了，这里不能说多了，说多容易跑题。</p>\n<p>&nbsp; &nbsp; &nbsp; 数据库访问类的设计是重点，除了提供基本方法外，还要处理好数据库连接、数据库关闭，开启事务、关闭事务，事务回滚。这都是很重要的概念，如果数据库只开不关，很快连接数量就用完了。初学者很容易犯的错误，一旦出现还很难排查。再有一个重要的概念是同一批数据操作尽量在一个数据库开闭中完成，不要反复的开闭数据库，例如，修改一条商品信息，先查询商品编号是否已经存在，如果不存在可以保存，已经存在提示重复，不能保存。这个功能包括2个数据操作，一个是按编号查询商品表，一个是更新商品表。这两个动作要在一个数据库连接中完成。不能每个动作都要开闭数据库。在早期的数据库访问层HFBPM3.5中，存在这个问题。那时候的设计考虑要支持本地调用和远程调用（WCF的方式），每个数据操作都可以调用远程的方法，不能在一个本地连接里完成。后来的版本去掉了远程调用。</p>\n<p>&nbsp; &nbsp; &nbsp; 提到WCF不得不跑个题，因为涉及到微软的技术框架，很早微软推出了三大框架WCF、WFF、WPF，至今只留下了WPF，其他两个在微软Core中基本消失了。微软的东西是好，用起来方便，功能也强大，但淘汰也快，太理想化的东西容易走偏，有些东西出的晚，生态就不好。比如这个MVC的架构，我到现在没怎么使用这个架构，但是这个思想我一直在用，在微软asp.net的时候，web界面要使用服务端控件，这个不方便，很快就被淘汰了，随着ajax和jquery的兴起时，我们在传统的aspx上使用ajax和jquery，即使用了aspx的后台功能，又使用了js前端框架的优势，就没有使用MVC，说实话微软的MVC框架出来的有点晚，我们已经在做了，HFbpm4.0使用的就是这种架构，这种架构也类似于NetCore的WebAPI架构，后台接口使用的MVC的路由机制，利用反射技术动态调用方法，比WebAPI还要灵活，WebAPI的依赖注入也有很多不灵活的地方，这里要细讲也需要很大的篇幅，先不赘述了，有兴趣的可以看一下hfbpm4.0的程序架构，总之一句话，用最简单的技术实现最基本的功能，大道至简。</p>\n<p>&nbsp; &nbsp; &nbsp; 这个题跑的有点远，赶紧回到正题上，开闭数据库和数据库事务，这些功能要手动来完成，默认的情况下，每次数据操作都要开闭数据库一次。我们通过数学控制数据操作后下不要关闭数据库连接，等操作完后再手动关闭。如下面的代码：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162056417-2110537453.png\" /></p>\n<p>&nbsp; &nbsp; &nbsp; 手动开启事务，手动关闭事务，如下图：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162056835-527302775.png\" /></p>\n<p>&nbsp; &nbsp; &nbsp; 这些测试工作是比较复杂的，为了方便测试开发了一个测试工具，主要测试多个操作是否开闭了一次数据库，数据库事务是否能正常回滚等。在执行数据库操作时为每次数据库连接定义一个随机数，从数据库连接打开到关闭，所有的数据库操作都返回这个随机数，如果随机数不一样，说明不是在一个数据库连接中完成的操作。如下图：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162055237-1397352915.png\" /></p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162052854-1127795205.png\" /></p>\n<p>&nbsp; &nbsp; &nbsp; 上面介绍的这些功能，是数据库操作的基本功能，有了这些就可以完成数据库的增删改查了。但是如果对一个开发平台来说，这些还不够，一个开发平台，还需要有数据库维护的功能，即元数据操作的功能，比如创建表、创建字段、修改字段，获取表结构等。这些功能也要在数据库访问层中实现。一个完整的数据库访问层应该包括一下功能：</p>\n<p><img src=\"https://img2024.cnblogs.com/blog/34454/202602/34454-20260204162053674-1995650034.png\" /></p>\n<p>&nbsp; &nbsp; &nbsp; 以上是对数据访问层的一点浅浅的认识，不正确的地方欢迎批评指正，很期待与同行们的交流。淌过的水，走过的路，踩过的坑分享出来，共同提高进步！</p>\n\n</div>\n<div id=\"MySignature\">\n    我的程序人生\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 16:23</span>&nbsp;\n<a href=\"https://www.cnblogs.com/legweifang\">云飞扬</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Apache SeaTunnel Zeta、Flink、Spark 怎么选？底层原理 + 实战对比一次讲透",
      "link": "https://www.cnblogs.com/seatunnel/p/19575007",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/seatunnel/p/19575007\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 16:05\">\n    <span>Apache SeaTunnel Zeta、Flink、Spark 怎么选？底层原理 + 实战对比一次讲透</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文档将深入解析 Apache SeaTunnel 支持的三大执行引擎：Zeta (SeaTunnel Engine)、Flink 和 Spark。我们将从架构设计、核心特性、优缺点对比以及使用方法等多个维度进行详细讲解，帮助你根据业务需求选择最合适的引擎。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p><img alt=\"对比\" class=\"lazyload\" /></p>\n<p>本文档将深入解析 Apache SeaTunnel 支持的三大执行引擎：<strong>Zeta (SeaTunnel Engine)</strong>、<strong>Flink</strong> 和 <strong>Spark</strong>。我们将从架构设计、核心特性、优缺点对比以及使用方法等多个维度进行详细讲解，帮助你根据业务需求选择最合适的引擎。</p>\n<h2 id=\"1-引擎概览\">1. 引擎概览</h2>\n<p>SeaTunnel 的架构设计采用了 <strong>API 与执行引擎解耦</strong> 的策略。这意味着同一套数据同步逻辑（Config）可以无缝运行在不同的引擎上。</p>\n<ul>\n<li><strong>Zeta Engine</strong>: SeaTunnel 社区专门为数据集成场景自研的新一代引擎，专注于高性能、低延迟的数据同步。</li>\n<li><strong>Flink Engine</strong>: 利用 Flink 强大的流处理能力，适合已拥有 Flink 集群的用户。</li>\n<li><strong>Spark Engine</strong>: 利用 Spark 强大的批处理能力，适合离线大规模数据处理场景。</li>\n</ul>\n<h2 id=\"2-zeta-引擎核心推荐\">2. Zeta 引擎——核心推荐</h2>\n<p>Zeta 是目前 SeaTunnel 社区主推的默认引擎。它旨在解决 Flink/Spark 在简单数据同步场景下“资源消耗大、部署运维重”的问题。</p>\n<h3 id=\"21-核心架构\">2.1 核心架构</h3>\n<p>Zeta 采用无中心化（Decentralized）或 Master-Slave 架构（取决于部署模式），主要包含以下组件：</p>\n<ul>\n<li><strong>Coordinator (Master)</strong>:\n<ul>\n<li><strong>作业解析</strong>: 将逻辑 DAG (Logical DAG) 转换为物理 DAG (Physical DAG)。</li>\n<li><strong>资源调度</strong>: 管理 Slot，向 Worker 分配任务。</li>\n<li><strong>Checkpoint Coordinator</strong>: 负责触发和协调分布式快照（基于 Chandy-Lamport 算法），保障数据一致性。</li>\n</ul>\n</li>\n<li><strong>Worker (Slave)</strong>:\n<ul>\n<li><strong>Task Execution</strong>: 运行 Source, Transform, Sink 任务。</li>\n<li><strong>Data Transport</strong>: 负责节点间的数据传输。</li>\n</ul>\n</li>\n<li><strong>ResourceManager</strong>: 支持 Standalone, YARN, Kubernetes 等多种资源管理模式。</li>\n</ul>\n<p><img alt=\"SeaTunnel Engine\" class=\"lazyload\" /></p>\n<h3 id=\"22-关键特性\">2.2 关键特性</h3>\n<ol>\n<li><strong>Pipeline 级容错 (Pipeline-level Fault Tolerance)</strong>:\n<ul>\n<li>不同于 Flink 的“全图重启”，Zeta 可以只重启失败的 Pipeline（例如多表同步中，表 A 失败不影响表 B）。</li>\n</ul>\n</li>\n<li><strong>增量快照 (Incremental Checkpoint)</strong>:\n<ul>\n<li>支持高频 Checkpoint，最小化数据丢失风险，同时对性能影响极小。</li>\n</ul>\n</li>\n<li><strong>动态扩缩容 (Dynamic Scaling)</strong>:\n<ul>\n<li>支持在作业运行时动态增加或减少 Worker 节点，无需重启作业。</li>\n</ul>\n</li>\n<li><strong>Schema Evolution (表结构变更)</strong>:\n<ul>\n<li>原生支持 DDL 变更同步（如 Add Column），这对 CDC 场景至关重要。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"23-使用指南\">2.3 使用指南</h3>\n<p>Zeta 引擎通常包含在 SeaTunnel 的二进制包中，开箱即用。</p>\n<p><strong>启动命令 (Local 模式 - 开发测试):</strong></p>\n<pre><code class=\"language-bash\">./bin/seatunnel.sh --config ./config/your_job.conf -e local\n</code></pre>\n<p><strong>启动命令 (Cluster 模式 - 生产环境):</strong></p>\n<ol>\n<li>启动 Server (Master/Worker):<pre><code class=\"language-bash\">./bin/seatunnel-cluster.sh -d\n</code></pre>\n</li>\n<li>提交任务到集群:<pre><code class=\"language-bash\">./bin/seatunnel.sh --config ./config/your_job.conf -e cluster\n</code></pre>\n</li>\n</ol>\n<h2 id=\"3-flink-引擎\">3. Flink 引擎</h2>\n<p><img alt=\"flink-1_highres\" class=\"lazyload\" /></p>\n<p>SeaTunnel 通过翻译层（Translation Layer）将内部的 Source/Sink API 适配为 Flink 的 <code>SourceFunction</code> / <code>SinkFunction</code> (或 Flink 新版 Source/Sink API)。</p>\n<h3 id=\"31-架构原理\">3.1 架构原理</h3>\n<ul>\n<li><strong>Translation</strong>: SeaTunnel 在 Client 端将 Config 解析并翻译成 Flink JobGraph。</li>\n<li><strong>Execution</strong>: 提交给 Flink Cluster 执行。此时，SeaTunnel 任务就是一个标准的 Flink 任务。</li>\n<li><strong>State Backend</strong>: 依赖 Flink 的 Checkpoint 机制（RocksDB/FsStateBackend）管理状态。</li>\n</ul>\n<h3 id=\"32-优缺点\">3.2 优缺点</h3>\n<ul>\n<li><strong>优点</strong>: 生态成熟，运维工具丰富，适合复杂的流式计算+同步场景。</li>\n<li><strong>缺点</strong>: 版本耦合严重（需适配 Flink 1.13-1.18 等不同版本），对于纯同步任务显得过重。</li>\n</ul>\n<h3 id=\"33-使用指南\">3.3 使用指南</h3>\n<p>需要下载对应的 <code>seatunnel-flink-starter</code> jar 包，并确保 Flink 环境已准备好。</p>\n<p><strong>启动命令 (Flink 1.13+):</strong></p>\n<pre><code class=\"language-bash\">./bin/start-seatunnel-flink-13-connector-v2.sh \\\n    --config ./config/your_job.conf \\\n    --run-mode run # 或 run-application\n</code></pre>\n<p><em>(注意：不同 Flink 版本脚本名称略有不同，如 <code>flink-15</code>, <code>flink-18</code>)</em></p>\n<h2 id=\"4-spark-引擎\">4. Spark 引擎</h2>\n<p><img alt=\"spark\" class=\"lazyload\" /></p>\n<p>类似于 Flink，SeaTunnel 将 Source/Sink 适配为 Spark 的 <code>DataSource V2</code> API。</p>\n<h3 id=\"41-架构原理\">4.1 架构原理</h3>\n<ul>\n<li><strong>Batch</strong>: 使用 Spark RDD / DataFrame API 执行离线批处理。</li>\n<li><strong>Streaming</strong>: 使用 Spark Streaming (Micro-batch) 执行流式处理。</li>\n</ul>\n<h3 id=\"42-优缺点\">4.2 优缺点</h3>\n<ul>\n<li><strong>优点</strong>: 批处理性能强大，在大规模离线数据清洗/ETL 场景表现优异。</li>\n<li><strong>缺点</strong>: 流处理基于微批（Micro-batch），延迟通常高于 Flink/Zeta；资源调度较慢。</li>\n</ul>\n<h3 id=\"43-使用指南\">4.3 使用指南</h3>\n<p>需要下载对应的 <code>seatunnel-spark-starter</code> jar 包。</p>\n<p><strong>启动命令 (Spark 3.x):</strong></p>\n<pre><code class=\"language-bash\">./bin/start-seatunnel-spark-3-connector-v2.sh \\\n    --config ./config/your_job.conf \\\n    --master local[4] # 或 yarn, k8s\n</code></pre>\n<h2 id=\"5-三大引擎全方位对比\">5. 三大引擎全方位对比</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">Zeta (SeaTunnel Engine)</th>\n<th style=\"text-align: left;\">Flink Engine</th>\n<th style=\"text-align: left;\">Spark Engine</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>定位</strong></td>\n<td style=\"text-align: left;\"><strong>数据同步专用</strong></td>\n<td style=\"text-align: left;\">通用流批计算</td>\n<td style=\"text-align: left;\">通用批流计算</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>适用场景</strong></td>\n<td style=\"text-align: left;\">海量数据集成、CDC 实时同步、多表整库同步</td>\n<td style=\"text-align: left;\">复杂流式计算 + 同步</td>\n<td style=\"text-align: left;\">大规模离线清洗、ETL</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>部署复杂度</strong></td>\n<td style=\"text-align: left;\"><strong>低</strong> (内置，开箱即用)</td>\n<td style=\"text-align: left;\">中 (需维护 Flink 集群)</td>\n<td style=\"text-align: left;\">中 (需维护 Spark 集群)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>资源消耗</strong></td>\n<td style=\"text-align: left;\"><strong>低</strong> (针对同步优化，无多余开销)</td>\n<td style=\"text-align: left;\">中/高</td>\n<td style=\"text-align: left;\">中/高</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>延迟</strong></td>\n<td style=\"text-align: left;\"><strong>低</strong> (实时流)</td>\n<td style=\"text-align: left;\">低 (实时流)</td>\n<td style=\"text-align: left;\">中 (微批)</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>容错粒度</strong></td>\n<td style=\"text-align: left;\"><strong>Pipeline 级</strong> (局部重启)</td>\n<td style=\"text-align: left;\">Job 级 (全局重启)</td>\n<td style=\"text-align: left;\">Stage/Task 级</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>CDC 支持</strong></td>\n<td style=\"text-align: left;\"><strong>完美</strong> (支持 Schema Evolution)</td>\n<td style=\"text-align: left;\">良好</td>\n<td style=\"text-align: left;\">一般</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>多版本适配</strong></td>\n<td style=\"text-align: left;\">无需适配 (自带)</td>\n<td style=\"text-align: left;\">需严格匹配 Flink 版本</td>\n<td style=\"text-align: left;\">需严格匹配 Spark 版本</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"6-如何选择\">6. 如何选择？</h2>\n<ol>\n<li>\n<p><strong>如果你是新项目，或者主要需求是数据同步 (Data Integration)</strong>:</p>\n<ul>\n<li>👉 <strong>首选 Zeta 引擎</strong>。它最轻量、性能最好，且对 CDC 和多表同步有特殊优化。</li>\n</ul>\n</li>\n<li>\n<p><strong>如果你已经有现成的 Flink/Spark 集群，且运维团队不想维护新引擎</strong>:</p>\n<ul>\n<li>👉 选择 <strong>Flink</strong> 或 <strong>Spark</strong> 引擎，复用现有基础设施。</li>\n</ul>\n</li>\n<li>\n<p><strong>如果你的任务包含极其复杂的自定义计算逻辑 (Complex Computation)</strong>:</p>\n<ul>\n<li>👉 优先考虑 <strong>Flink</strong> (流) 或 <strong>Spark</strong> (批)，利用其丰富的算子生态。但也可以考虑 <strong>Zeta + SQL Transform</strong> 满足大部分需求。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"7-新手入门指南\">7. 新手入门指南</h2>\n<p>如果你是第一次接触 SeaTunnel，请按照以下步骤快速体验 Zeta 引擎的强大功能。</p>\n<h3 id=\"71-环境准备\">7.1 环境准备</h3>\n<p>确保你的机器上安装了 Java 8 或 Java 11。</p>\n<pre><code class=\"language-bash\">java -version\n</code></pre>\n<h3 id=\"72-下载与安装\">7.2 下载与安装</h3>\n<ol>\n<li><strong>下载</strong>: 从 <a href=\"https://seatunnel.apache.org/download\" rel=\"noopener nofollow\" target=\"_blank\">Apache SeaTunnel 官网</a> 下载最新版本的二进制包 (<code>apache-seatunnel-x.x.x-bin.tar.gz</code>)。</li>\n<li><strong>解压</strong>:<pre><code class=\"language-bash\">tar -zxvf apache-seatunnel-*.tar.gz\ncd apache-seatunnel-*\n</code></pre>\n</li>\n</ol>\n<h3 id=\"73-安装-connector-插件-重要\">7.3 安装 Connector 插件 (重要!)</h3>\n<p><strong>这是新手最容易忽略的一步</strong>。默认包不包含所有 Connector，你需要运行脚本自动下载。</p>\n<pre><code class=\"language-bash\"># 自动安装 plugin_config 配置文件中定义的所有插件\nsh bin/install-plugin.sh\n</code></pre>\n<h3 id=\"74-快速运行第一个任务\">7.4 快速运行第一个任务</h3>\n<p>创建一个简单的配置文件 <code>config/quick_start.conf</code>，将数据从 Fake 源生成并打印到控制台：</p>\n<pre><code class=\"language-hocon\">env {\n  execution.parallelism = 1\n  job.mode = \"BATCH\"\n}\n\nsource {\n  FakeSource {\n    result_table_name = \"fake\"\n    row.num = 100\n    schema = {\n      fields {\n        name = \"string\"\n        age = \"int\"\n      }\n    }\n  }\n}\n\ntransform {\n  # 简单的 SQL 处理\n  Sql {\n    source_table_name = \"fake\"\n    result_table_name = \"sql_result\"\n    query = \"select name, age from fake where age &gt; 50\"\n  }\n}\n\nsink {\n  Console {\n    source_table_name = \"sql_result\"\n  }\n}\n</code></pre>\n<p><strong>运行任务 (Local 模式)</strong>:</p>\n<pre><code class=\"language-bash\">./bin/seatunnel.sh --config ./config/quick_start.conf -e local\n</code></pre>\n<p>如果看到控制台输出了数据表格，恭喜你，你已经成功掌握了 SeaTunnel 的基本用法！</p>\n<h2 id=\"8-zeta-引擎原理深度学习路径\">8. Zeta 引擎原理深度学习路径</h2>\n<p>如果你希望深入了解 Zeta 引擎的内部运作机制，或者想参与社区贡献，可以按照以下路径进行源码阅读和调试。</p>\n<h3 id=\"81-核心模块概览\">8.1 核心模块概览</h3>\n<p>Zeta 引擎的代码主要集中在 <code>seatunnel-engine</code> 模块下：</p>\n<ul>\n<li><strong>seatunnel-engine-core</strong>: 定义了核心数据结构（如 <code>Job</code>, <code>Task</code>）和通信协议。</li>\n<li><strong>seatunnel-engine-server</strong>: 包含了 Coordinator 和 Worker 的具体实现逻辑。</li>\n<li><strong>seatunnel-engine-client</strong>: 客户端提交逻辑。</li>\n</ul>\n<h3 id=\"82-源码阅读推荐路径\">8.2 源码阅读推荐路径</h3>\n<h4 id=\"1-作业提交与解析-coordinator-侧\">1. 作业提交与解析 (Coordinator 侧)</h4>\n<p>从 <code>JobMaster</code> 类开始，了解作业是如何被接收和初始化的。</p>\n<ul>\n<li><strong>入口</strong>: <code>org.apache.seatunnel.engine.server.master.JobMaster</code></li>\n<li><strong>逻辑</strong>: 关注 <code>init</code> 和 <code>run</code> 方法，了解 <code>LogicalDag</code> 到 <code>PhysicalPlan</code> 的转换过程。</li>\n</ul>\n<h4 id=\"2-任务执行-worker-侧\">2. 任务执行 (Worker 侧)</h4>\n<p>了解 Task 是如何被调度和执行的。</p>\n<ul>\n<li><strong>服务入口</strong>: <a href=\"seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java\" rel=\"noopener nofollow\" target=\"_blank\">TaskExecutionService.java</a>\n<ul>\n<li>该类负责管理 Worker 节点上的所有 TaskGroup。</li>\n</ul>\n</li>\n<li><strong>执行上下文</strong>: <code>org.apache.seatunnel.engine.server.execution.TaskExecutionContext</code></li>\n</ul>\n<h4 id=\"3-checkpoint-机制-核心难点\">3. Checkpoint 机制 (核心难点)</h4>\n<p>Zeta 的快照机制是保证数据一致性的关键。</p>\n<ul>\n<li><strong>协调器</strong>: <a href=\"seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java\" rel=\"noopener nofollow\" target=\"_blank\">CheckpointCoordinator.java</a>\n<ul>\n<li>重点阅读 <code>triggerCheckpoint</code> 方法，了解 Barrier 是如何分发的。</li>\n</ul>\n</li>\n<li><strong>计划</strong>: <a href=\"seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointPlan.java\" rel=\"noopener nofollow\" target=\"_blank\">CheckpointPlan.java</a>\n<ul>\n<li>了解 Checkpoint 涉及的任务范围是如何计算的。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"83-调试技巧\">8.3 调试技巧</h3>\n<ol>\n<li><strong>修改日志级别</strong>: 在 <code>config/log4j2.properties</code> 中，将 <code>org.apache.seatunnel</code> 的级别调整为 <code>DEBUG</code>，可以看到详细的 RPC 通信和状态变更日志。</li>\n<li><strong>本地调试</strong>: 在 IDE 中直接运行 <code>org.apache.seatunnel.core.starter.seatunnel.SeaTunnelStarter</code> 类，传入 <code>-c config/your_job.conf -e local</code> 参数，即可断点调试整个流程。</li>\n</ol>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 16:05</span>&nbsp;\n<a href=\"https://www.cnblogs.com/seatunnel\">ApacheSeaTunnel</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "从零开始学Flink：状态管理与容错机制",
      "link": "https://www.cnblogs.com/daimajiangxin/p/19574902",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/daimajiangxin/p/19574902\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 15:48\">\n    <span>从零开始学Flink：状态管理与容错机制</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"从零开始学Flink：状态管理与容错机制\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3365149/202602/3365149-20260204154757186-1959035735.png\" />\n        本文深入解析 Apache Flink 的核心特性——状态管理（State Management）与容错机制（Fault Tolerance），涵盖状态类型、State Backend 选择、Checkpoint 原理及配置、以及 Savepoint 的生产实践。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>流式计算任务通常需要 7x24 小时长期运行，面对网络抖动、机器故障或代码 Bug，如何保证任务不挂？或者挂了之后能自动恢复且数据不丢、不重？这正是 Flink 引以为傲的资本：<strong>强大的状态管理</strong>与<strong>基于 Checkpoint 的容错机制</strong>。</p>\n<p>本文将带你深入理解 Flink 是如何“记忆”数据的，以及它是如何在故障发生时“时光倒流”恢复现场的。</p>\n<h2 id=\"一什么是状态state\">一、什么是状态（State）</h2>\n<p>在流计算中，数据是一条条流过的。如果处理一条数据时，需要依赖<strong>之前</strong>的数据（例如：计算过去一小时的总和、去重、模式匹配），那么这些“之前的数据”或“中间计算结果”就是<strong>状态</strong>。</p>\n<h3 id=\"1-状态的分类\">1. 状态的分类</h3>\n<p>Flink 的状态分为两大类：<strong>Managed State（托管状态）</strong> 和 <strong>Raw State（原生状态）</strong>。我们日常开发 99% 使用的是托管状态，由 Flink 运行时自动管理内存、序列化和故障恢复。</p>\n<p>Managed State 又细分为：</p>\n<ul>\n<li><strong>Keyed State（键控状态）</strong>\n<ul>\n<li>只能在 <code>KeyedStream</code>（即 <code>keyBy</code> 之后）上使用。</li>\n<li>状态是跟 Key 绑定的。Flink 为每个 Key 维护一份独立的状态实例。</li>\n<li>常用类型：<code>ValueState</code>、<code>ListState</code>、<code>MapState</code>、<code>ReducingState</code>、<code>AggregatingState</code>。</li>\n</ul>\n</li>\n<li><strong>Operator State（算子状态）</strong>\n<ul>\n<li>绑定到算子并行实例（SubTask），与 Key 无关。</li>\n<li>常用于 Source Connector（记录读取的 Offset）或 Sink Connector（事务控制）。</li>\n<li>常用接口：<code>ListState</code>、<code>UnionListState</code>、<code>BroadcastState</code>。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"二状态后端state-backends\">二、状态后端（State Backends）</h2>\n<p>状态存在哪里？是内存还是磁盘？这由 <strong>State Backend</strong> 决定。在 Flink 1.13 之后，配置方式简化为以下两种主要模式：</p>\n<h3 id=\"1-hashmapstatebackend-基于内存\">1. HashMapStateBackend (基于内存)</h3>\n<ul>\n<li><strong>存储位置</strong>：Java 堆内存（Heap）。</li>\n<li><strong>特点</strong>：读写速度极快（对象直接访问，无序列化开销）。</li>\n<li><strong>适用场景</strong>：状态较小（例如仅仅是简单的 Count 或去重），对延迟极其敏感的场景。</li>\n<li><strong>缺点</strong>：受限于 JVM 堆大小，容易 GC；状态过大时可能 OOM。</li>\n</ul>\n<h3 id=\"2-embeddedrocksdbstatebackend-基于磁盘\">2. EmbeddedRocksDBStateBackend (基于磁盘)</h3>\n<ul>\n<li><strong>存储位置</strong>：TaskManager 本地磁盘（基于 RocksDB 数据库），内存中只作为缓存（Off-heap）。</li>\n<li><strong>特点</strong>：支持超大状态（TB 级别），不受 JVM 堆限制。</li>\n<li><strong>适用场景</strong>：超大窗口、超长周期的聚合、海量 Key 的去重。</li>\n<li><strong>缺点</strong>：需要序列化/反序列化，读写性能略低于内存版；需要调优 RocksDB 参数。</li>\n</ul>\n<h3 id=\"3-配置示例\">3. 配置示例</h3>\n<pre><code class=\"language-java\">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n// 设置状态后端为 RocksDB\nenv.setStateBackend(new EmbeddedRocksDBStateBackend());\n\n// 配合 Checkpoint 存储路径（存储在本地文件系统）\nenv.getCheckpointConfig().setCheckpointStorage(\"file:///tmp/flink/checkpoints\");\n</code></pre>\n<h2 id=\"三容错核心checkpoint\">三、容错核心：Checkpoint</h2>\n<p>Checkpoint（检查点）是 Flink 容错机制的灵魂。它是一个<strong>全局一致性快照</strong>，定期将所有算子的状态持久化到远程存储（如 HDFS）。</p>\n<h3 id=\"1-核心原理barrier-对齐\">1. 核心原理：Barrier 对齐</h3>\n<p>Flink 使用 <strong>Chandy-Lamport 算法</strong> 的变体。</p>\n<ol>\n<li><strong>Barrier 注入</strong>：JobManager 向 Source 发送 Checkpoint Barrier。</li>\n<li><strong>Barrier 流动</strong>：Barrier 像普通数据一样在流中传输。</li>\n<li><strong>对齐（Alignment）</strong>：当算子有多个输入流时，必须等待所有流的 Barrier 到齐，才能进行 Snapshot。这保证了状态的一致性（即 Exactly-Once）。</li>\n<li><strong>异步快照</strong>：算子将状态写入远程存储（异步过程），不阻塞数据处理。</li>\n<li><strong>确认完成</strong>：所有算子都完成快照后，JobManager 确认 Checkpoint 成功。</li>\n</ol>\n<h3 id=\"2-checkpoint-配置实战\">2. Checkpoint 配置实战</h3>\n<p>默认情况下 Checkpoint 是关闭的，生产环境<strong>必须开启</strong>。</p>\n<pre><code class=\"language-java\">// 1. 开启 Checkpoint，每 5000ms 触发一次\nenv.enableCheckpointing(5000);\n\n// 2. 设置 Checkpoint 模式（默认 EXACTLY_ONCE，也可以设为 AT_LEAST_ONCE）\nenv.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);\n\n// 3. 设置两次 Checkpoint 之间的最小间隔（防止频繁 Checkpoint 导致性能下降）\nenv.getCheckpointConfig().setMinPauseBetweenCheckpoints(1000);\n\n// 4. Checkpoint 超时时间（默认 10分钟）\nenv.getCheckpointConfig().setCheckpointTimeout(60000);\n\n// 5. 允许同时进行的 Checkpoint 数量（通常设为 1）\nenv.getCheckpointConfig().setMaxConcurrentCheckpoints(1);\n\n// 6. 开启作业取消时保留 Checkpoint（非常重要！否则 Cancel 任务会删除 Checkpoint）\nenv.getCheckpointConfig().setExternalizedCheckpointCleanup(\n    CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION\n);\n\n// 7. 容忍 Checkpoint 失败次数（默认 0，即 Checkpoint 失败会导致任务重启）\nenv.getCheckpointConfig().setTolerableCheckpointFailureNumber(3);\n</code></pre>\n<h2 id=\"四savepoint手动的超级-checkpoint\">四、Savepoint：手动的超级 Checkpoint</h2>\n<p>虽然 Checkpoint 和 Savepoint 看起来很像（都是快照），但它们的定位完全不同：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">特性</th>\n<th style=\"text-align: left;\">Checkpoint</th>\n<th style=\"text-align: left;\">Savepoint</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\"><strong>触发方式</strong></td>\n<td style=\"text-align: left;\">Flink 定时自动触发</td>\n<td style=\"text-align: left;\">用户手动命令触发</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>主要目的</strong></td>\n<td style=\"text-align: left;\"><strong>故障恢复</strong>（Failover）</td>\n<td style=\"text-align: left;\"><strong>运维操作</strong>（升级、扩容、迁移）</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>存储格式</strong></td>\n<td style=\"text-align: left;\">增量存储（依赖 StateBackend 优化）</td>\n<td style=\"text-align: left;\">标准格式，全量存储（可跨版本）</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>生命周期</strong></td>\n<td style=\"text-align: left;\">随作业生命周期管理（除非设置保留）</td>\n<td style=\"text-align: left;\">用户自行管理（删除需手动）</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"常用命令\">常用命令</h3>\n<pre><code class=\"language-bash\"># 触发 Savepoint\nbin/flink savepoint &lt;jobId&gt; [targetDirectory]\n\n# 从 Savepoint 重启作业 (或者 Checkpoint)\nbin/flink run -s &lt;savepointPath&gt; ...\n</code></pre>\n<h2 id=\"五重启策略restart-strategies\">五、重启策略（Restart Strategies）</h2>\n<p>当任务发生故障（Exception）时，Flink 会尝试根据配置的策略自动重启。</p>\n<pre><code class=\"language-java\">// 1. 固定延迟重启（尝试 3 次，每次间隔 10秒）\nenv.setRestartStrategy(RestartStrategies.fixedDelayRestart(\n    3, \n    Duration.ofSeconds(10)\n));\n\n// 2. 失败率重启（在 5 分钟内失败超过 3 次则停止，否则每次间隔 10秒重启）\nenv.setRestartStrategy(RestartStrategies.failureRateRestart(\n    3, \n    Duration.ofMinutes(5), \n    Duration.ofSeconds(10)\n));\n\n// 3. 无重启（直接失败）\nenv.setRestartStrategy(RestartStrategies.noRestart());\n</code></pre>\n<h2 id=\"六总结\">六、总结</h2>\n<ul>\n<li><strong>State</strong> 是 Flink 实现复杂逻辑的记忆。</li>\n<li><strong>State Backend</strong> 决定了记忆存哪里（内存快但小，RocksDB 大但需序列化）。</li>\n<li><strong>Checkpoint</strong> 是自动化的定期备份，保证故障恢复后的数据一致性。</li>\n<li><strong>Savepoint</strong> 是手动的高级备份，用于版本升级和应用迁移。</li>\n</ul>\n<p>掌握了状态与容错，你的 Flink 任务才算真正具备了“生产级”的健壮性。下一篇，我们将探讨 Flink SQL，看看如何用 SQL 解决 80% 的流计算需求。</p>\n<hr />\n<p>原文来自：<a href=\"http://blog.daimajiangxin.com.cn\" rel=\"noopener nofollow\" target=\"_blank\">http://blog.daimajiangxin.com.cn</a></p>\n<p>源码地址：<a href=\"https://gitee.com/daimajiangxin/flink-learning\" rel=\"noopener nofollow\" target=\"_blank\">https://gitee.com/daimajiangxin/flink-learning</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 15:48</span>&nbsp;\n<a href=\"https://www.cnblogs.com/daimajiangxin\">代码匠心</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "istio流量分发实战：从配置到踩坑全解析",
      "link": "https://www.cnblogs.com/MrVolleyball/p/19574573",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/MrVolleyball/p/19574573\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 15:04\">\n    <span>istio流量分发实战：从配置到踩坑全解析</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        \n        本文通过一个真实的 Istio 流量分发案例，系统梳理按比例、按 Header、按 URL 前缀等常见路由方式，并重点分析 Host 不匹配导致流量失效的根因。结合 Nginx 与 Sidecar 共存场景，详细说明金丝雀、灰度、蓝绿及 A/B 测试在 Istio 中的落地方式，适合正在或即将引入 Istio 的工程实践参考\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<h2 id=\"前言\">前言</h2>\n<p>上一小节，istio成功的安装，并且还解决了常见的426的问题，本节内容主要探讨一下istio关于流量转发的问题</p>\n<h2 id=\"按比例分发\">按比例分发</h2>\n<h4 id=\"配置\">配置</h4>\n<p>需要创建一个backend-v1，它与backend的selector都是<code>app: backend</code>，backend-v1部署完成之后，它会立即分走50%的流量，为了测试istio流控，我们需要在不改变任何配置的情况下实现9:1分流，也就是90%进入原backend，10%进入新的backend-v1</p>\n<p><img alt=\"watermarked-istio_functions_1\" class=\"lazyload\" /></p>\n<ul>\n<li>\n<p>标记2个deployment，追加标签，backend为<code>version: v0</code>，backend-v1为<code>version: v1</code></p>\n<pre><code>kubectl patch deployment backend -p '{\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"version\":\"v0\"}}}}}'\nkubectl patch deployment backend-v1 -p '{\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"version\":\"v1\"}}}}}'\n</code></pre>\n</li>\n<li>\n<p>创建istio资源：DestinationRule，该资源主要用来标记istio要往哪个地方转发</p>\n<pre><code>apiVersion: networking.istio.io/v1\nkind: DestinationRule\nmetadata:\n  name: backend-dr\n  namespace: default\nspec:\n  host: backend-service\n  subsets:\n  - labels:\n      version: v0\n    name: v0\n  - labels:\n      version: v1\n    name: v1\n\n</code></pre>\n</li>\n<li>\n<p>创建istio资源：VirtualService，该资源用来确定转发的权重</p>\n<pre><code>apiVersion: networking.istio.io/v1\nkind: VirtualService\nmetadata:\n  name: backend-vs\n  namespace: default\nspec:\n  hosts:\n  - backend-service\n  http:\n  - route:\n    - destination:\n        host: backend-service\n        subset: v0\n      weight: 90\n    - destination:\n        host: backend-service\n        subset: v1\n      weight: 10\n</code></pre>\n</li>\n</ul>\n<h4 id=\"调试\">调试</h4>\n<ul>\n<li>\n<p>测试命令： <code>for i in {1..10}; do curl -s 10.22.12.178:30785/test &gt; /dev/null ; done</code></p>\n</li>\n<li>\n<p>登录到k8s的istio-proxy控制台查看： <code>kubectl logs -f -l app=backend -c istio-proxy</code></p>\n<pre><code>[2026-01-28T08:24:55.670Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n[2026-01-28T08:24:55.687Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n[2026-01-28T08:24:55.706Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:24:55.741Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=1ms route=default\n[2026-01-28T08:24:55.751Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:24:55.759Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:24:55.696Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n[2026-01-28T08:24:55.716Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n[2026-01-28T08:24:55.725Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n[2026-01-28T08:24:55.734Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n\n</code></pre>\n<pre><code>▶ kubectl get pod -owide\nNAME                          READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES\nbackend-86b958bdc-5zjgn       2/2     Running   0          21m     10.244.0.53   wilson   &lt;none&gt;           &lt;none&gt;\nbackend-v1-75ccff86dc-sl6bt   2/2     Running   0          119s    10.244.0.55   wilson   &lt;none&gt;           &lt;none&gt;\nnginx-test-7d87875694-8vsrp   2/2     Running   0          30m     10.244.0.61   wilson   &lt;none&gt;           &lt;none&gt;\n</code></pre>\n</li>\n<li>\n<p>明显不对，10.244.0.55与10.244.0.53的比例并没有呈现9:1，转发到backend要backend-v1还是5:5</p>\n</li>\n</ul>\n<h4 id=\"修复\">修复</h4>\n<p>可以直接修改nginx的配置</p>\n<pre><code>server {\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n\n    location /test {\n        proxy_http_version 1.1;\n        # proxy_set_header Host $host; # 原配置\n        proxy_set_header Host backend-service.default.svc.cluster.local; # 新配置\n        proxy_pass http://backend-service:10000;\n    }\n}\n</code></pre>\n<p>重启之后再次测试：</p>\n<pre><code>[2026-01-28T08:30:59.968Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:30:59.988Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=1ms route=default\n[2026-01-28T08:31:00.027Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=1ms route=default\n[2026-01-28T08:31:00.037Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:31:00.048Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:31:00.056Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:31:00.008Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.55:10000 duration=0ms route=default\n[2026-01-28T08:31:00.066Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:31:00.074Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n[2026-01-28T08:31:00.083Z] \"GET /test HTTP/1.1\" 200 - upstream=10.244.0.53:10000 duration=0ms route=default\n</code></pre>\n<p>已经生效了，这次只有1次10.244.0.55:10000</p>\n<h4 id=\"疑问\">疑问</h4>\n<p>有位大哥说了，如果这样配置的，明显影响了业务：</p>\n<ul>\n<li>nginx的配置被修改了</li>\n<li>所有的host被写死了，都成了：backend-service.default.svc.cluster.local，而后端业务是需要把客户端的host带入过去的，改了之后后端业务收到严重影响</li>\n</ul>\n<p>确实，固定host属于粗暴简单的写法，还有更加惊喜的解决方法，调整VirtualService，添加hosts</p>\n<pre><code>apiVersion: networking.istio.io/v1\nkind: VirtualService\nmetadata:\n  name: backend-vs\n  namespace: default\nspec:\n  hosts:\n  - backend-service\n  - api.wilsontest.com # 新增\n  http:\n  - route:\n    - destination:\n        host: backend-service\n        subset: v0\n      weight: 90\n    - destination:\n        host: backend-service\n        subset: v1\n      weight: 10\n</code></pre>\n<p>客户端访问的时候必须带上该域名： <code>for i in {1..10}; do curl -s -H 'host: api.wilsontest.com' 10.22.12.178:30785/test &gt; /dev/null ; done</code></p>\n<p>这样也可以解决问题，不过坑点也来了，年久失修，从无数前人继承的祖传代码，就需要好好的梳理到底有哪些host来访问，否则漏掉host的话，就会出现配置问题。-_-!</p>\n<p>再次凸显了istio之中，host是非常非常重要的，Istio 的路由决策、Service 的匹配完全依赖 Host 头</p>\n<ul>\n<li>Istio 的 VirtualService 本质上是一个“增强版”的路由器。如果发现请求的 Host 是 backend-service，就按 90:10 分配。</li>\n<li>之前的配置是$host，由于客户端没有传输host，当请求经过 Nginx 的 Sidecar时，它会检查Host，发现为空。由于路由表里没有对应的记录 ，sidecar并不认识，按普通 K8s 流量处理</li>\n</ul>\n<h2 id=\"按header分发\">按header分发</h2>\n<pre><code>apiVersion: networking.istio.io/v1\nkind: VirtualService\nmetadata:\n  name: backend-vs\n  namespace: default\nspec:\n  hosts:\n  - backend-service\n  - api.wilsontest.com\n  http:\n  - match:\n    - headers:\n        hellotest:\n          exact: \"true\"\n    route:\n    - destination:\n        host: backend-service\n        subset: v1\n  - route:\n    - destination:\n        host: backend-service\n        subset: v0\n</code></pre>\n<p><code>curl -s -H 'host: api.wilsontest.com' -H 'hellotest: true' 10.22.12.178:30785/test</code>。只有header里面匹配了<code>hellotest: true</code>才会去v1，否则全部去v0</p>\n<h2 id=\"按前缀分发\">按前缀分发</h2>\n<pre><code>apiVersion: networking.istio.io/v1\nkind: VirtualService\nmetadata:\n  name: backend-vs\n  namespace: default\nspec:\n  hosts:\n  - backend-service\n  - api.wilsontest.com\n  http:\n  - match:\n    - uri:\n        prefix: /test/v1\n    route:\n    - destination:\n        host: backend-service\n        subset: v1\n  - route:\n    - destination:\n        host: backend-service\n        subset: v0\n</code></pre>\n<p>带有/test/v1前缀的都会去新版本v1，满足不了条件都会走默认的版本v0</p>\n<h2 id=\"url改写\">url改写</h2>\n<pre><code>apiVersion: networking.istio.io/v1\nkind: VirtualService\nmetadata:\n  name: backend-vs\n  namespace: default\nspec:\n  hosts:\n  - backend-service\n  - api.wilsontest.com\n  http:\n  - match:\n    - uri:\n        prefix: /test/v1\n    route:\n    - destination:\n        host: backend-service\n        subset: v1\n  - match:\n    - uri:\n        prefix: /test/v2\n    rewrite:\n      uri: /test\n    route:\n    - destination:\n        host: backend-service\n        subset: v0\n  - route:\n    - destination:\n        host: backend-service\n        subset: v0\n\n</code></pre>\n<p>如果是/test/v1，就访问v1版本，/test/v2重写成/test并且访问v0版本，其余的默认都会走v0版本</p>\n<h2 id=\"蓝绿金丝雀灰度ab测试\">蓝绿、金丝雀、灰度、A/B测试</h2>\n<p>关于流量分流的各种操作，大部分都集中在以下场景：</p>\n<ul>\n<li>蓝绿：实现瞬间切换与零宕机回滚，消除发布期间的中间状态</li>\n<li>金丝雀：像矿工用金丝雀探测毒气一样，先让一小部分用户（如1%~5%）访问新版本，观察系统指标（如错误率、延迟），若无问题再逐步扩大范围</li>\n<li>灰度：将用户群体按比例或特定规则（如地域、设备）逐步切换到新版本（例如10%→30%→100%），持续观察反馈</li>\n<li>A/B：同时向随机分组的用户展示不同版本（A组用旧版，B组用新版），通过统计指标（如点击率、转化率）判断哪个版本更优</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>蓝绿发布</th>\n<th>金丝雀发布</th>\n<th>灰度发布</th>\n<th>A/B测试</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>主要目标</td>\n<td>零停机、瞬时回滚</td>\n<td>用真实流量快速发现技术风险</td>\n<td>平稳、可控地逐步替换所有用户</td>\n<td>验证不同版本的业务效果</td>\n</tr>\n<tr>\n<td>流量路由</td>\n<td>全量切换（100%→0%）</td>\n<td>极小比例引流（如1%-5%）</td>\n<td>按比例分阶段扩大（10%→50%→100%）</td>\n<td>按规则/随机分配（如50%/50%）</td>\n</tr>\n<tr>\n<td>关注重点</td>\n<td>系统可用性与回滚速度</td>\n<td>系统稳定性指标（错误率、延迟）</td>\n<td>发布过程平稳性与综合反馈</td>\n<td>业务指标（转化率、留存率）</td>\n</tr>\n<tr>\n<td>所需资源</td>\n<td>两套完整环境，成本高</td>\n<td>一套环境，新版本实例较少</td>\n<td>一套环境，新旧版本实例共存</td>\n<td>一套或多套环境，并行运行多个版本</td>\n</tr>\n<tr>\n<td>用户选择</td>\n<td>全体用户同时切换</td>\n<td>小部分用户随机或按基础设施选择</td>\n<td>用户按比例或属性逐步迁移</td>\n<td>用户随机分组或按属性定向分配</td>\n</tr>\n<tr>\n<td>持续时间</td>\n<td>极短（切换在几分钟内）</td>\n<td>短（几小时到一天）</td>\n<td>中长（几天到数周）</td>\n<td>长（数周到数月）</td>\n</tr>\n<tr>\n<td>典型场景</td>\n<td>关键业务大版本升级、基础设施更换</td>\n<td>后端服务、中间件、数据库变更</td>\n<td>前端功能、用户界面更新</td>\n<td>UI设计、文案、算法策略、定价优化</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"联系我\">联系我</h2>\n<ul>\n<li>联系我，做深入的交流</li>\n</ul>\n<p><img alt=\"\" class=\"lazyload\" height=\"200\" width=\"500\" /></p>\n<hr />\n<p>至此，本文结束<br />\n在下才疏学浅，有撒汤漏水的，请各位不吝赐教...</p>\n\n\n</div>\n<div id=\"MySignature\">\n    <p>本文来自博客园，作者：<a href=\"https://www.cnblogs.com/MrVolleyball/\" target=\"_blank\">it排球君</a>，转载请注明原文链接：<a href=\"https://www.cnblogs.com/MrVolleyball/p/19574573\" target=\"_blank\">https://www.cnblogs.com/MrVolleyball/p/19574573</a></p>\n<div>本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须在文章页面给出原文连接，否则保留追究法律责任的权利。 </div>\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 15:04</span>&nbsp;\n<a href=\"https://www.cnblogs.com/MrVolleyball\">it排球君</a>&nbsp;\n阅读(<span id=\"post_view_count\">0</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Agentic Coding一些实践总结",
      "link": "https://www.cnblogs.com/tsingroo/p/19573451",
      "published": "",
      "description": "<h2 class=\"post-title\">\n            <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/tsingroo/p/19573451\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 11:55\">\n    <span>Agentic Coding一些实践总结</span>\n    \n\n</a>\n\n        </h2>\n        <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p>&nbsp; 最近一年AI编码飞速发展，现在我的90%以上的代码都是出自AI。想想在2024年调用OpneAI官方接口（3.5模型）,超过10K的Token就让LLM的上下文完全混乱，导致LLM无法记住太多东西，更不用说调用工具，生成代码了。到目前为止，用了各种工具已经半年以上了，记录一下总体的实践经验。后面将cursor、Claude Code、OpenCode等工具统称为AgenticCoding工具，我的主要工作语言是go/Rust，各个工具和模型在不同语言上会有所差异，你自己的结论可能和我不太一样。</p>\n<p><strong><span style=\"font-size: 16px;\">&nbsp; 1.Agentic Coding是工具的扩展，而不是智能的扩展（就目前来看）</span></strong></p>\n<p>&nbsp; 虽然现在接近90%以上的代码都能由AI生成，但是这些工具还是依赖于你或者团队原先的见识、知识、流程等，本质还是工具。<strong><span style=\"color: rgba(255, 0, 0, 1);\">如果之前你的团队或者你没有接触过良好的软件工程管理、规范或实践，那你在有了Agentic Coding之后只是感觉上让你更爽了一点而已，对于软件工程的管理甚至会起到反作用。</span></strong><span style=\"color: rgba(0, 0, 0, 1);\">比如更多的未经审查的代码会进入git仓库，更多的不明确的需求导致Agnetic Coding工具的自由发挥空间过大，AI在不恰当的地方过度设计，未经审查合并代码后导致测试人员更难发现BUG，以及提交自己看不明白的代码导致线上出问题后无法快速排查，技术债越来越多。</span></p>\n<p><strong><span style=\"font-size: 16px;\">&nbsp; 2.【好的上下文工程+一般的模型】效果好于【一般的上下文工程+好的大模型】</span></strong></p>\n<p>&nbsp; 这里的上下文工程就是各类编码工具。Agentic Coding工具就是使用良好的上下文管理加上你提供的提示词来调用大模型接口，并使用大模型的接口的返回来决定下一步如何做。</p>\n<p>&nbsp; 仅就go语言而言，经过几个月的测试，Claude Code使用GLM 4.7(或者Kimi 2.5) 要好于 Kiro使用Claude Opus 4.5或者antigravity使用 Claude Opus 4.5。这个也可能是与语言相关。 我没用过Claude Code搭配原生的Sonnet或者Opus模型，但是在cursor+Opus跟使用cursor+kimi差异没有想的那么大。</p>\n<p><span style=\"font-size: 16px;\"><strong>&nbsp; 3.如果你需求管理混乱，你要先规范需求；如果你的团队流程混乱，你要先规范流程</strong></span></p>\n<p>&nbsp; 有些公司，包括一些大公司的一些部门，管理比较混乱。需求评审的时候，产品只能拿出一个想法和简单的几句话的文档，但是又要开发预估时间，之后开发过程中会不断发现问题，导致后面需求和前面的需求大相径庭，有时候进入测试之后产品还在调整需求文档。部门领导对此视而不见，如果有人说流程混乱、需求混乱，那就先把提问题的这个人解决掉，就不会有问题了。有些小公司有这种情况，有些大公司的某些部分也有这种情况。<span style=\"color: rgba(255, 0, 0, 1);\">如果我没遇到，我敢瞎说？😓</span></p>\n<p>&nbsp; 不解决需求和流程混乱的问题，在Agentic Coding的加持下，每个人只会更累，生成的代码也会更乱。<span style=\"color: rgba(255, 0, 0, 1);\">AI时代，你首先得知道自己想要什么，你不能在你自己还不清楚的情况下先把代码写完了</span>。</p>\n<p><span style=\"font-size: 16px;\"><strong>&nbsp; 4.要注重知识共享和落地讲解，跟随AI工具的发展</strong></span></p>\n<p>&nbsp; 不要口头说一个东西多好多有用，要在团队中，打开项目，以一个实际需求为例，给大家展示一下这个技术有多好。比如MCP/Skills，不要夸他有多好，不光要推荐给大家，还要以实际拉个会议来讲解如果落地使用，否则就跟空喊：“努力努力，加油加油”一样。当然这也不是一个人责任，团队中可以定期分享。比如Claude Code中的斜杠命令、SubAgents、Skill等。</p>\n<p>&nbsp; 附加: 斯坦福大学的<a href=\"https://themodernsoftware.dev/\" rel=\"noopener nofollow\" target=\"_blank\">《CS 146S: 现代软件开发者》</a>这门课。</p>\n<p><span style=\"font-size: 16px;\"><strong>&nbsp; 5.一些技巧</strong></span></p>\n<ul>\n<li>&nbsp;编写代码的时候一定要先使用Plan模式制定规划，并再次让AI审查计划，之后才让AI编写代码。目前主流Agentic Coding工具均已支持Plan模式</li>\n<li>让AI写代码之前，先将当前的代码都提交。这样如果AI生成的不满意可以随时撤销代码。同时【个人建议】不要给工具git commit和git push权限</li>\n<li>如果Agentic Coding工具生成的代码，时常偏离项目或者你的预期。你需要将你的预期以及限制写到类似CLAUDE.md或者skills中，来让AI来遵守</li>\n<li>所有AI生成的代码，目前阶段都要人工审核后才能提交到代码仓库</li>\n<li>在达到LLM的上下文阈值之前开启新会话来做任务。目前几百K的Token注意力，在某些时候感觉已经超过了人类的注意力(我没有关注的点，AI会意外的考虑到)，但是上下文一长之后就容易腐坏(Context Rot)。</li>\n</ul>\n<p>&nbsp;</p>\n\n</div>\n<div class=\"clear\"></div>\n\n        <p class=\"postfoot\">\n            posted on \n<span id=\"post-date\">2026-02-04 11:55</span>&nbsp;\n<a href=\"https://www.cnblogs.com/tsingroo\">阿摩罗识</a>&nbsp;\n阅读(<span id=\"post_view_count\">82</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n\n        </p>"
    },
    {
      "title": "AI开发-python-langchain框架（1-10 返回日期-格式解析器）",
      "link": "https://www.cnblogs.com/yclh/p/19573432",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/yclh/p/19573432\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 11:52\">\n    <span>AI开发-python-langchain框架（1-10 返回日期-格式解析器）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body blogpost-body-html\" id=\"cnblogs_post_body\">\n<p><span class=\"qwen-markdown-text\">如何让大模型返回的结果是一个标准的日期格式？</span></p>\n<p><span class=\"qwen-markdown-text\">如下这段代码展示了如何使用 LangChain 构建一个结构化输出链（chain），将自然语言问题（“中华人民共和国是什么时候创立的？”）通过大语言模型（LLM）转换为标准的 Python <code class=\"qwen-markdown-codespan\" style=\"cursor: pointer;\">datetime</code><span class=\"qwen-markdown-text\"> 对象</span></span></p>\n<div class=\"cnblogs_Highlighter\">\n<pre class=\"brush:python;gutter:true;\">from langchain.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain.output_parsers import DatetimeOutputParser\nimport os\n\n# 日期时间输出解析器 自动将模型返回的文本字符串解析为 Python 的 datetime 对象\noutput_parser = DatetimeOutputParser()\n\nprint('###########原生的提示词是英文的')\nformat_instructions=output_parser.get_format_instructions()\nprint(format_instructions)\nprint('###########')\n\n\ntemplate = \"\"\"回答用户的问题:\n{question}\n{format_instructions}\"\"\"\n\nformat_instructions='''响应的格式用日期时间字符串:“%Y-%m-%dT%H:%M:%S.%fZ”。\n示例: 1898-05-31T06:59:40.248940Z, 1808- 10-20T01:56:09.167633Z、0226-10-17T06:18:24.192024Z\n仅返回此字符串！'''\n\nprompt = PromptTemplate.from_template(\n    template,\n    partial_variables={\"format_instructions\":format_instructions},\n)\n\n#输出提示词\nprint(prompt.invoke({\"question\": \"中华人民共和国是什么时候创立的？\"}).text)\n\nllm = ChatOpenAI(\n    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n    base_url=os.getenv(\"BASE_URL\"),  # Deepseek 的 API 基础地址\n    model=\"deepseek-v3:671b\",  # Deepseek 对话模型（可选：deepseek-chat-pro 等高级模型）\n    temperature=0.7,  # 温度参数（0-1，越低越稳定）\n    max_tokens=1024  # 最大生成 tokens\n)\n\n\nchain = prompt | llm | output_parser\n\nprint('--------------')\nresult = chain.invoke({\"question\": \"中华人民共和国是什么时候创立的？\"})\nprint(result)\n</pre>\n</div>\n<p>&nbsp;返回结果：</p>\n<p>###########原生的提示词是英文的<br />Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.<br /><br />Examples: 1466-10-12T18:56:24.473648Z, 0322-04-03T12:00:41.805552Z, 1762-08-02T08:58:50.100670Z<br /><br />Return ONLY this string, no other words!<br />###########<br />回答用户的问题:<br />中华人民共和国是什么时候创立的？<br />响应的格式用日期时间字符串:“%Y-%m-%dT%H:%M:%S.%fZ”。<br />示例: 1898-05-31T06:59:40.248940Z, 1808- 10-20T01:56:09.167633Z、0226-10-17T06:18:24.192024Z<br />仅返回此字符串！<br />--------------<br />1949-10-01 00:00:00</p>\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 11:52</span>&nbsp;\n<a href=\"https://www.cnblogs.com/yclh\">万笑佛</a>&nbsp;\n阅读(<span id=\"post_view_count\">21</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "Redisson 使用手册：从 API 误区到看门狗失效，在此终结分布式锁的噩梦",
      "link": "https://www.cnblogs.com/xzqcsj/p/19573422",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/xzqcsj/p/19573422\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 11:49\">\n    <span>Redisson 使用手册：从 API 误区到看门狗失效，在此终结分布式锁的噩梦</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                    <div id=\"cnblogs_post_description\" style=\"display: none;\">\n        <img alt=\"Redisson 使用手册：从 API 误区到看门狗失效，在此终结分布式锁的噩梦\" class=\"desc_img\" src=\"https://img2024.cnblogs.com/blog/3703499/202602/3703499-20260204114906823-385277354.png\" />\n        在上一篇《分布式锁的代价与选择：为什么我们最终拥抱了Redisson？》中，我们聊到了手写 SETNX 的\"茹毛饮血\"时代。既然选择了 Redisson，就意味着我们已经告别了那些让人提心吊胆的死锁噩梦。\n很多时候，我们以为只是调用了一个简单的 lock.lock()，但背后其实是一整套复杂的自动续期、Lua 脚本原子执行和发布订阅机制在默默支撑。\n这篇文章不讲虚的，我们从常用的 API 起手，一路通过生产环境的避坑实战，最后钻进底层数据结构与 Lua 源码里，把 Redisson 彻底扒个干干净净。\n    </div>\n<div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<blockquote>\n<p><strong>写在前面</strong></p>\n<p>在上一篇<a href=\"https://mp.weixin.qq.com/s/IkRhzVdLvjr4V3ojdu_4gA\" rel=\"noopener nofollow\" target=\"_blank\">《分布式锁的代价与选择：为什么我们最终拥抱了Redisson？》</a>中，我们聊到了手写 <code>SETNX</code> 的\"茹毛饮血\"时代。既然选择了 <strong>Redisson</strong>，就意味着我们已经告别了那些让人提心吊胆的死锁噩梦。</p>\n<p>很多时候，我们以为只是调用了一个简单的 <code>lock.lock()</code>，但背后其实是一整套复杂的<strong>自动续期</strong>、<strong>Lua 脚本原子执行</strong>和<strong>发布订阅机制</strong>在默默支撑。</p>\n<p>这篇文章不讲虚的，我们从<strong>常用的 API</strong> 起手，一路通过<strong>生产环境的避坑实战</strong>，最后钻进<strong>底层数据结构与 Lua 源码</strong>里，把 Redisson 彻底扒个干干净净。</p>\n</blockquote>\n<hr />\n<h2 id=\"一不仅是-lock-这么简单核心-api-全景\">一、不仅是 Lock 这么简单：核心 API 全景</h2>\n<p>Redisson 之所以受欢迎，是因为它把分布式锁封装成了我们最熟悉的 <code>java.util.concurrent.locks.Lock</code> 接口风格，<strong>极大地降低了学习成本</strong>。但除了最基础的 <code>lock()</code>，还有核心功能是你必须掌握的。</p>\n<h3 id=\"1-基础那把锁rlock\">1. 基础那把锁：<code>RLock</code></h3>\n<p>这是 <strong>90% 场景下</strong>的默认选择。它对应 Redis 底层的 <strong>Hash</strong> 结构。</p>\n<pre><code class=\"language-java\">RLock lock = redisson.getLock(\"order:1001\");\nlock.lock(); // 阻塞式等待，默认 30秒过期，自带看门狗\ntry {\n   // 业务逻辑\n} finally {\n   lock.unlock();\n}\n</code></pre>\n<h3 id=\"2-更聪明的锁trylock-️推荐\">2. 更聪明的锁：<code>tryLock</code> (⚡️推荐)</h3>\n<p>在实际业务中，我们往往不希望线程无限死等，浪费资源。这里有两种常见姿势：</p>\n<h4 id=\"姿势-a要等待--启用看门狗-最常用\">姿势 A：要等待 + 启用看门狗 (最常用)</h4>\n<p>只指定 <code>waitTime</code>，不指定 <code>leaseTime</code>。这是<strong>既想要非阻塞（或有限等待），又想要自动续期</strong>的最佳实践。</p>\n<pre><code class=\"language-java\">// 参数1：wait time，我只愿意排队 3秒，拿不到就走人\n// 参数2：时间单位\n// 重点：没传 leaseTime，所以看门狗机制会自动生效！\nboolean res = lock.tryLock(3, TimeUnit.SECONDS);\n\nif (res) {\n   try {\n     // 处理业务（哪怕跑 5分钟 也不怕锁过期）\n   } finally {\n     lock.unlock();\n   }\n} else {\n   log.warn(\"抢锁失败，别挤了！\");\n}\n</code></pre>\n<h4 id=\"姿势-b要等待--自动过期-慎用\">姿势 B：要等待 + 自动过期 (慎用)</h4>\n<p>指定了 <code>leaseTime</code>，看门狗会失效。</p>\n<pre><code class=\"language-java\">// 参数1：wait time，排队 3秒\n// 参数2：lease time，上锁后 10秒 自动强制释放（注意：指定 leaseTime 会让看门狗失效！）\n// 参数3：时间单位\nboolean res = lock.tryLock(3, 10, TimeUnit.SECONDS);\n\nif (res) {\n   try {\n     // 处理业务，必须保证在 10秒 内完成！\n   } finally {\n     lock.unlock();\n   }\n}\n</code></pre>\n<h3 id=\"3-文明的排队公平锁-fairlock\">3. 文明的排队：公平锁 <code>FairLock</code></h3>\n<p>默认的锁是<strong>非公平</strong>的（Non-Fair），线程抢锁全靠 CPU 调度，谁快谁得。但如果你的业务要求\"先来后到\"（比如抢票排队），请务必使用公平锁。</p>\n<pre><code class=\"language-java\">// 内部利用 Redis 的 List（作为线程等待队列）和 Hash（作为超时记录）实现\nRLock fairLock = redisson.getFairLock(\"ticket:queue\");\nfairLock.lock();\n</code></pre>\n<h3 id=\"4-读多写少的神器读写锁-readwritelock\">4. 读多写少的神器：读写锁 <code>ReadWriteLock</code></h3>\n<p>这个场景太经典了：商品详情页，读的人多（10000次/秒），改库存的人少（1次/秒）。如果全互斥，性能直接崩盘。</p>\n<pre><code class=\"language-java\">RReadWriteLock rwLock = redisson.getReadWriteLock(\"product:stock:101\");\n\n// 读锁：多个线程可以同时加读锁，只要没有写锁\nrwLock.readLock().lock();\n\n// 写锁：必须等所有读锁和写锁都释放了才能加，全互斥\nrwLock.writeLock().lock();\n</code></pre>\n<h3 id=\"5-联锁-multilock-原子性加多把锁\">5. 联锁 <code>MultiLock</code> (原子性加多把锁)</h3>\n<p>有时候我们需要同时锁定多个资源，比如\"库存\"和\"余额\"，要么都锁住，要么都不锁，<strong>防止死锁</strong>。</p>\n<pre><code class=\"language-java\">RLock lock1 = redisson.getLock(\"lock:order\");\nRLock lock2 = redisson.getLock(\"lock:stock\");\n// 同时加锁：lock1 lock2\nRedissonMultiLock lock = new RedissonMultiLock(lock1, lock2);\nlock.lock();\n</code></pre>\n<hr />\n<h2 id=\"二扒开底层hash-结构与-lua-脚本\">二、扒开底层：Hash 结构与 Lua 脚本</h2>\n<blockquote>\n<p>以下源码基于 <strong>Redisson 3.16+</strong> 版本（目前生产环境主流版本）分析。</p>\n</blockquote>\n<p>Redisson 为什么能实现<strong>可重入锁</strong>？为什么它比我们自己写的 SETNX 强？<br />\n答案藏在 Redis 的数据结构里。Redisson 并没有使用简单的 <code>String</code> 类型，而是使用了 <strong><code>Hash</code></strong>。</p>\n<h3 id=\"1-redis-里的样子\">1. Redis 里的样子</h3>\n<p>假设我们对 <code>order:1001</code> 加锁，Redis 里实际存储的数据长这样：</p>\n<pre><code class=\"language-bash\">KEY: order:1001\nTYPE: Hash\n\n# hash 对应 value 内容\n{\n    \"UUID:ThreadID\" : 1  # 锁的持有者 : 重入次数\n}\n</code></pre>\n<ul>\n<li><strong>KEY</strong>: 锁的名字。</li>\n<li><strong>FIELD</strong> (Key): <code>UUID:ThreadId</code>。这里由客户端生成的唯一 UUID 加上当前线程 ID 拼接而成。<strong>为什么要加 UUID？</strong> 因为不同服务器上的 JVM 进程 ID 可能一样，必须通过客户端启动时生成的 UUID（ConnectionManagerId）来唯一标识一个 Redisson 实例。</li>\n<li><strong>VALUE</strong>: <code>1</code>。这是重入计数器。如果同一个线程再 lock 一次，这里变成 2。</li>\n</ul>\n<h3 id=\"2-加锁的-lua-脚本\">2. 加锁的 Lua 脚本</h3>\n<p>Redisson 为了保证一系列判断和写入是原子的，把它封装在 Lua 脚本里发给 Redis。</p>\n<pre><code class=\"language-lua\">-- KEYS[1] = 锁名称\n-- ARGV[1] = 过期时间 (默认 30000ms)\n-- ARGV[2] = 锁持有者唯一ID (UUID:ThreadId)\n\n-- 情况 1：锁根本不存在\nif (redis.call('exists', KEYS[1]) == 0) then\n    -- 创建 Hash，设置重入次数为 1\n    redis.call('hincrby', KEYS[1], ARGV[2], 1);\n    -- 设置过期时间\n    redis.call('pexpire', KEYS[1], ARGV[1]);\n    return nil; -- 返回 null 表示加锁成功\nend;\n\n-- 情况 2：锁存在，且持有者就是我（重入）\nif (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then\n    -- 重入次数 +1\n    redis.call('hincrby', KEYS[1], ARGV[2], 1);\n    -- 重新续期\n    redis.call('pexpire', KEYS[1], ARGV[1]);\n    return nil;\nend;\n\n-- 情况 3：锁存在，但不是我\n-- 返回当前锁还剩多少毫秒过期，方便客户端等待\nreturn redis.call('pttl', KEYS[1]);\n</code></pre>\n<p>这段脚本完美解释了：</p>\n<ol>\n<li><strong>原子性</strong>：这一大坨逻辑在 Redis 里是原子执行的，不会插队。</li>\n<li><strong>可重入</strong>：通过 <code>hexists</code> 判断是不是自己，是的话就 <code>hincrby</code>。</li>\n<li><strong>互斥性</strong>：如果既不是新锁，也不是自己的锁，直接返回剩余时间，让你可以去睡一会儿再来。</li>\n</ol>\n<hr />\n<h2 id=\"三拆开看门狗的黑盒源码漫游\">三、拆开看门狗的黑盒：源码漫游</h2>\n<p>经常听说\"看门狗\"，它到底长什么样？<br />\n其实，它本质上是一个 <strong>HashedWheelTimer（时间轮）</strong> 驱动的定时任务。</p>\n<h3 id=\"1-启动入口\">1. 启动入口</h3>\n<p>当我们调用 <code>lock()</code> <strong>不传时间</strong>时，最终会走到这里：</p>\n<pre><code class=\"language-java\">// RedissonLock.java\nprivate void lock(long leaseTime, TimeUnit unit, boolean interruptibly) throws InterruptedException {\n    long threadId = Thread.currentThread().getId();\n    Long ttl = tryAcquire(leaseTime, unit, threadId);\n\n    // 如果 lock 成功，ttl 会返回 null\n    if (ttl == null) {\n        return;\n    }\n    \n    // 如果失败，会订阅一个 Redis Channel，等待锁释放的消息（不用死循环空转）\n    // ... 省略订阅逻辑\n}\n</code></pre>\n<p>关键在 <code>tryAcquireAsync</code> 里：</p>\n<pre><code class=\"language-java\">private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) {\n    if (leaseTime != -1) {\n        // 如果你传了时间，就按你的时间走，不启动看门狗\n        return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\n    }\n    \n    // 没传时间（leaseTime = -1）\n    // 先设置默认 30秒 过期\n    RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\n    \n    // 加锁成功后，开启续期任务\n    ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; {\n        if (e == null) {\n           if (ttlRemaining == null) {\n               // 重点：启动定时续期\n               scheduleExpirationRenewal(threadId);\n           }\n        }\n    });\n    return ttlRemainingFuture;\n}\n</code></pre>\n<h3 id=\"2-续期的无限套娃\">2. 续期的无限套娃</h3>\n<p><code>scheduleExpirationRenewal</code> 最终会调用 <code>renewExpiration</code>：</p>\n<pre><code class=\"language-java\">private void renewExpiration() {\n    // 这里的 1/3 是硬编码的规则\n    // 默认 lockWatchdogTimeout 是 30000ms\n    // 所以每 10000ms 执行一次\n    Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() {\n        @Override\n        public void run(Timeout timeout) throws Exception {\n            \n            // 执行 Lua 脚本，把 ttl 重新刷回 30秒\n            RFuture&lt;Boolean&gt; future = renewExpirationAsync(threadId);\n            \n            future.onComplete((res, e) -&gt; {\n                if (res) {\n                    // 如果续期成功，这就形成了递归调用：自己调自己\n                    renewExpiration();\n                }\n            });\n        }\n    }, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS);\n}\n</code></pre>\n<p><strong>核心逻辑总结</strong>：</p>\n<ol>\n<li><strong>三分之一原则</strong>：每隔锁超时时间的 1/3（默认10秒），检查一次。</li>\n<li><strong>无限递归</strong>：只要检查到锁还在，就重置过期时间，并注册下一次检查。</li>\n<li><strong>生死绑定</strong>：这个任务跑在客户端进程里，如果客户端宕机，任务停止，Redis 里的锁在 30秒 后自动过期。</li>\n</ol>\n<hr />\n<h2 id=\"四我在生产环境踩过的坑避坑实战\">四、我在生产环境踩过的坑：避坑实战</h2>\n<p>API 谁都会调，但能避开坑的才是老司机。这六个坑，都是真金白银换来的教训。</p>\n<h3 id=\"-陷阱一好心办坏事--弄死看门狗\">💣 陷阱一：好心办坏事 —— 弄死看门狗</h3>\n<p>这是新手最容易犯的错。</p>\n<p><strong>❌ 错误姿势</strong>：</p>\n<pre><code class=\"language-java\">// 我怕死锁，所以强行指定 10秒 过期\nlock.lock(10, TimeUnit.SECONDS); \n// 或者\nlock.tryLock(1, 10, TimeUnit.SECONDS);\n</code></pre>\n<p><strong>⚠️ 后果</strong>：<br />\n<strong>Redisson 的看门狗（WatchDog）机制只有在你<code>未指定</code>锁过期时间时才会生效！</strong><br />\n一旦你手动传了 <code>leaseTime</code>，Redisson 就会认为你有自己的想法，不再插手。如果你的业务因为数据库卡顿跑了 15秒，第 10秒 时锁就会强制过期，其他线程长驱直入，爆发并发事故。</p>\n<p><strong>✅ 正确姿势</strong>：<br />\n除非你非常确定业务能在指定时间内跑完，否则<strong>尽量不要传 leaseTime，让看门狗帮你自动续期</strong>。</p>\n<h3 id=\"-陷阱二锁粒度太粗--全服暂停键\">💣 陷阱二：锁粒度太粗 —— 全服暂停键</h3>\n<p><strong>❌ 错误姿势</strong>：</p>\n<pre><code class=\"language-java\">// 所有订单共用一把锁\nRLock lock = redisson.getLock(\"LOCK_ORDER\");\n</code></pre>\n<p><strong>⚠️ 后果</strong>：<br />\n这相当于把高速公路封成了独木桥。不管有多少个用户下单，同一时间只能处理一个。性能直接归零。</p>\n<p><strong>✅ 正确姿势</strong>：<br />\n<strong>锁的粒度越细越好</strong>。只锁那个具体产生竞争的资源 ID。</p>\n<pre><code class=\"language-java\">// 只锁这个订单\nRLock lock = redisson.getLock(\"order:pay:\" + orderId);\n</code></pre>\n<h3 id=\"-陷阱三解锁的艺术--谁加的锁谁来解\">💣 陷阱三：解锁的艺术 —— 谁加的锁谁来解</h3>\n<p><strong>❌ 错误姿势</strong>：</p>\n<pre><code class=\"language-java\">try {\n    // 业务逻辑\n} finally {\n    lock.unlock(); // 直接解锁\n}\n</code></pre>\n<p><strong>⚠️ 后果</strong>：</p>\n<ol>\n<li>如果业务执行超时，锁已经被自动释放了，你再去 <code>unlock</code> 会抛出 <code>IllegalMonitorStateException</code>。</li>\n<li>如果不小心解了别人的锁（虽然 Redisson 有 ID 校验防止误删，但异常处理依然重要）。</li>\n</ol>\n<p><strong>✅ 正确姿势</strong>：</p>\n<pre><code class=\"language-java\">if (lock.isLocked() &amp;&amp; lock.isHeldByCurrentThread()) {\n    lock.unlock();\n}\n</code></pre>\n<h3 id=\"-陷阱四重入锁的递归噩梦\">💣 陷阱四：重入锁的\"递归噩梦\"</h3>\n<p>Redisson 的锁虽然是可重入的（Reentrant），但如果你在递归或嵌套调用中不注意，很容易逻辑混乱。</p>\n<p><strong>❌ 风险代码</strong>：</p>\n<pre><code class=\"language-java\">void methodA() {\n    lock.lock();\n    try {\n        methodB(); // methodB 里又 lock 了一次\n    } finally {\n        lock.unlock(); // 只解了一层\n    }\n}\n</code></pre>\n<p><strong>⚠️ 后果</strong>：<br />\nRedis 里的锁计数器（Counter）如果不归零，锁是不会释放的。确保你的加锁次数和解锁次数<strong>严格匹配</strong>。</p>\n<h3 id=\"-陷阱五主从切换的幽灵锁\">💣 陷阱五：主从切换的\"幽灵锁\"</h3>\n<p>这是 Redis 架构天生的短板。</p>\n<ol>\n<li>Client A 在 <strong>Master</strong> 节点拿到了锁。</li>\n<li>Master 还没来得及把锁同步给 Slave，就<strong>宕机</strong>了。</li>\n<li>Slave 升级为新的 Master。</li>\n<li>Client B 来加锁，发现新 Master 上没锁，于是也<strong>加锁成功</strong>。</li>\n</ol>\n<p><strong>⚠️ 后果</strong>：<br />\nA 和 B 同时持有了锁。<br />\n<strong>解法</strong>：如果你不能容忍这个概率（极低），请看下文的 RedLock，或者转投 Zookeeper。对于 99% 的业务，我们选择<strong>接受</strong>这个风险。</p>\n<hr />\n<h2 id=\"五redlock-的爱恨情仇\">五、RedLock 的爱恨情仇</h2>\n<p>有些面试官特别喜欢问 RedLock，但在实际工作中，它是一个让人爱恨交加的存在。</p>\n<h3 id=\"1-它是为了解决什么\">1. 它是为了解决什么？</h3>\n<p>解决 Redis 主从集群在 Failover（故障转移）时可能丢锁的问题。</p>\n<h3 id=\"2-怎么用\">2. 怎么用？</h3>\n<p>你需要准备 <strong>3个或5个</strong> 完全独立的 Redis 实例（不是 Cluster，不是 Sentinel，就是干干净净的单实例）。</p>\n<pre><code class=\"language-java\">RLock lock1 = redissonInstance1.getLock(\"lock\");\nRLock lock2 = redissonInstance2.getLock(\"lock\");\nRLock lock3 = redissonInstance3.getLock(\"lock\");\n\n// 创建红锁\nRedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);\n\ntry {\n    // 同时向 3个 Redis 申请锁\n    // 只要有 &gt; 1.5个 (即2个) 申请成功，就算赢\n    lock.lock();\n    // 业务逻辑\n} finally {\n    lock.unlock();\n}\n</code></pre>\n<h3 id=\"3-灵魂拷问值得吗\">3. 灵魂拷问：值得吗？</h3>\n<p>我的看法是：<strong>不值得</strong>。</p>\n<ul>\n<li><strong>运维成本飙升</strong>：为了个锁，我要多维护好几个独立的 Redis？</li>\n<li><strong>性能打折</strong>：串行或者并发去多个节点请求，网络开销大。</li>\n<li><strong>并非绝对安全</strong>：Martin Kleppmann 指出，如果发生 STW（Stop-The-World）GC，或者时钟发生跳跃，RedLock 依然可能失效。</li>\n</ul>\n<p><strong>建议</strong>：<br />\n如果你在做银行核心账务系统，请用 <strong>Zookeeper</strong> 或 <strong>Etcd</strong>。<br />\n除此之外的 99% 的场景，<strong>Redisson 配合主从集群</strong> 已经足够优秀了。</p>\n<hr />\n<blockquote>\n<p><strong>结语</strong></p>\n<p>很多时候，我们在技术选型时容易陷入\"既要又要\"的怪圈。但软件工程的本质，就是<strong>权衡</strong>（Trade-off）。</p>\n<p><strong>Redisson</strong> 不是神，它只是一把被打磨得足够锋利的刀。它不能解决所有的一致性问题，但它在<strong>易用性</strong>、<strong>性能</strong>和<strong>可靠性</strong>之间找到了一个极佳的平衡点。</p>\n<p>希望这篇文章能帮你不仅\"会用\"锁，更能\"懂\"锁。愿你的系统在洪峰流量下，依然稳如泰山；愿你的代码，既有逻辑的骨架，又有温度的血肉。、</p>\n</blockquote>\n<hr />\n<blockquote>\n<p>文章的最后，想和你多聊两句。</p>\n<p>技术之路，常常是热闹与孤独并存。那些深夜的调试、灵光一闪的方案、还有踩坑爬起后的顿悟，如果能有人一起聊聊，该多好。</p>\n<p>为此，我建了一个小花园——我的微信公众号「<strong>[努力的小郑]</strong>」。</p>\n<p>这里没有高深莫测的理论堆砌，只有我对后端开发、系统设计和工程实践的持续思考与沉淀。它更像我的<strong>数字笔记本</strong>，记录着那些值得被记住的解决方案和思维火花。</p>\n<p>如果你觉得今天的文章还有一点启发，或者单纯想找一个同行者偶尔聊聊技术、谈谈思考，那么，欢迎你来坐坐。<br />\n<img alt=\"85f114bceb12e933bb817ec5fecdfef7\" class=\"lazyload\" /></p>\n<p>愿你前行路上，总有代码可写，有梦可追，也有灯火可亲。</p>\n</blockquote>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 11:49</span>&nbsp;\n<a href=\"https://www.cnblogs.com/xzqcsj\">一旅人</a>&nbsp;\n阅读(<span id=\"post_view_count\">22</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    },
    {
      "title": "kubectl top 没数据：一次从 metrics-server 追到 kubelet feature gate 的排查（OrbStack 2.0.5）",
      "link": "https://www.cnblogs.com/suknna/p/19573394",
      "published": "",
      "description": "<h1 class=\"postTitle\">\n                <a class=\"postTitle2 vertical-middle\" href=\"https://www.cnblogs.com/suknna/p/19573394\" id=\"cb_post_title_url\" title=\"发布于 2026-02-04 11:44\">\n    <span>kubectl top 没数据：一次从 metrics-server 追到 kubelet feature gate 的排查（OrbStack 2.0.5）</span>\n    \n\n</a>\n\n            </h1>\n            <div class=\"clear\"></div>\n            <div class=\"postBody\">\n                <div class=\"blogpost-body cnblogs-markdown\" id=\"cnblogs_post_body\">\n<p>日期：2026-02-04</p>\n<p>环境信息：</p>\n<ul>\n<li>OrbStack：2.0.5 (19905)</li>\n<li>kubectl：v1.32.7</li>\n<li>kube-apiserver / kubelet（集群）：v1.33.5+orb1</li>\n</ul>\n<ol>\n<li>问题出现：<code>kubectl top</code> 失灵</li>\n</ol>\n<hr />\n<p>我想在本地集群里看一下 Pod 的资源使用量，按惯例跑：</p>\n<pre><code class=\"language-bash\">kubectl top pod -A\n</code></pre>\n<p>这一步如果正常，应该能看到每个 Pod 的 CPU(cores)/MEMORY(bytes)。</p>\n<p>但现实是：<code>top</code> 没有指标可用（典型表现是无数据或 Metrics not available 之类的提示）。直觉告诉我：metrics-server 可能没装好。</p>\n<ol start=\"2\">\n<li>先不要动 metrics-server：先把链路理清楚</li>\n</ol>\n<hr />\n<p><code>kubectl top</code> 的数据来源是 <code>metrics.k8s.io</code> API，而 <code>metrics.k8s.io</code> 是 metrics-server 聚合出来的。metrics-server 本身不采集，它去各节点 kubelet 拉指标。</p>\n<p>所以链路是这样的：</p>\n<ul>\n<li>kubelet 暴露 Summary API：<code>/stats/summary</code></li>\n<li>metrics-server 抓 Summary API（或相关 kubelet stats）</li>\n<li>metrics-server 生成 <code>metrics.k8s.io</code></li>\n<li><code>kubectl top</code> 读取 <code>metrics.k8s.io</code></li>\n</ul>\n<p>结论：排查时必须先确认 kubelet 有没有“原材料”。</p>\n<ol start=\"3\">\n<li>metrics 层排查：API 还在，但可能只是空转</li>\n</ol>\n<hr />\n<p>我先直接看 <code>metrics.k8s.io</code> 是否返回内容：</p>\n<pre><code class=\"language-bash\">kubectl get --raw \"/apis/metrics.k8s.io/v1beta1/pods\" | head\n</code></pre>\n<p>当它返回 <code>PodMetricsList</code> 时，说明 metrics-server 至少活着、API 路由也通。<br />\n但这不代表数据就完整，因为 metrics-server 可能只是拿到了一部分，或者 kubelet 根本没吐 Pod/Container stats。</p>\n<p>接着看 metrics-server 日志（用于确认它是否在抱怨 kubelet）：</p>\n<pre><code class=\"language-bash\">kubectl -n kube-system logs deploy/metrics-server --tail=200\n</code></pre>\n<p>Kubernetes 社区里有一类非常典型的错误：metrics-server 抓 kubelet 的 <code>/stats/summary</code> 时得到 500，然后 <code>kubectl top</code> 没数据。[1]</p>\n<ol start=\"4\">\n<li>kubelet 层排查：Summary API 才是真相</li>\n</ol>\n<hr />\n<p>既然 metrics-server 只是中间商，那就绕过它，直接查 kubelet Summary API。</p>\n<p>先取一个 node 名：</p>\n<pre><code class=\"language-bash\">NODE=\"$(kubectl get node -o name | head -n1 | cut -d/ -f2)\"\n</code></pre>\n<p>然后通过 apiserver proxy 请求：</p>\n<pre><code class=\"language-bash\">kubectl get --raw \"/api/v1/nodes/$NODE/proxy/stats/summary\" | head\n</code></pre>\n<p>关键点在 <code>pods</code> 字段。我用 <code>rg</code> 快速定位：</p>\n<pre><code class=\"language-bash\">kubectl get --raw \"/api/v1/nodes/$NODE/proxy/stats/summary\" | rg '\"pods\"' -n\n</code></pre>\n<p>当时的核心现象是：Summary 里 Pod/Container 级别统计不对劲（常见就是 <code>pods</code> 为空或缺失）。<br />\n这就解释了为什么 <code>kubectl top</code> 没法工作：上游根本拿不到 Pod 的资源使用量。</p>\n<ol start=\"5\">\n<li>查 GitHub：OrbStack issue 给了答案</li>\n</ol>\n<hr />\n<p>到这一步，问题从“metrics-server 配置”变成了“kubelet 的 stats 从哪里来”。</p>\n<p>继续搜索后，找到了 OrbStack 的相关 issue：</p>\n<p><a href=\"https://github.com/orbstack/orbstack/issues/2143\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/orbstack/orbstack/issues/2143</a></p>\n<p>里面提到：需要在 kubelet 配置中开启一个 feature gate：</p>\n<pre><code class=\"language-yaml\">featureGates:\n  PodAndContainerStatsFromCRI: true\n</code></pre>\n<ol start=\"6\">\n<li>修复：在 kubelet 配置里开启 <code>PodAndContainerStatsFromCRI</code></li>\n</ol>\n<hr />\n<p>我在 OrbStack 的 Kubernetes 设置页（Kubelet Configuration）里加上：</p>\n<pre><code class=\"language-yaml\">apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nfeatureGates:\n  PodAndContainerStatsFromCRI: true\n</code></pre>\n<p>应用并重启集群后，再验证：</p>\n<pre><code class=\"language-bash\">kubectl top pod -A\nkubectl get --raw \"/apis/metrics.k8s.io/v1beta1/pods\" | head\nkubectl get --raw \"/api/v1/nodes/$NODE/proxy/stats/summary\" | rg '\"pods\"' -n\n</code></pre>\n<p>这次 <code>kubectl top</code> 正常输出，<code>metrics.k8s.io</code> 也能看到容器级的 <code>usage.cpu</code> / <code>usage.memory</code>。</p>\n<ol start=\"7\">\n<li>这个配置的作用：为什么加了它就好？</li>\n</ol>\n<hr />\n<p>Kubernetes 官方文档对这个开关的解释很明确：</p>\n<ul>\n<li>默认情况下，kubelet 使用内嵌 cAdvisor 获取节点概要指标数据</li>\n<li>如果启用 <code>PodAndContainerStatsFromCRI</code>，并且容器运行时支持通过 CRI 访问统计信息，那么 kubelet 会改为通过 CRI 获取 Pod/容器级别指标，而不是从 cAdvisor 获取。[2]</li>\n</ul>\n<p>把它翻译成一句话就是：</p>\n<p>让 kubelet “别自己猜”，而是“直接问容器运行时（CRI）你到底用了多少 CPU/内存”。</p>\n<p>在 OrbStack 这种“本地虚拟化封装很深”的环境里，cAdvisor 的观测路径可能不完整；改走 CRI stats 之后，kubelet 能拿到更可靠的 Pod/Container 统计，于是 Summary API 变完整，metrics-server 才有东西可聚合，<code>kubectl top</code> 才能恢复。</p>\n<ol start=\"8\">\n<li>收获：以后遇到 <code>kubectl top</code> 问题怎么最快定位？</li>\n</ol>\n<hr />\n<p>我把排查顺序固定成三步，基本就不会走弯路：</p>\n<p>1）看聚合层：<code>metrics.k8s.io</code> 是否有数据</p>\n<pre><code class=\"language-bash\">kubectl get --raw \"/apis/metrics.k8s.io/v1beta1/pods\" | head\n</code></pre>\n<p>2）看源头：kubelet Summary API 的 <code>pods</code> 是否正常</p>\n<pre><code class=\"language-bash\">kubectl get --raw \"/api/v1/nodes/$NODE/proxy/stats/summary\" | rg '\"pods\"' -n\n</code></pre>\n<p>3）如果 Summary 的 pod stats 不正常，再去找“该发行版/环境”的已知问题<br />\n这次就是 OrbStack issue 直接给了 feature gate 的解法。</p>\n<ol start=\"9\">\n<li>延伸阅读</li>\n</ol>\n<hr />\n<ul>\n<li>\n<p>OrbStack issue（本次直接线索）：<code>orbstack/orbstack#2143</code><br />\n<a href=\"https://github.com/orbstack/orbstack/issues/2143\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/orbstack/orbstack/issues/2143</a></p>\n</li>\n<li>\n<p>Kubernetes 官方文档：Node metrics、Summary API、以及 <code>PodAndContainerStatsFromCRI</code> 的说明<br />\n<a href=\"https://kubernetes.io/zh-cn/docs/reference/instrumentation/node-metrics/\" rel=\"noopener nofollow\" target=\"_blank\">https://kubernetes.io/zh-cn/docs/reference/instrumentation/node-metrics/</a>  [2]</p>\n</li>\n<li>\n<p>Kubernetes issue：metrics-server 抓 <code>/stats/summary</code> 返回 500、<code>kubectl top</code> 无数据的典型案例（用于对照症状）<br />\n<a href=\"https://github.com/kubernetes/kubernetes/issues/111276\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/kubernetes/kubernetes/issues/111276</a>  [1]</p>\n</li>\n</ul>\n<h2 id=\"参考\">参考</h2>\n<p>[1] <a href=\"https://github.com/kubernetes/kubernetes/issues/111276\" rel=\"noopener nofollow\" target=\"_blank\">https://github.com/kubernetes/kubernetes/issues/111276</a><br />\n[2] <a href=\"https://kubernetes.io/zh-cn/docs/reference/instrumentation/node-metrics/\" rel=\"noopener nofollow\" target=\"_blank\">https://kubernetes.io/zh-cn/docs/reference/instrumentation/node-metrics/</a></p>\n\n\n</div>\n<div class=\"clear\"></div>\n\n            </div>\n            <div class=\"postDesc\">posted @ \n<span id=\"post-date\">2026-02-04 11:44</span>&nbsp;\n<a href=\"https://www.cnblogs.com/suknna\">suknna</a>&nbsp;\n阅读(<span id=\"post_view_count\">13</span>)&nbsp;\n评论(<span id=\"post_comment_count\">0</span>)&nbsp;\n&nbsp;\n<a href=\"\">收藏</a>&nbsp;\n<a href=\"\">举报</a>\n</div>"
    }
  ]
}